[
  {
    "id": "arXiv:2208.07893",
    "title": "On the Convergence of Multi-Server Federated Learning with Overlapping  Area",
    "abstract": "Multi-server Federated learning (FL) has been considered as a promising\nsolution to address the limited communication resource problem of single-server\nFL. We consider a typical multi-server FL architecture, where the coverage\nareas of regional servers may overlap. The key point of this architecture is\nthat the clients located in the overlapping areas update their local models\nbased on the average model of all accessible regional models, which enables\nindirect model sharing among different regional servers. Due to the complicated\nnetwork topology, the convergence analysis is much more challenging than\nsingle-server FL. In this paper, we firstly propose a novel MS-FedAvg algorithm\nfor this multi-server FL architecture and analyze its convergence on non-iid\ndatasets for general non-convex settings. Since the number of clients located\nin each regional server is much less than in single-server FL, the bandwidth of\neach client should be large enough to successfully communicate training models\nwith the server, which indicates that full client participation can work in\nmulti-server FL. Also, we provide the convergence analysis of the partial\nclient participation scheme and develop a new biased partial participation\nstrategy to further accelerate convergence. Our results indicate that the\nconvergence results highly depend on the ratio of the number of clients in each\narea type to the total number of clients in all three strategies. The extensive\nexperiments show remarkable performance and support our theoretical results.",
    "descriptor": "",
    "authors": [
      "Zhe Qu",
      "Xingyu Li",
      "Jie Xu",
      "Bo Tang",
      "Zhuo Lu",
      "Yao Liu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.07893"
  },
  {
    "id": "arXiv:2208.07903",
    "title": "Casual Indoor HDR Radiance Capture from Omnidirectional Images",
    "abstract": "We present PanoHDR-NeRF, a novel pipeline to casually capture a plausible\nfull HDR radiance field of a large indoor scene without elaborate setups or\ncomplex capture protocols. First, a user captures a low dynamic range (LDR)\nomnidirectional video of the scene by freely waving an off-the-shelf camera\naround the scene. Then, an LDR2HDR network uplifts the captured LDR frames to\nHDR, subsequently used to train a tailored NeRF++ model. The resulting\nPanoHDR-NeRF pipeline can estimate full HDR panoramas from any location of the\nscene. Through experiments on a novel test dataset of a variety of real scenes\nwith the ground truth HDR radiance captured at locations not seen during\ntraining, we show that PanoHDR-NeRF predicts plausible radiance from any scene\npoint. We also show that the HDR images produced by PanoHDR-NeRF can synthesize\ncorrect lighting effects, enabling the augmentation of indoor scenes with\nsynthetic objects that are lit correctly.",
    "descriptor": "",
    "authors": [
      "Pulkit Gera",
      "Mohammad Reza Karimi Dastjerdi",
      "Charles Renaud",
      "P. J. Narayanan",
      "Jean-Fran\u00e7ois Lalonde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07903"
  },
  {
    "id": "arXiv:2208.07904",
    "title": "Sturm's Theorem with Endpoints",
    "abstract": "Sturm's Theorem is a fundamental 19th century result relating the number of\nreal roots of a polynomial $f$ in an interval to the number of sign\nalternations in a sequence of polynomial division-like calculations. We provide\na short direct proof of Sturm's Theorem, including the numerically vexing case\n(ignored in many published accounts) where an interval endpoint is a root of\n$f$.",
    "descriptor": "\nComments: 4 pages. A software implementation can be found in algorithm vtkPolynomialSolversUnivariate , within the VTK (Visualization Toolkit) software package\n",
    "authors": [
      "Philippe P\u00e9bay",
      "J. Maurice Rojas",
      "David C. Thompson"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2208.07904"
  },
  {
    "id": "arXiv:2208.07905",
    "title": "Reshi: Recommending Resources for Scientific Workflow Tasks on  Heterogeneous Infrastructures",
    "abstract": "Scientific workflows typically comprise a multitude of different processing\nsteps which often are executed in parallel on different partitions of the input\ndata. These executions, in turn, must be scheduled on the compute nodes of the\ncomputational infrastructure at hand. This assignment is complicated by the\nfacts that (a) tasks typically have highly heterogeneous resource requirements\nand (b) in many infrastructures, compute nodes offer highly heterogeneous\nresources. In consequence, predictions of the runtime of a given task on a\ngiven node, as required by many scheduling algorithms, are often rather\nimprecise, which can lead to sub-optimal scheduling decisions.\nWe propose Reshi, a method for recommending task-node assignments during\nworkflow execution that can cope with heterogeneous tasks and heterogeneous\nnodes. Reshi approaches the problem as a regression task, where task-node pairs\nare modeled as feature vectors over the results of dedicated micro benchmarks\nand past task executions. Based on these features, Reshi trains a regression\ntree model to rank and recommend nodes for each ready-to-run task, which can be\nused as input to a scheduler. For our evaluation, we benchmarked 27 AWS machine\ntypes using three representative workflows. We compare Reshi's recommendations\nwith three state-of-the-art schedulers. Our evaluation shows that Reshi\noutperforms HEFT by a mean makespan reduction of 7.18% and 18.01% assuming a\nmean task runtime prediction error of 15%.",
    "descriptor": "\nComments: Paper accepted in 41st IEEE -- International Performance Computing and Communications Conference (IPCCC 2022)\n",
    "authors": [
      "Jonathan Bader",
      "Fabian Lehmann",
      "Alexander Groth",
      "Lauritz Thamsen",
      "Dominik Scheinert",
      "Jonathan Will",
      "Ulf Leser",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.07905"
  },
  {
    "id": "arXiv:2208.07912",
    "title": "FOLD-SE: Scalable Explainable AI",
    "abstract": "FOLD-R++ is a highly efficient and explainable rule-based machine learning\nalgorithm for binary classification tasks. It generates a stratified normal\nlogic program as an (explainable) trained model. We present an improvement over\nthe FOLD-R++ algorithm, termed FOLD-SE, that provides scalable explainability\n(SE) while inheriting all the merits of FOLD-R++. Scalable explainability means\nthat regardless of the size of the dataset, the number of learned rules and\nlearned literals stay small and, hence, understandable by human beings, while\nmaintaining good performance in classification. FOLD-SE is competitive in\nperformance with state-of-the-art algorithms such as XGBoost and Multi-Layer\nPerceptrons (MLP). However, unlike XGBoost and MLP, the FOLD-SE algorithm\ngenerates a model with scalable explainability. The FOLD-SE algorithm\noutperforms FOLD-R++ and RIPPER algorithms in efficiency, performance, and\nexplainability, especially for large datasets. The FOLD-RM algorithm is an\nextension of FOLD-R++ for multi-class classification tasks. An improved FOLD-RM\nalgorithm built upon FOLD-SE is also presented.",
    "descriptor": "",
    "authors": [
      "Huaduo Wang",
      "Gopal Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.07912"
  },
  {
    "id": "arXiv:2208.07914",
    "title": "PD-MORL: Preference-Driven Multi-Objective Reinforcement Learning  Algorithm",
    "abstract": "Many real-world problems involve multiple, possibly conflicting, objectives.\nMulti-objective reinforcement learning (MORL) approaches have emerged to tackle\nthese problems by maximizing a joint objective function weighted by a\npreference vector. These approaches find fixed customized policies\ncorresponding to preference vectors specified during training. However, the\ndesign constraints and objectives typically change dynamically in real-life\nscenarios. Furthermore, storing a policy for each potential preference is not\nscalable. Hence, obtaining a set of Pareto front solutions for the entire\npreference space in a given domain with a single training is critical. To this\nend, we propose a novel MORL algorithm that trains a single universal network\nto cover the entire preference space. The proposed approach, Preference-Driven\nMORL (PD-MORL), utilizes the preferences as guidance to update the network\nparameters. After demonstrating PD-MORL using classical Deep Sea Treasure and\nFruit Tree Navigation benchmarks, we evaluate its performance on challenging\nmulti-objective continuous control tasks.",
    "descriptor": "\nComments: 24 pages, 9 Figures, 9 Tables\n",
    "authors": [
      "Toygun Basaklar",
      "Suat Gumussoy",
      "Umit Y. Ogras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.07914"
  },
  {
    "id": "arXiv:2208.07918",
    "title": "Ex-Ante Assessment of Discrimination in Dataset",
    "abstract": "Data owners face increasing liability for how the use of their data could\nharm under-priviliged communities. Stakeholders would like to identify the\ncharacteristics of data that lead to algorithms being biased against any\nparticular demographic groups, for example, defined by their race, gender, age,\nand/or religion. Specifically, we are interested in identifying subsets of the\nfeature space where the ground truth response function from features to\nobserved outcomes differs across demographic groups. To this end, we propose\nFORESEE, a FORESt of decision trEEs algorithm, which generates a score that\ncaptures how likely an individual's response varies with sensitive attributes.\nEmpirically, we find that our approach allows us to identify the individuals\nwho are most likely to be misclassified by several classifiers, including\nRandom Forest, Logistic Regression, Support Vector Machine, and k-Nearest\nNeighbors. The advantage of our approach is that it allows stakeholders to\ncharacterize risky samples that may contribute to discrimination, as well as,\nuse the FORESEE to estimate the risk of upcoming samples.",
    "descriptor": "",
    "authors": [
      "Jonathan Vasquez",
      "Xavier Gitiaux",
      "Huzefa Rangwala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.07918"
  },
  {
    "id": "arXiv:2208.07922",
    "title": "FedPerm: Private and Robust Federated Learning by Parameter Permutation",
    "abstract": "Federated Learning (FL) is a distributed learning paradigm that enables\nmutually untrusting clients to collaboratively train a common machine learning\nmodel. Client data privacy is paramount in FL. At the same time, the model must\nbe protected from poisoning attacks from adversarial clients. Existing\nsolutions address these two problems in isolation. We present FedPerm, a new FL\nalgorithm that addresses both these problems by combining a novel intra-model\nparameter shuffling technique that amplifies data privacy, with Private\nInformation Retrieval (PIR) based techniques that permit cryptographic\naggregation of clients' model updates. The combination of these techniques\nfurther helps the federation server constrain parameter updates from clients so\nas to curtail effects of model poisoning attacks by adversarial clients. We\nfurther present FedPerm's unique hyperparameters that can be used effectively\nto trade off computation overheads with model utility. Our empirical evaluation\non the MNIST dataset demonstrates FedPerm's effectiveness over existing\nDifferential Privacy (DP) enforcement solutions in FL.",
    "descriptor": "",
    "authors": [
      "Hamid Mozaffari",
      "Virendra J. Marathe",
      "Dave Dice"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.07922"
  },
  {
    "id": "arXiv:2208.07928",
    "title": "Business Process Simulation with Differentiated Resources: Does it Make  a Difference?",
    "abstract": "Business process simulation is a versatile technique to predict the impact of\none or more changes on the performance of a process. Mainstream approaches in\nthis space suffer from various limitations, some stemming from the fact that\nthey treat resources as undifferentiated entities grouped into resource pools.\nThese approaches assume that all resources in a pool have the same performance\nand share the same availability calendars. Previous studies have acknowledged\nthese assumptions, without quantifying their impact on simulation model\naccuracy. This paper addresses this gap in the context of simulation models\nautomatically discovered from event logs. The paper proposes a simulation\napproach and a method for discovering simulation models, wherein each resource\nis treated as an individual entity, with its own performance and availability\ncalendar. An evaluation shows that simulation models with differentiated\nresources more closely replicate the distributions of cycle times and the work\nrhythm in a process than models with undifferentiated resources.",
    "descriptor": "\nComments: Published in the Proceedings of the International Conference on Business Process Management (BPM'2022)\n",
    "authors": [
      "Orlenys Lopez-Pintado",
      "Marlon Dumas"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2208.07928"
  },
  {
    "id": "arXiv:2208.07929",
    "title": "ViT-ReT: Vision and Recurrent Transformer Neural Networks for Human  Activity Recognition in Videos",
    "abstract": "Human activity recognition is an emerging and important area in computer\nvision which seeks to determine the activity an individual or group of\nindividuals are performing. The applications of this field ranges from\ngenerating highlight videos in sports, to intelligent surveillance and gesture\nrecognition. Most activity recognition systems rely on a combination of\nconvolutional neural networks (CNNs) to perform feature extraction from the\ndata and recurrent neural networks (RNNs) to determine the time dependent\nnature of the data. This paper proposes and designs two transformer neural\nnetworks for human activity recognition: a recurrent transformer (ReT), a\nspecialized neural network used to make predictions on sequences of data, as\nwell as a vision transformer (ViT), a transformer optimized for extracting\nsalient features from images, to improve speed and scalability of activity\nrecognition. We have provided an extensive comparison of the proposed\ntransformer neural networks with the contemporary CNN and RNN-based human\nactivity recognition models in terms of speed and accuracy.",
    "descriptor": "",
    "authors": [
      "James Wensel",
      "Hayat Ullah",
      "Arslan Munir",
      "Erik Blasch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07929"
  },
  {
    "id": "arXiv:2208.07934",
    "title": "Measuring Statistical Dependencies via Maximum Norm and Characteristic  Functions",
    "abstract": "In this paper, we focus on the problem of statistical dependence estimation\nusing characteristic functions. We propose a statistical dependence measure,\nbased on the maximum-norm of the difference between joint and product-marginal\ncharacteristic functions. The proposed measure can detect arbitrary statistical\ndependence between two random vectors of possibly different dimensions, is\ndifferentiable, and easily integrable into modern machine learning and deep\nlearning pipelines. We also conduct experiments both with simulated and real\ndata. Our simulations show, that the proposed method can measure statistical\ndependencies in high-dimensional, non-linear data, and is less affected by the\ncurse of dimensionality, compared to the previous work in this line of\nresearch. The experiments with real data demonstrate the potential\napplicability of our statistical measure for two different empirical inference\nscenarios, showing statistically significant improvement in the performance\ncharacteristics when applied for supervised feature extraction and deep neural\nnetwork regularization. In addition, we provide a link to the accompanying\nopen-source repository https://bit.ly/3d4ch5I.",
    "descriptor": "",
    "authors": [
      "Povilas Daniu\u0161is",
      "Shubham Juneja",
      "Lukas Kuzma",
      "Virginijus Marcinkevi\u010dius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.07934"
  },
  {
    "id": "arXiv:2208.07935",
    "title": "Conservative Bayesian Assessment of Software-based Systems Exhibiting  Correlated Executions",
    "abstract": "This paper presents Bayesian methods that support conservative dependability\nclaims for a software-based safety-critical system, particularly when evidence\nsuggests the software's executions are not statistically independent. We\nformalise informal notions of \"doubting\" that the software's executions are\nindependent, and incorporate such doubts into dependability assessments. We\nstudy the extent to which an assumption of independent executions can undermine\nconservatism in assessments, and identify conditions under which this impact\nis, or is not, significant. These techniques -- novel extensions of\nconservative Bayesian inference (CBI) methods -- are illustrated in two\napplications: the assessment of a nuclear power-plant safety protection system\nand the assessment of autonomous vehicle (AV) safety. Our analyses reveals: 1)\nthe required amount of confidence an assessor should possess before subjecting\na system to operational testing. Otherwise, such testing is shown to be futile\n-- no amount of favourable operational testing evidence will increase one's\nconfidence in the system being sufficiently dependable; 2) the independence\nassumption supports optimistic claims in certain situations, and conservative\nclaims in other situations; 3) in some scenarios, upon observing a system\noperate without failure, an assessor's confidence in the system being\nsufficiently dependable is less than it would be had the system exhibited some\nfailures; 4) posterior confidence in a system being sufficiently dependable is\nvery sensitive to failures -- each additional failure means significantly more\noperational testing evidence is required, in order to support a dependability\nclaim.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Kizito Salako",
      "Xingyu Zhao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.07935"
  },
  {
    "id": "arXiv:2208.07943",
    "title": "TRoVE: Transforming Road Scene Datasets into Photorealistic Virtual  Environments",
    "abstract": "High-quality structured data with rich annotations are critical components in\nintelligent vehicle systems dealing with road scenes. However, data curation\nand annotation require intensive investments and yield low-diversity scenarios.\nThe recently growing interest in synthetic data raises questions about the\nscope of improvement in such systems and the amount of manual work still\nrequired to produce high volumes and variations of simulated data. This work\nproposes a synthetic data generation pipeline that utilizes existing datasets,\nlike nuScenes, to address the difficulties and domain-gaps present in simulated\ndatasets. We show that using annotations and visual cues from existing\ndatasets, we can facilitate automated multi-modal data generation, mimicking\nreal scene properties with high-fidelity, along with mechanisms to diversify\nsamples in a physically meaningful way. We demonstrate improvements in mIoU\nmetrics by presenting qualitative and quantitative experiments with real and\nsynthetic data for semantic segmentation on the Cityscapes and KITTI-STEP\ndatasets. All relevant code and data is released on github\n(https://github.com/shubham1810/trove_toolkit).",
    "descriptor": "\nComments: 18 pages, 5 figures, Accepted in European Conference on Computer Vision (ECCV 2022)\n",
    "authors": [
      "Shubham Dokania",
      "Anbumani Subramanian",
      "Manmohan Chandraker",
      "C. V. Jawahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07943"
  },
  {
    "id": "arXiv:2208.07949",
    "title": "Riemannian Diffusion Models",
    "abstract": "Diffusion models are recent state-of-the-art methods for image generation and\nlikelihood estimation. In this work, we generalize continuous-time diffusion\nmodels to arbitrary Riemannian manifolds and derive a variational framework for\nlikelihood estimation. Computationally, we propose new methods for computing\nthe Riemannian divergence which is needed in the likelihood estimation.\nMoreover, in generalizing the Euclidean case, we prove that maximizing this\nvariational lower-bound is equivalent to Riemannian score matching.\nEmpirically, we demonstrate the expressive power of Riemannian diffusion models\non a wide spectrum of smooth manifolds, such as spheres, tori, hyperboloids,\nand orthogonal groups. Our proposed method achieves new state-of-the-art\nlikelihoods on all benchmarks.",
    "descriptor": "",
    "authors": [
      "Chin-Wei Huang",
      "Milad Aghajohari",
      "Avishek Joey Bose",
      "Prakash Panangaden",
      "Aaron Courville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.07949"
  },
  {
    "id": "arXiv:2208.07951",
    "title": "On the generalization of learning algorithms that do not converge",
    "abstract": "Generalization analyses of deep learning typically assume that the training\nconverges to a fixed point. But, recent results indicate that in practice, the\nweights of deep neural networks optimized with stochastic gradient descent\noften oscillate indefinitely. To reduce this discrepancy between theory and\npractice, this paper focuses on the generalization of neural networks whose\ntraining dynamics do not necessarily converge to fixed points. Our main\ncontribution is to propose a notion of statistical algorithmic stability (SAS)\nthat extends classical algorithmic stability to non-convergent algorithms and\nto study its connection to generalization. This ergodic-theoretic approach\nleads to new insights when compared to the traditional optimization and\nlearning theory perspectives. We prove that the stability of the\ntime-asymptotic behavior of a learning algorithm relates to its generalization\nand empirically demonstrate how loss dynamics can provide clues to\ngeneralization performance. Our findings provide evidence that networks that\n\"train stably generalize better\" even when the training continues indefinitely\nand the weights do not converge.",
    "descriptor": "\nComments: 27 pages, under review\n",
    "authors": [
      "Nisha Chandramoorthy",
      "Andreas Loukas",
      "Khashayar Gatmiry",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.07951"
  },
  {
    "id": "arXiv:2208.07952",
    "title": "Generative Thermal Design Through Boundary Representation and  Multi-Agent Cooperative Environment",
    "abstract": "Generative design has been growing across the design community as a viable\nmethod for design space exploration. Thermal design is more complex than\nmechanical or aerodynamic design because of the additional convection-diffusion\nequation and its pertinent boundary interaction. We present a generative\nthermal design using cooperative multi-agent deep reinforcement learning and\ncontinuous geometric representation of the fluid and solid domain. The proposed\nframework consists of a pre-trained neural network surrogate model as an\nenvironment to predict heat transfer and pressure drop of the generated\ngeometries. The design space is parameterized by composite Bezier curve to\nsolve multiple fin shape optimization. We show that our multi-agent framework\ncan learn the policy for design strategy using multi-objective reward without\nthe need for shape derivation or differentiable objective function.",
    "descriptor": "",
    "authors": [
      "Hadi Keramati",
      "Feridun Hamdullahpur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geometric Topology (math.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.07952"
  },
  {
    "id": "arXiv:2208.07955",
    "title": "The least-used key selection method for information retrieval in  large-scale Cloud-based service repositories",
    "abstract": "As the number of devices connected to the Internet of Things (IoT) increases\nsignificantly, it leads to an exponential growth in the number of services that\nneed to be processed and stored in the large-scale Cloud-based service\nrepositories. An efficient service indexing model is critical for service\nretrieval and management of large-scale Cloud-based service repositories. The\nmultilevel index model is the state-of-art service indexing model in recent\nyears to improve service discovery and combination. This paper aims to optimize\nthe model to consider the impact of unequal appearing probability of service\nretrieval request parameters and service input parameters on service retrieval\nand service addition operations. The least-used key selection method has been\nproposed to narrow the search scope of service retrieval and reduce its time.\nThe experimental results show that the proposed least-used key selection method\nimproves the service retrieval efficiency significantly compared with the\ndesignated key selection method in the case of the unequal appearing\nprobability of parameters in service retrieval requests under three indexing\nmodels.",
    "descriptor": "",
    "authors": [
      "Jiayan Gu",
      "Ashiq Anjum",
      "Yan Wu",
      "Lu Liu",
      "John Panneerselvam",
      "Yao Lu",
      "Bo Yuan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.07955"
  },
  {
    "id": "arXiv:2208.07960",
    "title": "Advancing Human-AI Complementarity: The Impact of User Expertise and  Algorithmic Tuning on Joint Decision Making",
    "abstract": "Human-AI collaboration for decision-making strives to achieve team\nperformance that exceeds the performance of humans or AI alone. However, many\nfactors can impact success of Human-AI teams, including a user's domain\nexpertise, mental models of an AI system, trust in recommendations, and more.\nThis work examines users' interaction with three simulated algorithmic models,\nall with similar accuracy but different tuning on their true positive and true\nnegative rates. Our study examined user performance in a non-trivial blood\nvessel labeling task where participants indicated whether a given blood vessel\nwas flowing or stalled.\nOur results show that while recommendations from an AI-Assistant can aid user\ndecision making, factors such as users' baseline performance relative to the AI\nand complementary tuning of AI error types significantly impact overall team\nperformance. Novice users improved, but not to the accuracy level of the AI.\nHighly proficient users were generally able to discern when they should follow\nthe AI recommendation and typically maintained or improved their performance.\nMid-performers, who had a similar level of accuracy to the AI, were most\nvariable in terms of whether the AI recommendations helped or hurt their\nperformance. In addition, we found that users' perception of the AI's\nperformance relative on their own also had a significant impact on whether\ntheir accuracy improved when given AI recommendations. This work provides\ninsights on the complexity of factors related to Human-AI collaboration and\nprovides recommendations on how to develop human-centered AI algorithms to\ncomplement users in decision-making tasks.",
    "descriptor": "\nComments: Paper accepted and to be published in Transactions on Computer Human Interaction\n",
    "authors": [
      "Kori Inkpen",
      "Shreya Chappidi",
      "Keri Mallari",
      "Besmira Nushi",
      "Divya Ramesh",
      "Pietro Michelucci",
      "Vani Mandava",
      "Libu\u0161e Hannah Vep\u0159ek",
      "Gabrielle Quinn"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.07960"
  },
  {
    "id": "arXiv:2208.07965",
    "title": "Improving the Cybersecurity of Critical National Infrastructure using  Modelling and Simulation",
    "abstract": "The UK Critical National Infrastructure is critically dependent on digital\ntechnologies that provide communications, monitoring, control, and\ndecision-support functionalities. Digital technologies are progressively\nenhancing efficiency, reliability, and availability of infrastructure, and\nenabling new benefits not previously available. These benefits can introduce\nvulnerabilities through the connectivity enabled by the digital systems, thus,\nmaking it easier for would-be attackers, who frequently use socio-technical\napproaches, exploiting humans-in-the-loop to break in and sabotage an\norganization. Therefore, policies and strategies that minimize and manage risks\nmust include an understanding of operator and corporate behaviors, as well as\ntechnical elements and the interfaces between them and humans. Better security\nvia socio-technical security Modelling and Simulation can be achieved if backed\nby government effort, including appropriate policy interventions. Government,\nthrough its departments and agencies, can contribute by sign-posting and\nshaping the decision-making environment concerning cybersecurity M&S approaches\nand tools, showing how they can contribute to enhancing security in Modern\nCritical Infrastructure Systems.",
    "descriptor": "\nComments: 7 pages, 5 Figures, Policy Briefing\n",
    "authors": [
      "Uchenna D Ani",
      "Jeremy D McK Watson",
      "Nilufer Tuptuk",
      "Steve Hailes",
      "Madeline Carr",
      "Carsten Maple"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.07965"
  },
  {
    "id": "arXiv:2208.07968",
    "title": "Blind Users Accessing Their Training Images in Teachable Object  Recognizers",
    "abstract": "Iteration of training and evaluating a machine learning model is an important\nprocess to improve its performance. However, while teachable interfaces enable\nblind users to train and test an object recognizer with photos taken in their\ndistinctive environment, accessibility of training iteration and evaluation\nsteps has received little attention. Iteration assumes visual inspection of the\ntraining photos, which is inaccessible for blind users. We explore this\nchallenge through MyCam, a mobile app that incorporates automatically estimated\ndescriptors for non-visual access to the photos in the users' training sets. We\nexplore how blind participants (N=12) interact with MyCam and the descriptors\nthrough an evaluation study in their homes. We demonstrate that the real-time\nphoto-level descriptors enabled blind users to reduce photos with cropped\nobjects, and that participants could add more variations by iterating through\nand accessing the quality of their training sets. Also, Participants found the\napp simple to use indicating that they could effectively train it and that the\ndescriptors were useful. However, subjective responses were not reflected in\nthe performance of their models, partially due to little variation in training\nand cluttered backgrounds.",
    "descriptor": "",
    "authors": [
      "Jonggi Hong",
      "Jaina Gandhi",
      "Ernest Essuah Mensah",
      "Ebrima H Jarjue",
      "Kyungjun Lee",
      "Hernisa Kacorri"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07968"
  },
  {
    "id": "arXiv:2208.07969",
    "title": "An optimal sensors-based simulation method for spatiotemporal event  detection",
    "abstract": "Human movements in urban areas are essential for understanding the\nhuman-environment interactions. However, activities and associated movements\nare full of uncertainties due to the complexity of a city. In this paper, we\npropose an optimal sensors-based simulation method for spatiotemporal event\ndetection using human activity signals derived from taxi trip data. A sensor\nhere is an abstract concept such that only the true observation data at the\nsensor location will be treated as known data for the simulation. Specifically,\nwe first identify the optimal number of sensors and their locations that have\nthe strongest correlation with the whole dataset. The observation data points\nfrom these sensors are then used to simulate a regular, uneventful scenario\nusing the Discrete Empirical Interpolation Method. By comparing the simulated\nand observation scenarios, events are extracted both spatially and temporally.\nWe apply this method in New York City with taxi trip records data. Results show\nthat this method is effective in detecting when and where events occur.",
    "descriptor": "",
    "authors": [
      "Yuqin Jiang",
      "Andrey A. Popov",
      "Zhenlong Li",
      "Michael E. Hodgson"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.07969"
  },
  {
    "id": "arXiv:2208.07974",
    "title": "NMPC-LBF: Nonlinear MPC with Learned Barrier Function for Decentralized  Safe Navigation of Multiple Robots in Unknown Environments",
    "abstract": "In this paper, we present a decentralized control approach based on a\nNonlinear Model Predictive Control (NMPC) method that employs barrier\ncertificates for safe navigation of multiple nonholonomic wheeled mobile robots\nin unknown environments with static and/or dynamic obstacles. This method\nincorporates a Learned Barrier Function (LBF) into the NMPC design in order to\nguarantee safe robot navigation, i.e., prevent robot collisions with other\nrobots and the obstacles. We refer to our proposed control approach as\nNMPC-LBF. Since each robot does not have a priori knowledge about the obstacles\nand other robots, we use a Deep Neural Network (DeepNN) running in real-time on\neach robot to learn the Barrier Function (BF) only from the robot's LiDAR and\nodometry measurements. The DeepNN is trained to learn the BF that separates\nsafe and unsafe regions. We implemented our proposed method on simulated and\nactual Turtlebot3 Burger robot(s) in different scenarios. The implementation\nresults show the effectiveness of the NMPC-LBF method at ensuring safe\nnavigation of the robots.",
    "descriptor": "",
    "authors": [
      "Amir Salimi Lafmejani",
      "Spring Berman",
      "Georgios Fainekos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.07974"
  },
  {
    "id": "arXiv:2208.07978",
    "title": "Resource-aware Federated Learning using Knowledge Extraction and  Multi-model Fusion",
    "abstract": "With increasing concern about user data privacy, federated learning (FL) has\nbeen developed as a unique training paradigm for training machine learning\nmodels on edge devices without access to sensitive data. Traditional FL and\nexisting methods directly employ aggregation methods on all edges of the same\nmodels and training devices for a cloud server. Although these methods protect\ndata privacy, they are not capable of model heterogeneity, even ignore the\nheterogeneous computing power, and incur steep communication costs. In this\npaper, we purpose a resource-aware FL to aggregate an ensemble of local\nknowledge extracted from edge models, instead of aggregating the weights of\neach local model, which is then distilled into a robust global knowledge as the\nserver model through knowledge distillation. The local model and the global\nknowledge are extracted into a tiny size knowledge network by deep mutual\nlearning. Such knowledge extraction allows the edge client to deploy a\nresource-aware model and perform multi-model knowledge fusion while maintaining\ncommunication efficiency and model heterogeneity. Empirical results show that\nour approach has significantly improved over existing FL algorithms in terms of\ncommunication cost and generalization performance in heterogeneous data and\nmodels. Our approach reduces the communication cost of VGG-11 by up to\n102$\\times$ and ResNet-32 by up to 30$\\times$ when training ResNet-20 as the\nknowledge network.",
    "descriptor": "",
    "authors": [
      "Sixing Yu",
      "Wei Qian",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.07978"
  },
  {
    "id": "arXiv:2208.07981",
    "title": "Tiny-HR: Towards an interpretable machine learning pipeline for heart  rate estimation on edge devices",
    "abstract": "The focus of this paper is a proof of concept, machine learning (ML) pipeline\nthat extracts heart rate from pressure sensor data acquired on low-power edge\ndevices. The ML pipeline consists an upsampler neural network, a signal quality\nclassifier, and a 1D-convolutional neural network optimized for efficient and\naccurate heart rate estimation. The models were designed so the pipeline was\nless than 40 kB. Further, a hybrid pipeline consisting of the upsampler and\nclassifier, followed by a peak detection algorithm was developed. The pipelines\nwere deployed on ESP32 edge device and benchmarked against signal processing to\ndetermine the energy usage, and inference times. The results indicate that the\nproposed ML and hybrid pipeline reduces energy and time per inference by 82%\nand 28% compared to traditional algorithms. The main trade-off for ML pipeline\nwas accuracy, with a mean absolute error (MAE) of 3.28, compared to 2.39 and\n1.17 for the hybrid and signal processing pipelines. The ML models thus show\npromise for deployment in energy and computationally constrained devices.\nFurther, the lower sampling rate and computational requirements for the ML\npipeline could enable custom hardware solutions to reduce the cost and energy\nneeds of wearable devices.",
    "descriptor": "\nComments: 10 pages, 6 figures, Preprint Submitted to IEEE Transactions on Consumer Electronics\n",
    "authors": [
      "Preetam Anbukarasu",
      "Shailesh Nanisetty",
      "Ganesh Tata",
      "Nilanjan Ray"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.07981"
  },
  {
    "id": "arXiv:2208.07982",
    "title": "MosaicSets: Embedding Set Systems into Grid Graphs",
    "abstract": "Visualizing sets of elements and their relations is an important research\narea in information visualization. In this paper, we present MosaicSets: a\nnovel approach to create Euler-like diagrams from non-spatial set systems such\nthat each element occupies one cell of a regular hexagonal or square grid. The\nmain challenge is to find an assignment of the elements to the grid cells such\nthat each set constitutes a contiguous region. As use case, we consider the\nresearch groups of a university faculty as elements, and the departments and\njoint research projects as sets. We aim at finding a suitable mapping between\nthe research groups and the grid cells such that the department structure forms\na base map layout. Our objectives are to optimize both the compactness of the\nentirety of all cells and of each set by itself. We show that computing the\nmapping is NP-hard. However, using integer linear programming we can solve\nreal-world instances optimally within a few seconds. Moreover, we propose a\nrelaxation of the contiguity requirement to visualize otherwise non-embeddable\nset systems. We present and discuss different rendering styles for the set\noverlays. Based on a case study with real-world data, our evaluation comprises\nquantitative measures as well as expert interviews.",
    "descriptor": "\nComments: Paper accepted at IEEE VIS 2022\n",
    "authors": [
      "Peter Rottmann",
      "Markus Wallinger",
      "Annika Bonerath",
      "Sven Gedicke",
      "Martin N\u00f6llenburg",
      "Jan-Henrik Haunert"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2208.07982"
  },
  {
    "id": "arXiv:2208.07984",
    "title": "Private Estimation with Public Data",
    "abstract": "We initiate the study of differentially private (DP) estimation with access\nto a small amount of public data. For private estimation of d-dimensional\nGaussians, we assume that the public data comes from a Gaussian that may have\nvanishing similarity in total variation distance with the underlying Gaussian\nof the private data. We show that under the constraints of pure or concentrated\nDP, d+1 public data samples are sufficient to remove any dependence on the\nrange parameters of the private data distribution from the private sample\ncomplexity, which is known to be otherwise necessary without public data. For\nseparated Gaussian mixtures, we assume that the underlying public and private\ndistributions are the same, and we consider two settings: (1) when given a\ndimension-independent amount of public data, the private sample complexity can\nbe improved polynomially in terms of the number of mixture components, and any\ndependence on the range parameters of the distribution can be removed in the\napproximate DP case; (2) when given an amount of public data linear in the\ndimension, the private sample complexity can be made independent of range\nparameters even under concentrated DP, and additional improvements can be made\nto the overall sample complexity.",
    "descriptor": "\nComments: 53 pages\n",
    "authors": [
      "Alex Bie",
      "Gautam Kamath",
      "Vikrant Singhal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.07984"
  },
  {
    "id": "arXiv:2208.07985",
    "title": "Federated Multi-Discriminator BiWGAN-GP based Collaborative Anomaly  Detection for Virtualized Network Slicing",
    "abstract": "Virtualized network slicing allows a multitude of logical networks to be\ncreated on a common substrate infrastructure to support diverse services. A\nvirtualized network slice is a logical combination of multiple virtual network\nfunctions, which run on virtual machines (VMs) as software applications by\nvirtualization techniques. As the performance of network slices hinges on the\nnormal running of VMs, detecting and analyzing anomalies in VMs are critical.\nBased on the three-tier management framework of virtualized network slicing, we\nfirst develop a federated learning (FL) based three-tier distributed VM anomaly\ndetection framework, which enables distributed network slice managers to\ncollaboratively train a global VM anomaly detection model while keeping metrics\ndata locally. The high-dimensional, imbalanced, and distributed data features\nin virtualized network slicing scenarios invalidate the existing anomaly\ndetection models. Considering the powerful ability of generative adversarial\nnetwork (GAN) in capturing the distribution from complex data, we design a new\nmulti-discriminator Bidirectional Wasserstein GAN with Gradient Penalty\n(BiWGAN-GP) model to learn the normal data distribution from high-dimensional\nresource metrics datasets that are spread on multiple VM monitors. The\nmulti-discriminator BiWGAN-GP model can be trained over distributed data\nsources, which avoids high communication and computation overhead caused by the\ncentralized collection and processing of local data. We define an anomaly score\nas the discriminant criterion to quantify the deviation of new metrics data\nfrom the learned normal distribution to detect abnormal behaviors arising in\nVMs. The efficiency and effectiveness of the proposed collaborative anomaly\ndetection algorithm are validated through extensive experimental evaluation on\na real-world dataset.",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Mobile Computing\n",
    "authors": [
      "Weili Wang",
      "Chengchao Liang",
      "Lun Tang",
      "Halim Yanikomeroglu",
      "Qianbin Chen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.07985"
  },
  {
    "id": "arXiv:2208.07986",
    "title": "Vehicle Electrification Solutions: review and open challengers",
    "abstract": "An Electric Vehicle (EV) usually refers to any vehicle that is partially or\nfully powered by a battery that can be directly plugged into the mains.\nTherefore, the new vehicles provide various benefits, including convenience,\nefficiency, sustainability, and economy. The present study concerns a\ncomprehensive review of the vehicle electrification solutions. Indeed, the\nmajor electric vehicle technologies are presented. Moreover, based on several\nresearch works from the literature, the main electrification solutions are\nillustrated, including: degree of electrification, battery system management,\non-board chargers, and power converters. In addition, these solutions, as well\nas the open challenges, are discussed and evaluated.",
    "descriptor": "",
    "authors": [
      "Youssef El Amrani",
      "Saad Motahhir",
      "Abdelaziz El Ghzizal"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.07986"
  },
  {
    "id": "arXiv:2208.07989",
    "title": "DICE: Data-Efficient Clinical Event Extraction with Generative Models",
    "abstract": "Event extraction in the clinical domain is an under-explored research area.\nThe lack of training data in addition to the high volume of domain-specific\njargon that includes long entities with vague boundaries make the task\nespecially challenging. In this paper, we introduce DICE, a robust and\ndata-efficient generative model for clinical event extraction. DICE frames\nevent extraction as a conditional generation problem and utilizes descriptions\nprovided by domain experts to boost the performance under low-resource\nsettings. Furthermore, DICE learns to locate and bound biomedical mentions with\nan auxiliary mention identification task trained jointly with event extraction\ntasks to leverage inter-task dependencies and further incorporates the\nidentified mentions as trigger and argument candidates for their respective\ntasks. We also introduce MACCROBAT-EE, the first clinical event extraction\ndataset with event argument annotation. Our experiments demonstrate the\nrobustness of DICE under low data settings for the clinical domain and the\nbenefits of incorporating flexible joint training and mention markers into\ngenerative approaches.",
    "descriptor": "\nComments: 7 pages, 4 figures, 6 tables\n",
    "authors": [
      "Mingyu Derek Ma",
      "Alex Taylor",
      "Wei Wang",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.07989"
  },
  {
    "id": "arXiv:2208.07993",
    "title": "Recent Advances of Blockchain and its Applications",
    "abstract": "Blockchain is an emerging decentralized data collection, sharing and storage\ntechnology, which have provided abundant transparent, secure, tamper-proof,\nsecure and robust ledger services for various real-world use cases. Recent\nyears have witnessed notable developments of blockchain technology itself as\nwell as blockchain-adopting applications. Most existing surveys limit the\nscopes on several particular issues of blockchain or applications, which are\nhard to depict the general picture of current giant blockchain ecosystem. In\nthis paper, we investigate recent advances of both blockchain technology and\nits most active research topics in real-world applications. We first review the\nrecent developments of consensus mechanisms and storage mechanisms in general\nblockchain systems. Then extensive literature is conducted on blockchain\nenabled IoT, edge computing, federated learning and several emerging\napplications including healthcare, COVID-19 pandemic, social network and supply\nchain, where detailed specific research topics are discussed in each. Finally,\nwe discuss the future directions, challenges and opportunities in both academia\nand industry.",
    "descriptor": "",
    "authors": [
      "Xiao Li",
      "Weili Wu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.07993"
  },
  {
    "id": "arXiv:2208.07994",
    "title": "Enhancing Audio Perception of Music By AI Picked Room Acoustics",
    "abstract": "Every sound that we hear is the result of successive convolutional operations\n(e.g. room acoustics, microphone characteristics, resonant properties of the\ninstrument itself, not to mention characteristics and limitations of the sound\nreproduction system). In this work we seek to determine the best room in which\nto perform a particular piece using AI. Additionally, we use room acoustics as\na way to enhance the perceptual qualities of a given sound. Historically, rooms\n(particularly Churches and concert halls) were designed to host and serve\nspecific musical functions. In some cases the architectural acoustical\nqualities enhanced the music performed there. We try to mimic this, as a first\nstep, by designating room impulse responses that would correlate to producing\nenhanced sound quality for particular music. A convolutional architecture is\nfirst trained to take in an audio sample and mimic the ratings of experts with\nabout 78 % accuracy for various instrument families and notes for perceptual\nqualities. This gives us a scoring function for any audio sample which can rate\nthe perceptual pleasantness of a note automatically. Now, via a library of\nabout 60,000 synthetic impulse responses mimicking all kinds of room,\nmaterials, etc, we use a simple convolution operation, to transform the sound\nas if it was played in a particular room. The perceptual evaluator is used to\nrank the musical sounds, and yield the \"best room or the concert hall\" to play\na sound. As a byproduct it can also use room acoustics to turn a poor quality\nsound into a \"good\" sound.",
    "descriptor": "\nComments: 24th International Congress on Acoustics, Gyeongju, South Korea\n",
    "authors": [
      "Prateek Verma",
      "Jonathan Berger"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2208.07994"
  },
  {
    "id": "arXiv:2208.07997",
    "title": "Deep Learning Enabled Time-Lapse 3D Cell Analysis",
    "abstract": "This paper presents a method for time-lapse 3D cell analysis. Specifically,\nwe consider the problem of accurately localizing and quantitatively analyzing\nsub-cellular features, and for tracking individual cells from time-lapse 3D\nconfocal cell image stacks. The heterogeneity of cells and the volume of\nmulti-dimensional images presents a major challenge for fully automated\nanalysis of morphogenesis and development of cells. This paper is motivated by\nthe pavement cell growth process, and building a quantitative morphogenesis\nmodel. We propose a deep feature based segmentation method to accurately detect\nand label each cell region. An adjacency graph based method is used to extract\nsub-cellular features of the segmented cells. Finally, the robust graph based\ntracking algorithm using multiple cell features is proposed for associating\ncells at different time instances. Extensive experiment results are provided\nand demonstrate the robustness of the proposed method. The code is available on\nGithub and the method is available as a service through the BisQue portal.",
    "descriptor": "",
    "authors": [
      "Jiaxiang Jiang",
      "Amil Khan",
      "S.Shailja",
      "Samuel A. Belteton",
      "Michael Goebel",
      "Daniel B. Szymanski",
      "B.S. Manjunath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2208.07997"
  },
  {
    "id": "arXiv:2208.07998",
    "title": "What Artificial Neural Networks Can Tell Us About Human Language  Acquisition",
    "abstract": "Rapid progress in machine learning for natural language processing has the\npotential to transform debates about how humans learn language. However, the\nlearning environments and biases of current artificial learners and humans\ndiverge in ways that weaken the impact of the evidence obtained from learning\nsimulations. For example, today's most effective neural language models are\ntrained on roughly one thousand times the amount of linguistic data available\nto a typical child. To increase the relevance of learnability results from\ncomputational models, we need to train model learners without significant\nadvantages over humans. If an appropriate model successfully acquires some\ntarget linguistic knowledge, it can provide a proof of concept that the target\nis learnable in a hypothesized human learning scenario. Plausible model\nlearners will enable us to carry out experimental manipulations to make causal\ninferences about variables in the learning environment, and to rigorously test\npoverty-of-the-stimulus-style claims arguing for innate linguistic knowledge in\nhumans on the basis of speculations about learnability. Comparable experiments\nwill never be possible with human subjects due to practical and ethical\nconsiderations, making model learners an indispensable resource. So far,\nattempts to deprive current models of unfair advantages obtain sub-human\nresults for key grammatical behaviors such as acceptability judgments. But\nbefore we can justifiably conclude that language learning requires more prior\ndomain-specific knowledge than current models possess, we must first explore\nnon-linguistic inputs in the form of multimodal stimuli and multi-agent\ninteraction as ways to make our learners more efficient at learning from\nlimited linguistic input.",
    "descriptor": "\nComments: To appear in Algebraic Structures in Natural Language. Shalom Lappin & Jean-Philippe Bernardy, editors. Taylor & Francis\n",
    "authors": [
      "Alex Warstadt",
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.07998"
  },
  {
    "id": "arXiv:2208.07999",
    "title": "Evaluating the Feasibility of a Provably Secure Privacy-Preserving  Entity Resolution Adaptation of PPJoin using Homomorphic Encryption",
    "abstract": "Entity resolution is the task of disambiguating records that refer to the\nsame entity in the real world. In this work, we explore adapting one of the\nmost efficient and accurate Jaccard-based entity resolution algorithms -\nPPJoin, to the private domain via homomorphic encryption. Towards this, we\npresent our precise adaptation of PPJoin (HE-PPJoin) that details certain\nsubtle data structure modifications and algorithmic additions needed for\ncorrectness and privacy. We implement HE-PPJoin by extending the PALISADE\nhomomorphic encryption library and evaluate over it for accuracy and incurred\noverhead. Furthermore, we directly compare HE-PPJoin against P4Join, an\nexisting privacy-preserving variant of PPJoin which uses fingerprinting for raw\ncontent obfuscation, by demonstrating a rigorous analysis of the efficiency,\naccuracy, and privacy properties achieved by our adaptation as well as a\ncharacterization of those same attributes in P4Join.",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Tanmay Ghai",
      "Yixiang Yao",
      "Srivatsan Ravi",
      "Pedro Szekely"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.07999"
  },
  {
    "id": "arXiv:2208.08000",
    "title": "DeeperDive: The Unreasonable Effectiveness of Weak Supervision in  Document Understanding A Case Study in Collaboration with UiPath Inc",
    "abstract": "Weak supervision has been applied to various Natural Language Understanding\ntasks in recent years. Due to technical challenges with scaling weak\nsupervision to work on long-form documents, spanning up to hundreds of pages,\napplications in the document understanding space have been limited. At Lexion,\nwe built a weak supervision-based system tailored for long-form (10-200 pages\nlong) PDF documents. We use this platform for building dozens of language\nunderstanding models and have applied it successfully to various domains, from\ncommercial agreements to corporate formation documents.\nIn this paper, we demonstrate the effectiveness of supervised learning with\nweak supervision in a situation with limited time, workforce, and training\ndata. We built 8 high quality machine learning models in the span of one week,\nwith the help of a small team of just 3 annotators working with a dataset of\nunder 300 documents. We share some details about our overall architecture, how\nwe utilize weak supervision, and what results we are able to achieve. We also\ninclude the dataset for researchers who would like to experiment with alternate\napproaches or refine ours.\nFurthermore, we shed some light on the additional complexities that arise\nwhen working with poorly scanned long-form documents in PDF format, and some of\nthe techniques that help us achieve state-of-the-art performance on such data.",
    "descriptor": "",
    "authors": [
      "Emad Elwany",
      "Allison Hegel",
      "Marina Shah",
      "Brendan Roof",
      "Genevieve Peaslee",
      "Quentin Rivet"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08000"
  },
  {
    "id": "arXiv:2208.08002",
    "title": "A Study on Learning and Simulating Personalized Car-Following Driving  Style",
    "abstract": "Automated vehicles are gradually entering people's daily life to provide a\ncomfortable driving experience for the users. The generic and user-agnostic\nautomated vehicles have limited ability to accommodate the different driving\nstyles of different users. This limitation not only impacts users' satisfaction\nbut also causes safety concerns. Learning from user demonstrations can provide\ndirect insights regarding users' driving preferences. However, it is difficult\nto understand a driver's preference with limited data. In this study, we use a\nmodel-free inverse reinforcement learning method to study drivers'\ncharacteristics in the car-following scenario from a naturalistic driving\ndataset, and show this method is capable of representing users' preferences\nwith reward functions. In order to predict the driving styles for drivers with\nlimited data, we apply Gaussian Mixture Models and compute the similarity of a\nspecific driver to the clusters of drivers. We design a personalized adaptive\ncruise control (P-ACC) system through a partially observable Markov decision\nprocess (POMDP) model. The reward function with the model to mimic drivers'\ndriving style is integrated, with a constraint on the relative distance to\nensure driving safety. Prediction of the driving styles achieves 85.7% accuracy\nwith the data of less than 10 car-following events. The model-based\nexperimental driving trajectories demonstrate that the P-ACC system can provide\na personalized driving experience.",
    "descriptor": "",
    "authors": [
      "Shili Sheng",
      "Erfan Pakdamanian",
      "Kyungtae Han",
      "Ziran Wang",
      "Lu Feng"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.08002"
  },
  {
    "id": "arXiv:2208.08003",
    "title": "Superior generalization of smaller models in the presence of significant  label noise",
    "abstract": "The benefits of over-parameterization in achieving superior generalization\nperformance have been shown in several recent studies, justifying the trend of\nusing larger models in practice. In the context of robust learning however, the\neffect of neural network size has not been well studied. In this work, we find\nthat in the presence of a substantial fraction of mislabeled examples,\nincreasing the network size beyond some point can be harmful. In particular,\nthe originally monotonic or `double descent' test loss curve (w.r.t. network\nwidth) turns into a U-shaped or a double U-shaped curve when label noise\nincreases, suggesting that the best generalization is achieved by some model\nwith intermediate size. We observe that when network size is controlled by\ndensity through random pruning, similar test loss behaviour is observed. We\nalso take a closer look into both phenomenon through bias-variance\ndecomposition and theoretically characterize how label noise shapes the\nvariance term. Similar behavior of the test loss can be observed even when\nstate-of-the-art robust methods are applied, indicating that limiting the\nnetwork size could further boost existing methods. Finally, we empirically\nexamine the effect of network size on the smoothness of learned functions, and\nfind that the originally negative correlation between size and smoothness is\nflipped by label noise.",
    "descriptor": "",
    "authors": [
      "Yihao Xue",
      "Kyle Whitecross",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.08003"
  },
  {
    "id": "arXiv:2208.08004",
    "title": "Field-wise Embedding Size Search via Structural Hard Auxiliary Mask  Pruning for Click-Through Rate Prediction",
    "abstract": "Feature embeddings are one of the most essential steps when training deep\nlearning based Click-Through Rate prediction models, which map high-dimensional\nsparse features to dense embedding vectors. Classic human-crafted embedding\nsize selection methods are shown to be \"sub-optimal\" in terms of the trade-off\nbetween memory usage and model capacity. The trending methods in Neural\nArchitecture Search (NAS) have demonstrated their efficiency to search for\nembedding sizes. However, most existing NAS-based works suffer from expensive\ncomputational costs, the curse of dimensionality of the search space, and the\ndiscrepancy between continuous search space and discrete candidate space. Other\nworks that prune embeddings in an unstructured manner fail to reduce the\ncomputational costs explicitly. In this paper, to address those limitations, we\npropose a novel strategy that searches for the optimal mixed-dimension\nembedding scheme by structurally pruning a super-net via Hard Auxiliary Mask.\nOur method aims to directly search candidate models in the discrete space using\na simple and efficient gradient-based method. Furthermore, we introduce\northogonal regularity on embedding tables to reduce correlations within\nembedding columns and enhance representation capacity. Extensive experiments\ndemonstrate it can effectively remove redundant embedding dimensions without\ngreat performance loss.",
    "descriptor": "",
    "authors": [
      "Tesi Xiao",
      "Xia Xiao",
      "Ming Chen",
      "Youlong Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.08004"
  },
  {
    "id": "arXiv:2208.08005",
    "title": "Transformer Encoder for Social Science",
    "abstract": "High-quality text data has become an important data source for social\nscientists. We have witnessed the success of pretrained deep neural network\nmodels, such as BERT and RoBERTa, in recent social science research. In this\npaper, we propose a compact pretrained deep neural network, Transformer Encoder\nfor Social Science (TESS), explicitly designed to tackle text processing tasks\nin social science research. Using two validation tests, we demonstrate that\nTESS outperforms BERT and RoBERTa by 16.7% on average when the number of\ntraining samples is limited (<1,000 training instances). The results display\nthe superiority of TESS over BERT and RoBERTa on social science text processing\ntasks. Lastly, we discuss the limitation of our model and present advice for\nfuture researchers.",
    "descriptor": "",
    "authors": [
      "Haosen Ge",
      "In Young Park",
      "Xuancheng Qian",
      "Grace Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08005"
  },
  {
    "id": "arXiv:2208.08009",
    "title": "Resource Allocation in Quantum Key Distribution (QKD) for  Space-Air-Ground Integrated Networks",
    "abstract": "Space-air-ground integrated networks (SAGIN) are one of the most promising\nadvanced paradigms in the sixth generation (6G) communication. SAGIN can\nsupport high data rates, low latency, and seamless network coverage for\ninterconnected applications and services. However, communications in SAGIN are\nfacing tremendous security threats from the ever-increasing capacity of quantum\ncomputers. Fortunately, quantum key distribution (QKD) for establishing secure\ncommunications in SAGIN, i.e., QKD over SAGIN, can provide\ninformation-theoretic security. To minimize the QKD deployment cost in SAGIN\nwith heterogeneous nodes, in this paper, we propose a resource allocation\nscheme for QKD over SAGIN using stochastic programming. The proposed scheme is\nformulated via two-stage stochastic programming (SP), while considering\nuncertainties such as security requirements and weather conditions. Under\nextensive experiments, the results clearly show that the proposed scheme can\nachieve the optimal deployment cost under various security requirements and\nunpredictable weather conditions.",
    "descriptor": "\nComments: 6 pages, 9 figures, conference paper\n",
    "authors": [
      "Rakpong Kaewpuang",
      "Minrui Xu",
      "Dusit Niyato",
      "Han Yu",
      "Zehui Xiong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.08009"
  },
  {
    "id": "arXiv:2208.08010",
    "title": "ShortcutLens: A Visual Analytics Approach for Exploring Shortcuts in  Natural Language Understanding Dataset",
    "abstract": "Benchmark datasets play an important role in evaluating Natural Language\nUnderstanding (NLU) models. However, shortcuts -- unwanted biases in the\nbenchmark datasets -- can damage the effectiveness of benchmark datasets in\nrevealing models' real capabilities. Since shortcuts vary in coverage,\nproductivity, and semantic meaning, it is challenging for NLU experts to\nsystematically understand and avoid them when creating benchmark datasets. In\nthis paper, we develop a visual analytics system, ShortcutLens, to help NLU\nexperts explore shortcuts in NLU benchmark datasets. The system allows users to\nconduct multi-level exploration of shortcuts. Specifically, Statistics View\nhelps users grasp the statistics such as coverage and productivity of shortcuts\nin the benchmark dataset. Template View employs hierarchical and interpretable\ntemplates to summarize different types of shortcuts. Instance View allows users\nto check the corresponding instances covered by the shortcuts. We conduct case\nstudies and expert interviews to evaluate the effectiveness and usability of\nthe system. The results demonstrate that ShortcutLens supports users in gaining\na better understanding of benchmark dataset issues through shortcuts, inspiring\nthem to create challenging and pertinent benchmark datasets.",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Zhihua Jin",
      "Xingbo Wang",
      "Furui Cheng",
      "Chunhui Sun",
      "Qun Liu",
      "Huamin Qu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08010"
  },
  {
    "id": "arXiv:2208.08011",
    "title": "Re4: Learning to Re-contrast, Re-attend, Re-construct for Multi-interest  Recommendation",
    "abstract": "Effectively representing users lie at the core of modern recommender systems.\nSince users' interests naturally exhibit multiple aspects, it is of increasing\ninterest to develop multi-interest frameworks for recommendation, rather than\nrepresent each user with an overall embedding. Despite their effectiveness,\nexisting methods solely exploit the encoder (the forward flow) to represent\nmultiple aspects of interests. However, without explicit regularization, the\ninterest embeddings may not be distinct from each other nor semantically\nreflect representative historical items. Towards this end, we propose the Re4\nframework, which leverages the backward flow to reexamine each interest\nembedding. Specifically, Re4 encapsulates three backward flows, i.e., 1)\nRe-contrast, which drives each interest embedding to be distinct from other\ninterests using contrastive learning; 2) Re-attend, which ensures the\ninterest-item correlation estimation in the forward flow to be consistent with\nthe criterion used in final recommendation; and 3) Re-construct, which ensures\nthat each interest embedding can semantically reflect the information of\nrepresentative items that relate to the corresponding interest. We demonstrate\nthe novel forward-backward multi-interest paradigm on ComiRec, and perform\nextensive experiments on three real-world datasets. Empirical studies validate\nthat Re4 helps to learn learning distinct and effective multi-interest\nrepresentations.",
    "descriptor": "\nComments: 11 pages, 4 figures, accepted by WWW 2022\n",
    "authors": [
      "Shengyu Zhang",
      "Lingxiao Yang",
      "Dong Yao",
      "Yujie Lu",
      "Fuli Feng",
      "Zhou Zhao",
      "Tat-seng Chua",
      "Fei Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.08011"
  },
  {
    "id": "arXiv:2208.08014",
    "title": "AUGER: Automatically Generating Review Comments with Pre-training Models",
    "abstract": "Code review is one of the best practices as a powerful safeguard for software\nquality. In practice, senior or highly skilled reviewers inspect source code\nand provide constructive comments, considering what authors may ignore, for\nexample, some special cases. The collaborative validation between contributors\nresults in code being highly qualified and less chance of bugs. However, since\npersonal knowledge is limited and varies, the efficiency and effectiveness of\ncode review practice are worthy of further improvement. In fact, it still takes\na colossal and time-consuming effort to deliver useful review comments. This\npaper explores a synergy of multiple practical review comments to enhance code\nreview and proposes AUGER (AUtomatically GEnerating Review comments): a review\ncomments generator with pre-training models. We first collect empirical review\ndata from 11 notable Java projects and construct a dataset of 10,882 code\nchanges. By leveraging Text-to-Text Transfer Transformer (T5) models, the\nframework synthesizes valuable knowledge in the training stage and effectively\noutperforms baselines by 37.38% in ROUGE-L. 29% of our automatic review\ncomments are considered useful according to prior studies. The inference\ngenerates just in 20 seconds and is also open to training further. Moreover,\nthe performance also gets improved when thoroughly analyzed in case study.",
    "descriptor": "\nComments: Accepted by ESEC/FSE-2022\n",
    "authors": [
      "Lingwei Li",
      "Li Yang",
      "Huaxi Jiang",
      "Jun Yan",
      "Tiejian Luo",
      "Zihan Hua",
      "Geng Liang",
      "Chun Zuo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.08014"
  },
  {
    "id": "arXiv:2208.08015",
    "title": "Cross-Domain Few-Shot Classification via Inter-Source Stylization",
    "abstract": "Cross-Domain Few Shot Classification (CDFSC) leverages prior knowledge\nlearned from a supervised auxiliary dataset to solve a target task with limited\nsupervised information available, where the auxiliary and target datasets come\nfrom the different domains. It is challenging due to the domain shift between\nthese datasets. Inspired by Multisource Domain Adaptation (MDA), the recent\nworks introduce the multiple domains to improve the performance. However, they,\non the one hand, evaluate only on the benchmark with natural images, and on the\nother hand, they need many annotations even in the source domains can be\ncostly. To address the above mentioned issues, this paper explore a new\nMultisource CDFSC setting (MCDFSC) where only one source domain is fully\nlabeled while the rest source domains remain unlabeled. These sources are from\ndifferent fileds, means they are not only natural images. Considering the\ninductive bias of CNNs, this paper proposed Inter-Source stylization network\n(ISSNet) for this new MCDFSC setting. It transfers the styles of unlabeled\nsources to labeled source, which expands the distribution of labeled source and\nfurther improves the model generalization ability. Experiments on 8 target\ndatasets demonstrate ISSNet effectively suppresses the performance degradation\ncaused by different domains.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Huali Xu",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08015"
  },
  {
    "id": "arXiv:2208.08017",
    "title": "Towards Generating Robust, Fair, and Emotion-Aware Explanations for  Recommender Systems",
    "abstract": "As recommender systems become increasingly sophisticated and complex, they\noften suffer from lack of fairness and transparency. Providing robust and\nunbiased explanations for recommendations has been drawing more and more\nattention as it can help address these issues and improve trustworthiness and\ninformativeness of recommender systems. However, despite the fact that such\nexplanations are generated for humans who respond more strongly to messages\nwith appropriate emotions, there is a lack of consideration for emotions when\ngenerating explanations for recommendations. Current explanation generation\nmodels are found to exaggerate certain emotions without accurately capturing\nthe underlying tone or the meaning. In this paper, we propose a novel method\nbased on a multi-head transformer, called Emotion-aware Transformer for\nExplainable Recommendation (EmoTER), to generate more robust, fair, and\nemotion-enhanced explanations. To measure the linguistic quality and emotion\nfairness of the generated explanations, we adopt both automatic text metrics\nand human perceptions for evaluation. Experiments on three widely-used\nbenchmark datasets with multiple evaluation metrics demonstrate that EmoTER\nconsistently outperforms the existing state-of-the-art explanation generation\nmodels in terms of text quality, explainability, and consideration for fairness\nto emotion distribution. Implementation of EmoTER will be released as an\nopen-source toolkit to support further research.",
    "descriptor": "",
    "authors": [
      "Bingbing Wen",
      "Yunhe Feng",
      "Yongfeng Zhang",
      "Chirag Shah"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08017"
  },
  {
    "id": "arXiv:2208.08019",
    "title": "Interference Cancellation GAN Framework for Dynamic Channels",
    "abstract": "Symbol detection is a fundamental and challenging problem in modern\ncommunication systems, e.g., multiuser multiple-input multiple-output (MIMO)\nsetting. Iterative Soft Interference Cancellation (SIC) is a state-of-the-art\nmethod for this task and recently motivated data-driven neural network models,\ne.g. DeepSIC, that can deal with unknown non-linear channels. However, these\nneural network models require thorough timeconsuming training of the networks\nbefore applying, and is thus not readily suitable for highly dynamic channels\nin practice. We introduce an online training framework that can swiftly adapt\nto any changes in the channel. Our proposed framework unifies the recent deep\nunfolding approaches with the emerging generative adversarial networks (GANs)\nto capture any changes in the channel and quickly adjust the networks to\nmaintain the top performance of the model. We demonstrate that our framework\nsignificantly outperforms recent neural network models on highly dynamic\nchannels and even surpasses those on the static channel in our experiments.",
    "descriptor": "",
    "authors": [
      "Hung T. Nguyen",
      "Steven Bottone",
      "Kwang Taik Kim",
      "Mung Chiang",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.08019"
  },
  {
    "id": "arXiv:2208.08021",
    "title": "Streaming Adaptive Submodular Maximization",
    "abstract": "Many sequential decision making problems can be formulated as an adaptive\nsubmodular maximization problem. However, most of existing studies in this\nfield focus on pool-based setting, where one can pick items in any order, and\nthere have been few studies for the stream-based setting where items arrive in\nan arbitrary order and one must immediately decide whether to select an item or\nnot upon its arrival. In this paper, we introduce a new class of utility\nfunctions, semi-policywise submodular functions. We develop a series of\neffective algorithms to maximize a semi-policywise submodular function under\nthe stream-based setting.",
    "descriptor": "\nComments: This paper has been accepted at The 16th International Conference on Algorithmic Aspects in Information and Management (AAIM 2022)\n",
    "authors": [
      "Shaojie Tang",
      "Jing Yuan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08021"
  },
  {
    "id": "arXiv:2208.08023",
    "title": "Few-shot Named Entity Recognition with Entity-level Prototypical Network  Enhanced by Dispersedly Distributed Prototypes",
    "abstract": "Few-shot named entity recognition (NER) enables us to build a NER system for\na new domain using very few labeled examples. However, existing prototypical\nnetworks for this task suffer from roughly estimated label dependency and\nclosely distributed prototypes, thus often causing misclassifications. To\naddress the above issues, we propose EP-Net, an Entity-level Prototypical\nNetwork enhanced by dispersedly distributed prototypes. EP-Net builds\nentity-level prototypes and considers text spans to be candidate entities, so\nit no longer requires the label dependency. In addition, EP-Net trains the\nprototypes from scratch to distribute them dispersedly and aligns spans to\nprototypes in the embedding space using a space projection. Experimental\nresults on two evaluation tasks and the Few-NERD settings demonstrate that\nEP-Net consistently outperforms the previous strong models in terms of overall\nperformance. Extensive analyses further validate the effectiveness of EP-Net.",
    "descriptor": "\nComments: Accept to COLING2022\n",
    "authors": [
      "Bin Ji",
      "Shasha Li",
      "Shaoduo Gan",
      "Jie Yu",
      "Jun Ma",
      "Huijun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08023"
  },
  {
    "id": "arXiv:2208.08024",
    "title": "CCL4Rec: Contrast over Contrastive Learning for Micro-video  Recommendation",
    "abstract": "Micro-video recommender systems suffer from the ubiquitous noises in users'\nbehaviors, which might render the learned user representation indiscriminating,\nand lead to trivial recommendations (e.g., popular items) or even weird ones\nthat are far beyond users' interests. Contrastive learning is an emergent\ntechnique for learning discriminating representations with random data\naugmentations. However, due to neglecting the noises in user behaviors and\ntreating all augmented samples equally, the existing contrastive learning\nframework is insufficient for learning discriminating user representations in\nrecommendation. To bridge this research gap, we propose the Contrast over\nContrastive Learning framework for training recommender models, named CCL4Rec,\nwhich models the nuances of different augmented views by further contrasting\naugmented positives/negatives with adaptive pulling/pushing strengths, i.e.,\nthe contrast over (vanilla) contrastive learning. To accommodate these\ncontrasts, we devise the hardness-aware augmentations that track the importance\nof behaviors being replaced in the query user and the relatedness of\nsubstitutes, and thus determining the quality of augmented positives/negatives.\nThe hardness-aware augmentation also permits controllable contrastive learning,\nleading to performance gains and robust training. In this way, CCL4Rec captures\nthe nuances of historical behaviors for a given user, which explicitly shields\noff the learned user representation from the effects of noisy behaviors. We\nconduct extensive experiments on two micro-video recommendation benchmarks,\nwhich demonstrate that CCL4Rec with far less model parameters could achieve\ncomparable performance to existing state-of-the-art method, and improve the\ntraining/inference speed by several orders of magnitude.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Shengyu Zhang",
      "Bofang Li",
      "Dong Yao",
      "Fuli Feng",
      "Jieming Zhu",
      "Wenyan Fan",
      "Zhou Zhao",
      "Xiaofei He",
      "Tat-seng Chua",
      "Fei Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.08024"
  },
  {
    "id": "arXiv:2208.08025",
    "title": "AutoCAT: Reinforcement Learning for Automated Exploration of Cache  Timing-Channel Attacks",
    "abstract": "The aggressive performance optimizations in modern microprocessors can result\nin security vulnerabilities. For example, the timing-based attacks in processor\ncaches are shown to be successful in stealing secret keys or causing privilege\nescalation. So far, finding cache-timing vulnerabilities is mostly performed by\nhuman experts, which is inefficient and laborious. There is a need for\nautomatic tools that can explore vulnerabilities because unreported\nvulnerabilities leave the systems at risk. In this paper, we propose AutoCAT,\nan automated exploration framework that finds cache timing-channel attacks\nusing reinforcement learning (RL). Specifically, AutoCAT formulates the cache\ntiming-channel attack as a guessing game between the attacker program and the\nvictim program holding a secret, which can thus be solved via modern deep RL\ntechniques. AutoCAT can explore attacks in various cache configurations without\nknowing design details and under different attacker and victim configurations,\nand also find attacks to bypass known detection and defense mechanisms. In\nparticular, AutoCAT discovered StealthyStreamline, a new attack that is able to\nbypass detection based on performance counters and has up to a 71% higher\ninformation leakage rate than the state-of-the-art LRU-based attacks on real\nprocessors. AutoCAT is the first of its kind using RL for crafting\nmicroarchitectural timing-channel attack sequences and can accelerate cache\ntiming-channel exploration for secure microprocessor designs.",
    "descriptor": "",
    "authors": [
      "Mulong Luo",
      "Wenjie Xiong",
      "Geunbae Lee",
      "Yueying Li",
      "Xiaomeng Yang",
      "Amy Zhang",
      "Yuandong Tian",
      "Hsien Hsin S. Lee",
      "G. Edward Suh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2208.08025"
  },
  {
    "id": "arXiv:2208.08028",
    "title": "Deep Learning based Security-Constrained Unit Commitment Considering  Locational Frequency Stability in Low-Inertia Power Systems",
    "abstract": "With the goal of electricity system decarbonization, conventional synchronous\ngenerators are gradually replaced by converter-interfaced renewable\ngenerations. Such transition is causing concerns over system frequency and\nrate-of-change-of-frequency (RoCoF) security due to significant reduction in\nsystem inertia. Existing efforts are mostly derived from uniform system\nfrequency response model which may fail to capture all characteristics of the\nsystems. To ensure the locational frequency security, this paper presents a\ndeep neural network (DNN) based RoCoF-constrained unit commitment (DNN-RCUC)\nmodel. RoCoF predictor is trained to predict the highest locational RoCoF based\non a high-fidelity simulation dataset. Training samples are generated from\nmodels over various scenarios, which can avoid simulation divergence and system\ninstability. The trained network is then reformulated into a set of\nmixed-integer linear constraints representing the locational RoCoF-limiting\nconstraints in unit commitment. The proposed DNN-RCUC model is studied on the\nIEEE 24-bus system. Time domain simulation results on PSS/E demonstrate the\neffectiveness of the proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Mingjian Tuo",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.08028"
  },
  {
    "id": "arXiv:2208.08029",
    "title": "A Context-Aware Approach for Textual Adversarial Attack through  Probability Difference Guided Beam Search",
    "abstract": "Textual adversarial attacks expose the vulnerabilities of text classifiers\nand can be used to improve their robustness. Existing context-aware methods\nsolely consider the gold label probability and use the greedy search when\nsearching an attack path, often limiting the attack efficiency. To tackle these\nissues, we propose PDBS, a context-aware textual adversarial attack model using\nProbability Difference guided Beam Search. The probability difference is an\noverall consideration of all class label probabilities, and PDBS uses it to\nguide the selection of attack paths. In addition, PDBS uses the beam search to\nfind a successful attack path, thus avoiding suffering from limited search\nspace. Extensive experiments and human evaluation demonstrate that PDBS\noutperforms previous best models in a series of evaluation metrics, especially\nbringing up to a +19.5% attack success rate. Ablation studies and qualitative\nanalyses further confirm the efficiency of PDBS.",
    "descriptor": "",
    "authors": [
      "Huijun Liu",
      "Jie Yu",
      "Shasha Li",
      "Jun Ma",
      "Bin Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08029"
  },
  {
    "id": "arXiv:2208.08034",
    "title": "Deep Reinforcement Learning based Robot Navigation in Dynamic  Environments using Occupancy Values of Motion Primitives",
    "abstract": "This paper presents a Deep Reinforcement Learning based navigation approach\nin which we define the occupancy observations as heuristic evaluations of\nmotion primitives, rather than using raw sensor data. Our method enables fast\nmapping of the occupancy data, generated by multi-sensor fusion, into\ntrajectory values in 3D workspace. The computationally efficient trajectory\nevaluation allows dense sampling of the action space. We utilize our occupancy\nobservations in different data structures to analyze their effects on both\ntraining process and navigation performance. We train and test our methodology\non two different robots within challenging physics-based simulation\nenvironments including static and dynamic obstacles. We benchmark our occupancy\nrepresentations with other conventional data structures from state-of-the-art\nmethods. The trained navigation policies are also validated successfully with\nphysical robots in dynamic environments. The results show that our method not\nonly decreases the required training time but also improves the navigation\nperformance as compared to other occupancy representations. The open-source\nimplementation of our work and all related info are available at\n\\url{https://github.com/RIVeR-Lab/tentabot}.",
    "descriptor": "\nComments: Accepted to 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Ne\u015fet \u00dcnver Akmandor",
      "Hongyu Li",
      "Gary Lvov",
      "Eric Dusel",
      "Ta\u015fk\u0131n Pad\u0131r"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.08034"
  },
  {
    "id": "arXiv:2208.08035",
    "title": "EGCR: Explanation Generation for Conversational Recommendation",
    "abstract": "Growing attention has been paid in Conversational Recommendation System\n(CRS), which works as a conversation-based and recommendation task-oriented\ntool to provide items of interest and explore user preference. However,\nexisting work in CRS fails to explicitly show the reasoning logic to users and\nthe whole CRS still remains a black box. Therefore we propose a novel\nend-to-end framework named Explanation Generation for Conversational\nRecommendation (EGCR) based on generating explanations for conversational\nagents to explain why they make the action. EGCR incorporates user reviews to\nenhance the item representation and increase the informativeness of the whole\nconversation. To the best of our knowledge, this is the first framework for\nexplainable conversational recommendation on real-world datasets. Moreover, we\nevaluate EGCR on one benchmark conversational recommendation datasets and\nachieve better performance on both recommendation accuracy and conversation\nquality than other state-of-the art models. Finally, extensive experiments\ndemonstrate that generated explanations are not only having high quality and\nexplainability, but also making CRS more trustworthy. We will make our code\navailable to contribute to the CRS community",
    "descriptor": "",
    "authors": [
      "Bingbing Wen",
      "Xiaoning Bu",
      "Chirag Shah"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08035"
  },
  {
    "id": "arXiv:2208.08037",
    "title": "UniLayout: Taming Unified Sequence-to-Sequence Transformers for Graphic  Layout Generation",
    "abstract": "To satisfy various user needs, different subtasks of graphic layout\ngeneration have been explored intensively in recent years. Existing studies\nusually propose task-specific methods with diverse input-output formats,\ndedicated model architectures, and different learning methods. However, those\nspecialized approaches make the adaption to unseen subtasks difficult, hinder\nthe knowledge sharing between different subtasks, and are contrary to the trend\nof devising general-purpose models. In this work, we propose UniLayout, which\nhandles different subtasks for graphic layout generation in a unified manner.\nFirst, we uniformly represent diverse inputs and outputs of subtasks as the\nsequences of tokens. Then, based on the unified sequence format, we naturally\nleverage an identical encoder-decoder architecture with Transformers for\ndifferent subtasks. Moreover, based on the above two kinds of unification, we\nfurther develop a single model that supports all subtasks concurrently.\nExperiments on two public datasets demonstrate that while simple, UniLayout\nsignificantly outperforms the previous task-specific methods.",
    "descriptor": "\nComments: 28 pages, under review\n",
    "authors": [
      "Zhaoyun Jiang",
      "Huayu Deng",
      "Zhongkai Wu",
      "Jiaqi Guo",
      "Shizhao Sun",
      "Vuksan Mijovic",
      "Zijiang Yang",
      "Jian-Guang Lou",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08037"
  },
  {
    "id": "arXiv:2208.08040",
    "title": "A Survey on Incomplete Multi-view Clustering",
    "abstract": "Conventional multi-view clustering seeks to partition data into respective\ngroups based on the assumption that all views are fully observed. However, in\npractical applications, such as disease diagnosis, multimedia analysis, and\nrecommendation system, it is common to observe that not all views of samples\nare available in many cases, which leads to the failure of the conventional\nmulti-view clustering methods. Clustering on such incomplete multi-view data is\nreferred to as incomplete multi-view clustering. In view of the promising\napplication prospects, the research of incomplete multi-view clustering has\nnoticeable advances in recent years. However, there is no survey to summarize\nthe current progresses and point out the future research directions. To this\nend, we review the recent studies of incomplete multi-view clustering.\nImportantly, we provide some frameworks to unify the corresponding incomplete\nmulti-view clustering methods, and make an in-depth comparative analysis for\nsome representative methods from theoretical and experimental perspectives.\nFinally, some open problems in the incomplete multi-view clustering field are\noffered for researchers.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Systems, Man, and Cybernetics: Systems (2022)\n",
    "authors": [
      "Jie Wen",
      "Zheng Zhang",
      "Lunke Fei",
      "Bob Zhang",
      "Yong Xu",
      "Zhao Zhang",
      "Jinxing Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2208.08040"
  },
  {
    "id": "arXiv:2208.08041",
    "title": "InterTrack: Interaction Transformer for 3D Multi-Object Tracking",
    "abstract": "3D multi-object tracking (MOT) is a key problem for autonomous vehicles,\nrequired to perform well-informed motion planning in dynamic environments.\nParticularly for densely occupied scenes, associating existing tracks to new\ndetections remains challenging as existing systems tend to omit critical\ncontextual information. Our proposed solution, InterTrack, introduces the\nInteraction Transformer for 3D MOT to generate discriminative object\nrepresentations for data association. We extract state and shape features for\neach track and detection, and efficiently aggregate global information via\nattention. We then perform a learned regression on each track/detection feature\npair to estimate affinities, and use a robust two-stage data association and\ntrack management approach to produce the final tracks. We validate our approach\non the nuScenes 3D MOT benchmark, where we observe significant improvements,\nparticularly on classes with small physical sizes and clustered objects. As of\nsubmission, InterTrack ranks 1st in overall AMOTA among methods using\nCenterPoint detections.",
    "descriptor": "",
    "authors": [
      "John Willes",
      "Cody Reading",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08041"
  },
  {
    "id": "arXiv:2208.08042",
    "title": "The Conversational Short-phrase Speaker Diarization (CSSD) Task:  Dataset, Evaluation Metric and Baselines",
    "abstract": "The conversation scenario is one of the most important and most challenging\nscenarios for speech processing technologies because people in conversation\nrespond to each other in a casual style. Detecting the speech activities of\neach person in a conversation is vital to downstream tasks, like natural\nlanguage processing, machine translation, etc. People refer to the detection\ntechnology of \"who speak when\" as speaker diarization (SD). Traditionally,\ndiarization error rate (DER) has been used as the standard evaluation metric of\nSD systems for a long time. However, DER fails to give enough importance to\nshort conversational phrases, which are short but important on the semantic\nlevel. Also, a carefully and accurately manually-annotated testing dataset\nsuitable for evaluating the conversational SD technologies is still unavailable\nin the speech community. In this paper, we design and describe the\nConversational Short-phrases Speaker Diarization (CSSD) task, which consists of\ntraining and testing datasets, evaluation metric and baselines. In the dataset\naspect, despite the previously open-sourced 180-hour conversational\nMagicData-RAMC dataset, we prepare an individual 20-hour conversational speech\ntest dataset with carefully and artificially verified speakers timestamps\nannotations for the CSSD task. In the metric aspect, we design the new\nconversational DER (CDER) evaluation metric, which calculates the SD accuracy\nat the utterance level. In the baseline aspect, we adopt a commonly used\nmethod: Variational Bayes HMM x-vector system, as the baseline of the CSSD\ntask. Our evaluation metric is publicly available at\nhttps://github.com/SpeechClub/CDER_Metric.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.16844\n",
    "authors": [
      "Gaofeng Cheng",
      "Yifan Chen",
      "Runyan Yang",
      "Qingxuan Li",
      "Zehui Yang",
      "Lingxuan Ye",
      "Pengyuan Zhang",
      "Qingqing Zhang",
      "Lei Xie",
      "Yanmin Qian",
      "Kong Aik Lee",
      "Yonghong Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2208.08042"
  },
  {
    "id": "arXiv:2208.08047",
    "title": "Urban feature analysis from aerial remote sensing imagery using  self-supervised and semi-supervised computer vision",
    "abstract": "Analysis of overhead imagery using computer vision is a problem that has\nreceived considerable attention in academic literature. Most techniques that\noperate in this space are both highly specialised and require expensive manual\nannotation of large datasets. These problems are addressed here through the\ndevelopment of a more generic framework, incorporating advances in\nrepresentation learning which allows for more flexibility in analysing new\ncategories of imagery with limited labeled data. First, a robust representation\nof an unlabeled aerial imagery dataset was created based on the momentum\ncontrast mechanism. This was subsequently specialised for different tasks by\nbuilding accurate classifiers with as few as 200 labeled images. The successful\nlow-level detection of urban infrastructure evolution over a 10-year period\nfrom 60 million unlabeled images, exemplifies the substantial potential of our\napproach to advance quantitative urban research.",
    "descriptor": "\nComments: Submitted to journal 'Sustainable Cities and Society'\n",
    "authors": [
      "Sachith Seneviratne",
      "Jasper S. Wijnands",
      "Kerry Nice",
      "Haifeng Zhao",
      "Branislava Godic",
      "Suzanne Mavoa",
      "Rajith Vidanaarachchi",
      "Mark Stevenson",
      "Leandro Garcia",
      "Ruth F. Hunter",
      "Jason Thompson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08047"
  },
  {
    "id": "arXiv:2208.08049",
    "title": "PDRF: Progressively Deblurring Radiance Field for Fast and Robust Scene  Reconstruction from Blurry Images",
    "abstract": "We present Progressively Deblurring Radiance Field (PDRF), a novel approach\nto efficiently reconstruct high quality radiance fields from blurry images.\nWhile current State-of-The-Art (SoTA) scene reconstruction methods achieve\nphoto-realistic rendering results from clean source views, their performances\nsuffer when the source views are affected by blur, which is commonly observed\nfor images in the wild. Previous deblurring methods either do not account for\n3D geometry, or are computationally intense. To addresses these issues, PDRF, a\nprogressively deblurring scheme in radiance field modeling, accurately models\nblur by incorporating 3D scene context. PDRF further uses an efficient\nimportance sampling scheme, which results in fast scene optimization.\nSpecifically, PDRF proposes a Coarse Ray Renderer to quickly estimate voxel\ndensity and feature; a Fine Voxel Renderer is then used to achieve high quality\nray tracing. We perform extensive experiments and show that PDRF is 15X faster\nthan previous SoTA while achieving better performance on both synthetic and\nreal scenes.",
    "descriptor": "",
    "authors": [
      "Cheng Peng",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08049"
  },
  {
    "id": "arXiv:2208.08052",
    "title": "Imperceptible and Robust Backdoor Attack in 3D Point Cloud",
    "abstract": "With the thriving of deep learning in processing point cloud data, recent\nworks show that backdoor attacks pose a severe security threat to 3D vision\napplications. The attacker injects the backdoor into the 3D model by poisoning\na few training samples with trigger, such that the backdoored model performs\nwell on clean samples but behaves maliciously when the trigger pattern appears.\nExisting attacks often insert some additional points into the point cloud as\nthe trigger, or utilize a linear transformation (e.g., rotation) to construct\nthe poisoned point cloud. However, the effects of these poisoned samples are\nlikely to be weakened or even eliminated by some commonly used pre-processing\ntechniques for 3D point cloud, e.g., outlier removal or rotation augmentation.\nIn this paper, we propose a novel imperceptible and robust backdoor attack\n(IRBA) to tackle this challenge. We utilize a nonlinear and local\ntransformation, called weighted local transformation (WLT), to construct\npoisoned samples with unique transformations. As there are several\nhyper-parameters and randomness in WLT, it is difficult to produce two similar\ntransformations. Consequently, poisoned samples with unique transformations are\nlikely to be resistant to aforementioned pre-processing techniques. Besides, as\nthe controllability and smoothness of the distortion caused by a fixed WLT, the\ngenerated poisoned samples are also imperceptible to human inspection.\nExtensive experiments on three benchmark datasets and four models show that\nIRBA achieves 80%+ ASR in most cases even with pre-processing techniques, which\nis significantly higher than previous state-of-the-art attacks.",
    "descriptor": "",
    "authors": [
      "Kuofeng Gao",
      "Jiawang Bai",
      "Baoyuan Wu",
      "Mengxi Ya",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.08052"
  },
  {
    "id": "arXiv:2208.08053",
    "title": "A Sequence Tagging based Framework for Few-Shot Relation Extraction",
    "abstract": "Relation Extraction (RE) refers to extracting the relation triples in the\ninput text. Existing neural work based systems for RE rely heavily on manually\nlabeled training data, but there are still a lot of domains where sufficient\nlabeled data does not exist. Inspired by the distance-based few-shot named\nentity recognition methods, we put forward the definition of the few-shot RE\ntask based on the sequence tagging joint extraction approaches, and propose a\nfew-shot RE framework for the task. Besides, we apply two actual sequence\ntagging models to our framework (called Few-shot TPLinker and Few-shot BiTT),\nand achieves solid results on two few-shot RE tasks constructed from a public\ndataset.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Xukun Luo",
      "Ping Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08053"
  },
  {
    "id": "arXiv:2208.08054",
    "title": "Hierarchical Motion Planning Framework for Cooperative Transportation of  Multiple Mobile Manipulators",
    "abstract": "Multiple mobile manipulators show superiority in the tasks requiring mobility\nand dexterity compared with a single robot, especially when\nmanipulating/transporting bulky objects. When the object and the manipulators\nare rigidly connected, closed-chain will form and the motion of the whole\nsystem will be restricted onto a lower-dimensional manifold. However, current\nresearch on multi-robot motion planning did not fully consider the formation of\nthe whole system, the redundancy of the mobile manipulator and obstacles in the\nenvironment, which make the tasks challenging. Therefore, this paper proposes a\nhierarchical framework to efficiently solve the above challenges, where the\ncentralized layer plans the object's motion offline and the decentralized layer\nindependently explores the redundancy of each robot in real-time. In addition,\nclosed-chain, obstacle-avoidance and the lower bound of the formation\nconstraints are guaranteed in the centralized layer, which cannot be achieved\nsimultaneously by other planners. Moreover, capability map, which represents\nthe distribution of the formation constraint, is applied to speed up the two\nlayers. Both simulation and experimental results show that the proposed\nframework outperforms the benchmark planners significantly. The system could\nbypass or cross obstacles in cluttered environments, and the framework can be\napplied to different numbers of heterogeneous mobile manipulators.",
    "descriptor": "",
    "authors": [
      "Heng Zhang",
      "Haoyi Song",
      "Wenhang Liu",
      "Xinjun Sheng",
      "Zhenhua Xiong",
      "Xiangyang Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.08054"
  },
  {
    "id": "arXiv:2208.08055",
    "title": "Performance Analysis and Optimization for RIS-Assisted Multi-User  Massive MIMO Systems with Imperfect Hardware",
    "abstract": "The paper studies a reconfigurable intelligent surface (RIS)-assisted\nmulti-user uplink massive multiple-input multiple-output (MIMO) system with\nimperfect hardware. At the RIS, the paper considers phase noise, while at the\nbase station, the paper takes into consideration the radio frequency\nimpairments and low-resolution analog-to-digital converters. The paper derives\napproximate expressions for the ergodic achievable rate in closed forms under\nRician fading channels. For the cases of infinite numbers of antennas and\ninfinite numbers of reflecting elements, asymptotic data rates are derived to\nprovide new design insights. The derived power scaling laws indicate that while\nguaranteeing a required system performance, the transmit power of the users can\nbe scaled down at most by the factor 1/M when M goes infinite, or by the factor\n1/(MN) when M and N go infinite, where M is the number of antennas and N is the\nnumber of the reflecting units. Furthermore, an optimization algorithm is\nproposed based on the genetic algorithm to solve the phase shift optimization\nproblem with the aim of maximizing the sum rate of the system. Additionally,\nthe optimization problem with discrete phase shifts is considered. Finally,\nnumerical results are provided to validate the correctness of the analytical\nresults.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Vehicular Technology (TVT)\n",
    "authors": [
      "Zhangjie Peng",
      "Xianzhe Chen",
      "Cunhua Pan",
      "Maged Elkashlan",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.08055"
  },
  {
    "id": "arXiv:2208.08056",
    "title": "Sampling Through the Lens of Sequential Decision Making",
    "abstract": "Sampling is ubiquitous in machine learning methodologies. Due to the growth\nof large datasets and model complexity, we want to learn and adapt the sampling\nprocess while training a representation. Towards achieving this grand goal, a\nvariety of sampling techniques have been proposed. However, most of them either\nuse a fixed sampling scheme or adjust the sampling scheme based on simple\nheuristics. They cannot choose the best sample for model training in different\nstages. Inspired by \"Think, Fast and Slow\" (System 1 and System 2) in cognitive\nscience, we propose a reward-guided sampling strategy called Adaptive Sample\nwith Reward (ASR) to tackle this challenge. To the best of our knowledge, this\nis the first work utilizing reinforcement learning (RL) to address the sampling\nproblem in representation learning. Our approach optimally adjusts the sampling\nprocess to achieve optimal performance. We explore geographical relationships\namong samples by distance-based sampling to maximize overall cumulative reward.\nWe apply ASR to the long-standing sampling problems in similarity-based loss\nfunctions. Empirical results in information retrieval and clustering\ndemonstrate ASR's superb performance across different datasets. We also discuss\nan engrossing phenomenon which we name as \"ASR gravity well\" in experiments.",
    "descriptor": "",
    "authors": [
      "Jason Xiaotian Dou",
      "Alvin Qingkai Pan",
      "Runxue Bao",
      "Haiyi Harry Mao",
      "Lei Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.08056"
  },
  {
    "id": "arXiv:2208.08058",
    "title": "Semi-supervised Learning with Deterministic Labeling and Large Margin  Projection",
    "abstract": "The centrality and diversity of the labeled data are very influential to the\nperformance of semi-supervised learning (SSL), but most SSL models select the\nlabeled data randomly. How to guarantee the centrality and diversity of the\nlabeled data has so far received little research attention. Optimal leading\nforest (OLF) has been observed to have the advantage of revealing the\ndifference evolution within a class when it was utilized to develop an SSL\nmodel. Our key intuition of this study is to learn a kernelized large margin\nmetric for a small amount of most stable and most divergent data that are\nrecognized based on the OLF structure. An optimization problem is formulated to\nachieve this goal. Also with OLF the multiple local metrics learning is\nfacilitated to address multi-modal and mix-modal problem in SSL. Attribute to\nthis novel design, the accuracy and performance stableness of the SSL model\nbased on OLF is significantly improved compared with its baseline methods\nwithout sacrificing much efficiency. The experimental studies have shown that\nthe proposed method achieved encouraging accuracy and running time when\ncompared to the state-of-the-art graph SSL methods. Code has been made\navailable at https://github.com/alanxuji/DeLaLA.",
    "descriptor": "\nComments: 8 pages, contains only the core content of the method DeLaLA. It needs further extension\n",
    "authors": [
      "Ji Xu",
      "Gang Ren",
      "Yao Xiao",
      "Shaobo Li",
      "Guoyin Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08058"
  },
  {
    "id": "arXiv:2208.08061",
    "title": "Efficient dynamic point cloud coding using Slice-Wise Segmentation",
    "abstract": "With the fast growth of immersive video sequences, achieving seamless and\nhigh-quality compressed 3D content is even more critical. MPEG recently\ndeveloped a video-based point cloud compression (V-PCC) standard for dynamic\npoint cloud coding. However, reconstructed point clouds using V-PCC suffer from\ndifferent artifacts, including losing data during pre-processing before\napplying existing video coding techniques, e.g., High-Efficiency Video Coding\n(HEVC). Patch generations and self-occluded points in the 3D to the 2D\nprojection are the main reasons for missing data using V-PCC. This paper\nproposes a new method that introduces overlapping slicing as an alternative to\npatch generation to decrease the number of patches generated and the amount of\ndata lost. In the proposed method, the entire point cloud has been\ncross-sectioned into variable-sized slices based on the number of self-occluded\npoints so that data loss can be minimized in the patch generation process and\nprojection. For this, a variable number of layers are considered, partially\noverlapped to retain the self-occluded points. The proposed method's added\nadvantage is to reduce the bits requirement and to encode geometric data using\nthe slicing base position. The experimental results show that the proposed\nmethod is much more flexible than the standard V-PCC method, improves the\nrate-distortion performance, and decreases the data loss significantly compared\nto the standard V-PCC method.",
    "descriptor": "",
    "authors": [
      "Faranak Tohidi",
      "Manoranjan Paul",
      "Anwaar Ulhaq"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.08061"
  },
  {
    "id": "arXiv:2208.08063",
    "title": "NECE: Narrative Event Chain Extraction Toolkit",
    "abstract": "NECE is an event-based text analysis toolkit built for narrative documents.\nNECE aims to provide users open and easy accesses to an event-based summary and\nabstraction of long narrative documents through both a graphic interface and a\npython package, which can be readily used in narrative analysis, understanding,\nor other advanced purposes. Our work addresses the challenge of long passage\nevents extraction and temporal ordering of key events; at the same time, it\noffers options to select and view events related to narrative entities, such as\nmain characters and gender groups. We conduct human evaluation to demonstrate\nthe quality of the event chain extraction system and character features mining\nalgorithms. Lastly, we shed light on the toolkit's potential downstream\napplications by demonstrating its usage in gender bias analysis and\nQuestion-Answering tasks.",
    "descriptor": "",
    "authors": [
      "Guangxuan Xu",
      "Paulina Toro Isaza",
      "Moshi Li",
      "Akintoye Oloko",
      "Bingsheng Yao",
      "Aminat Adebeyi",
      "Yufang Hou",
      "Nanyun Peng",
      "Dakuo Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.08063"
  },
  {
    "id": "arXiv:2208.08067",
    "title": "ASTRO: An AST-Assisted Approach for Generalizable Neural Clone Detection",
    "abstract": "Neural clone detection has attracted the attention of software engineering\nresearchers and practitioners. However, most neural clone detection methods do\nnot generalize beyond the scope of clones that appear in the training dataset.\nThis results in poor model performance, especially in terms of model recall. In\nthis paper, we present an Abstract Syntax Tree (AST) assisted approach for\ngeneralizable neural clone detection, or ASTRO, a framework for finding clones\nin codebases reflecting industry practices. We present three main components:\n(1) an AST-inspired representation for source code that leverages program\nstructure and semantics, (2) a global graph representation that captures the\ncontext of an AST among a corpus of programs, and (3) a graph embedding for\nprograms that, in combination with extant large-scale language models, improves\nstate-of-the-art code clone detection. Our experimental results show that ASTRO\nimproves state-of-the-art neural clone detection approaches in both recall and\nF-1 scores.",
    "descriptor": "",
    "authors": [
      "Yifan Zhang",
      "Junwen Yang",
      "Haoyu Dong",
      "Qingchen Wang",
      "Huajie Shao",
      "Kevin Leach",
      "Yu Huang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.08067"
  },
  {
    "id": "arXiv:2208.08070",
    "title": "Proof Engineering with Predicate Transformer Semantics",
    "abstract": "We present a lightweight, open source Agda framework for manually verifying\neffectful programs using predicate transformer semantics. We represent the\nabstract syntax trees (AST) of effectful programs with a generalized algebraic\ndatatype (GADT) AST, whose generality enables even complex operations to be\nprimitive AST nodes. Users can then assign bespoke predicate transformers to\nsuch operations to aid the proof effort, for example by automatically\ndecomposing proof obligations for branching code. Our framework codifies and\ngeneralizes a proof engineering methodology used by the authors to reason about\na prototype implementation of LibraBFT, a Byzantine fault tolerant consensus\nprotocol in which code executed by participants may have effects such as\nupdating state and sending messages. Successful use of our framework in this\ncontext demonstrates its practical applicability.",
    "descriptor": "\nComments: 15 pages excluding references\n",
    "authors": [
      "Christa Jenkins",
      "Mark Moir",
      "Harold Carr"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2208.08070"
  },
  {
    "id": "arXiv:2208.08071",
    "title": "An Efficient Multi-Step Framework for Malware Packing Identification",
    "abstract": "Malware developers use combinations of techniques such as compression,\nencryption, and obfuscation to bypass anti-virus software. Malware with\nanti-analysis technologies can bypass AI-based anti-virus software and malware\nanalysis tools. Therefore, classifying pack files is one of the big challenges.\nProblems arise if the malware classifiers learn packers' features, not those of\nmalware. Training the models with unintended erroneous data turn into poisoning\nattacks, adversarial attacks, and evasion attacks. Therefore, researchers\nshould consider packing to build appropriate malware classifier models. In this\npaper, we propose a multi-step framework for classifying and identifying packed\nsamples which consists of pseudo-optimal feature selection, machine\nlearning-based classifiers, and packer identification steps. In the first step,\nwe use the CART algorithm and the permutation importance to preselect important\n20 features. In the second step, each model learns 20 preselected features for\nclassifying the packed files with the highest performance. As a result, the\nXGBoost, which learned the features preselected by XGBoost with the permutation\nimportance, showed the highest performance of any other experiment scenarios\nwith an accuracy of 99.67%, an F1-Score of 99.46%, and an area under the curve\n(AUC) of 99.98%. In the third step, we propose a new approach that can identify\npackers only for samples classified as Well-Known Packed.",
    "descriptor": "",
    "authors": [
      "Jong-Wouk Kim",
      "Yang-Sae Moon",
      "Mi-Jung Choi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08071"
  },
  {
    "id": "arXiv:2208.08076",
    "title": "Significance of Skeleton-based Features in Virtual Try-On",
    "abstract": "The idea of \\textit{Virtual Try-ON} (VTON) benefits e-retailing by giving an\nuser the convenience of trying a clothing at the comfort of their home. In\ngeneral, most of the existing VTON methods produce inconsistent results when a\nperson posing with his arms folded i.e., bent or crossed, wants to try an\noutfit. The problem becomes severe in the case of long-sleeved outfits. As\nthen, for crossed arm postures, overlap among different clothing parts might\nhappen. The existing approaches, especially the warping-based methods employing\n\\textit{Thin Plate Spline (TPS)} transform can not tackle such cases. To this\nend, we attempt a solution approach where the clothing from the source person\nis segmented into semantically meaningful parts and each part is warped\nindependently to the shape of the person. To address the bending issue, we\nemploy hand-crafted geometric features consistent with human body geometry for\nwarping the source outfit. In addition, we propose two learning-based modules:\na synthesizer network and a mask prediction network. All these together attempt\nto produce a photo-realistic, pose-robust VTON solution without requiring any\npaired training data. Comparison with some of the benchmark methods clearly\nestablishes the effectiveness of the approach.",
    "descriptor": "",
    "authors": [
      "Debapriya Roy",
      "Diganta Mukherjee",
      "Bhabatosh Chanda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08076"
  },
  {
    "id": "arXiv:2208.08078",
    "title": "Look in Different Views: Multi-Scheme Regression Guided Cell Instance  Segmentation",
    "abstract": "Cell instance segmentation is a new and challenging task aiming at joint\ndetection and segmentation of every cell in an image. Recently, many instance\nsegmentation methods have applied in this task. Despite their great success,\nthere still exists two main weaknesses caused by uncertainty of localizing cell\ncenter points. First, densely packed cells can easily be recognized into one\ncell. Second, elongated cell can easily be recognized into two cells. To\novercome these two weaknesses, we propose a novel cell instance segmentation\nnetwork based on multi-scheme regression guidance. With multi-scheme regression\nguidance, the network has the ability to look each cell in different views.\nSpecifically, we first propose a gaussian guidance attention mechanism to use\ngaussian labels for guiding the network's attention. We then propose a\npoint-regression module for assisting the regression of cell center. Finally,\nwe utilize the output of the above two modules to further guide the instance\nsegmentation. With multi-scheme regression guidance, we can take full advantage\nof the characteristics of different regions, especially the central region of\nthe cell. We conduct extensive experiments on benchmark datasets, DSB2018,\nCA2.5 and SCIS. The encouraging results show that our network achieves SOTA\n(state-of-the-art) performance. On the DSB2018 and CA2.5, our network surpasses\nprevious methods by 1.2% (AP50). Particularly on SCIS dataset, our network\nperforms stronger by large margin (3.0% higher AP50). Visualization and\nanalysis further prove that our proposed method is interpretable.",
    "descriptor": "\nComments: 7 pages, 8 figures\n",
    "authors": [
      "Menghao Li",
      "Wenquan Feng",
      "Shuchang Lyu",
      "Lijiang Chen",
      "Qi Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08078"
  },
  {
    "id": "arXiv:2208.08080",
    "title": "Multimodal Lecture Presentations Dataset: Understanding Multimodality in  Educational Slides",
    "abstract": "Lecture slide presentations, a sequence of pages that contain text and\nfigures accompanied by speech, are constructed and presented carefully in order\nto optimally transfer knowledge to students. Previous studies in multimedia and\npsychology attribute the effectiveness of lecture presentations to their\nmultimodal nature. As a step toward developing AI to aid in student learning as\nintelligent teacher assistants, we introduce the Multimodal Lecture\nPresentations dataset as a large-scale benchmark testing the capabilities of\nmachine learning models in multimodal understanding of educational content. Our\ndataset contains aligned slides and spoken language, for 180+ hours of video\nand 9000+ slides, with 10 lecturers from various subjects (e.g., computer\nscience, dentistry, biology). We introduce two research tasks which are\ndesigned as stepping stones towards AI agents that can explain (automatically\ncaptioning a lecture presentation) and illustrate (synthesizing visual figures\nto accompany spoken explanations) educational content. We provide manual\nannotations to help implement these two research tasks and evaluate\nstate-of-the-art models on them. Comparing baselines and human student\nperformances, we find that current models struggle in (1) weak crossmodal\nalignment between slides and spoken text, (2) learning novel visual mediums,\n(3) technical language, and (4) long-range sequences. Towards addressing this\nissue, we also introduce PolyViLT, a multimodal transformer trained with a\nmulti-instance learning loss that is more effective than current approaches. We\nconclude by shedding light on the challenges and opportunities in multimodal\nunderstanding of educational presentations.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Dong Won Lee",
      "Chaitanya Ahuja",
      "Paul Pu Liang",
      "Sanika Natu",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2208.08080"
  },
  {
    "id": "arXiv:2208.08082",
    "title": "A Hybrid SFANC-FxNLMS Algorithm for Active Noise Control based on Deep  Learning",
    "abstract": "The selective fixed-filter active noise control (SFANC) method selecting the\nbest pre-trained control filters for various types of noise can achieve a fast\nresponse time. However, it may lead to large steady-state errors due to\ninaccurate filter selection and the lack of adaptability. In comparison, the\nfiltered-X normalized least-mean-square (FxNLMS) algorithm can obtain lower\nsteady-state errors through adaptive optimization. Nonetheless, its slow\nconvergence has a detrimental effect on dynamic noise attenuation. Therefore,\nthis paper proposes a hybrid SFANC-FxNLMS approach to overcome the adaptive\nalgorithm's slow convergence and provide a better noise reduction level than\nthe SFANC method. A lightweight one-dimensional convolutional neural network\n(1D CNN) is designed to automatically select the most suitable pre-trained\ncontrol filter for each frame of the primary noise. Meanwhile, the FxNLMS\nalgorithm continues to update the coefficients of the chosen pre-trained\ncontrol filter at the sampling rate. Owing to the effective combination of the\ntwo algorithms, experimental results show that the hybrid SFANC-FxNLMS\nalgorithm can achieve a rapid response time, a low noise reduction error, and a\nhigh degree of robustness.",
    "descriptor": "",
    "authors": [
      "Zhengding Luo",
      "Dongyuan Shi",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2208.08082"
  },
  {
    "id": "arXiv:2208.08083",
    "title": "Two Heads are Better than One: Robust Learning Meets Multi-branch Models",
    "abstract": "Deep neural networks (DNNs) are vulnerable to adversarial examples, in which\nDNNs are misled to false outputs due to inputs containing imperceptible\nperturbations. Adversarial training, a reliable and effective method of\ndefense, may significantly reduce the vulnerability of neural networks and\nbecomes the de facto standard for robust learning. While many recent works\npractice the data-centric philosophy, such as how to generate better\nadversarial examples or use generative models to produce additional training\ndata, we look back to the models themselves and revisit the adversarial\nrobustness from the perspective of deep feature distribution as an insightful\ncomplementarity. In this paper, we propose Branch Orthogonality adveRsarial\nTraining (BORT) to obtain state-of-the-art performance with solely the original\ndataset for adversarial training. To practice our design idea of integrating\nmultiple orthogonal solution spaces, we leverage a simple and straightforward\nmulti-branch neural network that eclipses adversarial attacks with no increase\nin inference time. We heuristically propose a corresponding loss function,\nbranch-orthogonal loss, to make each solution space of the multi-branch model\northogonal. We evaluate our approach on CIFAR-10, CIFAR-100, and SVHN against\n\\ell_{\\infty} norm-bounded perturbations of size \\epsilon = 8/255,\nrespectively. Exhaustive experiments are conducted to show that our method goes\nbeyond all state-of-the-art methods without any tricks. Compared to all methods\nthat do not use additional data for training, our models achieve 67.3% and\n41.5% robust accuracy on CIFAR-10 and CIFAR-100 (improving upon the\nstate-of-the-art by +7.23% and +9.07%). We also outperform methods using a\ntraining set with a far larger scale than ours. All our models and codes are\navailable online at https://github.com/huangd1999/BORT.",
    "descriptor": "\nComments: 10 pages, 5 Figures\n",
    "authors": [
      "Dong Huang",
      "Qingwen Bu",
      "Yuhao Qing",
      "Haowen Pi",
      "Sen Wang",
      "Heming Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08083"
  },
  {
    "id": "arXiv:2208.08084",
    "title": "AdaBin: Improving Binary Neural Networks with Adaptive Binary Sets",
    "abstract": "This paper studies the Binary Neural Networks (BNNs) in which weights and\nactivations are both binarized into 1-bit values, thus greatly reducing the\nmemory usage and computational complexity. Since the modern deep neural\nnetworks are of sophisticated design with complex architecture for the accuracy\nreason, the diversity on distributions of weights and activations is very high.\nTherefore, the conventional sign function cannot be well used for effectively\nbinarizing full-precision values in BNNs. To this end, we present a simple yet\neffective approach called AdaBin to adaptively obtain the optimal binary sets\n$\\{b_1, b_2\\}$ ($b_1, b_2\\in \\mathbb{R}$) of weights and activations for each\nlayer instead of a fixed set (i.e., $\\{-1, +1\\}$). In this way, the proposed\nmethod can better fit different distributions and increase the representation\nability of binarized features. In practice, we use the center position and\ndistance of 1-bit values to define a new binary quantization function. For the\nweights, we propose an equalization method to align the symmetrical center of\nbinary distribution to real-valued distribution, and minimize the\nKullback-Leibler divergence of them. Meanwhile, we introduce a gradient-based\noptimization method to get these two parameters for activations, which are\njointly trained in an end-to-end manner. Experimental results on benchmark\nmodels and datasets demonstrate that the proposed AdaBin is able to achieve\nstate-of-the-art performance. For instance, we obtain a 66.4\\% Top-1 accuracy\non the ImageNet using ResNet-18 architecture, and a 69.4 mAP on PASCAL VOC\nusing SSD300.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Zhijun Tu",
      "Xinghao Chen",
      "Pengju Ren",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08084"
  },
  {
    "id": "arXiv:2208.08085",
    "title": "Efficient Detection and Filtering Systems for Distributed Training",
    "abstract": "A plethora of modern machine learning tasks require the utilization of\nlarge-scale distributed clusters as a critical component of the training\npipeline. However, abnormal Byzantine behavior of the worker nodes can derail\nthe training and compromise the quality of the inference. Such behavior can be\nattributed to unintentional system malfunctions or orchestrated attacks; as a\nresult, some nodes may return arbitrary results to the parameter server (PS)\nthat coordinates the training. Recent work considers a wide range of attack\nmodels and has explored robust aggregation and/or computational redundancy to\ncorrect the distorted gradients. In this work, we consider attack models\nranging from strong ones: $q$ omniscient adversaries with full knowledge of the\ndefense protocol that can change from iteration to iteration to weak ones: $q$\nrandomly chosen adversaries with limited collusion abilities which only change\nevery few iterations at a time. Our algorithms rely on redundant task\nassignments coupled with detection of adversarial behavior. For strong attacks,\nwe demonstrate a reduction in the fraction of distorted gradients ranging from\n16\\%-99\\% as compared to the prior state-of-the-art. Our top-1 classification\naccuracy results on the CIFAR-10 data set demonstrate 25\\% advantage in\naccuracy (averaged over strong and weak scenarios) under the most sophisticated\nattacks compared to state-of-the-art methods.",
    "descriptor": "\nComments: 18 pages, 14 figures, 6 tables. arXiv admin note: substantial text overlap with arXiv:2108.02416\n",
    "authors": [
      "Konstantinos Konstantinidis",
      "Aditya Ramamoorthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.08085"
  },
  {
    "id": "arXiv:2208.08086",
    "title": "Implementation of Multi-channel Active Noise Control based on  Back-propagation Mechanism",
    "abstract": "Active noise control (ANC) systems can efficiently attenuate low-frequency\nnoises by introducing anti-noises to combine with the unwanted noises. In ANC\nsystems, the filtered-x least mean square (FxLMS) and filtered-X normalized\nleast-mean-square (FxNLMS) algorithm are well-known algorithms for adaptively\nadjusting control filters. Multi-channel ANC systems are typically required to\nattenuate unwanted noises in a large space. However, open-source\nimplementations of the multi-channel FxLMS (McFxLMS) and multi-channel FxNLMS\n(McFxNLMS) algorithm continue to be scarce. Therefore, this paper proposes a\nsimple and effective implementation approach of the McFxLMS and McFxNLMS\nalgorithm. Motivated by the back-propagation process during neural network\ntraining, the McFxLMS and McFxNLMS algorithm can be implemented via automatic\nderivation mechanism. We implemented the two algorithms using the automatic\nderivation mechanism in PyTorch and made the source code available on GitHub.\nThis implementation method can improve the practicality of multi-channel ANC\nsystems, which is expected to be widely used in ANC applications.",
    "descriptor": "",
    "authors": [
      "Zhengding Luo",
      "Dongyuan Shi",
      "Junwei Ji",
      "Woon-seng Gan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.08086"
  },
  {
    "id": "arXiv:2208.08087",
    "title": "Autonomous Resource Management in Construction Companies Using Deep  Reinforcement Learning Based on IoT",
    "abstract": "Resource allocation is one of the most critical issues in planning\nconstruction projects, due to its direct impact on cost, time, and quality.\nThere are usually specific allocation methods for autonomous resource\nmanagement according to the projects objectives. However, integrated planning\nand optimization of utilizing resources in an entire construction organization\nare scarce. The purpose of this study is to present an automatic resource\nallocation structure for construction companies based on Deep Reinforcement\nLearning (DRL), which can be used in various situations. In this structure,\nData Harvesting (DH) gathers resource information from the distributed Internet\nof Things (IoT) sensor devices all over the companys projects to be employed in\nthe autonomous resource management approach. Then, Coverage Resources\nAllocation (CRA) is compared to the information obtained from DH in which the\nAutonomous Resource Management (ARM) determines the project of interest.\nLikewise, Double Deep Q-Networks (DDQNs) with similar models are trained on two\ndistinct assignment situations based on structured resource information of the\ncompany to balance objectives with resource constraints. The suggested\ntechnique in this paper can efficiently adjust to large resource management\nsystems by combining portfolio information with adopted individual project\ninformation. Also, the effects of important information processing parameters\non resource allocation performance are analyzed in detail. Moreover, the\nresults of the generalizability of management approaches are presented,\nindicating no need for additional training when the variables of situations\nchange.",
    "descriptor": "",
    "authors": [
      "Maryam Soleymani",
      "Mahdi Bonyani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08087"
  },
  {
    "id": "arXiv:2208.08088",
    "title": "AutoTSMM: An Auto-tuning Framework for Building High-Performance  Tall-and-Skinny Matrix-Matrix Multiplication on CPUs",
    "abstract": "In recent years, general matrix-matrix multiplication with non-regular-shaped\ninput matrices has been widely used in many applications like deep learning and\nhas drawn more and more attention. However, conventional implementations are\nnot suited for non-regular-shaped matrix-matrix multiplications, and few works\nfocus on optimizing tall-and-skinny matrix-matrix multiplication on CPUs. This\npaper proposes an auto-tuning framework, AutoTSMM, to build high-performance\ntall-and-skinny matrix-matrix multiplication. AutoTSMM selects the optimal\ninner kernels in the install-time stage and generates an execution plan for the\npre-pack tall-and-skinny matrix-matrix multiplication in the runtime stage.\nExperiments demonstrate that AutoTSMM achieves competitive performance\ncomparing to state-of-the-art tall-and-skinny matrix-matrix multiplication.\nAnd, it outperforms all conventional matrix-matrix multiplication\nimplementations.",
    "descriptor": "\nComments: 8 pages, 12 figures, published in IEEE ISPA 2021\n",
    "authors": [
      "Chendi Li",
      "Haipeng Jia",
      "Hang Cao",
      "Jianyu Yao",
      "Boqian Shi",
      "Chunyang Xiang",
      "Jinbo Sun",
      "Pengqi Lu",
      "Yunquan Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.08088"
  },
  {
    "id": "arXiv:2208.08089",
    "title": "Constrained Few-Shot Learning: Human-Like Low Sample Complexity Learning  and Non-Episodic Text Classification",
    "abstract": "Few-shot learning (FSL) is an emergent paradigm of learning that attempts to\nlearn with low sample complexity to mimic the way humans can learn, generalise\nand extrapolate based on only a few examples. While FSL attempts to mimic these\nhuman characteristics, fundamentally, the task of FSL as conventionally\ndescribed and modelled using meta-learning with episodic-based training does\nnot fully align with how humans acquire and reason with knowledge. FSL with\nepisodic training, while only using $K$ instances of each test class, still\nrequires a large number of labelled instances from disjoint training classes.\nIn this paper, we introduce the novel task of constrained few-shot learning\n(CFSL), a special case of FSL where the number of training instances of each\nclass is constrained to be less than some value $M$ thus applying a similar\nrestriction during training and test. We propose a method for CFSL leveraging\nCat2Vec using a novel categorical contrastive loss inspired by cognitive\ntheories such as fuzzy trace theory and prototype theory.",
    "descriptor": "",
    "authors": [
      "Jaron Mar",
      "Jiamou Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08089"
  },
  {
    "id": "arXiv:2208.08090",
    "title": "Progressive Cross-modal Knowledge Distillation for Human Action  Recognition",
    "abstract": "Wearable sensor-based Human Action Recognition (HAR) has achieved remarkable\nsuccess recently. However, the accuracy performance of wearable sensor-based\nHAR is still far behind the ones from the visual modalities-based system (i.e.,\nRGB video, skeleton, and depth). Diverse input modalities can provide\ncomplementary cues and thus improve the accuracy performance of HAR, but how to\ntake advantage of multi-modal data on wearable sensor-based HAR has rarely been\nexplored. Currently, wearable devices, i.e., smartwatches, can only capture\nlimited kinds of non-visual modality data. This hinders the multi-modal HAR\nassociation as it is unable to simultaneously use both visual and non-visual\nmodality data. Another major challenge lies in how to efficiently utilize\nmultimodal data on wearable devices with their limited computation resources.\nIn this work, we propose a novel Progressive Skeleton-to-sensor Knowledge\nDistillation (PSKD) model which utilizes only time-series data, i.e.,\naccelerometer data, from a smartwatch for solving the wearable sensor-based HAR\nproblem. Specifically, we construct multiple teacher models using data from\nboth teacher (human skeleton sequence) and student (time-series accelerometer\ndata) modalities. In addition, we propose an effective progressive learning\nscheme to eliminate the performance gap between teacher and student models. We\nalso designed a novel loss function called Adaptive-Confidence Semantic (ACS),\nto allow the student model to adaptively select either one of the teacher\nmodels or the ground-truth label it needs to mimic. To demonstrate the\neffectiveness of our proposed PSKD method, we conduct extensive experiments on\nBerkeley-MHAD, UTD-MHAD, and MMAct datasets. The results confirm that the\nproposed PSKD method has competitive performance compared to the previous mono\nsensor-based HAR methods.",
    "descriptor": "\nComments: ACM MM 2022\n",
    "authors": [
      "Jianyuan Ni",
      "Anne H.H. Ngu",
      "Yan Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2208.08090"
  },
  {
    "id": "arXiv:2208.08091",
    "title": "In-vehicle alertness monitoring for older adults",
    "abstract": "Alertness monitoring in the context of driving improves safety and saves\nlives. Computer vision based alertness monitoring is an active area of\nresearch. However, the algorithms and datasets that exist for alertness\nmonitoring are primarily aimed at younger adults (18-50 years old). We present\na system for in-vehicle alertness monitoring for older adults. Through a design\nstudy, we ascertained the variables and parameters that are suitable for older\nadults traveling independently in Level 5 vehicles. We implemented a prototype\ntraveler monitoring system and evaluated the alertness detection algorithm on\nten older adults (70 years and older). We report on the system design and\nimplementation at a level of detail that is suitable for the beginning\nresearcher or practitioner. Our study suggests that dataset development is the\nforemost challenge for developing alertness monitoring systems targeted at\nolder adults. This study is the first of its kind for a hitherto under-studied\npopulation and has implications for future work on algorithm development and\nsystem design through participatory methods.",
    "descriptor": "\nComments: 12 pages, 14 figures, 6 tables\n",
    "authors": [
      "Heng Yao",
      "Sanaz Motamedi",
      "Wayne C.W. Giang",
      "Alexandra Kondyli",
      "Eakta Jain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.08091"
  },
  {
    "id": "arXiv:2208.08092",
    "title": "Paint2Pix: Interactive Painting based Progressive Image Synthesis and  Editing",
    "abstract": "Controllable image synthesis with user scribbles is a topic of keen interest\nin the computer vision community. In this paper, for the first time we study\nthe problem of photorealistic image synthesis from incomplete and primitive\nhuman paintings. In particular, we propose a novel approach paint2pix, which\nlearns to predict (and adapt) \"what a user wants to draw\" from rudimentary\nbrushstroke inputs, by learning a mapping from the manifold of incomplete human\npaintings to their realistic renderings. When used in conjunction with recent\nworks in autonomous painting agents, we show that paint2pix can be used for\nprogressive image synthesis from scratch. During this process, paint2pix allows\na novice user to progressively synthesize the desired image output, while\nrequiring just few coarse user scribbles to accurately steer the trajectory of\nthe synthesis process. Furthermore, we find that our approach also forms a\nsurprisingly convenient approach for real image editing, and allows the user to\nperform a diverse range of custom fine-grained edits through the addition of\nonly a few well-placed brushstrokes. Supplemental video and demo are available\nat https://1jsingh.github.io/paint2pix",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Jaskirat Singh",
      "Liang Zheng",
      "Cameron Smith",
      "Jose Echevarria"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2208.08092"
  },
  {
    "id": "arXiv:2208.08093",
    "title": "Near Threshold Computation of Partitioned Ring Learning With Error  (RLWE) Post Quantum Cryptography on Reconfigurable Architecture",
    "abstract": "Ring Learning With Error (RLWE) algorithm is used in Post Quantum\nCryptography (PQC) and Homomorphic Encryption (HE) algorithm. The existing\nclassical crypto algorithms may be broken in quantum computers. The adversaries\ncan store all encrypted data. While the quantum computer will be available,\nthese encrypted data can be exposed by the quantum computer. Therefore, the PQC\nalgorithms are an essential solution in recent applications. On the other hand,\nthe HE allows operations on encrypted data which is appropriate for getting\nservices from third parties without revealing confidential plain-texts. The\nFPGA based PQC and HE hardware accelerators like RLWE is much cost-effective\nthan processor based platform and Application Specific Integrated Circuit\n(ASIC). FPGA based hardware accelerators still consume more power compare to\nASIC based design. Near Threshold Computation (NTC) may be a convenient\nsolution for FPGA based RLWE implementation. In this paper, we have implemented\nRLWE hardware accelerator which has 14 subcomponents. This paper creates\nclusters based on the critical path of all 14 subcomponents. Each cluster is\nimplemented in an FPGA partition which has the same biasing voltage\n$V_{ccint}$. The clusters that have higher critical paths use higher Vccint to\navoid timing failure. The clusters have lower critical paths use lower biasing\nvoltage Vccint. This voltage scaled, partitioned RLWE can save ~6% and ~11%\npower in Vivado and VTR platform respectively. The resource usage and\nthroughput of the implemented RLWE hardware accelerator is comparatively better\nthan existing literature.",
    "descriptor": "\nComments: Manuscript (yet to be published)\n",
    "authors": [
      "Paresh Baidya",
      "Swagata Mondal",
      "Rourab Paul"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2208.08093"
  },
  {
    "id": "arXiv:2208.08094",
    "title": "SelF-Eval: Self-supervised Fine-grained Dialogue Evaluation",
    "abstract": "This paper introduces a novel Self-supervised Fine-grained Dialogue\nEvaluation framework (SelF-Eval). The core idea is to model the correlation\nbetween turn quality and the entire dialogue quality. We first propose a novel\nautomatic data construction method that can automatically assign fine-grained\nscores for arbitrarily dialogue data. Then we train \\textbf{SelF-Eval} with a\nmulti-level contrastive learning schema which helps to distinguish different\nscore levels. Experimental results on multiple benchmarks show that SelF-Eval\nis highly consistent with human evaluations and better than the\nstate-of-the-art models. We give a detailed analysis of the experiments in this\npaper. Our code and data will be published on GitHub.",
    "descriptor": "\nComments: 11 pages, 2 figures, 5 tables\n",
    "authors": [
      "Longxuan Ma",
      "Ziyu Zhuang",
      "Weinan Zhang",
      "Mingda Li",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08094"
  },
  {
    "id": "arXiv:2208.08097",
    "title": "Brain Topography Adaptive Network for Satisfaction Modeling in  Interactive Information Access System",
    "abstract": "With the growth of information on the Web, most users heavily rely on\ninformation access systems (e.g., search engines, recommender systems, etc.) in\ntheir daily lives. During this procedure, modeling users' satisfaction status\nplays an essential part in improving their experiences with the systems. In\nthis paper, we aim to explore the benefits of using Electroencephalography\n(EEG) signals for satisfaction modeling in interactive information access\nsystem design. Different from existing EEG classification tasks, the arisen of\nsatisfaction involves multiple brain functions, such as arousal,\nprototypicality, and appraisals, which are related to different brain\ntopographical areas. Thus modeling user satisfaction raises great challenges to\nexisting solutions. To address this challenge, we propose BTA, a Brain\nTopography Adaptive network with a multi-centrality encoding module and a\nspatial attention mechanism module to capture cognitive connectivities in\ndifferent spatial distances. We explore the effectiveness of BTA for\nsatisfaction modeling in two popular information access scenarios, i.e., search\nand recommendation. Extensive experiments on two real-world datasets verify the\neffectiveness of introducing brain topography adaptive strategy in satisfaction\nmodeling. Furthermore, we also conduct search result re-ranking task and video\nrating prediction task based on the satisfaction inferred from brain signals on\nsearch and recommendation scenarios, respectively. Experimental results show\nthat brain signals extracted with BTA help improve the performance of\ninteractive information access systems significantly.",
    "descriptor": "\nComments: Accepted by Multimedia 2022 (MM'22) as a full paper\n",
    "authors": [
      "Ziyi Ye",
      "Xiaohui Xie",
      "Yiqun Liu",
      "Zhihong Wang",
      "Xuesong Chen",
      "Min Zhang",
      "Shaoping Ma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2208.08097"
  },
  {
    "id": "arXiv:2208.08099",
    "title": "Fuse and Mix: MACAM-Enabled Analog Activation for Energy-Efficient  Neural Acceleration",
    "abstract": "Analog computing has been recognized as a promising low-power alternative to\ndigital counterparts for neural network acceleration. However, conventional\nanalog computing is mainly in a mixed-signal manner. Tedious analog/digital\n(A/D) conversion cost significantly limits the overall system's energy\nefficiency. In this work, we devise an efficient analog activation unit with\nmagnetic tunnel junction (MTJ)-based analog content-addressable memory (MACAM),\nsimultaneously realizing nonlinear activation and A/D conversion in a fused\nfashion. To compensate for the nascent and therefore currently limited\nrepresentation capability of MACAM, we propose to mix our analog activation\nunit with digital activation dataflow. A fully differential framework,\nSuperMixer, is developed to search for an optimized activation workload\nassignment, adaptive to various activation energy constraints. The\neffectiveness of our proposed methods is evaluated on a silicon photonic\naccelerator. Compared to standard activation implementation, our mixed\nactivation system with the searched assignment can achieve competitive accuracy\nwith $>$60% energy saving on A/D conversion and activation.",
    "descriptor": "\nComments: Accepted by ICCAD 2022\n",
    "authors": [
      "Hanqing Zhu",
      "Keren Zhu",
      "Jiaqi Gu",
      "Harrison Jin",
      "Ray Chen",
      "Jean Anne Incorvia",
      "David Z. Pan"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2208.08099"
  },
  {
    "id": "arXiv:2208.08100",
    "title": "CommitBART: A Large Pre-trained Model for GitHub Commits",
    "abstract": "GitHub commits, which record the code changes with natural language messages\nfor description, play a critical role for software developers to comprehend the\nsoftware evolution. To promote the development of the open-source software\ncommunity, we collect a commit benchmark including over 7.99 million commits\nacross 7 programming languages. Based on this benchmark, we present CommitBART,\na large pre-trained encoder-decoder Transformer model for GitHub commits. The\nmodel is pre-trained by three categories (i.e., denoising objectives,\ncross-modal generation and contrastive learning) for six pre-training tasks to\nlearn commit fragment representations. Furthermore, we unify a \"commit\nintelligence\" framework with one understanding task and three generation tasks\nfor commits. The comprehensive experiments on these tasks demonstrate that\nCommitBART significantly outperforms previous pre-trained works for code.\nFurther analysis also reveals each pre-training task enhances the model\nperformance. We encourage the follow-up researchers to contribute more\ncommit-related downstream tasks to our framework in the future.",
    "descriptor": "",
    "authors": [
      "Shangqing Liu",
      "Yanzhou Li",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08100"
  },
  {
    "id": "arXiv:2208.08104",
    "title": "Understanding Attention for Vision-and-Language Tasks",
    "abstract": "Attention mechanism has been used as an important component across\nVision-and-Language(VL) tasks in order to bridge the semantic gap between\nvisual and textual features. While attention has been widely used in VL tasks,\nit has not been examined the capability of different attention alignment\ncalculation in bridging the semantic gap between visual and textual clues. In\nthis research, we conduct a comprehensive analysis on understanding the role of\nattention alignment by looking into the attention score calculation methods and\ncheck how it actually represents the visual region's and textual token's\nsignificance for the global assessment. We also analyse the conditions which\nattention score calculation mechanism would be more (or less) interpretable,\nand which may impact the model performance on three different VL tasks,\nincluding visual question answering, text-to-image generation, text-and-image\nmatching (both sentence and image retrieval). Our analysis is the first of its\nkind and provides useful insights of the importance of each attention alignment\nscore calculation when applied at the training phase of VL tasks, commonly\nignored in attention-based cross modal models, and/or pretrained models.",
    "descriptor": "\nComments: Accepted in COLING 2022\n",
    "authors": [
      "Feiqi Cao",
      "Soyeon Caren Han",
      "Siqu Long",
      "Changwei Xu",
      "Josiah Poon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08104"
  },
  {
    "id": "arXiv:2208.08106",
    "title": "Disentangling Identity and Pose for Facial Expression Recognition",
    "abstract": "Facial expression recognition (FER) is a challenging problem because the\nexpression component is always entangled with other irrelevant factors, such as\nidentity and head pose. In this work, we propose an identity and pose\ndisentangled facial expression recognition (IPD-FER) model to learn more\ndiscriminative feature representation. We regard the holistic facial\nrepresentation as the combination of identity, pose and expression. These three\ncomponents are encoded with different encoders. For identity encoder, a well\npre-trained face recognition model is utilized and fixed during training, which\nalleviates the restriction on specific expression training data in previous\nworks and makes the disentanglement practicable on in-the-wild datasets. At the\nsame time, the pose and expression encoder are optimized with corresponding\nlabels. Combining identity and pose feature, a neutral face of input individual\nshould be generated by the decoder. When expression feature is added, the input\nimage should be reconstructed. By comparing the difference between synthesized\nneutral and expressional images of the same individual, the expression\ncomponent is further disentangled from identity and pose. Experimental results\nverify the effectiveness of our method on both lab-controlled and in-the-wild\ndatabases and we achieve state-of-the-art recognition performance.",
    "descriptor": "",
    "authors": [
      "Jing Jiang",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08106"
  },
  {
    "id": "arXiv:2208.08109",
    "title": "Boosting Modern and Historical Handwritten Text Recognition with  Deformable Convolutions",
    "abstract": "Handwritten Text Recognition (HTR) in free-layout pages is a challenging\nimage understanding task that can provide a relevant boost to the digitization\nof handwritten documents and reuse of their content. The task becomes even more\nchallenging when dealing with historical documents due to the variability of\nthe writing style and degradation of the page quality. State-of-the-art HTR\napproaches typically couple recurrent structures for sequence modeling with\nConvolutional Neural Networks for visual feature extraction. Since\nconvolutional kernels are defined on fixed grids and focus on all input pixels\nindependently while moving over the input image, this strategy disregards the\nfact that handwritten characters can vary in shape, scale, and orientation even\nwithin the same document and that the ink pixels are more relevant than the\nbackground ones. To cope with these specific HTR difficulties, we propose to\nadopt deformable convolutions, which can deform depending on the input at hand\nand better adapt to the geometric variations of the text. We design two\ndeformable architectures and conduct extensive experiments on both modern and\nhistorical datasets. Experimental results confirm the suitability of deformable\nconvolutions for the HTR task.",
    "descriptor": "",
    "authors": [
      "Silvia Cascianelli",
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08109"
  },
  {
    "id": "arXiv:2208.08110",
    "title": "PCC: Paraphrasing with Bottom-k Sampling and Cyclic Learning for  Curriculum Data Augmentation",
    "abstract": "Curriculum Data Augmentation (CDA) improves neural models by presenting\nsynthetic data with increasing difficulties from easy to hard. However,\ntraditional CDA simply treats the ratio of word perturbation as the difficulty\nmeasure and goes through the curriculums only once. This paper presents\n\\textbf{PCC}: \\textbf{P}araphrasing with Bottom-k Sampling and \\textbf{C}yclic\nLearning for \\textbf{C}urriculum Data Augmentation, a novel CDA framework via\nparaphrasing, which exploits the textual paraphrase similarity as the\ncurriculum difficulty measure. We propose a curriculum-aware paraphrase\ngeneration module composed of three units: a paraphrase candidate generator\nwith bottom-k sampling, a filtering mechanism and a difficulty measure. We also\npropose a cyclic learning strategy that passes through the curriculums multiple\ntimes. The bottom-k sampling is proposed to generate super-hard instances for\nthe later curriculums. Experimental results on few-shot text classification as\nwell as dialogue generation indicate that PCC surpasses competitive baselines.\nHuman evaluation and extensive case studies indicate that bottom-k sampling\neffectively generates super-hard instances, and PCC significantly improves the\nbaseline dialogue agent.",
    "descriptor": "",
    "authors": [
      "Hongyuan Lu",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08110"
  },
  {
    "id": "arXiv:2208.08112",
    "title": "DLCFT: Deep Linear Continual Fine-Tuning for General Incremental  Learning",
    "abstract": "Pre-trained representation is one of the key elements in the success of\nmodern deep learning. However, existing works on continual learning methods\nhave mostly focused on learning models incrementally from scratch. In this\npaper, we explore an alternative framework to incremental learning where we\ncontinually fine-tune the model from a pre-trained representation. Our method\ntakes advantage of linearization technique of a pre-trained neural network for\nsimple and effective continual learning. We show that this allows us to design\na linear model where quadratic parameter regularization method is placed as the\noptimal continual learning policy, and at the same time enjoying the high\nperformance of neural networks. We also show that the proposed algorithm\nenables parameter regularization methods to be applied to class-incremental\nproblems. Additionally, we provide a theoretical reason why the existing\nparameter-space regularization algorithms such as EWC underperform on neural\nnetworks trained with cross-entropy loss. We show that the proposed method can\nprevent forgetting while achieving high continual fine-tuning performance on\nimage classification tasks. To show that our method can be applied to general\ncontinual learning settings, we evaluate our method in data-incremental,\ntask-incremental, and class-incremental learning problems.",
    "descriptor": "\nComments: European Conference on Computer Vision (ECCV) 2022\n",
    "authors": [
      "Hyounguk Shon",
      "Janghyeon Lee",
      "Seung Hwan Kim",
      "Junmo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08112"
  },
  {
    "id": "arXiv:2208.08114",
    "title": "An Empirical Study on the Membership Inference Attack against Tabular  Data Synthesis Models",
    "abstract": "Tabular data typically contains private and important information; thus,\nprecautions must be taken before they are shared with others. Although several\nmethods (e.g., differential privacy and k-anonymity) have been proposed to\nprevent information leakage, in recent years, tabular data synthesis models\nhave become popular because they can well trade-off between data utility and\nprivacy. However, recent research has shown that generative models for image\ndata are susceptible to the membership inference attack, which can determine\nwhether a given record was used to train a victim synthesis model. In this\npaper, we investigate the membership inference attack in the context of tabular\ndata synthesis. We conduct experiments on 4 state-of-the-art tabular data\nsynthesis models under two attack scenarios (i.e., one black-box and one\nwhite-box attack), and find that the membership inference attack can seriously\njeopardize these models. We next conduct experiments to evaluate how well two\npopular differentially-private deep learning training algorithms, DP-SGD and\nDP-GAN, can protect the models against the attack. Our key finding is that both\nalgorithms can largely alleviate this threat by sacrificing the generation\nquality. Code and data available at: https://github.com/JayoungKim408/MIA",
    "descriptor": "\nComments: CIKM 2022 short paper accepted\n",
    "authors": [
      "Jihyeon Hyeong",
      "Jayoung Kim",
      "Noseong Park",
      "Sushil Jajodia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08114"
  },
  {
    "id": "arXiv:2208.08116",
    "title": "Road detection via a dual-task network based on cross-layer graph fusion  modules",
    "abstract": "Road detection based on remote sensing images is of great significance to\nintelligent traffic management. The performances of the mainstream road\ndetection methods are mainly determined by their extracted features, whose\nrichness and robustness can be enhanced by fusing features of different types\nand cross-layer connections. However, the features in the existing mainstream\nmodel frameworks are often similar in the same layer by the single-task\ntraining, and the traditional cross-layer fusion ways are too simple to obtain\nan efficient effect, so more complex fusion ways besides concatenation and\naddition deserve to be explored. Aiming at the above defects, we propose a\ndual-task network (DTnet) for road detection and cross-layer graph fusion\nmodule (CGM): the DTnet consists of two parallel branches for road area and\nedge detection, respectively, while enhancing the feature diversity by fusing\nfeatures between two branches through our designed feature bridge modules\n(FBM). The CGM improves the cross-layer fusion effect by a complex feature\nstream graph, and four graph patterns are evaluated. Experimental results on\nthree public datasets demonstrate that our method effectively improves the\nfinal detection result.",
    "descriptor": "",
    "authors": [
      "Zican Hu",
      "Wurui Shi",
      "Hongkun Liu",
      "Xueyun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08116"
  },
  {
    "id": "arXiv:2208.08118",
    "title": "Extreme-scale Talking-Face Video Upsampling with Audio-Visual Priors",
    "abstract": "In this paper, we explore an interesting question of what can be obtained\nfrom an $8\\times8$ pixel video sequence. Surprisingly, it turns out to be quite\na lot. We show that when we process this $8\\times8$ video with the right set of\naudio and image priors, we can obtain a full-length, $256\\times256$ video. We\nachieve this $32\\times$ scaling of an extremely low-resolution input using our\nnovel audio-visual upsampling network. The audio prior helps to recover the\nelemental facial details and precise lip shapes and a single high-resolution\ntarget identity image prior provides us with rich appearance details. Our\napproach is an end-to-end multi-stage framework. The first stage produces a\ncoarse intermediate output video that can be then used to animate single target\nidentity image and generate realistic, accurate and high-quality outputs. Our\napproach is simple and performs exceedingly well (an $8\\times$ improvement in\nFID score) compared to previous super-resolution methods. We also extend our\nmodel to talking-face video compression, and show that we obtain a $3.5\\times$\nimprovement in terms of bits/pixel over the previous state-of-the-art. The\nresults from our network are thoroughly analyzed through extensive ablation\nexperiments (in the paper and supplementary material). We also provide the demo\nvideo along with code and models on our website:\n\\url{this http URL}.",
    "descriptor": "\nComments: Accepted in ACM-MM 2022, 10 pages, 6 pages supplementary, 18 Figures\n",
    "authors": [
      "Sindhu B Hegde",
      "Rudrabha Mukhopadhyay",
      "Vinay P Namboodiri",
      "C. V. Jawahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08118"
  },
  {
    "id": "arXiv:2208.08119",
    "title": "Fast Distributed Vertex Splitting with Applications",
    "abstract": "We present ${\\rm poly\\log\\log n}$-round randomized distributed algorithms to\ncompute vertex splittings, a partition of the vertices of a graph into $k$\nparts such that a node of degree $d(u)$ has $\\approx d(u)/k$ neighbors in each\npart. Our techniques can be seen as the first progress towards general ${\\rm\npoly\\log\\log n}$-round algorithms for the Lov\\'asz Local Lemma.\nAs the main application of our result, we obtain a randomized ${\\rm\npoly\\log\\log n}$-round CONGEST algorithm for $(1+\\epsilon)\\Delta$-edge coloring\n$n$-node graphs of sufficiently large constant maximum degree $\\Delta$, for any\n$\\epsilon>0$. Further, our results improve the computation of defective\ncolorings and certain tight list coloring problems. All the results improve the\nstate-of-the-art round complexity exponentially, even in the LOCAL model.",
    "descriptor": "\nComments: accepted at DISC 2022\n",
    "authors": [
      "Magn\u00fas M. Halld\u00f3rsson",
      "Yannic Maus",
      "Alexandre Nolin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.08119"
  },
  {
    "id": "arXiv:2208.08120",
    "title": "Highly dynamic locomotion control of biped robot enhanced by swing arms",
    "abstract": "Swing arms have an irreplaceable role in promoting highly dynamic locomotion\non bipedal robots by a larger angular momentum control space from the viewpoint\nof biomechanics. Few bipedal robots utilize swing arms and its redundancy\ncharacteristic of multiple degrees of freedom due to the lack of appropriate\nlocomotion control strategies to perfectly integrate modeling and control. This\npaper presents a kind of control strategy by modeling the bipedal robot as a\nflywheel-spring loaded inverted pendulum (F-SLIP) to extract characteristics of\nswing arms and using the whole-body controller (WBC) to achieve these\ncharacteristics, and also proposes a evaluation system including three aspects\nof agility defined by us, stability and energy consumption for the highly\ndynamic locomotion of bipedal robots. We design several sets of simulation\nexperiments and analyze the effects of swing arms according to the evaluation\nsystem during the jumping motion of Purple (Purple energy rises in the\neast)V1.0, a kind of bipedal robot designed to test high explosive locomotion.\nResults show that Purple's agility is increased by more than 10 percent,\nstabilization time is reduced by a factor of two, and energy consumption is\nreduced by more than 20 percent after introducing swing arms.",
    "descriptor": "\nComments: 7 pages, 12 figures\n",
    "authors": [
      "Weijie Wang",
      "Song Liu",
      "Qinfeng Shan",
      "Lihao Jia"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.08120"
  },
  {
    "id": "arXiv:2208.08124",
    "title": "Boosting Distributed Training Performance of the Unpadded BERT Model",
    "abstract": "Pre-training models are an important tool in Natural Language Processing\n(NLP), while the BERT model is a classic pre-training model whose structure has\nbeen widely adopted by followers. It was even chosen as the reference model for\nthe MLPerf training benchmark. The distributed training performance\noptimization of BERT models plays an important role in accelerating the\nsolutions of most NLP tasks. BERT model often uses padding tensors as its\ninputs, leading to excessive redundant computations. Thus, removing these\nredundant computations is essential to improve the distributed training\nperformance.\nThis paper designs a new approach to train BERT models with variable-length\ninputs efficiently. Firstly, we propose a general structure for the\nvariable-length BERT models, and accelerate the encoder layer via our grouped\nmulti-stream FMHA (Fused Multi-Head Attention) method. Secondly, through data\nexchange, we address the unbalanced workload problem caused by the\nvariable-length inputs, which overlaps highly with the training process.\nFinally, we optimize the overall performance of the BERT model, such as kernel\nfusion, and operator optimization. Our experimental results show that our\nhighly optimized BERT model achieves state-of-the-art throughput and ranks\nfirst in MLPerf Training v2.0 within the same GPU configuration. The\noptimizations in this paper can be applied to more BERT-like models in our\nfuture works.",
    "descriptor": "",
    "authors": [
      "Jinle Zeng",
      "Min Li",
      "Zhihua Wu",
      "Jiaqi Liu",
      "Yuang Liu",
      "Dianhai Yu",
      "Yanjun Ma"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.08124"
  },
  {
    "id": "arXiv:2208.08125",
    "title": "A Tutorial Introduction to Lattice-based Cryptography and Homomorphic  Encryption",
    "abstract": "Why study Lattice-based Cryptography? There are a few ways to answer this\nquestion. 1. It is useful to have cryptosystems that are based on a variety of\nhard computational problems so the different cryptosystems are not all\nvulnerable in the same way. 2. The computational aspects of lattice-based\ncryptosystem are usually simple to understand and fairly easy to implement in\npractice. 3. Lattice-based cryptosystems have lower encryption/decryption\ncomputational complexities compared to popular cryptosystems that are based on\nthe integer factorisation or the discrete logarithm problems. 4. Lattice-based\ncryptosystems enjoy strong worst-case hardness security proofs based on\napproximate versions of known NP-hard lattice problems. 5. Lattice-based\ncryptosystems are believed to be good candidates for post-quantum cryptography,\nsince there are currently no known quantum algorithms for solving lattice\nproblems that perform significantly better than the best-known classical\n(non-quantum) algorithms, unlike for integer factorisation and (elliptic curve)\ndiscrete logarithm problems. 6. Last but not least, interesting structures in\nlattice problems have led to significant advances in Homomorphic Encryption, a\nnew research area with wide-ranging applications.",
    "descriptor": "",
    "authors": [
      "Yang Li",
      "Kee Siong Ng",
      "Michael Purcell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.08125"
  },
  {
    "id": "arXiv:2208.08128",
    "title": "On the Performance of Deep Learning-based Data-aided Active-user  Detection for GF-SCMA System",
    "abstract": "The recent works on a deep learning (DL)-based joint design of preamble set\nfor the transmitters and data-aided active user detection (AUD) in the receiver\nhas demonstrated a significant performance improvement for grant-free sparse\ncode multiple access (GF-SCMA) system. The autoencoder for the joint design can\nbe trained only in a given environment, but in an actual situation where the\noperating environment is constantly changing, it is difficult to optimize the\npreamble set for every possible environment. Therefore, a conventional, yet\ngeneral approach may implement the data-aided AUD while relying on the preamble\nset that is designed independently rather than the joint design. In this paper,\nthe activity detection error rate (ADER) performance of the data-aided AUD\nsubject to the two preamble designs, i.e., independently designed preamble and\njointly designed preamble, were directly compared. Fortunately, it was found\nthat the performance loss in the data-aided AUD induced by the independent\npreamble design is limited to only 1dB. Furthermore, such performance\ncharacteristics of jointly designed preamble set is interpreted through average\ncross-correlation among the preambles associated with the same codebook (CB)\n(average intra-CB cross-correlation) and average cross-correlation among\npreambles associated with the different CBs (average inter-CB\ncross-correlation).",
    "descriptor": "",
    "authors": [
      "Minsig Han",
      "Ameha Tsegaye Abebe",
      "Chung G. Kang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.08128"
  },
  {
    "id": "arXiv:2208.08130",
    "title": "Knowledge Graph Curation: A Practical Framework",
    "abstract": "Knowledge Graphs (KGs) have shown to be very important for applications such\nas personal assistants, question-answering systems, and search engines.\nTherefore, it is crucial to ensure their high quality. However, KGs inevitably\ncontain errors, duplicates, and missing values, which may hinder their adoption\nand utility in business applications, as they are not curated, e.g.,\nlow-quality KGs produce low-quality applications that are built on top of them.\nIn this vision paper, we propose a practical knowledge graph curation framework\nfor improving the quality of KGs. First, we define a set of quality metrics for\nassessing the status of KGs, Second, we describe the verification and\nvalidation of KGs as cleaning tasks, Third, we present duplicate detection and\nknowledge fusion strategies for enriching KGs. Furthermore, we give insights\nand directions toward a better architecture for curating KGs.",
    "descriptor": "\nComments: 6 pages, 1 figure, published in The 10th International Joint Conference on Knowledge Graphs (IJCKG'21) proceeding\n",
    "authors": [
      "Elwin Huaman",
      "Dieter Fensel"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.08130"
  },
  {
    "id": "arXiv:2208.08131",
    "title": "Domestic sound event detection by shift consistency mean-teacher  training and adversarial domain adaptation",
    "abstract": "Semi-supervised learning and domain adaptation techniques have drawn\nincreasing attention in the field of domestic sound event detection thanks to\nthe availability of large amounts of unlabeled data and the relative ease to\ngenerate synthetic strongly-labeled data. In a previous work, several\nsemi-supervised learning strategies were designed to boost the performance of a\nmean-teacher model. Namely, these strategies include shift consistency training\n(SCT), interpolation consistency training (ICT), and pseudo-labeling. However,\nadversarial domain adaptation (ADA) did not seem to improve the event detection\naccuracy further when we attempt to compensate for the domain gap between\nsynthetic and real data. In this research, we empirically found that ICT tends\nto pull apart the distributions of synthetic and real data in t-SNE plots.\nTherefore, ICT is abandoned while SCT, in contrast, is applied to train both\nthe student and the teacher models. With these modifications, the system\nsuccessfully integrates with an ADA network, and we achieve 47.2% in the F1\nscore on the DCASE 2020 task 4 dataset, which is 2.1% higher than what was\nreported in the previous work.",
    "descriptor": "",
    "authors": [
      "Fang-Ching Chen",
      "Kuan-Dar Chen",
      "Yi-Wen Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2208.08131"
  },
  {
    "id": "arXiv:2208.08132",
    "title": "Maximising the Utility of Validation Sets for Imbalanced Noisy-label  Meta-learning",
    "abstract": "Meta-learning is an effective method to handle imbalanced and noisy-label\nlearning, but it depends on a validation set containing randomly selected,\nmanually labelled and balanced distributed samples. The random selection and\nmanual labelling and balancing of this validation set is not only sub-optimal\nfor meta-learning, but it also scales poorly with the number of classes. Hence,\nrecent meta-learning papers have proposed ad-hoc heuristics to automatically\nbuild and label this validation set, but these heuristics are still sub-optimal\nfor meta-learning. In this paper, we analyse the meta-learning algorithm and\npropose new criteria to characterise the utility of the validation set, based\non: 1) the informativeness of the validation set; 2) the class distribution\nbalance of the set; and 3) the correctness of the labels of the set.\nFurthermore, we propose a new imbalanced noisy-label meta-learning (INOLML)\nalgorithm that automatically builds a validation set by maximising its utility\nusing the criteria above. Our method shows significant improvements over\nprevious meta-learning approaches and sets the new state-of-the-art on several\nbenchmarks.",
    "descriptor": "",
    "authors": [
      "Dung Anh Hoang",
      "Cuong Nguyen anh Belagiannis Vasileios",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08132"
  },
  {
    "id": "arXiv:2208.08133",
    "title": "Metric Residual Networks for Sample Efficient Goal-conditioned  Reinforcement Learning",
    "abstract": "Goal-conditioned reinforcement learning (GCRL) has a wide range of potential\nreal-world applications, including manipulation and navigation problems in\nrobotics. Especially in such robotics task, sample efficiency is of the utmost\nimportance for GCRL since, by default, the agent is only rewarded when it\nreaches its goal. While several methods have been proposed to improve the\nsample efficiency of GCRL, one relatively under-studied approach is the design\nof neural architectures to support sample efficiency. In this work, we\nintroduce a novel neural architecture for GCRL that achieves significantly\nbetter sample efficiency than the commonly-used monolithic network\narchitecture. They key insight is that the optimal action value function Q^*(s,\na, g) must satisfy the triangle inequality in a specific sense. Furthermore, we\nintroduce the metric residual network (MRN) that deliberately decomposes the\naction-value function Q(s,a,g) into the negated summation of a metric plus a\nresidual asymmetric component. MRN provably approximates any optimal\naction-value function Q^*(s,a,g), thus making it a fitting neural architecture\nfor GCRL. We conduct comprehensive experiments across 12 standard benchmark\nenvironments in GCRL. The empirical results demonstrate that MRN uniformly\noutperforms other state-of-the-art GCRL neural architectures in terms of sample\nefficiency.",
    "descriptor": "\nComments: Goal-conditioned reinforcement learning, neural architecture design\n",
    "authors": [
      "Bo Liu",
      "Yihao Feng",
      "Qiang Liu",
      "Peter Stone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.08133"
  },
  {
    "id": "arXiv:2208.08135",
    "title": "Gradient-Based Meta-Learning Using Uncertainty to Weigh Loss for  Few-Shot Learning",
    "abstract": "Model-Agnostic Meta-Learning (MAML) is one of the most successful\nmeta-learning techniques for few-shot learning. It uses gradient descent to\nlearn commonalities between various tasks, enabling the model to learn the\nmeta-initialization of its own parameters to quickly adapt to new tasks using a\nsmall amount of labeled training data. A key challenge to few-shot learning is\ntask uncertainty. Although a strong prior can be obtained from meta-learning\nwith a large number of tasks, a precision model of the new task cannot be\nguaranteed because the volume of the training dataset is normally too small. In\nthis study, first,in the process of choosing initialization parameters, the new\nmethod is proposed for task-specific learner adaptively learn to select\ninitialization parameters that minimize the loss of new tasks. Then, we propose\ntwo improved methods for the meta-loss part: Method 1 generates weights by\ncomparing meta-loss differences to improve the accuracy when there are few\nclasses, and Method 2 introduces the homoscedastic uncertainty of each task to\nweigh multiple losses based on the original gradient descent,as a way to\nenhance the generalization ability to novel classes while ensuring accuracy\nimprovement. Compared with previous gradient-based meta-learning methods, our\nmodel achieves better performance in regression tasks and few-shot\nclassification and improves the robustness of the model to the learning rate\nand query sets in the meta-test set.",
    "descriptor": "",
    "authors": [
      "Lin Ding",
      "Peng Liu",
      "Wenfeng Shen",
      "Weijia Lu",
      "Shengbo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08135"
  },
  {
    "id": "arXiv:2208.08140",
    "title": "Differential Privacy in Natural Language Processing: The Story So Far",
    "abstract": "As the tide of Big Data continues to influence the landscape of Natural\nLanguage Processing (NLP), the utilization of modern NLP methods has grounded\nitself in this data, in order to tackle a variety of text-based tasks. These\nmethods without a doubt can include private or otherwise personally\nidentifiable information. As such, the question of privacy in NLP has gained\nfervor in recent years, coinciding with the development of new\nPrivacy-Enhancing Technologies (PETs). Among these PETs, Differential Privacy\nboasts several desirable qualities in the conversation surrounding data\nprivacy. Naturally, the question becomes whether Differential Privacy is\napplicable in the largely unstructured realm of NLP. This topic has sparked\nnovel research, which is unified in one basic goal: how can one adapt\nDifferential Privacy to NLP methods? This paper aims to summarize the\nvulnerabilities addressed by Differential Privacy, the current thinking, and\nabove all, the crucial next steps that must be considered.",
    "descriptor": "",
    "authors": [
      "Oleksandra Klymenko",
      "Stephen Meisenbacher",
      "Florian Matthes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08140"
  },
  {
    "id": "arXiv:2208.08145",
    "title": "Stereo Superpixel Segmentation Via Decoupled Dynamic Spatial-Embedding  Fusion Network",
    "abstract": "Stereo superpixel segmentation aims at grouping the discretizing pixels into\nperceptual regions through left and right views more collaboratively and\nefficiently. Existing superpixel segmentation algorithms mostly utilize color\nand spatial features as input, which may impose strong constraints on spatial\ninformation while utilizing the disparity information in terms of stereo image\npairs. To alleviate this issue, we propose a stereo superpixel segmentation\nmethod with a decoupling mechanism of spatial information in this work. To\ndecouple stereo disparity information and spatial information, the spatial\ninformation is temporarily removed before fusing the features of stereo image\npairs, and a decoupled stereo fusion module (DSFM) is proposed to handle the\nstereo features alignment as well as occlusion problems. Moreover, since the\nspatial information is vital to superpixel segmentation, we further design a\ndynamic spatiality embedding module (DSEM) to re-add spatial information, and\nthe weights of spatial information will be adaptively adjusted through the\ndynamic fusion (DF) mechanism in DSEM for achieving a finer segmentation.\nComprehensive experimental results demonstrate that our method can achieve the\nstate-of-the-art performance on the KITTI2015 and Cityscapes datasets, and also\nverify the efficiency when applied in salient object detection on NJU2K\ndataset. The source code will be available publicly after paper is accepted.",
    "descriptor": "\nComments: 11 pages, 13 figures\n",
    "authors": [
      "Hua Li",
      "Junyan Liang",
      "Ruiqi Wu",
      "Runmin Cong",
      "Junhui Wu",
      "Sam Tak Wu Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08145"
  },
  {
    "id": "arXiv:2208.08147",
    "title": "On Specifications and Proofs of Timed Circuits",
    "abstract": "Given a discrete-state continuous-time reactive system, like a digital\ncircuit, the classical approach is to first model it as a state transition\nsystem and then prove its properties. Our contribution advocates a different\napproach: to directly operate on the input-output behavior of such systems,\nwithout identifying states and their transitions in the first place. We discuss\nthe benefits of this approach at hand of some examples, which demonstrate that\nit nicely integrates with concepts of self-stabilization and fault-tolerance.\nWe also elaborate on some unexpected artefacts of module composition in our\nframework, and conclude with some open research questions.",
    "descriptor": "\nComments: will be published in \"Thomas Henzinger Festschrift - Conference celebrating his 60th birthday\"\n",
    "authors": [
      "Matthias Fuegger",
      "Christoph Lenzen",
      "Ulrich Schmid"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.08147"
  },
  {
    "id": "arXiv:2208.08149",
    "title": "A Concept and Argumentation based Interpretable Model in High Risk  Domains",
    "abstract": "Interpretability has become an essential topic for artificial intelligence in\nsome high-risk domains such as healthcare, bank and security. For commonly-used\ntabular data, traditional methods trained end-to-end machine learning models\nwith numerical and categorical data only, and did not leverage human\nunderstandable knowledge such as data descriptions. Yet mining human-level\nknowledge from tabular data and using it for prediction remain a challenge.\nTherefore, we propose a concept and argumentation based model (CAM) that\nincludes the following two components: a novel concept mining method to obtain\nhuman understandable concepts and their relations from both descriptions of\nfeatures and the underlying data, and a quantitative argumentation-based method\nto do knowledge representation and reasoning. As a result of it, CAM provides\ndecisions that are based on human-level knowledge and the reasoning process is\nintrinsically interpretable. Finally, to visualize the purposed interpretable\nmodel, we provide a dialogical explanation that contain dominated reasoning\npath within CAM. Experimental results on both open source benchmark dataset and\nreal-word business dataset show that (1) CAM is transparent and interpretable,\nand the knowledge inside the CAM is coherent with human understanding; (2) Our\ninterpretable approach can reach competitive results comparing with other\nstate-of-art models.",
    "descriptor": "",
    "authors": [
      "Haixiao Chi",
      "Dawei Wang",
      "Gaojie Cui",
      "Feng Mao",
      "Beishui Liao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08149"
  },
  {
    "id": "arXiv:2208.08153",
    "title": "Maximum-norm a posteriori error bounds for an extrapolated Euler/finite  element discretisation of parabolic equations",
    "abstract": "A class of linear parabolic equations are considered. We give a posteriori\nerror estimates in the maximum norm for a method that comprises extrapolation\napplied to the backward Euler method in time and finite element discretisations\nin space. We use the idea of elliptic reconstructions and certain bounds for\nthe Green's function of the parabolic operator.",
    "descriptor": "",
    "authors": [
      "Torsten Lin\u00df",
      "Goran Radojev"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.08153"
  },
  {
    "id": "arXiv:2208.08157",
    "title": "On Establishing Robust Consistency in Answer Set Programs",
    "abstract": "Answer set programs used in real-world applications often require that the\nprogram is usable with different input data. This, however, can often lead to\ncontradictory statements and consequently to an inconsistent program. Causes\nfor potential contradictions in a program are conflicting rules. In this paper,\nwe show how to ensure that a program $\\mathcal{P}$ remains non-contradictory\ngiven any allowed set of such input data. For that, we introduce the notion of\nconflict-resolving $\\lambda$- extensions. A conflict-resolving\n$\\lambda$-extension for a conflicting rule $r$ is a set $\\lambda$ of (default)\nliterals such that extending the body of $r$ by $\\lambda$ resolves all\nconflicts of $r$ at once. We investigate the properties that suitable\n$\\lambda$-extensions should possess and building on that, we develop a strategy\nto compute all such conflict-resolving $\\lambda$-extensions for each\nconflicting rule in $\\mathcal{P}$. We show that by implementing a conflict\nresolution process that successively resolves conflicts using\n$\\lambda$-extensions eventually yields a program that remains non-contradictory\ngiven any allowed set of input data.",
    "descriptor": "\nComments: Under consideration in Theory and Practice of Logic Programming (TPLP)\n",
    "authors": [
      "Andre Thevapalan",
      "Gabriele Kern-Isberner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08157"
  },
  {
    "id": "arXiv:2208.08159",
    "title": "Gathering Despite Defected View",
    "abstract": "An autonomous mobile robot system consisting of many mobile computational\nentities (called robots) attracts much attention of researchers, and to clarify\nthe relation between the capabilities of robots and solvability of the problems\nis an emerging issue for a recent couple of decades. Generally, each robot can\nobserve all other robots as long as there are no restrictions for visibility\nrange or obstructions, regardless of the number of robots. In this paper, we\nprovide a new perspective on the observation by robots; a robot cannot\nnecessarily observe all other robots regardless of distances to them. We call\nthis new computational model defected view model. Under this model, in this\npaper, we consider the gathering problem that requires all the robots to gather\nat the same point and propose two algorithms to solve the gathering problem in\nthe adversarial ($N$,$N-2$)-defected model for $N \\geq 5$ (where each robot\nobserves at most $N-2$ robots chosen adversarially) and the distance-based\n(4,2)-defected model (where each robot observes at most 2 closest robots to\nitself) respectively, where $N$ is the number of robots. Moreover, we present\nan impossibility result showing that there is no (deterministic) gathering\nalgorithm in the adversarial or distance-based (3,1)-defected model. Moreover,\nwe show an impossibility result for the gathering in a relaxed ($N$,\n$N-2$)-defected model.",
    "descriptor": "\nComments: 18 pages, 11 figures, will be published as a brief announcement (short version) in DISC2022\n",
    "authors": [
      "Yonghwan Kim",
      "Masahiro Shibata",
      "Yuichi Sudo",
      "Junya Nakamura",
      "Yoshiaki Katayama",
      "Toshimitsu Masuzawa"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.08159"
  },
  {
    "id": "arXiv:2208.08160",
    "title": "Information Loss in Euclidean Preference Models",
    "abstract": "Spatial models of preference, in the form of vector embeddings, are learned\nby many deep learning systems including recommender systems. Often these models\nare assumed to approximate a Euclidean structure, where an individual prefers\nalternatives positioned closer to their \"ideal point\", as measured by the\nEuclidean metric. However, Bogomolnaia and Laslier (2007) showed that there\nexist ordinal preference profiles that cannot be represented with this\nstructure if the Euclidean space has two fewer dimensions than there are\nindividuals or alternatives. We extend this result, showing that there are\nrealistic situations in which almost all preference profiles cannot be\nrepresented with the Euclidean model, and derive a theoretical lower bound on\nthe information lost when approximating non-representable preferences with the\nEuclidean model. Our results have implications for the interpretation and use\nof vector embeddings, because in some cases close approximation of arbitrary,\ntrue preferences is possible only if the dimensionality of the embeddings is a\nsubstantial fraction of the number of individuals or alternatives.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Luke Thorburn",
      "Maria Polukarov",
      "Carmine Ventre"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08160"
  },
  {
    "id": "arXiv:2208.08161",
    "title": "KAM -- a Kernel Attention Module for Emotion Classification with EEG  Data",
    "abstract": "In this work, a kernel attention module is presented for the task of\nEEG-based emotion classification with neural networks. The proposed module\nutilizes a self-attention mechanism by performing a kernel trick, demanding\nsignificantly fewer trainable parameters and computations than standard\nattention modules. The design also provides a scalar for quantitatively\nexamining the amount of attention assigned during deep feature refinement,\nhence help better interpret a trained model. Using EEGNet as the backbone\nmodel, extensive experiments are conducted on the SEED dataset to assess the\nmodule's performance on within-subject classification tasks compared to other\nSOTA attention modules. Requiring only one extra parameter, the inserted module\nis shown to boost the base model's mean prediction accuracy up to more than 1\\%\nacross 15 subjects. A key component of the method is the interpretability of\nsolutions, which is addressed using several different techniques, and is\nincluded throughout as part of the dependency analysis.",
    "descriptor": "\nComments: This preprint has not undergone peer review. The updated version is accepted by MICCAI2022 workshop: iMIMIC - Interpretability of Machine Intelligence in Medical Image Computing\n",
    "authors": [
      "Dongyang Kuang",
      "Craig Michoski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08161"
  },
  {
    "id": "arXiv:2208.08165",
    "title": "Towards Open-vocabulary Scene Graph Generation with Prompt-based  Finetuning",
    "abstract": "Scene graph generation (SGG) is a fundamental task aimed at detecting visual\nrelations between objects in an image. The prevailing SGG methods require all\nobject classes to be given in the training set. Such a closed setting limits\nthe practical application of SGG. In this paper, we introduce open-vocabulary\nscene graph generation, a novel, realistic and challenging setting in which a\nmodel is trained on a set of base object classes but is required to infer\nrelations for unseen target object classes. To this end, we propose a two-step\nmethod that firstly pre-trains on large amounts of coarse-grained\nregion-caption data and then leverages two prompt-based techniques to finetune\nthe pre-trained model without updating its parameters. Moreover, our method can\nsupport inference over completely unseen object classes, which existing methods\nare incapable of handling. On extensive experiments on three benchmark\ndatasets, Visual Genome, GQA, and Open-Image, our method significantly\noutperforms recent, strong SGG methods on the setting of Ov-SGG, as well as on\nthe conventional closed SGG.",
    "descriptor": "",
    "authors": [
      "Tao He",
      "Lianli Gao",
      "Jingkuan Song",
      "Yuan-Fang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08165"
  },
  {
    "id": "arXiv:2208.08166",
    "title": "Data-Efficient Vision Transformers for Multi-Label Disease  Classification on Chest Radiographs",
    "abstract": "Radiographs are a versatile diagnostic tool for the detection and assessment\nof pathologies, for treatment planning or for navigation and localization\npurposes in clinical interventions. However, their interpretation and\nassessment by radiologists can be tedious and error-prone. Thus, a wide variety\nof deep learning methods have been proposed to support radiologists\ninterpreting radiographs. Mostly, these approaches rely on convolutional neural\nnetworks (CNN) to extract features from images. Especially for the multi-label\nclassification of pathologies on chest radiographs (Chest X-Rays, CXR), CNNs\nhave proven to be well suited. On the Contrary, Vision Transformers (ViTs) have\nnot been applied to this task despite their high classification performance on\ngeneric images and interpretable local saliency maps which could add value to\nclinical interventions. ViTs do not rely on convolutions but on patch-based\nself-attention and in contrast to CNNs, no prior knowledge of local\nconnectivity is present. While this leads to increased capacity, ViTs typically\nrequire an excessive amount of training data which represents a hurdle in the\nmedical domain as high costs are associated with collecting large medical data\nsets. In this work, we systematically compare the classification performance of\nViTs and CNNs for different data set sizes and evaluate more data-efficient ViT\nvariants (DeiT). Our results show that while the performance between ViTs and\nCNNs is on par with a small benefit for ViTs, DeiTs outperform the former if a\nreasonably large data set is available for training.",
    "descriptor": "\nComments: Accepted at CURAC22 Conference\n",
    "authors": [
      "Finn Behrendt",
      "Debayan Bhattacharya",
      "Julia Kr\u00fcger",
      "Roland Opfer",
      "Alexander Schlaefer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08166"
  },
  {
    "id": "arXiv:2208.08168",
    "title": "Finding Fair Allocations under Budget Constraints",
    "abstract": "We study the fair allocation of indivisible goods among agents with\nidentical, additive valuations but individual budget constraints. Here, the\nindivisible goods--each with a specific size and value--need to be allocated\nsuch that the bundle assigned to each agent is of total size at most the\nagent's budget. Since envy-free allocations do not necessarily exist in the\nindivisible goods context, compelling relaxations--in particular, the notion of\nenvy-freeness up to $k$ goods (EFk)--have received significant attention in\nrecent years. In an EFk allocation, each agent prefers its own bundle over that\nof any other agent, up to the removal of $k$ goods, and the agents have\nsimilarly bounded envy against the charity (which corresponds to the set of all\nunallocated goods). Recently, Wu et al. (2021) showed that an allocation that\nsatisfies the budget constraints and maximizes the Nash social welfare is\n$1/4$-approximately EF1. However, the computation (or even existence) of exact\nEFk allocations remained an intriguing open problem.\nWe make notable progress towards this by proposing a simple, greedy,\npolynomial-time algorithm that computes EF2 allocations under budget\nconstraints. Our algorithmic result implies the universal existence of EF2\nallocations in this fair division context. The analysis of the algorithm\nexploits intricate structural properties of envy-freeness. Interestingly, the\nsame algorithm also provides EF1 guarantees for important special cases.\nSpecifically, we settle the existence of EF1 allocations for instances in\nwhich: (i) the value of each good is proportional to its size, (ii) all goods\nhave the same size, or (iii) all the goods have the same value. Our EF2 result\nextends to the setting wherein the goods' sizes are agent specific.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Siddharth Barman",
      "Arindam Khan",
      "Sudarshan Shyam",
      "K.V.N. Sreenivas"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2208.08168"
  },
  {
    "id": "arXiv:2208.08170",
    "title": "Random Search Hyper-Parameter Tuning: Expected Improvement Estimation  and the Corresponding Lower Bound",
    "abstract": "Hyperparameter tuning is a common technique for improving the performance of\nneural networks. Most techniques for hyperparameter search involve an iterated\nprocess where the model is retrained at every iteration. However, the expected\naccuracy improvement from every additional search iteration, is still unknown.\nCalculating the expected improvement can help create stopping rules for\nhyperparameter tuning and allow for a wiser allocation of a project's\ncomputational budget. In this paper, we establish an empirical estimate for the\nexpected accuracy improvement from an additional iteration of hyperparameter\nsearch. Our results hold for any hyperparameter tuning method which is based on\nrandom search \\cite{bergstra2012random} and samples hyperparameters from a\nfixed distribution. We bound our estimate with an error of\n$O\\left(\\sqrt{\\frac{\\log k}{k}}\\right)$ w.h.p. where $k$ is the current number\nof iterations. To the best of our knowledge this is the first bound on the\nexpected gain from an additional iteration of hyperparameter search. Finally,\nwe demonstrate that the optimal estimate for the expected accuracy will still\nhave an error of $\\frac{1}{k}$.",
    "descriptor": "",
    "authors": [
      "Dan Navon",
      "Alex M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08170"
  },
  {
    "id": "arXiv:2208.08173",
    "title": "An In-depth Study of Java Deserialization Remote-Code Execution Exploits  and Vulnerabilities",
    "abstract": "Nowadays, an increasing number of applications uses deserialization. This\ntechnique, based on rebuilding the instance of objects from serialized byte\nstreams, can be dangerous since it can open the application to attacks such as\nremote code execution (RCE) if the data to deserialize is originating from an\nuntrusted source. Deserialization vulnerabilities are so critical that they are\nin OWASP's list of top 10 security risks for web applications. This is mainly\ncaused by faults in the development process of applications and by flaws in\ntheir dependencies, i.e., flaws in the libraries used by these applications. No\nprevious work has studied deserialization attacks in-depth: How are they\nperformed? How are weaknesses introduced and patched? And for how long are\nvulnerabilities present in the codebase? To yield a deeper understanding of\nthis important kind of vulnerability, we perform two main analyses: one on\nattack gadgets, i.e., exploitable pieces of code, present in Java libraries,\nand one on vulnerabilities present in Java applications. For the first\nanalysis, we conduct an exploratory large-scale study by running 256515\nexperiments in which we vary the versions of libraries for each of the 19\npublicly available exploits. Such attacks rely on a combination of gadgets\npresent in one or multiple Java libraries. A gadget is a method which is using\nobjects or fields that can be attacker-controlled. Our goal is to precisely\nidentify library versions containing gadgets and to understand how gadgets have\nbeen introduced and how they have been patched. We observe that the\nmodification of one innocent-looking detail in a class -- such as making it\npublic -- can already introduce a gadget. Furthermore, we noticed that among\nthe studied libraries, 37.5% are not patched, leaving gadgets available for\nfuture attacks. For the second analysis, we manually analyze 104\ndeserialization vulnerabilities CVEs to understand how vulnerabilities are\nintroduced and patched in real-life Java applications. Results indicate that\nthe vulnerabilities are not always completely patched or that a workaround\nsolution is proposed. With a workaround solution, applications are still\nvulnerable since the code itself is unchanged.",
    "descriptor": "\nComments: ACM Transactions on Software Engineering and Methodology, Association for Computing Machinery, 2022\n",
    "authors": [
      "Imen Sayar",
      "Alexandre Bartel",
      "Eric Bodden",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.08173"
  },
  {
    "id": "arXiv:2208.08175",
    "title": "Expressivity of Hidden Markov Chains vs. Recurrent Neural Networks from  a system theoretic viewpoint",
    "abstract": "Hidden Markov Chains (HMC) and Recurrent Neural Networks (RNN) are two well\nknown tools for predicting time series. Even though these solutions were\ndeveloped independently in distinct communities, they share some similarities\nwhen considered as probabilistic structures. So in this paper we first consider\nHMC and RNN as generative models, and we embed both structures in a common\ngenerative unified model (GUM). We next address a comparative study of the\nexpressivity of these models. To that end we assume that the models are\nfurthermore linear and Gaussian. The probability distributions produced by\nthese models are characterized by structured covariance series, and as a\nconsequence expressivity reduces to comparing sets of structured covariance\nseries, which enables us to call for stochastic realization theory (SRT). We\nfinally provide conditions under which a given covariance series can be\nrealized by a GUM, an HMC or an RNN.",
    "descriptor": "",
    "authors": [
      "Fran\u00e7ois Desbouvries",
      "Yohan Petetin",
      "Achille Sala\u00fcn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.08175"
  },
  {
    "id": "arXiv:2208.08176",
    "title": "Visual Comparison of Language Model Adaptation",
    "abstract": "Neural language models are widely used; however, their model parameters often\nneed to be adapted to the specific domains and tasks of an application, which\nis time- and resource-consuming. Thus, adapters have recently been introduced\nas a lightweight alternative for model adaptation. They consist of a small set\nof task-specific parameters with a reduced training time and simple parameter\ncomposition. The simplicity of adapter training and composition comes along\nwith new challenges, such as maintaining an overview of adapter properties and\neffectively comparing their produced embedding spaces. To help developers\novercome these challenges, we provide a twofold contribution. First, in close\ncollaboration with NLP researchers, we conducted a requirement analysis for an\napproach supporting adapter evaluation and detected, among others, the need for\nboth intrinsic (i.e., embedding similarity-based) and extrinsic (i.e.,\nprediction-based) explanation methods. Second, motivated by the gathered\nrequirements, we designed a flexible visual analytics workspace that enables\nthe comparison of adapter properties. In this paper, we discuss several design\niterations and alternatives for interactive, comparative visual explanation\nmethods. Our comparative visualizations show the differences in the adapted\nembedding vectors and prediction outcomes for diverse human-interpretable\nconcepts (e.g., person names, human qualities). We evaluate our workspace\nthrough case studies and show that, for instance, an adapter trained on the\nlanguage debiasing task according to context-0 (decontextualized) embeddings\nintroduces a new type of bias where words (even gender-independent words such\nas countries) become more similar to female than male pronouns. We demonstrate\nthat these are artifacts of context-0 embeddings.",
    "descriptor": "",
    "authors": [
      "Rita Sevastjanova",
      "Eren Cakmak",
      "Shauli Ravfogel",
      "Ryan Cotterell",
      "Mennatallah El-Assady"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08176"
  },
  {
    "id": "arXiv:2208.08182",
    "title": "Deep Learning-Based Discrete Calibrated Survival Prediction",
    "abstract": "Deep neural networks for survival prediction outper-form classical approaches\nin discrimination, which is the ordering of patients according to their\ntime-of-event. Conversely, classical approaches like the Cox Proportional\nHazards model display much better calibration, the correct temporal prediction\nof events of the underlying distribution. Especially in the medical domain,\nwhere it is critical to predict the survival of a single patient, both\ndiscrimination and calibration are important performance metrics. Here we\npresent Discrete Calibrated Survival (DCS), a novel deep neural network for\ndiscriminated and calibrated survival prediction that outperforms competing\nsurvival models in discrimination on three medical datasets, while achieving\nbest calibration among all discrete time models. The enhanced performance of\nDCS can be attributed to two novel features, the variable temporal output node\nspacing and the novel loss term that optimizes the use of uncensored and\ncensored patient data. We believe that DCS is an important step towards\nclinical application of deep-learning-based survival prediction with\nstate-of-the-art discrimination and good calibration.",
    "descriptor": "\nComments: Accepted as a short conference paper at ICDH 2022\n",
    "authors": [
      "Patrick Fuhlert",
      "Anne Ernst",
      "Esther Dietrich",
      "Fabian Westhaeusser",
      "Karin Kloiber",
      "Stefan Bonn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08182"
  },
  {
    "id": "arXiv:2208.08190",
    "title": "DeepSportradar-v1: Computer Vision Dataset for Sports Understanding with  High Quality Annotations",
    "abstract": "With the recent development of Deep Learning applied to Computer Vision,\nsport video understanding has gained a lot of attention, providing much richer\ninformation for both sport consumers and leagues. This paper introduces\nDeepSportradar-v1, a suite of computer vision tasks, datasets and benchmarks\nfor automated sport understanding. The main purpose of this framework is to\nclose the gap between academic research and real world settings. To this end,\nthe datasets provide high-resolution raw images, camera parameters and high\nquality annotations. DeepSportradar currently supports four challenging tasks\nrelated to basketball: ball 3D localization, camera calibration, player\ninstance segmentation and player re-identification. For each of the four tasks,\na detailed description of the dataset, objective, performance metrics, and the\nproposed baseline method are provided. To encourage further research on\nadvanced methods for sport understanding, a competition is organized as part of\nthe MMSports workshop from the ACM Multimedia 2022 conference, where\nparticipants have to develop state-of-the-art methods to solve the above tasks.\nThe four datasets, development kits and baselines are publicly available.",
    "descriptor": "",
    "authors": [
      "Gabriel Van Zandycke",
      "Vladimir Somers",
      "Maxime Istasse",
      "Carlo Del Don",
      "Davide Zambrano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.08190"
  },
  {
    "id": "arXiv:2208.08191",
    "title": "Transformer Vs. MLP-Mixer Exponential Expressive Gap For NLP Problems",
    "abstract": "Vision-Transformers are widely used in various vision tasks. Meanwhile, there\nis another line of works starting with the MLP-mixer trying to achieve similar\nperformance using mlp-based architectures. Interestingly, until now none\nreported using them for NLP tasks, additionally until now non of those\nmlp-based architectures claimed to achieve state-of-the-art in vision tasks. In\nthis paper, we analyze the expressive power of mlp-based architectures in\nmodeling dependencies between multiple different inputs simultaneously, and\nshow an exponential gap between the attention and the mlp-based mechanisms. Our\nresults suggest a theoretical explanation for the mlp inability to compete with\nattention-based mechanisms in NLP problems, they also suggest that the\nperformance gap in vision tasks may be due to the mlp relative weakness in\nmodeling dependencies between multiple different locations, and that combining\nsmart input permutations to the mlp architectures may not suffice alone to\nclose the performance gap.",
    "descriptor": "",
    "authors": [
      "Dan Navon",
      "Alex M. Bronstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08191"
  },
  {
    "id": "arXiv:2208.08193",
    "title": "A Survey of User Perspectives on Security and Privacy in a Home  Networking Environment",
    "abstract": "The security and privacy of smart home systems, particularly from a home\nuser's perspective, have been a very active research area in recent years.\nHowever, via a meta-review of 52 review papers covering related topics\n(published between 2000 and 2021), this paper shows a lack of a more recent\nliterature review on user perspectives of smart home security and privacy since\nthe 2010s. This identified gap motivated us to conduct a systematic literature\nreview (SLR) covering 126 relevant research papers published from 2010 to 2021.\nOur SLR led to the discovery of a number of important areas where further\nresearch is needed; these include holistic methods that consider a more diverse\nand heterogeneous range of home devices, interactions between multiple home\nusers, complicated data flow between multiple home devices and home users, some\nless-studied demographic factors, and advanced conceptual frameworks. Based on\nthese findings, we recommended key future research directions, e.g., research\nfor a better understanding of security and privacy aspects in different\nmulti-device and multi-user contexts, and a more comprehensive ontology on the\nsecurity and privacy of the smart home covering varying types of home devices\nand behaviors of different types of home users.",
    "descriptor": "\nComments: 37 pages, Accepted to be published in ACM Computing Surveys\n",
    "authors": [
      "Nandita Pattnaik",
      "Shujun Li",
      "Jason R.C. Nurse"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.08193"
  },
  {
    "id": "arXiv:2208.08195",
    "title": "Learning Transductions to Test Systematic Compositionality",
    "abstract": "Recombining known primitive concepts into larger novel combinations is a\nquintessentially human cognitive capability. Whether large neural models in NLP\nacquire this ability while learning from data is an open question. In this\npaper, we look at this problem from the perspective of formal languages. We use\ndeterministic finite-state transducers to make an unbounded number of datasets\nwith controllable properties governing compositionality. By randomly sampling\nover many transducers, we explore which of their properties (number of states,\nalphabet size, number of transitions etc.) contribute to learnability of a\ncompositional relation by a neural network. In general, we find that the models\neither learn the relations completely or not at all. The key is transition\ncoverage, setting a soft learnability limit at 400 examples per transition.",
    "descriptor": "",
    "authors": [
      "Josef Valvoda",
      "Naomi Saphra",
      "Jonathan Rawski",
      "Ryan Cotterell",
      "Adina Williams"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08195"
  },
  {
    "id": "arXiv:2208.08198",
    "title": "Assurance Cases as Foundation Stone for Auditing AI-enabled and  Autonomous Systems: Workshop Results and Political Recommendations for Action  from the ExamAI Project",
    "abstract": "The European Machinery Directive and related harmonized standards do consider\nthat software is used to generate safety-relevant behavior of the machinery but\ndo not consider all kinds of software. In particular, software based on machine\nlearning (ML) are not considered for the realization of safety-relevant\nbehavior. This limits the introduction of suitable safety concepts for\nautonomous mobile robots and other autonomous machinery, which commonly depend\non ML-based functions. We investigated this issue and the way safety standards\ndefine safety measures to be implemented against software faults. Functional\nsafety standards use Safety Integrity Levels (SILs) to define which safety\nmeasures shall be implemented. They provide rules for determining the SIL and\nrules for selecting safety measures depending on the SIL. In this paper, we\nargue that this approach can hardly be adopted with respect to ML and other\nkinds of Artificial Intelligence (AI). Instead of simple rules for determining\nan SIL and applying related measures against faults, we propose the use of\nassurance cases to argue that the individually selected and applied measures\nare sufficient in the given case. To get a first rating regarding the\nfeasibility and usefulness of our proposal, we presented and discussed it in a\nworkshop with experts from industry, German statutory accident insurance\ncompanies, work safety and standardization commissions, and representatives\nfrom various national, European, and international working groups dealing with\nsafety and AI. In this paper, we summarize the proposal and the workshop\ndiscussion. Moreover, we check to which extent our proposal is in line with the\nEuropean AI Act proposal and current safety standardization initiatives\naddressing AI and Autonomous Systems",
    "descriptor": "",
    "authors": [
      "Rasmus Adler",
      "Michael Klaes"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08198"
  },
  {
    "id": "arXiv:2208.08200",
    "title": "AHEAD: A Triple Attention Based Heterogeneous Graph Anomaly Detection  Approach",
    "abstract": "Graph anomaly detection on attributed networks has become a prevalent\nresearch topic due to its broad applications in many influential domains. In\nreal-world scenarios, nodes and edges in attributed networks usually display\ndistinct heterogeneity, i.e. attributes of different types of nodes show great\nvariety, different types of relations represent diverse meanings. Anomalies\nusually perform differently from the majority in various perspectives of\nheterogeneity in these networks. However, existing graph anomaly detection\napproaches do not leverage heterogeneity in attributed networks, which is\nhighly related to anomaly detection. In light of this problem, we propose\nAHEAD: a heterogeneity-aware unsupervised graph anomaly detection approach\nbased on the encoder-decoder framework. Specifically, for the encoder, we\ndesign three levels of attention, i.e. attribute level, node type level, and\nedge level attentions to capture the heterogeneity of network structure, node\nproperties and information of a single node, respectively. In the decoder, we\nexploit structure, attribute, and node type reconstruction terms to obtain an\nanomaly score for each node. Extensive experiments show the superiority of\nAHEAD on several real-world heterogeneous information networks compared with\nthe state-of-arts in the unsupervised setting. Further experiments verify the\neffectiveness and robustness of our triple attention, model backbone, and\ndecoder in general.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Shujie Yang",
      "Binchi Zhang",
      "Shangbin Feng",
      "Zhaoxuan Tan",
      "Qinghua Zheng",
      "Jun Zhou",
      "Minnan Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08200"
  },
  {
    "id": "arXiv:2208.08201",
    "title": "Understanding Long Documents with Different Position-Aware Attentions",
    "abstract": "Despite several successes in document understanding, the practical task for\nlong document understanding is largely under-explored due to several challenges\nin computation and how to efficiently absorb long multimodal input. Most\ncurrent transformer-based approaches only deal with short documents and employ\nsolely textual information for attention due to its prohibitive computation and\nmemory limit. To address those issues in long document understanding, we\nexplore different approaches in handling 1D and new 2D position-aware attention\nwith essentially shortened context. Experimental results show that our proposed\nmodels have advantages for this task based on various evaluation metrics.\nFurthermore, our model makes changes only to the attention and thus can be\neasily adapted to any transformer-based architecture.",
    "descriptor": "",
    "authors": [
      "Hai Pham",
      "Guoxin Wang",
      "Yijuan Lu",
      "Dinei Florencio",
      "Cha Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08201"
  },
  {
    "id": "arXiv:2208.08202",
    "title": "Elevation State-Space: Surfel-Based Navigation in Uneven Environments  for Mobile Robots",
    "abstract": "This paper introduces a new method for robot motion planning and navigation\nin uneven environments through a surfel representation of underlying point\nclouds. The proposed method addresses the shortcomings of state-of-the-art\nnavigation methods by incorporating both kinematic and physical constraints of\na robot with standard motion planning algorithms (e.g., those from the Open\nMotion Planning Library), thus enabling efficient sampling-based planners for\nchallenging uneven terrain navigation on raw point cloud maps. Unlike\ntechniques based on Digital Elevation Maps (DEMs), our novel surfel-based\nstate-space formulation and implementation are based on raw point cloud maps,\nallowing for the modeling of overlapping surfaces such as bridges, piers, and\ntunnels. Experimental results demonstrate the robustness of the proposed method\nfor robot navigation in real and simulated unstructured environments. The\nproposed approach also optimizes planners' performances by boosting their\nsuccess rates up to 5x for challenging unstructured terrain planning and\nnavigation, thanks to our surfel-based approach's robot constraint-aware\nsampling strategy. Finally, we provide an open-source implementation of the\nproposed method to benefit the robotics community.",
    "descriptor": "\nComments: Accepted to IROS 2022\n",
    "authors": [
      "Fetullah Atas",
      "Grzegorz Cielniak",
      "Lars Grimstad"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.08202"
  },
  {
    "id": "arXiv:2208.08207",
    "title": "Time flies by: Analyzing the Impact of Face Ageing on the Recognition  Performance with Synthetic Data",
    "abstract": "The vast progress in synthetic image synthesis enables the generation of\nfacial images in high resolution and photorealism. In biometric applications,\nthe main motivation for using synthetic data is to solve the shortage of\npublicly-available biometric data while reducing privacy risks when processing\nsuch sensitive information. These advantages are exploited in this work by\nsimulating human face ageing with recent face age modification algorithms to\ngenerate mated samples, thereby studying the impact of ageing on the\nperformance of an open-source biometric recognition system. Further, a real\ndataset is used to evaluate the effects of short-term ageing, comparing the\nbiometric performance to the synthetic domain. The main findings indicate that\nshort-term ageing in the range of 1-5 years has only minor effects on the\ngeneral recognition performance. However, the correct verification of mated\nfaces with long-term age differences beyond 20 years poses still a significant\nchallenge and requires further investigation.",
    "descriptor": "",
    "authors": [
      "Marcel Grimmer",
      "Haoyu Zhang",
      "Raghavendra Ramachandra",
      "Kiran Raja",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08207"
  },
  {
    "id": "arXiv:2208.08211",
    "title": "Path Planning of Cleaning Robot with Reinforcement Learning",
    "abstract": "Recently, as the demand for cleaning robots has steadily increased, therefore\nhousehold electricity consumption is also increasing. To solve this electricity\nconsumption issue, the problem of efficient path planning for cleaning robot\nhas become important and many studies have been conducted. However, most of\nthem are about moving along a simple path segment, not about the whole path to\nclean all places. As the emerging deep learning technique, reinforcement\nlearning (RL) has been adopted for cleaning robot. However, the models for RL\noperate only in a specific cleaning environment, not the various cleaning\nenvironment. The problem is that the models have to retrain whenever the\ncleaning environment changes. To solve this problem, the proximal policy\noptimization (PPO) algorithm is combined with an efficient path planning that\noperates in various cleaning environments, using transfer learning (TL),\ndetection nearest cleaned tile, reward shaping, and making elite set methods.\nThe proposed method is validated with an ablation study and comparison with\nconventional methods such as random and zigzag. The experimental results\ndemonstrate that the proposed method achieves improved training performance and\nincreased convergence speed over the original PPO. And it also demonstrates\nthat this proposed method is better performance than conventional methods\n(random, zigzag).",
    "descriptor": "\nComments: 7 pages with 11 figures\n",
    "authors": [
      "Woohyeon Moon",
      "Bumgeun Park",
      "Sarvar Hussain Nengroo",
      "Taeyoung Kim",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08211"
  },
  {
    "id": "arXiv:2208.08213",
    "title": "Node and Edge Averaged Complexities of Local Graph Problems",
    "abstract": "The node-averaged complexity of a distributed algorithm running on a graph\n$G=(V,E)$ is the average over the times at which the nodes $V$ of $G$ finish\ntheir computation and commit to their outputs. We study the node-averaged\ncomplexity for some distributed symmetry breaking problems and provide the\nfollowing results (among others):\n- The randomized node-averaged complexity of computing a maximal independent\nset (MIS) in $n$-node graphs of maximum degree $\\Delta$ is at least\n$\\Omega\\big(\\min\\big\\{\\frac{\\log\\Delta}{\\log\\log\\Delta},\\sqrt{\\frac{\\log\nn}{\\log\\log n}}\\big\\}\\big)$. This bound is obtained by a novel adaptation of\nthe well-known KMW lower bound [JACM'16]. As a side result, we obtain the same\nlower bound for the worst-case randomized round complexity for computing an MIS\nin trees -- this essentially answers open problem 11.15 in the book of\nBarenboim and Elkin and resolves the complexity of MIS on trees up to an\n$O(\\sqrt{\\log\\log n})$ factor. We also show that, $(2,2)$-ruling sets, which\nare a minimal relaxation of MIS, have $O(1)$ randomized node-averaged\ncomplexity.\n- For maximal matching, we show that while the randomized node-averaged\ncomplexity is\n$\\Omega\\big(\\min\\big\\{\\frac{\\log\\Delta}{\\log\\log\\Delta},\\sqrt{\\frac{\\log\nn}{\\log\\log n}}\\big\\}\\big)$, the randomized edge-averaged complexity is $O(1)$.\nFurther, we show that the deterministic edge-averaged complexity of maximal\nmatching is $O(\\log^2\\Delta + \\log^* n)$ and the deterministic node-averaged\ncomplexity of maximal matching is $O(\\log^3\\Delta + \\log^* n)$.\n- Finally, we consider the problem of computing a sinkless orientation of a\ngraph. The deterministic worst-case complexity of the problem is known to be\n$\\Theta(\\log n)$, even on bounded-degree graphs. We show that the problem can\nbe solved deterministically with node-averaged complexity $O(\\log^* n)$, while\nkeeping the worst-case complexity in $O(\\log n)$.",
    "descriptor": "",
    "authors": [
      "Alkida Balliu",
      "Mohsen Ghaffari",
      "Fabian Kuhn",
      "Dennis Olivetti"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.08213"
  },
  {
    "id": "arXiv:2208.08216",
    "title": "Convergence of a class of high order corrected trapezoidal rules",
    "abstract": "We present convergence theory for corrected quadrature rules on uniform\nCartesian grids for functions with a point singularity. We begin by deriving an\nerror estimate for the punctured trapezoidal rule, and then derive error\nexpansions. We define the corrected trapezoidal rules, based on the punctured\ntrapezoidal rule, where the weights for the nodes close to the singularity are\njudiciously corrected based on these expansions. Then we define the composite\ncorrected trapezoidal rules for a larger family of functions using series\nexpansions around the point singularity and applying corrected trapezoidal\nrules appropriately. We prove that we can achieve high order accuracy by using\na sufficient number of correction nodes around the point singularity and of\nexpansion terms.",
    "descriptor": "\nComments: 23 pages, 1 figure\n",
    "authors": [
      "Federico Izzo",
      "Olof Runborg",
      "Richard Tsai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.08216"
  },
  {
    "id": "arXiv:2208.08217",
    "title": "How does the degree of novelty impacts semi-supervised representation  learning for novel class retrieval?",
    "abstract": "Supervised representation learning with deep networks tends to overfit the\ntraining classes and the generalization to novel classes is a challenging\nquestion. It is common to evaluate a learned embedding on held-out images of\nthe same training classes. In real applications however, data comes from new\nsources and novel classes are likely to arise. We hypothesize that\nincorporating unlabelled images of novel classes in the training set in a\nsemi-supervised fashion would be beneficial for the efficient retrieval of\nnovel-class images compared to a vanilla supervised representation. To verify\nthis hypothesis in a comprehensive way, we propose an original evaluation\nmethodology that varies the degree of novelty of novel classes by partitioning\nthe dataset category-wise either randomly, or semantically, i.e. by minimizing\nthe shared semantics between base and novel classes. This evaluation procedure\nallows to train a representation blindly to any novel-class labels and evaluate\nthe frozen representation on the retrieval of base or novel classes. We find\nthat a vanilla supervised representation falls short on the retrieval of novel\nclasses even more so when the semantics gap is higher. Semi-supervised\nalgorithms allow to partially bridge this performance gap but there is still\nmuch room for improvement.",
    "descriptor": "",
    "authors": [
      "Quentin Leroy",
      "Olivier Buisson",
      "Alexis Joly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08217"
  },
  {
    "id": "arXiv:2208.08218",
    "title": "ODformer: Spatial-Temporal Transformers for Long Sequence  Origin-Destination Matrix Forecasting Against Cross Application Scenario",
    "abstract": "Origin-Destination (OD) matrices record directional flow data between pairs\nof OD regions. The intricate spatiotemporal dependency in the matrices makes\nthe OD matrix forecasting (ODMF) problem not only intractable but also\nnon-trivial. However, most of the related methods are designed for very short\nsequence time series forecasting in specific application scenarios, which\ncannot meet the requirements of the variation in scenarios and forecasting\nlength of practical applications. To address these issues, we propose a\nTransformer-like model named ODformer, with two salient characteristics: (i)\nthe novel OD Attention mechanism, which captures special spatial dependencies\nbetween OD pairs of the same origin (destination), greatly improves the ability\nof the model to predict cross-application scenarios after combining with 2D-GCN\nthat captures spatial dependencies between OD regions. (ii) a PeriodSparse\nSelf-attention that effectively forecasts long sequence OD matrix series while\nadapting to the periodic differences in different scenarios. Generous\nexperiments in three application backgrounds (i.e., transportation traffic, IP\nbackbone network traffic, crowd flow) show our method outperforms the\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Jin Huang",
      "Bosong Huang",
      "Weihao Yu",
      "Jing Xiao",
      "Ruzhong Xie",
      "Ke Ruan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08218"
  },
  {
    "id": "arXiv:2208.08220",
    "title": "Towards an Error-free Deep Occupancy Detector for Smart Camera Parking  System",
    "abstract": "Although the smart camera parking system concept has existed for decades, a\nfew approaches have fully addressed the system's scalability and reliability.\nAs the cornerstone of a smart parking system is the ability to detect\noccupancy, traditional methods use the classification backbone to predict spots\nfrom a manual labeled grid. This is time-consuming and loses the system's\nscalability. Additionally, most of the approaches use deep learning models,\nmaking them not error-free and not reliable at scale. Thus, we propose an\nend-to-end smart camera parking system where we provide an autonomous detecting\noccupancy by an object detector called OcpDet. Our detector also provides\nmeaningful information from contrastive modules: training and spatial\nknowledge, which avert false detections during inference. We benchmark OcpDet\non the existing PKLot dataset and reach competitive results compared to\ntraditional classification solutions. We also introduce an additional SNU-SPS\ndataset, in which we estimate the system performance from various views and\nconduct system evaluation in parking assignment tasks. The result from our\ndataset shows that our system is promising for real-world applications.",
    "descriptor": "\nComments: Paper got accepted to ECCV workshop\n",
    "authors": [
      "Tung-Lam Duong",
      "Van-Duc Le",
      "Tien-Cuong Bui",
      "Hai-Thien To"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08220"
  },
  {
    "id": "arXiv:2208.08221",
    "title": "Which Factors Drive Open Access Publishing? A Springer Nature Case Study",
    "abstract": "Open Access (OA) facilitates access to articles. But, authors or funders\noften must pay the publishing costs preventing authors who do not receive\nfinancial support from participating in OA publishing and citation advantage\nfor OA articles. OA may exacerbate existing inequalities in the publication\nsystem rather than overcome them. To investigate this, we studied 522,664\narticles published by Springer Nature. Employing statistical methods, we\ndescribe the relationship between authors affiliated with countries from\ndifferent income levels, their choice of publishing (OA or closed access), and\nthe citation impact of their papers. A machine learning classification method\nhelped us to explore the association between OA-publishing and attributes of\nthe author, especially eligibility for APC-waivers or discounts, journal,\ncountry, and paper. The results indicate that authors eligible for the\nAPC-waivers publish more in gold-OA-journals than other authors. In contrast,\nauthors eligible for an APC discount have the lowest ratio of OA publications,\nleading to the assumption that this discount insufficiently motivates authors\nto publish in a gold-OA-journal. The rank of journals is a significant driver\nfor publishing in a gold-OA-journal, whereas the OA option is mostly avoided in\nhybrid journals. Seniority, experience with OA publications, and the scientific\nfield are the most decisive factors in OA-publishing.",
    "descriptor": "",
    "authors": [
      "Fakhri Momeni",
      "Stefan Dietze",
      "Philipp Mayr",
      "Kristin Biesenbender",
      "Isabella Peters"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08221"
  },
  {
    "id": "arXiv:2208.08224",
    "title": "Blind-Spot Collision Detection System for Commercial Vehicles Using  Multi Deep CNN Architecture",
    "abstract": "Buses and heavy vehicles have more blind spots compared to cars and other\nroad vehicles due to their large sizes. Therefore, accidents caused by these\nheavy vehicles are more fatal and result in severe injuries to other road\nusers. These possible blind-spot collisions can be identified early using\nvision-based object detection approaches. Yet, the existing state-of-the-art\nvision-based object detection models rely heavily on a single feature\ndescriptor for making decisions. In this research, the design of two\nconvolutional neural networks (CNNs) based on high-level feature descriptors\nand their integration with faster R-CNN is proposed to detect blind-spot\ncollisions for heavy vehicles. Moreover, a fusion approach is proposed to\nintegrate two pre-trained networks (i.e., Resnet 50 and Resnet 101) for\nextracting high level features for blind-spot vehicle detection. The fusion of\nfeatures significantly improves the performance of faster R-CNN and\noutperformed the existing state-of-the-art methods. Both approaches are\nvalidated on a self-recorded blind-spot vehicle detection dataset for buses and\nan online LISA dataset for vehicle detection. For both proposed approaches, a\nfalse detection rate (FDR) of 3.05% and 3.49% are obtained for the self\nrecorded dataset, making these approaches suitable for real time applications.",
    "descriptor": "",
    "authors": [
      "Muhammad Muzammel",
      "Mohd Zuki Yusoff",
      "Mohamad Naufal Mohamad Saad",
      "Faryal Sheikh",
      "Muhammad Ahsan Awais"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.08224"
  },
  {
    "id": "arXiv:2208.08225",
    "title": "On the Role of Negative Precedent in Legal Outcome Prediction",
    "abstract": "Every legal case sets a precedent by developing the law in one of the\nfollowing two ways. It either expands its scope, in which case it sets positive\nprecedent, or it narrows it down, in which case it sets negative precedent.\nWhile legal outcome prediction, which is nothing other than the prediction of\npositive precedents, is an increasingly popular task in AI, we are the first to\ninvestigate negative precedent prediction by focusing on negative outcomes. We\ndiscover an asymmetry in existing models' ability to predict positive and\nnegative outcomes. Where state-of-the-art outcome prediction models predicts\npositive outcomes at 75.06 F1, they predicts negative outcomes at only 10.09\nF1, worse than a random baseline. To address this performance gap, we develop\ntwo new models inspired by the dynamics of a court process. Our first model\nsignificantly improves positive outcome prediction score to 77.15 F1 and our\nsecond model more than doubles the negative outcome prediction performance to\n24.01 F1. Despite this improvement, shifting focus to negative outcomes reveals\nthat there is still plenty of room to grow when it comes to modelling law.",
    "descriptor": "",
    "authors": [
      "Josef Valvoda",
      "Ryan Cotterell",
      "Simone Teufel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08225"
  },
  {
    "id": "arXiv:2208.08227",
    "title": "A Scalable and Extensible Approach to Benchmarking NL2Code for 18  Programming Languages",
    "abstract": "Large language models have demonstrated the ability to condition on and\ngenerate both natural language and programming language text. Such models open\nup the possibility of multi-language code generation: could code generation\nmodels generalize knowledge from one language to another? Although contemporary\ncode generation models can generate semantically correct Python code, little is\nknown about their abilities with other languages. We facilitate the exploration\nof this topic by proposing MultiPL-E, the first multi-language parallel\nbenchmark for natural-language-to-code-generation.\nMultiPL-E extends the HumanEval benchmark (Chen et al, 2021) to support 18\nmore programming languages, encompassing a range of programming paradigms and\npopularity. We evaluate two state-of-the-art code generation models on\nMultiPL-E: Codex and InCoder. We find that on several languages, Codex matches\nand even exceeds its performance on Python. The range of programming languages\nrepresented in MultiPL-E allow us to explore the impact of language frequency\nand language features on model performance. Finally, the MultiPL-E approach of\ncompiling code generation benchmarks to new programming languages is both\nscalable and extensible. We describe a general approach for easily adding\nsupport for new benchmarks and languages to MultiPL-E.",
    "descriptor": "",
    "authors": [
      "Federico Cassano",
      "John Gouwar",
      "Daniel Nguyen",
      "Sydney Nguyen",
      "Luna Phipps-Costin",
      "Donald Pinckney",
      "Ming Ho Yee",
      "Yangtian Zi",
      "Carolyn Jane Anderson",
      "Molly Q Feldman",
      "Arjun Guha",
      "Michael Greenberg",
      "Abhinav Jangda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2208.08227"
  },
  {
    "id": "arXiv:2208.08231",
    "title": "Deep Autoencoder Model Construction Based on Pytorch",
    "abstract": "This paper proposes a deep autoencoder model based on Pytorch. This algorithm\nintroduces the idea of Pytorch into the auto-encoder, and randomly clears the\ninput weights connected to the hidden layer neurons with a certain probability,\nso as to achieve the effect of sparse network, which is similar to the starting\npoint of the sparse auto-encoder. The new algorithm effectively solves the\nproblem of possible overfitting of the model and improves the accuracy of image\nclassification. Finally, the experiment is carried out, and the experimental\nresults are compared with ELM, RELM, AE, SAE, DAE.",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Junan Pan",
      "Zhihao Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08231"
  },
  {
    "id": "arXiv:2208.08232",
    "title": "HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create  Customized Content with Models",
    "abstract": "Controlling the text generated by language models and customizing the content\nhas been a long-standing challenge. Existing prompting techniques proposed in\npursuit of providing control are task-specific and lack generality; this\nprovides overwhelming choices for non-expert users to find a suitable method\nfor their task. The effort associated with those techniques, such as in writing\nexamples, explanations, instructions, etc. further limits their adoption among\nnon-expert users. In this paper, we propose a simple prompting strategy HELP ME\nTHINK where we encourage GPT3 to help non-expert users by asking a set of\nrelevant questions and leveraging user answers to execute the task. We\ndemonstrate the efficacy of our technique HELP ME THINK on a variety of tasks.\nSpecifically, we focus on tasks that are hard for average humans and require\nsignificant thinking to perform. We hope our work will encourage the\ndevelopment of unconventional ways to harness the power of large language\nmodels.",
    "descriptor": "\nComments: 54 pages\n",
    "authors": [
      "Swaroop Mishra",
      "Elnaz Nouri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08232"
  },
  {
    "id": "arXiv:2208.08235",
    "title": "Input Repair via Synthesis and Lightweight Error Feedback",
    "abstract": "Often times, input data may ostensibly conform to a given input format, but\ncannot be parsed by a conforming program, for instance, due to human error or\ndata corruption. In such cases, a data engineer is tasked with input repair,\ni.e., she has to manually repair the corrupt data such that it follows a given\nformat, and hence can be processed by the conforming program. Such manual\nrepair can be time-consuming and error-prone. In particular, input repair is\nchallenging without an input specification (e.g., input grammar) or program\nanalysis.\nIn this work, we show that incorporating lightweight failure feedback (e.g.,\ninput incompleteness) to parsers is sufficient to repair any corrupt input data\nwith maximal closeness to the semantics of the input data. We propose an\napproach (called FSYNTH) that leverages lightweight error-feedback and input\nsynthesis to repair invalid inputs. FSYNTH is grammar-agnostic, and it does not\nrequire program analysis. Given a conforming program, and any invalid input,\nFSYNTH provides a set of repairs prioritized by the distance of the repair from\nthe original input. We evaluate FSYNTH on 806 (real-world) invalid inputs using\nfour well-known input formats, namely INI, TinyC, SExp, and cJSON. In our\nevaluation, we found that FSYNTH recovers 91% of valid input data. FSYNTH is\nalso highly effective and efficient in input repair: It repairs 77% of invalid\ninputs within four minutes. It is up to 35% more effective than DDMax, the\npreviously best-known approach. Overall, our approach addresses several\nlimitations of DDMax, both in terms of what it can repair, as well as in terms\nof the set of repairs offered.",
    "descriptor": "",
    "authors": [
      "Lukas Kirschner",
      "Ezekiel Soremekun",
      "Rahul Gopinath",
      "Andreas Zeller"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2208.08235"
  },
  {
    "id": "arXiv:2208.08237",
    "title": "Safety Assessment for Autonomous System Perception Capabilities",
    "abstract": "Autonomous Systems (AS) are being increasingly proposed, or used, in Safety\nCritical (SC) applications, e.g., road vehicles. Many such systems make use of\nsophisticated sensor suites and processing to provide scene understanding which\ninforms the AS' decision-making, e.g., path planning. The sensor processing\ntypically makes use of Machine Learning (ML) and has to work in challenging\nenvironments, further the ML algorithms have known limitations, e.g., the\npossibility of false negatives or false positives in object classification. The\nwell-established safety analysis methods developed for conventional SC systems\nare not well-matched to AS, ML, or the sensing systems used by AS. This paper\nproposes an adaptation of well-established safety analysis methods to address\nthe specifics of sensing systems for AS, including addressing environmental\neffects and the potential failure modes of ML, and provides a rationale for\nchoosing particular sets of guide words, or prompts, for safety analysis. It\ngoes on to show how the results of the analysis can be used to inform the\ndesign and verification of the AS system and illustrates the new method by\npresenting a partial analysis of a mobile robot. The illustrations in the paper\nare primarily based on optical sensing, however the paper discusses the\napplicability of the method to other sensing modalities and its role in a wider\nsafety process addressing the overall capabilities of AS",
    "descriptor": "\nComments: 53 pages, 9 figures, 19 tables\n",
    "authors": [
      "John Molloy",
      "John McDermid"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.08237"
  },
  {
    "id": "arXiv:2208.08238",
    "title": "Last-iterate Convergence to Trembling-hand Perfect Equilibria",
    "abstract": "Designing efficient algorithms to find Nash equilibrium (NE) refinements in\nsequential games is of paramount importance in practice. Indeed, it is well\nknown that the NE has several weaknesses, since it may prescribe to play\nsub-optimal actions in those parts of the game that are never reached at the\nequilibrium. NE refinements, such as the extensive-form perfect equilibrium\n(EFPE), amend such weaknesses by accounting for the possibility of players'\nmistakes. This is crucial in real-world applications, where bounded rationality\nplayers are usually involved, and it turns out being useful also in boosting\nthe performances of superhuman agents for recreational games like Poker.\nNevertheless, only few works addressed the problem of computing NE refinements.\nMost of them propose algorithms finding exact NE refinements by means of linear\nprogramming, and, thus, these do not have the potential of scaling up to\nreal-world-size games. On the other hand, existing iterative algorithms that\nexploit the tree structure of sequential games only provide convergence\nguarantees to approximate refinements. In this paper, we provide the first\nefficient last-iterate algorithm that provably converges to an EFPE in\ntwo-player zero-sum sequential games with imperfect information. Our algorithm\nworks by tracking a sequence of equilibria of suitably-defined,\nregularized-perturbed games. In order to do that, it uses a procedure that is\ntailored to converge last-iterate to the equilibria of such games. Crucially,\nthe updates performed by such a procedure can be performed efficiently by\nvisiting the game tree, thus making our algorithm potentially more scalable\nthan its linear-programming-based competitors. Finally, we evaluate our\nalgorithm on a standard testbed of games, showing that it produces strategies\nwhich are much more robust to players' mistakes than those of state-of-the-art\nNE-computation algorithms.",
    "descriptor": "",
    "authors": [
      "Martino Bernasconi",
      "Alberto Marchesi",
      "Francesco Trov\u00f2"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2208.08238"
  },
  {
    "id": "arXiv:2208.08239",
    "title": "Performance Optimization for Semantic Communications: An Attention-based  Reinforcement Learning Approach",
    "abstract": "In this paper, a semantic communication framework is proposed for textual\ndata transmission. In the studied model, a base station (BS) extracts the\nsemantic information from textual data, and transmits it to each user. The\nsemantic information is modeled by a knowledge graph (KG) that consists of a\nset of semantic triples. After receiving the semantic information, each user\nrecovers the original text using a graph-to-text generation model. To measure\nthe performance of the considered semantic communication framework, a metric of\nsemantic similarity (MSS) that jointly captures the semantic accuracy and\ncompleteness of the recovered text is proposed. Due to wireless resource\nlimitations, the BS may not be able to transmit the entire semantic information\nto each user and satisfy the transmission delay constraint. Hence, the BS must\nselect an appropriate resource block for each user as well as determine and\ntransmit part of the semantic information to the users. As such, we formulate\nan optimization problem whose goal is to maximize the total MSS by jointly\noptimizing the resource allocation policy and determining the partial semantic\ninformation to be transmitted. To solve this problem, a\nproximal-policy-optimization-based reinforcement learning (RL) algorithm\nintegrated with an attention network is proposed. The proposed algorithm can\nevaluate the importance of each triple in the semantic information using an\nattention network and then, build a relationship between the importance\ndistribution of the triples in the semantic information and the total MSS.\nCompared to traditional RL algorithms, the proposed algorithm can dynamically\nadjust its learning rate thus ensuring convergence to a locally optimal\nsolution.",
    "descriptor": "",
    "authors": [
      "Yining Wang",
      "Mingzhe Chen",
      "Tao Luo",
      "Walid Saad",
      "Dusit Niyato",
      "H. Vincent Poor",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08239"
  },
  {
    "id": "arXiv:2208.08241",
    "title": "ILLUME: Rationalizing Vision-Language Models by Interacting with their  Jabber",
    "abstract": "Bootstrapping from pre-trained language models has been proven to be an\nefficient approach for building foundation vision-language models (VLM) for\ntasks such as image captioning or visual question answering. However, it is\ndifficult-if not impossible-to utilize it to make the model conform with user's\nrationales for specific answers. To elicit and reinforce commonsense reasons,\nwe propose an iterative sampling and tuning paradigm, called ILLUME, that\nexecutes the following loop: Given an image-question-answer prompt, the VLM\nsamples multiple candidate rationales, and a human critic provides minimal\nfeedback via preference selection, used for fine-tuning. This loop increases\nthe training data and gradually carves out the VLM's rationalization\ncapabilities. Our exhaustive experiments demonstrate that ILLUME is competitive\nwith standard supervised fine-tuning while using significantly fewer training\ndata and only requiring minimal feedback.",
    "descriptor": "",
    "authors": [
      "Manuel Brac",
      "Patrick Schramowski",
      "Bj\u00f6rn Deiseroth",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.08241"
  },
  {
    "id": "arXiv:2208.08253",
    "title": "An Efficient Coarse-to-Fine Facet-Aware Unsupervised Summarization  Framework based on Semantic Blocks",
    "abstract": "Unsupervised summarization methods have achieved remarkable results by\nincorporating representations from pre-trained language models. However,\nexisting methods fail to consider efficiency and effectiveness at the same time\nwhen the input document is extremely long. To tackle this problem, in this\npaper, we proposed an efficient Coarse-to-Fine Facet-Aware Ranking (C2F-FAR)\nframework for unsupervised long document summarization, which is based on the\nsemantic block. The semantic block refers to continuous sentences in the\ndocument that describe the same facet. Specifically, we address this problem by\nconverting the one-step ranking method into the hierarchical multi-granularity\ntwo-stage ranking. In the coarse-level stage, we propose a new segment\nalgorithm to split the document into facet-aware semantic blocks and then\nfilter insignificant blocks. In the fine-level stage, we select salient\nsentences in each block and then extract the final summary from selected\nsentences. We evaluate our framework on four long document summarization\ndatasets: Gov-Report, BillSum, arXiv, and PubMed. Our C2F-FAR can achieve new\nstate-of-the-art unsupervised summarization results on Gov-Report and BillSum.\nIn addition, our method speeds up 4-28 times more than previous\nmethods.\\footnote{\\url{https://github.com/xnliang98/c2f-far}}",
    "descriptor": "\nComments: Accpeted by COLING 2022 Long paper\n",
    "authors": [
      "Xinnian Liang",
      "Jing Li",
      "Shuangzhi Wu",
      "Jiali Zeng",
      "Yufan Jiang",
      "Mu Li",
      "Zhoujun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08253"
  },
  {
    "id": "arXiv:2208.08254",
    "title": "Robustness of the Tangle 2.0 Consensus",
    "abstract": "In this paper, we investigate the performance of the Tangle 2.0 consensus\nprotocol in a Byzantine environment. We use an agent-based simulation model\nthat incorporates the main features of the Tangle 2.0 consensus protocol. Our\nexperimental results demonstrate that the Tangle 2.0 protocol is robust to the\nbait-and-switch attack up to the theoretical upper bound of the adversary's 33%\nvoting weight. We further show that the common coin mechanism in Tangle 2.0 is\nnecessary for robustness against powerful adversaries. Moreover, the\nexperimental results confirm that the protocol can achieve around 1s\nconfirmation time in typical scenarios and that the confirmation times of\nnon-conflicting transactions are not affected by the presence of conflicts.",
    "descriptor": "",
    "authors": [
      "Bing-Yang Lin",
      "Daria Dziuba\u0142towska",
      "Piotr Macek",
      "Andreas Penzkofer",
      "Sebastian M\u00fcller"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.08254"
  },
  {
    "id": "arXiv:2208.08255",
    "title": "On the Elements of Datasets for Cyber Physical Systems Security",
    "abstract": "Datasets are essential to apply AI algorithms to Cyber Physical System (CPS)\nSecurity. Due to scarcity of real CPS datasets, researchers elected to generate\ntheir own datasets using either real or virtualized testbeds. However, unlike\nother AI domains, a CPS is a complex system with many interfaces that determine\nits behavior. A dataset that comprises merely a collection of sensor\nmeasurements and network traffic may not be sufficient to develop resilient AI\ndefensive or offensive agents. In this paper, we study the \\emph{elements} of\nCPS security datasets required to capture the system behavior and interactions,\nand propose a dataset architecture that has the potential to enhance the\nperformance of AI algorithms in securing cyber physical systems. The framework\nincludes dataset elements, attack representation, and required dataset\nfeatures. We compare existing datasets to the proposed architecture to identify\nthe current limitations and discuss the future of CPS dataset generation using\ntestbeds.",
    "descriptor": "\nComments: Submitted for peer review\n",
    "authors": [
      "Ashraf Tantawy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.08255"
  },
  {
    "id": "arXiv:2208.08257",
    "title": "Partitioning Hypergraphs is Hard: Models, Inapproximability, and  Applications",
    "abstract": "We study the balanced $k$-way hypergraph partitioning problem, with a special\nfocus on its practical applications to manycore scheduling. Given a hypergraph\non $n$ nodes, our goal is to partition the node set into $k$ parts of size at\nmost $(1+\\epsilon)\\cdot \\frac{n}{k}$ each, while minimizing the cost of the\npartitioning, defined as the number of cut hyperedges, possibly also weighted\nby the number of partitions they intersect. We show that this problem cannot be\napproximated to within a $n^{1/\\text{poly} \\log\\log n}$ factor of the optimal\nsolution in polynomial time if the Exponential Time Hypothesis holds, even for\nhypergraphs of maximal degree 2. We also study the hardness of the partitioning\nproblem from a parameterized complexity perspective, and in the more general\ncase when we have multiple balance constraints.\nFurthermore, we consider two extensions of the partitioning problem that are\nmotivated from practical considerations. Firstly, we introduce the concept of\nhyperDAGs to model precedence-constrained computations as hypergraphs, and we\nanalyze the adaptation of the balanced partitioning problem to this case.\nSecondly, we study the hierarchical partitioning problem to model hierarchical\nNUMA (non-uniform memory access) effects in modern computer architectures, and\nwe show that ignoring this hierarchical aspect of the communication cost can\nyield significantly weaker solutions.",
    "descriptor": "",
    "authors": [
      "P\u00e1l Andr\u00e1s Papp",
      "Georg Anegg",
      "A. N. Yzelman"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.08257"
  },
  {
    "id": "arXiv:2208.08263",
    "title": "Multimodal foundation models are better simulators of the human brain",
    "abstract": "Multimodal learning, especially large-scale multimodal pre-training, has\ndeveloped rapidly over the past few years and led to the greatest advances in\nartificial intelligence (AI). Despite its effectiveness, understanding the\nunderlying mechanism of multimodal pre-training models still remains a grand\nchallenge. Revealing the explainability of such models is likely to enable\nbreakthroughs of novel learning paradigms in the AI field. To this end, given\nthe multimodal nature of the human brain, we propose to explore the\nexplainability of multimodal learning models with the aid of non-invasive brain\nimaging technologies such as functional magnetic resonance imaging (fMRI).\nConcretely, we first present a newly-designed multimodal foundation model\npre-trained on 15 million image-text pairs, which has shown strong multimodal\nunderstanding and generalization abilities in a variety of cognitive downstream\ntasks. Further, from the perspective of neural encoding (based on our\nfoundation model), we find that both visual and lingual encoders trained\nmultimodally are more brain-like compared with unimodal ones. Particularly, we\nidentify a number of brain regions where multimodally-trained encoders\ndemonstrate better neural encoding performance. This is consistent with the\nfindings in existing studies on exploring brain multi-sensory integration.\nTherefore, we believe that multimodal foundation models are more suitable tools\nfor neuroscientists to study the multimodal signal processing mechanisms in the\nhuman brain. Our findings also demonstrate the potential of multimodal\nfoundation models as ideal computational simulators to promote both\nAI-for-brain and brain-for-AI research.",
    "descriptor": "",
    "authors": [
      "Haoyu Lu",
      "Qiongyi Zhou",
      "Nanyi Fei",
      "Zhiwu Lu",
      "Mingyu Ding",
      "Jingyuan Wen",
      "Changde Du",
      "Xin Zhao",
      "Hao Sun",
      "Huiguang He",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2208.08263"
  },
  {
    "id": "arXiv:2208.08267",
    "title": "Error analysis for the numerical approximation of the harmonic map heat  flow with nodal constraints",
    "abstract": "An error estimate for a canonical discretization of the harmonic map heat\nflow into spheres is derived. The numerical scheme uses standard finite\nelements with a nodal treatment of linearized unit-length constraints. The\nanalysis is based on elementary approximation results and only uses the\ndiscrete weak formulation.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "S\u00f6ren Bartels",
      "Bal\u00e1zs Kov\u00e1cs",
      "Zhangxian Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.08267"
  },
  {
    "id": "arXiv:2208.08268",
    "title": "Prediction of Oral Food Challenges via Machine Learning",
    "abstract": "Oral Food Challenges (OFCs) are essential to accurately diagnosing food\nallergy in patients. However, patients are hesitant to undergo OFCs, and for\nthose that do, there is limited access to allergists in rural/community\nhealthcare settings. The prediction of OFC outcomes through machine learning\nmethods can facilitate the de-labeling of food allergens at home, improve\npatient and physician comfort during OFCs, and economize medical resources by\nminimizing the number of OFCs performed. Clinical data was gathered from 1,112\npatients who collectively underwent a total of 1,284 OFCs, and consisted of\nclinical factors including serum specific IgE, total IgE, skin prick tests\n(SPTs), symptoms, sex, and age. Using these clinical features, machine learning\nmodels were constructed to predict outcomes for peanut, egg, and milk\nchallenge. The best performing model for each allergen was created using the\nLearning Using Concave and Convex Kernels (LUCCK) method, which achieved an\nArea under the Curve (AUC) for peanut, egg, and milk OFC prediction of 0.76,\n0.68, and 0.70, respectively. Model interpretation via SHapley Additive\nexPlanations (SHAP) indicate that specific IgE, along with wheal and flare\nvalues from SPTs, are highly predictive of OFC outcomes. The results of this\nanalysis suggest that machine learning has the potential to predict OFC\noutcomes and reveal relevant clinical factors for further study.",
    "descriptor": "",
    "authors": [
      "Justin Zhang",
      "Deborah Lee",
      "Kylie Jungles",
      "Diane Shaltis",
      "Kayvan Najarian",
      "Rajan Ravikumar",
      "Georgiana Sanders",
      "Jonathan Gryak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08268"
  },
  {
    "id": "arXiv:2208.08269",
    "title": "LeXInt: Package for Exponential Integrators employing Leja interpolation",
    "abstract": "We present a publicly available software for exponential integrators that\ncomputes the $\\varphi_l(z)$ functions using polynomial interpolation. The\ninterpolation method at Leja points have recently been shown to be competitive\nwith the traditionally-used Krylov subspace method. The developed framework\nfacilitates easy adaptation into any Python software package for time\nintegration.",
    "descriptor": "\nComments: Publicly available software available at this https URL, in submission\n",
    "authors": [
      "Pranab J. Deka",
      "Lukas Einkemmer",
      "Mayya Tokman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Applied Physics (physics.app-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.08269"
  },
  {
    "id": "arXiv:2208.08270",
    "title": "On the Privacy Effect of Data Enhancement via the Lens of Memorization",
    "abstract": "Machine learning poses severe privacy concerns as it is shown that the\nlearned models can reveal sensitive information about their training data. Many\nworks have investigated the effect of widely-adopted data augmentation (DA) and\nadversarial training (AT) techniques, termed data enhancement in the paper, on\nthe privacy leakage of machine learning models. Such privacy effects are often\nmeasured by membership inference attacks (MIAs), which aim to identify whether\na particular example belongs to the training set or not. We propose to\ninvestigate privacy from a new perspective called memorization. Through the\nlens of memorization, we find that previously deployed MIAs produce misleading\nresults as they are less likely to identify samples with higher privacy risks\nas members compared to samples with low privacy risks. To solve this problem,\nwe deploy a recent attack that can capture the memorization degrees of\nindividual samples for evaluation. Through extensive experiments, we unveil\nnon-trivial findings about the connections between three important properties\nof machine learning models, including privacy, generalization gap, and\nadversarial robustness. We demonstrate that, unlike existing results, the\ngeneralization gap is shown not highly correlated with privacy leakage.\nMoreover, stronger adversarial robustness does not necessarily imply that the\nmodel is more susceptible to privacy attacks.",
    "descriptor": "",
    "authors": [
      "Xiao Li",
      "Qiongxiu Li",
      "Zhanhao Hu",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08270"
  },
  {
    "id": "arXiv:2208.08274",
    "title": "SMPL-IK: Learned Morphology-Aware Inverse Kinematics for AI Driven  Artistic Workflows",
    "abstract": "Inverse Kinematics (IK) systems are often rigid with respect to their input\ncharacter, thus requiring user intervention to be adapted to new skeletons. In\nthis paper we aim at creating a flexible, learned IK solver applicable to a\nwide variety of human morphologies. We extend a state-of-the-art machine\nlearning IK solver to operate on the well known Skinned Multi-Person Linear\nmodel (SMPL). We call our model SMPL-IK, and show that when integrated into\nreal-time 3D software, this extended system opens up opportunities for defining\nnovel AI-assisted animation workflows. For example, pose authoring can be made\nmore flexible with SMPL-IK by allowing users to modify gender and body shape\nwhile posing a character. Additionally, when chained with existing pose\nestimation algorithms, SMPL-IK accelerates posing by allowing users to\nbootstrap 3D scenes from 2D images while allowing for further editing. Finally,\nwe propose a novel SMPL Shape Inversion mechanism (SMPL-SI) to map arbitrary\nhumanoid characters to the SMPL space, allowing artists to leverage SMPL-IK on\ncustom characters. In addition to qualitative demos showing proposed tools, we\npresent quantitative SMPL-IK baselines on the H36M and AMASS datasets.",
    "descriptor": "",
    "authors": [
      "Vikram Voleti",
      "Boris N. Oreshkin",
      "Florent Bocquelet",
      "F\u00e9lix G. Harvey",
      "Louis-Simon M\u00e9nard",
      "Christopher Pal"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08274"
  },
  {
    "id": "arXiv:2208.08277",
    "title": "Providing High Capacity for AR/VR traffic in 5G Systems with  Multi-Connectivity",
    "abstract": "Augmented and Virtual Reality (AR/VR) is often called a \"killer\" application\nof 5G systems because it imposes very strict Quality of Service (QoS)\nrequirements related to throughput, latency, and reliability. A high-resolution\nAR/VR flow requires a bandwidth of dozens of MHz. Since the existing\nlow-frequency bands (i.e., below 6 GHz) have limited bandwidth and are\noverpopulated, one of the ways to satisfy high AR/VR demands is to use wide\nfrequency channels available in the millimeter-Wave (mmWave) band. However,\ntransmission in the mmWave band suffers from high throughput fluctuation and\neven blockage, which leads to violation of strict AR/VR latency and reliability\nrequirements. To address this problem, 5G specifications introduce a\nMulti-Connectivity (MC) feature that allows a mobile user to connect\nsimultaneously to several base stations. The paper considers a scenario with\ntwo base stations: the first base station operates in the low-frequency band to\nprovide reliable data delivery, while the second one operates in the mmWave\nband and offers high data rates when the channel conditions are favorable. An\nopen question that falls out of the scope of specifications is how to balance\nAR/VR traffic between two links with different characteristics. The paper\nproposes a Delay-Based Traffic Balancing (DBTB) algorithm that minimizes\nresource consumption of the low-frequency link while satisfying strict AR/VR\nQoS requirements. With extensive simulations, DBTB is shown to double the\nnetwork capacity for AR/VR traffic compared with the state-of-the-art traffic\nbalancing algorithms.",
    "descriptor": "\nComments: Submitted to 2022 IEEE International Black Sea Conference on Communications and Networking (BlackSeaCom)\n",
    "authors": [
      "Maxim Susloparov",
      "Artem Krasilov",
      "Evgeny Khorov"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.08277"
  },
  {
    "id": "arXiv:2208.08279",
    "title": "Error Parity Fairness: Testing for Group Fairness in Regression Tasks",
    "abstract": "The applications of Artificial Intelligence (AI) surround decisions on\nincreasingly many aspects of human lives. Society responds by imposing legal\nand social expectations for the accountability of such automated decision\nsystems (ADSs). Fairness, a fundamental constituent of AI accountability, is\nconcerned with just treatment of individuals and sensitive groups (e.g., based\non sex, race). While many studies focus on fair learning and fairness testing\nfor the classification tasks, the literature is rather limited on how to\nexamine fairness in regression tasks. This work presents error parity as a\nregression fairness notion and introduces a testing methodology to assess group\nfairness based on a statistical hypothesis testing procedure. The error parity\ntest checks whether prediction errors are distributed similarly across\nsensitive groups to determine if an ADS is fair. It is followed by a suitable\npermutation test to compare groups on several statistics to explore disparities\nand identify impacted groups. The usefulness and applicability of the proposed\nmethodology are demonstrated via a case study on COVID-19 projections in the US\nat the county level, which revealed race-based differences in forecast errors.\nOverall, the proposed regression fairness testing methodology fills a gap in\nthe fair machine learning literature and may serve as a part of larger\naccountability assessments and algorithm audits.",
    "descriptor": "",
    "authors": [
      "Furkan Gursoy",
      "Ioannis A. Kakadiaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.08279"
  },
  {
    "id": "arXiv:2208.08280",
    "title": "Exploiting Unlabeled Data for Target-Oriented Opinion Words Extraction",
    "abstract": "Target-oriented Opinion Words Extraction (TOWE) is a fine-grained sentiment\nanalysis task that aims to extract the corresponding opinion words of a given\nopinion target from the sentence. Recently, deep learning approaches have made\nremarkable progress on this task. Nevertheless, the TOWE task still suffers\nfrom the scarcity of training data due to the expensive data annotation\nprocess. Limited labeled data increase the risk of distribution shift between\ntest data and training data. In this paper, we propose exploiting massive\nunlabeled data to reduce the risk by increasing the exposure of the model to\nvarying distribution shifts. Specifically, we propose a novel Multi-Grained\nConsistency Regularization (MGCR) method to make use of unlabeled data and\ndesign two filters specifically for TOWE to filter noisy data at different\ngranularity. Extensive experimental results on four TOWE benchmark datasets\nindicate the superiority of MGCR compared with current state-of-the-art\nmethods. The in-depth analysis also demonstrates the effectiveness of the\ndifferent-granularity filters. Our codes are available at\nhttps://github.com/TOWESSL/TOWESSL.",
    "descriptor": "\nComments: Accepted by COLING 2022\n",
    "authors": [
      "Yidong Wang",
      "Hao Wu",
      "Ao Liu",
      "Wenxin Hou",
      "Zhen Wu",
      "Jindong Wang",
      "Takahiro Shinozaki",
      "Manabu Okumura",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08280"
  },
  {
    "id": "arXiv:2208.08287",
    "title": "Sparse Nonnegative Tucker Decomposition and Completion under Noisy  Observations",
    "abstract": "Tensor decomposition is a powerful tool for extracting physically meaningful\nlatent factors from multi-dimensional nonnegative data, and has been an\nincreasing interest in a variety of fields such as image processing, machine\nlearning, and computer vision. In this paper, we propose a sparse nonnegative\nTucker decomposition and completion method for the recovery of underlying\nnonnegative data under noisy observations. Here the underlying nonnegative data\ntensor is decomposed into a core tensor and several factor matrices with all\nentries being nonnegative and the factor matrices being sparse. The loss\nfunction is derived by the maximum likelihood estimation of the noisy\nobservations, and the $\\ell_0$ norm is employed to enhance the sparsity of the\nfactor matrices. We establish the error bound of the estimator of the proposed\nmodel under generic noise scenarios, which is then specified to the\nobservations with additive Gaussian noise, additive Laplace noise, and Poisson\nobservations, respectively. Our theoretical results are better than those by\nexisting tensor-based or matrix-based methods. Moreover, the minimax lower\nbounds are shown to be matched with the derived upper bounds up to logarithmic\nfactors. Numerical examples on both synthetic and real-world data sets\ndemonstrate the superiority of the proposed method for nonnegative tensor data\ncompletion.",
    "descriptor": "",
    "authors": [
      "Xiongjun Zhang",
      "Michael K. Ng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.08287"
  },
  {
    "id": "arXiv:2208.08289",
    "title": "CCTEST: Testing and Repairing Code Completion Systems",
    "abstract": "Code completion, a highly valuable topic in the software development domain,\nhas been increasingly promoted for use by recent advances in large language\nmodels (LLMs). To date, visible LLM-based code completion frameworks like\nGitHub Copilot and GPT are trained using deep learning over vast quantities of\nunstructured text and open source codes. As the paramount component and the\ncornerstone in daily programming tasks, code completion has largely boosted\nprofessionals' efficiency in building real-world software systems. In contrast\nto this flourishing market, we find that code completion models often output\nsuspicious results, and to date, an automated testing and enhancement framework\nfor code completion models is not available. This research proposes CCTEST, a\nframework to test and repair code completion systems in blackbox settings.\nCCTEST features a novel mutation strategy, namely program structure-consistency\n(PSC) mutations, to generate mutated code completion inputs. Then, it detects\ninconsistent outputs, representing likely erroneous cases, from all the\ncompleted code cases. Moreover, CCTEST repairs the code completion outputs by\nselecting the output that mostly reflects the \"average\" appearance of all\noutput cases, as the final output of the code completion systems. We detected a\ntotal of 33,540 inputs that can trigger likely erroneous cases from eight\npopular LLM-based code completion systems. With repairing, we show that the\nperformance of code completion models notably increased by 53.51% on average.",
    "descriptor": "\nComments: 14 pages, 10 figures, 5 tables\n",
    "authors": [
      "Zongjie Li",
      "Chaozheng Wang",
      "Zhibo Liu",
      "Haoxuan Wang",
      "Shuai Wang",
      "Cuiyun Gao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.08289"
  },
  {
    "id": "arXiv:2208.08292",
    "title": "IDAN: Image Difference Attention Network for Change Detection",
    "abstract": "Remote sensing image change detection is of great importance in disaster\nassessment and urban planning. The mainstream method is to use encoder-decoder\nmodels to detect the change region of two input images. Since the change\ncontent of remote sensing images has the characteristics of wide scale range\nand variety, it is necessary to improve the detection accuracy of the network\nby increasing the attention mechanism, which commonly includes:\nSqueeze-and-Excitation block, Non-local and Convolutional Block Attention\nModule, among others. These methods consider the importance of different\nlocation features between channels or within channels, but fail to perceive the\ndifferences between input images. In this paper, we propose a novel image\ndifference attention network (IDAN). In the image preprocessing stage, we use a\npre-training model to extract the feature differences between two input images\nto obtain the feature difference map (FD-map), and Canny for edge detection to\nobtain the edge difference map (ED-map). In the image feature extracting stage,\nthe FD-map and ED-map are input to the feature difference attention module and\nedge compensation module, respectively, to optimize the features extracted by\nIDAN. Finally, the change detection result is obtained through the feature\ndifference operation. IDAN comprehensively considers the differences in\nregional and edge features of images and thus optimizes the extracted image\nfeatures. The experimental results demonstrate that the F1-score of IDAN\nimproves 1.62% and 1.98% compared to the baseline model on WHU dataset and\nLEVIR-CD dataset, respectively.",
    "descriptor": "",
    "authors": [
      "Hongkun Liu",
      "Zican Hu",
      "Qichen Ding",
      "Xueyun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08292"
  },
  {
    "id": "arXiv:2208.08295",
    "title": "ParaColorizer: Realistic Image Colorization using Parallel Generative  Networks",
    "abstract": "Grayscale image colorization is a fascinating application of AI for\ninformation restoration. The inherently ill-posed nature of the problem makes\nit even more challenging since the outputs could be multi-modal. The\nlearning-based methods currently in use produce acceptable results for\nstraightforward cases but usually fail to restore the contextual information in\nthe absence of clear figure-ground separation. Also, the images suffer from\ncolor bleeding and desaturated backgrounds since a single model trained on full\nimage features is insufficient for learning the diverse data modes. To address\nthese issues, we present a parallel GAN-based colorization framework. In our\napproach, each separately tailored GAN pipeline colorizes the foreground (using\nobject-level features) or the background (using full-image features). The\nforeground pipeline employs a Residual-UNet with self-attention as its\ngenerator trained using the full-image features and the corresponding\nobject-level features from the COCO dataset. The background pipeline relies on\nfull-image features and additional training examples from the Places dataset.\nWe design a DenseFuse-based fusion network to obtain the final colorized image\nby feature-based fusion of the parallelly generated outputs. We show the\nshortcomings of the non-perceptual evaluation metrics commonly used to assess\nmulti-modal problems like image colorization and perform extensive performance\nevaluation of our framework using multiple perceptual metrics. Our approach\noutperforms most of the existing learning-based methods and produces results\ncomparable to the state-of-the-art. Further, we performed a runtime analysis\nand obtained an average inference time of 24ms per image.",
    "descriptor": "",
    "authors": [
      "Himanshu Kumar",
      "Abeer Banerjee",
      "Sumeet Saurav",
      "Sanjay Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08295"
  },
  {
    "id": "arXiv:2208.08297",
    "title": "Attackar: Attack of the Evolutionary Adversary",
    "abstract": "Deep neural networks (DNNs) are sensitive to adversarial data in a variety of\nscenarios, including the black-box scenario, where the attacker is only allowed\nto query the trained model and receive an output. Existing black-box methods\nfor creating adversarial instances are costly, often using gradient estimation\nor training a replacement network. This paper introduces \\textit{Attackar}, an\nevolutionary, score-based, black-box attack. Attackar is based on a novel\nobjective function that can be used in gradient-free optimization problems. The\nattack only requires access to the output logits of the classifier and is thus\nnot affected by gradient masking. No additional information is needed,\nrendering our method more suitable to real-life situations. We test its\nperformance with three different state-of-the-art models -- Inception-v3,\nResNet-50, and VGG-16-BN -- against three benchmark datasets: MNIST, CIFAR10\nand ImageNet. Furthermore, we evaluate Attackar's performance on\nnon-differential transformation defenses and state-of-the-art robust models.\nOur results demonstrate the superior performance of Attackar, both in terms of\naccuracy score and query efficiency.",
    "descriptor": "",
    "authors": [
      "Raz Lapid",
      "Zvika Haramaty",
      "Moshe Sipper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2208.08297"
  },
  {
    "id": "arXiv:2208.08302",
    "title": "Position-aware Structure Learning for Graph Topology-imbalance by  Relieving Under-reaching and Over-squashing",
    "abstract": "Topology-imbalance is a graph-specific imbalance problem caused by the uneven\ntopology positions of labeled nodes, which significantly damages the\nperformance of GNNs. What topology-imbalance means and how to measure its\nimpact on graph learning remain under-explored. In this paper, we provide a new\nunderstanding of topology-imbalance from a global view of the supervision\ninformation distribution in terms of under-reaching and over-squashing, which\nmotivates two quantitative metrics as measurements. In light of our analysis,\nwe propose a novel position-aware graph structure learning framework named\nPASTEL, which directly optimizes the information propagation path and solves\nthe topology-imbalance issue in essence. Our key insight is to enhance the\nconnectivity of nodes within the same class for more supervision information,\nthereby relieving the under-reaching and over-squashing phenomena.\nSpecifically, we design an anchor-based position encoding mechanism, which\nbetter incorporates relative topology position and enhances the intra-class\ninductive bias by maximizing the label influence. We further propose a\nclass-wise conflict measure as the edge weights, which benefits the separation\nof different node classes. Extensive experiments demonstrate the superior\npotential and adaptability of PASTEL in enhancing GNNs' power in different data\nannotation scenarios.",
    "descriptor": "\nComments: Accepted by CIKM 2022\n",
    "authors": [
      "Qingyun Sun",
      "Jianxin Li",
      "Haonan Yuan",
      "Xingcheng Fu",
      "Hao Peng",
      "Cheng Ji",
      "Qian Li",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08302"
  },
  {
    "id": "arXiv:2208.08307",
    "title": "Incremental 3D Scene Completion for Safe and Efficient Exploration  Mapping and Planning",
    "abstract": "Exploration of unknown environments is a fundamental problem in robotics and\nan essential component in numerous applications of autonomous systems. A major\nchallenge in exploring unknown environments is that the robot has to plan with\nthe limited information available at each time step. While most current\napproaches rely on heuristics and assumption to plan paths based on these\npartial observations, we instead propose a novel way to integrate deep learning\ninto exploration by leveraging 3D scene completion for informed, safe, and\ninterpretable exploration mapping and planning. Our approach, SC-Explorer,\ncombines scene completion using a novel incremental fusion mechanism and a\nnewly proposed hierarchical multi-layer mapping approach, to guarantee safety\nand efficiency of the robot. We further present an informative path planning\nmethod, leveraging the capabilities of our mapping approach and a novel\nscene-completion-aware information gain. While our method is generally\napplicable, we evaluate it in the use case of a Micro Aerial Vehicle (MAV). We\nthoroughly study each component in high-fidelity simulation experiments using\nonly mobile hardware, and show that our method can speed up coverage of an\nenvironment by 73% compared to the baselines with only minimal reduction in map\naccuracy. Even if scene completions are not included in the final map, we show\nthat they can be used to guide the robot to choose more informative paths,\nspeeding up the measurement of the scene with the robot's sensors by 35%. We\nmake our methods available as open-source.",
    "descriptor": "\nComments: 16 pages, 12 figures. Code will be released at this https URL\n",
    "authors": [
      "Lukas Schmid",
      "Mansoor Nasir Cheema",
      "Victor Reijgwart",
      "Roland Siegwart",
      "Federico Tombari",
      "Cesar Cadena"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08307"
  },
  {
    "id": "arXiv:2208.08319",
    "title": "Active Learning for Deterministic Bottom-up Nominal Tree Automata",
    "abstract": "Nominal set plays a central role in a group-theoretic extension of finite\nautomata to those over an infinite set of data values. Moerman et al. proposed\nan active learning algorithm for nominal word automata with the equality\nsymmetry. In this paper, we introduce deterministic bottom-up nominal tree\nautomata (DBNTA), which operate on trees whose nodes are labelled with elements\nof an orbit finite nominal set. We then prove a Myhill-Nerode theorem for the\nclass of languages recognized by DBNTA and propose an active learning algorithm\nfor DBNTA. The algorithm can deal with any data symmetry that admits least\nsupport, not restricted to the equality symmetry and/or the total order\nsymmetry. To prove the termination of the algorithm, we define a partial order\non nominal sets and show that there is no infinite chain of orbit finite\nnominal sets with respect to this partial order between any two orbit finite\nsets.",
    "descriptor": "",
    "authors": [
      "R. Nakanishi",
      "Y. Takata",
      "H. Seki"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2208.08319"
  },
  {
    "id": "arXiv:2208.08320",
    "title": "BIC: Twitter Bot Detection with Text-Graph Interaction and Semantic  Consistency",
    "abstract": "Twitter bot detection is an important and meaningful task. Existing\ntext-based methods can deeply analyze user tweet content, achieving high\nperformance. However, novel Twitter bots evade these detections by stealing\ngenuine users' tweets and diluting malicious content with benign tweets. These\nnovel bots are proposed to be characterized by semantic inconsistency. In\naddition, methods leveraging Twitter graph structure are recently emerging,\nshowing great competitiveness. However, hardly a method has made text and graph\nmodality deeply fused and interacted to leverage both advantages and learn the\nrelative importance of the two modalities. In this paper, we propose a novel\nmodel named BIC that makes the text and graph modalities deeply interactive and\ndetects tweet semantic inconsistency. Specifically, BIC contains a text\npropagation module, a graph propagation module to conduct bot detection\nrespectively on text and graph structure, and a proven effective text-graph\ninteractive module to make the two interact. Besides, BIC contains a semantic\nconsistency detection module to learn semantic consistency information from\ntweets. Extensive experiments demonstrate that our framework outperforms\ncompetitive baselines on a comprehensive Twitter bot benchmark. We also prove\nthe effectiveness of the proposed interaction and semantic consistency\ndetection.",
    "descriptor": "",
    "authors": [
      "Zhenyu Lei",
      "Herun Wan",
      "Wenqian Zhang",
      "Shangbin Feng",
      "Zilong Chen",
      "Qinghua Zheng",
      "Minnan Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08320"
  },
  {
    "id": "arXiv:2208.08330",
    "title": "The proper conflict-free $k$-coloring problem and the odd $k$-coloring  problem are NP-complete on bipartite graphs",
    "abstract": "A proper coloring of a graph is \\emph{proper conflict-free} if every\nnon-isolated vertex $v$ has a neighbor whose color is unique in the\nneighborhood of $v$. A proper coloring of a graph is \\emph{odd} if for every\nnon-isolated vertex $v$, there is a color appearing an odd number of times in\nthe neighborhood of $v$. For an integer $k$, the \\textsc{PCF $k$-Coloring}\nproblem asks whether an input graph admits a proper conflict-free $k$-coloring\nand the \\textsc{Odd $k$-Coloring} asks whether an input graph admits an odd\n$k$-coloring. We show that for every integer $k\\geq3$, both problems are\nNP-complete, even if the input graph is bipartite. Furthermore, we show that\nthe \\textsc{PCF $4$-Coloring} problem is NP-complete when the input graph is\nplanar.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Jungho Ahn",
      "Seonghyuk Im",
      "Sang-il Oum"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2208.08330"
  },
  {
    "id": "arXiv:2208.08338",
    "title": "SO(3)-Pose: SO(3)-Equivariance Learning for 6D Object Pose Estimation",
    "abstract": "6D pose estimation of rigid objects from RGB-D images is crucial for object\ngrasping and manipulation in robotics. Although RGB channels and the depth (D)\nchannel are often complementary, providing respectively the appearance and\ngeometry information, it is still non-trivial how to fully benefit from the two\ncross-modal data. From the simple yet new observation, when an object rotates,\nits semantic label is invariant to the pose while its keypoint offset direction\nis variant to the pose. To this end, we present SO(3)-Pose, a new\nrepresentation learning network to explore SO(3)-equivariant and\nSO(3)-invariant features from the depth channel for pose estimation. The\nSO(3)-invariant features facilitate to learn more distinctive representations\nfor segmenting objects with similar appearance from RGB channels. The\nSO(3)-equivariant features communicate with RGB features to deduce the (missed)\ngeometry for detecting keypoints of an object with the reflective surface from\nthe depth channel. Unlike most of existing pose estimation methods, our\nSO(3)-Pose not only implements the information communication between the RGB\nand depth channels, but also naturally absorbs the SO(3)-equivariance geometry\nknowledge from depth images, leading to better appearance and geometry\nrepresentation learning. Comprehensive experiments show that our method\nachieves the state-of-the-art performance on three benchmarks.",
    "descriptor": "",
    "authors": [
      "Haoran Pan",
      "Jun Zhou",
      "Yuanpeng Liu",
      "Xuequan Lu",
      "Weiming Wang",
      "Xuefeng Yan",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08338"
  },
  {
    "id": "arXiv:2208.08340",
    "title": "Class-Aware Visual Prompt Tuning for Vision-Language Pre-Trained Model",
    "abstract": "With the emergence of large pre-trained vison-language model like CLIP,\ntransferrable representations can be adapted to a wide range of downstream\ntasks via prompt tuning. Prompt tuning tries to probe the beneficial\ninformation for downstream tasks from the general knowledge stored in both the\nimage and text encoders of the pre-trained vision-language model. A recently\nproposed method named Context Optimization (CoOp) introduces a set of learnable\nvectors as text prompt from the language side, while tuning the text prompt\nalone can not affect the computed visual features of the image encoder, thus\nleading to sub-optimal. In this paper, we propose a dual modality prompt tuning\nparadigm through learning text prompts and visual prompts for both the text and\nimage encoder simultaneously. In addition, to make the visual prompt\nconcentrate more on the target visual concept, we propose Class-Aware Visual\nPrompt Tuning (CAVPT), which is generated dynamically by performing the cross\nattention between language descriptions of template prompts and visual class\ntoken embeddings. Our method provides a new paradigm for tuning the large\npre-trained vision-language model and extensive experimental results on 8\ndatasets demonstrate the effectiveness of the proposed method. Our code is\navailable in the supplementary materials.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Yinghui Xing",
      "Qirui Wu",
      "De Cheng",
      "Shizhou Zhang",
      "Guoqiang Liang",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08340"
  },
  {
    "id": "arXiv:2208.08342",
    "title": "Semantic Communications with Discrete-time Analog Transmission: A PAPR  Perspective",
    "abstract": "Recent progress in deep learning (DL)-based joint source-channel coding\n(DeepJSCC) has led to a new paradigm of semantic communications. Two salient\nfeatures of DeepJSCC-based semantic communications are the exploitation of\nsemantic-aware features directly from the source signal, and the discrete-time\nanalog transmission (DTAT) of these features. Compared with traditional digital\ncommunications, semantic communications with DeepJSCC provide superior\nreconstruction performance at the receiver and graceful degradation with\ndiminishing channel quality, but also exhibit a large peak-to-average power\nratio (PAPR) in the transmitted signal. An open question has been whether the\ngains of DeepJSCC come from the additional freedom brought by the high-PAPR\ncontinuous-amplitude signal. In this paper, we address this question by\nexploring three PAPR reduction techniques in the application of image\ntransmission. We confirm that the superior image reconstruction performance of\nDeepJSCC-based semantic communications can be retained while the transmitted\nPAPR is suppressed to an acceptable level. This observation is an important\nstep towards the implementation of DeepJSCC in practical semantic communication\nsystems.",
    "descriptor": "\nComments: Keywords: semantic communication, DeepJSCC, discrete-time analog transmission, PAPR\n",
    "authors": [
      "Yulin Shao",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.08342"
  },
  {
    "id": "arXiv:2208.08345",
    "title": "Discovering Agents",
    "abstract": "Causal models of agents have been used to analyse the safety aspects of\nmachine learning systems. But identifying agents is non-trivial -- often the\ncausal model is just assumed by the modeler without much justification -- and\nmodelling failures can lead to mistakes in the safety analysis. This paper\nproposes the first formal causal definition of agents -- roughly that agents\nare systems that would adapt their policy if their actions influenced the world\nin a different way. From this we derive the first causal discovery algorithm\nfor discovering agents from empirical data, and give algorithms for translating\nbetween causal models and game-theoretic influence diagrams. We demonstrate our\napproach by resolving some previous confusions caused by incorrect causal\nmodelling of agents.",
    "descriptor": "",
    "authors": [
      "Zachary Kenton",
      "Ramana Kumar",
      "Sebastian Farquhar",
      "Jonathan Richens",
      "Matt MacDermott",
      "Tom Everitt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08345"
  },
  {
    "id": "arXiv:2208.08349",
    "title": "Open Long-Tailed Recognition in a Dynamic World",
    "abstract": "Real world data often exhibits a long-tailed and open-ended (with unseen\nclasses) distribution. A practical recognition system must balance between\nmajority (head) and minority (tail) classes, generalize across the\ndistribution, and acknowledge novelty upon the instances of unseen classes\n(open classes). We define Open Long-Tailed Recognition++ (OLTR++) as learning\nfrom such naturally distributed data and optimizing for the classification\naccuracy over a balanced test set which includes both known and open classes.\nOLTR++ handles imbalanced classification, few-shot learning, open-set\nrecognition, and active learning in one integrated algorithm, whereas existing\nclassification approaches often focus only on one or two aspects and deliver\npoorly over the entire spectrum. The key challenges are: 1) how to share visual\nknowledge between head and tail classes, 2) how to reduce confusion between\ntail and open classes, and 3) how to actively explore open classes with learned\nknowledge. Our algorithm, OLTR++, maps images to a feature space such that\nvisual concepts can relate to each other through a memory association mechanism\nand a learned metric (dynamic meta-embedding) that both respects the closed\nworld classification of seen classes and acknowledges the novelty of open\nclasses. Additionally, we propose an active learning scheme based on visual\nmemory, which learns to recognize open classes in a data-efficient manner for\nfuture expansions. On three large-scale open long-tailed datasets we curated\nfrom ImageNet (object-centric), Places (scene-centric), and MS1M (face-centric)\ndata, as well as three standard benchmarks (CIFAR-10-LT, CIFAR-100-LT, and\niNaturalist-18), our approach, as a unified framework, consistently\ndemonstrates competitive performance. Notably, our approach also shows strong\npotential for the active exploration of open classes and the fairness analysis\nof minority groups.",
    "descriptor": "\nComments: To appear in IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022. Extended version of our previous CVPR oral paper (arXiv:1904.05160)\n",
    "authors": [
      "Ziwei Liu",
      "Zhongqi Miao",
      "Xiaohang Zhan",
      "Jiayun Wang",
      "Boqing Gong",
      "Stella X. Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08349"
  },
  {
    "id": "arXiv:2208.08351",
    "title": "Minimum Cost Adaptive Submodular Cover",
    "abstract": "We consider the problem of minimum cost cover of adaptive-submodular\nfunctions, and provide a 4(ln Q+1)-approximation algorithm, where Q is the goal\nvalue. This bound is nearly the best possible as the problem does not admit any\napproximation ratio better than ln Q (unless P=NP). Our result is the first\nO(ln Q)-approximation algorithm for this problem. Previously, O(ln Q)\napproximation algorithms were only known assuming either independent items or\nunit-cost items. Furthermore, our result easily extends to the setting where\none wants to simultaneously cover multiple adaptive-submodular functions: we\nobtain the first approximation algorithm for this generalization.",
    "descriptor": "\nComments: 19 pages, 3 figures\n",
    "authors": [
      "Yubing Cui",
      "Viswanath Nagarajan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08351"
  },
  {
    "id": "arXiv:2208.08354",
    "title": "Extract fundamental frequency based on CNN combined with PYIN",
    "abstract": "This paper refers to the extraction of multiple fundamental frequencies\n(multiple F0) based on PYIN, an algorithm for extracting the fundamental\nfrequency (F0) of monophonic music, and a trained convolutional neural networks\n(CNN) model, where a pitch salience function of the input signal is produced to\nestimate the multiple F0. The implementation of these two algorithms and their\ncorresponding advantages and disadvantages are discussed in this article.\nAnalysing the different performance of these two methods, PYIN is applied to\nsupplement the F0 extracted from the trained CNN model to combine the\nadvantages of these two algorithms. For evaluation, four pieces played by two\nviolins are used, and the performance of the models are evaluated accoring to\nthe flatness of the F0 curve extracted. The result shows the combined model\noutperforms the original algorithms when extracting F0 from monophonic music\nand polyphonic music.",
    "descriptor": "",
    "authors": [
      "Ruowei Xing",
      "Shengchen Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2208.08354"
  },
  {
    "id": "arXiv:2208.08367",
    "title": "Ask Question First for Enhancing Lifelong Language Learning",
    "abstract": "Lifelong language learning aims to stream learning NLP tasks while retaining\nknowledge of previous tasks. Previous works based on the language model and\nfollowing data-free constraint approaches have explored formatting all data as\n\"begin token (\\textit{B}) + context (\\textit{C}) + question (\\textit{Q}) +\nanswer (\\textit{A})\" for different tasks. However, they still suffer from\ncatastrophic forgetting and are exacerbated when the previous task's pseudo\ndata is insufficient for the following reasons: (1) The model has difficulty\ngenerating task-corresponding pseudo data, and (2) \\textit{A} is prone to error\nwhen \\textit{A} and \\textit{C} are separated by \\textit{Q} because the\ninformation of the \\textit{C} is diminished before generating \\textit{A}.\nTherefore, we propose the Ask Question First and Replay Question (AQF-RQ),\nincluding a novel data format \"\\textit{BQCA}\" and a new training task to train\npseudo questions of previous tasks. Experimental results demonstrate that\nAQF-RQ makes it easier for the model to generate more pseudo data that match\ncorresponding tasks, and is more robust to both sufficient and insufficient\npseudo-data when the task boundary is both clear and unclear. AQF-RQ can\nachieve only 0.36\\% lower performance than multi-task learning.",
    "descriptor": "\nComments: This paper has been accepted for publication at COLING 2022\n",
    "authors": [
      "Han Wang",
      "Ruiliu Fu",
      "Xuejun Zhang",
      "Jun Zhou",
      "Qingwei Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08367"
  },
  {
    "id": "arXiv:2208.08368",
    "title": "The condition number of singular subspaces",
    "abstract": "The condition number of computing the invariant left or right singular\nsubspace corresponding to any selected subset of singular values of matrices is\ndetermined in the Frobenius norm on the input space of matrices and the\nchordal, Frobenius, and Procrustes distances on the Grassmannian output space.\nUp to a small factor, this condition number equals the inverse minimum singular\nvalue gap between the singular values selected by the projector and those not\nselected, including any ghost singular values.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Nick Vannieuwenhoven"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.08368"
  },
  {
    "id": "arXiv:2208.08369",
    "title": "Radial basis approximation of tensor fields on manifolds: From operator  estimation to manifold learning",
    "abstract": "We study the Radial Basis Function (RBF) approximation to differential\noperators on smooth tensor fields defined on closed Riemannian submanifolds of\nEuclidean space, identified by randomly sampled point cloud data. We establish\nthe spectral convergence for the classical pointwise RBF discrete non-symmetric\napproximation of Laplacians. Numerically, we found that this formulation\nproduces a very accurate estimation of leading spectra with large enough data,\nwhich leads to a computationally expensive task of solving an eigenvalue\nproblem of not only large but also dense, non-symmetric matrix. However, when\nthe size data is small and/or when the local tangent plane of the unknown\nmanifold is poorly estimated, the accuracy deteriorates. Particularly, this\nformulation produces irrelevant eigenvalues, in the sense that they are not\napproximating any of the underlying Laplacian spectra. While these findings\nsuggest that the RBF pointwise formulation may not be reliable to approximate\nLaplacians for manifold learning, it is still an effective method to\napproximate general differential operators on smooth manifolds for other\napplications, including solving PDEs and supervised learning. When the\nmanifolds are unknown, the error bound of the pointwise operator estimation\ndepends on the accuracy of the approximate local tangent spaces. To improve\nthis approximation accuracy, we develop a second-order local SVD technique for\nestimating local tangent spaces on the manifold that offsets the errors induced\nby the curvature in the classical first-order local SVD technique. For manifold\nlearning, we introduce a symmetric RBF discrete approximation of the Laplacians\ninduced by a weak formulation on appropriate Hilbert spaces. We establish the\nconvergence of the eigenpairs of both the Laplace-Beltrami operator and Bochner\nLaplacian in the limit of large data, and provide supporting numerical\nexamples.",
    "descriptor": "\nComments: 14 figures\n",
    "authors": [
      "John Harlim",
      "Shixiao Willing Jiang",
      "John Wilson Peoples"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.08369"
  },
  {
    "id": "arXiv:2208.08370",
    "title": "Energy-grade double pricing mechanism for a combined heat and power  system using the asynchronous dispatch method",
    "abstract": "The problem of heat and electricity pricing in combined heat and power\nsystems regarding the time scales of electricity and heat, as well as thermal\nenergy quality, is studied. Based on the asynchronous coordinated dispatch of\nthe combined heat and power system, an energy-grade double pricing mechanism is\nproposed. Under the pricing mechanism, the resulting merchandise surplus of the\nheat system operator at each heat dispatch interval can be decomposed into\ninterpretable parts and its revenue adequacy can be guaranteed for all heat\ndispatch intervals. And the electric power system operator's resulting\nmerchandise surplus is composed of non-negative components at each electricity\ndispatch interval, also ensuring its revenue adequacy. In addition, the effects\nof different time scales and cogeneration are analyzed in different kinds of\ncombined heat and power units' pricing.",
    "descriptor": "",
    "authors": [
      "Xinyi Yi",
      "Ye Guo",
      "Hongbin Sun",
      "Qiuwei Wu",
      "Li Xiao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.08370"
  },
  {
    "id": "arXiv:2208.08373",
    "title": "Perceptive Locomotion through Nonlinear Model Predictive Control",
    "abstract": "Dynamic locomotion in rough terrain requires accurate foot placement,\ncollision avoidance, and planning of the underactuated dynamics of the system.\nReliably optimizing for such motions and interactions in the presence of\nimperfect and often incomplete perceptive information is challenging. We\npresent a complete perception, planning, and control pipeline, that can\noptimize motions for all degrees of freedom of the robot in real-time. To\nmitigate the numerical challenges posed by the terrain a sequence of convex\ninequality constraints is extracted as local approximations of foothold\nfeasibility and embedded into an online model predictive controller.\nSteppability classification, plane segmentation, and a signed distance field\nare precomputed per elevation map to minimize the computational effort during\nthe optimization. A combination of multiple-shooting, real-time iteration, and\na filter-based line-search are used to solve the formulated problem reliably\nand at high rate. We validate the proposed method in scenarios with gaps,\nslopes, and stepping stones in simulation and experimentally on the ANYmal\nquadruped platform, resulting in state-of-the-art dynamic climbing.",
    "descriptor": "",
    "authors": [
      "Ruben Grandia",
      "Fabian Jenelten",
      "Shaohui Yang",
      "Farbod Farshidian",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.08373"
  },
  {
    "id": "arXiv:2208.08374",
    "title": "Commander's Intent: A Dataset and Modeling Approach for Human-AI Task  Specification in Strategic Play",
    "abstract": "Effective Human-AI teaming requires the ability to communicate the goals of\nthe team and constraints under which you need the agent to operate. Providing\nthe ability to specify the shared intent or operation criteria of the team can\nenable an AI agent to perform its primary function while still being able to\ncater to the specific desires of the current team. While significant work has\nbeen conducted to instruct an agent to perform a task, via language or\ndemonstrations, prior work lacks a focus on building agents which can operate\nwithin the parameters specified by a team. Worse yet, there is a dearth of\nresearch pertaining to enabling humans to provide their specifications through\nunstructured, naturalist language. In this paper, we propose the use of goals\nand constraints as a scaffold to modulate and evaluate autonomous agents. We\ncontribute to this field by presenting a novel dataset, and an associated data\ncollection protocol, which maps language descriptions to goals and constraints\ncorresponding to specific strategies developed by human participants for the\nboard game Risk. Leveraging state-of-the-art language models and augmentation\nprocedures, we develop a machine learning framework which can be used to\nidentify goals and constraints from unstructured strategy descriptions. To\nempirically validate our approach we conduct a human-subjects study to\nestablish a human-baseline for our dataset. Our results show that our machine\nlearning architecture is better able to interpret unstructured language\ndescriptions into strategy specifications than human raters tasked with\nperforming the same machine translation task (F(1,272.53) = 17.025, p < 0.001).",
    "descriptor": "\nComments: 12 Pages, 5 figures, 1 page appendix\n",
    "authors": [
      "Pradyumna Tambwekar",
      "Nathan Vaska",
      "Lakshita Dodeja",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08374"
  },
  {
    "id": "arXiv:2208.08376",
    "title": "Image Varifolds on Meshes for Mapping Spatial Transcriptomics",
    "abstract": "Advances in the development of largely automated microscopy methods such as\nMERFISH for imaging cellular structures in mouse brains are providing spatial\ndetection of micron resolution gene expression. While there has been tremendous\nprogress made in the field Computational Anatomy (CA) to perform diffeomorphic\nmapping technologies at the tissue scales for advanced neuroinformatic studies\nin common coordinates, integration of molecular- and cellular-scale populations\nthrough statistical averaging via common coordinates remains yet unattained.\nThis paper describes the first set of algorithms for calculating geodesics in\nthe space of diffeomorphisms, what we term Image-Varifold LDDMM,extending the\nfamily of large deformation diffeomorphic metric mapping (LDDMM) algorithms to\naccommodate the \"copy and paste\" varifold action of particles which extends\nconsistently to the tissue scales. We represent the brain data as geometric\nmeasures, termed as {\\em image varifolds} supported by a large number of\nunstructured points, % (i.e., not aligned on a 2D or 3D grid), each point\nrepresenting a small volume in space % (which may be incompletely described)\nand carrying a list of densities of {\\em features} elements of a\nhigh-dimensional feature space. The shape of image varifold brain spaces is\nmeasured by transforming them by diffeomorphisms. The metric between image\nvarifolds is obtained after embedding these objects in a linear space equipped\nwith the norm, yielding a so-called \"chordal metric.\"",
    "descriptor": "",
    "authors": [
      "Michael I Miller",
      "Alain Trouv\u00e9",
      "Laurent Younes"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.08376"
  },
  {
    "id": "arXiv:2208.08382",
    "title": "Deep Generative Views to Mitigate Gender Classification Bias Across  Gender-Race Groups",
    "abstract": "Published studies have suggested the bias of automated face-based gender\nclassification algorithms across gender-race groups. Specifically, unequal\naccuracy rates were obtained for women and dark-skinned people. To mitigate the\nbias of gender classifiers, the vision community has developed several\nstrategies. However, the efficacy of these mitigation strategies is\ndemonstrated for a limited number of races mostly, Caucasian and\nAfrican-American. Further, these strategies often offer a trade-off between\nbias and classification accuracy. To further advance the state-of-the-art, we\nleverage the power of generative views, structured learning, and evidential\nlearning towards mitigating gender classification bias. We demonstrate the\nsuperiority of our bias mitigation strategy in improving classification\naccuracy and reducing bias across gender-racial groups through extensive\nexperimental validation, resulting in state-of-the-art performance in intra-\nand cross dataset evaluations.",
    "descriptor": "\nComments: 20 pages, 4 figures, 9 tables, ICPR workshop\n",
    "authors": [
      "Sreeraj Ramachandran",
      "Ajita Rattani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08382"
  },
  {
    "id": "arXiv:2208.08384",
    "title": "Temporal Relaxation of Signal Temporal Logic Specifications for  Resilient Control Synthesis",
    "abstract": "We introduce a metric that can quantify the temporal relaxation of Signal\nTemporal Logic (STL) specifications and facilitate resilient control synthesis\nin the face of infeasibilities. The proposed metric quantifies a cumulative\nnotion of relaxation among the subtasks, and minimizing it yields to structural\nchanges in the original STL specification by i) modifying time-intervals, ii)\nremoving subtasks entirely if needed. To this end, we formulate an optimal\ncontrol problem that extracts state and input sequences by minimally violating\nthe temporal requirements while achieving the desired predicates. We encode\nthis problem in the form of a computationally efficient mixed-integer program.\nWe show some theoretical results on the properties of the new metric. Finally,\nwe present a case study of a robot that minimally violates the time constraints\nof desired tasks in the face of an infeasibility.",
    "descriptor": "\nComments: Accepted to the 2022 IEEE 61st Conference on Decision and Control (CDC)\n",
    "authors": [
      "Ali Tevfik Buyukkocak",
      "Derya Aksaray"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.08384"
  },
  {
    "id": "arXiv:2208.08386",
    "title": "Neural Embeddings for Text",
    "abstract": "We propose a new kind of embedding for natural language text that deeply\nrepresents semantic meaning. Standard text embeddings use the vector output of\na pretrained language model. In our method, we let a language model learn from\nthe text and then literally pick its brain, taking the actual weights of the\nmodel's neurons to generate a vector. We call this representation of the text a\nneural embedding. The technique may generalize beyond text and language models,\nbut we first explore its properties for natural language processing. We compare\nneural embeddings with GPT sentence (SGPT) embeddings on several datasets. We\nobserve that neural embeddings achieve comparable performance with a far\nsmaller model, and the errors are different.",
    "descriptor": "\nComments: 7 pages, 4 figures, 4 tables\n",
    "authors": [
      "Oleg Vasilyev",
      "John Bohannon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08386"
  },
  {
    "id": "arXiv:2208.08388",
    "title": "LAMA-Net: Unsupervised Domain Adaptation via Latent Alignment and  Manifold Learning for RUL Prediction",
    "abstract": "Prognostics and Health Management (PHM) is an emerging field which has\nreceived much attention from the manufacturing industry because of the benefits\nand efficiencies it brings to the table. And Remaining Useful Life (RUL)\nprediction is at the heart of any PHM system. Most recent data-driven research\ndemand substantial volumes of labelled training data before a performant model\ncan be trained under the supervised learning paradigm. This is where Transfer\nLearning (TL) and Domain Adaptation (DA) methods step in and make it possible\nfor us to generalize a supervised model to other domains with different data\ndistributions with no labelled data. In this paper, we propose\n\\textit{LAMA-Net}, an encoder-decoder based model (Transformer) with an induced\nbottleneck, Latent Alignment using Maximum Mean Discrepancy (MMD) and manifold\nlearning is proposed to tackle the problem of Unsupervised Homogeneous Domain\nAdaptation for RUL prediction. \\textit{LAMA-Net} is validated using the C-MAPSS\nTurbofan Engine dataset by NASA and compared against other state-of-the-art\ntechniques for DA. The results suggest that the proposed method offers a\npromising approach to perform domain adaptation in RUL prediction. Code will be\nmade available once the paper comes out of review.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Manu Joseph",
      "Varchita Lalwani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08388"
  },
  {
    "id": "arXiv:2208.08390",
    "title": "Auditory Feedback to Make Walking in Virtual Reality More Accessible",
    "abstract": "The objective of this study is to investigate the impact of several auditory\nfeedback modalities on gait (i.e., walking patterns) in virtual reality (VR).\nPrior research has substantiated gait disturbances in VR users as one of the\nprimary obstacles to VR usability. However, minimal research has been done to\nmitigate this issue. We recruited 39 participants (with mobility impairments:\n18, without mobility impairments: 21) who completed timed walking tasks in a\nreal-world environment and the same tasks in a VR environment with various\ntypes of auditory feedback. Within-subject results showed that each auditory\ncondition significantly improved gait performance while in VR (p < .001)\ncompared to the no auditory condition in VR for both groups of participants\nwith and without mobility impairments. Moreover, spatial audio improved gait\nperformance significantly (p < .001) compared to other auditory conditions for\nboth groups of participants. This research could help to make walking in VR\nmore accessible for people with and without mobility impairments.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "M. Rasel Mahmud",
      "Michael Stewart",
      "Alberto Cordova",
      "John Quarles"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.08390"
  },
  {
    "id": "arXiv:2208.08394",
    "title": "Constant-Depth Sorting Networks",
    "abstract": "In this paper, we address sorting networks that are constructed from\ncomparators of arity $k > 2$. That is, in our setting the arity of the\ncomparators -- or, in other words, the number of inputs that can be sorted at\nthe unit cost -- is a parameter. We study its relationship with two other\nparameters -- $n$, the number of inputs, and $d$, the depth.\nThis model received considerable attention. Partly, its motivation is to\nbetter understand the structure of sorting networks. In particular, sorting\nnetworks with large arity are related to recursive constructions of ordinary\nsorting networks. Additionally, studies of this model have natural\ncorrespondence with a recent line of work on constructing circuits for majority\nfunctions from majority gates of lower fan-in.\nMotivated by these questions, we obtain the first lower bounds on the arity\nof constant-depth sorting networks. More precisely, we consider sorting\nnetworks of depth $d$ up to 4, and determine the minimal $k$ for which there is\nsuch a network with comparators of arity $k$. For depths $d=1,2$ we observe\nthat $k=n$. For $d=3$ we show that $k = \\lceil \\frac n2 \\rceil$. For $d=4$ the\nminimal arity becomes sublinear: $k = \\Theta(n^{2/3})$. This contrasts with the\ncase of majority circuits, in which $k = O(n^{2/3})$ is achievable already for\ndepth $d=3$.",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Natalia Dobrokhotova-Maikova",
      "Alexander Kozachinskiy",
      "Vladimir Podolskii"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2208.08394"
  },
  {
    "id": "arXiv:2208.08398",
    "title": "Safety in the Emerging Holodeck Applications",
    "abstract": "Technological advances in holography, robotics, and 3D printing are starting\nto realize the vision of a holodeck. These immersive 3D displays must address\nuser safety from the start to be viable. A holodeck's safety challenges are\nnovel because its applications will involve explicit physical interactions\nbetween humans and synthesized 3D objects and experiences in real-time. This\npioneering paper first proposes research directions for modeling safety in\nfuture holodeck applications from traditional physical human-robot interaction\nmodeling. Subsequently, we propose a test-bed to enable safety validation of\nphysical human-robot interaction based on existing augmented reality and\nvirtual simulation technology.",
    "descriptor": "\nComments: Appeared in the CHI Conference on Human Factors in Computing Systems (CHI'22), April 29-May 5, 2022, New Orleans, LA, USA. ACM, New York, NY, 3 pages\n",
    "authors": [
      "Shahram Ghandeharizadeh",
      "Luis Garcia"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2208.08398"
  },
  {
    "id": "arXiv:2208.08399",
    "title": "The Counterfactual-Shapley Value: Attributing Change in System Metrics",
    "abstract": "Given an unexpected change in the output metric of a large-scale system, it\nis important to answer why the change occurred: which inputs caused the change\nin metric? A key component of such an attribution question is estimating the\ncounterfactual: the (hypothetical) change in the system metric due to a\nspecified change in a single input. However, due to inherent stochasticity and\ncomplex interactions between parts of the system, it is difficult to model an\noutput metric directly. We utilize the computational structure of a system to\nbreak up the modelling task into sub-parts, such that each sub-part corresponds\nto a more stable mechanism that can be modelled accurately over time. Using the\nsystem's structure also helps to view the metric as a computation over a\nstructural causal model (SCM), thus providing a principled way to estimate\ncounterfactuals. Specifically, we propose a method to estimate counterfactuals\nusing time-series predictive models and construct an attribution score,\nCF-Shapley, that is consistent with desirable axioms for attributing an\nobserved change in the output metric. Unlike past work on causal shapley\nvalues, our proposed method can attribute a single observed change in output\n(rather than a population-level effect) and thus provides more accurate\nattribution scores when evaluated on simulated datasets. As a real-world\napplication, we analyze a query-ad matching system with the goal of attributing\nobserved change in a metric for ad matching density. Attribution scores explain\nhow query volume and ad demand from different query categories affect the ad\nmatching density, leading to actionable insights and uncovering the role of\nexternal events (e.g., \"Cheetah Day\") in driving the matching density.",
    "descriptor": "",
    "authors": [
      "Amit Sharma",
      "Hua Li",
      "Jian Jiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.08399"
  },
  {
    "id": "arXiv:2208.08402",
    "title": "Numerical analysis for electromagnetic scattering from nonlinear  boundary conditions",
    "abstract": "This work studies time-dependent electromagnetic scattering from obstacles\nwhose interaction with the wave is fully determined by a nonlinear boundary\ncondition. In particular, the boundary condition studied in this work enforces\na power law type relation between the electric and magnetic field along the\nboundary. Based on time-dependent jump conditions of classical boundary\noperators, we derive a nonlinear system of time-dependent boundary integral\nequations that determines the tangential traces of the scattered electric and\nmagnetic fields. These fields can subsequently be computed at arbitrary points\nin the exterior domain by evaluating a time-dependent representation formula.\nFully discrete schemes are obtained by discretising the nonlinear system of\nboundary integral equations with Runge--Kutta based convolution quadrature in\ntime and Raviart--Thomas boundary elements in space. Error bounds with\nexplicitly stated convergence rates are proven, under the assumption of\nsufficient regularity of the exact solution. The error analysis is conducted\nthrough novel techniques based on time-discrete transmission problems and the\nuse of a new discrete partial integration inequality. Numerical experiments\nillustrate the use of the proposed method and provide empirical convergence\nrates.",
    "descriptor": "",
    "authors": [
      "J\u00f6rg Nick"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.08402"
  },
  {
    "id": "arXiv:2208.08407",
    "title": "Self-Supervised Depth Estimation in Laparoscopic Image using 3D  Geometric Consistency",
    "abstract": "Depth estimation is a crucial step for image-guided intervention in robotic\nsurgery and laparoscopic imaging system. Since per-pixel depth ground truth is\ndifficult to acquire for laparoscopic image data, it is rarely possible to\napply supervised depth estimation to surgical applications. As an alternative,\nself-supervised methods have been introduced to train depth estimators using\nonly synchronized stereo image pairs. However, most recent work focused on the\nleft-right consistency in 2D and ignored valuable inherent 3D information on\nthe object in real world coordinates, meaning that the left-right 3D geometric\nstructural consistency is not fully utilized. To overcome this limitation, we\npresent M3Depth, a self-supervised depth estimator to leverage 3D geometric\nstructural information hidden in stereo pairs while keeping monocular\ninference. The method also removes the influence of border regions unseen in at\nleast one of the stereo images via masking, to enhance the correspondences\nbetween left and right images in overlapping areas. Intensive experiments show\nthat our method outperforms previous self-supervised approaches on both a\npublic dataset and a newly acquired dataset by a large margin, indicating a\ngood generalization across different samples and laparoscopes.",
    "descriptor": "\nComments: Accepted by MICCAI2022\n",
    "authors": [
      "Baoru Huang",
      "Jian-Qing Zheng",
      "Anh Nguyen",
      "Chi Xu",
      "Ioannis Gkouzionis",
      "Kunal Vyas",
      "David Tuch",
      "Stamatia Giannarou",
      "Daniel S. Elson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2208.08407"
  },
  {
    "id": "arXiv:2208.08408",
    "title": "Summarizing Patients Problems from Hospital Progress Notes Using  Pre-trained Sequence-to-Sequence Models",
    "abstract": "Automatically summarizing patients' main problems from daily progress notes\nusing natural language processing methods helps to battle against information\nand cognitive overload in hospital settings and potentially assists providers\nwith computerized diagnostic decision support. Problem list summarization\nrequires a model to understand, abstract, and generate clinical documentation.\nIn this work, we propose a new NLP task that aims to generate a list of\nproblems in a patient's daily care plan using input from the provider's\nprogress notes during hospitalization. We investigate the performance of T5 and\nBART, two state-of-the-art seq2seq transformer architectures, in solving this\nproblem. We provide a corpus built on top of progress notes from publicly\navailable electronic health record progress notes in the Medical Information\nMart for Intensive Care (MIMIC)-III. T5 and BART are trained on general domain\ntext, and we experiment with a data augmentation method and a domain adaptation\npre-training method to increase exposure to medical vocabulary and knowledge.\nEvaluation methods include ROUGE, BERTScore, cosine similarity on sentence\nembedding, and F-score on medical concepts. Results show that T5 with domain\nadaptive pre-training achieves significant performance gains compared to a\nrule-based system and general domain pre-trained language models, indicating a\npromising direction for tackling the problem summarization task.",
    "descriptor": "\nComments: Paper is accepted to COLING 2022\n",
    "authors": [
      "Yanjun Gao",
      "Dmitry Dligach",
      "Timothy Miller",
      "Dongfang Xu",
      "Matthew M. Churpek",
      "Majid Afshar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08408"
  },
  {
    "id": "arXiv:2208.08410",
    "title": "Distributed Out-of-Memory SVD on CPU/GPU Architectures",
    "abstract": "We propose an efficient, distributed, out-of-memory implementation of the\ntruncated singular value decomposition (t-SVD) for heterogeneous (CPU+GPU) high\nperformance computing (HPC) systems. Various implementations of SVD have been\nproposed, but most only estimate the singular values as an estimation of the\nsingular vectors which can significantly increase the time and memory\ncomplexity of the algorithm. In this work, we propose an implementation of SVD\nbased on the power method, which is a truncated singular values and singular\nvectors estimation method. Memory utilization bottlenecks seen in the power\nmethod are typically associated with the computation of the Gram matrix\n$\\mat{A}^T\\mat{A}$, which can be significant when $\\mat{A}$ is large and dense,\nor when $\\mat{A}$ is super-large and sparse. The proposed implementation is\noptimized for out-of-memory problems where the memory required to factorize a\ngiven matrix is greater than the available GPU memory. We reduce the memory\ncomplexity of $\\mat{A}^T\\mat{A}$ by using a batching strategy where the\nintermediate factors are computed block by block. We also suppress I/O latency\nassociated with both host-to-device (H2D) and device-to-host (D2H) batch copies\nby overlapping each batch copy with compute using CUDA streams. Furthermore, we\nuse optimized \\textit{NCCL} based communicators to reduce the latency\nassociated with collective communications (both intra-node and inter-node). In\naddition, sparse and dense matrix multiplications are significantly accelerated\nwith GPU cores (or tensors cores when available), resulting in an\nimplementation with good scaling. We demonstrate the scalability of our\ndistributed out of core SVD algorithm to successfully decompose dense matrix of\nsize 1TB and sparse matrix of size 128PB with 1e-6 sparsity.",
    "descriptor": "\nComments: Accepted at IEEE HPEC Conference 2022 with Outstanding Paper Award\n",
    "authors": [
      "Ismael Boureima",
      "Manish Bhattarai",
      "Maksim E. Eren",
      "Nick Solovyev",
      "Hristo Djidjev",
      "Boian S. Alexandrov"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.08410"
  },
  {
    "id": "arXiv:2208.08417",
    "title": "Extracting Medication Changes in Clinical Narratives using Pre-trained  Language Models",
    "abstract": "An accurate and detailed account of patient medications, including medication\nchanges within the patient timeline, is essential for healthcare providers to\nprovide appropriate patient care. Healthcare providers or the patients\nthemselves may initiate changes to patient medication. Medication changes take\nmany forms, including prescribed medication and associated dosage modification.\nThese changes provide information about the overall health of the patient and\nthe rationale that led to the current care. Future care can then build on the\nresulting state of the patient. This work explores the automatic extraction of\nmedication change information from free-text clinical notes. The Contextual\nMedication Event Dataset (CMED) is a corpus of clinical notes with annotations\nthat characterize medication changes through multiple change-related\nattributes, including the type of change (start, stop, increase, etc.),\ninitiator of the change, temporality, change likelihood, and negation. Using\nCMED, we identify medication mentions in clinical text and propose three novel\nhigh-performing BERT-based systems that resolve the annotated medication change\ncharacteristics. We demonstrate that our proposed architectures improve\nmedication change classification performance over the initial work exploring\nCMED. We identify medication mentions with high performance at 0.959 F1, and\nour proposed systems classify medication changes and their attributes at an\noverall average of 0.827 F1.",
    "descriptor": "",
    "authors": [
      "Giridhar Kaushik Ramachandran",
      "Kevin Lybarger",
      "Yaya Liu",
      "Diwakar Mahajan",
      "Jennifer J. Liang",
      "Ching-Huei Tsou",
      "Meliha Yetisgen",
      "\u00d6zlem Uzuner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08417"
  },
  {
    "id": "arXiv:2208.08425",
    "title": "SYNTHESIS: A Semi-Asynchronous Path-Integrated Stochastic Gradient  Method for Distributed Learning in Computing Clusters",
    "abstract": "To increase the training speed of distributed learning, recent years have\nwitnessed a significant amount of interest in developing both synchronous and\nasynchronous distributed stochastic variance-reduced optimization methods.\nHowever, all existing synchronous and asynchronous distributed training\nalgorithms suffer from various limitations in either convergence speed or\nimplementation complexity. This motivates us to propose an algorithm called\n\\algname (\\ul{s}emi-as\\ul{yn}chronous pa\\ul{th}-int\\ul{e}grated \\ul{s}tochastic\ngrad\\ul{i}ent \\ul{s}earch), which leverages the special structure of the\nvariance-reduction framework to overcome the limitations of both synchronous\nand asynchronous distributed learning algorithms, while retaining their salient\nfeatures. We consider two implementations of \\algname under distributed and\nshared memory architectures. We show that our \\algname algorithms have\n\\(O(\\sqrt{N}\\epsilon^{-2}(\\Delta+1)+N)\\) and\n\\(O(\\sqrt{N}\\epsilon^{-2}(\\Delta+1) d+N)\\) computational complexities for\nachieving an \\(\\epsilon\\)-stationary point in non-convex learning under\ndistributed and shared memory architectures, respectively, where \\(N\\) denotes\nthe total number of training samples and \\(\\Delta\\) represents the maximum\ndelay of the workers. Moreover, we investigate the generalization performance\nof \\algname by establishing algorithmic stability bounds for quadratic strongly\nconvex and non-convex optimization. We further conduct extensive numerical\nexperiments to verify our theoretical findings",
    "descriptor": "",
    "authors": [
      "Zhuqing Liu",
      "Xin Zhang",
      "Jia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08425"
  },
  {
    "id": "arXiv:2208.08426",
    "title": "\"We Need a Woman in Music\": Exploring Wikipedia's Values on Article  Priority",
    "abstract": "Wikipedia -- like most peer production communities -- suffers from a basic\nproblem: the amount of work that needs to be done (articles to be created and\nimproved) exceeds the available resources (editor effort). Recommender systems\nhave been deployed to address this problem, but they have tended to recommend\nwork tasks that match individuals' personal interests, ignoring more global\ncommunity values. In English Wikipedia, discussion about Vital articles\nconstitutes a proxy for community values about the types of articles that are\nmost important, and should therefore be prioritized for improvement. We first\nanalyzed these discussions, finding that an article's priority is considered a\nfunction of 1) its inherent importance and 2) its effects on Wikipedia's global\ncomposition. One important example of the second consideration is balance,\nincluding along the dimensions of gender and geography. We then conducted a\nquantitative analysis evaluating how four different article prioritization\nmethods -- two from prior research -- would affect Wikipedia's overall balance\non these two dimensions; we found significant differences among the methods. We\ndiscuss the implications of our results, including particularly how they can\nguide the design of recommender systems that take into account community\nvalues, not just individuals' interests.",
    "descriptor": "\nComments: To appear at the 25th ACM Conference On Computer-Supported Cooperative Work And Social Computing (CSCW 2022)\n",
    "authors": [
      "Mo Houtti",
      "Isaac Johnson",
      "Joel Cepeda",
      "Soumya Khandelwal",
      "Aviral Bhatnagar",
      "Loren Terveen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.08426"
  },
  {
    "id": "arXiv:2208.08429",
    "title": "New primitives for bounded degradation in network service",
    "abstract": "Certain new ascendant data center workloads can absorb some degradation in\nnetwork service, not needing fully reliable data transport and/or their\nfair-share of network bandwidth. This opens up opportunities for superior\nnetwork and infrastructure multiplexing by having this flexible traffic cede\ncapacity under congestion to regular traffic with stricter needs. We posit\nthere is opportunity in network service primitives which permit degradation\nwithin certain bounds, such that flexible traffic still receives an acceptable\nlevel of service, while benefiting from its weaker requirements. We propose two\nprimitives, namely guaranteed partial delivery and bounded deprioritization. We\ndesign a budgeting algorithm to provide guarantees relative to their fair\nshare, which is measured via probing. The requirement of budgeting and probing\nlimits the algorithm's applicability to large flexible flows.\nWe evaluate our algorithm with large flexible flows and for three workloads\nof regular flows of small size, large size and a distribution of sizes. Across\nthe workloads, our algorithm achieves less speed-up of regular flows than fixed\nprioritization, especially for the small flows workload (1.25x vs. 6.82 in the\n99th %-tile). Our algorithm provides better guarantees in the workload with\nlarge regular flows (with 14.5% vs. 32.5% of flexible flows being slowed down\nbeyond their guarantee). However, it provides not much better or even slightly\nworse guarantees for the other two workloads. The ability to enforce guarantees\nis influenced by flow fair share interdependence, measurement inaccuracies and\ndependency on convergence. We observe that priority changes to probe or to\ndeprioritize causes queue shifts which deteriorate guarantees and limit\npossible speed-up, especially of small flows. We find that mechanisms to both\nprioritize traffic and track guarantees should be as non-disruptive as\npossible.",
    "descriptor": "",
    "authors": [
      "Simon Kassing",
      "Vojislav Dukic",
      "Ce Zhang",
      "Ankit Singla"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.08429"
  },
  {
    "id": "arXiv:2208.08431",
    "title": "Computationally Efficient Robust Model Predictive Control for Uncertain  System Using Causal State-Feedback Parameterization",
    "abstract": "This paper investigates the problem of robust model predictive control (RMPC)\nof linear-time-invariant (LTI) discrete-time systems subject to structured\nuncertainty and bounded disturbances. Typically, the constrained RMPC problem\nwith state-feedback parameterizations is nonlinear (and nonconvex) with a\nprohibitively high computational burden for online implementation. To remedy\nthis, a novel approach is proposed to linearize the state-feedback RMPC\nproblem, with minimal conservatism, through the use of semidefinite relaxation\ntechniques. The proposed algorithm computes the state-feedback gain and\nperturbation online by solving a linear matrix inequality (LMI) optimization\nthat, in comparison to other schemes in the literature is shown to have a\nsubstantially reduced computational burden without adversely affecting the\ntracking performance of the controller. Additionally, an offline strategy that\nprovides initial feasibility on the RMPC problem is presented. The\neffectiveness of the proposed scheme is demonstrated through numerical examples\nfrom the literature.",
    "descriptor": "\nComments: IEEE TRANSACTIONS ON AUTOMATIC CONTROL\n",
    "authors": [
      "Anastasis Georgiou",
      "Furqan Tahir",
      "Imad M. Jaimoukha",
      "Simos A. Evangelou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.08431"
  },
  {
    "id": "arXiv:2208.08433",
    "title": "Label Flipping Data Poisoning Attack Against Wearable Human Activity  Recognition System",
    "abstract": "Human Activity Recognition (HAR) is a problem of interpreting sensor data to\nhuman movement using an efficient machine learning (ML) approach. The HAR\nsystems rely on data from untrusted users, making them susceptible to data\npoisoning attacks. In a poisoning attack, attackers manipulate the sensor\nreadings to contaminate the training set, misleading the HAR to produce\nerroneous outcomes. This paper presents the design of a label flipping data\npoisoning attack for a HAR system, where the label of a sensor reading is\nmaliciously changed in the data collection phase. Due to high noise and\nuncertainty in the sensing environment, such an attack poses a severe threat to\nthe recognition system. Besides, vulnerability to label flipping attacks is\ndangerous when activity recognition models are deployed in safety-critical\napplications. This paper shades light on how to carry out the attack in\npractice through smartphone-based sensor data collection applications. This is\nan earlier research work, to our knowledge, that explores attacking the HAR\nmodels via label flipping poisoning. We implement the proposed attack and test\nit on activity recognition models based on the following machine learning\nalgorithms: multi-layer perceptron, decision tree, random forest, and XGBoost.\nFinally, we evaluate the effectiveness of K-nearest neighbors (KNN)-based\ndefense mechanism against the proposed attack.",
    "descriptor": "\nComments: Submitted to IEEE SSCI 2022 Conference\n",
    "authors": [
      "Abdur R. Shahid",
      "Ahmed Imteaj",
      "Peter Y. Wu",
      "Diane A. Igoche",
      "Tauhidul Alam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.08433"
  },
  {
    "id": "arXiv:2208.08437",
    "title": "Multi-View Correlation Consistency for Semi-Supervised Semantic  Segmentation",
    "abstract": "Semi-supervised semantic segmentation needs rich and robust supervision on\nunlabeled data. Consistency learning enforces the same pixel to have similar\nfeatures in different augmented views, which is a robust signal but neglects\nrelationships with other pixels. In comparison, contrastive learning considers\nrich pairwise relationships, but it can be a conundrum to assign binary\npositive-negative supervision signals for pixel pairs. In this paper, we take\nthe best of both worlds and propose multi-view correlation consistency (MVCC)\nlearning: it considers rich pairwise relationships in self-correlation matrices\nand matches them across views to provide robust supervision. Together with this\ncorrelation consistency loss, we propose a view-coherent data augmentation\nstrategy that guarantees pixel-pixel correspondence between different views. In\na series of semi-supervised settings on two datasets, we report competitive\naccuracy compared with the state-of-the-art methods. Notably, on Cityscapes, we\nachieve 76.8% mIoU with 1/8 labeled data, just 0.6% shy from the fully\nsupervised oracle.",
    "descriptor": "",
    "authors": [
      "Yunzhong Hou",
      "Stephen Gould",
      "Liang Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08437"
  },
  {
    "id": "arXiv:2208.08438",
    "title": "Learning to Structure an Image with Few Colors and Beyond",
    "abstract": "Color and structure are the two pillars that combine to give an image its\nmeaning. Interested in critical structures for neural network recognition, we\nisolate the influence of colors by limiting the color space to just a few bits,\nand find structures that enable network recognition under such constraints. To\nthis end, we propose a color quantization network, ColorCNN, which learns to\nstructure an image in limited color spaces by minimizing the classification\nloss. Building upon the architecture and insights of ColorCNN, we introduce\nColorCNN+, which supports multiple color space size configurations, and\naddresses the previous issues of poor recognition accuracy and undesirable\nvisual fidelity under large color spaces. Via a novel imitation learning\napproach, ColorCNN+ learns to cluster colors like traditional color\nquantization methods. This reduces overfitting and helps both visual fidelity\nand recognition accuracy under large color spaces. Experiments verify that\nColorCNN+ achieves very competitive results under most circumstances,\npreserving both key structures for network recognition and visual fidelity with\naccurate colors. We further discuss differences between key structures and\naccurate colors, and their specific contributions to network recognition. For\npotential applications, we show that ColorCNNs can be used as image compression\nmethods for network recognition.",
    "descriptor": "",
    "authors": [
      "Yunzhong Hou",
      "Liang Zheng",
      "Stephen Gould"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08438"
  },
  {
    "id": "arXiv:2208.08439",
    "title": "MoCapDeform: Monocular 3D Human Motion Capture in Deformable Scenes",
    "abstract": "3D human motion capture from monocular RGB images respecting interactions of\na subject with complex and possibly deformable environments is a very\nchallenging, ill-posed and under-explored problem. Existing methods address it\nonly weakly and do not model possible surface deformations often occurring when\nhumans interact with scene surfaces. In contrast, this paper proposes\nMoCapDeform, i.e., a new framework for monocular 3D human motion capture that\nis the first to explicitly model non-rigid deformations of a 3D scene for\nimproved 3D human pose estimation and deformable environment reconstruction.\nMoCapDeform accepts a monocular RGB video and a 3D scene mesh aligned in the\ncamera space. It first localises a subject in the input monocular video along\nwith dense contact labels using a new raycasting based strategy. Next, our\nhuman-environment interaction constraints are leveraged to jointly optimise\nglobal 3D human poses and non-rigid surface deformations. MoCapDeform achieves\nsuperior accuracy than competing methods on several datasets, including our\nnewly recorded one with deforming background scenes.",
    "descriptor": "\nComments: 11 pages, 8 figures, 3 tables; project page: this https URL\n",
    "authors": [
      "Zhi Li",
      "Soshi Shimada",
      "Bernt Schiele",
      "Christian Theobalt",
      "Vladislav Golyanik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08439"
  },
  {
    "id": "arXiv:2008.12166",
    "title": "Synchronizing Times for $k$-sets in Automata",
    "abstract": "An automaton is synchronizing if there is a word that maps all states onto\nthe same state. \\v{C}ern\\'{y}'s conjecture on the length of the shortest such\nword is probably the most famous open problem in automata theory. We consider\nthe closely related question of determining the minimum length of a word that\nmaps $k$ states onto a single state. For synchronizing automata, we improve the\nupper bound on the minimum length of a word that sends some triple to a a\nsingle state from $0.5n^2$ to $\\approx 0.19n^2$. We further extend this to an\nimproved bound on the length of such a word for 4 states and 5 states. In the\ncase of non-synchronizing automata, we give an example to show that the minimum\nlength of a word that sends $k$ states to a single state can be as large as\n$\\Theta\\left(n^{k-1}\\right)$.",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Natalie C. Behague",
      "J. Robert Johnson"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2008.12166"
  },
  {
    "id": "arXiv:2203.10786",
    "title": "Classifications of Skull Fractures using CT Scan Images via CNN with  Lazy Learning Approach",
    "abstract": "Classification of skull fracture is a challenging task for both radiologists\nand researchers. Skull fractures result in broken pieces of bone, which can cut\ninto the brain and cause bleeding and other injury types. So it is vital to\ndetect and classify the fracture very early. In real world, often fractures\noccur at multiple sites. This makes it harder to detect the fracture type where\nmany fracture types might summarize a skull fracture. Unfortunately, manual\ndetection of skull fracture and the classification process is time-consuming,\nthreatening a patient's life. Because of the emergence of deep learning, this\nprocess could be automated. Convolutional Neural Networks (CNNs) are the most\nwidely used deep learning models for image categorization because they deliver\nhigh accuracy and outstanding outcomes compared to other models. We propose a\nnew model called SkullNetV1 comprising a novel CNN by taking advantage of CNN\nfor feature extraction and lazy learning approach which acts as a classifier\nfor classification of skull fractures from brain CT images to classify five\nfracture types. Our suggested model achieved a subset accuracy of 88%, an F1\nscore of 93%, the Area Under the Curve (AUC) of 0.89 to 0.98, a Hamming score\nof 92% and a Hamming loss of 0.04 for this seven-class multi-labeled\nclassification.",
    "descriptor": "",
    "authors": [
      "Md Moniruzzaman Emon",
      "Tareque Rahman Ornob",
      "Moqsadur Rahman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.10786"
  },
  {
    "id": "arXiv:2208.07898",
    "title": "Collaborative causal inference on distributed data",
    "abstract": "The development of technologies for causal inference with the privacy\npreservation of distributed data has attracted considerable attention in recent\nyears. To address this issue, we propose a quasi-experiment based on data\ncollaboration (DC-QE) that enables causal inference from distributed data with\nprivacy preservation. Our method preserves the privacy of private data by\nsharing only dimensionality-reduced intermediate representations, which are\nindividually constructed by each party. Moreover, our method can reduce both\nrandom errors and biases, whereas existing methods can only reduce random\nerrors in the estimation of treatment effects. Through numerical experiments on\nboth artificial and real-world data, we confirmed that our method can lead to\nbetter estimation results than individual analyses. With the spread of our\nmethod, intermediate representations can be published as open data to help\nresearchers find causalities and accumulated as a knowledge base.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Yuji Kawamata",
      "Ryoki Motai",
      "Yukihiko Okada",
      "Akira Imakura",
      "Tetsuya Sakurai"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.07898"
  },
  {
    "id": "arXiv:2208.07919",
    "title": "Dynamic Pricing for Non-fungible Resources",
    "abstract": "Public blockchains implement a fee mechanism to allocate scarce computational\nresources across competing transactions. Most existing fee market designs\nutilize a joint, fungible unit of account (e.g., gas in Ethereum) to price\notherwise non-fungible resources such as bandwidth, computation, and storage,\nby hardcoding their relative prices. Fixing the relative price of each resource\nin this way inhibits granular price discovery, limiting scalability and opening\nup the possibility of denial-of-service attacks. As a result, many prominent\nnetworks such as Ethereum and Solana have proposed multi-dimensional fee\nmarkets. In this paper, we provide a principled way to design fee markets that\nefficiently price multiple non-fungible resources. Starting from a loss\nfunction specified by the network designer, we show how to compute dynamic\nprices that align the network's incentives (to minimize the loss) with those of\nthe users and miners (to maximize their welfare), even as demand for these\nresources changes. Our pricing mechanism follows from a natural decomposition\nof the network designer's problem into two parts that are related to each other\nvia the resource prices. These results can be used to efficiently set fees in\norder to improve network performance.",
    "descriptor": "",
    "authors": [
      "Theo Diamandis",
      "Alex Evans",
      "Tarun Chitra",
      "Guillermo Angeris"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2208.07919"
  },
  {
    "id": "arXiv:2208.07926",
    "title": "Mental health concerns prelude the Great Resignation: Evidence from  Social Media",
    "abstract": "To study the causes of the 2021 Great Resignation, we use text analysis to\ninvestigate the changes in work- and quit-related posts between 2018 and 2021\non Reddit. We find that the Reddit discourse evolution resembles the dynamics\nof the U.S. quit and layoff rates. Furthermore, when the COVID-19 pandemic\nstarted, conversations related to working from home, switching jobs,\nwork-related distress, and mental health increased. We distinguish between\ngeneral work-related and specific quit-related discourse changes using a\ndifference-in-differences method. Our main finding is that mental health and\nwork-related distress topics disproportionally increased among quit-related\nposts since the onset of the pandemic, likely contributing to the Great\nResignation. Along with better labor market conditions, some relief came\nbeginning-to-mid-2021 when these concerns decreased. Our study validates the\nuse of forums such as Reddit for studying emerging economic phenomena in real\ntime, complementing traditional labor market surveys and administrative data.",
    "descriptor": "",
    "authors": [
      "R. Maria del Rio-Chanona",
      "Alejandro Hermida-Carrillo",
      "Melody Sepahpour-Fard",
      "Luning Sun",
      "Renata Topinkova",
      "Ljubica Nedelkoska"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2208.07926"
  },
  {
    "id": "arXiv:2208.07957",
    "title": "Uniform observable error bounds of Trotter formulae for the  semiclassical Schr\u00f6dinger equation",
    "abstract": "By no fast-forwarding theorem, the simulation time for the Hamiltonian\nevolution needs to be $O(\\|H\\| t)$, which essentially states that one can not\ngo across the multiple scales as the simulation time for the Hamiltonian\nevolution needs to be strictly greater than the physical time. We demonstrated\nin the context of the semiclassical Schr\\\"odinger equation that the\ncomputational cost for a class of observables can be much lower than the\nstate-of-the-art bounds. In the semiclassical regime (the effective Planck\nconstant $h \\ll 1$), the operator norm of the Hamiltonian is $O(h^{-1})$. We\nshow that the number of Trotter steps used for the observable evolution can be\n$O(1)$, that is, to simulate some observables of the Schr\\\"odinger equation on\na quantum scale only takes the simulation time comparable to the classical\nscale. In terms of error analysis, we improve the additive observable error\nbounds [Lasser-Lubich 2020] to uniform-in-$h$ observable error bounds. This is,\nto our knowledge, the first uniform observable error bound for semiclassical\nSchr\\\"odinger equation without sacrificing the convergence order of the\nnumerical method. Based on semiclassical calculus and discrete microlocal\nanalysis, our result showcases the potential improvements taking advantage of\nmultiscale properties, such as the smallness of the effective Planck constant,\nof the underlying dynamics and sheds light on going across the scale for\nquantum dynamics simulation.",
    "descriptor": "\nComments: 32 pages, 3 figures\n",
    "authors": [
      "Yonah Borns-Weil",
      "Di Fang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.07957"
  },
  {
    "id": "arXiv:2208.07961",
    "title": "Online Learning for Mixture of Multivariate Hawkes Processes",
    "abstract": "Online learning of Hawkes processes has received increasing attention in the\nlast couple of years especially for modeling a network of actors. However,\nthese works typically either model the rich interaction between the events or\nthe latent cluster of the actors or the network structure between the actors.\nWe propose to model the latent structure of the network of actors as well as\ntheir rich interaction across events for real-world settings of medical and\nfinancial applications. Experimental results on both synthetic and real-world\ndata showcase the efficacy of our approach.",
    "descriptor": "\nComments: 12 pages, 6 figures, 3 tables\n",
    "authors": [
      "Mohsen Ghassemi",
      "Niccol\u00f2 Dalmasso",
      "Simran Lamba",
      "Vamsi K. Potluru",
      "Sameena Shah",
      "Tucker Balch",
      "Manuela Veloso"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2208.07961"
  },
  {
    "id": "arXiv:2208.07963",
    "title": "Mixed Quantum-Classical Method For Fraud Detection with Quantum Feature  Selection",
    "abstract": "This paper presents a first end-to-end application of a Quantum Support\nVector Machine (QSVM) algorithm for a classification problem in the financial\npayment industry using the IBM Safer Payments and IBM Quantum Computers via the\nQiskit software stack. Based on real card payment data, a thorough comparison\nis performed to assess the complementary impact brought in by the current\nstate-of-the-art Quantum Machine Learning algorithms with respect to the\nClassical Approach. A new method to search for best features is explored using\nthe Quantum Support Vector Machine's feature map characteristics. The results\nare compared using fraud specific key performance indicators: Accuracy, Recall,\nand False Positive Rate, extracted from analyses based on human expertise (rule\ndecisions), classical machine learning algorithms (Random Forest, XGBoost) and\nquantum based machine learning algorithms using QSVM. In addition, a hybrid\nclassical-quantum approach is explored by using an ensemble model that combines\nclassical and quantum algorithms to better improve the fraud prevention\ndecision. We found, as expected, that the results highly depend on feature\nselections and algorithms that are used to select them. The QSVM provides a\ncomplementary exploration of the feature space which led to an improved\naccuracy of the mixed quantum-classical method for fraud detection, on a\ndrastically reduced data set to fit current state of Quantum Hardware.",
    "descriptor": "\nComments: 11 pages, 12 figures, 9 tables\n",
    "authors": [
      "Michele Grossi",
      "Noelle Ibrahim",
      "Voica Radescu",
      "Robert Loredo",
      "Kirsten Voigt",
      "Constantin Von Altrock",
      "Andreas Rudnik"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.07963"
  },
  {
    "id": "arXiv:2208.07979",
    "title": "Transceiver designs to attain the entanglement assisted communications  capacity",
    "abstract": "Pre-shared entanglement can significantly boost communication rates in the\nhigh thermal noise and low-brightness transmitter regime. In this regime, for a\nlossy-bosonic channel with additive thermal noise, the ratio between the\nentanglement-assisted capacity and the Holevo capacity - the maximum\nreliable-communications rate permitted by quantum mechanics without any\npre-shared entanglement - scales as $\\log(1/{\\bar N}_{\\rm S})$, where the mean\ntransmitted photon number per mode, ${\\bar N}_{\\rm S} \\ll 1$. Thus, pre-shared\nentanglement, e.g., distributed by the quantum internet or a satellite-assisted\nquantum link, promises to significantly improve low-power radio-frequency\ncommunications. In this paper, we propose a pair of structured quantum\ntransceiver designs that leverage continuous-variable pre-shared entanglement\ngenerated, e.g., from a down-conversion source, binary phase modulation, and\nnon-Gaussian joint detection over a code word block, to achieve this scaling\nlaw of capacity enhancement. Further, we describe a modification to the\naforesaid receiver using a front-end that uses sum-frequency generation\nsandwiched with dynamically-programmable in-line two-mode squeezers, and a\nreceiver back-end that takes full advantage of the output of the receiver's\nfront-end by employing a non-destructive multimode vacuum-or-not measurement to\nachieve the entanglement-assisted classical communications capacity.",
    "descriptor": "\nComments: 23 pages excluding appendices, 35 pages including appendices and bibliography. 33 figures. Work extending arXiv:2001.03934\n",
    "authors": [
      "Ali Cox",
      "Quntao Zhuang",
      "Christos Gagatsos",
      "Boulat Bash",
      "Saikat Guha"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.07979"
  },
  {
    "id": "arXiv:2208.08012",
    "title": "Disentangled Speaker Representation Learning via Mutual Information  Minimization",
    "abstract": "Domain mismatch problem caused by speaker-unrelated feature has been a major\ntopic in speaker recognition. In this paper, we propose an explicit\ndisentanglement framework to unravel speaker-relevant features from\nspeaker-unrelated features via mutual information (MI) minimization. To achieve\nour goal of minimizing MI between speaker-related and speaker-unrelated\nfeatures, we adopt a contrastive log-ratio upper bound (CLUB), which exploits\nthe upper bound of MI. Our framework is constructed in a 3-stage structure.\nFirst, in the front-end encoder, input speech is encoded into shared initial\nembedding. Next, in the decoupling block, shared initial embedding is split\ninto separate speaker-related and speaker-unrelated embeddings. Finally,\ndisentanglement is conducted by MI minimization in the last stage. Experiments\non Far-Field Speaker Verification Challenge 2022 (FFSVC2022) demonstrate that\nour proposed framework is effective for disentanglement. Also, to utilize\ndomain-unknown datasets containing numerous speakers, we pre-trained the\nfront-end encoder with VoxCeleb datasets. We then fine-tuned the speaker\nembedding model in the disentanglement framework with FFSVC 2022 dataset. The\nexperimental results show that fine-tuning with a disentanglement framework on\na existing pre-trained model is valid and can further improve performance.",
    "descriptor": "\nComments: 7 pages, 4 figures, and 1 table\n",
    "authors": [
      "Sung Hwan Mun",
      "Min Hyun Han",
      "Minchan Kim",
      "Dongjune Lee",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2208.08012"
  },
  {
    "id": "arXiv:2208.08039",
    "title": "Artificial Intelligence Empowered Multiple Access for Ultra Reliable and  Low Latency THz Wireless Networks",
    "abstract": "Terahertz (THz) wireless networks are expected to catalyze the beyond fifth\ngeneration (B5G) era. However, due to the directional nature and the\nline-of-sight demand of THz links, as well as the ultra-dense deployment of THz\nnetworks, a number of challenges that the medium access control (MAC) layer\nneeds to face are created. In more detail, the need of rethinking user\nassociation and resource allocation strategies by incorporating artificial\nintelligence (AI) capable of providing \"real-time\" solutions in complex and\nfrequently changing environments becomes evident. Moreover, to satisfy the\nultra-reliability and low-latency demands of several B5G applications, novel\nmobility management approaches are required. Motivated by this, this article\npresents a holistic MAC layer approach that enables intelligent user\nassociation and resource allocation, as well as flexible and adaptive mobility\nmanagement, while maximizing systems' reliability through blockage\nminimization. In more detail, a fast and centralized joint user association,\nradio resource allocation, and blockage avoidance by means of a novel\nmetaheuristic-machine learning framework is documented, that maximizes the THz\nnetworks performance, while minimizing the association latency by approximately\nthree orders of magnitude. To support, within the access point (AP) coverage\narea, mobility management and blockage avoidance, a deep reinforcement learning\n(DRL) approach for beam-selection is discussed. Finally, to support user\nmobility between coverage areas of neighbor APs, a proactive hand-over\nmechanism based on AI-assisted fast channel prediction is~reported.",
    "descriptor": "\nComments: 8 pages, 4 figures, 2 tables\n",
    "authors": [
      "Alexandros-Apostolos A. Boulogeorgos",
      "Edwin Yaqub",
      "Rachana Desai",
      "Tachporn Sanguanpuak",
      "Nikos Katzouris",
      "Fotis Lazarakis",
      "Angeliki Alexiou",
      "Marco Di Renzo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.08039"
  },
  {
    "id": "arXiv:2208.08048",
    "title": "REGAS: REspiratory-GAted Synthesis of Views for Multi-Phase CBCT  Reconstruction from a single 3D CBCT Acquisition",
    "abstract": "It is a long-standing challenge to reconstruct Cone Beam Computed Tomography\n(CBCT) of the lung under respiratory motion. This work takes a step further to\naddress a challenging setting in reconstructing a multi-phase}4D lung image\nfrom just a single}3D CBCT acquisition. To this end, we introduce\nREpiratory-GAted Synthesis of views, or REGAS. REGAS proposes a self-supervised\nmethod to synthesize the undersampled tomographic views and mitigate aliasing\nartifacts in reconstructed images. This method allows a much better estimation\nof between-phase Deformation Vector Fields (DVFs), which are used to enhance\nreconstruction quality from direct observations without synthesis. To address\nthe large memory cost of deep neural networks on high resolution 4D data, REGAS\nintroduces a novel Ray Path Transformation (RPT) that allows for distributed,\ndifferentiable forward projections. REGAS require no additional measurements\nlike prior scans, air-flow volume, or breathing velocity. Our extensive\nexperiments show that REGAS significantly outperforms comparable methods in\nquantitative metrics and visual quality.",
    "descriptor": "",
    "authors": [
      "Cheng Peng",
      "Haofu Liao",
      "S. Kevin Zhou",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08048"
  },
  {
    "id": "arXiv:2208.08068",
    "title": "Quantum Bayes AI",
    "abstract": "Quantum Bayesian AI (Q-B) is an emerging field that levers the computational\ngains available in Quantum computing. The promise is an exponential speed-up in\nmany Bayesian algorithms. Our goal is to apply these methods directly to\nstatistical and machine learning problems. We provide a duality between\nclassical and quantum probability for calculating of posterior quantities of\ninterest. Our framework unifies MCMC, Deep Learning and Quantum Learning\ncalculations from the viewpoint from von Neumann's principle of quantum\nmeasurement. Quantum embeddings and neural gates are also an important part of\ndata encoding and feature selection. There is a natural duality with well-known\nkernel methods in statistical learning. We illustrate the behaviour of quantum\nalgorithms on two simple classification algorithms. Finally, we conclude with\ndirections for future research.",
    "descriptor": "",
    "authors": [
      "Nick Polson",
      "Vadim Sokolov",
      "Jianeng Xu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Quantum Algebra (math.QA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2208.08068"
  },
  {
    "id": "arXiv:2208.08105",
    "title": "Reach-avoid Verification Based on Convex Optimization",
    "abstract": "In this paper we propose novel optimization-based methods for verifying\nreach-avoid (or, eventuality) properties of continuous-time systems modelled by\nordinary differential equations. Given a system, an initial set, a safe set and\na target set of states, we say that the reach-avoid property holds if for all\ninitial conditions in the initial set, any trajectory of the system starting at\nthem will eventually, i.e.\\ in unbounded yet finite time, enter the target set\nwhile remaining inside the safe set until that first target hit. Based on a\ndiscount value function, two sets of quantified constraints are derived for\nverifying the reach-avoid property via the computation of\nexponential/asymptotic guidance-barrier functions (they form a barrier\nescorting the system to the target set safely at an exponential or asymptotic\nrate). It is interesting to find that one set of constraints whose solution is\ntermed exponential guidance-barrier functions is just a simplified version of\nthe existing one derived from the moment based method, while the other one\nwhose solution is termed asymptotic guidance-barrier functions is completely\nnew. Furthermore, built upon this new set of constraints, we derive a set of\nmore expressive constraints, which includes the aforementioned two sets of\nconstraints as special instances, providing more chances for verifying the\nreach-avoid properties successfully. When the involved datum are polynomials,\ni.e., the initial set, safe set and target set are semi-algebraic, and the\nsystem has polynomial dynamics, the problem of solving these sets of\nconstraints can be framed as a semi-definite optimization problem using\nsum-of-squares decomposition techniques and thus can be efficiently solved in\npolynomial time via interior point methods. Finally, several examples\ndemonstrate the theoretical developments and performance of proposed methods.",
    "descriptor": "",
    "authors": [
      "Bai Xue",
      "Naijun Zhan",
      "Martin Fr\u00e4nzle",
      "Ji Wang",
      "Wanwei Liu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.08105"
  },
  {
    "id": "arXiv:2208.08138",
    "title": "Shallow neural network representation of polynomials",
    "abstract": "We show that $d$-variate polynomials of degree $R$ can be represented on\n$[0,1]^d$ as shallow neural networks of width\n$d+1+\\sum_{r=2}^R\\binom{r+d-1}{d-1}[\\binom{r+d-1}{d-1}+1]$. Also, by SNN\nrepresentation of localized Taylor polynomials of univariate $C^\\beta$-smooth\nfunctions, we derive for shallow networks the minimax optimal rate of\nconvergence, up to a logarithmic factor, to unknown univariate regression\nfunction.",
    "descriptor": "",
    "authors": [
      "Aleksandr Beknazaryan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08138"
  },
  {
    "id": "arXiv:2208.08155",
    "title": "A Monotonicity Constrained Attention Module for Emotion Classification  with Limited EEG Data",
    "abstract": "In this work, a parameter-efficient attention module is presented for emotion\nclassification using a limited, or relatively small, number of\nelectroencephalogram (EEG) signals. This module is called the Monotonicity\nConstrained Attention Module (MCAM) due to its capability of incorporating\npriors on the monotonicity when converting features' Gram matrices into\nattention matrices for better feature refinement. Our experiments have shown\nthat MCAM's effectiveness is comparable to state-of-the-art attention modules\nin boosting the backbone network's performance in prediction while requiring\nless parameters. Several accompanying sensitivity analyses on trained models'\nprediction concerning different attacks are also performed. These attacks\ninclude various frequency domain filtering levels and gradually morphing\nbetween samples associated with multiple labels. Our results can help better\nunderstand different modules' behaviour in prediction and can provide guidance\nin applications where data is limited and are with noises.",
    "descriptor": "\nComments: A Preprint for the accepted work by MICCAI 2022 workshop: Medical Image Learning with Noisy and Limited Data\n",
    "authors": [
      "Dongyang Kuang",
      "Craig Michoski",
      "Wenting Li",
      "Rui Guo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08155"
  },
  {
    "id": "arXiv:2208.08226",
    "title": "Auto-segmentation of Hip Joints using MultiPlanar UNet with Transfer  learning",
    "abstract": "Accurate geometry representation is essential in developing finite element\nmodels. Although generally good, deep-learning segmentation approaches with\nonly few data have difficulties in accurately segmenting fine features, e.g.,\ngaps and thin structures. Subsequently, segmented geometries need\nlabor-intensive manual modifications to reach a quality where they can be used\nfor simulation purposes. We propose a strategy that uses transfer learning to\nreuse datasets with poor segmentation combined with an interactive learning\nstep where fine-tuning of the data results in anatomically accurate\nsegmentations suitable for simulations. We use a modified MultiPlanar UNet that\nis pre-trained using inferior hip joint segmentation combined with a dedicated\nloss function to learn the gap regions and post-processing to correct tiny\ninaccuracies on symmetric classes due to rotational invariance. We demonstrate\nthis robust yet conceptually simple approach applied with clinically validated\nresults on publicly available computed tomography scans of hip joints. Code and\nresulting 3D models are available at:\n\\url{https://github.com/MICCAI2022-155/AuToSeg}",
    "descriptor": "",
    "authors": [
      "Peidi Xu",
      "Faezeh Moshfeghifar",
      "Torkan Gholamalizadeh",
      "Michael Bachmann Nielsen",
      "Kenny Erleben",
      "Sune Darkner"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08226"
  },
  {
    "id": "arXiv:2208.08230",
    "title": "Two-Stage Robust and Sparse Distributed Statistical Inference for  Large-Scale Data",
    "abstract": "In this paper, we address the problem of conducting statistical inference in\nsettings involving large-scale data that may be high-dimensional and\ncontaminated by outliers. The high volume and dimensionality of the data\nrequire distributed processing and storage solutions. We propose a two-stage\ndistributed and robust statistical inference procedures coping with\nhigh-dimensional models by promoting sparsity. In the first stage, known as\nmodel selection, relevant predictors are locally selected by applying robust\nLasso estimators to the distinct subsets of data. The variable selections from\neach computation node are then fused by a voting scheme to find the sparse\nbasis for the complete data set. It identifies the relevant variables in a\nrobust manner. In the second stage, the developed statistically robust and\ncomputationally efficient bootstrap methods are employed. The actual inference\nconstructs confidence intervals, finds parameter estimates and quantifies\nstandard deviation. Similar to stage 1, the results of local inference are\ncommunicated to the fusion center and combined there. By using analytical\nmethods, we establish the favorable statistical properties of the robust and\ncomputationally efficient bootstrap methods including consistency for a fixed\nnumber of predictors, and robustness. The proposed two-stage robust and\ndistributed inference procedures demonstrate reliable performance and\nrobustness in variable selection, finding confidence intervals and bootstrap\napproximations of standard deviations even when data is high-dimensional and\ncontaminated by outliers.",
    "descriptor": "",
    "authors": [
      "Emadaldin Mozafari-Majd",
      "Visa Koivunen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.08230"
  },
  {
    "id": "arXiv:2208.08233",
    "title": "Dynamical softassign and adaptive parameter tuning for graph matching",
    "abstract": "This paper studies a framework, projected fixed-point method, for graph\nmatching. The framework contains a class of popular graph matching algorithms,\nincluding graduated assignment (GA), integer projected fixed-point method\n(IPFP) and doubly stochastic projected fixed-point method (DSPFP). We propose\nan adaptive strategy to tune the step size parameter in this framework. Such a\nstrategy improves these algorithms in efficiency and accuracy. Further, it\nguarantees the convergence of the underlying algorithms. Some preliminary\nanalysis based on distance geometry seems to support that the optimal step size\nparameter has a high probability of 1 when graphs are fully connected.\nSecondly, it is observed that a popular projection method, softassign, is\nsensitive to graphs' cardinality(size). We proposed a dynamical softassign\nalgorithm that is robust to graphs' cardinality. Combining the adaptive step\nsize and the dynamical softassign, we propose a novel graph matching algorithm:\nthe adaptive projected fixed-point method with dynamical softassign. Various\nexperiments demonstrate that the proposed algorithm is significantly faster\nthan several other state-of-art algorithms with no loss of accuracy.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Binrui Shen",
      "Qiang Niu",
      "Shengxin Zhu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08233"
  },
  {
    "id": "arXiv:2208.08236",
    "title": "DPA-1: Pretraining of Attention-based Deep Potential Model for Molecular  Simulation",
    "abstract": "Machine learning assisted modeling of the inter-atomic potential energy\nsurface (PES) is revolutionizing the field of molecular simulation. With the\naccumulation of high-quality electronic structure data, a model that can be\npretrained on all available data and finetuned on downstream tasks with a small\nadditional effort would bring the field to a new stage. Here we propose DPA-1,\na Deep Potential model with a novel attention mechanism, which is highly\neffective for representing the conformation and chemical spaces of atomic\nsystems and learning the PES. We tested DPA-1 on a number of systems and\nobserved superior performance compared with existing benchmarks. When\npretrained on large-scale datasets containing 56 elements, DPA-1 can be\nsuccessfully applied to various downstream tasks with a great improvement of\nsample efficiency. Surprisingly, for different elements, the learned type\nembedding parameters form a $spiral$ in the latent space and have a natural\ncorrespondence with their positions on the periodic table, showing interesting\ninterpretability of the pretrained DPA-1 model.",
    "descriptor": "",
    "authors": [
      "Duo Zhang",
      "Hangrui Bi",
      "Fu-Zhi Dai",
      "Wanrun Jiang",
      "Linfeng Zhang",
      "Han Wang"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.08236"
  },
  {
    "id": "arXiv:2208.08247",
    "title": "Domain Knowledge in A*-Based Causal Discovery",
    "abstract": "Causal discovery has become a vital tool for scientists and practitioners\nwanting to discover causal relationships from observational data. While most\nprevious approaches to causal discovery have implicitly assumed that no expert\ndomain knowledge is available, practitioners can often provide such domain\nknowledge from prior experience. Recent work has incorporated domain knowledge\ninto constraint-based causal discovery. The majority of such constraint-based\nmethods, however, assume causal faithfulness, which has been shown to be\nfrequently violated in practice. Consequently, there has been renewed attention\ntowards exact-search score-based causal discovery methods, which do not assume\ncausal faithfulness, such as A*-based methods. However, there has been no\nconsideration of these methods in the context of domain knowledge. In this\nwork, we focus on efficiently integrating several types of domain knowledge\ninto A*-based causal discovery. In doing so, we discuss and explain how domain\nknowledge can reduce the graph search space and then provide an analysis of the\npotential computational gains. We support these findings with experiments on\nsynthetic and real data, showing that even small amounts of domain knowledge\ncan dramatically speed up A*-based causal discovery and improve its performance\nand practicality.",
    "descriptor": "",
    "authors": [
      "Steven Kleinegesse",
      "Andrew R. Lawrence",
      "Hana Chockler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08247"
  },
  {
    "id": "arXiv:2208.08265",
    "title": "Semi-Supervised Anomaly Detection Based on Quadratic Multiform  Separation",
    "abstract": "In this paper we propose a novel method for semi-supervised anomaly detection\n(SSAD). Our classifier is named QMS22 as its inception was dated 2022 upon the\nframework of quadratic multiform separation (QMS), a recently introduced\nclassification model. QMS22 tackles SSAD by solving a multi-class\nclassification problem involving both the training set and the test set of the\noriginal problem. The classification problem intentionally includes classes\nwith overlapping samples. One of the classes contains mixture of normal samples\nand outliers, and all other classes contain only normal samples. An outlier\nscore is then calculated for every sample in the test set using the outcome of\nthe classification problem. We also include performance evaluation of QMS22\nagainst top performing classifiers using ninety-five benchmark imbalanced\ndatasets from the KEEL repository. These classifiers are BRM (Bagging-Random\nMiner), OCKRA (One-Class K-means with Randomly-projected features Algorithm),\nISOF (Isolation Forest), and ocSVM (One-Class Support Vector Machine). It is\nshown by using the area under the curve of the receiver operating\ncharacteristic curve as the performance measure, QMS22 significantly\noutperforms ISOF and ocSVM. Moreover, the Wilcoxon signed-rank tests reveal\nthat there is no statistically significant difference when testing QMS22\nagainst BRM nor QMS22 against OCKRA.",
    "descriptor": "",
    "authors": [
      "Ko-Hui Michael Fan",
      "Chih-Chung Chang",
      "Kuang-Hsiao-Yin Kongguoluo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08265"
  },
  {
    "id": "arXiv:2208.08273",
    "title": "Quantum Machine Learning for Material Synthesis and Hardware Security",
    "abstract": "Using quantum computing, this paper addresses two scientifically pressing and\nday-to-day relevant problems, namely, chemical retrosynthesis which is an\nimportant step in drug/material discovery and security of the semiconductor\nsupply chain. We show that Quantum Long Short-Term Memory (QLSTM) is a viable\ntool for retrosynthesis. We achieve 65% training accuracy with QLSTM, whereas\nclassical LSTM can achieve 100%. However, in testing, we achieve 80% accuracy\nwith the QLSTM while classical LSTM peaks at only 70% accuracy! We also\ndemonstrate an application of Quantum Neural Network (QNN) in the hardware\nsecurity domain, specifically in Hardware Trojan (HT) detection using a set of\npower and area Trojan features. The QNN model achieves detection accuracy as\nhigh as 97.27%.",
    "descriptor": "\nComments: 7 pages, ICCAD'22\n",
    "authors": [
      "Collin Beaudoin",
      "Satwik Kundu",
      "Rasit Onur Topaloglu",
      "Swaroop Ghosh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08273"
  },
  {
    "id": "arXiv:2208.08276",
    "title": "Wave simulation in non-smooth media by PINN with quadratic neural  network and PML condition",
    "abstract": "Frequency-domain simulation of seismic waves plays an important role in\nseismic inversion, but it remains challenging in large models. The recently\nproposed physics-informed neural network (PINN), as an effective deep learning\nmethod, has achieved successful applications in solving a wide range of partial\ndifferential equations (PDEs), and there is still room for improvement on this\nfront. For example, PINN can lead to inaccurate solutions when PDE coefficients\nare non-smooth and describe structurally-complex media. In this paper, we solve\nthe acoustic and visco-acoustic scattered-field wave equation in the frequency\ndomain with PINN instead of the wave equation to remove source singularity. We\nfirst illustrate that non-smooth velocity models lead to inaccurate wavefields\nwhen no boundary conditions are implemented in the loss function. Then, we add\nthe perfectly matched layer (PML) conditions in the loss function of PINN and\ndesign a quadratic neural network to overcome the detrimental effects of\nnon-smooth models in PINN. We show that PML and quadratic neurons improve the\nresults as well as attenuation and discuss the reason for this improvement. We\nalso illustrate that a network trained during a wavefield simulation can be\nused to pre-train the neural network of another wavefield simulation after\nPDE-coefficient alteration and improve the convergence speed accordingly. This\npre-training strategy should find application in iterative full waveform\ninversion (FWI) and time-lag target-oriented imaging when the model\nperturbation between two consecutive iterations or two consecutive experiments\ncan be small.",
    "descriptor": "",
    "authors": [
      "Yanqi Wu",
      "Hossein S. Aghamiry",
      "Stephane Operto",
      "Jianwei Ma"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08276"
  },
  {
    "id": "arXiv:2208.08284",
    "title": "Novel Deep Learning Approach to Derive Cytokeratin Expression and  Epithelium Segmentation from DAPI",
    "abstract": "Generative Adversarial Networks (GANs) are state of the art for image\nsynthesis. Here, we present dapi2ck, a novel GAN-based approach to synthesize\ncytokeratin (CK) staining from immunofluorescent (IF) DAPI staining of nuclei\nin non-small cell lung cancer (NSCLC) images. We use the synthetic CK to\nsegment epithelial regions, which, compared to expert annotations, yield\nequally good results as segmentation on stained CK. Considering the limited\nnumber of markers in a multiplexed IF (mIF) panel, our approach allows to\nreplace CK by another marker addressing the complexity of the tumor\nmicro-environment (TME) to facilitate patient selection for immunotherapies. In\ncontrast to stained CK, dapi2ck does not suffer from issues like unspecific CK\nstaining or loss of tumoral CK expression.",
    "descriptor": "\nComments: Short Paper - MIDL2022 (Medical Imaging with Deep Learning)\n",
    "authors": [
      "Felix Jakob Segerer",
      "Katharina Nekolla",
      "Lorenz Rognoni",
      "Ansh Kapil",
      "Markus Schick",
      "Helen Angell",
      "G\u00fcnter Schmidt"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08284"
  },
  {
    "id": "arXiv:2208.08288",
    "title": "Metal artifact correction in cone beam computed tomography using  synthetic X-ray data",
    "abstract": "Metal artifact correction is a challenging problem in cone beam computed\ntomography (CBCT) scanning. Metal implants inserted into the anatomy cause\nsevere artifacts in reconstructed images. Widely used inpainting-based metal\nartifact reduction (MAR) methods require segmentation of metal traces in the\nprojections as a first step which is a challenging task. One approach is to use\na deep learning method to segment metals in the projections. However, the\nsuccess of deep learning methods is limited by the availability of realistic\ntraining data. It is challenging and time consuming to get reliable ground\ntruth annotations due to unclear implant boundary and large number of\nprojections. We propose to use X-ray simulations to generate synthetic metal\nsegmentation training dataset from clinical CBCT scans. We compare the effect\nof simulations with different number of photons and also compare several\ntraining strategies to augment the available data. We compare our model's\nperformance on real clinical scans with conventional threshold-based MAR and a\nrecent deep learning method. We show that simulations with relatively small\nnumber of photons are suitable for the metal segmentation task and that\ntraining the deep learning model with full size and cropped projections\ntogether improves the robustness of the model. We show substantial improvement\nin the image quality affected by severe motion, voxel size under-sampling, and\nout-of-FOV metals. Our method can be easily implemented into the existing\nprojection-based MAR pipeline to get improved image quality. This method can\nprovide a novel paradigm to accurately segment metals in CBCT projections.",
    "descriptor": "",
    "authors": [
      "Harshit Agrawal",
      "Ari Hietanen",
      "Simo S\u00e4rkk\u00e4"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08288"
  },
  {
    "id": "arXiv:2208.08300",
    "title": "Transformer-Based Deep Learning Model for Stock Price Prediction: A Case  Study on Bangladesh Stock Market",
    "abstract": "In modern capital market the price of a stock is often considered to be\nhighly volatile and unpredictable because of various social, financial,\npolitical and other dynamic factors. With calculated and thoughtful investment,\nstock market can ensure a handsome profit with minimal capital investment,\nwhile incorrect prediction can easily bring catastrophic financial loss to the\ninvestors. This paper introduces the application of a recently introduced\nmachine learning model - the Transformer model, to predict the future price of\nstocks of Dhaka Stock Exchange (DSE), the leading stock exchange in Bangladesh.\nThe transformer model has been widely leveraged for natural language processing\nand computer vision tasks, but, to the best of our knowledge, has never been\nused for stock price prediction task at DSE. Recently the introduction of\ntime2vec encoding to represent the time series features has made it possible to\nemploy the transformer model for the stock price prediction. This paper\nconcentrates on the application of transformer-based model to predict the price\nmovement of eight specific stocks listed in DSE based on their historical daily\nand weekly data. Our experiments demonstrate promising results and acceptable\nroot mean squared error on most of the stocks.",
    "descriptor": "\nComments: 16 Pages, 14 Figures (including some containing subfigures)\n",
    "authors": [
      "Tashreef Muhammad",
      "Anika Bintee Aftab",
      "Md. Mainul Ahsan",
      "Maishameem Meherin Muhu",
      "Muhammad Ibrahim",
      "Shahidul Islam Khan",
      "Mohammad Shafiul Alam"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08300"
  },
  {
    "id": "arXiv:2208.08304",
    "title": "Low-Gain Stabilizers for Linear-Convex Optimal Steady-State Control",
    "abstract": "We consider the problem of designing a feedback controller which robustly\nregulates an LTI system to an optimal operating point in the presence of\nunmeasured disturbances. A general design framework based on so-called\noptimality models was previously put forward for this class of problems,\neffectively reducing the problem to that of stabilization of an associated\nnonlinear plant. This paper presents several simple and fully constructive\nstabilizer designs to accompany the optimality model designs from [1]. The\ndesigns are based on a low-gain integral control approach, which enforces\ntime-scale separation between the exponentially stable plant and the\ncontroller. We provide explicit formulas for controllers and gains, along with\nLMI-based methods for the computation of robust/optimal gains. The results are\nillustrated via an academic example and an application to power system\nfrequency control.",
    "descriptor": "\nComments: 8 pages, to appear in IEEE CDC 2022\n",
    "authors": [
      "John W. Simpson-Porco"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.08304"
  },
  {
    "id": "arXiv:2208.08310",
    "title": "Algorithmic reconstruction of discrete dynamics",
    "abstract": "Functional graphs (FG) allow to model under graph structures the behavior of\nmapping functions from a discrete set to itself. These functions are used to\nstudy real complex phenomena evolving in time. As the systems studied can be\nlarge, it can be interesting to decompose and factorise them into several\nsub-graphs acting together. Polynomial equations over functional graphs can\nhelp to define in a formal way this decomposition and factorisation mechanism,\nand solving them validates or invalidates our hypotheses on their\ndecomposability. The current solution methods breaks done the main equation in\na series of basic equations of the form A x X=B, with A, X, and B being FG, but\nthey focus only on the cyclic nodes without taking into account the transient\none. In this work, we propose an algorithm which solves these basic equations\nincluding also this behavior for FG. We exploit a connection with the\ncancellation problem over the direct product of digraphs to introduce a first\nupper bound to the number of solutions for these equations. Then, we introduce\na polynomial algorithm able to give some information about the dynamics of all\nthe solutions, and a second exponential version able to concretely find all\nsolutions X for a basic equation. The goal is to make a step forward in the\nanalysis of finite but complex functions such as those used in biological\nregulatory networks or in systems biology.",
    "descriptor": "",
    "authors": [
      "Fran\u00e7ois Dor\u00e9",
      "Enrico Formenti",
      "Antonio E. Porreca",
      "Sara Riva"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.08310"
  },
  {
    "id": "arXiv:2208.08315",
    "title": "Video-TransUNet: Temporally Blended Vision Transformer for CT VFSS  Instance Segmentation",
    "abstract": "We propose Video-TransUNet, a deep architecture for instance segmentation in\nmedical CT videos constructed by integrating temporal feature blending into the\nTransUNet deep learning framework. In particular, our approach amalgamates\nstrong frame representation via a ResNet CNN backbone, multi-frame feature\nblending via a Temporal Context Module (TCM), non-local attention via a Vision\nTransformer, and reconstructive capabilities for multiple targets via a\nUNet-based convolutional-deconvolutional architecture with multiple heads. We\nshow that this new network design can significantly outperform other\nstate-of-the-art systems when tested on the segmentation of bolus and\npharynx/larynx in Videofluoroscopic Swallowing Study (VFSS) CT sequences. On\nour VFSS2022 dataset it achieves a dice coefficient of $0.8796\\%$ and an\naverage surface distance of $1.0379$ pixels. Note that tracking the pharyngeal\nbolus accurately is a particularly important application in clinical practice\nsince it constitutes the primary method for diagnostics of swallowing\nimpairment. Our findings suggest that the proposed model can indeed enhance the\nTransUNet architecture via exploiting temporal information and improving\nsegmentation performance by a significant margin. We publish key source code,\nnetwork weights, and ground truth annotations for simplified performance\nreproduction.",
    "descriptor": "\nComments: Accepted by International Conference on Machine Vision 2022\n",
    "authors": [
      "Chengxi Zeng",
      "Xinyu Yang",
      "Majid Mirmehdi",
      "Alberto M Gambaruto",
      "Tilo Burghardt"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08315"
  },
  {
    "id": "arXiv:2208.08326",
    "title": "Poisson approximation to the binomial distribution: extensions to the  convergence of positive operators",
    "abstract": "The idea behind Poisson approximation to the binomial distribution was used\nin [J. de la Cal, F. Luquin, J. Approx. Theory, 68(3), 1992, 322-329] and\nsubsequent papers in order to establish the convergence of suitable sequences\nof positive linear operators. The proofs in these papers are given using\nprobabilistic methods. We use similar methods, but in analytic terms. In this\nway we recover some known results and establish several new ones. In\nparticular, we enlarge the list of the limit operators and give\ncharacterizations of them.",
    "descriptor": "",
    "authors": [
      "Ana-Maria Acu",
      "Margareta Heilmann",
      "Ioan Rasa",
      "Andra Seserman"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.08326"
  },
  {
    "id": "arXiv:2208.08331",
    "title": "Leukocyte Classification using Multimodal Architecture Enhanced by  Knowledge Distillation",
    "abstract": "Recently, a lot of automated white blood cells (WBC) or leukocyte\nclassification techniques have been developed. However, all of these methods\nonly utilize a single modality microscopic image i.e. either blood smear or\nfluorescence based, thus missing the potential of a better learning from\nmultimodal images. In this work, we develop an efficient multimodal\narchitecture based on a first of its kind multimodal WBC dataset for the task\nof WBC classification. Specifically, our proposed idea is developed in two\nsteps - 1) First, we learn modality specific independent subnetworks inside a\nsingle network only; 2) We further enhance the learning capability of the\nindependent subnetworks by distilling knowledge from high complexity\nindependent teacher networks. With this, our proposed framework can achieve a\nhigh performance while maintaining low complexity for a multimodal dataset. Our\nunique contribution is two-fold - 1) We present a first of its kind multimodal\nWBC dataset for WBC classification; 2) We develop a high performing multimodal\narchitecture which is also efficient and low in complexity at the same time.",
    "descriptor": "\nComments: Accepted to MICCAI 2022 workshop - MOVI2022\n",
    "authors": [
      "Litao Yang",
      "Deval Mehta",
      "Dwarikanath Mahapatra",
      "Zongyuan Ge"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08331"
  },
  {
    "id": "arXiv:2208.08343",
    "title": "Transferability limitations for Covid 3D Localization Using SARS-CoV-2  segmentation models in 4D CT images",
    "abstract": "In this paper, we investigate the transferability limitations when using deep\nlearning models, for semantic segmentation of pneumonia-infected areas in CT\nimages. The proposed approach adopts a 4 channel input; 3 channels based on\nHounsfield scale, plus one channel (binary) denoting the lung area. We used 3\ndifferent, publicly available, CT datasets. If the lung area mask was not\navailable, a deep learning model generates a proxy image. Experimental results\nsuggesting that transferability should be used carefully, when creating Covid\nsegmentation models; retraining the model more than one times in large sets of\ndata results in a decrease in segmentation accuracy.",
    "descriptor": "\nComments: arXiv:2205.02152v4\n",
    "authors": [
      "Constantine Maganaris",
      "Eftychios Protopapadakis",
      "Nikolaos Bakalos",
      "Nikolaos Doulamis",
      "Dimitris Kalogeras",
      "Aikaterini Angeli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08343"
  },
  {
    "id": "arXiv:2208.08352",
    "title": "FCN-Transformer Feature Fusion for Polyp Segmentation",
    "abstract": "Colonoscopy is widely recognised as the gold standard procedure for the early\ndetection of colorectal cancer (CRC). Segmentation is valuable for two\nsignificant clinical applications, namely lesion detection and classification,\nproviding means to improve accuracy and robustness. The manual segmentation of\npolyps in colonoscopy images is time-consuming. As a result, the use of deep\nlearning (DL) for automation of polyp segmentation has become important.\nHowever, DL-based solutions can be vulnerable to overfitting and the resulting\ninability to generalise to images captured by different colonoscopes. Recent\ntransformer-based architectures for semantic segmentation both achieve higher\nperformance and generalise better than alternatives, however typically predict\na segmentation map of $\\frac{h}{4}\\times\\frac{w}{4}$ spatial dimensions for a\n$h\\times w$ input image. To this end, we propose a new architecture for\nfull-size segmentation which leverages the strengths of a transformer in\nextracting the most important features for segmentation in a primary branch,\nwhile compensating for its limitations in full-size prediction with a secondary\nfully convolutional branch. The resulting features from both branches are then\nfused for final prediction of a $h\\times w$ segmentation map. We demonstrate\nour method's state-of-the-art performance with respect to the mDice, mIoU,\nmPrecision, and mRecall metrics, on both the Kvasir-SEG and CVC-ClinicDB\ndataset benchmarks. Additionally, we train the model on each of these datasets\nand evaluate on the other to demonstrate its superior generalisation\nperformance.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Edward Sanderson",
      "Bogdan J. Matuszewski"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08352"
  },
  {
    "id": "arXiv:2208.08361",
    "title": "I-GWAS: Privacy-Preserving Interdependent Genome-Wide Association  Studies",
    "abstract": "Genome-wide Association Studies (GWASes) identify genomic variations that are\nstatistically associated with a trait, such as a disease, in a group of\nindividuals. Unfortunately, careless sharing of GWAS statistics might give rise\nto privacy attacks. Several works attempted to reconcile secure processing with\nprivacy-preserving releases of GWASes. However, we highlight that these\napproaches remain vulnerable if GWASes utilize overlapping sets of individuals\nand genomic variations. In such conditions, we show that even when relying on\nstate-of-the-art techniques for protecting releases, an adversary could\nreconstruct the genomic variations of up to 28.6% of participants, and that the\nreleased statistics of up to 92.3% of the genomic variations would enable\nmembership inference attacks. We introduce I-GWAS, a novel framework that\nsecurely computes and releases the results of multiple possibly interdependent\nGWASes. I-GWAScontinuously releases privacy-preserving and noise-free GWAS\nresults as new genomes become available.",
    "descriptor": "",
    "authors": [
      "T\u00falio Pascoal",
      "J\u00e9r\u00e9mie Decouchant",
      "Antoine Boutet",
      "Marcus V\u00f6lp"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.08361"
  },
  {
    "id": "arXiv:2208.08401",
    "title": "Conformal Inference for Online Prediction with Arbitrary Distribution  Shifts",
    "abstract": "Conformal inference is a flexible methodology for transforming the\npredictions made by any black-box model (e.g. neural nets, random forests) into\nvalid prediction sets. The only necessary assumption is that the training and\ntest data be exchangeable (e.g. i.i.d.). Unfortunately, this assumption is\nusually unrealistic in online environments in which the processing generating\nthe data may vary in time and consecutive data-points are often temporally\ncorrelated. In this article, we develop an online algorithm for producing\nprediction intervals that are robust to these deviations. Our methods build\nupon conformal inference and thus can be combined with any black-box predictor.\nWe show that the coverage error of our algorithm is controlled by the size of\nthe underlying change in the environment and thus directly connect the size of\nthe distribution shift with the difficulty of the prediction problem. Finally,\nwe apply our procedure in two real-world settings and find that our method\nproduces robust prediction intervals under real-world dynamics.",
    "descriptor": "\nComments: 27 pages, 10 figures\n",
    "authors": [
      "Isaac Gibbs",
      "Emmanuel Cand\u00e8s"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08401"
  },
  {
    "id": "arXiv:1705.10692",
    "title": "A Snowballing Literature Study on Test Amplification",
    "abstract": "A Snowballing Literature Study on Test Amplification",
    "descriptor": "",
    "authors": [
      "Benjamin Danglot",
      "Oscar Luis Vera-P\u00e9rez",
      "Zhongxing Yu",
      "Andy Zaidman",
      "Martin Monperrus",
      "Benoit Baudry"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/1705.10692"
  },
  {
    "id": "arXiv:1912.12463",
    "title": "Arachne: Search Based Repair of Deep Neural Networks",
    "abstract": "Arachne: Search Based Repair of Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Jeongju Sohn",
      "Sungmin Kang",
      "Shin Yoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1912.12463"
  },
  {
    "id": "arXiv:1912.12945",
    "title": "Localized Debiased Machine Learning: Efficient Inference on Quantile  Treatment Effects and Beyond",
    "abstract": "Localized Debiased Machine Learning: Efficient Inference on Quantile  Treatment Effects and Beyond",
    "descriptor": "",
    "authors": [
      "Nathan Kallus",
      "Xiaojie Mao",
      "Masatoshi Uehara"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/1912.12945"
  },
  {
    "id": "arXiv:2006.00165",
    "title": "Cyber LOPA: An Integrated Approach for the Design of Dependable and  Secure Cyber Physical Systems",
    "abstract": "Comments: Preprint version of the published paper",
    "descriptor": "\nComments: Preprint version of the published paper\n",
    "authors": [
      "Ashraf Tantawy",
      "Sherif Abdelwahed",
      "Abdelkarim Erradi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.00165"
  },
  {
    "id": "arXiv:2007.01610",
    "title": "Logical Separability of Labeled Data Examples under Ontologies",
    "abstract": "Comments: Full Version of KR'20 paper",
    "descriptor": "\nComments: Full Version of KR'20 paper\n",
    "authors": [
      "Jean Christoph Jung",
      "Carsten Lutz",
      "Hadrien Pulcini",
      "Frank Wolter"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2007.01610"
  },
  {
    "id": "arXiv:2007.02736",
    "title": "Living Without Beth and Craig: Definitions and Interpolants in  Description and Modal Logics with Nominals and Role Inclusions",
    "abstract": "Comments: We have added many new results to the previous version. The new results are published in the proceedings of the Description Logic Workshop 2022. Also added a section on hybrid modal logic and a discussion of the link between concept learning and interpolation. The title of the paper now mentions modal logic explicitly",
    "descriptor": "\nComments: We have added many new results to the previous version. The new results are published in the proceedings of the Description Logic Workshop 2022. Also added a section on hybrid modal logic and a discussion of the link between concept learning and interpolation. The title of the paper now mentions modal logic explicitly\n",
    "authors": [
      "Alessandro Artale",
      "Jean Christoph Jung",
      "Andrea Mazzullo",
      "Ana Ozaki",
      "Frank Wolter"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2007.02736"
  },
  {
    "id": "arXiv:2007.07464",
    "title": "Further results on Hendry's Conjecture",
    "abstract": "Comments: 9 pages, 2 figures. The results in this manuscript were originally presented at the Canadian Discrete and Algorithmic Mathematics Conference (CanaDAM) in 2015. v2: Edited to acknowledge recent similar results obtained by Rong at al (arXiv:2007.04698 [cs.DM])",
    "descriptor": "\nComments: 9 pages, 2 figures. The results in this manuscript were originally presented at the Canadian Discrete and Algorithmic Mathematics Conference (CanaDAM) in 2015. v2: Edited to acknowledge recent similar results obtained by Rong at al (arXiv:2007.04698 [cs.DM])\n",
    "authors": [
      "Manuel Lafond",
      "Ben Seamone",
      "Rezvan Sherkati"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2007.07464"
  },
  {
    "id": "arXiv:2008.03325",
    "title": "Approximating Two-Stage Stochastic Supplier Problems",
    "abstract": "Approximating Two-Stage Stochastic Supplier Problems",
    "descriptor": "",
    "authors": [
      "Brian Brubach",
      "Nathaniel Grammel",
      "David G. Harris",
      "Aravind Srinivasan",
      "Leonidas Tsepenekas",
      "Anil Vullikanti"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2008.03325"
  },
  {
    "id": "arXiv:2008.13339",
    "title": "A Bidirectional Tree Tagging Scheme for Joint Medical Relation  Extraction",
    "abstract": "Comments: 8 pages, 3 figures",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Xukun Luo",
      "Weijie Liu",
      "Meng Ma",
      "Ping Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2008.13339"
  },
  {
    "id": "arXiv:2011.00884",
    "title": "Mobile Human Ad Hoc Networks: A Communication Engineering Viewpoint on  Interhuman Airborne Pathogen Transmission",
    "abstract": "Comments: 13 pages, 9 figures, to be published in Nano Communication Networks",
    "descriptor": "\nComments: 13 pages, 9 figures, to be published in Nano Communication Networks\n",
    "authors": [
      "Fatih Gulec",
      "Baris Atakan",
      "Falko Dressler"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Social and Information Networks (cs.SI)",
      "Other Quantitative Biology (q-bio.OT)"
    ],
    "url": "https://arxiv.org/abs/2011.00884"
  },
  {
    "id": "arXiv:2011.05309",
    "title": "Supervised PCA: A Multiobjective Approach",
    "abstract": "Supervised PCA: A Multiobjective Approach",
    "descriptor": "",
    "authors": [
      "Alexander Ritchie",
      "Laura Balzano",
      "Daniel Kessler",
      "Chandra S. Sripada",
      "Clayton Scott"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.05309"
  },
  {
    "id": "arXiv:2011.06690",
    "title": "Adversarial Image Color Transformations in Explicit Color Filter Space",
    "abstract": "Comments: Code is available at this https URL This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: Code is available at this https URL This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Zhengyu Zhao",
      "Zhuoran Liu",
      "Martha Larson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.06690"
  },
  {
    "id": "arXiv:2101.03271",
    "title": "HypoSVI: Hypocenter inversion with Stein variational inference and  Physics Informed Neural Networks",
    "abstract": "Comments: Updating to accepted version of the paper",
    "descriptor": "\nComments: Updating to accepted version of the paper\n",
    "authors": [
      "Jonathan D. Smith",
      "Zachary E. Ross",
      "Kamyar Azizzadenesheli",
      "Jack B. Muir"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.03271"
  },
  {
    "id": "arXiv:2101.08525",
    "title": "GhostSR: Learning Ghost Features for Efficient Image Super-Resolution",
    "abstract": "GhostSR: Learning Ghost Features for Efficient Image Super-Resolution",
    "descriptor": "",
    "authors": [
      "Ying Nie",
      "Kai Han",
      "Zhenhua Liu",
      "Chuanjian Liu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.08525"
  },
  {
    "id": "arXiv:2102.02524",
    "title": "Efficient adaptive step size control for exponential integrators",
    "abstract": "Comments: 23 pages, 14 figures, matches with the published version",
    "descriptor": "\nComments: 23 pages, 14 figures, matches with the published version\n",
    "authors": [
      "Pranab Jyoti Deka",
      "Lukas Einkemmer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.02524"
  },
  {
    "id": "arXiv:2102.04539",
    "title": "Placing Green Bridges Optimally, with a Multivariate Analysis",
    "abstract": "Comments: An extended abstract of this work appeared at CiE '21",
    "descriptor": "\nComments: An extended abstract of this work appeared at CiE '21\n",
    "authors": [
      "Till Fluschnik",
      "Leon Kellerhals"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.04539"
  },
  {
    "id": "arXiv:2102.06984",
    "title": "Learning low-rank latent mesoscale structures in networks",
    "abstract": "Comments: 75 pages, 21 figures, 2 tables",
    "descriptor": "\nComments: 75 pages, 21 figures, 2 tables\n",
    "authors": [
      "Hanbaek Lyu",
      "Yacoub H. Kureh",
      "Joshua Vendrow",
      "Mason A. Porter"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06984"
  },
  {
    "id": "arXiv:2103.07298",
    "title": "Augmented Environment Representations with Complete Object Models",
    "abstract": "Comments: Accepted for publication in the 31st IEEE International Conference on Robot & Human Interactive Communication (RO-MAN 2022)",
    "descriptor": "\nComments: Accepted for publication in the 31st IEEE International Conference on Robot & Human Interactive Communication (RO-MAN 2022)\n",
    "authors": [
      "Krishnananda Prabhu Sivananda",
      "Francesco Verdoja",
      "Ville Kyrki"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.07298"
  },
  {
    "id": "arXiv:2104.00687",
    "title": "Classically-Verifiable Quantum Advantage from a Computational Bell Test",
    "abstract": "Comments: 12 pages, 4 figures, 1 table (main text); 12 pages, 1 table (methods + supplementary information). v2: improved notation and clarity, and fixed small errors/typos; no changes to results",
    "descriptor": "\nComments: 12 pages, 4 figures, 1 table (main text); 12 pages, 1 table (methods + supplementary information). v2: improved notation and clarity, and fixed small errors/typos; no changes to results\n",
    "authors": [
      "Gregory D. Kahanamoku-Meyer",
      "Soonwon Choi",
      "Umesh V. Vazirani",
      "Norman Y. Yao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.00687"
  },
  {
    "id": "arXiv:2104.14654",
    "title": "Adversarial Inverse Reinforcement Learning for Mean Field Games",
    "abstract": "Adversarial Inverse Reinforcement Learning for Mean Field Games",
    "descriptor": "",
    "authors": [
      "Yang Chen",
      "Libo Zhang",
      "Jiamou Liu",
      "Zhenyun Deng",
      "Ne\u015fet \u00d6zkan Tan",
      "Michael Witbrock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14654"
  },
  {
    "id": "arXiv:2105.06131",
    "title": "Further Improvements for SAT in Terms of Formula Length",
    "abstract": "Comments: An initial version of this paper with a weaker result was presented at SAT 2021",
    "descriptor": "\nComments: An initial version of this paper with a weaker result was presented at SAT 2021\n",
    "authors": [
      "Junqiang Peng",
      "Mingyu Xiao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.06131"
  },
  {
    "id": "arXiv:2106.01078",
    "title": "Physics-Guided Discovery of Highly Nonlinear Parametric Partial  Differential Equations",
    "abstract": "Comments: 22 pages, 11 figures",
    "descriptor": "\nComments: 22 pages, 11 figures\n",
    "authors": [
      "Yingtao Luo",
      "Qiang Liu",
      "Yuntian Chen",
      "Wenbo Hu",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01078"
  },
  {
    "id": "arXiv:2106.03374",
    "title": "RegMix: Data Mixing Augmentation for Regression",
    "abstract": "Comments: 10 pages, 9 figures, 6 tables",
    "descriptor": "\nComments: 10 pages, 9 figures, 6 tables\n",
    "authors": [
      "Seong-Hyeon Hwang",
      "Steven Euijong Whang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03374"
  },
  {
    "id": "arXiv:2106.06234",
    "title": "A deep learning approach to clustering visual arts",
    "abstract": "Comments: Published on Int J Comput Vis (2022)",
    "descriptor": "\nComments: Published on Int J Comput Vis (2022)\n",
    "authors": [
      "Giovanna Castellano",
      "Gennaro Vessio"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06234"
  },
  {
    "id": "arXiv:2106.06455",
    "title": "Certifying the LTL Formula p Until q in Hybrid Systems",
    "abstract": "Comments: 21 pages. The technical report accompanying \"Certifying the LTL Formula p Until q in Hybrid Systems\" submitted to IEEE Transactions on Automatic Control, 2021",
    "descriptor": "\nComments: 21 pages. The technical report accompanying \"Certifying the LTL Formula p Until q in Hybrid Systems\" submitted to IEEE Transactions on Automatic Control, 2021\n",
    "authors": [
      "Hyejin Han",
      "Mohamed Maghenem",
      "Ricardo G. Sanfelice"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06455"
  },
  {
    "id": "arXiv:2106.08972",
    "title": "Redefining Neural Architecture Search of Heterogeneous Multi-Network  Models by Characterizing Variation Operators and Model Components",
    "abstract": "Redefining Neural Architecture Search of Heterogeneous Multi-Network  Models by Characterizing Variation Operators and Model Components",
    "descriptor": "",
    "authors": [
      "Unai Garciarena",
      "Roberto Santana",
      "Alexander Mendiburu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.08972"
  },
  {
    "id": "arXiv:2106.09637",
    "title": "AttDLNet: Attention-based DL Network for 3D LiDAR Place Recognition",
    "abstract": "Comments: Submitted to ROBOT 2022. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: Submitted to ROBOT 2022. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Tiago Barros",
      "Lu\u00eds Garrote",
      "Ricardo Pereira",
      "Cristiano Premebida",
      "Urbano J. Nunes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09637"
  },
  {
    "id": "arXiv:2106.10852",
    "title": "CUDA-GHR: Controllable Unsupervised Domain Adaptation for Gaze and Head  Redirection",
    "abstract": "Comments: Accepted at WACV2023",
    "descriptor": "\nComments: Accepted at WACV2023\n",
    "authors": [
      "Swati Jindal",
      "Xin Eric Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10852"
  },
  {
    "id": "arXiv:2106.15018",
    "title": "Representing polynomial of ST-CONNECTIVITY",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "J\u0101nis Iraids",
      "Juris Smotrovs"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.15018"
  },
  {
    "id": "arXiv:2107.01312",
    "title": "Lonely individuals process the world in idiosyncratic ways",
    "abstract": "Comments: revised version. arXiv admin note: text overlap with arXiv:2106.02726",
    "descriptor": "\nComments: revised version. arXiv admin note: text overlap with arXiv:2106.02726\n",
    "authors": [
      "Elisa C. Baek",
      "Ryan Hyon",
      "Karina L\u00f3pez",
      "Meng Du",
      "Mason A. Porter",
      "Carolyn Parkinson"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.01312"
  },
  {
    "id": "arXiv:2107.01590",
    "title": "Deep Gaussian Process Emulation using Stochastic Imputation",
    "abstract": "Comments: This article has been accepted for publication in Technometrics, published by Taylor & Francis",
    "descriptor": "\nComments: This article has been accepted for publication in Technometrics, published by Taylor & Francis\n",
    "authors": [
      "Deyu Ming",
      "Daniel Williamson",
      "Serge Guillas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.01590"
  },
  {
    "id": "arXiv:2107.03758",
    "title": "Investigate the Essence of Long-Tailed Recognition from a Unified  Perspective",
    "abstract": "Comments: unfinished version",
    "descriptor": "\nComments: unfinished version\n",
    "authors": [
      "Lei Liu",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.03758"
  },
  {
    "id": "arXiv:2107.06658",
    "title": "A Framework for Machine Learning of Model Error in Dynamical Systems",
    "abstract": "A Framework for Machine Learning of Model Error in Dynamical Systems",
    "descriptor": "",
    "authors": [
      "Matthew E. Levine",
      "Andrew M. Stuart"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06658"
  },
  {
    "id": "arXiv:2107.12824",
    "title": "A Low-Cost Neural ODE with Depthwise Separable Convolution for Edge  Domain Adaptation on FPGAs",
    "abstract": "A Low-Cost Neural ODE with Depthwise Separable Convolution for Edge  Domain Adaptation on FPGAs",
    "descriptor": "",
    "authors": [
      "Hiroki Kawakami",
      "Hirohisa Watanabe",
      "Keisuke Sugiura",
      "Hiroki Matsutani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2107.12824"
  },
  {
    "id": "arXiv:2108.01360",
    "title": "Towards a Better Understanding Human Reading Comprehension with Brain  Signals",
    "abstract": "Comments: Accepted by The Web Conference 2022 (WWW'22) as a full paper",
    "descriptor": "\nComments: Accepted by The Web Conference 2022 (WWW'22) as a full paper\n",
    "authors": [
      "Ziyi Ye",
      "Xiaohui Xie",
      "Yiqun Liu",
      "Zhihong Wang",
      "Xuesong Chen",
      "Min Zhang",
      "Shaoping Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.01360"
  },
  {
    "id": "arXiv:2108.08296",
    "title": "Deep Contrastive Multiview Network Embedding",
    "abstract": "Comments: 5 pages, accepted to CIKM 2022",
    "descriptor": "\nComments: 5 pages, accepted to CIKM 2022\n",
    "authors": [
      "Mengqi Zhang",
      "Yanqiao Zhu",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.08296"
  },
  {
    "id": "arXiv:2108.09440",
    "title": "Unsupervised Local Discrimination for Medical Images",
    "abstract": "Comments: 18 pages, 12 figures",
    "descriptor": "\nComments: 18 pages, 12 figures\n",
    "authors": [
      "Huai Chen",
      "Renzhen Wang",
      "Xiuying Wang",
      "Jieyu Li",
      "Qu Fang",
      "Hui Li",
      "Jianhao Bai",
      "Qing Peng",
      "Deyu Meng",
      "Lisheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.09440"
  },
  {
    "id": "arXiv:2108.13897",
    "title": "mMARCO: A Multilingual Version of the MS MARCO Passage Ranking Dataset",
    "abstract": "mMARCO: A Multilingual Version of the MS MARCO Passage Ranking Dataset",
    "descriptor": "",
    "authors": [
      "Luiz Bonifacio",
      "Vitor Jeronymo",
      "Hugo Queiroz Abonizio",
      "Israel Campiotti",
      "Marzieh Fadaee",
      "Roberto Lotufo",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13897"
  },
  {
    "id": "arXiv:2109.01413",
    "title": "Frequency-Severity Experience Rating based on Latent Markovian Risk  Profiles",
    "abstract": "Frequency-Severity Experience Rating based on Latent Markovian Risk  Profiles",
    "descriptor": "",
    "authors": [
      "Robert Matthijs Verschuren"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01413"
  },
  {
    "id": "arXiv:2109.08170",
    "title": "Quantum message-passing algorithm for optimal and efficient decoding",
    "abstract": "Comments: 56 pages, 22 figures, submitted to Quantum",
    "descriptor": "\nComments: 56 pages, 22 figures, submitted to Quantum\n",
    "authors": [
      "Christophe Piveteau",
      "Joseph M. Renes"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.08170"
  },
  {
    "id": "arXiv:2109.10282",
    "title": "TrOCR: Transformer-based Optical Character Recognition with Pre-trained  Models",
    "abstract": "Comments: Work in Progress",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Minghao Li",
      "Tengchao Lv",
      "Jingye Chen",
      "Lei Cui",
      "Yijuan Lu",
      "Dinei Florencio",
      "Cha Zhang",
      "Zhoujun Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.10282"
  },
  {
    "id": "arXiv:2110.01456",
    "title": "Planning 5G Networks for Rural Fixed Wireless Access",
    "abstract": "Comments: 16 pages, 9 figures, 5 tables",
    "descriptor": "\nComments: 16 pages, 9 figures, 5 tables\n",
    "authors": [
      "Andrew Lappalainen",
      "Yuhao Zhang",
      "Catherine Rosenberg"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.01456"
  },
  {
    "id": "arXiv:2110.04350",
    "title": "FRL: Federated Rank Learning",
    "abstract": "FRL: Federated Rank Learning",
    "descriptor": "",
    "authors": [
      "Hamid Mozaffari",
      "Virat Shejwalkar",
      "Amir Houmansadr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04350"
  },
  {
    "id": "arXiv:2110.04820",
    "title": "Better Pseudo-label: Joint Domain-aware Label and Dual-classifier for  Semi-supervised Domain Generalization",
    "abstract": "Comments: Accepted by Pattern Recognition (PR)",
    "descriptor": "\nComments: Accepted by Pattern Recognition (PR)\n",
    "authors": [
      "Ruiqi Wang",
      "Lei Qi",
      "Yinghuan Shi",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04820"
  },
  {
    "id": "arXiv:2110.04925",
    "title": "Quadratic Multiform Separation: A New Classification Model in Machine  Learning",
    "abstract": "Quadratic Multiform Separation: A New Classification Model in Machine  Learning",
    "descriptor": "",
    "authors": [
      "Ko-Hui Michael Fan",
      "Chih-Chung Chang",
      "Kuang-Hsiao-Yin Kongguoluo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04925"
  },
  {
    "id": "arXiv:2110.06196",
    "title": "GraPE: fast and scalable Graph Processing and Embedding",
    "abstract": "GraPE: fast and scalable Graph Processing and Embedding",
    "descriptor": "",
    "authors": [
      "Luca Cappelletti",
      "Tommaso Fontana",
      "Elena Casiraghi",
      "Vida Ravanmehr",
      "Tiffany J.Callahan",
      "Marcin P. Joachimiak",
      "Christopher J. Mungall",
      "Peter N. Robinson",
      "Justin Reese",
      "Giorgio Valentini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.06196"
  },
  {
    "id": "arXiv:2110.11021",
    "title": "Stability and performance analysis of NMPC: Detectable stage costs and  general terminal costs",
    "abstract": "Comments: Contains an additional nonlinear numerical example",
    "descriptor": "\nComments: Contains an additional nonlinear numerical example\n",
    "authors": [
      "Johannes K\u00f6hler",
      "Melanie Zeilinger",
      "Lars Gr\u00fcne"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11021"
  },
  {
    "id": "arXiv:2110.11567",
    "title": "Logical Assessment Formula and Its Principles for Evaluations with  Inaccurate Ground-Truth Labels",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Yongquan Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11567"
  },
  {
    "id": "arXiv:2110.12340",
    "title": "Adversarial Prefetch: New Cross-Core Cache Side Channel Attacks",
    "abstract": "Comments: camera-ready for IEEE S&P 2022",
    "descriptor": "\nComments: camera-ready for IEEE S&P 2022\n",
    "authors": [
      "Yanan Guo",
      "Andrew Zigerelli",
      "Youtao Zhang",
      "Jun Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.12340"
  },
  {
    "id": "arXiv:2110.14047",
    "title": "Bounding the Distance to Unsafe Sets with Convex Optimization",
    "abstract": "Comments: 28 pages, 16 figures",
    "descriptor": "\nComments: 28 pages, 16 figures\n",
    "authors": [
      "Jared Miller",
      "Mario Sznaier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14047"
  },
  {
    "id": "arXiv:2111.01294",
    "title": "Learning to Operate an Electric Vehicle Charging Station Considering  Vehicle-grid Integration",
    "abstract": "Comments: 11 pages, 7 figures",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Zuzhao Ye",
      "Yuanqi Gao",
      "Nanpeng Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01294"
  },
  {
    "id": "arXiv:2111.03701",
    "title": "Functional Choreographic Programming",
    "abstract": "Functional Choreographic Programming",
    "descriptor": "",
    "authors": [
      "Lu\u00eds Cruz-Filipe",
      "Eva Graversen",
      "Lovro Lugovi\u0107",
      "Fabrizio Montesi",
      "Marco Peressotti"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.03701"
  },
  {
    "id": "arXiv:2111.04254",
    "title": "Alternating Automatic Register Machines",
    "abstract": "Comments: 26 pages, 2 figures",
    "descriptor": "\nComments: 26 pages, 2 figures\n",
    "authors": [
      "Ziyuan Gao",
      "Sanjay Jain",
      "Zeyong Li",
      "Ammar Fathin Sabili",
      "Frank Stephan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.04254"
  },
  {
    "id": "arXiv:2111.07628",
    "title": "Recognizing Series-Parallel Matrices in Linear Time",
    "abstract": "Comments: 16 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: 16 pages, 6 figures, 2 tables\n",
    "authors": [
      "Matthias Walter"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.07628"
  },
  {
    "id": "arXiv:2111.12853",
    "title": "Domain Prompt Learning for Efficiently Adapting CLIP to Unseen Domains",
    "abstract": "Domain Prompt Learning for Efficiently Adapting CLIP to Unseen Domains",
    "descriptor": "",
    "authors": [
      "Xin Zhang",
      "Shixiang Shane Gu",
      "Yutaka Matsuo",
      "Yusuke Iwasawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12853"
  },
  {
    "id": "arXiv:2111.15210",
    "title": "Point Cloud Instance Segmentation with Semi-supervised Bounding-Box  Mining",
    "abstract": "Comments: IEEE Trans on Pattern Analysis and Machine Intelligence",
    "descriptor": "\nComments: IEEE Trans on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Yongbin Liao",
      "Hongyuan Zhu",
      "Yanggang Zhang",
      "Chuangguan Ye",
      "Tao Chen",
      "Jiayuan Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15210"
  },
  {
    "id": "arXiv:2112.10103",
    "title": "SAGA: Stochastic Whole-Body Grasping with Contact",
    "abstract": "Comments: Accepted by ECCV 2022. Project page: this https URL",
    "descriptor": "\nComments: Accepted by ECCV 2022. Project page: this https URL\n",
    "authors": [
      "Yan Wu",
      "Jiahao Wang",
      "Yan Zhang",
      "Siwei Zhang",
      "Otmar Hilliges",
      "Fisher Yu",
      "Siyu Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.10103"
  },
  {
    "id": "arXiv:2112.13747",
    "title": "Modeling Occasion Evolution in Frequency Domain for Promotion-Aware  Click-Through Rate Prediction",
    "abstract": "Modeling Occasion Evolution in Frequency Domain for Promotion-Aware  Click-Through Rate Prediction",
    "descriptor": "",
    "authors": [
      "Xiaofeng Pan",
      "Yibin Shen",
      "Jing Zhang",
      "Xu He",
      "Yang Huang",
      "Hong Wen",
      "Chengjun Mao",
      "Bo Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.13747"
  },
  {
    "id": "arXiv:2112.15386",
    "title": "Efficient Single Image Super-Resolution Using Dual Path Connections with  Multiple Scale Learning",
    "abstract": "Comments: 21 pages, 9 figures, 5 tables",
    "descriptor": "\nComments: 21 pages, 9 figures, 5 tables\n",
    "authors": [
      "Bin-Cheng Yang",
      "Gangshan Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.15386"
  },
  {
    "id": "arXiv:2201.06597",
    "title": "Outsourcing Adjudication to Strategic Jurors",
    "abstract": "Outsourcing Adjudication to Strategic Jurors",
    "descriptor": "",
    "authors": [
      "Ioannis Caragiannis",
      "Nikolaj I. Schwartzbach"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.06597"
  },
  {
    "id": "arXiv:2201.06701",
    "title": "Motion Inbetweening via Deep $\u0394$-Interpolator",
    "abstract": "Motion Inbetweening via Deep $\u0394$-Interpolator",
    "descriptor": "",
    "authors": [
      "Boris N. Oreshkin",
      "Antonios Valkanas",
      "F\u00e9lix G. Harvey",
      "Louis-Simon M\u00e9nard",
      "Florent Bocquelet",
      "Mark J. Coates"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06701"
  },
  {
    "id": "arXiv:2201.10776",
    "title": "DSFormer: A Dual-domain Self-supervised Transformer for Accelerated  Multi-contrast MRI Reconstruction",
    "abstract": "Comments: Accepted at WACV 2023",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Bo Zhou",
      "Neel Dey",
      "Jo Schlemper",
      "Seyed Sadegh Mohseni Salehi",
      "Chi Liu",
      "James S. Duncan",
      "Michal Sofka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10776"
  },
  {
    "id": "arXiv:2201.12590",
    "title": "Map Equation Centrality: Community-aware Centrality based on the Map  Equation",
    "abstract": "Map Equation Centrality: Community-aware Centrality based on the Map  Equation",
    "descriptor": "",
    "authors": [
      "Christopher Bl\u00f6cker",
      "Juan Carlos Nieves",
      "Martin Rosvall"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.12590"
  },
  {
    "id": "arXiv:2202.02607",
    "title": "Lazy Risk-Limiting Ballot Comparison Audits",
    "abstract": "Comments: 33 pages. Substantial technical and editorial revision",
    "descriptor": "\nComments: 33 pages. Substantial technical and editorial revision\n",
    "authors": [
      "Benjamin Fuller",
      "Abigail Harrison",
      "Alexander Russell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02607"
  },
  {
    "id": "arXiv:2202.07455",
    "title": "Transforming agrifood production systems and supply chains with digital  twins",
    "abstract": "Transforming agrifood production systems and supply chains with digital  twins",
    "descriptor": "",
    "authors": [
      "Asaf Tzachor",
      "Catherine E. Richards",
      "Scott Jeen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07455"
  },
  {
    "id": "arXiv:2202.08753",
    "title": "Strong spatial mixing for repulsive point processes",
    "abstract": "Strong spatial mixing for repulsive point processes",
    "descriptor": "",
    "authors": [
      "Marcus Michelen",
      "Will Perkins"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.08753"
  },
  {
    "id": "arXiv:2202.10966",
    "title": "Designing Menus of Contracts Efficiently: The Power of Randomization",
    "abstract": "Designing Menus of Contracts Efficiently: The Power of Randomization",
    "descriptor": "",
    "authors": [
      "Matteo Castiglioni",
      "Alberto Marchesi",
      "Nicola Gatti"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.10966"
  },
  {
    "id": "arXiv:2202.11857",
    "title": "Complexity Results on Untangling Red-Blue Matchings",
    "abstract": "Comments: 26 pages, 24 figures, accepted at EuroCG 2022, at CORE 2022 (ICALP Workshop), and at LATIN 2022",
    "descriptor": "\nComments: 26 pages, 24 figures, accepted at EuroCG 2022, at CORE 2022 (ICALP Workshop), and at LATIN 2022\n",
    "authors": [
      "Arun Kumar Das",
      "Sandip Das",
      "Guilherme D. da Fonseca",
      "Yan Gerard",
      "Bastien Rivier"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2202.11857"
  },
  {
    "id": "arXiv:2203.00504",
    "title": "Analysis of Digitalized ECG Signals Based on Artificial Intelligence and  Spectral Analysis Methods Specialized in ARVC",
    "abstract": "Comments: 28 pages, 10 figures",
    "descriptor": "\nComments: 28 pages, 10 figures\n",
    "authors": [
      "Vasileios E. Papageorgiou",
      "Thomas Zegkos",
      "Georgios Efthimiadis",
      "George Tsaklidis"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Spectral Theory (math.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.00504"
  },
  {
    "id": "arXiv:2203.01693",
    "title": "Learning Neural Set Functions Under the Optimal Subset Oracle",
    "abstract": "Learning Neural Set Functions Under the Optimal Subset Oracle",
    "descriptor": "",
    "authors": [
      "Zijing Ou",
      "Tingyang Xu",
      "Qinliang Su",
      "Yingzhen Li",
      "Peilin Zhao",
      "Yatao Bian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.01693"
  },
  {
    "id": "arXiv:2203.04100",
    "title": "Low-rank approximation of continuous functions in Sobolev spaces with  dominating mixed smoothness",
    "abstract": "Low-rank approximation of continuous functions in Sobolev spaces with  dominating mixed smoothness",
    "descriptor": "",
    "authors": [
      "Michael Griebel",
      "Helmut Harbrecht",
      "Reinhold Schneider"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.04100"
  },
  {
    "id": "arXiv:2203.06810",
    "title": "Automated Learning for Deformable Medical Image Registration by Jointly  Optimizing Network Architectures and Objective Functions",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Xin Fan",
      "Zi Li",
      "Ziyang Li",
      "Xiaolin Wang",
      "Risheng Liu",
      "Zhongxuan Luo",
      "Hao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06810"
  },
  {
    "id": "arXiv:2204.00620",
    "title": "Computation of optimal beams in weak turbulence",
    "abstract": "Computation of optimal beams in weak turbulence",
    "descriptor": "",
    "authors": [
      "Qin Li",
      "Anjali Nair",
      "Samuel N Stechmann"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2204.00620"
  },
  {
    "id": "arXiv:2204.01326",
    "title": "Price Optimal Routing in Public Transportation",
    "abstract": "Comments: Improved Abstract, Introduction, Sections 2-4",
    "descriptor": "\nComments: Improved Abstract, Introduction, Sections 2-4\n",
    "authors": [
      "Ricardo Euler",
      "Niels Lindner",
      "Ralf Bornd\u00f6rfer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.01326"
  },
  {
    "id": "arXiv:2204.05266",
    "title": "Minimizing a low-dimensional convex function over a high-dimensional  cube",
    "abstract": "Minimizing a low-dimensional convex function over a high-dimensional  cube",
    "descriptor": "",
    "authors": [
      "Christoph Hunkenschr\u00f6der",
      "Sebastian Pokutta",
      "Robert Weismantel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.05266"
  },
  {
    "id": "arXiv:2204.08922",
    "title": "Feature Structure Distillation with Centered Kernel Alignment in BERT  Transferring",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Hee-Jun Jung",
      "Doyeon Kim",
      "Seung-Hoon Na",
      "Kangil Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08922"
  },
  {
    "id": "arXiv:2204.09007",
    "title": "Opal: Multimodal Image Generation for News Illustration",
    "abstract": "Opal: Multimodal Image Generation for News Illustration",
    "descriptor": "",
    "authors": [
      "Vivian Liu",
      "Han Qiao",
      "Lydia Chilton"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.09007"
  },
  {
    "id": "arXiv:2204.09615",
    "title": "Dissipative stabilization of linear input delay systems via dynamical  state feedback controllers: an optimization based approach",
    "abstract": "Comments: Accepted by Joint SSSC, TDS, LPVS 2022",
    "descriptor": "\nComments: Accepted by Joint SSSC, TDS, LPVS 2022\n",
    "authors": [
      "Qian Feng",
      "Bo Wei"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.09615"
  },
  {
    "id": "arXiv:2205.09873",
    "title": "Differentially Private Linear Sketches: Efficient Implementations and  Applications",
    "abstract": "Differentially Private Linear Sketches: Efficient Implementations and  Applications",
    "descriptor": "",
    "authors": [
      "Fuheng Zhao",
      "Dan Qiao",
      "Rachel Redberg",
      "Divyakant Agrawal",
      "Amr El Abbadi",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.09873"
  },
  {
    "id": "arXiv:2205.10454",
    "title": "E2FL: Equal and Equitable Federated Learning",
    "abstract": "E2FL: Equal and Equitable Federated Learning",
    "descriptor": "",
    "authors": [
      "Hamid Mozaffari",
      "Amir Houmansadr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10454"
  },
  {
    "id": "arXiv:2205.11648",
    "title": "Deep Representations for Time-varying Brain Datasets",
    "abstract": "Deep Representations for Time-varying Brain Datasets",
    "descriptor": "",
    "authors": [
      "Sikun Lin",
      "Shuyun Tang",
      "Scott Grafton",
      "Ambuj Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2205.11648"
  },
  {
    "id": "arXiv:2205.12358",
    "title": "A Benchmark and Asymmetrical-Similarity Learning for Practical Image  Copy Detection",
    "abstract": "A Benchmark and Asymmetrical-Similarity Learning for Practical Image  Copy Detection",
    "descriptor": "",
    "authors": [
      "Wenhao Wang",
      "Yifan Sun",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12358"
  },
  {
    "id": "arXiv:2205.12997",
    "title": "An Algorithmic Approach to Emergence",
    "abstract": "Comments: 46 pages, 11 figures",
    "descriptor": "\nComments: 46 pages, 11 figures\n",
    "authors": [
      "Charles Alexandre B\u00e9dard",
      "Geoffroy Bergeron"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.12997"
  },
  {
    "id": "arXiv:2205.13504",
    "title": "Are Transformers Effective for Time Series Forecasting?",
    "abstract": "Comments: Code is available at this https URL",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Ailing Zeng",
      "Muxi Chen",
      "Lei Zhang",
      "Qiang Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13504"
  },
  {
    "id": "arXiv:2205.15479",
    "title": "Learning to Represent Programs with Code Hierarchies",
    "abstract": "Learning to Represent Programs with Code Hierarchies",
    "descriptor": "",
    "authors": [
      "Minh H. Nguyen",
      "Nghi D. Q. Bui",
      "Truong Son Hy",
      "Long Tran-Thanh",
      "Risi Kondor"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.15479"
  },
  {
    "id": "arXiv:2206.01018",
    "title": "Score-Based Generative Models Detect Manifolds",
    "abstract": "Comments: 19 pages, 4 figures",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Jakiw Pidstrigach"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.01018"
  },
  {
    "id": "arXiv:2206.01939",
    "title": "Learning Generative Factors of EEG Data with Variational auto-encoders",
    "abstract": "Comments: Accepted to DGM4MICCAI workshop at MICCAI 2022",
    "descriptor": "\nComments: Accepted to DGM4MICCAI workshop at MICCAI 2022\n",
    "authors": [
      "Maksim Zhdanov",
      "Saskia Steinmann",
      "Nico Hoffmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.01939"
  },
  {
    "id": "arXiv:2206.02150",
    "title": "BenchFaaS: Benchmarking Serverless Functions in an Edge Computing  Network Testbed",
    "abstract": "BenchFaaS: Benchmarking Serverless Functions in an Edge Computing  Network Testbed",
    "descriptor": "",
    "authors": [
      "Francisco Carpio",
      "Marc Michalke",
      "Admela Jukan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.02150"
  },
  {
    "id": "arXiv:2206.02424",
    "title": "Slim-neck by GSConv: A better design paradigm of detector architectures  for autonomous vehicles",
    "abstract": "Comments: 18 pages, 12 figures",
    "descriptor": "\nComments: 18 pages, 12 figures\n",
    "authors": [
      "Hulin Li",
      "Jun Li",
      "Hanbing Wei",
      "Zheng Liu",
      "Zhenfei Zhan",
      "Qiliang Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02424"
  },
  {
    "id": "arXiv:2206.04564",
    "title": "TwiBot-22: Towards Graph-Based Twitter Bot Detection",
    "abstract": "TwiBot-22: Towards Graph-Based Twitter Bot Detection",
    "descriptor": "",
    "authors": [
      "Shangbin Feng",
      "Zhaoxuan Tan",
      "Herun Wan",
      "Ningnan Wang",
      "Zilong Chen",
      "Binchi Zhang",
      "Qinghua Zheng",
      "Wenqian Zhang",
      "Zhenyu Lei",
      "Shujie Yang",
      "Xinshun Feng",
      "Qingyue Zhang",
      "Hongrui Wang",
      "Yuhan Liu",
      "Yuyang Bai",
      "Heng Wang",
      "Zijian Cai",
      "Yanbo Wang",
      "Lijing Zheng",
      "Zihan Ma",
      "Jundong Li",
      "Minnan Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04564"
  },
  {
    "id": "arXiv:2206.05195",
    "title": "Nominal Metaphor Generation with Multitask Learning",
    "abstract": "Nominal Metaphor Generation with Multitask Learning",
    "descriptor": "",
    "authors": [
      "Yucheng Li",
      "Chenghua Lin",
      "Frank Geurin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05195"
  },
  {
    "id": "arXiv:2206.05273",
    "title": "A General Framework for the Representation of Function and Affordance: A  Cognitive, Causal, and Grounded Approach, and a Step Toward AGI",
    "abstract": "Comments: 66 pages, 49 figures",
    "descriptor": "\nComments: 66 pages, 49 figures\n",
    "authors": [
      "Seng-Beng Ho"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05273"
  },
  {
    "id": "arXiv:2206.06174",
    "title": "Predicting Corporate Risk by Jointly Modeling Company Networks and  Dialogues in Earnings Conference Calls",
    "abstract": "Predicting Corporate Risk by Jointly Modeling Company Networks and  Dialogues in Earnings Conference Calls",
    "descriptor": "",
    "authors": [
      "Yunxin Sang",
      "Yang Bao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06174"
  },
  {
    "id": "arXiv:2206.07468",
    "title": "PolyU-BPCoMa: A Dataset and Benchmark Towards Mobile Colorized Mapping  Using a Backpack Multisensorial System",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Wenzhong Shi",
      "Pengxin Chen",
      "Muyang Wang",
      "Sheng Bao",
      "Haodong Xiang",
      "Yue Yu",
      "Daping Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.07468"
  },
  {
    "id": "arXiv:2206.08006",
    "title": "Energy-Grade Double Pricing Rule in the Heating Market",
    "abstract": "Energy-Grade Double Pricing Rule in the Heating Market",
    "descriptor": "",
    "authors": [
      "Xinyi Yi",
      "Ye Guo",
      "Hongbin Sun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.08006"
  },
  {
    "id": "arXiv:2206.08522",
    "title": "VLMbench: A Compositional Benchmark for Vision-and-Language Manipulation",
    "abstract": "VLMbench: A Compositional Benchmark for Vision-and-Language Manipulation",
    "descriptor": "",
    "authors": [
      "Kaizhi Zheng",
      "Xiaotong Chen",
      "Odest Chadwicke Jenkins",
      "Xin Eric Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08522"
  },
  {
    "id": "arXiv:2206.08631",
    "title": "On Computing Optimal Linear Diagrams",
    "abstract": "Comments: 17 pages, 4 figures. Extended version of Diagrams 2022 paper",
    "descriptor": "\nComments: 17 pages, 4 figures. Extended version of Diagrams 2022 paper\n",
    "authors": [
      "Alexander Dobler",
      "Martin N\u00f6llenburg"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.08631"
  },
  {
    "id": "arXiv:2206.09061",
    "title": "Design of Supervision-Scalable Learning Systems: Methodology and  Performance Benchmarking",
    "abstract": "Comments: 16 pages, 12 figures, 4 tables, under consideration at Pattern Recognition",
    "descriptor": "\nComments: 16 pages, 12 figures, 4 tables, under consideration at Pattern Recognition\n",
    "authors": [
      "Yijing Yang",
      "Hongyu Fu",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09061"
  },
  {
    "id": "arXiv:2206.10314",
    "title": "Goal-Oriented Adaptive Finite Element Multilevel Monte Carlo with  Convergence Rates",
    "abstract": "Comments: Fixed typos, included more proofs and discussions",
    "descriptor": "\nComments: Fixed typos, included more proofs and discussions\n",
    "authors": [
      "Joakim Beck",
      "Yang Liu",
      "Erik von Schwerin",
      "Ra\u00fal Tempone"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.10314"
  },
  {
    "id": "arXiv:2206.10847",
    "title": "Connecting Algorithmic Research and Usage Contexts: A Perspective of  Contextualized Evaluation for Explainable AI",
    "abstract": "Comments: Forthcoming for AAAI HCOMP 2022",
    "descriptor": "\nComments: Forthcoming for AAAI HCOMP 2022\n",
    "authors": [
      "Q. Vera Liao",
      "Yunfeng Zhang",
      "Ronny Luss",
      "Finale Doshi-Velez",
      "Amit Dhurandhar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.10847"
  },
  {
    "id": "arXiv:2206.11561",
    "title": "ReuseKNN: Neighborhood Reuse for Differentially-Private KNN-Based  Recommendations",
    "abstract": "Comments: 24 pages, 7 figures, 6 tables, under review for TIST",
    "descriptor": "\nComments: 24 pages, 7 figures, 6 tables, under review for TIST\n",
    "authors": [
      "Peter M\u00fcllner",
      "Elisabeth Lex",
      "Markus Schedl",
      "Dominik Kowald"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.11561"
  },
  {
    "id": "arXiv:2206.14390",
    "title": "Diet Code is Healthy: Simplifying Programs for Pre-Trained Models of  Code",
    "abstract": "Comments: Accepted to be published in ESEC/FSE 2022",
    "descriptor": "\nComments: Accepted to be published in ESEC/FSE 2022\n",
    "authors": [
      "Zhaowei Zhang",
      "Hongyu Zhang",
      "Beijun Shen",
      "Xiaodong Gu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.14390"
  },
  {
    "id": "arXiv:2206.15073",
    "title": "COVID Detection and Severity Prediction with 3D-ConvNeXt and Custom  Pretrainings",
    "abstract": "Comments: 17 pages, 3 figures, informations about challenge submission",
    "descriptor": "\nComments: 17 pages, 3 figures, informations about challenge submission\n",
    "authors": [
      "Daniel Kienzle",
      "Julian Lorenz",
      "Robin Sch\u00f6n",
      "Katja Ludwig",
      "Rainer Lienhart"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15073"
  },
  {
    "id": "arXiv:2207.00164",
    "title": "Deep Optical Coding Design in Computational Imaging",
    "abstract": "Deep Optical Coding Design in Computational Imaging",
    "descriptor": "",
    "authors": [
      "Henry Arguello",
      "Jorge Bacca",
      "Hasindu Kariyawasam",
      "Edwin Vargas",
      "Miguel Marquez",
      "Ramith Hettiarachchi",
      "Hans Garcia",
      "Kithmini Herath",
      "Udith Haputhanthri",
      "Balpreet Singh Ahluwalia",
      "Peter So",
      "Dushan N. Wadduwage",
      "Chamira U. S. Edussooriya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.00164"
  },
  {
    "id": "arXiv:2207.06332",
    "title": "Symmetry-Aware Transformer-based Mirror Detection",
    "abstract": "Symmetry-Aware Transformer-based Mirror Detection",
    "descriptor": "",
    "authors": [
      "Tianyu Huang",
      "Bowen Dong",
      "Jiaying Lin",
      "Xiaohui Liu",
      "Rynson W.H. Lau",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06332"
  },
  {
    "id": "arXiv:2207.07038",
    "title": "From Shapley back to Pearson: Hypothesis Testing via the Shapley Value",
    "abstract": "From Shapley back to Pearson: Hypothesis Testing via the Shapley Value",
    "descriptor": "",
    "authors": [
      "Jacopo Teneggi",
      "Beepul Bharti",
      "Yaniv Romano",
      "Jeremias Sulam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.07038"
  },
  {
    "id": "arXiv:2207.07874",
    "title": "Model-Aware Contrastive Learning: Towards Escaping Uniformity-Tolerance  Dilemma in Training",
    "abstract": "Model-Aware Contrastive Learning: Towards Escaping Uniformity-Tolerance  Dilemma in Training",
    "descriptor": "",
    "authors": [
      "Zizheng Huang",
      "Chao Zhang",
      "Huaxiong Li",
      "Bo Wang",
      "Chunlin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.07874"
  },
  {
    "id": "arXiv:2207.08548",
    "title": "GATE: Gated Additive Tree Ensemble for Tabular Classification and  Regression",
    "abstract": "GATE: Gated Additive Tree Ensemble for Tabular Classification and  Regression",
    "descriptor": "",
    "authors": [
      "Manu Joseph",
      "Harsh Raj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.08548"
  },
  {
    "id": "arXiv:2207.08824",
    "title": "Energy-Motivated Equivariant Pretraining for 3D Molecular Graphs",
    "abstract": "Energy-Motivated Equivariant Pretraining for 3D Molecular Graphs",
    "descriptor": "",
    "authors": [
      "Rui Jiao",
      "Jiaqi Han",
      "Wenbing Huang",
      "Yu Rong",
      "Yang Liu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.08824"
  },
  {
    "id": "arXiv:2207.10345",
    "title": "CADyQ: Content-Aware Dynamic Quantization for Image Super-Resolution",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Cheeun Hong",
      "Sungyong Baik",
      "Heewon Kim",
      "Seungjun Nah",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.10345"
  },
  {
    "id": "arXiv:2207.10400",
    "title": "Correspondence Matters for Video Referring Expression Comprehension",
    "abstract": "Comments: Accepted by ACM MM 2022",
    "descriptor": "\nComments: Accepted by ACM MM 2022\n",
    "authors": [
      "Meng Cao",
      "Ji Jiang",
      "Long Chen",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10400"
  },
  {
    "id": "arXiv:2207.13645",
    "title": "Do Quantum Circuit Born Machines Generalize?",
    "abstract": "Do Quantum Circuit Born Machines Generalize?",
    "descriptor": "",
    "authors": [
      "Kaitlin Gili",
      "Mohamed Hibat-Allah",
      "Marta Mauri",
      "Chris Ballance",
      "Alejandro Perdomo-Ortiz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.13645"
  },
  {
    "id": "arXiv:2208.00956",
    "title": "An Adjoint-Free Algorithm for CNOP via Sampling",
    "abstract": "Comments: 14 pages, 14 figures",
    "descriptor": "\nComments: 14 pages, 14 figures\n",
    "authors": [
      "Bin Shi",
      "Guodong Sun"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.00956"
  },
  {
    "id": "arXiv:2208.01889",
    "title": "Multi-Scale User Behavior Network for Entire Space Multi-Task Learning",
    "abstract": "Comments: CIKM 2022",
    "descriptor": "\nComments: CIKM 2022\n",
    "authors": [
      "Jiarui Jin",
      "Xianyu Chen",
      "Weinan Zhang",
      "Yuanbo Chen",
      "Zaifan Jiang",
      "Zekun Zhu",
      "Zhewen Su",
      "Yong Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.01889"
  },
  {
    "id": "arXiv:2208.02112",
    "title": "Various bounds on the minimum number of arcs in a $k$-dicritical digraph",
    "abstract": "Various bounds on the minimum number of arcs in a $k$-dicritical digraph",
    "descriptor": "",
    "authors": [
      "Pierre Aboulker",
      "Quentin Vermande"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.02112"
  },
  {
    "id": "arXiv:2208.02126",
    "title": "Noise tolerance of learning to rank under class-conditional label noise",
    "abstract": "Noise tolerance of learning to rank under class-conditional label noise",
    "descriptor": "",
    "authors": [
      "Dany Haddad"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.02126"
  },
  {
    "id": "arXiv:2208.02845",
    "title": "Decision SincNet: Neurocognitive models of decision making that predict  cognitive processes from neural signals",
    "abstract": "Comments: This paper was accepted as an oral presentation at IEEE WCCI 2022 (IJCNN 2022), under the session Neurodynamics and computational Neuroscience. This paper is published in International Joint Conference on Neural Networks (IJCNN) Proceedings 2022",
    "descriptor": "\nComments: This paper was accepted as an oral presentation at IEEE WCCI 2022 (IJCNN 2022), under the session Neurodynamics and computational Neuroscience. This paper is published in International Joint Conference on Neural Networks (IJCNN) Proceedings 2022\n",
    "authors": [
      "Qinhua Jenny Sun",
      "Khuong Vo",
      "Kitty Lui",
      "Michael Nunez",
      "Joachim Vandekerckhove",
      "Ramesh Srinivasan"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.02845"
  },
  {
    "id": "arXiv:2208.03059",
    "title": "Sinusoidal Sensitivity Calculation for Line Segment Geometries",
    "abstract": "Sinusoidal Sensitivity Calculation for Line Segment Geometries",
    "descriptor": "",
    "authors": [
      "Luciano Vinas",
      "Atchar Sudyadhom"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.03059"
  },
  {
    "id": "arXiv:2208.03895",
    "title": "Contrastive Learning with Bidirectional Transformers for Sequential  Recommendation",
    "abstract": "Comments: Accepted by CIKM 2022",
    "descriptor": "\nComments: Accepted by CIKM 2022\n",
    "authors": [
      "Hanwen Du",
      "Hui Shi",
      "Pengpeng Zhao",
      "Deqing Wang",
      "Victor S.Sheng",
      "Yanchi Liu",
      "Guanfeng Liu",
      "Lei Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.03895"
  },
  {
    "id": "arXiv:2208.03934",
    "title": "Inflating 2D Convolution Weights for Efficient Generation of 3D Medical  Images",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Yanbin Liu",
      "Girish Dwivedi",
      "Farid Boussaid",
      "Frank Sanfilippo",
      "Makoto Yamada",
      "Mohammed Bennamoun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.03934"
  },
  {
    "id": "arXiv:2208.04977",
    "title": "A Bivariate Invariance Principle",
    "abstract": "Comments: Accepted for presentation at ITW 2022",
    "descriptor": "\nComments: Accepted for presentation at ITW 2022\n",
    "authors": [
      "Alexander Mariona",
      "Homa Esfahanizadeh",
      "Rafael G. L. D'Oliveira",
      "Muriel M\u00e9dard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.04977"
  },
  {
    "id": "arXiv:2208.05045",
    "title": "Adaptive Resources Allocation CUSUM for Binomial Count Data Monitoring  with Application to COVID-19 Hotspot Detection",
    "abstract": "Comments: Accepted in Journal of Applied Statistics",
    "descriptor": "\nComments: Accepted in Journal of Applied Statistics\n",
    "authors": [
      "Jiuyun Hu",
      "Yajun Mei",
      "Sarah Holte",
      "Hao Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2208.05045"
  },
  {
    "id": "arXiv:2208.05225",
    "title": "How Effective is Byte Pair Encoding for Out-Of-Vocabulary Words in  Neural Machine Translation?",
    "abstract": "Comments: 14 pages, 6 figures, 1 table, To be published in AMTA 2022 conference",
    "descriptor": "\nComments: 14 pages, 6 figures, 1 table, To be published in AMTA 2022 conference\n",
    "authors": [
      "Ali Araabi",
      "Christof Monz",
      "Vlad Niculae"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.05225"
  },
  {
    "id": "arXiv:2208.05456",
    "title": "Revisiting Piggyback Prototyping: Examining Benefits and Tradeoffs in  Extending Existing Social Computing Systems",
    "abstract": "Comments: To appear at the 25th ACM Conference On Computer-Supported Cooperative Work And Social Computing (CSCW '22)",
    "descriptor": "\nComments: To appear at the 25th ACM Conference On Computer-Supported Cooperative Work And Social Computing (CSCW '22)\n",
    "authors": [
      "Daniel A. Epstein",
      "Fannie Liu",
      "Andr\u00e9s Monroy-Hern\u00e1ndez",
      "Dennis Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.05456"
  },
  {
    "id": "arXiv:2208.05664",
    "title": "Two Classes of Constacyclic Codes with Variable Parameters",
    "abstract": "Two Classes of Constacyclic Codes with Variable Parameters",
    "descriptor": "",
    "authors": [
      "Zhonghua Sun",
      "Cunsheng Ding",
      "Xiaoqiang Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.05664"
  },
  {
    "id": "arXiv:2208.06146",
    "title": "Feature-Based Time-Series Analysis in R using the theft Package",
    "abstract": "Feature-Based Time-Series Analysis in R using the theft Package",
    "descriptor": "",
    "authors": [
      "Trent Henderson",
      "Ben D. Fulcher"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2208.06146"
  },
  {
    "id": "arXiv:2208.06243",
    "title": "Semi-automatic tuning of coupled climate models with multiple intrinsic  timescales: lessons learned from the Lorenz96 model",
    "abstract": "Comments: Submission to JAMES journal (AGU), added link to code",
    "descriptor": "\nComments: Submission to JAMES journal (AGU), added link to code\n",
    "authors": [
      "Redouane Lguensat",
      "Julie Deshayes",
      "Homer Durand",
      "V. Balaji"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.06243"
  },
  {
    "id": "arXiv:2208.06448",
    "title": "RLang: A Declarative Language for Expression Prior Knowledge for  Reinforcement Learning",
    "abstract": "RLang: A Declarative Language for Expression Prior Knowledge for  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Rafael Rodriguez-Sanchez",
      "Benjamin A. Spiegel",
      "Jennifer Wang",
      "Roma Patel",
      "Stefanie Tellex",
      "George Konidaris"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.06448"
  },
  {
    "id": "arXiv:2208.06553",
    "title": "Happiness Maximizing Sets under Group Fairness Constraints (Technical  Report)",
    "abstract": "Comments: technical report under review",
    "descriptor": "\nComments: technical report under review\n",
    "authors": [
      "Jiping Zheng",
      "Yuan Ma",
      "Wei Ma",
      "Yanhao Wang",
      "Xiaoyang Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computers and Society (cs.CY)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.06553"
  },
  {
    "id": "arXiv:2208.06590",
    "title": "Recognition of All Categories of Entities by AI",
    "abstract": "Comments: 7 pages (without references), 3 figures",
    "descriptor": "\nComments: 7 pages (without references), 3 figures\n",
    "authors": [
      "Hiroshi Yamakawa",
      "Yutaka Matsuo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.06590"
  },
  {
    "id": "arXiv:2208.06671",
    "title": "Bidirectional Feature Globalization for Few-shot Semantic Segmentation  of 3D Point Cloud Scenes",
    "abstract": "Comments: Institutional error",
    "descriptor": "\nComments: Institutional error\n",
    "authors": [
      "Yongqiang Mao",
      "Zonghao Guo",
      "Xiaonan Lu",
      "Zhiqiang Yuan",
      "Haowen Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.06671"
  },
  {
    "id": "arXiv:2208.06859",
    "title": "Virgo: Scalable Unsupervised Classification of Cosmological Shock Waves",
    "abstract": "Virgo: Scalable Unsupervised Classification of Cosmological Shock Waves",
    "descriptor": "",
    "authors": [
      "Max Lamparth",
      "Ludwig B\u00f6ss",
      "Ulrich Steinwandel",
      "Klaus Dolag"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2208.06859"
  },
  {
    "id": "arXiv:2208.06974",
    "title": "Learning Semantic Correspondence with Sparse Annotations",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Shuaiyi Huang",
      "Luyu Yang",
      "Bo He",
      "Songyang Zhang",
      "Xuming He",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.06974"
  },
  {
    "id": "arXiv:2208.07208",
    "title": "Virtual Reality Assisted Human Perception in ADAS Development: a Munich  3D Model Study",
    "abstract": "Virtual Reality Assisted Human Perception in ADAS Development: a Munich  3D Model Study",
    "descriptor": "",
    "authors": [
      "Felix Bognar",
      "Oster Markus",
      "Herman Van der Auweraer",
      "Tong Duy Son"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.07208"
  },
  {
    "id": "arXiv:2208.07295",
    "title": "Antipodal two-weight rank metric codes",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Rakhi Pratihar",
      "Tovohery Hajatiana Randrianarisoa"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.07295"
  },
  {
    "id": "arXiv:2208.07463",
    "title": "Conv-Adapter: Exploring Parameter Efficient Transfer Learning for  ConvNets",
    "abstract": "Comments: wrong version",
    "descriptor": "\nComments: wrong version\n",
    "authors": [
      "Hao Chen",
      "Ran Tao",
      "Han Zhang",
      "Yidong Wang",
      "Wei Ye",
      "Jindong Wang",
      "Guosheng Hu",
      "Marios Savvides"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.07463"
  },
  {
    "id": "arXiv:2208.07522",
    "title": "Reliable Decision from Multiple Subtasks through Threshold Optimization:  Content Moderation in the Wild",
    "abstract": "Reliable Decision from Multiple Subtasks through Threshold Optimization:  Content Moderation in the Wild",
    "descriptor": "",
    "authors": [
      "Donghyun Son",
      "Byounggyu Lew",
      "Kwanghee Choi",
      "Yongsu Baek",
      "Seungwoo Choi",
      "Beomjun Shin",
      "Sungjoo Ha",
      "Buru Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2208.07522"
  },
  {
    "id": "arXiv:2208.07541",
    "title": "Social Interactions for Autonomous Driving: A Review and Perspective",
    "abstract": "Comments: 122 pages, 36 figures",
    "descriptor": "\nComments: 122 pages, 36 figures\n",
    "authors": [
      "Wenshuo Wang",
      "Letian Wang",
      "Chengyuan Zhang",
      "Changliu Liu",
      "Lijun Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.07541"
  },
  {
    "id": "arXiv:2208.07581",
    "title": "A unifying partially-interpretable framework for neural network-based  extreme quantile regression",
    "abstract": "A unifying partially-interpretable framework for neural network-based  extreme quantile regression",
    "descriptor": "",
    "authors": [
      "Jordan Richards",
      "Rapha\u00ebl Huser"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2208.07581"
  },
  {
    "id": "arXiv:2208.07655",
    "title": "A Hybrid Deep Feature-Based Deformable Image Registration Method for  Pathological Images",
    "abstract": "Comments: 23 pages, 12 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 23 pages, 12 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Chulong Zhang",
      "Yuming Jiang",
      "Na Li",
      "Zhicheng Zhang",
      "Md Tauhidul Islam",
      "Jingjing Dai",
      "Lin Liu",
      "Wenfeng He",
      "Wenjian Qin",
      "Jing Xiong",
      "Yaoqin Xie",
      "Xiaokun Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.07655"
  },
  {
    "id": "arXiv:2208.07698",
    "title": "Score-Based Diffusion meets Annealed Importance Sampling",
    "abstract": "Comments: under review",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Arnaud Doucet",
      "Will Grathwohl",
      "Alexander G. D. G. Matthews",
      "Heiko Strathmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.07698"
  },
  {
    "id": "arXiv:2208.07711",
    "title": "Towards Local Underexposed Photo Enhancement",
    "abstract": "Towards Local Underexposed Photo Enhancement",
    "descriptor": "",
    "authors": [
      "Yizhan Huang",
      "Xiaogang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07711"
  },
  {
    "id": "arXiv:2208.07728",
    "title": "Simple deterministic O(n log n) algorithm finding a solution of  Erd\u0151s-Ginzburg-Ziv theorem",
    "abstract": "Simple deterministic O(n log n) algorithm finding a solution of  Erd\u0151s-Ginzburg-Ziv theorem",
    "descriptor": "",
    "authors": [
      "Seokhwan Choi",
      "Hanpil Kang",
      "Dongjae Lim"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2208.07728"
  },
  {
    "id": "arXiv:2208.07833",
    "title": "What Your Firmware Tells You Is Not How You Should Emulate It: A  Specification-Guided Approach for Firmware Emulation",
    "abstract": "Comments: Wei Zhou and Lan Zhang contributed equally to this work",
    "descriptor": "\nComments: Wei Zhou and Lan Zhang contributed equally to this work\n",
    "authors": [
      "Wei Zhou",
      "Lan Zhang",
      "Le Guan",
      "Peng Liu",
      "Yuqing Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.07833"
  },
  {
    "id": "arXiv:2208.07864",
    "title": "BERTifying Sinhala -- A Comprehensive Analysis of Pre-trained Language  Models for Sinhala Text Classification",
    "abstract": "BERTifying Sinhala -- A Comprehensive Analysis of Pre-trained Language  Models for Sinhala Text Classification",
    "descriptor": "",
    "authors": [
      "Vinura Dhananjaya",
      "Piyumal Demotte",
      "Surangika Ranathunga",
      "Sanath Jayasena"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.07864"
  }
]
[
  {
    "id": "arXiv:2112.00004",
    "title": "cliquematch: Finding correspondence via cliques in large graphs",
    "abstract": "The maximum clique problem finds applications in computer vision,\nbioinformatics, and network analysis, many of which involve the construction of\ncorrespondence graphs to find similarities between two given objects.\ncliquematch is a Python package designed for this purpose: it provides a simple\nframework to construct correspondence graphs, and implements an algorithm to\nfind and enumerate maximum cliques in C++, that can process graphs of a few\nmillion edges on consumer hardware, with comparable performance to publicly\navailable methods.",
    "descriptor": "\nComments: 11 pages, 3 figures, 1 table; Code available at this https URL\n",
    "authors": [
      "Gautham Venkatasubramanian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2112.00004"
  },
  {
    "id": "arXiv:2112.00006",
    "title": "Towards algorithm-free physical equilibrium model of computing",
    "abstract": "Our computers today, from sophisticated servers to small smartphones, operate\nbased on the same computing model, which requires running a sequence of\ndiscrete instructions, specified as an algorithm. This sequential computing\nparadigm has not yet led to a fast algorithm for an NP-complete problem despite\nnumerous attempts over the past half a century. Unfortunately, even after the\nintroduction of quantum mechanics to the world of computing, we still followed\na similar sequential paradigm, which has not yet helped us obtain such an\nalgorithm either. Here a completely different model of computing is proposed to\nreplace the sequential paradigm of algorithms with inherent parallelism of\nphysical processes. Using the proposed model, instead of writing algorithms to\nsolve NP-complete problems, we construct physical systems whose equilibrium\nstates correspond to the desired solutions and let them evolve to search for\nthe solutions. The main requirements of the model are identified and quantum\ncircuits are proposed for its potential implementation.",
    "descriptor": "",
    "authors": [
      "Seyed Mousavi"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00006"
  },
  {
    "id": "arXiv:2112.00007",
    "title": "Sound-Guided Semantic Image Manipulation",
    "abstract": "The recent success of the generative model shows that leveraging the\nmulti-modal embedding space can manipulate an image using text information.\nHowever, manipulating an image with other sources rather than text, such as\nsound, is not easy due to the dynamic characteristics of the sources.\nEspecially, sound can convey vivid emotions and dynamic expressions of the real\nworld. Here, we propose a framework that directly encodes sound into the\nmulti-modal (image-text) embedding space and manipulates an image from the\nspace. Our audio encoder is trained to produce a latent representation from an\naudio input, which is forced to be aligned with image and text representations\nin the multi-modal embedding space. We use a direct latent optimization method\nbased on aligned embeddings for sound-guided image manipulation. We also show\nthat our method can mix text and audio modalities, which enrich the variety of\nthe image modification. We verify the effectiveness of our sound-guided image\nmanipulation quantitatively and qualitatively. We also show that our method can\nmix different modalities, i.e., text and audio, which enrich the variety of the\nimage modification. The experiments on zero-shot audio classification and\nsemantic-level image classification show that our proposed model outperforms\nother text and sound-guided state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Seung Hyun Lee",
      "Wonseok Roh",
      "Wonmin Byeon",
      "Sang Ho Yoon",
      "Chan Young Kim",
      "Jinkyu Kim",
      "Sangpil Kim"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.00007"
  },
  {
    "id": "arXiv:2112.00011",
    "title": "Predicting Poverty Level from Satellite Imagery using Deep Neural  Networks",
    "abstract": "Determining the poverty levels of various regions throughout the world is\ncrucial in identifying interventions for poverty reduction initiatives and\ndirecting resources fairly. However, reliable data on global economic\nlivelihoods is hard to come by, especially for areas in the developing world,\nhampering efforts to both deploy services and monitor/evaluate progress. This\nis largely due to the fact that this data is obtained from traditional\ndoor-to-door surveys, which are time consuming and expensive. Overhead\nsatellite imagery contain characteristics that make it possible to estimate the\nregion's poverty level. In this work, I develop deep learning computer vision\nmethods that can predict a region's poverty level from an overhead satellite\nimage. I experiment with both daytime and nighttime imagery. Furthermore,\nbecause data limitations are often the barrier to entry in poverty prediction\nfrom satellite imagery, I explore the impact that data quantity and data\naugmentation have on the representational power and overall accuracy of the\nnetworks. Lastly, to evaluate the robustness of the networks, I evaluate them\non data from continents that were absent in the development set.",
    "descriptor": "\nComments: 14 pages, 5 Figures\n",
    "authors": [
      "Varun Chitturi",
      "Zaid Nabulsi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.00011"
  },
  {
    "id": "arXiv:2112.00029",
    "title": "Pixelated Butterfly: Simple and Efficient Sparse training for Neural  Network Models",
    "abstract": "Overparameterized neural networks generalize well but are expensive to train.\nIdeally, one would like to reduce their computational cost while retaining\ntheir generalization benefits. Sparse model training is a simple and promising\napproach to achieve this, but there remain challenges as existing methods\nstruggle with accuracy loss, slow training runtime, or difficulty in\nsparsifying all model components. The core problem is that searching for a\nsparsity mask over a discrete set of sparse matrices is difficult and\nexpensive. To address this, our main insight is to optimize over a continuous\nsuperset of sparse matrices with a fixed structure known as products of\nbutterfly matrices. As butterfly matrices are not hardware efficient, we\npropose simple variants of butterfly (block and flat) to take advantage of\nmodern hardware. Our method (Pixelated Butterfly) uses a simple fixed sparsity\npattern based on flat block butterfly and low-rank matrices to sparsify most\nnetwork layers (e.g., attention, MLP). We empirically validate that Pixelated\nButterfly is 3x faster than butterfly and speeds up training to achieve\nfavorable accuracy--efficiency tradeoffs. On the ImageNet classification and\nWikiText-103 language modeling tasks, our sparse models train up to 2.5x faster\nthan the dense MLP-Mixer, Vision Transformer, and GPT-2 medium with no drop in\naccuracy.",
    "descriptor": "",
    "authors": [
      "Beidi Chen",
      "Tri Dao",
      "Kaizhao Liang",
      "Jiaming Yang",
      "Zhao Song",
      "Atri Rudra",
      "Christopher Re"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00029"
  },
  {
    "id": "arXiv:2112.00038",
    "title": "Robust and Provably Monotonic Networks",
    "abstract": "The Lipschitz constant of the map between the input and output space\nrepresented by a neural network is a natural metric for assessing the\nrobustness of the model. We present a new method to constrain the Lipschitz\nconstant of dense deep learning models that can also be generalized to other\narchitectures. The method relies on a simple weight normalization scheme during\ntraining that ensures the Lipschitz constant of every layer is below an upper\nlimit specified by the analyst. A simple residual connection can then be used\nto make the model monotonic in any subset of its inputs, which is useful in\nscenarios where domain knowledge dictates such dependence. Examples can be\nfound in algorithmic fairness requirements or, as presented here, in the\nclassification of the decays of subatomic particles produced at the CERN Large\nHadron Collider. Our normalization is minimally constraining and allows the\nunderlying architecture to maintain higher expressiveness compared to other\ntechniques which aim to either control the Lipschitz constant of the model or\nensure its monotonicity. We show how the algorithm was used to train a\npowerful, robust, and interpretable discriminator for heavy-flavor decays in\nthe LHCb realtime data-processing system.",
    "descriptor": "\nComments: 7 pages, 3 figures, accepted to Machine Learning and the Physical Sciences Workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS) December 13, 2021\n",
    "authors": [
      "Ouail Kitouni",
      "Niklas Nolte",
      "Mike Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2112.00038"
  },
  {
    "id": "arXiv:2112.00050",
    "title": "Pattern-Aware Data Augmentation for LiDAR 3D Object Detection",
    "abstract": "Autonomous driving datasets are often skewed and in particular, lack training\ndata for objects at farther distances from the ego vehicle. The imbalance of\ndata causes a performance degradation as the distance of the detected objects\nincreases. In this paper, we propose pattern-aware ground truth sampling, a\ndata augmentation technique that downsamples an object's point cloud based on\nthe LiDAR's characteristics. Specifically, we mimic the natural diverging point\npattern variation that occurs for objects at depth to simulate samples at\nfarther distances. Thus, the network has more diverse training examples and can\ngeneralize to detecting farther objects more effectively. We evaluate against\nexisting data augmentation techniques that use point removal or perturbation\nmethods and find that our method outperforms all of them. Additionally, we\npropose using equal element AP bins to evaluate the performance of 3D object\ndetectors across distance. We improve the performance of PV-RCNN on the car\nclass by more than 0.7 percent on the KITTI validation split at distances\ngreater than 25 m.",
    "descriptor": "\nComments: Published paper in the IEEE Intelligent Transportation Systems Conference - ITSC 2021\n",
    "authors": [
      "Jordan S.K. Hu",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00050"
  },
  {
    "id": "arXiv:2112.00053",
    "title": "Task Assignment in Distributed Systems based on PSO Approach",
    "abstract": "In a distributed system, Task Assignment Problem (TAP) is a key factor for\nobtaining efficiency. TAP illustrates the appropriate allocation of tasks to\nthe processor of each computer. In this problem, the proposed methods up to now\ntry to minimize Makespan and maximizing CPU utilization. Since this problem is\nNP-complete, many genetic algorithms have been proposed to search optimal\nsolutions from the entire solution space. Disregarding the techniques which can\nreduce the complexity of optimization, the existing approaches scan the entire\nsolution space. On the other hand, this approach is time-consuming in\nscheduling which is considered a shortcoming. Therefore, in this paper, a\nhybrid genetic algorithm has been proposed to overcome this shortcoming.\nParticle Swarm Optimization (PSO) has been applied as local search in the\nproposed genetic algorithm in this paper. The results obtained from simulation\ncan prove that, in terms of CPU utilization and Makespan, the proposed approach\noutperforms the GA-based approach.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Mostafa Haghi Kashani"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.00053"
  },
  {
    "id": "arXiv:2112.00054",
    "title": "Task2Sim : Towards Effective Pre-training and Transfer from Synthetic  Data",
    "abstract": "Pre-training models on Imagenet or other massive datasets of real images has\nled to major advances in computer vision, albeit accompanied with shortcomings\nrelated to curation cost, privacy, usage rights, and ethical issues. In this\npaper, for the first time, we study the transferability of pre-trained models\nbased on synthetic data generated by graphics simulators to downstream tasks\nfrom very different domains. In using such synthetic data for pre-training, we\nfind that downstream performance on different tasks are favored by different\nconfigurations of simulation parameters (e.g. lighting, object pose,\nbackgrounds, etc.), and that there is no one-size-fits-all solution. It is thus\nbetter to tailor synthetic pre-training data to a specific downstream task, for\nbest performance. We introduce Task2Sim, a unified model mapping downstream\ntask representations to optimal simulation parameters to generate synthetic\npre-training data for them. Task2Sim learns this mapping by training to find\nthe set of best parameters on a set of \"seen\" tasks. Once trained, it can then\nbe used to predict best simulation parameters for novel \"unseen\" tasks in one\nshot, without requiring additional training. Given a budget in number of images\nper class, our extensive experiments with 20 diverse downstream tasks show\nTask2Sim's task-adaptive pre-training data results in significantly better\ndownstream performance than non-adaptively choosing simulation parameters on\nboth seen and unseen tasks. It is even competitive with pre-training on real\nimages from Imagenet.",
    "descriptor": "\nComments: Pre-print\n",
    "authors": [
      "Samarth Mishra",
      "Rameswar Panda",
      "Cheng Perng Phoo",
      "Chun-Fu Chen",
      "Leonid Karlinsky",
      "Kate Saenko",
      "Venkatesh Saligrama",
      "Rogerio S. Feris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00054"
  },
  {
    "id": "arXiv:2112.00057",
    "title": "Successive Syndrome-Check Decoding of Polar Codes",
    "abstract": "A two-part successive syndrome-check decoding of polar codes is proposed with\nthe first part successively refining the received codeword and the second part\nchecking its syndrome. A new formulation of the successive-cancellation (SC)\ndecoding algorithm is presented that allows for successively refining the\nreceived codeword by comparing the log-likelihood ratio value of a frozen bit\nwith its predefined value. The syndrome of the refined received codeword is\nthen checked for possible errors. In case there are no errors, the decoding\nprocess is terminated. Otherwise, the decoder continues to refine the received\ncodeword. The proposed method is extended to the case of SC list (SCL) decoding\nby terminating the decoding process when the syndrome of the best candidate in\nthe list indicates no errors. Simulation results show that the proposed method\nreduces the time-complexity of SC and SCL decoders and their fast variants,\nespecially at high signal-to-noise ratios.",
    "descriptor": "\nComments: 2021 Asilomar Conference on Signals, Systems, and Computers\n",
    "authors": [
      "Seyyed Ali Hashemi",
      "Marco Mondelli",
      "John Cioffi",
      "Andrea Goldsmith"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.00057"
  },
  {
    "id": "arXiv:2112.00059",
    "title": "Evaluating Gradient Inversion Attacks and Defenses in Federated Learning",
    "abstract": "Gradient inversion attack (or input recovery from gradient) is an emerging\nthreat to the security and privacy preservation of Federated learning, whereby\nmalicious eavesdroppers or participants in the protocol can recover (partially)\nthe clients' private data. This paper evaluates existing attacks and defenses.\nWe find that some attacks make strong assumptions about the setup. Relaxing\nsuch assumptions can substantially weaken these attacks. We then evaluate the\nbenefits of three proposed defense mechanisms against gradient inversion\nattacks. We show the trade-offs of privacy leakage and data utility of these\ndefense methods, and find that combining them in an appropriate manner makes\nthe attack less effective, even under the original strong assumptions. We also\nestimate the computation cost of end-to-end recovery of a single image under\neach evaluated defense. Our findings suggest that the state-of-the-art attacks\ncan currently be defended against with minor data utility loss, as summarized\nin a list of potential strategies. Our code is available at:\nhttps://github.com/Princeton-SysML/GradAttack.",
    "descriptor": "",
    "authors": [
      "Yangsibo Huang",
      "Samyak Gupta",
      "Zhao Song",
      "Kai Li",
      "Sanjeev Arora"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00059"
  },
  {
    "id": "arXiv:2112.00061",
    "title": "Open-Domain, Content-based, Multi-modal Fact-checking of Out-of-Context  Images via Online Resources",
    "abstract": "Misinformation is now a major problem due to its potential high risks to our\ncore democratic and societal values and orders. Out-of-context misinformation\nis one of the easiest and effective ways used by adversaries to spread viral\nfalse stories. In this threat, a real image is re-purposed to support other\nnarratives by misrepresenting its context and/or elements. The internet is\nbeing used as the go-to way to verify information using different sources and\nmodalities. Our goal is an inspectable method that automates this\ntime-consuming and reasoning-intensive process by fact-checking the\nimage-caption pairing using Web evidence. To integrate evidence and cues from\nboth modalities, we introduce the concept of 'multi-modal cycle-consistency\ncheck'; starting from the image/caption, we gather textual/visual evidence,\nwhich will be compared against the other paired caption/image, respectively.\nMoreover, we propose a novel architecture, Consistency-Checking Network (CCN),\nthat mimics the layered human reasoning across the same and different\nmodalities: the caption vs. textual evidence, the image vs. visual evidence,\nand the image vs. caption. Our work offers the first step and benchmark for\nopen-domain, content-based, multi-modal fact-checking, and significantly\noutperforms previous baselines that did not leverage external evidence.",
    "descriptor": "",
    "authors": [
      "Sahar Abdelnabi",
      "Rakibul Hasan",
      "Mario Fritz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00061"
  },
  {
    "id": "arXiv:2112.00064",
    "title": "Acute Tours in the Plane",
    "abstract": "We confirm the following conjecture of Fekete and Woeginger from 1997: for\nany sufficiently large even number $n$, every set of $n$ points in the plane\ncan be connected by a spanning tour (Hamiltonian cycle) consisting of\nstraight-line edges such that the angle between any two consecutive edges is at\nmost $\\pi/2$. Our proof is constructive and suggests a simple $O(n\\log n)$-time\nalgorithm for finding such a tour. The previous best-known upper bound on the\nangle is $2\\pi/3$, and it is due to Dumitrescu, Pach and T\\'oth (2009).",
    "descriptor": "",
    "authors": [
      "Ahmad Biniaz"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.00064"
  },
  {
    "id": "arXiv:2112.00065",
    "title": "Boosting EfficientNets Ensemble Performance via Pseudo-Labels and  Synthetic Images by pix2pixHD for Infection and Ischaemia Classification in  Diabetic Foot Ulcers",
    "abstract": "Diabetic foot ulcers are a common manifestation of lesions on the diabetic\nfoot, a syndrome acquired as a long-term complication of diabetes mellitus.\nAccompanying neuropathy and vascular damage promote acquisition of pressure\ninjuries and tissue death due to ischaemia. Affected areas are prone to\ninfections, hindering the healing progress. The research at hand investigates\nan approach on classification of infection and ischaemia, conducted as part of\nthe Diabetic Foot Ulcer Challenge (DFUC) 2021. Different models of the\nEfficientNet family are utilized in ensembles. An extension strategy for the\ntraining data is applied, involving pseudo-labeling for unlabeled images, and\nextensive generation of synthetic images via pix2pixHD to cope with severe\nclass imbalances. The resulting extended training dataset features $8.68$ times\nthe size of the baseline and shows a real to synthetic image ratio of $1:3$.\nPerformances of models and ensembles trained on the baseline and extended\ntraining dataset are compared. Synthetic images featured a broad qualitative\nvariety. Results show that models trained on the extended training dataset as\nwell as their ensemble benefit from the large extension. F1-Scores for rare\nclasses receive outstanding boosts, while those for common classes are either\nnot harmed or boosted moderately. A critical discussion concretizes benefits\nand identifies limitations, suggesting improvements. The work concludes that\nclassification performance of individual models as well as that of ensembles\ncan be boosted utilizing synthetic images. Especially performance for rare\nclasses benefits notably.",
    "descriptor": "\nComments: Accepted for Workshop Proceedings of the Diabetic Foot Ulcers Challenge (DFUC) as part of the 2021 24th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)\n",
    "authors": [
      "Louise Bloch",
      "Raphael Br\u00fcngel",
      "Christoph M. Friedrich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00065"
  },
  {
    "id": "arXiv:2112.00068",
    "title": "Scaling Shared-Memory Data Structures as Distributed Global-View Data  Structures in the Partitioned Global Address Space model",
    "abstract": "The Partitioned Global Address Space (PGAS), a memory model in which the\nglobal address space is explicitly partitioned across compute nodes in a\ncluster, strives to bridge the gap between shared-memory and distributed-memory\nprogramming. To further bridge this gap, there has been an adoption of\nglobal-view distributed data structures, such as 'global arrays' or\n'distributed arrays'. This work demonstrates how shared-memory data structures\ncan be modified to scale in distributed memory. Presented in this work is the\nDistributed Interlocked Hash Table (DIHT), a global-view distributed map data\nstructure inpired by the Interlocked Hash Table (IHT). At 64 nodes with 44\ncores per node, DIHT provides upto 110x the performance of the Chapel\nstandard-library HashedDist.",
    "descriptor": "",
    "authors": [
      "Garvit Dewan",
      "Louis Jenkins"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.00068"
  },
  {
    "id": "arXiv:2112.00071",
    "title": "What to Learn, and How: Toward Effective Learning from Rationales",
    "abstract": "Learning from rationales seeks to augment model training with human-provided\nrationales (i.e., a subset of input tokens) that justify those labels. While\nintuitive, this idea has proven elusive in practice. We make two observations\nabout human rationales via empirical analyses: 1) maximizing predicted\nrationale accuracy is not necessarily the optimal objective for improving model\nperformance; 2) human rationales vary in whether they provide sufficient\ninformation for the model to exploit for prediction, and we can use this\nvariance to assess a dataset's potential improvement from learning from\nrationales. Building on these insights, we propose loss functions and learning\nstrategies, and evaluate their effectiveness on three datasets with human\nrationales. Our results demonstrate consistent improvements over baselines in\nboth label performance and rationale performance, including a 3% accuracy\nimprovement on MultiRC. Our work highlights the importance of understanding\nproperties of human explanations and exploiting them accordingly in model\ntraining.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Samuel Carton",
      "Surya Kanoria",
      "Chenhao Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00071"
  },
  {
    "id": "arXiv:2112.00075",
    "title": "A Multi-purposed Unsupervised Framework for Comparing Embeddings of  Undirected and Directed Graphs",
    "abstract": "Graph embedding is a transformation of nodes of a network into a set of\nvectors. A good embedding should capture the underlying graph topology and\nstructure, node-to-node relationship, and other relevant information about the\ngraph, its subgraphs, and nodes themselves. If these objectives are achieved,\nan embedding is a meaningful, understandable, and often compressed\nrepresentation of a network. Unfortunately, selecting the best embedding is a\nchallenging task and very often requires domain experts. In this paper, we\nextend the framework for evaluating graph embeddings that was recently\nintroduced by the authors. Now, the framework assigns two scores, local and\nglobal, to each embedding that measure the quality of an evaluated embedding\nfor tasks that require good representation of local and, respectively, global\nproperties of the network. The best embedding, if needed, can be selected in an\nunsupervised way, or the framework can identify a few embeddings that are worth\nfurther investigation. The framework is flexible, scalable, and can deal with\nundirected/directed, weighted/unweighted graphs.",
    "descriptor": "\nComments: 32 pages, 15 figures\n",
    "authors": [
      "Bogumi\u0142 Kami\u0144ski",
      "\u0141ukasz Krai\u0144ski",
      "Pawe\u0142 Pra\u0142at",
      "Fran\u00e7ois Th\u00e9berge"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00075"
  },
  {
    "id": "arXiv:2112.00076",
    "title": "Using Conversational Artificial Intelligence to Support Children's  Search in the Classroom",
    "abstract": "We present pathways of investigation regarding conversational user interfaces\n(CUIs) for children in the classroom. We highlight anticipated challenges to be\naddressed in order to advance knowledge on CUIs for children. Further, we\ndiscuss preliminary ideas on strategies for evaluation.",
    "descriptor": "\nComments: Presented at CUI@CSCW 2021 -- this https URL\n",
    "authors": [
      "Garrett Allen",
      "Jie Yang",
      "Maria Soledad Pera",
      "Ujwal Gadiraju"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.00076"
  },
  {
    "id": "arXiv:2112.00086",
    "title": "Dyna-bAbI: unlocking bAbI's potential with dynamic synthetic  benchmarking",
    "abstract": "While neural language models often perform surprisingly well on natural\nlanguage understanding (NLU) tasks, their strengths and limitations remain\npoorly understood. Controlled synthetic tasks are thus an increasingly\nimportant resource for diagnosing model behavior. In this work we focus on\nstory understanding, a core competency for NLU systems. However, the main\nsynthetic resource for story understanding, the bAbI benchmark, lacks such a\nsystematic mechanism for controllable task generation. We develop Dyna-bAbI, a\ndynamic framework providing fine-grained control over task generation in bAbI.\nWe demonstrate our ideas by constructing three new tasks requiring\ncompositional generalization, an important evaluation setting absent from the\noriginal benchmark. We tested both special-purpose models developed for bAbI as\nwell as state-of-the-art pre-trained methods, and found that while both\napproaches solve the original tasks (>99% accuracy), neither approach succeeded\nin the compositional generalization setting, indicating the limitations of the\noriginal training data. We explored ways to augment the original data, and\nfound that though diversifying training data was far more useful than simply\nincreasing dataset size, it was still insufficient for driving robust\ncompositional generalization (with <70% accuracy for complex compositions). Our\nresults underscore the importance of highly controllable task generators for\ncreating robust NLU systems through a virtuous cycle of model and data\ndevelopment.",
    "descriptor": "\nComments: Code and data will be made available at project page: this https URL\n",
    "authors": [
      "Ronen Tamari",
      "Kyle Richardson",
      "Aviad Sar-Shalom",
      "Noam Kahlon",
      "Nelson Liu",
      "Reut Tsarfaty",
      "Dafna Shahaf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00086"
  },
  {
    "id": "arXiv:2112.00087",
    "title": "Coupling and Simulation of Fluid-Structure Interaction Problems for  Automotive Sun-roof on Graphics Processing Unit",
    "abstract": "In this paper, the authors propose an analysis of the frequency response\nfunction in a car compartment, subject to some fluctuating pressure\ndistribution along the open cavity of the sun-roof at the top of a car.\nCoupling of a computational fluid dynamics and of a computational acoustics\ncode is considered to simulate the acoustic fluid-structure interaction\nproblem. Iterative Krylov methods and domain decomposition methods, tuned on\nGraphic Processing Unit (GPU), are considered to solve the acoustic problem\nwith complex number arithmetics with double precision. Numerical simulations\nillustrate the efficiency, robustness and accuracy of the proposed approaches.",
    "descriptor": "",
    "authors": [
      "Liang S. Lai",
      "Choi-Hong Lai",
      "Abal-Kassim Cheik Ahamed",
      "Frederic Magoules"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.00087"
  },
  {
    "id": "arXiv:2112.00089",
    "title": "Minimal order $H(\\operatorname{div})$-conforming velocity-vorticity  approximations for incompressible fluids",
    "abstract": "We introduce a novel minimal order hybrid Discontinuous Galerkin (HDG) and a\nnovel mass conserving mixed stress (MCS) method for the approximation of\nincompressible flows. For this we employ the $H(\\operatorname{div})$-conforming\nlinear Brezzi-Douglas-Marini space and the lowest order Raviart-Thomas space\nfor the approximation of the velocity and the vorticity, respectively. Our\nmethods are based on the physically correct diffusive flux $-\\nu\n\\varepsilon(u)$ and provide exactly divergence-free discrete velocity\nsolutions, optimal (pressure robust) error estimates and a minimal number of\ncoupling degrees of freedom. For the stability analysis we introduce a new\nKorn-like inequality for vector-valued element-wise $H^1$ and normal continuous\nfunctions. Numerical examples conclude the work where the theoretical findings\nare validated and the novel methods are compared in terms of condition numbers\nwith respect to discrete stability parameters.",
    "descriptor": "",
    "authors": [
      "Jay Gopalakrishnan",
      "Lukas Kogler",
      "Philip L. Lederer",
      "Joachim Sch\u00f6berl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.00089"
  },
  {
    "id": "arXiv:2112.00093",
    "title": "\"Vironment\": An Art of Wearable Social Distancing",
    "abstract": "\"Vironment\" is a series of art pieces, social commentary, technology, etc.,\nbased on wearable health technologies of social-distancing, culminating in a\nsocial-distancing device that takes the familiar world of security and\nsurveillance technologies that surround us and re-situates it on the body of\nthe wearer (technologies that become part of us). This piece also introduces a\nconceptual framework for (1) the sensing of the self together with (2) sensing\nof others and (3) sensing of the environment around us.",
    "descriptor": "",
    "authors": [
      "Cayden Pierce",
      "Steve Mann"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.00093"
  },
  {
    "id": "arXiv:2112.00094",
    "title": "Leveraging Intrinsic Gradient Information for Machine Learning Model  Training",
    "abstract": "Designing models that produce accurate predictions is the fundamental\nobjective of machine learning. This work presents methods demonstrating that\nwhen the derivatives of target variables with respect to inputs can be\nextracted from processes of interest, they can be leveraged to improve the\naccuracy of differentiable machine learning models. Four key ideas are\nexplored: (1) Improving the predictive accuracy of linear regression models and\nfeed-forward neural networks (NNs); (2) Using the difference between the\nperformance of feedforward NNs trained with and without gradient information to\ntune NN complexity (in the form of hidden node number); (3) Using gradient\ninformation to regularise linear regression; and (4) Using gradient information\nto improve generative image models. Across this variety of applications,\ngradient information is shown to enhance each predictive model, demonstrating\nits value for a variety of applications.",
    "descriptor": "",
    "authors": [
      "Chris McDonagh",
      "Xi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00094"
  },
  {
    "id": "arXiv:2112.00098",
    "title": "Connected Components for Infinite Graph Streams: Theory and Practice",
    "abstract": "Motivated by the properties of unending real-world cybersecurity streams, we\npresent a new graph streaming model: XStream. We maintain a streaming graph and\nits connected components at single-edge granularity. In cybersecurity graph\napplications, input streams typically consist of edge insertions; individual\ndeletions are not explicit. Analysts maintain as much history as possible and\nwill trigger customized bulk deletions when necessary Despite a variety of\ndynamic graph processing systems and some canonical literature on theoretical\nsliding-window graph streaming, XStream is the first model explicitly designed\nto accommodate this usage model. Users can provide Boolean predicates to define\nbulk deletions. Edge arrivals are expected to occur continuously and must\nalways be handled. XStream is implemented via a ring of finite-memory\nprocessors. We give algorithms to maintain connected components on the input\nstream, answer queries about connectivity, and to perform bulk deletion. The\nsystem requires bandwidth for internal messages that is some constant factor\ngreater than the stream arrival rate. We prove a relationship among four\nquantities: the proportion of query downtime allowed, the proportion of edges\nthat survive an aging event, the proportion of duplicated edges, and the\nbandwidth expansion factor. In addition to presenting the theory behind\nXStream, we present computational results for a single-threaded prototype\nimplementation. Stream ingestion rates are bounded by computer architecture. We\ndetermine this bound for XStream inter-process message-passing rates in Intel\nTBB applications on Intel Sky Lake processors: between one and five million\ngraph edges per second. Our single-threaded prototype runs our full protocols\nthrough multiple aging events at between one half and one a million edges per\nsecond, and we give ideas for speeding this up by orders of magnitude.",
    "descriptor": "\nComments: 23 pages, 12 figures\n",
    "authors": [
      "Jonathan W. Berry",
      "Cynthia A Phillips",
      "Alexandra M. Porter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.00098"
  },
  {
    "id": "arXiv:2112.00100",
    "title": "A Mathematical Framework for Evaluation of SOAR Tools with Limited  Survey Data",
    "abstract": "Security operation centers (SOCs) all over the world are tasked with reacting\nto cybersecurity alerts ranging in severity. Security Orchestration,\nAutomation, and Response (SOAR) tools streamline cybersecurity alert responses\nby SOC operators. SOAR tool adoption is expensive both in effort and finances.\nHence, it is crucial to limit adoption to those most worthwhile; yet no\nresearch evaluating or comparing SOAR tools exists. The goal of this work is to\nevaluate several SOAR tools using specific criteria pertaining to their\nusability. SOC operators were asked to first complete a survey about what SOAR\ntool aspects are most important. Operators were then assigned a set of SOAR\ntools for which they viewed demonstration and overview videos, and then\noperators completed a second survey wherein they were tasked with evaluating\neach of the tools on the aspects from the first survey. In addition, operators\nprovided an overall rating to each of their assigned tools, and provided a\nranking of their tools in order of preference. Due to time constraints on SOC\noperators for thorough testing, we provide a systematic method of downselecting\na large pool of SOAR tools to a select few that merit next-step hands-on\nevaluation by SOC operators. Furthermore, the analyses conducted in this survey\nhelp to inform future development of SOAR tools to ensure that the appropriate\nfunctions are available for use in a SOC.",
    "descriptor": "",
    "authors": [
      "Savannah Norem",
      "Ashley E Rice",
      "Samantha Erwin",
      "Robert A Bridges",
      "Sean Oesch",
      "Brian Weber"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.00100"
  },
  {
    "id": "arXiv:2112.00101",
    "title": "Fast Topological Clustering with Wasserstein Distance",
    "abstract": "The topological patterns exhibited by many real-world networks motivate the\ndevelopment of topology-based methods for assessing the similarity of networks.\nHowever, extracting topological structure is difficult, especially for large\nand dense networks whose node degrees range over multiple orders of magnitude.\nIn this paper, we propose a novel and computationally practical topological\nclustering method that clusters complex networks with intricate topology using\nprincipled theory from persistent homology and optimal transport. Such networks\nare aggregated into clusters through a centroid-based clustering strategy based\non both their topological and geometric structure, preserving correspondence\nbetween nodes in different networks. The notions of topological proximity and\ncentroid are characterized using a novel and efficient approach to computation\nof the Wasserstein distance and barycenter for persistence barcodes associated\nwith connected components and cycles. The proposed method is demonstrated to be\neffective using both simulated networks and measured functional brain networks.",
    "descriptor": "",
    "authors": [
      "Tananun Songdechakraiwut",
      "Bryan M. Krause",
      "Matthew I. Banks",
      "Kirill V. Nourski",
      "Barry D. Van Veen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00101"
  },
  {
    "id": "arXiv:2112.00107",
    "title": "LGBTQ Privacy Concerns on Social Media",
    "abstract": "We conducted semi-structured interviews with members of the LGBTQ community\nabout their privacy practices and concerns on social networking sites.\nParticipants used different social media sites for different needs and adapted\nto not being completely out on each site. We would value the opportunity to\ndiscuss the unique privacy and security needs of this population with workshop\nparticipants and learn more about the privacy needs of other marginalized user\ngroups from researchers who have worked in those communities.",
    "descriptor": "\nComments: Workshop at 2018 CHI conference on human factors in computing systems: Exploring Individual Differences in Privacy\n",
    "authors": [
      "Christine Geeng",
      "Alexis Hiniker"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.00107"
  },
  {
    "id": "arXiv:2112.00113",
    "title": "Beyond Flatland: Pre-training with a Strong 3D Inductive Bias",
    "abstract": "Pre-training on large-scale databases consisting of natural images and then\nfine-tuning them to fit the application at hand, or transfer-learning, is a\npopular strategy in computer vision. However, Kataoka et al., 2020 introduced a\ntechnique to eliminate the need for natural images in supervised deep learning\nby proposing a novel synthetic, formula-based method to generate 2D fractals as\ntraining corpus. Using one synthetically generated fractal for each class, they\nachieved transfer learning results comparable to models pre-trained on natural\nimages. In this project, we take inspiration from their work and build on this\nidea -- using 3D procedural object renders. Since the image formation process\nin the natural world is based on its 3D structure, we expect pre-training with\n3D mesh renders to provide an implicit bias leading to better generalization\ncapabilities in a transfer learning setting and that invariances to 3D rotation\nand illumination are easier to be learned based on 3D data. Similar to the\nprevious work, our training corpus will be fully synthetic and derived from\nsimple procedural strategies; we will go beyond classic data augmentation and\nalso vary illumination and pose which are controllable in our setting and study\ntheir effect on transfer learning capabilities in context to prior work. In\naddition, we will compare the 2D fractal and 3D procedural object networks to\nhuman and non-human primate brain data to learn more about the 2D vs. 3D nature\nof biological vision.",
    "descriptor": "\nComments: NeurIPS 2021 pre-registration workshop\n",
    "authors": [
      "Shubhaankar Gupta",
      "Thomas P. O'Connell",
      "Bernhard Egger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00113"
  },
  {
    "id": "arXiv:2112.00114",
    "title": "Show Your Work: Scratchpads for Intermediate Computation with Language  Models",
    "abstract": "Large pre-trained language models perform remarkably well on tasks that can\nbe done \"in one pass\", such as generating realistic text or synthesizing\ncomputer programs. However, they struggle with tasks that require unbounded\nmulti-step computation, such as adding integers or executing programs.\nSurprisingly, we find that these same models are able to perform complex\nmulti-step computations -- even in the few-shot regime -- when asked to perform\nthe operation \"step by step\", showing the results of intermediate computations.\nIn particular, we train transformers to perform multi-step computations by\nasking them to emit intermediate computation steps into a \"scratchpad\". On a\nseries of increasingly complex tasks ranging from long addition to the\nexecution of arbitrary programs, we show that scratchpads dramatically improve\nthe ability of language models to perform multi-step computations.",
    "descriptor": "",
    "authors": [
      "Maxwell Nye",
      "Anders Johan Andreassen",
      "Guy Gur-Ari",
      "Henryk Michalewski",
      "Jacob Austin",
      "David Bieber",
      "David Dohan",
      "Aitor Lewkowycz",
      "Maarten Bosma",
      "David Luan",
      "Charles Sutton",
      "Augustus Odena"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00114"
  },
  {
    "id": "arXiv:2112.00115",
    "title": "Risk-based implementation of COLREGs for autonomous surface vehicles  using deep reinforcement learning",
    "abstract": "Autonomous systems are becoming ubiquitous and gaining momentum within the\nmarine sector. Since the electrification of transport is happening\nsimultaneously, autonomous marine vessels can reduce environmental impact,\nlower costs, and increase efficiency. Although close monitoring is still\nrequired to ensure safety, the ultimate goal is full autonomy. One major\nmilestone is to develop a control system that is versatile enough to handle any\nweather and encounter that is also robust and reliable. Additionally, the\ncontrol system must adhere to the International Regulations for Preventing\nCollisions at Sea (COLREGs) for successful interaction with human sailors.\nSince the COLREGs were written for the human mind to interpret, they are\nwritten in ambiguous prose and therefore not machine-readable or verifiable.\nDue to these challenges and the wide variety of situations to be tackled,\nclassical model-based approaches prove complicated to implement and\ncomputationally heavy. Within machine learning (ML), deep reinforcement\nlearning (DRL) has shown great potential for a wide range of applications. The\nmodel-free and self-learning properties of DRL make it a promising candidate\nfor autonomous vessels. In this work, a subset of the COLREGs is incorporated\ninto a DRL-based path following and obstacle avoidance system using collision\nrisk theory. The resulting autonomous agent dynamically interpolates between\npath following and COLREG-compliant collision avoidance in the training\nscenario, isolated encounter situations, and AIS-based simulations of\nreal-world scenarios.",
    "descriptor": "",
    "authors": [
      "Thomas Nakken Larsen",
      "Amalie Heiberg",
      "Eivind Meyer",
      "Adil Rasheeda",
      "Omer San",
      "Damiano Varagnolo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00115"
  },
  {
    "id": "arXiv:2112.00116",
    "title": "A Review on Parallel Virtual Screening Softwares for High Performance  Computers",
    "abstract": "Drug discovery is the most expensive, time demanding and challenging project\nin biopharmaceutical companies which aims at the identification and\noptimization of lead compounds from large-sized chemical libraries. The lead\ncompounds should have high affinity binding and specificity for a target\nassociated with a disease and in addition they should have favorable\npharmacodynamic and pharmacokinetic properties (grouped as ADMET properties).\nOverall, drug discovery is a multivariable optimization and can be carried out\nin supercomputers using a reliable scoring function which is a measure of\nbinding affinity or inhibition potential of the drug-like compound. The major\nproblem is that the number of compounds in the chemical spaces is huge making\nthe computational drug discovery very demanding. However, it is cheaper and\nless time consuming when compared to experimental high throughput screening. As\nthe problem is to find the most stable (global) minima for numerous\nprotein-ligand complexes (at the order of 10$^6$ to 10$^{12}$), the parallel\nimplementation of in-silico virtual screening can be exploited to make the drug\ndiscovery in affordable time. In this review, we discuss such implementations\nof parallelization algorithms in virtual screening programs. The nature of\ndifferent scoring functions and search algorithms are discussed, together with\na performance analysis of several docking softwares ported on high-performance\ncomputing architectures.",
    "descriptor": "\nComments: Submitted to Pharmaceuticals, MPDI journal\n",
    "authors": [
      "Natarajan Arul Murugan",
      "Artur Podobas",
      "Davide Gadioli",
      "Emanuele Vitali",
      "Gianluca Palermo",
      "Stefano Markidis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.00116"
  },
  {
    "id": "arXiv:2112.00117",
    "title": "CIDAN: Computing in DRAM with\\\\Artificial Neurons",
    "abstract": "Numerous applications such as graph processing, cryptography, databases,\nbioinformatics, etc., involve the repeated evaluation of Boolean functions on\nlarge bit vectors. In-memory architectures which perform processing in memory\n(PIM) are tailored for such applications. This paper describes a different\narchitecture for in-memory computation called CIDAN, that achieves a 3X\nimprovement in performance and a 2X improvement in energy for a representative\nset of algorithms over the state-of-the-art in-memory architectures. CIDAN uses\na new basic processing element called a TLPE, which comprises a threshold logic\ngate (TLG) (a.k.a artificial neuron or perceptron). The implementation of a TLG\nwithin a TLPE is equivalent to a multi-input, edge-triggered flipflop that\ncomputes a subset of threshold functions of its inputs. The specific threshold\nfunction is selected on each cycle by enabling/disabling a subset of the\nweights associated with the threshold function, by using logic signals. In\naddition to the TLG, a TLPE realizes some non-threshold functions by a sequence\nof TLG evaluations. An equivalent CMOS implementation of a TLPE requires a\nsubstantially higher area and power. CIDAN has an array of TLPE(s) that is\nintegrated with a DRAM, to allow fast evaluation of any one of its set of\nfunctions on large bit vectors. Results of running several common in-memory\napplications in graph processing and cryptography are presented.",
    "descriptor": "",
    "authors": [
      "Gian Singh",
      "Ankit Wagle",
      "Sarma Vrudhula",
      "Sunil Khatri"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.00117"
  },
  {
    "id": "arXiv:2112.00124",
    "title": "CryoCiM: Cryogenic Compute-in-Memory based on the Quantum Anomalous Hall  Effect",
    "abstract": "The scaling of the matured CMOS technology is steadily approaching its\nphysical limit, motivating the quest for a suitable alternative. Cryogenic\noperation offers a promising pathway towards continued improvement in computing\nspeed and energy efficiency without aggressive scaling. However, the memory\nwall bottleneck of the traditional von-Neumann architecture persists even at\nlow temperatures. That is where the compute-in-memory (CiM) architectures, that\nembed computing within the memory unit, come into play. Computations within the\nmemory unit help reduce the expensive data transfer between the memory and the\ncomputing units. Therefore, CiM provides extreme energy efficiency that can\nenable lower cooling costs at cryogenic temperatures. In this work, we\ndemonstrate CryoCiM (a cryogenic compute-in-memory framework that can perform\nmemory read and vector bitwise operations for logical NAND, NOR, and XOR\noperations) with a non-volatile cryogenic memory system based on the quantum\nanomalous Hall effect (QAHE). The utilization of a QAHE-based memory system\nleads to better energy efficiency, robustness against process variations, and\nmore scalable CiM architectures. The proposed QAHE-based CiM should enable\nlarge-scale cryogenic systems that demonstrate excellent energy efficiency.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Shamiul Alam",
      "Md Mazharul Islam",
      "Nazmul Amin",
      "Md Shafayat Hossain",
      "Akhilesh Jaiswal",
      "Ahmedullah Aziz"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.00124"
  },
  {
    "id": "arXiv:2112.00126",
    "title": "Martingale product estimators for sensitivity analysis in computational  statistical physics",
    "abstract": "We introduce a new class of estimators for the linear response of steady\nstates of stochastic dynamics. We generalize the likelihood ratio approach and\nformulate the linear response as a product of two martingales, hence the name\n\"martingale product estimators\". We present a systematic derivation of the\nmartingale product estimator, and show how to construct such estimator so its\nbias is consistent with the weak order of the numerical scheme that\napproximates the underlying stochastic differential equation. Motivated by the\nestimation of transport properties in molecular systems, we present a rigorous\nnumerical analysis of the bias and variance for these new estimators in the\ncase of Langevin dynamics. We prove that the variance is uniformly bounded in\ntime and derive a specific form of the estimator for second-order splitting\nschemes for Langevin dynamics. For comparison, we also study the bias and\nvariance of a Green-Kubo estimator, motivated, in part, by its variance growing\nlinearly in time. Presented analysis shows that the new martingale product\nestimators, having uniformly bounded variance in time, offer a competitive\nalternative to the traditional Green-Kubo estimator. We compare on illustrative\nnumerical tests the new estimators with results obtained by the Green-Kubo\nmethod.",
    "descriptor": "\nComments: 34 pages, 4 figures\n",
    "authors": [
      "Petr Plechac",
      "Gabriel Stoltz",
      "Ting Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.00126"
  },
  {
    "id": "arXiv:2112.00131",
    "title": "CovidAlert -- A Wristwatch-based System to Alert Users from Face  Touching",
    "abstract": "Worldwide 2019 million people have been infected and 4.5 million have lost\ntheir lives in the ongoing Covid-19 pandemic. Until vaccines became widely\navailable, precautions and safety measures like wearing masks, physical\ndistancing, avoiding face touching were some of the primary means to curb the\nspread of virus. Face touching is a compulsive human begavior that can not be\nprevented without making a continuous consious effort, even then it is\ninevitable. To address this problem, we have designed a smartwatch-based\nsolution, CovidAlert, that leverages Random Forest algorithm trained on\naccelerometer and gyroscope data from the smartwatch to detects hand transition\nto face and sends a quick haptic alert to the users. CovidALert is highly\nenergy efficient as it employs STA/LTA algorithm as a gatekeeper to curtail the\nusage of Random Forest model on the watch when user is inactive. The overall\naccuracy of our system is 88.4% with low false negatives and false positives.\nWe also demonstrated the system viability by implementing it on a commercial\nFossil Gen 5 smartwatch.",
    "descriptor": "\nComments: 17 pages, 9 figures, PervasiveHealth2021 conference\n",
    "authors": [
      "Mrinmoy Roy",
      "Venkata Devesh Reddy Seethi",
      "Pratool Bharti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.00131"
  },
  {
    "id": "arXiv:2112.00132",
    "title": "Atos: A Task-Parallel GPU Dynamic Scheduling Framework for Dynamic  Irregular Computations",
    "abstract": "We present Atos, a task-parallel GPU dynamic scheduling framework that is\nespecially suited to dynamic irregular applications. Compared to the dominant\nBulk Synchronous Parallel (BSP) frameworks, Atos exposes additional concurrency\nby supporting task-parallel formulations of applications with relaxed\ndependencies, achieving higher GPU utilization, which is particularly\nsignificant for problems with concurrency bottlenecks. Atos also offers\nimplicit task-parallel load balancing in addition to data-parallel load\nbalancing, providing users the flexibility to balance between them to achieve\noptimal performance. Finally, Atos allows users to adapt to different use cases\nby controlling the kernel strategy and task-parallel granularity. We\ndemonstrate that each of these controls is important in practice. We evaluate\nand analyze the performance of Atos vs. BSP on three applications:\nbreadth-first search, PageRank, and graph coloring. Atos implementations\nachieve geomean speedups of 3.44x, 2.1x, and 2.77x and peak speedups of 12.8x,\n3.2x, and 9.08x across three case studies, compared to a state-of-the-art BSP\nGPU implementation. Beyond simply quantifying the speedup, we extensively\nanalyze the reasons behind each speedup. This deeper understanding allows us to\nderive general guidelines for how to select the optimal Atos configuration for\ndifferent applications. Finally, our analysis provides insights for future\ndynamic scheduling framework designs.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Yuxin Chen",
      "Benjamin Brock",
      "Serban Porumbescu",
      "Ayd\u0131n Bulu\u00e7",
      "Katherine Yelick",
      "John D. Owens"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.00132"
  },
  {
    "id": "arXiv:2112.00133",
    "title": "PokeBNN: A Binary Pursuit of Lightweight Accuracy",
    "abstract": "Top-1 ImageNet optimization promotes enormous networks that may be\nimpractical in inference settings. Binary neural networks (BNNs) have the\npotential to significantly lower the compute intensity but existing models\nsuffer from low quality. To overcome this deficiency, we propose PokeConv, a\nbinary convolution block which improves quality of BNNs by techniques such as\nadding multiple residual paths, and tuning the activation function. We apply it\nto ResNet-50 and optimize ResNet's initial convolutional layer which is hard to\nbinarize. We name the resulting network family PokeBNN. These techniques are\nchosen to yield favorable improvements in both top-1 accuracy and the network's\ncost. In order to enable joint optimization of the cost together with accuracy,\nwe define arithmetic computation effort (ACE), a hardware- and energy-inspired\ncost metric for quantized and binarized networks. We also identify a need to\noptimize an under-explored hyper-parameter controlling the binarization\ngradient approximation.\nWe establish a new, strong state-of-the-art (SOTA) on top-1 accuracy together\nwith commonly-used CPU64 cost, ACE cost and network size metrics.\nReActNet-Adam, the previous SOTA in BNNs, achieved a 70.5% top-1 accuracy with\n7.9 ACE. A small variant of PokeBNN achieves 70.5% top-1 with 2.6 ACE, more\nthan 3x reduction in cost; a larger PokeBNN achieves 75.6% top-1 with 7.8 ACE,\nmore than 5% improvement in accuracy without increasing the cost. PokeBNN\nimplementation in JAX/Flax and reproduction instructions are open sourced.",
    "descriptor": "",
    "authors": [
      "Yichi Zhang",
      "Zhiru Zhang",
      "Lukasz Lew"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00133"
  },
  {
    "id": "arXiv:2112.00141",
    "title": "Solving reward-collecting problems with UAVs: a comparison of online  optimization and Q-learning",
    "abstract": "Uncrewed autonomous vehicles (UAVs) have made significant contributions to\nreconnaissance and surveillance missions in past US military campaigns. As the\nprevalence of UAVs increases, there has also been improvements in counter-UAV\ntechnology that makes it difficult for them to successfully obtain valuable\nintelligence within an area of interest. Hence, it has become important that\nmodern UAVs can accomplish their missions while maximizing their chances of\nsurvival. In this work, we specifically study the problem of identifying a\nshort path from a designated start to a goal, while collecting all rewards and\navoiding adversaries that move randomly on the grid. We also provide a possible\napplication of the framework in a military setting, that of autonomous casualty\nevacuation. We present a comparison of three methods to solve this problem:\nnamely we implement a Deep Q-Learning model, an $\\varepsilon$-greedy tabular\nQ-Learning model, and an online optimization framework. Our computational\nexperiments, designed using simple grid-world environments with random\nadversaries showcase how these approaches work and compare them in terms of\nperformance, accuracy, and computational time.",
    "descriptor": "",
    "authors": [
      "Yixuan Liu",
      "Chrysafis Vogiatzis",
      "Ruriko Yoshida",
      "Erich Morman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.00141"
  },
  {
    "id": "arXiv:2112.00142",
    "title": "ZCSD: a Computational Storage Device over Zoned Namespaces (ZNS) SSDs",
    "abstract": "The Big Data trend is putting strain on modern storage systems, which have to\nsupport high-performance I/O accesses for the large quantities of data. With\nthe prevalent Von Neumann computing architecture, this data is constantly moved\nback and forth between the computing (i.e., CPU) and storage entities (DRAM,\nNon-Volatile Memory NVM storage). Hence, as the data volume grows, this\nconstant data movement between the CPU and storage devices has emerged as a key\nperformance bottleneck. To improve the situation, researchers have advocated to\nleverage computational storage devices (CSDs), which offer a programmable\ninterface to run user-defined data processing operations close to the storage\nwithout excessive data movement, thus offering performance improvements.\nHowever, despite its potential, building CSD-aware applications remains a\nchallenging task due to the lack of exploration and experimentation with the\nright API and abstraction. This is due to the limited accessibility to latest\nCSD/NVM devices, emerging device interfaces, and closed-source software\ninternals of the devices. To remedy the situation, in this work we present an\nopen-source CSD prototype over emerging NVMe Zoned Namespaces (ZNS) SSDs and an\ninterface that can be used to explore application designs for CSD/NVM storage\ndevices. In this paper we summarize the current state of the practice with CSD\ndevices, make a case for designing a CSD prototype with the ZNS interface and\neBPF (ZCSD), and present our initial findings. The prototype is available at\nhttps://github.com/Dantali0n/qemu-csd.",
    "descriptor": "",
    "authors": [
      "Corne Lukken",
      "Giulia Frascaria",
      "Animesh Trivedi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.00142"
  },
  {
    "id": "arXiv:2112.00143",
    "title": "A Comprehensive Survey on the Convergence of Vehicular Social Networks  and Fog Computing",
    "abstract": "In recent years, the number of IoT devices has been growing fast which leads\nto a challenging task for managing, storing, analyzing, and making decisions\nabout raw data from different IoT devices, especially for delay-sensitive\napplications. In a vehicular network (VANET) environment, the dynamic nature of\nvehicles makes the current open research issues even more challenging due to\nthe frequent topology changes that can lead to disconnections between vehicles.\nTo this end, a number of research works have been proposed in the context of\ncloud and fog computing over the 5G infrastructure. On the other hand, there\nare a variety of research proposals that aim to extend the connection time\nbetween vehicles. Vehicular Social Networks (VSNs) have been defined to\ndecrease the burden of connection time between the vehicles. This survey paper\nfirst provides the necessary background information and definitions about fog,\ncloud and related paradigms such as 5G and SDN. Then, it introduces the reader\nto Vehicular Social Networks, the different metrics and the main differences\nbetween VSNs and Online Social Networks. Finally, this survey investigates the\nrelated works in the context of VANETs that have demonstrated different\narchitectures to address the different issues in fog computing. Moreover, it\nprovides a categorization of the different approaches and discusses the\nrequired metrics in the context of fog and cloud and compares them to Vehicular\nsocial networks. A comparison of the relevant related works is discussed along\nwith new research challenges and trends in the domain of VSNs and fog\ncomputing.",
    "descriptor": "",
    "authors": [
      "Farimasadat Miri",
      "Richard Pazzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00143"
  },
  {
    "id": "arXiv:2112.00147",
    "title": "Slicing Scheduling for Supporting Critical Traffic in Beyond 5G",
    "abstract": "One of the most challenging services fifth-generation (5G) mobile network is\ndesigned to support, is the critical services in-need of very low latency,\nand/or high reliability. It is now clear that such critical services will also\nbe at the core of beyond 5G (B5G) networks. While 5G radio design accommodates\nsuch supports by introducing more flexibility in timing, how efficiently those\nservices could be scheduled over a shared network with other broadband services\nremains as a challenge. In this paper, we use network slicing as an enabler for\nnetwork sharing and propose an optimization framework to schedule resources to\ncritical services via puncturing technique with minimal impact on the regular\nbroadband services. We then thoroughly examine the performance of the framework\nin terms of throughput and reliability through simulation.",
    "descriptor": "\nComments: The paper has been accepted at CCNC 2022\n",
    "authors": [
      "Ali Esmaeily",
      "Katina Kralevska",
      "Toktam Mahmoodi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.00147"
  },
  {
    "id": "arXiv:2112.00155",
    "title": "Space-time hp finite elements for heat evolution in laser-based additive  manufacturing",
    "abstract": "The direct numerical simulation of metal additive manufacturing processes\nsuch as laser powder bed fusion is challenging due to the vast differences in\nspatial and temporal scales. Classical approaches based on locally refined\nfinite elements combined with time-stepping schemes can only address the\nspatial multi-scale nature and provide only limited scaling potential for\nmassively parallel computations. We address these shortcomings in a space-time\nGalerkin framework where the finite element interpolation also includes the\ntemporal direction. In this setting, we construct four-dimensional meshes that\nare locally refined towards the laser spot and allow for varying temporal\naccuracy depending on the position in space. By splitting the mesh into\nconforming time slabs, we recover a stepwise solution to solve the space-time\nproblem locally in time at this slab; additionally, we can choose time-slab\nsizes significantly larger than classical time-stepping schemes. As a result,\nwe believe this setting to be well suited for large-scale parallelization. In\nour work, we use a continuous Galerkin-Petrov formulation of the nonlinear heat\nequation with an apparent heat capacity model to account for the phase change.\nWe validate our approach by computing the AMB2018-02 benchmark, where we obtain\nan excellent agreement with the measured melt pool shape. Using the same setup,\nwe demonstrate the performance potential of our approach by hatching a square\narea with a laser path length of about one meter.",
    "descriptor": "",
    "authors": [
      "Philipp Kopp",
      "Victor Calo",
      "Ernst Rank",
      "Stefan Kollmannsberger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.00155"
  },
  {
    "id": "arXiv:2112.00160",
    "title": "Towards Full-Fledged Argument Search: A Framework for Extracting and  Clustering Arguments from Unstructured Text",
    "abstract": "Argument search aims at identifying arguments in natural language texts. In\nthe past, this task has been addressed by a combination of keyword search and\nargument identification on the sentence- or document-level. However, existing\nframeworks often address only specific components of argument search and do not\naddress the following aspects: (1) argument-query matching: identifying\narguments that frame the topic slightly differently than the actual search\nquery; (2) argument identification: identifying arguments that consist of\nmultiple sentences; (3) argument clustering: selecting retrieved arguments by\ntopical aspects. In this paper, we propose a framework for addressing these\nshortcomings. We suggest (1) to combine the keyword search with precomputed\ntopic clusters for argument-query matching, (2) to apply a novel approach based\non sentence-level sequence-labeling for argument identification, and (3) to\npresent aggregated arguments to users based on topic-aware argument clustering.\nOur experiments on several real-world debate data sets demonstrate that\ndensity-based clustering algorithms, such as HDBSCAN, are particularly suitable\nfor argument-query matching. With our sentence-level, BiLSTM-based\nsequence-labeling approach we achieve a macro F1 score of 0.71. Finally,\nevaluating our argument clustering method indicates that a fine-grained\nclustering of arguments by subtopics remains challenging but is worthwhile to\nbe explored.",
    "descriptor": "",
    "authors": [
      "Michael F\u00e4rber",
      "Anna Steyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.00160"
  },
  {
    "id": "arXiv:2112.00165",
    "title": "Coordinated Multi-Robot Trajectory Tracking over Sampled Communication",
    "abstract": "In this paper, we propose an inverse-kinematics controller for a class of\nmulti-robot systems in the scenario of sampled communication. The goal is to\nmake a group of robots perform trajectory tracking {in a coordinated way} when\nthe sampling time of communications is non-negligible, disrupting the\ntheoretical convergence guarantees of standard control designs. Given a\nfeasible desired trajectory in the configuration space, the proposed controller\nreceives measurements from the system at sampled time instants and computes\nvelocity references for the robots, which are tracked by a low-level\ncontroller. We propose a jointly designed feedback plus feedforward controller\nwith provable stability and error convergence guarantees, and further show that\nthe obtained controller is amenable of decentralized implementation. We test\nthe proposed control strategy via numerical simulations in the scenario of\ncooperative aerial manipulation of a cable-suspended load using a realistic\nsimulator (Fly-Crane). Finally, we compare our proposed decentralized\ncontroller with centralized approaches that adapt the feedback gain online\nthrough smart heuristics, and show that it achieves comparable performance.",
    "descriptor": "\nComments: 23 pages (main article: 14 pages; proofs: 9 pages); 22 figures (main article: 12 figures). Submitted to Automatica\n",
    "authors": [
      "Enrica Rossi",
      "Marco Tognon",
      "Luca Ballotta",
      "Ruggero Carli",
      "Juan Cort\u00e9s",
      "Antonio Franchi",
      "Luca Schenato"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00165"
  },
  {
    "id": "arXiv:2112.00166",
    "title": "TALISMAN: Targeted Active Learning for Object Detection with Rare  Classes and Slices using Submodular Mutual Information",
    "abstract": "Deep neural networks based object detectors have shown great success in a\nvariety of domains like autonomous vehicles, biomedical imaging, etc. It is\nknown that their success depends on a large amount of data from the domain of\ninterest. While deep models often perform well in terms of overall accuracy,\nthey often struggle in performance on rare yet critical data slices. For\nexample, data slices like \"motorcycle at night\" or \"bicycle at night\" are often\nrare but very critical slices for self-driving applications and false negatives\non such rare slices could result in ill-fated failures and accidents. Active\nlearning (AL) is a well-known paradigm to incrementally and adaptively build\ntraining datasets with a human in the loop. However, current AL based\nacquisition functions are not well-equipped to tackle real-world datasets with\nrare slices, since they are based on uncertainty scores or global descriptors\nof the image. We propose TALISMAN, a novel framework for Targeted Active\nLearning or object detectIon with rare slices using Submodular MutuAl\niNformation. Our method uses the submodular mutual information functions\ninstantiated using features of the region of interest (RoI) to efficiently\ntarget and acquire data points with rare slices. We evaluate our framework on\nthe standard PASCAL VOC07+12 and BDD100K, a real-world self-driving dataset. We\nobserve that TALISMAN outperforms other methods by in terms of average\nprecision on rare slices, and in terms of mAP.",
    "descriptor": "",
    "authors": [
      "Suraj Kothawade",
      "Saikat Ghosh",
      "Sumit Shekhar",
      "Yu Xiang",
      "Rishabh Iyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00166"
  },
  {
    "id": "arXiv:2112.00167",
    "title": "MEFNet: Multi-scale Event Fusion Network for Motion Deblurring",
    "abstract": "Traditional frame-based cameras inevitably suffer from motion blur due to\nlong exposure times. As a kind of bio-inspired camera, the event camera records\nthe intensity changes in an asynchronous way with high temporal resolution,\nproviding valid image degradation information within the exposure time. In this\npaper, we rethink the event-based image deblurring problem and unfold it into\nan end-to-end two-stage image restoration network. To effectively utilize event\ninformation, we design (i) a novel symmetric cumulative event representation\nspecifically for image deblurring, and (ii) an affine event-image fusion module\napplied at multiple levels of our network. We also propose an event mask gated\nconnection between the two stages of the network so as to avoid information\nloss. At the dataset level, to foster event-based motion deblurring and to\nfacilitate evaluation on challenging real-world images, we introduce the\nHigh-Quality Blur (HQBlur) dataset, captured with an event camera in an\nillumination-controlled optical laboratory. Our Multi-Scale Event Fusion\nNetwork (MEFNet) sets the new state of the art for motion deblurring,\nsurpassing both the prior best-performing image-based method and all\nevent-based methods with public implementations on the GoPro (by up to 2.38dB)\nand HQBlur datasets, even in extreme blurry conditions. Source code and dataset\nwill be made publicly available.",
    "descriptor": "",
    "authors": [
      "Lei Sun",
      "Christos Sakaridis",
      "Jingyun Liang",
      "Qi Jiang",
      "Kailun Yang",
      "Peng Sun",
      "Yaozu Ye",
      "Kaiwei Wang",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00167"
  },
  {
    "id": "arXiv:2112.00169",
    "title": "3D Photo Stylization: Learning to Generate Stylized Novel Views from a  Single Image",
    "abstract": "Visual content creation has spurred a soaring interest given its applications\nin mobile photography and AR / VR. Style transfer and single-image 3D\nphotography as two representative tasks have so far evolved independently. In\nthis paper, we make a connection between the two, and address the challenging\ntask of 3D photo stylization - generating stylized novel views from a single\nimage given an arbitrary style. Our key intuition is that style transfer and\nview synthesis have to be jointly modeled for this task. To this end, we\npropose a deep model that learns geometry-aware content features for\nstylization from a point cloud representation of the scene, resulting in\nhigh-quality stylized images that are consistent across views. Further, we\nintroduce a novel training protocol to enable the learning using only 2D\nimages. We demonstrate the superiority of our method via extensive qualitative\nand quantitative studies, and showcase key applications of our method in light\nof the growing demand for 3D content creation from 2D image assets.",
    "descriptor": "\nComments: Project page: this http URL\n",
    "authors": [
      "Fangzhou Mu",
      "Jian Wang",
      "Yicheng Wu",
      "Yin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.00169"
  },
  {
    "id": "arXiv:2112.00170",
    "title": "SAMO: Optimised Mapping of Convolutional Neural Networks to Streaming  Architectures",
    "abstract": "Toolflows that map Convolutional Neural Network (CNN) models to Field\nProgrammable Gate Arrays (FPGAs) have been an important tool in accelerating a\nrange of applications across different deployment settings. However, the\nsignificance of the problem of finding an optimal mapping is often overlooked,\nwith the expectation that the end user will tune their generated hardware to\ntheir desired platform. This is particularly prominent within Streaming\nArchitectures toolflows, where there is a large design space to explore. There\nhave been many Streaming Architectures proposed, however apart from\nfpgaConvNet, there is limited support for optimisation methods that explore\nboth performance objectives and platform constraints. In this work, we\nestablish a framework, SAMO: a Streaming Architecture Mapping Optimiser, which\ngeneralises the optimisation problem of mapping Streaming Architectures to FPGA\nplatforms. We also implement both Brute Force and Simulated Annealing\noptimisation methods in order to generate valid, high performance designs for a\nrange of target platforms and CNN models. We are able to observe a 4x increase\nin performance compared to example designs for the popular Streaming\nArchitecture framework FINN.",
    "descriptor": "",
    "authors": [
      "Alexander Montgomerie-Corcoran",
      "Zhewen Yu",
      "Christos-Savvas Bouganis"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.00170"
  },
  {
    "id": "arXiv:2112.00171",
    "title": "Improving Differentiable Architecture Search with a Generative Model",
    "abstract": "In differentiable neural architecture search (NAS) algorithms like DARTS, the\ntraining set used to update model weight and the validation set used to update\nmodel architectures are sampled from the same data distribution. Thus, the\nuncommon features in the dataset fail to receive enough attention during\ntraining. In this paper, instead of introducing more complex NAS algorithms, we\nexplore the idea that adding quality synthesized datasets into training can\nhelp the classification model identify its weakness and improve recognition\naccuracy. We introduce a training strategy called ``Differentiable Architecture\nSearch with a Generative Model(DASGM).\" In DASGM, the training set is used to\nupdate the classification model weight, while a synthesized dataset is used to\ntrain its architecture. The generated images have different distributions from\nthe training set, which can help the classification model learn better features\nto identify its weakness. We formulate DASGM into a multi-level optimization\nframework and develop an effective algorithm to solve it. Experiments on\nCIFAR-10, CIFAR-100, and ImageNet have demonstrated the effectiveness of DASGM.\nCode will be made available.",
    "descriptor": "",
    "authors": [
      "Ruisi Zhang",
      "Youwei Liang",
      "Sai Ashish Somayajula",
      "Pengtao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00171"
  },
  {
    "id": "arXiv:2112.00174",
    "title": "Adaptive Optimization with Examplewise Gradients",
    "abstract": "We propose a new, more general approach to the design of stochastic\ngradient-based optimization methods for machine learning. In this new\nframework, optimizers assume access to a batch of gradient estimates per\niteration, rather than a single estimate. This better reflects the information\nthat is actually available in typical machine learning setups. To demonstrate\nthe usefulness of this generalized approach, we develop Eve, an adaptation of\nthe Adam optimizer which uses examplewise gradients to obtain more accurate\nsecond-moment estimates. We provide preliminary experiments, without\nhyperparameter tuning, which show that the new optimizer slightly outperforms\nAdam on a small scale benchmark and performs the same or worse on larger scale\nbenchmarks. Further work is needed to refine the algorithm and tune\nhyperparameters.",
    "descriptor": "\nComments: 9 pages, 1 figure, 3 tables\n",
    "authors": [
      "Julius Kunze",
      "James Townsend",
      "David Barber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00174"
  },
  {
    "id": "arXiv:2112.00179",
    "title": "A collection of the accepted abstracts for the Machine Learning for  Health (ML4H) symposium 2021",
    "abstract": "A collection of the accepted abstracts for the Machine Learning for Health\n(ML4H) symposium 2021. This index is not complete, as some accepted abstracts\nchose to opt-out of inclusion.",
    "descriptor": "",
    "authors": [
      "Fabian Falck",
      "Yuyin Zhou",
      "Emma Rocheteau",
      "Liyue Shen",
      "Luis Oala",
      "Girmaw Abebe",
      "Subhrajit Roy",
      "Stephen Pfohl",
      "Emily Alsentzer",
      "Matthew B. A. McDermott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00179"
  },
  {
    "id": "arXiv:2112.00180",
    "title": "SpaceEdit: Learning a Unified Editing Space for Open-Domain Image  Editing",
    "abstract": "Recently, large pretrained models (e.g., BERT, StyleGAN, CLIP) have shown\ngreat knowledge transfer and generalization capability on various downstream\ntasks within their domains. Inspired by these efforts, in this paper we propose\na unified model for open-domain image editing focusing on color and tone\nadjustment of open-domain images while keeping their original content and\nstructure. Our model learns a unified editing space that is more semantic,\nintuitive, and easy to manipulate than the operation space (e.g., contrast,\nbrightness, color curve) used in many existing photo editing softwares. Our\nmodel belongs to the image-to-image translation framework which consists of an\nimage encoder and decoder, and is trained on pairs of before- and after-images\nto produce multimodal outputs. We show that by inverting image pairs into\nlatent codes of the learned editing space, our model can be leveraged for\nvarious downstream editing tasks such as language-guided image editing,\npersonalized editing, editing-style clustering, retrieval, etc. We extensively\nstudy the unique properties of the editing space in experiments and demonstrate\nsuperior performance on the aforementioned tasks.",
    "descriptor": "",
    "authors": [
      "Jing Shi",
      "Ning Xu",
      "Haitian Zheng",
      "Alex Smith",
      "Jiebo Luo",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.00180"
  },
  {
    "id": "arXiv:2112.00182",
    "title": "Maliva: Using Machine Learning to Rewrite Visualization Queries Under  Time Constraints",
    "abstract": "We consider data-visualization systems where data is stored in a database,\nand a middleware layer translates a frontend request to a SQL query to the\ndatabase to compute visual results. We focus on the problem of handling\nvisualization requests with predetermined time constraints. We study how to\nrewrite the original query by adding hints and/or conducting approximations so\nthat the total time is within the time constraint. We develop a novel\nmiddleware solution called Maliva, which adopts machine learning (ML)\ntechniques to solve the problem. It applies the Markov Decision Process (MDP)\nmodel to decide how to rewrite queries and uses training instances to learn an\nagent that can make a sequence of decisions judiciously for an online request.\nOur experiments on both real and synthetic datasets show that compared to the\nbaseline approach that relies on the original SQL query, Maliva performs\nsignificantly better in terms of both the chance of serving requests\ninteractively and query execution time.",
    "descriptor": "",
    "authors": [
      "Qiushi Bai",
      "Sadeem Alsudais",
      "Chen Li",
      "Shuang Zhao"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.00182"
  },
  {
    "id": "arXiv:2112.00185",
    "title": "Light Field Implicit Representation for Flexible Resolution  Reconstruction",
    "abstract": "Inspired by the recent advances in implicitly representing signals with\ntrained neural networks, we aim to learn a continuous representation for\nnarrow-baseline 4D light fields. We propose an implicit representation model\nfor 4D light fields which is conditioned on a sparse set of input views. Our\nmodel is trained to output the light field values for a continuous range of\nquery spatio-angular coordinates. Given a sparse set of input views, our scheme\ncan super-resolve the input in both spatial and angular domains by flexible\nfactors. consists of a feature extractor and a decoder which are trained on a\ndataset of light field patches. The feature extractor captures per-pixel\nfeatures from the input views. These features can be resized to a desired\nspatial resolution and fed to the decoder along with the query coordinates.\nThis formulation enables us to reconstruct light field views at any desired\nspatial and angular resolution. Additionally, our network can handle scenarios\nin which input views are either of low-resolution or with missing pixels.\nExperiments show that our method achieves state-of-the-art performance for the\ntask of view synthesis while being computationally fast.",
    "descriptor": "",
    "authors": [
      "Paramanand Chandramouli",
      "Hendrik Sommerhoff",
      "Andreas Kolb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.00185"
  },
  {
    "id": "arXiv:2112.00189",
    "title": "InfoPrint: Embedding Information into 3D Printed Objects",
    "abstract": "We present a technique to embed information invisible to the eye inside 3D\nprinted objects. The information is integrated in the object model, and then\nfabricated using off-the-shelf dual-head FDM (Fused Deposition Modeling) 3D\nprinters. Our process does not require human intervention during or after\nprinting with the integrated model. The information can be arbitrary symbols,\nsuch as icons, text,binary, or handwriting. To retrieve the information, we\nevaluate two different infrared-based imaging devices that are readily\navailable-thermal cameras and near-infrared scanners. Based on our results, we\npropose design guidelines for a range of use cases to embed and extract hidden\ninformation. We demonstrate how our method can be used for different\napplications, such as interactive thermal displays, hidden board game tokens,\ntagging functional printed objects, and autographing non-fungible fabrication\nwork.",
    "descriptor": "\nComments: 24 pages, 18 figures\n",
    "authors": [
      "Weiwei Jiang",
      "Chaofan Wang",
      "Zhanna Sarsenbayeva",
      "Andrew Irlitti",
      "Jarrod Knibbe",
      "Tilman Dingler",
      "Jorge Goncalves",
      "Vassilis Kostakos"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.00189"
  },
  {
    "id": "arXiv:2112.00190",
    "title": "Is the use of Deep Learning and Artificial Intelligence an appropriate  means to locate debris in the ocean without harming aquatic wildlife?",
    "abstract": "With the global issue of plastic debris ever expanding, it is about time that\nthe technology industry stepped in. This study aims to assess whether deep\nlearning can successfully distinguish between marine life and man-made debris\nunderwater. The aim is to find if we are safely able to clean up our oceans\nwith Artificial Intelligence without disrupting the delicate balance of the\naquatic ecosystems. The research explores the use of Convolutional Neural\nNetworks from the perspective of protecting the ecosystem, rather than\nprimarily collecting rubbish. We did this by building a custom-built, deep\nlearning model, with an original database including 1,644 underwater images and\nused a binary classification to sort synthesised material from aquatic life. We\nconcluded that although it is possible to safely distinguish between debris and\nlife, further exploration with a larger database and stronger CNN structure has\nthe potential for much more promising results.",
    "descriptor": "\nComments: reference list is added/updated; sorry for causing any inconveniences. 3681 words, 14 pages\n",
    "authors": [
      "Zoe Moorton",
      "Zeyneb Kurt",
      "Wai Lok Woo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.00190"
  },
  {
    "id": "arXiv:2112.00193",
    "title": "Public Data-Assisted Mirror Descent for Private Model Training",
    "abstract": "We revisit the problem of using public data to improve the privacy/utility\ntrade-offs for differentially private (DP) model training. Here, public data\nrefers to auxiliary data sets that have no privacy concerns. We consider public\ndata that is from the same distribution as the private training data.\nFor convex losses, we show that a variant of Mirror Descent provides\npopulation risk guarantees which are independent of the dimension of the model\n($p$). Specifically, we apply Mirror Descent with the loss generated by the\npublic data as the mirror map, and using DP gradients of the loss generated by\nthe private (sensitive) data. To obtain dimension independence, we require\n$G_Q^2 \\leq p$ public data samples, where $G_Q$ is a measure of the isotropy of\nthe loss function. We further show that our algorithm has a natural ``noise\nstability'' property: If around the current iterate the public loss satisfies\n$\\alpha_v$-strong convexity in a direction $v$, then using noisy gradients\ninstead of the exact gradients shifts our next iterate in the direction $v$ by\nan amount proportional to $1/\\alpha_v$ (in contrast with DP-SGD, where the\nshift is isotropic). Analogous results in prior works had to explicitly learn\nthe geometry using the public data in the form of preconditioner matrices. Our\nmethod is also applicable to non-convex losses, as it does not rely on\nconvexity assumptions to ensure DP guarantees.\nWe demonstrate the empirical efficacy of our algorithm by showing\nprivacy/utility trade-offs on linear regression, deep learning benchmark\ndatasets (WikiText-2, CIFAR-10, and EMNIST), and in federated learning\n(StackOverflow). We show that our algorithm not only significantly improves\nover traditional DP-SGD and DP-FedAvg, which do not have access to public data,\nbut also improves over DP-SGD and DP-FedAvg on models that have been\npre-trained with the public data to begin with.",
    "descriptor": "\nComments: 20 pages, 9 figures, 3 tables\n",
    "authors": [
      "Ehsan Amid",
      "Arun Ganesh",
      "Rajiv Mathews",
      "Swaroop Ramaswamy",
      "Shuang Song",
      "Thomas Steinke",
      "Vinith M. Suriyakumar",
      "Om Thakkar",
      "Abhradeep Thakurta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.00193"
  },
  {
    "id": "arXiv:2112.00195",
    "title": "Efficient Online Bayesian Inference for Neural Bandits",
    "abstract": "In this paper we present a new algorithm for online (sequential) inference in\nBayesian neural networks, and show its suitability for tackling contextual\nbandit problems. The key idea is to combine the extended Kalman filter (which\nlocally linearizes the likelihood function at each time step) with a (learned\nor random) low-dimensional affine subspace for the parameters; the use of a\nsubspace enables us to scale our algorithm to models with $\\sim 1M$ parameters.\nWhile most other neural bandit methods need to store the entire past dataset in\norder to avoid the problem of \"catastrophic forgetting\", our approach uses\nconstant memory. This is possible because we represent uncertainty about all\nthe parameters in the model, not just the final linear layer. We show good\nresults on the \"Deep Bayesian Bandit Showdown\" benchmark, as well as MNIST and\na recommender system.",
    "descriptor": "",
    "authors": [
      "Gerardo Duran-Martin",
      "Aleyna Kara",
      "Kevin Murphy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00195"
  },
  {
    "id": "arXiv:2112.00200",
    "title": "Efficient Big Text Data Clustering Algorithms using Hadoop and Spark",
    "abstract": "Document clustering is a traditional, efficient and yet quite effective, text\nmining technique when we need to get a better insight of the documents of a\ncollection that could be grouped together. The K-Means algorithm and the\nHierarchical Agglomerative Clustering (HAC) algorithm are two of the most known\nand commonly used clustering algorithms; the former due to its low time cost\nand the latter due to its accuracy. However, even the use of K-Means in text\nclustering over large-scale collections can lead to unacceptable time costs. In\nthis paper we first address some of the most valuable approaches for document\nclustering over such 'big data' (large-scale) collections. We then present two\nvery promising alternatives: (a) a variation of an existing K-Means-based fast\nclustering technique (known as BigKClustering - BKC) so that it can be applied\nin document clustering, and (b) a hybrid clustering approach based on a\ncustomized version of the Buckshot algorithm, which first applies a\nhierarchical clustering procedure on a sample of the input dataset and then it\nuses the results as the initial centers for a K-Means based assignment of the\nrest of the documents, with very few iterations. We also give highly efficient\nadaptations of the proposed techniques in the MapReduce model which are then\nexperimentally tested using Apache Hadoop and Spark over a real cluster\nenvironment. As it comes out of the experiments, they both lead to acceptable\nclustering quality as well as to significant time improvements (compared to\nK-Means - especially the Buckshot-based algorithm), thus constituting very\npromising alternatives for big document collections.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Sergios Gerakidis",
      "Sofia Megarchioti",
      "Basilis Mamalis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.00200"
  },
  {
    "id": "arXiv:2112.00202",
    "title": "3DVNet: Multi-View Depth Prediction and Volumetric Refinement",
    "abstract": "We present 3DVNet, a novel multi-view stereo (MVS) depth-prediction method\nthat combines the advantages of previous depth-based and volumetric MVS\napproaches. Our key idea is the use of a 3D scene-modeling network that\niteratively updates a set of coarse depth predictions, resulting in highly\naccurate predictions which agree on the underlying scene geometry. Unlike\nexisting depth-prediction techniques, our method uses a volumetric 3D\nconvolutional neural network (CNN) that operates in world space on all depth\nmaps jointly. The network can therefore learn meaningful scene-level priors.\nFurthermore, unlike existing volumetric MVS techniques, our 3D CNN operates on\na feature-augmented point cloud, allowing for effective aggregation of\nmulti-view information and flexible iterative refinement of depth maps.\nExperimental results show our method exceeds state-of-the-art accuracy in both\ndepth prediction and 3D reconstruction metrics on the ScanNet dataset, as well\nas a selection of scenes from the TUM-RGBD and ICL-NUIM datasets. This shows\nthat our method is both effective and generalizes to new settings.",
    "descriptor": "\nComments: 10 pages, 6 figures, 3 tables. Accepted to 3DV 2021\n",
    "authors": [
      "Alexander Rich",
      "Noah Stier",
      "Pradeep Sen",
      "Tobias H\u00f6llerer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00202"
  },
  {
    "id": "arXiv:2112.00206",
    "title": "Querying Labelled Data with Scenario Programs for Sim-to-Real Validation",
    "abstract": "Simulation-based testing of autonomous vehicles (AVs) has become an essential\ncomplement to road testing to ensure safety. Consequently, substantial research\nhas focused on searching for failure scenarios in simulation. However, a\nfundamental question remains: are AV failure scenarios identified in simulation\nmeaningful in reality, i.e., are they reproducible on the real system? Due to\nthe sim-to-real gap arising from discrepancies between simulated and real\nsensor data, a failure scenario identified in simulation can be either a\nspurious artifact of the synthetic sensor data or an actual failure that\npersists with real sensor data. An approach to validate simulated failure\nscenarios is to identify instances of the scenario in a corpus of real data,\nand check if the failure persists on the real data. To this end, we propose a\nformal definition of what it means for a labelled data item to match an\nabstract scenario, encoded as a scenario program using the SCENIC probabilistic\nprogramming language. Using this definition, we develop a querying algorithm\nwhich, given a scenario program and a labelled dataset, finds the subset of\ndata matching the scenario. Experiments demonstrate that our algorithm is\naccurate and efficient on a variety of realistic traffic scenarios, and scales\nto a reasonable number of agents.",
    "descriptor": "\nComments: pre-print\n",
    "authors": [
      "Edward Kim",
      "Jay Shenoy",
      "Sebastian Junges",
      "Daniel Fremont",
      "Alberto Sangiovanni-Vincentelli",
      "Sanjit Seshia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00206"
  },
  {
    "id": "arXiv:2112.00207",
    "title": "Improved sparse PCA method for face and image recognition",
    "abstract": "Face recognition is the very significant field in pattern recognition area.\nIt has multiple applications in military and finance, to name a few. In this\npaper, the combination of the sparse PCA with the nearest-neighbor method (and\nwith the kernel ridge regression method) will be proposed and will be applied\nto solve the face recognition problem. Experimental results illustrate that the\naccuracy of the combination of the sparse PCA method (using the proximal\ngradient method and the FISTA method) and one specific classification system\nmay be lower than the accuracy of the combination of the PCA method and one\nspecific classification system but sometimes the combination of the sparse PCA\nmethod (using the proximal gradient method or the FISTA method) and one\nspecific classification system leads to better accuracy. Moreover, we recognize\nthat the process computing the sparse PCA algorithm using the FISTA method is\nalways faster than the process computing the sparse PCA algorithm using the\nproximal gradient method.",
    "descriptor": "\nComments: 11 pages. arXiv admin note: substantial text overlap with arXiv:1904.08496\n",
    "authors": [
      "Loc Hoang Tran",
      "Tuan Tran",
      "An Mai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00207"
  },
  {
    "id": "arXiv:2112.00209",
    "title": "Environmental Sound Extraction Using Onomatopoeia",
    "abstract": "Onomatopoeia, which is a character sequence that phonetically imitates a\nsound, is effective in expressing characteristics of sound such as duration,\npitch, and timbre. We propose an environmental-sound-extraction method using\nonomatopoeia to specify the target sound to be extracted. With this method, we\nestimate a time-frequency mask from an input mixture spectrogram and\nonomatopoeia by using U-Net architecture then extract the corresponding target\nsound by masking the spectrogram. Experimental results indicate that the\nproposed method can extract only the target sound corresponding to onomatopoeia\nand performs better than conventional methods that use sound-event classes to\nspecify the target sound.",
    "descriptor": "\nComments: Submitted to ICASSP2022\n",
    "authors": [
      "Yuki Okamoto",
      "Shota Horiguchi",
      "Masaaki Yamamoto",
      "Keisuke Imoto",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.00209"
  },
  {
    "id": "arXiv:2112.00216",
    "title": "PoseKernelLifter: Metric Lifting of 3D Human Pose using Sound",
    "abstract": "Reconstructing the 3D pose of a person in metric scale from a single view\nimage is a geometrically ill-posed problem. For example, we can not measure the\nexact distance of a person to the camera from a single view image without\nadditional scene assumptions (e.g., known height). Existing learning based\napproaches circumvent this issue by reconstructing the 3D pose up to scale.\nHowever, there are many applications such as virtual telepresence, robotics,\nand augmented reality that require metric scale reconstruction. In this paper,\nwe show that audio signals recorded along with an image, provide complementary\ninformation to reconstruct the metric 3D pose of the person.\nThe key insight is that as the audio signals traverse across the 3D space,\ntheir interactions with the body provide metric information about the body's\npose. Based on this insight, we introduce a time-invariant transfer function\ncalled pose kernel -- the impulse response of audio signals induced by the body\npose. The main properties of the pose kernel are that (1) its envelope highly\ncorrelates with 3D pose, (2) the time response corresponds to arrival time,\nindicating the metric distance to the microphone, and (3) it is invariant to\nchanges in the scene geometry configurations. Therefore, it is readily\ngeneralizable to unseen scenes. We design a multi-stage 3D CNN that fuses audio\nand visual signals and learns to reconstruct 3D pose in a metric scale. We show\nthat our multi-modal method produces accurate metric reconstruction in real\nworld scenes, which is not possible with state-of-the-art lifting approaches\nincluding parametric mesh regression and depth regression.",
    "descriptor": "",
    "authors": [
      "Zhijian Yang",
      "xiaoran Fan",
      "Volkan Isler",
      "Hyun Soo Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.00216"
  },
  {
    "id": "arXiv:2112.00219",
    "title": "Scalable Primitives for Generalized Sensor Fusion in Autonomous Vehicles",
    "abstract": "In autonomous driving, there has been an explosion in the use of deep neural\nnetworks for perception, prediction and planning tasks. As autonomous vehicles\n(AVs) move closer to production, multi-modal sensor inputs and heterogeneous\nvehicle fleets with different sets of sensor platforms are becoming\nincreasingly common in the industry. However, neural network architectures\ntypically target specific sensor platforms and are not robust to changes in\ninput, making the problem of scaling and model deployment particularly\ndifficult. Furthermore, most players still treat the problem of optimizing\nsoftware and hardware as entirely independent problems. We propose a new end to\nend architecture, Generalized Sensor Fusion (GSF), which is designed in such a\nway that both sensor inputs and target tasks are modular and modifiable. This\nenables AV system designers to easily experiment with different sensor\nconfigurations and methods and opens up the ability to deploy on heterogeneous\nfleets using the same models that are shared across a large engineering\norganization. Using this system, we report experimental results where we\ndemonstrate near-parity of an expensive high-density (HD) LiDAR sensor with a\ncheap low-density (LD) LiDAR plus camera setup in the 3D object detection task.\nThis paves the way for the industry to jointly design hardware and software\narchitectures as well as large fleets with heterogeneous configurations.",
    "descriptor": "\nComments: Presented in Machine Learning for Autonomous Driving Workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia. 11 pages, 8 figures\n",
    "authors": [
      "Sammy Sidhu",
      "Linda Wang",
      "Tayyab Naseer",
      "Ashish Malhotra",
      "Jay Chia",
      "Aayush Ahuja",
      "Ella Rasmussen",
      "Qiangui Huang",
      "Ray Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00219"
  },
  {
    "id": "arXiv:2112.00220",
    "title": "A generic physics-informed neural network-based framework for  reliability assessment of multi-state systems",
    "abstract": "In this paper, we leverage the recent advances in physics-informed neural\nnetwork (PINN) and develop a generic PINN-based framework to assess the\nreliability of multi-state systems (MSSs). The proposed methodology consists of\ntwo major steps. In the first step, we recast the reliability assessment of MSS\nas a machine learning problem using the framework of PINN. A feedforward neural\nnetwork with two individual loss groups are constructed to encode the initial\ncondition and state transitions governed by ordinary differential equations\n(ODEs) in MSS. Next, we tackle the problem of high imbalance in the magnitude\nof the back-propagated gradients in PINN from a multi-task learning\nperspective. Particularly, we treat each element in the loss function as an\nindividual task, and adopt a gradient surgery approach named projecting\nconflicting gradients (PCGrad), where a task's gradient is projected onto the\nnorm plane of any other task that has a conflicting gradient. The gradient\nprojection operation significantly mitigates the detrimental effects caused by\nthe gradient interference when training PINN, thus accelerating the convergence\nspeed of PINN to high-precision solutions to MSS reliability assessment. With\nthe proposed PINN-based framework, we investigate its applications for MSS\nreliability assessment in several different contexts in terms of\ntime-independent or dependent state transitions and system scales varying from\nsmall to medium. The results demonstrate that the proposed PINN-based framework\nshows generic and remarkable performance in MSS reliability assessment, and the\nincorporation of PCGrad in PINN leads to substantial improvement in solution\nquality and convergence speed.",
    "descriptor": "",
    "authors": [
      "Taotao Zhou",
      "Xiaoge Zhang",
      "Enrique Lopez Droguett",
      "Ali Mosleh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00220"
  },
  {
    "id": "arXiv:2112.00227",
    "title": "A Machine Learning Analysis of COVID-19 Mental Health Data",
    "abstract": "In late December 2019, the novel coronavirus (Sars-Cov-2) and the resulting\ndisease COVID-19 were first identified in Wuhan China. The disease slipped\nthrough containment measures, with the first known case in the United States\nbeing identified on January 20th, 2020. In this paper, we utilize survey data\nfrom the Inter-university Consortium for Political and Social Research and\napply several statistical and machine learning models and techniques such as\nDecision Trees, Multinomial Logistic Regression, Naive Bayes, k-Nearest\nNeighbors, Support Vector Machines, Neural Networks, Random Forests, Gradient\nTree Boosting, XGBoost, CatBoost, LightGBM, Synthetic Minority Oversampling,\nand Chi-Squared Test to analyze the impacts the COVID-19 pandemic has had on\nthe mental health of frontline workers in the United States. Through the\ninterpretation of the many models applied to the mental health survey data, we\nhave concluded that the most important factor in predicting the mental health\ndecline of a frontline worker is the healthcare role the individual is in\n(Nurse, Emergency Room Staff, Surgeon, etc.), followed by the amount of sleep\nthe individual has had in the last week, the amount of COVID-19 related news an\nindividual has consumed on average in a day, the age of the worker, and the\nusage of alcohol and cannabis.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Mostafa Rezapour",
      "Lucas Hansen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.00227"
  },
  {
    "id": "arXiv:2112.00228",
    "title": "Efficient loading of reduced data ensembles produced at ORNL SNS/HFIR  neutron time-of-flight facilities",
    "abstract": "We present algorithmic improvements to the loading operations of certain\nreduced data ensembles produced from neutron scattering experiments at Oak\nRidge National Laboratory (ORNL) facilities. Ensembles from multiple\nmeasurements are required to cover a wide range of the phase space of a sample\nmaterial of interest. They are stored using the standard NeXus schema on\nindividual HDF5 files. This makes it a scalability challenge, as the number of\nexperiments stored increases in a single ensemble file. The present work\nfollows up on our previous efforts on data management algorithms, to address\nidentified input output (I/O) bottlenecks in Mantid, an open-source data\nanalysis framework used across several neutron science facilities around the\nworld. We reuse an in-memory binary-tree metadata index that resembles data\naccess patterns, to provide a scalable search and extraction mechanism. In\naddition, several memory operations are refactored and optimized for the\ncurrent common use cases, ranging most frequently from 10 to 180, and up to 360\nseparate measurement configurations. Results from this work show consistent\nspeed ups in wall-clock time on the Mantid LoadMD routine, ranging from 19\\% to\n23\\% on average, on ORNL production computing systems. The latter depends on\nthe complexity of the targeted instrument-specific data and the system I/O and\ncompute variability for the shared computational resources available to users\nof ORNL's Spallation Neutron Source (SNS) and the High Flux Isotope Reactor\n(HFIR) instruments. Nevertheless, we continue to highlight the need for more\nresearch to address reduction challenges as experimental data volumes, user\ntime and processing costs increase.",
    "descriptor": "\nComments: 7 pages, 6 figures, 4 tables, The Second International Workshop on Big Data Reduction held with 2021 IEEE International Conference on Big Data\n",
    "authors": [
      "William F Godoy",
      "Andrei T Savici",
      "Steven E Hahn",
      "Peter F Peterson"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.00228"
  },
  {
    "id": "arXiv:2112.00229",
    "title": "Frequency Fitness Assignment: Optimization without a Bias for Good  Solutions can be Efficient",
    "abstract": "A fitness assignment process transforms the features (such as the objective\nvalue) of a candidate solution to a scalar fitness, which then is the basis for\nselection. Under Frequency Fitness Assignment (FFA), the fitness corresponding\nto an objective value is its encounter frequency and is subject to\nminimization. FFA creates algorithms that are not biased towards better\nsolutions and are invariant under all bijections of the objective function\nvalue. We investigate the impact of FFA on the performance of two\ntheory-inspired, state-of-the-art EAs, the Greedy (2+1) GA and the\nSelf-Adjusting (1+lambda,lambda)) GA. FFA improves their performance\nsignificantly on some problems that are hard for them. We empirically find that\none FFA-based algorithm can solve all theory-based benchmark problems in this\nstudy, including traps, jumps, and plateaus, in polynomial time. We propose two\nhybrid approaches that use both direct and FFA-based optimization and find that\nthey perform well. All FFA-based algorithms also perform better on\nsatisfiability problems than all pure algorithm variants.",
    "descriptor": "",
    "authors": [
      "Thomas Weise",
      "Zhize Wu",
      "Xinlu Li",
      "Yan Chen",
      "J\u00f6rg L\u00e4ssig"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.00229"
  },
  {
    "id": "arXiv:2112.00234",
    "title": "Benchmarking Deep Deblurring Algorithms: A Large-Scale Multi-Cause  Dataset and A New Baseline Model",
    "abstract": "Blur artifacts can seriously degrade the visual quality of images, and\nnumerous deblurring methods have been proposed for specific scenarios. However,\nin most real-world images, blur is caused by different factors, e.g., motion\nand defocus. In this paper, we address how different deblurring methods perform\non general types of blur. For in-depth performance evaluation, we construct a\nnew large-scale multi-cause image deblurring dataset called (MC-Blur) including\nreal-world and synthesized blurry images with mixed factors of blurs. The\nimages in the proposed MC-Blur dataset are collected using different\ntechniques: convolving Ultra-High-Definition (UHD) sharp images with large\nkernels, averaging sharp images captured by a 1000 fps high-speed camera,\nadding defocus to images, and real-world blurred images captured by various\ncamera models. These results provide a comprehensive overview of the advantages\nand limitations of current deblurring methods. Further, we propose a new\nbaseline model, level-attention deblurring network, to adapt to multiple causes\nof blurs. By including different weights of attention to the different levels\nof features, the proposed network derives more powerful features with larger\nweights assigned to more important levels, thereby enhancing the feature\nrepresentation. Extensive experimental results on the new dataset demonstrate\nthe effectiveness of the proposed model for the multi-cause blur scenarios.",
    "descriptor": "",
    "authors": [
      "Kaihao Zhang",
      "Wenhan Luo",
      "Boheng Chen",
      "Wenqi Ren",
      "Bjorn Stenger",
      "Wei Liu",
      "Hongdong Li",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00234"
  },
  {
    "id": "arXiv:2112.00236",
    "title": "VoRTX: Volumetric 3D Reconstruction With Transformers for Voxelwise View  Selection and Fusion",
    "abstract": "Recent volumetric 3D reconstruction methods can produce very accurate\nresults, with plausible geometry even for unobserved surfaces. However, they\nface an undesirable trade-off when it comes to multi-view fusion. They can fuse\nall available view information by global averaging, thus losing fine detail, or\nthey can heuristically cluster views for local fusion, thus restricting their\nability to consider all views jointly. Our key insight is that greater detail\ncan be retained without restricting view diversity by learning a view-fusion\nfunction conditioned on camera pose and image content. We propose to learn this\nmulti-view fusion using a transformer. To this end, we introduce VoRTX, an\nend-to-end volumetric 3D reconstruction network using transformers for\nwide-baseline, multi-view feature fusion. Our model is occlusion-aware,\nleveraging the transformer architecture to predict an initial, projective scene\ngeometry estimate. This estimate is used to avoid backprojecting image features\nthrough surfaces into occluded regions. We train our model on ScanNet and show\nthat it produces better reconstructions than state-of-the-art methods. We also\ndemonstrate generalization without any fine-tuning, outperforming the same\nstate-of-the-art methods on two other datasets, TUM-RGBD and ICL-NUIM.",
    "descriptor": "\nComments: 3DV 2021\n",
    "authors": [
      "Noah Stier",
      "Alexander Rich",
      "Pradeep Sen",
      "Tobias H\u00f6llerer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00236"
  },
  {
    "id": "arXiv:2112.00238",
    "title": "Imbalanced Graph Classification via Graph-of-Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have achieved unprecedented success in learning\ngraph representations to identify categorical labels of graphs. However, most\nexisting graph classification problems with GNNs follow a balanced data\nsplitting protocol, which is misaligned with many real-world scenarios in which\nsome classes have much fewer labels than others. Directly training GNNs under\nthis imbalanced situation may lead to uninformative representations of graphs\nin minority classes, and compromise the overall performance of downstream\nclassification, which signifies the importance of developing effective GNNs for\nhandling imbalanced graph classification. Existing methods are either tailored\nfor non-graph structured data or designed specifically for imbalance node\nclassification while few focus on imbalance graph classification. To this end,\nwe introduce a novel framework, Graph-of-Graph Neural Networks (G$^2$GNN),\nwhich alleviates the graph imbalance issue by deriving extra supervision\nglobally from neighboring graphs and locally from graphs themselves. Globally,\nwe construct a graph of graphs (GoG) based on kernel similarity and perform GoG\npropagation to aggregate neighboring graph representations, which are initially\nobtained by node-level propagation with pooling via a GNN encoder. Locally, we\nemploy topological augmentation via masking nodes or dropping edges to improve\nthe model generalizability in discerning topology of unseen testing graphs.\nExtensive graph classification experiments conducted on seven benchmark\ndatasets demonstrate our proposed G$^2$GNN outperforms numerous baselines by\nroughly 5\\% in both F1-macro and F1-micro scores. The implementation of\nG$^2$GNN is available at\n\\href{https://github.com/YuWVandy/G2GNN}{https://github.com/YuWVandy/G2GNN}.",
    "descriptor": "",
    "authors": [
      "Yu Wang",
      "Yuying Zhao",
      "Neil Shah",
      "Tyler Derr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.00238"
  },
  {
    "id": "arXiv:2112.00245",
    "title": "True or False: Does the Deep Learning Model Learn to Detect Rumors?",
    "abstract": "It is difficult for humans to distinguish the true and false of rumors, but\ncurrent deep learning models can surpass humans and achieve excellent accuracy\non many rumor datasets. In this paper, we investigate whether deep learning\nmodels that seem to perform well actually learn to detect rumors. We evaluate\nmodels on their generalization ability to out-of-domain examples by fine-tuning\nBERT-based models on five real-world datasets and evaluating against all test\nsets. The experimental results indicate that the generalization ability of the\nmodels on other unseen datasets are unsatisfactory, even common-sense rumors\ncannot be detected. Moreover, we found through experiments that models take\nshortcuts and learn absurd knowledge when the rumor datasets have serious data\npitfalls. This means that simple modifications to the rumor text based on\nspecific rules will lead to inconsistent model predictions. To more\nrealistically evaluate rumor detection models, we proposed a new evaluation\nmethod called paired test (PairT), which requires models to correctly predict a\npair of test samples at the same time. Furthermore, we make recommendations on\nhow to better create rumor dataset and evaluate rumor detection model at the\nend of this paper.",
    "descriptor": "\nComments: 5 pages, 3 figures, 8 tables\n",
    "authors": [
      "Shiwen Ni",
      "Jiawen Li",
      "Hung-Yu Kao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00245"
  },
  {
    "id": "arXiv:2112.00246",
    "title": "AdaAfford: Learning to Adapt Manipulation Affordance for 3D Articulated  Objects via Few-shot Interactions",
    "abstract": "Perceiving and interacting with 3D articulated objects, such as cabinets,\ndoors, and faucets, pose particular challenges for future home-assistant robots\nperforming daily tasks in human environments. Besides parsing the articulated\nparts and joint parameters, researchers recently advocate learning manipulation\naffordance over the input shape geometry which is more task-aware and\ngeometrically fine-grained. However, taking only passive observations as\ninputs, these methods ignore many hidden but important kinematic constraints\n(e.g., joint location and limits) and dynamic factors (e.g., joint friction and\nrestitution), therefore losing significant accuracy for test cases with such\nuncertainties. In this paper, we propose a novel framework, named AdaAfford,\nthat learns to perform very few test-time interactions for quickly adapting the\naffordance priors to more accurate instance-specific posteriors. We conduct\nlarge-scale experiments using the PartNet-Mobility dataset and prove that our\nsystem performs better than baselines.",
    "descriptor": "",
    "authors": [
      "Yian Wang",
      "Ruihai Wu",
      "Kaichun Mo",
      "Jiaqi Ke",
      "Qingnan Fan",
      "Leonidas Guibas",
      "Hao Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00246"
  },
  {
    "id": "arXiv:2112.00247",
    "title": "Adversarial Attacks Against Deep Generative Models on Data: A Survey",
    "abstract": "Deep generative models have gained much attention given their ability to\ngenerate data for applications as varied as healthcare to financial technology\nto surveillance, and many more - the most popular models being generative\nadversarial networks and variational auto-encoders. Yet, as with all machine\nlearning models, ever is the concern over security breaches and privacy leaks\nand deep generative models are no exception. These models have advanced so\nrapidly in recent years that work on their security is still in its infancy. In\nan attempt to audit the current and future threats against these models, and to\nprovide a roadmap for defense preparations in the short term, we prepared this\ncomprehensive and specialized survey on the security and privacy preservation\nof GANs and VAEs. Our focus is on the inner connection between attacks and\nmodel architectures and, more specifically, on five components of deep\ngenerative models: the training data, the latent code, the generators/decoders\nof GANs/ VAEs, the discriminators/encoders of GANs/ VAEs, and the generated\ndata. For each model, component and attack, we review the current research\nprogress and identify the key challenges. The paper concludes with a discussion\nof possible future attacks and research directions in the field.",
    "descriptor": "\nComments: To be published in IEEE Transactions on Knowledge and Data Engineering\n",
    "authors": [
      "Hui Sun",
      "Tianqing Zhu",
      "Zhiqiu Zhang",
      "Dawei Jin.Ping Xiong",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.00247"
  },
  {
    "id": "arXiv:2112.00248",
    "title": "Simulation platform for pattern recognition based on reservoir computing  with memristor networks",
    "abstract": "Memristive systems and devices are potentially available for implementing\nreservoir computing (RC) systems applied to pattern recognition. However, the\ncomputational ability of memristive RC systems depends on intertwined factors\nsuch as system architectures and physical properties of memristive elements,\nwhich complicates identifying the key factor for system performance. Here we\ndevelop a simulation platform for RC with memristor device networks, which\nenables testing different system designs for performance improvement. Numerical\nsimulations show that the memristor-network-based RC systems can yield high\ncomputational performance comparable to that of state-of-the-art methods in\nthree time series classification tasks. We demonstrate that the excellent and\nrobust computation under device-to-device variability can be achieved by\nappropriately setting network structures, nonlinearity of memristors, and\npre/post-processing, which increases the potential for reliable computation\nwith unreliable component devices. Our results contribute to an establishment\nof a design guide for memristive reservoirs toward a realization of\nenergy-efficient machine learning hardware.",
    "descriptor": "\nComments: 14 pages, 7 figures, 5 supplementary figures\n",
    "authors": [
      "Gouhei Tanaka",
      "Ryosho Nakane"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.00248"
  },
  {
    "id": "arXiv:2112.00250",
    "title": "Shallow Network Based on Depthwise Over-Parameterized Convolution for  Hyperspectral Image Classification",
    "abstract": "Recently, convolutional neural network (CNN) techniques have gained\npopularity as a tool for hyperspectral image classification (HSIC). To improve\nthe feature extraction efficiency of HSIC under the condition of limited\nsamples, the current methods generally use deep models with plenty of layers.\nHowever, deep network models are prone to overfitting and gradient vanishing\nproblems when samples are limited. In addition, the spatial resolution\ndecreases severely with deeper depth, which is very detrimental to spatial edge\nfeature extraction. Therefore, this letter proposes a shallow model for HSIC,\nwhich is called depthwise over-parameterized convolutional neural network\n(DOCNN). To ensure the effective extraction of the shallow model, the depthwise\nover-parameterized convolution (DO-Conv) kernel is introduced to extract the\ndiscriminative features. The depthwise over-parameterized Convolution kernel is\ncomposed of a standard convolution kernel and a depthwise convolution kernel,\nwhich can extract the spatial feature of the different channels individually\nand fuse the spatial features of the whole channels simultaneously. Moreover,\nto further reduce the loss of spatial edge features due to the convolution\noperation, a dense residual connection (DRC) structure is proposed to apply to\nthe feature extraction part of the whole network. Experimental results obtained\nfrom three benchmark data sets show that the proposed method outperforms other\nstate-of-the-art methods in terms of classification accuracy and computational\nefficiency.",
    "descriptor": "",
    "authors": [
      "Hongmin Gao",
      "Member",
      "IEEE",
      "Zhonghao Chen",
      "Student Member",
      "IEEE",
      "Chenming Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.00250"
  },
  {
    "id": "arXiv:2112.00260",
    "title": "Ranking Distance Calibration for Cross-Domain Few-Shot Learning",
    "abstract": "Recent progress in few-shot learning promotes a more realistic cross-domain\nsetting, where the source and target datasets are from different domains. Due\nto the domain gap and disjoint label spaces between source and target datasets,\ntheir shared knowledge is extremely limited. This encourages us to explore more\ninformation in the target domain rather than to overly elaborate training\nstrategies on the source domain as in many existing methods. Hence, we start\nfrom a generic representation pre-trained by a cross-entropy loss and a\nconventional distance-based classifier, along with an image retrieval view, to\nemploy a re-ranking process for calibrating a target distance matrix by\ndiscovering the reciprocal k-nearest neighbours within the task. Assuming the\npre-trained representation is biased towards the source, we construct a\nnon-linear subspace to minimise task-irrelevant features therewithin while keep\nmore transferrable discriminative information by a hyperbolic tangent\ntransformation. The calibrated distance in this target-aware non-linear\nsubspace is complementary to that in the pre-trained representation. To impose\nsuch distance calibration information onto the pre-trained representation, a\nKullback-Leibler divergence loss is employed to gradually guide the model\ntowards the calibrated distance-based distribution. Extensive evaluations on\neight target domains show that this target ranking calibration process can\nimprove conventional distance-based classifiers in few-shot learning.",
    "descriptor": "",
    "authors": [
      "Pan Li",
      "Shaogang Gong",
      "Yanwei Fu",
      "Chengjie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00260"
  },
  {
    "id": "arXiv:2112.00262",
    "title": "A Blockchain-Enabled Incentivised Framework for Cyber Threat  Intelligence Sharing in ICS",
    "abstract": "In recent years Industrial Control Systems (ICS) have been targeted\nincreasingly by sophisticated cyberattacks. Improving ICS security has drawn\nsignificant attention in the literature that emphasises the importance of Cyber\nThreat Intelligence (CTI) sharing in accelerating detection, mitigation, and\nprevention of cyberattacks. However, organisations are reluctant to exchange\nCTI due to fear of exposure, reputational damage, and lack of incentives.\nFurthermore, there has been limited discussion about the factors influencing\nparticipation in sharing CTI about ICS. The existing CTI-sharing platforms rely\non centralised trusted architectures that suffer from a single point of failure\nand risk companies' privacy as the central node maintains CTI details. In this\npaper, we address the needs of organisations involved in the management and\nprotection of ICS and present a novel framework that facilitates secure,\nprivate, and incentivised exchange of CTI related to ICS using blockchain. We\npropose a new blockchain-enabled framework that facilitates the secure\ndissemination of CTI data among multiple stakeholders in ICS. We provide the\nframework design, technical development and evaluate the framework's\nfeasibility in a real-world application environment using practical use-case\nscenarios. Our proposed design shows a more practical and efficient framework\nfor a CTI sharing network for ICS, including the bestowal and acknowledgment of\ndata privacy, trust barriers, and security issues ingrained in this domain.",
    "descriptor": "",
    "authors": [
      "Kathy Nguyen",
      "Shantanu Pal",
      "Zahra Jadidi",
      "Ali Dorri",
      "Raja Jurdak"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.00262"
  },
  {
    "id": "arXiv:2112.00263",
    "title": "GLocal: Global Graph Reasoning and Local Structure Transfer for Person  Image Generation",
    "abstract": "In this paper, we focus on person image generation, namely, generating person\nimage under various conditions, e.g., corrupted texture or different pose. To\naddress texture occlusion and large pose misalignment in this task, previous\nworks just use the corresponding region's style to infer the occluded area and\nrely on point-wise alignment to reorganize the context texture information,\nlacking the ability to globally correlate the region-wise style codes and\npreserve the local structure of the source. To tackle these problems, we\npresent a GLocal framework to improve the occlusion-aware texture estimation by\nglobally reasoning the style inter-correlations among different semantic\nregions, which can also be employed to recover the corrupted images in texture\ninpainting. For local structural information preservation, we further extract\nthe local structure of the source image and regain it in the generated image\nvia local structure transfer. We benchmark our method to fully characterize its\nperformance on DeepFashion dataset and present extensive ablation studies that\nhighlight the novelty of our method.",
    "descriptor": "",
    "authors": [
      "Liyuan Ma",
      "Kejie Huang",
      "Dongxu Wei",
      "Haibin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00263"
  },
  {
    "id": "arXiv:2112.00265",
    "title": "Training BatchNorm Only in Neural Architecture Search and Beyond",
    "abstract": "This work investigates the usage of batch normalization in neural\narchitecture search (NAS). Specifically, Frankle et al. find that training\nBatchNorm only can achieve nontrivial performance. Furthermore, Chen et al.\nclaim that training BatchNorm only can speed up the training of the one-shot\nNAS supernet over ten times. Critically, there is no effort to understand 1)\nwhy training BatchNorm only can find the perform-well architectures with the\nreduced supernet-training time, and 2) what is the difference between the\ntrain-BN-only supernet and the standard-train supernet. We begin by showing\nthat the train-BN-only networks converge to the neural tangent kernel regime,\nobtain the same training dynamics as train all parameters theoretically. Our\nproof supports the claim to train BatchNorm only on supernet with less training\ntime. Then, we empirically disclose that train-BN-only supernet provides an\nadvantage on convolutions over other operators, cause unfair competition\nbetween architectures. This is due to only the convolution operator being\nattached with BatchNorm. Through experiments, we show that such unfairness\nmakes the search algorithm prone to select models with convolutions. To solve\nthis issue, we introduce fairness in the search space by placing a BatchNorm\nlayer on every operator. However, we observe that the performance predictor in\nChen et al. is inapplicable on the new search space. To this end, we propose a\nnovel composite performance indicator to evaluate networks from three\nperspectives: expressivity, trainability, and uncertainty, derived from the\ntheoretical property of BatchNorm. We demonstrate the effectiveness of our\napproach on multiple NAS-benchmarks (NAS-Bench101, NAS-Bench-201) and search\nspaces (DARTS search space and MobileNet search space).",
    "descriptor": "\nComments: 11 pages Technical report\n",
    "authors": [
      "Yichen Zhu",
      "Jie Du",
      "Yuqin Zhu",
      "Yi Wang",
      "Zhicai Ou",
      "Feifei Feng",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00265"
  },
  {
    "id": "arXiv:2112.00267",
    "title": "CAMA: Energy and Memory Efficient Automata Processing in  Content-Addressable Memories",
    "abstract": "Accelerating finite automata processing is critical for advancing real-time\nanalytic in pattern matching, data mining, bioinformatics, intrusion detection,\nand machine learning. Recent in-memory automata accelerators leveraging SRAMs\nand DRAMs have shown exciting improvements over conventional digital designs.\nHowever, the bit-vector representation of state transitions used by all SOTA\ndesigns is only optimal in processing worst-case completely random patterns,\nwhile a significant amount of memory and energy is wasted in running most\nreal-world benchmarks. We present CAMA, a Content-Addressable Memory (CAM)\nenabled Automata accelerator for processing homogeneous non-deterministic\nfinite automata (NFA). A radically different state representation scheme, along\nwith co-designed novel circuits and data encoding schemes, greatly reduces\nenergy, memory, and chip area for most realistic NFAs. CAMA is holistically\noptimized with the following major contributions: (1) a 16x256 8-transistor\n(8T) CAM array for state matching, replacing the 256x256 6T SRAM array or two\n16x256 6T SRAM banks in SOTA designs; (2) a novel encoding scheme that enables\ncontent searching within 8T SRAMs and adapts to different applications; (3) a\nreconfigurable and scalable architecture that improves efficiency on all tested\nbenchmarks, without losing support for any NFA that is compatible with SOTA\ndesigns; (4) an optimization framework that automates the choice of encoding\nschemes and maps a given NFA to the proposed hardware. Two versions of CAMA,\none optimized for energy (CAMA-E) and the other for throughput (CAMA-T), are\ncomprehensively evaluated in a 28nm CMOS process, and across 21 real-world and\nsynthetic benchmarks. CAMA-E achieves 2.1x, 2.8x, and 2.04x lower energy than\nCA, 2-stride Impala, and eAP. CAMA-T shows 2.68x, 3.87x and 2.62x higher\naverage compute density than 2-stride Impala, CA, and eAP.",
    "descriptor": "\nComments: This work has been accepted by IEEE International Symposium on High-Performance Computer Architecture (HPCA 2022)\n",
    "authors": [
      "Yi Huang",
      "Zhiyu Chen",
      "Dai Li",
      "Kaiyuan Yang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2112.00267"
  },
  {
    "id": "arXiv:2112.00269",
    "title": "Unequal Opportunities in Multi-hop Referral Programs",
    "abstract": "As modern social networks allow for faster and broader interactions with\nfriends and acquaintances, online referral programs that promote sales through\nexisting users are becoming increasingly popular. Because it is all too common\nthat online networks reproduce historical structural bias, members of\ndisadvantaged groups often benefit less from such referral opportunities. For\ninstance, one-hop referral programs that distribute rewards only among pairs of\nfriends or followers may offer less rewards and opportunities to minorities in\nnetworks where it was proved that their degrees is statistically smaller. Here,\nwe examine the fairness of general referral programs, increasingly popular\nforms of marketing in which an existing referrer is encouraged to initiate the\nrecruitment of new referred users over multiple hops. While this clearly\nexpands opportunities for rewards, it remains unclear whether it helps\naddressing fairness concerns, or make them worse. We show, from studying 4\nreal-world networks and performing theoretical analysis on networks created\nwith minority-majority affiliations and homophily, that the change of bias in\nmulti-hop referral programs highly depends on the network structures and the\nreferral strategies. Specifically, under three different constrained referral\nstrategies which limit the number of referrals each person can share to a fixed\nnumber, we show that even with no explicit intention to discriminate and\nwithout access to sensitive attributes such as gender and race, certain\nreferral strategies can still amplify the structural biases further when higher\nhops are allowed. Moreover, when there is no constraint on the number of\nreferrals each person can distribute and when the effect of referral strategies\nis removed, we prove a precise condition under which the bias in 1-hop referral\nprograms is amplified in higher-hop referral programs.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Yiguang Zhang",
      "Augustin Chaintreau"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.00269"
  },
  {
    "id": "arXiv:2112.00270",
    "title": "An Enhanced Decoding Algorithm for Coded Compressed Sensing with  Applications to Unsourced Random Access",
    "abstract": "Unsourced random access (URA) has emerged as a pragmatic framework for\nnext-generation distributed sensor networks. Within URA, concatenated coding\nstructures are often employed to ensure that the central base station can\naccurately recover the set of sent codewords during a given transmission\nperiod. Many URA algorithms employ independent inner and outer decoders, which\ncan help reduce computational complexity at the expense of a decay in\nperformance. In this article, an enhanced decoding algorithm is presented for a\nconcatenated coding structure consisting of a wide range of inner codes and an\nouter tree-based code. It is shown that this algorithmic enhancement has the\npotential to simultaneously improve error performance and decrease the\ncomputational complexity of the decoder. This enhanced decoding algorithm is\napplied to two existing URA algorithms and the performance benefits of the\nalgorithm are characterized. Findings are supported by numerical simulations.",
    "descriptor": "\nComments: Submitted to MDPI Sensors\n",
    "authors": [
      "Vamsi K. Amalladinne",
      "Jamison R. Ebert",
      "Jean-Francois Chamberland",
      "Krishna R. Narayanan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.00270"
  },
  {
    "id": "arXiv:2112.00273",
    "title": "Concurrent Transmission for Multi-Robot Coordination",
    "abstract": "An efficient communication mechanism forms the backbone for any multi-robot\nsystem to achieve fruitful collaboration and coordination. Limitation in the\nexisting asynchronous transmission based strategies in fast dissemination and\naggregation compels the designers to prune down such requirements as much as\npossible. This also restricts the possible application areas of mobile\nmulti-robot systems. In this work, we introduce concurrent transmission based\nstrategy as an alternative. Despite the commonly found difficulties in\nconcurrent transmission such as microsecond level time synchronization,\nhardware heterogeneity, etc., we demonstrate how it can be exploited for\nmulti-robot systems. We propose a split architecture where the two major\nactivities - communication and computation are carried out independently and\ncoordinate through periodic interactions. The proposed split architecture is\napplied on a custom build full networked control system consisting of five\ntwo-wheel differential drive mobile robots having heterogeneous architecture.\nWe use the proposed design in a leader-follower setting for coordinated dynamic\nspeed variation as well as the independent formation of various shapes.\nExperiments show a centimeter-level spatial and millisecond-level temporal\naccuracy while spending very low radio duty-cycling over multi-hop\ncommunication under a wide testing area.",
    "descriptor": "\nComments: Accepted in Robocom 2022 in conjunction with IEEE CCNC 2022\n",
    "authors": [
      "Sourabha Bharadwaj",
      "Karunakar Gonabattula",
      "Sudipta Saha",
      "Chayan Sarkar",
      "Rekha Raja"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.00273"
  },
  {
    "id": "arXiv:2112.00275",
    "title": "Learning from Mistakes based on Class Weighting with Application to  Neural Architecture Search",
    "abstract": "Learning from mistakes is an effective learning approach widely used in human\nlearning, where a learner pays greater focus on mistakes to circumvent them in\nthe future. It aids in improving the overall learning outcomes. In this work,\nwe aim to investigate how effectively this exceptional learning ability can be\nused to improve machine learning models as well. We propose a simple and\neffective multi-level optimization framework called learning from mistakes\n(LFM), inspired by mistake-driven learning to train better machine learning\nmodels. Our LFM framework consists of a formulation involving three learning\nstages. The primary objective is to train a model to perform effectively on\ntarget tasks by using a re-weighting technique to prevent similar mistakes in\nthe future. In this formulation, we learn the class weights by minimizing the\nvalidation loss of the model and re-train the model with the synthetic data\nfrom the image generator weighted by class-wise performance and real data. We\napply our LFM framework for differential architecture search methods on image\nclassification datasets such as CIFAR and ImageNet, where the results\ndemonstrate the effectiveness of our proposed strategy.",
    "descriptor": "",
    "authors": [
      "Jay Gala",
      "Pengtao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00275"
  },
  {
    "id": "arXiv:2112.00277",
    "title": "MeSH Term Suggestion for Systematic Review Literature Search",
    "abstract": "High-quality medical systematic reviews require comprehensive literature\nsearches to ensure the recommendations and outcomes are sufficiently reliable.\nIndeed, searching for relevant medical literature is a key phase in\nconstructing systematic reviews and often involves domain (medical researchers)\nand search (information specialists) experts in developing the search queries.\nQueries in this context are highly complex, based on Boolean logic, include\nfree-text terms and index terms from standardised terminologies (e.g., MeSH),\nand are difficult and time-consuming to build. The use of MeSH terms, in\nparticular, has been shown to improve the quality of the search results.\nHowever, identifying the correct MeSH terms to include in a query is difficult:\ninformation experts are often unfamiliar with the MeSH database and unsure\nabout the appropriateness of MeSH terms for a query. Naturally, the full value\nof the MeSH terminology is often not fully exploited.\nThis paper investigates methods to suggest MeSH terms based on an initial\nBoolean query that includes only free-text terms. These methods promise to\nautomatically identify highly effective MeSH terms for inclusion in a\nsystematic review query. Our study contributes an empirical evaluation of\nseveral MeSH term suggestion methods. We perform an extensive analysis of the\nretrieval, ranking, and refinement of MeSH term suggestions for each method and\nhow these suggestions impact the effectiveness of Boolean queries.",
    "descriptor": "\nComments: To be published in Australasian Document Computing Symposium 2021, Melbourne, Australia\n",
    "authors": [
      "Shuai Wang",
      "Hang Li",
      "Harrisen Scells",
      "Daniel Locke",
      "Guido Zuccon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.00277"
  },
  {
    "id": "arXiv:2112.00279",
    "title": "A Barrier Pair Method for Safe Human-Robot Shared Autonomy",
    "abstract": "Shared autonomy provides a framework where a human and an automated system,\nsuch as a robot, jointly control the system's behavior, enabling an effective\nsolution for various applications, including human-robot interaction. However,\na challenging problem in shared autonomy is safety because the human input may\nbe unknown and unpredictable, which affects the robot's safety constraints. If\nthe human input is a force applied through physical contact with the robot, it\nalso alters the robot's behavior to maintain safety. We address the safety\nissue of shared autonomy in real-time applications by proposing a two-layer\ncontrol framework. In the first layer, we use the history of human input\nmeasurements to infer what the human wants the robot to do and define the\nrobot's safety constraints according to that inference. In the second layer, we\nformulate a rapidly-exploring random tree of barrier pairs, with each barrier\npair composed of a barrier function and a controller. Using the controllers in\nthese barrier pairs, the robot is able to maintain its safe operation under the\nintervention from the human input. This proposed control framework allows the\nrobot to assist the human while preventing them from encountering safety\nissues. We demonstrate the proposed control framework on a simulation of a\ntwo-linkage manipulator robot.",
    "descriptor": "\nComments: Accepted in Proceedings of the 60th IEEE Conference on Decision and Control\n",
    "authors": [
      "Binghan He",
      "Mahsa Ghasemi",
      "Ufuk Topcu",
      "Luis Sentis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.00279"
  },
  {
    "id": "arXiv:2112.00281",
    "title": "FDA-GAN: Flow-based Dual Attention GAN for Human Pose Transfer",
    "abstract": "Human pose transfer aims at transferring the appearance of the source person\nto the target pose. Existing methods utilizing flow-based warping for non-rigid\nhuman image generation have achieved great success. However, they fail to\npreserve the appearance details in synthesized images since the spatial\ncorrelation between the source and target is not fully exploited. To this end,\nwe propose the Flow-based Dual Attention GAN (FDA-GAN) to apply occlusion- and\ndeformation-aware feature fusion for higher generation quality. Specifically,\ndeformable local attention and flow similarity attention, constituting the dual\nattention mechanism, can derive the output features responsible for deformable-\nand occlusion-aware fusion, respectively. Besides, to maintain the pose and\nglobal position consistency in transferring, we design a pose normalization\nnetwork for learning adaptive normalization from the target pose to the source\nperson. Both qualitative and quantitative results show that our method\noutperforms state-of-the-art models in public iPER and DeepFashion datasets.",
    "descriptor": "",
    "authors": [
      "Liyuan Ma",
      "Kejie Huang",
      "Dongxu Wei",
      "Zhaoyan Ming",
      "Haibin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00281"
  },
  {
    "id": "arXiv:2112.00283",
    "title": "Wiki to Automotive: Understanding the Distribution Shift and its impact  on Named Entity Recognition",
    "abstract": "While transfer learning has become a ubiquitous technique used across Natural\nLanguage Processing (NLP) tasks, it is often unable to replicate the\nperformance of pre-trained models on text of niche domains like Automotive. In\nthis paper we aim to understand the main characteristics of the distribution\nshift with automotive domain text (describing technical functionalities such as\nCruise Control) and attempt to explain the potential reasons for the gap in\nperformance. We focus on performing the Named Entity Recognition (NER) task as\nit requires strong lexical, syntactic and semantic understanding by the model.\nOur experiments with 2 different encoders, namely BERT-Base-Uncased and\nSciBERT-Base-Scivocab-Uncased have lead to interesting findings that showed: 1)\nThe performance of SciBERT is better than BERT when used for automotive domain,\n2) Fine-tuning the language models with automotive domain text did not make\nsignificant improvements to the NER performance, 3) The distribution shift is\nchallenging as it is characterized by lack of repeating contexts, sparseness of\nentities, large number of Out-Of-Vocabulary (OOV) words and class overlap due\nto domain specific nuances.",
    "descriptor": "\nComments: 6 pages, 1 figure\n",
    "authors": [
      "Anmol Nayak",
      "Hari Prasad Timmapathini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00283"
  },
  {
    "id": "arXiv:2112.00284",
    "title": "Interactive Model with Structural Loss for Language-based Abductive  Reasoning",
    "abstract": "The abductive natural language inference task ($\\alpha$NLI) is proposed to\ninfer the most plausible explanation between the cause and the event. In the\n$\\alpha$NLI task, two observations are given, and the most plausible hypothesis\nis asked to pick out from the candidates. Existing methods model the relation\nbetween each candidate hypothesis separately and penalize the inference network\nuniformly. In this paper, we argue that it is unnecessary to distinguish the\nreasoning abilities among correct hypotheses; and similarly, all wrong\nhypotheses contribute the same when explaining the reasons of the observations.\nTherefore, we propose to group instead of ranking the hypotheses and design a\nstructural loss called ``joint softmax focal loss'' in this paper. Based on the\nobservation that the hypotheses are generally semantically related, we have\ndesigned a novel interactive language model aiming at exploiting the rich\ninteraction among competing hypotheses. We name this new model for $\\alpha$NLI:\nInteractive Model with Structural Loss (IMSL). The experimental results show\nthat our IMSL has achieved the highest performance on the RoBERTa-large\npretrained model, with ACC and AUC results increased by about 1\\% and 5\\%\nrespectively.",
    "descriptor": "",
    "authors": [
      "Linhao Li",
      "Ming Xu",
      "Yongfeng Dong",
      "Xin Li",
      "Ao Wang",
      "Qinghua Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00284"
  },
  {
    "id": "arXiv:2112.00286",
    "title": "Conflict-free Collaborative Set Sharing for Distributed Systems",
    "abstract": "Collaborative Data Sharing is widely noticed to be essential for distributed\nsystems. Among several proposed strategies, conflict-free techniques are\nconsidered useful for serverless concurrent systems. They aim at making shared\ndata be consistent between peers in such a way that their local data do not\nbecome equal at once, but they arrive at the same data eventually when no\nupdates occur in any peer. Although the Conflict-free Replicated Data Type\n(CRDT) approach could be used in data sharing as well, it puts restrictions on\navailable operations so as to concurrent updates never cause conflicts. Even\nfor sets, popular operations such as insertion and deletion are not freely\nused, for example. We propose a novel scheme for Conflict-free Collaborative\nSet Sharing that allows both insertion and deletion operations. It will provide\na new synchronization method for data sharing and gives a fresh insight into\ndesigning conflict-free replicated data types. We might consider that this\nbecomes a substitute for CRDTs.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Masato Takeichi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.00286"
  },
  {
    "id": "arXiv:2112.00288",
    "title": "Operation-based Collaborative Data Sharing for Distributed Systems",
    "abstract": "Collaborative Data Sharing raises a fundamental issue in distributed systems.\nSeveral strategies have been proposed for making shared data consistent between\npeers in such a way that the shared part of their local data become equal. Most\nof the proposals rely on state-based semantics. But this suffers from a lack of\ndescriptiveness in conflict-free features of synchronization required for\nflexible network connections. Recent applications tend to use non-permanent\nconnection with mobile devices or allow temporary breakaways from the system,\nfor example. To settle ourselves in conflict-free data sharing, we propose a\nnovel scheme \"Operation-based Collaborative Data Sharing\" that enables\nconflict-free strategies for synchronization based on operational semantics.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Masato Takeichi"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.00288"
  },
  {
    "id": "arXiv:2112.00289",
    "title": "Point Cloud Segmentation Using Sparse Temporal Local Attention",
    "abstract": "Point clouds are a key modality used for perception in autonomous vehicles,\nproviding the means for a robust geometric understanding of the surrounding\nenvironment. However despite the sensor outputs from autonomous vehicles being\nnaturally temporal in nature, there is still limited exploration of exploiting\npoint cloud sequences for 3D seman-tic segmentation. In this paper we propose a\nnovel Sparse Temporal Local Attention (STELA) module which aggregates\nintermediate features from a local neighbourhood in previous point cloud frames\nto provide a rich temporal context to the decoder. Using the sparse local\nneighbourhood enables our approach to gather features more flexibly than those\nwhich directly match point features, and more efficiently than those which\nperform expensive global attention over the whole point cloud frame. We achieve\na competitive mIoU of 64.3% on the SemanticKitti dataset, and demonstrate\nsignificant improvement over the single-frame baseline in our ablation studies.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Joshua Knights",
      "Peyman Moghadam",
      "Clinton Fookes",
      "Sridha Sridharan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00289"
  },
  {
    "id": "arXiv:2112.00290",
    "title": "Unsupervised Statistical Learning for Die Analysis in Ancient  Numismatics",
    "abstract": "Die analysis is an essential numismatic method, and an important tool of\nancient economic history. Yet, manual die studies are too labor-intensive to\ncomprehensively study large coinages such as those of the Roman Empire. We\naddress this problem by proposing a model for unsupervised computational die\nanalysis, which can reduce the time investment necessary for large-scale die\nstudies by several orders of magnitude, in many cases from years to weeks. From\na computer vision viewpoint, die studies present a challenging unsupervised\nclustering problem, because they involve an unknown and large number of highly\nsimilar semantic classes of imbalanced sizes. We address these issues through\ndetermining dissimilarities between coin faces derived from specifically\ndevised Gaussian process-based keypoint features in a Bayesian distance\nclustering framework. The efficacy of our method is demonstrated through an\nanalysis of 1135 Roman silver coins struck between 64-66 C.E..",
    "descriptor": "",
    "authors": [
      "Andreas Heinecke",
      "Emanuel Mayer",
      "Abhinav Natarajan",
      "Yoonju Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00290"
  },
  {
    "id": "arXiv:2112.00291",
    "title": "Bumblebee: A Path Towards Fully Autonomous Robotic Vine Pruning",
    "abstract": "Dormant season grapevine pruning requires skilled seasonal workers during the\nwinter season which are becoming less available. As workers hasten to prune\nmore vines in less time amid to the short-term seasonal hiring culture and low\nwages, vines are often pruned inconsistently leading to imbalanced grapevines.\nIn addition to this, currently existing mechanical methods cannot selectively\nprune grapevines and manual follow-up operations are often required that\nfurther increase production cost. In this paper, we present the design and\nfield evaluation of a rugged, and fully autonomous robot for end-to-end pruning\nof dormant season grapevines. The proposed design incorporates novel camera\nsystems, a kinematically redundant manipulator, a ground robot, and novel\nalgorithms in the perception system. The presented research prototype robot\nsystem was able to spur prune a row of vines from both sides completely in 213\nsec/vine with a total pruning accuracy of 87%. Initial field tests of the\nautonomous system in a commercial vineyard have shown significant variability\nreduction in dormant season pruning when compared to mechanical pre-pruning\ntrials. The design approach, system components, lessons learned, future\nenhancements as well as a brief economic analysis are described in the\nmanuscript.",
    "descriptor": "\nComments: 35 pages, 23 images\n",
    "authors": [
      "Abhisesh Silwal",
      "Francisco Yandun",
      "Anjana Nellithimaru",
      "Terry Bates",
      "George Kantor"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00291"
  },
  {
    "id": "arXiv:2112.00294",
    "title": "Mixed displacement-pressure-phase field framework for finite strain  fracture of nearly incompressible hyperelastic materials",
    "abstract": "The favored phase field method (PFM) has encountered challenges in the finite\nstrain fracture modeling of nearly or truly incompressible hyperelastic\nmaterials. We identified that the underlying cause lies in the innate\ncontradiction between incompressibility and smeared crack opening. Drawing on\nthe stiffness-degradation idea in PFM, we resolved this contradiction through\nloosening incompressible constraint of the damaged phase without affecting the\nincompressibility of intact material. By modifying the perturbed Lagrangian\napproach, we derived a novel mixed formulation. In numerical aspects, the\nfinite element discretization uses the classical Q1/P0 and high-order P2/P1\nschemes, respectively. To ease the mesh distortion at large strains, an\nadaptive mesh deletion technology is also developed. The validity and\nrobustness of the proposed mixed framework are corroborated by four\nrepresentative numerical examples. By comparing the performance of Q1/P0 and\nP2/P1, we conclude that the Q1/P0 formulation is a better choice for finite\nstrain fracture in nearly incompressible cases. Moreover, the numerical\nexamples also show that the combination of the proposed framework and\nmethodology has vast potential in simulating complex peeling and tearing\nproblems",
    "descriptor": "",
    "authors": [
      "Fucheng Tian",
      "Jun Zeng",
      "Mengnan Zhang",
      "Liangbin Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Soft Condensed Matter (cond-mat.soft)"
    ],
    "url": "https://arxiv.org/abs/2112.00294"
  },
  {
    "id": "arXiv:2112.00295",
    "title": "Multiple Fusion Adaptation: A Strong Framework for Unsupervised Semantic  Segmentation Adaptation",
    "abstract": "This paper challenges the cross-domain semantic segmentation task, aiming to\nimprove the segmentation accuracy on the unlabeled target domain without\nincurring additional annotation. Using the pseudo-label-based unsupervised\ndomain adaptation (UDA) pipeline, we propose a novel and effective Multiple\nFusion Adaptation (MFA) method. MFA basically considers three parallel\ninformation fusion strategies, i.e., the cross-model fusion, temporal fusion\nand a novel online-offline pseudo label fusion. Specifically, the\nonline-offline pseudo label fusion encourages the adaptive training to pay\nadditional attention to difficult regions that are easily ignored by offline\npseudo labels, therefore retaining more informative details. While the other\ntwo fusion strategies may look standard, MFA pays significant efforts to raise\nthe efficiency and effectiveness for integration, and succeeds in injecting all\nthe three strategies into a unified framework. Experiments on two widely used\nbenchmarks, i.e., GTA5-to-Cityscapes and SYNTHIA-to-Cityscapes, show that our\nmethod significantly improves the semantic segmentation adaptation, and sets up\nnew state of the art (58.2% and 62.5% mIoU, respectively). The code will be\navailable at https://github.com/KaiiZhang/MFA.",
    "descriptor": "\nComments: 13 pages, 2 figures, submitted to BMVC2021\n",
    "authors": [
      "Kai Zhang",
      "Yifan Sun",
      "Rui Wang",
      "Haichang Li",
      "Xiaohui Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00295"
  },
  {
    "id": "arXiv:2112.00298",
    "title": "Exploring Social Posterior Collapse in Variational Autoencoder for  Interaction Modeling",
    "abstract": "Multi-agent behavior modeling and trajectory forecasting are crucial for the\nsafe navigation of autonomous agents in interactive scenarios. Variational\nAutoencoder (VAE) has been widely applied in multi-agent interaction modeling\nto generate diverse behavior and learn a low-dimensional representation for\ninteracting systems. However, existing literature did not formally discuss if a\nVAE-based model can properly encode interaction into its latent space. In this\nwork, we argue that one of the typical formulations of VAEs in multi-agent\nmodeling suffers from an issue we refer to as social posterior collapse, i.e.,\nthe model is prone to ignoring historical social context when predicting the\nfuture trajectory of an agent. It could cause significant prediction errors and\npoor generalization performance. We analyze the reason behind this\nunder-explored phenomenon and propose several measures to tackle it. Afterward,\nwe implement the proposed framework and experiment on real-world datasets for\nmulti-agent trajectory prediction. In particular, we propose a novel sparse\ngraph attention message-passing (sparse-GAMP) layer, which helps us detect\nsocial posterior collapse in our experiments. In the experiments, we verify\nthat social posterior collapse indeed occurs. Also, the proposed measures are\neffective in alleviating the issue. As a result, the model attains better\ngeneralization performance when historical social context is informative for\nprediction.",
    "descriptor": "\nComments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Chen Tang",
      "Wei Zhan",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.00298"
  },
  {
    "id": "arXiv:2112.00299",
    "title": "STAR-RISs: A Correlated T&R Phase-Shift Model and Practical Phase-Shift  Configuration Strategies",
    "abstract": "A correlated transmission and reflection (T&R) phase-shift model is proposed\nfor passive lossless simultaneously transmitting and reflecting reconfigurable\nintelligent surfaces (STAR-RISs). A STAR-RIS-aided two-user downlink\ncommunication system is investigated for both orthogonal multiple access (OMA)\nand non-orthogonal multiple access (NOMA). To evaluate the impact of the\ncorrelated T&R phase-shift model on the communication performance, three\nphase-shift configuration strategies are developed, namely the\nprimary-secondary phase-shift configuration (PS-PSC), the diversity preserving\nphase-shift configuration (DP-PSC), and the T/R-group phase-shift configuration\n(TR-PSC) strategies. Furthermore, we derive the outage probabilities for the\nthree proposed phase-shift configuration strategies as well as for those of the\nrandom phase-shift configuration and the independent phase-shift model, which\nconstitute performance lower and upper bounds, respectively. Then, the\ndiversity order of each strategy is investigated based on the obtained\nanalytical results. It is shown that the proposed DP-PSC strategy achieves full\ndiversity order simultaneously for users located on both sides of the STAR-RIS.\nMoreover, power scaling laws are derived for the three proposed strategies and\nfor the random phase-shift configuration. Numerical simulations reveal a\nperformance gain if the users on both sides of the STAR-RIS are served by NOMA\ninstead of OMA. Moreover, it is shown that the proposed DP-PSC strategy yields\nthe same diversity order as achieved by STAR-RISs under the independent\nphase-shift model and a comparable power scaling law with only 4 dB reduction\nin received power.",
    "descriptor": "\nComments: 31 pages, 9 figures, submitted to IEEE journals for possible publication\n",
    "authors": [
      "Jiaqi Xu",
      "Yuanwei Liu",
      "Xidong Mu",
      "Robert Schober",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.00299"
  },
  {
    "id": "arXiv:2112.00301",
    "title": "Uncertainty in Criminal Justice Algorithms: simulation studies of the  Pennsylvania Additive Classification Tool",
    "abstract": "Much attention has been paid to algorithms related to sentencing, the setting\nof bail, parole decisions and recidivism while less attention has been paid to\ncarceral algorithms, those algorithms used to determine an incarcerated\nindividual's lived experience. In this paper we study one such algorithm, the\nPennsylvania Additive Classification Tool (PACT) that assigns custody levels to\nincarcerated individuals. We analyze the PACT in ways that criminal justice\nalgorithms are often analyzed: namely, we train an accurate machine learning\nmodel for the PACT; we study its fairness across sex, age and race; and we\ndetermine which features are most important. In addition to these conventional\ncomputations, we propose and carry out some new ways to study such algorithms.\nInstead of focusing on the outcomes themselves, we propose shifting our\nattention to the variability in the outcomes, especially because many carceral\nalgorithms are used repeatedly and there can be a propagation of uncertainty.\nBy carrying out several simulations of assigning custody levels, we shine light\non problematic aspects of tools like the PACT.",
    "descriptor": "\nComments: 21 pages, 11 figures, 6 tables\n",
    "authors": [
      "Swarup Dhar",
      "Vanessa Massaro",
      "Darakhshan Mir",
      "Nathan C. Ryan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.00301"
  },
  {
    "id": "arXiv:2112.00302",
    "title": "Graph Convolutional Module for Temporal Action Localization in Videos",
    "abstract": "Temporal action localization has long been researched in computer vision.\nExisting state-of-the-art action localization methods divide each video into\nmultiple action units (i.e., proposals in two-stage methods and segments in\none-stage methods) and then perform action recognition/regression on each of\nthem individually, without explicitly exploiting their relations during\nlearning. In this paper, we claim that the relations between action units play\nan important role in action localization, and a more powerful action detector\nshould not only capture the local content of each action unit but also allow a\nwider field of view on the context related to it. To this end, we propose a\ngeneral graph convolutional module (GCM) that can be easily plugged into\nexisting action localization methods, including two-stage and one-stage\nparadigms. To be specific, we first construct a graph, where each action unit\nis represented as a node and their relations between two action units as an\nedge. Here, we use two types of relations, one for capturing the temporal\nconnections between different action units, and the other one for\ncharacterizing their semantic relationship. Particularly for the temporal\nconnections in two-stage methods, we further explore two different kinds of\nedges, one connecting the overlapping action units and the other one connecting\nsurrounding but disjointed units. Upon the graph we built, we then apply graph\nconvolutional networks (GCNs) to model the relations among different action\nunits, which is able to learn more informative representations to enhance\naction localization. Experimental results show that our GCM consistently\nimproves the performance of existing action localization methods, including\ntwo-stage methods (e.g., CBR and R-C3D) and one-stage methods (e.g., D-SSAD),\nverifying the generality and effectiveness of our GCM.",
    "descriptor": "\nComments: Accepted by T-PAMI\n",
    "authors": [
      "Runhao Zeng",
      "Wenbing Huang",
      "Mingkui Tan",
      "Yu Rong",
      "Peilin Zhao",
      "Junzhou Huang",
      "Chuang Gan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00302"
  },
  {
    "id": "arXiv:2112.00304",
    "title": "Software Variants for Hardware Trojan Detection and Resilience in COTS  Processors",
    "abstract": "The commercial off-the-shelf (COTS) component based ecosystem provides an\nattractive system design paradigm due to the drastic reduction in development\ntime and cost compared to custom solutions. However, it brings in a growing\nconcern of trustworthiness arising from the possibility of embedded malicious\nlogic, or hardware Trojans in COTS components. Existing trust-verification\napproaches are typically not applicable to COTS hardware due to the absence of\ngolden models and the lack of observability of internal signals. In this work,\nwe propose a novel approach for runtime Trojan detection and resilience in\nuntrusted COTS processors through judicious modifications in software. The\nproposed approach does not rely on any hardware redundancy or architectural\nmodification and hence seamlessly integrates with the COTS-based system design\nprocess. Trojan resilience is achieved through the execution of multiple\nfunctionally equivalent software variants. We have developed and implemented a\nsolution for compiler-based automatic generation of program variants,\nmetric-guided selection of variants, and their integration in a single\nexecutable. To evaluate the proposed approach, we first analyzed the\neffectiveness of program variants in avoiding the activation of a random pool\nof Trojans. By implementing several Trojans in an OpenRISC 1000 processor, we\nanalyzed the detectability and resilience during Trojan activation in both\nsingle and multiple variants. We also present delay and code size overhead for\nthe automatically generated variants for several programs and discuss future\nresearch directions to reduce the overhead.",
    "descriptor": "",
    "authors": [
      "Mahmudul Hasan",
      "Jonathan Cruz",
      "Prabuddha Chakraborty",
      "Swarup Bhunia",
      "Tamzidul Hoque"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.00304"
  },
  {
    "id": "arXiv:2112.00305",
    "title": "Forward Operator Estimation in Generative Models with Kernel Transfer  Operators",
    "abstract": "Generative models which use explicit density modeling (e.g., variational\nautoencoders, flow-based generative models) involve finding a mapping from a\nknown distribution, e.g. Gaussian, to the unknown input distribution. This\noften requires searching over a class of non-linear functions (e.g.,\nrepresentable by a deep neural network). While effective in practice, the\nassociated runtime/memory costs can increase rapidly, usually as a function of\nthe performance desired in an application. We propose a much cheaper (and\nsimpler) strategy to estimate this mapping based on adapting known results in\nkernel transfer operators. We show that our formulation enables highly\nefficient distribution approximation and sampling, and offers surprisingly good\nempirical performance that compares favorably with powerful baselines, but with\nsignificant runtime savings. We show that the algorithm also performs well in\nsmall sample size settings (in brain imaging).",
    "descriptor": "",
    "authors": [
      "Zhichun Huang",
      "Rudrasis Chakraborty",
      "Vikas Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00305"
  },
  {
    "id": "arXiv:2112.00312",
    "title": "Experimental Validation of Multi-lane Formation Control for Connected  and Automated Vehicles in Multiple Scenarios",
    "abstract": "Formation control methods of connected and automated vehicles have been\nproposed to smoothly switch the structure of vehicular formations in different\nscenarios. In the previous research, simulations are often conducted to verify\nthe performance of formation control methods. This paper presents the\nexperimental results of multi-lane formation control for connected and\nautomated vehicles. The coordinated formation control framework and specific\nmethods utilized for different scenarios are introduced. The details of\nexperimental platform and vehicle control strategy is provided. Simulations and\nexperiments are conducted in different scenarios, and the results indicate that\nthe formation control method is applicable to multiple traffic scenarios and\nable to improve formation-structure-switching efficiency compared with\nbenchmark methods.",
    "descriptor": "",
    "authors": [
      "Mengchi Cai",
      "Qing Xu",
      "Chunying Yang",
      "Jianghong Dong",
      "Chaoyi Chen",
      "Jiawei Wang",
      "Jianqiang Wang",
      "Keqiang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00312"
  },
  {
    "id": "arXiv:2112.00317",
    "title": "Unleashing the Potential of Unsupervised Pre-Training with  Intra-Identity Regularization for Person Re-Identification",
    "abstract": "Existing person re-identification (ReID) methods typically directly load the\npre-trained ImageNet weights for initialization. However, as a fine-grained\nclassification task, ReID is more challenging and exists a large domain gap\nbetween ImageNet classification. Inspired by the great success of\nself-supervised representation learning with contrastive objectives, in this\npaper, we design an Unsupervised Pre-training framework for ReID based on the\ncontrastive learning (CL) pipeline, dubbed UP-ReID. During the pre-training, we\nattempt to address two critical issues for learning fine-grained ReID features:\n(1) the augmentations in CL pipeline may distort the discriminative clues in\nperson images. (2) the fine-grained local features of person images are not\nfully-explored. Therefore, we introduce an intra-identity\n(I$^2$-)regularization in the UP-ReID, which is instantiated as two constraints\ncoming from global image aspect and local patch aspect: a global consistency is\nenforced between augmented and original person images to increase robustness to\naugmentation, while an intrinsic contrastive constraint among local patches of\neach image is employed to fully explore the local discriminative clues.\nExtensive experiments on multiple popular Re-ID datasets, including PersonX,\nMarket1501, CUHK03, and MSMT17, demonstrate that our UP-ReID pre-trained model\ncan significantly benefit the downstream ReID fine-tuning and achieve\nstate-of-the-art performance. Codes and models will be released to\nhttps://github.com/Frost-Yang-99/UP-ReID.",
    "descriptor": "\nComments: Technical report, code: this https URL\n",
    "authors": [
      "Zizheng Yang",
      "Xin Jin",
      "Kecheng Zheng",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.00317"
  },
  {
    "id": "arXiv:2112.00319",
    "title": "Object-Aware Cropping for Self-Supervised Learning",
    "abstract": "A core component of the recent success of self-supervised learning is\ncropping data augmentation, which selects sub-regions of an image to be used as\npositive views in the self-supervised loss. The underlying assumption is that\nrandomly cropped and resized regions of a given image share information about\nthe objects of interest, which the learned representation will capture. This\nassumption is mostly satisfied in datasets such as ImageNet where there is a\nlarge, centered object, which is highly likely to be present in random crops of\nthe full image. However, in other datasets such as OpenImages or COCO, which\nare more representative of real world uncurated data, there are typically\nmultiple small objects in an image. In this work, we show that self-supervised\nlearning based on the usual random cropping performs poorly on such datasets.\nWe propose replacing one or both of the random crops with crops obtained from\nan object proposal algorithm. This encourages the model to learn both object\nand scene level semantic representations. Using this approach, which we call\nobject-aware cropping, results in significant improvements over scene cropping\non classification and object detection benchmarks. For example, on OpenImages,\nour approach achieves an improvement of 8.8% mAP over random scene-level\ncropping using MoCo-v2 based pre-training. We also show significant\nimprovements on COCO and PASCAL-VOC object detection and segmentation tasks\nover the state-of-the-art self-supervised learning approaches. Our approach is\nefficient, simple and general, and can be used in most existing contrastive and\nnon-contrastive self-supervised learning frameworks.",
    "descriptor": "",
    "authors": [
      "Shlok Mishra",
      "Anshul Shah",
      "Ankan Bansal",
      "Abhyuday Jagannatha",
      "Abhishek Sharma",
      "David Jacobs",
      "Dilip Krishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00319"
  },
  {
    "id": "arXiv:2112.00320",
    "title": "Multistage Online Maxmin Allocation of Indivisible Entities",
    "abstract": "We consider an online allocation problem that involves a set $P$ of $n$\nplayers and a set $E$ of $m$ indivisible entities over discrete time steps\n$1,2,\\ldots,\\tau$. At each time step $t \\in [1,\\tau]$, for every entity $e \\in\nE$, there is a restriction list $L_t(e)$ that prescribes the subset of players\nto whom $e$ can be assigned and a non-negative value $v_t(e,p)$ of $e$ to every\nplayer $p \\in P$. The sets $P$ and $E$ are fixed beforehand. The sets\n$L_t(\\cdot)$ and values $v_t(\\cdot,\\cdot)$ are given in an online fashion. An\nallocation is a distribution of $E$ among $P$, and we are interested in the\nminimum total value of the entities received by a player according to the\nallocation. In the static case, it is NP-hard to find an optimal allocation the\nmaximizes this minimum value. On the other hand, $\\rho$-approximation\nalgorithms have been developed for certain values of $\\rho \\in (0,1]$. We\npropose a $w$-lookahead algorithm for the multistage online maxmin allocation\nproblem for any fixed $w \\geq 1$ in which the restriction lists and values of\nentities may change between time steps, and there is a fixed stability reward\nfor an entity to be assigned to the same player from one time step to the next.\nThe objective is to maximize the sum of the minimum values and stability\nrewards over the time steps $1, 2, \\ldots, \\tau$. Our algorithm achieves a\ncompetitive ratio of $(1-c)\\rho$, where $c$ is the positive root of the\nequation $wc^2 = \\rho (w+1)(1-c)$. When $w = 1$, it is greater than\n$\\frac{\\rho}{4\\rho+2} + \\frac{\\rho}{10}$, which improves upon the previous\nratio of $\\frac{\\rho}{4\\rho+2 - 2^{1-\\tau}(2\\rho+1)}$ obtained for the case of\n1-lookahead.",
    "descriptor": "",
    "authors": [
      "Siu-Wing Cheng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.00320"
  },
  {
    "id": "arXiv:2112.00322",
    "title": "FCAF3D: Fully Convolutional Anchor-Free 3D Object Detection",
    "abstract": "Recently, promising applications in robotics and augmented reality have\nattracted considerable attention to 3D object detection from point clouds. In\nthis paper, we present FCAF3D - a first-in-class fully convolutional\nanchor-free indoor 3D object detection method. It is a simple yet effective\nmethod that uses a voxel representation of a point cloud and processes voxels\nwith sparse convolutions. FCAF3D can handle large-scale scenes with minimal\nruntime through a single fully convolutional feed-forward pass. Existing 3D\nobject detection methods make prior assumptions on the geometry of objects, and\nwe argue that it limits their generalization ability. To get rid of any prior\nassumptions, we propose a novel parametrization of oriented bounding boxes that\nallows obtaining better results in a purely data-driven way. The proposed\nmethod achieves state-of-the-art 3D object detection results in terms of\nmAP@0.5 on ScanNet V2 (+4.5), SUN RGB-D (+3.5), and S3DIS (+20.5) datasets. The\ncode and models are available at https://github.com/samsunglabs/fcaf3d.",
    "descriptor": "",
    "authors": [
      "Danila Rukhovich",
      "Anna Vorontsova",
      "Anton Konushin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00322"
  },
  {
    "id": "arXiv:2112.00323",
    "title": "Push Stricter to Decide Better: A Class-Conditional Feature Adaptive  Framework for Improving Adversarial Robustness",
    "abstract": "In response to the threat of adversarial examples, adversarial training\nprovides an attractive option for enhancing the model robustness by training\nmodels on online-augmented adversarial examples. However, most of the existing\nadversarial training methods focus on improving the robust accuracy by\nstrengthening the adversarial examples but neglecting the increasing shift\nbetween natural data and adversarial examples, leading to a dramatic decrease\nin natural accuracy. To maintain the trade-off between natural and robust\naccuracy, we alleviate the shift from the perspective of feature adaption and\npropose a Feature Adaptive Adversarial Training (FAAT) optimizing the\nclass-conditional feature adaption across natural data and adversarial\nexamples. Specifically, we propose to incorporate a class-conditional\ndiscriminator to encourage the features become (1) class-discriminative and (2)\ninvariant to the change of adversarial attacks. The novel FAAT framework\nenables the trade-off between natural and robust accuracy by generating\nfeatures with similar distribution across natural and adversarial data, and\nachieve higher overall robustness benefited from the class-discriminative\nfeature characteristics. Experiments on various datasets demonstrate that FAAT\nproduces more discriminative features and performs favorably against\nstate-of-the-art methods. Codes are available at\nhttps://github.com/VisionFlow/FAAT.",
    "descriptor": "",
    "authors": [
      "Jia-Li Yin",
      "Lehui Xie",
      "Wanqing Zhu",
      "Ximeng Liu",
      "Bo-Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00323"
  },
  {
    "id": "arXiv:2112.00324",
    "title": "Optimizing for In-memory Deep Learning with Emerging Memory Technology",
    "abstract": "In-memory deep learning computes neural network models where they are stored,\nthus avoiding long distance communication between memory and computation units,\nresulting in considerable savings in energy and time. In-memory deep learning\nhas already demonstrated orders of magnitude higher performance density and\nenergy efficiency. The use of emerging memory technology promises to increase\nthe gains in density, energy, and performance even further. However, emerging\nmemory technology is intrinsically unstable, resulting in random fluctuations\nof data reads. This can translate to non-negligible accuracy loss, potentially\nnullifying the gains. In this paper, we propose three optimization techniques\nthat can mathematically overcome the instability problem of emerging memory\ntechnology. They can improve the accuracy of the in-memory deep learning model\nwhile maximizing its energy efficiency. Experiments show that our solution can\nfully recover most models' state-of-the-art accuracy, and achieves at least an\norder of magnitude higher energy efficiency than the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Zhehui Wang",
      "Tao Luo",
      "Rick Siow Mong Goh",
      "Wei Zhang",
      "Weng-Fai Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.00324"
  },
  {
    "id": "arXiv:2112.00328",
    "title": "A Daily Tourism Demand Prediction Framework Based on Multi-head  Attention CNN: The Case of The Foreign Entrant in South Korea",
    "abstract": "Developing an accurate tourism forecasting model is essential for making\ndesirable policy decisions for tourism management. Early studies on tourism\nmanagement focus on discovering external factors related to tourism demand.\nRecent studies utilize deep learning in demand forecasting along with these\nexternal factors. They mainly use recursive neural network models such as LSTM\nand RNN for their frameworks. However, these models are not suitable for use in\nforecasting tourism demand. This is because tourism demand is strongly affected\nby changes in various external factors, and recursive neural network models\nhave limitations in handling these multivariate inputs. We propose a multi-head\nattention CNN model (MHAC) for addressing these limitations. The MHAC uses\n1D-convolutional neural network to analyze temporal patterns and the attention\nmechanism to reflect correlations between input variables. This model makes it\npossible to extract spatiotemporal characteristics from time-series data of\nvarious variables. We apply our forecasting framework to predict inbound\ntourist changes in South Korea by considering external factors such as\npolitics, disease, season, and attraction of Korean culture. The performance\nresults of extensive experiments show that our method outperforms other\ndeep-learning-based prediction frameworks in South Korea tourism forecasting.",
    "descriptor": "\nComments: Accepted to IEEE Symposium Series on Computational Intelligence (IEEE SSCI 2021)\n",
    "authors": [
      "Dong-Keon Kim",
      "Sung Kuk Shyn",
      "Donghee Kim",
      "Seungwoo Jang",
      "Kwangsu Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00328"
  },
  {
    "id": "arXiv:2112.00330",
    "title": "Soft-Output Joint Channel Estimation and Data Detection using Deep  Unfolding",
    "abstract": "We propose a novel soft-output joint channel estimation and data detection\n(JED) algorithm for multiuser (MU) multiple-input multiple-output (MIMO)\nwireless communication systems. Our algorithm approximately solves a maximum\na-posteriori JED optimization problem using deep unfolding and generates\nsoft-output information for the transmitted bits in every iteration. The\nparameters of the unfolded algorithm are computed by a hyper-network that is\ntrained with a binary cross entropy (BCE) loss. We evaluate the performance of\nour algorithm in a coded MU-MIMO system with 8 basestation antennas and 4 user\nequipments and compare it to state-of-the-art algorithms separate channel\nestimation from soft-output data detection. Our results demonstrate that our\nJED algorithm outperforms such data detectors with as few as 10 iterations.",
    "descriptor": "\nComments: Presented at the 2021 IEEE Information Theory Workshop (ITW)\n",
    "authors": [
      "Haochuan Song",
      "Xiaohu You",
      "Chuan Zhang",
      "Christoph Studer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.00330"
  },
  {
    "id": "arXiv:2112.00331",
    "title": "Mutltimodal AI Companion for Interactive Fairytale Co-creation",
    "abstract": "AI fairy tale companions play an important role in early childhood education\nas an augmentation for parents' efforts to close the participation gap and\nboost kids' mental and language development. Existing systems are generally\ndesigned to provide vivid materials as unidirectional entertaining reading\nenvironments, e.g, visualizing inputting texts. However, due to the limited\nvocabulary of kids, these systems failed to afford effective interaction to\nmotivate kids to write their own fairy tales. In this work, we propose AI.R\nTaletorium, an illustrative, immersive, and inclusive multimodal AI companion,\nfor interactive fairy tale co-creation that actively involves kids to create\nfairy tales with both the AI agent and their normal peers. AI.R Taletorium\nconsists a neural story generator and a doodler-based fairy tale visualizer. We\ndesign a character-centric bidirectional connection mechanism between the story\ngenerator and visualizer equipped with Contrastive Language Image Pretraining\n(CLIP), thus enabling kids to participant in the story generation process by\nsimple sketching. Extensive experiments and user studies show that our system\nwas able to generate and visualize meaningful and vivid fairy tales with\nlimited training data and complete the full interaction cycle under various\ninputs (text, doodler) through the bidirectional connection.",
    "descriptor": "",
    "authors": [
      "Ruiyang Liu",
      "Predrag K. Nikolic"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.00331"
  },
  {
    "id": "arXiv:2112.00333",
    "title": "Joint Cluster Head Selection and Trajectory Planning in UAV-Aided IoT  Networks by Reinforcement Learning with Sequential Model",
    "abstract": "Employing unmanned aerial vehicles (UAVs) has attracted growing interests and\nemerged as the state-of-the-art technology for data collection in\nInternet-of-Things (IoT) networks. In this paper, with the objective of\nminimizing the total energy consumption of the UAV-IoT system, we formulate the\nproblem of jointly designing the UAV's trajectory and selecting cluster heads\nin the IoT network as a constrained combinatorial optimization problem which is\nclassified as NP-hard and challenging to solve. We propose a novel deep\nreinforcement learning (DRL) with a sequential model strategy that can\neffectively learn the policy represented by a sequence-to-sequence neural\nnetwork for the UAV's trajectory design in an unsupervised manner. Through\nextensive simulations, the obtained results show that the proposed DRL method\ncan find the UAV's trajectory that requires much less energy consumption when\ncompared to other baseline algorithms and achieves close-to-optimal\nperformance. In addition, simulation results show that the trained model by our\nproposed DRL algorithm has an excellent generalization ability to larger\nproblem sizes without the need to retrain the model.",
    "descriptor": "\nComments: This paper has been accepted in IEEE IoT-J\n",
    "authors": [
      "Botao Zhu",
      "Ebrahim Bedeer",
      "Ha H. Nguyen",
      "Robert Barton",
      "Jerome Henry"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00333"
  },
  {
    "id": "arXiv:2112.00334",
    "title": "VisRuler: Visual Analytics for Extracting Decision Rules from Bagged and  Boosted Decision Trees",
    "abstract": "Bagging and boosting are two popular ensemble methods in machine learning\n(ML) that produce many individual decision trees. Due to the inherent ensemble\ncharacteristic of these methods, they typically outperform single decision\ntrees or other ML models in predictive performance. However, numerous decision\npaths are generated for each decision tree, increasing the overall complexity\nof the model and hindering its use in domains that require trustworthy and\nexplainable decisions, such as finance, social care, and health care. Thus, the\ninterpretability of bagging and boosting algorithms, such as random forests and\nadaptive boosting, reduces as the number of decisions rises. In this paper, we\npropose a visual analytics tool that aims to assist users in extracting\ndecisions from such ML models via a thorough visual inspection workflow that\nincludes selecting a set of robust and diverse models (originating from\ndifferent ensemble learning algorithms), choosing important features according\nto their global contribution, and deciding which decisions are essential for\nglobal explanation (or locally, for specific cases). The outcome is a final\ndecision based on the class agreement of several models and the explored manual\ndecisions exported by users. Finally, we evaluate the applicability and\neffectiveness of VisRuler via a use case, a usage scenario, and a user study.",
    "descriptor": "\nComments: This manuscript is currently under review\n",
    "authors": [
      "Angelos Chatzimparmpas",
      "Rafael M. Martins",
      "Andreas Kerren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00334"
  },
  {
    "id": "arXiv:2112.00336",
    "title": "Multi-View Stereo with Transformer",
    "abstract": "This paper proposes a network, referred to as MVSTR, for Multi-View Stereo\n(MVS). It is built upon Transformer and is capable of extracting dense features\nwith global context and 3D consistency, which are crucial to achieving reliable\nmatching for MVS. Specifically, to tackle the problem of the limited receptive\nfield of existing CNN-based MVS methods, a global-context Transformer module is\nfirst proposed to explore intra-view global context. In addition, to further\nenable dense features to be 3D-consistent, a 3D-geometry Transformer module is\nbuilt with a well-designed cross-view attention mechanism to facilitate\ninter-view information interaction. Experimental results show that the proposed\nMVSTR achieves the best overall performance on the DTU dataset and strong\ngeneralization on the Tanks & Temples benchmark dataset.",
    "descriptor": "",
    "authors": [
      "Jie Zhu",
      "Bo Peng",
      "Wanqing Li",
      "Haifeng Shen",
      "Zhe Zhang",
      "Jianjun Lei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00336"
  },
  {
    "id": "arXiv:2112.00337",
    "title": "A Unified Benchmark for the Unknown Detection Capability of Deep Neural  Networks",
    "abstract": "Deep neural networks have achieved outstanding performance over various\ntasks, but they have a critical issue: over-confident predictions even for\ncompletely unknown samples. Many studies have been proposed to successfully\nfilter out these unknown samples, but they only considered narrow and specific\ntasks, referred to as misclassification detection, open-set recognition, or\nout-of-distribution detection. In this work, we argue that these tasks should\nbe treated as fundamentally an identical problem because an ideal model should\npossess detection capability for all those tasks. Therefore, we introduce the\nunknown detection task, an integration of previous individual tasks, for a\nrigorous examination of the detection capability of deep neural networks on a\nwide spectrum of unknown samples. To this end, unified benchmark datasets on\ndifferent scales were constructed and the unknown detection capabilities of\nexisting popular methods were subject to comparison. We found that Deep\nEnsemble consistently outperforms the other approaches in detecting unknowns;\nhowever, all methods are only successful for a specific type of unknown. The\nreproducible code and benchmark datasets are available at\nhttps://github.com/daintlab/unknown-detection-benchmarks .",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Jihyo Kim",
      "Jiin Koo",
      "Sangheum Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00337"
  },
  {
    "id": "arXiv:2112.00342",
    "title": "Confidence Propagation Cluster: Unleash Full Potential of Object  Detectors",
    "abstract": "It has been a long history that most object detection methods obtain objects\nby using the non-maximum suppression (NMS) and its improved versions like\nSoft-NMS to remove redundant bounding boxes. We challenge those NMS-based\nmethods from three aspects: 1) The bounding box with highest confidence value\nmay not be the true positive having the biggest overlap with the ground-truth\nbox. 2) Not only suppression is required for redundant boxes, but also\nconfidence enhancement is needed for those true positives. 3) Sorting candidate\nboxes by confidence values is not necessary so that full parallelism is\nachievable.\nIn this paper, inspired by belief propagation (BP), we propose the Confidence\nPropagation Cluster (CP-Cluster) to replace NMS-based methods, which is fully\nparallelizable as well as better in accuracy. In CP-Cluster, we borrow the\nmessage passing mechanism from BP to penalize redundant boxes and enhance true\npositives simultaneously in an iterative way until convergence. We verified the\neffectiveness of CP-Cluster by applying it to various mainstream detectors such\nas FasterRCNN, SSD, FCOS, YOLOv3, YOLOv5, Centernet etc. Experiments on MS COCO\nshow that our plug and play method, without retraining detectors, is able to\nsteadily improve average mAP of all those state-of-the-art models with a clear\nmargin from 0.2 to 1.9 respectively when compared with NMS-based methods.\nSource code is available at https://github.com/shenyi0220/CP-Cluster",
    "descriptor": "\nComments: Submitted to CVPR2022\n",
    "authors": [
      "Yichun Shen*",
      "Wanli Jiang*",
      "Zhen Xu",
      "Rundong Li",
      "Junghyun Kwon",
      "Siyi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00342"
  },
  {
    "id": "arXiv:2112.00343",
    "title": "Camera Motion Agnostic 3D Human Pose Estimation",
    "abstract": "Although the performance of 3D human pose and shape estimation methods has\nimproved significantly in recent years, existing approaches typically generate\n3D poses defined in camera or human-centered coordinate system. This makes it\ndifficult to estimate a person's pure pose and motion in world coordinate\nsystem for a video captured using a moving camera. To address this issue, this\npaper presents a camera motion agnostic approach for predicting 3D human pose\nand mesh defined in the world coordinate system. The core idea of the proposed\napproach is to estimate the difference between two adjacent global poses (i.e.,\nglobal motion) that is invariant to selecting the coordinate system, instead of\nthe global pose coupled to the camera motion. To this end, we propose a network\nbased on bidirectional gated recurrent units (GRUs) that predicts the global\nmotion sequence from the local pose sequence consisting of relative rotations\nof joints called global motion regressor (GMR). We use 3DPW and synthetic\ndatasets, which are constructed in a moving-camera environment, for evaluation.\nWe conduct extensive experiments and prove the effectiveness of the proposed\nmethod empirically. Code and datasets are available at\nhttps://github.com/seonghyunkim1212/GMR",
    "descriptor": "",
    "authors": [
      "Seong Hyun Kim",
      "Sunwon Jeong",
      "Sungbum Park",
      "Ju Yong Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00343"
  },
  {
    "id": "arXiv:2112.00346",
    "title": "Trusted And Confidential Program Analysis",
    "abstract": "We develop the concept of Trusted and Confidential Program Analysis (TCPA)\nwhich enables program certification to be used where previously there was\ninsufficient trust. Imagine a scenario where a producer may not be trusted to\ncertify its own software (perhaps by a foreign regulator), and the producer is\nunwilling to release its sources and detailed design to any external body. We\npresent a protocol that can, using trusted computing based on encrypted\nsources, create certification via which all can trust the delivered object code\nwithout revealing the unencrypted sources to any party. Furthermore, we\ndescribe a realization of TCPA with trusted execution environments (TEE) that\nenables general and efficient computation. We have implemented the TCPA\nprotocol in a system called TCWasm for web assembly architectures. In our\nevaluation with 33 benchmark cases, TCWasm managed to finish the analysis with\nrelatively slight overheads.",
    "descriptor": "",
    "authors": [
      "Han Liu",
      "Pedro Antonino",
      "Zhiqiang Yang",
      "Chao Liu",
      "A.W. Roscoe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.00346"
  },
  {
    "id": "arXiv:2112.00347",
    "title": "An Open Source Software Stack for Tuning the Dynamical Behavior of  Complex Power Systems",
    "abstract": "BlockSystems.jl and NetworkDynamics.jl are two novel software packages which\nfacilitate highly efficient transient stability simulations of power networks.\nUsers may specify inputs and power system design in a convenient modular and\nequation-based manner without compromising on speed or model detail. Written in\nthe high-level, high-performance programming language Julia a rich open-source\npackage ecosystem is available, which provides state-of-the-art solvers and\nmachine learning algorithms. Motivated by the recent interest in the Nordic\ninertia challenge we have implemented the Nordic5 test case and tuned its\ncontrol parameters by making use of the machine learning and automatic\ndifferentiation capabilities of our software stack.",
    "descriptor": "",
    "authors": [
      "Anna B\u00fcttner",
      "Hans W\u00fcrfel",
      "Anton Plietzsch",
      "Michael Lindner",
      "Frank Hellmann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.00347"
  },
  {
    "id": "arXiv:2112.00348",
    "title": "Automatic travel pattern extraction from visa page stamps using CNN  models",
    "abstract": "We propose an automated document analysis system that processes scanned visa\npages and automatically extracts the travel pattern from detected stamps. The\nsystem processes the page via the following pipeline: stamp detection in the\nvisa page; general stamp country and entry/exit recognition; Schengen area\nstamp country and entry/exit recognition; Schengen area stamp date extraction.\nFor each stage of the proposed pipeline we construct neural network models. We\nintegrated Schengen area stamp detection and date, country, entry/exit\nrecognition models together with graphical user interface into an automatic\ntravel pattern extraction tool, which is precise enough for practical\napplications.",
    "descriptor": "\nComments: 13 pages, 13 figures, 4 tables, submitted for peer review\n",
    "authors": [
      "Eimantas Ledinauskas",
      "Julius Ruseckas",
      "Julius Marozas",
      "Kasparas Karlauskas",
      "Justas Terentjevas",
      "Augustas Ma\u010dijauskas",
      "Alfonsas Jur\u0161\u0117nas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00348"
  },
  {
    "id": "arXiv:2112.00350",
    "title": "Investigation of Training Label Error Impact on RNN-T",
    "abstract": "In this paper, we propose an approach to quantitatively analyze impacts of\ndifferent training label errors to RNN-T based ASR models. The result shows\ndeletion errors are more harmful than substitution and insertion label errors\nin RNN-T training data. We also examined label error impact mitigation\napproaches on RNN-T and found that, though all the methods mitigate the\nlabel-error-caused degradation to some extent, they could not remove the\nperformance gap between the models trained with and without the presence of\nlabel errors. Based on the analysis results, we suggest to design data\npipelines for RNN-T with higher priority on reducing deletion label errors. We\nalso find that ensuring high-quality training labels remains important, despite\nof the existence of the label error mitigation approaches.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "I-Fan Chen",
      "Brian King",
      "Jasha Droppo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.00350"
  },
  {
    "id": "arXiv:2112.00351",
    "title": "Energy Management of a Multi-Battery System for Renewable-Based High  Power EV Charging",
    "abstract": "Stationary battery systems facilitate renewable-based electric vehicle fast\ncharging with power levels above the connection capacity of distribution grids.\nThis paper proposes heuristic energy management strategies for a novel\nmulti-battery design that directly connects its strings to other DC components\nwithout the need of interfacing power converters. Hence, the energy management\nsystem has two degrees of control: (i) allocating strings to other DC microgrid\ncomponents, in this case a photovoltaic system, two electric vehicle fast\nchargers, and a grid-tie inverter, and (ii) managing the energy exchange with\nthe local distribution grid. For the grid exchange, a basic droop control is\ncompared to an enhanced control including forecasts in the decision making. To\nthis end, this paper evaluates results from multiple Monte Carlo simulations\ncapturing the uncertainty of electric vehicle charging instances under varying\ncharging frequencies. Using actual photovoltaic measurements from different\nmonths, the numerical analyses show that the enhanced control increases\nself-sufficiency by reducing grid exchange, and decreases the number of battery\ncycles. However, the enhanced control operates the battery closer to its state\nof charge limits, which accelerates calendar ageing.",
    "descriptor": "\nComments: Submitted to the 22nd Power Systems Computation Conference (PSCC 2022)\n",
    "authors": [
      "Jan Engelhardt",
      "Jan Martin Zepter",
      "Jesper Gejl Lage",
      "Tatiana Gabderakhmanova",
      "Mattia Marinelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00351"
  },
  {
    "id": "arXiv:2112.00355",
    "title": "Score Transformer: Generating Musical Score from Note-level  Representation",
    "abstract": "In this paper, we explore the tokenized representation of musical scores\nusing the Transformer model to automatically generate musical scores. Thus far,\nsequence models have yielded fruitful results with note-level (MIDI-equivalent)\nsymbolic representations of music. Although the note-level representations can\ncomprise sufficient information to reproduce music aurally, they cannot contain\nadequate information to represent music visually in terms of notation. Musical\nscores contain various musical symbols (e.g., clef, key signature, and notes)\nand attributes (e.g., stem direction, beam, and tie) that enable us to visually\ncomprehend musical content. However, automated estimation of these elements has\nyet to be comprehensively addressed. In this paper, we first design score token\nrepresentation corresponding to the various musical elements. We then train the\nTransformer model to transcribe note-level representation into appropriate\nmusic notation. Evaluations of popular piano scores show that the proposed\nmethod significantly outperforms existing methods on all 12 musical aspects\nthat were investigated. We also explore an effective notation-level token\nrepresentation to work with the model and determine that our proposed\nrepresentation produces the steadiest results.",
    "descriptor": "\nComments: Accepted at ACM Multimedia Asia 2021 (MMAsia '21); Project page: this https URL\n",
    "authors": [
      "Masahiro Suzuki"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.00355"
  },
  {
    "id": "arXiv:2112.00359",
    "title": "Tool as Embodiment for Recursive Manipulation",
    "abstract": "Humans and many animals exhibit a robust capability to manipulate diverse\nobjects, often directly with their bodies and sometimes indirectly with tools.\nSuch flexibility is likely enabled by the fundamental consistency in underlying\nphysics of object manipulation such as contacts and force closures. Inspired by\nviewing tools as extensions of our bodies, we present Tool-As-Embodiment (TAE),\na parameterization for tool-based manipulation policies that treat hand-object\nand tool-object interactions in the same representation space. The result is a\nsingle policy that can be applied recursively on robots to use end effectors to\nmanipulate objects, and use objects as tools, i.e. new end-effectors, to\nmanipulate other objects. By sharing experiences across different embodiments\nfor grasping or pushing, our policy exhibits higher performance than if\nseparate policies were trained. Our framework could utilize all experiences\nfrom different resolutions of tool-enabled embodiments to a single generic\npolicy for each manipulation skill. Videos at\nhttps://sites.google.com/view/recursivemanipulation",
    "descriptor": "",
    "authors": [
      "Yuki Noguchi",
      "Tatsuya Matsushima",
      "Yutaka Matsuo",
      "Shixiang Shane Gu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00359"
  },
  {
    "id": "arXiv:2112.00362",
    "title": "Dimensionality Reduction for Categorical Data",
    "abstract": "Categorical attributes are those that can take a discrete set of values,\ne.g., colours. This work is about compressing vectors over categorical\nattributes to low-dimension discrete vectors. The current hash-based methods\ncompressing vectors over categorical attributes to low-dimension discrete\nvectors do not provide any guarantee on the Hamming distances between the\ncompressed representations. Here we present FSketch to create sketches for\nsparse categorical data and an estimator to estimate the pairwise Hamming\ndistances among the uncompressed data only from their sketches. We claim that\nthese sketches can be used in the usual data mining tasks in place of the\noriginal data without compromising the quality of the task. For that, we ensure\nthat the sketches also are categorical, sparse, and the Hamming distance\nestimates are reasonably precise. Both the sketch construction and the Hamming\ndistance estimation algorithms require just a single-pass; furthermore, changes\nto a data point can be incorporated into its sketch in an efficient manner. The\ncompressibility depends upon how sparse the data is and is independent of the\noriginal dimension -- making our algorithm attractive for many real-life\nscenarios. Our claims are backed by rigorous theoretical analysis of the\nproperties of FSketch and supplemented by extensive comparative evaluations\nwith related algorithms on some real-world datasets. We show that FSketch is\nsignificantly faster, and the accuracy obtained by using its sketches are among\nthe top for the standard unsupervised tasks of RMSE, clustering and similarity\nsearch.",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Knowledge and Data Engineering. Copyright IEEE, 1969\n",
    "authors": [
      "Debajyoti Bera",
      "Rameshwar Pratap",
      "Bhisham Dev Verma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00362"
  },
  {
    "id": "arXiv:2112.00364",
    "title": "Universal Probabilistic Programming Language Compilation with Parallel  Efficient Sequential Monte Carlo Inference",
    "abstract": "Probabilistic programming languages (PPLs) allow for natural encoding of\narbitrary inference problems, and PPL implementations can provide automatic\ngeneral-purpose inference for these problems. However, constructing inference\nimplementations that are efficient enough is challenging for many real-world\nproblems. Often, this is due to PPLs not fully exploiting available\nparallelization and optimization opportunities. For example, handling of\nprobabilistic checkpoints in PPLs through the use of continuation-passing style\ntransformations or non-preemptive multitasking -- as is done in many popular\nPPLs -- often disallows compilation to low-level languages required for\nhigh-performance platforms such as graphics processing units (GPUs). As a\nsolution to this checkpoint problem, we introduce the concept of PPL\ncontrol-flow graphs (PCFGs), providing a simple and efficient approach that can\nbe used for handling checkpoints in such languages. We use this approach to\nimplement RootPPL: a low-level PPL built on CUDA and C++ with OpenMP, providing\nhighly efficient and massively parallel SMC inference. We also introduce a\ngeneral method of compiling universal high-level PPLs to PCFGs, and illustrate\nits application when compiling Miking CorePPL -- a high-level universal PPL --\nto RootPPL. This is the first time a universal PPL has been compiled to GPUs\nwith SMC inference. Both RootPPL and the CorePPL compiler are evaluated through\na set of real-world experiments in the domains of phylogenetics and\nepidemiology, demonstrating up to 6x speedups over state-of-the-art PPLs\nimplementing SMC inference.",
    "descriptor": "",
    "authors": [
      "Daniel Lund\u00e9n",
      "Joey \u00d6hman",
      "Jan Kudlicka",
      "Viktor Senderov",
      "Fredrik Ronquist",
      "David Broman"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.00364"
  },
  {
    "id": "arXiv:2112.00374",
    "title": "CLIPstyler: Image Style Transfer with a Single Text Condition",
    "abstract": "Existing neural style transfer methods require reference style images to\ntransfer texture information of style images to content images. However, in\nmany practical situations, users may not have reference style images but still\nbe interested in transferring styles by just imagining them. In order to deal\nwith such applications, we propose a new framework that enables a style\ntransfer `without' a style image, but only with a text description of the\ndesired style. Using the pre-trained text-image embedding model of CLIP, we\ndemonstrate the modulation of the style of content images only with a single\ntext condition. Specifically, we propose a patch-wise text-image matching loss\nwith multiview augmentations for realistic texture transfer. Extensive\nexperimental results confirmed the successful image style transfer with\nrealistic textures that reflect semantic query texts.",
    "descriptor": "",
    "authors": [
      "Gihyun Kwon",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.00374"
  },
  {
    "id": "arXiv:2112.00378",
    "title": "$\\ell_\\infty$-Robustness and Beyond: Unleashing Efficient Adversarial  Training",
    "abstract": "Neural networks are vulnerable to adversarial attacks: adding well-crafted,\nimperceptible perturbations to their input can modify their output. Adversarial\ntraining is one of the most effective approaches in training robust models\nagainst such attacks. However, it is much slower than vanilla training of\nneural networks since it needs to construct adversarial examples for the entire\ntraining data at every iteration, which has hampered its effectiveness.\nRecently, Fast Adversarial Training was proposed that can obtain robust models\nefficiently. However, the reasons behind its success are not fully understood,\nand more importantly, it can only train robust models for $\\ell_\\infty$-bounded\nattacks as it uses FGSM during training. In this paper, by leveraging the\ntheory of coreset selection we show how selecting a small subset of training\ndata provides a more principled approach towards reducing the time complexity\nof robust training. Unlike existing methods, our approach can be adapted to a\nwide variety of training objectives, including TRADES, $\\ell_p$-PGD, and\nPerceptual Adversarial Training. Our experimental results indicate that our\napproach speeds up adversarial training by 2-3 times, while experiencing a\nsmall reduction in the clean and robust accuracy.",
    "descriptor": "",
    "authors": [
      "Hadi M. Dolatabadi",
      "Sarah Erfani",
      "Christopher Leckie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00378"
  },
  {
    "id": "arXiv:2112.00380",
    "title": "Deep Measurement Updates for Bayes Filters",
    "abstract": "Measurement update rules for Bayes filters often contain hand-crafted\nheuristics to compute observation probabilities for high-dimensional sensor\ndata, like images. In this work, we propose the novel approach Deep Measurement\nUpdate (DMU) as a general update rule for a wide range of systems. DMU has a\nconditional encoder-decoder neural network structure to process depth images as\nraw inputs. Even though the network is trained only on synthetic data, the\nmodel shows good performance at evaluation time on real-world data. With our\nproposed training scheme primed data training , we demonstrate how the DMU\nmodels can be trained efficiently to be sensitive to condition variables\nwithout having to rely on a stochastic information bottleneck. We validate the\nproposed methods in multiple scenarios of increasing complexity, beginning with\nthe pose estimation of a single object to the joint estimation of the pose and\nthe internal state of an articulated system. Moreover, we provide a benchmark\nagainst Articulated Signed Distance Functions(A-SDF) on the RBO dataset as a\nbaseline comparison for articulation state estimation.",
    "descriptor": "",
    "authors": [
      "Johannes Pankert",
      "Maria Vittoria Minniti",
      "Lorenz Wellhausen",
      "Marco Hutter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00380"
  },
  {
    "id": "arXiv:2112.00382",
    "title": "Lagrange and $H(\\operatorname{curl},{\\cal B})$ based Finite Element  formulations for the relaxed micromorphic model",
    "abstract": "Modeling the unusual mechanical properties of metamaterials is a challenging\ntopic for the mechanics community and enriched continuum theories are promising\ncomputational tools for such materials. The so-called relaxed micromorphic\nmodel has shown many advantages in this field. In this contribution, we present\nthe significant aspects related to the relaxed micromorphic model realization\nwith the finite element method. The variational problem is derived and\ndifferent FEM-formulations for the two-dimensional case are presented. These\nare a nodal standard formulation $H^1({\\cal B}) \\times H^1({\\cal B})$ and a\nnodal-edge formulation $H^1({\\cal B}) \\times H(\\operatorname{curl}, {\\cal B})$,\nwhere the latter employs the N\\'ed\\'elec space. However, the implementation of\nhigher-order N\\'ed\\'elec elements is not trivial and requires some\ntechnicalities which are demonstrated. We discuss the convergence behavior of\nLagrange-type and tangential-conforming finite element discretizations.\nMoreover, we analyze the characteristic length effect on the different\ncomponents of the model and reveal how the size-effect property is captured via\nthis characteristic length.",
    "descriptor": "",
    "authors": [
      "J\u00f6rg Schr\u00f6der",
      "Mohammad Sarhil",
      "Lisa Scheunemann",
      "Patrizio Neff"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.00382"
  },
  {
    "id": "arXiv:2112.00384",
    "title": "Translation-equivariant Image Quantizer for Bi-directional Image-Text  Generation",
    "abstract": "Recently, vector-quantized image modeling has demonstrated impressive\nperformance on generation tasks such as text-to-image generation. However, we\ndiscover that the current image quantizers do not satisfy translation\nequivariance in the quantized space due to aliasing, degrading performance in\nthe downstream text-to-image generation and image-to-text generation, even in\nsimple experimental setups. Instead of focusing on anti-aliasing, we take a\ndirect approach to encourage translation equivariance in the quantized space.\nIn particular, we explore a desirable property of image quantizers, called\n'Translation Equivariance in the Quantized Space' and propose a simple but\neffective way to achieve translation equivariance by regularizing orthogonality\nin the codebook embedding vectors. Using this method, we improve accuracy by\n+22% in text-to-image generation and +26% in image-to-text generation,\noutperforming the VQGAN.",
    "descriptor": "",
    "authors": [
      "Woncheol Shin",
      "Gyubok Lee",
      "Jiyoung Lee",
      "Joonseok Lee",
      "Edward Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00384"
  },
  {
    "id": "arXiv:2112.00386",
    "title": "Spurious Valleys, Spurious Minima and NP-hardness of Sparse Matrix  Factorization With Fixed Support",
    "abstract": "The problem of approximating a dense matrix by a product of sparse factors is\na fundamental problem for many signal processing and machine learning tasks. It\ncan be decomposed into two subproblems: finding the position of the non-zero\ncoefficients in the sparse factors, and determining their values. While the\nfirst step is usually seen as the most challenging one due to its combinatorial\nnature, this paper focuses on the second step, referred to as sparse matrix\napproximation with fixed support. First, we show its NP-hardness, while also\npresenting a nontrivial family of supports making the problem practically\ntractable with a dedicated algorithm. Then, we investigate the landscape of its\nnatural optimization formulation, proving the absence of spurious local valleys\nand spurious local minima, whose presence could prevent local optimization\nmethods to achieve global optimality. The advantages of the proposed algorithm\nover state-of-the-art first-order optimization methods are discussed.",
    "descriptor": "",
    "authors": [
      "Quoc-Tung Le",
      "Elisa Riccietti",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.00386"
  },
  {
    "id": "arXiv:2112.00387",
    "title": "How Parallel Circuit Execution Can Be Useful for NISQ Computing?",
    "abstract": "Quantum computing is performed on Noisy Intermediate-Scale Quantum (NISQ)\nhardware in the short term. Only small circuits can be executed reliably on a\nquantum machine due to the unavoidable noisy quantum operations on NISQ\ndevices, leading to the under-utilization of hardware resources. With the\ngrowing demand to access quantum hardware, how to utilize it more efficiently\nwhile maintaining output fidelity is becoming a timely issue. A parallel\ncircuit execution technique has been proposed to address this problem by\nexecuting multiple programs on hardware simultaneously. It can improve the\nhardware throughput and reduce the overall runtime. However, accumulative\nnoises such as crosstalk can decrease the output fidelity in parallel workload\nexecution. In this paper, we first give an in-depth overview of stateof-the-art\nparallel circuit execution methods. Second, we propose a Quantum\nCrosstalk-aware Parallel workload execution method (QuCP) without the overhead\nof crosstalk characterization. Third, we investigate the trade-off between\nhardware throughput and fidelity loss to explore the hardware limitation with\nparallel circuit execution. Finally, we apply parallel circuit execution to VQE\nand zero-noise extrapolation error mitigation method to showcase its various\napplications on advancing NISQ computing.",
    "descriptor": "\nComments: 2022 Design, Automation & Test in Europe Conference & Exhibition (DATE), Mar 2022, ANTWERP, Belgium\n",
    "authors": [
      "Siyuan Niu",
      "Aida Todri-Sanial"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.00387"
  },
  {
    "id": "arXiv:2112.00390",
    "title": "SegDiff: Image Segmentation with Diffusion Probabilistic Models",
    "abstract": "Diffusion Probabilistic Methods are employed for state-of-the-art image\ngeneration. In this work, we present a method for extending such models for\nperforming image segmentation. The method learns end-to-end, without relying on\na pre-trained backbone. The information in the input image and in the current\nestimation of the segmentation map is merged by summing the output of two\nencoders. Additional encoding layers and a decoder are then used to iteratively\nrefine the segmentation map using a diffusion model. Since the diffusion model\nis probabilistic, it is applied multiple times and the results are merged into\na final segmentation map. The new method obtains state-of-the-art results on\nthe Cityscapes validation set, the Vaihingen building segmentation benchmark,\nand the MoNuSeg dataset.",
    "descriptor": "",
    "authors": [
      "Tomer Amit",
      "Eliya Nachmani",
      "Tal Shaharbany",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00390"
  },
  {
    "id": "arXiv:2112.00394",
    "title": "Wiretap Secret Key Agreement Via Secure Omniscience",
    "abstract": "In this paper, we explore the connection between secret key agreement and\nsecure omniscience within the setting of the multiterminal source model with a\nwiretapper who has side information. While the secret key agreement problem\nconsiders the generation of a maximum-rate secret key through public\ndiscussion, the secure omniscience problem is concerned with communication\nprotocols for omniscience that minimize the rate of information leakage to the\nwiretapper. The starting point of our work is a lower bound on the minimum\nleakage rate for omniscience, $R_{\\mathop{\\mathrm{L}}}$, in terms of the\nwiretap secret key capacity, $C_{\\mathop{\\mathrm{W}}}$. Our interest is in\nidentifying broad classes of sources for which this lower bound is met with\nequality, in which case we say that there is a duality between secure\nomniscience and secret key agreement. We show that this duality holds in the\ncase of certain finite linear source (FLS) models, such as two-terminal FLS\nmodels and pairwise independent network models on trees with a linear\nwiretapper. Duality also holds for any FLS model in which\n$C_{\\mathop{\\mathrm{W}}}$ is achieved by a perfect linear secret key agreement\nscheme. We conjecture that the duality in fact holds unconditionally for any\nFLS model. On the negative side, we give an example of a (non-FLS) source model\nfor which duality does not hold if we limit ourselves to\ncommunication-for-omniscience protocols with at most two (interactive)\ncommunications. Finally, we demonstrate the usefulness of our lower bound on\n$R_{\\mathop{\\mathrm{L}}}$ by using it to derive equivalent conditions for the\npositivity of $C_{\\mathop{\\mathrm{W}}}$ in the multiterminal model. This\nextends a recent result of Gohari, G\\\"{u}nl\\\"{u} and Kramer (2020) obtained for\nthe two-user setting.",
    "descriptor": "\nComments: 23 pages, 7 figures. arXiv admin note: text overlap with arXiv:2102.01771\n",
    "authors": [
      "Praneeth Kumar Vippathalla",
      "Chung Chan",
      "Navin Kashyap",
      "Qiaoqiao Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.00394"
  },
  {
    "id": "arXiv:2112.00395",
    "title": "A Comprehensive Study on Various Statistical Techniques for Prediction  of Movie Success",
    "abstract": "The film industry is one of the most popular entertainment industries and one\nof the biggest markets for business. Among the contributing factors to this\nwould be the success of a movie in terms of its popularity as well as its box\noffice performance. Hence, we create a comprehensive comparison between the\nvarious machine learning models to predict the rate of success of a movie. The\neffectiveness of these models along with their statistical significance is\nstudied to conclude which of these models is the best predictor. Some insights\nregarding factors that affect the success of the movies are also found. The\nmodels studied include some Regression models, Machine Learning models, a Time\nSeries model and a Neural Network with the Neural Network being the best\nperforming model with an accuracy of about 86%. Additionally, as part of the\ntesting data for the movies released in 2020 are analysed.",
    "descriptor": "\nComments: 14 pages, 12 figures Conference: 2nd International Conference on Machine Learning Techniques and Data Science (MLDS 2021)\n",
    "authors": [
      "Manav Agarwal",
      "Shreya Venugopal",
      "Rishab Kashyap",
      "R Bharathi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00395"
  },
  {
    "id": "arXiv:2112.00396",
    "title": "Dyadic Human Motion Prediction",
    "abstract": "Prior work on human motion forecasting has mostly focused on predicting the\nfuture motion of single subjects in isolation from their past pose sequence. In\nthe presence of closely interacting people, however, this strategy fails to\naccount for the dependencies between the different subject's motions. In this\npaper, we therefore introduce a motion prediction framework that explicitly\nreasons about the interactions of two observed subjects. Specifically, we\nachieve this by introducing a pairwise attention mechanism that models the\nmutual dependencies in the motion history of the two subjects. This allows us\nto preserve the long-term motion dynamics in a more realistic way and more\nrobustly predict unusual and fast-paced movements, such as the ones occurring\nin a dance scenario. To evaluate this, and because no existing motion\nprediction datasets depict two closely-interacting subjects, we introduce the\nLindyHop600K dance dataset. Our results evidence that our approach outperforms\nthe state-of-the-art single person motion prediction techniques.",
    "descriptor": "",
    "authors": [
      "Isinsu Katircioglu",
      "Costa Georgantas",
      "Mathieu Salzmann",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00396"
  },
  {
    "id": "arXiv:2112.00398",
    "title": "Effective and efficient structure learning with pruning and model  averaging strategies",
    "abstract": "Learning the structure of a Bayesian Network (BN) with score-based solutions\ninvolves exploring the search space of possible graphs and moving towards the\ngraph that maximises a given objective function. Some algorithms offer exact\nsolutions that guarantee to return the graph with the highest objective score,\nwhile others offer approximate solutions in exchange for reduced computational\ncomplexity. This paper describes an approximate BN structure learning\nalgorithm, which we call Model Averaging Hill-Climbing (MAHC), that combines\ntwo novel strategies with hill-climbing search. The algorithm starts by pruning\nthe search space of graphs, where the pruning strategy can be viewed as an\naggressive version of the pruning strategies that are typically applied to\ncombinatorial optimisation structure learning problems. It then performs model\naveraging in the hill-climbing search process and moves to the neighbouring\ngraph that maximises the objective function, on average, for that neighbouring\ngraph and over all its valid neighbouring graphs. Comparisons with other\nalgorithms spanning different classes of learning suggest that the combination\nof aggressive pruning with model averaging is both effective and efficient,\nparticularly in the presence of data noise.",
    "descriptor": "",
    "authors": [
      "Anthony C. Constantinou",
      "Yang Liu",
      "Neville K. Kitson",
      "Kiattikun Chobtham",
      "Zhigao Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00398"
  },
  {
    "id": "arXiv:2112.00399",
    "title": "Quantum-Resistant Cryptography",
    "abstract": "Quantum-resistant cryptography is cryptography that aims to deliver\ncryptographic functions and protocols that remain secure even if large-scale\nfault-tolerant quantum computers are built. NIST will soon announce the first\nselected public-key cryptography algorithms in its Post-Quantum Cryptography\n(PQC) standardization which is the most important current effort in the field\nof quantum-resistant cryptography. This report provides an overview to security\nexperts who do not yet have a deep understanding of quantum-resistant\ncryptography. It surveys the computational model of quantum computers; the\nquantum algorithms that affect cryptography the most; the risk of\nCryptographically Relevant Quantum Computers (CRQCs) being built; the security\nof symmetric and public-key cryptography in the presence of CRQCs; the NIST PQC\nstandardization effort; the migration to quantum-resistant public-key\ncryptography; the relevance of Quantum Key Distribution as a complement to\nconventional cryptography; and the relevance of Quantum Random Number\nGenerators as a complement to current hardware Random Number Generators.",
    "descriptor": "",
    "authors": [
      "John Preu\u00df Mattsson",
      "Ben Smeets",
      "Erik Thormarker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.00399"
  },
  {
    "id": "arXiv:2112.00403",
    "title": "Orientation of Fitch Graphs and Detection of Horizontal Gene Transfer in  Gene Trees",
    "abstract": "Horizontal gene transfer events partition a gene tree $T$ and thus, its leaf\nset into subsets of genes whose evolutionary history is described by speciation\nand duplication events alone. Indirect phylogenetic methods can be used to\ninfer such partitions $\\mathcal{P}$ from sequence similarity or evolutionary\ndistances without any a priory knowledge about the underlying tree $T$. In this\ncontribution, we assume that such a partition $\\mathcal{P}$ of a set of genes\n$X$ is given and that, independently, an estimate $T$ of the original gene tree\non $X$ has been derived. We then ask to what extent $T$ and the xenology\ninformation, i.e., $\\mathcal{P}$ can be combined to determine the horizontal\ntransfer edges in $T$. We show that for each pair of genes $x$ and $y$ with\n$x,y$ being in different parts of $\\mathcal{P}$, it can be decided whether\nthere always exists or never exists a horizontal gene transfer in $T$ along the\npath connecting $y$ and the most recent common ancestor of $x$ and $y$. This\nproblem is equivalent to determining the presence or absence of the directed\nedge $(x,y)$ in so-called Fitch graphs; a more fine-grained version of graphs\nthat represent the dependencies between the sets in $\\mathcal{P}$. We then\nconsider the generalization to insufficiently resolved gene trees and show that\nanalogous results can be obtained. We show that the classification of $(x,y)$\ncan be computed in constant time after linear-time preprocessing. Using\nsimulated gene family histories, we observe empirically that the vast majority\nof horizontal transfer edges in the gene tree $T$ can be recovered\nunambiguously.",
    "descriptor": "",
    "authors": [
      "David Schaller",
      "Marc Hellmuth",
      "Peter F. Stadler"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2112.00403"
  },
  {
    "id": "arXiv:2112.00405",
    "title": "NER-BERT: A Pre-trained Model for Low-Resource Entity Tagging",
    "abstract": "Named entity recognition (NER) models generally perform poorly when large\ntraining datasets are unavailable for low-resource domains. Recently,\npre-training a large-scale language model has become a promising direction for\ncoping with the data scarcity issue. However, the underlying discrepancies\nbetween the language modeling and NER task could limit the models' performance,\nand pre-training for the NER task has rarely been studied since the collected\nNER datasets are generally small or large but with low quality. In this paper,\nwe construct a massive NER corpus with a relatively high quality, and we\npre-train a NER-BERT model based on the created dataset. Experimental results\nshow that our pre-trained model can significantly outperform BERT as well as\nother strong baselines in low-resource scenarios across nine diverse domains.\nMoreover, a visualization of entity representations further indicates the\neffectiveness of NER-BERT for categorizing a variety of entities.",
    "descriptor": "",
    "authors": [
      "Zihan Liu",
      "Feijun Jiang",
      "Yuxiang Hu",
      "Chen Shi",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00405"
  },
  {
    "id": "arXiv:2112.00407",
    "title": "Compare Where It Matters: Using Layer-Wise Regularization To Improve  Federated Learning on Heterogeneous Data",
    "abstract": "Federated Learning is a widely adopted method to train neural networks over\ndistributed data. One main limitation is the performance degradation that\noccurs when data is heterogeneously distributed. While many works have\nattempted to address this problem, these methods under-perform because they are\nfounded on a limited understanding of neural networks. In this work, we verify\nthat only certain important layers in a neural network require regularization\nfor effective training. We additionally verify that Centered Kernel Alignment\n(CKA) most accurately calculates similarity between layers of neural networks\ntrained on different data. By applying CKA-based regularization to important\nlayers during training, we significantly improve performance in heterogeneous\nsettings. We present FedCKA: a simple framework that out-performs previous\nstate-of-the-art methods on various deep learning tasks while also improving\nefficiency and scalability.",
    "descriptor": "\nComments: 8 pages, 5 figures, 4 tables\n",
    "authors": [
      "Ha Min Son",
      "Moon Hyun Kim",
      "Tai-Myoung Chung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.00407"
  },
  {
    "id": "arXiv:2112.00408",
    "title": "Approximating Length-Restricted Means under Dynamic Time Warping",
    "abstract": "We study variants of the mean problem under the $p$-Dynamic Time Warping\n($p$-DTW) distance, a popular and robust distance measure for sequential data.\nIn our setting we are given a set of finite point sequences over an arbitrary\nmetric space and we want to compute a mean point sequence of given length that\nminimizes the sum of $p$-DTW distances, each raised to the $q$th power, between\nthe input sequences and the mean sequence. In general, the problem is\n$\\mathrm{NP}$-hard and known not to be fixed-parameter tractable in the number\nof sequences. We show that it is even hard to approximate within any constant\nfactor unless $\\mathrm{P} = \\mathrm{NP}$ and moreover if there exists a\n$\\delta>0$ such that there is a $(\\log n)^{\\delta}$-approximation algorithm for\nDTW mean then $\\mathrm{NP} \\subseteq \\mathrm{QP}$. On the positive side, we\nshow that restricting the length of the mean sequence significantly reduces the\nhardness of the problem. We give an exact algorithm running in polynomial time\nfor constant-length means. We explore various approximation algorithms that\nprovide a trade-off between the approximation factor and the running time. Our\napproximation algorithms have a running time with only linear dependency on the\nnumber of input sequences. In addition, we use our mean algorithms to obtain\nclustering algorithms with theoretical guarantees.",
    "descriptor": "",
    "authors": [
      "Maike Buchin",
      "Anne Driemel",
      "Koen van Greevenbroek",
      "Ioannis Psarros",
      "Dennis Rohde"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.00408"
  },
  {
    "id": "arXiv:2112.00410",
    "title": "Rethink, Revisit, Revise: A Spiral Reinforced Self-Revised Network for  Zero-Shot Learning",
    "abstract": "Current approaches to Zero-Shot Learning (ZSL) struggle to learn\ngeneralizable semantic knowledge capable of capturing complex correlations.\nInspired by \\emph{Spiral Curriculum}, which enhances learning processes by\nrevisiting knowledge, we propose a form of spiral learning which revisits\nvisual representations based on a sequence of attribute groups (e.g., a\ncombined group of \\emph{color} and \\emph{shape}). Spiral learning aims to learn\ngeneralized local correlations, enabling models to gradually enhance global\nlearning and thus understand complex correlations. Our implementation is based\non a 2-stage \\emph{Reinforced Self-Revised (RSR)} framework: \\emph{preview} and\n\\emph{review}. RSR first previews visual information to construct diverse\nattribute groups in a weakly-supervised manner. Then, it spirally learns\nrefined localities based on attribute groups and uses localities to revise\nglobal semantic correlations. Our framework outperforms state-of-the-art\nalgorithms on four benchmark datasets in both zero-shot and generalized\nzero-shot settings, which demonstrates the effectiveness of spiral learning in\nlearning generalizable and complex correlations. We also conduct extensive\nanalysis to show that attribute groups and reinforced decision processes can\ncapture complementary semantic information to improve predictions and aid\nexplainability.",
    "descriptor": "",
    "authors": [
      "Zhe Liu",
      "Yun Li",
      "Lina Yao",
      "Julian McAuley",
      "Sam Dixon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00410"
  },
  {
    "id": "arXiv:2112.00412",
    "title": "The Majority Can Help The Minority: Context-rich Minority Oversampling  for Long-tailed Classification",
    "abstract": "The problem of class imbalanced data lies in that the generalization\nperformance of the classifier is deteriorated due to the lack of data of the\nminority classes. In this paper, we propose a novel minority over-sampling\nmethod to augment diversified minority samples by leveraging the rich context\nof the majority classes as background images. To diversify the minority\nsamples, our key idea is to paste a foreground patch from a minority class to a\nbackground image from a majority class having affluent contexts. Our method is\nsimple and can be easily combined with the existing long-tailed recognition\nmethods. We empirically prove the effectiveness of the proposed oversampling\nmethod through extensive experiments and ablation studies. Without any\narchitectural changes or complex algorithms, our method achieves\nstate-of-the-art performance on various long-tailed classification benchmarks.\nOur code will be publicly available at link.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Seulki Park",
      "Youngkyu Hong",
      "Byeongho Heo",
      "Sangdoo Yun",
      "Jin Young Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00412"
  },
  {
    "id": "arXiv:2112.00420",
    "title": "An adaptive mixture-population Monte Carlo method for likelihood-free  inference",
    "abstract": "This paper focuses on variational inference with intractable likelihood\nfunctions that can be unbiasedly estimated. A flexible variational\napproximation based on Gaussian mixtures is developed, by adopting the mixture\npopulation Monte Carlo (MPMC) algorithm in \\cite{cappe2008adaptive}. MPMC\nupdates iteratively the parameters of mixture distributions with importance\nsampling computations, instead of the complicated gradient estimation of the\noptimization objective in usual variational Bayes. Noticing that MPMC uses a\nfixed number of mixture components, which is difficult to predict for real\napplications, we further propose an automatic component--updating procedure to\nderive an appropriate number of components. The derived adaptive MPMC algorithm\nis capable of finding good approximations of the multi-modal posterior\ndistributions even with a standard Gaussian as the initial distribution, as\ndemonstrated in our numerical experiments.",
    "descriptor": "\nComments: 23 pages, 7 figures\n",
    "authors": [
      "Zhijian He",
      "Shifeng Huo",
      "Tianhui Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.00420"
  },
  {
    "id": "arXiv:2112.00424",
    "title": "Multi-Agent Transfer Learning in Reinforcement Learning-Based  Ride-Sharing Systems",
    "abstract": "Reinforcement learning (RL) has been used in a range of simulated real-world\ntasks, e.g., sensor coordination, traffic light control, and on-demand mobility\nservices. However, real world deployments are rare, as RL struggles with\ndynamic nature of real world environments, requiring time for learning a task\nand adapting to changes in the environment. Transfer Learning (TL) can help\nlower these adaptation times. In particular, there is a significant potential\nof applying TL in multi-agent RL systems, where multiple agents can share\nknowledge with each other, as well as with new agents that join the system. To\nobtain the most from inter-agent transfer, transfer roles (i.e., determining\nwhich agents act as sources and which as targets), as well as relevant transfer\ncontent parameters (e.g., transfer size) should be selected dynamically in each\nparticular situation. As a first step towards fully dynamic transfers, in this\npaper we investigate the impact of TL transfer parameters with fixed source and\ntarget roles. Specifically, we label every agent-environment interaction with\nagent's epistemic confidence, and we filter the shared examples using varying\nthreshold levels and sample sizes. We investigate impact of these parameters in\ntwo scenarios, a standard predator-prey RL benchmark and a simulation of a\nride-sharing system with 200 vehicle agents and 10,000 ride-requests.",
    "descriptor": "",
    "authors": [
      "Alberto Castagna",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.00424"
  },
  {
    "id": "arXiv:2112.00425",
    "title": "How to use Persistent Memory in your Database",
    "abstract": "Persistent or Non Volatile Memory (PMEM or NVM) has recently become\ncommercially available under several configurations with different purposes and\ngoals. Despite the attention to the topic, we are not aware of a comprehensive\nempirical analysis of existing relational database engines under different PMEM\nconfigurations. Such a study is important to understand the performance\nimplications of the various hardware configurations and how different DB\nengines can benefit from them. To this end, we analyze three different engines\n(PostgreSQL, MySQL, and SQLServer) under common workloads (TPC-C and TPC-H)\nwith all possible PMEM configurations supported by Intel's Optane NVM devices\n(PMEM as persistent memory in AppDirect mode and PMEM as volatile memory in\nMemory mode). Our results paint a complex picture and are not always intuitive\ndue to the many factors involved. Based on our findings, we provide insights on\nhow the different engines behave with PMEM and which configurations and queries\nperform best. Our results show that using PMEM as persistent storage usually\nspeeds up query execution, but with some caveats as the I/O path is not fully\noptimized. Additionally, using PMEM in Memory mode does not offer any\nperformance advantage despite the larger volatile memory capacity. Through the\nextensive coverage of engines and parameters, we provide an important starting\npoint for exploiting PMEM in databases and tuning relational engines to take\nadvantage of this new technology.",
    "descriptor": "",
    "authors": [
      "Dimitrios Koutsoukos",
      "Raghav Bhartia",
      "Ana Klimovic",
      "Gustavo Alonso"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.00425"
  },
  {
    "id": "arXiv:2112.00427",
    "title": "Research on Event Accumulator Settings for Event-Based SLAM",
    "abstract": "Event cameras are a new type of sensors that are different from traditional\ncameras. Each pixel is triggered asynchronously by event. The trigger event is\nthe change of the brightness irradiated on the pixel. If the increment or\ndecrement of brightness is higher than a certain threshold, an event is output.\nCompared with traditional cameras, event cameras have the advantages of high\ndynamic range and no motion blur. Accumulating events to frames and using\ntraditional SLAM algorithm is a direct and efficient way for event-based SLAM.\nDifferent event accumulator settings, such as slice method of event stream,\nprocessing method for no motion, using polarity or not, decay function and\nevent contribution, can cause quite different accumulating results. We\nconducted the research on how to accumulate event frames to achieve a better\nevent-based SLAM performance. For experiment verification, accumulated event\nframes are fed to the traditional SLAM system to construct an event-based SLAM\nsystem. Our strategy of setting event accumulator has been evaluated on the\npublic dataset. The experiment results show that our method can achieve better\nperformance in most sequences compared with the state-of-the-art event frame\nbased SLAM algorithm. In addition, the proposed approach has been tested on a\nquadrotor UAV to show the potential of applications in real scenario. Code and\nresults are open sourced to benefit the research community of event cameras",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2008.05749 by other authors\n",
    "authors": [
      "Kun Xiao",
      "Guohui Wang",
      "Yi Chen",
      "Yongfeng Xie",
      "Hong Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00427"
  },
  {
    "id": "arXiv:2112.00428",
    "title": "Adv-4-Adv: Thwarting Changing Adversarial Perturbations via Adversarial  Domain Adaptation",
    "abstract": "Whereas adversarial training can be useful against specific adversarial\nperturbations, they have also proven ineffective in generalizing towards\nattacks deviating from those used for training. However, we observe that this\nineffectiveness is intrinsically connected to domain adaptability, another\ncrucial issue in deep learning for which adversarial domain adaptation appears\nto be a promising solution. Consequently, we proposed Adv-4-Adv as a novel\nadversarial training method that aims to retain robustness against unseen\nadversarial perturbations. Essentially, Adv-4-Adv treats attacks incurring\ndifferent perturbations as distinct domains, and by leveraging the power of\nadversarial domain adaptation, it aims to remove the domain/attack-specific\nfeatures. This forces a trained model to learn a robust domain-invariant\nrepresentation, which in turn enhances its generalization ability. Extensive\nevaluations on Fashion-MNIST, SVHN, CIFAR-10, and CIFAR-100 demonstrate that a\nmodel trained by Adv-4-Adv based on samples crafted by simple attacks (e.g.,\nFGSM) can be generalized to more advanced attacks (e.g., PGD), and the\nperformance exceeds state-of-the-art proposals on these datasets.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Tianyue Zheng",
      "Zhe Chen",
      "Shuya Ding",
      "Chao Cai",
      "Jun Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00428"
  },
  {
    "id": "arXiv:2112.00429",
    "title": "Security issues of CFS-like digital signature algorithms",
    "abstract": "We analyse the security of some variants of the CFS code-based digital\nsignature scheme. We show how the adoption of some code-based hash-functions to\nimprove the efficiency of CFS leads to the ability of an attacker to produce a\nforgery compatible to the rightful user's public key.",
    "descriptor": "",
    "authors": [
      "Giuseppe D'Alconzo",
      "Alessio Meneghetti",
      "Paolo Piasenti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.00429"
  },
  {
    "id": "arXiv:2112.00431",
    "title": "MAD: A Scalable Dataset for Language Grounding in Videos from Movie  Audio Descriptions",
    "abstract": "The recent and increasing interest in video-language research has driven the\ndevelopment of large-scale datasets that enable data-intensive machine learning\ntechniques. In comparison, limited effort has been made at assessing the\nfitness of these datasets for the video-language grounding task. Recent works\nhave begun to discover significant limitations in these datasets, suggesting\nthat state-of-the-art techniques commonly overfit to hidden dataset biases. In\nthis work, we present MAD (Movie Audio Descriptions), a novel benchmark that\ndeparts from the paradigm of augmenting existing video datasets with text\nannotations and focuses on crawling and aligning available audio descriptions\nof mainstream movies. MAD contains over 384,000 natural language sentences\ngrounded in over 1,200 hours of video and exhibits a significant reduction in\nthe currently diagnosed biases for video-language grounding datasets. MAD's\ncollection strategy enables a novel and more challenging version of\nvideo-language grounding, where short temporal moments (typically seconds long)\nmust be accurately grounded in diverse long-form videos that can last up to\nthree hours.",
    "descriptor": "\nComments: 12 Pages, 6 Figures, 7 Tables\n",
    "authors": [
      "Mattia Soldan",
      "Alejandro Pardo",
      "Juan Le\u00f3n Alc\u00e1zar",
      "Fabian Caba Heilbron",
      "Chen Zhao",
      "Silvio Giancola",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00431"
  },
  {
    "id": "arXiv:2112.00432",
    "title": "A benchmark with decomposed distribution shifts for 360 monocular depth  estimation",
    "abstract": "In this work we contribute a distribution shift benchmark for a computer\nvision task; monocular depth estimation. Our differentiation is the\ndecomposition of the wider distribution shift of uncontrolled testing on\nin-the-wild data, to three distinct distribution shifts. Specifically, we\ngenerate data via synthesis and analyze them to produce covariate (color\ninput), prior (depth output) and concept (their relationship) distribution\nshifts. We also synthesize combinations and show how each one is indeed a\ndifferent challenge to address, as stacking them produces increased performance\ndrops and cannot be addressed horizontally using standard approaches.",
    "descriptor": "",
    "authors": [
      "Georgios Albanis",
      "Nikolaos Zioulis",
      "Petros Drakoulis",
      "Federico Alvarez",
      "Dimitrios Zarpalas",
      "Petros Daras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00432"
  },
  {
    "id": "arXiv:2112.00434",
    "title": "Training Experimentally Robust and Interpretable Binarized Regression  Models Using Mixed-Integer Programming",
    "abstract": "In this paper, we explore model-based approach to training robust and\ninterpretable binarized regression models for multiclass classification tasks\nusing Mixed-Integer Programming (MIP). Our MIP model balances the optimization\nof prediction margin and model size by using a weighted objective that:\nminimizes the total margin of incorrectly classified training instances,\nmaximizes the total margin of correctly classified training instances, and\nmaximizes the overall model regularization. We conduct two sets of experiments\nto test the classification accuracy of our MIP model over standard and\ncorrupted versions of multiple classification datasets, respectively. In the\nfirst set of experiments, we show that our MIP model outperforms an equivalent\nPseudo-Boolean Optimization (PBO) model and achieves competitive results to\nLogistic Regression (LR) and Gradient Descent (GD) in terms of classification\naccuracy over the standard datasets. In the second set of experiments, we show\nthat our MIP model outperforms the other models (i.e., GD and LR) in terms of\nclassification accuracy over majority of the corrupted datasets. Finally, we\nvisually demonstrate the interpretability of our MIP model in terms of its\nlearned parameters over the MNIST dataset. Overall, we show the effectiveness\nof training robust and interpretable binarized regression models using MIP.",
    "descriptor": "",
    "authors": [
      "Sanjana Tule",
      "Nhi Ha Lan Le",
      "Buser Say"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00434"
  },
  {
    "id": "arXiv:2112.00443",
    "title": "TROLLMAGNIFIER: Detecting State-Sponsored Troll Accounts on Reddit",
    "abstract": "Growing evidence points to recurring influence campaigns on social media,\noften sponsored by state actors aiming to manipulate public opinion on\nsensitive political topics. Typically, campaigns are performed through\ninstrumented accounts, known as troll accounts; despite their prominence,\nhowever, little work has been done to detect these accounts in the wild. In\nthis paper, we present TROLLMAGNIFIER, a detection system for troll accounts.\nOur key observation, based on analysis of known Russian-sponsored troll\naccounts identified by Reddit, is that they show loose coordination, often\ninteracting with each other to further specific narratives. Therefore, troll\naccounts controlled by the same actor often show similarities that can be\nleveraged for detection. TROLLMAGNIFIER learns the typical behavior of known\ntroll accounts and identifies more that behave similarly. We train\nTROLLMAGNIFIER on a set of 335 known troll accounts and run it on a large\ndataset of Reddit accounts. Our system identifies 1,248 potential troll\naccounts; we then provide a multi-faceted analysis to corroborate the\ncorrectness of our classification. In particular, 66% of the detected accounts\nshow signs of being instrumented by malicious actors (e.g., they were created\non the same exact day as a known troll, they have since been suspended by\nReddit, etc.). They also discuss similar topics as the known troll accounts and\nexhibit temporal synchronization in their activity. Overall, we show that using\nTROLLMAGNIFIER, one can grow the initial knowledge of potential trolls provided\nby Reddit by over 300%.",
    "descriptor": "",
    "authors": [
      "Mohammad Hammas Saeed",
      "Shiza Ali",
      "Jeremy Blackburn",
      "Emiliano De Cristofaro",
      "Savvas Zannettou",
      "Gianluca Stringhini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.00443"
  },
  {
    "id": "arXiv:2112.00448",
    "title": "On-Device Spatial Attention based Sequence Learning Approach for Scene  Text Script Identification",
    "abstract": "Automatic identification of script is an essential component of a\nmultilingual OCR engine. In this paper, we present an efficient, lightweight,\nreal-time and on-device spatial attention based CNN-LSTM network for scene text\nscript identification, feasible for deployment on resource constrained mobile\ndevices. Our network consists of a CNN, equipped with a spatial attention\nmodule which helps reduce the spatial distortions present in natural images.\nThis allows the feature extractor to generate rich image representations while\nignoring the deformities and thereby, enhancing the performance of this fine\ngrained classification task. The network also employs residue convolutional\nblocks to build a deep network to focus on the discriminative features of a\nscript. The CNN learns the text feature representation by identifying each\ncharacter as belonging to a particular script and the long term spatial\ndependencies within the text are captured using the sequence learning\ncapabilities of the LSTM layers. Combining the spatial attention mechanism with\nthe residue convolutional blocks, we are able to enhance the performance of the\nbaseline CNN to build an end-to-end trainable network for script\nidentification. The experimental results on several standard benchmarks\ndemonstrate the effectiveness of our method. The network achieves competitive\naccuracy with state-of-the-art methods and is superior in terms of network\nsize, with a total of just 1.1 million parameters and inference time of 2.7\nmilliseconds.",
    "descriptor": "\nComments: Accepted for publication in CVIP 2021\n",
    "authors": [
      "Rutika Moharir",
      "Arun D Prabhu",
      "Sukumar Moharana",
      "Gopi Ramena",
      "Rachit S Munjal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00448"
  },
  {
    "id": "arXiv:2112.00449",
    "title": "Frequent-Pattern Based Broadcast Scheduling for Conflict Avoidance in  Multi-Channel Data Dissemination Systems",
    "abstract": "With the popularity of mobile devices, using the traditional client-server\nmodel to handle a large number of requests is very challenging. Wireless data\nbroadcasting can be used to provide services to many users at the same time, so\nreducing the average access time has become a popular research topic. For\nexample, some location-based services (LBS) consider using multiple channels to\ndisseminate information to reduce access time. However, data conflicts may\noccur when multiple channels are used, where multiple data items associated\nwith the request are broadcast at about the same time. In this article, we\nconsider the channel switching time and identify the data conflict issue in an\non-demand multi-channel dissemination system. We model the considered problem\nas a Data Broadcast with Conflict Avoidance (DBCA) problem and prove it is\nNP-complete. We hence propose the frequent-pattern based broadcast scheduling\n(FPBS), which provides a new variant of the frequent pattern tree, FP*-tree, to\nschedule the requested data. Using FPBS, the system can avoid data conflicts\nwhen assigning data items to time slots in the channels. In the simulation, we\ndiscussed two modes of FPBS: online and offline. The results show that,\ncompared with the existing heuristic methods, FPBS can shorten the average\naccess time by 30%.",
    "descriptor": "\nComments: 10 figures, accepted by Wireless Communications and Mobile Computing, Special Issue on Innovative Artificial Intelligence-Based Internet of Things for Smart Cities and Smart Homes\n",
    "authors": [
      "Chuan-Chi Lai",
      "Yu-De Lin",
      "Chuan-Ming Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.00449"
  },
  {
    "id": "arXiv:2112.00451",
    "title": "Unconditional well-posedness and IMEX improvement of a family of  predictor-corrector methods in micromagnetics",
    "abstract": "Recently, Kim & Wilkening (Convergence of a mass-lumped finite element method\nfor the Landau-Lifshitz equation, Quart. Appl. Math., 76, 383-405, 2018)\nproposed two novel predictor-corrector methods for the Landau-Lifshitz-Gilbert\nequation (LLG) in micromagnetics, which models the dynamics of the\nmagnetization in ferromagnetic materials. Both integrators are based on the\nso-called Landau-Lifshitz form of LLG, use mass-lumped variational formulations\ndiscretized by first-order finite elements, and only require the solution of\nlinear systems, despite the nonlinearity of LLG. The first(-order in time)\nmethod combines a linear update with an explicit projection of an intermediate\napproximation onto the unit sphere in order to fulfill the LLG-inherent\nunit-length constraint at the discrete level. In the second(-order in time)\nintegrator, the projection step is replaced by a linear constraint-preserving\nvariational formulation. In this paper, we extend the analysis of the\nintegrators by proving unconditional well-posedness and by establishing a close\nconnection of the methods with other approaches available in the literature.\nMoreover, the new analysis also provides a well-posed integrator for the\nSchr\\\"odinger map equation (which is the limit case of LLG for vanishing\ndamping). Finally, we design an implicit-explicit strategy for the treatment of\nthe lower-order field contributions, which significantly reduces the\ncomputational cost of the schemes, while preserving their theoretical\nproperties.",
    "descriptor": "\nComments: 29 pages, 6 figures\n",
    "authors": [
      "Norbert J. Mauser",
      "Carl-Martin Pfeiler",
      "Dirk Praetorius",
      "Michele Ruggeri"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.00451"
  },
  {
    "id": "arXiv:2112.00454",
    "title": "Hyperbolae are the locus of constant angle difference",
    "abstract": "Given two points A,B in the plane, the locus of all points P for which the\nangles at A and B in the triangle A,B,P have a constant sum is a circular arc,\nby Thales' theorem. We show that the difference of these angles is kept a\nconstant by points P on a hyperbola (albeit with foci different from A and B).\nWhereas hyperbolae are well-known to maintain a constant difference between the\ndistances to their foci, the above angle property seems not to be widely known.\nThe question was motivated by recent work by Alegr\\'ia et al. and De Berg et\nal. on Voronoi diagrams of turning rays.",
    "descriptor": "\nComments: 3 pages, 2 figures\n",
    "authors": [
      "Herman Haverkort",
      "Rolf Klein"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.00454"
  },
  {
    "id": "arXiv:2112.00457",
    "title": "Broadband beam steering for misaligned multi-mode OAM communication  systems",
    "abstract": "Orbital angular momentum (OAM) at radio frequency (RF) has attracted more and\nmore attention as a novel approach of multiplexing a set of orthogonal OAM\nmodes on the same frequency channel to achieve high spectral efficiency (SE).\nHowever, the precondition for maintaining the orthogonality among different OAM\nmodes is perfect alignment of the transmit and receive uniform circular arrays\n(UCAs), which is difficult to be satisfied in practical wireless communication\nscenario. Therefore, to achieve available multi-mode OAM broadband wireless\ncommunication, we first investigate the effect of oblique angles on the\ntransmission performance of the multi-mode OAM broadband system in the\nnon-parallel misalignment case. Then, we compare the UCA-based RF analog and\nbaseband digital transceiver structures and corresponding beam steering\nschemes. Mathematical analysis and numerical simulations validate that the SE\nof the misaligned multi-mode OAM broadband system is quite low, while analog\nand digital beam steering both can significantly improve the SE of the system.\nHowever, digital beam steering can obtain higher SE than analog beam steering\nespecially when the bandwidth and the number of array elements are large, which\nvalidates that baseband digital transceiver with digital beam steering is more\nsuitable for multi-mode OAM broadband wireless communication systems in\npractice.",
    "descriptor": "",
    "authors": [
      "Zhengjuan Tian",
      "Rui Chen",
      "Wen-Xuan Long",
      "Hong Zhou",
      "Marco Moretti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.00457"
  },
  {
    "id": "arXiv:2112.00459",
    "title": "Information Theoretic Representation Distillation",
    "abstract": "Despite the empirical success of knowledge distillation, there still lacks a\ntheoretical foundation that can naturally lead to computationally inexpensive\nimplementations. To address this concern, we forge an alternative connection\nbetween information theory and knowledge distillation using a recently proposed\nentropy-like functional. In doing so, we introduce two distinct complementary\nlosses which aim to maximise the correlation and mutual information between the\nstudent and teacher representations. Our method achieves competitive\nperformance to state-of-the-art on the knowledge distillation and cross-model\ntransfer tasks, while incurring significantly less training overheads than\nclosely related and similarly performing approaches. We further demonstrate the\neffectiveness of our method on a binary distillation task, whereby we shed\nlight to a new state-of-the-art for binary quantisation. The code, evaluation\nprotocols, and trained models will be publicly available.",
    "descriptor": "",
    "authors": [
      "Roy Miles",
      "Adri\u00e1n L\u00f3pez Rodr\u00edguez",
      "Krystian Mikolajczyk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00459"
  },
  {
    "id": "arXiv:2112.00463",
    "title": "The Norm Must Go On: Dynamic Unsupervised Domain Adaptation by  Normalization",
    "abstract": "Domain adaptation is crucial to adapt a learned model to new scenarios, such\nas domain shifts or changing data distributions. Current approaches usually\nrequire a large amount of labeled or unlabeled data from the shifted domain.\nThis can be a hurdle in fields which require continuous dynamic adaptation or\nsuffer from scarcity of data, e.g. autonomous driving in challenging weather\nconditions. To address this problem of continuous adaptation to distribution\nshifts, we propose Dynamic Unsupervised Adaptation (DUA). We modify the feature\nrepresentations of the model by continuously adapting the statistics of the\nbatch normalization layers. We show that by accessing only a tiny fraction of\nunlabeled data from the shifted domain and adapting sequentially, a strong\nperformance gain can be achieved. With even less than 1% of unlabeled data from\nthe target domain, DUA already achieves competitive results to strong\nbaselines. In addition, the computational overhead is minimal in contrast to\nprevious approaches. Our approach is simple, yet effective and can be applied\nto any architecture which uses batch normalization as one of its components. We\nshow the utility of DUA by evaluating it on a variety of domain adaptation\ndatasets and tasks including object recognition, digit recognition and object\ndetection.",
    "descriptor": "",
    "authors": [
      "M. Jehanzeb Mirza",
      "Jakub Micorek",
      "Horst Possegger",
      "Horst Bischof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00463"
  },
  {
    "id": "arXiv:2112.00467",
    "title": "A unified framework to improve the interoperability between HPC and Big  Data languages and programming models",
    "abstract": "One of the most important issues in the path to the convergence of HPC and\nBig Data is caused by the differences in their software stacks. Despite some\nresearch efforts, the interoperability between their programming models and\nlanguages is still limited. To deal with this problem we introduce a new\ncomputing framework called IgnisHPC, whose main objective is to unify the\nexecution of Big Data and HPC workloads in the same framework. IgnisHPC has\nnative support for multi-language applications using JVM and non-JVM-based\nlanguages. Since MPI was used as its backbone technology, IgnisHPC takes\nadvantage of many communication models and network architectures. Moreover, MPI\napplications can be directly executed in a efficient way in the framework. The\nmain consequence is that users could combine in the same multi-language code\nHPC tasks (using MPI) with Big Data tasks (using MapReduce operations). The\nexperimental evaluation demonstrates the benefits of our proposal in terms of\nperformance and productivity with respect to other frameworks such as Apache\nSpark. IgnisHPC is publicly available for the Big Data and HPC research\ncommunity.",
    "descriptor": "\nComments: 18 pages, 22 Figures, 5 Tables, submitted to Future Generation Computer Systems journal\n",
    "authors": [
      "C\u00e9sar Pi\u00f1eiro",
      "Juan C. Pichel"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.00467"
  },
  {
    "id": "arXiv:2112.00468",
    "title": "Seeking Sinhala Sentiment: Predicting Facebook Reactions of Sinhala  Posts",
    "abstract": "The Facebook network allows its users to record their reactions to text via a\ntypology of emotions. This network, taken at scale, is therefore a prime data\nset of annotated sentiment data. This paper uses millions of such reactions,\nderived from a decade worth of Facebook post data centred around a Sri Lankan\ncontext, to model an eye of the beholder approach to sentiment detection for\nonline Sinhala textual content. Three different sentiment analysis models are\nbuilt, taking into account a limited subset of reactions, all reactions, and\nanother that derives a positive/negative star rating value. The efficacy of\nthese models in capturing the reactions of the observers are then computed and\ndiscussed. The analysis reveals that binary classification of reactions, for\nSinhala content, is significantly more accurate than the other approaches.\nFurthermore, the inclusion of the like reaction hinders the capability of\naccurately predicting other reactions.",
    "descriptor": "",
    "authors": [
      "Vihanga Jayawickrama",
      "Gihan Weeraprameshwara",
      "Nisansa de Silva",
      "Yudhanjaya Wijeratne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00468"
  },
  {
    "id": "arXiv:2112.00471",
    "title": "Triangle Counting Accelerations: From Algorithm to In-Memory Computing  Architecture",
    "abstract": "Triangles are the basic substructure of networks and triangle counting (TC)\nhas been a fundamental graph computing problem in numerous fields such as\nsocial network analysis. Nevertheless, like other graph computing problems, due\nto the high memory-computation ratio and random memory access pattern, TC\ninvolves a large amount of data transfers thus suffers from the bandwidth\nbottleneck in the traditional Von-Neumann architecture. To overcome this\nchallenge, in this paper, we propose to accelerate TC with the emerging\nprocessing-in-memory (PIM) architecture through an algorithm-architecture\nco-optimization manner. To enable the efficient in-memory implementations, we\ncome up to reformulate TC with bitwise logic operations (such as AND), and\ndevelop customized graph compression and mapping techniques for efficient data\nflow management. With the emerging computational Spin-Transfer Torque Magnetic\nRAM (STT-MRAM) array, which is one of the most promising PIM enabling\ntechniques, the device-to-architecture co-simulation results demonstrate that\nthe proposed TC in-memory accelerator outperforms the state-of-the-art GPU and\nFPGA accelerations by 12.2x and 31.8x, respectively, and achieves a 34x energy\nefficiency improvement over the FPGA accelerator.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2007.10702\n",
    "authors": [
      "Xueyan Wang",
      "Jianlei Yang",
      "Yinglin Zhao",
      "Xiaotao Jia",
      "Rong Yin",
      "Xuhang Chen",
      "Gang Qu",
      "Weisheng Zhao"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.00471"
  },
  {
    "id": "arXiv:2112.00475",
    "title": "Weakly-Supervised Video Object Grounding via Causal Intervention",
    "abstract": "We target at the task of weakly-supervised video object grounding (WSVOG),\nwhere only video-sentence annotations are available during model learning. It\naims to localize objects described in the sentence to visual regions in the\nvideo, which is a fundamental capability needed in pattern analysis and machine\nlearning. Despite the recent progress, existing methods all suffer from the\nsevere problem of spurious association, which will harm the grounding\nperformance. In this paper, we start from the definition of WSVOG and pinpoint\nthe spurious association from two aspects: (1) the association itself is not\nobject-relevant but extremely ambiguous due to weak supervision, and (2) the\nassociation is unavoidably confounded by the observational bias when taking the\nstatistics-based matching strategy in existing methods. With this in mind, we\ndesign a unified causal framework to learn the deconfounded object-relevant\nassociation for more accurate and robust video object grounding. Specifically,\nwe learn the object-relevant association by causal intervention from the\nperspective of video data generation process. To overcome the problems of\nlacking fine-grained supervision in terms of intervention, we propose a novel\nspatial-temporal adversarial contrastive learning paradigm. To further remove\nthe accompanying confounding effect within the object-relevant association, we\npursue the true causality by conducting causal intervention via backdoor\nadjustment. Finally, the deconfounded object-relevant association is learned\nand optimized under a unified causal framework in an end-to-end manner.\nExtensive experiments on both IID and OOD testing sets of three benchmarks\ndemonstrate its accurate and robust grounding performance against\nstate-of-the-arts.",
    "descriptor": "",
    "authors": [
      "Wei Wang",
      "Junyu Gao",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00475"
  },
  {
    "id": "arXiv:2112.00476",
    "title": "Data Augmentation Based on Null Model for Graph Classification",
    "abstract": "In network science, null model is typically used to generate a series of\ngraphs based on randomization under certain condition, which is widely used as\na term of comparison to verify whether the networks in question display some\nnon-trivial features, such as community structure. Since such non-trivial\nfeatures may play a significant role in graph classification, the null model\ncould provide a new perspective for regularization, so as to lead to the\nenhancement of classification performance. In this paper, we propose a novel\ndata augmentation framework based on null model for graph classification, which\ncontains four parts: feature ranking, graph data augmentation, data filtration,\nand model retraining. Moreover, in this framework, three heuristic null model\ngeneration methods are proposed for different features. Experiments are\nconducted on five famous benchmark datasets, and the results show that our\nframework has promising performance, providing a new direction of data\naugmentation for graph classification.",
    "descriptor": "",
    "authors": [
      "Qi Xuan",
      "Zeyu Wang",
      "Jinhuan Wang",
      "* Yalu Shan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.00476"
  },
  {
    "id": "arXiv:2112.00478",
    "title": "On the Practical Consistency of Meta-Reinforcement Learning Algorithms",
    "abstract": "Consistency is the theoretical property of a meta learning algorithm that\nensures that, under certain assumptions, it can adapt to any task at test time.\nAn open question is whether and how theoretical consistency translates into\npractice, in comparison to inconsistent algorithms. In this paper, we\nempirically investigate this question on a set of representative meta-RL\nalgorithms. We find that theoretically consistent algorithms can indeed usually\nadapt to out-of-distribution (OOD) tasks, while inconsistent ones cannot,\nalthough they can still fail in practice for reasons like poor exploration. We\nfurther find that theoretically inconsistent algorithms can be made consistent\nby continuing to update all agent components on the OOD tasks, and adapt as\nwell or better than originally consistent ones. We conclude that theoretical\nconsistency is indeed a desirable property, and inconsistent meta-RL algorithms\ncan easily be made consistent to enjoy the same benefits.",
    "descriptor": "",
    "authors": [
      "Zheng Xiong",
      "Luisa Zintgraf",
      "Jacob Beck",
      "Risto Vuorio",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00478"
  },
  {
    "id": "arXiv:2112.00484",
    "title": "Both Style and Fog Matter: Cumulative Domain Adaptation for Semantic  Foggy Scene Understanding",
    "abstract": "Although considerable progress has been made in semantic scene understanding\nunder clear weather, it is still a tough problem under adverse weather\nconditions, such as dense fog, due to the uncertainty caused by imperfect\nobservations. Besides, difficulties in collecting and labeling foggy images\nhinder the progress of this field. Considering the success in semantic scene\nunderstanding under clear weather, we think it is reasonable to transfer\nknowledge learned from clear images to the foggy domain. As such, the problem\nbecomes to bridge the domain gap between clear images and foggy images. Unlike\nprevious methods that mainly focus on closing the domain gap caused by fog --\ndefogging the foggy images or fogging the clear images, we propose to alleviate\nthe domain gap by considering fog influence and style variation simultaneously.\nThe motivation is based on our finding that the style-related gap and the\nfog-related gap can be divided and closed respectively, by adding an\nintermediate domain. Thus, we propose a new pipeline to cumulatively adapt\nstyle, fog and the dual-factor (style and fog). Specifically, we devise a\nunified framework to disentangle the style factor and the fog factor\nseparately, and then the dual-factor from images in different domains.\nFurthermore, we collaborate the disentanglement of three factors with a novel\ncumulative loss to thoroughly disentangle these three factors. Our method\nachieves the state-of-the-art performance on three benchmarks and shows\ngeneralization ability in rainy and snowy scenes.",
    "descriptor": "",
    "authors": [
      "Xianzheng Ma",
      "Zhixiang Wang",
      "Yacheng Zhan",
      "Yinqiang Zheng",
      "Zheng Wang",
      "Dengxin Dai",
      "Chia-Wen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00484"
  },
  {
    "id": "arXiv:2112.00485",
    "title": "Learning Transformer Features for Image Quality Assessment",
    "abstract": "Objective image quality evaluation is a challenging task, which aims to\nmeasure the quality of a given image automatically. According to the\navailability of the reference images, there are Full-Reference and No-Reference\nIQA tasks, respectively. Most deep learning approaches use regression from deep\nfeatures extracted by Convolutional Neural Networks. For the FR task, another\noption is conducting a statistical comparison on deep features. For all these\nmethods, non-local information is usually neglected. In addition, the\nrelationship between FR and NR tasks is less explored. Motivated by the recent\nsuccess of transformers in modeling contextual information, we propose a\nunified IQA framework that utilizes CNN backbone and transformer encoder to\nextract features. The proposed framework is compatible with both FR and NR\nmodes and allows for a joint training scheme. Evaluation experiments on three\nstandard IQA datasets, i.e., LIVE, CSIQ and TID2013, and KONIQ-10K, show that\nour proposed model can achieve state-of-the-art FR performance. In addition,\ncomparable NR performance is achieved in extensive experiments, and the results\nshow that the NR performance can be leveraged by the joint training scheme.",
    "descriptor": "",
    "authors": [
      "Chao Zeng",
      "Sam Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.00485"
  },
  {
    "id": "arXiv:2112.00491",
    "title": "An Age of Information Characterization of Frameless ALOHA",
    "abstract": "We provide a characterization of the peak age of information (AoI) achievable\nin a random-access system operating according to the frameless ALOHA protocol.\nDifferently from previous studies, our analysis accounts for the fact that the\nnumber of terminals contending the channel may vary over time, as a function of\nthe duration of the previous contention period. The exact characterization of\nthe AoI provided in this paper, which is based on a Markovian analysis, reveals\nthe impact of some key protocol parameters such as the maximum length of the\ncontention period, on the average peak AoI. Specifically, we show that setting\nthis parameter so as to maximize the throughput may result in an AoI\ndegradation.",
    "descriptor": "",
    "authors": [
      "Andrea Munari",
      "Francisco L\u00e1zaro",
      "Giuseppe Durisi",
      "Gianluigi Liva"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.00491"
  },
  {
    "id": "arXiv:2112.00492",
    "title": "Human-Object Interaction Detection via Weak Supervision",
    "abstract": "The goal of this paper is Human-object Interaction (HO-I) detection. HO-I\ndetection aims to find interacting human-objects regions and classify their\ninteraction from an image. Researchers obtain significant improvement in recent\nyears by relying on strong HO-I alignment supervision from [5]. HO-I alignment\nsupervision pairs humans with their interacted objects, and then aligns\nhuman-object pair(s) with their interaction categories. Since collecting such\nannotation is expensive, in this paper, we propose to detect HO-I without\nalignment supervision. We instead rely on image-level supervision that only\nenumerates existing interactions within the image without pointing where they\nhappen. Our paper makes three contributions: i) We propose Align-Former, a\nvisual-transformer based CNN that can detect HO-I with only image-level\nsupervision. ii) Align-Former is equipped with HO-I align layer, that can learn\nto select appropriate targets to allow detector supervision. iii) We evaluate\nAlign-Former on HICO-DET [5] and V-COCO [13], and show that Align-Former\noutperforms existing image-level supervised HO-I detectors by a large margin\n(4.71% mAP improvement from 16.14% to 20.85% on HICO-DET [5]).",
    "descriptor": "\nComments: Accepted at BMVC'21\n",
    "authors": [
      "Mert Kilickaya",
      "Arnold Smeulders"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00492"
  },
  {
    "id": "arXiv:2112.00494",
    "title": "Closeness Centrality via the Condorcet Principle",
    "abstract": "We uncover a new relation between Closeness centrality and the Condorcet\nprinciple. We define a Condorcet winner in a graph as a node that compared to\nany other node is closer to more nodes. In other words, if we assume that nodes\nvote on a closer candidate, a Condorcet winner would win a two-candidate\nelection against any other node in a plurality vote. We show that Closeness\ncentrality and its random-walk version, Random-Walk Closeness centrality, are\nthe only classic centrality measures that are Condorcet consistent on trees,\ni.e., if a Condorcet winner exists, they rank it first. While they are not\nCondorcet consistent in general graphs, we show that Closeness centrality\nsatisfies the Condorcet Comparison property that states that out of two\nadjacent nodes, the one preferred by more nodes has higher centrality. We show\nthat Closeness centrality is the only regular distance-based centrality with\nsuch a property.",
    "descriptor": "",
    "authors": [
      "Oskar Skibski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00494"
  },
  {
    "id": "arXiv:2112.00496",
    "title": "Revisiting the Transferability of Supervised Pretraining: an MLP  Perspective",
    "abstract": "The pretrain-finetune paradigm is a classical pipeline in visual learning.\nRecent progress on unsupervised pretraining methods shows superior transfer\nperformance to their supervised counterparts. This paper revisits this\nphenomenon and sheds new light on understanding the transferability gap between\nunsupervised and supervised pretraining from a multilayer perceptron (MLP)\nperspective. While previous works focus on the effectiveness of MLP on\nunsupervised image classification where pretraining and evaluation are\nconducted on the same dataset, we reveal that the MLP projector is also the key\nfactor to better transferability of unsupervised pretraining methods than\nsupervised pretraining methods. Based on this observation, we attempt to close\nthe transferability gap between supervised and unsupervised pretraining by\nadding an MLP projector before the classifier in supervised pretraining. Our\nanalysis indicates that the MLP projector can help retain intra-class variation\nof visual features, decrease the feature distribution distance between\npretraining and evaluation datasets, and reduce feature redundancy. Extensive\nexperiments on public benchmarks demonstrate that the added MLP projector\nsignificantly boosts the transferability of supervised pretraining, \\eg\n\\textbf{+7.2\\%} top-1 accuracy on the concept generalization task,\n\\textbf{+5.8\\%} top-1 accuracy for linear evaluation on 12-domain\nclassification tasks, and \\textbf{+0.8\\%} AP on COCO object detection task,\nmaking supervised pretraining comparable or even better than unsupervised\npretraining. Codes will be released upon acceptance.",
    "descriptor": "",
    "authors": [
      "Yizhou Wang",
      "Shixiang Tang",
      "Feng Zhu",
      "Lei Bai",
      "Rui Zhao",
      "Donglian Qi",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00496"
  },
  {
    "id": "arXiv:2112.00499",
    "title": "Structure-Aware Label Smoothing for Graph Neural Networks",
    "abstract": "Representing a label distribution as a one-hot vector is a common practice in\ntraining node classification models. However, the one-hot representation may\nnot adequately reflect the semantic characteristics of a node in different\nclasses, as some nodes may be semantically close to their neighbors in other\nclasses. It would cause over-confidence since the models are encouraged to\nassign full probabilities when classifying every node. While training models\nwith label smoothing can ease this problem to some degree, it still fails to\ncapture the nodes' semantic characteristics implied by the graph structures. In\nthis work, we propose a novel SALS (\\textit{Structure-Aware Label Smoothing})\nmethod as an enhancement component to popular node classification models. SALS\nleverages the graph structures to capture the semantic correlations between the\nconnected nodes and generate the structure-aware label distribution to replace\nthe original one-hot label vectors, thus improving the node classification\nperformance without inference costs. Extensive experiments on seven node\nclassification benchmark datasets reveal the effectiveness of our SALS on\nimproving both transductive and inductive node classification. Empirical\nresults show that SALS is superior to the label smoothing method and enhances\nthe node classification models to outperform the baseline methods.",
    "descriptor": "",
    "authors": [
      "Yiwei Wang",
      "Yujun Cai",
      "Yuxuan Liang",
      "Wei Wang",
      "Henghui Ding",
      "Muhao Chen",
      "Jing Tang",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.00499"
  },
  {
    "id": "arXiv:2112.00503",
    "title": "Zero-Shot Cross-Lingual Machine Reading Comprehension via Inter-Sentence  Dependency Graph",
    "abstract": "We target the task of cross-lingual Machine Reading Comprehension (MRC) in\nthe direct zero-shot setting, by incorporating syntactic features from\nUniversal Dependencies (UD), and the key features we use are the syntactic\nrelations within each sentence. While previous work has demonstrated effective\nsyntax-guided MRC models, we propose to adopt the inter-sentence syntactic\nrelations, in addition to the rudimentary intra-sentence relations, to further\nutilize the syntactic dependencies in the multi-sentence input of the MRC task.\nIn our approach, we build the Inter-Sentence Dependency Graph (ISDG) connecting\ndependency trees to form global syntactic relations across sentences. We then\npropose the ISDG encoder that encodes the global dependency graph, addressing\nthe inter-sentence relations via both one-hop and multi-hop dependency paths\nexplicitly. Experiments on three multilingual MRC datasets (XQuAD, MLQA,\nTyDiQA-GoldP) show that our encoder that is only trained on English is able to\nimprove the zero-shot performance on all 14 test sets covering 8 languages,\nwith up to 3.8 F1 / 5.2 EM improvement on-average, and 5.2 F1 / 11.2 EM on\ncertain languages. Further analysis shows the improvement can be attributed to\nthe attention on the cross-linguistically consistent syntactic path.",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Liyan Xu",
      "Xuchao Zhang",
      "Bo Zong",
      "Yanchi Liu",
      "Wei Cheng",
      "Jingchao Ni",
      "Haifeng Chen",
      "Liang Zhao",
      "Jinho D. Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00503"
  },
  {
    "id": "arXiv:2112.00504",
    "title": "Learning Oriented Remote Sensing Object Detection via Naive Geometric  Computing",
    "abstract": "Detecting oriented objects along with estimating their rotation information\nis one crucial step for analyzing remote sensing images. Despite that many\nmethods proposed recently have achieved remarkable performance, most of them\ndirectly learn to predict object directions under the supervision of only one\n(e.g. the rotation angle) or a few (e.g. several coordinates) groundtruth\nvalues individually. Oriented object detection would be more accurate and\nrobust if extra constraints, with respect to proposal and rotation information\nregression, are adopted for joint supervision during training. To this end, we\ninnovatively propose a mechanism that simultaneously learns the regression of\nhorizontal proposals, oriented proposals, and rotation angles of objects in a\nconsistent manner, via naive geometric computing, as one additional steady\nconstraint (see Figure 1). An oriented center prior guided label assignment\nstrategy is proposed for further enhancing the quality of proposals, yielding\nbetter performance. Extensive experiments demonstrate the model equipped with\nour idea significantly outperforms the baseline by a large margin to achieve a\nnew state-of-the-art result without any extra computational burden during\ninference. Our proposed idea is simple and intuitive that can be readily\nimplemented. Source codes and trained models are involved in supplementary\nfiles.",
    "descriptor": "",
    "authors": [
      "Yanjie Wang",
      "Xu Zou",
      "Zhijun Zhang",
      "Wenhui Xu",
      "Liqun Chen",
      "Sheng Zhong",
      "Luxin Yan",
      "Guodong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00504"
  },
  {
    "id": "arXiv:2112.00508",
    "title": "A symmetrized parametric finite element method for anisotropic surface  diffusion of closed curves via a Cahn-Hoffman $\\boldsymbol\u03be$-vector  formulation",
    "abstract": "We deal with a long-standing problem about how to design an energy-stable\nnumerical scheme for solving the motion of a closed curve under {\\sl\nanisotropic surface diffusion} with a general anisotropic surface energy\n$\\gamma(\\boldsymbol{n})$ in two dimensions, where $\\boldsymbol{n}$ is the\noutward unit normal vector. By introducing a novel symmetric positive definite\nsurface energy matrix $Z_k(\\boldsymbol{n})$ depending on the Cahn-Hoffman\n$\\boldsymbol{\\xi}$-vector and a stabilizing function $k(\\boldsymbol{n})$, we\nfirst reformulate the anisotropic surface diffusion into a conservative form\nand then derive a new symmetrized variational formulation for the anisotropic\nsurface diffusion with both weakly and strongly anisotropic surface energies. A\nsemi-discretization in space for the symmetrized variational formulation is\nproposed and its area (or mass) conservation and energy dissipation are proved.\nThe semi-discretization is then discretized in time by either an implicit\nstructural-preserving scheme (SP-PFEM) which preserves the area in the\ndiscretized level or a semi-implicit energy-stable method (ES-PFEM) which needs\nonly solve a linear system at each time step. Under a relatively simple and\nmild condition on $\\gamma(\\boldsymbol{n})$, we show that both SP-PFEM and\nES-PFEM are energy dissipative and thus are unconditionally energy-stable for\nalmost all anisotropic surface energies $\\gamma(\\boldsymbol{n})$ arising in\npractical applications. Specifically, for several commonly-used anisotropic\nsurface energies, we construct $Z_k(\\boldsymbol{n})$ explicitly. Finally,\nextensive numerical results are reported to demonstrate the efficiency and\naccuracy as well as the unconditional energy-stability of the proposed\nsymmetrized parametric finite element method.",
    "descriptor": "\nComments: 25 pages, 8 figures. arXiv admin note: text overlap with arXiv:2012.05610\n",
    "authors": [
      "Weizhu Bao",
      "Wei Jiang",
      "Yifei Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.00508"
  },
  {
    "id": "arXiv:2112.00510",
    "title": "Trimap-guided Feature Mining and Fusion Network for Natural Image  Matting",
    "abstract": "Utilizing trimap guidance and fusing multi-level features are two important\nissues for trimap-based matting with pixel-level prediction. To utilize trimap\nguidance, most existing approaches simply concatenate trimaps and images\ntogether to feed a deep network or apply an extra network to extract more\ntrimap guidance, which meets the conflict between efficiency and effectiveness.\nFor emerging content-based feature fusion, most existing matting methods only\nfocus on local features which lack the guidance of a global feature with strong\nsemantic information related to the interesting object. In this paper, we\npropose a trimap-guided feature mining and fusion network consisting of our\ntrimap-guided non-background multi-scale pooling (TMP) module and global-local\ncontext-aware fusion (GLF) modules. Considering that trimap provides strong\nsemantic guidance, our TMP module focuses effective feature mining on\ninteresting objects under the guidance of trimap without extra parameters.\nFurthermore, our GLF modules use global semantic information of interesting\nobjects mined by our TMP module to guide an effective global-local\ncontext-aware multi-level feature fusion. In addition, we build a common\ninteresting object matting (CIOM) dataset to advance high-quality image\nmatting. Experimental results on the Composition-1k test set, Alphamatting\nbenchmark, and our CIOM test set demonstrate that our method outperforms\nstate-of-the-art approaches. Code and models will be publicly available soon.",
    "descriptor": "",
    "authors": [
      "Weihao Jiang",
      "Dongdong Yu",
      "Zhaozhi Xie",
      "Yaoyi Li",
      "Zehuan Yuan",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00510"
  },
  {
    "id": "arXiv:2112.00515",
    "title": "TXOP sharing with Coordinated Spatial Reuse in Multi-AP Cooperative IEEE  802.11be WLANs",
    "abstract": "IEEE 802.11be networks (aka Wi-Fi 7) will have to cope with new\nbandwidth-hungry and low-latency services such as eXtended Reality and\nmulti-party cloud gaming. With this goal in mind, transmit opportunity (TXOP)\nsharing between coordinated access points (APs) may contribute to alleviating\ninter-AP contention, hence increasing the overall network throughput. This\npaper evaluates two coordinated TXOP sharing strategies: coordinated time\ndivision multiple access (c-TDMA) and coordinated-TDMA with spatial reuse\n(c-TDMA/SR). We show that, while c-TDMA alone does not result in any\nsignificant improvement in terms of the WLAN throughput, it lays the groundwork\nto implement coordinated SR (c-SR) techniques. To evaluate the performance of\nc-TDMA/SR, we propose a fair scheduler able to select the best subset of\nparallel transmissions in WLAN deployments, as well as the appropriate power\nlevels to be used by APs and stations (STAs), leading to maximum performance.\nThe results obtained for c-TDMA/SR show significant throughput gains compared\nwith c-TDMA, with values higher than 140% in 90% of the considered scenarios.",
    "descriptor": "",
    "authors": [
      "D. Nunez",
      "F. Wilhelmi",
      "S. Avallone",
      "M. Smith",
      "B. Bellalta"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.00515"
  },
  {
    "id": "arXiv:2112.00516",
    "title": "Simultaneous Controller and Lyapunov Function Design for Constrained  Nonlinear Systems",
    "abstract": "This paper presents a method to stabilize state and input constrained\nnonlinear systems using an offline optimization on variable triangulations of\nthe set of admissible states. For control-affine systems, by choosing a\ncontinuous piecewise affine (CPA) controller structure, the non-convex\noptimization is formulated as iterative semi-definite programming (SDP), which\ncan be solved efficiently using available software. The method has very general\nassumptions on the system's dynamics and constraints. Unlike similar existing\nmethods, it avoids finding terminal invariant sets, solving non-convex\noptimizations, and does not rely on knowing a control Lyapunov function (CLF),\nas it finds a CPA Lyapunov function explicitly. The method enforces a desired\nupper-bound on the decay rate of the state norm and finds the exact region of\nattraction. Thus, it can be also viewed as a systematic approach for finding\nLipschitz CLFs in state and input constrained control-affine systems. Using the\nCLF, a minimum norm controller is also formulated by quadratic programming for\nonline application.",
    "descriptor": "\nComments: Initial submission to ACC 2022\n",
    "authors": [
      "Reza Lavaei",
      "Leila Bridgeman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00516"
  },
  {
    "id": "arXiv:2112.00519",
    "title": "On the Complexity of the Geometric Median Problem with Outliers",
    "abstract": "In the Geometric Median problem with outliers, we are given a finite set of\npoints in d-dimensional real space and an integer m, the goal is to locate a\nnew point in space (center) and choose m of the input points to minimize the\nsum of the Euclidean distances from the center to the chosen points. This\nproblem can be solved \"almost exactly\" in polynomial time if d is fixed and\nadmits an approximation scheme PTAS in high dimensions. However, the complexity\nof the problem was an open question. We prove that, if the dimension of space\nis not fixed, Geometric Median with outliers is strongly NP-hard, does not\nadmit approximation schemes FPTAS unless P=NP, and is W[1]-hard with respect to\nthe parameter m. The proof is done by a reduction from the Independent Set\nproblem. Based on a similar reduction, we also get the NP-hardness of closely\nrelated geometric 2-clustering problems in which it is required to partition a\ngiven set of points into two balanced clusters minimizing the cost of median\nclustering. Finally, we study Geometric Median with outliers in $\\ell_\\infty$\nspace and prove the same complexity results as for the Euclidean problem.",
    "descriptor": "",
    "authors": [
      "Vladimir Shenmaier"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.00519"
  },
  {
    "id": "arXiv:2112.00527",
    "title": "Subtask-dominated Transfer Learning for Long-tail Person Search",
    "abstract": "Person search unifies person detection and person re-identification (Re-ID)\nto locate query persons from the panoramic gallery images. One major challenge\ncomes from the imbalanced long-tail person identity distributions, which\nprevents the one-step person search model from learning discriminative person\nfeatures for the final re-identification. However, it is under-explored how to\nsolve the heavy imbalanced identity distributions for the one-step person\nsearch. Techniques designed for the long-tail classification task, for example,\nimage-level re-sampling strategies, are hard to be effectively applied to the\none-step person search which jointly solves person detection and Re-ID subtasks\nwith a detection-based multi-task framework. To tackle this problem, we propose\na Subtask-dominated Transfer Learning (STL) method. The STL method solves the\nlong-tail problem in the pretraining stage of the dominated Re-ID subtask and\nimproves the one-step person search by transfer learning of the pretrained\nmodel. We further design a Multi-level RoI Fusion Pooling layer to enhance the\ndiscrimination ability of person features for the one-step person search.\nExtensive experiments on CUHK-SYSU and PRW datasets demonstrate the superiority\nand effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Chuang Liu",
      "Hua Yang",
      "Qin Zhou",
      "Shibao Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00527"
  },
  {
    "id": "arXiv:2112.00529",
    "title": "Improving gearshift controllers for electric vehicles with reinforcement  learning",
    "abstract": "During a multi-speed transmission development process, the final calibration\nof the gearshift controller parameters is usually performed on a physical test\nbench. Engineers typically treat the mapping from the controller parameters to\nthe gearshift quality as a black-box, and use methods rooted in experimental\ndesign -- a purely statistical approach -- to infer the parameter combination\nthat will maximize a chosen gearshift performance indicator. This approach\nunfortunately requires thousands of gearshift trials, ultimately discouraging\nthe exploration of different control strategies. In this work, we calibrate the\nfeedforward and feedback parameters of a gearshift controller using a\nmodel-based reinforcement learning algorithm adapted from Pilco. Experimental\nresults show that the method optimizes the controller parameters with few\ngearshift trials. This approach can accelerate the exploration of gearshift\ncontrol strategies, which is especially important for the emerging technology\nof multi-speed transmissions for electric vehicles.",
    "descriptor": "",
    "authors": [
      "Marc-Antoine Beaudoin",
      "Benoit Boulet"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00529"
  },
  {
    "id": "arXiv:2112.00532",
    "title": "FaceTuneGAN: Face Autoencoder for Convolutional Expression Transfer  Using Neural Generative Adversarial Networks",
    "abstract": "In this paper, we present FaceTuneGAN, a new 3D face model representation\ndecomposing and encoding separately facial identity and facial expression. We\npropose a first adaptation of image-to-image translation networks, that have\nsuccessfully been used in the 2D domain, to 3D face geometry. Leveraging\nrecently released large face scan databases, a neural network has been trained\nto decouple factors of variations with a better knowledge of the face, enabling\nfacial expressions transfer and neutralization of expressive faces.\nSpecifically, we design an adversarial architecture adapting the base\narchitecture of FUNIT and using SpiralNet++ for our convolutional and sampling\noperations. Using two publicly available datasets (FaceScape and CoMA),\nFaceTuneGAN has a better identity decomposition and face neutralization than\nstate-of-the-art techniques. It also outperforms classical deformation transfer\napproach by predicting blendshapes closer to ground-truth data and with less of\nundesired artifacts due to too different facial morphologies between source and\ntarget.",
    "descriptor": "",
    "authors": [
      "Nicolas Olivier",
      "Kelian Baert",
      "Fabien Danieau",
      "Franck Multon",
      "Quentin Avril"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.00532"
  },
  {
    "id": "arXiv:2112.00534",
    "title": "Empirical evaluation of shallow and deep learning classifiers for Arabic  sentiment analysis",
    "abstract": "This work presents a detailed comparison of the performance of deep learning\nmodels such as convolutional neural networks (CNN), long short-term memory\n(LSTM), gated recurrent units (GRU), their hybrids, and a selection of shallow\nlearning classifiers for sentiment analysis of Arabic reviews. Additionally,\nthe comparison includes state-of-the-art models such as the transformer\narchitecture and the araBERT pre-trained model. The datasets used in this study\nare multi-dialect Arabic hotel and book review datasets, which are some of the\nlargest publicly available datasets for Arabic reviews. Results showed deep\nlearning outperforming shallow learning for binary and multi-label\nclassification, in contrast with the results of similar work reported in the\nliterature. This discrepancy in outcome was caused by dataset size as we found\nit to be proportional to the performance of deep learning models. The\nperformance of deep and shallow learning techniques was analyzed in terms of\naccuracy and F1 score. The best performing shallow learning technique was\nRandom Forest followed by Decision Tree, and AdaBoost. The deep learning models\nperformed similarly using a default embedding layer, while the transformer\nmodel performed best when augmented with araBERT.",
    "descriptor": "",
    "authors": [
      "Ali Bou Nassif",
      "Abdollah Masoud Darya",
      "Ashraf Elnagar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00534"
  },
  {
    "id": "arXiv:2112.00538",
    "title": "'Entanglement' -- A new dynamic metric to measure team flow",
    "abstract": "We introduce \"entanglement\", a novel metric to measure how synchronized\ncommunication between team members is. This measure calculates the Euclidean\ndistance among team members' social network metrics timeseries. We validate the\nmetric with four case studies. The first case study uses entanglement of 11\nmedical innovation teams to predict team performance and learning behavior. The\nsecond case looks at the e-mail communication of 113 senior executives of an\ninternational services firm, predicting employee turnover through lack of\nentanglement of an employee. The third case analyzes the individual employee\nperformance of 81 managers. The fourth case study predicts performance of 13\ncustomer-dedicated teams at a big international company by comparing\nentanglement in the e-mail interactions with satisfaction of their customers\nmeasured through Net Promoter Score (NPS). While we can only speculate about\nwhat is causing the entanglement effect, we find that it is a new and versatile\nindicator for the analysis of employees' communication, analyzing the hitherto\nunderused temporal dimension of online social networks which could be used as a\npowerful predictor of employee and team performance, employee turnover, and\ncustomer satisfaction.",
    "descriptor": "",
    "authors": [
      "P. A.Gloor",
      "M. P. Zylka",
      "A. Fronzetti Colladon",
      "M. Makai"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.00538"
  },
  {
    "id": "arXiv:2112.00544",
    "title": "Molecular Contrastive Learning with Chemical Element Knowledge Graph",
    "abstract": "Molecular representation learning contributes to multiple downstream tasks\nsuch as molecular property prediction and drug design. To properly represent\nmolecules, graph contrastive learning is a promising paradigm as it utilizes\nself-supervision signals and has no requirements for human annotations.\nHowever, prior works fail to incorporate fundamental domain knowledge into\ngraph semantics and thus ignore the correlations between atoms that have common\nattributes but are not directly connected by bonds. To address these issues, we\nconstruct a Chemical Element Knowledge Graph (KG) to summarize microscopic\nassociations between elements and propose a novel Knowledge-enhanced\nContrastive Learning (KCL) framework for molecular representation learning. KCL\nframework consists of three modules. The first module, knowledge-guided graph\naugmentation, augments the original molecular graph based on the Chemical\nElement KG. The second module, knowledge-aware graph representation, extracts\nmolecular representations with a common graph encoder for the original\nmolecular graph and a Knowledge-aware Message Passing Neural Network (KMPNN) to\nencode complex information in the augmented molecular graph. The final module\nis a contrastive objective, where we maximize agreement between these two views\nof molecular graphs. Extensive experiments demonstrated that KCL obtained\nsuperior performances against state-of-the-art baselines on eight molecular\ndatasets. Visualization experiments properly interpret what KCL has learned\nfrom atoms and attributes in the augmented molecular graphs. Our codes and data\nare available in supplementary materials.",
    "descriptor": "\nComments: Accepted in AAAI 2022 Main track\n",
    "authors": [
      "Yin Fang",
      "Qiang Zhang",
      "Haihong Yang",
      "Xiang Zhuang",
      "Shumin Deng",
      "Wen Zhang",
      "Ming Qin",
      "Zhuo Chen",
      "Xiaohui Fan",
      "Huajun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.00544"
  },
  {
    "id": "arXiv:2112.00552",
    "title": "SaDe: Learning Models that Provably Satisfy Domain Constraints",
    "abstract": "With increasing real world applications of machine learning, models are often\nrequired to comply with certain domain based requirements, e.g., safety\nguarantees in aircraft systems, legal constraints in a loan approval model. A\nnatural way to represent these properties is in the form of constraints.\nIncluding such constraints in machine learning is typically done by the means\nof regularization, which does not guarantee satisfaction of the constraints. In\nthis paper, we present a machine learning approach that can handle a wide\nvariety of constraints, and guarantee that these constraints will be satisfied\nby the model even on unseen data. We cast machine learning as a maximum\nsatisfiability problem, and solve it using a novel algorithm SaDe which\ncombines constraint satisfaction with gradient descent. We demonstrate on three\nuse cases that this approach learns models that provably satisfy the given\nconstraints.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Kshitij Goyal",
      "Sebastijan Dumancic",
      "Hendrik Blockeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.00552"
  },
  {
    "id": "arXiv:2112.00554",
    "title": "Quoting is not Citing: Disentangling Affiliation and Interaction on  Twitter",
    "abstract": "Interaction networks are generally much less homophilic than affiliation\nnetworks, accommodating for many more cross-cutting links. By statistically\nassigning a political valence to users from their network-level affiliation\npatterns, and by further contrasting interaction and affiliation (quotes and\nretweets) within specific discursive events, namely quote trees, we describe a\nvariety of cross-cutting patterns which significantly nuance the traditional\n\"echo chamber\" narrative.",
    "descriptor": "\nComments: Proc. Complex Networks'21, 10th International Conference on Complex Networks and their Applications\n",
    "authors": [
      "Camille Roth",
      "Jonathan St-Onge",
      "Katrin Herms"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2112.00554"
  },
  {
    "id": "arXiv:2112.00556",
    "title": "Semi-Supervised Surface Anomaly Detection of Composite Wind Turbine  Blades From Drone Imagery",
    "abstract": "Within commercial wind energy generation, the monitoring and predictive\nmaintenance of wind turbine blades in-situ is a crucial task, for which remote\nmonitoring via aerial survey from an Unmanned Aerial Vehicle (UAV) is\ncommonplace. Turbine blades are susceptible to both operational and\nweather-based damage over time, reducing the energy efficiency output of\nturbines. In this study, we address automating the otherwise time-consuming\ntask of both blade detection and extraction, together with fault detection\nwithin UAV-captured turbine blade inspection imagery. We propose BladeNet, an\napplication-based, robust dual architecture to perform both unsupervised\nturbine blade detection and extraction, followed by super-pixel generation\nusing the Simple Linear Iterative Clustering (SLIC) method to produce regional\nclusters. These clusters are then processed by a suite of semi-supervised\ndetection methods. Our dual architecture detects surface faults of glass fibre\ncomposite material blades with high aptitude while requiring minimal prior\nmanual image annotation. BladeNet produces an Average Precision (AP) of 0.995\nacross our {\\O}rsted blade inspection dataset for offshore wind turbines and\n0.223 across the Danish Technical University (DTU) NordTank turbine blade\ninspection dataset. BladeNet also obtains an AUC of 0.639 for surface anomaly\ndetection across the {\\O}rsted blade inspection dataset.",
    "descriptor": "\nComments: In-proceedings at 2022 17th International Conference on Computer Vision Theory and Applications (VISAPP)\n",
    "authors": [
      "Jack. W. Barker",
      "Neelanjan Bhowmik",
      "Toby. P. Breckon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.00556"
  },
  {
    "id": "arXiv:2112.00557",
    "title": "3D Reconstruction Using a Linear Laser Scanner and a Camera",
    "abstract": "With the rapid development of computer graphics and vision, several\nthree-dimensional (3D) reconstruction techniques have been proposed and used to\nobtain the 3D representation of objects in the form of point cloud models, mesh\nmodels, and geometric models. The cost of 3D reconstruction is declining due to\nthe maturing of this technology, however, the inexpensive 3D reconstruction\nscanners on the market may not be able to generate a clear point cloud model as\nexpected. This study systematically reviews some basic types of 3D\nreconstruction technology and introduces an easy implementation using a linear\nlaser scanner, a camera, and a turntable. The implementation is based on the\nmonovision with laser and has tested several objects like wiki and mug. The\naccuracy and resolution of the point cloud result are quite satisfying. It\nturns out everyone can build such a 3D reconstruction system with appropriate\nprocedures.",
    "descriptor": "\nComments: 8 pages, 16 figures, published in The 2nd International Conference on Artificial Intelligence and Computer Engineering (ICAICE2021)\n",
    "authors": [
      "Rui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00557"
  },
  {
    "id": "arXiv:2112.00560",
    "title": "Attribute Artifacts Removal for Geometry-based Point Cloud Compression",
    "abstract": "Geometry-based point cloud compression (G-PCC) can achieve remarkable\ncompression efficiency for point clouds. However, it still leads to serious\nattribute compression artifacts, especially under low bitrate scenarios. In\nthis paper, we propose a Multi-Scale Graph Attention Network (MS-GAT) to remove\nthe artifacts of point cloud attributes compressed by G-PCC. We first construct\na graph based on point cloud geometry coordinates and then use the Chebyshev\ngraph convolutions to extract features of point cloud attributes. Considering\nthat one point may be correlated with points both near and far away from it, we\npropose a multi-scale scheme to capture the short and long range correlations\nbetween the current point and its neighboring and distant points. To address\nthe problem that various points may have different degrees of artifacts caused\nby adaptive quantization, we introduce the quantization step per point as an\nextra input to the proposed network. We also incorporate a graph attentional\nlayer into the network to pay special attention to the points with more\nattribute artifacts. To the best of our knowledge, this is the first attribute\nartifacts removal method for G-PCC. We validate the effectiveness of our method\nover various point clouds. Experimental results show that our proposed method\nachieves an average of 9.28% BD-rate reduction. In addition, our approach\nachieves some performance improvements for the downstream point cloud semantic\nsegmentation task.",
    "descriptor": "",
    "authors": [
      "Xihua Sheng",
      "Li Li",
      "Dong Liu",
      "Zhiwei Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.00560"
  },
  {
    "id": "arXiv:2112.00566",
    "title": "NLP Research and Resources at DaSciM, Ecole Polytechnique",
    "abstract": "DaSciM (Data Science and Mining) part of LIX at Ecole Polytechnique,\nestablished in 2013 and since then producing research results in the area of\nlarge scale data analysis via methods of machine and deep learning. The group\nhas been specifically active in the area of NLP and text mining with\ninteresting results at methodological and resources level. Here follow our\ndifferent contributions of interest to the AFIA community.",
    "descriptor": "",
    "authors": [
      "Hadi Abdine",
      "Yanzhu Guo",
      "Moussa Kamal Eddine",
      "Giannis Nikolentzos",
      "Stamatis Outsios",
      "Guokan Shang",
      "Christos Xypolopoulos",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00566"
  },
  {
    "id": "arXiv:2112.00567",
    "title": "DPRK-BERT: The Supreme Language Model",
    "abstract": "Deep language models have achieved remarkable success in the NLP domain. The\nstandard way to train a deep language model is to employ unsupervised learning\nfrom scratch on a large unlabeled corpus. However, such large corpora are only\navailable for widely-adopted and high-resource languages and domains. This\nstudy presents the first deep language model, DPRK-BERT, for the DPRK language.\nWe achieve this by compiling the first unlabeled corpus for the DPRK language\nand fine-tuning a preexisting the ROK language model. We compare the proposed\nmodel with existing approaches and show significant improvements on two DPRK\ndatasets. We also present a cross-lingual version of this model which yields\nbetter generalization across the two Korean languages. Finally, we provide\nvarious NLP tools related to the DPRK language that would foster future\nresearch.",
    "descriptor": "",
    "authors": [
      "Arda Akdemir",
      "Yeojoo Jeon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00567"
  },
  {
    "id": "arXiv:2112.00568",
    "title": "Dual Spoof Disentanglement Generation for Face Anti-spoofing with Depth  Uncertainty Learning",
    "abstract": "Face anti-spoofing (FAS) plays a vital role in preventing face recognition\nsystems from presentation attacks. Existing face anti-spoofing datasets lack\ndiversity due to the insufficient identity and insignificant variance, which\nlimits the generalization ability of FAS model. In this paper, we propose Dual\nSpoof Disentanglement Generation (DSDG) framework to tackle this challenge by\n\"anti-spoofing via generation\". Depending on the interpretable factorized\nlatent disentanglement in Variational Autoencoder (VAE), DSDG learns a joint\ndistribution of the identity representation and the spoofing pattern\nrepresentation in the latent space. Then, large-scale paired live and spoofing\nimages can be generated from random noise to boost the diversity of the\ntraining set. However, some generated face images are partially distorted due\nto the inherent defect of VAE. Such noisy samples are hard to predict precise\ndepth values, thus may obstruct the widely-used depth supervised optimization.\nTo tackle this issue, we further introduce a lightweight Depth Uncertainty\nModule (DUM), which alleviates the adverse effects of noisy samples by depth\nuncertainty learning. DUM is developed without extra-dependency, thus can be\nflexibly integrated with any depth supervised network for face anti-spoofing.\nWe evaluate the effectiveness of the proposed method on five popular benchmarks\nand achieve state-of-the-art results under both intra- and inter- test\nsettings. The codes are available at\nhttps://github.com/JDAI-CV/FaceX-Zoo/tree/main/addition_module/DSDG.",
    "descriptor": "\nComments: Accepted to TCSVT, arXiv version. The codes are available at this https URL\n",
    "authors": [
      "Hangtong Wu",
      "Dan Zen",
      "Yibo Hu",
      "Hailin Shi",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00568"
  },
  {
    "id": "arXiv:2112.00570",
    "title": "Toward Foundation Models for Earth Monitoring: Proposal for a Climate  Change Benchmark",
    "abstract": "Recent progress in self-supervision shows that pre-training large neural\nnetworks on vast amounts of unsupervised data can lead to impressive increases\nin generalisation for downstream tasks. Such models, recently coined as\nfoundation models, have been transformational to the field of natural language\nprocessing. While similar models have also been trained on large corpuses of\nimages, they are not well suited for remote sensing data. To stimulate the\ndevelopment of foundation models for Earth monitoring, we propose to develop a\nnew benchmark comprised of a variety of downstream tasks related to climate\nchange. We believe that this can lead to substantial improvements in many\nexisting applications and facilitate the development of new applications. This\nproposal is also a call for collaboration with the aim of developing a better\nevaluation process to mitigate potential downsides of foundation models for\nEarth monitoring.",
    "descriptor": "",
    "authors": [
      "Alexandre Lacoste",
      "Evan David Sherwin",
      "Hannah Kerner",
      "Hamed Alemohammad",
      "Bj\u00f6rn L\u00fctjens",
      "Jeremy Irvin",
      "David Dao",
      "Alex Chang",
      "Mehmet Gunturkun",
      "Alexandre Drouin",
      "Pau Rodriguez",
      "David Vazquez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.00570"
  },
  {
    "id": "arXiv:2112.00574",
    "title": "Collective discrete optimisation as judgment aggregation",
    "abstract": "Many important collective decision-making problems can be seen as multi-agent\nversions of discrete optimisation problems. Participatory budgeting, for\ninstance, is the collective version of the knapsack problem; other examples\ninclude collective scheduling, and collective spanning trees. Rather than\ndeveloping a specific model, as well as specific algorithmic techniques, for\neach of these problems, we propose to represent and solve them in the unifying\nframework of judgment aggregation with weighted issues. We provide a modular\ndefinition of collective discrete optimisation (CDO) rules based on coupling a\nset scoring function with an operator, and we show how they generalise several\nexisting procedures developed for specific CDO problems. We also give an\nimplementation based on integer linear programming (ILP) and test it on the\nproblem of collective spanning trees.",
    "descriptor": "",
    "authors": [
      "Linus Boes",
      "Rachael Colley",
      "Umberto Grandi",
      "Jerome Lang",
      "Arianna Novaro"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.00574"
  },
  {
    "id": "arXiv:2112.00578",
    "title": "Systematic Generalization with Edge Transformers",
    "abstract": "Recent research suggests that systematic generalization in natural language\nunderstanding remains a challenge for state-of-the-art neural models such as\nTransformers and Graph Neural Networks. To tackle this challenge, we propose\nEdge Transformer, a new model that combines inspiration from Transformers and\nrule-based symbolic AI. The first key idea in Edge Transformers is to associate\nvector states with every edge, that is, with every pair of input nodes -- as\nopposed to just every node, as it is done in the Transformer model. The second\nmajor innovation is a triangular attention mechanism that updates edge\nrepresentations in a way that is inspired by unification from logic\nprogramming. We evaluate Edge Transformer on compositional generalization\nbenchmarks in relational reasoning, semantic parsing, and dependency parsing.\nIn all three settings, the Edge Transformer outperforms Relation-aware,\nUniversal and classical Transformer baselines.",
    "descriptor": "\nComments: Accepted as a conference paper at NeurIPS 2021\n",
    "authors": [
      "Leon Bergen",
      "Timothy J. O'Donnell",
      "Dzmitry Bahdanau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00578"
  },
  {
    "id": "arXiv:2112.00579",
    "title": "Conditional Expectation based Value Decomposition for Scalable On-Demand  Ride Pooling",
    "abstract": "Owing to the benefits for customers (lower prices), drivers (higher\nrevenues), aggregation companies (higher revenues) and the environment (fewer\nvehicles), on-demand ride pooling (e.g., Uber pool, Grab Share) has become\nquite popular. The significant computational complexity of matching vehicles to\ncombinations of requests has meant that traditional ride pooling approaches are\nmyopic in that they do not consider the impact of current matches on future\nvalue for vehicles/drivers. Recently, Neural Approximate Dynamic Programming\n(NeurADP) has employed value decomposition with Approximate Dynamic Programming\n(ADP) to outperform leading approaches by considering the impact of an\nindividual agent's (vehicle) chosen actions on the future value of that agent.\nHowever, in order to ensure scalability and facilitate city-scale ride pooling,\nNeurADP completely ignores the impact of other agents actions on individual\nagent/vehicle value. As demonstrated in our experimental results, ignoring the\nimpact of other agents actions on individual value can have a significant\nimpact on the overall performance when there is increased competition among\nvehicles for demand. Our key contribution is a novel mechanism based on\ncomputing conditional expectations through joint conditional probabilities for\ncapturing dependencies on other agents actions without increasing the\ncomplexity of training or decision making. We show that our new approach,\nConditional Expectation based Value Decomposition (CEVD) outperforms NeurADP by\nup to 9.76% in terms of overall requests served, which is a significant\nimprovement on a city wide benchmark taxi dataset.",
    "descriptor": "\nComments: Preprint. Under Review. arXiv admin note: text overlap with arXiv:1911.08842\n",
    "authors": [
      "Avinandan Bose",
      "Pradeep Varakantham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.00579"
  },
  {
    "id": "arXiv:2112.00580",
    "title": "Background Activation Suppression for Weakly Supervised Object  Localization",
    "abstract": "Weakly supervised object localization (WSOL) aims to localize the object\nregion using only image-level labels as supervision. Recently a new paradigm\nhas emerged by generating a foreground prediction map (FPM) to achieve the\nlocalization task. Existing FPM-based methods use cross-entropy (CE) to\nevaluate the foreground prediction map and to guide the learning of generator.\nWe argue for using activation value to achieve more efficient learning. It is\nbased on the experimental observation that, for a trained network, CE converges\nto zero when the foreground mask covers only part of the object region. While\nactivation value increases until the mask expands to the object boundary, which\nindicates that more object areas can be learned by using activation value. In\nthis paper, we propose a Background Activation Suppression (BAS) method.\nSpecifically, an Activation Map Constraint module (AMC) is designed to\nfacilitate the learning of generator by suppressing the background activation\nvalues. Meanwhile, by using the foreground region guidance and the area\nconstraint, BAS can learn the whole region of the object. Furthermore, in the\ninference phase, we consider the prediction maps of different categories\ntogether to obtain the final localization results. Extensive experiments show\nthat BAS achieves significant and consistent improvement over the baseline\nmethods on the CUB-200-2011 and ILSVRC datasets.",
    "descriptor": "\nComments: Technical report, Code: this https URL\n",
    "authors": [
      "Pingyu Wu",
      "Wei Zhai",
      "Yang Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00580"
  },
  {
    "id": "arXiv:2112.00582",
    "title": "Transformer-based Network for RGB-D Saliency Detection",
    "abstract": "RGB-D saliency detection integrates information from both RGB images and\ndepth maps to improve prediction of salient regions under challenging\nconditions. The key to RGB-D saliency detection is to fully mine and fuse\ninformation at multiple scales across the two modalities. Previous approaches\ntend to apply the multi-scale and multi-modal fusion separately via local\noperations, which fails to capture long-range dependencies. Here we propose a\ntransformer-based network to address this issue. Our proposed architecture is\ncomposed of two modules: a transformer-based within-modality feature\nenhancement module (TWFEM) and a transformer-based feature fusion module\n(TFFM). TFFM conducts a sufficient feature fusion by integrating features from\nmultiple scales and two modalities over all positions simultaneously. TWFEM\nenhances feature on each scale by selecting and integrating complementary\ninformation from other scales within the same modality before TFFM. We show\nthat transformer is a uniform operation which presents great efficacy in both\nfeature fusion and feature enhancement, and simplifies the model design.\nExtensive experimental results on six benchmark datasets demonstrate that our\nproposed network performs favorably against state-of-the-art RGB-D saliency\ndetection methods.",
    "descriptor": "",
    "authors": [
      "Yue Wang",
      "Xu Jia",
      "Lu Zhang",
      "Yuke Li",
      "James Elder",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00582"
  },
  {
    "id": "arXiv:2112.00583",
    "title": "Meta Arcade: A Configurable Environment Suite for Meta-Learning",
    "abstract": "Most approaches to deep reinforcement learning (DRL) attempt to solve a\nsingle task at a time. As a result, most existing research benchmarks consist\nof individual games or suites of games that have common interfaces but little\noverlap in their perceptual features, objectives, or reward structures. To\nfacilitate research into knowledge transfer among trained agents (e.g. via\nmulti-task and meta-learning), more environment suites that provide\nconfigurable tasks with enough commonality to be studied collectively are\nneeded. In this paper we present Meta Arcade, a tool to easily define and\nconfigure custom 2D arcade games that share common visuals, state spaces,\naction spaces, game components, and scoring mechanisms. Meta Arcade differs\nfrom prior environments in that both task commonality and configurability are\nprioritized: entire sets of games can be constructed from common elements, and\nthese elements are adjustable through exposed parameters. We include a suite of\n24 predefined games that collectively illustrate the possibilities of this\nframework and discuss how these games can be configured for research\napplications. We provide several experiments that illustrate how Meta Arcade\ncould be used, including single-task benchmarks of predefined games, sample\ncurriculum-based approaches that change game parameters over a set schedule,\nand an exploration of transfer learning between games.",
    "descriptor": "\nComments: 17 pages, 6 figures, 6 tables, extended version of an accepted paper to NeurIPS DRL Workshop 2021\n",
    "authors": [
      "Edward W. Staley",
      "Chace Ashcraft",
      "Benjamin Stoler",
      "Jared Markowitz",
      "Gautam Vallabha",
      "Christopher Ratto",
      "Kapil D. Katyal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00583"
  },
  {
    "id": "arXiv:2112.00584",
    "title": "The Shape Part Slot Machine: Contact-based Reasoning for Generating 3D  Shapes from Parts",
    "abstract": "We present the Shape Part Slot Machine, a new method for assembling novel 3D\nshapes from existing parts by performing contact-based reasoning. Our method\nrepresents each shape as a graph of \"slots,\" where each slot is a region of\ncontact between two shape parts. Based on this representation, we design a\ngraph-neural-network-based model for generating new slot graphs and retrieving\ncompatible parts, as well as a gradient-descent-based optimization scheme for\nassembling the retrieved parts into a complete shape that respects the\ngenerated slot graph. This approach does not require any semantic part labels;\ninterestingly, it also does not require complete part geometries -- reasoning\nabout the regions where parts connect proves sufficient to generate novel,\nhigh-quality 3D shapes. We demonstrate that our method generates shapes that\noutperform existing modeling-by-assembly approaches in terms of quality,\ndiversity, and structural complexity.",
    "descriptor": "",
    "authors": [
      "Kai Wang",
      "Paul Guerrero",
      "Vladimir Kim",
      "Siddhartha Chaudhuri",
      "Minhyuk Sung",
      "Daniel Ritchie"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00584"
  },
  {
    "id": "arXiv:2112.00585",
    "title": "Neural Emotion Director: Speech-preserving semantic control of facial  expressions in \"in-the-wild\" videos",
    "abstract": "In this paper, we introduce a novel deep learning method for photo-realistic\nmanipulation of the emotional state of actors in \"in-the-wild\" videos. The\nproposed method is based on a parametric 3D face representation of the actor in\nthe input scene that offers a reliable disentanglement of the facial identity\nfrom the head pose and facial expressions. It then uses a novel deep domain\ntranslation framework that alters the facial expressions in a consistent and\nplausible manner, taking into account their dynamics. Finally, the altered\nfacial expressions are used to photo-realistically manipulate the facial region\nin the input scene based on an especially-designed neural face renderer. To the\nbest of our knowledge, our method is the first to be capable of controlling the\nactor's facial expressions by even using as a sole input the semantic labels of\nthe manipulated emotions, while at the same time preserving the speech-related\nlip movements. We conduct extensive qualitative and quantitative evaluations\nand comparisons, which demonstrate the effectiveness of our approach and the\nespecially promising results that we obtain. Our method opens a plethora of new\npossibilities for useful applications of neural rendering technologies, ranging\nfrom movie post-production and video games to photo-realistic affective\navatars.",
    "descriptor": "",
    "authors": [
      "Foivos Paraperas Papantoniou",
      "Panagiotis P. Filntisis",
      "Petros Maragos",
      "Anastasios Roussos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00585"
  },
  {
    "id": "arXiv:2112.00588",
    "title": "Outlier Detection using AI: A Survey",
    "abstract": "An outlier is an event or observation that is defined as an unusual activity,\nintrusion, or a suspicious data point that lies at an irregular distance from a\npopulation. The definition of an outlier event, however, is subjective and\ndepends on the application and the domain (Energy, Health, Wireless Network,\netc.). It is important to detect outlier events as carefully as possible to\navoid infrastructure failures because anomalous events can cause minor to\nsevere damage to infrastructure. For instance, an attack on a cyber-physical\nsystem such as a microgrid may initiate voltage or frequency instability,\nthereby damaging a smart inverter which involves very expensive repairing.\nUnusual activities in microgrids can be mechanical faults, behavior changes in\nthe system, human or instrument errors or a malicious attack. Accordingly, and\ndue to its variability, Outlier Detection (OD) is an ever-growing research\nfield. In this chapter, we discuss the progress of OD methods using AI\ntechniques. For that, the fundamental concepts of each OD model are introduced\nvia multiple categories. Broad range of OD methods are categorized into six\nmajor categories: Statistical-based, Distance-based, Density-based,\nClustering-based, Learning-based, and Ensemble methods. For every category, we\ndiscuss recent state-of-the-art approaches, their application areas, and\nperformances. After that, a brief discussion regarding the advantages,\ndisadvantages, and challenges of each technique is provided with\nrecommendations on future research directions. This survey aims to guide the\nreader to better understand recent progress of OD methods for the assurance of\nAI.",
    "descriptor": "\nComments: Chapter 7 in book: AI Assurance, by Elsevier Academic Press. Edited by: Feras A. Batarseh and Laura Freeman Publication year: 2022\n",
    "authors": [
      "Md Nazmul Kabir Sikder",
      "Feras A. Batarseh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00588"
  },
  {
    "id": "arXiv:2112.00590",
    "title": "Building astroBERT, a language model for Astronomy & Astrophysics",
    "abstract": "The existing search tools for exploring the NASA Astrophysics Data System\n(ADS) can be quite rich and empowering (e.g., similar and trending operators),\nbut researchers are not yet allowed to fully leverage semantic search. For\nexample, a query for \"results from the Planck mission\" should be able to\ndistinguish between all the various meanings of Planck (person, mission,\nconstant, institutions and more) without further clarification from the user.\nAt ADS, we are applying modern machine learning and natural language processing\ntechniques to our dataset of recent astronomy publications to train astroBERT,\na deeply contextual language model based on research at Google. Using\nastroBERT, we aim to enrich the ADS dataset and improve its discoverability,\nand in particular we are developing our own named entity recognition tool. We\npresent here our preliminary results and lessons learned.",
    "descriptor": "",
    "authors": [
      "Felix Grezes",
      "Sergi Blanco-Cuaresma",
      "Alberto Accomazzi",
      "Michael J. Kurtz",
      "Golnaz Shapurian",
      "Edwin Henneken",
      "Carolyn S. Grant",
      "Donna M. Thompson",
      "Roman Chyla",
      "Stephen McDonald",
      "Timothy W. Hostetler",
      "Matthew R. Templeton",
      "Kelly E. Lockhart",
      "Nemanja Martinovic",
      "Shinyi Chen",
      "Chris Tanner",
      "Pavlos Protopapas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00590"
  },
  {
    "id": "arXiv:2112.00591",
    "title": "AI Assurance using Causal Inference: Application to Public Policy",
    "abstract": "Developing and implementing AI-based solutions help state and federal\ngovernment agencies, research institutions, and commercial companies enhance\ndecision-making processes, automate chain operations, and reduce the\nconsumption of natural and human resources. At the same time, most AI\napproaches used in practice can only be represented as \"black boxes\" and suffer\nfrom the lack of transparency. This can eventually lead to unexpected outcomes\nand undermine trust in such systems. Therefore, it is crucial not only to\ndevelop effective and robust AI systems, but to make sure their internal\nprocesses are explainable and fair. Our goal in this chapter is to introduce\nthe topic of designing assurance methods for AI systems with high-impact\ndecisions using the example of the technology sector of the US economy. We\nexplain how these fields would benefit from revealing cause-effect\nrelationships between key metrics in the dataset by providing the causal\nexperiment on technology economics dataset. Several causal inference approaches\nand AI assurance techniques are reviewed and the transformation of the data\ninto a graph-structured dataset is demonstrated.",
    "descriptor": "\nComments: Chapter 8 in book: AI Assurance, by Elsevier Academic Press. Edited by: Feras A. Batarseh and Laura Freeman Publication year: 2022\n",
    "authors": [
      "Andrei Svetovidov",
      "Abdul Rahman",
      "Feras A. Batarseh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.00591"
  },
  {
    "id": "arXiv:2112.00592",
    "title": "BeamSync: Over-The-Air Carrier Synchronization in Distributed  RadioWeaves",
    "abstract": "In a distributed multi-antenna system, multiple geographically separated\ntransmit nodes communicate simultaneously to a receive node. Synchronization of\nthese nodes is essential to achieve a good performance at the receiver.\nRadioWeaves is a new paradigm of cell-free massive MIMO array deployment using\ndistributed multi-antenna panels in indoor environments. In this paper, we\nstudy the carrier frequency synchronization problem in distributed RadioWeave\npanels. We propose a novel, over-the-air synchronization protocol, which we\ncall as BeamSync, to synchronize all the different multi-antenna transmit\npanels. We also show that beamforming the synchronization signal in the\ndominant direction of the channel between the panels is optimal and the\nsynchronization performance is significantly better than traditional\nbeamforming techniques.",
    "descriptor": "\nComments: 6 pages, 6 figures. Accepted in 25th International ITG Workshop on Smart Antennas (WSA 2021)\n",
    "authors": [
      "Unnikrishnan Kunnath Ganesan",
      "Rimalapudi Sarvendranath",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.00592"
  },
  {
    "id": "arXiv:2112.00597",
    "title": "Wish you were here: Hindsight Goal Selection for long-horizon dexterous  manipulation",
    "abstract": "Complex sequential tasks in continuous-control settings often require agents\nto successfully traverse a set of \"narrow passages\" in their state space.\nSolving such tasks with a sparse reward in a sample-efficient manner poses a\nchallenge to modern reinforcement learning (RL) due to the associated\nlong-horizon nature of the problem and the lack of sufficient positive signal\nduring learning. Various tools have been applied to address this challenge.\nWhen available, large sets of demonstrations can guide agent exploration.\nHindsight relabelling on the other hand does not require additional sources of\ninformation. However, existing strategies explore based on task-agnostic goal\ndistributions, which can render the solution of long-horizon tasks impractical.\nIn this work, we extend hindsight relabelling mechanisms to guide exploration\nalong task-specific distributions implied by a small set of successful\ndemonstrations. We evaluate the approach on four complex, single and dual arm,\nrobotics manipulation tasks against strong suitable baselines. The method\nrequires far fewer demonstrations to solve all tasks and achieves a\nsignificantly higher overall performance as task complexity increases. Finally,\nwe investigate the robustness of the proposed solution with respect to the\nquality of input representations and the number of demonstrations.",
    "descriptor": "",
    "authors": [
      "Todor Davchev",
      "Oleg Sushkov",
      "Jean-Baptiste Regli",
      "Stefan Schaal",
      "Yusuf Aytar",
      "Markus Wulfmeier",
      "Jon Scholz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00597"
  },
  {
    "id": "arXiv:2112.00599",
    "title": "An implementation of the \"Guess who?\" game using CLIP",
    "abstract": "CLIP (Contrastive Language-Image Pretraining) is an efficient method for\nlearning computer vision tasks from natural language supervision that has\npowered a recent breakthrough in deep learning due to its zero-shot transfer\ncapabilities. By training from image-text pairs available on the internet, the\nCLIP model transfers non-trivially to most tasks without the need for any data\nset specific training. In this work, we use CLIP to implement the engine of the\npopular game \"Guess who?\", so that the player interacts with the game using\nnatural language prompts and CLIP automatically decides whether an image in the\ngame board fulfills that prompt or not. We study the performance of this\napproach by benchmarking on different ways of prompting the questions to CLIP,\nand show the limitations of its zero-shot capabilites.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Arnau Mart\u00ed Sarri",
      "Victor Rodriguez-Fernandez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00599"
  },
  {
    "id": "arXiv:2112.00600",
    "title": "Towards Futuristic Autonomous Experimentation--A Surprise-Reacting  Sequential Experiment Policy",
    "abstract": "An autonomous experimentation platform in manufacturing is supposedly capable\nof conducting a sequential search for finding suitable manufacturing conditions\nfor advanced materials by itself or even for discovering new materials with\nminimal human intervention. The core of the intelligent control of such\nplatforms is the policy directing sequential experiments, namely, to decide\nwhere to conduct the next experiment based on what has been done thus far. Such\npolicy inevitably trades off exploitation versus exploration and the current\npractice is under the Bayesian optimization framework using the expected\nimprovement criterion or its variants. We discuss whether it is beneficial to\ntrade off exploitation versus exploration by measuring the element and degree\nof surprise associated with the immediate past observation. We devise a\nsurprise-reacting policy using two existing surprise metrics, known as the\nShannon surprise and Bayesian surprise. Our analysis shows that the\nsurprise-reacting policy appears to be better suited for quickly characterizing\nthe overall landscape of a response surface or a design place under resource\nconstraints. We argue that such capability is much needed for futuristic\nautonomous experimentation platforms. We do not claim that we have a fully\nautonomous experimentation platform, but believe that our current effort sheds\nnew lights or provides a different view angle as researchers are racing to\nelevate the autonomy of various primitive autonomous experimentation systems.",
    "descriptor": "",
    "authors": [
      "Imtiaz Ahmed",
      "Satish Bukkapatnam",
      "Bhaskar Botcha",
      "Yu Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00600"
  },
  {
    "id": "arXiv:2112.00604",
    "title": "Near-Optimal Distributed Degree+1 Coloring",
    "abstract": "We present a new approach to randomized distributed graph coloring that is\nsimpler and more efficient than previous ones. In particular, it allows us to\ntackle the $(\\operatorname{deg}+1)$-list-coloring (D1LC) problem, where each\nnode $v$ of degree $d_v$ is assigned a palette of $d_v+1$ colors, and the\nobjective is to find a proper coloring using these palettes. While for\n$(\\Delta+1)$-coloring (where $\\Delta$ is the maximum degree), there is a fast\nrandomized distributed $O(\\log^3\\log n)$-round algorithm (Chang, Li, and Pettie\n[SIAM J. Comp. 2020]), no $o(\\log n)$-round algorithms are known for the D1LC\nproblem.\nWe give a randomized distributed algorithm for D1LC that is optimal under\nplausible assumptions about the deterministic complexity of the problem. Using\nthe recent deterministic algorithm of Ghaffari and Kuhn [FOCS2021], our\nalgorithm runs in $O(\\log^3 \\log n)$ time, matching the best bound known for\n$(\\Delta+1)$-coloring. In addition, it colors all nodes of degree\n$\\Omega(\\log^7 n)$ in $O(\\log^* n)$ rounds.\nA key contribution is a subroutine to generate slack for D1LC. When placed\ninto the framework of Assadi, Chen, and Khanna [SODA2019] and Alon and Assadi\n[APPROX/RANDOM2020], this almost immediately leads to a palette sparsification\ntheorem for D1LC, generalizing previous results. That gives fast algorithms for\nD1LC in three different models: an $O(1)$-round algorithm in the MPC model with\n$\\tilde{O}(n)$ memory per machine; a single-pass semi-streaming algorithm in\ndynamic streams; and an $\\tilde{O}(n\\sqrt{n})$-time algorithm in the standard\nquery model.",
    "descriptor": "",
    "authors": [
      "Magn\u00fas M. Halld\u00f3rsson",
      "Fabian Kuhn",
      "Alexandre Nolin",
      "Tigran Tonoyan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.00604"
  },
  {
    "id": "arXiv:2112.00616",
    "title": "Roadmap for Edge AI: A Dagstuhl Perspective",
    "abstract": "Based on the collective input of Dagstuhl Seminar (21342), this paper\npresents a comprehensive discussion on AI methods and capabilities in the\ncontext of edge computing, referred as Edge AI. In a nutshell, we envision Edge\nAI to provide adaptation for data-driven applications, enhance network and\nradio access, and allow the creation, optimization, and deployment of\ndistributed AI/ML pipelines with given quality of experience, trust, security\nand privacy targets. The Edge AI community investigates novel ML methods for\nthe edge computing environment, spanning multiple sub-fields of computer\nscience, engineering and ICT. The goal is to share an envisioned roadmap that\ncan bring together key actors and enablers to further advance the domain of\nEdge AI.",
    "descriptor": "\nComments: for ACM SIGCOMM CCR\n",
    "authors": [
      "Aaron Yi Ding",
      "Ella Peltonen",
      "Tobias Meuser",
      "Atakan Aral",
      "Christian Becker",
      "Schahram Dustdar",
      "Thomas Hiessl",
      "Dieter Kranzlmuller",
      "Madhusanka Liyanage",
      "Setareh Magshudi",
      "Nitinder Mohan",
      "Joerg Ott",
      "Jan S. Rellermeyer",
      "Stefan Schulte",
      "Henning Schulzrinne",
      "Gurkan Solmaz",
      "Sasu Tarkoma",
      "Blesson Varghese",
      "Lars Wolf"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00616"
  },
  {
    "id": "arXiv:2112.00619",
    "title": "Edge computing for cyber-physical systems: A systematic mapping study  emphasizing trustworthiness",
    "abstract": "Edge computing is projected to have profound implications in the coming\ndecades, proposed to provide solutions for applications such as augmented\nreality, predictive functionalities, and collaborative Cyber-Physical Systems\n(CPS). For such applications, edge computing addresses the new computational\nneeds, as well as privacy, availability, and real-time constraints, by\nproviding local high-performance computing capabilities to deal with the\nlimitations and constraints of cloud and embedded systems. Our interests lie in\nthe applications of edge computing as part of CPS, where several properties (or\nattributes) of trustworthiness, including safety, security, and\npredictability/availability are of particular concern, each facing challenges\nfor the introduction of edge-based CPS. We present the results of a systematic\nmapping study, a kind of systematic literature survey, investigating the use of\nedge computing for CPS with a special emphasis on trustworthiness. The main\ncontributions of this study are a detailed description of the current research\nefforts in edge-based CPS and the identification and discussion of trends and\nresearch gaps. The results show that the main body of research in edge-based\nCPS only to a very limited extent consider key attributes of system\ntrustworthiness, despite many efforts referring to critical CPS and\napplications like intelligent transportation. More research and industrial\nefforts will be needed on aspects of trustworthiness of future edge-based CPS\nincluding their experimental evaluation. Such research needs to consider the\nmultiple interrelated attributes of trustworthiness including safety, security,\nand predictability, and new methodologies and architectures to address them. It\nis further important to provide bridges and collaboration between edge\ncomputing and CPS disciplines.",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 Manuel Gaspar S\u00e1nchez",
      "Nils J\u00f6rgensen",
      "Martin T\u00f6rngren",
      "Rafia Inam",
      "Andrii Berezovskyi",
      "Lei Feng",
      "Elena Fersman",
      "Muhammad Rusyadi Ramli",
      "Kaige Tan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.00619"
  },
  {
    "id": "arXiv:2112.00621",
    "title": "A Two-Level Approximate Logic Synthesis Combining Cube Insertion and  Removal",
    "abstract": "Approximate computing is an attractive paradigm for reducing the design\ncomplexity of error-resilient systems, therefore improving performance and\nsaving power consumption. In this work, we propose a new two-level approximate\nlogic synthesis method based on cube insertion and removal procedures.\nExperimental results have shown significant literal count and runtime reduction\ncompared to the state-of-the-art approach. The method scalability is\nillustrated for a high error threshold over large benchmark circuits. The\nobtained solutions have presented a literal number reduction up to 38%, 56% and\n93% with respect to an error rate of 1%, 3% and 5%, respectively.",
    "descriptor": "\nComments: 5 Pages, submitted to IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems\n",
    "authors": [
      "Gabriel Ammes",
      "Walter Lau Neto",
      "Paulo Butzen",
      "Pierre-Emmanuel Gaillardon",
      "Renato P. Ribas"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Hardware Architecture (cs.AR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.00621"
  },
  {
    "id": "arXiv:2112.00626",
    "title": "The Effect of People Recommenders on Echo Chambers and Polarization",
    "abstract": "The effects of social media on critical issues, such as polarization and\nmisinformation, are under scrutiny due to the disruptive consequences that\nthese phenomena can have on our societies. Among the algorithms routinely used\nby social media platforms, people-recommender systems are of special interest,\nas they directly contribute to the evolution of the social network structure,\naffecting the information and the opinions users are exposed to.\nIn this paper, we propose a framework to assess the effect of people\nrecommenders on the evolution of opinions. Our proposal is based on Monte Carlo\nsimulations combining link recommendation and opinion-dynamics models. In order\nto control initial conditions, we define a random network model to generate\ngraphs with opinions, with tunable amounts of modularity and homophily. We join\nthese elements into a methodology to study the effects of the recommender\nsystem on echo chambers and polarization. We also show how to use our framework\nto measure, by means of simulations, the impact of different intervention\nstrategies.\nOur thorough experimentation shows that people recommenders can in fact lead\nto a significant increase in echo chambers. However, this happens only if there\nis considerable initial homophily in the network. Also, we find that if the\nnetwork already contains echo chambers, the effect of the recommendation\nalgorithm is negligible. Such findings are robust to two very different opinion\ndynamics models, a bounded confidence model and an epistemological model.",
    "descriptor": "\nComments: To appear in: Proceedings of the International AAAI Conference on Web and Social Media, vol. 16 (ICWSM '22)\n",
    "authors": [
      "Federico Cinus",
      "Marco Minici",
      "Corrado Monti",
      "Francesco Bonchi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.00626"
  },
  {
    "id": "arXiv:2112.00627",
    "title": "DeepSportLab: a Unified Framework for Ball Detection, Player Instance  Segmentation and Pose Estimation in Team Sports Scenes",
    "abstract": "This paper presents a unified framework to (i) locate the ball, (ii) predict\nthe pose, and (iii) segment the instance mask of players in team sports scenes.\nThose problems are of high interest in automated sports analytics, production,\nand broadcast. A common practice is to individually solve each problem by\nexploiting universal state-of-the-art models, \\eg, Panoptic-DeepLab for player\nsegmentation. In addition to the increased complexity resulting from the\nmultiplication of single-task models, the use of the off-the-shelf models also\nimpedes the performance due to the complexity and specificity of the team\nsports scenes, such as strong occlusion and motion blur. To circumvent those\nlimitations, our paper proposes to train a single model that simultaneously\npredicts the ball and the player mask and pose by combining the part intensity\nfields and the spatial embeddings principles. Part intensity fields provide the\nball and player location, as well as player joints location. Spatial embeddings\nare then exploited to associate player instance pixels to their respective\nplayer center, but also to group player joints into skeletons. We demonstrate\nthe effectiveness of the proposed model on the DeepSport basketball dataset,\nachieving comparable performance to the SoA models addressing each individual\ntask separately.",
    "descriptor": "\nComments: 13 pages, 5 figures, BMVC, BMVC2021\n",
    "authors": [
      "Seyed Abolfazl Ghasemzadeh",
      "Gabriel Van Zandycke",
      "Maxime Istasse",
      "Niels Sayez",
      "Amirafshar Moshtaghpour",
      "Christophe De Vleeschouwer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00627"
  },
  {
    "id": "arXiv:2112.00629",
    "title": "Classifying grounded intersection graphs via ordered forbidden patterns",
    "abstract": "It was noted already in the 90s that many classic graph classes, such as\ninterval, chordal, and bipartite graphs, can be characterized by the existence\nof an ordering of the vertices avoiding some ordered subgraphs, called\n\\emph{patterns}. Very recently, all the classes corresponding to patterns on\nthree vertices (including the ones mentioned above) have been listed, and\nproved to be efficiently recognizable. In contrast, very little is known about\npatterns on four vertices.\nOne of the few graph classes characterized by a pattern on four vertices is\nthe class of intersection graphs of rectangles that are said to be\n\\emph{grounded on a line}. This class appears naturally in the study of\nintersection graphs, and similar grounded classes have recently attracted a lot\nof attention.\nThis paper contains three parts. First, we make a survey of grounded\nintersection graph classes, summarizing all the known inclusions between these\nvarious classes. Second, we show that the correspondence between a pattern on\nfour vertices and grounded rectangle graphs is not an isolated phenomenon. We\nestablish several other pattern characterizations for geometric classes, and\nshow that the hierarchy of grounded intersection graph classes is tightly\ninterleaved with the classes defined patterns on four vertices. We claim that\nforbidden patterns are a useful tool to classify grounded intersection graphs.\nFinally, we give an overview of the complexity of the recognition of classes\ndefined by forbidden patterns on four vertices and list several interesting\nopen problems.",
    "descriptor": "",
    "authors": [
      "Laurent Feuilloley",
      "Michel Habib"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.00629"
  },
  {
    "id": "arXiv:2112.00633",
    "title": "TEDGE-Caching: Transformer-based Edge Caching Towards 6G Networks",
    "abstract": "As a consequence of the COVID-19 pandemic, the demand for telecommunication\nfor remote learning/working and telemedicine has significantly increased.\nMobile Edge Caching (MEC) in the 6G networks has been evolved as an efficient\nsolution to meet the phenomenal growth of the global mobile data traffic by\nbringing multimedia content closer to the users. Although massive connectivity\nenabled by MEC networks will significantly increase the quality of\ncommunications, there are several key challenges ahead. The limited storage of\nedge nodes, the large size of multimedia content, and the time-variant users'\npreferences make it critical to efficiently and dynamically predict the\npopularity of content to store the most upcoming requested ones before being\nrequested. Recent advancements in Deep Neural Networks (DNNs) have drawn much\nresearch attention to predict the content popularity in proactive caching\nschemes. Existing DNN models in this context, however, suffer from longterm\ndependencies, computational complexity, and unsuitability for parallel\ncomputing. To tackle these challenges, we propose an edge caching framework\nincorporated with the attention-based Vision Transformer (ViT) neural network,\nreferred to as the Transformer-based Edge (TEDGE) caching, which to the best of\nour knowledge, is being studied for the first time. Moreover, the TEDGE caching\nframework requires no data pre-processing and additional contextual\ninformation. Simulation results corroborate the effectiveness of the proposed\nTEDGE caching framework in comparison to its counterparts.",
    "descriptor": "",
    "authors": [
      "Zohreh Hajiakhondi Meybodi",
      "Arash Mohammadi",
      "Elahe Rahimian",
      "Shahin Heidarian",
      "Jamshid Abouei",
      "Konstantinos N. Plataniotis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.00633"
  },
  {
    "id": "arXiv:2112.00639",
    "title": "Robustness in Deep Learning for Computer Vision: Mind the gap?",
    "abstract": "Deep neural networks for computer vision tasks are deployed in increasingly\nsafety-critical and socially-impactful applications, motivating the need to\nclose the gap in model performance under varied, naturally occurring imaging\nconditions. Robustness, ambiguously used in multiple contexts including\nadversarial machine learning, here then refers to preserving model performance\nunder naturally-induced image corruptions or alterations.\nWe perform a systematic review to identify, analyze, and summarize current\ndefinitions and progress towards non-adversarial robustness in deep learning\nfor computer vision. We find that this area of research has received\ndisproportionately little attention relative to adversarial machine learning,\nyet a significant robustness gap exists that often manifests in performance\ndegradation similar in magnitude to adversarial conditions.\nTo provide a more transparent definition of robustness across contexts, we\nintroduce a structural causal model of the data generating process and\ninterpret non-adversarial robustness as pertaining to a model's behavior on\ncorrupted images which correspond to low-probability samples from the unaltered\ndata distribution. We then identify key architecture-, data augmentation-, and\noptimization tactics for improving neural network robustness. This causal view\nof robustness reveals that common practices in the current literature, both in\nregards to robustness tactics and evaluations, correspond to causal concepts,\nsuch as soft interventions resulting in a counterfactually-altered distribution\nof imaging conditions. Through our findings and analysis, we offer perspectives\non how future research may mind this evident and significant non-adversarial\nrobustness gap.",
    "descriptor": "",
    "authors": [
      "Nathan Drenkow",
      "Numair Sani",
      "Ilya Shpitser",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00639"
  },
  {
    "id": "arXiv:2112.00646",
    "title": "Reliability Assessment and Safety Arguments for Machine Learning  Components in Assuring Learning-Enabled Autonomous Systems",
    "abstract": "The increasing use of Machine Learning (ML) components embedded in autonomous\nsystems -- so-called Learning-Enabled Systems (LES) -- has resulted in the\npressing need to assure their functional safety. As for traditional functional\nsafety, the emerging consensus within both, industry and academia, is to use\nassurance cases for this purpose. Typically assurance cases support claims of\nreliability in support of safety, and can be viewed as a structured way of\norganising arguments and evidence generated from safety analysis and\nreliability modelling activities. While such assurance activities are\ntraditionally guided by consensus-based standards developed from vast\nengineering experience, LES pose new challenges in safety-critical application\ndue to the characteristics and design of ML models. In this article, we first\npresent an overall assurance framework for LES with an emphasis on quantitative\naspects, e.g., breaking down system-level safety targets to component-level\nrequirements and supporting claims stated in reliability metrics. We then\nintroduce a novel model-agnostic Reliability Assessment Model (RAM) for ML\nclassifiers that utilises the operational profile and robustness verification\nevidence. We discuss the model assumptions and the inherent challenges of\nassessing ML reliability uncovered by our RAM and propose practical solutions.\nProbabilistic safety arguments at the lower ML component-level are also\ndeveloped based on the RAM. Finally, to evaluate and demonstrate our methods,\nwe not only conduct experiments on synthetic/benchmark datasets but also\ndemonstrate the scope of our methods with a comprehensive case study on\nAutonomous Underwater Vehicles in simulation.",
    "descriptor": "\nComments: Submitted, under review\n",
    "authors": [
      "Xingyu Zhao",
      "Wei Huang",
      "Vibhav Bharti",
      "Yi Dong",
      "Victoria Cox",
      "Alec Banks",
      "Sen Wang",
      "Sven Schewe",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00646"
  },
  {
    "id": "arXiv:2112.00648",
    "title": "Remixing Functionally Graded Structures: Data-Driven Topology  Optimization with Multiclass Shape Blending",
    "abstract": "To create heterogeneous, multiscale structures with unprecedented\nfunctionalities, recent topology optimization approaches design either fully\naperiodic systems or functionally graded structures, which compete in terms of\ndesign freedom and efficiency. We propose to inherit the advantages of both\nthrough a data-driven framework for multiclass functionally graded structures\nthat mixes several families, i.e., classes, of microstructure topologies to\ncreate spatially-varying designs with guaranteed feasibility. The key is a new\nmulticlass shape blending scheme that generates smoothly graded microstructures\nwithout requiring compatible classes or connectivity and feasibility\nconstraints. Moreover, it transforms the microscale problem into an efficient,\nlow-dimensional one without confining the design to predefined shapes.\nCompliance and shape matching examples using common truss geometries and\ndiversity-based freeform topologies demonstrate the versatility of our\nframework, while studies on the effect of the number and diversity of classes\nillustrate the effectiveness. The generality of the proposed methods supports\nfuture extensions beyond the linear applications presented.",
    "descriptor": "\nComments: Submitted to Structural and Multidisciplinary Optimization: Selected papers from WCSMO-14\n",
    "authors": [
      "Yu-Chin Chan",
      "Daicong Da",
      "Liwei Wang",
      "Wei Chen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00648"
  },
  {
    "id": "arXiv:2112.00649",
    "title": "Digital Twinning Remote Laboratories for Online Practical Learning",
    "abstract": "The COVID19 pandemic has demonstrated a need for remote learning and virtual\nlearning applications such as virtual reality (VR) and tablet-based solutions.\nCreating complex learning scenarios by developers is highly time-consuming and\ncan take over a year. It is also costly to employ teams of system analysts,\ndevelopers and 3D artists. There is a requirement to provide a simple method to\nenable lecturers to create their own content for their laboratory tutorials.\nResearch has been undertaken into developing generic models to enable the\nsemi-automatic creation of a virtual learning tools for subjects that require\npractical interactions with the lab resources. In addition to the system for\ncreating digital twins, a case study describing the creation of a virtual\nlearning application for an electrical laboratory tutorial has been presented.",
    "descriptor": "\nComments: 56 pages, 14 figures. arXiv admin note: text overlap with arXiv:2106.09344\n",
    "authors": [
      "Claire Palmer",
      "Ben Roullier",
      "Mohammed Aamir",
      "Frank McQuade",
      "Leonardo Stella",
      "Ashiq Anjum"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00649"
  },
  {
    "id": "arXiv:2112.00653",
    "title": "Variational Learning for Unsupervised Knowledge Grounded Dialogs",
    "abstract": "Recent methods for knowledge grounded dialogs generate responses by\nincorporating information from an external textual document. These methods do\nnot require the exact document to be known during training and rely on the use\nof a retrieval system to fetch relevant documents from a large index. The\ndocuments used to generate the responses are modeled as latent variables whose\nprior probabilities need to be estimated. Models such as RAG , marginalize the\ndocument probabilities over the documents retrieved from the index to define\nthe log likelihood loss function which is optimized end-to-end.\nIn this paper, we develop a variational approach to the above technique\nwherein, we instead maximize the Evidence Lower bound (ELBO). Using a\ncollection of three publicly available open-conversation datasets, we\ndemonstrate how the posterior distribution, that has information from the\nground-truth response, allows for a better approximation of the objective\nfunction during training. To overcome the challenges associated with sampling\nover a large knowledge collection, we develop an efficient approach to\napproximate the ELBO. To the best of our knowledge we are the first to apply\nvariational training for open-scale unsupervised knowledge grounded dialog\nsystems.",
    "descriptor": "",
    "authors": [
      "Mayank Mishra",
      "Dhiraj Madan",
      "Gaurav Pandey",
      "Danish Contractor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00653"
  },
  {
    "id": "arXiv:2112.00654",
    "title": "Siamese Neural Encoders for Long-Term Indoor Localization with Mobile  Devices",
    "abstract": "Fingerprinting-based indoor localization is an emerging application domain\nfor enhanced positioning and tracking of people and assets within indoor\nlocales. The superior pairing of ubiquitously available WiFi signals with\ncomputationally capable smartphones is set to revolutionize the area of indoor\nlocalization. However, the observed signal characteristics from independently\nmaintained WiFi access points vary greatly over time. Moreover, some of the\nWiFi access points visible at the initial deployment phase may be replaced or\nremoved over time. These factors are often ignored in indoor localization\nframeworks and cause gradual and catastrophic degradation of localization\naccuracy post-deployment (over weeks and months). To overcome these challenges,\nwe propose a Siamese neural encoder-based framework that offers up to 40%\nreduction in degradation of localization accuracy over time compared to the\nstate-of-the-art in the area, without requiring any retraining.",
    "descriptor": "",
    "authors": [
      "Saideep Tiku",
      "Sudeep Pasricha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00654"
  },
  {
    "id": "arXiv:2112.00655",
    "title": "Efficient and Local Parallel Random Walks",
    "abstract": "Random walks are a fundamental primitive used in many machine learning\nalgorithms with several applications in clustering and semi-supervised\nlearning. Despite their relevance, the first efficient parallel algorithm to\ncompute random walks has been introduced very recently (Lacki et al.).\nUnfortunately their method has a fundamental shortcoming: their algorithm is\nnon-local in that it heavily relies on computing random walks out of all nodes\nin the input graph, even though in many practical applications one is\ninterested in computing random walks only from a small subset of nodes in the\ngraph. In this paper, we present a new algorithm that overcomes this limitation\nby building random walk efficiently and locally at the same time. We show that\nour technique is both memory and round efficient, and in particular yields an\nefficient parallel local clustering algorithm. Finally, we complement our\ntheoretical analysis with experimental results showing that our algorithm is\nsignificantly more scalable than previous approaches.",
    "descriptor": "",
    "authors": [
      "Michael Kapralov",
      "Silvio Lattanzi",
      "Navid Nouri",
      "Jakab Tardos"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00655"
  },
  {
    "id": "arXiv:2112.00656",
    "title": "Object-aware Video-language Pre-training for Retrieval",
    "abstract": "Recently, by introducing large-scale dataset and strong transformer network,\nvideo-language pre-training has shown great success especially for retrieval.\nYet, existing video-language transformer models do not explicitly fine-grained\nsemantic align. In this work, we present Object-aware Transformers, an\nobject-centric approach that extends video-language transformer to incorporate\nobject representations. The key idea is to leverage the bounding boxes and\nobject tags to guide the training process. We evaluate our model on three\nstandard sub-tasks of video-text matching on four widely used benchmarks. We\nalso provide deep analysis and detailed ablation about the proposed method. We\nshow clear improvement in performance across all tasks and datasets considered,\ndemonstrating the value of a model that incorporates object representations\ninto a video-language architecture. The code will be released at\n\\url{https://github.com/FingerRec/OA-Transformer}.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Alex Jinpeng Wang",
      "Yixiao Ge",
      "Guanyu Cai",
      "Rui Yan",
      "Xudong Lin",
      "Ying Shan",
      "Xiaohu Qie",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00656"
  },
  {
    "id": "arXiv:2112.00659",
    "title": "Certified Adversarial Defenses Meet Out-of-Distribution Corruptions:  Benchmarking Robustness and Simple Baselines",
    "abstract": "Certified robustness guarantee gauges a model's robustness to test-time\nattacks and can assess the model's readiness for deployment in the real world.\nIn this work, we critically examine how the adversarial robustness guarantees\nfrom randomized smoothing-based certification methods change when\nstate-of-the-art certifiably robust models encounter out-of-distribution (OOD)\ndata. Our analysis demonstrates a previously unknown vulnerability of these\nmodels to low-frequency OOD data such as weather-related corruptions, rendering\nthese models unfit for deployment in the wild. To alleviate this issue, we\npropose a novel data augmentation scheme, FourierMix, that produces\naugmentations to improve the spectral coverage of the training data.\nFurthermore, we propose a new regularizer that encourages consistent\npredictions on noise perturbations of the augmented data to improve the quality\nof the smoothed models. We find that FourierMix augmentations help eliminate\nthe spectral bias of certifiably robust models enabling them to achieve\nsignificantly better robustness guarantees on a range of OOD benchmarks. Our\nevaluation also uncovers the inability of current OOD benchmarks at\nhighlighting the spectral biases of the models. To this end, we propose a\ncomprehensive benchmarking suite that contains corruptions from different\nregions in the spectral domain. Evaluation of models trained with popular\naugmentation methods on the proposed suite highlights their spectral biases and\nestablishes the superiority of FourierMix trained models at achieving\nbetter-certified robustness guarantees under OOD shifts over the entire\nfrequency spectrum.",
    "descriptor": "\nComments: 21 pages, 15 figures, and 9 tables\n",
    "authors": [
      "Jiachen Sun",
      "Akshay Mehra",
      "Bhavya Kailkhura",
      "Pin-Yu Chen",
      "Dan Hendrycks",
      "Jihun Hamm",
      "Z. Morley Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.00659"
  },
  {
    "id": "arXiv:2112.00661",
    "title": "MOMO -- Deep Learning-driven classification of external DICOM studies  for PACS archivation",
    "abstract": "Patients regularly continue assessment or treatment in other facilities than\nthey began them in, receiving their previous imaging studies as a CD-ROM and\nrequiring clinical staff at the new hospital to import these studies into their\nlocal database. However, between different facilities, standards for\nnomenclature, contents, or even medical procedures may vary, often requiring\nhuman intervention to accurately classify the received studies in the context\nof the recipient hospital's standards. In this study, the authors present MOMO\n(MOdality Mapping and Orchestration), a deep learning-based approach to\nautomate this mapping process utilizing metadata substring matching and a\nneural network ensemble, which is trained to recognize the 76 most common\nimaging studies across seven different modalities. A retrospective study is\nperformed to measure the accuracy that this algorithm can provide. To this end,\na set of 11,934 imaging series with existing labels was retrieved from the\nlocal hospital's PACS database to train the neural networks. A set of 843\ncompletely anonymized external studies was hand-labeled to assess the\nperformance of our algorithm. Additionally, an ablation study was performed to\nmeasure the performance impact of the network ensemble in the algorithm, and a\ncomparative performance test with a commercial product was conducted. In\ncomparison to a commercial product (96.20% predictive power, 82.86% accuracy,\n1.36% minor errors), a neural network ensemble alone performs the\nclassification task with less accuracy (99.05% predictive power, 72.69%\naccuracy, 10.3% minor errors). However, MOMO outperforms either by a large\nmargin in accuracy and with increased predictive power (99.29% predictive\npower, 92.71% accuracy, 2.63% minor errors).",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Frederic Jonske",
      "Maximilian Dederichs",
      "Moon-Sung Kim",
      "Jan Egger",
      "Lale Umutlu",
      "Michael Forsting",
      "Felix Nensa",
      "Jens Kleesiek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.00661"
  },
  {
    "id": "arXiv:2112.00662",
    "title": "A general locomotion control framework for serially connected  multi-legged robots",
    "abstract": "Serially connected robots are promising candidates for performing tasks in\nconfined spaces such as search-and-rescue in large-scale disasters. Such robots\nare typically limbless, and we hypothesize that the addition of limbs could\nimprove mobility. However, a challenge in designing and controlling such\ndevices lies in the coordination of high-dimensional redundant modules in a way\nthat improves mobility. Here we develop a general framework to control serially\nconnected multi-legged robots. Specifically, we combine two approaches to build\na general shape control scheme which can provide baseline patterns of\nself-deformation (\"gaits\") for effective locomotion in diverse robot\nmorphologies. First, we take inspiration from a dimensionality reduction and a\nbiological gait classification scheme to generate cyclic patterns of body\ndeformation and foot lifting/lowering, which facilitate generation of arbitrary\nsubstrate contact patterns. Second, we use geometric mechanics methods to\nfacilitates identification of optimal phasing of these undulations to maximize\nspeed and/or stability. Our scheme allows the development of effective gaits in\nmulti-legged robots locomoting on flat frictional terrain with diverse number\nof limbs (4, 6, 16, and even 0 limbs) and body actuation capabilities\n(including sidewinding gaits on limbless devices). By properly coordinating the\nbody undulation and the leg placement, our framework combines the advantages of\nboth limbless robots (modularity) and legged robots (mobility). We expect that\nour framework can provide general control schemes for the rapid deployment of\ngeneral multi-legged robots, paving the ways toward machines that can traverse\ncomplex environments under real-life conditions.",
    "descriptor": "",
    "authors": [
      "Baxi Chong",
      "Yasemin O. Aydin",
      "Jennifer M. Rieser",
      "Guillaume Sartoretti",
      "Tianyu Wang",
      "Julian Whitman",
      "Abdul Kaba",
      "Enes Aydin",
      "Ciera McFarland",
      "Howie Choset",
      "Daniel I. Goldman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00662"
  },
  {
    "id": "arXiv:2112.00663",
    "title": "Graph Conditioned Sparse-Attention for Improved Source Code  Understanding",
    "abstract": "Transformer architectures have been successfully used in learning source code\nrepresentations. The fusion between a graph representation like Abstract Syntax\nTree (AST) and a source code sequence makes the use of current approaches\ncomputationally intractable for large input sequence lengths. Source code can\nhave long-range dependencies that require larger sequence lengths to model\neffectively. Current approaches have a quadratic growth in computational and\nmemory costs with respect to the sequence length. Using such models in\npractical scenarios is difficult. In this work, we propose the conditioning of\na source code snippet with its graph modality by using the graph adjacency\nmatrix as an attention mask for a sparse self-attention mechanism and the use\nof a graph diffusion mechanism to model longer-range token dependencies. Our\nmodel reaches state-of-the-art results in BLEU, METEOR, and ROUGE-L metrics for\nthe code summarization task and near state-of-the-art accuracy in the variable\nmisuse task. The memory use and inference time of our model have linear growth\nwith respect to the input sequence length as compared to the quadratic growth\nof previous works.",
    "descriptor": "",
    "authors": [
      "Junyan Cheng",
      "Iordanis Fostiropoulos",
      "Barry Boehm"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.00663"
  },
  {
    "id": "arXiv:2112.00665",
    "title": "Saliency Enhancement using Superpixel Similarity",
    "abstract": "Saliency Object Detection (SOD) has several applications in image analysis.\nDeep-learning-based SOD methods are among the most effective, but they may miss\nforeground parts with similar colors. To circumvent the problem, we introduce a\npost-processing method, named \\textit{Saliency Enhancement over Superpixel\nSimilarity} (SESS), which executes two operations alternately for saliency\ncompletion: object-based superpixel segmentation and superpixel-based saliency\nestimation. SESS uses an input saliency map to estimate seeds for superpixel\ndelineation and define superpixel queries in foreground and background. A new\nsaliency map results from color similarities between queries and superpixels.\nThe process repeats for a given number of iterations, such that all generated\nsaliency maps are combined into a single one by cellular automata. Finally,\npost-processed and initial maps are merged using their average values per\nsuperpixel. We demonstrate that SESS can consistently and considerably improve\nthe results of three deep-learning-based SOD methods on five image datasets.",
    "descriptor": "",
    "authors": [
      "Leonardo de Melo Joao",
      "Alexandre Xavier Falcao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00665"
  },
  {
    "id": "arXiv:2112.00668",
    "title": "A Few-Shot Meta-Learning based Siamese Neural Network using Entropy  Features for Ransomware Classification",
    "abstract": "Ransomware defense solutions that can quickly detect and classify different\nransomware classes to formulate rapid response plans have been in high demand\nin recent years. Though the applicability of adopting deep learning techniques\nto provide automation and self-learning provision has been proven in many\napplication domains, the lack of data available for ransomware (and other\nmalware)samples has been raised as a barrier to developing effective deep\nlearning-based solutions. To address this concern, we propose a few-shot\nmeta-learning based Siamese Neural Network that not only detects ransomware\nattacks but is able to classify them into different classes. Our proposed model\nutilizes the entropy feature directly extracted from ransomware binary files to\nretain more fine-grained features associated with different ransomware\nsignatures. These entropy features are used further to train and optimize our\nmodel using a pre-trained network (e.g. VGG-16) in a meta-learning fashion.\nThis approach generates more accurate weight factors, compared to feature\nimages are used, to avoid the bias typically associated with a model trained\nwith a limited number of training samples. Our experimental results show that\nour proposed model is highly effective in providing a weighted F1-score\nexceeding the rate>86% compared",
    "descriptor": "",
    "authors": [
      "Jinting Zhu",
      "Julian Jang-Jaccard",
      "Amardeep Singh",
      "Ian Welch",
      "Harith AI-Sahaf",
      "Seyit Camtepe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.00668"
  },
  {
    "id": "arXiv:2112.00673",
    "title": "Robustly Self-Ordered Graphs: Constructions and Applications to Property  Testing",
    "abstract": "A graph $G$ is called self-ordered (a.k.a asymmetric) if the identity\npermutation is its only automorphism. Equivalently, there is a unique\nisomorphism from $G$ to any graph that is isomorphic to $G$. We say that\n$G=(V,E)$ is robustly self-ordered if the size of the symmetric difference\nbetween $E$ and the edge-set of the graph obtained by permuting $V$ using any\npermutation $\\pi:V\\to V$ is proportional to the number of non-fixed-points of\n$\\pi$. In this work, we initiate the study of the structure, construction and\nutility of robustly self-ordered graphs.\nWe show that robustly self-ordered bounded-degree graphs exist (in\nabundance), and that they can be constructed efficiently, in a strong sense.\nSpecifically, given the index of a vertex in such a graph, it is possible to\nfind all its neighbors in polynomial-time (i.e., in time that is\npoly-logarithmic in the size of the graph).\nWe also consider graphs of unbounded degree, seeking correspondingly\nunbounded robustness parameters. We again demonstrate that such graphs (of\nlinear degree) exist (in abundance), and that they can be constructed\nefficiently, in a strong sense. This turns out to require very different tools.\nSpecifically, we show that the construction of such graphs reduces to the\nconstruction of non-malleable two-source extractors (with very weak parameters\nbut with some additional natural features).\nWe demonstrate that robustly self-ordered bounded-degree graphs are useful\ntowards obtaining lower bounds on the query complexity of testing graph\nproperties both in the bounded-degree and the dense graph models. One of the\nresults that we obtain, via such a reduction, is a subexponential separation\nbetween the query complexities of testing and tolerant testing of graph\nproperties in the bounded-degree graph model.",
    "descriptor": "\nComments: Slightly modified version of a CCC 2021 paper that also appeared on ECCC 27: 149 (2020)\n",
    "authors": [
      "Oded Goldreich",
      "Avi Wigderson"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.00673"
  },
  {
    "id": "arXiv:2112.00682",
    "title": "Quasi-3D Magneto-Thermal Quench Simulation Scheme for Superconducting  Accelerator Magnets",
    "abstract": "To tackle the strong multi-scale problem in the quench simulation of\nsuperconducting accelerator magnets, this work proposes a hybrid numerical\nmethod which uses two-dimensional first-order finite-elements in the magnet\ncross-section and one-dimensional higher-order orthogonal polynomials in\nlongitudinal direction.",
    "descriptor": "\nComments: 5 pages, 8 figures, MT27 conference special issue paper\n",
    "authors": [
      "Laura A. M. D'Angelo",
      "Yvonne Sp\u00e4ck-Leigsnering",
      "Herbert De Gersem"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00682"
  },
  {
    "id": "arXiv:2112.00686",
    "title": "CYBORG: Blending Human Saliency Into the Loss Improves Deep Learning",
    "abstract": "Can deep learning models achieve greater generalization if their training is\nguided by reference to human perceptual abilities? And how can we implement\nthis in a practical manner? This paper proposes a first-ever training strategy\nto ConveY Brain Oversight to Raise Generalization (CYBORG). This new training\napproach incorporates human-annotated saliency maps into a CYBORG loss function\nthat guides the model towards learning features from image regions that humans\nfind salient when solving a given visual task. The Class Activation Mapping\n(CAM) mechanism is used to probe the model's current saliency in each training\nbatch, juxtapose model saliency with human saliency, and penalize the model for\nlarge differences. Results on the task of synthetic face detection show that\nthe CYBORG loss leads to significant improvement in performance on unseen\nsamples consisting of face images generated from six Generative Adversarial\nNetworks (GANs) across multiple classification network architectures. We also\nshow that scaling to even seven times as much training data with standard loss\ncannot beat the accuracy of CYBORG loss. As a side effect, we observed that the\naddition of explicit region annotation to the task of synthetic face detection\nincreased human classification performance. This work opens a new area of\nresearch on how to incorporate human visual saliency into loss functions. All\ndata, code and pre-trained models used in this work are offered with this\npaper.",
    "descriptor": "",
    "authors": [
      "Aidan Boyd",
      "Patrick Tinsley",
      "Kevin Bowyer",
      "Adam Czajka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00686"
  },
  {
    "id": "arXiv:2112.00690",
    "title": "MDFM: Multi-Decision Fusing Model for Few-Shot Learning",
    "abstract": "In recent years, researchers pay growing attention to the few-shot learning\n(FSL) task to address the data-scarce problem. A standard FSL framework is\ncomposed of two components: i) Pre-train. Employ the base data to generate a\nCNN-based feature extraction model (FEM). ii) Meta-test. Apply the trained FEM\nto the novel data (category is different from base data) to acquire the feature\nembeddings and recognize them. Although researchers have made remarkable\nbreakthroughs in FSL, there still exists a fundamental problem. Since the\ntrained FEM with base data usually cannot adapt to the novel class flawlessly,\nthe novel data's feature may lead to the distribution shift problem. To address\nthis challenge, we hypothesize that even if most of the decisions based on\ndifferent FEMs are viewed as \\textit{weak decisions}, which are not available\nfor all classes, they still perform decently in some specific categories.\nInspired by this assumption, we propose a novel method Multi-Decision Fusing\nModel (MDFM), which comprehensively considers the decisions based on multiple\nFEMs to enhance the efficacy and robustness of the model. MDFM is a simple,\nflexible, non-parametric method that can directly apply to the existing FEMs.\nBesides, we extend the proposed MDFM to two FSL settings (i.e., supervised and\nsemi-supervised settings). We evaluate the proposed method on five benchmark\ndatasets and achieve significant improvements of 3.4%-7.3\\% compared with\nstate-of-the-arts.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT). arXiv admin note: text overlap with arXiv:2109.07785\n",
    "authors": [
      "Shuai Shao",
      "Lei Xing",
      "Rui Xu",
      "Weifeng Liu",
      "Yan-Jiang Wang",
      "Bao-Di Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00690"
  },
  {
    "id": "arXiv:2112.00694",
    "title": "Label-Free Model Evaluation with Semi-Structured Dataset Representations",
    "abstract": "Label-free model evaluation, or AutoEval, estimates model accuracy on\nunlabeled test sets, and is critical for understanding model behaviors in\nvarious unseen environments. In the absence of image labels, based on dataset\nrepresentations, we estimate model performance for AutoEval with regression. On\nthe one hand, image feature is a straightforward choice for such\nrepresentations, but it hampers regression learning due to being unstructured\n(\\ie no specific meanings for component at certain location) and of\nlarge-scale. On the other hand, previous methods adopt simple structured\nrepresentations (like average confidence or average feature), but insufficient\nto capture the data characteristics given their limited dimensions. In this\nwork, we take the best of both worlds and propose a new semi-structured dataset\nrepresentation that is manageable for regression learning while containing rich\ninformation for AutoEval. Based on image features, we integrate distribution\nshapes, clusters, and representative samples for a semi-structured dataset\nrepresentation. Besides the structured overall description with distribution\nshapes, the unstructured description with clusters and representative samples\ninclude additional fine-grained information facilitating the AutoEval task. On\nthree existing datasets and 25 newly introduced ones, we experimentally show\nthat the proposed representation achieves competitive results. Code and dataset\nare available at\nhttps://github.com/sxzrt/Semi-Structured-Dataset-Representations.",
    "descriptor": "\nComments: 10 pages, 8 figures, 3 tables\n",
    "authors": [
      "Xiaoxiao Sun",
      "Yunzhong Hou",
      "Hongdong Li",
      "Liang Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00694"
  },
  {
    "id": "arXiv:2112.00698",
    "title": "CondenseNeXt: An Ultra-Efficient Deep Neural Network for Embedded  Systems",
    "abstract": "Due to the advent of modern embedded systems and mobile devices with\nconstrained resources, there is a great demand for incredibly efficient deep\nneural networks for machine learning purposes. There is also a growing concern\nof privacy and confidentiality of user data within the general public when\ntheir data is processed and stored in an external server which has further\nfueled the need for developing such efficient neural networks for real-time\ninference on local embedded systems. The scope of our work presented in this\npaper is limited to image classification using a convolutional neural network.\nA Convolutional Neural Network (CNN) is a class of Deep Neural Network (DNN)\nwidely used in the analysis of visual images captured by an image sensor,\ndesigned to extract information and convert it into meaningful representations\nfor real-time inference of the input data. In this paper, we propose a neoteric\nvariant of deep convolutional neural network architecture to ameliorate the\nperformance of existing CNN architectures for real-time inference on embedded\nsystems. We show that this architecture, dubbed CondenseNeXt, is remarkably\nefficient in comparison to the baseline neural network architecture,\nCondenseNet, by reducing trainable parameters and FLOPs required to train the\nnetwork whilst maintaining a balance between the trained model size of less\nthan 3.0 MB and accuracy trade-off resulting in an unprecedented computational\nefficiency.",
    "descriptor": "\nComments: 5 pages, 3 figures, published in an IEEE Conference\n",
    "authors": [
      "Priyank Kalgaonkar",
      "Mohamed El-Sharkawy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.00698"
  },
  {
    "id": "arXiv:2112.00699",
    "title": "BERT_SE: A Pre-trained Language Representation Model for Software  Engineering",
    "abstract": "The application of Natural Language Processing (NLP) has achieved a high\nlevel of relevance in several areas. In the field of software engineering (SE),\nNLP applications are based on the classification of similar texts (e.g.\nsoftware requirements), applied in tasks of estimating software effort,\nselection of human resources, etc. Classifying software requirements has been a\ncomplex task, considering the informality and complexity inherent in the texts\nproduced during the software development process. The pre-trained embedding\nmodels are shown as a viable alternative when considering the low volume of\ntextual data labeled in the area of software engineering, as well as the lack\nof quality of these data. Although there is much research around the\napplication of word embedding in several areas, to date, there is no knowledge\nof studies that have explored its application in the creation of a specific\nmodel for the domain of the SE area. Thus, this article presents the proposal\nfor a contextualized embedding model, called BERT_SE, which allows the\nrecognition of specific and relevant terms in the context of SE. The assessment\nof BERT_SE was performed using the software requirements classification task,\ndemonstrating that this model has an average improvement rate of 13% concerning\nthe BERT_base model, made available by the authors of BERT. The code and\npre-trained models are available at https://github.com/elianedb.",
    "descriptor": "",
    "authors": [
      "Eliane Maria De Bortoli F\u00e1vero",
      "Dalcimar Casanova"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.00699"
  },
  {
    "id": "arXiv:2112.00702",
    "title": "Semi-supervised music emotion recognition using noisy student training  and harmonic pitch class profiles",
    "abstract": "We present Mirable's submission to the 2021 Emotions and Themes in Music\nchallenge. In this work, we intend to address the question: can we leverage\nsemi-supervised learning techniques on music emotion recognition? With that, we\nexperiment with noisy student training, which has improved model performance in\nthe image classification domain. As the noisy student method requires a strong\nteacher model, we further delve into the factors including (i) input training\nlength and (ii) complementary music representations to further boost the\nperformance of the teacher model. For (i), we find that models trained with\nshort input length perform better in PR-AUC, whereas those trained with long\ninput length perform better in ROC-AUC. For (ii), we find that using harmonic\npitch class profiles (HPCP) consistently improve tagging performance, which\nsuggests that harmonic representation is useful for music emotion tagging.\nFinally, we find that noisy student method only improves tagging results for\nthe case of long training length. Additionally, we find that ensembling\nrepresentations trained with different training lengths can improve tagging\nresults significantly, which suggest a possible direction to explore\nincorporating multiple temporal resolutions in the network architecture for\nfuture work.",
    "descriptor": "\nComments: MediaEval 2021 submission for Emotion and Themes in Music\n",
    "authors": [
      "Hao Hao Tan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.00702"
  },
  {
    "id": "arXiv:2112.00706",
    "title": "Clustering Mixtures with Almost Optimal Separation in Polynomial Time",
    "abstract": "We consider the problem of clustering mixtures of mean-separated Gaussians in\nhigh dimensions. We are given samples from a mixture of $k$ identity covariance\nGaussians, so that the minimum pairwise distance between any two pairs of means\nis at least $\\Delta$, for some parameter $\\Delta > 0$, and the goal is to\nrecover the ground truth clustering of these samples. It is folklore that\nseparation $\\Delta = \\Theta (\\sqrt{\\log k})$ is both necessary and sufficient\nto recover a good clustering, at least information theoretically. However, the\nestimators which achieve this guarantee are inefficient. We give the first\nalgorithm which runs in polynomial time, and which almost matches this\nguarantee. More precisely, we give an algorithm which takes polynomially many\nsamples and time, and which can successfully recover a good clustering, so long\nas the separation is $\\Delta = \\Omega (\\log^{1/2 + c} k)$, for any $c > 0$.\nPreviously, polynomial time algorithms were only known for this problem when\nthe separation was polynomial in $k$, and all algorithms which could tolerate\n$\\textsf{poly}( \\log k )$ separation required quasipolynomial time. We also\nextend our result to mixtures of translations of a distribution which satisfies\nthe Poincar\\'{e} inequality, under additional mild assumptions. Our main\ntechnical tool, which we believe is of independent interest, is a novel way to\nimplicitly represent and estimate high degree moments of a distribution, which\nallows us to extract important information about high-degree moments without\never writing down the full moment tensors explicitly.",
    "descriptor": "",
    "authors": [
      "Jerry Li",
      "Allen Liu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00706"
  },
  {
    "id": "arXiv:2112.00708",
    "title": "Optimal Resource Scheduling and Allocation in Distributed Computing  Systems",
    "abstract": "The essence of distributed computing systems is how to schedule incoming\nrequests and how to allocate all computing nodes to minimize both time and\ncomputation costs. In this paper, we propose a cost-aware optimal scheduling\nand allocation strategy for distributed computing systems while minimizing the\ncost function including response time and service cost. First, based on the\nproposed cost function, we derive the optimal request scheduling policy and the\noptimal resource allocation policy synchronously. Second, considering the\neffects of incoming requests on the scheduling policy, the additive increase\nmultiplicative decrease (AIMD) mechanism is implemented to model the relation\nbetween the request arrival and scheduling. In particular, the AIMD parameters\ncan be designed such that the derived optimal strategy is still valid. Finally,\na numerical example is presented to illustrate the derived results.",
    "descriptor": "\nComments: This work has been submitted to ACC2022\n",
    "authors": [
      "Wei Ren",
      "Eleftherios Vlahakis",
      "Nikolaos Athanasopoulos",
      "Raphael Jungers"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.00708"
  },
  {
    "id": "arXiv:2112.00709",
    "title": "GPU-Accelerated Forward-Backward algorithm with Application to  Lattice-Free MMI",
    "abstract": "We propose to express the forward-backward algorithm in terms of operations\nbetween sparse matrices in a specific semiring. This new perspective naturally\nleads to a GPU-friendly algorithm which is easy to implement in Julia or any\nprogramming languages with native support of semiring algebra. We use this new\nimplementation to train a TDNN with the LF-MMI objective function and we\ncompare the training time of our system with PyChain - a recently introduced\nC++/CUDA implementation of the LF-MMI loss. Our implementation is about two\ntimes faster while not having to use any approximation such as the \"leaky-HMM\".",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Lucas Ondel",
      "L\u00e9a-Marie Lam-Yee-Mui",
      "Martin Kocour",
      "Caio Filippo Corro",
      "Luk\u00e1\u0161 Burget"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00709"
  },
  {
    "id": "arXiv:2112.00710",
    "title": "Stateful Entities: Object-oriented Cloud Applications as Distributed  Dataflows",
    "abstract": "Programming stateful cloud applications remains a very painful experience.\nInstead of focusing on the business logic, programmers spend most of their time\ndealing with distributed systems considerations, with the most important being\nconsistency, load balancing, failure management, recovery, and scalability. At\nthe same time, we witness an unprecedented adoption of modern dataflow systems\nsuch as Apache Flink, Google Dataflow, and Timely Dataflow. These systems are\nnow performant and fault-tolerant, and they offer excellent state management\nprimitives.\nWith this line of work, we aim at investigating the opportunities and limits\nof compiling general-purpose programs into stateful dataflows. Given a set of\neasy-to-follow code conventions, programmers can author stateful entities, a\nprogramming abstraction embedded in Python. We present a compiler pipeline\nnamed StateFlow, to analyze the abstract syntax tree of a Python application\nand rewrite it into an intermediate representation based on stateful dataflow\ngraphs. StateFlow compiles that intermediate representation to a target\nexecution system: Apache Flink and Beam, AWS Lambda, Flink's Statefun, and\nCloudburst. Through an experimental evaluation, we demonstrate that the code\ngenerated by StateFlow incurs minimal overhead. While developing and deploying\nour prototype, we came to observe important limitations of current dataflow\nsystems in executing cloud applications at scale.",
    "descriptor": "",
    "authors": [
      "Wouter Zorgdrager",
      "Kyriakos Psarakis",
      "Marios Fragkoulis",
      "Eelco Visser",
      "Asterios Katsifodimos"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.00710"
  },
  {
    "id": "arXiv:2112.00712",
    "title": "STEM: Unsupervised STructural EMbedding for Stance Detection",
    "abstract": "Stance detection is an important task, supporting many downstream tasks such\nas discourse parsing and modeling the propagation of fake news, rumors, and\nscience denial. In this paper, we propose a novel framework for stance\ndetection. Our framework is unsupervised and domain-independent. Given a claim\nand a multi-participant discussion - we construct the interaction network from\nwhich we derive topological embeddings for each speaker. These speaker\nembeddings enjoy the following property: speakers with the same stance tend to\nbe represented by similar vectors, while antipodal vectors represent speakers\nwith opposing stances. These embeddings are then used to divide the speakers\ninto stance-partitions. We evaluate our method on three different datasets from\ndifferent platforms. Our method outperforms or is comparable with supervised\nmodels while providing confidence levels for its output. Furthermore, we\ndemonstrate how the structural embeddings relate to the valence expressed by\nthe speakers. Finally, we discuss some limitations inherent to the framework.",
    "descriptor": "",
    "authors": [
      "Ron Korenblum Pick",
      "Vladyslav Kozhukhov",
      "Dan Vilenchik",
      "Oren Tsur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.00712"
  },
  {
    "id": "arXiv:2112.00713",
    "title": "hIPPYlib-MUQ: A Bayesian Inference Software Framework for Integration of  Data with Complex Predictive Models under Uncertainty",
    "abstract": "Bayesian inference provides a systematic means of quantifying uncertainty in\nthe solution of the inverse problem. However, solution of Bayesian inverse\nproblems governed by complex forward models described by partial differential\nequations (PDEs) remains prohibitive with black-box Markov chain Monte Carlo\n(MCMC) methods. We present hIPPYlib-MUQ, an extensible and scalable software\nframework that contains implementations of state-of-the art algorithms aimed to\novercome the challenges of high-dimensional, PDE-constrained Bayesian inverse\nproblems. hIPPYlib-MUQ integrates two complementary open-source software\npackages. hIPPYlib solves PDE-constrained inverse problems using\nautomatically-generated adjoint-based derivatives, but it lacks full Bayesian\ncapabilities. MUQ provides numerous powerful Bayesian inversion algorithms, but\nexpects forward models to come equipped with derivatives to permit large-scale\nsolution. By combining these two libraries, we created a robust, scalable, and\nefficient software framework that can be used to tackle complex large-scale\nBayesian inverse problems across a broad spectrum of scientific and engineering\ndisciplines. To illustrate the capabilities of hIPPYlib-MUQ, we compare a\nnumber of MCMC methods on several high-dimensional Bayesian inverse problems.\nThe results demonstrate that large ($\\sim 50\\times$) speedups over conventional\nblack box and gradient-based MCMC algorithms can be obtained by exploiting\nHessian information (from the log-posterior), underscoring the power of the\nintegrated hIPPYlib-MUQ framework.",
    "descriptor": "",
    "authors": [
      "Ki-Tae Kim",
      "Umberto Villa",
      "Matthew Parno",
      "Youssef Marzouk",
      "Omar Ghattas",
      "Noemi Petra"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)",
      "Optimization and Control (math.OC)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.00713"
  },
  {
    "id": "arXiv:2112.00718",
    "title": "Improving GAN Equilibrium by Raising Spatial Awareness",
    "abstract": "The success of Generative Adversarial Networks (GANs) is largely built upon\nthe adversarial training between a generator (G) and a discriminator (D). They\nare expected to reach a certain equilibrium where D cannot distinguish the\ngenerated images from the real ones. However, in practice it is difficult to\nachieve such an equilibrium in GAN training, instead, D almost always surpasses\nG. We attribute this phenomenon to the information asymmetry between D and G.\nSpecifically, we observe that D learns its own visual attention when\ndetermining whether an image is real or fake, but G has no explicit clue on\nwhich regions to focus on for a particular synthesis. To alleviate the issue of\nD dominating the competition in GANs, we aim to raise the spatial awareness of\nG. Randomly sampled multi-level heatmaps are encoded into the intermediate\nlayers of G as an inductive bias. Thus G can purposefully improve the synthesis\nof certain image regions. We further propose to align the spatial awareness of\nG with the attention map induced from D. Through this way we effectively lessen\nthe information gap between D and G. Extensive results show that our method\npushes the two-player game in GANs closer to the equilibrium, leading to a\nbetter synthesis performance. As a byproduct, the introduced spatial awareness\nfacilitates interactive editing over the output synthesis. Demo video and more\nresults are at https://genforce.github.io/eqgan/.",
    "descriptor": "",
    "authors": [
      "Jianyuan Wang",
      "Ceyuan Yang",
      "Yinghao Xu",
      "Yujun Shen",
      "Hongdong Li",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00718"
  },
  {
    "id": "arXiv:2112.00719",
    "title": "HyperInverter: Improving StyleGAN Inversion via Hypernetwork",
    "abstract": "Real-world image manipulation has achieved fantastic progress in recent years\nas a result of the exploration and utilization of GAN latent spaces. GAN\ninversion is the first step in this pipeline, which aims to map the real image\nto the latent code faithfully. Unfortunately, the majority of existing GAN\ninversion methods fail to meet at least one of the three requirements listed\nbelow: high reconstruction quality, editability, and fast inference. We present\na novel two-phase strategy in this research that fits all requirements at the\nsame time. In the first phase, we train an encoder to map the input image to\nStyleGAN2 $\\mathcal{W}$-space, which was proven to have excellent editability\nbut lower reconstruction quality. In the second phase, we supplement the\nreconstruction ability in the initial phase by leveraging a series of\nhypernetworks to recover the missing information during inversion. These two\nsteps complement each other to yield high reconstruction quality thanks to the\nhypernetwork branch and excellent editability due to the inversion done in the\n$\\mathcal{W}$-space. Our method is entirely encoder-based, resulting in\nextremely fast inference. Extensive experiments on two challenging datasets\ndemonstrate the superiority of our method.",
    "descriptor": "\nComments: 26 pages, 29 figures, project page is located at this https URL\n",
    "authors": [
      "Tan M. Dinh",
      "Anh Tuan Tran",
      "Rang Nguyen",
      "Binh-Son Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00719"
  },
  {
    "id": "arXiv:2112.00722",
    "title": "Faster Maxflow via Improved Dynamic Spectral Vertex Sparsifiers",
    "abstract": "We make several advances broadly related to the maintenance of electrical\nflows in weighted graphs undergoing dynamic resistance updates, including:\n1. More efficient dynamic spectral vertex sparsification, achieved by faster\nlength estimation of random walks in weighted graphs using Morris counters\n[Morris 1978, Nelson-Yu 2020].\n2. A direct reduction from detecting edges with large energy in dynamic\nelectric flows to dynamic spectral vertex sparsifiers.\n3. A procedure for turning algorithms for estimating a sequence of vectors\nunder updates from an oblivious adversary to one that tolerates adaptive\nadversaries via the Gaussian-mechanism from differential privacy.\nCombining these pieces with modifications to prior robust interior point\nframeworks gives an algorithm that on graphs with $m$ edges computes a mincost\nflow with edge costs and capacities in $[1, U]$ in time\n$\\widetilde{O}(m^{3/2-1/58} \\log^2 U)$. In prior and independent work,\n[Axiotis-M\\k{a}dry-Vladu FOCS 2021] also obtained an improved algorithm for\nsparse mincost flows on capacitated graphs. Our algorithm implies a\n$\\widetilde{O}(m^{3/2-1/58} \\log U)$ time maxflow algorithm, improving over the\n$\\widetilde{O}(m^{3/2-1/328}\\log U)$ time maxflow algorithm of [Gao-Liu-Peng\nFOCS 2021].",
    "descriptor": "\nComments: 63 pages\n",
    "authors": [
      "Jan van den Brand",
      "Yu Gao",
      "Arun Jambulapati",
      "Yin Tat Lee",
      "Yang P. Liu",
      "Richard Peng",
      "Aaron Sidford"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.00722"
  },
  {
    "id": "arXiv:2112.00724",
    "title": "RegNeRF: Regularizing Neural Radiance Fields for View Synthesis from  Sparse Inputs",
    "abstract": "Neural Radiance Fields (NeRF) have emerged as a powerful representation for\nthe task of novel view synthesis due to their simplicity and state-of-the-art\nperformance. Though NeRF can produce photorealistic renderings of unseen\nviewpoints when many input views are available, its performance drops\nsignificantly when this number is reduced. We observe that the majority of\nartifacts in sparse input scenarios are caused by errors in the estimated scene\ngeometry, and by divergent behavior at the start of training. We address this\nby regularizing the geometry and appearance of patches rendered from unobserved\nviewpoints, and annealing the ray sampling space during training. We\nadditionally use a normalizing flow model to regularize the color of unobserved\nviewpoints. Our model outperforms not only other methods that optimize over a\nsingle scene, but in many cases also conditional models that are extensively\npre-trained on large multi-view datasets.",
    "descriptor": "\nComments: Project page available at this https URL\n",
    "authors": [
      "Michael Niemeyer",
      "Jonathan T. Barron",
      "Ben Mildenhall",
      "Mehdi S. M. Sajjadi",
      "Andreas Geiger",
      "Noha Radwan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.00724"
  },
  {
    "id": "arXiv:2112.00725",
    "title": "Extrapolating from a Single Image to a Thousand Classes using  Distillation",
    "abstract": "What can neural networks learn about the visual world from a single image?\nWhile it obviously cannot contain the multitudes of possible objects, scenes\nand lighting conditions that exist - within the space of all possible\n256^(3x224x224) 224-sized square images, it might still provide a strong prior\nfor natural images. To analyze this hypothesis, we develop a framework for\ntraining neural networks from scratch using a single image by means of\nknowledge distillation from a supervisedly pretrained teacher. With this, we\nfind that the answer to the above question is: 'surprisingly, a lot'. In\nquantitative terms, we find top-1 accuracies of 94%/74% on CIFAR-10/100, 59% on\nImageNet and, by extending this method to audio, 84% on SpeechCommands. In\nextensive analyses we disentangle the effect of augmentations, choice of source\nimage and network architectures and also discover \"panda neurons\" in networks\nthat have never seen a panda. This work shows that one image can be used to\nextrapolate to thousands of object classes and motivates a renewed research\nagenda on the fundamental interplay of augmentations and image.",
    "descriptor": "\nComments: Webpage: this https URL\n",
    "authors": [
      "Yuki M. Asano",
      "Aaqib Saeed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00725"
  },
  {
    "id": "arXiv:2112.00726",
    "title": "MonoScene: Monocular 3D Semantic Scene Completion",
    "abstract": "MonoScene proposes a 3D Semantic Scene Completion (SSC) framework, where the\ndense geometry and semantics of a scene are inferred from a single monocular\nRGB image. Different from the SSC literature, relying on 2.5 or 3D input, we\nsolve the complex problem of 2D to 3D scene reconstruction while jointly\ninferring its semantics. Our framework relies on successive 2D and 3D UNets\nbridged by a novel 2D-3D features projection inspiring from optics and\nintroduces a 3D context relation prior to enforce spatio-semantic consistency.\nAlong with architectural contributions, we introduce novel global scene and\nlocal frustums losses. Experiments show we outperform the literature on all\nmetrics and datasets while hallucinating plausible scenery even beyond the\ncamera field of view. Our code and trained models are available at\nhttps://github.com/cv-rits/MonoScene",
    "descriptor": "",
    "authors": [
      "Anh-Quan Cao",
      "Raoul de Charette"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00726"
  },
  {
    "id": "arXiv:2111.13051",
    "title": "Ranking by Momentum based on Pareto ordering of entities",
    "abstract": "Given a set of changing entities, which ones are the most uptrending over\nsome time T? Which entities are standing out as the biggest movers?\nTo answer this question we define the concept of momentum. Two parameters -\nabsolute gain and relative gain over time T play the key role in defining\nmomentum. Neither alone is sufficient since they are each biased towards a\nsubset of entities. Absolute gain favors large entities, while relative gain\nfavors small ones. To accommodate both absolute and relative gain in an\nunbiased way, we define Pareto ordering between entities. For entity E to\ndominate another entity F in Pareto ordering, E's absolute and relative gains\nover time T must be higher than F's absolute and relative gains respectively.\nMomentum leaders are defined as maximal elements of this partial order - the\nPareto frontier. We show how to compute momentum leaders and propose linear\nordering among them to help rank entities with the most momentum on the top.\nAdditionally, we show that when vectors follow power-law, the cardinality of\nthe set of Momentum leaders (Pareto frontier) is of the order of square root of\nthe logarithm of the number of entities, thus it is very small.",
    "descriptor": "\nComments: 12 pages, 12 figures\n",
    "authors": [
      "Tomasz Imielinski"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.13051"
  },
  {
    "id": "arXiv:2112.00002",
    "title": "Zero-Shot Learning of Continuous 3D Refractive Index Maps from Discrete  Intensity-Only Measurements",
    "abstract": "Intensity diffraction tomography (IDT) refers to a class of optical\nmicroscopy techniques for imaging the 3D refractive index (RI) distribution of\na sample from a set of 2D intensity-only measurements. The reconstruction of\nartifact-free RI maps is a fundamental challenge in IDT due to the loss of\nphase information and the missing cone problem. Neural fields (NF) has recently\nemerged as a new deep learning (DL) paradigm for learning continuous\nrepresentations of complex 3D scenes without external training datasets. We\npresent DeCAF as the first NF-based IDT method that can learn a high-quality\ncontinuous representation of a RI volume directly from its intensity-only and\nlimited-angle measurements. We show on three different IDT modalities and\nmultiple biological samples that DeCAF can generate high-contrast and\nartifact-free RI maps.",
    "descriptor": "",
    "authors": [
      "Renhao Liu",
      "Yu Sun",
      "Jiabei Zhu",
      "Lei Tian",
      "Ulugbek Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00002"
  },
  {
    "id": "arXiv:2112.00016",
    "title": "Learning knot invariants across dimensions",
    "abstract": "We use deep neural networks to machine learn correlations between knot\ninvariants in various dimensions. The three-dimensional invariant of interest\nis the Jones polynomial $J(q)$, and the four-dimensional invariants are the\nKhovanov polynomial $\\text{Kh}(q,t)$, smooth slice genus $g$, and Rasmussen's\n$s$-invariant. We find that a two-layer feed-forward neural network can predict\n$s$ from $\\text{Kh}(q,-q^{-4})$ with greater than $99\\%$ accuracy. A\ntheoretical explanation for this performance exists in knot theory via the now\ndisproven knight move conjecture, which is obeyed by all knots in our dataset.\nMore surprisingly, we find similar performance for the prediction of $s$ from\n$\\text{Kh}(q,-q^{-2})$, which suggests a novel relationship between the\nKhovanov and Lee homology theories of a knot. The network predicts $g$ from\n$\\text{Kh}(q,t)$ with similarly high accuracy, and we discuss the extent to\nwhich the machine is learning $s$ as opposed to $g$, since there is a general\ninequality $|s| \\leq 2g$. The Jones polynomial, as a three-dimensional\ninvariant, is not obviously related to $s$ or $g$, but the network achieves\ngreater than $95\\%$ accuracy in predicting either from $J(q)$. Moreover,\nsimilar accuracy can be achieved by evaluating $J(q)$ at roots of unity. This\nsuggests a relationship with $SU(2)$ Chern--Simons theory, and we review the\ngauge theory construction of Khovanov homology which may be relevant for\nexplaining the network's performance.",
    "descriptor": "\nComments: 35 pages, 6 figures\n",
    "authors": [
      "Jessica Craven",
      "Mark Hughes",
      "Vishnu Jejjala",
      "Arjun Kar"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (cs.LG)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.00016"
  },
  {
    "id": "arXiv:2112.00045",
    "title": "Limiting the Search Space in Optimal Quantum Circuit Mapping",
    "abstract": "Executing quantum circuits on currently available quantum computers requires\ncompiling them to a representation that conforms to all restrictions imposed by\nthe targeted architecture. Due to the limited connectivity of the devices'\nphysical qubits, an important step in the compilation process is to map the\ncircuit in such a way that all its gates are executable on the hardware.\nExisting solutions delivering optimal solutions to this task are severely\nchallenged by the exponential complexity of the problem. In this paper, we show\nthat the search space of the mapping problem can be limited drastically while\nstill preserving optimality. The proposed strategies are generic,\narchitecture-independent, and can be adapted to various mapping methodologies.\nThe findings are backed by both, theoretical considerations and experimental\nevaluations. Results confirm that, by limiting the search space, optimal\nsolutions can be determined for instances that timeouted before or speed-ups of\nup to three orders of magnitude can be achieved.",
    "descriptor": "\nComments: 7 pages, 5 figures, to be published at Asia and South Pacific Design Automation Conference (ASP-DAC), 2022\n",
    "authors": [
      "Lukas Burgholzer",
      "Sarah Schneider",
      "Robert Wille"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.00045"
  },
  {
    "id": "arXiv:2112.00152",
    "title": "One-step replica symmetry breaking of random regular NAE-SAT II",
    "abstract": "Continuing our earlier work in \\cite{nss20a}, we study the random regular\nk-NAE-SAT model in the condensation regime. In \\cite{nss20a}, the 1RSB\nproperties of the model were established with positive probability. In this\npaper, we improve the result to probability arbitrarily close to one. To do so,\nwe introduce a new framework which is the synthesis of two approaches: the\nsmall subgraph conditioning and a variance decomposition technique using Doob\nmartingales and discrete Fourier analysis. The main challenge is a delicate\nintegration of the two methods to overcome the difficulty arising from applying\nthe moment method to an unbounded state space.",
    "descriptor": "\nComments: This is Part II of a two-paper series\n",
    "authors": [
      "Danny Nam",
      "Allan Sly",
      "Youngtak Sohn"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.00152"
  },
  {
    "id": "arXiv:2112.00183",
    "title": "Descriptive vs. inferential community detection: pitfalls, myths and  half-truths",
    "abstract": "Community detection is one of the most important methodological fields of\nnetwork science, and one which has attracted a significant amount of attention\nover the past decades. This area deals with the automated division of a network\ninto fundamental building blocks, with the objective of providing a summary of\nits large-scale structure. Despite its importance and widespread adoption,\nthere is a noticeable gap between what is considered the state-of-the-art and\nthe methods that are actually used in practice in a variety of fields. Here we\nattempt to address this discrepancy by dividing existing methods according to\nwhether they have a \"descriptive\" or an \"inferential\" goal. While descriptive\nmethods find patterns in networks based on intuitive notions of community\nstructure, inferential methods articulate a precise generative model, and\nattempt to fit it to data. In this way, they are able to provide insights into\nthe mechanisms of network formation, and separate structure from randomness in\na manner supported by statistical evidence. We review how employing descriptive\nmethods with inferential aims is riddled with pitfalls and misleading answers,\nand thus should be in general avoided. We argue that inferential methods are\nmore typically aligned with clearer scientific questions, yield more robust\nresults, and should be in general preferred. We attempt to dispel some myths\nand half-truths often believed when community detection is employed in\npractice, in an effort to improve both the use of such methods as well as the\ninterpretation of their results.",
    "descriptor": "\nComments: 51 pages, 16 figures\n",
    "authors": [
      "Tiago P. Peixoto"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00183"
  },
  {
    "id": "arXiv:2112.00187",
    "title": "Quantum Compiling",
    "abstract": "Quantum compiling fills the gap between the computing layer of high-level\nquantum algorithms and the layer of physical qubits with their specific\nproperties and constraints. Quantum compiling is a hybrid between the\ngeneral-purpose compilers of computers, transforming high-level language to\nassembly language and hardware synthesis by hardware description language,\nwhere functions are automatically synthesized into customized hardware. Here we\nreview the quantum compiling stack of both gate model quantum computers and the\nadiabatic quantum computers, respectively. The former involves low level qubit\ncontrol, quantum error correction, synthesis of short quantum circuits,\ntranspiling, while the latter involves the virtualization of qubits by\nembedding of QUBO and HUBO problems on constrained graphs of physical qubits\nand both quantum error suppression and correction. Commercial initiatives and\nquantum compiling products are reviewed, including explicit programming\nexamples.",
    "descriptor": "\nComments: 37 pages, 8 figures\n",
    "authors": [
      "Marco Maronese",
      "Lorenzo Moro",
      "Lorenzo Rocutto",
      "Enrico Prati"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.00187"
  },
  {
    "id": "arXiv:2112.00222",
    "title": "Convergence of GANs Training: A Game and Stochastic Control Methodology",
    "abstract": "Training of generative adversarial networks (GANs) is known for its\ndifficulty to converge. This paper first confirms analytically one of the\nculprits behind this convergence issue: the lack of convexity in GANs objective\nfunctions, hence the well-posedness problem of GANs models. Then, it proposes a\nstochastic control approach for hyper-parameters tuning in GANs training. In\nparticular, it presents an optimal solution for adaptive learning rate which\ndepends on the convexity of the objective function, and builds a precise\nrelation between improper choices of learning rate and explosion in GANs\ntraining. Finally, empirical studies demonstrate that training algorithms\nincorporating this selection methodology outperform standard ones.",
    "descriptor": "",
    "authors": [
      "Othmane Mounjid",
      "Xin Guo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00222"
  },
  {
    "id": "arXiv:2112.00257",
    "title": "Harmonic numbers as the summation of integrals",
    "abstract": "Harmonic numbers arise from the truncation of the harmonic series. The\n$n^\\text{th}$ harmonic number is the sum of the reciprocals of each positive\ninteger up to $n$. In addition to briefly introducing the properties of\nharmonic numbers, we cover harmonic numbers as the summation of integrals that\ninvolve the product of exponential and hyperbolic secant functions. The proof\nis relatively simple since it only comprises the Principle of Mathematical\nInduction and integration by parts.",
    "descriptor": "\nComments: 4 pages, 16 references\n",
    "authors": [
      "N. Karjanto"
    ],
    "subjectives": [
      "History and Overview (math.HO)",
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2112.00257"
  },
  {
    "id": "arXiv:2112.00274",
    "title": "Distributed Forward-Backward Methods without Central Coordination",
    "abstract": "In this work, we propose and analyse forward-backward-type algorithms for\nfinding a zero in the sum of finitely many monotone operators, which are not\nbased on reduction to a two operator inclusion in the product space. Each\niteration of the studied algorithms requires one resolvent evaluation per\nset-valued operator, one forward evaluation per cocoercive operator, and two\nforward evaluations per monotone operator. Unlike existing methods, the\nstructure of the proposed algorithms are suitable for distributed,\ndecentralised implementation in ring networks without the need for a central\ncoordinator to enforce consensus between nodes.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Francisco J. Arag\u00f3n-Artacho",
      "Yura Malitsky",
      "Matthew K. Tam",
      "David Torregrosa-Bel\u00e9n"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.00274"
  },
  {
    "id": "arXiv:2112.00307",
    "title": "A note on simple games with two equivalence classes of players",
    "abstract": "Many real-world voting systems consist of voters that occur in just two\ndifferent types. Indeed, each voting system with a {\\lq\\lq}House{\\rq\\rq} and a\n{\\lq\\lq}Senat{\\rq\\rq} is of that type. Here we present structural\ncharacterizations and explicit enumeration formulas for these so-called\nbipartite simple games.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Sascha Kurz",
      "Dani Samaniego"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.00307"
  },
  {
    "id": "arXiv:2112.00313",
    "title": "Discriminating Quantum States with Quantum Machine Learning",
    "abstract": "Quantum machine learning (QML) algorithms have obtained great relevance in\nthe machine learning (ML) field due to the promise of quantum speedups when\nperforming basic linear algebra subroutines (BLAS), a fundamental element in\nmost ML algorithms. By making use of BLAS operations, we propose, implement and\nanalyze a quantum k-means (qk-means) algorithm with a low time complexity of\n$\\mathcal{O}(NKlog(D)I/C)$ to apply it to the fundamental problem of\ndiscriminating quantum states at readout. Discriminating quantum states allows\nthe identification of quantum states $|0\\rangle$ and $|1\\rangle$ from low-level\nin-phase and quadrature signal (IQ) data, and can be done using custom ML\nmodels. In order to reduce dependency on a classical computer, we use the\nqk-means to perform state discrimination on the IBMQ Bogota device and managed\nto find assignment fidelities of up to 98.7% that were only marginally lower\nthan that of the k-means algorithm. Inspection of assignment fidelity scores\nresulting from applying both algorithms to a combination of quantum states\nshowed concordance to our correlation analysis using Pearson Correlation\ncoefficients, where evidence shows cross-talk in the (1, 2) and (2, 3)\nneighboring qubit couples for the analyzed device.",
    "descriptor": "",
    "authors": [
      "David Quiroga",
      "Prasanna Date",
      "Raphael C. Pooser"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00313"
  },
  {
    "id": "arXiv:2112.00314",
    "title": "Asymmetric error control under imperfect supervision: a  label-noise-adjusted Neyman-Pearson umbrella algorithm",
    "abstract": "Label noise in data has long been an important problem in supervised learning\napplications as it affects the effectiveness of many widely used classification\nmethods. Recently, important real-world applications, such as medical diagnosis\nand cybersecurity, have generated renewed interest in the Neyman-Pearson (NP)\nclassification paradigm, which constrains the more severe type of error (e.g.,\nthe type I error) under a preferred level while minimizing the other (e.g., the\ntype II error). However, there has been little research on the NP paradigm\nunder label noise. It is somewhat surprising that even when common NP\nclassifiers ignore the label noise in the training stage, they are still able\nto control the type I error with high probability. However, the price they pay\nis excessive conservativeness of the type I error and hence a significant drop\nin power (i.e., $1 - $ type II error). Assuming that domain experts provide\nlower bounds on the corruption severity, we propose the first theory-backed\nalgorithm that adapts most state-of-the-art classification methods to the\ntraining label noise under the NP paradigm. The resulting classifiers not only\ncontrol the type I error with high probability under the desired level but also\nimprove power.",
    "descriptor": "",
    "authors": [
      "Shunan Yao",
      "Bradley Rava",
      "Xin Tong",
      "Gareth James"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00314"
  },
  {
    "id": "arXiv:2112.00344",
    "title": "Leveraging Sequence Embedding and Convolutional Neural Network for  Protein Function Prediction",
    "abstract": "The capability of accurate prediction of protein functions and properties is\nessential in the biotechnology industry, e.g. drug development and artificial\nprotein synthesis, etc. The main challenges of protein function prediction are\nthe large label space and the lack of labeled training data. Our method\nleverages unsupervised sequence embedding and the success of deep convolutional\nneural network to overcome these challenges. In contrast, most of the existing\nmethods delete the rare protein functions to reduce the label space.\nFurthermore, some existing methods require additional bio-information (e.g.,\nthe 3-dimensional structure of the proteins) which is difficult to be\ndetermined in biochemical experiments. Our proposed method significantly\noutperforms the other methods on the publicly available benchmark using only\nprotein sequences as input. This allows the process of identifying protein\nfunctions to be sped up.",
    "descriptor": "\nComments: Published in NeurIPS 2018 Machine Learning for Molecules and Materials Workshop\n",
    "authors": [
      "Wei-Cheng Tseng",
      "Po-Han Chi",
      "Jia-Hua Wu",
      "Min Sun"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2112.00344"
  },
  {
    "id": "arXiv:2112.00365",
    "title": "Mixed neural network Gaussian processes",
    "abstract": "This paper makes two contributions. Firstly, it introduces mixed\ncompositional kernels and mixed neural network Gaussian processes (NGGPs).\nMixed compositional kernels are generated by composition of probability\ngenerating functions (PGFs). A mixed NNGP is a Gaussian process (GP) with a\nmixed compositional kernel, arising in the infinite-width limit of multilayer\nperceptrons (MLPs) that have a different activation function for each layer.\nSecondly, $\\theta$ activation functions for neural networks and $\\theta$\ncompositional kernels are introduced by building upon the theory of branching\nprocesses, and more specifically upon $\\theta$ PGFs. While $\\theta$\ncompositional kernels are recursive, they are expressed in closed form. It is\nshown that $\\theta$ compositional kernels have non-degenerate asymptotic\nproperties under certain conditions. Thus, GPs with $\\theta$ compositional\nkernels do not require non-explicit recursive kernel evaluations and have\ncontrollable infinite-depth asymptotic properties. An open research question is\nwhether GPs with $\\theta$ compositional kernels are limits of infinitely-wide\nMLPs with $\\theta$ activation functions.",
    "descriptor": "",
    "authors": [
      "Alexey Lindo",
      "Theodore Papamarkou",
      "Serik Sagitov",
      "Laura Stewart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00365"
  },
  {
    "id": "arXiv:2112.00391",
    "title": "Non-Sturmian sequences of matrices providing the maximum growth rate of  matrix products",
    "abstract": "One of the most pressing problems in modern analysis is the study of the\ngrowth rate of the norms of all possible matrix products $\\|A_{i_{n}}\\cdots\nA_{i_{0}}\\|$ with factors from a set of matrices $\\mathscr{A}$. So far, only\nfor a relatively small number of classes of matrices $\\mathscr{A}$ has it been\npossible to rigorously describe the sequences of matrices $\\{A_{i_{n}}\\}$ that\nguarantee the maximal growth rate of the corresponding norms. Moreover, in\nalmost all theoretically studied cases, the index sequences $\\{i_{n}\\}$ of\nmatrices maximizing the norms of the corresponding matrix products turned out\nto be periodic or so-called Sturmian sequences, which entails a whole set of\n``good'' properties of the sequences $\\{A_{i_{n}}\\}$, in particular the\nexistence of a limiting frequency of occurrence of each matrix factor\n$A_{i}\\in\\mathscr{A}$ in them. The paper determines a class of $2\\times 2$\nmatrices consisting of two matrices similar to rotations of the plane in which\nthe sequence $\\{A_{i_{n}}\\}$ maximizing the growth rate of the norms\n$\\|A_{i_{n}}\\cdots A_{i_{0}}\\|$ is not Sturmian. All considerations are based\non numerical modeling and cannot be considered mathematically rigorous in this\npart. Rather, they should be interpreted as a set of questions for further\ncomprehensive theoretical analysis.",
    "descriptor": "\nComments: 27 pages, 11 figures, 50 bibliography references, 1 Python program listing\n",
    "authors": [
      "Victor Kozyakin"
    ],
    "subjectives": [
      "Rings and Algebras (math.RA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.00391"
  },
  {
    "id": "arXiv:2112.00423",
    "title": "Controlling Wasserstein distances by Kernel norms with application to  Compressive Statistical Learning",
    "abstract": "Comparing probability distributions is at the crux of many machine learning\nalgorithms. Maximum Mean Discrepancies (MMD) and Optimal Transport distances\n(OT) are two classes of distances between probability measures that have\nattracted abundant attention in past years. This paper establishes some\nconditions under which the Wasserstein distance can be controlled by MMD norms.\nOur work is motivated by the compressive statistical learning (CSL) theory, a\ngeneral framework for resource-efficient large scale learning in which the\ntraining data is summarized in a single vector (called sketch) that captures\nthe information relevant to the considered learning task. Inspired by existing\nresults in CSL, we introduce the H\\\"older Lower Restricted Isometric Property\n(H\\\"older LRIP) and show that this property comes with interesting guarantees\nfor compressive statistical learning. Based on the relations between the MMD\nand the Wasserstein distance, we provide guarantees for compressive statistical\nlearning by introducing and studying the concept of Wasserstein learnability of\nthe learning task, that is when some task-specific metric between probability\ndistributions can be bounded by a Wasserstein distance.",
    "descriptor": "",
    "authors": [
      "Titouan Vayer",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00423"
  },
  {
    "id": "arXiv:2112.00456",
    "title": "Lecture notes on complexity of quantifier elimination over the reals",
    "abstract": "These are lecture notes for a course I gave in mid-1990s for MSc students at\nthe University of Bath. It presents an algorithm with singly exponential\ncomplexity for the existential theory of the reals, in the spirit of J.\nRenegar. The aim was to convey the main underlying ideas, so many of the proofs\nand finer details of algorithms are either missing or just sketched. I changed\nnothing in the original notes except adding references, bibliography, and\ncorrecting obvious typos.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Nicolai Vorobjov"
    ],
    "subjectives": [
      "History and Overview (math.HO)",
      "Symbolic Computation (cs.SC)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.00456"
  },
  {
    "id": "arXiv:2112.00460",
    "title": "Machine learning Hadron Spectral Functions in Lattice QCD",
    "abstract": "Hadron spectral functions carry all the information of hadrons and are\nencoded in the Euclidean two-point correlation functions. The extraction of\nhadron spectral functions from the correlator is a typical ill-posed inverse\nproblem and infinite number of solutions to this problem exists. We propose a\nnovel neural network (sVAE) based on the Variation Auto-Encoder (VAE) and\nBayesian theorem. Inspired by the maximum entropy method (MEM) we construct the\nloss function of the neural work such that it includes a Shannon-Jaynes entropy\nterm and a likelihood term. The sVAE is then trained to provide the most\nprobable spectral functions. For the training samples of spectral function we\nused general spectral functions produced from the Gaussian Mixture Model. After\nthe training is done we performed the mock data tests with input spectral\nfunctions consisting 1) only a free continuum, 2) only a resonance peak, 3) a\nresonance peak plus a free continuum and 4) a NRQCD motivated spectral\nfunction. From the mock data test we find that the sVAE in most cases is\ncomparable to the maximum entropy method in the quality of reconstructing\nspectral functions and even outperforms the MEM in the case where the spectral\nfunction has sharp peaks with insufficient number of data points in the\ncorrelator. By applying to temporal correlation functions of charmonium in the\npseudoscalar channel obtained in the quenched lattice QCD at 0.75 $T_c$ on\n$128^3\\times96$ lattices and $1.5$ $T_c$ on $128^3\\times48$ lattices, we find\nthat the resonance peak of $\\eta_c$ extracted from both the sVAE and MEM has a\nsubstantial dependence on the number of points in the temporal direction\n($N_\\tau$) adopted in the lattice simulation and $N_\\tau$ larger than 48 is\nneeded to resolve the fate of $\\eta_c$ at 1.5 $T_c$.",
    "descriptor": "\nComments: 9 pages, 7 figures. Talk presented at the 38th International Symposium on Lattice Field Theory (Lattice 2021), 26-30 July, 2021, Zoom/Gather@Massachusetts Institute of Technology\n",
    "authors": [
      "Shi-Yang Chen",
      "Heng-Tong Ding",
      "Fei-Yi Liu",
      "Gabor Papp",
      "Chun-Bin Yang"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "High Energy Physics - Theory (hep-th)",
      "Nuclear Theory (nucl-th)"
    ],
    "url": "https://arxiv.org/abs/2112.00460"
  },
  {
    "id": "arXiv:2112.00539",
    "title": "Finitary type theories with and without contexts",
    "abstract": "We give a definition of finitary type theories that subsumes many examples of\ndependent type theories, such as variants of Martin-L\\\"of type theory, simple\ntype theories, first-order and higher-order logics, and homotopy type theory.\nWe prove several general meta-theorems about finitary type theories: weakening,\nadmissibility of substitution and instantiation of metavariables, derivability\nof presuppositions, uniqueness of typing, and inversion principles.\nWe then give a second formulation of finitary type theories in which there\nare no explicit contexts. Instead, free variables are explicitly annotated with\ntheir types. We provide translations between finitary type theories with and\nwithout contexts, thereby showing that they have the same expressive power. The\ncontext-free type theory is implemented in the nucleus of the Andromeda 2 proof\nassistant.",
    "descriptor": "",
    "authors": [
      "Philipp G. Haselwarter",
      "Andrej Bauer"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.00539"
  },
  {
    "id": "arXiv:2112.00543",
    "title": "(Causal)-Activation of Complex Entanglement Structures in Quantum  Networks",
    "abstract": "Entanglement represents \"the\" key resource for several applications of\nquantum information processing, ranging from quantum communications to\ndistributed quantum computing. Despite its fundamental importance,\ndeterministic generation of maximally entangled qubits represents an on-going\nopen problem. Here, we design a novel generation scheme exhibiting two\nattractive features, namely, i) deterministically generating genuinely\nmultipartite entangled states, ii) without requiring any direct interaction\nbetween the qubits. Indeed, the only necessary condition is the possibility of\ncoherently controlling -- according to the indefinite causal order framework --\nthe causal order among some unitaries acting on the qubits. Through the paper,\nwe analyze and derive the conditions on the unitaries for deterministic\ngeneration, and we provide examples for unitaries practical implementation. We\nconclude the paper by discussing the scalability of the proposed scheme to\nhigher dimensional GME states and by introducing some possible applications of\nthe proposal for quantum networks.",
    "descriptor": "",
    "authors": [
      "Seid Koudia",
      "Angela Sara Cacciapuoti",
      "Marcello Caleffi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.00543"
  },
  {
    "id": "arXiv:2112.00565",
    "title": "On Mixing Times of Metropolized Algorithm With Optimization Step (MAO) :  A New Framework",
    "abstract": "In this paper, we consider sampling from a class of distributions with thin\ntails supported on $\\mathbb{R}^d$ and make two primary contributions. First, we\npropose a new Metropolized Algorithm With Optimization Step (MAO), which is\nwell suited for such targets. Our algorithm is capable of sampling from\ndistributions where the Metropolis-adjusted Langevin algorithm (MALA) is not\nconverging or lacking in theoretical guarantees. Second, we derive upper bounds\non the mixing time of MAO. Our results are supported by simulations on multiple\ntarget distributions.",
    "descriptor": "\nComments: 24 pages, 27 Figures, 4 Tables\n",
    "authors": [
      "EL Mahdi Khribch",
      "George Deligiannidis",
      "Daniel Paulin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.00565"
  },
  {
    "id": "arXiv:2112.00573",
    "title": "Uniqueness for the q-state antiferromagnetic Potts model on the regular  tree",
    "abstract": "We present an elementary proof for the uniqueness regime of the general\n$q$-state antiferromagnetic Potts model on the $d$-ary tree. The key\nobservation is a positive association property of its boundary condition. We\nalso obtain the exact exponential decay rate in all of the subcritical regime,\nand power law decay rate at the critical temperature.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Chenlin Gu",
      "Wei Wu",
      "Kuan Yang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Mathematical Physics (math-ph)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.00573"
  },
  {
    "id": "arXiv:2112.00635",
    "title": "Predicting lexical skills from oral reading with acoustic measures",
    "abstract": "Literacy assessment is an important activity for education administrators\nacross the globe. Typically achieved in a school setting by testing a child's\noral reading, it is intensive in human resources. While automatic speech\nrecognition (ASR) is a potential solution to the problem, it tends to be\ncomputationally expensive for hand-held devices apart from needing language and\naccent-specific speech for training. In this work, we propose a system to\npredict the word-decoding skills of a student based on simple acoustic features\nderived from the recording. We first identify a meaningful categorization of\nword-decoding skills by analyzing a manually transcribed data set of children's\noral reading recordings. Next the automatic prediction of the category is\nattempted with the proposed acoustic features. Pause statistics, syllable rate\nand spectral and intensity dynamics are found to be reliable indicators of\nspecific types of oral reading deficits, providing useful feedback by\ndiscriminating the different characteristics of beginning readers. This\ncomputationally simple and language-agnostic approach is found to provide a\nperformance close to that obtained using a language dependent ASR that required\nconsiderable tuning of its parameters.",
    "descriptor": "",
    "authors": [
      "Charvi Vitthal",
      "Shreeharsha B S",
      "Kamini Sabu",
      "Preeti Rao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.00635"
  },
  {
    "id": "arXiv:2112.00672",
    "title": "Controlling for multiple covariates",
    "abstract": "A fundamental problem in statistics is to compare the outcomes attained by\nmembers of subpopulations. This problem arises in the analysis of randomized\ncontrolled trials, in the analysis of A/B tests, and in the assessment of\nfairness and bias in the treatment of sensitive subpopulations, especially when\nmeasuring the effects of algorithms and machine learning. Often the comparison\nmakes the most sense when performed separately for individuals who are similar\naccording to certain characteristics given by the values of covariates of\ninterest; the separate comparisons can also be aggregated in various ways to\ncompare across all values of the covariates. Separating, segmenting, or\nstratifying into those with similar values of the covariates is also known as\n\"conditioning on\" or \"controlling for\" those covariates; controlling for age or\nannual income is common.\nTwo standard methods of controlling for covariates are (1) binning and (2)\nregression modeling. Binning requires making fairly arbitrary, yet frequently\nhighly influential choices, and is unsatisfactorily temperamental in multiple\ndimensions, with multiple covariates. Regression analysis works wonderfully\nwhen there is good reason to believe in a particular parameterized regression\nmodel or classifier (such as logistic regression). Thus, there appears to be no\nextant canonical fully non-parametric regression for the comparison of\nsubpopulations, not while conditioning on multiple specified covariates.\nExisting methods rely on analysts to make choices, and those choices can be\ndebatable; analysts can deceive others or even themselves. The present paper\naims to fill the gap, combining two ingredients: (1) recently developed\nmethodologies for such comparisons that already exist when conditioning on a\nsingle scalar covariate and (2) the Hilbert space-filling curve that maps\ncontinuously from one dimension to multiple dimensions.",
    "descriptor": "\nComments: 29 pages, 21 figures, 2 tables\n",
    "authors": [
      "Mark Tygert"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computers and Society (cs.CY)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.00672"
  },
  {
    "id": "arXiv:2112.00695",
    "title": "DeepAoANet: Learning Angle of Arrival from Software Defined Radios with  Deep Neural Networks",
    "abstract": "Direction finding and positioning systems based on RF signals are\nsignificantly impacted by multipath propagation, particularly in indoor\nenvironments. Existing algorithms (e.g MUSIC) perform poorly in resolving Angle\nof Arrival (AoA) in the presence of multipath or when operating in a weak\nsignal regime. We note that digitally sampled RF frontends allow for the easy\nanalysis of signals, and their delayed components. Low-cost Software-Defined\nRadio (SDR) modules enable Channel State Information (CSI) extraction across a\nwide spectrum, motivating the design of an enhanced Angle-of-Arrival (AoA)\nsolution. We propose a Deep Learning approach to deriving AoA from a single\nsnapshot of the SDR multichannel data. We compare and contrast deep-learning\nbased angle classification and regression models, to estimate up to two AoAs\naccurately. We have implemented the inference engines on different platforms to\nextract AoAs in real-time, demonstrating the computational tractability of our\napproach. To demonstrate the utility of our approach we have collected IQ\n(In-phase and Quadrature components) samples from a four-element Universal\nLinear Array (ULA) in various Light-of-Sight (LOS) and Non-Line-of-Sight (NLOS)\nenvironments, and published the dataset. Our proposed method demonstrates\nexcellent reliability in determining number of impinging signals and realized\nmean absolute AoA errors less than $2^{\\circ}$.",
    "descriptor": "\nComments: Angle-of-arrival estimation from Software Defined Radios, Benchmark and Baseline\n",
    "authors": [
      "Zhuangzhuang Dai",
      "Yuhang He",
      "Tran Vu",
      "Niki Trigoni",
      "Andrew Markham"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00695"
  },
  {
    "id": "arXiv:2112.00720",
    "title": "Quasi-universality of Reeb graph distances",
    "abstract": "We establish bi-Lipschitz bounds certifying quasi-universality (universality\nup to a constant factor) for various distances between Reeb graphs: the\ninterleaving distance, the functional distortion distance, and the functional\ncontortion distance. The definition of the latter distance is a novel\ncontribution, and for the special case of contour trees we also prove strict\nuniversality of this distance. Furthermore, we prove that for the special case\nof merge trees the functional contortion distance coincides with the\ninterleaving distance, yielding universality of all four distances in this\ncase.",
    "descriptor": "",
    "authors": [
      "Ulrich Bauer",
      "H\u00e5vard Bakke Bjerkevik",
      "Benedikt Fluhr"
    ],
    "subjectives": [
      "Geometric Topology (math.GT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.00720"
  },
  {
    "id": "arXiv:2112.00723",
    "title": "Infinite Neural Network Quantum States",
    "abstract": "We study infinite limits of neural network quantum states ($\\infty$-NNQS),\nwhich exhibit representation power through ensemble statistics, and also\ntractable gradient descent dynamics. Ensemble averages of Renyi entropies are\nexpressed in terms of neural network correlators, and architectures that\nexhibit volume-law entanglement are presented. A general framework is developed\nfor studying the gradient descent dynamics of neural network quantum states\n(NNQS), using a quantum state neural tangent kernel (QS-NTK). For $\\infty$-NNQS\nthe training dynamics is simplified, since the QS-NTK becomes deterministic and\nconstant. An analytic solution is derived for quantum state supervised\nlearning, which allows an $\\infty$-NNQS to recover any target wavefunction.\nNumerical experiments on finite and infinite NNQS in the transverse field Ising\nmodel and Fermi Hubbard model demonstrate excellent agreement with theory.\n$\\infty$-NNQS opens up new opportunities for studying entanglement and training\ndynamics in other physics applications, such as in finding ground states.",
    "descriptor": "",
    "authors": [
      "Di Luo",
      "James Halverson"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2112.00723"
  },
  {
    "id": "arXiv:1609.04382",
    "title": "Warped Convolutions: Efficient Invariance to Spatial Transformations",
    "abstract": "Comments: Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017",
    "descriptor": "\nComments: Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017\n",
    "authors": [
      "Jo\u00e3o F. Henriques",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1609.04382"
  },
  {
    "id": "arXiv:1811.11858",
    "title": "Can you sign a quantum state?",
    "abstract": "Comments: 26+12 pages, v4: version for publication in Quantum",
    "descriptor": "\nComments: 26+12 pages, v4: version for publication in Quantum\n",
    "authors": [
      "Gorjan Alagic",
      "Tommaso Gagliardoni",
      "Christian Majenz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1811.11858"
  },
  {
    "id": "arXiv:1905.12707",
    "title": "Heterogeneous causal effects with imperfect compliance: a Bayesian  machine learning approach",
    "abstract": "Comments: To appear in the Annals of Applied Statistics",
    "descriptor": "\nComments: To appear in the Annals of Applied Statistics\n",
    "authors": [
      "Falco J. Bargagli-Stoffi",
      "Kristof De-Witte",
      "Giorgio Gnecco"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.12707"
  },
  {
    "id": "arXiv:1906.01756",
    "title": "Slack Channels Ecology in Enterprises: How Employees Collaborate Through  Group Chat",
    "abstract": "Comments: Accepted at ACM CSCW'22",
    "descriptor": "\nComments: Accepted at ACM CSCW'22\n",
    "authors": [
      "Dakuo Wang",
      "Haoyu Wang",
      "Mo Yu",
      "Zahra Ashktorab",
      "Ming Tan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1906.01756"
  },
  {
    "id": "arXiv:1906.01820",
    "title": "Risks from Learned Optimization in Advanced Machine Learning Systems",
    "abstract": "Risks from Learned Optimization in Advanced Machine Learning Systems",
    "descriptor": "",
    "authors": [
      "Evan Hubinger",
      "Chris van Merwijk",
      "Vladimir Mikulik",
      "Joar Skalse",
      "Scott Garrabrant"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1906.01820"
  },
  {
    "id": "arXiv:1910.03332",
    "title": "Upper and Lower Bounds for Fully Retroactive Graph Problems",
    "abstract": "Upper and Lower Bounds for Fully Retroactive Graph Problems",
    "descriptor": "",
    "authors": [
      "Monika Henzinger",
      "Xiaowei Wu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1910.03332"
  },
  {
    "id": "arXiv:1910.05065",
    "title": "A Theory of Relation Learning and Cross-domain Generalization",
    "abstract": "Comments: Includes supplemental material",
    "descriptor": "\nComments: Includes supplemental material\n",
    "authors": [
      "Leonidas A. A. Doumas",
      "Guillermo Puebla",
      "Andrea E. Martin",
      "John E. Hummel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1910.05065"
  },
  {
    "id": "arXiv:1910.08953",
    "title": "Overcoming Free-Riding in Bandit Games",
    "abstract": "Comments: 66 pages, 4 figures; minor corrections and updated references",
    "descriptor": "\nComments: 66 pages, 4 figures; minor corrections and updated references\n",
    "authors": [
      "Johannes H\u00f6rner",
      "Nicolas Klein",
      "Sven Rady"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1910.08953"
  },
  {
    "id": "arXiv:1910.11656",
    "title": "Attend to the Difference: Cross-Modality Person Re-identification via  Contrastive Correlation",
    "abstract": "Comments: The paper is accepted by TIP",
    "descriptor": "\nComments: The paper is accepted by TIP\n",
    "authors": [
      "Shizhou Zhang",
      "Yifei Yang",
      "Peng Wang",
      "Guoqiang Liang",
      "Xiuwei Zhang",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1910.11656"
  },
  {
    "id": "arXiv:1911.02883",
    "title": "Graph Domain Adaptation with Localized Graph Signal Representations",
    "abstract": "Graph Domain Adaptation with Localized Graph Signal Representations",
    "descriptor": "",
    "authors": [
      "Yusuf Yigit Pilavci",
      "Eylem Tugce Guneyi",
      "Cemil Cengiz",
      "Elif Vural"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.02883"
  },
  {
    "id": "arXiv:1912.07362",
    "title": "Dynamic controller that operates over homomorphically encrypted data for  infinite time horizon",
    "abstract": "Comments: 12 pages, 3 figures",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Junsoo Kim",
      "Hyungbo Shim",
      "Kyoohyung Han"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1912.07362"
  },
  {
    "id": "arXiv:1912.10036",
    "title": "A Family of Deep Learning Architectures for Channel Estimation and  Hybrid Beamforming in Multi-Carrier mm-Wave Massive MIMO",
    "abstract": "Comments: Accepted Paper in IEEE Transactions on Cognitive Communications and Networking. arXiv admin note: text overlap with arXiv:1910.14240",
    "descriptor": "\nComments: Accepted Paper in IEEE Transactions on Cognitive Communications and Networking. arXiv admin note: text overlap with arXiv:1910.14240\n",
    "authors": [
      "Ahmet M. Elbir",
      "Kumar Vijay Mishra",
      "M. R. Bhavani Shankar",
      "Bj\u00f6rn Ottersten"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1912.10036"
  },
  {
    "id": "arXiv:1912.10769",
    "title": "Online Throughput Maximization on Unrelated Machines: Commitment is No  Burden",
    "abstract": "Online Throughput Maximization on Unrelated Machines: Commitment is No  Burden",
    "descriptor": "",
    "authors": [
      "Franziska Eberle",
      "Nicole Megow",
      "Kevin Schewior"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1912.10769"
  },
  {
    "id": "arXiv:2001.08510",
    "title": "Bibliography of distributed approximation beyond bounded degree",
    "abstract": "Comments: An annotated bibliography. Third version",
    "descriptor": "\nComments: An annotated bibliography. Third version\n",
    "authors": [
      "Laurent Feuilloley"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2001.08510"
  },
  {
    "id": "arXiv:2002.00885",
    "title": "Diffusion bridges for stochastic Hamiltonian systems and shape  evolutions",
    "abstract": "Diffusion bridges for stochastic Hamiltonian systems and shape  evolutions",
    "descriptor": "",
    "authors": [
      "Alexis Arnaudon",
      "Frank van der Meulen",
      "Moritz Schauer",
      "Stefan Sommer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2002.00885"
  },
  {
    "id": "arXiv:2003.01416",
    "title": "An Online Learning Framework for Energy-Efficient Navigation of Electric  Vehicles",
    "abstract": "Comments: Accepted at IJCAI 2020 Main Track. Sole copyright holder is IJCAI (International Joint Conferences on Artificial Intelligence), all rights reserved. Available at this https URL",
    "descriptor": "\nComments: Accepted at IJCAI 2020 Main Track. Sole copyright holder is IJCAI (International Joint Conferences on Artificial Intelligence), all rights reserved. Available at this https URL\n",
    "authors": [
      "Niklas \u00c5kerblom",
      "Yuxin Chen",
      "Morteza Haghir Chehreghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.01416"
  },
  {
    "id": "arXiv:2003.10094",
    "title": "Penalized and Decentralized Contextual Bandit Learning for WLAN Channel  Allocation with Contention-Driven Feature Extraction",
    "abstract": "Comments: 12 pages, 6 figures, 3 Tables",
    "descriptor": "\nComments: 12 pages, 6 figures, 3 Tables\n",
    "authors": [
      "Kota Yamashita",
      "Shotaro Kamiya",
      "Koji Yamamoto",
      "Yusuke Koda",
      "Takayuki Nishio",
      "Masahiro Morikura"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2003.10094"
  },
  {
    "id": "arXiv:2003.13607",
    "title": "Non-asymptotic Superlinear Convergence of Standard Quasi-Newton Methods",
    "abstract": "Non-asymptotic Superlinear Convergence of Standard Quasi-Newton Methods",
    "descriptor": "",
    "authors": [
      "Qiujiang Jin",
      "Aryan Mokhtari"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.13607"
  },
  {
    "id": "arXiv:2003.13896",
    "title": "Robust Multiple-Path Orienteering Problem: Securing Against Adversarial  Attacks",
    "abstract": "Comments: submitted to TRO",
    "descriptor": "\nComments: submitted to TRO\n",
    "authors": [
      "Guangyao Shi",
      "Lifeng Zhou",
      "Pratap Tokekar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2003.13896"
  },
  {
    "id": "arXiv:2003.13966",
    "title": "Individual Fairness in Advertising Auctions through Inverse  Proportionality",
    "abstract": "Comments: To appear at ITCS 2022; this is the full version",
    "descriptor": "\nComments: To appear at ITCS 2022; this is the full version\n",
    "authors": [
      "Shuchi Chawla",
      "Meena Jagadeesan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.13966"
  },
  {
    "id": "arXiv:2006.12242",
    "title": "Exploiting topology awareness for routing in LEO satellite  constellations",
    "abstract": "Comments: Accepted for publication at IEEE GLOBECOM 2021",
    "descriptor": "\nComments: Accepted for publication at IEEE GLOBECOM 2021\n",
    "authors": [
      "Jonas W. Rabjerg",
      "Israel Leyva-Mayorga",
      "Beatriz Soret",
      "Petar Popovski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2006.12242"
  },
  {
    "id": "arXiv:2007.02931",
    "title": "Adaptive Risk Minimization: Learning to Adapt to Domain Shift",
    "abstract": "Comments: NeurIPS 2021 ; Project website: this https URL ; Code: this https URL",
    "descriptor": "\nComments: NeurIPS 2021 ; Project website: this https URL ; Code: this https URL\n",
    "authors": [
      "Marvin Zhang",
      "Henrik Marklund",
      "Nikita Dhawan",
      "Abhishek Gupta",
      "Sergey Levine",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.02931"
  },
  {
    "id": "arXiv:2007.14390",
    "title": "Flower: A Friendly Federated Learning Research Framework",
    "abstract": "Comments: Open-Source, mobile-friendly Federated Learning framework",
    "descriptor": "\nComments: Open-Source, mobile-friendly Federated Learning framework\n",
    "authors": [
      "Daniel J. Beutel",
      "Taner Topal",
      "Akhil Mathur",
      "Xinchi Qiu",
      "Javier Fernandez-Marques",
      "Yan Gao",
      "Lorenzo Sani",
      "Kwing Hei Li",
      "Titouan Parcollet",
      "Pedro Porto Buarque de Gusm\u00e3o",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.14390"
  },
  {
    "id": "arXiv:2007.14823",
    "title": "Theory of gating in recurrent neural networks",
    "abstract": "Comments: 13 figures",
    "descriptor": "\nComments: 13 figures\n",
    "authors": [
      "Kamesh Krishnamurthy",
      "Tankut Can",
      "David J. Schwab"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2007.14823"
  },
  {
    "id": "arXiv:2008.00742",
    "title": "Collaborative Learning in the Jungle (Decentralized, Byzantine,  Heterogeneous, Asynchronous and Nonconvex Learning)",
    "abstract": "Comments: 34 pages, 1 figure",
    "descriptor": "\nComments: 34 pages, 1 figure\n",
    "authors": [
      "El-Mahdi El-Mhamdi",
      "Sadegh Farhadkhani",
      "Rachid Guerraoui",
      "Arsany Guirguis",
      "L\u00ea Nguy\u00ean Hoang",
      "S\u00e9bastien Rouault"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.00742"
  },
  {
    "id": "arXiv:2008.07527",
    "title": "Music Boundary Detection using Convolutional Neural Networks: A  comparative analysis of combined input features",
    "abstract": "Music Boundary Detection using Convolutional Neural Networks: A  comparative analysis of combined input features",
    "descriptor": "",
    "authors": [
      "Carlos Hernandez-Olivan",
      "Jose R. Beltran",
      "David Diaz-Guerra"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2008.07527"
  },
  {
    "id": "arXiv:2009.09899",
    "title": "Clustering COVID-19 Lung Scans",
    "abstract": "Comments: 11 pages, 7 figures",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Jacob Householder",
      "Andrew Householder",
      "John Paul Gomez-Reed",
      "Fredrick Park",
      "Shuai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.09899"
  },
  {
    "id": "arXiv:2010.09453",
    "title": "Fast accuracy estimation of deep learning based multi-class musical  source separation",
    "abstract": "Fast accuracy estimation of deep learning based multi-class musical  source separation",
    "descriptor": "",
    "authors": [
      "Alexandru Mocanu",
      "Benjamin Ricaud",
      "Milos Cernak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2010.09453"
  },
  {
    "id": "arXiv:2010.12751",
    "title": "Model Extraction Attacks on Graph Neural Networks: Taxonomy and  Realization",
    "abstract": "Comments: This paper has been published in the 17th ACM ASIA Conference on Computer and Communications Security (ACM ASIACCS 2022)",
    "descriptor": "\nComments: This paper has been published in the 17th ACM ASIA Conference on Computer and Communications Security (ACM ASIACCS 2022)\n",
    "authors": [
      "Bang Wu",
      "Xiangwen Yang",
      "Shirui Pan",
      "Xingliang Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2010.12751"
  },
  {
    "id": "arXiv:2011.00740",
    "title": "Influence Patterns for Explaining Information Flow in BERT",
    "abstract": "Comments: Neurips 2021",
    "descriptor": "\nComments: Neurips 2021\n",
    "authors": [
      "Kaiji Lu",
      "Zifan Wang",
      "Piotr Mardziel",
      "Anupam Datta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2011.00740"
  },
  {
    "id": "arXiv:2011.06782",
    "title": "A Nested Bi-level Optimization Framework for Robust Few Shot Learning",
    "abstract": "Comments: To appear in the proceedings of AAAI 2022",
    "descriptor": "\nComments: To appear in the proceedings of AAAI 2022\n",
    "authors": [
      "Krishnateja Killamsetty",
      "Changbin Li",
      "Chen Zhao",
      "Rishabh Iyer",
      "Feng Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.06782"
  },
  {
    "id": "arXiv:2011.12108",
    "title": "Wide-angle Image Rectification: A Survey",
    "abstract": "Comments: Accepted by the International Journal of Computer Vision (IJCV). Both the datasets and source code are available at this https URL",
    "descriptor": "\nComments: Accepted by the International Journal of Computer Vision (IJCV). Both the datasets and source code are available at this https URL\n",
    "authors": [
      "Jinlong Fan",
      "Jing Zhang",
      "Stephen J. Maybank",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2011.12108"
  },
  {
    "id": "arXiv:2011.14303",
    "title": "A Probabilistic Higher-order Fixpoint Logic",
    "abstract": "A Probabilistic Higher-order Fixpoint Logic",
    "descriptor": "",
    "authors": [
      "Yo Mitani",
      "Naoki Kobayashi",
      "Takeshi Tsukada"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2011.14303"
  },
  {
    "id": "arXiv:2011.14989",
    "title": "The $\\aleph$ Calculus",
    "abstract": "Comments: 51 pages, 18 figures/listings; update references and acknowledgements",
    "descriptor": "\nComments: 51 pages, 18 figures/listings; update references and acknowledgements\n",
    "authors": [
      "Hannah Earley"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2011.14989"
  },
  {
    "id": "arXiv:2011.15014",
    "title": "Learning from Human Directional Corrections",
    "abstract": "Comments: Please find the codes and games at this https URL",
    "descriptor": "\nComments: Please find the codes and games at this https URL\n",
    "authors": [
      "Wanxin Jin",
      "Todd D. Murphey",
      "Zehui Lu",
      "Shaoshuai Mou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.15014"
  },
  {
    "id": "arXiv:2012.00118",
    "title": "A new operational representation of dependencies in Event Structures",
    "abstract": "A new operational representation of dependencies in Event Structures",
    "descriptor": "",
    "authors": [
      "G. Michele Pinna"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2012.00118"
  },
  {
    "id": "arXiv:2012.00675",
    "title": "Topological Learning for Brain Networks",
    "abstract": "Topological Learning for Brain Networks",
    "descriptor": "",
    "authors": [
      "Tananun Songdechakraiwut",
      "Moo K. Chung"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2012.00675"
  },
  {
    "id": "arXiv:2012.03646",
    "title": "A novel dataset for the identification of computer generated melodies in  the CSMT challenge",
    "abstract": "Comments: Published by Conference on Sound and Music Technology",
    "descriptor": "\nComments: Published by Conference on Sound and Music Technology\n",
    "authors": [
      "Shengchen Li",
      "Yinji Jing",
      "Gy\u00f6rgy Fazekas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2012.03646"
  },
  {
    "id": "arXiv:2012.04731",
    "title": "Long Term Motion Prediction Using Keyposes",
    "abstract": "Comments: Code publicly available at: this https URL",
    "descriptor": "\nComments: Code publicly available at: this https URL\n",
    "authors": [
      "Sena Kiciroglu",
      "Wei Wang",
      "Mathieu Salzmann",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.04731"
  },
  {
    "id": "arXiv:2012.09855",
    "title": "Infinite Nature: Perpetual View Generation of Natural Scenes from a  Single Image",
    "abstract": "Comments: ICCV 2021 (oral); Project page: this https URL; Video: this https URL",
    "descriptor": "\nComments: ICCV 2021 (oral); Project page: this https URL; Video: this https URL\n",
    "authors": [
      "Andrew Liu",
      "Richard Tucker",
      "Varun Jampani",
      "Ameesh Makadia",
      "Noah Snavely",
      "Angjoo Kanazawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2012.09855"
  },
  {
    "id": "arXiv:2012.15254",
    "title": "Post-Quantum Blockchain Proofs of Work",
    "abstract": "Comments: 30 pages. (v3) changed the title and improved readability. This work supersedes the result of our previous work in eprint.iacr.org/2019/1150",
    "descriptor": "\nComments: 30 pages. (v3) changed the title and improved readability. This work supersedes the result of our previous work in eprint.iacr.org/2019/1150\n",
    "authors": [
      "Alexandru Cojocaru",
      "Juan Garay",
      "Aggelos Kiayias",
      "Fang Song",
      "Petros Wallden"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2012.15254"
  },
  {
    "id": "arXiv:2101.10011",
    "title": "They See Me Rollin': Inherent Vulnerability of the Rolling Shutter in  CMOS Image Sensors",
    "abstract": "Comments: 15 pages, 15 figures",
    "descriptor": "\nComments: 15 pages, 15 figures\n",
    "authors": [
      "Sebastian K\u00f6hler",
      "Giulio Lovisotto",
      "Simon Birnbach",
      "Richard Baker",
      "Ivan Martinovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2101.10011"
  },
  {
    "id": "arXiv:2101.10166",
    "title": "A Machine-checked proof of Birkhoff's Variety Theorem in Martin-L\u00f6f  Type Theory",
    "abstract": "Comments: This is the long (35 page) version of a paper submitted to TYPES 2021; the previous draft, [v2], was a comprehensive description of an old version of the Agda Universal Algebra Library (called UALib; ver. 1.0.0); the library was rewritten and renamed agda-algebras (ver. 2.0.0); this paper describes only a subset of the agda-algebras library that we used to prove Birkhoff's HSP theorem in Agda",
    "descriptor": "\nComments: This is the long (35 page) version of a paper submitted to TYPES 2021; the previous draft, [v2], was a comprehensive description of an old version of the Agda Universal Algebra Library (called UALib; ver. 1.0.0); the library was rewritten and renamed agda-algebras (ver. 2.0.0); this paper describes only a subset of the agda-algebras library that we used to prove Birkhoff's HSP theorem in Agda\n",
    "authors": [
      "William DeMeo",
      "Jacques Carette"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2101.10166"
  },
  {
    "id": "arXiv:2101.11091",
    "title": "Nonconvex Regularized Gradient Projection Sparse Reconstruction for  Massive MIMO Channel Estimation",
    "abstract": "Nonconvex Regularized Gradient Projection Sparse Reconstruction for  Massive MIMO Channel Estimation",
    "descriptor": "",
    "authors": [
      "Pengxia Wu",
      "Julian Cheng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.11091"
  },
  {
    "id": "arXiv:2101.11970",
    "title": "AHMoSe: A Knowledge-Based Visual Support System for Selecting Regression  Machine Learning Models",
    "abstract": "Comments: 27 pages, 6 figures, 5 tables. Accepted manuscript version. Published in Computers and Electronics in Agriculture",
    "descriptor": "\nComments: 27 pages, 6 figures, 5 tables. Accepted manuscript version. Published in Computers and Electronics in Agriculture\n",
    "authors": [
      "Diego Rojo",
      "Nyi Nyi Htun",
      "Denis Parra",
      "Robin De Croon",
      "Katrien Verbert"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.11970"
  },
  {
    "id": "arXiv:2102.00405",
    "title": "BNLP: Natural language processing toolkit for Bengali language",
    "abstract": "Comments: 5 pages, 4 figures",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Sagor Sarker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.00405"
  },
  {
    "id": "arXiv:2102.00883",
    "title": "Stochastic High Fidelity Simulation and Scenarios for Testing of Fixed  Wing Autonomous GNSS-Denied Navigation Algorithms",
    "abstract": "Comments: 25 pages, 17 figures",
    "descriptor": "\nComments: 25 pages, 17 figures\n",
    "authors": [
      "Eduardo Gallo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.00883"
  },
  {
    "id": "arXiv:2102.01381",
    "title": "Generalized Facial Manipulation Detection with Edge Region Feature  Extraction",
    "abstract": "Comments: Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision 2022 (WACV 2022)",
    "descriptor": "\nComments: Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision 2022 (WACV 2022)\n",
    "authors": [
      "Dong-Keon Kim",
      "Kwangsu Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.01381"
  },
  {
    "id": "arXiv:2102.04877",
    "title": "Noisy Recurrent Neural Networks",
    "abstract": "Comments: 38 pages",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Soon Hoe Lim",
      "N. Benjamin Erichson",
      "Liam Hodgkinson",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2102.04877"
  },
  {
    "id": "arXiv:2102.06492",
    "title": "Customizable Stochastic High Fidelity Model of the Sensors and Camera  onboard a Low SWaP Fixed Wing Autonomous Aircraft",
    "abstract": "Comments: 32 pages, 6 figures",
    "descriptor": "\nComments: 32 pages, 6 figures\n",
    "authors": [
      "Eduado Gallo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.06492"
  },
  {
    "id": "arXiv:2102.07173",
    "title": "A note on VNP-completeness and border complexity",
    "abstract": "Comments: Theorem 1 has been strengthened. The topology has been adjusted. Section 7 is new",
    "descriptor": "\nComments: Theorem 1 has been strengthened. The topology has been adjusted. Section 7 is new\n",
    "authors": [
      "Christian Ikenmeyer",
      "Abhiroop Sanyal"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2102.07173"
  },
  {
    "id": "arXiv:2103.00347",
    "title": "Better Together? How Externalities of Size Complicate Notions of  Solidarity and Actuarial Fairness",
    "abstract": "Comments: Presented at ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT) 2021",
    "descriptor": "\nComments: Presented at ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT) 2021\n",
    "authors": [
      "Kate Donahue",
      "Solon Barocas"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2103.00347"
  },
  {
    "id": "arXiv:2103.09577",
    "title": "Theoretical bounds on data requirements for the ray-based classification",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Brian J. Weber",
      "Sandesh S. Kalantre",
      "Thomas McJunkin",
      "Jacob M. Taylor",
      "Justyna P. Zwolak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.09577"
  },
  {
    "id": "arXiv:2103.09812",
    "title": "Molecular Index Modulation using Convolutional Neural Networks",
    "abstract": "Comments: In submission to Elsevier Nano Communication Networks",
    "descriptor": "\nComments: In submission to Elsevier Nano Communication Networks\n",
    "authors": [
      "Ozgur Kara",
      "Gokberk Yaylali",
      "Ali Emre Pusane",
      "Tuna Tugcu"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2103.09812"
  },
  {
    "id": "arXiv:2103.11594",
    "title": "Deep Neural Networks Learn Meta-Structures from Noisy Labels in Semantic  Segmentation",
    "abstract": "Deep Neural Networks Learn Meta-Structures from Noisy Labels in Semantic  Segmentation",
    "descriptor": "",
    "authors": [
      "Yaoru Luo",
      "Guole Liu",
      "Wenjing Li",
      "Yuanhao Guo",
      "Ge Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11594"
  },
  {
    "id": "arXiv:2103.11791",
    "title": "Machine Learning Empowered Resource Allocation in IRS Aided MISO-NOMA  Networks",
    "abstract": "Machine Learning Empowered Resource Allocation in IRS Aided MISO-NOMA  Networks",
    "descriptor": "",
    "authors": [
      "X. Gao",
      "Y. Liu",
      "X. Liu",
      "L. Song"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.11791"
  },
  {
    "id": "arXiv:2103.13135",
    "title": "Homomorphic encoders of profinite abelian groups I",
    "abstract": "Homomorphic encoders of profinite abelian groups I",
    "descriptor": "",
    "authors": [
      "Mar\u00eda V. Ferrer",
      "Salvador Hern\u00e1ndez"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Information Theory (cs.IT)",
      "General Topology (math.GN)"
    ],
    "url": "https://arxiv.org/abs/2103.13135"
  },
  {
    "id": "arXiv:2103.14785",
    "title": "A Comprehensive Review of the Video-to-Text Problem",
    "abstract": "Comments: 66 pages, 6 figures. Accepted by Artificial Intelligence Review",
    "descriptor": "\nComments: 66 pages, 6 figures. Accepted by Artificial Intelligence Review\n",
    "authors": [
      "Jesus Perez-Martin",
      "Benjamin Bustos",
      "Silvio Jamil F. Guimar\u00e3es",
      "Ivan Sipiran",
      "Jorge P\u00e9rez",
      "Grethel Coello Said"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.14785"
  },
  {
    "id": "arXiv:2104.01632",
    "title": "Isconna: Streaming Anomaly Detection with Frequency and Patterns",
    "abstract": "Isconna: Streaming Anomaly Detection with Frequency and Patterns",
    "descriptor": "",
    "authors": [
      "Rui Liu",
      "Siddharth Bhatia",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.01632"
  },
  {
    "id": "arXiv:2104.03926",
    "title": "Conditional Meta-Network for Blind Super-Resolution with Multiple  Degradations",
    "abstract": "Comments: Under review. Our code will be released after reviewing!",
    "descriptor": "\nComments: Under review. Our code will be released after reviewing!\n",
    "authors": [
      "Guanghao Yin",
      "Wei Wang",
      "Zehuan Yuan",
      "Wei Ji",
      "Dongdong Yu",
      "Shouqian Sun",
      "Tat-Seng Chua",
      "Changhu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03926"
  },
  {
    "id": "arXiv:2104.05128",
    "title": "A Scalable Algorithm for Decentralized Actor Termination Detection",
    "abstract": "Comments: 33 pages, 4 figures. Extended version of CONCUR 2020 paper arXiv:2007.10553. Accepted to LMCS. This version incorporates comments from reviewers, leading several paragraphs to be expanded and rephrased",
    "descriptor": "\nComments: 33 pages, 4 figures. Extended version of CONCUR 2020 paper arXiv:2007.10553. Accepted to LMCS. This version incorporates comments from reviewers, leading several paragraphs to be expanded and rephrased\n",
    "authors": [
      "Dan Plyukhin",
      "Gul Agha"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.05128"
  },
  {
    "id": "arXiv:2104.05755",
    "title": "Tensor Processing Primitives: A Programming Abstraction for Efficiency  and Portability in Deep Learning & HPC Workloads",
    "abstract": "Tensor Processing Primitives: A Programming Abstraction for Efficiency  and Portability in Deep Learning & HPC Workloads",
    "descriptor": "",
    "authors": [
      "Evangelos Georganas",
      "Dhiraj Kalamkar",
      "Sasikanth Avancha",
      "Menachem Adelman",
      "Deepti Aggarwal",
      "Cristina Anderson",
      "Alexander Breuer",
      "Jeremy Bruestle",
      "Narendra Chaudhary",
      "Abhisek Kundu",
      "Denise Kutnick",
      "Frank Laub",
      "Vasimuddin Md",
      "Sanchit Misra",
      "Ramanarayan Mohanty",
      "Hans Pabst",
      "Brian Retford",
      "Barukh Ziv",
      "Alexander Heinecke"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.05755"
  },
  {
    "id": "arXiv:2104.08646",
    "title": "Competency Problems: On Finding and Removing Artifacts in Language Data",
    "abstract": "Comments: EMNLP 2021. This version fixes an error in Proposition 1 and adds discussion (the EMNLP camera ready version is unfixed)",
    "descriptor": "\nComments: EMNLP 2021. This version fixes an error in Proposition 1 and adds discussion (the EMNLP camera ready version is unfixed)\n",
    "authors": [
      "Matt Gardner",
      "William Merrill",
      "Jesse Dodge",
      "Matthew E. Peters",
      "Alexis Ross",
      "Sameer Singh",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08646"
  },
  {
    "id": "arXiv:2104.09766",
    "title": "Solution landscape of the Onsager model identifies non-axisymmetric  critical points",
    "abstract": "Solution landscape of the Onsager model identifies non-axisymmetric  critical points",
    "descriptor": "",
    "authors": [
      "Jianyuan Yin",
      "Lei Zhang",
      "Pingwen Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.09766"
  },
  {
    "id": "arXiv:2104.12147",
    "title": "Learning Aided Auctioning based Spectrum Access System in a Wireless  Optical Network",
    "abstract": "Comments: Communicated to IEEE for possible publication",
    "descriptor": "\nComments: Communicated to IEEE for possible publication\n",
    "authors": [
      "Atri Mukhopadhyay",
      "Goutam Das"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2104.12147"
  },
  {
    "id": "arXiv:2105.03210",
    "title": "Series reversion in Calder\u00f3n's problem",
    "abstract": "Comments: 24 pages, 5 figures",
    "descriptor": "\nComments: 24 pages, 5 figures\n",
    "authors": [
      "Henrik Garde",
      "Nuutti Hyv\u00f6nen"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.03210"
  },
  {
    "id": "arXiv:2105.04738",
    "title": "Lightweight Distributed Gaussian Process Regression for Online Machine  Learning",
    "abstract": "Lightweight Distributed Gaussian Process Regression for Online Machine  Learning",
    "descriptor": "",
    "authors": [
      "Zhenyuan Yuan",
      "Minghui Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.04738"
  },
  {
    "id": "arXiv:2105.08291",
    "title": "Independent Asymmetric Embedding for Cascade Prediction on Social  Networks",
    "abstract": "Independent Asymmetric Embedding for Cascade Prediction on Social  Networks",
    "descriptor": "",
    "authors": [
      "Wenjin Xie",
      "Xiaomeng Wang",
      "Tao Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.08291"
  },
  {
    "id": "arXiv:2105.09045",
    "title": "Do Models Learn the Directionality of Relations? A New Evaluation:  Relation Direction Recognition",
    "abstract": "Comments: 10 pages, 4 figures. accepted by IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI)",
    "descriptor": "\nComments: 10 pages, 4 figures. accepted by IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI)\n",
    "authors": [
      "Shengfei Lyu",
      "Xingyu Wu",
      "Jinlong Li",
      "Qiuju Chen",
      "Huanhuan Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.09045"
  },
  {
    "id": "arXiv:2105.09163",
    "title": "High-Performance FPGA-based Accelerator for Bayesian Neural Networks",
    "abstract": "Comments: Design Automation Conference (DAC) 2021",
    "descriptor": "\nComments: Design Automation Conference (DAC) 2021\n",
    "authors": [
      "Hongxiang Fan",
      "Martin Ferianc",
      "Miguel Rodrigues",
      "Hongyu Zhou",
      "Xinyu Niu",
      "Wayne Luk"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.09163"
  },
  {
    "id": "arXiv:2105.11521",
    "title": "Deep neural network enabled corrective source term approach to hybrid  analysis and modeling",
    "abstract": "Deep neural network enabled corrective source term approach to hybrid  analysis and modeling",
    "descriptor": "",
    "authors": [
      "Sindre Stenen Blakseth",
      "Adil Rasheed",
      "Trond Kvamsdal",
      "Omer San"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.11521"
  },
  {
    "id": "arXiv:2105.13598",
    "title": "End-to-End Deep Fault Tolerant Control",
    "abstract": "Comments: 11 pages, 7 figures",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Daulet Baimukashev",
      "Bexultan Rakhim",
      "Matteo Rubagotti",
      "Huseyin Atakan Varol"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.13598"
  },
  {
    "id": "arXiv:2105.14656",
    "title": "Human-level COVID-19 Diagnosis from Low-dose CT Scans Using a Two-stage  Time-distributed Capsule Network",
    "abstract": "Human-level COVID-19 Diagnosis from Low-dose CT Scans Using a Two-stage  Time-distributed Capsule Network",
    "descriptor": "",
    "authors": [
      "Parnian Afshar",
      "Moezedin Javad Rafiee",
      "Farnoosh Naderkhani",
      "Shahin Heidarian",
      "Nastaran Enshaei",
      "Anastasia Oikonomou",
      "Faranak Babaki Fard",
      "Reut Anconina",
      "Keyvan Farahani",
      "Konstantinos N. Plataniotis",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14656"
  },
  {
    "id": "arXiv:2105.15168",
    "title": "MSG-Transformer: Exchanging Local Spatial Information by Manipulating  Messenger Tokens",
    "abstract": "MSG-Transformer: Exchanging Local Spatial Information by Manipulating  Messenger Tokens",
    "descriptor": "",
    "authors": [
      "Jiemin Fang",
      "Lingxi Xie",
      "Xinggang Wang",
      "Xiaopeng Zhang",
      "Wenyu Liu",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15168"
  },
  {
    "id": "arXiv:2106.00774",
    "title": "Optimizing Functionals on the Space of Probabilities with Input Convex  Neural Networks",
    "abstract": "Optimizing Functionals on the Space of Probabilities with Input Convex  Neural Networks",
    "descriptor": "",
    "authors": [
      "David Alvarez-Melis",
      "Yair Schiff",
      "Youssef Mroueh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00774"
  },
  {
    "id": "arXiv:2106.03996",
    "title": "Lessons learned developing and using a machine learning model to  automatically transcribe 2.3 million handwritten occupation codes",
    "abstract": "Lessons learned developing and using a machine learning model to  automatically transcribe 2.3 million handwritten occupation codes",
    "descriptor": "",
    "authors": [
      "Bj\u00f8rn-Richard Pedersen",
      "Einar Holsb\u00f8",
      "Trygve Andersen",
      "Nikita Shvetsov",
      "Johan Ravn",
      "Hilde Leikny Sommerseth",
      "Lars Ailo Bongo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03996"
  },
  {
    "id": "arXiv:2106.04550",
    "title": "DETReg: Unsupervised Pretraining with Region Priors for Object Detection",
    "abstract": "Comments: Tech report",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Amir Bar",
      "Xin Wang",
      "Vadim Kantorov",
      "Colorado J Reed",
      "Roei Herzig",
      "Gal Chechik",
      "Anna Rohrbach",
      "Trevor Darrell",
      "Amir Globerson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04550"
  },
  {
    "id": "arXiv:2106.05390",
    "title": "Optimizing Reusable Knowledge for Continual Learning via Metalearning",
    "abstract": "Optimizing Reusable Knowledge for Continual Learning via Metalearning",
    "descriptor": "",
    "authors": [
      "Julio Hurtado",
      "Alain Raymond-Saez",
      "Alvaro Soto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05390"
  },
  {
    "id": "arXiv:2106.06097",
    "title": "Neural Optimization Kernel: Towards Robust Deep Learning",
    "abstract": "Comments: Deep Learning, Kernel Methods, Deep Learning Theory, Kernel Approximation, Integral Approximation",
    "descriptor": "\nComments: Deep Learning, Kernel Methods, Deep Learning Theory, Kernel Approximation, Integral Approximation\n",
    "authors": [
      "Yueming Lyu",
      "Ivor Tsang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06097"
  },
  {
    "id": "arXiv:2106.06201",
    "title": "Distributed Urban Freeway Traffic Optimization Considering Congestion  Propagation",
    "abstract": "Distributed Urban Freeway Traffic Optimization Considering Congestion  Propagation",
    "descriptor": "",
    "authors": [
      "Fengkun Gao",
      "Bo Yang",
      "Cailian Chen",
      "Xinping Guan",
      "Yang Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06201"
  },
  {
    "id": "arXiv:2106.07533",
    "title": "Posterior Temperature Optimization in Variational Inference for Inverse  Problems",
    "abstract": "Comments: Accepted at Bayesian Deep Learning workshop, NeurIPS 2021",
    "descriptor": "\nComments: Accepted at Bayesian Deep Learning workshop, NeurIPS 2021\n",
    "authors": [
      "Max-Heinrich Laves",
      "Malte T\u00f6lle",
      "Alexander Schlaefer",
      "Sandy Engelhardt"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07533"
  },
  {
    "id": "arXiv:2106.07995",
    "title": "Learning of feature points without additional supervision improves  reinforcement learning from images",
    "abstract": "Learning of feature points without additional supervision improves  reinforcement learning from images",
    "descriptor": "",
    "authors": [
      "Rinu Boney",
      "Alexander Ilin",
      "Juho Kannala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.07995"
  },
  {
    "id": "arXiv:2106.09877",
    "title": "HIFIR: Hybrid Incomplete Factorization with Iterative Refinement for  Preconditioning Ill-conditioned and Singular Systems",
    "abstract": "Comments: Submitted to ACM Transactions on Mathematical Software (TOMS)",
    "descriptor": "\nComments: Submitted to ACM Transactions on Mathematical Software (TOMS)\n",
    "authors": [
      "Qiao Chen",
      "Xiangmin Jiao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2106.09877"
  },
  {
    "id": "arXiv:2106.11958",
    "title": "Prototypical Cross-Attention Networks for Multiple Object Tracking and  Segmentation",
    "abstract": "Comments: NeurIPS 2021, Spotlight; Our code and video resources are available at this http URL",
    "descriptor": "\nComments: NeurIPS 2021, Spotlight; Our code and video resources are available at this http URL\n",
    "authors": [
      "Lei Ke",
      "Xia Li",
      "Martin Danelljan",
      "Yu-Wing Tai",
      "Chi-Keung Tang",
      "Fisher Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11958"
  },
  {
    "id": "arXiv:2106.12052",
    "title": "Volume Rendering of Neural Implicit Surfaces",
    "abstract": "Volume Rendering of Neural Implicit Surfaces",
    "descriptor": "",
    "authors": [
      "Lior Yariv",
      "Jiatao Gu",
      "Yoni Kasten",
      "Yaron Lipman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.12052"
  },
  {
    "id": "arXiv:2106.12066",
    "title": "It's All in the Heads: Using Attention Heads as a Baseline for  Cross-Lingual Transfer in Commonsense Reasoning",
    "abstract": "Comments: Accepted to Findings of ACL 2021. 13 pages, 4 figures. Code: this https URL",
    "descriptor": "\nComments: Accepted to Findings of ACL 2021. 13 pages, 4 figures. Code: this https URL\n",
    "authors": [
      "Alexey Tikhonov",
      "Max Ryabinin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12066"
  },
  {
    "id": "arXiv:2106.13703",
    "title": "Task-Driven Detection of Distribution Shifts with Statistical Guarantees  for Robot Learning",
    "abstract": "Task-Driven Detection of Distribution Shifts with Statistical Guarantees  for Robot Learning",
    "descriptor": "",
    "authors": [
      "Alec Farid",
      "Sushant Veer",
      "Divyanshu Pachisia",
      "Anirudha Majumdar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.13703"
  },
  {
    "id": "arXiv:2106.15860",
    "title": "Understanding Adversarial Attacks on Observations in Deep Reinforcement  Learning",
    "abstract": "Understanding Adversarial Attacks on Observations in Deep Reinforcement  Learning",
    "descriptor": "",
    "authors": [
      "You Qiaoben",
      "Chengyang Ying",
      "Xinning Zhou",
      "Hang Su",
      "Jun Zhu",
      "Bo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15860"
  },
  {
    "id": "arXiv:2107.02156",
    "title": "Do Different Tracking Tasks Require Different Appearance Models?",
    "abstract": "Comments: To appear at NeurIPS 2021",
    "descriptor": "\nComments: To appear at NeurIPS 2021\n",
    "authors": [
      "Zhongdao Wang",
      "Hengshuang Zhao",
      "Ya-Li Li",
      "Shengjin Wang",
      "Philip H.S. Torr",
      "Luca Bertinetto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02156"
  },
  {
    "id": "arXiv:2107.02375",
    "title": "SplitAVG: A heterogeneity-aware federated deep learning method for  medical imaging",
    "abstract": "SplitAVG: A heterogeneity-aware federated deep learning method for  medical imaging",
    "descriptor": "",
    "authors": [
      "Miao Zhang",
      "Liangqiong Qu",
      "Praveer Singh",
      "Jayashree Kalpathy-Cramer",
      "Daniel L. Rubin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.02375"
  },
  {
    "id": "arXiv:2107.06608",
    "title": "Continuous vs. Discrete Optimization of Deep Neural Networks",
    "abstract": "Continuous vs. Discrete Optimization of Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Omer Elkabetz",
      "Nadav Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.06608"
  },
  {
    "id": "arXiv:2107.06912",
    "title": "From Show to Tell: A Survey on Deep Learning-based Image Captioning",
    "abstract": "From Show to Tell: A Survey on Deep Learning-based Image Captioning",
    "descriptor": "",
    "authors": [
      "Matteo Stefanini",
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Silvia Cascianelli",
      "Giuseppe Fiameni",
      "Rita Cucchiara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06912"
  },
  {
    "id": "arXiv:2107.07769",
    "title": "Architecture of Automated Crypto-Finance Agent",
    "abstract": "Comments: 9 pages, 7 figures",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Ali Raheman",
      "Anton Kolonin",
      "Ben Goertzel",
      "Gergely Hegykozi",
      "Ikram Ansari"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.07769"
  },
  {
    "id": "arXiv:2107.09153",
    "title": "User Association in Dense mmWave Networks as Restless Bandits",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "S. K. Singh",
      "V. S. Borkar",
      "G. S. Kasbekar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.09153"
  },
  {
    "id": "arXiv:2107.10407",
    "title": "Designing a Location Trace Anonymization Contest",
    "abstract": "Designing a Location Trace Anonymization Contest",
    "descriptor": "",
    "authors": [
      "Takao Murakami",
      "Hiromi Arai",
      "Koki Hamada",
      "Takuma Hatano",
      "Makoto Iguchi",
      "Hiroaki Kikuchi",
      "Atsushi Kuromasa",
      "Hiroshi Nakagawa",
      "Yuichi Nakamura",
      "Kenshiro Nishiyama",
      "Ryo Nojima",
      "Hidenobu Oguri",
      "Chiemi Watanabe",
      "Akira Yamada",
      "Takayasu Yamaguchi",
      "Yuji Yamaoka"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.10407"
  },
  {
    "id": "arXiv:2107.12045",
    "title": "How to Certify Machine Learning Based Safety-critical Systems? A  Systematic Literature Review",
    "abstract": "Comments: 60 pages (92 pages with references and complements), submitted to a journal (Automated Software Engineering). Changes: Emphasizing difference traditional software engineering / ML approach. Adding Related Works, Threats to Validity and Complementary Materials. Adding a table listing papers reference for each section/subsections",
    "descriptor": "\nComments: 60 pages (92 pages with references and complements), submitted to a journal (Automated Software Engineering). Changes: Emphasizing difference traditional software engineering / ML approach. Adding Related Works, Threats to Validity and Complementary Materials. Adding a table listing papers reference for each section/subsections\n",
    "authors": [
      "Florian Tambon",
      "Gabriel Laberge",
      "Le An",
      "Amin Nikanjam",
      "Paulina Stevia Nouwou Mindom",
      "Yann Pequignot",
      "Foutse Khomh",
      "Giulio Antoniol",
      "Ettore Merlo",
      "Fran\u00e7ois Laviolette"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.12045"
  },
  {
    "id": "arXiv:2107.12719",
    "title": "The CORSMAL benchmark for the prediction of the properties of containers",
    "abstract": "Comments: 13 pages, 6 tables, 7 figures, Pre-print submitted to IEEE Access",
    "descriptor": "\nComments: 13 pages, 6 tables, 7 figures, Pre-print submitted to IEEE Access\n",
    "authors": [
      "Alessio Xompero",
      "Santiago Donaher",
      "Vladimir Iashin",
      "Francesca Palermo",
      "G\u00f6khan Solak",
      "Claudio Coppola",
      "Reina Ishikawa",
      "Yuichi Nagao",
      "Ryo Hachiuma",
      "Qi Liu",
      "Fan Feng",
      "Chuanlin Lan",
      "Rosa H. M. Chan",
      "Guilherme Christmann",
      "Jyun-Ting Song",
      "Gonuguntla Neeharika",
      "Chinnakotla Krishna Teja Reddy",
      "Dinesh Jain",
      "Bakhtawar Ur Rehman",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.12719"
  },
  {
    "id": "arXiv:2107.13317",
    "title": "C3O: Collaborative Cluster Configuration Optimization for Distributed  Data Processing in Public Clouds",
    "abstract": "Comments: 10 pages, 5 figures, IEEE IC2E 2021. arXiv admin note: text overlap with arXiv:2011.07965",
    "descriptor": "\nComments: 10 pages, 5 figures, IEEE IC2E 2021. arXiv admin note: text overlap with arXiv:2011.07965\n",
    "authors": [
      "Jonathan Will",
      "Lauritz Thamsen",
      "Dominik Scheinert",
      "Jonathan Bader",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.13317"
  },
  {
    "id": "arXiv:2107.14604",
    "title": "Three-Dimensional Data-Driven Magnetostatic Field Computation using  Real-World Measurement Data",
    "abstract": "Comments: 10 pages, 8 figures",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Armin Galetzka",
      "Dimitrios Loukrezis",
      "Herbert De Gersem"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.14604"
  },
  {
    "id": "arXiv:2108.00236",
    "title": "Debiasing Samples from Online Learning Using Bootstrap",
    "abstract": "Debiasing Samples from Online Learning Using Bootstrap",
    "descriptor": "",
    "authors": [
      "Ningyuan Chen",
      "Xuefeng Gao",
      "Yi Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2108.00236"
  },
  {
    "id": "arXiv:2108.00927",
    "title": "Cloud Native Privacy Engineering through DevPrivOps",
    "abstract": "Comments: preprint version (2021-12-01), accepted for the Post-Proceedings at the 16th IFIP Summer School on Privacy and Identity Management 2021",
    "descriptor": "\nComments: preprint version (2021-12-01), accepted for the Post-Proceedings at the 16th IFIP Summer School on Privacy and Identity Management 2021\n",
    "authors": [
      "Elias Gr\u00fcnewald"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2108.00927"
  },
  {
    "id": "arXiv:2108.01819",
    "title": "Transfer Learning for Pose Estimation of Illustrated Characters",
    "abstract": "Comments: published at WACV2022",
    "descriptor": "\nComments: published at WACV2022\n",
    "authors": [
      "Shuhong Chen",
      "Matthias Zwicker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01819"
  },
  {
    "id": "arXiv:2108.06911",
    "title": "Optimal Actor-Critic Policy with Optimized Training Datasets",
    "abstract": "Optimal Actor-Critic Policy with Optimized Training Datasets",
    "descriptor": "",
    "authors": [
      "Chayan Banerjee",
      "Zhiyong Chen",
      "Nasimul Noman",
      "Mohsen Zamani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.06911"
  },
  {
    "id": "arXiv:2108.11761",
    "title": "A Framework for Learning Ante-hoc Explainable Models via Concepts",
    "abstract": "Comments: 16 pages, 15 figures",
    "descriptor": "\nComments: 16 pages, 15 figures\n",
    "authors": [
      "Anirban Sarkar",
      "Deepak Vijaykeerthy",
      "Anindya Sarkar",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11761"
  },
  {
    "id": "arXiv:2108.13342",
    "title": "DNNFusion: Accelerating Deep Neural Networks Execution with Advanced  Operator Fusion",
    "abstract": "DNNFusion: Accelerating Deep Neural Networks Execution with Advanced  Operator Fusion",
    "descriptor": "",
    "authors": [
      "Wei Niu",
      "Jiexiong Guan",
      "Yanzhi Wang",
      "Gagan Agrawal",
      "Bin Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13342"
  },
  {
    "id": "arXiv:2109.01093",
    "title": "What Users Want? WARHOL: A Generative Model for Recommendation",
    "abstract": "Comments: conflict with other editor",
    "descriptor": "\nComments: conflict with other editor\n",
    "authors": [
      "Jules Samaran",
      "Ugo Tanielian",
      "Romain Beaumont",
      "Flavian Vasile"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.01093"
  },
  {
    "id": "arXiv:2109.01120",
    "title": "Automatic Diagnosis of Schizophrenia in EEG Signals Using CNN-LSTM  Models",
    "abstract": "Automatic Diagnosis of Schizophrenia in EEG Signals Using CNN-LSTM  Models",
    "descriptor": "",
    "authors": [
      "Afshin Shoeibi",
      "Delaram Sadeghi",
      "Parisa Moridian",
      "Navid Ghassemi",
      "Jonathan Heras",
      "Roohallah Alizadehsani",
      "Ali Khadem",
      "Yinan Kong",
      "Saeid Nahavandi",
      "Yu-Dong Zhang",
      "Juan M. Gorriz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01120"
  },
  {
    "id": "arXiv:2109.03856",
    "title": "Local Augmentation for Graph Neural Networks",
    "abstract": "Comments: 16 pages, 5 figures",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Songtao Liu",
      "Hanze Dong",
      "Lanqing Li",
      "Tingyang Xu",
      "Yu Rong",
      "Peilin Zhao",
      "Junzhou Huang",
      "Dinghao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03856"
  },
  {
    "id": "arXiv:2109.04405",
    "title": "An Accelerated Proximal Gradient-based Model Predictive Control  Algorithm",
    "abstract": "An Accelerated Proximal Gradient-based Model Predictive Control  Algorithm",
    "descriptor": "",
    "authors": [
      "Jia Wang",
      "Ying Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04405"
  },
  {
    "id": "arXiv:2109.05975",
    "title": "Balancing the Budget: Feature Selection and Tracking for Multi-Camera  Visual-Inertial Odometry",
    "abstract": "Comments: Video at this https URL",
    "descriptor": "\nComments: Video at this https URL\n",
    "authors": [
      "Lintong Zhang",
      "David Wisth",
      "Marco Camurri",
      "Maurice Fallon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05975"
  },
  {
    "id": "arXiv:2109.07644",
    "title": "OPV2V: An Open Benchmark Dataset and Fusion Pipeline for Perception with  Vehicle-to-Vehicle Communication",
    "abstract": "Comments: Submitted to ICRA2022",
    "descriptor": "\nComments: Submitted to ICRA2022\n",
    "authors": [
      "Runsheng Xu",
      "Hao Xiang",
      "Xin Xia",
      "Xu Han",
      "Jinlong Li",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07644"
  },
  {
    "id": "arXiv:2109.09076",
    "title": "Towards Representation Learning for Atmospheric Dynamics",
    "abstract": "Towards Representation Learning for Atmospheric Dynamics",
    "descriptor": "",
    "authors": [
      "Sebastian Hoffmann",
      "Christian Lessig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.09076"
  },
  {
    "id": "arXiv:2109.09451",
    "title": "Money grows on (proof-)trees: the formal FA1.2 ledger standard",
    "abstract": "Money grows on (proof-)trees: the formal FA1.2 ledger standard",
    "descriptor": "",
    "authors": [
      "Murdoch Gabbay",
      "Arvid Jakobsson",
      "Kristina Sojakova"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.09451"
  },
  {
    "id": "arXiv:2109.09484",
    "title": "On Circuit-based Hybrid Quantum Neural Networks for Remote Sensing  Imagery Classification",
    "abstract": "Comments: Submitted to the JSTARS special issue on \"Quantum resources for Earth Observation\" for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: Submitted to the JSTARS special issue on \"Quantum resources for Earth Observation\" for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Alessandro Sebastianelli",
      "Daniela A. Zaidenberg",
      "Dario Spiller",
      "Bertrand Le Saux",
      "Silvia Liberata Ullo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.09484"
  },
  {
    "id": "arXiv:2109.10569",
    "title": "The Curse Revisited: When are Distances Informative for the Ground Truth  in Noisy High-Dimensional Data?",
    "abstract": "The Curse Revisited: When are Distances Informative for the Ground Truth  in Noisy High-Dimensional Data?",
    "descriptor": "",
    "authors": [
      "Robin Vandaele",
      "Bo Kang",
      "Tijl De Bie",
      "Yvan Saeys"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.10569"
  },
  {
    "id": "arXiv:2109.10619",
    "title": "Eliciting Thinking Hierarchy without Prior",
    "abstract": "Eliciting Thinking Hierarchy without Prior",
    "descriptor": "",
    "authors": [
      "Yuqing Kong",
      "Yunqi Li",
      "Yubo Zhang",
      "Zhihuan Huang",
      "Jinzhao Wu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.10619"
  },
  {
    "id": "arXiv:2109.11338",
    "title": "Orthogonal Graph Neural Networks",
    "abstract": "Orthogonal Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Kai Guo",
      "Kaixiong Zhou",
      "Xia Hu",
      "Yu Li",
      "Yi Chang",
      "Xin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.11338"
  },
  {
    "id": "arXiv:2109.12219",
    "title": "Influence of Mobility Restrictions on Transmission of COVID-19 in the  state of Maryland -- the USA",
    "abstract": "Influence of Mobility Restrictions on Transmission of COVID-19 in the  state of Maryland -- the USA",
    "descriptor": "",
    "authors": [
      "Nandini Raghuraman",
      "Kartik Kaushik"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.12219"
  },
  {
    "id": "arXiv:2109.12227",
    "title": "Bringing Generalization to Deep Multi-view Detection",
    "abstract": "Bringing Generalization to Deep Multi-view Detection",
    "descriptor": "",
    "authors": [
      "Jeet Vora",
      "Swetanjal Dutta",
      "Kanishk Jain",
      "Shyamgopal Karthik",
      "Vineet Gandhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12227"
  },
  {
    "id": "arXiv:2110.00528",
    "title": "Do Self-Supervised and Supervised Methods Learn Similar Visual  Representations?",
    "abstract": "Comments: Accepted to 2nd Workshop on Self-Supervised Learning: Theory and Practice (NeurIPS 2021), Sydney, Australia. Fixed typos, added acknowledgements. 5 pages + 2 pages of appendices, 5 figures, 1 table",
    "descriptor": "\nComments: Accepted to 2nd Workshop on Self-Supervised Learning: Theory and Practice (NeurIPS 2021), Sydney, Australia. Fixed typos, added acknowledgements. 5 pages + 2 pages of appendices, 5 figures, 1 table\n",
    "authors": [
      "Tom George Grigg",
      "Dan Busbridge",
      "Jason Ramapuram",
      "Russ Webb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.00528"
  },
  {
    "id": "arXiv:2110.01343",
    "title": "Taming singular stochastic differential equations: A numerical method",
    "abstract": "Comments: 63 pages",
    "descriptor": "\nComments: 63 pages\n",
    "authors": [
      "Khoa L\u00ea",
      "Chengcheng Ling"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.01343"
  },
  {
    "id": "arXiv:2110.05717",
    "title": "Relation-aware Video Reading Comprehension for Temporal Language  Grounding",
    "abstract": "Comments: Accepted by EMNLP-21",
    "descriptor": "\nComments: Accepted by EMNLP-21\n",
    "authors": [
      "Jialin Gao",
      "Xin Sun",
      "Mengmeng Xu",
      "Xi Zhou",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05717"
  },
  {
    "id": "arXiv:2110.06537",
    "title": "Well-classified Examples are Underestimated in Classification with Deep  Neural Networks",
    "abstract": "Comments: Accepted by AAAI 2022; 16 pages, 11 figures, 13 tables",
    "descriptor": "\nComments: Accepted by AAAI 2022; 16 pages, 11 figures, 13 tables\n",
    "authors": [
      "Guangxiang Zhao",
      "Wenkai Yang",
      "Xuancheng Ren",
      "Lei Li",
      "Xu Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06537"
  },
  {
    "id": "arXiv:2110.06634",
    "title": "End-to-end translation of human neural activity to speech with a  dual-dual generative adversarial network",
    "abstract": "Comments: 12 pages, 13 figures",
    "descriptor": "\nComments: 12 pages, 13 figures\n",
    "authors": [
      "Yina Guo",
      "Xiaofei Zhang",
      "Zhenying Gong",
      "Anhong Wang",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.06634"
  },
  {
    "id": "arXiv:2110.07037",
    "title": "Solving multiscale steady radiative transfer equation using neural  networks with uniform stability",
    "abstract": "Solving multiscale steady radiative transfer equation using neural  networks with uniform stability",
    "descriptor": "",
    "authors": [
      "Yulong Lu",
      "Li Wang",
      "Wuzhe Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.07037"
  },
  {
    "id": "arXiv:2110.07699",
    "title": "Safe Autonomous Racing via Approximate Reachability on Ego-vision",
    "abstract": "Comments: 17 pages, 15 figures, 3 tables",
    "descriptor": "\nComments: 17 pages, 15 figures, 3 tables\n",
    "authors": [
      "Bingqing Chen",
      "Jonathan Francis",
      "Jean Oh",
      "Eric Nyberg",
      "Sylvia L. Herbert"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.07699"
  },
  {
    "id": "arXiv:2110.08721",
    "title": "CAE-Transformer: Transformer-based Model to Predict Invasiveness of Lung  Adenocarcinoma Subsolid Nodules from Non-thin Section 3D CT Scans",
    "abstract": "CAE-Transformer: Transformer-based Model to Predict Invasiveness of Lung  Adenocarcinoma Subsolid Nodules from Non-thin Section 3D CT Scans",
    "descriptor": "",
    "authors": [
      "Shahin Heidarian",
      "Parnian Afshar",
      "Anastasia Oikonomou",
      "Konstantinos N. Plataniotis",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08721"
  },
  {
    "id": "arXiv:2110.08851",
    "title": "Unsupervised Representation Learning for Binary Networks by Joint  Classifier Learning",
    "abstract": "Comments: second revision",
    "descriptor": "\nComments: second revision\n",
    "authors": [
      "Dahyun Kim",
      "Jonghyun Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08851"
  },
  {
    "id": "arXiv:2110.09193",
    "title": "Topologically Regularized Data Embeddings",
    "abstract": "Topologically Regularized Data Embeddings",
    "descriptor": "",
    "authors": [
      "Robin Vandaele",
      "Bo Kang",
      "Jefrey Lijffijt",
      "Tijl De Bie",
      "Yvan Saeys"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09193"
  },
  {
    "id": "arXiv:2110.10249",
    "title": "Neural Stochastic Partial Differential Equations",
    "abstract": "Neural Stochastic Partial Differential Equations",
    "descriptor": "",
    "authors": [
      "Cristopher Salvi",
      "Maud Lemercier",
      "Andris Gerasimovics"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10249"
  },
  {
    "id": "arXiv:2110.10780",
    "title": "An Open Natural Language Processing Development Framework for EHR-based  Clinical Research: A case demonstration using the National COVID Cohort  Collaborative (N3C)",
    "abstract": "Comments: update on contents and metadata",
    "descriptor": "\nComments: update on contents and metadata\n",
    "authors": [
      "Sijia Liu",
      "Andrew Wen",
      "Liwei Wang",
      "Huan He",
      "Sunyang Fu",
      "Robert Miller",
      "Andrew Williams",
      "Daniel Harris",
      "Ramakanth Kavuluru",
      "Mei Liu",
      "Noor Abu-el-rub",
      "Rui Zhang",
      "Masoud Rouhizadeh",
      "John D. Osborne",
      "Yongqun He",
      "Umit Topaloglu",
      "Stephanie S Hong",
      "Joel H Saltz",
      "Thomas Schaffter",
      "Emily Pfaff",
      "Christopher G. Chute",
      "Tim Duong",
      "Melissa A. Haendel",
      "Rafael Fuentes",
      "Peter Szolovits",
      "Hua Xu",
      "Hongfang Liu",
      "National COVID Cohort Collaborative",
      "Natural Language Processing",
      "Subgroup",
      "National COVID Cohort Collaborative"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.10780"
  },
  {
    "id": "arXiv:2110.11571",
    "title": "Anti-Backdoor Learning: Training Clean Models on Poisoned Data",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Yige Li",
      "Xixiang Lyu",
      "Nodens Koren",
      "Lingjuan Lyu",
      "Bo Li",
      "Xingjun Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11571"
  },
  {
    "id": "arXiv:2110.11657",
    "title": "Projective Manifold Gradient Layer for Deep Rotation Regression",
    "abstract": "Projective Manifold Gradient Layer for Deep Rotation Regression",
    "descriptor": "",
    "authors": [
      "Jiayi Chen",
      "Yingda Yin",
      "Tolga Birdal",
      "Baoquan Chen",
      "Leonidas Guibas",
      "He Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11657"
  },
  {
    "id": "arXiv:2110.12667",
    "title": "Mixture-of-Variational-Experts for Continual Learning",
    "abstract": "Comments: 9 pages, 4 figures",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Heinke Hihn",
      "Daniel A. Braun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12667"
  },
  {
    "id": "arXiv:2110.13151",
    "title": "Self-supervised similarity search for large scientific datasets",
    "abstract": "Comments: 5 pages, 2 figures. The similarity search web app can be found at this https URL Accepted to the Fourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021). ArXiv admin note: text overlap with arXiv:2110.00023",
    "descriptor": "\nComments: 5 pages, 2 figures. The similarity search web app can be found at this https URL Accepted to the Fourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021). ArXiv admin note: text overlap with arXiv:2110.00023\n",
    "authors": [
      "George Stein",
      "Peter Harrington",
      "Jacqueline Blaum",
      "Tomislav Medan",
      "Zarija Lukic"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13151"
  },
  {
    "id": "arXiv:2110.13179",
    "title": "Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures",
    "abstract": "Comments: Probabilistic Hierarchical Forecasting, Neural Networks, Poisson Mixtures, Preprint submitted to IJF",
    "descriptor": "\nComments: Probabilistic Hierarchical Forecasting, Neural Networks, Poisson Mixtures, Preprint submitted to IJF\n",
    "authors": [
      "Kin G. Olivares",
      "O. Nganba Meetei",
      "Ruijun Ma",
      "Rohan Reddy",
      "Mengfei Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13179"
  },
  {
    "id": "arXiv:2111.00273",
    "title": "Cross-Modality Fusion Transformer for Multispectral Object Detection",
    "abstract": "Comments: 6 figures, 4 tables, under consideration at Pattern Recognition Letters",
    "descriptor": "\nComments: 6 figures, 4 tables, under consideration at Pattern Recognition Letters\n",
    "authors": [
      "Fang Qingyun",
      "Han Dapeng",
      "Wang Zhaokui"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00273"
  },
  {
    "id": "arXiv:2111.00765",
    "title": "Validate on Sim, Detect on Real -- Model Selection for Domain  Randomization",
    "abstract": "Comments: Updated results section. Project website: this https URL",
    "descriptor": "\nComments: Updated results section. Project website: this https URL\n",
    "authors": [
      "Gal Leibovich",
      "Guy Jacob",
      "Shadi Endrawis",
      "Gal Novik",
      "Aviv Tamar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00765"
  },
  {
    "id": "arXiv:2111.01853",
    "title": "Recursive Bayesian Networks: Generalising and Unifying Probabilistic  Context-Free Grammars and Dynamic Bayesian Networks",
    "abstract": "Comments: To be published in: Proceedings of the 35th Conference on Neural Information Processing Systems (NeurIPS 2021); Code: this https URL; Comments: corrected typo in outside probabilities: {\\alpha}(y) --&gt; {\\alpha}(x)",
    "descriptor": "\nComments: To be published in: Proceedings of the 35th Conference on Neural Information Processing Systems (NeurIPS 2021); Code: this https URL; Comments: corrected typo in outside probabilities: {\\alpha}(y) --&gt; {\\alpha}(x)\n",
    "authors": [
      "Robert Lieck",
      "Martin Rohrmeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.01853"
  },
  {
    "id": "arXiv:2111.02174",
    "title": "Unsupervised detection and open-set classification of fast-ramped  flexibility activation events",
    "abstract": "Comments: Submitted to Applied Energy. Revised by the authors",
    "descriptor": "\nComments: Submitted to Applied Energy. Revised by the authors\n",
    "authors": [
      "Nils M\u00fcller",
      "Carsten Heinrich",
      "Kai Heussen",
      "Henrik W. Bindner"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.02174"
  },
  {
    "id": "arXiv:2111.02363",
    "title": "Deep Learning-based Non-Intrusive Multi-Objective Speech Assessment  Model with Cross-Domain Features",
    "abstract": "Deep Learning-based Non-Intrusive Multi-Objective Speech Assessment  Model with Cross-Domain Features",
    "descriptor": "",
    "authors": [
      "Ryandhimas E. Zezario",
      "Szu-Wei Fu",
      "Fei Chen",
      "Chiou-Shann Fuh",
      "Hsin-Min Wang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.02363"
  },
  {
    "id": "arXiv:2111.02666",
    "title": "Sensory attenuation develops as a result of sensorimotor experience",
    "abstract": "Sensory attenuation develops as a result of sensorimotor experience",
    "descriptor": "",
    "authors": [
      "Hayato Idei",
      "Wataru Ohata",
      "Yuichi Yamashita",
      "Tetsuya Ogata",
      "Jun Tani"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.02666"
  },
  {
    "id": "arXiv:2111.03221",
    "title": "Breaking the $n^k$ Barrier for Minimum $k$-cut on Simple Graphs",
    "abstract": "Breaking the $n^k$ Barrier for Minimum $k$-cut on Simple Graphs",
    "descriptor": "",
    "authors": [
      "Zhiyang He",
      "Jason Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.03221"
  },
  {
    "id": "arXiv:2111.03941",
    "title": "Time Discretization-Invariant Safe Action Repetition for Policy Gradient  Methods",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Seohong Park",
      "Jaekyeom Kim",
      "Gunhee Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.03941"
  },
  {
    "id": "arXiv:2111.04357",
    "title": "Can semi-supervised learning reduce the amount of manual labelling  required for effective radio galaxy morphology classification?",
    "abstract": "Comments: Accepted in: Fourth Workshop on Machine Learning and the Physical Sciences (35th Conference on Neural Information Processing Systems; NeurIPS2021); final version",
    "descriptor": "\nComments: Accepted in: Fourth Workshop on Machine Learning and the Physical Sciences (35th Conference on Neural Information Processing Systems; NeurIPS2021); final version\n",
    "authors": [
      "Inigo V. Slijepcevic",
      "Anna M. M. Scaife"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.04357"
  },
  {
    "id": "arXiv:2111.06721",
    "title": "Causal Multi-Agent Reinforcement Learning: Review and Open Problems",
    "abstract": "Comments: Accepted at Cooperative AI Workshop, NeurIPS 2021",
    "descriptor": "\nComments: Accepted at Cooperative AI Workshop, NeurIPS 2021\n",
    "authors": [
      "St John Grimbly",
      "Jonathan Shock",
      "Arnu Pretorius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.06721"
  },
  {
    "id": "arXiv:2111.08096",
    "title": "VisualEnv: visual Gym environments with Blender",
    "abstract": "VisualEnv: visual Gym environments with Blender",
    "descriptor": "",
    "authors": [
      "Andrea Scorsoglio",
      "Roberto Furfaro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08096"
  },
  {
    "id": "arXiv:2111.08795",
    "title": "A Projection Operator-based Newton Method for the Trajectory  Optimization of Closed Quantum Systems",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Jieqiu Shao",
      "Joshua Combes",
      "John Hauser",
      "Marco M. Nicotra"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.08795"
  },
  {
    "id": "arXiv:2111.09512",
    "title": "ILUT Smoothers for Hybrid C-AMG with Scaled Triangular Factors",
    "abstract": "Comments: v2 updated citation information",
    "descriptor": "\nComments: v2 updated citation information\n",
    "authors": [
      "Stephen Thomas",
      "Arielle Carr",
      "Kasia \u015awirydowicz",
      "Marc Day"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2111.09512"
  },
  {
    "id": "arXiv:2111.09838",
    "title": "On Efficient Uncertainty Estimation for Resource-Constrained Mobile  Applications",
    "abstract": "Comments: 7 pages; Accepted at the Bayesian Deep Learning Workshop, NeurIPS 2021",
    "descriptor": "\nComments: 7 pages; Accepted at the Bayesian Deep Learning Workshop, NeurIPS 2021\n",
    "authors": [
      "Johanna Rock",
      "Tiago Azevedo",
      "Ren\u00e9 de Jong",
      "Daniel Ruiz-Mu\u00f1oz",
      "Partha Maji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09838"
  },
  {
    "id": "arXiv:2111.10430",
    "title": "Some Error Analysis for the Quantum Phase Estimation Algorithms",
    "abstract": "Some Error Analysis for the Quantum Phase Estimation Algorithms",
    "descriptor": "",
    "authors": [
      "Xiantao Li"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.10430"
  },
  {
    "id": "arXiv:2111.10780",
    "title": "FCOSR: A Simple Anchor-free Rotated Detector for Aerial Object Detection",
    "abstract": "Comments: 10 pages, 6 tables, 7 figures",
    "descriptor": "\nComments: 10 pages, 6 tables, 7 figures\n",
    "authors": [
      "Zhonghua Li",
      "Biao Hou",
      "Zitong Wu",
      "Licheng Jiao",
      "Bo Ren",
      "Chen Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10780"
  },
  {
    "id": "arXiv:2111.11294",
    "title": "Scaling Law for Recommendation Models: Towards General-purpose User  Representations",
    "abstract": "Comments: 11 pages, 6 figures, 5 tables",
    "descriptor": "\nComments: 11 pages, 6 figures, 5 tables\n",
    "authors": [
      "Kyuyong Shin",
      "Hanock Kwak",
      "Kyung-Min Kim",
      "Su Young Kim",
      "Max Nihlen Ramstrom",
      "Jisu Jeong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11294"
  },
  {
    "id": "arXiv:2111.11305",
    "title": "Universal Efficient Variable-rate Neural Image Compression",
    "abstract": "Comments: 5 pages, 5 figures",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Shanzhi Yin",
      "Chao Li",
      "Youneng Bao",
      "Yongshang Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11305"
  },
  {
    "id": "arXiv:2111.12124",
    "title": "Towards Learning Universal Audio Representations",
    "abstract": "Towards Learning Universal Audio Representations",
    "descriptor": "",
    "authors": [
      "Luyu Wang",
      "Pauline Luc",
      "Yan Wu",
      "Adria Recasens",
      "Lucas Smaira",
      "Andrew Brock",
      "Andrew Jaegle",
      "Jean-Baptiste Alayrac",
      "Sander Dieleman",
      "Joao Carreira",
      "Aaron van den Oord"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.12124"
  },
  {
    "id": "arXiv:2111.12143",
    "title": "Critical initialization of wide and deep neural networks through partial  Jacobians: general theory and applications to LayerNorm",
    "abstract": "Comments: 28 pages, 8 figures",
    "descriptor": "\nComments: 28 pages, 8 figures\n",
    "authors": [
      "Darshil Doshi",
      "Tianyu He",
      "Andrey Gromov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12143"
  },
  {
    "id": "arXiv:2111.12389",
    "title": "Track Boosting and Synthetic Data Aided Drone Detection",
    "abstract": "Track Boosting and Synthetic Data Aided Drone Detection",
    "descriptor": "",
    "authors": [
      "Fatih Cagatay Akyon",
      "Ogulcan Eryuksel",
      "Kamil Anil Ozfuttu",
      "Sinan Onur Altinuc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12389"
  },
  {
    "id": "arXiv:2111.12525",
    "title": "Causality-inspired Single-source Domain Generalization for Medical Image  Segmentation",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Cheng Ouyang",
      "Chen Chen",
      "Surui Li",
      "Zeju Li",
      "Chen Qin",
      "Wenjia Bai",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12525"
  },
  {
    "id": "arXiv:2111.12888",
    "title": "Effectiveness of Detection-based and Regression-based Approaches for  Estimating Mask-Wearing Ratio",
    "abstract": "Effectiveness of Detection-based and Regression-based Approaches for  Estimating Mask-Wearing Ratio",
    "descriptor": "",
    "authors": [
      "Khanh-Duy Nguyen",
      "Huy H. Nguyen",
      "Trung-Nghia Le",
      "Junichi Yamagishi",
      "Isao Echizen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12888"
  },
  {
    "id": "arXiv:2111.12978",
    "title": "Observing Interventions: A logic for thinking about experiments",
    "abstract": "Comments: This is the extended version of a paper that will appear in a special issue of the Journal of Logic and Computation dedicated to the 3rd DaL{\\'i} Workshop on Dynamic Logic: New Trends and Applications. Different from the journal version, here the reader can find the full technical appendix",
    "descriptor": "\nComments: This is the extended version of a paper that will appear in a special issue of the Journal of Logic and Computation dedicated to the 3rd DaL{\\'i} Workshop on Dynamic Logic: New Trends and Applications. Different from the journal version, here the reader can find the full technical appendix\n",
    "authors": [
      "Fausto Barbero",
      "Katrin Schulz",
      "Fernando R. Vel\u00e1zquez-Quesada",
      "Kaibo Xie"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.12978"
  },
  {
    "id": "arXiv:2111.13579",
    "title": "VL-LTR: Learning Class-wise Visual-Linguistic Representation for  Long-Tailed Visual Recognition",
    "abstract": "Comments: Technical report; 14 pages, 9 figures;",
    "descriptor": "\nComments: Technical report; 14 pages, 9 figures;\n",
    "authors": [
      "Changyao Tian",
      "Wenhai Wang",
      "Xizhou Zhu",
      "Xiaogang Wang",
      "Jifeng Dai",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13579"
  },
  {
    "id": "arXiv:2111.13670",
    "title": "Non-Convex Recovery from Phaseless Low-Resolution Blind Deconvolution  Measurements using Noisy Masked Patterns",
    "abstract": "Non-Convex Recovery from Phaseless Low-Resolution Blind Deconvolution  Measurements using Noisy Masked Patterns",
    "descriptor": "",
    "authors": [
      "Samuel Pinilla",
      "Kumar Vijay Mishra",
      "Brian Sadler"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.13670"
  },
  {
    "id": "arXiv:2111.13781",
    "title": "Common Sense Knowledge Learning for Open Vocabulary Neural Reasoning: A  First View into Chronic Disease Literature",
    "abstract": "Common Sense Knowledge Learning for Open Vocabulary Neural Reasoning: A  First View into Chronic Disease Literature",
    "descriptor": "",
    "authors": [
      "Ignacio Arroyo-Fern\u00e1ndez",
      "Jos\u00e9 Armando S\u00e1nchez-Rojas",
      "Arturo Tellez-Vel\u00e1zquez",
      "Flavio Ju\u00e1rez-Mart\u00ednez",
      "Ra\u00fal Cruz-Barbosa",
      "Enrique Guzm\u00e1n-Ram\u00edrez",
      "Yalbi Itzel Balderas-Mart\u00ednez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.13781"
  },
  {
    "id": "arXiv:2111.14080",
    "title": "Empirical Conditional Mean: A New Method of Predicting Throughput in  Uplink Data Network",
    "abstract": "Comments: 5 pages, 7 figures",
    "descriptor": "\nComments: 5 pages, 7 figures\n",
    "authors": [
      "Weijia Zheng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2111.14080"
  },
  {
    "id": "arXiv:2111.14382",
    "title": "VPFNet: Improving 3D Object Detection with Virtual Point based LiDAR and  Stereo Data Fusion",
    "abstract": "VPFNet: Improving 3D Object Detection with Virtual Point based LiDAR and  Stereo Data Fusion",
    "descriptor": "",
    "authors": [
      "Hanqi Zhu",
      "Jiajun Deng",
      "Yu Zhang",
      "Jianmin Ji",
      "Qiuyu Mao",
      "Houqiang Li",
      "Yanyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14382"
  },
  {
    "id": "arXiv:2111.14448",
    "title": "AVA-AVD: Audio-visual Speaker Diarization in the Wild",
    "abstract": "AVA-AVD: Audio-visual Speaker Diarization in the Wild",
    "descriptor": "",
    "authors": [
      "Eric Zhongcong Xu",
      "Zeyang Song",
      "Chao Feng",
      "Mang Ye",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.14448"
  },
  {
    "id": "arXiv:2111.14451",
    "title": "HDR-NeRF: High Dynamic Range Neural Radiance Fields",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Xin Huang",
      "Qi Zhang",
      "Ying Feng",
      "Hongdong Li",
      "Xuan Wang",
      "Qing Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14451"
  },
  {
    "id": "arXiv:2111.14592",
    "title": "GALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with  Semi-Supervised Learning and Explicit Policy Injection",
    "abstract": "Comments: 7 pages, 5 figures",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Wanwei He",
      "Yinpei Dai",
      "Yinhe Zheng",
      "Yuchuan Wu",
      "Zheng Cao",
      "Dermot Liu",
      "Peng Jiang",
      "Min Yang",
      "Fei Huang",
      "Luo Si",
      "Jian Sun",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.14592"
  },
  {
    "id": "arXiv:2111.14831",
    "title": "MIST-net: Multi-domain Integrative Swin Transformer network for  Sparse-View CT Reconstruction",
    "abstract": "Comments: 24 pages, 10 figures, 57 references",
    "descriptor": "\nComments: 24 pages, 10 figures, 57 references\n",
    "authors": [
      "Jiayi Pan",
      "Weiwen Wu",
      "Zhifan Gao",
      "Heye Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.14831"
  },
  {
    "id": "arXiv:2111.14955",
    "title": "Privacy-Preserving Serverless Edge Learning with Decentralized Small  Data",
    "abstract": "Comments: Submitted for publication in the IEEE Network",
    "descriptor": "\nComments: Submitted for publication in the IEEE Network\n",
    "authors": [
      "Shih-Chun Lin",
      "Chia-Hung Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.14955"
  },
  {
    "id": "arXiv:2111.14973",
    "title": "MultiPath++: Efficient Information Fusion and Trajectory Aggregation for  Behavior Prediction",
    "abstract": "MultiPath++: Efficient Information Fusion and Trajectory Aggregation for  Behavior Prediction",
    "descriptor": "",
    "authors": [
      "Balakrishnan Varadarajan",
      "Ahmed Hefny",
      "Avikalp Srivastava",
      "Khaled S. Refaat",
      "Nigamaa Nayakanti",
      "Andre Cornman",
      "Kan Chen",
      "Bertrand Douillard",
      "Chi Pang Lam",
      "Dragomir Anguelov",
      "Benjamin Sapp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.14973"
  },
  {
    "id": "arXiv:2111.15090",
    "title": "The Geometric Occam's Razor Implicit in Deep Learning",
    "abstract": "Comments: Accepted as a NeurIPS 2021 workshop paper (OPT2021)",
    "descriptor": "\nComments: Accepted as a NeurIPS 2021 workshop paper (OPT2021)\n",
    "authors": [
      "Benoit Dherin",
      "Michael Munn",
      "David G.T. Barrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.15090"
  },
  {
    "id": "arXiv:2111.15179",
    "title": "A Highly Effective Low-Rank Compression of Deep Neural Networks with  Modified Beam-Search and Modified Stable Rank",
    "abstract": "Comments: 8 pages, 8 figures, 2 tables",
    "descriptor": "\nComments: 8 pages, 8 figures, 2 tables\n",
    "authors": [
      "Moonjung Eo",
      "Suhyun Kang",
      "Wonjong Rhee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15179"
  },
  {
    "id": "arXiv:2111.15246",
    "title": "Hallucinated Neural Radiance Fields in the Wild",
    "abstract": "Hallucinated Neural Radiance Fields in the Wild",
    "descriptor": "",
    "authors": [
      "Xingyu Chen",
      "Qi Zhang",
      "Xiaoyu Li",
      "Yue Chen",
      "Ying Feng",
      "Xuan Wang",
      "Jue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15246"
  },
  {
    "id": "arXiv:2111.15288",
    "title": "Revisiting Temporal Alignment for Video Restoration",
    "abstract": "Comments: 15 pages. 17 figures, 10 tables/",
    "descriptor": "\nComments: 15 pages. 17 figures, 10 tables/\n",
    "authors": [
      "Kun Zhou",
      "Wenbo Li",
      "Liying Lu",
      "Xiaoguang Han",
      "Jiangbo Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15288"
  },
  {
    "id": "arXiv:2111.15365",
    "title": "Expert Aggregation for Financial Forecasting",
    "abstract": "Expert Aggregation for Financial Forecasting",
    "descriptor": "",
    "authors": [
      "Carl Remlinger",
      "Bri\u00e8re Marie",
      "Alasseur Cl\u00e9mence",
      "Joseph Mikael"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Portfolio Management (q-fin.PM)",
      "Risk Management (q-fin.RM)"
    ],
    "url": "https://arxiv.org/abs/2111.15365"
  },
  {
    "id": "arXiv:2111.15445",
    "title": "The Effect of Iterativity on Adversarial Opinion Forming",
    "abstract": "Comments: Title edited",
    "descriptor": "\nComments: Title edited\n",
    "authors": [
      "Konstantinos Panagiotou",
      "Simon Reisser"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.15445"
  },
  {
    "id": "arXiv:2111.15476",
    "title": "A Scheme of Channel Prediction Based on Artificial Neural Network",
    "abstract": "A Scheme of Channel Prediction Based on Artificial Neural Network",
    "descriptor": "",
    "authors": [
      "Zirui Wen",
      "Ruisi He",
      "Bo Ai",
      "Chen Huang",
      "Mi Yang",
      "Zhangdui Zhong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.15476"
  },
  {
    "id": "arXiv:2111.15588",
    "title": "Pureformer: Do We Even Need Attention?",
    "abstract": "Pureformer: Do We Even Need Attention?",
    "descriptor": "",
    "authors": [
      "Uladzislau Yorsh",
      "Pavel Kord\u00edk",
      "Alexander Kovalenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15588"
  },
  {
    "id": "arXiv:2111.15611",
    "title": "The Power of Communication in a Distributed Multi-Agent System",
    "abstract": "Comments: Cooperative AI Workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia",
    "descriptor": "\nComments: Cooperative AI Workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia\n",
    "authors": [
      "Philipp Dominic Siedler"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.15611"
  },
  {
    "id": "arXiv:2111.15626",
    "title": "Variational Autoencoders for Studying the Manifold of Precoding Matrices  with High Spectral Efficiency",
    "abstract": "Comments: 4 pages, 1 figure",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Evgeny Bobrov",
      "Alexander Markov",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.15626"
  },
  {
    "id": "arXiv:2111.15640",
    "title": "Diffusion Autoencoders: Toward a Meaningful and Decodable Representation",
    "abstract": "Comments: Please visit our project page: this https URL",
    "descriptor": "\nComments: Please visit our project page: this https URL\n",
    "authors": [
      "Konpat Preechakul",
      "Nattanat Chatthee",
      "Suttisak Wizadwongsa",
      "Supasorn Suwajanakorn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15640"
  },
  {
    "id": "arXiv:2111.15656",
    "title": "Attentive Prototypes for Source-free Unsupervised Domain Adaptive 3D  Object Detection",
    "abstract": "Attentive Prototypes for Source-free Unsupervised Domain Adaptive 3D  Object Detection",
    "descriptor": "",
    "authors": [
      "Deepti Hegde",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15656"
  }
]
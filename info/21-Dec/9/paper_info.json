[
  {
    "id": "arXiv:2112.03912",
    "title": "RID-Noise: Towards Robust Inverse Design under Noisy Environments",
    "abstract": "From an engineering perspective, a design should not only perform well in an\nideal condition, but should also resist noises. Such a design methodology,\nnamely robust design, has been widely implemented in the industry for product\nquality control. However, classic robust design requires a lot of evaluations\nfor a single design target, while the results of these evaluations could not be\nreused for a new target. To achieve a data-efficient robust design, we propose\nRobust Inverse Design under Noise (RID-Noise), which can utilize existing noisy\ndata to train a conditional invertible neural network (cINN). Specifically, we\nestimate the robustness of a design parameter by its predictability, measured\nby the prediction error of a forward neural network. We also define a\nsample-wise weight, which can be used in the maximum weighted likelihood\nestimation of an inverse model based on a cINN. With the visual results from\nexperiments, we clearly justify how RID-Noise works by learning the\ndistribution and robustness from data. Further experiments on several\nreal-world benchmark tasks with noises confirm that our method is more\neffective than other state-of-the-art inverse design methods. Code and\nsupplementary is publicly available at\nhttps://github.com/ThyrixYang/rid-noise-aaai22",
    "descriptor": "\nComments: AAAI'22\n",
    "authors": [
      "Jia-Qi Yang",
      "Ke-Bin Fan",
      "Hao Ma",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03912"
  },
  {
    "id": "arXiv:2112.03914",
    "title": "Synthetic Acute Hypotension and Sepsis Datasets Based on MIMIC-III and  Published as Part of the Health Gym Project",
    "abstract": "These two synthetic datasets comprise vital signs, laboratory test results,\nadministered fluid boluses and vasopressors for 3,910 patients with acute\nhypotension and for 2,164 patients with sepsis in the Intensive Care Unit\n(ICU). The patient cohorts were built using previously published inclusion and\nexclusion criteria and the data were created using Generative Adversarial\nNetworks (GANs) and the MIMIC-III Clinical Database. The risk of identity\ndisclosure associated with the release of these data was estimated to be very\nlow (0.045%). The datasets were generated and published as part of the Health\nGym, a project aiming to publicly distribute synthetic longitudinal health data\nfor developing machine learning algorithms (with a particular focus on offline\nreinforcement learning) and for educational purposes.",
    "descriptor": "",
    "authors": [
      "Nicholas I-Hsien Kuo",
      "Mark Polizzotto",
      "Simon Finfer",
      "Louisa Jorm",
      "Sebastiano Barbieri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03914"
  },
  {
    "id": "arXiv:2112.03917",
    "title": "Scalable 3D Semantic Segmentation for Gun Detection in CT Scans",
    "abstract": "With the increased availability of 3D data, the need for solutions processing\nthose also increased rapidly. However, adding dimension to already reliably\naccurate 2D approaches leads to immense memory consumption and higher\ncomputational complexity. These issues cause current hardware to reach its\nlimitations, with most methods forced to reduce the input resolution\ndrastically. Our main contribution is a novel deep 3D semantic segmentation\nmethod for gun detection in baggage CT scans that enables fast training and low\nvideo memory consumption for high-resolution voxelized volumes. We introduce a\nmoving pyramid approach that utilizes multiple forward passes at inference time\nfor segmenting an instance.",
    "descriptor": "\nComments: This work was part of the Project Lab Deep Learning in Computer Vision Winter Semester 2019/2020 at TU Darmstadt\n",
    "authors": [
      "Marius Memmel",
      "Christoph Reich",
      "Nicolas Wagner",
      "Faraz Saeedan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.03917"
  },
  {
    "id": "arXiv:2112.03942",
    "title": "Computing spectral properties of topological insulators without  artificial truncation or supercell approximation",
    "abstract": "Topological insulators (TIs) are renowned for their remarkable electronic\nproperties: quantised bulk Hall and edge conductivities, and robust edge\nwave-packet propagation, even in the presence of material defects and disorder.\nComputations of these physical properties generally rely on artificial\nperiodicity (the supercell approximation), or unphysical boundary conditions\n(artificial truncation). In this work, we build on recently developed methods\nfor computing spectral properties of infinite-dimensional operators. We apply\nthese techniques to develop efficient and accurate computational tools for\ncomputing the physical properties of TIs. These tools completely avoid such\nartificial restrictions and allow one to probe the spectral properties of the\ninfinite-dimensional operator directly, even in the presence of material\ndefects and disorder. Our methods permit computation of spectra, approximate\neigenstates, spectral measures, spectral projections, transport properties, and\nconductances. Numerical examples are given for the Haldane model, and the\ntechniques can be extended similarly to other TIs in two and three dimensions.",
    "descriptor": "",
    "authors": [
      "Matthew J. Colbrook",
      "Andrew Horning",
      "Kyle Thicke",
      "Alexander B. Watson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Mathematical Physics (math-ph)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.03942"
  },
  {
    "id": "arXiv:2112.03951",
    "title": "Few-Shot Image Classification Along Sparse Graphs",
    "abstract": "Few-shot learning remains a challenging problem, with unsatisfactory 1-shot\naccuracies for most real-world data. Here, we present a different perspective\nfor data distributions in the feature space of a deep network and show how to\nexploit it for few-shot learning. First, we observe that nearest neighbors in\nthe feature space are with high probability members of the same class while\ngenerally two random points from one class are not much closer to each other\nthan points from different classes. This observation suggests that classes in\nfeature space form sparse, loosely connected graphs instead of dense clusters.\nTo exploit this property, we propose using a small amount of label propagation\ninto the unlabeled space and then using a kernel PCA reconstruction error as\ndecision boundary for the feature-space data distribution of each class. Using\nthis method, which we call \"K-Prop,\" we demonstrate largely improved few-shot\nlearning performances (e.g., 83% accuracy for 1-shot 5-way classification on\nthe RESISC45 satellite-images dataset) for datasets for which a backbone\nnetwork can be trained with high within-class nearest-neighbor probabilities.\nWe demonstrate this relationship using six different datasets.",
    "descriptor": "",
    "authors": [
      "Joseph F Comer",
      "Philip L Jacobson",
      "Heiko Hoffmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03951"
  },
  {
    "id": "arXiv:2112.03968",
    "title": "Learning Theory Can (Sometimes) Explain Generalisation in Graph Neural  Networks",
    "abstract": "In recent years, several results in the supervised learning setting suggested\nthat classical statistical learning-theoretic measures, such as VC dimension,\ndo not adequately explain the performance of deep learning models which\nprompted a slew of work in the infinite-width and iteration regimes. However,\nthere is little theoretical explanation for the success of neural networks\nbeyond the supervised setting. In this paper we argue that, under some\ndistributional assumptions, classical learning-theoretic measures can\nsufficiently explain generalization for graph neural networks in the\ntransductive setting. In particular, we provide a rigorous analysis of the\nperformance of neural networks in the context of transductive inference,\nspecifically by analysing the generalisation properties of graph convolutional\nnetworks for the problem of node classification. While VC Dimension does result\nin trivial generalisation error bounds in this setting as well, we show that\ntransductive Rademacher complexity can explain the generalisation properties of\ngraph convolutional networks for stochastic block models. We further use the\ngeneralisation error bounds based on transductive Rademacher complexity to\ndemonstrate the role of graph convolutions and network architectures in\nachieving smaller generalisation error and provide insights into when the graph\nstructure can help in learning. The findings of this paper could re-new the\ninterest in studying generalisation in neural networks in terms of\nlearning-theoretic measures, albeit in specific problems.",
    "descriptor": "\nComments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Pascal Mattia Esser",
      "Leena Chennuru Vankadara",
      "Debarghya Ghoshdastidar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03968"
  },
  {
    "id": "arXiv:2112.03975",
    "title": "Tailored neural networks for learning optimal value functions in MPC",
    "abstract": "Learning-based predictive control is a promising alternative to\noptimization-based MPC. However, efficiently learning the optimal control\npolicy, the optimal value function, or the Q-function requires suitable\nfunction approximators. Often, artificial neural networks (ANN) are considered\nbut choosing a suitable topology is also non-trivial. Against this background,\nit has recently been shown that tailored ANN allow, in principle, to exactly\ndescribe the optimal control policy in linear MPC by exploiting its piecewise\naffine structure. In this paper, we provide a similar result for representing\nthe optimal value function and the Q-function that are both known to be\npiecewise quadratic for linear MPC.",
    "descriptor": "\nComments: 7 pages, 2 figures, 1 table\n",
    "authors": [
      "Dieter Teichrib",
      "Moritz Schulze Darup"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03975"
  },
  {
    "id": "arXiv:2112.03980",
    "title": "Output-sensitive Computation of Generalized Persistence Diagrams for  2-filtrations",
    "abstract": "When persistence diagrams are formalized as the Mobius inversion of the\nbirth-death function, they naturally generalize to the multi-parameter setting\nand enjoy many of the key properties, such as stability, that we expect in\napplications. The direct definition in the 2-parameter setting, and the\ncorresponding brute-force algorithm to compute them, require $\\Omega(n^4)$\noperations. But the size of the generalized persistence diagram, $C$, can be as\nlow as linear (and as high as cubic). We elucidate a connection between the\n2-parameter and the ordinary 1-parameter settings, which allows us to design an\noutput-sensitive algorithm, whose running time is in $O(n^3 + Cn)$.",
    "descriptor": "",
    "authors": [
      "Dmitriy Morozov",
      "Amit Patel"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2112.03980"
  },
  {
    "id": "arXiv:2112.03983",
    "title": "Almost Polynomial Factor Inapproximability for Parameterized k-Clique",
    "abstract": "The k-Clique problem is a canonical hard problem in parameterized complexity.\nIn this paper, we study the parameterized complexity of approximating the\nk-Clique problem where an integer k and a graph G on n vertices are given as\ninput, and the goal is to find a clique of size at least k/F(k) whenever the\ngraph G has a clique of size k. When such an algorithm runs in time T(k)poly(n)\n(i.e., FPT-time) for some computable function T, it is said to be an\nF(k)-FPT-approximation algorithm for the k-Clique problem.\nAlthough, the non-existence of an F(k)-FPT-approximation algorithm for any\ncomputable sublinear function F is known under gap-ETH [Chalermsook et al.,\nFOCS 2017], it has remained a long standing open problem to prove the same\ninapproximability result under the more standard and weaker assumption,\nW[1]$\\neq$FPT.\nIn a recent breakthrough, Lin [STOC 2021] ruled out constant factor (i.e.,\nF(k)=O(1)) FPT-approximation algorithms under W[1]$\\neq$FPT. In this paper, we\nimprove this inapproximability result (under the same assumption) to rule out\nevery $F(k)=k^{1/H(k)}$ factor FPT-approximation algorithm for any increasing\ncomputable function H (for example $H(k)=\\log^\\ast k$).\nOur main technical contribution is introducing list decoding of Hadamard\ncodes over large prime fields into the proof framework of Lin.",
    "descriptor": "",
    "authors": [
      "Karthik C. S.",
      "Subhash Khot"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.03983"
  },
  {
    "id": "arXiv:2112.03984",
    "title": "Emotion-Cause Pair Extraction in Customer Reviews",
    "abstract": "Emotion-Cause Pair Extraction (ECPE) is a complex yet popular area in Natural\nLanguage Processing due to its importance and potential applications in various\ndomains. In this report , we aim to present our work in ECPE in the domain of\nonline reviews. With a manually annotated dataset, we explore an algorithm to\nextract emotion cause pairs using a neural network. In addition, we propose a\nmodel using previous reference materials and combining emotion-cause pair\nextraction with research in the domain of emotion-aware word embeddings, where\nwe send these embeddings into a Bi-LSTM layer which gives us the emotionally\nrelevant clauses. With the constraint of a limited dataset, we achieved . The\noverall scope of our report comprises of a comprehensive literature review,\nimplementation of referenced methods for dataset construction and initial model\ntraining, and modifying previous work in ECPE by proposing an improvement to\nthe pipeline, as well as algorithm development and implementation for the\nspecific domain of reviews.",
    "descriptor": "\nComments: 7 Pages, 8 Figures\n",
    "authors": [
      "Arpit Mittal",
      "Jeel Tejaskumar Vaishnav",
      "Aishwarya Kaliki",
      "Nathan Johns",
      "Wyatt Pease"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03984"
  },
  {
    "id": "arXiv:2112.03985",
    "title": "Accelerating jackknife resampling for the Canonical Polyadic  Decomposition",
    "abstract": "The Canonical Polyadic (CP) tensor decomposition is frequently used as a\nmodel in applications in a variety of different fields. Using jackknife\nresampling to estimate parameter uncertainties is often desirable but results\nin an increase of the already high computational cost. Upon observation that\nthe resampled tensors, though different, are nearly identical, we show that it\nis possible to extend the recently proposed Concurrent ALS (CALS) technique to\na jackknife resampling scenario. This extension gives access to the\ncomputational efficiency advantage of CALS for the price of a modest increase\n(typically a few percent) in the number of floating point operations. Numerical\nexperiments on both synthetic and real-world datasets demonstrate that the new\nworkflow based on a CALS extension can be several times faster than a\nstraightforward workflow where the jackknife submodels are processed\nindividually.",
    "descriptor": "",
    "authors": [
      "Christos Psarras",
      "Lars Karlsson",
      "Rasmus Bro",
      "Paolo Bientinesi"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.03985"
  },
  {
    "id": "arXiv:2112.03997",
    "title": "Designing a Real-Time IoT Data Streaming Testbed for Horizontally  Scalable Analytical Platforms: Czech Post Case Study",
    "abstract": "There is a growing trend for enterprise-level Internet of Things (IoT)\napplications requiring real-time horizontally scalable data processing\nplatforms. Real-time processing platforms receiving data streams from sensor\nnetworks (e.g., autonomous and connected vehicles, smart security for\nbusinesses and homes, smartwatches, fitness trackers, and other wearables)\nrequire distributed MQTT brokers. This case study presents an IoT data\nstreaming testbed platform prepared for the Czech Post. The presented platform\nhas met the throughput requirement of 2 million messages per 24 hours\n(comprising SMS and emails). The tested MQTT broker runs on a single virtual\nnode of a horizontally scalable testbed platform. Soon the Czech Post will\nmodernise its eServices to increase package deliveries aligned with eCommerce\nand eGovernment demands. The presented testbed platform fulfils all\nrequirements, and it is also capable of processing thousands of messages per\nsecond. The presented platform and concepts are transferable to healthcare\nsystems, transport operations, the automotive industry, and other domains such\nas smart cities.",
    "descriptor": "\nComments: 8 pages, 4 figures, 6 tables\n",
    "authors": [
      "Martin \u0160tufi",
      "Boris Ba\u010di\u0107"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.03997"
  },
  {
    "id": "arXiv:2112.04002",
    "title": "SHRIMP: Sparser Random Feature Models via Iterative Magnitude Pruning",
    "abstract": "Sparse shrunk additive models and sparse random feature models have been\ndeveloped separately as methods to learn low-order functions, where there are\nfew interactions between variables, but neither offers computational\nefficiency. On the other hand, $\\ell_2$-based shrunk additive models are\nefficient but do not offer feature selection as the resulting coefficient\nvectors are dense. Inspired by the success of the iterative magnitude pruning\ntechnique in finding lottery tickets of neural networks, we propose a new\nmethod -- Sparser Random Feature Models via IMP (ShRIMP) -- to efficiently fit\nhigh-dimensional data with inherent low-dimensional structure in the form of\nsparse variable dependencies. Our method can be viewed as a combined process to\nconstruct and find sparse lottery tickets for two-layer dense networks. We\nexplain the observed benefit of SHRIMP through a refined analysis on the\ngeneralization error for thresholded Basis Pursuit and resulting bounds on\neigenvalues.\nFrom function approximation experiments on both synthetic data and real-world\nbenchmark datasets, we show that SHRIMP obtains better than or competitive test\naccuracy compared to state-of-art sparse feature and additive methods such as\nSRFE-S, SSAM, and SALSA. Meanwhile, SHRIMP performs feature selection with low\ncomputational complexity and is robust to the pruning rate, indicating a\nrobustness in the structure of the obtained subnetworks. We gain insight into\nthe lottery ticket hypothesis through SHRIMP by noting a correspondence between\nour model and weight/neuron subnetworks.",
    "descriptor": "",
    "authors": [
      "Yuege Xie",
      "Bobby Shi",
      "Hayden Schaeffer",
      "Rachel Ward"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04002"
  },
  {
    "id": "arXiv:2112.04005",
    "title": "Data-aided Sensing where Communication and Sensing Meet: An Introduction",
    "abstract": "Since there are a number of Internet-of-Things (IoT) applications that need\nto collect data sets from a large number of sensors or devices in real-time,\nsensing and communication need to be integrated for efficient uploading from\ndevices. In this paper, we introduce the notion of data-aided sensing (DAS)\nwhere a base station (BS) utilizes a subset of data that is already uploaded\nand available to select the next device for efficient data collection or\nsensing. Thus, using DAS, certain tasks in IoT applications, including\nfederated learning, can be completed by uploading from a small number of\nselected devices. Two different types of DAS are considered: one is centralized\nDAS and the other is distributed DAS. In centralized DAS, the BS decides the\nuploading order, while each device can decide when to upload its own local data\nset among multiple uploading rounds in distributed DAS. In distributed DAS,\nrandom access is employed where the access probability of each device is\ndecided according to its local measurement for efficient uploading.",
    "descriptor": "\nComments: 6 pages, IEEE WCNC 2020\n",
    "authors": [
      "Jinho Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.04005"
  },
  {
    "id": "arXiv:2112.04006",
    "title": "Comparative Review of Malware Analysis Methodologies",
    "abstract": "To fight against the evolution of malware and its development, the specific\nmethodologies that are applied by the malware analysts are crucial. Yet, this\nis something often overlooked in the relevant bibliography or in the formal and\ninformal training of the relevant professionals. There are only two generic and\nall-encompassing structured methodologies for Malware Analysis (MA) - SAMA and\nMARE. The question is whether they are adequate and there is no need for\nanother one or whether there is no such need at all. This paper will try to\nanswer the above and it will contribute in the following ways: it will present,\ncompare and dissect those two malware analysis methodologies, it will present\ntheir capacity for analysing modern malware by applying them on a random modern\nspecimen and finally, it will conclude on whether there is a procedural\noptimization for malware analysis over the evolution of these two\nmethodologies.",
    "descriptor": "",
    "authors": [
      "Ioannis G. Kiachidis",
      "Dimitrios A. Baltatzis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.04006"
  },
  {
    "id": "arXiv:2112.04008",
    "title": "Multinational Address Parsing: A Zero-Shot Evaluation",
    "abstract": "Address parsing consists of identifying the segments that make up an address,\nsuch as a street name or a postal code. Because of its importance for tasks\nlike record linkage, address parsing has been approached with many techniques,\nthe latest relying on neural networks. While these models yield notable\nresults, previous work on neural networks has only focused on parsing addresses\nfrom a single source country. This paper explores the possibility of\ntransferring the address parsing knowledge acquired by training deep learning\nmodels on some countries' addresses to others with no further training in a\nzero-shot transfer learning setting. We also experiment using an attention\nmechanism and a domain adversarial training algorithm in the same zero-shot\ntransfer setting to improve performance. Both methods yield state-of-the-art\nperformance for most of the tested countries while giving good results to the\nremaining countries. We also explore the effect of incomplete addresses on our\nbest model, and we evaluate the impact of using incomplete addresses during\ntraining. In addition, we propose an open-source Python implementation of some\nof our trained models.",
    "descriptor": "\nComments: Accepted in the International Journal of Information Science and Technology (iJIST). arXiv admin note: text overlap with arXiv:2006.16152\n",
    "authors": [
      "Marouane Yassine",
      "David Beauchemin",
      "Fran\u00e7ois Laviolette",
      "Luc Lamontagne"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04008"
  },
  {
    "id": "arXiv:2112.04011",
    "title": "Auxiliary Learning for Self-Supervised Video Representation via  Similarity-based Knowledge Distillation",
    "abstract": "Despite the outstanding success of self-supervised pretraining methods for\nvideo representation learning, they generalise poorly when the unlabeled\ndataset for pretraining is small or the domain difference between unlabelled\ndata in source task (pretraining) and labeled data in target task (finetuning)\nis significant. To mitigate these issues, we propose a novel approach to\ncomplement self-supervised pretraining via an auxiliary pretraining phase,\nbased on knowledge similarity distillation, auxSKD, for better generalisation\nwith a significantly smaller amount of video data, e.g. Kinetics-100 rather\nthan Kinetics-400. Our method deploys a teacher network that iteratively\ndistils its knowledge to the student model by capturing the similarity\ninformation between segments of unlabelled video data. The student model then\nsolves a pretext task by exploiting this prior knowledge. We also introduce a\nnovel pretext task, Video Segment Pace Prediction or VSPP, which requires our\nmodel to predict the playback speed of a randomly selected segment of the input\nvideo to provide more reliable self-supervised representations. Our\nexperimental results show superior results to the state of the art on both\nUCF101 and HMDB51 datasets when pretraining on K100. Additionally, we show that\nour auxiliary pertaining, auxSKD, when added as an extra pretraining phase to\nrecent state of the art self-supervised methods (e.g. VideoPace and RSPNet),\nimproves their results on UCF101 and HMDB51. Our code will be released soon.",
    "descriptor": "",
    "authors": [
      "Amirhossein Dadashzadeh",
      "Alan Whone",
      "Majid Mirmehdi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04011"
  },
  {
    "id": "arXiv:2112.04014",
    "title": "Unsupervised Representation Learning via Neural Activation Coding",
    "abstract": "We present neural activation coding (NAC) as a novel approach for learning\ndeep representations from unlabeled data for downstream applications. We argue\nthat the deep encoder should maximize its nonlinear expressivity on the data\nfor downstream predictors to take full advantage of its representation power.\nTo this end, NAC maximizes the mutual information between activation patterns\nof the encoder and the data over a noisy communication channel. We show that\nlearning for a noise-robust activation code increases the number of distinct\nlinear regions of ReLU encoders, hence the maximum nonlinear expressivity. More\ninterestingly, NAC learns both continuous and discrete representations of data,\nwhich we respectively evaluate on two downstream tasks: (i) linear\nclassification on CIFAR-10 and ImageNet-1K and (ii) nearest neighbor retrieval\non CIFAR-10 and FLICKR-25K. Empirical results show that NAC attains better or\ncomparable performance on both tasks over recent baselines including SimCLR and\nDistillHash. In addition, NAC pretraining provides significant benefits to the\ntraining of deep generative models. Our code is available at\nhttps://github.com/yookoon/nac.",
    "descriptor": "\nComments: Published in International Conference on Machine Learning (ICML), 2021\n",
    "authors": [
      "Yookoon Park",
      "Sangho Lee",
      "Gunhee Kim",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04014"
  },
  {
    "id": "arXiv:2112.04016",
    "title": "DeepFace-EMD: Re-ranking Using Patch-wise Earth Mover's Distance  Improves Out-Of-Distribution Face Identification",
    "abstract": "Face identification (FI) is ubiquitous and drives many high-stake decisions\nmade by law enforcement. State-of-the-art FI approaches compare two images by\ntaking the cosine similarity between their image embeddings. Yet, such an\napproach suffers from poor out-of-distribution (OOD) generalization to new\ntypes of images (e.g., when a query face is masked, cropped, or rotated) not\nincluded in the training set or the gallery. Here, we propose a re-ranking\napproach that compares two faces using the Earth Mover's Distance on the deep,\nspatial features of image patches. Our extra comparison stage explicitly\nexamines image similarity at a fine-grained level (e.g., eyes to eyes) and is\nmore robust to OOD perturbations and occlusions than traditional FI.\nInterestingly, without finetuning feature extractors, our method consistently\nimproves the accuracy on all tested OOD queries: masked, cropped, rotated, and\nadversarial while obtaining similar results on in-distribution images.",
    "descriptor": "",
    "authors": [
      "Hai Phan",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04016"
  },
  {
    "id": "arXiv:2112.04017",
    "title": "fastball: A fast algorithm to sample binary matrices with fixed  marginals",
    "abstract": "Many applications require randomly sampling binary graphs with fixed degrees,\nor randomly sampling binary matrices with fixed row and column marginals.\nAlthough several algorithms to perform this sampling have been proposed, the\n``curveball'' algorithm is the fastest that has been proven to sample uniformly\nat random. In this paper, we introduce a more efficient version of curveball\ncalled ``fastball'' that is roughly 8 times faster.",
    "descriptor": "",
    "authors": [
      "Karl Godard",
      "Zachary P. Neal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.04017"
  },
  {
    "id": "arXiv:2112.04019",
    "title": "The b-symbol weight hierarchy of the Kasami codes",
    "abstract": "The symbol-pair read channel was first proposed by Cassuto and Blaum. Later,\nYaakobi et al. generalized it to the $b$-symbol read channel. It is motivated\nby the limitations of the reading process in high density data storage systems.\nOne main task in $b$-symbol coding theory is to determine the $b$-symbol weight\nhierarchy of codes. In this paper, we study the $b$-symbol weight hierarchy of\nthe Kasami codes, which are well known for their applications to construct\nsequences with optimal correlation magnitudes. The complete symbol-pair weight\ndistribution of the Kasami codes is determined.",
    "descriptor": "",
    "authors": [
      "Hongwei Zhu",
      "Minjia Shi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.04019"
  },
  {
    "id": "arXiv:2112.04021",
    "title": "A Robust Completed Local Binary Pattern (RCLBP) for Surface Defect  Detection",
    "abstract": "In this paper, we present a Robust Completed Local Binary Pattern (RCLBP)\nframework for a surface defect detection task. Our approach uses a combination\nof Non-Local (NL) means filter with wavelet thresholding and Completed Local\nBinary Pattern (CLBP) to extract robust features which are fed into classifiers\nfor surface defects detection. This paper combines three components: A\ndenoising technique based on Non-Local (NL) means filter with wavelet\nthresholding is established to denoise the noisy image while preserving the\ntextures and edges. Second, discriminative features are extracted using the\nCLBP technique. Finally, the discriminative features are fed into the\nclassifiers to build the detection model and evaluate the performance of the\nproposed framework. The performance of the defect detection models are\nevaluated using a real-world steel surface defect database from Northeastern\nUniversity (NEU). Experimental results demonstrate that the proposed approach\nRCLBP is noise robust and can be applied for surface defect detection under\nvarying conditions of intra-class and inter-class changes and with illumination\nchanges.",
    "descriptor": "\nComments: Accepted to IEEE SMC 2021 as a special invited session paper\n",
    "authors": [
      "Nana Kankam Gyimah",
      "Abenezer Girma",
      "Mahmoud Nabil Mahmoud",
      "Shamila Nateghi",
      "Abdollah Homaifar",
      "Daniel Opoku"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04021"
  },
  {
    "id": "arXiv:2112.04023",
    "title": "Accelerating Understanding of Scientific Experiments with End to End  Symbolic Regression",
    "abstract": "We consider the problem of learning free-form symbolic expressions from raw\ndata, such as that produced by an experiment in any scientific domain. Accurate\nand interpretable models of scientific phenomena are the cornerstone of\nscientific research. Simple yet interpretable models, such as linear or\nlogistic regression and decision trees often lack predictive accuracy.\nAlternatively, accurate blackbox models such as deep neural networks provide\nhigh predictive accuracy, but do not readily admit human understanding in a way\nthat would enrich the scientific theory of the phenomenon. Many great\nbreakthroughs in science revolve around the development of parsimonious\nequational models with high predictive accuracy, such as Newton's laws,\nuniversal gravitation, and Maxwell's equations. Previous work on automating the\nsearch of equational models from data combine domain-specific heuristics as\nwell as computationally expensive techniques, such as genetic programming and\nMonte-Carlo search. We develop a deep neural network (MACSYMA) to address the\nsymbolic regression problem as an end-to-end supervised learning problem.\nMACSYMA can generate symbolic expressions that describe a dataset. The\ncomputational complexity of the task is reduced to the feedforward computation\nof a neural network. We train our neural network on a synthetic dataset\nconsisting of data tables of varying length and varying levels of noise, for\nwhich the neural network must learn to produce the correct symbolic expression\ntoken by token. Finally, we validate our technique by running on a public\ndataset from behavioral science.",
    "descriptor": "",
    "authors": [
      "Nikos Arechiga",
      "Francine Chen",
      "Yan-Ying Chen",
      "Yanxia Zhang",
      "Rumen Iliev",
      "Heishiro Toyoda",
      "Kent Lyons"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04023"
  },
  {
    "id": "arXiv:2112.04030",
    "title": "The Origin and Value of Disagreement Among Data Labelers: A Case Study  of the Individual Difference in Hate Speech Annotation",
    "abstract": "Human annotated data is the cornerstone of today's artificial intelligence\nefforts, yet data labeling processes can be complicated and expensive,\nespecially when human labelers disagree with each other. The current work\npractice is to use majority-voted labels to overrule the disagreement. However,\nin the subjective data labeling tasks such as hate speech annotation,\ndisagreement among individual labelers can be difficult to resolve. In this\npaper, we explored why such disagreements occur using a mixed-method approach -\nincluding interviews with experts, concept mapping exercises, and\nself-reporting items - to develop a multidimensional scale for distilling the\nprocess of how annotators label a hate speech corpus. We tested this scale with\n170 annotators in a hate speech annotation task. Results showed that our scale\ncan reveal facets of individual differences among annotators (e.g., age,\npersonality, etc.), and these facets' relationships to an annotator's final\nlabel decision of an instance. We suggest that this work contributes to the\nunderstanding of how humans annotate data. The proposed scale can potentially\nimprove the value of the currently discarded minority-vote labels.",
    "descriptor": "",
    "authors": [
      "Yisi Sang",
      "Jeffrey Stanton"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.04030"
  },
  {
    "id": "arXiv:2112.04031",
    "title": "Estimating Quality of Transmission in a Live Production Network using  Machine Learning",
    "abstract": "We demonstrate QoT estimation in a live network utilizing neural networks\ntrained on synthetic data spanning a large parameter space. The ML-model\npredicts the measured lightpath performance with <0.5dB SNR error over a wide\nconfiguration range.",
    "descriptor": "\nComments: The work has been partially funded by the German Ministry of Education and Research in the project OptiCON (contract #16KIS0989K)\n",
    "authors": [
      "Jasper M\u00fcller",
      "Tobias Fehenberger",
      "Sai Kireet Patri",
      "Kaida Kaeval",
      "Helmut Griesser",
      "Marko Tikas",
      "J\u00f6rg-Peter Elbers"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.04031"
  },
  {
    "id": "arXiv:2112.04033",
    "title": "Image classifiers can not be made robust to small perturbations",
    "abstract": "The sensitivity of image classifiers to small perturbations in the input is\noften viewed as a defect of their construction. We demonstrate that this\nsensitivity is a fundamental property of classifiers. For any arbitrary\nclassifier over the set of $n$-by-$n$ images, we show that for all but one\nclass it is possible to change the classification of all but a tiny fraction of\nthe images in that class with a tiny modification compared to the diameter of\nthe image space when measured in any $p$-norm, including the hamming distance.\nWe then examine how this phenomenon manifests in human visual perception and\ndiscuss its implications for the design considerations of computer vision\nsystems.",
    "descriptor": "",
    "authors": [
      "Zheng Dai",
      "David K. Gifford"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04033"
  },
  {
    "id": "arXiv:2112.04035",
    "title": "Relating transformers to models and neural representations of the  hippocampal formation",
    "abstract": "Many deep neural network architectures loosely based on brain networks have\nrecently been shown to replicate neural firing patterns observed in the brain.\nOne of the most exciting and promising novel architectures, the Transformer\nneural network, was developed without the brain in mind. In this work, we show\nthat transformers, when equipped with recurrent position encodings, replicate\nthe precisely tuned spatial representations of the hippocampal formation; most\nnotably place and grid cells. Furthermore, we show that this result is no\nsurprise since it is closely related to current hippocampal models from\nneuroscience. We additionally show the transformer version offers dramatic\nperformance gains over the neuroscience version. This work continues to bind\ncomputations of artificial and brain networks, offers a novel understanding of\nthe hippocampal-cortical interaction, and suggests how wider cortical areas may\nperform complex tasks beyond current neuroscience models such as language\ncomprehension.",
    "descriptor": "",
    "authors": [
      "James C.R. Whittington",
      "Joseph Warren",
      "Timothy E.J. Behrens"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2112.04035"
  },
  {
    "id": "arXiv:2112.04036",
    "title": "DeepDiagnosis: Automatically Diagnosing Faults and Recommending  Actionable Fixes in Deep Learning Programs",
    "abstract": "Deep Neural Networks (DNNs) are used in a wide variety of applications.\nHowever, as in any software application, DNN-based apps are afflicted with\nbugs. Previous work observed that DNN bug fix patterns are different from\ntraditional bug fix patterns. Furthermore, those buggy models are non-trivial\nto diagnose and fix due to inexplicit errors with several options to fix them.\nTo support developers in locating and fixing bugs, we propose DeepDiagnosis, a\nnovel debugging approach that localizes the faults, reports error symptoms and\nsuggests fixes for DNN programs. In the first phase, our technique monitors a\ntraining model, periodically checking for eight types of error conditions.\nThen, in case of problems, it reports messages containing sufficient\ninformation to perform actionable repairs to the model. In the evaluation, we\nthoroughly examine 444 models -53 real-world from GitHub and Stack Overflow,\nand 391 curated by AUTOTRAINER. DeepDiagnosis provides superior accuracy when\ncompared to UMLUAT and DeepLocalize. Our technique is faster than AUTOTRAINER\nfor fault localization. The results show that our approach can support\nadditional types of models, while state-of-the-art was only able to handle\nclassification ones. Our technique was able to report bugs that do not manifest\nas numerical errors during training. Also, it can provide actionable insights\nfor fix whereas DeepLocalize can only report faults that lead to numerical\nerrors during training. DeepDiagnosis manifests the best capabilities of fault\ndetection, bug localization, and symptoms identification when compared to other\napproaches.",
    "descriptor": "\nComments: Accepted at ICSE 2022\n",
    "authors": [
      "Mohammad Wardat",
      "Breno Dantas Cruz",
      "Wei Le",
      "Hridesh Rajan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04036"
  },
  {
    "id": "arXiv:2112.04037",
    "title": "Evaluation of Static Vulnerability Detection Tools with Java  Cryptographic API Benchmarks",
    "abstract": "Several studies showed that misuses of cryptographic APIs are common in\nreal-world code (e.g., Apache projects and Android apps). There exist several\nopen-sourced and commercial security tools that automatically screen Java\nprograms to detect misuses. To compare their accuracy and security guarantees,\nwe develop two comprehensive benchmarks named CryptoAPI-Bench and\nApacheCryptoAPI-Bench. CryptoAPI-Bench consists of 181 unit test cases that\ncover basic cases, as well as complex cases, including interprocedural, field\nsensitive, multiple class test cases, and path sensitive data flow of misuse\ncases. The benchmark also includes correct cases for testing false-positive\nrates. The ApacheCryptoAPI-Bench consists of 121 cryptographic cases from 10\nApache projects. We evaluate four tools, namely, SpotBugs, CryptoGuard, CrySL,\nand Coverity using both benchmarks. We present their performance and\ncomparative analysis. The ApacheCryptoAPI-Bench also examines the scalability\nof the tools. Our benchmarks are useful for advancing state-of-the-art\nsolutions in the space of misuse detection.",
    "descriptor": "",
    "authors": [
      "Sharmin Afrose",
      "Ya Xiao",
      "Sazzadur Rahaman",
      "Barton P. Miller",
      "Danfeng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.04037"
  },
  {
    "id": "arXiv:2112.04038",
    "title": "Presentation Attack Detection Methods based on Gaze Tracking and Pupil  Dynamic: A Comprehensive Survey",
    "abstract": "Purpose of the research: In the biometric community, visible human\ncharacteristics are popular and viable for verification and identification on\nmobile devices. However, imposters are able to spoof such characteristics by\ncreating fake and artificial biometrics to fool the system. Visible biometric\nsystems have suffered a high-security risk of presentation attack. Methods: In\nthe meantime, challenge-based methods, in particular, gaze tracking and pupil\ndynamic appear to be more secure methods than others for contactless biometric\nsystems. We review the existing work that explores gaze tracking and pupil\ndynamic liveness detection. The principal results: This research analyzes\nvarious aspects of gaze tracking and pupil dynamic presentation attacks, such\nas state-of-the-art liveness detection algorithms, various kinds of artifacts,\nthe accessibility of public databases, and a summary of standardization in this\narea. In addition, we discuss future work and the open challenges to creating a\nsecure liveness detection based on challenge-based systems.",
    "descriptor": "",
    "authors": [
      "Jalil Nourmohammadi Khiarak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04038"
  },
  {
    "id": "arXiv:2112.04039",
    "title": "A QoT Estimation Method using EGN-assisted Machine Learning for Network  Planning Applications",
    "abstract": "An ML model based on precomputed per-channel SCI is proposed. Due to its\nsuperior accuracy over closed-form GN, an average SNR gain of 1.1 dB in an\nend-to-end link optimization and a 40% reduction in required lightpaths to meet\ntraffic requests in a network planning scenario are shown.",
    "descriptor": "\nComments: This work has been performed in the framework of the CELTIC-NEXT project AI-NET-PROTECT (Project ID C2019/3-4), and it is partly funded by the German Federal Ministry of Education and Research (FKZ16KIS1279K)\n",
    "authors": [
      "Jasper M\u00fcller",
      "Sai Kireet Patri",
      "Tobias Fehenberger",
      "Carmen Mas-Machuca",
      "Helmut Griesser",
      "J\u00f6rg-Peter Elbers"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.04039"
  },
  {
    "id": "arXiv:2112.04041",
    "title": "A Transferable Approach for Partitioning Machine Learning Models on  Multi-Chip-Modules",
    "abstract": "Multi-Chip-Modules (MCMs) reduce the design and fabrication cost of machine\nlearning (ML) accelerators while delivering performance and energy efficiency\non par with a monolithic large chip. However, ML compilers targeting MCMs need\nto solve complex optimization problems optimally and efficiently to achieve\nthis high performance. One such problem is the multi-chip partitioning problem\nwhere compilers determine the optimal partitioning and placement of operations\nin tensor computation graphs on chiplets in MCMs. Partitioning ML graphs for\nMCMs is particularly hard as the search space grows exponentially with the\nnumber of chiplets available and the number of nodes in the neural network.\nFurthermore, the constraints imposed by the underlying hardware produce a\nsearch space where valid solutions are extremely sparse. In this paper, we\npresent a strategy using a deep reinforcement learning (RL) framework to emit a\npossibly invalid candidate partition that is then corrected by a constraint\nsolver. Using the constraint solver ensures that RL encounters valid solutions\nin the sparse space frequently enough to converge with fewer samples as\ncompared to non-learned strategies. The architectural choices we make for the\npolicy network allow us to generalize across different ML graphs. Our\nevaluation of a production-scale model, BERT, on real hardware reveals that the\npartitioning generated using RL policy achieves 6.11% and 5.85% higher\nthroughput than random search and simulated annealing. In addition, fine-tuning\nthe pre-trained RL policy reduces the search time from 3 hours to only 9\nminutes, while achieving the same throughput as training RL policy from\nscratch.",
    "descriptor": "",
    "authors": [
      "Xinfeng Xie",
      "Prakash Prabhu",
      "Ulysse Beaugnon",
      "Phitchaya Mangpo Phothilimthana",
      "Sudip Roy",
      "Azalia Mirhoseini",
      "Eugene Brevdo",
      "James Laudon",
      "Yanqi Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.04041"
  },
  {
    "id": "arXiv:2112.04042",
    "title": "Vision-Cloud Data Fusion for ADAS: A Lane Change Prediction Case Study",
    "abstract": "With the rapid development of intelligent vehicles and Advanced\nDriver-Assistance Systems (ADAS), a new trend is that mixed levels of human\ndriver engagements will be involved in the transportation system. Therefore,\nnecessary visual guidance for drivers is vitally important under this situation\nto prevent potential risks. To advance the development of visual guidance\nsystems, we introduce a novel vision-cloud data fusion methodology, integrating\ncamera image and Digital Twin information from the cloud to help intelligent\nvehicles make better decisions. Target vehicle bounding box is drawn and\nmatched with the help of the object detector (running on the ego-vehicle) and\nposition information (received from the cloud). The best matching result, a\n79.2% accuracy under 0.7 intersection over union threshold, is obtained with\ndepth images served as an additional feature source. A case study on lane\nchange prediction is conducted to show the effectiveness of the proposed data\nfusion methodology. In the case study, a multi-layer perceptron algorithm is\nproposed with modified lane change prediction approaches. Human-in-the-loop\nsimulation results obtained from the Unity game engine reveal that the proposed\nmodel can improve highway driving performance significantly in terms of safety,\ncomfort, and environmental sustainability.",
    "descriptor": "\nComments: Published on IEEE Transactions on Intelligent Vehicles\n",
    "authors": [
      "Yongkang Liu",
      "Ziran Wang",
      "Kyungtae Han",
      "Zhenyu Shou",
      "Prashant Tiwari",
      "John H.L. Hansen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04042"
  },
  {
    "id": "arXiv:2112.04046",
    "title": "Asymptotic MIMO Channel Model for Diffusive MC with Fully-absorbing  Receivers",
    "abstract": "his letter introduces an analytical model that gives the asymptotic\ncumulative number of molecules absorbed by spherical receivers in a diffusive\nmultiple-input multiple-output (MIMO) molecular communication (MC) system with\npointwise transmitters. In the proposed model, the reciprocal effect among the\nfully absorbing (FA) receivers is described by using the concept of fictitious\npointwise negative source of molecules, the best position of which for each\nspherical receiver being defined by its absorption barycenter. We show that\nthere is an agreement between the proposed asymptotic model and the numerical\nsolution of the exact analytical model from the literature that describes the\ninteraction among the receivers, which is solved for a sufficient long time. We\nresort to numerical solution because for the exact model there is no analytical\nsolution apart for the case of one transmitter and two receivers. We\ndemonstrate that the barycenter tends to coincide with the center of the FA\nreceivers in the temporal asymptotic case.",
    "descriptor": "",
    "authors": [
      "Fardad Vakilipoor",
      "Marco Ferrari",
      "Maurizio Magarini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.04046"
  },
  {
    "id": "arXiv:2112.04054",
    "title": "GPCO: An Unsupervised Green Point Cloud Odometry Method",
    "abstract": "Visual odometry aims to track the incremental motion of an object using the\ninformation captured by visual sensors. In this work, we study the point cloud\nodometry problem, where only the point cloud scans obtained by the LiDAR (Light\nDetection And Ranging) are used to estimate object's motion trajectory. A\nlightweight point cloud odometry solution is proposed and named the green point\ncloud odometry (GPCO) method. GPCO is an unsupervised learning method that\npredicts object motion by matching features of consecutive point cloud scans.\nIt consists of three steps. First, a geometry-aware point sampling scheme is\nused to select discriminant points from the large point cloud. Second, the view\nis partitioned into four regions surrounding the object, and the PointHop++\nmethod is used to extract point features. Third, point correspondences are\nestablished to estimate object motion between two consecutive scans.\nExperiments on the KITTI dataset are conducted to demonstrate the effectiveness\nof the GPCO method. It is observed that GPCO outperforms benchmarking deep\nlearning methods in accuracy while it has a significantly smaller model size\nand less training time.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Pranav Kadam",
      "Min Zhang",
      "Shan Liu",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04054"
  },
  {
    "id": "arXiv:2112.04062",
    "title": "Data-driven forward-inverse problems and modulational instability for  Yajima-Oikawa system using deep learning with parameter regularization",
    "abstract": "We investigate data-driven forward-inverse problems for Yajima-Oikawa system\nby employing two technologies which improve the performance of PINN in deep\nphysics-informed neural network (PINN), namely neuron-wise locally adaptive\nactivation functions and L2 norm parameter regularization. In particular, we\nnot only recover three different forms of vector rogue waves (RWs) in the\nforward problem of Yajima-Oikawa (YO) system, including bright-bright RWs,\nintermediatebright RWs and dark-bright RWs, but also study the inverse problem\nof YO system by data-driven with noise of different intensity. Compared with\nPINN method using only locally adaptive activation function, the PINN method\nwith two strategies shows amazing robustness when studying the inverse problem\nof YO system with noisy training data, that is, the improved PINN model\nproposed by us has excellent noise immunity. The asymptotic analysis of\nwavenumber k and the MI analysis for YO system with unknown parameters are\nderived systematically by applying the linearized instability analysis on plane\nwave.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2109.09266\n",
    "authors": [
      "Juncai Pu",
      "Yong Chen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Exactly Solvable and Integrable Systems (nlin.SI)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.04062"
  },
  {
    "id": "arXiv:2112.04063",
    "title": "Active Bayesian Multi-class Mapping from Range and Semantic Segmentation  Observations",
    "abstract": "The demand for robot exploration in unstructured and unknown environments has\nrecently grown substantially thanks to the host of inexpensive sensing and\nedge-computing solutions. In order to come closer to full autonomy, robots need\nto process the measurement stream in real-time, which calls for efficient\nexploration strategies. Information-based exploration techniques, such as\nCauchy-Schwarz quadratic mutual information (CSQMI) and fast Shannon mutual\ninformation (FSMI), have successfully achieved active binary occupancy mapping\nwith range measurements. However, as we envision robots performing complex\ntasks specified with semantically meaningful objects, it is necessary to\ncapture semantic categories in the measurements, map representation, and\nexploration objective. In this work we propose a Bayesian multi-class mapping\nalgorithm utilizing range-category measurements, as well as a closed-form\nefficiently computable lower bound for the Shannon mutual information between\nthe multi-class map and the measurements. The bound allows rapid evaluation of\nmany potential robot trajectories for autonomous exploration and mapping.\nFurthermore, we develop a compressed representation of 3-D environments with\nsemantic labels based on OcTree data structure, where each voxel maintains a\ncategorical distribution over object classes. The proposed 3-D representation\nfacilitates fast computation of Shannon mutual information between the semantic\nOctomap and the measurements using Run-Length Encoding (RLE) of range-category\nobservation rays. We compare our method against frontier-based and FSMI\nexploration and apply it in a variety of simulated and real-world experiments.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2101.01831\n",
    "authors": [
      "Arash Asgharivaskasi",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.04063"
  },
  {
    "id": "arXiv:2112.04068",
    "title": "Nanogrid Power Management Based on Fuzzy Logic Controller",
    "abstract": "The transport industry is undergoing unprecedented technological change. In\nthe automotive sector, the voices of progress are, among other things, linked\nto the partial or total electrification of vehicles. Thanks to bi-directional\ncharging technology, electric vehicles (EV) could significantly improve their\nhomeowners' energy balance. For islanded household buildings where a\nsupplementary turbine generator and photovoltaic (PV) generator are the main\nsupplies, it is crucial to minimize the running costs and maximize the use of\nthe PV power. In this paper, a supervisory controller based on fuzzy logic is\nproposed to utilize the battery in the EV, while parking, as an interactive\nelement to replace the auxiliary turbine and to assure that the battery power\nand energy do not exceed their design limits and maintaining a stable power\nflow. The nanogrid considered in this paper consists of a PV, EV battery, load\nand a turbine supplementary unit. The fuzzy logic controller alters the AC bus\nfrequency, which is used by the local controllers of the parallel units to\ncurtail the power generated by the PV or to supplement the power from the\nturbine unit. The proposed FLC performance is verified by Matlab simulation.",
    "descriptor": "",
    "authors": [
      "Walid Issa",
      "Rashid Albadwawi",
      "Tedjani Mesbahi",
      "Mohammad Abusara"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04068"
  },
  {
    "id": "arXiv:2112.04070",
    "title": "CoMP Enhanced Subcarrier and Power Allocation for Multi-Numerology based  5G-NR Networks",
    "abstract": "With proliferation of fifth generation (5G) new radio (NR) technology, it is\nexpected to meet the requirement of diverse traffic demands. We have designed a\ncoordinated multi-point (CoMP) enhanced flexible multi-numerology (MN) for\n5G-NR networks to improve the network performance in terms of throughput and\nlatency. We have proposed a CoMP enhanced joint subcarrier and power allocation\n(CESP) scheme which aims at maximizing sum rate under the considerations of\ntransmit power limitation and guaranteed quality-of-service (QoS) including\nthroughput and latency restrictions. By employing difference of two concave\nfunctions (D.C.) approximation and abstract Lagrangian duality method, we\ntheoretically transform the original non-convex nonlinear problem into a\nsolvable maximization problem. Moreover, the convergence of our proposed CESP\nalgorithm with D.C. approximation is analytically derived with proofs, and is\nfurther validated via numerical results. Simulation results demonstrated that\nour proposed CESP algorithm outperforms the conventional non-CoMP and single\nnumerology mechanisms along with other existing benchmarks in terms of lower\nlatency and higher throughput under the scenarios of uniform and edge users.",
    "descriptor": "",
    "authors": [
      "Li-Hsiang Shen",
      "Chia-Yu Su",
      "Kai-Ten Feng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.04070"
  },
  {
    "id": "arXiv:2112.04071",
    "title": "Learning to Localize, Grasp, and Hand Over Unmodified Surgical Needles",
    "abstract": "Robotic Surgical Assistants (RSAs) are commonly used to perform minimally\ninvasive surgeries by expert surgeons. However, long procedures filled with\ntedious and repetitive tasks such as suturing can lead to surgeon fatigue,\nmotivating the automation of suturing. As visual tracking of a thin reflective\nneedle is extremely challenging, prior work has modified the needle with\nnonreflective contrasting paint. As a step towards automation of a suturing\nsubtask without modifying the needle, we propose HOUSTON: Handoff of\nUnmodified, Surgical, Tool-Obstructed Needles, a problem and algorithm that\nuses a learned active sensing policy with a stereo camera to localize and align\nthe needle into a visible and accessible pose for the other arm. To compensate\nfor robot positioning and needle perception errors, the algorithm then executes\na high-precision grasping motion that uses multiple cameras. In physical\nexperiments using the da Vinci Research Kit (dVRK), HOUSTON successfully passes\nunmodified surgical needles with a success rate of 96.7% and is able to perform\nhandover sequentially between the arms 32.4 times on average before failure. On\nneedles unseen in training, HOUSTON achieves a success rate of 75 - 92.9%. To\nour knowledge, this work is the first to study handover of unmodified surgical\nneedles. See https://tinyurl.com/houston-surgery for additional materials.",
    "descriptor": "\nComments: 8 pages, 7 figures. First two authors contributed equally\n",
    "authors": [
      "Albert Wilcox",
      "Justin Kerr",
      "Brijen Thananjeyan",
      "Jeffrey Ichnowski",
      "Minho Hwang",
      "Samuel Paradis",
      "Danyal Fer",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.04071"
  },
  {
    "id": "arXiv:2112.04075",
    "title": "Active Sensing for Communications by Learning",
    "abstract": "This paper proposes a deep learning approach to a class of active sensing\nproblems in wireless communications in which an agent sequentially interacts\nwith an environment over a predetermined number of time frames to gather\ninformation in order to perform a sensing or actuation task for maximizing some\nutility function. In such an active learning setting, the agent needs to design\nan adaptive sensing strategy sequentially based on the observations made so\nfar. To tackle such a challenging problem in which the dimension of historical\nobservations increases over time, we propose to use a long short-term memory\n(LSTM) network to exploit the temporal correlations in the sequence of\nobservations and to map each observation to a fixed-size state information\nvector. We then use a deep neural network (DNN) to map the LSTM state at each\ntime frame to the design of the next measurement step. Finally, we employ\nanother DNN to map the final LSTM state to the desired solution. We investigate\nthe performance of the proposed framework for adaptive channel sensing problems\nin wireless communications. In particular, we consider the adaptive beamforming\nproblem for mmWave beam alignment and the adaptive reconfigurable intelligent\nsurface sensing problem for reflection alignment. Numerical results demonstrate\nthat the proposed deep active sensing strategy outperforms the existing\nadaptive or nonadaptive sensing schemes.",
    "descriptor": "\nComments: 14 Pages, 9 Figures\n",
    "authors": [
      "Foad Sohrabi",
      "Tao Jiang",
      "Wei Cui",
      "Wei Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04075"
  },
  {
    "id": "arXiv:2112.04079",
    "title": "Flexible Functional Split for Processing Sharing and CoMP-Enhanced Mixed  eMBB/URLLC Services in Beyond 5G Wireless Networks",
    "abstract": "With explosively escalating service demands, beyond fifth generation (B5G)\naims to realize various requirements for multi-service networks, i.e., mixed\nenhanced mobile broadband (eMBB) and ultra-reliable low-latency communication\n(URLLC) services. To flexibly serve diverse traffic, various functional split\noptions (FSOs) are specified by B5G protocols enabling different network\nfunctions. In order to improve signal qualities for edge users, we consider\nFSO-based coordinated multi-point (CoMP) transmission as a prominent technique\ncapable of supporting high traffic demands. However, due to conventional\nconfined hardware processing capability, a processing sharing (PS) model is\nintroduced to deal with high latency for multi-service FSO-based networks.\nTherefore, it becomes essential to assign CoMP-enhanced functional split modes\nunder PS model. A more tractable FSO-based network in terms of ergodic rate and\nreliability is derived by stochastic geometry approach. Moreover, we have\nproposed CoMP-enhanced functional split mode allocation (CFSMA) scheme to\nadaptively assign FSOs to provide enhanced mixed URLLC-eMBB services. The\nsimulation results have validated analytical derivation and demonstrated that\nthe proposed CFSMA scheme optimizes system spectrum efficiency while\nguaranteeing stringent latency requirement.",
    "descriptor": "",
    "authors": [
      "Li-Hsiang Shen",
      "Yung-Ting Huang",
      "Kai-Ten Feng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.04079"
  },
  {
    "id": "arXiv:2112.04080",
    "title": "Broadening the convergence domain of Seventh-order method satisfying  Lipschitz and H\u00f6lder conditions",
    "abstract": "In this paper, the local convergence analysis of the multi-step seventh order\nmethod is presented for solving nonlinear equations assuming that the\nfirst-order Fr\\'echet derivative belongs to the Lipschitz class. The\nsignificance of our work is that it avoids the standard practice of Taylor\nexpansion thereby, extends the applicability of the scheme by applying the\ntechnique based on the first-order derivative only. Also, this study provides\nradii of balls of convergence, the error bounds in terms of distances in\naddition to the uniqueness of the solution. Furthermore, generalization of this\nanalysis satisfying H\\\"{o}lder continuity condition is provided since it is\nmore relaxed than Lipschitz continuity condition. We have considered some\nnumerical examples and computed the radii of the convergence balls.",
    "descriptor": "",
    "authors": [
      "Akanksha Saxena",
      "J. P. Jaiswal",
      "K. R. Pardasani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.04080"
  },
  {
    "id": "arXiv:2112.04083",
    "title": "Best Arm Identification under Additive Transfer Bandits",
    "abstract": "We consider a variant of the best arm identification (BAI) problem in\nmulti-armed bandits (MAB) in which there are two sets of arms (source and\ntarget), and the objective is to determine the best target arm while only\npulling source arms. In this paper, we study the setting when, despite the\nmeans being unknown, there is a known additive relationship between the source\nand target MAB instances. We show how our framework covers a range of\npreviously studied pure exploration problems and additionally captures new\nproblems. We propose and theoretically analyze an LUCB-style algorithm to\nidentify an $\\epsilon$-optimal target arm with high probability. Our\ntheoretical analysis highlights aspects of this transfer learning problem that\ndo not arise in the typical BAI setup, and yet recover the LUCB algorithm for\nsingle domain BAI as a special case.",
    "descriptor": "",
    "authors": [
      "Ojash Neopane",
      "Aaditya Ramdas",
      "Aarti Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04083"
  },
  {
    "id": "arXiv:2112.04084",
    "title": "Hyper-parameter optimization based on soft actor critic and hierarchical  mixture regularization",
    "abstract": "Hyper-parameter optimization is a crucial problem in machine learning as it\naims to achieve the state-of-the-art performance in any model. Great efforts\nhave been made in this field, such as random search, grid search, Bayesian\noptimization. In this paper, we model hyper-parameter optimization process as a\nMarkov decision process, and tackle it with reinforcement learning. A novel\nhyper-parameter optimization method based on soft actor critic and hierarchical\nmixture regularization has been proposed. Experiments show that the proposed\nmethod can obtain better hyper-parameters in a shorter time.",
    "descriptor": "",
    "authors": [
      "Chaoyue Liu",
      "Yulai Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04084"
  },
  {
    "id": "arXiv:2112.04085",
    "title": "KoopmanizingFlows: Diffeomorphically Learning Stable Koopman Operators",
    "abstract": "We propose a novel framework for constructing linear time-invariant (LTI)\nmodels for data-driven representations of the Koopman operator for a class of\nstable nonlinear dynamics. The Koopman operator (generator) lifts a\nfinite-dimensional nonlinear system to a possibly infinite-dimensional linear\nfeature space. To utilize it for modeling, one needs to discover\nfinite-dimensional representations of the Koopman operator. Learning suitable\nfeatures is challenging, as one needs to learn LTI features that are both\nKoopman-invariant (evolve linearly under the dynamics) as well as relevant\n(spanning the original state) - a generally unsupervised learning task. For a\ntheoretically well-founded solution to this problem, we propose learning\nKoopman-invariant coordinates by composing a diffeomorphic learner with a\nlifted aggregate system of a latent linear model. Using an unconstrained\nparameterization of stable matrices along with the aforementioned feature\nconstruction, we learn the Koopman operator features without assuming a\npredefined library of functions or knowing the spectrum, while ensuring\nstability regardless of the operator approximation accuracy. We demonstrate the\nsuperior efficacy of the proposed method in comparison to a state-of-the-art\nmethod on the well-known LASA handwriting dataset.",
    "descriptor": "\nComments: Submitted to the 4th Annual Learning for Dynamics & Control Conference\n",
    "authors": [
      "Petar Bevanda",
      "Max Beier",
      "Sebastian Kerz",
      "Armin Lederer",
      "Stefan Sosnowski",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04085"
  },
  {
    "id": "arXiv:2112.04086",
    "title": "Supplementary Feedforward Voltage Control in a Reconfigurable  Distribution Network",
    "abstract": "Network reconfiguration (NR) has attracted much attention due to its ability\nto convert conventional distribution networks (DNs) into self-healing grids.\nThis paper proposes a new strategy for real-time voltage regulation (VR) in a\nreconfigurable DN, whereby optimal feedforward control of synchronous and\ninverter-based distributed generators (DGs) is achieved in coordination with\nthe operation of feeder line switches (SWs). This enables preemptive\ncompensation of upcoming deviations in DN voltages caused by NR-aided load\nrestoration. A robust optimization problem is formulated using a dynamic\nanalytical model of NR to design the feedforward voltage controllers (FVCs)\nthat minimize voltage deviations with respect to the H infinity norm. Errors in\nthe estimates of DG parameters and load demands are reflected in the design of\noptimal FVCs through polytopic uncertainty modeling, further improving the\nrobustness of the proposed VR strategy. Small-signal analysis and case studies\nare conducted, demonstrating the effectiveness of the optimal robust FVCs in\nimproving real-time VR when NR is activated for load restoration. The\nperformances of the proposed FVCs are also verified under various operating\nconditions of a reconfigurable DN, characterized principally by SW operations,\nnetwork parameter errors, and communication time delays.",
    "descriptor": "",
    "authors": [
      "Young-Jin Kim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04086"
  },
  {
    "id": "arXiv:2112.04087",
    "title": "Improving Knowledge Graph Representation Learning by Structure  Contextual Pre-training",
    "abstract": "Representation learning models for Knowledge Graphs (KG) have proven to be\neffective in encoding structural information and performing reasoning over KGs.\nIn this paper, we propose a novel pre-training-then-fine-tuning framework for\nknowledge graph representation learning, in which a KG model is firstly\npre-trained with triple classification task, followed by discriminative\nfine-tuning on specific downstream tasks such as entity type prediction and\nentity alignment. Drawing on the general ideas of learning deep contextualized\nword representations in typical pre-trained language models, we propose SCoP to\nlearn pre-trained KG representations with structural and contextual triples of\nthe target triple encoded. Experimental results demonstrate that fine-tuning\nSCoP not only outperforms results of baselines on a portfolio of downstream\ntasks but also avoids tedious task-specific model design and parameter\ntraining.",
    "descriptor": "\nComments: Accepted to IJCKG 2021\n",
    "authors": [
      "Ganqiang Ye",
      "Wen Zhang",
      "Zhen Bi",
      "Chi Man Wong",
      "Chen Hui",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04087"
  },
  {
    "id": "arXiv:2112.04088",
    "title": "SASG: Sparsification with Adaptive Stochastic Gradients for  Communication-efficient Distributed Learning",
    "abstract": "Stochastic optimization algorithms implemented on distributed computing\narchitectures are increasingly used to tackle large-scale machine learning\napplications. A key bottleneck in such distributed systems is the communication\noverhead for exchanging information such as stochastic gradients between\ndifferent workers. Sparse communication with memory and the adaptive\naggregation methodology are two successful frameworks among the various\ntechniques proposed to address this issue. In this paper, we creatively exploit\nthe advantages of Sparse communication and Adaptive aggregated Stochastic\nGradients to design a communication-efficient distributed algorithm named SASG.\nSpecifically, we first determine the workers that need to communicate based on\nthe adaptive aggregation rule and then sparse this transmitted information.\nTherefore, our algorithm reduces both the overhead of communication rounds and\nthe number of communication bits in the distributed system. We define an\nauxiliary sequence and give convergence results of the algorithm with the help\nof Lyapunov function analysis. Experiments on training deep neural networks\nshow that our algorithm can significantly reduce the number of communication\nrounds and bits compared to the previous methods, with little or no impact on\ntraining and testing accuracy.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Xiaoge Deng",
      "Tao Sun",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.04088"
  },
  {
    "id": "arXiv:2112.04090",
    "title": "Seed-driven Document Ranking for Systematic Reviews: A Reproducibility  Study",
    "abstract": "Screening or assessing studies is critical to the quality and outcomes of a\nsystematic review. Typically, a Boolean query retrieves the set of studies to\nscreen. As the set of studies retrieved is unordered, screening all retrieved\nstudies is usually required for high-quality systematic reviews. Screening\nprioritisation, or in other words, ranking the set of studies, enables\ndownstream activities of a systematic review to begin in parallel. We\ninvestigate a method that exploits seed studies -- potentially relevant studies\nused to seed the query formulation process -- for screening prioritisation. Our\ninvestigation aims to reproduce this method to determine if it is generalisable\non recently published datasets and determine the impact of using multiple seed\nstudies on effectiveness.We show that while we could reproduce the original\nmethods, we could not replicate their results exactly. However, we believe this\nis due to minor differences in document pre-processing, not deficiencies with\nthe original methodology. Our results also indicate that our reproduced\nscreening prioritisation method, (1) is generalisable across datasets of\nsimilar and different topicality compared to the original implementation, (2)\nthat when using multiple seed studies, the effectiveness of the method\nincreases using our techniques to enable this, (3) and that the use of multiple\nseed studies produces more stable rankings compared to single seed studies.\nFinally, we make our implementation and results publicly available at the\nfollowing URL: https://github.com/ielab/sdr",
    "descriptor": "\nComments: To be published in the 44th European Conference on Information Retrieval\n",
    "authors": [
      "Shuai Wang",
      "Harrisen Scells",
      "Ahmed Mourad",
      "Guido Zuccon"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.04090"
  },
  {
    "id": "arXiv:2112.04094",
    "title": "The Effect of Model Size on Worst-Group Generalization",
    "abstract": "Overparameterization is shown to result in poor test accuracy on rare\nsubgroups under a variety of settings where subgroup information is known. To\ngain a more complete picture, we consider the case where subgroup information\nis unknown. We investigate the effect of model size on worst-group\ngeneralization under empirical risk minimization (ERM) across a wide range of\nsettings, varying: 1) architectures (ResNet, VGG, or BERT), 2) domains (vision\nor natural language processing), 3) model size (width or depth), and 4)\ninitialization (with pre-trained or random weights). Our systematic evaluation\nreveals that increasing model size does not hurt, and may help, worst-group\ntest performance under ERM across all setups. In particular, increasing\npre-trained model size consistently improves performance on Waterbirds and\nMultiNLI. We advise practitioners to use larger pre-trained models when\nsubgroup labels are unknown.",
    "descriptor": "\nComments: The first four authors contributed equally to the work\n",
    "authors": [
      "Alan Pham",
      "Eunice Chan",
      "Vikranth Srivatsa",
      "Dhruba Ghosh",
      "Yaoqing Yang",
      "Yaodong Yu",
      "Ruiqi Zhong",
      "Joseph E. Gonzalez",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04094"
  },
  {
    "id": "arXiv:2112.04095",
    "title": "An Investigation of Drivers' Dynamic Situational Trust in Conditionally  Automated Driving",
    "abstract": "Understanding how trust is built over time is essential, as trust plays an\nimportant role in the acceptance and adoption of automated vehicles (AVs). This\nstudy aimed to investigate the effects of system performance and participants'\ntrust preconditions on dynamic situational trust during takeover transitions.\nWe evaluated the dynamic situational trust of 42 participants using both\nself-reported and behavioral measures while watching 30 videos with takeover\nscenarios. The study was a 3 by 2 mixed-subjects design, where the\nwithin-subjects variable was the system performance (i.e., accuracy levels of\n95\\%, 80\\%, and 70\\%) and the between-subjects variable was the preconditions\nof the participants' trust (i.e., overtrust and undertrust). Our results showed\nthat participants quickly adjusted their self-reported situational trust (SST)\nlevels which were consistent with different accuracy levels of system\nperformance in both trust preconditions. However, participants' behavioral\nsituational trust (BST) was affected by their trust preconditions across\ndifferent accuracy levels. For instance, the overtrust precondition\nsignificantly increased the agreement fraction compared to the undertrust\nprecondition. The undertrust precondition significantly decreased the switch\nfraction compared to the overtrust precondition. These results have important\nimplications for designing an in-vehicle trust calibration system for\nconditional AVs.",
    "descriptor": "",
    "authors": [
      "Jackie Ayoub",
      "Lilit Avetisyan",
      "Mustapha Makki",
      "Feng Zhou"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.04095"
  },
  {
    "id": "arXiv:2112.04096",
    "title": "Blocking Trails for $f$-factors of Multigraphs",
    "abstract": "Blocking flows, introduced by Dinic [2] for network flow, have been used to\nspeed up many augmenting-path type algorithms, especially matching algorithms\ne.g., [18, 23, 16]. We present an $O(m)$ time algorithm for blocking trails for\nf-factors of general multigraphs. This improves a previous algorithm by a\nfactor of $\\alpha(m,n)$. This speeds up a number of efficient algorithms for\nf-factors, e.g., the algorithm of [11] for maximum weight f-matching improves\nby the aforementioned $\\alpha(m,n)$ factor to running time $O( \\sqrt {\\Phi \\log\n\\Phi} m \\log (\\Phi W) )$ for $\\Phi =\\sum _{v\\in V} f(v)$, $W$ the maximum edge\nweight. This time bound is within a factor $\\sqrt {\\log \\Phi}$ of the bound for\nbipartite multigraphs. The technical difficulty for this work stems from the\nfact that previous algorithms for both matching and $f$-matching use vertex\ncontractions to form blossoms, but our dfs-based approach necessitates using\nedge contractions. As an example difficulty, edge contractions introduce a new\nform of blossoms we call \"skew blossoms\". These are configurations that must be\nreorganized in order to become valid blossoms.",
    "descriptor": "\nComments: 33 pages, 14 figures\n",
    "authors": [
      "Harold N. Gabow"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.04096"
  },
  {
    "id": "arXiv:2112.04100",
    "title": "Uncovering the Local Hidden Community Structure in Social Networks",
    "abstract": "Hidden community is a useful concept proposed recently for social network\nanalysis. To handle the rapid growth of network scale, in this work, we explore\nthe detection of hidden communities from the local perspective, and propose a\nnew method that detects and boosts each layer iteratively on a subgraph sampled\nfrom the original network. We first expand the seed set from a single seed node\nbased on our modified local spectral method and detect an initial dominant\nlocal community. Then we temporarily remove the members of this community as\nwell as their connections to other nodes, and detect all the neighborhood\ncommunities in the remaining subgraph, including some \"broken communities\" that\nonly contain a fraction of members in the original network. The local community\nand neighborhood communities form a dominant layer, and by reducing the edge\nweights inside these communities, we weaken this layer's structure to reveal\nthe hidden layers. Eventually, we repeat the whole process and all communities\ncontaining the seed node can be detected and boosted iteratively. We\ntheoretically show that our method can avoid some situations that a broken\ncommunity and the local community are regarded as one community in the\nsubgraph, leading to the inaccuracy on detection which can be caused by global\nhidden community detection methods. Extensive experiments show that our method\ncould significantly outperform the state-of-the-art baselines designed for\neither global hidden community detection or multiple local community detection.",
    "descriptor": "\nComments: 22 pages, 9 figures, submitted to a journal\n",
    "authors": [
      "Meng Wang",
      "Boyu Li",
      "Kun He",
      "John E. Hopcroft"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04100"
  },
  {
    "id": "arXiv:2112.04104",
    "title": "Learning to Select the Next Reasonable Mention for Entity Linking",
    "abstract": "Entity linking aims to establish a link between entity mentions in a document\nand the corresponding entities in knowledge graphs (KGs). Previous work has\nshown the effectiveness of global coherence for entity linking. However, most\nof the existing global linking methods based on sequential decisions focus on\nhow to utilize previously linked entities to enhance the later decisions. In\nthose methods, the order of mention is fixed, making the model unable to adjust\nthe subsequent linking targets according to the previously linked results,\nwhich will cause the previous information to be unreasonably utilized. To\naddress the problem, we propose a novel model, called DyMen, to dynamically\nadjust the subsequent linking target based on the previously linked entities\nvia reinforcement learning, enabling the model to select a link target that can\nfully use previously linked information. We sample mention by sliding window to\nreduce the action sampling space of reinforcement learning and maintain the\nsemantic coherence of mention. Experiments conducted on several benchmark\ndatasets have shown the effectiveness of the proposed model.",
    "descriptor": "\nComments: Accepted to AAAI-2022 Workshop on Knowledge Discovery from Unstructured Data in Financial Services\n",
    "authors": [
      "Jian Sun",
      "Yu Zhou",
      "Chengqing Zong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.04104"
  },
  {
    "id": "arXiv:2112.04107",
    "title": "Fully Context-Aware Image Inpainting with a Learned Semantic Pyramid",
    "abstract": "Restoring reasonable and realistic content for arbitrary missing regions in\nimages is an important yet challenging task. Although recent image inpainting\nmodels have made significant progress in generating vivid visual details, they\ncan still lead to texture blurring or structural distortions due to contextual\nambiguity when dealing with more complex scenes. To address this issue, we\npropose the Semantic Pyramid Network (SPN) motivated by the idea that learning\nmulti-scale semantic priors from specific pretext tasks can greatly benefit the\nrecovery of locally missing content in images. SPN consists of two components.\nFirst, it distills semantic priors from a pretext model into a multi-scale\nfeature pyramid, achieving a consistent understanding of the global context and\nlocal structures. Within the prior learner, we present an optional module for\nvariational inference to realize probabilistic image inpainting driven by\nvarious learned priors. The second component of SPN is a fully context-aware\nimage generator, which adaptively and progressively refines low-level visual\nrepresentations at multiple scales with the (stochastic) prior pyramid. We\ntrain the prior learner and the image generator as a unified model without any\npost-processing. Our approach achieves the state of the art on multiple\ndatasets, including Places2, Paris StreetView, CelebA, and CelebA-HQ, under\nboth deterministic and probabilistic inpainting setups.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Wendong Zhang",
      "Yunbo Wang",
      "Junwei Zhu",
      "Ying Tai",
      "Bingbing Ni",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04107"
  },
  {
    "id": "arXiv:2112.04108",
    "title": "Fully Attentional Network for Semantic Segmentation",
    "abstract": "Recent non-local self-attention methods have proven to be effective in\ncapturing long-range dependencies for semantic segmentation. These methods\nusually form a similarity map of RC*C (by compressing spatial dimensions) or\nRHW*HW (by compressing channels) to describe the feature relations along either\nchannel or spatial dimensions, where C is the number of channels, H and W are\nthe spatial dimensions of the input feature map. However, such practices tend\nto condense feature dependencies along the other dimensions,hence causing\nattention missing, which might lead to inferior results for small/thin\ncategories or inconsistent segmentation inside large objects. To address this\nproblem, we propose anew approach, namely Fully Attentional Network (FLANet),to\nencode both spatial and channel attentions in a single similarity map while\nmaintaining high computational efficiency. Specifically, for each channel map,\nour FLANet can harvest feature responses from all other channel maps, and the\nassociated spatial positions as well, through a novel fully attentional module.\nOur new method has achieved state-of-the-art performance on three challenging\nsemantic segmentation datasets,i.e., 83.6%, 46.99%, and 88.5% on the Cityscapes\ntest set,the ADE20K validation set, and the PASCAL VOC test set,respectively.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Qi Song",
      "Jie Li",
      "Chenghong Li",
      "Hao Guo",
      "Rui Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04108"
  },
  {
    "id": "arXiv:2112.04112",
    "title": "A Preamble Based MAC Mechanism in Ad-Hoc Network",
    "abstract": "In this paper, we propose a preamble based medium access control (P-MAC)\nmechanism in Ad-Hoc network. Different from traditional carrier sense multiple\naccess (CSMA) in Ad-Hoc network, P-MAC uses much shorter preamble to establish\nthe network. First, we propose the P-MAC mechanism to shorten the time of\nestablishing the Ad-Hoc network. Based on the P-MAC, we propose a more\nefficient way to maintain the network. Next, focusing on the power line\ncommunication (PLC) network which is a kind of Ad-Hoc network, we propose a\nfrequency division power line communication (FD-PLC) network architecture to\nobtain the best communication frequency. To obtain the best frequency, i.e.,\nhighest SNR, we design the frequency sweeping mechanism which can determine the\nfrequency of uplink and downlink communication before the transmitter and\nreceiver communicate. Due to the large-scale networks in industry, P-MAC can be\nexploited to speed up the establishment of the Ad-Hoc PLC network. Finally, we\ncompare our mechanism with CSMA. Numerical results indicate that our strategy\ngreatly shortens the time of establishing the Ad-Hoc network.",
    "descriptor": "\nComments: Accepted by IEEE JCIN\n",
    "authors": [
      "Chenchao Shi",
      "Biqian Feng",
      "Yongpeng Wu",
      "Wenjun Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.04112"
  },
  {
    "id": "arXiv:2112.04114",
    "title": "ESAFE: Enterprise Security and Forensics at Scale",
    "abstract": "Securing enterprise networks presents challenges in terms of both their size\nand distributed structure. Data required to detect and characterize malicious\nactivities may be diffused and may be located across network and endpoint\ndevices. Further, cyber-relevant data routinely exceeds total available\nstorage, bandwidth, and analysis capability, often by several orders of\nmagnitude. Real-time detection of threats within or across very large\nenterprise networks is not simply an issue of scale, but also a challenge due\nto the variable nature of malicious activities and their presentations. The\nsystem seeks to develop a hierarchy of cyber reasoning layers to detect\nmalicious behavior, characterize novel attack vectors and present an analyst\nwith a contextualized human-readable output from a series of machine learning\nmodels. We developed machine learning algorithms for scalable throughput and\nimproved recall for our Multi-Resolution Joint Optimization for Enterprise\nSecurity and Forensics (ESAFE) solution. This Paper will provide an overview of\nESAFE's Machine Learning Modules, Attack Ontologies, and Automated Smart Alert\ngeneration which provide multi-layer reasoning over cross-correlated sensors\nfor analyst consumption.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Bernard McShea",
      "Kevin Wright",
      "Denley Lam",
      "Steve Schmidt",
      "Anna Choromanska",
      "Devansh Bisla",
      "Shihong Fang",
      "Alireza Sarmadi",
      "Prashanth Krishnamurthy",
      "Farshad Khorrami"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.04114"
  },
  {
    "id": "arXiv:2112.04118",
    "title": "Convolutional codes with a maximum distance profile based on skew  polynomials",
    "abstract": "We construct a family of (n,k) convolutional codes with degree \\delta in\n{k,n-k} that have a maximum distance profile. The field size required for our\nconstruction is of the order n^{2\\delta}, which improves upon the known\nconstructions of convolutional codes with a maximum distance profile. Our\nconstruction is based on the theory of skew polynomials.",
    "descriptor": "",
    "authors": [
      "Zitan Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Complexity (cs.CC)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2112.04118"
  },
  {
    "id": "arXiv:2112.04120",
    "title": "Feature Statistics Mixing Regularization for Generative Adversarial  Networks",
    "abstract": "In generative adversarial networks, improving discriminators is one of the\nkey components for generation performance. As image classifiers are biased\ntoward texture and debiasing improves accuracy, we investigate 1) if the\ndiscriminators are biased, and 2) if debiasing the discriminators will improve\ngeneration performance. Indeed, we find empirical evidence that the\ndiscriminators are sensitive to the style (\\e.g., texture and color) of images.\nAs a remedy, we propose feature statistics mixing regularization (FSMR) that\nencourages the discriminator's prediction to be invariant to the styles of\ninput images. Specifically, we generate a mixed feature of an original and a\nreference image in the discriminator's feature space and we apply\nregularization so that the prediction for the mixed feature is consistent with\nthe prediction for the original image. We conduct extensive experiments to\ndemonstrate that our regularization leads to reduced sensitivity to style and\nconsistently improves the performance of various GAN architectures on nine\ndatasets. In addition, adding FSMR to recently-proposed augmentation-based GAN\nmethods further improves image quality. Code will be publicly available online\nfor the research community.",
    "descriptor": "",
    "authors": [
      "Junho Kim",
      "Yunjey Choi",
      "Youngjung Uh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04120"
  },
  {
    "id": "arXiv:2112.04123",
    "title": "ShinRL: A Library for Evaluating RL Algorithms from Theoretical and  Practical Perspectives",
    "abstract": "We present ShinRL, an open-source library specialized for the evaluation of\nreinforcement learning (RL) algorithms from both theoretical and practical\nperspectives. Existing RL libraries typically allow users to evaluate practical\nperformances of deep RL algorithms through returns. Nevertheless, these\nlibraries are not necessarily useful for analyzing if the algorithms perform as\ntheoretically expected, such as if Q learning really achieves the optimal Q\nfunction. In contrast, ShinRL provides an RL environment interface that can\ncompute metrics for delving into the behaviors of RL algorithms, such as the\ngap between learned and the optimal Q values and state visitation frequencies.\nIn addition, we introduce a flexible solver interface for evaluating both\ntheoretically justified algorithms (e.g., dynamic programming and tabular RL)\nand practically effective ones (i.e., deep RL, typically with some additional\nextensions and regularizations) in a consistent fashion. As a case study, we\nshow that how combining these two features of ShinRL makes it easier to analyze\nthe behavior of deep Q learning. Furthermore, we demonstrate that ShinRL can be\nused to empirically validate recent theoretical findings such as the effect of\nKL regularization for value iteration and for deep Q learning, and the\nrobustness of entropy-regularized policies to adversarial rewards. The source\ncode for ShinRL is available on GitHub: https://github.com/omron-sinicx/ShinRL.",
    "descriptor": "\nComments: Published at the NeurIPS Deep RL Workshop (2021)\n",
    "authors": [
      "Toshinori Kitamura",
      "Ryo Yonetani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04123"
  },
  {
    "id": "arXiv:2112.04126",
    "title": "FreeTalky: Don't Be Afraid! Conversations Made Easier by a Humanoid  Robot using Persona-based Dialogue",
    "abstract": "We propose a deep learning-based foreign language learning platform, named\nFreeTalky, for people who experience anxiety dealing with foreign languages, by\nemploying a humanoid robot NAO and various deep learning models. A\npersona-based dialogue system that is embedded in NAO provides an interesting\nand consistent multi-turn dialogue for users. Also, an grammar error correction\nsystem promotes improvement in grammar skills of the users. Thus, our system\nenables personalized learning based on persona dialogue and facilitates grammar\nlearning of a user using grammar error feedback. Furthermore, we verified\nwhether FreeTalky provides practical help in alleviating xenoglossophobia by\nreplacing the real human in the conversation with a NAO robot, through human\nevaluation.",
    "descriptor": "\nComments: Accepted for Artificial Intelligence for Education (AI4EDU) workshop at AAAI 2022\n",
    "authors": [
      "Chanjun Park",
      "Yoonna Jang",
      "Seolhwa Lee",
      "Sungjin Park",
      "Heuiseok Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.04126"
  },
  {
    "id": "arXiv:2112.04128",
    "title": "GIFdroid: Automated Replay of Visual Bug Reports for Android Apps",
    "abstract": "Bug reports are vital for software maintenance that allow users to inform\ndevelopers of the problems encountered while using software. However, it is\ndifficult for non-technical users to write clear descriptions about the bug\noccurrence. Therefore, more and more users begin to record the screen for\nreporting bugs as it is easy to be created and contains detailed procedures\ntriggering the bug. But it is still tedious and time-consuming for developers\nto reproduce the bug due to the length and unclear actions within the\nrecording. To overcome these issues, we propose GIFdroid, a light-weight\napproach to automatically replay the execution trace from visual bug reports.\nGIFdroid adopts image processing techniques to extract the keyframes from the\nrecording, map them to states in GUI Transitions Graph, and generate the\nexecution trace of those states to trigger the bug. Our automated experiments\nand user study demonstrate its accuracy, efficiency, and usefulness of the\napproach.",
    "descriptor": "",
    "authors": [
      "Sidong Feng",
      "Chunyang Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.04128"
  },
  {
    "id": "arXiv:2112.04136",
    "title": "SeaPlace: Process Variation Aware Placement for Reliable Combinational  Circuits against SETs and METs",
    "abstract": "Nowadays nanoscale combinational circuits are facing significant reliability\nchallenges including soft errors and process variations. This paper presents\nnovel process variation-aware placement strategies that include two algorithms\nto increase the reliability of combinational circuits against both Single Event\nTransients (SETs) and Multiple Event Transients (METs). The first proposed\nalgorithm is a global placement method (called SeaPlace-G) that places the\ncells for hardening the circuit against SETs by solving a quadratic\nformulation. Afterwards, a detailed placement algorithm (named SeaPlace-D) is\nproposed to increase the circuit reliability against METs by solving a linear\nprogramming optimization problem. Experimental results show that SeaPlace-G and\nSeaPlace-D averagely achieve 41.78% and 32.04% soft error reliability\nimprovement against SET and MET, respectively. Moreover, when SeaPlace-D is\nfollowed by SeaPlace-G, MET reduction can be improved by up to 53.3%.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Kiarash Saremi",
      "Hossein Pedram",
      "Behnam Ghavami",
      "Mohsen Raji",
      "Zhenman Fang",
      "Lesley Shannon"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.04136"
  },
  {
    "id": "arXiv:2112.04137",
    "title": "Pareto Domain Adaptation",
    "abstract": "Domain adaptation (DA) attempts to transfer the knowledge from a labeled\nsource domain to an unlabeled target domain that follows different distribution\nfrom the source. To achieve this, DA methods include a source classification\nobjective to extract the source knowledge and a domain alignment objective to\ndiminish the domain shift, ensuring knowledge transfer. Typically, former DA\nmethods adopt some weight hyper-parameters to linearly combine the training\nobjectives to form an overall objective. However, the gradient directions of\nthese objectives may conflict with each other due to domain shift. Under such\ncircumstances, the linear optimization scheme might decrease the overall\nobjective value at the expense of damaging one of the training objectives,\nleading to restricted solutions. In this paper, we rethink the optimization\nscheme for DA from a gradient-based perspective. We propose a Pareto Domain\nAdaptation (ParetoDA) approach to control the overall optimization direction,\naiming to cooperatively optimize all training objectives. Specifically, to\nreach a desirable solution on the target domain, we design a surrogate loss\nmimicking target classification. To improve target-prediction accuracy to\nsupport the mimicking, we propose a target-prediction refining mechanism which\nexploits domain labels via Bayes' theorem. On the other hand, since prior\nknowledge of weighting schemes for objectives is often unavailable to guide\noptimization to approach the optimal solution on the target domain, we propose\na dynamic preference mechanism to dynamically guide our cooperative\noptimization by the gradient of the surrogate loss on a held-out unlabeled\ntarget dataset. Extensive experiments on image classification and semantic\nsegmentation benchmarks demonstrate the effectiveness of ParetoDA",
    "descriptor": "\nComments: Accepted in NeurIPS 2021\n",
    "authors": [
      "Fangrui Lv",
      "Jian Liang",
      "Kaixiong Gong",
      "Shuang Li",
      "Chi Harold Liu",
      "Han Li",
      "Di Liu",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04137"
  },
  {
    "id": "arXiv:2112.04138",
    "title": "Contrastive Instruction-Trajectory Learning for Vision-Language  Navigation",
    "abstract": "The vision-language navigation (VLN) task requires an agent to reach a target\nwith the guidance of natural language instruction. Previous works learn to\nnavigate step-by-step following an instruction. However, these works may fail\nto discriminate the similarities and discrepancies across\ninstruction-trajectory pairs and ignore the temporal continuity of\nsub-instructions. These problems hinder agents from learning distinctive\nvision-and-language representations, harming the robustness and\ngeneralizability of the navigation policy. In this paper, we propose a\nContrastive Instruction-Trajectory Learning (CITL) framework that explores\ninvariance across similar data samples and variance across different ones to\nlearn distinctive representations for robust navigation. Specifically, we\npropose: (1) a coarse-grained contrastive learning objective to enhance\nvision-and-language representations by contrasting semantics of full trajectory\nobservations and instructions, respectively; (2) a fine-grained contrastive\nlearning objective to perceive instructions by leveraging the temporal\ninformation of the sub-instructions; (3) a pairwise sample-reweighting\nmechanism for contrastive learning to mine hard samples and hence mitigate the\ninfluence of data sampling bias in contrastive learning. Our CITL can be easily\nintegrated with VLN backbones to form a new learning paradigm and achieve\nbetter generalizability in unseen environments. Extensive experiments show that\nthe model with CITL surpasses the previous state-of-the-art methods on R2R,\nR4R, and RxR.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Xiwen Liang",
      "Fengda Zhu",
      "Yi Zhu",
      "Bingqian Lin",
      "Bing Wang",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04138"
  },
  {
    "id": "arXiv:2112.04139",
    "title": "Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand",
    "abstract": "Natural language processing researchers have identified limitations of\nevaluation methodology for generation tasks, with new questions raised about\nthe validity of automatic metrics and of crowdworker judgments. Meanwhile,\nefforts to improve generation models tend to focus on simple n-gram overlap\nmetrics (e.g., BLEU, ROUGE). We argue that new advances on models and metrics\nshould each more directly benefit and inform the other. We therefore propose a\ngeneralization of leaderboards, bidimensional leaderboards (Billboards), that\nsimultaneously tracks progress in language generation tasks and metrics for\ntheir evaluation. Unlike conventional unidimensional leaderboards that sort\nsubmitted systems by predetermined metrics, a Billboard accepts both generators\nand evaluation metrics as competing entries. A Billboard automatically creates\nan ensemble metric that selects and linearly combines a few metrics based on a\nglobal analysis across generators. Further, metrics are ranked based on their\ncorrelations with human judgments. We release four Billboards for machine\ntranslation, summarization, and image captioning. We demonstrate that a linear\nensemble of a few diverse metrics sometimes substantially outperforms existing\nmetrics in isolation. Our mixed-effects model analysis shows that most\nautomatic metrics, especially the reference-based ones, overrate machine over\nhuman generation, demonstrating the importance of updating metrics as\ngeneration models become stronger (and perhaps more similar to humans) in the\nfuture.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Jungo Kasai",
      "Keisuke Sakaguchi",
      "Ronan Le Bras",
      "Lavinia Dunagan",
      "Jacob Morrison",
      "Alexander R. Fabbri",
      "Yejin Choi",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.04139"
  },
  {
    "id": "arXiv:2112.04145",
    "title": "A Review for Deep Reinforcement Learning in Atari:Benchmarks,  Challenges, and Solutions",
    "abstract": "The Arcade Learning Environment (ALE) is proposed as an evaluation platform\nfor empirically assessing the generality of agents across dozens of Atari 2600\ngames. ALE offers various challenging problems and has drawn significant\nattention from the deep reinforcement learning (RL) community. From Deep\nQ-Networks (DQN) to Agent57, RL agents seem to achieve superhuman performance\nin ALE. However, is this the case? In this paper, to explore this problem, we\nfirst review the current evaluation metrics in the Atari benchmarks and then\nreveal that the current evaluation criteria of achieving superhuman performance\nare inappropriate, which underestimated the human performance relative to what\nis possible. To handle those problems and promote the development of RL\nresearch, we propose a novel Atari benchmark based on human world records\n(HWR), which puts forward higher requirements for RL agents on both final\nperformance and learning efficiency. Furthermore, we summarize the\nstate-of-the-art (SOTA) methods in Atari benchmarks and provide benchmark\nresults over new evaluation metrics based on human world records. We concluded\nthat at least four open challenges hinder RL agents from achieving superhuman\nperformance from those new benchmark results. Finally, we also discuss some\npromising ways to handle those problems.",
    "descriptor": "\nComments: AAAI-22 Workshop on Reinforcement Learning in Games\n",
    "authors": [
      "Jiajun Fan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04145"
  },
  {
    "id": "arXiv:2112.04148",
    "title": "Neural Points: Point Cloud Representation with Neural Fields",
    "abstract": "In this paper, we propose \\emph{Neural Points}, a novel point cloud\nrepresentation. Unlike traditional point cloud representation where each point\nonly represents a position or a local plane in the 3D space, each point in\nNeural Points represents a local continuous geometric shape via neural fields.\nTherefore, Neural Points can express much more complex details and thus have a\nstronger representation ability. Neural Points is trained with high-resolution\nsurface containing rich geometric details, such that the trained model has\nenough expression ability for various shapes. Specifically, we extract deep\nlocal features on the points and construct neural fields through the local\nisomorphism between the 2D parametric domain and the 3D local patch. In the\nfinal, local neural fields are integrated together to form the global surface.\nExperimental results show that Neural Points has powerful representation\nability and demonstrate excellent robustness and generalization ability. With\nNeural Points, we can resample point cloud with arbitrary resolutions, and it\noutperforms state-of-the-art point cloud upsampling methods by a large margin.",
    "descriptor": "",
    "authors": [
      "Wanquan Feng",
      "Jin Li",
      "Hongrui Cai",
      "Xiaonan Luo",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04148"
  },
  {
    "id": "arXiv:2112.04150",
    "title": "BA-Net: Bridge Attention for Deep Convolutional Neural Networks",
    "abstract": "In recent years, channel attention mechanism is widely investigated for its\ngreat potential in improving the performance of deep convolutional neural\nnetworks (CNNs). However, in most existing methods, only the output of the\nadjacent convolution layer is fed to the attention layer for calculating the\nchannel weights. Information from other convolution layers is ignored. With\nthese observations, a simple strategy, named Bridge Attention Net (BA-Net), is\nproposed for better channel attention mechanisms. The main idea of this design\nis to bridge the outputs of the previous convolution layers through skip\nconnections for channel weights generation. BA-Net can not only provide richer\nfeatures to calculate channel weight when feedforward, but also multiply paths\nof parameters updating when backforward. Comprehensive evaluation demonstrates\nthat the proposed approach achieves state-of-the-art performance compared with\nthe existing methods in regards to accuracy and speed. Bridge Attention\nprovides a fresh perspective on the design of neural network architectures and\nshows great potential in improving the performance of the existing channel\nattention mechanisms. The code is available at\n\\url{https://github.com/zhaoy376/Attention-mechanism",
    "descriptor": "",
    "authors": [
      "Yue Zhao",
      "Junzhou Chen",
      "Zirui Zhang",
      "Ronghui Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04150"
  },
  {
    "id": "arXiv:2112.04153",
    "title": "Model-Value Inconsistency as a Signal for Epistemic Uncertainty",
    "abstract": "Using a model of the environment and a value function, an agent can construct\nmany estimates of a state's value, by unrolling the model for different lengths\nand bootstrapping with its value function. Our key insight is that one can\ntreat this set of value estimates as a type of ensemble, which we call an\n\\emph{implicit value ensemble} (IVE). Consequently, the discrepancy between\nthese estimates can be used as a proxy for the agent's epistemic uncertainty;\nwe term this signal \\emph{model-value inconsistency} or\n\\emph{self-inconsistency} for short. Unlike prior work which estimates\nuncertainty by training an ensemble of many models and/or value functions, this\napproach requires only the single model and value function which are already\nbeing learned in most model-based reinforcement learning algorithms. We provide\nempirical evidence in both tabular and function approximation settings from\npixels that self-inconsistency is useful (i) as a signal for exploration, (ii)\nfor acting safely under distribution shifts, and (iii) for robustifying\nvalue-based planning with a model.",
    "descriptor": "\nComments: The first three authors contributed equally\n",
    "authors": [
      "Angelos Filos",
      "Eszter V\u00e9rtes",
      "Zita Marinho",
      "Gregory Farquhar",
      "Diana Borsa",
      "Abram Friesen",
      "Feryal Behbahani",
      "Tom Schaul",
      "Andr\u00e9 Barreto",
      "Simon Osindero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04153"
  },
  {
    "id": "arXiv:2112.04154",
    "title": "SNEAK: Synonymous Sentences-Aware Adversarial Attack on Natural Language  Video Localization",
    "abstract": "Natural language video localization (NLVL) is an important task in the\nvision-language understanding area, which calls for an in-depth understanding\nof not only computer vision and natural language side alone, but more\nimportantly the interplay between both sides. Adversarial vulnerability has\nbeen well-recognized as a critical security issue of deep neural network\nmodels, which requires prudent investigation. Despite its extensive yet\nseparated studies in video and language tasks, current understanding of the\nadversarial robustness in vision-language joint tasks like NLVL is less\ndeveloped. This paper therefore aims to comprehensively investigate the\nadversarial robustness of NLVL models by examining three facets of\nvulnerabilities from both attack and defense aspects. To achieve the attack\ngoal, we propose a new adversarial attack paradigm called synonymous\nsentences-aware adversarial attack on NLVL (SNEAK), which captures the\ncross-modality interplay between the vision and language sides.",
    "descriptor": "",
    "authors": [
      "Wenbo Gou",
      "Wen Shi",
      "Jian Lou",
      "Lijie Huang",
      "Pan Zhou",
      "Ruixuan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.04154"
  },
  {
    "id": "arXiv:2112.04155",
    "title": "Towards the classification of Self-Sovereign Identity properties",
    "abstract": "Self-Sovereign Identity (SSI) is a novel and emerging, decentralized identity\napproach that enables entities to fully control and manage their digital\nidentifiers and associated identity data while enhances trust, privacy,\nsecurity, and many other properties analyzed in this paper. The paper provides\nan overview of the SSI properties, focusing on an in-depth analysis,\nfurthermore presenting a comprehensive collection of SSI properties that are\nimportant for the implementation of the SSI system. In addition, it explores\nthe SSI process flow and highlights the steps in which individual properties\nare important. After the initial purification and classification phase, we then\nvalidated properties among experts in the field of decentralized and\nself-sovereign identity management using an online questionnaire, which\nresulted in a final set of classified and verified SSI properties. The results\ncan be used for further work on the definition and standardization of the SSI\nfield.",
    "descriptor": "\nComments: 20 pages, 5 figures, 6 tables, submitted to Computer Science Review\n",
    "authors": [
      "\u0160pela \u010cu\u010dko",
      "\u0160eila Be\u0107irovi\u0107",
      "Aida Kami\u0161ali\u0107",
      "Sa\u0161a Mrdovi\u0107",
      "Muhamed Turkanovi\u0107"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.04155"
  },
  {
    "id": "arXiv:2112.04159",
    "title": "Garment4D: Garment Reconstruction from Point Cloud Sequences",
    "abstract": "Learning to reconstruct 3D garments is important for dressing 3D human bodies\nof different shapes in different poses. Previous works typically rely on 2D\nimages as input, which however suffer from the scale and pose ambiguities. To\ncircumvent the problems caused by 2D images, we propose a principled framework,\nGarment4D, that uses 3D point cloud sequences of dressed humans for garment\nreconstruction. Garment4D has three dedicated steps: sequential garments\nregistration, canonical garment estimation, and posed garment reconstruction.\nThe main challenges are two-fold: 1) effective 3D feature learning for fine\ndetails, and 2) capture of garment dynamics caused by the interaction between\ngarments and the human body, especially for loose garments like skirts. To\nunravel these problems, we introduce a novel Proposal-Guided Hierarchical\nFeature Network and Iterative Graph Convolution Network, which integrate both\nhigh-level semantic features and low-level geometric features for fine details\nreconstruction. Furthermore, we propose a Temporal Transformer for smooth\ngarment motions capture. Unlike non-parametric methods, the reconstructed\ngarment meshes by our method are separable from the human body and have strong\ninterpretability, which is desirable for downstream tasks. As the first attempt\nat this task, high-quality reconstruction results are qualitatively and\nquantitatively illustrated through extensive experiments. Codes are available\nat https://github.com/hongfz16/Garment4D.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021. Project Page: this https URL . Codes are available: this https URL\n",
    "authors": [
      "Fangzhou Hong",
      "Liang Pan",
      "Zhongang Cai",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04159"
  },
  {
    "id": "arXiv:2112.04162",
    "title": "Symmetry Perception by Deep Networks: Inadequacy of Feed-Forward  Architectures and Improvements with Recurrent Connections",
    "abstract": "Symmetry is omnipresent in nature and perceived by the visual system of many\nspecies, as it facilitates detecting ecologically important classes of objects\nin our environment. Symmetry perception requires abstraction of non-local\nspatial dependencies between image regions, and its underlying neural\nmechanisms remain elusive. In this paper, we evaluate Deep Neural Network (DNN)\narchitectures on the task of learning symmetry perception from examples. We\ndemonstrate that feed-forward DNNs that excel at modelling human performance on\nobject recognition tasks, are unable to acquire a general notion of symmetry.\nThis is the case even when the DNNs are architected to capture non-local\nspatial dependencies, such as through `dilated' convolutions and the recently\nintroduced `transformers' design. By contrast, we find that recurrent\narchitectures are capable of learning to perceive symmetry by decomposing the\nnon-local spatial dependencies into a sequence of local operations, that are\nreusable for novel images. These results suggest that recurrent connections\nlikely play an important role in symmetry perception in artificial systems, and\npossibly, biological ones too.",
    "descriptor": "",
    "authors": [
      "Shobhita Sundaram",
      "Darius Sinha",
      "Matthew Groth",
      "Tomotake Sasaki",
      "Xavier Boix"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04162"
  },
  {
    "id": "arXiv:2112.04163",
    "title": "Assessing a Single Image in Reference-Guided Image Synthesis",
    "abstract": "Assessing the performance of Generative Adversarial Networks (GANs) has been\nan important topic due to its practical significance. Although several\nevaluation metrics have been proposed, they generally assess the quality of the\nwhole generated image distribution. For Reference-guided Image Synthesis (RIS)\ntasks, i.e., rendering a source image in the style of another reference image,\nwhere assessing the quality of a single generated image is crucial, these\nmetrics are not applicable. In this paper, we propose a general learning-based\nframework, Reference-guided Image Synthesis Assessment (RISA) to quantitatively\nevaluate the quality of a single generated image. Notably, the training of RISA\ndoes not require human annotations. In specific, the training data for RISA are\nacquired by the intermediate models from the training procedure in RIS, and\nweakly annotated by the number of models' iterations, based on the positive\ncorrelation between image quality and iterations. As this annotation is too\ncoarse as a supervision signal, we introduce two techniques: 1) a pixel-wise\ninterpolation scheme to refine the coarse labels, and 2) multiple binary\nclassifiers to replace a na\\\"ive regressor. In addition, an unsupervised\ncontrastive loss is introduced to effectively capture the style similarity\nbetween a generated image and its reference image. Empirical results on various\ndatasets demonstrate that RISA is highly consistent with human preference and\ntransfers well across models.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Jiayi Guo",
      "Chaoqun Du",
      "Jiangshan Wang",
      "Huijuan Huang",
      "Pengfei Wan",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04163"
  },
  {
    "id": "arXiv:2112.04165",
    "title": "Shortest Paths in Graphs with Matrix-Valued Edges: Concepts, Algorithm  and Application to 3D Multi-Shape Analysis",
    "abstract": "Finding shortest paths in a graph is relevant for numerous problems in\ncomputer vision and graphics, including image segmentation, shape matching, or\nthe computation of geodesic distances on discrete surfaces. Traditionally, the\nconcept of a shortest path is considered for graphs with scalar edge weights,\nwhich makes it possible to compute the length of a path by adding up the\nindividual edge weights. Yet, graphs with scalar edge weights are severely\nlimited in their expressivity, since oftentimes edges are used to encode\nsignificantly more complex interrelations. In this work we compensate for this\nmodelling limitation and introduce the novel graph-theoretic concept of a\nshortest path in a graph with matrix-valued edges. To this end, we define a\nmeaningful way for quantifying the path length for matrix-valued edges, and we\npropose a simple yet effective algorithm to compute the respective shortest\npath. While our formalism is universal and thus applicable to a wide range of\nsettings in vision, graphics and beyond, we focus on demonstrating its merits\nin the context of 3D multi-shape analysis.",
    "descriptor": "\nComments: published at 3DV\n",
    "authors": [
      "Viktoria Ehm",
      "Daniel Cremers",
      "Florian Bernard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.04165"
  },
  {
    "id": "arXiv:2112.04166",
    "title": "Weighted Fairness Notions for Indivisible Items Revisited",
    "abstract": "We revisit the setting of fairly allocating indivisible items when agents\nhave different weights representing their entitlements. First, we propose a\nparameterized family of relaxations for weighted envy-freeness and the same for\nweighted proportionality; the parameters indicate whether smaller-weight or\nlarger-weight agents should be given a higher priority. We show that each\nnotion in these families can always be satisfied, but any two cannot\nnecessarily be fulfilled simultaneously. We then introduce an intuitive\nweighted generalization of maximin share fairness and establish the optimal\napproximation of it that can be guaranteed. Furthermore, we characterize the\nimplication relations between the various weighted fairness notions introduced\nin this and prior work, and relate them to the lower and upper quota axioms\nfrom apportionment.",
    "descriptor": "\nComments: Appears in the 36th AAAI Conference on Artificial Intelligence (AAAI), 2022\n",
    "authors": [
      "Mithun Chakraborty",
      "Erel Segal-Halevi",
      "Warut Suksompong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2112.04166"
  },
  {
    "id": "arXiv:2112.04167",
    "title": "Assessment of high-order IMEX methods for incompressible flow",
    "abstract": "This paper investigates the competitiveness of semi-implicit Runge-Kutta (RK)\nand spectral deferred correction (SDC) time-integration methods up to order six\nfor incompressible Navier-Stokes problems in conjunction with a high-order\ndiscontinuous Galerkin method for space discretization. It is proposed to\nharness the implicit and explicit RK parts as a partitioned scheme, which\nprovides a natural basis for the underlying projection scheme and yields a\nstraight-forward approach for accommodating nonlinear viscosity. Numerical\nexperiments on laminar flow, variable viscosity and transition to turbulence\nare carried out to assess accuracy, convergence and computational efficiency.\nAlthough the methods of order 3 or higher are susceptible to order reduction\ndue to time-dependent boundary conditions, two third-order RK methods are\nidentified that perform well in all test cases and clearly surpass all\nsecond-order schemes including the popular extrapolated backward difference\nmethod. The considered SDC methods are more accurate than the RK methods, but\nbecome competitive only for relative errors smaller than ca $10^{-5}$.",
    "descriptor": "",
    "authors": [
      "Montadhar Guesmi",
      "Martina Grotteschi",
      "J\u00f6rg Stiller"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.04167"
  },
  {
    "id": "arXiv:2112.04169",
    "title": "Equity Promotion in Online Resource Allocation",
    "abstract": "We consider online resource allocation under a typical non-profit setting,\nwhere limited or even scarce resources are administered by a not-for-profit\norganization like a government. We focus on the internal-equity by assuming\nthat arriving requesters are homogeneous in terms of their external factors\nlike demands but heterogeneous for their internal attributes like demographics.\nSpecifically, we associate each arriving requester with one or several groups\nbased on their demographics (i.e., race, gender, and age), and we aim to design\nan equitable distributing strategy such that every group of requesters can\nreceive a fair share of resources proportional to a preset target ratio. We\npresent two LP-based sampling algorithms and investigate them both\ntheoretically (in terms of competitive-ratio analysis) and experimentally based\non real COVID-19 vaccination data maintained by the Minnesota Department of\nHealth. Both theoretical and numerical results show that our LP-based sampling\nstrategies can effectively promote equity, especially when the arrival\npopulation is disproportionately represented, as observed in the early stage of\nthe COVID-19 vaccine rollout.",
    "descriptor": "\nComments: A preliminary version will appear in the 36th AAAI Conference on Artificial Intelligence (AAAI 22)\n",
    "authors": [
      "Pan Xu",
      "Yifan Xu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.04169"
  },
  {
    "id": "arXiv:2112.04174",
    "title": "Boosting Contrastive Learning with Relation Knowledge Distillation",
    "abstract": "While self-supervised representation learning (SSL) has proved to be\neffective in the large model, there is still a huge gap between the SSL and\nsupervised method in the lightweight model when following the same solution. We\ndelve into this problem and find that the lightweight model is prone to\ncollapse in semantic space when simply performing instance-wise contrast. To\naddress this issue, we propose a relation-wise contrastive paradigm with\nRelation Knowledge Distillation (ReKD). We introduce a heterogeneous teacher to\nexplicitly mine the semantic information and transferring a novel relation\nknowledge to the student (lightweight model). The theoretical analysis supports\nour main concern about instance-wise contrast and verify the effectiveness of\nour relation-wise contrastive learning. Extensive experimental results also\ndemonstrate that our method achieves significant improvements on multiple\nlightweight models. Particularly, the linear evaluation on AlexNet obviously\nimproves the current state-of-art from 44.7% to 50.1%, which is the first work\nto get close to the supervised 50.5%. Code will be made available.",
    "descriptor": "\nComments: Accepted by AAAI-2022\n",
    "authors": [
      "Kai Zheng",
      "Yuanjiang Wang",
      "Ye Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04174"
  },
  {
    "id": "arXiv:2112.04176",
    "title": "Mobile BCI dataset of scalp- and ear-EEGs with ERP and SSVEP paradigms  while standing, walking, and running",
    "abstract": "We present a mobile dataset obtained from electroencephalography (EEG) of the\nscalp and around the ear as well as from locomotion sensors by 24 participants\nmoving at four different speeds while performing two brain-computer interface\n(BCI) tasks. The data were collected from 32-channel scalp-EEG, 14-channel\near-EEG, 4-channel electrooculography, and 9-channel inertial measurement units\nplaced at the forehead, left ankle, and right ankle. The recording conditions\nwere as follows: standing, slow walking, fast walking, and slight running at\nspeeds of 0, 0.8, 1.6, and 2.0m/s, respectively. For each speed, two different\nBCI paradigms, event-related potential and steady-state visual evoked\npotential, were recorded. To evaluate the signal quality, scalp- and ear-EEG\ndata were qualitatively and quantitatively validated during each speed. We\nbelieve that the dataset will facilitate BCIs in diverse mobile environments to\nanalyze brain activities and evaluate the performance quantitatively for\nexpanding the use of practical BCIs.",
    "descriptor": "\nComments: accepted paper from Scientific Data\n",
    "authors": [
      "Young-Eun Lee",
      "Gi-Hwan Shin",
      "Minji Lee",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.04176"
  },
  {
    "id": "arXiv:2112.04177",
    "title": "VISOLO: Grid-Based Space-Time Aggregation for Efficient Online Video  Instance Segmentation",
    "abstract": "For online video instance segmentation (VIS), fully utilizing the information\nfrom previous frames in an efficient manner is essential for real-time\napplications. Most previous methods follow a two-stage approach requiring\nadditional computations such as RPN and RoIAlign, and do not fully exploit the\navailable information in the video for all subtasks in VIS. In this paper, we\npropose a novel single-stage framework for online VIS built based on the grid\nstructured feature representation. The grid-based features allow us to employ\nfully convolutional networks for real-time processing, and also to easily reuse\nand share features within different components. We also introduce cooperatively\noperating modules that aggregate information from available frames, in order to\nenrich the features for all subtasks in VIS. Our design fully takes advantage\nof previous information in a grid form for all tasks in VIS in an efficient\nway, and we achieved the new state-of-the-art accuracy (38.6 AP and 36.9 AP)\nand speed (40.0 FPS) on YouTube-VIS 2019 and 2021 datasets among online VIS\nmethods.",
    "descriptor": "",
    "authors": [
      "Su Ho Han",
      "Sukjun Hwang",
      "Seoung Wug Oh",
      "Yeonchool Park",
      "Hyunwoo Kim",
      "Min-Jung Kim",
      "Seon Joo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04177"
  },
  {
    "id": "arXiv:2112.04178",
    "title": "Topology-aware Convolutional Neural Network for Efficient Skeleton-based  Action Recognition",
    "abstract": "In the context of skeleton-based action recognition, graph convolutional\nnetworks (GCNs) have been rapidly developed, whereas convolutional neural\nnetworks (CNNs) have received less attention. One reason is that CNNs are\nconsidered poor in modeling the irregular skeleton topology. To alleviate this\nlimitation, we propose a pure CNN architecture named Topology-aware CNN\n(Ta-CNN) in this paper. In particular, we develop a novel cross-channel feature\naugmentation module, which is a combo of map-attend-group-map operations. By\napplying the module to the coordinate level and the joint level subsequently,\nthe topology feature is effectively enhanced. Notably, we theoretically prove\nthat graph convolution is a special case of normal convolution when the joint\ndimension is treated as channels. This confirms that the topology modeling\npower of GCNs can also be implemented by using a CNN. Moreover, we creatively\ndesign a SkeletonMix strategy which mixes two persons in a unique manner and\nfurther boosts the performance. Extensive experiments are conducted on four\nwidely used datasets, i.e. N-UCLA, SBU, NTU RGB+D and NTU RGB+D 120 to verify\nthe effectiveness of Ta-CNN. We surpass existing CNN-based methods\nsignificantly. Compared with leading GCN-based methods, we achieve comparable\nperformance with much less complexity in terms of the required GFLOPs and\nparameters.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Kailin Xu",
      "Fanfan Ye",
      "Qiaoyong Zhong",
      "Di Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04178"
  },
  {
    "id": "arXiv:2112.04182",
    "title": "Unimodal Face Classification with Multimodal Training",
    "abstract": "Face recognition is a crucial task in various multimedia applications such as\nsecurity check, credential access and motion sensing games. However, the task\nis challenging when an input face is noisy (e.g. poor-condition RGB image) or\nlacks certain information (e.g. 3D face without color). In this work, we\npropose a Multimodal Training Unimodal Test (MTUT) framework for robust face\nclassification, which exploits the cross-modality relationship during training\nand applies it as a complementary of the imperfect single modality input during\ntesting. Technically, during training, the framework (1) builds both\nintra-modality and cross-modality autoencoders with the aid of facial\nattributes to learn latent embeddings as multimodal descriptors, (2) proposes a\nnovel multimodal embedding divergence loss to align the heterogeneous features\nfrom different modalities, which also adaptively avoids the useless modality\n(if any) from confusing the model. This way, the learned autoencoders can\ngenerate robust embeddings in single-modality face classification on test\nstage. We evaluate our framework in two face classification datasets and two\nkinds of testing input: (1) poor-condition image and (2) point cloud or 3D face\nmesh, when both 2D and 3D modalities are available for training. We\nexperimentally show that our MTUT framework consistently outperforms ten\nbaselines on 2D and 3D settings of both datasets.",
    "descriptor": "\nComments: Accepted by IEEE International Conference On Automatic Face and Gesture Recognition 2021\n",
    "authors": [
      "Wenbin Teng",
      "Chongyang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04182"
  },
  {
    "id": "arXiv:2112.04183",
    "title": "Twin-Distance-Hereditary Digraphs",
    "abstract": "We investigate structural and algorithmic advantages of a directed version of\nthe well-researched class of distance-hereditary graphs. Since the previously\ndefined distance-hereditary digraphs do not permit a recursive structure, we\ndefine directed twin-distance-hereditary graphs, which can be constructed by\nseveral twin and pendant vertex operations analogously to undirected\ndistance-hereditary graphs and which still preserves the distance hereditary\nproperty. We give a characterization by forbidden induced subdigraphs and place\nthe class in the hierarchy, comparing it to related classes. We further show\nalgorithmic advantages concerning directed width parameters, directed graph\ncoloring and some other well-known digraph problems which are NP-hard in\ngeneral, but computable in polynomial or even linear time on\ntwin-distance-hereditary digraphs. This includes computability of directed\npath-width and tree-width in linear time and the directed chromatic number in\npolynomial time. From our result that directed twin-distance-hereditary graphs\nhave directed clique-width at most $3$ it follows by Courcelle's theorem on\ndirected clique-width that we can compute every graph problem describable in\nwhich is describable in monadic second-order logic on quantification over\nvertices and vertex sets as well as some further problems like Hamiltonian\nPath/Cycle in polynomial time.",
    "descriptor": "",
    "authors": [
      "Dominique Komander",
      "Carolin Rehs"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.04183"
  },
  {
    "id": "arXiv:2112.04184",
    "title": "Zero-Shot Recommendation as Language Modeling",
    "abstract": "Recommendation is the task of ranking items (e.g. movies or products)\naccording to individual user needs. Current systems rely on collaborative\nfiltering and content-based techniques, which both require structured training\ndata. We propose a framework for recommendation with off-the-shelf pretrained\nlanguage models (LM) that only used unstructured text corpora as training data.\nIf a user $u$ liked \\textit{Matrix} and \\textit{Inception}, we construct a\ntextual prompt, e.g. \\textit{\"Movies like Matrix, Inception, ${<}m{>}$\"} to\nestimate the affinity between $u$ and $m$ with LM likelihood. We motivate our\nidea with a corpus analysis, evaluate several prompt structures, and we compare\nLM-based recommendation with standard matrix factorization trained on different\ndata regimes. The code for our experiments is publicly available\n(https://colab.research.google.com/drive/1f1mlZ-FGaLGdo5rPzxf3vemKllbh2esT?usp=sharing).",
    "descriptor": "\nComments: Accepted at ECIR 2022\n",
    "authors": [
      "Damien Sileo",
      "Wout Vossen",
      "Robbe Raymaekers"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.04184"
  },
  {
    "id": "arXiv:2112.04185",
    "title": "Transformaly -- Two (Feature Spaces) Are Better Than One",
    "abstract": "Anomaly detection is a well-established research area that seeks to identify\nsamples outside of a predetermined distribution. An anomaly detection pipeline\nis comprised of two main stages: (1) feature extraction and (2) normality score\nassignment. Recent papers used pre-trained networks for feature extraction\nachieving state-of-the-art results. However, the use of pre-trained networks\ndoes not fully-utilize the normal samples that are available at train time.\nThis paper suggests taking advantage of this information by using\nteacher-student training. In our setting, a pretrained teacher network is used\nto train a student network on the normal training samples. Since the student\nnetwork is trained only on normal samples, it is expected to deviate from the\nteacher network in abnormal cases. This difference can serve as a complementary\nrepresentation to the pre-trained feature vector. Our method -- Transformaly --\nexploits a pre-trained Vision Transformer (ViT) to extract both feature\nvectors: the pre-trained (agnostic) features and the teacher-student\n(fine-tuned) features. We report state-of-the-art AUROC results in both the\ncommon unimodal setting, where one class is considered normal and the rest are\nconsidered abnormal, and the multimodal setting, where all classes but one are\nconsidered normal, and just one class is considered abnormal. The code is\navailable at https://github.com/MatanCohen1/Transformaly.",
    "descriptor": "",
    "authors": [
      "Matan Jacob Cohen",
      "Shai Avidan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04185"
  },
  {
    "id": "arXiv:2112.04187",
    "title": "Pretrained Cost Model for Distributed Constraint Optimization Problems",
    "abstract": "Distributed Constraint Optimization Problems (DCOPs) are an important\nsubclass of combinatorial optimization problems, where information and controls\nare distributed among multiple autonomous agents. Previously, Machine Learning\n(ML) has been largely applied to solve combinatorial optimization problems by\nlearning effective heuristics. However, existing ML-based heuristic methods are\noften not generalizable to different search algorithms. Most importantly, these\nmethods usually require full knowledge about the problems to be solved, which\nare not suitable for distributed settings where centralization is not realistic\ndue to geographical limitations or privacy concerns. To address the generality\nissue, we propose a novel directed acyclic graph representation schema for\nDCOPs and leverage the Graph Attention Networks (GATs) to embed graph\nrepresentations. Our model, GAT-PCM, is then pretrained with optimally labelled\ndata in an offline manner, so as to construct effective heuristics to boost a\nbroad range of DCOP algorithms where evaluating the quality of a partial\nassignment is critical, such as local search or backtracking search.\nFurthermore, to enable decentralized model inference, we propose a distributed\nembedding schema of GAT-PCM where each agent exchanges only embedded vectors,\nand show its soundness and complexity. Finally, we demonstrate the\neffectiveness of our model by combining it with a local search or a\nbacktracking search algorithm. Extensive empirical evaluations indicate that\nthe GAT-PCM-boosted algorithms significantly outperform the state-of-the-art\nmethods in various benchmarks. The pretrained model is available at\nhttps://github.com/dyc941126/GAT-PCM.",
    "descriptor": "\nComments: Accepted by AAAI-22\n",
    "authors": [
      "Yanchen Deng",
      "Shufeng Kong",
      "Bo An"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04187"
  },
  {
    "id": "arXiv:2112.04189",
    "title": "Transformer-Based Approach for Joint Handwriting and Named Entity  Recognition in Historical documents",
    "abstract": "The extraction of relevant information carried out by named entities in\nhandwriting documents is still a challenging task. Unlike traditional\ninformation extraction approaches that usually face text transcription and\nnamed entity recognition as separate subsequent tasks, we propose in this paper\nan end-to-end transformer-based approach to jointly perform these two tasks.\nThe proposed approach operates at the paragraph level, which brings two main\nbenefits. First, it allows the model to avoid unrecoverable early errors due to\nline segmentation. Second, it allows the model to exploit larger bi-dimensional\ncontext information to identify the semantic categories, reaching a higher\nfinal prediction accuracy. We also explore different training scenarios to show\ntheir effect on the performance and we demonstrate that a two-stage learning\nstrategy can make the model reach a higher final prediction accuracy. As far as\nwe know, this work presents the first approach that adopts the transformer\nnetworks for named entity recognition in handwritten documents. We achieve the\nnew state-of-the-art performance in the ICDAR 2017 Information Extraction\ncompetition using the Esposalles database, for the complete task, even though\nthe proposed technique does not use any dictionaries, language modeling, or\npost-processing.",
    "descriptor": "",
    "authors": [
      "Ahmed Cheikh Rouhoua",
      "Marwa Dhiaf",
      "Yousri Kessentini",
      "Sinda Ben Salem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.04189"
  },
  {
    "id": "arXiv:2112.04191",
    "title": "Parallelizable global quasi-conformal parameterization of multiply  connected surfaces via partial welding",
    "abstract": "Conformal and quasi-conformal mappings have widespread applications in\nimaging science, computer vision and computer graphics, such as surface\nregistration, segmentation, remeshing, and texture map compression. While\nvarious conformal and quasi-conformal parameterization methods for simply\nconnected surfaces have been proposed, efficient parameterization methods for\nmultiply connected surfaces are less explored. In this paper, we propose a\nnovel parallelizable algorithm for computing the global conformal and\nquasi-conformal parameterization of multiply connected surfaces onto a 2D\ncircular domain using variants of the partial welding algorithm and the Koebe's\niteration. The main idea is to partition a multiply connected surface into\nseveral subdomains and compute the free-boundary conformal or quasi-conformal\nparameterizations of them respectively, and then apply a variant of the partial\nwelding algorithm to reconstruct the global mapping. We apply the Koebe's\niteration together with the geodesic algorithm to the boundary points and\nwelding paths before and after the global welding to transform all the\nboundaries to circles conformally. After getting all the updated boundary\nconditions, we obtain the global parameterization of the multiply connected\nsurface by solving the Laplace equation for each subdomain. Using this\ndivide-and-conquer approach, the parameterization of surfaces with very high\nresolution can be efficiently computed. Experimental results are presented to\ndemonstrate the effectiveness of our proposed algorithms.",
    "descriptor": "",
    "authors": [
      "Zhipeng Zhu",
      "Gary P. T. Choi",
      "Lok Ming Lui"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.04191"
  },
  {
    "id": "arXiv:2112.04193",
    "title": "Learnable Faster Kernel-PCA for Nonlinear Fault Detection: Deep  Autoencoder-Based Realization",
    "abstract": "Kernel principal component analysis (KPCA) is a well-recognized nonlinear\ndimensionality reduction method that has been widely used in nonlinear fault\ndetection tasks. As a kernel trick-based method, KPCA inherits two major\nproblems. First, the form and the parameters of the kernel function are usually\nselected blindly, depending seriously on trial-and-error. As a result, there\nmay be serious performance degradation in case of inappropriate selections.\nSecond, at the online monitoring stage, KPCA has much computational burden and\npoor real-time performance, because the kernel method requires to leverage all\nthe offline training data. In this work, to deal with the two drawbacks, a\nlearnable faster realization of the conventional KPCA is proposed. The core\nidea is to parameterize all feasible kernel functions using the novel nonlinear\nDAE-FE (deep autoencoder based feature extraction) framework and propose\nDAE-PCA (deep autoencoder based principal component analysis) approach in\ndetail. The proposed DAE-PCA method is proved to be equivalent to KPCA but has\nmore advantage in terms of automatic searching of the most suitable nonlinear\nhigh-dimensional space according to the inputs. Furthermore, the online\ncomputational efficiency improves by approximately 100 times compared with the\nconventional KPCA. With the Tennessee Eastman (TE) process benchmark, the\neffectiveness and superiority of the proposed method is illustrated.",
    "descriptor": "\nComments: 11 pages, 7 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Zelin Ren",
      "Xuebing Yang",
      "Yuchen Jiang",
      "Wensheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04193"
  },
  {
    "id": "arXiv:2112.04195",
    "title": "VIRT: Improving Representation-based Models for Text Matching through  Virtual Interaction",
    "abstract": "With the booming of pre-trained transformers, remarkable progress has been\nmade on textual pair modeling to support relevant natural language\napplications. Two lines of approaches are developed for text matching:\ninteraction-based models performing full interactions over the textual pair,\nand representation-based models encoding the pair independently with siamese\nencoders. The former achieves compelling performance due to its deep\ninteraction modeling ability, yet with a sacrifice in inference latency. The\nlatter is efficient and widely adopted for practical use, however, suffers from\nsevere performance degradation due to the lack of interactions. Though some\nprior works attempt to integrate interactive knowledge into\nrepresentation-based models, considering the computational cost, they only\nperform late interaction or knowledge transferring at the top layers.\nInteractive information in the lower layers is still missing, which limits the\nperformance of representation-based solutions. To remedy this, we propose a\nnovel \\textit{Virtual} InteRacTion mechanism, termed as VIRT, to enable full\nand deep interaction modeling in representation-based models without\n\\textit{actual} inference computations. Concretely, VIRT asks\nrepresentation-based encoders to conduct virtual interactions to mimic the\nbehaviors as interaction-based models do. In addition, the knowledge distilled\nfrom interaction-based encoders is taken as supervised signals to promise the\neffectiveness of virtual interactions. Since virtual interactions only happen\nat the training stage, VIRT would not increase the inference cost. Furthermore,\nwe design a VIRT-adapted late interaction strategy to fully utilize the learned\nvirtual interactive knowledge.",
    "descriptor": "",
    "authors": [
      "Dan Li",
      "Yang Yang",
      "Hongyin Tang",
      "Jingang Wang",
      "Tong Xu",
      "Wei Wu",
      "Enhong Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.04195"
  },
  {
    "id": "arXiv:2112.04197",
    "title": "A Fast Algorithm for PAC Combinatorial Pure Exploration",
    "abstract": "We consider the problem of Combinatorial Pure Exploration (CPE), which deals\nwith finding a combinatorial set or arms with a high reward, when the rewards\nof individual arms are unknown in advance and must be estimated using arm\npulls. Previous algorithms for this problem, while obtaining sample complexity\nreductions in many cases, are highly computationally intensive, thus making\nthem impractical even for mildly large problems. In this work, we propose a new\nCPE algorithm in the PAC setting, which is computationally light weight, and so\ncan easily be applied to problems with tens of thousands of arms. This is\nachieved since the proposed algorithm requires a very small number of\ncombinatorial oracle calls. The algorithm is based on successive acceptance of\narms, along with elimination which is based on the combinatorial structure of\nthe problem. We provide sample complexity guarantees for our algorithm, and\ndemonstrate in experiments its usefulness on large problems, whereas previous\nalgorithms are impractical to run on problems of even a few dozen arms. The\ncode for the algorithms and experiments is provided at\nhttps://github.com/noabdavid/csale.",
    "descriptor": "\nComments: Full version of paper accepted to AAAI-22\n",
    "authors": [
      "Noa Ben-David",
      "Sivan Sabato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04197"
  },
  {
    "id": "arXiv:2112.04199",
    "title": "Scores of a specific field-normalized indicator calculated with  different approaches of field-categorization: Are the scores different or  similar?",
    "abstract": "Usage of field-normalized citation scores is a bibliometric standard.\nDifferent methods for field-normalization are in use, but also the choice of\nfield-classification system determines the resulting field-normalized citation\nscores. Using Web of Science data, we calculated field-normalized citation\nscores using the same formula but different field-classification systems to\nanswer the question if the resulting scores are different or similar. Six\nfield-classification systems were used: three based on citation relations, one\non semantic similarity scores (i.e., a topical relatedness measure), one on\njournal sets, and one on intellectual classifications. Systems based on journal\nsets and intellectual classifications agree on at least the moderate level. Two\nout of the three sets based on citation relations also agree on at least the\nmoderate level. Larger differences were observed for the third data set based\non citation relations and semantic similarity scores.",
    "descriptor": "\nComments: 25 pages, 5 figures, and 2 tables\n",
    "authors": [
      "Robin Haunschild",
      "Angela D. Daniels",
      "Lutz Bornmann"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2112.04199"
  },
  {
    "id": "arXiv:2112.04203",
    "title": "Adversarial Parametric Pose Prior",
    "abstract": "The Skinned Multi-Person Linear (SMPL) model can represent a human body by\nmapping pose and shape parameters to body meshes. This has been shown to\nfacilitate inferring 3D human pose and shape from images via different learning\nmodels. However, not all pose and shape parameter values yield\nphysically-plausible or even realistic body meshes. In other words, SMPL is\nunder-constrained and may thus lead to invalid results when used to reconstruct\nhumans from images, either by directly optimizing its parameters, or by\nlearning a mapping from the image to these parameters.\nIn this paper, we therefore learn a prior that restricts the SMPL parameters\nto values that produce realistic poses via adversarial training. We show that\nour learned prior covers the diversity of the real-data distribution,\nfacilitates optimization for 3D reconstruction from 2D keypoints, and yields\nbetter pose estimates when used for regression from images. We found that the\nprior based on spherical distribution gets the best results. Furthermore, in\nall these tasks, it outperforms the state-of-the-art VAE-based approach to\nconstraining the SMPL parameters.",
    "descriptor": "",
    "authors": [
      "Andrey Davydov",
      "Anastasia Remizova",
      "Victor Constantin",
      "Sina Honari",
      "Mathieu Salzmann",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04203"
  },
  {
    "id": "arXiv:2112.04212",
    "title": "Do Pedestrians Pay Attention? Eye Contact Detection in the Wild",
    "abstract": "In urban or crowded environments, humans rely on eye contact for fast and\nefficient communication with nearby people. Autonomous agents also need to\ndetect eye contact to interact with pedestrians and safely navigate around\nthem. In this paper, we focus on eye contact detection in the wild, i.e.,\nreal-world scenarios for autonomous vehicles with no control over the\nenvironment or the distance of pedestrians. We introduce a model that leverages\nsemantic keypoints to detect eye contact and show that this high-level\nrepresentation (i) achieves state-of-the-art results on the publicly-available\ndataset JAAD, and (ii) conveys better generalization properties than leveraging\nraw images in an end-to-end network. To study domain adaptation, we create\nLOOK: a large-scale dataset for eye contact detection in the wild, which\nfocuses on diverse and unconstrained scenarios for real-world generalization.\nThe source code and the LOOK dataset are publicly shared towards an open\nscience mission.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Younes Belkada",
      "Lorenzo Bertoni",
      "Romain Caristan",
      "Taylor Mordan",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04212"
  },
  {
    "id": "arXiv:2112.04213",
    "title": "Convergence Results For Q-Learning With Experience Replay",
    "abstract": "A commonly used heuristic in RL is experience replay\n(e.g.~\\citet{lin1993reinforcement, mnih2015human}), in which a learner stores\nand re-uses past trajectories as if they were sampled online. In this work, we\ninitiate a rigorous study of this heuristic in the setting of tabular\nQ-learning. We provide a convergence rate guarantee, and discuss how it\ncompares to the convergence of Q-learning depending on important parameters\nsuch as the frequency and number of replay iterations. We also provide\ntheoretical evidence showing when we might expect this heuristic to strictly\nimprove performance, by introducing and analyzing a simple class of MDPs.\nFinally, we provide some experiments to support our theoretical findings.",
    "descriptor": "",
    "authors": [
      "Liran Szlak",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04213"
  },
  {
    "id": "arXiv:2112.04214",
    "title": "Learning music audio representations via weak language supervision",
    "abstract": "Audio representations for music information retrieval are typically learned\nvia supervised learning in a task-specific fashion. Although effective at\nproducing state-of-the-art results, this scheme lacks flexibility with respect\nto the range of applications a model can have and requires extensively\nannotated datasets. In this work, we pose the question of whether it may be\npossible to exploit weakly aligned text as the only supervisory signal to learn\ngeneral-purpose music audio representations. To address this question, we\ndesign a multimodal architecture for music and language pre-training (MuLaP)\noptimised via a set of proxy tasks. Weak supervision is provided in the form of\nnoisy natural language descriptions conveying the overall musical content of\nthe track. After pre-training, we transfer the audio backbone of the model to a\nset of music audio classification and regression tasks. We demonstrate the\nusefulness of our approach by comparing the performance of audio\nrepresentations produced by the same audio backbone with different training\nstrategies and show that our pre-training method consistently achieves\ncomparable or higher scores on all tasks and datasets considered. Our\nexperiments also confirm that MuLaP effectively leverages audio-caption pairs\nto learn representations that are competitive with audio-only and cross-modal\nself-supervised methods in the literature.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Ilaria Manco",
      "Emmanouil Benetos",
      "Elio Quinton",
      "Gyorgy Fazekas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.04214"
  },
  {
    "id": "arXiv:2112.04215",
    "title": "Self-Supervised Models are Continual Learners",
    "abstract": "Self-supervised models have been shown to produce comparable or better visual\nrepresentations than their supervised counterparts when trained offline on\nunlabeled data at scale. However, their efficacy is catastrophically reduced in\na Continual Learning (CL) scenario where data is presented to the model\nsequentially. In this paper, we show that self-supervised loss functions can be\nseamlessly converted into distillation mechanisms for CL by adding a predictor\nnetwork that maps the current state of the representations to their past state.\nThis enables us to devise a framework for Continual self-supervised visual\nrepresentation Learning that (i) significantly improves the quality of the\nlearned representations, (ii) is compatible with several state-of-the-art\nself-supervised objectives, and (iii) needs little to no hyperparameter tuning.\nWe demonstrate the effectiveness of our approach empirically by training six\npopular self-supervised models in various CL settings.",
    "descriptor": "",
    "authors": [
      "Enrico Fini",
      "Victor G. Turrisi da Costa",
      "Xavier Alameda-Pineda",
      "Elisa Ricci",
      "Karteek Alahari",
      "Julien Mairal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04215"
  },
  {
    "id": "arXiv:2112.04216",
    "title": "Specializing Versatile Skill Libraries using Local Mixture of Experts",
    "abstract": "A long-cherished vision in robotics is to equip robots with skills that match\nthe versatility and precision of humans. For example, when playing table\ntennis, a robot should be capable of returning the ball in various ways while\nprecisely placing it at the desired location. A common approach to model such\nversatile behavior is to use a Mixture of Experts (MoE) model, where each\nexpert is a contextual motion primitive. However, learning such MoEs is\nchallenging as most objectives force the model to cover the entire context\nspace, which prevents specialization of the primitives resulting in rather\nlow-quality components. Starting from maximum entropy reinforcement learning\n(RL), we decompose the objective into optimizing an individual lower bound per\nmixture component. Further, we introduce a curriculum by allowing the\ncomponents to focus on a local context region, enabling the model to learn\nhighly accurate skill representations. To this end, we use local context\ndistributions that are adapted jointly with the expert primitives. Our lower\nbound advocates an iterative addition of new components, where new components\nwill concentrate on local context regions not covered by the current MoE. This\nlocal and incremental learning results in a modular MoE model of high accuracy\nand versatility, where both properties can be scaled by adding more components\non the fly. We demonstrate this by an extensive ablation and on two challenging\nsimulated robot skill learning tasks. We compare our achieved performance to\nLaDiPS and HiREPS, a known hierarchical policy search method for learning\ndiverse skills.",
    "descriptor": "\nComments: published at CoRL 2021 London\n",
    "authors": [
      "Onur Celik",
      "Dongzhuoran Zhou",
      "Ge Li",
      "Philipp Becker",
      "Gerhard Neumann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.04216"
  },
  {
    "id": "arXiv:2112.04219",
    "title": "Learning over All Stabilizing Nonlinear Controllers for a  Partially-Observed Linear System",
    "abstract": "We propose a parameterization of nonlinear output feedback controllers for\nlinear dynamical systems based on a recently developed class of neural network\ncalled the recurrent equilibrium network (REN), and a nonlinear version of the\nYoula parameterization. Our approach guarantees the closed-loop stability of\npartially observable linear dynamical systems without requiring any constraints\nto be satisfied. This significantly simplifies model fitting as any\nunconstrained optimization procedure can be applied whilst still maintaining\nstability. We demonstrate our method on reinforcement learning tasks with both\nexact and approximate gradient methods. Simulation studies show that our method\nis significantly more scalable and significantly outperforms other approaches\nin the same problem setting.",
    "descriptor": "\nComments: submitted to L4DC-2022\n",
    "authors": [
      "Ruigang Wang",
      "Nicholas Barbara",
      "Max Revay",
      "Ian R. Manchester"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.04219"
  },
  {
    "id": "arXiv:2112.04221",
    "title": "Survey of charging scheduling, fleet management, and location planning  of charging stations for electrified demand-responsive transport systems:  methodologies and recent developments",
    "abstract": "The accelerated electrification of transport systems with EVs has brought new\nchallenges for charging scheduling, fleet management, and charging\ninfrastructure location and configuration planning. In this review, we have\nprovided a systematic review of the recent development in strategic, tactical,\nand operational decisions for demand responsive transport system planning using\nelectric vehicles (EV-DRT). We have summarized recent developments in\nmathematical modeling approaches and identified future research directions. A\nlist of existing open-access datasets, numerical test instances, and software\nare provided for future research in EV-DRT and related problems.",
    "descriptor": "",
    "authors": [
      "Tai-Yu Ma",
      "Yumeng Fang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04221"
  },
  {
    "id": "arXiv:2112.04222",
    "title": "Classification-Then-Grounding: Reformulating Video Scene Graphs as  Temporal Bipartite Graphs",
    "abstract": "Today's VidSGG models are all proposal-based methods, i.e., they first\ngenerate numerous paired subject-object snippets as proposals, and then conduct\npredicate classification for each proposal. In this paper, we argue that this\nprevalent proposal-based framework has three inherent drawbacks: 1) The\nground-truth predicate labels for proposals are partially correct. 2) They\nbreak the high-order relations among different predicate instances of a same\nsubject-object pair. 3) VidSGG performance is upper-bounded by the quality of\nthe proposals. To this end, we propose a new classification-then-grounding\nframework for VidSGG, which can avoid all the three overlooked drawbacks.\nMeanwhile, under this framework, we reformulate the video scene graphs as\ntemporal bipartite graphs, where the entities and predicates are two types of\nnodes with time slots, and the edges denote different semantic roles between\nthese nodes. This formulation takes full advantage of our new framework.\nAccordingly, we further propose a novel BIpartite Graph based SGG model: BIG.\nSpecifically, BIG consists of two parts: a classification stage and a grounding\nstage, where the former aims to classify the categories of all the nodes and\nthe edges, and the latter tries to localize the temporal location of each\nrelation instance. Extensive ablations on two VidSGG datasets have attested to\nthe effectiveness of our framework and BIG.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Kaifeng Gao",
      "Long Chen",
      "Yulei Niu",
      "Jian Shao",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.04222"
  },
  {
    "id": "arXiv:2112.04223",
    "title": "Progressive Multi-stage Interactive Training in Mobile Network for  Fine-grained Recognition",
    "abstract": "Fine-grained Visual Classification (FGVC) aims to identify objects from\nsubcategories. It is a very challenging task because of the subtle inter-class\ndifferences. Existing research applies large-scale convolutional neural\nnetworks or visual transformers as the feature extractor, which is extremely\ncomputationally expensive. In fact, real-world scenarios of fine-grained\nrecognition often require a more lightweight mobile network that can be\nutilized offline. However, the fundamental mobile network feature extraction\ncapability is weaker than large-scale models. In this paper, based on the\nlightweight MobilenetV2, we propose a Progressive Multi-Stage Interactive\ntraining method with a Recursive Mosaic Generator (RMG-PMSI). First, we propose\na Recursive Mosaic Generator (RMG) that generates images with different\ngranularities in different phases. Then, the features of different stages pass\nthrough a Multi-Stage Interaction (MSI) module, which strengthens and\ncomplements the corresponding features of different stages. Finally, using the\nprogressive training (P), the features extracted by the model in different\nstages can be fully utilized and fused with each other. Experiments on three\nprestigious fine-grained benchmarks show that RMG-PMSI can significantly\nimprove the performance with good robustness and transferability.",
    "descriptor": "",
    "authors": [
      "Zhenxin Wu",
      "Qingliang Chen",
      "Yifeng Liu",
      "Yinqi Zhang",
      "Chengkai Zhu",
      "Yang Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04223"
  },
  {
    "id": "arXiv:2112.04227",
    "title": "Online Elicitation of Necessarily Optimal Matchings",
    "abstract": "In this paper, we study the problem of eliciting preferences of agents in the\nhouse allocation model. For this we build on a recent model of Hosseini et\nal.[AAAI'21] and focus on the task of eliciting preferences to find matchings\nwhich are necessarily optimal, i.e., optimal under all possible completions of\nthe elicited preferences. In particular, we follow the approach of Hosseini et\nal. and investigate the elicitation of necessarily Pareto optimal (NPO) and\nnecessarily rank-maximal (NRM) matchings. Most importantly, we answer their\nopen question and give an online algorithm for eliciting an NRM matching in the\nnext-best query model which is 3/2-competitive, i.e., it takes at most 3/2 as\nmany queries as an optimal algorithm. Besides this, we extend this field of\nresearch by introducing two new natural models of elicitation and by studying\nboth the complexity of determining whether a necessarily optimal matching\nexists in them, and by giving online algorithms for these models.",
    "descriptor": "\nComments: Accepted at AAAI'22\n",
    "authors": [
      "Jannik Peters"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.04227"
  },
  {
    "id": "arXiv:2112.04228",
    "title": "SimulSLT: End-to-End Simultaneous Sign Language Translation",
    "abstract": "Sign language translation as a kind of technology with profound social\nsignificance has attracted growing researchers' interest in recent years.\nHowever, the existing sign language translation methods need to read all the\nvideos before starting the translation, which leads to a high inference latency\nand also limits their application in real-life scenarios. To solve this\nproblem, we propose SimulSLT, the first end-to-end simultaneous sign language\ntranslation model, which can translate sign language videos into target text\nconcurrently. SimulSLT is composed of a text decoder, a boundary predictor, and\na masked encoder. We 1) use the wait-k strategy for simultaneous translation.\n2) design a novel boundary predictor based on the integrate-and-fire module to\noutput the gloss boundary, which is used to model the correspondence between\nthe sign language video and the gloss. 3) propose an innovative re-encode\nmethod to help the model obtain more abundant contextual information, which\nallows the existing video features to interact fully. The experimental results\nconducted on the RWTH-PHOENIX-Weather 2014T dataset show that SimulSLT achieves\nBLEU scores that exceed the latest end-to-end non-simultaneous sign language\ntranslation model while maintaining low latency, which proves the effectiveness\nof our method.",
    "descriptor": "\nComments: Accepted by ACM Multimedia 2021\n",
    "authors": [
      "Aoxiong Yin",
      "Zhou Zhao",
      "Jinglin Liu",
      "Weike Jin",
      "Meng Zhang",
      "Xingshan Zeng",
      "Xiaofei He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04228"
  },
  {
    "id": "arXiv:2112.04229",
    "title": "Replay For Safety",
    "abstract": "Experience replay \\citep{lin1993reinforcement, mnih2015human} is a widely\nused technique to achieve efficient use of data and improved performance in RL\nalgorithms. In experience replay, past transitions are stored in a memory\nbuffer and re-used during learning. Various suggestions for sampling schemes\nfrom the replay buffer have been suggested in previous works, attempting to\noptimally choose those experiences which will most contribute to the\nconvergence to an optimal policy. Here, we give some conditions on the replay\nsampling scheme that will ensure convergence, focusing on the well-known\nQ-learning algorithm in the tabular setting. After establishing sufficient\nconditions for convergence, we turn to suggest a slightly different usage for\nexperience replay - replaying memories in a biased manner as a means to change\nthe properties of the resulting policy. We initiate a rigorous study of\nexperience replay as a tool to control and modify the properties of the\nresulting policy. In particular, we show that using an appropriate biased\nsampling scheme can allow us to achieve a \\emph{safe} policy. We believe that\nusing experience replay as a biasing mechanism that allows controlling the\nresulting policy in desirable ways is an idea with promising potential for many\napplications.",
    "descriptor": "",
    "authors": [
      "Liran Szlak",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04229"
  },
  {
    "id": "arXiv:2112.04231",
    "title": "Towards automation of threat modeling based on a semantic model of  attack patterns and weaknesses",
    "abstract": "This works considers challenges of building and usage a formal knowledge base\n(model), which unites the ATT&CK, CAPEC, CWE, CVE security enumerations. The\nproposed model can be used to learn relations between attack techniques, attack\npattern, weaknesses, and vulnerabilities in order to build various threat\nlandscapes, in particular, for threat modeling. The model is created as an\nontology with freely available datasets in the OWL and RDF formats. The use of\nontologies is an alternative of structural and graph based approaches to\nintegrate the security enumerations. In this work we consider an approach of\nthreat modeling with the data components of ATT&CK based on the knowledge base\nand an ontology driven threat modeling framework. Also, some evaluations are\nmade, how it can be possible to use the ontological approach of threat modeling\nand which challenges this can be faced.",
    "descriptor": "",
    "authors": [
      "Andrei Brazhuk"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04231"
  },
  {
    "id": "arXiv:2112.04236",
    "title": "Application of Deep Reinforcement Learning to Payment Fraud",
    "abstract": "The large variety of digital payment choices available to consumers today has\nbeen a key driver of e-commerce transactions in the past decade. Unfortunately,\nthis has also given rise to cybercriminals and fraudsters who are constantly\nlooking for vulnerabilities in these systems by deploying increasingly\nsophisticated fraud attacks. A typical fraud detection system employs standard\nsupervised learning methods where the focus is on maximizing the fraud recall\nrate. However, we argue that such a formulation can lead to sub-optimal\nsolutions. The design requirements for these fraud models requires that they\nare robust to the high-class imbalance in the data, adaptive to changes in\nfraud patterns, maintain a balance between the fraud rate and the decline rate\nto maximize revenue, and be amenable to asynchronous feedback since usually\nthere is a significant lag between the transaction and the fraud realization.\nTo achieve this, we formulate fraud detection as a sequential decision-making\nproblem by including the utility maximization within the model in the form of\nthe reward function. The historical decline rate and fraud rate define the\nstate of the system with a binary action space composed of approving or\ndeclining the transaction. In this study, we primarily focus on utility\nmaximization and explore different reward functions to this end. The\nperformance of the proposed Reinforcement Learning system has been evaluated\nfor two publicly available fraud datasets using Deep Q-learning and compared\nwith different classifiers. We aim to address the rest of the issues in future\nwork.",
    "descriptor": "\nComments: Multi-Armed Bandits and Reinforcement Learning: Advancing Decision Making in E-Commerce and Beyond at KDD 2021\n",
    "authors": [
      "Siddharth Vimal",
      "Kanishka Kayathwal",
      "Hardik Wadhwa",
      "Gaurav Dhama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04236"
  },
  {
    "id": "arXiv:2112.04244",
    "title": "Faster Algorithms for $k$-Subset Sum and Variations",
    "abstract": "We present new, faster pseudopolynomial time algorithms for the $k$-Subset\nSum problem, defined as follows: given a set $Z$ of $n$ positive integers and\n$k$ targets $t_1, \\ldots, t_k$, determine whether there exist $k$ disjoint\nsubsets $Z_1,\\dots,Z_k \\subseteq Z$, such that $\\Sigma(Z_i) = t_i$, for $i = 1,\n\\ldots, k$. Assuming $t = \\max \\{ t_1, \\ldots, t_k \\}$ is the maximum among the\ngiven targets, a standard dynamic programming approach based on Bellman's\nalgorithm [Bell57] can solve the problem in $O(n t^k)$ time. We build upon\nrecent advances on Subset Sum due to Koiliaris and Xu [Koil19] and Bringmann\n[Brin17] in order to provide faster algorithms for $k$-Subset Sum. We devise\ntwo algorithms: a deterministic one of time complexity $\\tilde{O}(n^{k / (k+1)}\nt^k)$ and a randomised one of $\\tilde{O}(n + t^k)$ complexity. We further\ndemonstrate how these algorithms can be used in order to cope with variations\nof $k$-Subset Sum, namely Subset Sum Ratio, $k$-Subset Sum Ratio and Multiple\nSubset Sum.",
    "descriptor": "\nComments: A preliminary version of this paper was presented at the 15th International Workshop on Frontiers in Algorithmics (FAW 2021)\n",
    "authors": [
      "Antonis Antonopoulos",
      "Aris Pagourtzis",
      "Stavros Petsalakis",
      "Manolis Vasilakis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.04244"
  },
  {
    "id": "arXiv:2112.04246",
    "title": "Information fractal dimension of mass function",
    "abstract": "Fractal plays an important role in nonlinear science. The most important\nparameter to model fractal is fractal dimension. Existing information dimension\ncan calculate the dimension of probability distribution. However, given a mass\nfunction which is the generalization of probability distribution, how to\ndetermine its fractal dimension is still an open problem of immense interest.\nThe main contribution of this work is to propose an information fractal\ndimension of mass function. Numerical examples are illustrated to show the\neffectiveness of our proposed dimension. We discover an important property in\nthat the dimension of mass function with the maximum Deng entropy is\n$\\frac{ln3}{ln2}\\approx 1.585$, which is the well-known fractal dimension of\nSierpi\\'nski triangle.",
    "descriptor": "",
    "authors": [
      "Chenhui Qiang",
      "Yong Deng",
      "Kang Hao Cheong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.04246"
  },
  {
    "id": "arXiv:2112.04251",
    "title": "FRETting about Requirements: Formalised Requirements for an Aircraft  Engine Controller",
    "abstract": "[Context & motivation] Eliciting requirements that are detailed and logical\nenough to be amenable to formal verification is a difficult task. Multiple\ntools exist for requirements elicitation and some of these also support\nformalisation of requirements in a way that is useful for formal methods.\n[Question/problem] This paper reports on our experience of using the FRET\nalongside our industrial partner. The use case that we investigate is an\naircraft engine controller. In this context, we evaluate the use of FRET to\nbridge the communication gap between formal methods experts and aerospace\nindustry specialists. [Principal ideas/results] We describe our journey from\nambiguous, natural-language requirements to concise, formalised FRET\nrequirements. We include our analysis of the formalised requirements from the\nperspective of patterns, translation into other formal methods and the\nrelationship between parent-child requirements in this set. We also provide\ninsight into lessons learned throughout this process and identify future\nimprovements to FRET. [Contribution] Previous experience reports have been\npublished by the FRET team, but this is the first such report of an industrial\nuse case that was written by researchers that have not been involved FRET's\ndevelopment.",
    "descriptor": "\nComments: 22 pages, 3 figures\n",
    "authors": [
      "Marie Farrell",
      "Matt Luckcuck",
      "Oisin Sheridan",
      "Rosemary Monahan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.04251"
  },
  {
    "id": "arXiv:2112.04255",
    "title": "Feature matching for multi-epoch historical aerial images",
    "abstract": "Historical imagery is characterized by high spatial resolution and\nstereo-scopic acquisitions, providing a valuable resource for recovering 3D\nland-cover information. Accurate geo-referencing of diachronic historical\nimages by means of self-calibration remains a bottleneck because of the\ndifficulty to find sufficient amount of feature correspondences under evolving\nlandscapes. In this research, we present a fully automatic approach to\ndetecting feature correspondences between historical images taken at different\ntimes (i.e., inter-epoch), without auxiliary data required. Based on relative\norientations computed within the same epoch (i.e., intra-epoch), we obtain DSMs\n(Digital Surface Model) and incorporate them in a rough-to-precise matching.\nThe method consists of: (1) an inter-epoch DSMs matching to roughly co-register\nthe orientations and DSMs (i.e, the 3D Helmert transformation), followed by (2)\na precise inter-epoch feature matching using the original RGB images. The\ninnate ambiguity of the latter is largely alleviated by narrowing down the\nsearch space using the co-registered data. With the inter-epoch features, we\nrefine the image orientations and quantitatively evaluate the results (1) with\nDoD (Difference of DSMs), (2) with ground check points, and (3) by quantifying\nground displacement due to an earthquake. We demonstrate that our method: (1)\ncan automatically georeference diachronic historical images; (2) can\neffectively mitigate systematic errors induced by poorly estimated camera\nparameters; (3) is robust to drastic scene changes. Compared to the\nstate-of-the-art, our method improves the image georeferencing accuracy by a\nfactor of 2. The proposed methods are implemented in MicMac, a free,\nopen-source photogrammetric software.",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Lulin Zhang",
      "Ewelina Rupnik",
      "Marc Pierrot-Deseilligny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04255"
  },
  {
    "id": "arXiv:2112.04257",
    "title": "Tutorial on communication between access networks and the 5G core",
    "abstract": "Fifth-generation (5G) networks enable a variety of use cases, e.g.,\nUltra-Reliable and Low-Latency Communications, enhanced Mobile Broadband, and\nmassive Machine Type Communication. To explore the full potential of these use\ncases, it is mandatory to understand the communication between User Equipment\n(UE), Radio Access Network (RAN), and 5G Core (5GC), which support new network\nconcepts and paradigms. For example, network slicing plays a crucial role in\nthe communication system to address the challenges expected by the 5G networks.\n3rd Generation Partnership Project has recently published Release 16, including\nthe protocols used to communicate between RANs and 5GC, i.e., Non-Access\nStratum (NAS) and NG Application Protocol (NGAP). The main goal of this article\nis to present a comprehensive tutorial about NAS and NGAP specifications using\na didactic and practical approach. The tutorial describes the protocol stacks\nand aspects of the functionality of these protocols in 5G networks, such as\nauthentication and identification procedures, data session establishment, and\nallocation of resources. Moreover, we review message flows related to these\nprotocols in UE and Next Generation Node B (gNodeB) registration. To illustrate\nthe concepts presented in the tutorial, we introduce a 5GC tester that\nimplements NAS and NGAP for availing of three open-source 5GC projects on a\nblack-box testing methodology.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Lucas Baleeiro Dominato",
      "Henrique Carvalho de Resende",
      "Cristiano Bonato Both",
      "Johann M. Marquez-Barja",
      "Bruno O. Silvestre",
      "Kleber V. Cardoso"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.04257"
  },
  {
    "id": "arXiv:2112.04261",
    "title": "Efficient Batch Homomorphic Encryption for Vertically Federated XGBoost",
    "abstract": "More and more orgainizations and institutions make efforts on using external\ndata to improve the performance of AI services. To address the data privacy and\nsecurity concerns, federated learning has attracted increasing attention from\nboth academia and industry to securely construct AI models across multiple\nisolated data providers. In this paper, we studied the efficiency problem of\nadapting widely used XGBoost model in real-world applications to vertical\nfederated learning setting. State-of-the-art vertical federated XGBoost\nframeworks requires large number of encryption operations and ciphertext\ntransmissions, which makes the model training much less efficient than training\nXGBoost models locally. To bridge this gap, we proposed a novel batch\nhomomorphic encryption method to cut the cost of encryption-related computation\nand transmission in nearly half. This is achieved by encoding the first-order\nderivative and the second-order derivative into a single number for encryption,\nciphertext transmission, and homomorphic addition operations. The sum of\nmultiple first-order derivatives and second-order derivatives can be\nsimultaneously decoded from the sum of encoded values. We are motivated by the\nbatch idea in the work of BatchCrypt for horizontal federated learning, and\ndesign a novel batch method to address the limitations of allowing quite few\nnumber of negative numbers. The encode procedure of the proposed batch method\nconsists of four steps, including shifting, truncating, quantizing and\nbatching, while the decoding procedure consists of de-quantization and shifting\nback. The advantages of our method are demonstrated through theoretical\nanalysis and extensive numerical experiments.",
    "descriptor": "",
    "authors": [
      "Wuxing Xu",
      "Hao Fan",
      "Kaixin Li",
      "Kai Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04261"
  },
  {
    "id": "arXiv:2112.04263",
    "title": "Artificial Intelligence Powered Mobile Networks: From Cognition to  Decision",
    "abstract": "Mobile networks (MN) are anticipated to provide unprecedented opportunities\nto enable a new world of connected experiences and radically shift the way\npeople interact with everything. MN are becoming more and more complex, driven\nby ever-increasingly complicated configuration issues and blossoming new\nservice requirements. This complexity poses significant challenges in\ndeployment, management, operation, optimization, and maintenance, since they\nrequire a complete understanding and cognition of MN. Artificial intelligence\n(AI), which deals with the simulation of intelligent behavior in computers, has\ndemonstrated enormous success in many application domains, suggesting its\npotential in cognizing the state of MN and making intelligent decisions. In\nthis paper, we first propose an AI-powered mobile network architecture and\ndiscuss challenges in terms of cognition complexity, decisions with\nhigh-dimensional action space, and self-adaption to system dynamics. Then,\npotential solutions that are associated with AI are discussed. Finally, we\npropose a deep learning approach that directly maps the state of MN to\nperceived QoS, integrating cognition with the decision. Our proposed approach\nhelps operators in making more intelligent decisions to guarantee QoS.\nMeanwhile, the effectiveness and advantages of our proposed approach are\ndemonstrated on a real-world dataset, involving $31261$ users over $77$\nstations within $5$ days.",
    "descriptor": "",
    "authors": [
      "Guiyang Luo",
      "Quan Yuan",
      "Jinglin Li",
      "Shangguang Wang",
      "Fangchun Yang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.04263"
  },
  {
    "id": "arXiv:2112.04271",
    "title": "RLBWT Tricks",
    "abstract": "Experts would probably have guessed that compressed sparse bitvectors were an\nessential component of pan-genomic indexes based on the run-length compressed\nBurrows-Wheeler Transform -- until Nishimoto and Tabei (2021) recently showed\nhow to replace them. In this paper we experimentally demonstrate the\npracticality of part of their result and adapt fractional cascading to obtain a\nsimilar result for the positional Burrows-Wheeler Transform.",
    "descriptor": "",
    "authors": [
      "Nathaniel K. Brown",
      "Travis Gagie",
      "Massimiliano Rossi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.04271"
  },
  {
    "id": "arXiv:2112.04274",
    "title": "On the Use of Unrealistic Predictions in Hundreds of Papers Evaluating  Graph Representations",
    "abstract": "Prediction using the ground truth sounds like an oxymoron in machine\nlearning. However, such an unrealistic setting was used in hundreds, if not\nthousands of papers in the area of finding graph representations. To evaluate\nthe multi-label problem of node classification by using the obtained\nrepresentations, many works assume in the prediction stage that the number of\nlabels of each test instance is known. In practice such ground truth\ninformation is rarely available, but we point out that such an inappropriate\nsetting is now ubiquitous in this research area. We detailedly investigate why\nthe situation occurs. Our analysis indicates that with unrealistic information,\nthe performance is likely over-estimated. To see why suitable predictions were\nnot used, we identify difficulties in applying some multi-label techniques. For\nthe use in future studies, we propose simple and effective settings without\nusing practically unknown information. Finally, we take this chance to conduct\na fair and serious comparison of major graph-representation learning methods on\nmulti-label node classification.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Li-Chung Lin",
      "Cheng-Hung Liu",
      "Chih-Ming Chen",
      "Kai-Chin Hsu",
      "I-Feng Wu",
      "Ming-Feng Tsai",
      "Chih-Jen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04274"
  },
  {
    "id": "arXiv:2112.04278",
    "title": "DMRVisNet: Deep Multi-head Regression Network for Pixel-wise Visibility  Estimation Under Foggy Weather",
    "abstract": "Scene perception is essential for driving decision-making and traffic safety.\nHowever, fog, as a kind of common weather, frequently appears in the real\nworld, especially in the mountain areas, making it difficult to accurately\nobserve the surrounding environments. Therefore, precisely estimating the\nvisibility under foggy weather can significantly benefit traffic management and\nsafety. To address this, most current methods use professional instruments\noutfitted at fixed locations on the roads to perform the visibility\nmeasurement; these methods are expensive and less flexible. In this paper, we\npropose an innovative end-to-end convolutional neural network framework to\nestimate the visibility leveraging Koschmieder's law exclusively using the\nimage data. The proposed method estimates the visibility by integrating the\nphysical model into the proposed framework, instead of directly predicting the\nvisibility value via the convolutional neural work. Moreover, we estimate the\nvisibility as a pixel-wise visibility map against those of previous visibility\nmeasurement methods which solely predict a single value for an entire image.\nThus, the estimated result of our method is more informative, particularly in\nuneven fog scenarios, which can benefit to developing a more precise early\nwarning system for foggy weather, thereby better protecting the intelligent\ntransportation infrastructure systems and promoting its development. To\nvalidate the proposed framework, a virtual dataset, FACI, containing 3,000\nfoggy images in different concentrations, is collected using the AirSim\nplatform. Detailed experiments show that the proposed method achieves\nperformance competitive to those of state-of-the-art methods.",
    "descriptor": "\nComments: 8 figures\n",
    "authors": [
      "Jing You",
      "Shaocheng Jia",
      "Xin Pei",
      "Danya Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04278"
  },
  {
    "id": "arXiv:2112.04282",
    "title": "Radar Occupancy Prediction with Lidar Supervision while Preserving  Long-Range Sensing and Penetrating Capabilities",
    "abstract": "Radar shows great potential for autonomous driving by accomplishing\nlong-range sensing under diverse weather conditions. But radar is also a\nparticularly challenging sensing modality due to the radar noises. Recent works\nhave made enormous progress in classifying free and occupied spaces in radar\nimages by leveraging lidar label supervision. However, there are still several\nunsolved issues. Firstly, the sensing distance of the results is limited by the\nsensing range of lidar. Secondly, the performance of the results is degenerated\nby lidar due to the physical sensing discrepancies between the two sensors. For\nexample, some objects visible to lidar are invisible to radar, and some objects\noccluded in lidar scans are visible in radar images because of the radar's\npenetrating capability. These sensing differences cause false positive and\npenetrating capability degeneration, respectively.\nIn this paper, we propose training data preprocessing and polar sliding\nwindow inference to solve the issues. The data preprocessing aims to reduce the\neffect caused by radar-invisible measurements in lidar scans. The polar sliding\nwindow inference aims to solve the limited sensing range issue by applying a\nnear-range trained network to the long-range region. Instead of using common\nCartesian representation, we propose to use polar representation to reduce the\nshape dissimilarity between long-range and near-range data. We find that\nextending a near-range trained network to long-range region inference in the\npolar space has 4.2 times better IoU than in Cartesian space. Besides, the\npolar sliding window inference can preserve the radar penetrating capability by\nchanging the viewpoint of the inference region, which makes some occluded\nmeasurements seem non-occluded for a pretrained network.",
    "descriptor": "",
    "authors": [
      "Pou-Chun Kung",
      "Chieh-Chih Wang",
      "Wen-Chieh Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04282"
  },
  {
    "id": "arXiv:2112.04283",
    "title": "Adverse Weather Image Translation with Asymmetric and Uncertainty-aware  GAN",
    "abstract": "Adverse weather image translation belongs to the unsupervised image-to-image\n(I2I) translation task which aims to transfer adverse condition domain (eg,\nrainy night) to standard domain (eg, day). It is a challenging task because\nimages from adverse domains have some artifacts and insufficient information.\nRecently, many studies employing Generative Adversarial Networks (GANs) have\nachieved notable success in I2I translation but there are still limitations in\napplying them to adverse weather enhancement. Symmetric architecture based on\nbidirectional cycle-consistency loss is adopted as a standard framework for\nunsupervised domain transfer methods. However, it can lead to inferior\ntranslation result if the two domains have imbalanced information. To address\nthis issue, we propose a novel GAN model, i.e., AU-GAN, which has an asymmetric\narchitecture for adverse domain translation. We insert a proposed feature\ntransfer network (${T}$-net) in only a normal domain generator (i.e., rainy\nnight-> day) to enhance encoded features of the adverse domain image. In\naddition, we introduce asymmetric feature matching for disentanglement of\nencoded features. Finally, we propose uncertainty-aware cycle-consistency loss\nto address the regional uncertainty of a cyclic reconstructed image. We\ndemonstrate the effectiveness of our method by qualitative and quantitative\ncomparisons with state-of-the-art models. Codes are available at\nhttps://github.com/jgkwak95/AU-GAN.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Jeong-gi Kwak",
      "Youngsaeng Jin",
      "Yuanming Li",
      "Dongsik Yoon",
      "Donghyeon Kim",
      "Hanseok Ko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.04283"
  },
  {
    "id": "arXiv:2112.04286",
    "title": "TempAMLSI : Temporal Action Model Learning based on Grammar Induction",
    "abstract": "Hand-encoding PDDL domains is generally accepted as difficult, tedious and\nerror-prone. The difficulty is even greater when temporal domains have to be\nencoded. Indeed, actions have a duration and their effects are not\ninstantaneous. In this paper, we present TempAMLSI, an algorithm based on the\nAMLSI approach able to learn temporal domains. TempAMLSI is based on the\nclassical assumption done in temporal planning that it is possible to convert a\nnon-temporal domain into a temporal domain. TempAMLSI is the first approach\nable to learn temporal domain with single hard envelope and Cushing's\nintervals. We show experimentally that TempAMLSI is able to learn accurate\ntemporal domains, i.e., temporal domain that can be used directly to solve new\nplanning problem, with different forms of action concurrency.",
    "descriptor": "\nComments: Proceedings of the International workshop of Knowledge Engineering for Planning and Scheduling (ICAPS), 2021\n",
    "authors": [
      "Maxence Grand",
      "Damien Pellier",
      "Humbert Fiorino"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04286"
  },
  {
    "id": "arXiv:2112.04288",
    "title": "Non parametric estimation of causal populations in a counterfactual  scenario",
    "abstract": "In causality, estimating the effect of a treatment without confounding\ninference remains a major issue because requires to assess the outcome in both\ncase with and without treatment. Not being able to observe simultaneously both\nof them, the estimation of potential outcome remains a challenging task. We\npropose an innovative approach where the problem is reformulated as a missing\ndata model. The aim is to estimate the hidden distribution of \\emph{causal\npopulations}, defined as a function of treatment and outcome. A Causal\nAuto-Encoder (CAE), enhanced by a prior dependent on treatment and outcome\ninformation, assimilates the latent space to the probability distribution of\nthe target populations. The features are reconstructed after being reduced to a\nlatent space and constrained by a mask introduced in the intermediate layer of\nthe network, containing treatment and outcome information.",
    "descriptor": "",
    "authors": [
      "Celine Beji",
      "Florian Yger",
      "Jamal Atif"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.04288"
  },
  {
    "id": "arXiv:2112.04289",
    "title": "iRoPro: An interactive Robot Programming Framework",
    "abstract": "The great diversity of end-user tasks ranging from manufacturing environments\nto personal homes makes pre-programming robots for general purpose applications\nextremely challenging. In fact, teaching robots new actions from scratch that\ncan be reused for previously unseen tasks remains a difficult challenge and is\ngenerally left up to robotics experts. In this work, we present iRoPro, an\ninteractive Robot Programming framework that allows end-users with little to no\ntechnical background to teach a robot new reusable actions. We combine\nProgramming by Demonstration and Automated Planning techniques to allow the\nuser to construct the robot's knowledge base by teaching new actions by\nkinesthetic demonstration. The actions are generalised and reused with a task\nplanner to solve previously unseen problems defined by the user. We implement\niRoPro as an end-to-end system on a Baxter Research Robot to simultaneously\nteach low- and high-level actions by demonstration that the user can customise\nvia a Graphical User Interface to adapt to their specific use case. To evaluate\nthe feasibility of our approach, we first conducted pre-design experiments to\nbetter understand the user's adoption of involved concepts and the proposed\nrobot programming process. We compare results with post-design experiments,\nwhere we conducted a user study to validate the usability of our approach with\nreal end-users. Overall, we showed that users with different programming levels\nand educational backgrounds can easily learn and use iRoPro and its robot\nprogramming process.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.14342\n",
    "authors": [
      "Ying Siu Liang",
      "Damien Pellier",
      "Humbert Fiorino",
      "Sylvie Pesty"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04289"
  },
  {
    "id": "arXiv:2112.04291",
    "title": "FastSGD: A Fast Compressed SGD Framework for Distributed Machine  Learning",
    "abstract": "With the rapid increase of big data, distributed Machine Learning (ML) has\nbeen widely applied in training large-scale models. Stochastic Gradient Descent\n(SGD) is arguably the workhorse algorithm of ML. Distributed ML models trained\nby SGD involve large amounts of gradient communication, which limits the\nscalability of distributed ML. Thus, it is important to compress the gradients\nfor reducing communication. In this paper, we propose FastSGD, a Fast\ncompressed SGD framework for distributed ML. To achieve a high compression\nratio at a low cost, FastSGD represents the gradients as key-value pairs, and\ncompresses both the gradient keys and values in linear time complexity. For the\ngradient value compression, FastSGD first uses a reciprocal mapper to transform\noriginal values into reciprocal values, and then, it utilizes a logarithm\nquantization to further reduce reciprocal values to small integers. Finally,\nFastSGD filters reduced gradient integers by a given threshold. For the\ngradient key compression, FastSGD provides an adaptive fine-grained delta\nencoding method to store gradient keys with fewer bits. Extensive experiments\non practical ML models and datasets demonstrate that FastSGD achieves the\ncompression ratio up to 4 orders of magnitude, and accelerates the convergence\ntime up to 8x, compared with state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Keyu Yang",
      "Lu Chen",
      "Zhihao Zeng",
      "Yunjun Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.04291"
  },
  {
    "id": "arXiv:2112.04294",
    "title": "A Hierarchical Spatio-Temporal Graph Convolutional Neural Network for  Anomaly Detection in Videos",
    "abstract": "Deep learning models have been widely used for anomaly detection in\nsurveillance videos. Typical models are equipped with the capability to\nreconstruct normal videos and evaluate the reconstruction errors on anomalous\nvideos to indicate the extent of abnormalities. However, existing approaches\nsuffer from two disadvantages. Firstly, they can only encode the movements of\neach identity independently, without considering the interactions among\nidentities which may also indicate anomalies. Secondly, they leverage\ninflexible models whose structures are fixed under different scenes, this\nconfiguration disables the understanding of scenes. In this paper, we propose a\nHierarchical Spatio-Temporal Graph Convolutional Neural Network (HSTGCNN) to\naddress these problems, the HSTGCNN is composed of multiple branches that\ncorrespond to different levels of graph representations. High-level graph\nrepresentations encode the trajectories of people and the interactions among\nmultiple identities while low-level graph representations encode the local body\npostures of each person. Furthermore, we propose to weightedly combine multiple\nbranches that are better at different scenes. An improvement over single-level\ngraph representations is achieved in this way. An understanding of scenes is\nachieved and serves anomaly detection. High-level graph representations are\nassigned higher weights to encode moving speed and directions of people in\nlow-resolution videos while low-level graph representations are assigned higher\nweights to encode human skeletons in high-resolution videos. Experimental\nresults show that the proposed HSTGCNN significantly outperforms current\nstate-of-the-art models on four benchmark datasets (UCSD Pedestrian,\nShanghaiTech, CUHK Avenue and IITB-Corridor) by using much less learnable\nparameters.",
    "descriptor": "",
    "authors": [
      "Xianlin Zeng",
      "Yalong Jiang",
      "Wenrui Ding",
      "Hongguang Li",
      "Yafeng Hao",
      "Zifeng Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04294"
  },
  {
    "id": "arXiv:2112.04298",
    "title": "GCA-Net : Utilizing Gated Context Attention for Improving Image Forgery  Localization and Detection",
    "abstract": "Forensic analysis depends on the identification of hidden traces from\nmanipulated images. Traditional neural networks fail in this task because of\ntheir inability in handling feature attenuation and reliance on the dominant\nspatial features. In this work we propose a novel Gated Context Attention\nNetwork (GCA-Net) that utilizes the non-local attention block for global\ncontext learning. Additionally, we utilize a gated attention mechanism in\nconjunction with a dense decoder network to direct the flow of relevant\nfeatures during the decoding phase, allowing for precise localization. The\nproposed attention framework allows the network to focus on relevant regions by\nfiltering the coarse features. Furthermore, by utilizing multi-scale feature\nfusion and efficient learning strategies, GCA-Net can better handle the scale\nvariation of manipulated regions. We show that our method outperforms\nstate-of-the-art networks by an average of 4.2%-5.4% AUC on multiple benchmark\ndatasets. Lastly, we also conduct extensive ablation experiments to demonstrate\nthe method's robustness for image forensics.",
    "descriptor": "",
    "authors": [
      "Sowmen Das",
      "Md. Saiful Islam",
      "Md. Ruhul Amin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04298"
  },
  {
    "id": "arXiv:2112.04299",
    "title": "On the use of Anderson acceleration in hierarchical control",
    "abstract": "This paper investigates the use of fixed-point Anderson acceleration method\n(AA) to a recently proposed hierarchical control framework. Due to its\nmodel-free property, the AA-based resulting hierarchical framework becomes more\ngeneric since no mathematical model of the subsystems at the lower layer is\nrequired at the upper coordinator layer. Numerical results are proposed to\nevaluate the effectiveness of this approach. The paper also presents a modified\nversion of the original hierarchical approach that involves the AA in\nhierarchical control.",
    "descriptor": "",
    "authors": [
      "Xuan-Huy Pham",
      "Mazen Alamir",
      "Fran\u00e7ois Bonne",
      "Patrick Bonnay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04299"
  },
  {
    "id": "arXiv:2112.04302",
    "title": "Rational-based model order reduction of Helmholtz frequency response  problems with adaptive finite element snapshots",
    "abstract": "We introduce several spatially adaptive model order reduction approaches\ntailored to non-coercive elliptic boundary value problems, specifically,\nparametric-in-frequency Helmholtz problems. The offline information is computed\nby means of adaptive finite elements, so that each snapshot lives on a\ndifferent discrete space that resolves the local singularities of the solution\nand is adjusted to the considered frequency value. A rational surrogate is then\nassembled adopting either a least-squares or an interpolatory approach,\nyielding the standard rational interpolation method (SRI), a vector- or\nfunction-valued version of it ($\\mathcal{V}$-SRI), and the minimal rational\ninterpolation method (MRI). In the context of building an approximation for\nlinear or quadratic functionals of the Helmholtz solution, we perform several\nnumerical experiments to compare the proposed methodologies. Our simulations\nshow that, for interior resonant problems (whose singularities are encoded by\npoles on the real axis), the spatially adaptive $\\mathcal{V}$-SRI and MRI work\ncomparably well. Instead, when dealing with exterior scattering problems, whose\nfrequency response is mostly smooth, the $\\mathcal{V}$-SRI method seems to be\nthe best-performing one.",
    "descriptor": "",
    "authors": [
      "Francesca Bonizzoni",
      "Davide Pradovera",
      "Michele Ruggeri"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.04302"
  },
  {
    "id": "arXiv:2112.04310",
    "title": "Cyber-Security Investment in the Context of Disruptive Technologies:  Extension of the Gordon-Loeb Model",
    "abstract": "Cyber-security breaches inflict significant costs on organizations. Hence,\nthe development of an information-systems defense capability through\ncyber-security investment is a prerequisite. The question of how to determine\nthe optimal amount to invest in cyber-security has been widely investigated in\nthe literature. In this respect, the Gordon-Loeb model and its extensions\nreceived wide-scale acceptance. However, such models predominantly rely on\nrestrictive assumptions that are not adapted for analyzing dynamic aspects of\ncyber-security investment. Yet, understanding such dynamic aspects is a key\nfeature for studying cyber-security investment in the context of a fast-paced\nand continuously evolving technological landscape. We propose an extension of\nthe Gordon-Loeb model by considering multi-period and relaxing the assumption\nof a continuous security-breach probability function. Such theoretical\nadaptations enable to capture dynamic aspects of cyber-security investment such\nas the advent of a disruptive technology and its investment consequences. Such\na proposed extension of the Gordon-Loeb model gives room for a hypothetical\ndecrease of the optimal level of cyber-security investment, due to a potential\ntechnological shift. While we believe our framework should be generalizable\nacross the cyber-security milieu, we illustrate our approach in the context of\ncritical-infrastructure protection, where security-cost reductions related to\nrisk events are of paramount importance as potential losses reach unaffordable\nproportions. Moreover, despite the fact that some technologies are considered\nas disruptive and thus promising for critical-infrastructure protection, their\neffects on cyber-security investment have been discussed little.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Dimitri Percia David",
      "Alain Mermoud",
      "S\u00e9bastien Gillard"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2112.04310"
  },
  {
    "id": "arXiv:2112.04312",
    "title": "Geometry-Guided Progressive NeRF for Generalizable and Efficient Neural  Human Rendering",
    "abstract": "In this work we develop a generalizable and efficient Neural Radiance Field\n(NeRF) pipeline for high-fidelity free-viewpoint human body synthesis under\nsettings with sparse camera views. Though existing NeRF-based methods can\nsynthesize rather realistic details for human body, they tend to produce poor\nresults when the input has self-occlusion, especially for unseen humans under\nsparse views. Moreover, these methods often require a large number of sampling\npoints for rendering, which leads to low efficiency and limits their real-world\napplicability. To address these challenges, we propose a Geometry-guided\nProgressive NeRF~(GP-NeRF). In particular, to better tackle self-occlusion, we\ndevise a geometry-guided multi-view feature integration approach that utilizes\nthe estimated geometry prior to integrate the incomplete information from input\nviews and construct a complete geometry volume for the target human body.\nMeanwhile, for achieving higher rendering efficiency, we introduce a\ngeometry-guided progressive rendering pipeline, which leverages the geometric\nfeature volume and the predicted density values to progressively reduce the\nnumber of sampling points and speed up the rendering process. Experiments on\nthe ZJU-MoCap and THUman datasets show that our method outperforms the\nstate-of-the-arts significantly across multiple generalization settings, while\nthe time cost is reduced >70% via applying our efficient progressive rendering\npipeline.",
    "descriptor": "",
    "authors": [
      "Mingfei Chen",
      "Jianfeng Zhang",
      "Xiangyu Xu",
      "Lijuan Liu",
      "Jiashi Feng",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.04312"
  },
  {
    "id": "arXiv:2112.04314",
    "title": "Trainability for Universal GNNs Through Surgical Randomness",
    "abstract": "Message passing neural networks (MPNN) have provable limitations, which can\nbe overcome by universal networks. However, universal networks are typically\nimpractical. The only exception is random node initialization (RNI), a data\naugmentation method that results in provably universal networks. Unfortunately,\nRNI suffers from severe drawbacks such as slow convergence and high sensitivity\nto changes in hyperparameters. We transfer powerful techniques from the\npractical world of graph isomorphism testing to MPNNs, resolving these\ndrawbacks. This culminates in individualization-refinement node initialization\n(IRNI). We replace the indiscriminate and haphazard randomness used in RNI by a\nsurgical incision of only a few random bits at well-selected nodes. Our novel\nnon-intrusive data-augmentation scheme maintains the networks' universality\nwhile resolving the trainability issues. We formally prove the claimed\nuniversality and corroborate experimentally -- on synthetic benchmarks sets\npreviously explicitly designed for that purpose -- that IRNI overcomes the\nlimitations of MPNNs. We also verify the practical efficacy of our approach on\nthe standard benchmark data sets PROTEINS and NCI1.",
    "descriptor": "",
    "authors": [
      "Billy Joe Franks",
      "Markus Anders",
      "Marius Kloft",
      "Pascal Schweitzer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04314"
  },
  {
    "id": "arXiv:2112.04319",
    "title": "Improving the Training of Graph Neural Networks with Consistency  Regularization",
    "abstract": "Graph neural networks (GNNs) have achieved notable success in the\nsemi-supervised learning scenario. The message passing mechanism in graph\nneural networks helps unlabeled nodes gather supervision signals from their\nlabeled neighbors. In this work, we investigate how consistency regularization,\none of widely adopted semi-supervised learning methods, can help improve the\nperformance of graph neural networks. We revisit two methods of consistency\nregularization for graph neural networks. One is simple consistency\nregularization (SCR), and the other is mean-teacher consistency regularization\n(MCR). We combine the consistency regularization methods with two\nstate-of-the-art GNNs and conduct experiments on the ogbn-products dataset.\nWith the consistency regularization, the performance of state-of-the-art GNNs\ncan be improved by 0.3% on the ogbn-products dataset of Open Graph Benchmark\n(OGB) both with and without external data.",
    "descriptor": "",
    "authors": [
      "Chenhui Zhang",
      "Yufei He",
      "Yukuo Cen",
      "Zhenyu Hou",
      "Jie Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04319"
  },
  {
    "id": "arXiv:2112.04321",
    "title": "Splitting schemes for the semi-linear wave equation with dynamic  boundary conditions",
    "abstract": "This paper introduces novel splitting schemes of first and second order for\nthe wave equation with kinetic and acoustic boundary conditions of semi-linear\ntype. For kinetic boundary conditions, we propose a reinterpretation of the\nsystem equations as a coupled system. This means that the bulk and surface\ndynamics are modeled separately and connected through a coupling constraint.\nThis allows the implementation of splitting schemes, which show first-order\nconvergence in numerical experiments. On the other hand, acoustic boundary\nconditions naturally separate bulk and surface dynamics. Here, Lie and Strang\nsplitting schemes reach first- and second-order convergence, respectively, as\nwe reveal numerically.",
    "descriptor": "",
    "authors": [
      "Robert Altmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.04321"
  },
  {
    "id": "arXiv:2112.04323",
    "title": "Contrastive Learning with Large Memory Bank and Negative Embedding  Subtraction for Accurate Copy Detection",
    "abstract": "Copy detection, which is a task to determine whether an image is a modified\ncopy of any image in a database, is an unsolved problem. Thus, we addressed\ncopy detection by training convolutional neural networks (CNNs) with\ncontrastive learning. Training with a large memory-bank and hard data\naugmentation enables the CNNs to obtain more discriminative representation. Our\nproposed negative embedding subtraction further boosts the copy detection\naccuracy. Using our methods, we achieved 1st place in the Facebook AI Image\nSimilarity Challenge: Descriptor Track. Our code is publicly available here:\n\\url{https://github.com/lyakaap/ISC21-Descriptor-Track-1st}",
    "descriptor": "",
    "authors": [
      "Shuhei Yokoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04323"
  },
  {
    "id": "arXiv:2112.04324",
    "title": "Deep Learning and Mathematical Intuition: A Review of (Davies et al.  2021)",
    "abstract": "A recent paper by Davies et al (2021) describes how deep learning (DL)\ntechnology was used to find plausible hypotheses that have led to two original\nmathematical results: one in knot theory, one in representation theory. I argue\nhere that the significance and novelty of this application of DL technology to\nmathematics is significantly overstated in the paper under review and has been\nwildly overstated in some of the accounts in the popular science press. In the\nknot theory result, the role of DL was small, and a conventional statistical\nanalysis would probably have sufficed. In the representation theory result, the\nrole of DL is much larger; however, it is not very different in kind from what\nhas been done in experimental mathematics for decades. Moreover, it is not\nclear whether the distinctive features of DL that make it useful here will\napply across a wide range of mathematical problems. Finally, I argue that the\nDL here \"guides human intuition\" is unhelpful and misleading; what the DL does\nprimarily does is to mark many possible conjectures as false and a few others\nas possibly worthy of study.\nCertainly the representation theory result represents an original and\ninteresting application of DL to mathematical research, but its larger\nsignificance is uncertain.",
    "descriptor": "",
    "authors": [
      "Ernest Davis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "History and Overview (math.HO)"
    ],
    "url": "https://arxiv.org/abs/2112.04324"
  },
  {
    "id": "arXiv:2112.04325",
    "title": "A PTAS for the Min-Max Euclidean Multiple TSP",
    "abstract": "We present a polynomial-time approximation scheme (PTAS) for the min-max\nmultiple TSP problem in Euclidean space, where multiple traveling salesmen are\ntasked with visiting a set of $n$ points and the objective is to minimize the\nmaximum tour length. For an arbitrary $\\varepsilon > 0$, our PTAS achieves a\n$(1 + \\varepsilon)$-approximation in time $O \\big(n ((1/\\varepsilon) \\log\n(n/\\varepsilon))^{O(1/\\varepsilon)} \\big)$. Our approach extends Sanjeev\nArora's dynamic-programming (DP) PTAS for the Euclidean TSP\n(https://doi.org/10.1145/290179.290180). Our algorithm introduces a rounding\nprocess to balance the allocation of path lengths among the multiple salesman.\nWe analyze the accumulation of error in the DP to prove that the solution is a\n$(1 + \\varepsilon)$-approximation.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "David M. Mount",
      "Mary Monroe"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.04325"
  },
  {
    "id": "arXiv:2112.04329",
    "title": "JABER: Junior Arabic BERt",
    "abstract": "Language-specific pre-trained models have proven to be more accurate than\nmultilingual ones in a monolingual evaluation setting, Arabic is no exception.\nHowever, we found that previously released Arabic BERT models were\nsignificantly under-trained. In this technical report, we present JABER, Junior\nArabic BERt, our pretrained language model prototype dedicated for Arabic. We\nconduct an empirical study to systematically evaluate the performance of models\nacross a diverse set of existing Arabic NLU tasks. Experimental results show\nthat JABER achieves the state-of-the-art performances on ALUE, a new benchmark\nfor Arabic Language Understanding Evaluation, as well as on a well-established\nNER benchmark",
    "descriptor": "\nComments: Techincal Report\n",
    "authors": [
      "Abbas Ghaddar",
      "Yimeng Wu",
      "Ahmad Rashid",
      "Khalil Bibi",
      "Mehdi Rezagholizadeh",
      "Chao Xing",
      "Yasheng Wang",
      "Duan Xinyu",
      "Zhefeng Wang",
      "Baoxing Huai",
      "Xin Jiang",
      "Qun Liu",
      "Philippe Langlais"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.04329"
  },
  {
    "id": "arXiv:2112.04335",
    "title": "Morphology of small snarks",
    "abstract": "The aim of this paper is to classify all snarks up to order $36$ and explain\nthe reasons of their uncolourability. The crucial part of our approach is a\ncomputer-assisted structural analysis of cyclically $5$-connected critical\nsnarks, which is justified by the fact that every other snark can be\nconstructed from them by a series of simple operations while preserving\nuncolourability. Our results reveal that most of the analysed snarks are built\nup from pieces of the Petersen graph and can be naturally distributed into a\nsmall number of classes having the same reason for uncolourability. This sheds\nnew light on the structure of all small snarks. Based on our analysis, we\ngeneralise certain individual snarks to infinite families and identify a rich\nfamily of cyclically $5$-connected critical snarks.",
    "descriptor": "",
    "authors": [
      "J\u00e1n Maz\u00e1k",
      "Jozef Rajn\u00edk",
      "Martin \u0160koviera"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.04335"
  },
  {
    "id": "arXiv:2112.04339",
    "title": "PageRank for Edges: Axiomatic Characterization",
    "abstract": "Edge centrality measures are functions that evaluate the importance of edges\nin a network. They can be used to assess the role of a backlink for the\npopularity of a website as well as the importance of a flight in virus\nspreading. Various node centralities have been translated to apply for edges,\nincluding Edge Betweenness, Eigenedge (edge version of Eigenvector centrality)\nand Edge PageRank. With this paper, we initiate the discussion on the axiomatic\nproperties of edge centrality measures. We do it by proposing an axiomatic\ncharacterization of Edge PageRank. Our characterization is the first\ncharacterization of any edge centrality measure in the literature.",
    "descriptor": "",
    "authors": [
      "Natalia Kucharczuk",
      "Tomasz Was",
      "Oskar Skibski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.04339"
  },
  {
    "id": "arXiv:2112.04343",
    "title": "The Complexity of the Hausdorff Distance",
    "abstract": "We investigate the computational complexity of computing the Hausdorff\ndistance. Specifically, we show that the decision problem of whether the\nHausdorff distance of two semi-algebraic sets is bounded by a given threshold\nis complete for the complexity class $\\forall\\exists_<\\mathbb{R}$. This implies\nthat the problem is NP-, co-NP-, $\\exists\\mathbb{R}$- and\n$\\forall\\mathbb{R}$-hard.",
    "descriptor": "\nComments: 27 pages, 5 figures\n",
    "authors": [
      "Paul Jungeblut",
      "Linda Kleist",
      "Tillmann Miltzow"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.04343"
  },
  {
    "id": "arXiv:2112.04344",
    "title": "Does Structure Matter? Leveraging Data-to-Text Generation for Answering  Complex Information Needs",
    "abstract": "In this work, our aim is to provide a structured answer in natural language\nto a complex information need. Particularly, we envision using generative\nmodels from the perspective of data-to-text generation. We propose the use of a\ncontent selection and planning pipeline which aims at structuring the answer by\ngenerating intermediate plans. The experimental evaluation is performed using\nthe TREC Complex Answer Retrieval (CAR) dataset. We evaluate both the generated\nanswer and its corresponding structure and show the effectiveness of\nplanning-based models in comparison to a text-to-text model.",
    "descriptor": "\nComments: 8 pages, 1 figure, ECIR 2022 short paper\n",
    "authors": [
      "Hanane Djeddal",
      "Thomas Gerald",
      "Laure Soulier",
      "Karen Pinel-Sauvagnat",
      "Lynda Tamine"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04344"
  },
  {
    "id": "arXiv:2112.04345",
    "title": "Burn After Reading: Online Adaptation for Cross-domain Streaming Data",
    "abstract": "In the context of online privacy, many methods propose complex privacy and\nsecurity preserving measures to protect sensitive data. In this paper, we argue\nthat: not storing any sensitive data is the best form of security. Thus we\npropose an online framework that \"burns after reading\", i.e. each online sample\nis immediately deleted after it is processed. Meanwhile, we tackle the\ninevitable distribution shift between the labeled public data and unlabeled\nprivate data as a problem of unsupervised domain adaptation. Specifically, we\npropose a novel algorithm that aims at the most fundamental challenge of the\nonline adaptation setting--the lack of diverse source-target data pairs.\nTherefore, we design a Cross-Domain Bootstrapping approach, called CroDoBo, to\nincrease the combined diversity across domains. Further, to fully exploit the\nvaluable discrepancies among the diverse combinations, we employ the training\nstrategy of multiple learners with co-supervision. CroDoBo achieves\nstate-of-the-art online performance on four domain adaptation benchmarks.",
    "descriptor": "",
    "authors": [
      "Luyu Yang",
      "Mingfei Gao",
      "Zeyuan Chen",
      "Ran Xu",
      "Abhinav Shrivastava",
      "Chetan Ramaiah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04345"
  },
  {
    "id": "arXiv:2112.04350",
    "title": "Transformer based trajectory prediction",
    "abstract": "To plan a safe and efficient route, an autonomous vehicle should anticipate\nfuture motions of other agents around it. Motion prediction is an extremely\nchallenging task which recently gained significant attention of the research\ncommunity. In this work, we present a simple and yet strong baseline for\nuncertainty aware motion prediction based purely on transformer neural\nnetworks, which has shown its effectiveness in conditions of domain change.\nWhile being easy-to-implement, the proposed approach achieves competitive\nperformance and ranks 1$^{st}$ on the 2021 Shifts Vehicle Motion Prediction\nCompetition.",
    "descriptor": "",
    "authors": [
      "Aleksey Postnikov",
      "Aleksander Gamayunov",
      "Gonzalo Ferrer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.04350"
  },
  {
    "id": "arXiv:2112.04351",
    "title": "Sentiment Analysis and Effect of COVID-19 Pandemic using College  SubReddit Data",
    "abstract": "The COVID-19 pandemic has affected societies and human health and well-being\nin various ways. In this study, we collected Reddit data from 2019\n(pre-pandemic) and 2020 (pandemic) from the subreddits communities associated\nwith 8 universities, applied natural language processing (NLP) techniques, and\ntrained graphical neural networks with social media data, to study how the\npandemic has affected people's emotions and psychological states compared to\nthe pre-pandemic era. Specifically, we first applied a pre-trained Robustly\nOptimized BERT pre-training approach (RoBERTa) to learn embedding from the\nsemantic information of Reddit messages and trained a graph attention network\n(GAT) for sentiment classification. The usage of GAT allows us to leverage the\nrelational information among the messages during training. We then applied\nsubgroup-adaptive model stacking to combine the prediction probabilities from\nRoBERTa and GAT to yield the final classification on sentiment. With the\nmanually labeled and model-predicted sentiment labels on the collected data, we\napplied a generalized linear mixed-effects model to estimate the effects of\npandemic and online teaching on people's sentiment in a statistically\nsignificant manner. The results suggest the odds of negative sentiments in 2020\nis $14.6\\%$ higher than the odds in 2019 ($p$-value $<0.001$), and the odds of\nnegative sentiments are $41.6\\%$ higher with in-person teaching than with\nonline teaching in 2020 ($p$-value $=0.037$) in the studied population.",
    "descriptor": "",
    "authors": [
      "Tian Yan",
      "Fang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04351"
  },
  {
    "id": "arXiv:2112.04352",
    "title": "Efficient Data Race Detection of Async-Finish Programs Using Vector  Clocks",
    "abstract": "Existing data race detectors for task-based programs incur large run time and\nspace overheads. The overheads arise because of frequent lookups in\nfine-grained tree data structures to check whether two accesses can happen in\nparallel.\nThis work shows how to efficiently apply vector clocks for dynamic race\ndetection of async-finish programs with locks. Our proposed technique,\nFastRacer, builds on the FastTrack algorithm with per-task and per-variable\noptimizations to reduce the size of vector clocks. FastRacer also exploits the\nstructured parallelism of async-finish programs to use a coarse-grained\nencoding of the dynamic task inheritance to limit the metadata in the presence\nof many concurrent readers. Our evaluation shows that FastRacer substantially\nimproves time and space overheads over FastTrack and is competitive with the\nstate-of-the-art data race detectors for async-finish programs with locks.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Shivam Kumar",
      "Anupam Agrawal",
      "Swarnendu Biswas"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.04352"
  },
  {
    "id": "arXiv:2112.04353",
    "title": "A decoupled numerical method for two-phase flows of different densities  and viscosities in superposed fluid and porous layers",
    "abstract": "In this article we consider the numerical modeling and simulation via the\nphase field approach of two-phase flows of different densities and viscosities\nin superposed fluid and porous layers. The model consists of the\nCahn-Hilliard-Navier-Stokes equations in the free flow region and the\nCahn-Hilliard-Darcy equations in porous media that are coupled by seven domain\ninterface boundary conditions. We show that the coupled model satisfies an\nenergy law. Based on the ideas of pressure stabilization and artificial\ncompressibility, we propose an unconditionally stable time stepping method that\ndecouples the computation of the phase field variable, the velocity and\npressure of free flow, the velocity and pressure of porous media, hence\nsignificantly reduces the computational cost. The energy stability of the\nscheme effected with the finite element spatial discretization is rigorously\nestablished. We verify numerically that our schemes are convergent and\nenergy-law preserving. Ample numerical experiments are performed to illustrate\nthe features of two-phase flows in the coupled free flow and porous media\nsetting.",
    "descriptor": "",
    "authors": [
      "Yali Gao",
      "Daozhi Han",
      "Xiaoming He",
      "Ulrich R\u00fcde"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.04353"
  },
  {
    "id": "arXiv:2112.04359",
    "title": "Ethical and social risks of harm from Language Models",
    "abstract": "This paper aims to help structure the risk landscape associated with\nlarge-scale Language Models (LMs). In order to foster advances in responsible\ninnovation, an in-depth understanding of the potential risks posed by these\nmodels is needed. A wide range of established and anticipated risks are\nanalysed in detail, drawing on multidisciplinary expertise and literature from\ncomputer science, linguistics, and social sciences.\nWe outline six specific risk areas: I. Discrimination, Exclusion and\nToxicity, II. Information Hazards, III. Misinformation Harms, V. Malicious\nUses, V. Human-Computer Interaction Harms, VI. Automation, Access, and\nEnvironmental Harms. The first area concerns the perpetuation of stereotypes,\nunfair discrimination, exclusionary norms, toxic language, and lower\nperformance by social group for LMs. The second focuses on risks from private\ndata leaks or LMs correctly inferring sensitive information. The third\naddresses risks arising from poor, false or misleading information including in\nsensitive domains, and knock-on risks such as the erosion of trust in shared\ninformation. The fourth considers risks from actors who try to use LMs to cause\nharm. The fifth focuses on risks specific to LLMs used to underpin\nconversational agents that interact with human users, including unsafe use,\nmanipulation or deception. The sixth discusses the risk of environmental harm,\njob automation, and other challenges that may have a disparate effect on\ndifferent social groups or communities.\nIn total, we review 21 risks in-depth. We discuss the points of origin of\ndifferent risks and point to potential mitigation approaches. Lastly, we\ndiscuss organisational responsibilities in implementing mitigations, and the\nrole of collaboration and participation. We highlight directions for further\nresearch, particularly on expanding the toolkit for assessing and evaluating\nthe outlined risks in LMs.",
    "descriptor": "",
    "authors": [
      "Laura Weidinger",
      "John Mellor",
      "Maribeth Rauh",
      "Conor Griffin",
      "Jonathan Uesato",
      "Po-Sen Huang",
      "Myra Cheng",
      "Mia Glaese",
      "Borja Balle",
      "Atoosa Kasirzadeh",
      "Zac Kenton",
      "Sasha Brown",
      "Will Hawkins",
      "Tom Stepleton",
      "Courtney Biles",
      "Abeba Birhane",
      "Julia Haas",
      "Laura Rimell",
      "Lisa Anne Hendricks",
      "William Isaac",
      "Sean Legassick",
      "Geoffrey Irving",
      "Iason Gabriel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.04359"
  },
  {
    "id": "arXiv:2112.04360",
    "title": "Synchronized Front Propagation and Delayed Flame Quenching in Strain  G-equation and Time-Periodic Cellular Flows",
    "abstract": "G-equations are level-set type Hamilton-Jacobi partial differential equations\nmodeling propagation of flame front along a flow velocity and a laminar\nvelocity. In consideration of flame stretching, strain rate may be added into\nthe laminar speed. We perform finite difference computation of G-equations with\nthe discretized strain term being monotone with respect to one-sided spatial\nderivatives. Let the flow velocity be the time-periodic cellular flow (modeling\nRayleigh-B\\'enard advection), we compute the turbulent flame speeds as the\nasymptotic propagation speeds from a planar initial flame front. In strain\nG-equation model, front propagation is enhanced by the cellular flow, and flame\nquenching occurs if the flow intensity is large enough. In contrast to the\nresults in steady cellular flow, front propagation in time periodic cellular\nflow may be locked into certain spatial-temporal periodicity pattern, and\nturbulent flame speed becomes a piecewise constant function of flow intensity.\nAlso the disturbed flame front does not cease propagating until much larger\nflow intensity.",
    "descriptor": "",
    "authors": [
      "Yu-Yu Liu",
      "Jack Xin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2112.04360"
  },
  {
    "id": "arXiv:2112.04362",
    "title": "Physics-based Mesh Deformation with Haptic Feedback and Material  Anisotropy",
    "abstract": "We present a physics-based framework to simulate porous, deformable materials\nand interactive tools with haptic feedback that can reshape it. In order to\nallow the material to be moulded non-homogeneously, we propose an algorithm to\nchange the material properties of the object depending on its water content. We\npresent a multi-resolution, multi-timescale simulation framework to enable\nstable visual and haptic feedback at interactive rates. We test our model for\nphysical consistency, accuracy, interactivity and appeal through a user study\nand quantitative performance evaluation.",
    "descriptor": "\nComments: 6 pages, 10 figures\n",
    "authors": [
      "Avirup Mandal",
      "Parag Chaudhuri",
      "Subhasis Chaudhuri"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.04362"
  },
  {
    "id": "arXiv:2112.04363",
    "title": "Geometry-Aware Fruit Grasping Estimation for Robotic Harvesting in  Orchards",
    "abstract": "Field robotic harvesting is a promising technique in recent development of\nagricultural industry. It is vital for robots to recognise and localise fruits\nbefore the harvesting in natural orchards. However, the workspace of harvesting\nrobots in orchards is complex: many fruits are occluded by branches and leaves.\nIt is important to estimate a proper grasping pose for each fruit before\nperforming the manipulation. In this study, a geometry-aware network, A3N, is\nproposed to perform end-to-end instance segmentation and grasping estimation\nusing both color and geometry sensory data from a RGB-D camera. Besides,\nworkspace geometry modelling is applied to assist the robotic manipulation.\nMoreover, we implement a global-to-local scanning strategy, which enables\nrobots to accurately recognise and retrieve fruits in field environments with\ntwo consumer-level RGB-D cameras. We also evaluate the accuracy and robustness\nof proposed network comprehensively in experiments. The experimental results\nshow that A3N achieves 0.873 on instance segmentation accuracy, with an average\ncomputation time of 35 ms. The average accuracy of grasping estimation is 0.61\ncm and 4.8$^{\\circ}$ in centre and orientation, respectively. Overall, the\nrobotic system that utilizes the global-to-local scanning and A3N, achieves\nsuccess rate of harvesting ranging from 70\\% - 85\\% in field harvesting\nexperiments.",
    "descriptor": "",
    "authors": [
      "Hanwen Kang",
      "Xing Wang",
      "Chao Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04363"
  },
  {
    "id": "arXiv:2112.04364",
    "title": "Generalization Error Bounds for Iterative Recovery Algorithms Unfolded  as Neural Networks",
    "abstract": "Motivated by the learned iterative soft thresholding algorithm (LISTA), we\nintroduce a general class of neural networks suitable for sparse reconstruction\nfrom few linear measurements. By allowing a wide range of degrees of\nweight-sharing between the layers, we enable a unified analysis for very\ndifferent neural network types, ranging from recurrent ones to networks more\nsimilar to standard feedforward neural networks. Based on training samples, via\nempirical risk minimization we aim at learning the optimal network parameters\nand thereby the optimal network that reconstructs signals from their\nlow-dimensional linear measurements. We derive generalization bounds by\nanalyzing the Rademacher complexity of hypothesis classes consisting of such\ndeep networks, that also take into account the thresholding parameters. We\nobtain estimates of the sample complexity that essentially depend only linearly\non the number of parameters and on the depth. We apply our main result to\nobtain specific generalization bounds for several practical examples, including\ndifferent algorithms for (implicit) dictionary learning, and convolutional\nneural networks.",
    "descriptor": "\nComments: 29 pages, 6 figures\n",
    "authors": [
      "Ekkehard Schnoor",
      "Arash Behboodi",
      "Holger Rauhut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04364"
  },
  {
    "id": "arXiv:2112.04367",
    "title": "On visual self-supervision and its effect on model robustness",
    "abstract": "Recent self-supervision methods have found success in learning feature\nrepresentations that could rival ones from full supervision, and have been\nshown to be beneficial to the model in several ways: for example improving\nmodels robustness and out-of-distribution detection. In our paper, we conduct\nan empirical study to understand more precisely in what way can self-supervised\nlearning - as a pre-training technique or part of adversarial training -\naffects model robustness to $l_2$ and $l_{\\infty}$ adversarial perturbations\nand natural image corruptions. Self-supervision can indeed improve model\nrobustness, however it turns out the devil is in the details. If one simply\nadds self-supervision loss in tandem with adversarial training, then one sees\nimprovement in accuracy of the model when evaluated with adversarial\nperturbations smaller or comparable to the value of $\\epsilon_{train}$ that the\nrobust model is trained with. However, if one observes the accuracy for\n$\\epsilon_{test} \\ge \\epsilon_{train}$, the model accuracy drops. In fact, the\nlarger the weight of the supervision loss, the larger the drop in performance,\ni.e. harming the robustness of the model. We identify primary ways in which\nself-supervision can be added to adversarial training, and observe that using a\nself-supervised loss to optimize both network parameters and find adversarial\nexamples leads to the strongest improvement in model robustness, as this can be\nviewed as a form of ensemble adversarial training. Although self-supervised\npre-training yields benefits in improving adversarial training as compared to\nrandom weight initialization, we observe no benefit in model robustness or\naccuracy if self-supervision is incorporated into adversarial training.",
    "descriptor": "",
    "authors": [
      "Michal Kucer",
      "Diane Oyen",
      "Garrett Kenyon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04367"
  },
  {
    "id": "arXiv:2112.04368",
    "title": "Semantic TrueLearn: Using Semantic Knowledge Graphs in Recommendation  Systems",
    "abstract": "In informational recommenders, many challenges arise from the need to handle\nthe semantic and hierarchical structure between knowledge areas. This work aims\nto advance towards building a state-aware educational recommendation system\nthat incorporates semantic relatedness between knowledge topics, propagating\nlatent information across semantically related topics. We introduce a novel\nlearner model that exploits this semantic relatedness between knowledge\ncomponents in learning resources using the Wikipedia link graph, with the aim\nto better predict learner engagement and latent knowledge in a lifelong\nlearning scenario. In this sense, Semantic TrueLearn builds a humanly intuitive\nknowledge representation while leveraging Bayesian machine learning to improve\nthe predictive performance of the educational engagement. Our experiments with\na large dataset demonstrate that this new semantic version of TrueLearn\nalgorithm achieves statistically significant improvements in terms of\npredictive performance with a simple extension that adds semantic awareness to\nthe model.",
    "descriptor": "\nComments: Presented at the First International Workshop on Joint Use of Probabilistic Graphical Models and Ontology at Conference on Knowledge Graph and Semantic Web 2021\n",
    "authors": [
      "Sahan Bulathwela",
      "Mar\u00eda P\u00e9rez-Ortiz",
      "Emine Yilmaz",
      "John Shawe-Taylor"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04368"
  },
  {
    "id": "arXiv:2112.04373",
    "title": "Stochastic Bounded Confidence Opinion Dynamics: How Far Apart Do  Opinions Drift?",
    "abstract": "In this era of fast and large-scale opinion formation, a mathematical\nunderstanding of opinion evolution, a.k.a. opinion dynamics, is especially\nimportant. Linear graph-based dynamics and bounded confidence dynamics are the\ntwo most popular models for opinion dynamics in social networks. Recently,\nstochastic bounded confidence opinion dynamics were proposed as a general\nframework that incorporates both these dynamics as special cases and also\ncaptures the inherent stochasticity and noise (errors) in real-life social\nexchanges. Although these dynamics are quite general and realistic, their\nanalysis is particularly challenging compared to other opinion dynamics models.\nThis is because these dynamics are nonlinear and stochastic, and belong to the\nclass of Markov processes that have asymptotically zero drift and unbounded\njumps. The asymptotic behavior of these dynamics was characterized in prior\nworks. However, they do not shed light on their finite-time behavior, which is\noften of interest in practice. We take a stride in this direction by analyzing\nthe finite time behavior of a two-agent system, which is fundamental to the\nunderstanding of multi-agent dynamics. In particular, we show that the opinion\ndifference between the two agents is well concentrated around zero under the\nconditions that lead to asymptotic stability of the dynamics.",
    "descriptor": "\nComments: Accepted in COMSNETS 2022\n",
    "authors": [
      "Sushmitha Shree S",
      "Kishore G V",
      "Avhishek Chatterjee",
      "Krishna Jagannathan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.04373"
  },
  {
    "id": "arXiv:2112.04374",
    "title": "Dependability Engineering in Isabelle",
    "abstract": "In this paper, we introduce a process of formal system development supported\nby interactive theorem proving in a dedicated Isabelle framework. This Isabelle\nInfrastructure framework implements specification and verification in a cyclic\nprocess supported by attack tree analysis closely inter-connected with formal\nrefinement of the specification. The process is cyclic: in a repeated iteration\nthe refinement adds more detail to the system specification. It is a known hard\nproblem how to find the next refinement step: this problem is addressed by the\nattack based analysis using Kripke structures and CTL logic. We call this\ncyclic process the Refinement-Risk cycle (RR-cycle). It has been developed for\nsecurity and privacy of IoT healthcare systems initially but is more generally\napplicable for safety as well, that is, dependability in general. In this\npaper, we present the extensions to the Isabelle Infrastructure framework\nimplementing a formal notion of property preserving refinement interleaved with\nattack tree analysis for the RR-cycle. The process is illustrated on the\nspecification development and privacy analysis of the mobile Corona-virus\nwarning app.",
    "descriptor": "",
    "authors": [
      "Florian Kamm\u00fcller"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.04374"
  },
  {
    "id": "arXiv:2112.04379",
    "title": "Player Modeling using Behavioral Signals in Competitive Online Games",
    "abstract": "Competitive online games use rating systems to match players with similar\nskills to ensure a satisfying experience for players. In this paper, we focus\non the importance of addressing different aspects of playing behavior when\nmodeling players for creating match-ups. To this end, we engineer several\nbehavioral features from a dataset of over 75,000 battle royale matches and\ncreate player models based on the retrieved features. We then use the created\nmodels to predict ranks for different groups of players in the data. The\npredicted ranks are compared to those of three popular rating systems. Our\nresults show the superiority of simple behavioral models over mainstream rating\nsystems. Some behavioral features provided accurate predictions for all groups\nof players while others proved useful for certain groups of players. The\nresults of this study highlight the necessity of considering different aspects\nof the player's behavior such as goals, strategy, and expertise when making\nassignments.",
    "descriptor": "\nComments: Accepted in the 2021 International Conference on Computational Science and Computational Intelligence (CSCI'21)\n",
    "authors": [
      "Arman Dehpanah",
      "Muheeb Faizan Ghori",
      "Jonathan Gemmell",
      "Bamshad Mobasher"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04379"
  },
  {
    "id": "arXiv:2112.04381",
    "title": "Topology and Geometry of the Third-Party Domains Ecosystem",
    "abstract": "Over the years, web content has evolved from simple text and static images\nhosted on a single server to a complex, interactive and multimedia-rich content\nhosted on different servers. As a result, a modern website during its loading\ntime fetches content not only from its owner's domain but also from a range of\nthird-party domains providing additional functionalities and services. Here we\ninfer the network of the third-party domains by observing the domains'\ninteractions within users' browsers from all over the globe. We find that this\nnetwork possesses structural properties commonly found in other complex\nnetworks in nature and society, such as power-law degree distribution, strong\nclustering, and the small-world property. These properties imply that a\nhyperbolic geometry underlies the ecosystem's topology and we use statistical\ninference methods to find the domains' coordinates in this geometry, which\nabstract how popular and similar the domains are. The hyperbolic map we obtain\nis meaningful, revealing collaborations between controversial services and\nsocial networks that have not been previously revealed. Furthermore, the map\ncan facilitate applications, such as the prediction of third-party domains\nco-hosting on the same physical machine, and merging in terms of company\nacquisition. Such predictions cannot be made by just observing the domains'\ninteractions within the users' browsers.",
    "descriptor": "",
    "authors": [
      "Costas Iordanou",
      "Fragkiskos Papadopoulos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.04381"
  },
  {
    "id": "arXiv:2112.04384",
    "title": "Reproducing software environments: a prerequisite for reproducible  research",
    "abstract": "As software has become an integral part of scientific workflows, reproducible\nresearch practices must take it into account. In what way? Archiving source\ncode is a necessary but insufficient condition. The ability to redeploy\nsoftware environments, which at first sight may be viewed as a technical\ndetail, is in fact a requirement. This article explores tools and methods to\nachieve this goal.",
    "descriptor": "\nComments: in French\n",
    "authors": [
      "Ludovic Court\u00e8s"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2112.04384"
  },
  {
    "id": "arXiv:2112.04387",
    "title": "Truth-tracking via Approval Voting: Size Matters",
    "abstract": "Epistemic social choice aims at unveiling a hidden ground truth given votes,\nwhich are interpreted as noisy signals about it. We consider here a simple\nsetting where votes consist of approval ballots: each voter approves a set of\nalternatives which they believe can possibly be the ground truth. Based on the\nintuitive idea that more reliable votes contain fewer alternatives, we define\nseveral noise models that are approval voting variants of the Mallows model.\nThe likelihood-maximizing alternative is then characterized as the winner of a\nweighted approval rule, where the weight of a ballot decreases with its\ncardinality. We have conducted an experiment on three image annotation\ndatasets; they conclude that rules based on our noise model outperform standard\napproval voting; the best performance is obtained by a variant of the Condorcet\nnoise model.",
    "descriptor": "\nComments: Accepted in the 36th AAAI Conference on Artificial Intelligence (AAAI 2022)\n",
    "authors": [
      "Tahar Allouche",
      "J\u00e9r\u00f4me Lang",
      "Florian Yger"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04387"
  },
  {
    "id": "arXiv:2112.04388",
    "title": "A graph representation based on fluid diffusion model for multimodal  data analysis: theoretical aspects and enhanced community detection",
    "abstract": "Representing data by means of graph structures identifies one of the most\nvalid approach to extract information in several data analysis applications.\nThis is especially true when multimodal datasets are investigated, as records\ncollected by means of diverse sensing strategies are taken into account and\nexplored. Nevertheless, classic graph signal processing is based on a model for\ninformation propagation that is configured according to heat diffusion\nmechanism. This system provides several constraints and assumptions on the data\nproperties that might be not valid for multimodal data analysis, especially\nwhen large scale datasets collected from heterogeneous sources are considered,\nso that the accuracy and robustness of the outcomes might be severely\njeopardized. In this paper, we introduce a novel model for graph definition\nbased on fluid diffusion. The proposed approach improves the ability of\ngraph-based data analysis to take into account several issues of modern data\nanalysis in operational scenarios, so to provide a platform for precise,\nversatile, and efficient understanding of the phenomena underlying the records\nunder exam, and to fully exploit the potential provided by the diversity of the\nrecords in obtaining a thorough characterization of the data and their\nsignificance. In this work, we focus our attention to using this fluid\ndiffusion model to drive a community detection scheme, i.e., to divide\nmultimodal datasets into many groups according to similarity among nodes in an\nunsupervised fashion. Experimental results achieved by testing real multimodal\ndatasets in diverse application scenarios show that our method is able to\nstrongly outperform state-of-the-art schemes for community detection in\nmultimodal data analysis.",
    "descriptor": "\nComments: 26 pages, 17 figures\n",
    "authors": [
      "Andrea Marinoni",
      "Christian Jutten",
      "Mark Girolami"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04388"
  },
  {
    "id": "arXiv:2112.04389",
    "title": "Mixed Membership Distribution-Free model",
    "abstract": "We consider the problem of detecting latent community information of mixed\nmembership weighted network in which nodes have mixed memberships and edges\nconnecting between nodes can be finite real numbers. We propose a general mixed\nmembership distribution-free model for this problem. The model has no\ndistribution constraints of edges but only the expected values, and can be\nviewed as generalizations of some previous models. We use an efficient spectral\nalgorithm to estimate community memberships under the model. We also derive the\nconvergence rate of the proposed algorithm under the model using delicate\nspectral analysis. We demonstrate the advantages of mixed membership\ndistribution-free model with applications to a small scale of simulated\nnetworks when edges follow different distributions.",
    "descriptor": "\nComments: 15 pages, 7 figures, comments are welcome\n",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04389"
  },
  {
    "id": "arXiv:2112.04392",
    "title": "Opportunistic Relay Selection over Generalized Fading and Inverse Gamma  Composite Fading Mixed Multicast Channels: A Secrecy Tradeoff",
    "abstract": "The secrecy performance of realistic wireless multicast scenarios can be\nsignificantly deteriorated by the simultaneous occurrence of multipath and\nshadowing. To resolve this security threat, in this work an opportunistic\nrelaying-based dual-hop wireless multicast framework is proposed in which the\nsource dispatches confidential information to a bunch of receivers via\nintermediate relays under the wiretapping attempts of multiple eavesdroppers.\nTwo scenarios, i.e. non-line of sight (NLOS) and line of sight (LOS)\ncommunications along with the multiplicative and LOS shadowing are considered\nwhere the first scenario assumes eta-mu and eta-mu/inverse Gamma (IG) composite\nfading channels and the latter one follows kappa-mu and kappa-mu/IG composite\nfading channels as the source to relay and relay to receiver's as well as\neavesdropper's links, respectively. Secrecy analysis is accomplished by\nderiving closed-form expressions of three familiar secrecy measures i.e. secure\noutage probability for multicasting, probability of non-zero secrecy multicast\ncapacity, and ergodic secrecy multicast capacity. We further capitalize on\nthose expressions to observe the effects of all system parameters which are\nagain corroborated via Monte-Carlo simulations. Our observations indicate that\na secrecy tradeoff between the number of relays and number of receivers,\neavesdroppers, and shadowing parameters can be established to maintain the\nadmissible security level by decreasing the detrimental influences of fading,\nshadowing, the number of multicast receivers and eavesdroppers.",
    "descriptor": "",
    "authors": [
      "MD. Shakhawat Hossen",
      "A. S. M. Badrudduza",
      "S. M. Riazul Islam",
      "Abu Hanif",
      "Milton Kumar Kundu",
      "Kyung-Sup Kwak"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.04392"
  },
  {
    "id": "arXiv:2112.04395",
    "title": "On anti-stochastic properties of unlabeled graphs",
    "abstract": "We study vulnerability of a uniformly distributed random graph to an attack\nby an adversary who aims for a global change of the distribution while being\nable to make only a local change in the graph. We call a graph property $A$\nanti-stochastic if the probability that a random graph $G$ satisfies $A$ is\nsmall but, with high probability, there is a small perturbation transforming\n$G$ into a graph satisfying $A$. While for labeled graphs such properties are\neasy to obtain from binary covering codes, the existence of anti-stochastic\nproperties for unlabeled graphs is not so evident. If an admissible\nperturbation is either the addition or the deletion of one edge, we exhibit an\nanti-stochastic property that is satisfied by a random unlabeled graph of order\n$n$ with probability $(2+o(1))/n^2$, which is as small as possible. We also\nexpress another anti-stochastic property in terms of the degree sequence of a\ngraph. This property has probability $(2+o(1))/(n\\ln n)$, which is optimal up\nto factor of 2.",
    "descriptor": "",
    "authors": [
      "Sergei Kiselev",
      "Andrey Kupavskii",
      "Oleg Verbitsky",
      "Maksim Zhukovskii"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Cryptography and Security (cs.CR)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.04395"
  },
  {
    "id": "arXiv:2112.04401",
    "title": "FPPN: Future Pseudo-LiDAR Frame Prediction for Autonomous Driving",
    "abstract": "LiDAR sensors are widely used in autonomous driving due to the reliable 3D\nspatial information. However, the data of LiDAR is sparse and the frequency of\nLiDAR is lower than that of cameras. To generate denser point clouds spatially\nand temporally, we propose the first future pseudo-LiDAR frame prediction\nnetwork. Given the consecutive sparse depth maps and RGB images, we first\npredict a future dense depth map based on dynamic motion information coarsely.\nTo eliminate the errors of optical flow estimation, an inter-frame aggregation\nmodule is proposed to fuse the warped depth maps with adaptive weights. Then,\nwe refine the predicted dense depth map using static contextual information.\nThe future pseudo-LiDAR frame can be obtained by converting the predicted dense\ndepth map into corresponding 3D point clouds. Experimental results show that\nour method outperforms the existing solutions on the popular KITTI benchmark.",
    "descriptor": "",
    "authors": [
      "Xudong Huang",
      "Chunyu Lin",
      "Haojie Liu",
      "Lang Nie",
      "Yao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04401"
  },
  {
    "id": "arXiv:2112.04404",
    "title": "Gaud\u00ed: Conversational Interactions with Deep Representations to  Generate Image Collections",
    "abstract": "Based on recent advances in realistic language modeling (GPT-3) and\ncross-modal representations (CLIP), Gaud\\'i was developed to help designers\nsearch for inspirational images using natural language. In the early stages of\nthe design process, with the goal of eliciting a client's preferred creative\ndirection, designers will typically create thematic collections of\ninspirational images called \"mood-boards\". Creating a mood-board involves\nsequential image searches which are currently performed using keywords or\nimages. Gaud\\'i transforms this process into a conversation where the user is\ngradually detailing the mood-board's theme. This representation allows our AI\nto generate new search queries from scratch, straight from a project briefing,\nfollowing a theme hypothesized by GPT-3. Compared to previous computational\napproaches to mood-board creation, to the best of our knowledge, ours is the\nfirst attempt to represent mood-boards as the stories that designers tell when\npresenting a creative direction to a client.",
    "descriptor": "\nComments: Accepted at the NeurIPS 2021 Workshop on Machine Learning for Creativity and Design\n",
    "authors": [
      "Victor S. Bursztyn",
      "Jennifer Healey",
      "Vishwa Vinay"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04404"
  },
  {
    "id": "arXiv:2112.04405",
    "title": "Improved Distributed Fractional Coloring Algorithms",
    "abstract": "We prove new bounds on the distributed fractional coloring problem in the\nLOCAL model. Fractional $c$-colorings can be understood as multicolorings as\nfollows. For some natural numbers $p$ and $q$ such that $p/q\\leq c$, each node\n$v$ is assigned a set of at least $q$ colors from $\\{1,\\dots,p\\}$ such that\nadjacent nodes are assigned disjoint sets of colors. The minimum $c$ for which\na fractional $c$-coloring of a graph $G$ exists is called the fractional\nchromatic number $\\chi_f(G)$ of $G$.\nRecently, [Bousquet, Esperet, and Pirot; SIROCCO '21] showed that for any\nconstant $\\epsilon>0$, a fractional $(\\Delta+\\epsilon)$-coloring can be\ncomputed in $\\Delta^{O(\\Delta)} + O(\\Delta\\cdot\\log^* n)$ rounds. We show that\nsuch a coloring can be computed in only $O(\\log^2 \\Delta)$ rounds, without any\ndependency on $n$.\nWe further show that in $O\\big(\\frac{\\log n}{\\epsilon}\\big)$ rounds, it is\npossible to compute a fractional $(1+\\epsilon)\\chi_f(G)$-coloring, even if the\nfractional chromatic number $\\chi_f(G)$ is not known. That is, this problem can\nbe approximated arbitrarily well by an efficient algorithm in the LOCAL model.\nFor the standard coloring problem, it is only known that an $O\\big(\\frac{\\log\nn}{\\log\\log n}\\big)$-approximation can be computed in polylogarithmic time in\nthe LOCAL model. We also show that our distributed fractional coloring\napproximation algorithm is best possible. We show that in trees, which have\nfractional chromatic number $2$, computing a fractional $(2+\\epsilon)$-coloring\nrequires at least $\\Omega\\big(\\frac{\\log n}{\\epsilon}\\big)$ rounds.\nWe finally study fractional colorings of regular grids. In [Bousquet,\nEsperet, and Pirot; SIROCCO '21], it is shown that in regular grids of bounded\ndimension, a fractional $(2+\\epsilon)$-coloring can be computed in time\n$O(\\log^* n)$. We show that such a coloring can even be computed in $O(1)$\nrounds in the LOCAL model.",
    "descriptor": "",
    "authors": [
      "Alkida Balliu",
      "Fabian Kuhn",
      "Dennis Olivetti"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.04405"
  },
  {
    "id": "arXiv:2112.04406",
    "title": "Adapting Procedural Content Generation to Player Personas Through  Evolution",
    "abstract": "Automatically adapting game content to players opens new doors for game\ndevelopment. In this paper we propose an architecture using persona agents and\nexperience metrics, which enables evolving procedurally generated levels\ntailored for particular player personas. Using our game, \"Grave Rave\", we\ndemonstrate that this approach successfully adapts to four rule-based persona\nagents over three different experience metrics. Furthermore, the adaptation is\nshown to be specific in nature, meaning that the levels are persona-conscious,\nand not just general optimizations with regard to the selected metric.",
    "descriptor": "",
    "authors": [
      "Pedro M. Fernandes",
      "Jonathan J\u00f8rgensen",
      "Niels N. T. G. Poldervaart"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.04406"
  },
  {
    "id": "arXiv:2112.04410",
    "title": "Simple Fair Power Allocation for NOMA-Based Visible Light Communication  Systems",
    "abstract": "Non-orthogonal multiple access (NOMA) in the power-domain has been recognized\nas a promising technique to overcome the bandwidth limitations of current\nvisible light communication (VLC) systems. In this letter, we investigate the\npower allocation (PA) problem in an NOMA-VLC system under high\nsignal-to-noise-ratio (SNR) regime. A simple fair power allocation strategy\n(SFPA) is proposed to ensure equitable allocation of transmission resources in\na multi-user scenario. SFPA requires minimal channel state information (CSI),\nmaking it less prone to channel estimation errors. Results show that NOMA with\nSFPA provides fairer and higher achievable rates per user (up to 79.5\\% higher\nin the studied setup), without significantly compromising the overall system\nperformance.",
    "descriptor": "",
    "authors": [
      "Carlos Alberto Rodr\u00edguez L\u00f3pez",
      "Vitalio Alfonso Reguera"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.04410"
  },
  {
    "id": "arXiv:2112.04415",
    "title": "On the Average Mutual Information of MIMO Keyhole Channels with Finite  Inputs",
    "abstract": "This letter studies the average mutual information (AMI) of keyhole\nmultiple-input multiple-output (MIMO) systems having finite input signals. At\nfirst, the AMI of single-stream transmission is investigated under two cases\nwhere the state information at the transmitter (CSIT) is available or not.\nThen, the derived results are further extended to the case of multi-stream\ntransmission. For the sake of providing more system insights, asymptotic\nanalyses are performed in the regime of high signal-to-noise ratio (SNR), which\nsuggests that the high-SNR AMI converges to some constant with its rate of\nconvergence determined by the diversity order. All the results are validated by\nnumerical simulations and are in excellent agreement.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Chongjun Ouyang",
      "Yuanwei Liu",
      "Julian Cheng",
      "Ralf R. M\u00fcller",
      "Hongwen Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.04415"
  },
  {
    "id": "arXiv:2112.04417",
    "title": "What I Cannot Predict, I Do Not Understand: A Human-Centered Evaluation  Framework for Explainability Methods",
    "abstract": "A multitude of explainability methods and theoretical evaluation scores have\nbeen proposed. However, it is not yet known: (1) how useful these methods are\nin real-world scenarios and (2) how well theoretical measures predict the\nusefulness of these methods for practical use by a human. To fill this gap, we\nconducted human psychophysics experiments at scale to evaluate the ability of\nhuman participants (n=1,150) to leverage representative attribution methods to\nlearn to predict the decision of different image classifiers. Our results\ndemonstrate that theoretical measures used to score explainability methods\npoorly reflect the practical usefulness of individual attribution methods in\nreal-world scenarios. Furthermore, the degree to which individual attribution\nmethods helped human participants predict classifiers' decisions varied widely\nacross categorization tasks and datasets.\nOverall, our results highlight fundamental challenges for the field --\nsuggesting a critical need to develop better explainability methods and to\ndeploy human-centered evaluation approaches. We will make the code of our\nframework available to ease the systematic evaluation of novel explainability\nmethods.",
    "descriptor": "",
    "authors": [
      "Thomas Fel",
      "Julien Colin",
      "Remi Cadene",
      "Thomas Serre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04417"
  },
  {
    "id": "arXiv:2112.04421",
    "title": "SoK: Vehicle Orientation Representations for Deep Rotation Estimation",
    "abstract": "In recent years, an influx of 3D autonomous vehicle object detection\nalgorithms. However, little attention was paid to orientation prediction.\nExisting research work proposed various prediction methods, but a holistic,\nconclusive review has not been conducted. Through our experiments, we\ncategorize and empirically compare the accuracy performance of various existing\norientation representations using the KITTI 3D object detection dataset, and\npropose a new form of orientation representation: Tricosine. Among these, the\n2D Cartesian-based representation, or Single Bin, achieves the highest\naccuracy, with additional channeled inputs (positional encoding and depth map)\nnot boosting prediction performance. Our code is published on Github:\nhttps://github.com/umd-fire-coml/KITTI-orientation-learning",
    "descriptor": "",
    "authors": [
      "Huahong Tu",
      "Siyuan Peng",
      "Vladimir Leung",
      "Richard Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04421"
  },
  {
    "id": "arXiv:2112.04424",
    "title": "Training Robust Zero-Shot Voice Conversion Models with Self-supervised  Features",
    "abstract": "Unsupervised Zero-Shot Voice Conversion (VC) aims to modify the speaker\ncharacteristic of an utterance to match an unseen target speaker without\nrelying on parallel training data. Recently, self-supervised learning of speech\nrepresentation has been shown to produce useful linguistic units without using\ntranscripts, which can be directly passed to a VC model. In this paper, we\nshowed that high-quality audio samples can be achieved by using a length\nresampling decoder, which enables the VC model to work in conjunction with\ndifferent linguistic feature extractors and vocoders without requiring them to\noperate on the same sequence length. We showed that our method can outperform\nmany baselines on the VCTK dataset. Without modifying the architecture, we\nfurther demonstrated that a) using pairs of different audio segments from the\nsame speaker, b) adding a cycle consistency loss, and c) adding a speaker\nclassification loss can help to learn a better speaker embedding. Our model\ntrained on LibriTTS using these techniques achieves the best performance,\nproducing audio samples transferred well to the target speaker's voice, while\npreserving the linguistic content that is comparable with actual human\nutterances in terms of Character Error Rate.",
    "descriptor": "",
    "authors": [
      "Trung Dang",
      "Dung Tran",
      "Peter Chin",
      "Kazuhito Koishida"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.04424"
  },
  {
    "id": "arXiv:2112.04426",
    "title": "Improving language models by retrieving from trillions of tokens",
    "abstract": "We enhance auto-regressive language models by conditioning on document chunks\nretrieved from a large corpus, based on local similarity with preceding tokens.\nWith a $2$ trillion token database, our Retrieval-Enhanced Transformer (RETRO)\nobtains comparable performance to GPT-3 and Jurassic-1 on the Pile, despite\nusing 25$\\times$ fewer parameters. After fine-tuning, RETRO performance\ntranslates to downstream knowledge-intensive tasks such as question answering.\nRETRO combines a frozen Bert retriever, a differentiable encoder and a chunked\ncross-attention mechanism to predict tokens based on an order of magnitude more\ndata than what is typically consumed during training. We typically train RETRO\nfrom scratch, yet can also rapidly RETROfit pre-trained transformers with\nretrieval and still achieve good performance. Our work opens up new avenues for\nimproving language models through explicit memory at unprecedented scale.",
    "descriptor": "",
    "authors": [
      "Sebastian Borgeaud",
      "Arthur Mensch",
      "Jordan Hoffmann",
      "Trevor Cai",
      "Eliza Rutherford",
      "Katie Millican",
      "George van den Driessche",
      "Jean-Baptiste Lespiau",
      "Bogdan Damoc",
      "Aidan Clark",
      "Diego de Las Casas",
      "Aurelia Guy",
      "Jacob Menick",
      "Roman Ring",
      "Tom Hennigan",
      "Saffron Huang",
      "Loren Maggiore",
      "Chris Jones",
      "Albin Cassirer",
      "Andy Brock",
      "Michela Paganini",
      "Geoffrey Irving",
      "Oriol Vinyals",
      "Simon Osindero",
      "Karen Simonyan",
      "Jack W. Rae",
      "Erich Elsen",
      "Laurent Sifre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04426"
  },
  {
    "id": "arXiv:2112.04432",
    "title": "Audio-Visual Synchronisation in the wild",
    "abstract": "In this paper, we consider the problem of audio-visual synchronisation\napplied to videos `in-the-wild' (ie of general classes beyond speech). As a new\ntask, we identify and curate a test set with high audio-visual correlation,\nnamely VGG-Sound Sync. We compare a number of transformer-based architectural\nvariants specifically designed to model audio and visual signals of arbitrary\nlength, while significantly reducing memory requirements during training. We\nfurther conduct an in-depth analysis on the curated dataset and define an\nevaluation metric for open domain audio-visual synchronisation. We apply our\nmethod on standard lip reading speech benchmarks, LRS2 and LRS3, with ablations\non various aspects. Finally, we set the first benchmark for general\naudio-visual synchronisation with over 160 diverse classes in the new VGG-Sound\nSync video dataset. In all cases, our proposed model outperforms the previous\nstate-of-the-art by a significant margin.",
    "descriptor": "",
    "authors": [
      "Honglie Chen",
      "Weidi Xie",
      "Triantafyllos Afouras",
      "Arsha Nagrani",
      "Andrea Vedaldi",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.04432"
  },
  {
    "id": "arXiv:2112.04439",
    "title": "Data-driven stochastic model predictive control",
    "abstract": "We propose a novel data-driven stochastic model predictive control (MPC)\nalgorithm to control linear time-invariant systems with additive stochastic\ndisturbances in the dynamics. The scheme centers around repeated predictions\nand computations of optimal control inputs based on a non-parametric\nrepresentation of the space of all possible trajectories, using the fundamental\nlemma from behavioral systems theory. This representation is based on a single\nmeasured input-state-disturbance trajectory generated by persistently exciting\ninputs and does not require any further identification step. Based on\nstochastic MPC ideas, we enforce the satisfaction of state constraints with a\npre-specified probability level, allowing for a systematic trade-off between\ncontrol performance and constraint satisfaction. The proposed data-driven\nstochastic MPC algorithm enables efficient control where robust methods are too\nconservative, which we demonstrate in a simulation example.",
    "descriptor": "\nComments: This work has been submitted to the L4DC 2022 conference\n",
    "authors": [
      "Sebastian Kerz",
      "Johannes Teutsch",
      "Tim Br\u00fcdigam",
      "Dirk Wollherr",
      "Marion Leibold"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04439"
  },
  {
    "id": "arXiv:2112.04441",
    "title": "Autoencoder-based Communications with Reconfigurable Intelligent  Surfaces",
    "abstract": "This paper presents a novel approach for the joint design of a reconfigurable\nintelligent surface (RIS) and a transmitter-receiver pair that are trained\ntogether as a set of deep neural networks (DNNs) to optimize the end-to-end\ncommunication performance at the receiver. The RIS is a software-defined array\nof unit cells that can be controlled in terms of the scattering and reflection\nprofiles to focus the incoming signals from the transmitter to the receiver.\nThe benefit of the RIS is to improve the coverage and spectral efficiency for\nwireless communications by overcoming physical obstructions of the\nline-of-sight (LoS) links. The selection process of the RIS beam codeword (out\nof a pre-defined codebook) is formulated as a DNN, while the operations of the\ntransmitter-receiver pair are modeled as two DNNs, one for the encoder (at the\ntransmitter) and the other one for the decoder (at the receiver) of an\nautoencoder, by accounting for channel effects including those induced by the\nRIS in between. The underlying DNNs are jointly trained to minimize the symbol\nerror rate at the receiver. Numerical results show that the proposed design\nachieves major gains in error performance with respect to various baseline\nschemes, where no RIS is used or the selection of the RIS beam is separated\nfrom the design of the transmitter-receiver pair.",
    "descriptor": "",
    "authors": [
      "Tugba Erpek",
      "Yalin E. Sagduyu",
      "Ahmed Alkhateeb",
      "Aylin Yener"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04441"
  },
  {
    "id": "arXiv:2112.04446",
    "title": "Everything at Once -- Multi-modal Fusion Transformer for Video Retrieval",
    "abstract": "Multi-modal learning from video data has seen increased attention recently as\nit allows to train semantically meaningful embeddings without human annotation\nenabling tasks like zero-shot retrieval and classification. In this work, we\npresent a multi-modal, modality agnostic fusion transformer approach that\nlearns to exchange information between multiple modalities, such as video,\naudio, and text, and integrate them into a joined multi-modal representation to\nobtain an embedding that aggregates multi-modal temporal information. We\npropose to train the system with a combinatorial loss on everything at once,\nsingle modalities as well as pairs of modalities, explicitly leaving out any\nadd-ons such as position or modality encoding. At test time, the resulting\nmodel can process and fuse any number of input modalities. Moreover, the\nimplicit properties of the transformer allow to process inputs of different\nlengths. To evaluate the proposed approach, we train the model on the large\nscale HowTo100M dataset and evaluate the resulting embedding space on four\nchallenging benchmark datasets obtaining state-of-the-art results in zero-shot\nvideo retrieval and zero-shot video action localization.",
    "descriptor": "",
    "authors": [
      "Nina Shvetsova",
      "Brian Chen",
      "Andrew Rouditchenko",
      "Samuel Thomas",
      "Brian Kingsbury",
      "Rogerio Feris",
      "David Harwath",
      "James Glass",
      "Hilde Kuehne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.04446"
  },
  {
    "id": "arXiv:2112.04453",
    "title": "MLP Architectures for Vision-and-Language Modeling: An Empirical Study",
    "abstract": "We initiate the first empirical study on the use of MLP architectures for\nvision-and-language (VL) fusion. Through extensive experiments on 5 VL tasks\nand 5 robust VQA benchmarks, we find that: (i) Without pre-training, using MLPs\nfor multimodal fusion has a noticeable performance gap compared to\ntransformers; (ii) However, VL pre-training can help close the performance gap;\n(iii) Instead of heavy multi-head attention, adding tiny one-head attention to\nMLPs is sufficient to achieve comparable performance to transformers. Moreover,\nwe also find that the performance gap between MLPs and transformers is not\nwidened when being evaluated on the harder robust VQA benchmarks, suggesting\nusing MLPs for VL fusion can generalize roughly to a similar degree as using\ntransformers. These results hint that MLPs can effectively learn to align\nvision and text features extracted from lower-level encoders without heavy\nreliance on self-attention. Based on this, we ask an even bolder question: can\nwe have an all-MLP architecture for VL modeling, where both VL fusion and the\nvision encoder are replaced with MLPs? Our result shows that an all-MLP VL\nmodel is sub-optimal compared to state-of-the-art full-featured VL models when\nboth of them get pre-trained. However, pre-training an all-MLP can surprisingly\nachieve a better average score than full-featured transformer models without\npre-training. This indicates the potential of large-scale pre-training of\nMLP-like architectures for VL modeling and inspires the future research\ndirection on simplifying well-established VL modeling with less inductive\ndesign bias. Our code is publicly available at:\nhttps://github.com/easonnie/mlp-vil",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Yixin Nie",
      "Linjie Li",
      "Zhe Gan",
      "Shuohang Wang",
      "Chenguang Zhu",
      "Michael Zeng",
      "Zicheng Liu",
      "Mohit Bansal",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04453"
  },
  {
    "id": "arXiv:2112.04454",
    "title": "Greedy-based Value Representation for Optimal Coordination in  Multi-agent Reinforcement Learning",
    "abstract": "Due to the representation limitation of the joint Q value function,\nmulti-agent reinforcement learning (MARL) methods with linear or monotonic\nvalue decomposition suffer from the relative overgeneralization. As a result,\nthey can not ensure the optimal coordination. Existing methods address the\nrelative overgeneralization by achieving complete expressiveness or learning a\nbias, which is insufficient to solve the problem. In this paper, we propose the\noptimal consistency, a criterion to evaluate the optimality of coordination. To\nachieve the optimal consistency, we introduce the True-Global-Max (TGM)\nprinciple for linear and monotonic value decomposition, where the TGM principle\ncan be ensured when the optimal stable point is the unique stable point.\nTherefore, we propose the greedy-based value representation (GVR) to ensure the\noptimal stable point via inferior target shaping and eliminate the non-optimal\nstable points via superior experience replay. Theoretical proofs and empirical\nresults demonstrate that our method can ensure the optimal consistency under\nsufficient exploration. In experiments on various benchmarks, GVR significantly\noutperforms state-of-the-art baselines.",
    "descriptor": "",
    "authors": [
      "Lipeng Wan",
      "Zeyang Liu",
      "Xingyu Chen",
      "Han Wang",
      "Xuguang Lan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.04454"
  },
  {
    "id": "arXiv:2112.04461",
    "title": "Enhancing Counterfactual Classification via Self-Training",
    "abstract": "Unlike traditional supervised learning, in many settings only partial\nfeedback is available. We may only observe outcomes for the chosen actions, but\nnot the counterfactual outcomes associated with other alternatives. Such\nsettings encompass a wide variety of applications including pricing, online\nmarketing and precision medicine. A key challenge is that observational data\nare influenced by historical policies deployed in the system, yielding a biased\ndata distribution. We approach this task as a domain adaptation problem and\npropose a self-training algorithm which imputes outcomes with categorical\nvalues for finite unseen actions in the observational data to simulate a\nrandomized trial through pseudolabeling, which we refer to as Counterfactual\nSelf-Training (CST). CST iteratively imputes pseudolabels and retrains the\nmodel. In addition, we show input consistency loss can further improve CST\nperformance which is shown in recent theoretical analysis of pseudolabeling. We\ndemonstrate the effectiveness of the proposed algorithms on both synthetic and\nreal datasets.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Ruijiang Gao",
      "Max Biggs",
      "Wei Sun",
      "Ligong Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04461"
  },
  {
    "id": "arXiv:2112.04465",
    "title": "Designing a Dashboard for Student Teamwork Analysis",
    "abstract": "Classroom dashboards are designed to help instructors effectively orchestrate\nclassrooms by providing summary statistics, activity tracking, and other\ninformation. Existing dashboards are generally specific to an LMS or platform\nand they generally summarize individual work, not group behaviors. However, CS\ncourses typically involve constellations of tools and mix on- and offline\ncollaboration. Thus, cross-platform monitoring of individuals and teams is\nimportant to develop a full picture of the class. In this work, we describe our\nwork on Concert, a data integration platform that collects data about student\nactivities from several sources such as Piazza, My Digital Hand, and GitHub and\nuses it to support classroom monitoring through analysis and visualizations. We\ndiscuss team visualizations that we have developed to support effective group\nmanagement and to help instructors identify teams in need of intervention.",
    "descriptor": "\nComments: In press: SIGCSE 2022\n",
    "authors": [
      "Niki Gitinabard",
      "Sarah Heckman",
      "Tiffany Barnes",
      "Collin F. Lynch"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.04465"
  },
  {
    "id": "arXiv:2112.04467",
    "title": "CoMPS: Continual Meta Policy Search",
    "abstract": "We develop a new continual meta-learning method to address challenges in\nsequential multi-task learning. In this setting, the agent's goal is to achieve\nhigh reward over any sequence of tasks quickly. Prior meta-reinforcement\nlearning algorithms have demonstrated promising results in accelerating the\nacquisition of new tasks. However, they require access to all tasks during\ntraining. Beyond simply transferring past experience to new tasks, our goal is\nto devise continual reinforcement learning algorithms that learn to learn,\nusing their experience on previous tasks to learn new tasks more quickly. We\nintroduce a new method, continual meta-policy search (CoMPS), that removes this\nlimitation by meta-training in an incremental fashion, over each task in a\nsequence, without revisiting prior tasks. CoMPS continuously repeats two\nsubroutines: learning a new task using RL and using the experience from RL to\nperform completely offline meta-learning to prepare for subsequent task\nlearning. We find that CoMPS outperforms prior continual learning and\noff-policy meta-reinforcement methods on several sequences of challenging\ncontinuous control tasks.",
    "descriptor": "\nComments: 23 pages, under review\n",
    "authors": [
      "Glen Berseth",
      "Zhiwei Zhang",
      "Grace Zhang",
      "Chelsea Finn",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.04467"
  },
  {
    "id": "arXiv:2112.04468",
    "title": "Revisiting Contrastive Learning through the Lens of Neighborhood  Component Analysis: an Integrated Framework",
    "abstract": "As a seminal tool in self-supervised representation learning, contrastive\nlearning has gained unprecedented attention in recent years. In essence,\ncontrastive learning aims to leverage pairs of positive and negative samples\nfor representation learning, which relates to exploiting neighborhood\ninformation in a feature space. By investigating the connection between\ncontrastive learning and neighborhood component analysis (NCA), we provide a\nnovel stochastic nearest neighbor viewpoint of contrastive learning and\nsubsequently propose a series of contrastive losses that outperform the\nexisting ones. Under our proposed framework, we show a new methodology to\ndesign integrated contrastive losses that could simultaneously achieve good\naccuracy and robustness on downstream tasks. With the integrated framework, we\nachieve up to 6\\% improvement on the standard accuracy and 17\\% improvement on\nthe adversarial accuracy.",
    "descriptor": "\nComments: The full version of SSLNeurIPS'21 contributed talk (NeurIPS 2021 Workshop: Self-Supervised Learning - Theory and Practice). Work in progress\n",
    "authors": [
      "Ching-Yun Ko",
      "Jeet Mohapatra",
      "Sijia Liu",
      "Pin-Yu Chen",
      "Luca Daniel",
      "Lily Weng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04468"
  },
  {
    "id": "arXiv:2112.04476",
    "title": "Canonical Representations for Direct Generation of Strategies in  High-level Petri Games",
    "abstract": "Petri games are a multi-player game model for the synthesis of distributed\nsystems with multiple concurrent processes based on Petri nets. The processes\nare the players in the game represented by the token of the net. The players\nare divided into two teams: the controllable system and the uncontrollable\nenvironment. An individual controller is synthesized for each process based\nonly on their locally available causality-based information. For one\nenvironment player and a bounded number of system players, the problem of\nsolving Petri games can be reduced to that of solving B\\\"uchi games. High-level\nPetri games are a concise representation of ordinary Petri games. Symmetries,\nderived from a high-level representation, can be exploited to significantly\nreduce the state space in the corresponding B\\\"uchi game. We present a new\nconstruction for solving high-level Petri games. It involves the definition of\na unique, canonical representation of the reduced B\\\"uchi game. This allows us\nto translate a strategy in the B\\\"uchi game directly into a strategy in the\nPetri game. An implementation applied on six structurally different benchmark\nfamilies shows in almost all cases a performance increase for larger state\nspaces.",
    "descriptor": "\nComments: 30 pages, 6 figures. arXiv admin note: substantial text overlap with arXiv:2103.10207\n",
    "authors": [
      "Manuel Gieseking",
      "Nick W\u00fcrdemann"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.04476"
  },
  {
    "id": "arXiv:2112.04477",
    "title": "Tracking People by Predicting 3D Appearance, Location & Pose",
    "abstract": "In this paper, we present an approach for tracking people in monocular\nvideos, by predicting their future 3D representations. To achieve this, we\nfirst lift people to 3D from a single frame in a robust way. This lifting\nincludes information about the 3D pose of the person, his or her location in\nthe 3D space, and the 3D appearance. As we track a person, we collect 3D\nobservations over time in a tracklet representation. Given the 3D nature of our\nobservations, we build temporal models for each one of the previous attributes.\nWe use these models to predict the future state of the tracklet, including 3D\nlocation, 3D appearance, and 3D pose. For a future frame, we compute the\nsimilarity between the predicted state of a tracklet and the single frame\nobservations in a probabilistic manner. Association is solved with simple\nHungarian matching, and the matches are used to update the respective\ntracklets. We evaluate our approach on various benchmarks and report\nstate-of-the-art results.",
    "descriptor": "\nComments: Project Page : this https URL\n",
    "authors": [
      "Jathushan Rajasegaran",
      "Georgios Pavlakos",
      "Angjoo Kanazawa",
      "Jitendra Malik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04477"
  },
  {
    "id": "arXiv:2112.04478",
    "title": "Prompting Visual-Language Models for Efficient Video Understanding",
    "abstract": "Visual-language pre-training has shown great success for learning joint\nvisual-textual representations from large-scale web data, demonstrating\nremarkable ability for zero-shot generalisation. This paper presents a simple\nmethod to efficiently adapt one pre-trained visual-language model to novel\ntasks with minimal training, and here, we consider video understanding tasks.\nSpecifically, we propose to optimise a few random vectors, termed as continuous\nprompt vectors, that convert the novel tasks into the same format as the\npre-training objectives. In addition, to bridge the gap between static images\nand videos, temporal information is encoded with lightweight Transformers\nstacking on top of frame-wise visual features. Experimentally, we conduct\nextensive ablation studies to analyse the critical components and necessities.\nOn 9 public benchmarks of action recognition, action localisation, and\ntext-video retrieval, across closed-set, few-shot, open-set scenarios, we\nachieve competitive or state-of-the-art performance to existing methods,\ndespite training significantly fewer parameters.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Chen Ju",
      "Tengda Han",
      "Kunhao Zheng",
      "Ya Zhang",
      "Weidi Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.04478"
  },
  {
    "id": "arXiv:2112.04480",
    "title": "Exploring Temporal Granularity in Self-Supervised Video Representation  Learning",
    "abstract": "This work presents a self-supervised learning framework named TeG to explore\nTemporal Granularity in learning video representations. In TeG, we sample a\nlong clip from a video and a short clip that lies inside the long clip. We then\nextract their dense temporal embeddings. The training objective consists of two\nparts: a fine-grained temporal learning objective to maximize the similarity\nbetween corresponding temporal embeddings in the short clip and the long clip,\nand a persistent temporal learning objective to pull together global embeddings\nof the two clips. Our study reveals the impact of temporal granularity with\nthree major findings. 1) Different video tasks may require features of\ndifferent temporal granularities. 2) Intriguingly, some tasks that are widely\nconsidered to require temporal awareness can actually be well addressed by\ntemporally persistent features. 3) The flexibility of TeG gives rise to\nstate-of-the-art results on 8 video benchmarks, outperforming supervised\npre-training in most cases.",
    "descriptor": "",
    "authors": [
      "Rui Qian",
      "Yeqing Li",
      "Liangzhe Yuan",
      "Boqing Gong",
      "Ting Liu",
      "Matthew Brown",
      "Serge Belongie",
      "Ming-Hsuan Yang",
      "Hartwig Adam",
      "Yin Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04480"
  },
  {
    "id": "arXiv:2112.04481",
    "title": "What's Behind the Couch? Directed Ray Distance Functions (DRDF) for 3D  Scene Reconstruction",
    "abstract": "We present an approach for scene-level 3D reconstruction, including occluded\nregions, from an unseen RGB image. Our approach is trained on real 3D scans and\nimages. This problem has proved difficult for multiple reasons; Real scans are\nnot watertight, precluding many methods; distances in scenes require reasoning\nacross objects (making it even harder); and, as we show, uncertainty about\nsurface locations motivates networks to produce outputs that lack basic\ndistance function properties. We propose a new distance-like function that can\nbe computed on unstructured scans and has good behavior under uncertainty about\nsurface location. Computing this function over rays reduces the complexity\nfurther. We train a deep network to predict this function and show it\noutperforms other methods on Matterport3D, 3D Front, and ScanNet.",
    "descriptor": "\nComments: Project Page see this https URL\n",
    "authors": [
      "Nilesh Kulkarni",
      "Justin Johnson",
      "David F. Fouhey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.04481"
  },
  {
    "id": "arXiv:2112.04482",
    "title": "FLAVA: A Foundational Language And Vision Alignment Model",
    "abstract": "State-of-the-art vision and vision-and-language models rely on large-scale\nvisio-linguistic pretraining for obtaining good performance on a variety of\ndownstream tasks. Generally, such models are often either cross-modal\n(contrastive) or multi-modal (with earlier fusion) but not both; and they often\nonly target specific modalities or tasks. A promising direction would be to use\na single holistic universal model, as a \"foundation\", that targets all\nmodalities at once -- a true vision and language foundation model should be\ngood at vision tasks, language tasks, and cross- and multi-modal vision and\nlanguage tasks. We introduce FLAVA as such a model and demonstrate impressive\nperformance on a wide range of 35 tasks spanning these target modalities.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Amanpreet Singh",
      "Ronghang Hu",
      "Vedanuj Goswami",
      "Guillaume Couairon",
      "Wojciech Galuba",
      "Marcus Rohrbach",
      "Douwe Kiela"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.04482"
  },
  {
    "id": "arXiv:2112.03251",
    "title": "Computing a link diagram from its exterior",
    "abstract": "A knot is circle piecewise-linearly embedded into the 3-sphere. The topology\nof a knot is intimately related to that of its exterior, which is the\ncomplement of an open regular neighborhood of the knot. Knots are typically\nencoded by planar diagrams, whereas their exteriors, which are compact\n3-manifolds with torus boundary, are encoded by triangulations. Here, we give\nthe first practical algorithm for finding a diagram of a knot given a\ntriangulation of its exterior. Our method applies to links as well as knots,\nand allows us to recover links with hundreds of crossings. We use it to find\nthe first diagrams known for 19 principal congruence arithmetic link exteriors;\nthe largest has over 1,000 crossings. Other applications include finding pairs\nof knots with the same 0-surgery, which relates to questions about slice knots\nand the smooth 4D Poincar\\'e conjecture.",
    "descriptor": "\nComments: 34 pages, 29 figures\n",
    "authors": [
      "Cameron Gates Rudd",
      "Nathan M. Dunfield",
      "Malik Obeidin"
    ],
    "subjectives": [
      "Geometric Topology (math.GT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.03251"
  },
  {
    "id": "arXiv:2112.03911",
    "title": "Dyadic Sex Composition and Task Classification Using fNIRS Hyperscanning  Data",
    "abstract": "Hyperscanning with functional near-infrared spectroscopy (fNIRS) is an\nemerging neuroimaging application that measures the nuanced neural signatures\nunderlying social interactions. Researchers have assessed the effect of sex and\ntask type (e.g., cooperation versus competition) on inter-brain coherence\nduring human-to-human interactions. However, no work has yet used deep\nlearning-based approaches to extract insights into sex and task-based\ndifferences in an fNIRS hyperscanning context. This work proposes a\nconvolutional neural network-based approach to dyadic sex composition and task\nclassification for an extensive hyperscanning dataset with $N = 222$\nparticipants. Inter-brain signal similarity computed using dynamic time warping\nis used as the input data. The proposed approach achieves a maximum\nclassification accuracy of greater than $80$ percent, thereby providing a new\navenue for exploring and understanding complex brain behavior.",
    "descriptor": "\nComments: 20th IEEE International Conference on Machine Learning and Applications\n",
    "authors": [
      "Liam A. Kruse",
      "Allan L. Reiss",
      "Mykel J. Kochenderfer",
      "Stephanie Balters"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03911"
  },
  {
    "id": "arXiv:2112.03915",
    "title": "GraDIRN: Learning Iterative Gradient Descent-based Energy Minimization  for Deformable Image Registration",
    "abstract": "We present a Gradient Descent-based Image Registration Network (GraDIRN) for\nlearning deformable image registration by embedding gradient-based iterative\nenergy minimization in a deep learning framework. Traditional image\nregistration algorithms typically use iterative energy-minimization\noptimization to find the optimal transformation between a pair of images, which\nis time-consuming when many iterations are needed. In contrast, recent\nlearning-based methods amortize this costly iterative optimization by training\ndeep neural networks so that registration of one pair of images can be achieved\nby fast network forward pass after training. Motivated by successes in image\nreconstruction techniques that combine deep learning with the mathematical\nstructure of iterative variational energy optimization, we formulate a novel\nregistration network based on multi-resolution gradient descent energy\nminimization. The forward pass of the network takes explicit image\ndissimilarity gradient steps and generalized regularization steps parameterized\nby Convolutional Neural Networks (CNN) for a fixed number of iterations. We use\nauto-differentiation to derive the forward computational graph for the explicit\nimage dissimilarity gradient w.r.t. the transformation, so arbitrary image\ndissimilarity metrics and transformation models can be used without complex and\nerror-prone gradient derivations. We demonstrate that this approach achieves\nstate-of-the-art registration performance while using fewer learnable\nparameters through extensive evaluations on registration tasks using 2D cardiac\nMR images and 3D brain MR images.",
    "descriptor": "",
    "authors": [
      "Huaqi Qiu",
      "Kerstin Hammernik",
      "Chen Qin",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03915"
  },
  {
    "id": "arXiv:2112.03916",
    "title": "BT-Unet: A self-supervised learning framework for biomedical image  segmentation using Barlow Twins with U-Net models",
    "abstract": "Deep learning has brought the most profound contribution towards biomedical\nimage segmentation to automate the process of delineation in medical imaging.\nTo accomplish such task, the models are required to be trained using huge\namount of annotated or labelled data that highlights the region of interest\nwith a binary mask. However, efficient generation of the annotations for such\nhuge data requires expert biomedical analysts and extensive manual effort. It\nis a tedious and expensive task, while also being vulnerable to human error. To\naddress this problem, a self-supervised learning framework, BT-Unet is proposed\nthat uses the Barlow Twins approach to pre-train the encoder of a U-Net model\nvia redundancy reduction in an unsupervised manner to learn data\nrepresentation. Later, complete network is fine-tuned to perform actual\nsegmentation. The BT-Unet framework can be trained with a limited number of\nannotated samples while having high number of unannotated samples, which is\nmostly the case in real-world problems. This framework is validated over\nmultiple U-Net models over diverse datasets by generating scenarios of a\nlimited number of labelled samples using standard evaluation metrics. With\nexhaustive experiment trials, it is observed that the BT-Unet framework\nenhances the performance of the U-Net models with significant margin under such\ncircumstances.",
    "descriptor": "",
    "authors": [
      "Narinder Singh Punn",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03916"
  },
  {
    "id": "arXiv:2112.03946",
    "title": "Generative Adversarial Network (GAN) and Enhanced Root Mean Square Error  (ERMSE): Deep Learning for Stock Price Movement Prediction",
    "abstract": "The prediction of stock price movement direction is significant in financial\ncircles and academic. Stock price contains complex, incomplete, and fuzzy\ninformation which makes it an extremely difficult task to predict its\ndevelopment trend. Predicting and analysing financial data is a nonlinear,\ntime-dependent problem. With rapid development in machine learning and deep\nlearning, this task can be performed more effectively by a purposely designed\nnetwork. This paper aims to improve prediction accuracy and minimizing\nforecasting error loss through deep learning architecture by using Generative\nAdversarial Networks. It was proposed a generic model consisting of Phase-space\nReconstruction (PSR) method for reconstructing price series and Generative\nAdversarial Network (GAN) which is a combination of two neural networks which\nare Long Short-Term Memory (LSTM) as Generative model and Convolutional Neural\nNetwork (CNN) as Discriminative model for adversarial training to forecast the\nstock market. LSTM will generate new instances based on historical basic\nindicators information and then CNN will estimate whether the data is predicted\nby LSTM or is real. It was found that the Generative Adversarial Network (GAN)\nhas performed well on the enhanced root mean square error to LSTM, as it was\n4.35% more accurate in predicting the direction and reduced processing time and\nRMSE by 78 secs and 0.029, respectively. This study provides a better result in\nthe accuracy of the stock index. It seems that the proposed system concentrates\non minimizing the root mean square error and processing time and improving the\ndirection prediction accuracy, and provides a better result in the accuracy of\nthe stock index.",
    "descriptor": "\nComments: 18 pages. Multimed Tools Appl, 2021\n",
    "authors": [
      "Ashish Kumar",
      "Abeer Alsadoon",
      "P. W. C. Prasad",
      "Salma Abdullah",
      "Tarik A. Rashid",
      "Duong Thu Hang Pham",
      "Tran Quoc Vinh Nguyen"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.03946"
  },
  {
    "id": "arXiv:2112.03998",
    "title": "Nuclei Segmentation in Histopathology Images using Deep Learning with  Local and Global Views",
    "abstract": "Digital pathology is one of the most significant developments in modern\nmedicine. Pathological examinations are the gold standard of medical protocols\nand play a fundamental role in diagnosis. Recently, with the advent of digital\nscanners, tissue histopathology slides can now be digitized and stored as\ndigital images. As a result, digitized histopathological tissues can be used in\ncomputer-aided image analysis programs and machine learning techniques.\nDetection and segmentation of nuclei are some of the essential steps in the\ndiagnosis of cancers. Recently, deep learning has been used for nuclei\nsegmentation. However, one of the problems in deep learning methods for nuclei\nsegmentation is the lack of information from out of the patches. This paper\nproposes a deep learning-based approach for nuclei segmentation, which\naddresses the problem of misprediction in patch border areas. We use both local\nand global patches to predict the final segmentation map. Experimental results\non the Multi-organ histopathology dataset demonstrate that our method\noutperforms the baseline nuclei segmentation and popular segmentation models.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Mahdi Arab Loodaricheh",
      "Nader Karimi",
      "Shadrokh Samavi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.03998"
  },
  {
    "id": "arXiv:2112.04013",
    "title": "A deep learning model for data-driven discovery of functional  connectivity",
    "abstract": "Functional connectivity (FC) studies have demonstrated the overarching value\nof studying the brain and its disorders through the undirected weighted graph\nof fMRI correlation matrix. Most of the work with the FC, however, depends on\nthe way the connectivity is computed, and further depends on the manual\npost-hoc analysis of the FC matrices. In this work we propose a deep learning\narchitecture BrainGNN that learns the connectivity structure as part of\nlearning to classify subjects. It simultaneously applies a graphical neural\nnetwork to this learned graph and learns to select a sparse subset of brain\nregions important to the prediction task. We demonstrate the model's\nstate-of-the-art classification performance on a schizophrenia fMRI dataset and\ndemonstrate how introspection leads to disorder relevant findings. The graphs\nlearned by the model exhibit strong class discrimination and the sparse subset\nof relevant regions are consistent with the schizophrenia literature.",
    "descriptor": "\nComments: Accepted at Algorithms 2021, 14(3), 75\n",
    "authors": [
      "Usman Mahmood",
      "Zening Fu",
      "Vince Calhoun",
      "Sergey Plis"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04013"
  },
  {
    "id": "arXiv:2112.04045",
    "title": "Efficient labeling algorithms for adjacent quadratic shortest paths",
    "abstract": "In this article, we study the Adjacent Quadratic Shortest Path Problem\n(AQSPP), which consists in finding the shortest path on a directed graph when\nits total weight component also includes the impact of consecutive arcs. We\nprovide a formal description of the AQSPP and propose an extension of\nDijkstra's algorithm (that we denote aqD) for solving AQSPPs in polynomial-time\nand provide a proof for its correctness under some mild assumptions.\nFurthermore, we introduce an adjacent quadratic A* algorithm (that we denote\naqA*) with a backward search for cost-to-go estimation to speed up the search.\nWe assess the performance of both algorithms by comparing their relative\nperformance with benchmark algorithms from the scientific literature and carry\nout a thorough collection of sensitivity analysis of the methods on a set of\nproblem characteristics using randomly generated graphs. Numerical results\nsuggest that: (i) aqA* outperforms all other algorithms, with a performance\nbeing about 75 times faster than aqD and the fastest alternative; (ii) the\nproposed solution procedures do not lose efficiency when the magnitude of\nquadratic costs vary; (iii) aqA* and aqD are fastest on random graph instances,\ncompared with benchmark algorithms from scientific literature. We conclude the\nnumerical experiments by presenting a stress test of the AQSPP in the context\nof real grid graph instances, with sizes up to $16 \\times 10^6$ nodes, $64\n\\times 10^6$ arcs, and $10^9$ quadratic arcs.",
    "descriptor": "",
    "authors": [
      "Jo\u00e3o Vilela",
      "Bruno Fanzeres",
      "Rafael Martinelli",
      "Claudio Contardo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.04045"
  },
  {
    "id": "arXiv:2112.04076",
    "title": "Experimental Characterization of Fault-Tolerant Circuits in Small-Scale  Quantum Processors",
    "abstract": "Experiments conducted on open-access cloud-based IBM Quantum devices are\npresented for characterizing their fault tolerance using $[4,2,2]$-encoded gate\nsequences. Up to 100 logical gates are activated in the IBMQ Bogota and IBMQ\nSantiago devices and we found that a $[4,2,2]$ code's logical gate set may be\ndeemed fault-tolerant for gate sequences larger than 10 gates. However, certain\ncircuits did not satisfy the fault tolerance criterion. In some cases, the\nencoded-gate sequences show a high error rate that is lower bounded at $\\approx\n0.1$, whereby the error inherent in these circuits cannot be mitigated by\nclassical post-selection. A comparison of the experimental results to a simple\nerror model reveals that the dominant gate errors cannot be readily represented\nby the popular Pauli error model. Finally, it is most accurate to assess the\nfault tolerance criterion when the circuits tested are restricted to those that\ngive rise to an output state with a low dimension.",
    "descriptor": "\nComments: Accepted for publication in IEEE Access\n",
    "authors": [
      "Rosie Cane",
      "Daryus Chandra",
      "Soon Xin Ng",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.04076"
  },
  {
    "id": "arXiv:2112.04101",
    "title": "Learning Linear Models Using Distributed Iterative Hessian Sketching",
    "abstract": "This work considers the problem of learning the Markov parameters of a linear\nsystem from observed data. Recent non-asymptotic system identification results\nhave characterized the sample complexity of this problem in the single and\nmulti-rollout setting. In both instances, the number of samples required in\norder to obtain acceptable estimates can produce optimization problems with an\nintractably large number of decision variables for a second-order algorithm. We\nshow that a randomized and distributed Newton algorithm based on\nHessian-sketching can produce $\\epsilon$-optimal solutions and converges\ngeometrically. Moreover, the algorithm is trivially parallelizable. Our results\nhold for a variety of sketching matrices and we illustrate the theory with\nnumerical examples.",
    "descriptor": "",
    "authors": [
      "Han Wang",
      "James Anderson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.04101"
  },
  {
    "id": "arXiv:2112.04121",
    "title": "Reverse image filtering using total derivative approximation and  accelerated gradient descent",
    "abstract": "In this paper, we address a new problem of reversing the effect of an image\nfilter, which can be linear or nonlinear. The assumption is that the algorithm\nof the filter is unknown and the filter is available as a black box. We\nformulate this inverse problem as minimizing a local patch-based cost function\nand use total derivative to approximate the gradient which is used in gradient\ndescent to solve the problem. We analyze factors affecting the convergence and\nquality of the output in the Fourier domain. We also study the application of\naccelerated gradient descent algorithms in three gradient-free reverse filters,\nincluding the one proposed in this paper. We present results from extensive\nexperiments to evaluate the complexity and effectiveness of the proposed\nalgorithm. Results demonstrate that the proposed algorithm outperforms the\nstate-of-the-art in that (1) it is at the same level of complexity as that of\nthe fastest reverse filter, but it can reverse a larger number of filters, and\n(2) it can reverse the same list of filters as that of the very complex reverse\nfilter, but its complexity is much smaller.",
    "descriptor": "",
    "authors": [
      "Fernando J. Galetto",
      "Guang Deng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04121"
  },
  {
    "id": "arXiv:2112.04151",
    "title": "A study on native American English speech recognition by Indian  listeners with varying word familiarity level",
    "abstract": "In this study, listeners of varied Indian nativities are asked to listen and\nrecognize TIMIT utterances spoken by American speakers. We have three kinds of\nresponses from each listener while they recognize an utterance: 1. Sentence\ndifficulty ratings, 2. Speaker difficulty ratings, and 3. Transcription of the\nutterance. From these transcriptions, word error rate (WER) is calculated and\nused as a metric to evaluate the similarity between the recognized and the\noriginal sentences.The sentences selected in this study are categorized into\nthree groups: Easy, Medium and Hard, based on the frequency ofoccurrence of the\nwords in them. We observe that the sentence, speaker difficulty ratings and the\nWERs increase from easy to hard categories of sentences. We also compare the\nhuman speech recognition performance with that using three automatic speech\nrecognition (ASR) under following three combinations of acoustic model (AM) and\nlanguage model(LM): ASR1) AM trained with recordings from speakers of Indian\norigin and LM built on TIMIT text, ASR2) AM using recordings from native\nAmerican speakers and LM built ontext from LIBRI speech corpus, and ASR3) AM\nusing recordings from native American speakers and LM build on LIBRI speech and\nTIMIT text. We observe that HSR performance is similar to that of ASR1 whereas\nASR3 achieves the best performance. Speaker nativity wise analysis shows that\nutterances from speakers of some nativity are more difficult to recognize by\nIndian listeners compared to few other nativities",
    "descriptor": "\nComments: 6 pages, 5 figues, COCOSDA 2021\n",
    "authors": [
      "Abhayjeet Singh",
      "Achuth Rao MV",
      "Rakesh Vaideeswaran",
      "Chiranjeevi Yarra",
      "Prasanta Kumar Ghosh"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.04151"
  },
  {
    "id": "arXiv:2112.04188",
    "title": "Beam Squint in Ultra-wideband mmWave Systems: RF Lens Array vs.  Phase-Shifter-Based Array",
    "abstract": "In this article, we discuss the potential of radio frequency (RF) lens for\nultra-wideband millimeter-wave (mmWave) systems. In terms of the beam squint,\nwe compare the proposed RF lens antenna with the phase shifter-based array for\nhybrid beamforming. To reduce the complexities for fully digital beamforming,\nresearchers have come up with RF lens-based hybrid beamforming. The use of\nmmWave systems, however, causes an increase in bandwidth, which gives rise to\nthe beam squint phenomenon. We first find the causative factors for beam squint\nin the dielectric RF lens antenna. Based on the beamforming gain at each\nfrequency, we verify that, in a specific situation, RF lens can be free of the\nbeam squint effect. We use 3D electromagnetic analysis software to numerically\ninterpret the beam squint of each antenna type. Based on the results, we\npresent the degraded spectral efficiency by system-level simulations with 3D\nindoor ray tracing. Finally, to verify our analysis, we fabricate an actual RF\nlens antenna and demonstrate the real performance using a mmWave, NI PXIe,\nsoftware-defined radio system.",
    "descriptor": "\nComments: 8 pages, 4 figures, 2 tables\n",
    "authors": [
      "Sang-Hyun Park",
      "Byoungnam Kim",
      "Dong Ku Kim",
      "Linglong Dai",
      "Kai-Kit Wong",
      "Chan-Byoung Chae"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04188"
  },
  {
    "id": "arXiv:2112.04234",
    "title": "A short review on quantum identity authentication protocols: How would  Bob know that he is talking with Alice?",
    "abstract": "Secure communication has achieved a new dimension with the advent of the\nschemes of quantum key distribution (QKD) as in contrast to classical\ncryptography, quantum cryptography can provide unconditional security. However,\na successful implementation of a scheme of QKD requires identity authentication\nas a prerequisite. A security loophole in the identity authentication scheme\nmay lead to the vulnerability of the entire secure communication scheme.\nConsequently, identity authentication is extremely important and in the last\nthree decades several schemes for identity authentication, using quantum\nresources have been proposed. The chronological development of these protocols,\nwhich are now referred to as quantum identity authentication (QIA) protocols,\nare briefly reviewed here with specific attention to the causal connection\ninvolved in their development. The existing protocols are classified on the\nbasis of the required quantum resources and their relative merits and demerits\nare analyzed. Further, in the process of the classification of the protocols\nfor QIA, it's observed that the existing protocols can also be classified in a\nfew groups based on the inherent computational tasks used to design the\nprotocols. Realization of these symmetries has led to the possibility of\ndesigning a set of new protocols for quantum identity authentication, which are\nbased on the existing schemes of the secure computational and communication\ntasks. The security of such protocols is also critically analyzed.",
    "descriptor": "\nComments: 3 New protocols of quantum identity authentication are proposed and the existing protocols are reviewed and classified\n",
    "authors": [
      "Arindam Dutta",
      "Anirban Pathak"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.04234"
  },
  {
    "id": "arXiv:2112.04267",
    "title": "Implicit Neural Representations for Image Compression",
    "abstract": "Recently Implicit Neural Representations (INRs) gained attention as a novel\nand effective representation for various data types. Thus far, prior work\nmostly focused on optimizing their reconstruction performance. This work\ninvestigates INRs from a novel perspective, i.e., as a tool for image\ncompression. To this end, we propose the first comprehensive compression\npipeline based on INRs including quantization, quantization-aware retraining\nand entropy coding. Encoding with INRs, i.e. overfitting to a data sample, is\ntypically orders of magnitude slower. To mitigate this drawback, we leverage\nmeta-learned initializations based on MAML to reach the encoding in fewer\ngradient updates which also generally improves rate-distortion performance of\nINRs. We find that our approach to source compression with INRs vastly\noutperforms similar prior work, is competitive with common compression\nalgorithms designed specifically for images and closes the gap to\nstate-of-the-art learned approaches based on Rate-Distortion Autoencoders.\nMoreover, we provide an extensive ablation study on the importance of\nindividual components of our method which we hope facilitates future research\non this novel approach to image compression.",
    "descriptor": "",
    "authors": [
      "Yannick Str\u00fcmpler",
      "Janis Postels",
      "Ren Yang",
      "Luc van Gool",
      "Federico Tombari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04267"
  },
  {
    "id": "arXiv:2112.04307",
    "title": "Physics-informed dynamic mode decomposition (piDMD)",
    "abstract": "In this work, we demonstrate how physical principles -- such as symmetries,\ninvariances, and conservation laws -- can be integrated into the dynamic mode\ndecomposition (DMD). DMD is a widely-used data analysis technique that extracts\nlow-rank modal structures and dynamics from high-dimensional measurements.\nHowever, DMD frequently produces models that are sensitive to noise, fail to\ngeneralize outside the training data, and violate basic physical laws. Our\nphysics-informed DMD (piDMD) optimization, which may be formulated as a\nProcrustes problem, restricts the family of admissible models to a matrix\nmanifold that respects the physical structure of the system. We focus on five\nfundamental physical principles -- conservation, self-adjointness,\nlocalization, causality, and shift-invariance -- and derive several closed-form\nsolutions and efficient algorithms for the corresponding piDMD optimizations.\nWith fewer degrees of freedom, piDMD models are less prone to overfitting,\nrequire less training data, and are often less computationally expensive to\nbuild than standard DMD models. We demonstrate piDMD on a range of challenging\nproblems in the physical sciences, including energy-preserving fluid flow,\ntravelling-wave systems, the Schr\\\"odinger equation, solute\nadvection-diffusion, a system with causal dynamics, and three-dimensional\ntransitional channel flow. In each case, piDMD significantly outperforms\nstandard DMD in metrics such as spectral identification, state prediction, and\nestimation of optimal forcings and responses.",
    "descriptor": "\nComments: 36 pages, 9 figures\n",
    "authors": [
      "Peter J. Baddoo",
      "Benjamin Herrmann",
      "Beverley J. McKeon",
      "J. Nathan Kutz",
      "Steven L. Brunton"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2112.04307"
  },
  {
    "id": "arXiv:2112.04322",
    "title": "Multiway Ensemble Kalman Filter",
    "abstract": "In this work, we study the emergence of sparsity and multiway structures in\nsecond-order statistical characterizations of dynamical processes governed by\npartial differential equations (PDEs). We consider several state-of-the-art\nmultiway covariance and inverse covariance (precision) matrix estimators and\nexamine their pros and cons in terms of accuracy and interpretability in the\ncontext of physics-driven forecasting when incorporated into the ensemble\nKalman filter (EnKF). In particular, we show that multiway data generated from\nthe Poisson and the convection-diffusion types of PDEs can be accurately\ntracked via EnKF when integrated with appropriate covariance and precision\nmatrix estimators.",
    "descriptor": "\nComments: Appeared in NeurIPS'21 Workshop on Machine Learning and the Physical Sciences\n",
    "authors": [
      "Yu Wang",
      "Alfred Hero"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.04322"
  },
  {
    "id": "arXiv:2112.04330",
    "title": "Estimation in Rotationally Invariant Generalized Linear Models via  Approximate Message Passing",
    "abstract": "We consider the problem of signal estimation in generalized linear models\ndefined via rotationally invariant design matrices. Since these matrices can\nhave an arbitrary spectral distribution, this model is well suited to capture\ncomplex correlation structures which often arise in applications. We propose a\nnovel family of approximate message passing (AMP) algorithms for signal\nestimation, and rigorously characterize their performance in the\nhigh-dimensional limit via a state evolution recursion. Assuming knowledge of\nthe design matrix spectrum, our rotationally invariant AMP has complexity of\nthe same order as the existing AMP for Gaussian matrices; it also recovers the\nexisting AMP as a special case. Numerical results showcase a performance close\nto Vector AMP (which is conjectured to be Bayes-optimal in some settings), but\nobtained with a much lower complexity, as the proposed algorithm does not\nrequire a computationally expensive singular value decomposition.",
    "descriptor": "\nComments: 31 pages, 4 figures\n",
    "authors": [
      "Ramji Venkataramanan",
      "Kevin K\u00f6gler",
      "Marco Mondelli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.04330"
  },
  {
    "id": "arXiv:2112.04336",
    "title": "Communication Now and Then: Analyzing the Republic of Letters as a  Communication Network",
    "abstract": "Huge advances in understanding patterns of human communication, and the\nunderlying social networks where it takes place, have been made recently using\nmassive automatically recorded data sets from digital communication, such as\nemails and phone calls. However, it is not clear to what extent these results\non human behaviour are artefacts of contemporary communication technology and\nculture and if the fundamental patterns in communication have changed over\nhistory. This paper presents an analysis of historical epistolary metadata with\nthe aim of comparing the underlying historical communication patterns with\nthose of contemporary communication. Our work uses a new epistolary dataset\ncontaining metadata on over 150 000 letters sent between the 16th and 19th\ncenturies. The analyses indicate striking resemblances between contemporary and\nepistolary communication network patterns, including dyadic interactions and\nego-level behaviour. Despite these positive findings, certain aspects of the\nletter datasets are insufficient to corroborate other similarities or\ndifferences for these communication networks.",
    "descriptor": "\nComments: 5 figures, presented in The 10th International Conference on Complex Networks and their Applications\n",
    "authors": [
      "Javier Ure\u00f1a-Carrion",
      "Petri Leskinen",
      "Jouni Tuominen",
      "Charles van den Heuvel",
      "Eero Hyv\u00f6nen",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.04336"
  },
  {
    "id": "arXiv:2112.04342",
    "title": "Micromechanical fatigue experiments for validation of  microstructure-sensitive fatigue simulation models",
    "abstract": "Crack initiation governs high cycle fatigue life and is susceptible to\nmicrostructural details. While corresponding microstructure-sensitive models\nare available, their validation is difficult. We propose a validation framework\nwhere a fatigue test is mimicked in a sub-modeling simulation by embedding the\nmeasured microstructure into the specimen geometry and adopting the\nexperimental boundary conditions. Exemplary, a phenomenological crystal\nplasticity model was applied to predict deformation in ferritic steel\n(EN1.4003). Hotspots in commonly used fatigue indicator parameter maps are\ncompared with damage segmented from micrographs. Along with the data, the\nframework is published for benchmarking future micromechanical fatigue models.",
    "descriptor": "",
    "authors": [
      "Ali Riza Durmaz",
      "Erik Natkowski",
      "Nikolai Arnaudov",
      "Petra Sonnweber-Ribic",
      "Stefan Weihe",
      "Sebastian M\u00fcnstermann",
      "Chris Eberl",
      "Peter Gumbsch"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.04342"
  },
  {
    "id": "arXiv:2112.04355",
    "title": "COSMIC: fast closed-form identification from large-scale data for LTV  systems",
    "abstract": "We introduce a closed-form method for identification of discrete-time linear\ntime-variant systems from data, formulating the learning problem as a\nregularized least squares problem where the regularizer favors smooth solutions\nwithin a trajectory. We develop a closed-form algorithm with guarantees of\noptimality and with a complexity that increases linearly with the number of\ninstants considered per trajectory. The COSMIC algorithm achieves the desired\nresult even in the presence of large volumes of data. Our method solved the\nproblem using two orders of magnitude less computational power than a general\npurpose convex solver and was about 3 times faster than a Stochastic Block\nCoordinate Descent especially designed method. Computational times of our\nmethod remained in the order of magnitude of the second even for 10k and 100k\ntime instants, where the general purpose solver crashed. To prove its\napplicability to real world systems, we test with spring-mass-damper system and\nuse the estimated model to find the optimal control path. Our algorithm was\napplied to both a Low Fidelity and Functional Engineering Simulators for the\nComet Interceptor mission, that requires precise pointing of the on-board\ncameras in a fast dynamics environment. Thus, this paper provides a fast\nalternative to classical system identification techniques for linear\ntime-variant systems, while proving to be a solid base for applications in the\nSpace industry and a step forward to the incorporation of algorithms that\nleverage data in such a safety-critical environment.",
    "descriptor": "",
    "authors": [
      "Maria Carvalho",
      "Claudia Soares",
      "Pedro Louren\u00e7o",
      "Rodrigo Ventura"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04355"
  },
  {
    "id": "arXiv:2112.04369",
    "title": "Adaptive R-Peak Detection on Wearable ECG Sensors for High-Intensity  Exercise",
    "abstract": "Objective: Continuous monitoring of biosignals via wearable sensors has\nquickly expanded in the medical and wellness fields. At rest, automatic\ndetection of vital parameters is generally accurate. However, in conditions\nsuch as high-intensity exercise, sudden physiological changes occur to the\nsignals, compromising the robustness of standard algorithms. Methods: Our\nmethod, called BayeSlope, is based on unsupervised learning, Bayesian\nfiltering, and non-linear normalization to enhance and correctly detect the R\npeaks according to their expected positions in the ECG. Furthermore, as\nBayeSlope is computationally heavy and can drain the device battery quickly, we\npropose an online design that adapts its robustness to sudden physiological\nchanges, and its complexity to the heterogeneous resources of modern embedded\nplatforms. This method combines BayeSlope with a lightweight algorithm,\nexecuted in cores with different capabilities, to reduce the energy consumption\nwhile preserving the accuracy. Results: BayeSlope achieves an F1 score of 99.3%\nin experiments during intense cycling exercise with 20 subjects. Additionally,\nthe online adaptive process achieves an F1 score of 99% across five different\nexercise intensities, with a total energy consumption of 1.55+-0.54~mJ.\nConclusion: We propose a highly accurate and robust method, and a complete\nenergy-efficient implementation in a modern ultra-low-power embedded platform\nto improve R peak detection in challenging conditions, such as during\nhigh-intensity exercise. Significance: The experiments show that BayeSlope\noutperforms a state-of-the-art algorithm up to 8.4% in F1 score, while our\nonline adaptive method can reach energy savings up to 38.7% on modern\nheterogeneous wearable platforms.",
    "descriptor": "\nComments: 12 pages, 14 figures, 2 tables\n",
    "authors": [
      "Elisabetta De Giovanni",
      "Tomas Teijeiro",
      "Gr\u00e9goire P. Millet",
      "David Atienza"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04369"
  },
  {
    "id": "arXiv:2112.04386",
    "title": "Which images to label for few-shot medical landmark detection?",
    "abstract": "The success of deep learning methods relies on the availability of\nwell-labeled large-scale datasets. However, for medical images, annotating such\nabundant training data often requires experienced radiologists and consumes\ntheir limited time. Few-shot learning is developed to alleviate this burden,\nwhich achieves competitive performances with only several labeled data.\nHowever, a crucial yet previously overlooked problem in few-shot learning is\nabout the selection of template images for annotation before learning, which\naffects the final performance. We herein propose a novel Sample Choosing Policy\n(SCP) to select \"the most worthy\" images for annotation, in the context of\nfew-shot medical landmark detection. SCP consists of three parts: 1)\nSelf-supervised training for building a pre-trained deep model to extract\nfeatures from radiological images, 2) Key Point Proposal for localizing\ninformative patches, and 3) Representative Score Estimation for searching the\nmost representative samples or templates. The advantage of SCP is demonstrated\nby various experiments on three widely-used public datasets. For one-shot\nmedical landmark detection, its use reduces the mean radial errors on\nCephalometric and HandXray datasets by 14.2% (from 3.595mm to 3.083mm) and\n35.5% (4.114mm to 2.653mm), respectively.",
    "descriptor": "",
    "authors": [
      "Quan Quan",
      "Qingsong Yao",
      "Jun Li",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04386"
  },
  {
    "id": "arXiv:2112.04416",
    "title": "The periodic complexity function of the Thue-Morse word and the  Rudin-Shapiro word",
    "abstract": "We revisit the periodic complexity function $h_{\\bf w}(n)$ introduced by\nMignosi and Restivo. This function gives the average of the first $n$ local\nperiods of a recurrent infinite word ${\\bf w}$. We give a different method than\nthat of Mignosi and Restivo for computing the asymptotics of the periodic\ncomplexity function of the Thue-Morse word and show how to apply the method to\nother automatic sequences, like the Rudin-Shapiro word.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Narad Rampersad"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2112.04416"
  },
  {
    "id": "arXiv:2112.04436",
    "title": "A Completeness Proof for A Regular Predicate Logic with Undefined Truth  Value",
    "abstract": "We provide a sound and complete proof system for an extension of Kleene's\nternary logic to predicates. The concept of theory is extended with, for each\nfunction symbol, a formula that specifies when the function is defined. The\nnotion of \"is defined\" is extended to terms and formulas via a straightforward\nrecursive algorithm. The \"is defined\" formulas are constructed so that they\nthemselves are always defined. The completeness proof relies on the Henkin\nconstruction. For each formula, precisely one of the formula, its negation, and\nthe negation of its \"is defined\" formula is true on the constructed model. Many\nother ternary logics in the literature can be reduced to ours. Partial\nfunctions are ubiquitous in computer science and even in (in)equation solving\nat schools. Our work was motivated by an attempt to explain, precisely in terms\nof logic, typical informal methods of reasoning in such applications.",
    "descriptor": "\nComments: 39 pages, 1 figure\n",
    "authors": [
      "Antti Valmari",
      "Lauri Hella"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.04436"
  },
  {
    "id": "arXiv:2112.04459",
    "title": "Self-Supervised Speaker Verification with Simple Siamese Network and  Self-Supervised Regularization",
    "abstract": "Training speaker-discriminative and robust speaker verification systems\nwithout speaker labels is still challenging and worthwhile to explore. In this\nstudy, we propose an effective self-supervised learning framework and a novel\nregularization strategy to facilitate self-supervised speaker representation\nlearning. Different from contrastive learning-based self-supervised learning\nmethods, the proposed self-supervised regularization (SSReg) focuses\nexclusively on the similarity between the latent representations of positive\ndata pairs. We also explore the effectiveness of alternative online data\naugmentation strategies on both the time domain and frequency domain. With our\nstrong online data augmentation strategy, the proposed SSReg shows the\npotential of self-supervised learning without using negative pairs and it can\nsignificantly improve the performance of self-supervised speaker representation\nlearning with a simple Siamese network architecture. Comprehensive experiments\non the VoxCeleb datasets demonstrate that our proposed self-supervised approach\nobtains a 23.4% relative improvement by adding the effective self-supervised\nregularization and outperforms other previous works.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Mufan Sang",
      "Haoqi Li",
      "Fang Liu",
      "Andrew O. Arnold",
      "Li Wan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.04459"
  },
  {
    "id": "arXiv:2112.04470",
    "title": "Optimistic Rates: A Unifying Theory for Interpolation Learning and  Regularization in Linear Regression",
    "abstract": "We study a localized notion of uniform convergence known as an \"optimistic\nrate\" (Panchenko 2002; Srebro et al. 2010) for linear regression with Gaussian\ndata. Our refined analysis avoids the hidden constant and logarithmic factor in\nexisting results, which are known to be crucial in high-dimensional settings,\nespecially for understanding interpolation learning. As a special case, our\nanalysis recovers the guarantee from Koehler et al. (2021), which tightly\ncharacterizes the population risk of low-norm interpolators under the benign\noverfitting conditions. Our optimistic rate bound, though, also analyzes\npredictors with arbitrary training error. This allows us to recover some\nclassical statistical guarantees for ridge and LASSO regression under random\ndesigns, and helps us obtain a precise understanding of the excess risk of\nnear-interpolators in the over-parameterized regime.",
    "descriptor": "",
    "authors": [
      "Lijia Zhou",
      "Frederic Koehler",
      "Danica J. Sutherland",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.04470"
  },
  {
    "id": "arXiv:2112.04475",
    "title": "Reliable Simulation of Quantum Channels",
    "abstract": "The Quantum Reverse Shannon Theorem has been a milestone in quantum\ninformation theory. It states that asymptotically reliable simulation of a\nquantum channel assisted by unlimited shared entanglement is possible, if and\nonly if, the classical communication cost is greater than or equal to the\nchannel's entanglement-assisted capacity. In this letter, we are concerned with\nthe performance of reliable reverse Shannon simulation of quantum channels. Our\nmain result is an in-depth characterization of the reliability function, that\nis, the optimal rate under which the performance of channel simulation\nasymptotically approaches the perfect. In particular, we have determined the\nexact formula of the reliability function when the classical communication cost\nis not too high -- below a critical value. In the derivation, we have also\nobtained an achievability bound for the simulation of finite many copies of the\nchannel, which is of realistic significance.",
    "descriptor": "",
    "authors": [
      "Ke Li",
      "Yongsheng Yao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.04475"
  },
  {
    "id": "arXiv:1811.11419",
    "title": "Mixture Martingales Revisited with Applications to Sequential Tests and  Confidence Intervals",
    "abstract": "Mixture Martingales Revisited with Applications to Sequential Tests and  Confidence Intervals",
    "descriptor": "",
    "authors": [
      "Emilie Kaufmann",
      "Wouter Koolen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1811.11419"
  },
  {
    "id": "arXiv:1901.01002",
    "title": "On Reproducing Kernel Banach Spaces: Generic Definitions and Unified  Framework of Constructions",
    "abstract": "On Reproducing Kernel Banach Spaces: Generic Definitions and Unified  Framework of Constructions",
    "descriptor": "",
    "authors": [
      "Rongrong Lin",
      "Haizhang Zhang",
      "Jun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1901.01002"
  },
  {
    "id": "arXiv:1905.10711",
    "title": "DISN: Deep Implicit Surface Network for High-quality Single-view 3D  Reconstruction",
    "abstract": "DISN: Deep Implicit Surface Network for High-quality Single-view 3D  Reconstruction",
    "descriptor": "",
    "authors": [
      "Qiangeng Xu",
      "Weiyue Wang",
      "Duygu Ceylan",
      "Radomir Mech",
      "Ulrich Neumann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1905.10711"
  },
  {
    "id": "arXiv:1906.06789",
    "title": "Providentia -- A Large-Scale Sensor System for the Assistance of  Autonomous Vehicles and Its Evaluation",
    "abstract": "Comments: Accepted for publication in the Journal of Field Robotics",
    "descriptor": "\nComments: Accepted for publication in the Journal of Field Robotics\n",
    "authors": [
      "Annkathrin Kr\u00e4mmer",
      "Christoph Sch\u00f6ller",
      "Dhiraj Gulati",
      "Venkatnarayanan Lakshminarasimhan",
      "Franz Kurz",
      "Dominik Rosenbaum",
      "Claus Lenz",
      "Alois Knoll"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1906.06789"
  },
  {
    "id": "arXiv:1907.00719",
    "title": "Expression of the peak time for time-domain boundary measurements in  diffuse light",
    "abstract": "Expression of the peak time for time-domain boundary measurements in  diffuse light",
    "descriptor": "",
    "authors": [
      "Junyong Eom",
      "Manabu Machida",
      "Gen Nakamura",
      "Goro Nishimura",
      "Chunlong Sun"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/1907.00719"
  },
  {
    "id": "arXiv:1907.09382",
    "title": "Domain-Specific Priors and Meta Learning for Few-Shot First-Person  Action Recognition",
    "abstract": "Comments: Paper has been accepted in Transactions on Pattern Analysis and Machine Intelligence",
    "descriptor": "\nComments: Paper has been accepted in Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Huseyin Coskun",
      "Zeeshan Zia",
      "Bugra Tekin",
      "Federica Bogo",
      "Nassir Navab",
      "Federico Tombari",
      "Harpreet Sawhney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1907.09382"
  },
  {
    "id": "arXiv:1910.09573",
    "title": "Detecting Underspecification with Local Ensembles",
    "abstract": "Comments: Published as a conference paper at ICLR 2020 under the title \"Detecting Extrapolation with Local Ensembles\"",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2020 under the title \"Detecting Extrapolation with Local Ensembles\"\n",
    "authors": [
      "David Madras",
      "James Atwood",
      "Alex D'Amour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.09573"
  },
  {
    "id": "arXiv:2002.05297",
    "title": "Solution manifold and Its Statistical Applications",
    "abstract": "Comments: Accepted to the Electronic Journal of Statistics. 34 page, 6 figures",
    "descriptor": "\nComments: Accepted to the Electronic Journal of Statistics. 34 page, 6 figures\n",
    "authors": [
      "Yen-Chi Chen"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Computational Geometry (cs.CG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2002.05297"
  },
  {
    "id": "arXiv:2003.01899",
    "title": "Robust Active Preference Elicitation",
    "abstract": "Comments: 74 pages, 10 figures, submitted for publication",
    "descriptor": "\nComments: 74 pages, 10 figures, submitted for publication\n",
    "authors": [
      "Phebe Vayanos",
      "Yingxiao Ye",
      "Duncan McElfresh",
      "John Dickerson",
      "Eric Rice"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2003.01899"
  },
  {
    "id": "arXiv:2003.12112",
    "title": "The Network Dynamics of Social and Technological Conventions",
    "abstract": "Comments: 21 pages, 6 figures",
    "descriptor": "\nComments: 21 pages, 6 figures\n",
    "authors": [
      "Joshua Becker"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2003.12112"
  },
  {
    "id": "arXiv:2006.10919",
    "title": "On the effect of normalization layers on Differentially Private training  of deep Neural networks",
    "abstract": "On the effect of normalization layers on Differentially Private training  of deep Neural networks",
    "descriptor": "",
    "authors": [
      "Ali Davody",
      "David Ifeoluwa Adelani",
      "Thomas Kleinbauer",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10919"
  },
  {
    "id": "arXiv:2006.11440",
    "title": "Local Convolutions Cause an Implicit Bias towards High Frequency  Adversarial Examples",
    "abstract": "Comments: 20 pages, 11 figures, 12 Tables",
    "descriptor": "\nComments: 20 pages, 11 figures, 12 Tables\n",
    "authors": [
      "Josue Ortega Caro",
      "Yilong Ju",
      "Ryan Pyle",
      "Sourav Dey",
      "Wieland Brendel",
      "Fabio Anselmi",
      "Ankit Patel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.11440"
  },
  {
    "id": "arXiv:2006.15294",
    "title": "Gradient-based Editing of Memory Examples for Online Task-free Continual  Learning",
    "abstract": "Comments: 10 pages. Accepted at NeurIPS 2021",
    "descriptor": "\nComments: 10 pages. Accepted at NeurIPS 2021\n",
    "authors": [
      "Xisen Jin",
      "Arka Sadhu",
      "Junyi Du",
      "Xiang Ren"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.15294"
  },
  {
    "id": "arXiv:2008.08401",
    "title": "Coverage-Based Debloating for Java Bytecode",
    "abstract": "Coverage-Based Debloating for Java Bytecode",
    "descriptor": "",
    "authors": [
      "C\u00e9sar Soto-Valero",
      "Thomas Durieux",
      "Nicolas Harrand",
      "Benoit Baudry"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2008.08401"
  },
  {
    "id": "arXiv:2008.10871",
    "title": "Analysis of the Feshbach-Schur method for the Fourier Spectral  discretizations of Schr{\u00f6}dinger operators",
    "abstract": "Analysis of the Feshbach-Schur method for the Fourier Spectral  discretizations of Schr{\u00f6}dinger operators",
    "descriptor": "",
    "authors": [
      "Genevi\u00e8ve Dusson",
      "Israel Sigal",
      "Benjamin Stamm"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.10871"
  },
  {
    "id": "arXiv:2009.04131",
    "title": "SoK: Certified Robustness for Deep Neural Networks",
    "abstract": "Comments: 14 pages for the main text",
    "descriptor": "\nComments: 14 pages for the main text\n",
    "authors": [
      "Linyi Li",
      "Xiangyu Qi",
      "Tao Xie",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.04131"
  },
  {
    "id": "arXiv:2009.12153",
    "title": "A Systematic Review on Model Watermarking for Neural Networks",
    "abstract": "A Systematic Review on Model Watermarking for Neural Networks",
    "descriptor": "",
    "authors": [
      "Franziska Boenisch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2009.12153"
  },
  {
    "id": "arXiv:2010.02787",
    "title": "Efficiently Approximating Vertex Cover on Scale-Free Networks with  Underlying Hyperbolic Geometry",
    "abstract": "Efficiently Approximating Vertex Cover on Scale-Free Networks with  Underlying Hyperbolic Geometry",
    "descriptor": "",
    "authors": [
      "Thomas Bl\u00e4sius",
      "Tobias Friedrich",
      "Maximilian Katzmann"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.02787"
  },
  {
    "id": "arXiv:2010.08036",
    "title": "State-Based Confidence Bounds for Data-Driven Stochastic Reachability  Using Hilbert Space Embeddings",
    "abstract": "State-Based Confidence Bounds for Data-Driven Stochastic Reachability  Using Hilbert Space Embeddings",
    "descriptor": "",
    "authors": [
      "Adam J. Thorpe",
      "Kendric R. Ortiz",
      "Meeko M. K. Oishi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.08036"
  },
  {
    "id": "arXiv:2011.02159",
    "title": "Reverse engineering learned optimizers reveals known and novel  mechanisms",
    "abstract": "Comments: Thirty-Fifth Conference on Neural Information Processing Systems. 2021",
    "descriptor": "\nComments: Thirty-Fifth Conference on Neural Information Processing Systems. 2021\n",
    "authors": [
      "Niru Maheswaranathan",
      "David Sussillo",
      "Luke Metz",
      "Ruoxi Sun",
      "Jascha Sohl-Dickstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.02159"
  },
  {
    "id": "arXiv:2011.07423",
    "title": "Declarative Approaches to Counterfactual Explanations for Classification",
    "abstract": "Comments: Camera-ready of journal version, with some final additions and revisions. Revised and considerably extended version of a RuleML-RR'20 paper [arXiv:2004.13237]. Submitted by invitation",
    "descriptor": "\nComments: Camera-ready of journal version, with some final additions and revisions. Revised and considerably extended version of a RuleML-RR'20 paper [arXiv:2004.13237]. Submitted by invitation\n",
    "authors": [
      "Leopoldo Bertossi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2011.07423"
  },
  {
    "id": "arXiv:2011.08148",
    "title": "Causal motifs and existence of endogenous cascades in directed networks  with application to company defaults",
    "abstract": "Comments: 12 pages, 4 figures",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Irena Barja\u0161i\u0107",
      "Hrvoje \u0160tefan\u010di\u0107",
      "Vedrana Pribi\u010devi\u0107",
      "Vinko Zlati\u0107"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Econometrics (econ.EM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2011.08148"
  },
  {
    "id": "arXiv:2011.13045",
    "title": "PLAD: Learning to Infer Shape Programs with Pseudo-Labels and  Approximate Distributions",
    "abstract": "PLAD: Learning to Infer Shape Programs with Pseudo-Labels and  Approximate Distributions",
    "descriptor": "",
    "authors": [
      "R. Kenny Jones",
      "Homer Walke",
      "Daniel Ritchie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.13045"
  },
  {
    "id": "arXiv:2012.06168",
    "title": "OpenHoldem: An Open Toolkit for Large-Scale Imperfect-Information Game  Research",
    "abstract": "OpenHoldem: An Open Toolkit for Large-Scale Imperfect-Information Game  Research",
    "descriptor": "",
    "authors": [
      "Kai Li",
      "Hang Xu",
      "Enmin Zhao",
      "Zhe Wu",
      "Junliang Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2012.06168"
  },
  {
    "id": "arXiv:2101.03280",
    "title": "Modeling and Detecting Network Communities with the Fusion of Node  Attributes",
    "abstract": "Comments: other authors do not want to preprint",
    "descriptor": "\nComments: other authors do not want to preprint\n",
    "authors": [
      "Ren Ren",
      "Jinliang Shao",
      "Wei Xing Zheng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2101.03280"
  },
  {
    "id": "arXiv:2101.06763",
    "title": "Multi-view Data Visualisation via Manifold Learning",
    "abstract": "Comments: 39 pages, 20 figures, 9 tables",
    "descriptor": "\nComments: 39 pages, 20 figures, 9 tables\n",
    "authors": [
      "Theodoulos Rodosthenous",
      "Vahid Shahrezaei",
      "Marina Evangelou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2101.06763"
  },
  {
    "id": "arXiv:2101.07295",
    "title": "Does Continual Learning = Catastrophic Forgetting?",
    "abstract": "Does Continual Learning = Catastrophic Forgetting?",
    "descriptor": "",
    "authors": [
      "Anh Thai",
      "Stefan Stojanov",
      "Zixuan Huang",
      "Isaac Rehg",
      "James M. Rehg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.07295"
  },
  {
    "id": "arXiv:2101.08331",
    "title": "A posteriori error estimates for hierarchical mixed-dimensional elliptic  equations",
    "abstract": "A posteriori error estimates for hierarchical mixed-dimensional elliptic  equations",
    "descriptor": "",
    "authors": [
      "Jhabriel Varela",
      "Elyes Ahmed",
      "Eirik Keilegavlen",
      "Jan Martin Nordbotten",
      "Florin Adrian Radu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.08331"
  },
  {
    "id": "arXiv:2101.08932",
    "title": "Sobolev Training for Physics Informed Neural Networks",
    "abstract": "Sobolev Training for Physics Informed Neural Networks",
    "descriptor": "",
    "authors": [
      "Hwijae Son",
      "Jin Woo Jang",
      "Woo Jin Han",
      "Hyung Ju Hwang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.08932"
  },
  {
    "id": "arXiv:2102.00983",
    "title": "Mosaics of combinatorial designs for information-theoretic security",
    "abstract": "Mosaics of combinatorial designs for information-theoretic security",
    "descriptor": "",
    "authors": [
      "Moritz Wiese",
      "Holger Boche"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2102.00983"
  },
  {
    "id": "arXiv:2102.03396",
    "title": "Error analysis of a decoupled finite element method for quad-curl  problems",
    "abstract": "Error analysis of a decoupled finite element method for quad-curl  problems",
    "descriptor": "",
    "authors": [
      "Shuhao Cao",
      "Long Chen",
      "Xuehai Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.03396"
  },
  {
    "id": "arXiv:2102.04640",
    "title": "Rethinking the Optimization of Average Precision: Only Penalizing  Negative Instances before Positive Ones is Enough",
    "abstract": "Rethinking the Optimization of Average Precision: Only Penalizing  Negative Instances before Positive Ones is Enough",
    "descriptor": "",
    "authors": [
      "Zhuo Li",
      "Weiqing Min",
      "Jiajun Song",
      "Yaohui Zhu",
      "Liping Kang",
      "Xiaoming Wei",
      "Xiaolin Wei",
      "Shuqiang Jiang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.04640"
  },
  {
    "id": "arXiv:2102.09284",
    "title": "Reduced-Order Neural Network Synthesis with Robustness Guarantees",
    "abstract": "Reduced-Order Neural Network Synthesis with Robustness Guarantees",
    "descriptor": "",
    "authors": [
      "Ross Drummond",
      "Mathew C. Turner",
      "Stephen R. Duncan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.09284"
  },
  {
    "id": "arXiv:2103.00218",
    "title": "Countering Malicious DeepFakes: Survey, Battleground, and Horizon",
    "abstract": "Comments: 48 pages",
    "descriptor": "\nComments: 48 pages\n",
    "authors": [
      "Felix Juefei-Xu",
      "Run Wang",
      "Yihao Huang",
      "Qing Guo",
      "Lei Ma",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.00218"
  },
  {
    "id": "arXiv:2103.01895",
    "title": "Adversarial Examples can be Effective Data Augmentation for Unsupervised  Machine Learning",
    "abstract": "Comments: This version has been accepted by AAAI-22",
    "descriptor": "\nComments: This version has been accepted by AAAI-22\n",
    "authors": [
      "Chia-Yi Hsu",
      "Pin-Yu Chen",
      "Songtao Lu",
      "Sijia Liu",
      "Chia-Mu Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.01895"
  },
  {
    "id": "arXiv:2103.04287",
    "title": "Reduction Free Normalisation for a proof irrelevant type of propositions",
    "abstract": "Comments: Corrected typos",
    "descriptor": "\nComments: Corrected typos\n",
    "authors": [
      "Thierry Coquand"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2103.04287"
  },
  {
    "id": "arXiv:2103.05895",
    "title": "WFA-IRL: Inverse Reinforcement Learning of Autonomous Behaviors Encoded  as Weighted Finite Automata",
    "abstract": "Comments: 15 pages, 7 figures",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Tianyu Wang",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2103.05895"
  },
  {
    "id": "arXiv:2103.08773",
    "title": "Unconstrained Face-Mask & Face-Hand Datasets: Building a Computer Vision  System to Help Prevent the Transmission of COVID-19",
    "abstract": "Comments: 9 pages, 4 figures",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Fevziye Irem Eyiokur",
      "Haz\u0131m Kemal Ekenel",
      "Alexander Waibel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.08773"
  },
  {
    "id": "arXiv:2103.10206",
    "title": "DanceFormer: Music Conditioned 3D Dance Generation with Parametric  Motion Transformer",
    "abstract": "Comments: This is the version accepted by AAAI-22",
    "descriptor": "\nComments: This is the version accepted by AAAI-22\n",
    "authors": [
      "Buyu Li",
      "Yongchi Zhao",
      "Zhelun Shi",
      "Lu Sheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.10206"
  },
  {
    "id": "arXiv:2103.11139",
    "title": "MogFace: Towards a Deeper Appreciation on Face Detection",
    "abstract": "MogFace: Towards a Deeper Appreciation on Face Detection",
    "descriptor": "",
    "authors": [
      "Yang Liu",
      "Fei Wang",
      "Baigui Sun",
      "Hao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.11139"
  },
  {
    "id": "arXiv:2103.11641",
    "title": "iRotate: Active Visual SLAM for Omnidirectional Robots",
    "abstract": "Comments: 13 pages, 11 figures, 3 tables. Submitted to RAS - Elsevier",
    "descriptor": "\nComments: 13 pages, 11 figures, 3 tables. Submitted to RAS - Elsevier\n",
    "authors": [
      "Elia Bonetto",
      "Pascal Goldschmid",
      "Michael Pabst",
      "Michael J. Black",
      "Aamir Ahmad"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.11641"
  },
  {
    "id": "arXiv:2103.14027",
    "title": "USB: Universal-Scale Object Detection Benchmark",
    "abstract": "USB: Universal-Scale Object Detection Benchmark",
    "descriptor": "",
    "authors": [
      "Yosuke Shinya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14027"
  },
  {
    "id": "arXiv:2103.15295",
    "title": "Best-Buddy GANs for Highly Detailed Image Super-Resolution",
    "abstract": "Best-Buddy GANs for Highly Detailed Image Super-Resolution",
    "descriptor": "",
    "authors": [
      "Wenbo Li",
      "Kun Zhou",
      "Lu Qi",
      "Liying Lu",
      "Nianjuan Jiang",
      "Jiangbo Lu",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15295"
  },
  {
    "id": "arXiv:2104.02721",
    "title": "Hierarchical compressed sensing",
    "abstract": "Comments: This book chapter is a report on findings within the DFG-funded priority program `Compressed Sensing in Information Processing' (CoSIP)",
    "descriptor": "\nComments: This book chapter is a report on findings within the DFG-funded priority program `Compressed Sensing in Information Processing' (CoSIP)\n",
    "authors": [
      "Jens Eisert",
      "Axel Flinth",
      "Benedikt Gro\u00df",
      "Ingo Roth",
      "Gerhard Wunder"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.02721"
  },
  {
    "id": "arXiv:2104.04450",
    "title": "Unsupervised Class-Incremental Learning Through Confusion",
    "abstract": "Unsupervised Class-Incremental Learning Through Confusion",
    "descriptor": "",
    "authors": [
      "Shivam Khare",
      "Kun Cao",
      "James Rehg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.04450"
  },
  {
    "id": "arXiv:2104.08029",
    "title": "T-LEAP: Occlusion-robust pose estimation of walking cows using temporal  information",
    "abstract": "T-LEAP: Occlusion-robust pose estimation of walking cows using temporal  information",
    "descriptor": "",
    "authors": [
      "Helena Russello",
      "Rik van der Tol",
      "Gert Kootstra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.08029"
  },
  {
    "id": "arXiv:2104.08793",
    "title": "SalKG: Learning From Knowledge Graph Explanations for Commonsense  Reasoning",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Aaron Chan",
      "Jiashu Xu",
      "Boyuan Long",
      "Soumya Sanyal",
      "Tanishq Gupta",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08793"
  },
  {
    "id": "arXiv:2104.15137",
    "title": "Tightening the Biological Constraints on Gradient-Based Predictive  Coding",
    "abstract": "Comments: This is a preprint of a published article. For final, published version see this https URL",
    "descriptor": "\nComments: This is a preprint of a published article. For final, published version see this https URL\n",
    "authors": [
      "Nick Alonso",
      "Emre Neftci"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2104.15137"
  },
  {
    "id": "arXiv:2105.02083",
    "title": "AdaBoost and robust one-bit compressed sensing",
    "abstract": "Comments: 40 pages, 4 figures, code available at this https URL, extended results to features that satisfy weak-moment and anti-concentration assumption",
    "descriptor": "\nComments: 40 pages, 4 figures, code available at this https URL, extended results to features that satisfy weak-moment and anti-concentration assumption\n",
    "authors": [
      "Geoffrey Chinot",
      "Felix Kuchelmeister",
      "Matthias L\u00f6ffler",
      "Sara van de Geer"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.02083"
  },
  {
    "id": "arXiv:2105.02087",
    "title": "Benchmarking Structured Policies and Policy Optimization for Real-World  Dexterous Object Manipulation",
    "abstract": "Benchmarking Structured Policies and Policy Optimization for Real-World  Dexterous Object Manipulation",
    "descriptor": "",
    "authors": [
      "Niklas Funk",
      "Charles Schaff",
      "Rishabh Madan",
      "Takuma Yoneda",
      "Julen Urain De Jesus",
      "Joe Watson",
      "Ethan K. Gordon",
      "Felix Widmaier",
      "Stefan Bauer",
      "Siddhartha S. Srinivasa",
      "Tapomayukh Bhattacharjee",
      "Matthew R. Walter",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.02087"
  },
  {
    "id": "arXiv:2105.06723",
    "title": "Bounded Reachability Problems are Decidable in FIFO Machines",
    "abstract": "Bounded Reachability Problems are Decidable in FIFO Machines",
    "descriptor": "",
    "authors": [
      "Benedikt Bollig",
      "Alain Finkel",
      "Amrita Suresh"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.06723"
  },
  {
    "id": "arXiv:2105.11590",
    "title": "A Quantum Hopfield Associative Memory Implemented on an Actual Quantum  Processor",
    "abstract": "Comments: This work is now published in Sci. Rep. at this https URL The e-print version shown here is 17 pages (13 for the main manuscript, 4 for the supplementary information), with a total of 11 figures and 3 tables. Figure S2 has been added since the prior pre-print version",
    "descriptor": "\nComments: This work is now published in Sci. Rep. at this https URL The e-print version shown here is 17 pages (13 for the main manuscript, 4 for the supplementary information), with a total of 11 figures and 3 tables. Figure S2 has been added since the prior pre-print version\n",
    "authors": [
      "Nathan Eli Miller",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11590"
  },
  {
    "id": "arXiv:2105.14039",
    "title": "Towards mental time travel: a hierarchical memory for reinforcement  learning agents",
    "abstract": "Comments: NeurIPS 2021; 10 pages main text; 29 pages total",
    "descriptor": "\nComments: NeurIPS 2021; 10 pages main text; 29 pages total\n",
    "authors": [
      "Andrew Kyle Lampinen",
      "Stephanie C.Y. Chan",
      "Andrea Banino",
      "Felix Hill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.14039"
  },
  {
    "id": "arXiv:2105.14785",
    "title": "Two Coupled Rejection Metrics Can Tell Adversarial Examples Apart",
    "abstract": "Two Coupled Rejection Metrics Can Tell Adversarial Examples Apart",
    "descriptor": "",
    "authors": [
      "Tianyu Pang",
      "Huishuai Zhang",
      "Di He",
      "Yinpeng Dong",
      "Hang Su",
      "Wei Chen",
      "Jun Zhu",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14785"
  },
  {
    "id": "arXiv:2106.00886",
    "title": "Partial Wasserstein Covering",
    "abstract": "Partial Wasserstein Covering",
    "descriptor": "",
    "authors": [
      "Keisuke Kawano",
      "Satoshi Koide",
      "Keisuke Otaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00886"
  },
  {
    "id": "arXiv:2106.01853",
    "title": "On the Computation of the Algebraic Closure of Finitely Generated Groups  of Matrices",
    "abstract": "On the Computation of the Algebraic Closure of Finitely Generated Groups  of Matrices",
    "descriptor": "",
    "authors": [
      "Klara Nosan",
      "Amaury Pouly",
      "Sylvain Schmitz",
      "Mahsa Shirmohammadi",
      "James Worrell"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Algebraic Geometry (math.AG)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.01853"
  },
  {
    "id": "arXiv:2106.02543",
    "title": "Accelerating Dynamical System Simulations with Contracting and  Physics-Projected Neural-Newton Solvers",
    "abstract": "Accelerating Dynamical System Simulations with Contracting and  Physics-Projected Neural-Newton Solvers",
    "descriptor": "",
    "authors": [
      "Samuel Chevalier",
      "Jochen Stiasny",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02543"
  },
  {
    "id": "arXiv:2106.05165",
    "title": "A Lyapunov-Based Methodology for Constrained Optimization with Bandit  Feedback",
    "abstract": "A Lyapunov-Based Methodology for Constrained Optimization with Bandit  Feedback",
    "descriptor": "",
    "authors": [
      "Semih Cayci",
      "Yilin Zheng",
      "Atilla Eryilmaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.05165"
  },
  {
    "id": "arXiv:2106.05963",
    "title": "Learning to See by Looking at Noise",
    "abstract": "Learning to See by Looking at Noise",
    "descriptor": "",
    "authors": [
      "Manel Baradad",
      "Jonas Wulff",
      "Tongzhou Wang",
      "Phillip Isola",
      "Antonio Torralba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05963"
  },
  {
    "id": "arXiv:2106.07880",
    "title": "Scaling Neural Tangent Kernels via Sketching and Random Features",
    "abstract": "Comments: This is a merger of arXiv:2104.01351, arXiv:2104.00415",
    "descriptor": "\nComments: This is a merger of arXiv:2104.01351, arXiv:2104.00415\n",
    "authors": [
      "Amir Zandieh",
      "Insu Han",
      "Haim Avron",
      "Neta Shoham",
      "Chaewon Kim",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.07880"
  },
  {
    "id": "arXiv:2106.08482",
    "title": "Minimizing Communication while Maximizing Performance in Multi-Agent  Reinforcement Learning",
    "abstract": "Minimizing Communication while Maximizing Performance in Multi-Agent  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Varun Kumar Vijay",
      "Hassam Sheikh",
      "Somdeb Majumdar",
      "Mariano Phielipp"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08482"
  },
  {
    "id": "arXiv:2106.08928",
    "title": "Recursive Construction of Stable Assemblies of Recurrent Neural Networks",
    "abstract": "Comments: 23 pages, 3 figures",
    "descriptor": "\nComments: 23 pages, 3 figures\n",
    "authors": [
      "Leo Kozachkov",
      "Michaela Ennis",
      "Jean-Jacques Slotine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.08928"
  },
  {
    "id": "arXiv:2106.11107",
    "title": "Electromagnetic Interference in RIS-Aided Communications",
    "abstract": "Comments: 5 pages, 5 figures, IEEE Wireless Communication Letters",
    "descriptor": "\nComments: 5 pages, 5 figures, IEEE Wireless Communication Letters\n",
    "authors": [
      "Andrea De Jesus Torres",
      "Luca Sanguinetti",
      "Emil Bj\u00f6rnson"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11107"
  },
  {
    "id": "arXiv:2106.12026",
    "title": "The Neurally-Guided Shape Parser: Grammar-based Labeling of 3D Shape  Regions with Approximate Inference",
    "abstract": "The Neurally-Guided Shape Parser: Grammar-based Labeling of 3D Shape  Regions with Approximate Inference",
    "descriptor": "",
    "authors": [
      "R. Kenny Jones",
      "Aalia Habib",
      "Rana Hanocka",
      "Daniel Ritchie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12026"
  },
  {
    "id": "arXiv:2106.13321",
    "title": "Game theory and scholarly publishing: premises for an agreement around  open access",
    "abstract": "Game theory and scholarly publishing: premises for an agreement around  open access",
    "descriptor": "",
    "authors": [
      "Abdelghani Maddi"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.13321"
  },
  {
    "id": "arXiv:2106.15796",
    "title": "Monocular 3D Object Detection: An Extrinsic Parameter Free Approach",
    "abstract": "Monocular 3D Object Detection: An Extrinsic Parameter Free Approach",
    "descriptor": "",
    "authors": [
      "Yunsong Zhou",
      "Yuan He",
      "Hongzi Zhu",
      "Cheng Wang",
      "Hongyang Li",
      "Qinhong Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15796"
  },
  {
    "id": "arXiv:2107.00650",
    "title": "CLIP-It! Language-Guided Video Summarization",
    "abstract": "Comments: Neurips 2021. Website at this https URL",
    "descriptor": "\nComments: Neurips 2021. Website at this https URL\n",
    "authors": [
      "Medhini Narasimhan",
      "Anna Rohrbach",
      "Trevor Darrell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.00650"
  },
  {
    "id": "arXiv:2107.05840",
    "title": "NucMM Dataset: 3D Neuronal Nuclei Instance Segmentation at Sub-Cubic  Millimeter Scale",
    "abstract": "Comments: MICCAI 2021. Fix typos and update citations",
    "descriptor": "\nComments: MICCAI 2021. Fix typos and update citations\n",
    "authors": [
      "Zudi Lin",
      "Donglai Wei",
      "Mariela D. Petkova",
      "Yuelong Wu",
      "Zergham Ahmed",
      "Krishna Swaroop K",
      "Silin Zou",
      "Nils Wendt",
      "Jonathan Boulanger-Weill",
      "Xueying Wang",
      "Nagaraju Dhanyasi",
      "Ignacio Arganda-Carreras",
      "Florian Engert",
      "Jeff Lichtman",
      "Hanspeter Pfister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05840"
  },
  {
    "id": "arXiv:2107.09480",
    "title": "Learned Sorted Table Search and Static Indexes in Small Model Space",
    "abstract": "Learned Sorted Table Search and Static Indexes in Small Model Space",
    "descriptor": "",
    "authors": [
      "Domenico Amato",
      "Giosu\u00e8 Lo Bosco",
      "Raffaele Giancarlo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.09480"
  },
  {
    "id": "arXiv:2107.10724",
    "title": "Reproducibility of COVID-19 pre-prints",
    "abstract": "Comments: 14 pages, 6 tables, 4 figures 2021-12-08 replacement fixes a few incorrect references and adds reference to some additional papers",
    "descriptor": "\nComments: 14 pages, 6 tables, 4 figures 2021-12-08 replacement fixes a few incorrect references and adds reference to some additional papers\n",
    "authors": [
      "Annie Collins",
      "Rohan Alexander"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)",
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.10724"
  },
  {
    "id": "arXiv:2107.10845",
    "title": "QuantumNAS: Noise-Adaptive Search for Robust Quantum Circuits",
    "abstract": "Comments: Published as a conference paper in HPCA 2022. 14 pages, 22 figures. Code available at this https URL",
    "descriptor": "\nComments: Published as a conference paper in HPCA 2022. 14 pages, 22 figures. Code available at this https URL\n",
    "authors": [
      "Hanrui Wang",
      "Yongshan Ding",
      "Jiaqi Gu",
      "Zirui Li",
      "Yujun Lin",
      "David Z. Pan",
      "Frederic T. Chong",
      "Song Han"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.10845"
  },
  {
    "id": "arXiv:2108.02866",
    "title": "Dual Reader-Parser on Hybrid Textual and Tabular Evidence for Open  Domain Question Answering",
    "abstract": "Comments: 15 pages, LaTeX; typos corrected, add the open source code link; published to ACL 2021",
    "descriptor": "\nComments: 15 pages, LaTeX; typos corrected, add the open source code link; published to ACL 2021\n",
    "authors": [
      "Alexander Hanbo Li",
      "Patrick Ng",
      "Peng Xu",
      "Henghui Zhu",
      "Zhiguo Wang",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.02866"
  },
  {
    "id": "arXiv:2108.02949",
    "title": "Auxiliary Class Based Multiple Choice Learning",
    "abstract": "Auxiliary Class Based Multiple Choice Learning",
    "descriptor": "",
    "authors": [
      "Sihwan Kim",
      "Dae Yon Jung",
      "Taejang Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.02949"
  },
  {
    "id": "arXiv:2108.02994",
    "title": "Rollout event-triggered control: Reconciling event- and time-triggered  control",
    "abstract": "Comments: 12 pages, 9 figures; extended literature review, justified assumptions on token bucket, updated numerical examples",
    "descriptor": "\nComments: 12 pages, 9 figures; extended literature review, justified assumptions on token bucket, updated numerical examples\n",
    "authors": [
      "Stefan Wildhagen",
      "Frank D\u00fcrr",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.02994"
  },
  {
    "id": "arXiv:2108.04591",
    "title": "Event-Triggered State Estimation with Multiple Noisy Sensor Nodes",
    "abstract": "Event-Triggered State Estimation with Multiple Noisy Sensor Nodes",
    "descriptor": "",
    "authors": [
      "Koen J. A. Scheres",
      "Michelle S. Chong",
      "Romain Postoyan",
      "W. P. Maurice H. Heemels"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.04591"
  },
  {
    "id": "arXiv:2108.10274",
    "title": "Towards Explainable Fact Checking",
    "abstract": "Comments: Thesis presented to the University of Copenhagen Faculty of Science in partial fulfillment of the requirements for the degree of Doctor Scientiarum (Dr. Scient.)",
    "descriptor": "\nComments: Thesis presented to the University of Copenhagen Faculty of Science in partial fulfillment of the requirements for the degree of Doctor Scientiarum (Dr. Scient.)\n",
    "authors": [
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.10274"
  },
  {
    "id": "arXiv:2108.10943",
    "title": "Correcting inter-scan motion artefacts in quantitative R1 mapping at 7T",
    "abstract": "Correcting inter-scan motion artefacts in quantitative R1 mapping at 7T",
    "descriptor": "",
    "authors": [
      "Ya\u00ebl Balbastre",
      "Ali Aghaeifar",
      "Nad\u00e8ge Corbin",
      "Mikael Brudfors",
      "John Ashburner",
      "Martina F. Callaghan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.10943"
  },
  {
    "id": "arXiv:2108.11345",
    "title": "A Unifying Theory of Thompson Sampling for Continuous Risk-Averse  Bandits",
    "abstract": "Comments: 9 pages main paper with 8 pages supplementary material. Accepted to the Association for the Advancement of Artificial Intelligence (AAAI) 2022",
    "descriptor": "\nComments: 9 pages main paper with 8 pages supplementary material. Accepted to the Association for the Advancement of Artificial Intelligence (AAAI) 2022\n",
    "authors": [
      "Joel Q. L. Chang",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.11345"
  },
  {
    "id": "arXiv:2108.12565",
    "title": "AMMASurv: Asymmetrical Multi-Modal Attention for Accurate Survival  Analysis with Whole Slide Images and Gene Expression Data",
    "abstract": "Comments: 4 pages. Accepted by IEEE BIBM 2021",
    "descriptor": "\nComments: 4 pages. Accepted by IEEE BIBM 2021\n",
    "authors": [
      "Ruoqi Wang",
      "Ziwang Huang",
      "Haitao Wang",
      "Hejun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.12565"
  },
  {
    "id": "arXiv:2108.12828",
    "title": "MEDIC: A Multi-Task Learning Dataset for Disaster Image Classification",
    "abstract": "Comments: Multi-task Learning, Social media images, Image Classification, Natural disasters, Crisis Informatics, Deep learning, Dataset",
    "descriptor": "\nComments: Multi-task Learning, Social media images, Image Classification, Natural disasters, Crisis Informatics, Deep learning, Dataset\n",
    "authors": [
      "Firoj Alam",
      "Tanvirul Alam",
      "Md. Arid Hasan",
      "Abul Hasnat",
      "Muhammad Imran",
      "Ferda Ofli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.12828"
  },
  {
    "id": "arXiv:2108.13659",
    "title": "Gray Cycles of Maximum Length Related to k-Character Substitutions",
    "abstract": "Gray Cycles of Maximum Length Related to k-Character Substitutions",
    "descriptor": "",
    "authors": [
      "Jean N\u00e9raud"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2108.13659"
  },
  {
    "id": "arXiv:2109.04442",
    "title": "FGOT: Graph Distances based on Filters and Optimal Transport",
    "abstract": "FGOT: Graph Distances based on Filters and Optimal Transport",
    "descriptor": "",
    "authors": [
      "Hermina Petric Maretic",
      "Mireille El Gheche",
      "Giovanni Chierchia",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04442"
  },
  {
    "id": "arXiv:2109.04756",
    "title": "On Inverse Inertia Matrix and Contact-Force Model for Robotic  Manipulators at Normal Impacts",
    "abstract": "On Inverse Inertia Matrix and Contact-Force Model for Robotic  Manipulators at Normal Impacts",
    "descriptor": "",
    "authors": [
      "Yuquan Wang",
      "Niels Dehio",
      "Abderrahmane Kheddar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04756"
  },
  {
    "id": "arXiv:2109.05327",
    "title": "An Objective Metric for Explainable AI: How and Why to Estimate the  Degree of Explainability",
    "abstract": "Comments: Source code at: this https URL",
    "descriptor": "\nComments: Source code at: this https URL\n",
    "authors": [
      "Francesco Sovrano",
      "Fabio Vitali"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05327"
  },
  {
    "id": "arXiv:2109.06576",
    "title": "The Effect of False Positives: Why Fuzzy Message Detection Leads to  Fuzzy Privacy Guarantees?",
    "abstract": "Comments: Financial Cryptography and Data Security 2022",
    "descriptor": "\nComments: Financial Cryptography and Data Security 2022\n",
    "authors": [
      "Istv\u00e1n Andr\u00e1s Seres",
      "Bal\u00e1zs Pej\u00f3",
      "P\u00e9ter Burcsi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.06576"
  },
  {
    "id": "arXiv:2109.07627",
    "title": "Adversarially Regularized Policy Learning Guided by Trajectory  Optimization",
    "abstract": "Adversarially Regularized Policy Learning Guided by Trajectory  Optimization",
    "descriptor": "",
    "authors": [
      "Zhigen Zhao",
      "Simiao Zuo",
      "Tuo Zhao",
      "Ye Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07627"
  },
  {
    "id": "arXiv:2109.08129",
    "title": "Does Summary Evaluation Survive Translation to Other Languages?",
    "abstract": "Comments: 9 pages, 6 figures, 1 table, 3 appendixes",
    "descriptor": "\nComments: 9 pages, 6 figures, 1 table, 3 appendixes\n",
    "authors": [
      "Spencer Braun",
      "Oleg Vasilyev",
      "Neslihan Iskender",
      "John Bohannon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.08129"
  },
  {
    "id": "arXiv:2109.09991",
    "title": "Learning Kernel-Smoothed Machine Translation with Retrieved Examples",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Qingnan Jiang",
      "Mingxuan Wang",
      "Jun Cao",
      "Shanbo Cheng",
      "Shujian Huang",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.09991"
  },
  {
    "id": "arXiv:2109.10074",
    "title": "STAR: Distributed Secret Sharing for Private Threshold Aggregation  Reporting",
    "abstract": "STAR: Distributed Secret Sharing for Private Threshold Aggregation  Reporting",
    "descriptor": "",
    "authors": [
      "Alex Davidson",
      "Peter Snyder",
      "E. B. Quirk",
      "Joseph Genereux",
      "Benjamin Livshits"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.10074"
  },
  {
    "id": "arXiv:2109.11817",
    "title": "Unbiased Gradient Estimation with Balanced Assignments for Mixtures of  Experts",
    "abstract": "Comments: I (Still) Can't Believe It's Not Better Workshop at NeurIPS 2021",
    "descriptor": "\nComments: I (Still) Can't Believe It's Not Better Workshop at NeurIPS 2021\n",
    "authors": [
      "Wouter Kool",
      "Chris J. Maddison",
      "Andriy Mnih"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.11817"
  },
  {
    "id": "arXiv:2109.13283",
    "title": "CS Education for the Socially-Just Worlds We Need: The Case for  Justice-Centered Approaches to CS in Higher Education",
    "abstract": "Comments: Position paper in the Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 1 (SIGCSE 2022); 7 pages",
    "descriptor": "\nComments: Position paper in the Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 1 (SIGCSE 2022); 7 pages\n",
    "authors": [
      "Kevin Lin"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.13283"
  },
  {
    "id": "arXiv:2109.13871",
    "title": "Expectation-based Minimalist Grammars",
    "abstract": "Comments: This is an extended version of a paper published in CLiC-it 2021 - Italian Conference on Computational Linguistics 2021 - Proceedings of the Eighth Italian Conference on Computational Linguistics Milan, Italy, January 26-28, 2022. Edited by Elisabetta Fersini, Marco Passarotti, Viviana Patti. CEUR-WS.org, ISSN 1613-0073",
    "descriptor": "\nComments: This is an extended version of a paper published in CLiC-it 2021 - Italian Conference on Computational Linguistics 2021 - Proceedings of the Eighth Italian Conference on Computational Linguistics Milan, Italy, January 26-28, 2022. Edited by Elisabetta Fersini, Marco Passarotti, Viviana Patti. CEUR-WS.org, ISSN 1613-0073\n",
    "authors": [
      "Cristiano Chesi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.13871"
  },
  {
    "id": "arXiv:2110.00954",
    "title": "Adaptive Real-Time Grid Operation via Online Feedback Optimization with  Sensitivity Estimation",
    "abstract": "Adaptive Real-Time Grid Operation via Online Feedback Optimization with  Sensitivity Estimation",
    "descriptor": "",
    "authors": [
      "Miguel Picallo",
      "Lukas Ortmann",
      "Saverio Bolognani",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.00954"
  },
  {
    "id": "arXiv:2110.01445",
    "title": "Robust and Decomposable Average Precision for Image Retrieval",
    "abstract": "Robust and Decomposable Average Precision for Image Retrieval",
    "descriptor": "",
    "authors": [
      "Elias Ramzi",
      "Nicolas Thome",
      "Cl\u00e9ment Rambour",
      "Nicolas Audebert",
      "Xavier Bitot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.01445"
  },
  {
    "id": "arXiv:2110.01471",
    "title": "Fine-Grained Neural Network Explanation by Identifying Input Features  with Predictive Information",
    "abstract": "Comments: NeurIPS 2021 (Neural Information Processing Systems)",
    "descriptor": "\nComments: NeurIPS 2021 (Neural Information Processing Systems)\n",
    "authors": [
      "Yang Zhang",
      "Ashkan Khakzar",
      "Yawei Li",
      "Azade Farshad",
      "Seong Tae Kim",
      "Nassir Navab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.01471"
  },
  {
    "id": "arXiv:2110.01607",
    "title": "Using Out-of-the-Box Frameworks for Contrastive Unpaired Image  Translation for Vestibular Schwannoma and Cochlea Segmentation: An approach  for the crossMoDA Challenge",
    "abstract": "Comments: 9 pages, 3 figures, MICCAI 2021 Cross-Modality Domain Adaptation for Medical Image Segmentation Challenge; extended manuscript and modified results",
    "descriptor": "\nComments: 9 pages, 3 figures, MICCAI 2021 Cross-Modality Domain Adaptation for Medical Image Segmentation Challenge; extended manuscript and modified results\n",
    "authors": [
      "Jae Won Choi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.01607"
  },
  {
    "id": "arXiv:2110.02905",
    "title": "Geometric and Physical Quantities Improve E(3) Equivariant Message  Passing",
    "abstract": "Comments: Github: this https URL",
    "descriptor": "\nComments: Github: this https URL\n",
    "authors": [
      "Johannes Brandstetter",
      "Rob Hesselink",
      "Elise van der Pol",
      "Erik J Bekkers",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02905"
  },
  {
    "id": "arXiv:2110.03165",
    "title": "Offline RL With Resource Constrained Online Deployment",
    "abstract": "Comments: Added experiments on discrete control and real world datasets along with more analyses on continuous control tasks",
    "descriptor": "\nComments: Added experiments on discrete control and real world datasets along with more analyses on continuous control tasks\n",
    "authors": [
      "Jayanth Reddy Regatti",
      "Aniket Anand Deshmukh",
      "Frank Cheng",
      "Young Hun Jung",
      "Abhishek Gupta",
      "Urun Dogan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03165"
  },
  {
    "id": "arXiv:2110.05610",
    "title": "TSK Fuzzy System Towards Few Labeled Incomplete Multi-View Data  Classification",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Wei Zhang",
      "Zhaohong Deng",
      "Qiongdan Lou",
      "Te Zhang",
      "Kup-Sze Choi",
      "Shitong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05610"
  },
  {
    "id": "arXiv:2110.05942",
    "title": "Resolution of the Linear-Bounded Automata Question",
    "abstract": "Comments: The definition of enumeration supplemented, feedbacks are welcome",
    "descriptor": "\nComments: The definition of enumeration supplemented, feedbacks are welcome\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.05942"
  },
  {
    "id": "arXiv:2110.06661",
    "title": "A Primer on Near-Field Beamforming for Arrays and Reconfigurable  Intelligent Surfaces",
    "abstract": "Comments: 8 pages, 9 figures, To appear on the Asilomar Conference on Signals, Systems, and Computers, 2021",
    "descriptor": "\nComments: 8 pages, 9 figures, To appear on the Asilomar Conference on Signals, Systems, and Computers, 2021\n",
    "authors": [
      "Emil Bj\u00f6rnson",
      "\u00d6zlem Tugfe Demir",
      "Luca Sanguinetti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06661"
  },
  {
    "id": "arXiv:2110.08614",
    "title": "Deep Learning and Spectral Embedding for Graph Partitioning",
    "abstract": "Deep Learning and Spectral Embedding for Graph Partitioning",
    "descriptor": "",
    "authors": [
      "Alice Gatti",
      "Zhixiong Hu",
      "Tess Smidt",
      "Esmond G. Ng",
      "Pieter Ghysels"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08614"
  },
  {
    "id": "arXiv:2110.10645",
    "title": "Combining Different V1 Brain Model Variants to Improve Robustness to  Image Corruptions in CNNs",
    "abstract": "Comments: 15 pages with supplementary material, 3 main figures, 2 supplementary figures, 4 supplementary tables",
    "descriptor": "\nComments: 15 pages with supplementary material, 3 main figures, 2 supplementary figures, 4 supplementary tables\n",
    "authors": [
      "Avinash Baidya",
      "Joel Dapello",
      "James J. DiCarlo",
      "Tiago Marques"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.10645"
  },
  {
    "id": "arXiv:2110.11265",
    "title": "Deep Reinforcement Learning for Online Control of Stochastic Partial  Differential Equations",
    "abstract": "Deep Reinforcement Learning for Online Control of Stochastic Partial  Differential Equations",
    "descriptor": "",
    "authors": [
      "Erfan Pirmorad",
      "Faraz Khoshbakhtian",
      "Farnam Mansouri",
      "Amir-massoud Farahmand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.11265"
  },
  {
    "id": "arXiv:2110.12340",
    "title": "Adversarial Prefetch: New Cross-Core Cache Side Channel Attacks",
    "abstract": "Adversarial Prefetch: New Cross-Core Cache Side Channel Attacks",
    "descriptor": "",
    "authors": [
      "Yanan Guo",
      "Andrew Zigerelli",
      "Youtao Zhang",
      "Jun Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.12340"
  },
  {
    "id": "arXiv:2110.13107",
    "title": "The Nuts and Bolts of Adopting Transformer in GANs",
    "abstract": "Comments: Technical Report. Project Page: this https URL",
    "descriptor": "\nComments: Technical Report. Project Page: this https URL\n",
    "authors": [
      "Rui Xu",
      "Xiangyu Xu",
      "Kai Chen",
      "Bolei Zhou",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13107"
  },
  {
    "id": "arXiv:2110.13623",
    "title": "Contrastive Neural Processes for Self-Supervised Learning",
    "abstract": "Comments: 16 pages, 6 figures, ACML 2021",
    "descriptor": "\nComments: 16 pages, 6 figures, ACML 2021\n",
    "authors": [
      "Konstantinos Kallidromitis",
      "Denis Gudovskiy",
      "Kazuki Kozuka",
      "Iku Ohama",
      "Luca Rigazio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.13623"
  },
  {
    "id": "arXiv:2111.01853",
    "title": "Recursive Bayesian Networks: Generalising and Unifying Probabilistic  Context-Free Grammars and Dynamic Bayesian Networks",
    "abstract": "Comments: In: Proceedings of the 35th Conference on Neural Information Processing Systems (NeurIPS 2021); Code: this https URL; Comments: corrected typo in outside probabilities: {\\alpha}(y) --&gt; {\\alpha}(x); corrected typo in Appendix C.2.1",
    "descriptor": "\nComments: In: Proceedings of the 35th Conference on Neural Information Processing Systems (NeurIPS 2021); Code: this https URL; Comments: corrected typo in outside probabilities: {\\alpha}(y) --&gt; {\\alpha}(x); corrected typo in Appendix C.2.1\n",
    "authors": [
      "Robert Lieck",
      "Martin Rohrmeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.01853"
  },
  {
    "id": "arXiv:2111.02643",
    "title": "Response Generation with Context-Aware Prompt Learning",
    "abstract": "Response Generation with Context-Aware Prompt Learning",
    "descriptor": "",
    "authors": [
      "Xiaodong Gu",
      "Kang Min Yoo",
      "Sang-Woo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.02643"
  },
  {
    "id": "arXiv:2111.04875",
    "title": "LiMoSeg: Real-time Bird's Eye View based LiDAR Motion Segmentation",
    "abstract": "Comments: Accepted for Presentation at International Conference on Computer Vision Theory and Applications (VISAPP 2022)",
    "descriptor": "\nComments: Accepted for Presentation at International Conference on Computer Vision Theory and Applications (VISAPP 2022)\n",
    "authors": [
      "Sambit Mohapatra",
      "Mona Hodaei",
      "Senthil Yogamani",
      "Stefan Milz",
      "Heinrich Gotzig",
      "Martin Simon",
      "Hazem Rashed",
      "Patrick Maeder"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.04875"
  },
  {
    "id": "arXiv:2111.05454",
    "title": "DP-REC: Private & Communication-Efficient Federated Learning",
    "abstract": "DP-REC: Private & Communication-Efficient Federated Learning",
    "descriptor": "",
    "authors": [
      "Aleksei Triastcyn",
      "Matthias Reisser",
      "Christos Louizos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.05454"
  },
  {
    "id": "arXiv:2111.09641",
    "title": "Evaluating Transformers for Lightweight Action Recognition",
    "abstract": "Comments: pre-print",
    "descriptor": "\nComments: pre-print\n",
    "authors": [
      "Raivo Koot",
      "Markus Hennerbichler",
      "Haiping Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09641"
  },
  {
    "id": "arXiv:2111.10009",
    "title": "ExoMiner: A Highly Accurate and Explainable Deep Learning Classifier  that Validates 301 New Exoplanets",
    "abstract": "Comments: Accepted for Publication in Astrophysical Journals, November 12, 2021",
    "descriptor": "\nComments: Accepted for Publication in Astrophysical Journals, November 12, 2021\n",
    "authors": [
      "Hamed Valizadegan",
      "Miguel Martinho",
      "Laurent S. Wilkens",
      "Jon M. Jenkins",
      "Jeffrey Smith",
      "Douglas A. Caldwell",
      "Joseph D. Twicken",
      "Pedro C. Gerum",
      "Nikash Walia",
      "Kaylie Hausknecht",
      "Noa Y. Lubin",
      "Stephen T. Bryson",
      "Nikunj C. Oza"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10009"
  },
  {
    "id": "arXiv:2111.10436",
    "title": "A counter-example to the probabilistic universal graph conjecture via  randomized communication complexity",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Lianna Hambardzumyan",
      "Hamed Hatami",
      "Pooya Hatami"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.10436"
  },
  {
    "id": "arXiv:2111.10510",
    "title": "Bayesian Learning via Neural Schr\u00f6dinger-F\u00f6llmer Flows",
    "abstract": "Bayesian Learning via Neural Schr\u00f6dinger-F\u00f6llmer Flows",
    "descriptor": "",
    "authors": [
      "Francisco Vargas",
      "Andrius Ovsianas",
      "David Fernandes",
      "Mark Girolami",
      "Neil D. Lawrence",
      "Nikolas N\u00fcsken"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10510"
  },
  {
    "id": "arXiv:2111.12494",
    "title": "Time-Energy-Constrained Closed-Loop FBL Communication for Dependable MEC",
    "abstract": "Comments: Accepted for publication at CSCN 2021",
    "descriptor": "\nComments: Accepted for publication at CSCN 2021\n",
    "authors": [
      "Bin Han",
      "Yao Zhu",
      "Anke Schmeink",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.12494"
  },
  {
    "id": "arXiv:2111.13149",
    "title": "A Comparative Analysis of Machine Learning Techniques for IoT Intrusion  Detection",
    "abstract": "Comments: 16 pages, 12 tables, 4 figures, FPS 2021 conference",
    "descriptor": "\nComments: 16 pages, 12 tables, 4 figures, FPS 2021 conference\n",
    "authors": [
      "Jo\u00e3o Vitorino",
      "Rui Andrade",
      "Isabel Pra\u00e7a",
      "Orlando Sousa",
      "Eva Maia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.13149"
  },
  {
    "id": "arXiv:2111.14271",
    "title": "ExCon: Explanation-driven Supervised Contrastive Learning for Image  Classification",
    "abstract": "ExCon: Explanation-driven Supervised Contrastive Learning for Image  Classification",
    "descriptor": "",
    "authors": [
      "Zhibo Zhang",
      "Jongseong Jang",
      "Chiheb Trabelsi",
      "Ruiwen Li",
      "Scott Sanner",
      "Yeonjeong Jeong",
      "Dongsub Shim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14271"
  },
  {
    "id": "arXiv:2112.00183",
    "title": "Descriptive vs. inferential community detection: pitfalls, myths and  half-truths",
    "abstract": "Comments: 52 pages, 16 figures",
    "descriptor": "\nComments: 52 pages, 16 figures\n",
    "authors": [
      "Tiago P. Peixoto"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00183"
  },
  {
    "id": "arXiv:2112.00552",
    "title": "SaDe: Learning Models that Provably Satisfy Domain Constraints",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Kshitij Goyal",
      "Sebastijan Dumancic",
      "Hendrik Blockeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.00552"
  },
  {
    "id": "arXiv:2112.00861",
    "title": "A General Language Assistant as a Laboratory for Alignment",
    "abstract": "Comments: 26+19 pages; v2 typos fixed, refs added, figure scale / colors fixed",
    "descriptor": "\nComments: 26+19 pages; v2 typos fixed, refs added, figure scale / colors fixed\n",
    "authors": [
      "Amanda Askell",
      "Yuntao Bai",
      "Anna Chen",
      "Dawn Drain",
      "Deep Ganguli",
      "Tom Henighan",
      "Andy Jones",
      "Nicholas Joseph",
      "Ben Mann",
      "Nova DasSarma",
      "Nelson Elhage",
      "Zac Hatfield-Dodds",
      "Danny Hernandez",
      "Jackson Kernion",
      "Kamal Ndousse",
      "Catherine Olsson",
      "Dario Amodei",
      "Tom Brown",
      "Jack Clark",
      "Sam McCandlish",
      "Chris Olah",
      "Jared Kaplan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00861"
  },
  {
    "id": "arXiv:2112.00913",
    "title": "CDLNet: Noise-Adaptive Convolutional Dictionary Learning Network for  Blind Denoising and Demosaicing",
    "abstract": "CDLNet: Noise-Adaptive Convolutional Dictionary Learning Network for  Blind Denoising and Demosaicing",
    "descriptor": "",
    "authors": [
      "Nikola Janju\u0161evi\u0107",
      "Amirhossein Khalilian-Gourtani",
      "Yao Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00913"
  },
  {
    "id": "arXiv:2112.00995",
    "title": "SwinTrack: A Simple and Strong Baseline for Transformer Tracking",
    "abstract": "Comments: Tech report",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Liting Lin",
      "Heng Fan",
      "Yong Xu",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00995"
  },
  {
    "id": "arXiv:2112.01035",
    "title": "Graph4Rec: A Universal Toolkit with Graph Neural Networks for  Recommender Systems",
    "abstract": "Comments: 8 pages, 4 figures",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Weibin Li",
      "Mingkai He",
      "Zhengjie Huang",
      "Xianming Wang",
      "Shikun Feng",
      "Weiyue Su",
      "Yu Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01035"
  },
  {
    "id": "arXiv:2112.01229",
    "title": "An AI-based Solution for Enhancing Delivery of Digital Learning for  Future Teachers",
    "abstract": "An AI-based Solution for Enhancing Delivery of Digital Learning for  Future Teachers",
    "descriptor": "",
    "authors": [
      "Yong-Bin Kang",
      "Abdur Rahim Mohammad Forkan",
      "Prem Prakash Jayaraman",
      "Natalie Wieland",
      "Elizabeth Kollias",
      "Hung Du",
      "Steven Thomson",
      "Yuan-Fang Li"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01229"
  },
  {
    "id": "arXiv:2112.01361",
    "title": "Phasic Policy Gradient Based Resource Allocation for Industrial Internet  of Things",
    "abstract": "Phasic Policy Gradient Based Resource Allocation for Industrial Internet  of Things",
    "descriptor": "",
    "authors": [
      "Lokesh Bommisetty",
      "TG Venkatesh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.01361"
  },
  {
    "id": "arXiv:2112.01402",
    "title": "Iterative Contrast-Classify For Semi-supervised Temporal Action  Segmentation",
    "abstract": "Comments: AAAI-2022",
    "descriptor": "\nComments: AAAI-2022\n",
    "authors": [
      "Dipika Singhania",
      "Rahul Rahaman",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01402"
  },
  {
    "id": "arXiv:2112.01406",
    "title": "Active Learning for Domain Adaptation: An Energy-based Approach",
    "abstract": "Comments: Accepted by AAAI 2022. Code is available at this https URL",
    "descriptor": "\nComments: Accepted by AAAI 2022. Code is available at this https URL\n",
    "authors": [
      "Binhui Xie",
      "Longhui Yuan",
      "Shuang Li",
      "Chi Harold Liu",
      "Xinjing Cheng",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01406"
  },
  {
    "id": "arXiv:2112.01538",
    "title": "Testing Reactive Systems Using Behavioural Programming, a Model Centric  Approach",
    "abstract": "Comments: 31 pages, 7 figures",
    "descriptor": "\nComments: 31 pages, 7 figures\n",
    "authors": [
      "Yeshayahu Weiss"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.01538"
  },
  {
    "id": "arXiv:2112.01839",
    "title": "Mind Your Clever Neighbours: Unsupervised Person Re-identification via  Adaptive Clustering Relationship Modeling",
    "abstract": "Comments: The experimental results are not sufficient",
    "descriptor": "\nComments: The experimental results are not sufficient\n",
    "authors": [
      "Lianjie Jia",
      "Chenyang Yu",
      "Xiehao Ye",
      "Tianyu Yan",
      "Yinjie Lei",
      "Pingping Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.01839"
  },
  {
    "id": "arXiv:2112.02220",
    "title": "Capacity Results for MIMO Optical Wireless Communication With  Per-Antenna Intensity Constraints",
    "abstract": "Capacity Results for MIMO Optical Wireless Communication With  Per-Antenna Intensity Constraints",
    "descriptor": "",
    "authors": [
      "Ru-Han Chen",
      "Longguang Li",
      "Jian Zhang",
      "Lin Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.02220"
  },
  {
    "id": "arXiv:2112.02222",
    "title": "Predicting Axillary Lymph Node Metastasis in Early Breast Cancer Using  Deep Learning on Primary Tumor Biopsy Slides",
    "abstract": "Comments: Accepted by Frontiers in Oncology, for more details, please see this https URL",
    "descriptor": "\nComments: Accepted by Frontiers in Oncology, for more details, please see this https URL\n",
    "authors": [
      "Feng Xu",
      "Chuang Zhu",
      "Wenqi Tang",
      "Ying Wang",
      "Yu Zhang",
      "Jie Li",
      "Hongchuan Jiang",
      "Zhongyue Shi",
      "Jun Liu",
      "Mulan Jin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.02222"
  },
  {
    "id": "arXiv:2112.02279",
    "title": "U2-Former: A Nested U-shaped Transformer for Image Restoration",
    "abstract": "U2-Former: A Nested U-shaped Transformer for Image Restoration",
    "descriptor": "",
    "authors": [
      "Haobo Ji",
      "Xin Feng",
      "Wenjie Pei",
      "Jinxing Li",
      "Guangming Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.02279"
  },
  {
    "id": "arXiv:2112.02355",
    "title": "SITA: Single Image Test-time Adaptation",
    "abstract": "SITA: Single Image Test-time Adaptation",
    "descriptor": "",
    "authors": [
      "Ansh Khurana",
      "Sujoy Paul",
      "Piyush Rai",
      "Soma Biswas",
      "Gaurav Aggarwal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.02355"
  },
  {
    "id": "arXiv:2112.02609",
    "title": "Computing Minimal Injective Resolutions of Sheaves on Finite Posets",
    "abstract": "Computing Minimal Injective Resolutions of Sheaves on Finite Posets",
    "descriptor": "",
    "authors": [
      "Adam Brown",
      "Ondrej Draganov"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.02609"
  },
  {
    "id": "arXiv:2112.02856",
    "title": "Optimal No-Regret Learning in Strongly Monotone Games with Bandit  Feedback",
    "abstract": "Comments: 40 pages, 3 figures",
    "descriptor": "\nComments: 40 pages, 3 figures\n",
    "authors": [
      "Tianyi Lin",
      "Zhengyuan Zhou",
      "Wenjia Ba",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.02856"
  },
  {
    "id": "arXiv:2112.02936",
    "title": "Pairwise Learning for Neural Link Prediction",
    "abstract": "Pairwise Learning for Neural Link Prediction",
    "descriptor": "",
    "authors": [
      "Zhitao Wang",
      "Yong Zhou",
      "Litao Hong",
      "Yuanhang Zou",
      "Hanjing Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.02936"
  },
  {
    "id": "arXiv:2112.03227",
    "title": "CALVIN: A Benchmark for Language-conditioned Policy Learning for  Long-horizon Robot Manipulation Tasks",
    "abstract": "Comments: this http URL",
    "descriptor": "\nComments: this http URL\n",
    "authors": [
      "Oier Mees",
      "Lukas Hermann",
      "Erick Rosete-Beas",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03227"
  },
  {
    "id": "arXiv:2112.03510",
    "title": "Model-free Nearly Optimal Control of Constrained-Input Nonlinear Systems  Based on Synchronous Reinforcement Learning",
    "abstract": "Model-free Nearly Optimal Control of Constrained-Input Nonlinear Systems  Based on Synchronous Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Han Zhao",
      "Lei Guo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03510"
  },
  {
    "id": "arXiv:2112.03649",
    "title": "Regularity Learning via Explicit Distribution Modeling for Skeletal  Video Anomaly Detection",
    "abstract": "Regularity Learning via Explicit Distribution Modeling for Skeletal  Video Anomaly Detection",
    "descriptor": "",
    "authors": [
      "Shoubin Yu",
      "Zhongyin Zhao",
      "Haoshu Fang",
      "Andong Deng",
      "Haisheng Su",
      "Dongliang Wang",
      "Weihao Gan",
      "Cewu Lu",
      "Wei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03649"
  },
  {
    "id": "arXiv:2112.03650",
    "title": "Activation to Saliency: Forming High-Quality Labels for Unsupervised  Salient Object Detection",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Huajun Zhou",
      "Peijia Chen",
      "Lingxiao Yang",
      "Jianhuang Lai",
      "Xiaohua Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03650"
  },
  {
    "id": "arXiv:2112.03677",
    "title": "On Baker-Gill-Solovay Oracle Turing Machines and Relativization Barrier",
    "abstract": "Comments: To overcome the so-called \"Relativization barrier\". Adding an additional result, feedbacks are welcome. arXiv admin note: text overlap with arXiv:2110.06211",
    "descriptor": "\nComments: To overcome the so-called \"Relativization barrier\". Adding an additional result, feedbacks are welcome. arXiv admin note: text overlap with arXiv:2110.06211\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.03677"
  },
  {
    "id": "arXiv:2112.03753",
    "title": "Tell me why! -- Explanations support learning of relational and causal  structure",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Andrew K. Lampinen",
      "Nicholas A. Roy",
      "Ishita Dasgupta",
      "Stephanie C. Y. Chan",
      "Allison C. Tam",
      "James L. McClelland",
      "Chen Yan",
      "Adam Santoro",
      "Neil C. Rabinowitz",
      "Jane X. Wang",
      "Felix Hill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03753"
  },
  {
    "id": "arXiv:2112.03798",
    "title": "PTR-PPO: Proximal Policy Optimization with Prioritized Trajectory Replay",
    "abstract": "Comments: 16 pages,10figure",
    "descriptor": "\nComments: 16 pages,10figure\n",
    "authors": [
      "Xingxing Liang",
      "Yang Ma",
      "Yanghe Feng",
      "Zhong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03798"
  },
  {
    "id": "arXiv:2112.03803",
    "title": "Suppressing Static Visual Cues via Normalizing Flows for Self-Supervised  Video Representation Learning",
    "abstract": "Comments: AAAI2022. v2: Add supplementary",
    "descriptor": "\nComments: AAAI2022. v2: Add supplementary\n",
    "authors": [
      "Manlin Zhang",
      "Jinpeng Wang",
      "Andy J. Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03803"
  },
  {
    "id": "arXiv:2112.03807",
    "title": "raceBERT -- A Transformer-based Model for Predicting Race and Ethnicity  from Names",
    "abstract": "Comments: See this http URL",
    "descriptor": "\nComments: See this http URL\n",
    "authors": [
      "Prasanna Parasurama"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03807"
  },
  {
    "id": "arXiv:2112.03815",
    "title": "Accurate parameter estimation using scan-specific unsupervised deep  learning for relaxometry and MR fingerprinting",
    "abstract": "Comments: 7 pages, 5 figures, submitted to International Society for Magnetic Resonance in Medicine 2022",
    "descriptor": "\nComments: 7 pages, 5 figures, submitted to International Society for Magnetic Resonance in Medicine 2022\n",
    "authors": [
      "Mengze Gao",
      "Huihui Ye",
      "Tae Hyung Kim",
      "Zijing Zhang",
      "Seohee So",
      "Berkin Bilgic"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.03815"
  }
]
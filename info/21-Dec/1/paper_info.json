[
  {
    "id": "arXiv:2111.14829",
    "title": "Nonparametric Topological Layers in Neural Networks",
    "abstract": "Various topological techniques and tools have been applied to neural networks\nin terms of network complexity, explainability, and performance. One\nfundamental assumption of this line of research is the existence of a global\n(Euclidean) coordinate system upon which the topological layer is constructed.\nDespite promising results, such a \\textit{topologization} method has yet to be\nwidely adopted because the parametrization of a topologization layer takes a\nconsiderable amount of time and more importantly, lacks a theoretical\nfoundation without which the performance of the neural network only achieves\nsuboptimal performance. This paper proposes a learnable topological layer for\nneural networks without requiring a Euclidean space; Instead, the proposed\nconstruction requires nothing more than a general metric space except for an\ninner product, i.e., a Hilbert space. Accordingly, the according\nparametrization for the proposed topological layer is free of user-specified\nhyperparameters, which precludes the costly parametrization stage and the\ncorresponding possibility of suboptimal networks.",
    "descriptor": "",
    "authors": [
      "Dongfang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14829"
  },
  {
    "id": "arXiv:2111.14830",
    "title": "Abusive and Threatening Language Detection in Urdu using Boosting based  and BERT based models: A Comparative Approach",
    "abstract": "Online hatred is a growing concern on many social media platforms. To address\nthis issue, different social media platforms have introduced moderation\npolicies for such content. They also employ moderators who can check the posts\nviolating moderation policies and take appropriate action. Academicians in the\nabusive language research domain also perform various studies to detect such\ncontent better. Although there is extensive research in abusive language\ndetection in English, there is a lacuna in abusive language detection in low\nresource languages like Hindi, Urdu etc. In this FIRE 2021 shared task -\n\"HASOC- Abusive and Threatening language detection in Urdu\" the organizers\npropose an abusive language detection dataset in Urdu along with threatening\nlanguage detection. In this paper, we explored several machine learning models\nsuch as XGboost, LGBM, m-BERT based models for abusive and threatening content\ndetection in Urdu based on the shared task. We observed the Transformer model\nspecifically trained on abusive language dataset in Arabic helps in getting the\nbest performance. Our model came First for both abusive and threatening content\ndetection with an F1scoreof 0.88 and 0.54, respectively.",
    "descriptor": "\nComments: Accepted in FIRE'21 (Track Abusive and Threatening Language Detection Task in Urdu). arXiv admin note: text overlap with arXiv:2111.13974\n",
    "authors": [
      "Mithun Das",
      "Somnath Banerjee",
      "Punyajoy Saha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.14830"
  },
  {
    "id": "arXiv:2111.14831",
    "title": "MIST-net: Multi-domain Integrative Swin Transformer network for  Sparse-View CT Reconstruction",
    "abstract": "The deep learning-based tomographic image reconstruction have been attracting\nmuch attention among these years. The sparse-view data reconstruction is one of\ntypical underdetermined inverse problems, how to reconstruct high-quality CT\nimages from dozens of projections is still a challenge in practice. To address\nthis challenge, in this article we proposed a Multi-domain Integrative Swin\nTransformer network (MIST-net). First, the proposed MIST-net incorporated\nlavish domain features from data, residual-data, image, and residual-image\nusing flexible network architectures. Here, the residual-data and\nresidual-image domains network components can be considered as the data\nconsistency module to eliminate interpolation errors in both residual data and\nimage domains, and then further retain image details. Second, to detect the\nimage features and further protect image edge, the trainable Sobel Filter was\nincorporated into the network to improve the encode-decode ability. Third, with\nthe classical Swin transformer, we further designed the high-quality\nreconstruction transformer (i.e., Recformer) to improve the reconstruction\nperformance. The Recformer inherited the power of Swin transformer to capture\nthe global and local features of the reconstructed image. The experiments on\nthe numerical datasets with 48 views demonstrated our proposed MIST-net\nprovided higher reconstructed image quality with small feature recovery and\nedge protection than other competitors including the advanced unrolled\nnetworks. The quantitative results show that our MIST-net also obtained the\nbest performance. The trained network was transferred to the real cardiac CT\ndataset with 48 views, the reconstruction results further validated the\nadvantages of our MIST-net and further demonstrated the good robustness of our\nMIST in clinical applications.",
    "descriptor": "\nComments: 21 pages, 8 figures, 57 references\n",
    "authors": [
      "Jiayi Pan",
      "Weiwen Wu",
      "Zhifan Gao",
      "Heye Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.14831"
  },
  {
    "id": "arXiv:2111.14833",
    "title": "Adversarial Attacks in Cooperative AI",
    "abstract": "Single-agent reinforcement learning algorithms in a multi-agent environment\nare inadequate for fostering cooperation. If intelligent agents are to interact\nand work together to solve complex problems, methods that counter\nnon-cooperative behavior are needed to facilitate the training of multiple\nagents. This is the goal of cooperative AI. Recent work in adversarial machine\nlearning, however, shows that models (e.g., image classifiers) can be easily\ndeceived into making incorrect decisions. In addition, some past research in\ncooperative AI has relied on new notions of representations, like public\nbeliefs, to accelerate the learning of optimally cooperative behavior. Hence,\ncooperative AI might introduce new weaknesses not investigated in previous\nmachine learning research. In this paper, our contributions include: (1)\narguing that three algorithms inspired by human-like social intelligence\nintroduce new vulnerabilities, unique to cooperative AI, that adversaries can\nexploit, and (2) an experiment showing that simple, adversarial perturbations\non the agents' beliefs can negatively impact performance. This evidence points\nto the possibility that formal representations of social behavior are\nvulnerable to adversarial attacks.",
    "descriptor": "",
    "authors": [
      "Ted Fujimoto",
      "Arthur Paul Pedersen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.14833"
  },
  {
    "id": "arXiv:2111.14834",
    "title": "Self-supervised Autoregressive Domain Adaptation for Time Series Data",
    "abstract": "Unsupervised domain adaptation (UDA) has successfully addressed the domain\nshift problem for visual applications. Yet, these approaches may have limited\nperformance for time series data due to the following reasons. First, they\nmainly rely on large-scale dataset (i.e., ImageNet) for the source pretraining,\nwhich is not applicable for time-series data. Second, they ignore the temporal\ndimension on the feature space of the source and target domains during the\ndomain alignment step. Last, most of prior UDA methods can only align the\nglobal features without considering the fine-grained class distribution of the\ntarget domain. To address these limitations, we propose a Self-supervised\nAutoregressive Domain Adaptation (SLARDA) framework. In particular, we first\ndesign a self-supervised learning module that utilizes forecasting as an\nauxiliary task to improve the transferability of the source features. Second,\nwe propose a novel autoregressive domain adaptation technique that incorporates\ntemporal dependency of both source and target features during domain alignment.\nFinally, we develop an ensemble teacher model to align the class-wise\ndistribution in the target domain via a confident pseudo labeling approach.\nExtensive experiments have been conducted on three real-world time series\napplications with 30 cross-domain scenarios. Results demonstrate that our\nproposed SLARDA method significantly outperforms the state-of-the-art\napproaches for time series domain adaptation.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Mohamed Ragab",
      "Emadeldeen Eldele",
      "Zhenghua Chen",
      "Min Wu",
      "Chee-Keong Kwoh",
      "Xiaoli Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14834"
  },
  {
    "id": "arXiv:2111.14836",
    "title": "Low-bit Quantization of Recurrent Neural Network Language Models Using  Alternating Direction Methods of Multipliers",
    "abstract": "The high memory consumption and computational costs of Recurrent neural\nnetwork language models (RNNLMs) limit their wider application on resource\nconstrained devices. In recent years, neural network quantization techniques\nthat are capable of producing extremely low-bit compression, for example,\nbinarized RNNLMs, are gaining increasing research interests. Directly training\nof quantized neural networks is difficult. By formulating quantized RNNLMs\ntraining as an optimization problem, this paper presents a novel method to\ntrain quantized RNNLMs from scratch using alternating direction methods of\nmultipliers (ADMM). This method can also flexibly adjust the trade-off between\nthe compression rate and model performance using tied low-bit quantization\ntables. Experiments on two tasks: Penn Treebank (PTB), and Switchboard (SWBD)\nsuggest the proposed ADMM quantization achieved a model size compression factor\nof up to 31 times over the full precision baseline RNNLMs. Faster convergence\nof 5 times in model training over the baseline binarized RNNLM quantization was\nalso obtained. Index Terms: Language models, Recurrent neural networks,\nQuantization, Alternating direction methods of multipliers.",
    "descriptor": "",
    "authors": [
      "Junhao Xu",
      "Xie Chen",
      "Shoukang Hu",
      "Jianwei Yu",
      "Xunying Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14836"
  },
  {
    "id": "arXiv:2111.14837",
    "title": "p2pGNN: A Decentralized Graph Neural Network for Node Classification in  Peer-to-Peer Networks",
    "abstract": "In this work, we aim to classify nodes of unstructured peer-to-peer networks\nwith communication uncertainty, such as users of decentralized social networks.\nGraph Neural Networks (GNNs) are known to improve the accuracy of simpler\nclassifiers in centralized settings by leveraging naturally occurring network\nlinks, but graph convolutional layers are challenging to implement in\ndecentralized settings when node neighbors are not constantly available. We\naddress this problem by employing decoupled GNNs, where base classifier\npredictions and errors are diffused through graphs after training. For these,\nwe deploy pre-trained and gossip-trained base classifiers and implement\npeer-to-peer graph diffusion under communication uncertainty. In particular, we\ndevelop an asynchronous decentralized formulation of diffusion that converges\nat the same predictions linearly with respect to communication rate. We\nexperiment on three real-world graphs with node features and labels and\nsimulate peer-to-peer networks with uniformly random communication frequencies;\ngiven a portion of known labels, our decentralized graph diffusion achieves\ncomparable accuracy to centralized GNNs.",
    "descriptor": "\nComments: 11 pages, 2 figures, preprint\n",
    "authors": [
      "Emmanouil Krasanakis",
      "Symeon Papadopoulos",
      "Ioannis Kompatsiaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.14837"
  },
  {
    "id": "arXiv:2111.14838",
    "title": "Evaluating Privacy-Preserving Machine Learning in Critical  Infrastructures: A Case Study on Time-Series Classification",
    "abstract": "With the advent of machine learning in applications of critical\ninfrastructure such as healthcare and energy, privacy is a growing concern in\nthe minds of stakeholders. It is pivotal to ensure that neither the model nor\nthe data can be used to extract sensitive information used by attackers against\nindividuals or to harm whole societies through the exploitation of critical\ninfrastructure. The applicability of machine learning in these domains is\nmostly limited due to a lack of trust regarding the transparency and the\nprivacy constraints. Various safety-critical use cases (mostly relying on\ntime-series data) are currently underrepresented in privacy-related\nconsiderations. By evaluating several privacy-preserving methods regarding\ntheir applicability on time-series data, we validated the inefficacy of\nencryption for deep learning, the strong dataset dependence of differential\nprivacy, and the broad applicability of federated methods.",
    "descriptor": "\nComments: 9 pages, 4 figures. 6 tables\n",
    "authors": [
      "Dominique Mercier",
      "Adriano Lucieri",
      "Mohsin Munir",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.14838"
  },
  {
    "id": "arXiv:2111.14839",
    "title": "PCA-based Category Encoder for Categorical to Numerical Variable  Conversion",
    "abstract": "Increasing the cardinality of categorical variables might decrease the\noverall performance of ML algorithms. This paper presents a novel computational\npreprocessing method to convert categorical to numerical variables for machine\nlearning (ML) algorithms. In this method, We select and convert three\ncategorical features to numerical features. First, we choose the threshold\nparameter based on the distribution of categories in variables. Then, we use\nconditional probabilities to convert each categorical variable into two new\nnumerical variables, resulting in six new numerical variables in total. After\nthat, we feed these six numerical variables to the Principal Component Analysis\n(PCA) algorithm. Next, we select the whole or partial numbers of Principal\nComponents (PCs). Finally, by applying binary classification with ten different\nclassifiers, We measured the performance of the new encoder and compared it\nwith the other 17 well-known category encoders. The proposed technique achieved\nthe highest performance related to accuracy and Area under the curve (AUC) on\nhigh cardinality categorical variables using the well-known cybersecurity\nNSLKDD dataset. Also, we defined harmonic average metrics to find the best\ntrade-off between train and test performance and prevent underfitting and\noverfitting. Ultimately, the number of newly created numerical variables is\nminimal. Consequently, this data reduction improves computational processing\ntime which might reduce processing data in 5G future telecommunication\nnetworks.",
    "descriptor": "\nComments: 7 pages, 4 figures, 5 tables\n",
    "authors": [
      "Hamed Farkhari",
      "Joseanne Viana",
      "Luis Miguel Campos",
      "Pedro Sebastiao",
      "Rodolfo Oliveira",
      "Luis Bernardo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14839"
  },
  {
    "id": "arXiv:2111.14843",
    "title": "Catch Me If You Hear Me: Audio-Visual Navigation in Complex Unmapped  Environments with Moving Sounds",
    "abstract": "Audio-visual navigation combines sight and hearing to navigate to a\nsound-emitting source in an unmapped environment. While recent approaches have\ndemonstrated the benefits of audio input to detect and find the goal, they\nfocus on clean and static sound sources and struggle to generalize to unheard\nsounds. In this work, we propose the novel dynamic audio-visual navigation\nbenchmark which requires to catch a moving sound source in an environment with\nnoisy and distracting sounds. We introduce a reinforcement learning approach\nthat learns a robust navigation policy for these complex settings. To achieve\nthis, we propose an architecture that fuses audio-visual information in the\nspatial feature space to learn correlations of geometric information inherent\nin both local maps and audio signals. We demonstrate that our approach\nconsistently outperforms the current state-of-the-art by a large margin across\nall tasks of moving sounds, unheard sounds, and noisy environments, on two\nchallenging 3D scanned real-world environments, namely Matterport3D and\nReplica. The benchmark is available at this http URL",
    "descriptor": "",
    "authors": [
      "Abdelrahman Younes",
      "Daniel Honerkamp",
      "Tim Welschehold",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.14843"
  },
  {
    "id": "arXiv:2111.14844",
    "title": "Evaluation of Machine Learning Techniques for Forecast Uncertainty  Quantification",
    "abstract": "Producing an accurate weather forecast and a reliable quantification of its\nuncertainty is an open scientific challenge. Ensemble forecasting is, so far,\nthe most successful approach to produce relevant forecasts along with an\nestimation of their uncertainty. The main limitations of ensemble forecasting\nare the high computational cost and the difficulty to capture and quantify\ndifferent sources of uncertainty, particularly those associated with model\nerrors. In this work proof-of-concept model experiments are conducted to\nexamine the performance of ANNs trained to predict a corrected state of the\nsystem and the state uncertainty using only a single deterministic forecast as\ninput. We compare different training strategies: one based on a direct training\nusing the mean and spread of an ensemble forecast as target, the other ones\nrely on an indirect training strategy using a deterministic forecast as target\nin which the uncertainty is implicitly learned from the data. For the last\napproach two alternative loss functions are proposed and evaluated, one based\non the data observation likelihood and the other one based on a local\nestimation of the error. The performance of the networks is examined at\ndifferent lead times and in scenarios with and without model errors.\nExperiments using the Lorenz'96 model show that the ANNs are able to emulate\nsome of the properties of ensemble forecasts like the filtering of the most\nunpredictable modes and a state-dependent quantification of the forecast\nuncertainty. Moreover, ANNs provide a reliable estimation of the forecast\nuncertainty in the presence of model error.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Maximiliano A. Sacco",
      "Juan J. Ruiz",
      "Manuel Pulido",
      "Pierre Tandeo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2111.14844"
  },
  {
    "id": "arXiv:2111.14887",
    "title": "DAFormer: Improving Network Architectures and Training Strategies for  Domain-Adaptive Semantic Segmentation",
    "abstract": "As acquiring pixel-wise annotations of real-world images for semantic\nsegmentation is a costly process, a model can instead be trained with more\naccessible synthetic data and adapted to real images without requiring their\nannotations. This process is studied in unsupervised domain adaptation (UDA).\nEven though a large number of methods propose new adaptation strategies, they\nare mostly based on outdated network architectures. As the influence of recent\nnetwork architectures has not been systematically studied, we first benchmark\ndifferent network architectures for UDA and then propose a novel UDA method,\nDAFormer, based on the benchmark results. The DAFormer network consists of a\nTransformer encoder and a multi-level context-aware feature fusion decoder. It\nis enabled by three simple but crucial training strategies to stabilize the\ntraining and to avoid overfitting DAFormer to the source domain: While the Rare\nClass Sampling on the source domain improves the quality of pseudo-labels by\nmitigating the confirmation bias of self-training towards common classes, the\nThing-Class ImageNet Feature Distance and a learning rate warmup promote\nfeature transfer from ImageNet pretraining. DAFormer significantly improves the\nstate-of-the-art performance by 10.8 mIoU for GTA->Cityscapes and 5.4 mIoU for\nSynthia->Cityscapes and enables learning even difficult classes such as train,\nbus, and truck well. The implementation is available at\nhttps://github.com/lhoyer/DAFormer.",
    "descriptor": "",
    "authors": [
      "Lukas Hoyer",
      "Dengxin Dai",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14887"
  },
  {
    "id": "arXiv:2111.14889",
    "title": "Rigorous data-driven computation of spectral properties of Koopman  operators for dynamical systems",
    "abstract": "Koopman operators are infinite-dimensional operators that globally linearize\nnonlinear dynamical systems, making their spectral information useful for\nunderstanding dynamics. However, Koopman operators can have continuous spectra\nand infinite-dimensional invariant subspaces, making computing their spectral\ninformation a considerable challenge. This paper describes data-driven\nalgorithms with rigorous convergence guarantees for computing spectral\ninformation of Koopman operators from trajectory data. We introduce residual\ndynamic mode decomposition (ResDMD), which provides the first scheme for\ncomputing the spectra and pseudospectra of general Koopman operators from\nsnapshot data without spectral pollution. Using the resolvent operator and\nResDMD, we also compute smoothed approximations of spectral measures associated\nwith measure-preserving dynamical systems. We prove explicit convergence\ntheorems for our algorithms, which can achieve high-order convergence even for\nchaotic systems, when computing the density of the continuous spectrum and the\ndiscrete spectrum. We demonstrate our algorithms on the tent map, Gauss\niterated map, nonlinear pendulum, double pendulum, Lorenz system, and an\n$11$-dimensional extended Lorenz system. Finally, we provide kernelized\nvariants of our algorithms for dynamical systems with a high-dimensional\nstate-space. This allows us to compute the spectral measure associated with the\ndynamics of a protein molecule that has a 20,046-dimensional state-space, and\ncompute nonlinear Koopman modes with error bounds for turbulent flow past\naerofoils with Reynolds number $>10^5$ that has a 295,122-dimensional\nstate-space.",
    "descriptor": "",
    "authors": [
      "Matthew J. Colbrook",
      "Alex Townsend"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Spectral Theory (math.SP)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2111.14889"
  },
  {
    "id": "arXiv:2111.14893",
    "title": "Learning Multiple Dense Prediction Tasks from Partially Annotated Data",
    "abstract": "Despite the recent advances in multi-task learning of dense prediction\nproblems, most methods rely on expensive labelled datasets. In this paper, we\npresent a label efficient approach and look at jointly learning of multiple\ndense prediction tasks on partially annotated data, which we call multi-task\npartially-supervised learning. We propose a multi-task training procedure that\nsuccessfully leverages task relations to supervise its multi-task learning when\ndata is partially annotated. In particular, we learn to map each task pair to a\njoint pairwise task-space which enables sharing information between them in a\ncomputationally efficient way through another network conditioned on task\npairs, and avoids learning trivial cross-task relations by retaining high-level\ninformation about the input image. We rigorously demonstrate that our proposed\nmethod effectively exploits the images with unlabelled tasks and outperforms\nexisting semi-supervised learning approaches and related methods on three\nstandard benchmarks.",
    "descriptor": "\nComments: Multi-task Partially-supervised Learning\n",
    "authors": [
      "Wei-Hong Li",
      "Xialei Liu",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14893"
  },
  {
    "id": "arXiv:2111.14901",
    "title": "A Computational Social Science Approach to Understanding Predictors of  Chafee Service Receipt",
    "abstract": "The John H. Chafee Foster Care Program for Successful Transition to Adulthood\n(CFCIP) allocates funding to provide services to youth who are likely to age\nout of foster care. These services, covering everything from mentoring to\nfinancial aid, are expected to be distributed in ways that prepare youth for\nlife after care. However, surprisingly little is known about which youth\nreceive which services. The present work makes use of the National Youth in\nTransition Database (NYTD), a large-scale administrative dataset that tracks\nservices allocated to youth that use CFCIP funds. Specifically, we conduct a\nforensic social science analysis of the NYTD data. To do so, we first use\ncomputational methods to help us uncover the most important factors associated\nwith service receipt. Doing so helps us to identify three major factors-youth\nage, youth time in care, and the state in which a youth is in care-that are\nmost heavily associated with service receive. We then conduct an analysis that\nlinks existing theory to these factors, expanding our understanding of how\nservices are allocated and paving the way to future work to understand why such\nassociations exist.",
    "descriptor": "",
    "authors": [
      "Jason Yan",
      "Melanie Sage",
      "Seventy F. Hall",
      "Yuhao Du",
      "Kenneth Joseph"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.14901"
  },
  {
    "id": "arXiv:2111.14905",
    "title": "Bounding the Last Mile: Efficient Learned String Indexing",
    "abstract": "We introduce the RadixStringSpline (RSS) learned index structure for\nefficiently indexing strings. RSS is a tree of radix splines each indexing a\nfixed number of bytes. RSS approaches or exceeds the performance of traditional\nstring indexes while using 7-70$\\times$ less memory. RSS achieves this by using\nthe minimal string prefix to sufficiently distinguish the data unlike most\nlearned approaches which index the entire string. Additionally, the\nbounded-error nature of RSS accelerates the last mile search and also enables a\nmemory-efficient hash-table lookup accelerator. We benchmark RSS on several\nreal-world string datasets against ART and HOT. Our experiments suggest this\nline of research may be promising for future memory-intensive database\napplications.",
    "descriptor": "\nComments: 3rd International Workshop on Applied AI for Database Systems and Applications (AIDB'21), August 20, 2021, Copenhagen, Denmark\n",
    "authors": [
      "Benjamin Spector",
      "Andreas Kipf",
      "Kapil Vaidya",
      "Chi Wang",
      "Umar Farooq Minhas",
      "Tim Kraska"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14905"
  },
  {
    "id": "arXiv:2111.14911",
    "title": "Optimizing High-Dimensional Physics Simulations via Composite Bayesian  Optimization",
    "abstract": "Physical simulation-based optimization is a common task in science and\nengineering. Many such simulations produce image- or tensor-based outputs where\nthe desired objective is a function of those outputs, and optimization is\nperformed over a high-dimensional parameter space. We develop a Bayesian\noptimization method leveraging tensor-based Gaussian process surrogates and\ntrust region Bayesian optimization to effectively model the image outputs and\nto efficiently optimize these types of simulations, including a radio-frequency\ntower configuration problem and an optical design problem.",
    "descriptor": "\nComments: Fourth Workshop on Machine Learning and the Physical Sciences at NeurIPS 2021\n",
    "authors": [
      "Wesley Maddox",
      "Qing Feng",
      "Max Balandat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.14911"
  },
  {
    "id": "arXiv:2111.14915",
    "title": "Promises and Pitfalls of a New Early Warning System for Gentrification  in Buffalo, NY",
    "abstract": "Gentrification and its resultant displacement are one of the many \"wicked\nproblems\" of social policy. The study of gentrification and displacement spans\nhalf a century, concerns a variety of spatial, temporal, and social contexts,\nand describes socio-political processes of across the globe and throughout\nhistory. One current iteration of this field of inquiry are efforts to identify\n\"early indicators\" of gentrification and/or displacement, or the creation of\n\"early warning systems\" (EWS). The current work adds to scholarship on the\nutility of developing an EWS by examining the methodological considerations\nrequired for such systems to serve a justice-oriented preventative role.",
    "descriptor": "",
    "authors": [
      "Jan Voltaire Vergara",
      "Maria Y. Rodriguez",
      "Ehren Dohler",
      "Jonathan Phillips",
      "Melissa Villodas",
      "Amy Blank Wilson",
      "Kenneth Joseph"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.14915"
  },
  {
    "id": "arXiv:2111.14917",
    "title": "A Separation Logic for Negative Dependence",
    "abstract": "Formal reasoning about hashing-based probabilistic data structures often\nrequires reasoning about random variables where when one variable gets larger\n(such as the number of elements hashed into one bucket), the others tend to be\nsmaller (like the number of elements hashed into the other buckets). This is an\nexample of negative dependence, a generalization of probabilistic independence\nthat has recently found interesting applications in algorithm design and\nmachine learning. Despite the usefulness of negative dependence for the\nanalyses of probabilistic data structures, existing verification methods cannot\nestablish this property for randomized programs.\nTo fill this gap, we design LINA, a probabilistic separation logic for\nreasoning about negative dependence. Following recent works on probabilistic\nseparation logic using separating conjunction to reason about the probabilistic\nindependence of random variables, we use separating conjunction to reason about\nnegative dependence. Our assertion logic features two separating conjunctions,\none for independence and one for negative dependence. We generalize the logic\nof bunched implications (BI) to support multiple separating conjunctions, and\nprovide a sound and complete proof system. Notably, the semantics for\nseparating conjunction relies on a non-deterministic, rather than partial,\noperation for combining resources. By drawing on closure properties for\nnegative dependence, our program logic supports a Frame-like rule for negative\ndependence and monotone operations. We demonstrate how LINA can verify\nprobabilistic properties of hash-based data structures and balls-into-bins\nprocesses.",
    "descriptor": "\nComments: 61 pages, 9 figures, to appear in Proceedings of the ACM on Programming Languages (POPL 2022)\n",
    "authors": [
      "Jialu Bao",
      "Marco Gaboardi",
      "Justin Hsu",
      "Joseph Tassarotti"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.14917"
  },
  {
    "id": "arXiv:2111.14923",
    "title": "Equitable modelling of brain imaging by counterfactual augmentation with  morphologically constrained 3D deep generative models",
    "abstract": "We describe Countersynth, a conditional generative model of diffeomorphic\ndeformations that induce label-driven, biologically plausible changes in\nvolumetric brain images. The model is intended to synthesise counterfactual\ntraining data augmentations for downstream discriminative modelling tasks where\nfidelity is limited by data imbalance, distributional instability, confounding,\nor underspecification, and exhibits inequitable performance across distinct\nsubpopulations. Focusing on demographic attributes, we evaluate the quality of\nsynthesized counterfactuals with voxel-based morphometry, classification and\nregression of the conditioning attributes, and the Fr\\'{e}chet inception\ndistance. Examining downstream discriminative performance in the context of\nengineered demographic imbalance and confounding, we use UK Biobank magnetic\nresonance imaging data to benchmark CounterSynth augmentation against current\nsolutions to these problems. We achieve state-of-the-art improvements, both in\noverall fidelity and equity. The source code for CounterSynth is available\nonline.",
    "descriptor": "",
    "authors": [
      "Guilherme Pombo",
      "Robert Gray",
      "Jorge Cardoso",
      "Sebastien Ourselin",
      "Geraint Rees",
      "John Ashburner",
      "Parashkev Nachev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14923"
  },
  {
    "id": "arXiv:2111.14924",
    "title": "Architecture Matters: Investigating the Influence of Differential  Privacy on Neural Network Design",
    "abstract": "One barrier to more widespread adoption of differentially private neural\nnetworks is the entailed accuracy loss. To address this issue, the relationship\nbetween neural network architectures and model accuracy under differential\nprivacy constraints needs to be better understood. As a first step, we test\nwhether extant knowledge on architecture design also holds in the\ndifferentially private setting. Our findings show that it does not;\narchitectures that perform well without differential privacy, do not\nnecessarily do so with differential privacy. Consequently, extant knowledge on\nneural network architecture design cannot be seamlessly translated into the\ndifferential privacy context. Future research is required to better understand\nthe relationship between neural network architectures and model accuracy to\nenable better architecture design choices under differential privacy\nconstraints.",
    "descriptor": "\nComments: To be presented at Privacy in Machine Learning (NeurIPS 2021 Workshop)\n",
    "authors": [
      "Felix Morsbach",
      "Tobias Dehling",
      "Ali Sunyaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14924"
  },
  {
    "id": "arXiv:2111.14929",
    "title": "Trend and Thoughts: Understanding Climate Change Concern using Machine  Learning and Social Media Data",
    "abstract": "Nowadays social media platforms such as Twitter provide a great opportunity\nto understand public opinion of climate change compared to traditional survey\nmethods. In this paper, we constructed a massive climate change Twitter dataset\nand conducted comprehensive analysis using machine learning. By conducting\ntopic modeling and natural language processing, we show the relationship\nbetween the number of tweets about climate change and major climate events; the\ncommon topics people discuss climate change; and the trend of sentiment. Our\ndataset was published on Kaggle\n(\\url{https://www.kaggle.com/leonshangguan/climate-change-tweets-ids-until-aug-2021})\nand can be used in further research.",
    "descriptor": "",
    "authors": [
      "Zhongkai Shangguan",
      "Zihe Zheng",
      "Lei Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.14929"
  },
  {
    "id": "arXiv:2111.14931",
    "title": "How Facial Features Convey Attention in Stationary Environments",
    "abstract": "Awareness detection technologies have been gaining traction in a variety of\nenterprises; most often used for driver fatigue detection, recent research has\nshifted towards using computer vision technologies to analyze user attention in\nenvironments such as online classrooms. This paper aims to extend previous\nresearch on distraction detection by analyzing which visual features contribute\nmost to predicting awareness and fatigue. We utilized the open source facial\nanalysis toolkit OpenFace in order to analyze visual data of subjects at\nvarying levels of attentiveness. Then, using a Support-Vector Machine (SVM) we\ncreated several prediction models for user attention and identified Histogram\nof Oriented Gradients (HOG) and Action Units to be the greatest predictors of\nthe features we tested. We also compared the performance of this SVM to deep\nlearning approaches that utilize Convolutional and/or Recurrent neural networks\n(CNN's and CRNN's). Interestingly, CRNN's did not appear to perform\nsignificantly better than their CNN counterparts. While deep learning methods\nachieved greater prediction accuracy, SVMs utilized less resources and, using\ncertain parameters, were able to approach the performance of deep learning\nmethods.",
    "descriptor": "",
    "authors": [
      "Janelle Domantay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14931"
  },
  {
    "id": "arXiv:2111.14932",
    "title": "Learning with Noisy Labels by Efficient Transition Matrix Estimation to  Combat Label Miscorrection",
    "abstract": "Recent studies on learning with noisy labels have shown remarkable\nperformance by exploiting a small clean dataset. In particular, model agnostic\nmeta-learning-based label correction methods further improve performance by\ncorrecting noisy labels on the fly. However, there is no safeguard on the label\nmiscorrection, resulting in unavoidable performance degradation. Moreover,\nevery training step requires at least three back-propagations, significantly\nslowing down the training speed. To mitigate these issues, we propose a robust\nand efficient method that learns a label transition matrix on the fly.\nEmploying the transition matrix makes the classifier skeptical about all the\ncorrected samples, which alleviates the miscorrection issue. We also introduce\na two-head architecture to efficiently estimate the label transition matrix\nevery iteration within a single back-propagation, so that the estimated matrix\nclosely follows the shifting noise distribution induced by label correction.\nExtensive experiments demonstrate that our approach shows the best performance\nin training efficiency while having comparable or better accuracy than existing\nmethods.",
    "descriptor": "",
    "authors": [
      "Seong Min Kye",
      "Kwanghee Choi",
      "Joonyoung Yi",
      "Buru Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.14932"
  },
  {
    "id": "arXiv:2111.14934",
    "title": "GAN-CNMP: An Interactive Generative Drawing Tool",
    "abstract": "Sketches are abstract representations of visual perception and visuospatial\nconstruction. In this work, we proposed a new framework, GAN-CNMP, that\nincorporates a novel adversarial loss on CNMP to increase sketch smoothness and\nconsistency. Through the experiments, we show that our model can be trained\nwith few unlabeled samples, can construct distributions automatically in the\nlatent space, and produces better results than the base model in terms of shape\nconsistency and smoothness.",
    "descriptor": "\nComments: 9 pages, 10 figures\n",
    "authors": [
      "S. Ece Ada",
      "M. Yunus Seker",
      "Pinar Yanardag"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.14934"
  },
  {
    "id": "arXiv:2111.14937",
    "title": "Forecasting battery capacity and power degradation with multi-task  learning",
    "abstract": "Lithium-ion batteries degrade due to usage and exposure to environmental\nconditions, which affects their capability to store energy and supply power.\nAccurately predicting the capacity and power fade of lithium-ion battery cells\nis challenging due to intrinsic manufacturing variances and coupled nonlinear\nageing mechanisms. In this paper, we propose a data-driven prognostics\nframework to predict both capacity and power fade simultaneously with\nmulti-task learning. The model is able to predict the degradation trajectory of\nboth capacity and internal resistance together with knee-points and end-of-life\npoints accurately with as little as 100 cycles. The validation shows an average\npercentage error of 2.37% and 1.24% for the prediction of capacity fade and\nresistance rise, respectively. The model's ability to accurately predict the\ndegradation, facing capacity and resistance estimation errors, further\ndemonstrates the model's robustness and generalizability. Compared with\nsingle-task learning models for forecasting capacity and power degradation, the\nmodel shows a significant prediction accuracy improvement and computational\ncost reduction. This work presents the highlights of multi-task learning in the\ndegradation prognostics for lithium-ion batteries.",
    "descriptor": "",
    "authors": [
      "Weihan Li",
      "Haotian Zhang",
      "Bruis van Vlijmen",
      "Philipp Dechent",
      "Dirk Uwe Sauer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.14937"
  },
  {
    "id": "arXiv:2111.14938",
    "title": "Distribution Shift in Airline Customer Behavior during COVID-19",
    "abstract": "Traditional AI approaches in customized (personalized) contextual pricing\napplications assume that the data distribution at the time of online pricing is\nsimilar to that observed during training. However, this assumption may be\nviolated in practice because of the dynamic nature of customer buying patterns,\nparticularly due to unanticipated system shocks such as COVID-19. We study the\nchanges in customer behavior for a major airline during the COVID-19 pandemic\nby framing it as a covariate shift and concept drift detection problem. We\nidentify which customers changed their travel and purchase behavior and the\nattributes affecting that change using (i) Fast Generalized Subset Scanning and\n(ii) Causal Forests. In our experiments with simulated and real-world data, we\npresent how these two techniques can be used through qualitative analysis.",
    "descriptor": "\nComments: 6 papes, 5 figures, NeurIPS 2021 Workshop on Distribution Shifts: connecting methods and applications (DistShift)\n",
    "authors": [
      "Abhinav Garg",
      "Naman Shukla",
      "Lavanya Marla",
      "Sriram Somanchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2111.14938"
  },
  {
    "id": "arXiv:2111.14943",
    "title": "Morph Detection Enhanced by Structured Group Sparsity",
    "abstract": "In this paper, we consider the challenge of face morphing attacks, which\nsubstantially undermine the integrity of face recognition systems such as those\nadopted for use in border protection agencies. Morph detection can be\nformulated as extracting fine-grained representations, where local\ndiscriminative features are harnessed for learning a hypothesis. To acquire\ndiscriminative features at different granularity as well as a decoupled\nspectral information, we leverage wavelet domain analysis to gain insight into\nthe spatial-frequency content of a morphed face. As such, instead of using\nimages in the RGB domain, we decompose every image into its wavelet sub-bands\nusing 2D wavelet decomposition and a deep supervised feature selection scheme\nis employed to find the most discriminative wavelet sub-bands of input images.\nTo this end, we train a Deep Neural Network (DNN) morph detector using the\ndecomposed wavelet sub-bands of the morphed and bona fide images. In the\ntraining phase, our structured group sparsity-constrained DNN picks the most\ndiscriminative wavelet sub-bands out of all the sub-bands, with which we\nretrain our DNN, resulting in a precise detection of morphed images when\ninference is achieved on a probe image. The efficacy of our deep morph detector\nwhich is enhanced by structured group lasso is validated through experiments on\nthree facial morph image databases, i.e., VISAPP17, LMA, and MorGAN.",
    "descriptor": "",
    "authors": [
      "Poorya Aghdaie",
      "Baaria Chaudhary",
      "Sobhan Soleymani",
      "Jeremy Dawson",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14943"
  },
  {
    "id": "arXiv:2111.14946",
    "title": "Verifying Transactional Consistency of MongoDB",
    "abstract": "MongoDB is a popular general-purpose, document-oriented, distributed NoSQL\ndatabase. It supports transactions in three different deployments:\nsingle-document transactions utilizing the WiredTiger storage engine in a\nstandalone node, multi-document transactions in a replica set which consists of\na primary node and several secondary nodes, and distributed transactions in a\nsharded cluster which is a group of multiple replica sets, among which data is\nsharded. A natural and fundamental question about MongoDB transactions is: What\ntransactional consistency guarantee do MongoDB Transactions in each deployment\nprovide? However, it lacks both concise pseudocode of MongoDB transactions in\neach deployment and formal specification of the consistency guarantees which\nMongoDB claimed to provide. In this work, we formally specify and verify the\ntransactional consistency protocols of MongoDB. Specifically, we provide a\nconcise pseudocode for the transactional consistency protocols in each MongoDB\ndeployment, namely WIREDTIGER, REPLICASET, and SHARDEDCLUSTER, based on the\nofficial documents and source code. We then prove that WIREDTIGER, REPLICASET,\nand SHARDEDCLUSTER satisfy different variants of snapshot isolation, namely\nStrong-SI, Realtime-SI, and Session-SI, respectively. We also propose and\nevaluate efficient white-box checking algorithms for MongoDB transaction\nprotocols against their consistency guarantees, effectively circumventing the\nNP-hard obstacle in theory.",
    "descriptor": "\nComments: v0.1, without correctness proo and data of experimental results. 13 pages(12 pages excluding reference), 8 algorithms, 6 tables and 1 figure\n",
    "authors": [
      "Hongrong Ouyang",
      "Hengfeng Wei",
      "Yu Huang",
      "Haixiang Li",
      "Anqun Pan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.14946"
  },
  {
    "id": "arXiv:2111.14947",
    "title": "An Asymptotic Cost Model for Autoscheduling Sparse Tensor Programs",
    "abstract": "While loop reordering and fusion can make big impacts on the constant-factor\nperformance of dense tensor programs, the effects on sparse tensor programs are\nasymptotic, often leading to orders of magnitude performance differences in\npractice. Sparse tensors also introduce a choice of compressed storage formats\nthat can have asymptotic effects. Research into sparse tensor compilers has led\nto simplified languages that express these tradeoffs, but the user is expected\nto provide a schedule that makes the decisions. This is challenging because\nschedulers must anticipate the interaction between sparse formats, loop\nstructure, potential sparsity patterns, and the compiler itself. Automating\nthis decision making process stands to finally make sparse tensor compilers\naccessible to end users.\nWe present, to the best of our knowledge, the first automatic asymptotic\nscheduler for sparse tensor programs. We provide an approach to abstractly\nrepresent the asymptotic cost of schedules and to choose between them. We\nnarrow down the search space to a manageably small \"Pareto frontier\" of\nasymptotically undominated kernels. We test our approach by compiling these\nkernels with the TACO sparse tensor compiler and comparing them with those\ngenerated with the default TACO schedules. Our results show that our approach\nreduces the scheduling space by orders of magnitude and that the generated\nkernels perform asymptotically better than those generated using the default\nschedules.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Peter Ahrens",
      "Fredrik Kjolstad",
      "Saman Amarasinghe"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.14947"
  },
  {
    "id": "arXiv:2111.14948",
    "title": "Image denoising by Super Neurons: Why go deep?",
    "abstract": "Classical image denoising methods utilize the non-local self-similarity\nprinciple to effectively recover image content from noisy images. Current\nstate-of-the-art methods use deep convolutional neural networks (CNNs) to\neffectively learn the mapping from noisy to clean images. Deep denoising CNNs\nmanifest a high learning capacity and integrate non-local information owing to\nthe large receptive field yielded by numerous cascade of hidden layers.\nHowever, deep networks are also computationally complex and require large data\nfor training. To address these issues, this study draws the focus on the\nSelf-organized Operational Neural Networks (Self-ONNs) empowered by a novel\nneuron model that can achieve a similar or better denoising performance with a\ncompact and shallow model. Recently, the concept of super-neurons has been\nintroduced which augment the non-linear transformations of generative neurons\nby utilizing non-localized kernel locations for an enhanced receptive field\nsize. This is the key accomplishment which renders the need for a deep network\nconfiguration. As the integration of non-local information is known to benefit\ndenoising, in this work we investigate the use of super neurons for both\nsynthetic and real-world image denoising. We also discuss the practical issues\nin implementing the super neuron model on GPUs and propose a trade-off between\nthe heterogeneity of non-localized operations and computational complexity. Our\nresults demonstrate that with the same width and depth, Self-ONNs with super\nneurons provide a significant boost of denoising performance over the networks\nwith generative and convolutional neurons for both denoising tasks. Moreover,\nresults demonstrate that Self-ONNs with super neurons can achieve a competitive\nand superior synthetic denoising performances than well-known deep CNN\ndenoisers for synthetic and real-world denoising, respectively.",
    "descriptor": "",
    "authors": [
      "Junaid Malik",
      "Serkan Kiranyaz",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14948"
  },
  {
    "id": "arXiv:2111.14951",
    "title": "Expressive Communication: A Common Framework for Evaluating Developments  in Generative Models and Steering Interfaces",
    "abstract": "There is an increasing interest from ML and HCI communities in empowering\ncreators with better generative models and more intuitive interfaces with which\nto control them. In music, ML researchers have focused on training models\ncapable of generating pieces with increasing long-range structure and musical\ncoherence, while HCI researchers have separately focused on designing steering\ninterfaces that support user control and ownership. In this study, we\ninvestigate through a common framework how developments in both models and user\ninterfaces are important for empowering co-creation where the goal is to create\nmusic that communicates particular imagery or ideas (e.g., as is common for\nother purposeful tasks in music creation like establishing mood or creating\naccompanying music for another media). Our study is distinguished in that it\nmeasures communication through both composer's self-reported experiences, and\nhow listeners evaluate this communication through the music. In an evaluation\nstudy with 26 composers creating 100+ pieces of music and listeners providing\n1000+ head-to-head comparisons, we find that more expressive models and more\nsteerable interfaces are important and complementary ways to make a difference\nin composers communicating through music and supporting their creative\nempowerment.",
    "descriptor": "\nComments: 15 pages, 6 figures, submitted to ACM Intelligent User Interfaces 2022 Conference\n",
    "authors": [
      "Ryan Louie",
      "Jesse Engel",
      "Anna Huang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.14951"
  },
  {
    "id": "arXiv:2111.14955",
    "title": "Privacy-Preserving Serverless Edge Learning with Decentralized Small  Data",
    "abstract": "In the last decade, data-driven algorithms outperformed traditional\noptimization-based algorithms in many research areas, such as computer vision,\nnatural language processing, etc. However, extensive data usages bring a new\nchallenge or even threat to deep learning algorithms, i.e., privacy-preserving.\nDistributed training strategies have recently become a promising approach to\nensure data privacy when training deep models. This paper extends conventional\nserverless platforms with serverless edge learning architectures and provides\nan efficient distributed training framework from the networking perspective.\nThis framework dynamically orchestrates available resources among heterogeneous\nphysical units to efficiently fulfill deep learning objectives. The design\njointly considers learning task requests and underlying infrastructure\nheterogeneity, including last-mile transmissions, computation abilities of\nmobile devices, edge and cloud computing centers, and devices battery status.\nFurthermore, to significantly reduce distributed training overheads,\nsmall-scale data training is proposed by integrating with a general, simple\ndata classifier. This low-load enhancement can seamlessly work with various\ndistributed deep models to improve communications and computation efficiencies\nduring the training phase. Finally, open challenges and future research\ndirections encourage the research community to develop efficient distributed\ndeep learning techniques.",
    "descriptor": "\nComments: Submitted for publication in the IEEE Network\n",
    "authors": [
      "Shih-Chun Lin",
      "Chia-Hung Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.14955"
  },
  {
    "id": "arXiv:2111.14956",
    "title": "Third-Party Hardware IP Assurance against Trojans through Supervised  Learning and Post-processing",
    "abstract": "System-on-chip (SoC) developers increasingly rely on pre-verified hardware\nintellectual property (IP) blocks acquired from untrusted third-party vendors.\nThese IPs might contain hidden malicious functionalities or hardware Trojans to\ncompromise the security of the fabricated SoCs. Recently, supervised machine\nlearning (ML) techniques have shown promising capability in identifying nets of\npotential Trojans in third party IPs (3PIPs). However, they bring several major\nchallenges. First, they do not guide us to an optimal choice of features that\nreliably covers diverse classes of Trojans. Second, they require multiple\nTrojan-free/trusted designs to insert known Trojans and generate a trained\nmodel. Even if a set of trusted designs are available for training, the suspect\nIP could be inherently very different from the set of trusted designs, which\nmay negatively impact the verification outcome. Third, these techniques only\nidentify a set of suspect Trojan nets that require manual intervention to\nunderstand the potential threat. In this paper, we present VIPR, a systematic\nmachine learning (ML) based trust verification solution for 3PIPs that\neliminates the need for trusted designs for training. We present a\ncomprehensive framework, associated algorithms, and a tool flow for obtaining\nan optimal set of features, training a targeted machine learning model,\ndetecting suspect nets, and identifying Trojan circuitry from the suspect nets.\nWe evaluate the framework on several Trust-Hub Trojan benchmarks and provide a\ncomparative analysis of detection performance across different trained models,\nselection of features, and post-processing techniques. The proposed\npost-processing algorithms reduce false positives by up to 92.85%.",
    "descriptor": "",
    "authors": [
      "Pravin Gaikwad",
      "Jonathan Cruz",
      "Prabuddha Chakraborty",
      "Swarup Bhunia",
      "Tamzidul Hoque"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14956"
  },
  {
    "id": "arXiv:2111.14971",
    "title": "Classification of animal sounds in a hyperdiverse rainforest using  Convolutional Neural Networks",
    "abstract": "To protect tropical forest biodiversity, we need to be able to detect it\nreliably, cheaply, and at scale. Automated species detection from passively\nrecorded soundscapes via machine-learning approaches is a promising technique\ntowards this goal, but it is constrained by the necessity of large training\ndata sets. Using soundscapes from a tropical forest in Borneo and a\nConvolutional Neural Network model (CNN) created with transfer learning, we\ninvestigate i) the minimum viable training data set size for accurate\nprediction of call types ('sonotypes'), and ii) the extent to which data\naugmentation can overcome the issue of small training data sets. We found that\neven relatively high sample sizes (> 80 per call type) lead to mediocre\naccuracy, which however improves significantly with data augmentation,\nincluding at extremely small sample sizes, regardless of taxonomic group or\ncall characteristics. Our results suggest that transfer learning and data\naugmentation can make the use of CNNs to classify species' vocalizations\nfeasible even for small soundscape-based projects with many rare species. Our\nopen-source method has the potential to enable conservation initiatives become\nmore evidence-based by using soundscape data in the adaptive management of\nbiodiversity.",
    "descriptor": "",
    "authors": [
      "Yuren Sun",
      "Tatiana Midori Maeda",
      "Claudia Solis-Lemus",
      "Daniel Pimentel-Alarcon",
      "Zuzana Burivalova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14971"
  },
  {
    "id": "arXiv:2111.14972",
    "title": "Design and Control of a Recovery System for Legged Robots",
    "abstract": "This paper describes the design and control of a support and recovery system\nfor use with planar legged robots. The system operates in three modes. First,\nit can be operated in a fully transparent mode where no forces are applied to\nthe robot. In this mode, the system follows the robot closely to be able to\nquickly catch the robot if needed. Second, it can provide a vertical supportive\nforce to assist a robot during operation. Third, it can catch the robot and\npull it away from the ground after a failure to avoid falls and the associated\ndamages. In this mode, the system automatically resets the robot after a trial\nallowing for multiple consecutive trials to be run without manual intervention.\nThe supportive forces are applied to the robot through an actuated cable and\npulley system that uses series elastic actuation with a unidirectional spring\nto enable truly transparent operation. The nonlinear nature of this system\nnecessitates careful design of controllers to ensure predictable, safe\nbehaviors. In this paper we introduce the mechatronic design of the recovery\nsystem, develop suitable controllers, and evaluate the system's performance on\nthe bipedal robot RAMone.",
    "descriptor": "\nComments: 6 pages, 10 figures, Published in 2016 International Conference on Advanced Intelligent Mechatronics (AIM)\n",
    "authors": [
      "Kevin Green",
      "Nils Smit-Anseeuw",
      "Rodney Gleason",
      "C. David Remy"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.14972"
  },
  {
    "id": "arXiv:2111.14973",
    "title": "MultiPath++: Efficient Information Fusion and Trajectory Aggregation for  Behavior Prediction",
    "abstract": "Predicting the future behavior of road users is one of the most challenging\nand important problems in autonomous driving. Applying deep learning to this\nproblem requires fusing heterogeneous world state in the form of rich\nperception signals and map information, and inferring highly multi-modal\ndistributions over possible futures. In this paper, we present MultiPath++, a\nfuture prediction model that achieves state-of-the-art performance on popular\nbenchmarks. MultiPath++ improves the MultiPath architecture by revisiting many\ndesign choices. The first key design difference is a departure from dense\nimage-based encoding of the input world state in favor of a sparse encoding of\nheterogeneous scene elements: MultiPath++ consumes compact and efficient\npolylines to describe road features, and raw agent state information directly\n(e.g., position, velocity, acceleration). We propose a context-aware fusion of\nthese elements and develop a reusable multi-context gating fusion component.\nSecond, we reconsider the choice of pre-defined, static anchors, and develop a\nway to learn latent anchor embeddings end-to-end in the model. Lastly, we\nexplore ensembling and output aggregation techniques -- common in other ML\ndomains -- and find effective variants for our probabilistic multimodal output\nrepresentation. We perform an extensive ablation on these design choices, and\nshow that our proposed model achieves state-of-the-art performance on the\nArgoverse Motion Forecasting Competition and the Waymo Open Dataset Motion\nPrediction Challenge.",
    "descriptor": "",
    "authors": [
      "Balakrishnan Varadarajan",
      "Ahmed Hefny",
      "Avikalp Srivastava",
      "Khaled S. Refaat",
      "Nigamaa Nayakanti",
      "Andre Cornman",
      "Kan Chen",
      "Bertrand Douillard",
      "Chi Pang Lam",
      "Dragomir Anguelov",
      "Benjamin Sapp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.14973"
  },
  {
    "id": "arXiv:2111.14974",
    "title": "Algorithms and Lower Bounds for Comparator Circuits from Shrinkage",
    "abstract": "Comparator circuits are a natural circuit model for studying bounded fan-out\ncomputation whose power sits between nondeterministic branching programs and\ngeneral circuits. Despite having been studied for nearly three decades, the\nfirst superlinear lower bound against comparator circuits was proved only\nrecently by G\\'al and Robere (ITCS 2020), who established a $\\Omega((n/\\log\nn)^{1.5})$ lower bound on the size of comparator circuits computing an explicit\nfunction of $n$ bits.\nIn this paper, we initiate the study of average-case complexity and circuit\nanalysis algorithms for comparator circuits. Departing from previous\napproaches, we exploit the technique of shrinkage under random restrictions to\nobtain a variety of new results for this model. Among them, we show\n- Average-case Lower Bounds. For every $k = k(n)$ with $k \\geq \\log n$, there\nexists a polynomial-time computable function $f_k$ on $n$ bits such that, for\nevery comparator circuit $C$ with at most $n^{1.5}/O(k\\cdot \\sqrt{\\log n})$\ngates, we have \\[ \\text{Pr}_{x\\in\\left\\{ 0,1\n\\right\\}^n}\\left[C(x)=f_k(x)\\right]\\leq \\frac{1}{2} + \\frac{1}{2^{\\Omega(k)}}.\n\\] This average-case lower bound matches the worst-case lower bound of G\\'al\nand Robere by letting $k=O(\\log n)$.\n- #SAT Algorithms. There is an algorithm that counts the number of satisfying\nassignments of a given comparator circuit with at most $n^{1.5}/O\\!\\left(k\\cdot\n\\sqrt{\\log n}\\right)$ gates, in time $2^{n-k}\\cdot\\text{poly}(n)$, for any\n$k\\leq n/4$. The running time is non-trivial when $k=\\omega(\\log n)$.\n- Pseudorandom Generators and MCSP Lower Bounds. There is a pseudorandom\ngenerator of seed length $s^{2/3+o(1)}$ that fools comparator circuits with $s$\ngates. Also, using this PRG, we obtain an $n^{1.5-o(1)}$ lower bound for MCSP\nagainst comparator circuits.",
    "descriptor": "",
    "authors": [
      "Bruno P. Cavalar",
      "Zhenjian Lu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.14974"
  },
  {
    "id": "arXiv:2111.14977",
    "title": "A Natural Language Processing and Deep Learning based Model for  Automated Vehicle Diagnostics using Free-Text Customer Service Reports",
    "abstract": "Initial fault detection and diagnostics are imperative measures to improve\nthe efficiency, safety, and stability of vehicle operation. In recent years,\nnumerous studies have investigated data-driven approaches to improve the\nvehicle diagnostics process using available vehicle data. Moreover, data-driven\nmethods are employed to enhance customer-service agent interactions. In this\nstudy, we demonstrate a machine learning pipeline to improve automated vehicle\ndiagnostics. First, Natural Language Processing (NLP) is used to automate the\nextraction of crucial information from free-text failure reports (generated\nduring customers' calls to the service department). Then, deep learning\nalgorithms are employed to validate service requests and filter vague or\nmisleading claims. Ultimately, different classification algorithms are\nimplemented to classify service requests so that valid service requests can be\ndirected to the relevant service department. The proposed model- Bidirectional\nLong Short Term Memory (BiLSTM) along with Convolution Neural Network (CNN)-\nshows more than 18\\% accuracy improvement in validating service requests\ncompared to technicians' capabilities. In addition, using domain-based NLP\ntechniques at preprocessing and feature extraction stages along with CNN-BiLSTM\nbased request validation enhanced the accuracy ($>25\\%$), sensitivity\n($>39\\%$), specificity ($>11\\%$), and precision ($>11\\%$) of Gradient Tree\nBoosting (GTB) service classification model. The Receiver Operating\nCharacteristic Area Under the Curve (ROC-AUC) reached 0.82.",
    "descriptor": "\nComments: 24 page, 8 figures\n",
    "authors": [
      "Ali Khodadadi",
      "Soroush Ghandiparsi",
      "Chen-Nee Chuah"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computation and Language (cs.CL)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.14977"
  },
  {
    "id": "arXiv:2111.14984",
    "title": "Continuous conditional generative adversarial networks for data-driven  solutions of poroelasticity with heterogeneous material properties",
    "abstract": "Machine learning-based data-driven modeling can be computationally efficient\nsolutions of time-dependent subsurface geophysical systems. In this work, our\nprevious approach of conditional generative adversarial networks (cGAN)\ndeveloped for steady-state problems with heterogeneous materials is extended to\ntime-dependent problems by adopting the concept of continuous cGAN (CcGAN). The\nCcGAN that can condition continuous variables in the cGAN framework is\ndeveloped to incorporate the time domain through either element-wise addition\nor conditional batch normalization. As a demonstration case, the transient\nresponse of the coupled poroelastic process is studied in two different\npermeability fields: Zinn \\& Harvey transformation and a bimodal\ntransformation. The proposed CcGAN uses heterogeneous permeability fields as\ninput parameters while pressure and displacement fields over time are model\noutput. Our results show that the model provides sufficient accuracy with\ncomputational speed-up. This robust framework will enable us to perform\nreal-time reservoir management and robust uncertainty quantification in\nrealistic problems.",
    "descriptor": "",
    "authors": [
      "T. Kadeethum",
      "D. O'Malley",
      "Y. Choi",
      "H. S. Viswanathan",
      "N. Bouklas",
      "H. Yoon"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.14984"
  },
  {
    "id": "arXiv:2111.14987",
    "title": "Ankle Torque During Mid-Stance Does Not Lower Energy Requirements of  Steady Gaits",
    "abstract": "In this paper, we investigate whether applying ankle torques during\nmid-stance can be a more effective way to reduce energetic cost of locomotion\nthan actuating leg length alone. Ankles are useful in human gaits for many\nreasons including static balancing. In this work, we specifically avoid the\nheel-strike and toe-off benefits to investigate whether the progression of the\ncenter of pressure from heel-to-toe during mid-stance, or some other approach,\nis beneficial in and of itself. We use an \"Ankle Actuated Spring Loaded\nInverted Pendulum\" model to simulate the shifting center of pressure dynamics,\nand trajectory optimization is applied to find limit cycles that minimize cost\nof transport. The results show that, for the vast majority of gaits, ankle\ntorques do not affect cost of transport. Ankles reduce the cost of transport\nduring a narrow band of gaits at the transition from grounded running to aerial\nrunning. This suggests that applying ankle torque during mid-stance of a steady\ngait is not a directly beneficial strategy, but is most likely a path between\nbeneficial heel-strikes and toe-offs.",
    "descriptor": "\nComments: 8 pages, 5 figures, published in 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Mike Hector",
      "Kevin Green",
      "Burak Sencer",
      "Jonathan Hurst"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.14987"
  },
  {
    "id": "arXiv:2111.14988",
    "title": "Adversarial Training for a Hybrid Approach to Aspect-Based Sentiment  Analysis",
    "abstract": "The increasing popularity of the Web has subsequently increased the abundance\nof reviews on products and services. Mining these reviews for expressed\nsentiment is beneficial for both companies and consumers, as quality can be\nimproved based on this information. In this paper, we consider the\nstate-of-the-art HAABSA++ algorithm for aspect-based sentiment analysis tasked\nwith identifying the sentiment expressed towards a given aspect in review\nsentences. Specifically, we train the neural network part of this algorithm\nusing an adversarial network, a novel machine learning training method where a\ngenerator network tries to fool the classifier network by generating highly\nrealistic new samples, as such increasing robustness. This method, as of yet\nnever in its classical form applied to aspect-based sentiment analysis, is\nfound to be able to considerably improve the out-of-sample accuracy of\nHAABSA++: for the SemEval 2015 dataset, accuracy was increased from 81.7% to\n82.5%, and for the SemEval 2016 task, accuracy increased from 84.4% to 87.3%.",
    "descriptor": "\nComments: 22nd International Conference on Web Information Systems Engineering\n",
    "authors": [
      "Ron Hochstenbach",
      "Flavius Frasincar",
      "Maria Mihaela Trusca"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.14988"
  },
  {
    "id": "arXiv:2111.14990",
    "title": "MIXER: A Principled Framework for Multimodal, Multiway Data Association",
    "abstract": "A fundamental problem in robotic perception is matching identical objects or\ndata, with applications such as loop closure detection, place recognition,\nobject tracking, and map fusion. While the problem becomes considerably more\nchallenging when matching should be done jointly across multiple, multimodal\nsets of data, the robustness and accuracy of matching in the presence of noise\nand outliers can be greatly improved in this setting. At present, multimodal\ntechniques do not leverage multiway information, and multiway techniques do not\nincorporate different modalities, leading to inferior results. In contrast, we\npresent a principled mixed-integer quadratic framework to address this issue.\nWe use a novel continuous relaxation in a projected gradient descent algorithm\nthat guarantees feasible solutions of the integer program are obtained\nefficiently. We demonstrate experimentally that correspondences obtained from\nour approach are more stable to noise and errors than state-of-the-art\ntechniques. Tested on a robotics dataset, our algorithm resulted in a 35%\nincrease in F1 score when compared to the best alternative.",
    "descriptor": "\nComments: presented in ICRA 2021 Workshop on Robust Perception for Autonomous Field Robots in Challenging Environments\n",
    "authors": [
      "Parker C. Lusk",
      "Ronak Roy",
      "Kaveh Fathian",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.14990"
  },
  {
    "id": "arXiv:2111.14991",
    "title": "Bayesian Optimization for auto-tuning GPU kernels",
    "abstract": "Finding optimal parameter configurations for tunable GPU kernels is a\nnon-trivial exercise for large search spaces, even when automated. This poses\nan optimization task on a non-convex search space, using an expensive to\nevaluate function with unknown derivative. These characteristics make a good\ncandidate for Bayesian Optimization, which has not been applied to this problem\nbefore. However, the application of Bayesian Optimization to this problem is\nchallenging. We demonstrate how to deal with the rough, discrete, constrained\nsearch spaces, containing invalid configurations. We introduce a novel\ncontextual variance exploration factor, as well as new acquisition functions\nwith improved scalability, combined with an informed acquisition function\nselection mechanism. By comparing the performance of our Bayesian Optimization\nimplementation on various test cases to the existing search strategies in\nKernel Tuner, as well as other Bayesian Optimization implementations, we\ndemonstrate that our search strategies generalize well and consistently\noutperform other search strategies by a wide margin.",
    "descriptor": "\nComments: In context of the 2021 International Workshop on Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS) at SuperComputing 2021. Pending publication in IEEE Computer Society Technical Consortium on High Performance Computing (TCHPC)\n",
    "authors": [
      "Floris-Jan Willemsen",
      "Rob van Nieuwpoort",
      "Ben van Werkhoven"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.14991"
  },
  {
    "id": "arXiv:2111.14994",
    "title": "A General Purpose Data and Query Privacy Preserving Protocol for  Wireless Sensor Networks",
    "abstract": "Wireless Sensor Networks (WSNs) are composed of a large number of spatially\ndistributed devices equipped with sensing technology and interlinked via radio\nsignaling. A WSN deployed for monitoring purposes can provide a ubiquitous view\nover the monitored environment. However, the management of collected data is\nvery resource-consuming and raises security and privacy issues. In this paper,\nwe propose a privacy preserving protocol for collecting aggregated data from\nWSNs. The protocol relies on the Onion Routing technique to provide uniformly\ndistributed network traffic and confine the knowledge a foreign actor can gain\nfrom monitoring messages traveling the network. Our solution employs the\ncomputing power of nodes in the network by conveying them general-purpose\ncomputer code for in-situ processing and aggregation of data sourcing from\nmultiple sensor nodes. We complement our work with a simulation of the proposed\nsolution using the network simulator ns-3. Results of the simulation give an\noverview of the scalability of the solution and highlight potential\nconstraints.",
    "descriptor": "\nComments: Submitted to IEEE IoT Journal, 18 pages, 16 figures\n",
    "authors": [
      "Niki Hrovatin",
      "Aleksandar To\u0161i\u0107",
      "Michael Mrissa",
      "Jernej Vi\u010di\u010d"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.14994"
  },
  {
    "id": "arXiv:2111.14998",
    "title": "Harnessing expressive capacity of Machine Learning modeling to represent  complex coupling of Earth's auroral space weather regimes",
    "abstract": "We develop multiple Deep Learning (DL) models that advance the\nstate-of-the-art predictions of the global auroral particle precipitation. We\nuse observations from low Earth orbiting spacecraft of the electron energy flux\nto develop a model that improves global nowcasts (predictions at the time of\nobservation) of the accelerated particles. Multiple Machine Learning (ML)\nmodeling approaches are compared, including a novel multi-task model, models\nwith tail- and distribution-based loss functions, and a spatio-temporally\nsparse 2D-convolutional model. We detail the data preparation process as well\nas the model development that will be illustrative for many similar time series\nglobal regression problems in space weather and across domains. Our ML\nimprovements are three-fold: 1) loss function engineering; 2) multi-task\nlearning; and 3) transforming the task from time series prediction to\nspatio-temporal prediction. Notably, the ML models improve prediction of the\nextreme events, historically obstinate to accurate specification and indicate\nthat increased expressive capacity provided by ML innovation can address grand\nchallenges in the science of space weather.",
    "descriptor": "\nComments: Lower resolution\n",
    "authors": [
      "Jack Ziegler",
      "Ryan M. Mcgranaghan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14998"
  },
  {
    "id": "arXiv:2111.15000",
    "title": "Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable  Prototypes",
    "abstract": "Machine learning has been widely adopted in many domains, including\nhigh-stakes applications such as healthcare, finance, and criminal justice. To\naddress concerns of fairness, accountability and transparency, predictions made\nby machine learning models in these critical domains must be interpretable. One\nline of work approaches this challenge by integrating the power of deep neural\nnetworks and the interpretability of case-based reasoning to produce accurate\nyet interpretable image classification models. These models generally classify\ninput images by comparing them with prototypes learned during training,\nyielding explanations in the form of \"this looks like that.\" However, methods\nfrom this line of work use spatially rigid prototypes, which cannot explicitly\naccount for pose variations. In this paper, we address this shortcoming by\nproposing a case-based interpretable neural network that provides spatially\nflexible prototypes, called a deformable prototypical part network (Deformable\nProtoPNet). In a Deformable ProtoPNet, each prototype is made up of several\nprototypical parts that adaptively change their relative spatial positions\ndepending on the input image. This enables each prototype to detect object\nfeatures with a higher tolerance to spatial transformations, as the parts\nwithin a prototype are allowed to move. Consequently, a Deformable ProtoPNet\ncan explicitly capture pose variations, improving both model accuracy and the\nrichness of explanations provided. Compared to other case-based interpretable\nmodels using prototypes, our approach achieves competitive accuracy, gives an\nexplanation with greater context, and is easier to train, thus enabling wider\nuse of interpretable models for computer vision.",
    "descriptor": "",
    "authors": [
      "Jon Donnelly",
      "Alina Jade Barnett",
      "Chaofan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15000"
  },
  {
    "id": "arXiv:2111.15002",
    "title": "LEGS: Learning Efficient Grasp Sets for Exploratory Grasping",
    "abstract": "Previous work defined Exploratory Grasping, where a robot iteratively grasps\nand drops an unknown complex polyhedral object to discover a set of robust\ngrasps for each recognizably distinct stable pose of the object. Recent work\nused a multi-armed bandit model with a small set of candidate grasps per pose;\nhowever, for objects with few successful grasps, this set may not include the\nmost robust grasp. We present Learned Efficient Grasp Sets (LEGS), an algorithm\nthat can efficiently explore thousands of possible grasps by constructing small\nactive sets of promising grasps and uses learned confidence bounds to determine\nwhen, with high confidence, it can stop exploring the object. Experiments\nsuggest that LEGS can identify a high-quality grasp more efficiently than prior\nalgorithms which do not learn active sets. In simulation experiments, we\nmeasure the optimality gap between the success probability of the best grasp\nidentified by LEGS and baselines and that of the true most robust grasp. After\n3000 steps of exploration, LEGS outperforms baseline algorithms on 10 of the 14\nDex-Net Adversarial objects and 25 of the 39 EGAD! objects. We then develop a\nself-supervised grasping system, where the robot explores grasps with minimal\nhuman intervention. Physical experiments across 3 objects suggest that LEGS\nconverges to high-performing grasps significantly faster than baselines. See\n\\url{https://sites.google.com/view/legs-exp-grasping} for supplemental material\nand videos.",
    "descriptor": "",
    "authors": [
      "Letian Fu",
      "Michael Danielczuk",
      "Ashwin Balakrishna",
      "Daniel S. Brown",
      "Jeffrey Ichnowski",
      "Eugen Solowjow",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.15002"
  },
  {
    "id": "arXiv:2111.15008",
    "title": "Real-Time CRLB based Antenna Selection in Planar Antenna Arrays",
    "abstract": "Estimation of User Terminals' (UTs') Angle of Arrival (AoA) plays a\nsignificant role in the next generation of wireless systems. Due to high\ndemands, energy efficiency concerns, and scarcity of available resources, it is\npivotal how these resources are used. Installed antennas and their\ncorresponding hardware at the Base Station (BS) are of these resources. In this\npaper, we address the problem of antenna selection to minimize Cramer-Rao Lower\nBound (CRLB) of a planar antenna array when fewer antennas than total available\nantennas have to be used for a UT. First, the optimal antenna selection\nstrategy to minimize the expected CRLB in a planar antenna array is proposed.\nThen, using this strategy as a preliminary step, we present a two-step antenna\nselection method whose goal is to minimize the instantaneous CRLB. Minimizing\ninstantaneous CRLB through antenna selection is a combinatorial optimization\nproblem for which we utilize a greedy algorithm. The optimal start point of the\ngreedy algorithm is presented alongside some methods to reduce the\ncomputational complexity of the selection procedure. Numerical results confirm\nthe accuracy of the proposed solutions and highlight the benefits of using\nantenna selection in the localization phase in a wireless system.",
    "descriptor": "",
    "authors": [
      "Masoud Arash",
      "Ivan Stupia",
      "Luc Vandendorpe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.15008"
  },
  {
    "id": "arXiv:2111.15013",
    "title": "DeepCQ+: Robust and Scalable Routing with Multi-Agent Deep Reinforcement  Learning for Highly Dynamic Networks",
    "abstract": "Highly dynamic mobile ad-hoc networks (MANETs) remain as one of the most\nchallenging environments to develop and deploy robust, efficient, and scalable\nrouting protocols. In this paper, we present DeepCQ+ routing protocol which, in\na novel manner integrates emerging multi-agent deep reinforcement learning\n(MADRL) techniques into existing Q-learning-based routing protocols and their\nvariants and achieves persistently higher performance across a wide range of\ntopology and mobility configurations. While keeping the overall protocol\nstructure of the Q-learning-based routing protocols, DeepCQ+ replaces\nstatically configured parameterized thresholds and hand-written rules with\ncarefully designed MADRL agents such that no configuration of such parameters\nis required a priori. Extensive simulation shows that DeepCQ+ yields\nsignificantly increased end-to-end throughput with lower overhead and no\napparent degradation of end-to-end delays (hop counts) compared to its\nQ-learning based counterparts. Qualitatively, and perhaps more significantly,\nDeepCQ+ maintains remarkably similar performance gains under many scenarios\nthat it was not trained for in terms of network sizes, mobility conditions, and\ntraffic dynamics. To the best of our knowledge, this is the first successful\napplication of the MADRL framework for the MANET routing problem that\ndemonstrates a high degree of scalability and robustness even under\nenvironments that are outside the trained range of scenarios. This implies that\nour MARL-based DeepCQ+ design solution significantly improves the performance\nof Q-learning based CQ+ baseline approach for comparison and increases its\npracticality and explainability because the real-world MANET environment will\nlikely vary outside the trained range of MANET scenarios. Additional techniques\nto further increase the gains in performance and scalability are discussed.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2101.03273\n",
    "authors": [
      "Saeed Kaviani",
      "Bo Ryu",
      "Ejaz Ahmed",
      "Kevin Larson",
      "Anh Le",
      "Alex Yahja",
      "Jae H. Kim"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15013"
  },
  {
    "id": "arXiv:2111.15015",
    "title": "Neural Attention for Image Captioning: Review of Outstanding Methods",
    "abstract": "Image captioning is the task of automatically generating sentences that\ndescribe an input image in the best way possible. The most successful\ntechniques for automatically generating image captions have recently used\nattentive deep learning models. There are variations in the way deep learning\nmodels with attention are designed. In this survey, we provide a review of\nliterature related to attentive deep learning models for image captioning.\nInstead of offering a comprehensive review of all prior work on deep image\ncaptioning models, we explain various types of attention mechanisms used for\nthe task of image captioning in deep learning models. The most successful deep\nlearning models used for image captioning follow the encoder-decoder\narchitecture, although there are differences in the way these models employ\nattention mechanisms. Via analysis on performance results from different\nattentive deep models for image captioning, we aim at finding the most\nsuccessful types of attention mechanisms in deep models for image captioning.\nSoft attention, bottom-up attention, and multi-head attention are the types of\nattention mechanism widely used in state-of-the-art attentive deep learning\nmodels for image captioning. At the current time, the best results are achieved\nfrom variants of multi-head attention with bottom-up attention.",
    "descriptor": "\nComments: This is the accepted version, which we are allowed to publish on arxiv based on Springer Nature policies. For the published version please refer to Springer Nature Artificial Intelligence Review Journal. DOI number is attached. For Citation refer to AIRE journal using DOI link\n",
    "authors": [
      "Zanyar Zohourianshahzadi",
      "Jugal K. Kalita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15015"
  },
  {
    "id": "arXiv:2111.15016",
    "title": "Joint Modeling of Code-Switched and Monolingual ASR via Conditional  Factorization",
    "abstract": "Conversational bilingual speech encompasses three types of utterances: two\npurely monolingual types and one intra-sententially code-switched type. In this\nwork, we propose a general framework to jointly model the likelihoods of the\nmonolingual and code-switch sub-tasks that comprise bilingual speech\nrecognition. By defining the monolingual sub-tasks with label-to-frame\nsynchronization, our joint modeling framework can be conditionally factorized\nsuch that the final bilingual output, which may or may not be code-switched, is\nobtained given only monolingual information. We show that this conditionally\nfactorized joint framework can be modeled by an end-to-end differentiable\nneural network. We demonstrate the efficacy of our proposed model on bilingual\nMandarin-English speech recognition across both monolingual and code-switched\ncorpora.",
    "descriptor": "",
    "authors": [
      "Brian Yan",
      "Chunlei Zhang",
      "Meng Yu",
      "Shi-Xiong Zhang",
      "Siddharth Dalmia",
      "Dan Berrebbi",
      "Chao Weng",
      "Shinji Watanabe",
      "Dong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.15016"
  },
  {
    "id": "arXiv:2111.15018",
    "title": "Hyperspectral Image Segmentation based on Graph Processing over  Multilayer Networks",
    "abstract": "Hyperspectral imaging is an important sensing technology with broad\napplications and impact in areas including environmental science, weather, and\ngeo/space exploration. One important task of hyperspectral image (HSI)\nprocessing is the extraction of spectral-spatial features. Leveraging on the\nrecent-developed graph signal processing over multilayer networks (M-GSP), this\nwork proposes several approaches to HSI segmentation based on M-GSP feature\nextraction. To capture joint spectral-spatial information, we first customize a\ntensor-based multilayer network (MLN) model for HSI, and define a MLN singular\nspace for feature extraction. We then develop an unsupervised HSI segmentation\nmethod by utilizing MLN spectral clustering. Regrouping HSI pixels via\nMLN-based clustering, we further propose a semi-supervised HSI classification\nbased on multi-resolution fusions of superpixels. Our experimental results\ndemonstrate the strength of M-GSP in HSI processing and spectral-spatial\ninformation extraction.",
    "descriptor": "",
    "authors": [
      "Songyang Zhang",
      "Qinwen Deng",
      "Zhi Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.15018"
  },
  {
    "id": "arXiv:2111.15020",
    "title": "US-Rule: Discovering Utility-driven Sequential Rules",
    "abstract": "Utility-driven mining is an important task in data science and has many\napplications in real life. High utility sequential pattern mining (HUSPM) is\none kind of utility-driven mining. HUSPM aims to discover all sequential\npatterns with high utility. However, the existing algorithms of HUSPM can not\nprovide an accurate probability to deal with some scenarios for prediction or\nrecommendation. High-utility sequential rule mining (HUSRM) was proposed to\ndiscover all sequential rules with high utility and high confidence. There is\nonly one algorithm proposed for HUSRM, which is not enough efficient. In this\npaper, we propose a faster algorithm, called US-Rule, to efficiently mine\nhigh-utility sequential rules. It utilizes rule estimated utility co-occurrence\npruning strategy (REUCP) to avoid meaningless computation. To improve the\nefficiency on dense and long sequence datasets, four tighter upper bounds\n(LEEU, REEU, LERSU, RERSU) and their corresponding pruning strategies (LEEUP,\nREEUP, LERSUP, RERSUP) are proposed. Besides, US-Rule proposes rule estimated\nutility recomputing pruning strategy (REURP) to deal with sparse datasets. At\nlast, a large number of experiments on different datasets compared to the\nstate-of-the-art algorithm demonstrate that US-Rule can achieve better\nperformance in terms of execution time, memory consumption and scalability.",
    "descriptor": "\nComments: Preprint. 3 figures, 9 tables\n",
    "authors": [
      "Gengsen Huang",
      "Wensheng Gan",
      "Jian Weng",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15020"
  },
  {
    "id": "arXiv:2111.15023",
    "title": "Georacle: Enabling Geospatially Aware Smart Contracts",
    "abstract": "Smart contracts have enabled a paradigm shift in computing by leveraging\ndecentralized networks of trust to achieve consensus at scale. Oracle networks\nfurther extend the power of smart contracts by solving the so-called \"oracle\nproblem\". Such networks enable smart contracts to make use of the vast amount\npre-existing data available on the web today without jeopardizing the integrity\nof the underlying network of trust. By leveraging oracle networks, smart\ncontracts can make decisions based on data corresponding to the physical world.\nTo this end, we introduce Georacle - an oracle service that enables\ngeospatially aware smart contracts in a way that respects the space constrained\nnature of blockchain environments. Contracts can query the location of objects\nin a given area, map between street addresses and coordinates, and retrieve the\ngeometry of a desired region of space while conserving gas consumption and\navoiding unnecessary data processing.",
    "descriptor": "",
    "authors": [
      "Taha Azzaoui"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.15023"
  },
  {
    "id": "arXiv:2111.15024",
    "title": "A Highly Configurable Hardware/Software Stack for DNN Inference  Acceleration",
    "abstract": "This work focuses on an efficient Agile design methodology for\ndomain-specific accelerators. We employ feature-by-feature enhancement of a\nvertical development stack and apply it to the TVM/VTA inference accelerator.\nWe have enhanced the VTA design space and enabled end-to-end support for\nadditional workloads. This has been accomplished by augmenting the VTA\nmicro-architecture and instruction set architecture (ISA), as well as by\nenhancing the TVM compilation stack to support a wide range of VTA configs.\nThe VTA tsim implementation (CHISEL-based) has been enhanced with fully\npipelined versions of the ALU/GEMM execution units. In tsim, memory width can\nnow range between 8-64 bytes. Field widths have been made more flexible to\nsupport larger scratchpads. New instructions have been added: element-wise\n8-bit multiplication to support depthwise convolution, and load with a choice\nof pad values to support max pooling. Support for more layers and better double\nbuffering has also been added.\nFully pipelining ALU/GEMM helps significantly: 4.9x fewer cycles with minimal\narea change to run ResNet-18 under the default config. Configs featuring a\nfurther 11.5x decrease in cycle count at a cost of 12x greater area can be\ninstantiated. Many points on the area-performance pareto curve are shown,\nshowcasing the balance of execution unit sizing, memory interface width, and\nscratchpad sizing. Finally, VTA is now able to run Mobilenet 1.0 and all layers\nfor ResNets, including the previously disabled pooling and fully connected\nlayers.\nThe TVM/VTA architecture has always featured end-to-end workload evaluation\non RTL in minutes. With our modifications, it now offers a much greater number\nof feasible configurations with a wide range of cost vs. performance. All\ncapabilities mentioned are available in opensource forks while a subset of\nthese capabilities have already been upstreamed.",
    "descriptor": "",
    "authors": [
      "Suvadeep Banerjee",
      "Steve Burns",
      "Pasquale Cocchini",
      "Abhijit Davare",
      "Shweta Jain",
      "Desmond Kirkpatrick",
      "Anton Sorokin",
      "Jin Yang",
      "Zhenkun Yang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15024"
  },
  {
    "id": "arXiv:2111.15026",
    "title": "Anomaly Rule Detection in Sequence Data",
    "abstract": "Analyzing sequence data usually leads to the discovery of interesting\npatterns and then anomaly detection. In recent years, numerous frameworks and\nmethods have been proposed to discover interesting patterns in sequence data as\nwell as detect anomalous behavior. However, existing algorithms mainly focus on\nfrequency-driven analytic, and they are challenging to be applied in real-world\nsettings. In this work, we present a new anomaly detection framework called\nDUOS that enables Discovery of Utility-aware Outlier Sequential rules from a\nset of sequences. In this pattern-based anomaly detection algorithm, we\nincorporate both the anomalousness and utility of a group, and then introduce\nthe concept of utility-aware outlier sequential rule (UOSR). We show that this\nis a more meaningful way for detecting anomalies. Besides, we propose some\nefficient pruning strategies w.r.t. upper bounds for mining UOSR, as well as\nthe outlier detection. An extensive experimental study conducted on several\nreal-world datasets shows that the proposed DUOS algorithm has a better\neffectiveness and efficiency. Finally, DUOS outperforms the baseline algorithm\nand has a suitable scalability.",
    "descriptor": "\nComments: Preprint. 6 figures, 7 tables\n",
    "authors": [
      "Wensheng Gan",
      "Lili Chen",
      "Shicheng Wan",
      "Jiahui Chen",
      "Chien-Ming Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15026"
  },
  {
    "id": "arXiv:2111.15029",
    "title": "Reinforcement Learning Algorithm for Traffic Steering in Heterogeneous  Network",
    "abstract": "Heterogeneous radio access networks require efficient traffic steering\nmethods to reach near-optimal results in order to maximize network capacity.\nThis paper aims to propose a novel traffic steering algorithm for usage in\nHetNets, which utilizes a reinforcement learning algorithm in combination with\nan artificial neural network to maximize total user satisfaction in the\nsimulated cellular network. The novel algorithm was compared with two reference\nalgorithms using network simulation results. The results prove that the novel\nalgorithm provides noticeably better efficiency in comparison with reference\nalgorithms, especially in terms of the number of served users with limited\nfrequency resources of the radio access network.",
    "descriptor": "\nComments: Originally published to IEEE's WiMob '21 (2021 Fourteenth International Workshop on Selected Topics in Mobile and Wireless Computing)\n",
    "authors": [
      "Cezary Adamczyk",
      "Adrian Kliks"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.15029"
  },
  {
    "id": "arXiv:2111.15031",
    "title": "MOTIF: A Large Malware Reference Dataset with Ground Truth Family Labels",
    "abstract": "Malware family classification is a significant issue with public safety and\nresearch implications that has been hindered by the high cost of expert labels.\nThe vast majority of corpora use noisy labeling approaches that obstruct\ndefinitive quantification of results and study of deeper interactions. In order\nto provide the data needed to advance further, we have created the Malware\nOpen-source Threat Intelligence Family (MOTIF) dataset. MOTIF contains 3,095\nmalware samples from 454 families, making it the largest and most diverse\npublic malware dataset with ground truth family labels to date, nearly 3x\nlarger than any prior expert-labeled corpus and 36x larger than the prior\nWindows malware corpus. MOTIF also comes with a mapping from malware samples to\nthreat reports published by reputable industry sources, which both validates\nthe labels and opens new research opportunities in connecting opaque malware\nsamples to human-readable descriptions. This enables important evaluations that\nare normally infeasible due to non-standardized reporting in industry. For\nexample, we provide aliases of the different names used to describe the same\nmalware family, allowing us to benchmark for the first time accuracy of\nexisting tools when names are obtained from differing sources. Evaluation\nresults obtained using the MOTIF dataset indicate that existing tasks have\nsignificant room for improvement, with accuracy of antivirus majority voting\nmeasured at only 62.10% and the well-known AVClass tool having just 46.78%\naccuracy. Our findings indicate that malware family classification suffers a\ntype of labeling noise unlike that studied in most ML literature, due to the\nlarge open set of classes that may not be known from the sample under\nconsideration",
    "descriptor": "",
    "authors": [
      "Robert J. Joyce",
      "Dev Amlani",
      "Charles Nicholas",
      "Edward Raff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.15031"
  },
  {
    "id": "arXiv:2111.15037",
    "title": "CO-SNE: Dimensionality Reduction and Visualization for Hyperbolic Data",
    "abstract": "Hyperbolic space can embed tree metric with little distortion, a desirable\nproperty for modeling hierarchical structures of real-world data and semantics.\nWhile high-dimensional embeddings often lead to better representations, most\nhyperbolic models utilize low-dimensional embeddings, due to non-trivial\noptimization as well as the lack of a visualization for high-dimensional\nhyperbolic data.\nWe propose CO-SNE, extending the Euclidean space visualization tool, t-SNE,\nto hyperbolic space. Like t-SNE, it converts distances between data points to\njoint probabilities and tries to minimize the Kullback-Leibler divergence\nbetween the joint probabilities of high-dimensional data $X$ and\nlow-dimensional embeddings $Y$. However, unlike Euclidean space, hyperbolic\nspace is inhomogeneous: a volume could contain a lot more points at a location\nfar from the origin. CO-SNE thus uses hyperbolic normal distributions for $X$\nand hyberbolic \\underline{C}auchy instead of t-SNE's Student's t-distribution\nfor $Y$, and it additionally attempts to preserve $X$'s individual distances to\nthe \\underline{O}rigin in $Y$.\nWe apply CO-SNE to high-dimensional hyperbolic biological data as well as\nunsupervisedly learned hyperbolic representations. Our results demonstrate that\nCO-SNE deflates high-dimensional hyperbolic data into a low-dimensional space\nwithout losing their hyperbolic characteristics, significantly outperforming\npopular visualization tools such as PCA, t-SNE, UMAP, and HoroPCA, the last of\nwhich is specifically designed for hyperbolic data.",
    "descriptor": "\nComments: 14 pages, 11 figures\n",
    "authors": [
      "Yunhui Guo",
      "Haoran Guo",
      "Stella Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15037"
  },
  {
    "id": "arXiv:2111.15039",
    "title": "Living-Off-The-Land Command Detection Using Active Learning",
    "abstract": "In recent years, enterprises have been targeted by advanced adversaries who\nleverage creative ways to infiltrate their systems and move laterally to gain\naccess to critical data. One increasingly common evasive method is to hide the\nmalicious activity behind a benign program by using tools that are already\ninstalled on user computers. These programs are usually part of the operating\nsystem distribution or another user-installed binary, therefore this type of\nattack is called \"Living-Off-The-Land\". Detecting these attacks is challenging,\nas adversaries may not create malicious files on the victim computers and\nanti-virus scans fail to detect them. We propose the design of an Active\nLearning framework called LOLAL for detecting Living-Off-the-Land attacks that\niteratively selects a set of uncertain and anomalous samples for labeling by a\nhuman analyst. LOLAL is specifically designed to work well when a limited\nnumber of labeled samples are available for training machine learning models to\ndetect attacks. We investigate methods to represent command-line text using\nword-embedding techniques, and design ensemble boosting classifiers to\ndistinguish malicious and benign samples based on the embedding representation.\nWe leverage a large, anonymized dataset collected by an endpoint security\nproduct and demonstrate that our ensemble classifiers achieve an average F1\nscore of 0.96 at classifying different attack classes. We show that our active\nlearning method consistently improves the classifier performance, as more\ntraining data is labeled, and converges in less than 30 iterations when\nstarting with a small number of labeled instances.",
    "descriptor": "\nComments: 14 pages, published in RAID 2021\n",
    "authors": [
      "Talha Ongun",
      "Jack W. Stokes",
      "Jonathan Bar Or",
      "Ke Tian",
      "Farid Tajaddodianfar",
      "Joshua Neil",
      "Christian Seifert",
      "Alina Oprea",
      "John C. Platt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.15039"
  },
  {
    "id": "arXiv:2111.15041",
    "title": "Online Learning for Receding Horizon Control with Provable Regret  Guarantees",
    "abstract": "We address the problem of learning to control an unknown linear dynamical\nsystem with time varying cost functions through the framework of online\nReceding Horizon Control (RHC). We consider the setting where the control\nalgorithm does not know the true system model and has only access to a\nfixed-length (that does not grow with the control horizon) preview of the\nfuture cost functions. We characterize the performance of an algorithm using\nthe metric of dynamic regret, which is defined as the difference between the\ncumulative cost incurred by the algorithm and that of the best sequence of\nactions in hindsight. We propose two different online RHC algorithms to address\nthis problem, namely Certainty Equivalence RHC (CE-RHC) algorithm and\nOptimistic RHC (O-RHC) algorithm. We show that under the standard stability\nassumption for the model estimate, the CE-RHC algorithm achieves\n$\\mathcal{O}(T^{2/3})$ dynamic regret. We then extend this result to the\nsetting where the stability assumption hold only for the true system model by\nproposing the O-RHC algorithm. We show that O-RHC algorithm achieves\n$\\mathcal{O}(T^{2/3})$ dynamic regret but with some additional computation.",
    "descriptor": "",
    "authors": [
      "Deepan Muthirayan",
      "Jianjun Yuan",
      "Dileep Kalathil",
      "Pramod P. Khargonekar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.15041"
  },
  {
    "id": "arXiv:2111.15042",
    "title": "Sequential Transmission Over Binary Asymmetric Channels With Feedback",
    "abstract": "In this paper, we consider the problem of variable-length coding over the\nclass of memoryless binary asymmetric channels (BACs) with noiseless feedback,\nincluding the binary symmetric channel (BSC) as a special case. In 2012,\nNaghshvar et al. introduced an encoding scheme, which we refer to as the\nsmall-enough-difference (SED) encoder, which asymptotically achieves both\ncapacity and Burnashev's optimal error exponent for symmetric binary-input\nchannels. Building on the work of Naghshvar et al., this paper extends the SED\nencoding scheme to the class of BACs and develops a non-asymptotic upper bound\non the average blocklength that is shown to achieve both capacity and the\noptimal error exponent. For the specific case of the BSC, we develop an\nadditional non-asymptotic bound using a two-phase analysis that leverages both\na submartingale synthesis and a Markov chain time of first passage analysis.\nFor the BSC with capacity $1/2$, both new achievability bounds exceed the\nachievability bound of Polyanskiy et al. for a system limited to stop-feedback\ncodes.",
    "descriptor": "\nComments: 18 pages; submitted to IEEE Transactions on Information Theory\n",
    "authors": [
      "Hengjie Yang",
      "Minghao Pan",
      "Amaael Antonini",
      "Richard D. Wesel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.15042"
  },
  {
    "id": "arXiv:2111.15043",
    "title": "RailLoMer: Rail Vehicle Localization and Mapping with  LiDAR-IMU-Odometer-GNSS Data Fusion",
    "abstract": "We present RailLoMer in this article, to achieve real-time accurate and\nrobust odometry and mapping for rail vehicles. RailLoMer receives measurements\nfrom two LiDARs, an IMU, train odometer, and a global navigation satellite\nsystem (GNSS) receiver. As frontend, the estimated motion from IMU/odometer\npreintegration de-skews the denoised point clouds and produces initial guess\nfor frame-to-frame LiDAR odometry. As backend, a sliding window based factor\ngraph is formulated to jointly optimize multi-modal information. In addition,\nwe leverage the plane constraints from extracted rail tracks and the structure\nappearance descriptor to further improve the system robustness against\nrepetitive structures. To ensure a globally-consistent and less blurry mapping\nresult, we develop a two-stage mapping method that first performs scan-to-map\nin local scale, then utilizes the GNSS information to register the submaps. The\nproposed method is extensively evaluated on datasets gathered for a long time\nrange over numerous scales and scenarios, and show that RailLoMer delivers\ndecimeter-grade localization accuracy even in large or degenerated\nenvironments. We also integrate RailLoMer into an interactive train state and\nrailway monitoring system prototype design, which has already been deployed to\nan experimental freight traffic railroad.",
    "descriptor": "",
    "authors": [
      "Yusheng Wang",
      "Yidong Lou",
      "Yi Zhang",
      "Weiwei Song",
      "Fei Huang",
      "Zhiyong Tu",
      "Shimin Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.15043"
  },
  {
    "id": "arXiv:2111.15044",
    "title": "A multi-sensor human gait dataset captured through an optical system and  inertial measurement units",
    "abstract": "Different technologies can acquire data for gait analysis, such as optical\nsystems and inertial measurement units (IMUs). Each technology has its\ndrawbacks and advantages, fitting best to particular applications. The\npresented multi-sensor human gait dataset comprises synchronized inertial and\noptical motion data from 25 subjects free of lower-limb injuries, aged between\n18 and 47 years. A smartphone and a custom micro-controlled device with an IMU\nwere attached to one of the subject's legs to capture accelerometer data, and\n42 reflexive markers were taped over the whole body to record three-dimensional\ntrajectories. The trajectories and accelerations were simultaneously recorded\nand synchronized. Participants were instructed to walk on a straight-level\nwalkway at their normal pace. Ten trials for each participant were recorded and\npre-processed in each of two sessions, performed on different days. This\ndataset supports the comparison of gait parameters and properties of inertial\nand optical capture systems, whereas allows the study of gait characteristics\nspecific for each system.",
    "descriptor": "",
    "authors": [
      "Geise Santos",
      "Marcelo Wanderley",
      "Tiago Tavares",
      "Anderson Rocha"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.15044"
  },
  {
    "id": "arXiv:2111.15046",
    "title": "A Secure Key Sharing Algorithm Exploiting Phase Reciprocity in Wireless  Channels",
    "abstract": "This article presents a secure key exchange algorithm that exploits\nreciprocity in wireless channels to share a secret key between two nodes $A$\nand $B$. Reciprocity implies that the channel phases in the links $A\\rightarrow\nB$ and $B\\rightarrow A$ are the same. A number of such reciprocal phase values\nare measured at nodes $A$ and $B$, called shared phase values hereafter. Each\nshared phase value is used to mask points of a Phase Shift Keying (PSK)\nconstellation. Masking is achieved by rotating each PSK constellation with a\nshared phase value. Rotation of constellation is equivalent to adding phases\nmodulo-$2\\pi$, and as the channel phase is uniformly distributed in $[0,2\\pi)$,\nthe result of summation conveys zero information about summands. To enlarge the\nkey size over a static or slow fading channel, the Radio Frequency (RF)\npropagation path is perturbed to create several independent realizations of\nmulti-path fading, each used to share a new phase value. To eavesdrop a phase\nvalue shared in this manner, the Eavesdropper (Eve) will always face an\nunder-determined system of linear equations which will not reveal any useful\ninformation about its actual solution value. This property is used to establish\na secure key between two legitimate users.",
    "descriptor": "",
    "authors": [
      "Shayan Mohajer Hamidi",
      "Amir Keyvan Khandani",
      "Ehsan Bateni"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.15046"
  },
  {
    "id": "arXiv:2111.15047",
    "title": "Adaptive Gating for Single-Photon 3D Imaging",
    "abstract": "Single-photon avalanche diodes (SPADs) are growing in popularity for depth\nsensing tasks. However, SPADs still struggle in the presence of high ambient\nlight due to the effects of pile-up. Conventional techniques leverage fixed or\nasynchronous gating to minimize pile-up effects, but these gating schemes are\nall non-adaptive, as they are unable to incorporate factors such as scene\npriors and previous photon detections into their gating strategy. We propose an\nadaptive gating scheme built upon Thompson sampling. Adaptive gating\nperiodically updates the gate position based on prior photon observations in\norder to minimize depth errors. Our experiments show that our gating strategy\nresults in significantly reduced depth reconstruction error and acquisition\ntime, even when operating outdoors under strong sunlight conditions.",
    "descriptor": "",
    "authors": [
      "Ryan Po",
      "Adithya Pediredla",
      "Ioannis Gkioulekas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15047"
  },
  {
    "id": "arXiv:2111.15050",
    "title": "AssistSR: Affordance-centric Question-driven Video Segment Retrieval",
    "abstract": "It is still a pipe dream that AI assistants on phone and AR glasses can\nassist our daily life in addressing our questions like \"how to adjust the date\nfor this watch?\" and \"how to set its heating duration? (while pointing at an\noven)\". The queries used in conventional tasks (i.e. Video Question Answering,\nVideo Retrieval, Moment Localization) are often factoid and based on pure text.\nIn contrast, we present a new task called Affordance-centric Question-driven\nVideo Segment Retrieval (AQVSR). Each of our questions is an image-box-text\nquery that focuses on affordance of items in our daily life and expects\nrelevant answer segments to be retrieved from a corpus of instructional\nvideo-transcript segments. To support the study of this AQVSR task, we\nconstruct a new dataset called AssistSR. We design novel guidelines to create\nhigh-quality samples. This dataset contains 1.4k multimodal questions on 1k\nvideo segments from instructional videos on diverse daily-used items. To\naddress AQVSR, we develop a straightforward yet effective model called Dual\nMultimodal Encoders (DME) that significantly outperforms several baseline\nmethods while still having large room for improvement in the future. Moreover,\nwe present detailed ablation analyses. Our codes and data are available at\nhttps://github.com/StanLei52/AQVSR.",
    "descriptor": "\nComments: 15 pages, 11 figures\n",
    "authors": [
      "Stan Weixian Lei",
      "Yuxuan Wang",
      "Dongxing Mao",
      "Difei Gao",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15050"
  },
  {
    "id": "arXiv:2111.15053",
    "title": "Deep Learning for Enhanced Scratch Input",
    "abstract": "The vibrations generated from scratching and tapping on surfaces can be\nhighly expressive and recognizable, and have therefore been proposed as a\nmethod of natural user interface (NUI). Previous systems require custom sensor\nhardware such as contact microphones and have struggled with gesture\nclassification accuracy.\nWe propose a deep learning approach to scratch input. Using smartphones and\ntablets laid on tabletops or other similar surfaces, our system achieved a\ngesture classification accuracy of 95.8\\%, substantially reducing gesture\nmisclassification from previous works. Further, our system achieved this\nperformance when tested on a wide variety of surfaces, mobile devices, and in\nhigh noise environments.\nThe results indicate high potential for the application of deep learning\ntechniques to natural user interface (NUI) systems that can readily convert\nlarge unpowered surfaces into a user interface using just a smartphone with no\nspecial-purpose sensors or hardware.",
    "descriptor": "\nComments: 15 pages, 11 figures\n",
    "authors": [
      "Aman Bhargava",
      "Alice X. Zhou",
      "Adam Carnaffan",
      "Steve Mann"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.15053"
  },
  {
    "id": "arXiv:2111.15056",
    "title": "Camera Distortion-aware 3D Human Pose Estimation in Video with  Optimization-based Meta-Learning",
    "abstract": "Existing 3D human pose estimation algorithms trained on distortion-free\ndatasets suffer performance drop when applied to new scenarios with a specific\ncamera distortion. In this paper, we propose a simple yet effective model for\n3D human pose estimation in video that can quickly adapt to any distortion\nenvironment by utilizing MAML, a representative optimization-based\nmeta-learning algorithm. We consider a sequence of 2D keypoints in a particular\ndistortion as a single task of MAML. However, due to the absence of a\nlarge-scale dataset in a distorted environment, we propose an efficient method\nto generate synthetic distorted data from undistorted 2D keypoints. For the\nevaluation, we assume two practical testing situations depending on whether a\nmotion capture sensor is available or not. In particular, we propose Inference\nStage Optimization using bone-length symmetry and consistency. Extensive\nevaluation shows that our proposed method successfully adapts to various\ndegrees of distortion in the testing phase and outperforms the existing\nstate-of-the-art approaches. The proposed method is useful in practice because\nit does not require camera calibration and additional computations in a testing\nset-up.",
    "descriptor": "\nComments: Accepted to ICCV 2021 (poster)\n",
    "authors": [
      "Hanbyel Cho",
      "Yooshin Cho",
      "Jaemyung Yu",
      "Junmo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15056"
  },
  {
    "id": "arXiv:2111.15064",
    "title": "Hole-robust Wireframe Detection",
    "abstract": "\"Wireframe\" is a line segment based representation designed to well capture\nlarge-scale visual properties of regular, structural shaped man-made scenes\nsurrounding us. Unlike the wireframes, conventional edges or line segments\nfocus on all visible edges and lines without particularly distinguishing which\nof them are more salient to man-made structural information. Existing wireframe\ndetection models rely on supervising the annotated data but do not explicitly\npay attention to understand how to compose the structural shapes of the scene.\nIn addition, we often face that many foreground objects occluding the\nbackground scene interfere with proper inference of the full scene structure\nbehind them. To resolve these problems, we first time in the field, propose new\nconditional data generation and training that help the model understand how to\nignore occlusion indicated by holes, such as foreground object regions masked\nout on the image. In addition, we first time combine GAN in the model to let\nthe model better predict underlying scene structure even beyond large holes. We\nalso introduce pseudo labeling to further enlarge the model capacity to\novercome small-scale labeled data. We show qualitatively and quantitatively\nthat our approach significantly outperforms previous works unable to handle\nholes, as well as improves ordinary detection without holes given.",
    "descriptor": "\nComments: To appear in Proceedings of the 2022 IEEE Winter Conference on Applications of Computer Vision (WACV 2022)\n",
    "authors": [
      "Naejin Kong",
      "Kiwoong Park",
      "Harshith Goka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15064"
  },
  {
    "id": "arXiv:2111.15065",
    "title": "An Analysis of the Numerical Stability of the Immersed Boundary Method",
    "abstract": "We present a numerical stability analysis of the immersed boundary(IB) method\nfor a special case which is constructed so that Fourier analysis is applicable.\nWe examine the stability of the immersed boundary method with the discrete\nFourier transforms defined differently on the fluid grid and the boundary grid.\nThis approach gives accurate theoretical results about the stability boundary\nsince it takes the effects of the spreading kernel of the immersed boundary\nmethod on the numerical stability into account. In this paper, the spreading\nkernel is the standard 4-point IB delta function. A three-dimensional\nincompressible viscous flow and a no-slip planar boundary are considered. The\ncase of a planar elastic membrane is also analyzed using the same analysis\nframework and it serves as an example of many possible generalizations of our\ntheory. We present some numerical results and show that the observed stability\nbehaviors are consistent with what are predicted by our theory.",
    "descriptor": "\nComments: 33 pages, 13 figures\n",
    "authors": [
      "Mengjian Hua",
      "Charles S. Peskin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.15065"
  },
  {
    "id": "arXiv:2111.15068",
    "title": "MISS: Multi-Interest Self-Supervised Learning Framework for  Click-Through Rate Prediction",
    "abstract": "CTR prediction is essential for modern recommender systems. Ranging from\nearly factorization machines to deep learning based models in recent years,\nexisting CTR methods focus on capturing useful feature interactions or mining\nimportant behavior patterns. Despite the effectiveness, we argue that these\nmethods suffer from the risk of label sparsity (i.e., the user-item\ninteractions are highly sparse with respect to the feature space), label noise\n(i.e., the collected user-item interactions are usually noisy), and the\nunderuse of domain knowledge (i.e., the pairwise correlations between samples).\nTo address these challenging problems, we propose a novel Multi-Interest\nSelf-Supervised learning (MISS) framework which enhances the feature embeddings\nwith interest-level self-supervision signals. With the help of two novel\nCNN-based multi-interest extractors,self-supervision signals are discovered\nwith full considerations of different interest representations (point-wise and\nunion-wise), interest dependencies (short-range and long-range), and interest\ncorrelations (inter-item and intra-item). Based on that, contrastive learning\nlosses are further applied to the augmented views of interest representations,\nwhich effectively improves the feature representation learning. Furthermore,\nour proposed MISS framework can be used as an plug-in component with existing\nCTR prediction models and further boost their performances. Extensive\nexperiments on three large-scale datasets show that MISS significantly\noutperforms the state-of-the-art models, by up to 13.55% in AUC, and also\nenjoys good compatibility with representative deep CTR models.",
    "descriptor": "\nComments: Accepted by ICDE2022\n",
    "authors": [
      "Wei Guo",
      "Can Zhang",
      "Zhicheng He",
      "Jiarui Qin",
      "Huifeng Guo",
      "Bo Chen",
      "Ruiming Tang",
      "Xiuqiang He",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.15068"
  },
  {
    "id": "arXiv:2111.15069",
    "title": "Maximizing Social Welfare in Selfish Multi-Modal Routing using Strategic  Information Design for Quantal Response Travelers",
    "abstract": "Traditional selfish routing literature quantifies inefficiency in\ntransportation systems with single-attribute costs using price-of-anarchy\n(PoA), and provides various technical approaches (e.g. marginal cost pricing)\nto improve PoA of the overall network. Unfortunately, practical transportation\nsystems have dynamic, multi-attribute costs and the state-of-the-art technical\napproaches proposed in the literature are infeasible for practical deployment.\nIn this paper, we offer a paradigm shift to selfish routing via characterizing\nidiosyncratic, multi-attribute costs at boundedly-rational travelers, as well\nas improving network efficiency using strategic information design.\nSpecifically, we model the interaction between the system and travelers as a\nStackelberg game, where travelers adopt multi-attribute logit responses. We\nmodel the strategic information design as an optimization problem, and develop\na novel approximate algorithm to steer Logit Response travelers towards social\nwelfare using strategic Information design (in short, LoRI). We demonstrate the\nperformance of LoRI on a Wheatstone network with multi-modal route choices at\nthe travelers. In our simulation experiments, we find that LoRI outperforms\nSSSP in terms of system utility, especially when there is a motive mismatch\nbetween the two systems and improves social welfare. For instance, we find that\nLoRI persuades a traveler towards a socially optimal route for 66.66% of the\ntime on average, when compared to SSSP, when the system has 0.3 weight on\ncarbon emissions. However, we also present a tradeoff between system\nperformance and runtime in our simulation results.",
    "descriptor": "",
    "authors": [
      "Sainath Sanga",
      "Venkata Sriram Siddhardh Nadendla",
      "Sajal K. Das"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.15069"
  },
  {
    "id": "arXiv:2111.15070",
    "title": "Core but not peripheral online social ties is a protective factor  against depression: evidence from a nationally representative sample of young  adults",
    "abstract": "As social interactions are increasingly taking place in the digital\nenvironment, online friendship and its effects on various life outcomes from\nhealth to happiness attract growing research attention. In most studies, online\nties are treated as representing a single type of relationship. However, our\nonline friendship networks are not homogeneous and could include close\nconnections, e.g. a partner, as well as people we have never met in person. In\nthis paper, we investigate the potentially differential effects of online\nfriendship ties on mental health. Using data from a Russian panel study (N =\n4,400), we find that - consistently with previous research - the number of\nonline friends correlates with depression symptoms. However, this is true only\nfor networks that do not exceed Dunbar's number in size (N <= 150) and only for\ncore but not peripheral nodes of a friendship network. The findings suggest\nthat online friendship could encode different types of social relationships\nthat should be treated separately while investigating the association between\nonline social integration and life outcomes, in particular well-being or mental\nhealth.",
    "descriptor": "",
    "authors": [
      "Sofia Dokuka",
      "Elizaveta Sivak",
      "Ivan Smirnov"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.15070"
  },
  {
    "id": "arXiv:2111.15071",
    "title": "Communication-Efficient Federated Learning via Quantized Compressed  Sensing",
    "abstract": "In this paper, we present a communication-efficient federated learning\nframework inspired by quantized compressed sensing. The presented framework\nconsists of gradient compression for wireless devices and gradient\nreconstruction for a parameter server (PS). Our strategy for gradient\ncompression is to sequentially perform block sparsification, dimensional\nreduction, and quantization. Thanks to gradient sparsification and\nquantization, our strategy can achieve a higher compression ratio than one-bit\ngradient compression. For accurate aggregation of the local gradients from the\ncompressed signals at the PS, we put forth an approximate minimum mean square\nerror (MMSE) approach for gradient reconstruction using the\nexpectation-maximization generalized-approximate-message-passing (EM-GAMP)\nalgorithm. Assuming Bernoulli Gaussian-mixture prior, this algorithm\niteratively updates the posterior mean and variance of local gradients from the\ncompressed signals. We also present a low-complexity approach for the gradient\nreconstruction. In this approach, we use the Bussgang theorem to aggregate\nlocal gradients from the compressed signals, then compute an approximate MMSE\nestimate of the aggregated gradient using the EM-GAMP algorithm. We also\nprovide a convergence rate analysis of the presented framework. Using the MNIST\ndataset, we demonstrate that the presented framework achieves almost identical\nperformance with the case that performs no compression, while significantly\nreducing communication overhead for federated learning.",
    "descriptor": "",
    "authors": [
      "Yongjeong Oh",
      "Namyoon Lee",
      "Yo-Seb Jeon",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.15071"
  },
  {
    "id": "arXiv:2111.15072",
    "title": "Transition Motion Tensor: A Data-Driven Approach for Versatile and  Controllable Agents in Physically Simulated Environments",
    "abstract": "This paper proposes the Transition Motion Tensor, a data-driven framework\nthat creates novel and physically accurate transitions outside of the motion\ndataset. It enables simulated characters to adopt new motion skills efficiently\nand robustly without modifying existing ones. Given several physically\nsimulated controllers specializing in different motions, the tensor serves as a\ntemporal guideline to transition between them. Through querying the tensor for\ntransitions that best fit user-defined preferences, we can create a unified\ncontroller capable of producing novel transitions and solving complex tasks\nthat may require multiple motions to work coherently. We apply our framework on\nboth quadrupeds and bipeds, perform quantitative and qualitative evaluations on\ntransition quality, and demonstrate its capability of tackling complex motion\nplanning problems while following user control directives.",
    "descriptor": "\nComments: 4 pages, 6 figures\n",
    "authors": [
      "Jonathan Hans Soeseno",
      "Ying-Sheng Luo",
      "Trista Pei-Chun Chen",
      "Wei-Chao Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15072"
  },
  {
    "id": "arXiv:2111.15077",
    "title": "Unsupervised Domain Generalization for Person Re-identification: A  Domain-specific Adaptive Framework",
    "abstract": "Domain generalization (DG) has attracted much attention in person\nre-identification (ReID) recently. It aims to make a model trained on multiple\nsource domains generalize to an unseen target domain. Although achieving\npromising progress, existing methods usually need the source domains to be\nlabeled, which could be a significant burden for practical ReID tasks. In this\npaper, we turn to investigate unsupervised domain generalization for ReID, by\nassuming that no label is available for any source domains.\nTo address this challenging setting, we propose a simple and efficient\ndomain-specific adaptive framework, and realize it with an adaptive\nnormalization module designed upon the batch and instance normalization\ntechniques. In doing so, we successfully yield reliable pseudo-labels to\nimplement training and also enhance the domain generalization capability of the\nmodel as required. In addition, we show that our framework can even be applied\nto improve person ReID under the settings of supervised domain generalization\nand unsupervised domain adaptation, demonstrating competitive performance with\nrespect to relevant methods. Extensive experimental study on benchmark datasets\nis conducted to validate the proposed framework. A significance of our work\nlies in that it shows the potential of unsupervised domain generalization for\nperson ReID and sets a strong baseline for the further research on this topic.",
    "descriptor": "",
    "authors": [
      "Lei Qi",
      "Lei Wang",
      "Yinghuan Shi",
      "Xin Geng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15077"
  },
  {
    "id": "arXiv:2111.15078",
    "title": "SketchEdit: Mask-Free Local Image Manipulation with Partial Sketches",
    "abstract": "Sketch-based image manipulation is an interactive image editing task to\nmodify an image based on input sketches from users. Existing methods typically\nformulate this task as a conditional inpainting problem, which requires users\nto draw an extra mask indicating the region to modify in addition to sketches.\nThe masked regions are regarded as holes and filled by an inpainting model\nconditioned on the sketch. With this formulation, paired training data can be\neasily obtained by randomly creating masks and extracting edges or contours.\nAlthough this setup simplifies data preparation and model design, it\ncomplicates user interaction and discards useful information in masked regions.\nTo this end, we investigate a new paradigm of sketch-based image manipulation:\nmask-free local image manipulation, which only requires sketch inputs from\nusers and utilizes the entire original image. Given an image and sketch, our\nmodel automatically predicts the target modification region and encodes it into\na structure agnostic style vector. A generator then synthesizes the new image\ncontent based on the style vector and sketch. The manipulated image is finally\nproduced by blending the generator output into the modification region of the\noriginal image. Our model can be trained in a self-supervised fashion by\nlearning the reconstruction of an image region from the style vector and\nsketch. The proposed method offers simpler and more intuitive user workflows\nfor sketch-based image manipulation and provides better results than previous\napproaches. More results, code and interactive demo will be available at\n\\url{https://zengxianyu.github.io/sketchedit}.",
    "descriptor": "",
    "authors": [
      "Yu Zeng",
      "Zhe Lin",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2111.15078"
  },
  {
    "id": "arXiv:2111.15083",
    "title": "Metal Blossom: Laser Forming Complex and Freeform Metal Structures  Imitating Flower Blooming",
    "abstract": "For centuries, human civilizations devised metal forming techniques to make\ntools and items; yet, customized metal forming remains costly and intricate.\nLaser-forming origami} (lasergami) is a metal forming process where a laser\nbeam cuts and folds a planar metal sheet to form a three-dimensional (3D)\nshape. Designing foldable structures formable by lasers, however, has long been\na trial-and-error practice that requires significant mental effort and hinders\nthe possibility of creating practical structures. This work demonstrates for\nthe first time that lasergami can form a freeform set of metallic structures\npreviously believed to have been impossible to be laser-formed. This\ntechnological breakthrough is enabled by new computational origami methods that\nimitate flower blooming and optimize laser folding instructions. Combined with\nnew ideas that address laser line of sight and minimize fabrication energy, we\nreport a low-cost manufacturing framework that can be readily adopted by\nhobbyists and professionals alike.",
    "descriptor": "",
    "authors": [
      "Yue Hao",
      "Peiwen J. Ma",
      "Huaishu Peng",
      "Edwin A. Peraza Hernandez",
      "Jyh-Ming Lien"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.15083"
  },
  {
    "id": "arXiv:2111.15087",
    "title": "MAMRL: Exploiting Multi-agent Meta Reinforcement Learning in WAN Traffic  Engineering",
    "abstract": "Traffic optimization challenges, such as load balancing, flow scheduling, and\nimproving packet delivery time, are difficult online decision-making problems\nin wide area networks (WAN). Complex heuristics are needed for instance to find\noptimal paths that improve packet delivery time and minimize interruptions\nwhich may be caused by link failures or congestion. The recent success of\nreinforcement learning (RL) algorithms can provide useful solutions to build\nbetter robust systems that learn from experience in model-free settings.\nIn this work, we consider a path optimization problem, specifically for\npacket routing, in large complex networks. We develop and evaluate a model-free\napproach, applying multi-agent meta reinforcement learning (MAMRL) that can\ndetermine the next-hop of each packet to get it delivered to its destination\nwith minimum time overall. Specifically, we propose to leverage and compare\ndeep policy optimization RL algorithms for enabling distributed model-free\ncontrol in communication networks and present a novel meta-learning-based\nframework, MAMRL, for enabling quick adaptation to topology changes. To\nevaluate the proposed framework, we simulate with various WAN topologies. Our\nextensive packet-level simulation results show that compared to classical\nshortest path and traditional reinforcement learning approaches, MAMRL\nsignificantly reduces the average packet delivery time even when network demand\nincreases; and compared to a non-meta deep policy optimization algorithm, our\nresults show the reduction of packet loss in much fewer episodes when link\nfailures occur while offering comparable average packet delivery time.",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "Shan Sun",
      "Mariam Kiran",
      "Wei Ren"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.15087"
  },
  {
    "id": "arXiv:2111.15088",
    "title": "A novel multigrid method for elliptic distributed control problems",
    "abstract": "Large linear systems of saddle-point type have arisen in a wide variety of\napplications throughout computational science and engineering. The\ndiscretizations of distributed control problems have a saddle-point structure.\nThe numerical solution of saddle-point problems has attracted considerable\ninterest in recent years. In this work, we propose a novel Braess-Sarazin\nmultigrid relaxation scheme for finite element discretizations of the\ndistributed control problems, where we use the stiffness matrix obtained from\nthe five-point finite difference method for the Laplacian to approximate the\ninverse of the mass matrix arising in the saddle-point system. We apply local\nFourier analysis to examine the smoothing properties of the Braess-Sarazin\nmultigrid relaxation. From our analysis, the optimal smoothing factor for\nBraess-Sarazin relaxation is derived. Numerical experiments validate our\ntheoretical results. The relaxation scheme considered here shows its high\nefficiency and robustness with respect to the regularization parameter and grid\nsize.",
    "descriptor": "\nComments: 14 pages, 6 tables\n",
    "authors": [
      "Yunhui He"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.15088"
  },
  {
    "id": "arXiv:2111.15090",
    "title": "The Geometric Occam's Razor Implicit in Deep Learning",
    "abstract": "In over-parameterized deep neural networks there can be many possible\nparameter configurations that fit the training data exactly. However, the\nproperties of these interpolating solutions are poorly understood. We argue\nthat over-parameterized neural networks trained with stochastic gradient\ndescent are subject to a Geometric Occam's Razor; that is, these networks are\nimplicitly regularized by the geometric model complexity. For one-dimensional\nregression, the geometric model complexity is simply given by the arc length of\nthe function. For higher-dimensional settings, the geometric model complexity\ndepends on the Dirichlet energy of the function. We explore the relationship\nbetween this Geometric Occam's Razor, the Dirichlet energy and other known\nforms of implicit regularization. Finally, for ResNets trained on CIFAR-10, we\nobserve that Dirichlet energy measurements are consistent with the action of\nthis implicit Geometric Occam's Razor.",
    "descriptor": "\nComments: Accepted as a NeurIPS 2021 workshop paper (OPT2021)\n",
    "authors": [
      "Benoit Dherin",
      "Micheal Munn",
      "David G.T. Barrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.15090"
  },
  {
    "id": "arXiv:2111.15093",
    "title": "Learning to Predict Persona Information forDialogue Personalization  without Explicit Persona Description",
    "abstract": "Personalizing dialogue agents is important for dialogue systems to generate\nmore specific, consistent, and engaging responses. However, most current\ndialogue personalization approaches rely on explicit persona descriptions\nduring inference, which severely restricts its application. In this paper, we\npropose a novel approach that learns to predict persona information based on\nthe dialogue history to personalize the dialogue agent without relying on any\nexplicit persona descriptions during inference. Experimental results on the\nPersonaChat dataset show that the proposed method can improve the consistency\nof generated responses when conditioning on the predicted profile of the\ndialogue agent (i.e. \"self persona\"), and improve the engagingness of the\ngenerated responses when conditioning on the predicted persona of the dialogue\npartner (i.e. \"their persona\"). We also find that a trained persona prediction\nmodel can be successfully transferred to other datasets and help generate more\nrelevant responses.",
    "descriptor": "",
    "authors": [
      "Wangchunshu Zhou",
      "Qifei Li",
      "Chenle Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15093"
  },
  {
    "id": "arXiv:2111.15097",
    "title": "EAGAN: Efficient Two-stage Evolutionary Architecture Search for GANs",
    "abstract": "Generative Adversarial Networks (GANs) have been proven hugely successful in\nimage generation tasks, but GAN training has the problem of instability. Many\nworks have improved the stability of GAN training by manually modifying the GAN\narchitecture, which requires human expertise and extensive trial-and-error.\nThus, neural architecture search (NAS), which aims to automate the model\ndesign, has been applied to search GANs on the task of unconditional image\ngeneration. The early NAS-GAN works only search generators for reducing the\ndifficulty. Some recent works have attempted to search both generator (G) and\ndiscriminator (D) to improve GAN performance, but they still suffer from the\ninstability of GAN training during the search. To alleviate the instability\nissue, we propose an efficient two-stage evolutionary algorithm (EA) based NAS\nframework to discover GANs, dubbed \\textbf{EAGAN}. Specifically, we decouple\nthe search of G and D into two stages and propose the weight-resetting strategy\nto improve the stability of GAN training. Besides, we perform evolution\noperations to produce the Pareto-front architectures based on multiple\nobjectives, resulting in a superior combination of G and D. By leveraging the\nweight-sharing strategy and low-fidelity evaluation, EAGAN can significantly\nshorten the search time. EAGAN achieves highly competitive results on the\nCIFAR-10 (IS=8.81$\\pm$0.10, FID=9.91) and surpasses previous NAS-searched GANs\non the STL-10 dataset (IS=10.44$\\pm$0.087, FID=22.18).",
    "descriptor": "",
    "authors": [
      "Guohao Ying",
      "Xin He",
      "Bin Gao",
      "Bo Han",
      "Xiaowen Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.15097"
  },
  {
    "id": "arXiv:2111.15098",
    "title": "Technical Report: Edge-centric Programming for IoT Applications with  EdgeProg",
    "abstract": "IoT application development usually involves separate programming at the\ndevice side and server side. While separate programming style is sufficient for\nmany simple applications, it is not suitable for many complex applications that\ninvolve complex interactions and intensive data processing. We propose\nEdgeProg, an edge-centric programming approach to simplify IoT application\nprogramming, motivated by the increasing popularity of edge computing. With\nEdgeProg, users could write application logic in a centralized manner with an\naugmented If-This-Then-That (IFTTT) syntax and virtual sensor mechanism. The\nprogram can be processed at the edge server, which can automatically generate\nthe actual application code and intelligently partition the code into device\ncode and server code, for achieving the optimal latency. EdgeProg employs\ndynamic linking and loading to deploy the device code on a variety of IoT\ndevices, which do not run any application-specific codes at the start. Results\nshow that EdgeProg achieves an average reduction of 20.96%, 27.8% and 79.41% in\nterms of execution latency, energy consumption, and lines of code compared with\nstate-of-the-art approaches.",
    "descriptor": "\nComments: 16 pages, 21 figures. Conference version is accepted by IEEE ICDCS 2020, and journal version is accepted by IEEE Transactions on Computers\n",
    "authors": [
      "Borui Li",
      "Wei Dong"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.15098"
  },
  {
    "id": "arXiv:2111.15099",
    "title": "Trust the Critics: Generatorless and Multipurpose WGANs with Initial  Convergence Guarantees",
    "abstract": "Inspired by ideas from optimal transport theory we present Trust the Critics\n(TTC), a new algorithm for generative modelling. This algorithm eliminates the\ntrainable generator from a Wasserstein GAN; instead, it iteratively modifies\nthe source data using gradient descent on a sequence of trained critic\nnetworks. This is motivated in part by the misalignment which we observed\nbetween the optimal transport directions provided by the gradients of the\ncritic and the directions in which data points actually move when parametrized\nby a trainable generator. Previous work has arrived at similar ideas from\ndifferent viewpoints, but our basis in optimal transport theory motivates the\nchoice of an adaptive step size which greatly accelerates convergence compared\nto a constant step size. Using this step size rule, we prove an initial\ngeometric convergence rate in the case of source distributions with densities.\nThese convergence rates cease to apply only when a non-negligible set of\ngenerated data is essentially indistinguishable from real data. Resolving the\nmisalignment issue improves performance, which we demonstrate in experiments\nthat show that given a fixed number of training epochs, TTC produces higher\nquality images than a comparable WGAN, albeit at increased memory requirements.\nIn addition, TTC provides an iterative formula for the transformed density,\nwhich traditional WGANs do not. Finally, TTC can be applied to map any source\ndistribution onto any target; we demonstrate through experiments that TTC can\nobtain competitive performance in image generation, translation, and denoising\nwithout dedicated algorithms.",
    "descriptor": "\nComments: 20 pages, 8 figures\n",
    "authors": [
      "Tristan Milne",
      "\u00c9tienne Bilocq",
      "Adrian Nachman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.15099"
  },
  {
    "id": "arXiv:2111.15101",
    "title": "A novel data-driven algorithm to predict anomalous prescription based on  patient's feature set",
    "abstract": "Appropriate dosing of radiation is crucial to patient safety in radiotherapy.\nCurrent quality assurance depends heavily on a peer-review process, where the\nphysicians' peer review on each patient's treatment plan, including dose and\nfractionation. However, such a process is manual and laborious. Physicians may\nnot identify errors due to time constraints and caseload. We designed a novel\nprescription anomaly detection algorithm that utilizes historical data to\npredict anomalous cases. Such a tool can serve as an electronic peer who will\nassist the peer-review process providing extra safety to the patients. In our\nprimary model, we created two dissimilarity metrics, R and F. R defining how\nfar a new patient's prescription is from historical prescriptions. F represents\nhow far away a patient's feature set is from the group with an identical or\nsimilar prescription. We flag prescription if either metric is greater than\nspecific optimized cut-off values. We used thoracic cancer patients (n=2356) as\nan example and extracted seven features. Here, we report our testing f1 score,\nbetween 75%-94% for different treatment technique groups. We also independently\nvalidate our results by conducting a mock peer review with three thoracic\nspecialists. Our model has a lower type 2 error rate compared to manual\npeer-review physicians. Our model has many advantages over traditional machine\nlearning algorithms, particularly in that it does not suffer from class\nimbalance. It can also explain why it flags each case and separate prescription\nand non-prescription-related features without learning from the data.",
    "descriptor": "",
    "authors": [
      "Qiongge Li",
      "Jean Wright",
      "Russell Hales",
      "Ranh Voong",
      "Todd McNutt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.15101"
  },
  {
    "id": "arXiv:2111.15106",
    "title": "MAPLE: Microprocessor A Priori for Latency Estimation",
    "abstract": "Modern deep neural networks must demonstrate state-of-the-art accuracy while\nexhibiting low latency and energy consumption. As such, neural architecture\nsearch (NAS) algorithms take these two constraints into account when generating\na new architecture. However, efficiency metrics such as latency are typically\nhardware dependent requiring the NAS algorithm to either measure or predict the\narchitecture latency. Measuring the latency of every evaluated architecture\nadds a significant amount of time to the NAS process. Here we propose\nMicroprocessor A Priori for Latency Estimation MAPLE that does not rely on\ntransfer learning or domain adaptation but instead generalizes to new hardware\nby incorporating a prior hardware characteristics during training. MAPLE takes\nadvantage of a novel quantitative strategy to characterize the underlying\nmicroprocessor by measuring relevant hardware performance metrics, yielding a\nfine-grained and expressive hardware descriptor. Moreover, the proposed MAPLE\nbenefits from the tightly coupled I/O between the CPU and GPU and their\ndependency to predict DNN latency on GPUs while measuring microprocessor\nperformance hardware counters from the CPU feeding the GPU hardware. Through\nthis quantitative strategy as the hardware descriptor, MAPLE can generalize to\nnew hardware via a few shot adaptation strategy where with as few as 3 samples\nit exhibits a 3% improvement over state-of-the-art methods requiring as much as\n10 samples. Experimental results showed that, increasing the few shot\nadaptation samples to 10 improves the accuracy significantly over the\nstate-of-the-art methods by 12%. Furthermore, it was demonstrated that MAPLE\nexhibiting 8-10% better accuracy, on average, compared to relevant baselines at\nany number of adaptation samples.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Saad Abbasi",
      "Alexander Wong",
      "Mohammad Javad Shafiee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15106"
  },
  {
    "id": "arXiv:2111.15108",
    "title": "Interval-valued q-Rung Orthopair Fuzzy Choquet Integral Operators and  Its Application in Group Decision Making",
    "abstract": "It is more flexible for decision makers to evaluate by interval-valued q-rung\northopair fuzzy set (IVq-ROFS),which offers fuzzy decision-making more\napplicational space. Meanwhile, Choquet integralses non-additive set function\n(fuzzy measure) to describe the interaction between attributes directly.In\nparticular, there are a large number of practical issues that have relevance\nbetween attributes.Therefore,this paper proposes the correlation operator and\ngroup decision-making method based on the interval-valued q-rung orthopair\nfuzzy set Choquet integral.First,interval-valued q-rung orthopair fuzzy Choquet\nintegral average operator (IVq-ROFCA) and interval-valued q-rung orthopair\nfuzzy Choquet integral geometric operator (IVq-ROFCG) are inves-tigated,and\ntheir basic properties are proved.Furthermore, several operators based on\nIVq-ROFCA and IVq-ROFCG are developed. Then, a group decision-making method\nbased on IVq-ROFCA is developed,which can solve the decision making problems\nwith interaction between attributes.Finally,through the implementation of the\nwarning management system for hypertension,it is shown that the operator and\ngroup decision-making method proposed in this paper can handle complex\ndecision-making cases in reality, and the decision result is consistent with\nthe doctor's diagnosis result.Moreover,the comparison with the results of other\noperators shows that the proposed operators and group decision-making method\nare correct and effective,and the decision result will not be affected by the\nchange of q value.",
    "descriptor": "",
    "authors": [
      "Benting Wan",
      "Juelin Huang",
      "Xi Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15108"
  },
  {
    "id": "arXiv:2111.15110",
    "title": "Reconfigurable Intelligent Surface Optimization for Uplink Sparse Code  Multiple Access",
    "abstract": "The reconfigurable intelligent surface (RIS)-assisted sparse code multiple\naccess (RIS-SCMA) is an attractive scheme for future wireless networks. In this\nletter, for the first time, the RIS phase shifts of the uplink RIS-SCMA system\nare optimized based on the alternate optimization (AO) technique to improve the\nreceived signal-to-noise ratio (SNR) for a discrete set of RIS phase shifts.\nThe system model of the uplink RIS-SCMA is formulated to utilize the AO\nalgorithm. For further reduction in the computational complexity, a\nlow-complexity AO (LC-AO) algorithm is proposed. The complexity analysis of the\ntwo proposed algorithms is performed. Monte Carlo simulations and complexity\nanalysis show that the proposed algorithms significantly improve the received\nSNR compared to the non-optimized RIS-SCMA scenario. The LC-AO provides the\nsame received SNR as the AO algorithm, with a significant reduction in\ncomplexity. Moreover, the deployment of RISs for the uplink RIS-SCMA is\ninvestigated.",
    "descriptor": "\nComments: 6 pages, 5 figures, published in IEEE Communications Letters\n",
    "authors": [
      "Ibrahim Al-Nahhal",
      "Octavia A. Dobre",
      "Ertugrul Basar",
      "Telex M. N. Ngatched",
      "Salama Ikki"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.15110"
  },
  {
    "id": "arXiv:2111.15111",
    "title": "Automatic tracing of mandibular canal pathways using deep learning",
    "abstract": "There is an increasing demand in medical industries to have automated systems\nfor detection and localization which are manually inefficient otherwise. In\ndentistry, it bears great interest to trace the pathway of mandibular canals\naccurately. Proper localization of the position of the mandibular canals, which\nsurrounds the inferior alveolar nerve (IAN), reduces the risk of damaging it\nduring dental implantology. Manual detection of canal paths is not an efficient\nway in terms of time and labor. Here, we propose a deep learning-based\nframework to detect mandibular canals from CBCT data. It is a 3-stage process\nfully automatic end-to-end. Ground truths are generated in the preprocessing\nstage. Instead of using commonly used fixed diameter tubular-shaped ground\ntruth, we generate centerlines of the mandibular canals and used them as ground\ntruths in the training process. A 3D U-Net architecture is used for model\ntraining. An efficient post-processing stage is developed to rectify the\ninitial prediction. The precision, recall, F1-score, and IoU are measured to\nanalyze the voxel-level segmentation performance. However, to analyze the\ndistance-based measurements, mean curve distance (MCD) both from ground truth\nto prediction and prediction to ground truth is calculated. Extensive\nexperiments are conducted to demonstrate the effectiveness of the model.",
    "descriptor": "",
    "authors": [
      "Mrinal Kanti Dhar",
      "Zeyun Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15111"
  },
  {
    "id": "arXiv:2111.15112",
    "title": "AugLiChem: Data Augmentation Library ofChemical Structures for Machine  Learning",
    "abstract": "Machine learning (ML) has demonstrated the promise for accurate andefficient\nproperty prediction of molecules and crystalline materials. Todevelop highly\naccurate ML models for chemical structure property pre-diction, datasets with\nsufficient samples are required. However, obtainingclean and sufficient data of\nchemical properties can be expensive andtime-consuming, which greatly limits\nthe performance of ML models.Inspired by the success of data augmentations in\ncomputer vision andnatural language processing, we developed AugLiChem: the\ndata aug-mentation library for chemical structures. Augmentation methods\nforboth crystalline systems and molecules are introduced, which can beutilized\nfor fingerprint-based ML models and Graph Neural Networks(GNNs). We show that\nusing our augmentation strategies significantlyimproves the performance of ML\nmodels, especially when using GNNs.In addition, the augmentations that we\ndeveloped can be used as adirect plug-in module during training and have\ndemonstrated the effec-tiveness when implemented with different GNN models\nthrough theAugliChem library. The Python-based package for our implementa-tion\nof Auglichem: Data augmentation library for chemical structures,is publicly\navailable at: https://github.com/BaratiLab/AugLiChem.1",
    "descriptor": "\nComments: Preprint under review 4 figures, 3 tables\n",
    "authors": [
      "Rishikesh Magar",
      "Yuyang Wang",
      "Cooper Lorsung",
      "Chen Liang",
      "Hariharan Ramasubramanian",
      "Peiyuan Li",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.15112"
  },
  {
    "id": "arXiv:2111.15113",
    "title": "LatentHuman: Shape-and-Pose Disentangled Latent Representation for Human  Bodies",
    "abstract": "3D representation and reconstruction of human bodies have been studied for a\nlong time in computer vision. Traditional methods rely mostly on parametric\nstatistical linear models, limiting the space of possible bodies to linear\ncombinations. It is only recently that some approaches try to leverage neural\nimplicit representations for human body modeling, and while demonstrating\nimpressive results, they are either limited by representation capability or not\nphysically meaningful and controllable. In this work, we propose a novel neural\nimplicit representation for the human body, which is fully differentiable and\noptimizable with disentangled shape and pose latent spaces. Contrary to prior\nwork, our representation is designed based on the kinematic model, which makes\nthe representation controllable for tasks like pose animation, while\nsimultaneously allowing the optimization of shape and pose for tasks like 3D\nfitting and pose tracking. Our model can be trained and fine-tuned directly on\nnon-watertight raw data with well-designed losses. Experiments demonstrate the\nimproved 3D reconstruction performance over SoTA approaches and show the\napplicability of our method to shape interpolation, model fitting, pose\ntracking, and motion retargeting.",
    "descriptor": "\nComments: Accepted to 3DV 2021. Project Page: this https URL\n",
    "authors": [
      "Sandro Lombardi",
      "Bangbang Yang",
      "Tianxing Fan",
      "Hujun Bao",
      "Guofeng Zhang",
      "Marc Pollefeys",
      "Zhaopeng Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15113"
  },
  {
    "id": "arXiv:2111.15114",
    "title": "ePose: Let's Make EfficientPose More Generally Applicable",
    "abstract": "EfficientPose is an impressive 3D object detection model. It has been\ndemonstrated to be quick, scalable, and accurate, especially when considering\nthat it uses only RGB inputs. In this paper we try to improve on EfficientPose\nby giving it the ability to infer an object's size, and by simplifying both the\ndata collection and loss calculations. We evaluated ePose using the Linemod\ndataset and a new subset of it called \"Occlusion 1-class\". We also outline our\ncurrent progress and thoughts about using ePose with the NuScenes and the 2017\nKITTI 3D Object Detection datasets. The source code is available at\nhttps://github.com/tbd-clip/EfficientPose.",
    "descriptor": "\nComments: 7 pages, 8 figures\n",
    "authors": [
      "Austin Lally",
      "Robert Bain",
      "Mazen Alotaibi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15114"
  },
  {
    "id": "arXiv:2111.15119",
    "title": "Aerial Images Meet Crowdsourced Trajectories: A New Approach to Robust  Road Extraction",
    "abstract": "Land remote sensing analysis is a crucial research in earth science. In this\nwork, we focus on a challenging task of land analysis, i.e., automatic\nextraction of traffic roads from remote sensing data, which has widespread\napplications in urban development and expansion estimation. Nevertheless,\nconventional methods either only utilized the limited information of aerial\nimages, or simply fused multimodal information (e.g., vehicle trajectories),\nthus cannot well recognize unconstrained roads. To facilitate this problem, we\nintroduce a novel neural network framework termed Cross-Modal Message\nPropagation Network (CMMPNet), which fully benefits the complementary different\nmodal data (i.e., aerial images and crowdsourced trajectories). Specifically,\nCMMPNet is composed of two deep Auto-Encoders for modality-specific\nrepresentation learning and a tailor-designed Dual Enhancement Module for\ncross-modal representation refinement. In particular, the complementary\ninformation of each modality is comprehensively extracted and dynamically\npropagated to enhance the representation of another modality. Extensive\nexperiments on three real-world benchmarks demonstrate the effectiveness of our\nCMMPNet for robust road extraction benefiting from blending different modal\ndata, either using image and trajectory data or image and Lidar data. From the\nexperimental results, we observe that the proposed approach outperforms current\nstate-of-the-art methods by large margins.",
    "descriptor": "",
    "authors": [
      "Lingbo Liu",
      "Zewei Yang",
      "Guanbin Li",
      "Kuo Wang",
      "Tianshui Chen",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15119"
  },
  {
    "id": "arXiv:2111.15121",
    "title": "Pyramid Adversarial Training Improves ViT Performance",
    "abstract": "Aggressive data augmentation is a key component of the strong generalization\ncapabilities of Vision Transformer (ViT). One such data augmentation technique\nis adversarial training; however, many prior works have shown that this often\nresults in poor clean accuracy. In this work, we present Pyramid Adversarial\nTraining, a simple and effective technique to improve ViT's overall\nperformance. We pair it with a \"matched\" Dropout and stochastic depth\nregularization, which adopts the same Dropout and stochastic depth\nconfiguration for the clean and adversarial samples. Similar to the\nimprovements on CNNs by AdvProp (not directly applicable to ViT), our Pyramid\nAdversarial Training breaks the trade-off between in-distribution accuracy and\nout-of-distribution robustness for ViT and related architectures. It leads to\n$1.82\\%$ absolute improvement on ImageNet clean accuracy for the ViT-B model\nwhen trained only on ImageNet-1K data, while simultaneously boosting\nperformance on $7$ ImageNet robustness metrics, by absolute numbers ranging\nfrom $1.76\\%$ to $11.45\\%$. We set a new state-of-the-art for ImageNet-C (41.4\nmCE), ImageNet-R ($53.92\\%$), and ImageNet-Sketch ($41.04\\%$) without extra\ndata, using only the ViT-B/16 backbone and our Pyramid Adversarial Training.\nOur code will be publicly available upon acceptance.",
    "descriptor": "\nComments: 32 pages, including references & supplementary material\n",
    "authors": [
      "Charles Herrmann",
      "Kyle Sargent",
      "Lu Jiang",
      "Ramin Zabih",
      "Huiwen Chang",
      "Ce Liu",
      "Dilip Krishnan",
      "Deqing Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15121"
  },
  {
    "id": "arXiv:2111.15123",
    "title": "Outage and Finite-SNR DMT Analysis for IRS-aided MIMO Systems: How Large  IRSs Need to Be?",
    "abstract": "Intelligent reflecting surfaces (IRSs) are promising enablers for\nhigh-capacity wireless communication systems by constructing favorable channels\nbetween the transmitter and receiver. However, general, accurate, and tractable\noutage analysis for IRS-aided multiple-input-multiple-output (MIMO) systems is\nnot available in the literature. In this paper, we first characterize the\nmutual information (MI) of IRS-aided MIMO systems by capitalizing on large\nrandom matrix theory (RMT). Based on this result, a closed-form approximation\nfor the outage probability is derived and a gradient-based algorithm is\nproposed to minimize the outage probability with statistical channel state\ninformation (CSI). We also investigate the diversity-multiplexing tradeoff\n(DMT) with the finite signal-to-noise ratio (SNR). Based on these theoretical\nresults, we further study the impact of the IRS size on system performance. In\nthe high SNR regime, we provide closed-form expressions for the ergodic mutual\ninformation (EMI) and outage probability as a function of the IRS size, which\nanalytically reveal that the benefit of increasing the IRS size saturates\nquickly. Simulation results validate the accuracy of the theoretical analysis\nand confirm the increasing cost for deploying larger IRSs to improve system\nperformance. For example, for an IRS-aided MIMO system with 20 antennas at both\nthe transmitter and receiver, we need to double the size of the IRS to increase\nthe throughout from 90% to 95% of its maximum value.",
    "descriptor": "",
    "authors": [
      "Xin Zhang",
      "Xianghao Yu",
      "S.H. Song"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.15123"
  },
  {
    "id": "arXiv:2111.15124",
    "title": "In-Bed Human Pose Estimation from Unseen and Privacy-Preserving Image  Domains",
    "abstract": "Medical applications have benefited from the rapid advancement in computer\nvision. For patient monitoring in particular, in-bed human posture estimation\nprovides important health-related metrics with potential value in medical\ncondition assessments. Despite great progress in this domain, it remains a\nchallenging task due to substantial ambiguity during occlusions, and the lack\nof large corpora of manually labeled data for model training, particularly with\ndomains such as thermal infrared imaging which are privacy-preserving, and thus\nof great interest. Motivated by the effectiveness of self-supervised methods in\nlearning features directly from data, we propose a multi-modal conditional\nvariational autoencoder (MC-VAE) capable of reconstructing features from\nmissing modalities seen during training. This approach is used with HRNet to\nenable single modality inference for in-bed pose estimation. Through extensive\nevaluations, we demonstrate that body positions can be effectively recognized\nfrom the available modality, achieving on par results with baseline models that\nare highly dependent on having access to multiple modes at inference time. The\nproposed framework supports future research towards self-supervised learning\nthat generates a robust model from a single source, and expects it to\ngeneralize over many unknown distributions in clinical environments.",
    "descriptor": "",
    "authors": [
      "Ting Cao",
      "Mohammad Ali Armin",
      "Simon Denman",
      "Lars Petersson",
      "David Ahmedt-Aristizabal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15124"
  },
  {
    "id": "arXiv:2111.15127",
    "title": "A Unified Pruning Framework for Vision Transformers",
    "abstract": "Recently, vision transformer (ViT) and its variants have achieved promising\nperformances in various computer vision tasks. Yet the high computational costs\nand training data requirements of ViTs limit their application in\nresource-constrained settings. Model compression is an effective method to\nspeed up deep learning models, but the research of compressing ViTs has been\nless explored. Many previous works concentrate on reducing the number of\ntokens. However, this line of attack breaks down the spatial structure of ViTs\nand is hard to be generalized into downstream tasks. In this paper, we design a\nunified framework for structural pruning of both ViTs and its variants, namely\nUP-ViTs. Our method focuses on pruning all ViTs components while maintaining\nthe consistency of the model structure. Abundant experimental results show that\nour method can achieve high accuracy on compressed ViTs and variants, e.g.,\nUP-DeiT-T achieves 75.79% accuracy on ImageNet, which outperforms the vanilla\nDeiT-T by 3.59% with the same computational cost. UP-PVTv2-B0 improves the\naccuracy of PVTv2-B0 by 4.83% for ImageNet classification. Meanwhile, UP-ViTs\nmaintains the consistency of the token representation and gains consistent\nimprovements on object detection tasks.",
    "descriptor": "",
    "authors": [
      "Hao Yu",
      "Jianxin Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15127"
  },
  {
    "id": "arXiv:2111.15129",
    "title": "Anonymization for Skeleton Action Recognition",
    "abstract": "The skeleton-based action recognition attracts practitioners and researchers\ndue to the lightweight, compact nature of datasets. Compared with\nRGB-video-based action recognition, skeleton-based action recognition is a\nsafer way to protect the privacy of subjects while having competitive\nrecognition performance. However, due to the improvements of skeleton\nestimation algorithms as well as motion- and depth-sensors, more details of\nmotion characteristics can be preserved in the skeleton dataset, leading to a\npotential privacy leakage from the dataset. To investigate the potential\nprivacy leakage from the skeleton datasets, we first train a classifier to\ncategorize sensitive private information from a trajectory of joints.\nExperiments show the model trained to classify gender can predict with 88%\naccuracy and re-identify a person with 82% accuracy. We propose two variants of\nanonymization algorithms to protect the potential privacy leakage from the\nskeleton dataset. Experimental results show that the anonymized dataset can\nreduce the risk of privacy leakage while having marginal effects on the action\nrecognition performance.",
    "descriptor": "",
    "authors": [
      "Myeonghyeon Kim",
      "Zhenyue Qin",
      "Yang Liu",
      "Dongwoo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15129"
  },
  {
    "id": "arXiv:2111.15130",
    "title": "Thermal entropy based hesitant fuzzy linguistic term set analysis in  energy efficient opportunistic clustering",
    "abstract": "Limited energy resources and sensor nodes adaptability with the surrounding\nenvironment play a significant role in the sustainable Wireless Sensor\nNetworks. This paper proposes a novel, dynamic, self-organizing opportunistic\nclustering using Hesitant Fuzzy Linguistic Term Analysis-based Multi-Criteria\nDecision Modeling methodology in order to overcome the CH decision making\nproblems and network lifetime bottlenecks. The asynchronous sleep/awake cycle\nstrategy could be exploited to make an opportunistic connection between sensor\nnodes using opportunistic connection random graph. Every node in the network\nobserve the node gain degree, energy welfare, relative thermal entropy, link\nconnectivity, expected optimal hop, link quality factor etc. to form the\ncriteria for Hesitant Fuzzy Linguistic Term Set. It makes the node to evaluate\nits current state and make the decision about the required action (CH, CM or\nrelay). The simulation results reveal that our proposed scheme leads to an\nimprovement in network lifetime, packet delivery ratio and overall energy\nconsumption against existing benchmarks.",
    "descriptor": "\nComments: 10 pages, 5 figures, International Conference on Networks and Communications (NETWORKS 2021)\n",
    "authors": [
      "Junaid Anees",
      "Hao-Chun Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.15130"
  },
  {
    "id": "arXiv:2111.15133",
    "title": "LossPlot: A Better Way to Visualize Loss Landscapes",
    "abstract": "Investigations into the loss landscapes of deep neural networks are often\nlaborious. This work documents our user-driven approach to create a platform\nfor semi-automating this process. LossPlot accepts data in the form of a csv,\nand allows multiple trained minimizers of the loss function to be manipulated\nin sync. Other features include a simple yet intuitive checkbox UI, summary\nstatistics, and the ability to control clipping which other methods do not\noffer.",
    "descriptor": "\nComments: 5 pages; 2 large figures\n",
    "authors": [
      "Robert Bain",
      "Mikhail Tokarev",
      "Harsh Kothari",
      "Rahul Damineni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.15133"
  },
  {
    "id": "arXiv:2111.15135",
    "title": "Beyond Periodicity: Towards a Unifying Framework for Activations in  Coordinate-MLPs",
    "abstract": "Coordinate-MLPs are emerging as an effective tool for modeling\nmultidimensional continuous signals, overcoming many drawbacks associated with\ndiscrete grid-based approximations. However, coordinate-MLPs with ReLU\nactivations, in their rudimentary form, demonstrate poor performance in\nrepresenting signals with high fidelity, promoting the need for positional\nembedding layers. Recently, Sitzmann et al. proposed a sinusoidal activation\nfunction that has the capacity to omit positional embedding from\ncoordinate-MLPs while still preserving high signal fidelity. Despite its\npotential, ReLUs are still dominating the space of coordinate-MLPs; we\nspeculate that this is due to the hyper-sensitivity of networks -- that employ\nsuch sinusoidal activations -- to the initialization schemes. In this paper, we\nattempt to broaden the current understanding of the effect of activations in\ncoordinate-MLPs, and show that there exists a broader class of activations that\nare suitable for encoding signals. We affirm that sinusoidal activations are\nonly a single example in this class, and propose several non-periodic functions\nthat empirically demonstrate more robust performance against random\ninitializations than sinusoids. Finally, we advocate for a shift towards\ncoordinate-MLPs that employ these non-traditional activation functions due to\ntheir high performance and simplicity.",
    "descriptor": "",
    "authors": [
      "Sameera Ramasinghe",
      "Simon Lucey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15135"
  },
  {
    "id": "arXiv:2111.15139",
    "title": "Breaking the Linear Iteration Cost Barrier for Some Well-known  Conditional Gradient Methods Using MaxIP Data-structures",
    "abstract": "Conditional gradient methods (CGM) are widely used in modern machine\nlearning. CGM's overall running time usually consists of two parts: the number\nof iterations and the cost of each iteration. Most efforts focus on reducing\nthe number of iterations as a means to reduce the overall running time. In this\nwork, we focus on improving the per iteration cost of CGM. The bottleneck step\nin most CGM is maximum inner product search (MaxIP), which requires a linear\nscan over the parameters. In practice, approximate MaxIP data-structures are\nfound to be helpful heuristics. However, theoretically, nothing is known about\nthe combination of approximate MaxIP data-structures and CGM. In this work, we\nanswer this question positively by providing a formal framework to combine the\nlocality sensitive hashing type approximate MaxIP data-structures with CGM\nalgorithms. As a result, we show the first algorithm, where the cost per\niteration is sublinear in the number of parameters, for many fundamental\noptimization algorithms, e.g., Frank-Wolfe, Herding algorithm, and policy\ngradient.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Anshumali Shrivastava",
      "Zhao Song",
      "Zhaozhuo Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15139"
  },
  {
    "id": "arXiv:2111.15140",
    "title": "Robust 3D Garment Digitization from Monocular 2D Images for 3D Virtual  Try-On Systems",
    "abstract": "In this paper, we develop a robust 3D garment digitization solution that can\ngeneralize well on real-world fashion catalog images with cloth texture\nocclusions and large body pose variations. We assumed fixed topology parametric\ntemplate mesh models for known types of garments (e.g., T-shirts, Trousers) and\nperform mapping of high-quality texture from an input catalog image to UV map\npanels corresponding to the parametric mesh model of the garment. We achieve\nthis by first predicting a sparse set of 2D landmarks on the boundary of the\ngarments. Subsequently, we use these landmarks to perform\nThin-Plate-Spline-based texture transfer on UV map panels. Subsequently, we\nemploy a deep texture inpainting network to fill the large holes (due to view\nvariations & self-occlusions) in TPS output to generate consistent UV maps.\nFurthermore, to train the supervised deep networks for landmark prediction &\ntexture inpainting tasks, we generated a large set of synthetic data with\nvarying texture and lighting imaged from various views with the human present\nin a wide variety of poses. Additionally, we manually annotated a small set of\nfashion catalog images crawled from online fashion e-commerce platforms to\nfinetune. We conduct thorough empirical evaluations and show impressive\nqualitative results of our proposed 3D garment texture solution on fashion\ncatalog images. Such 3D garment digitization helps us solve the challenging\ntask of enabling 3D Virtual Try-on.",
    "descriptor": "",
    "authors": [
      "Sahib Majithia",
      "Sandeep N. Parameswaran",
      "Sadbhavana Babar",
      "Vikram Garg",
      "Astitva Srivastava",
      "Avinash Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15140"
  },
  {
    "id": "arXiv:2111.15141",
    "title": "Path Integral Sampler: a stochastic control approach for sampling",
    "abstract": "We present Path Integral Sampler~(PIS), a novel algorithm to draw samples\nfrom unnormalized probability density functions. The PIS is built on the\nSchr\\\"odinger bridge problem which aims to recover the most likely evolution of\na diffusion process given its initial distribution and terminal distribution.\nThe PIS draws samples from the initial distribution and then propagates the\nsamples through the Schr\\\"odinger bridge to reach the terminal distribution.\nApplying the Girsanov theorem, with a simple prior diffusion, we formulate the\nPIS as a stochastic optimal control problem whose running cost is the control\nenergy and terminal cost is chosen according to the target distribution. By\nmodeling the control as a neural network, we establish a sampling algorithm\nthat can be trained end-to-end. We provide theoretical justification of the\nsampling quality of PIS in terms of Wasserstein distance when sub-optimal\ncontrol is used. Moreover, the path integrals theory is used to compute\nimportance weights of the samples to compensate for the bias induced by the\nsub-optimality of the controller and time-discretization. We experimentally\ndemonstrate the advantages of PIS compared with other start-of-the-art sampling\nmethods on a variety of tasks.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Qinsheng Zhang",
      "Yongxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15141"
  },
  {
    "id": "arXiv:2111.15143",
    "title": "HEAT: Holistic Edge Attention Transformer for Structured Reconstruction",
    "abstract": "This paper presents a novel attention-based neural network for structured\nreconstruction, which takes a 2D raster image as an input and reconstructs a\nplanar graph depicting an underlying geometric structure. The approach detects\ncorners and classifies edge candidates between corners in an end-to-end manner.\nOur contribution is a holistic edge classification architecture, which 1)\ninitializes the feature of an edge candidate by a trigonometric positional\nencoding of its end-points; 2) fuses image feature to each edge candidate by\ndeformable attention; 3) employs two weight-sharing Transformer decoders to\nlearn holistic structural patterns over the graph edge candidates; and 4) is\ntrained with a masked learning strategy. The corner detector is a variant of\nthe edge classification architecture, adapted to operate on pixels as corner\ncandidates. We conduct experiments on two structured reconstruction tasks:\noutdoor building architecture and indoor floorplan planar graph reconstruction.\nExtensive qualitative and quantitative evaluations demonstrate the superiority\nof our approach over the state of the art. We will share code and models.",
    "descriptor": "",
    "authors": [
      "Jiacheng Chen",
      "Yiming Qian",
      "Yasutaka Furukawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15143"
  },
  {
    "id": "arXiv:2111.15146",
    "title": "Molecular Attributes Transfer from Non-Parallel Data",
    "abstract": "Optimizing chemical molecules for desired properties lies at the core of drug\ndevelopment. Despite initial successes made by deep generative models and\nreinforcement learning methods, these methods were mostly limited by the\nrequirement of predefined attribute functions or parallel data with manually\npre-compiled pairs of original and optimized molecules. In this paper, for the\nfirst time, we formulate molecular optimization as a style transfer problem and\npresent a novel generative model that could automatically learn internal\ndifferences between two groups of non-parallel data through adversarial\ntraining strategies. Our model further enables both preservation of molecular\ncontents and optimization of molecular properties through combining auxiliary\nguided-variational autoencoders and generative flow techniques. Experiments on\ntwo molecular optimization tasks, toxicity modification and synthesizability\nimprovement, demonstrate that our model significantly outperforms several\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Shuangjia Zheng",
      "Ying Song",
      "Zhang Pan",
      "Chengtao Li",
      "Le Song",
      "Yuedong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15146"
  },
  {
    "id": "arXiv:2111.15147",
    "title": "State-of-Charge Aware EV Charging",
    "abstract": "Recent proliferation in electric vehicles (EVs) are posing profound impacts\nover the operation of electrical grids. In particular, due to the physical\nconstraints on charging stations' capacity and uncertainty in charging demand,\nit becomes an emerging challenge to design high performance scheduling\nalgorithms to better serve charging sessions. In this paper, we design a\npredictive charging controller by actively incorporating each EV's\nstate-of-charge (SOC) information, which has strong effects on the utilization\nof dispatchable power during peak hours. Simulation results on both synthetic\nand real-world EV session and charging demand data demonstrate the proposed\nalgorithm's benefits on maximizing charging throughput and achieving higher\nrate of feasible charging sessions while satisfying battery and station\nphysical constraints at the same time.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Yize Chen",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.15147"
  },
  {
    "id": "arXiv:2111.15149",
    "title": "SteelCore: An Extensible Concurrent Separation Logic for Effectful  Dependently Typed Programs",
    "abstract": "Much recent research has been devoted to modeling effects within type theory.\nBuilding on this work, we observe that effectful type theories can provide a\nfoundation on which to build semantics for more complex programming constructs\nand program logics, extending the reasoning principles that apply within the\nhost effectful type theory itself. Concretely, our main contribution is a\nsemantics for concurrent separation logic (CSL) within the F* proof assistant\nin a manner that enables dependently typed, effectful F* programs to make use\nof concurrency and to be specified and verified using a full-featured,\nextensible CSL. In contrast to prior approaches, we directly derive the\npartial-correctness Hoare rules for CSL from the denotation of computations in\nthe effectful semantics of non-deterministically interleaved atomic actions.\nDemonstrating the flexibility of our semantics, we build generic, verified\nlibraries that support various concurrency constructs, ranging from dynamically\nallocated, storable spin locks, to protocol-indexed channels. We conclude that\nour effectful semantics provides a simple yet expressive basis on which to\nlayer domain-specific languages and logics for verified, concurrent\nprogramming.",
    "descriptor": "\nComments: ICFP 2020 camera-ready version\n",
    "authors": [
      "Nikhil Swamy",
      "Aseem Rastogi",
      "Aymeric Fromherz",
      "Denis Merigoux",
      "Danel Ahman",
      "Guido Mart\u00ednez"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.15149"
  },
  {
    "id": "arXiv:2111.15150",
    "title": "AirObject: A Temporally Evolving Graph Embedding for Object  Identification",
    "abstract": "Object encoding and identification are vital for robotic tasks such as\nautonomous exploration, semantic scene understanding, and re-localization.\nPrevious approaches have attempted to either track objects or generate\ndescriptors for object identification. However, such systems are limited to a\n\"fixed\" partial object representation from a single viewpoint. In a robot\nexploration setup, there is a requirement for a temporally \"evolving\" global\nobject representation built as the robot observes the object from multiple\nviewpoints. Furthermore, given the vast distribution of unknown novel objects\nin the real world, the object identification process must be class-agnostic. In\nthis context, we propose a novel temporal 3D object encoding approach, dubbed\nAirObject, to obtain global keypoint graph-based embeddings of objects.\nSpecifically, the global 3D object embeddings are generated using a temporal\nconvolutional network across structural information of multiple frames obtained\nfrom a graph attention-based encoding method. We demonstrate that AirObject\nachieves the state-of-the-art performance for video object identification and\nis robust to severe occlusion, perceptual aliasing, viewpoint shift,\ndeformation, and scale transform, outperforming the state-of-the-art\nsingle-frame and sequential descriptors. To the best of our knowledge,\nAirObject is one of the first temporal object encoding methods.",
    "descriptor": "",
    "authors": [
      "Nikhil Varma Keetha",
      "Chen Wang",
      "Yuheng Qiu",
      "Kuan Xu",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.15150"
  },
  {
    "id": "arXiv:2111.15152",
    "title": "SAVER: Safe Learning-Based Controller for Real-Time Voltage Regulation",
    "abstract": "Fast and safe voltage regulation algorithms can serve as fundamental schemes\nfor achieving a high level of renewable penetration in the modern distribution\npower grids. Faced with uncertain or even unknown distribution grid models and\nfast-changing power injections, model-free deep reinforcement learning (DRL)\nalgorithms have been proposed to find the reactive power injections for\ninverters while optimizing the voltage profiles. However, such data-driven\ncontrollers can not guarantee satisfaction of the hard operational constraints,\nsuch as maintaining voltage profiles within a certain range of the nominal\nvalue. To this end, we propose SAVER: SAfe VoltagE Regulator, which is composed\nof an RL learner and a specifically designed, computational efficient safety\nprojection layer. SAVER provides a plug-and-play interface for a set of DRL\nalgorithms that guarantees the system voltages to be within safe bounds.\nNumerical simulations on real-world data validate the performance of the\nproposed algorithm.",
    "descriptor": "",
    "authors": [
      "Yize Chen",
      "Yuanyuan Shi",
      "Daniel Arnold",
      "Sean Peisert"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.15152"
  },
  {
    "id": "arXiv:2111.15155",
    "title": "gCastle: A Python Toolbox for Causal Discovery",
    "abstract": "$\\texttt{gCastle}$ is an end-to-end Python toolbox for causal structure\nlearning. It provides functionalities of generating data from either simulator\nor real-world dataset, learning causal structure from the data, and evaluating\nthe learned graph, together with useful practices such as prior knowledge\ninsertion, preliminary neighborhood selection, and post-processing to remove\nfalse discoveries. Compared with related packages, $\\texttt{gCastle}$ includes\nmany recently developed gradient-based causal discovery methods with optional\nGPU acceleration. $\\texttt{gCastle}$ brings convenience to researchers who may\ndirectly experiment with the code as well as practitioners with graphical user\ninterference. Three real-world datasets in telecommunications are also provided\nin the current version. $\\texttt{gCastle}$ is available under Apache License\n2.0 at \\url{https://github.com/huawei-noah/trustworthyAI/tree/master/gcastle}.",
    "descriptor": "\nComments: Tech report describing the gCastle toolbox. More details can be found in the github repository this https URL\n",
    "authors": [
      "Keli Zhang",
      "Shengyu Zhu",
      "Marcus Kalander",
      "Ignavier Ng",
      "Junjian Ye",
      "Zhitang Chen",
      "Lujia Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.15155"
  },
  {
    "id": "arXiv:2111.15156",
    "title": "Automated Speech Scoring System Under The Lens: Evaluating and  interpreting the linguistic cues for language proficiency",
    "abstract": "English proficiency assessments have become a necessary metric for filtering\nand selecting prospective candidates for both academia and industry. With the\nrise in demand for such assessments, it has become increasingly necessary to\nhave the automated human-interpretable results to prevent inconsistencies and\nensure meaningful feedback to the second language learners. Feature-based\nclassical approaches have been more interpretable in understanding what the\nscoring model learns. Therefore, in this work, we utilize classical machine\nlearning models to formulate a speech scoring task as both a classification and\na regression problem, followed by a thorough study to interpret and study the\nrelation between the linguistic cues and the English proficiency level of the\nspeaker. First, we extract linguist features under five categories (fluency,\npronunciation, content, grammar and vocabulary, and acoustic) and train models\nto grade responses. In comparison, we find that the regression-based models\nperform equivalent to or better than the classification approach. Second, we\nperform ablation studies to understand the impact of each of the feature and\nfeature categories on the performance of proficiency grading. Further, to\nunderstand individual feature contributions, we present the importance of top\nfeatures on the best performing algorithm for the grading task. Third, we make\nuse of Partial Dependence Plots and Shapley values to explore feature\nimportance and conclude that the best performing trained model learns the\nunderlying rubrics used for grading the dataset used in this study.",
    "descriptor": "\nComments: Accepted for publication in the International Journal of Artificial Intelligence in Education (IJAIED)\n",
    "authors": [
      "Pakhi Bamdev",
      "Manraj Singh Grover",
      "Yaman Kumar Singla",
      "Payman Vafaee",
      "Mika Hama",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.15156"
  },
  {
    "id": "arXiv:2111.15157",
    "title": "MMPTRACK: Large-scale Densely Annotated Multi-camera Multiple People  Tracking Benchmark",
    "abstract": "Multi-camera tracking systems are gaining popularity in applications that\ndemand high-quality tracking results, such as frictionless checkout because\nmonocular multi-object tracking (MOT) systems often fail in cluttered and\ncrowded environments due to occlusion. Multiple highly overlapped cameras can\nsignificantly alleviate the problem by recovering partial 3D information.\nHowever, the cost of creating a high-quality multi-camera tracking dataset with\ndiverse camera settings and backgrounds has limited the dataset scale in this\ndomain. In this paper, we provide a large-scale densely-labeled multi-camera\ntracking dataset in five different environments with the help of an\nauto-annotation system. The system uses overlapped and calibrated depth and RGB\ncameras to build a high-performance 3D tracker that automatically generates the\n3D tracking results. The 3D tracking results are projected to each RGB camera\nview using camera parameters to create 2D tracking results. Then, we manually\ncheck and correct the 3D tracking results to ensure the label quality, which is\nmuch cheaper than fully manual annotation. We have conducted extensive\nexperiments using two real-time multi-camera trackers and a person\nre-identification (ReID) model with different settings. This dataset provides a\nmore reliable benchmark of multi-camera, multi-object tracking systems in\ncluttered and crowded environments. Also, our results demonstrate that adapting\nthe trackers and ReID models on this dataset significantly improves their\nperformance. Our dataset will be publicly released upon the acceptance of this\nwork.",
    "descriptor": "",
    "authors": [
      "Xiaotian Han",
      "Quanzeng You",
      "Chunyu Wang",
      "Zhizheng Zhang",
      "Peng Chu",
      "Houdong Hu",
      "Jiang Wang",
      "Zicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15157"
  },
  {
    "id": "arXiv:2111.15158",
    "title": "A Dataset-Dispersion Perspective on Reconstruction Versus Recognition in  Single-View 3D Reconstruction Networks",
    "abstract": "Neural networks (NN) for single-view 3D reconstruction (SVR) have gained in\npopularity. Recent work points out that for SVR, most cutting-edge NNs have\nlimited performance on reconstructing unseen objects because they rely\nprimarily on recognition (i.e., classification-based methods) rather than shape\nreconstruction. To understand this issue in depth, we provide a systematic\nstudy on when and why NNs prefer recognition to reconstruction and vice versa.\nOur finding shows that a leading factor in determining recognition versus\nreconstruction is how dispersed the training data is. Thus, we introduce the\ndispersion score, a new data-driven metric, to quantify this leading factor and\nstudy its effect on NNs. We hypothesize that NNs are biased toward recognition\nwhen training images are more dispersed and training shapes are less dispersed.\nOur hypothesis is supported and the dispersion score is proved effective\nthrough our experiments on synthetic and benchmark datasets. We show that the\nproposed metric is a principal way to analyze reconstruction quality and\nprovides novel information in addition to the conventional reconstruction\nscore.",
    "descriptor": "\nComments: Accepted to 3DV 2021\n",
    "authors": [
      "Yefan Zhou",
      "Yiru Shen",
      "Yujun Yan",
      "Chen Feng",
      "Yaoqing Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15158"
  },
  {
    "id": "arXiv:2111.15159",
    "title": "CycleTransGAN-EVC: A CycleGAN-based Emotional Voice Conversion Model  with Transformer",
    "abstract": "In this study, we explore the transformer's ability to capture\nintra-relations among frames by augmenting the receptive field of models.\nConcretely, we propose a CycleGAN-based model with the transformer and\ninvestigate its ability in the emotional voice conversion task. In the training\nprocedure, we adopt curriculum learning to gradually increase the frame length\nso that the model can see from the short segment till the entire speech. The\nproposed method was evaluated on the Japanese emotional speech dataset and\ncompared to several baselines (ACVAE, CycleGAN) with objective and subjective\nevaluations. The results show that our proposed model is able to convert\nemotion with higher strength and quality.",
    "descriptor": "",
    "authors": [
      "Changzeng Fu",
      "Chaoran Liu",
      "Carlos Toshinori Ishi",
      "Hiroshi Ishiguro"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.15159"
  },
  {
    "id": "arXiv:2111.15160",
    "title": "Mitigating Adversarial Attacks by Distributing Different Copies to  Different Users",
    "abstract": "Machine learning models are vulnerable to adversarial attacks. In this paper,\nwe consider the scenario where a model is to be distributed to multiple users,\namong which a malicious user attempts to attack another user. The malicious\nuser probes its copy of the model to search for adversarial samples and then\npresents the found samples to the victim's model in order to replicate the\nattack. We point out that by distributing different copies of the model to\ndifferent users, we can mitigate the attack such that adversarial samples found\non one copy would not work on another copy. We first observed that training a\nmodel with different randomness indeed mitigates such replication to certain\ndegree. However, there is no guarantee and retraining is computationally\nexpensive. Next, we propose a flexible parameter rewriting method that directly\nmodifies the model's parameters. This method does not require additional\ntraining and is able to induce different sets of adversarial samples in\ndifferent copies in a more controllable manner. Experimentation studies show\nthat our approach can significantly mitigate the attacks while retaining high\nclassification accuracy. From this study, we believe that there are many\nfurther directions worth exploring.",
    "descriptor": "",
    "authors": [
      "Jiyi Zhang",
      "Wesley Joon-Wie Tann",
      "Ee-Chien Chang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15160"
  },
  {
    "id": "arXiv:2111.15162",
    "title": "CLIP Meets Video Captioners: Attribute-Aware Representation Learning  Promotes Accurate Captioning",
    "abstract": "For video captioning, \"pre-training and fine-tuning\" has become a de facto\nparadigm, where ImageNet Pre-training (INP) is usually used to help encode the\nvideo content, and a task-oriented network is fine-tuned from scratch to cope\nwith caption generation. Comparing INP with the recently proposed CLIP\n(Contrastive Language-Image Pre-training), this paper investigates the\npotential deficiencies of INP for video captioning and explores the key to\ngenerating accurate descriptions. Specifically, our empirical study on INP vs.\nCLIP shows that INP makes video caption models tricky to capture attributes'\nsemantics and sensitive to irrelevant background information. By contrast,\nCLIP's significant boost in caption quality highlights the importance of\nattribute-aware representation learning. We are thus motivated to introduce\nDual Attribute Prediction, an auxiliary task requiring a video caption model to\nlearn the correspondence between video content and attributes and the\nco-occurrence relations between attributes. Extensive experiments on benchmark\ndatasets demonstrate that our approach enables better learning of\nattribute-aware representations, bringing consistent improvements on models\nwith different architectures and decoding algorithms.",
    "descriptor": "\nComments: 10 pages, 9 figures, 5 tables\n",
    "authors": [
      "Bang Yang",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15162"
  },
  {
    "id": "arXiv:2111.15164",
    "title": "WALK-VIO: Walking-motion-Adaptive Leg Kinematic Constraint  Visual-Inertial Odometry for Quadruped Robots",
    "abstract": "In this paper, WALK-VIO, a novel visual-inertial odometry (VIO) with\nwalking-motion-adaptive leg kinematic constraints that change with body motion\nfor localization of quadruped robots, is proposed. Quadruped robots primarily\nuse VIO because they require fast localization for control and path planning.\nHowever, since quadruped robots are mainly used outdoors, extraneous features\nextracted from the sky or ground cause tracking failures. In addition, the\nquadruped robots' walking motion cause wobbling, which lowers the localization\naccuracy due to the camera and inertial measurement unit (IMU). To overcome\nthese limitations, many researchers use VIO with leg kinematic constraints.\nHowever, since the quadruped robot's walking motion varies according to the\ncontroller, gait, quadruped robots' velocity, and so on, these factors should\nbe considered in the process of adding leg kinematic constraints. We propose\nVIO that can be used regardless of walking motion by adjusting the leg\nkinematic constraint factor. In order to evaluate WALK-VIO, we create and\npublish datasets of quadruped robots that move with various types of walking\nmotion in a simulation environment. In addition, we verified the validity of\nWALK-VIO through comparison with current state-of-the-art algorithms.",
    "descriptor": "",
    "authors": [
      "Hyunjun Lim",
      "Byeongho Yu",
      "Yeeun Kim",
      "Joowoong Byun",
      "Soonpyo Kwon",
      "Haewon Park",
      "Hyun Myung"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.15164"
  },
  {
    "id": "arXiv:2111.15166",
    "title": "Improvement in Machine Translation with Generative Adversarial Networks",
    "abstract": "In this paper, we explore machine translation improvement via Generative\nAdversarial Network (GAN) architecture. We take inspiration from RelGAN, a\nmodel for text generation, and NMT-GAN, an adversarial machine translation\nmodel, to implement a model that learns to transform awkward, non-fluent\nEnglish sentences to fluent ones, while only being trained on monolingual\ncorpora. We utilize a parameter $\\lambda$ to control the amount of deviation\nfrom the input sentence, i.e. a trade-off between keeping the original tokens\nand modifying it to be more fluent. Our results improved upon phrase-based\nmachine translation in some cases. Especially, GAN with a transformer generator\nshows some promising results. We suggests some directions for future works to\nbuild upon this proof-of-concept.",
    "descriptor": "",
    "authors": [
      "Jay Ahn",
      "Hari Madhu",
      "Viet Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15166"
  },
  {
    "id": "arXiv:2111.15169",
    "title": "Online metric allocation",
    "abstract": "We introduce a natural online allocation problem that connects several of the\nmost fundamental problems in online optimization. Let $M$ be an $n$-point\nmetric space. Consider a resource that can be allocated in arbitrary fractions\nto the points of $M$. At each time $t$, a convex monotone cost function $c_t:\n[0,1]\\to\\mathbb{R}_+$ appears at some point $r_t\\in M$. In response, an\nalgorithm may change the allocation of the resource, paying movement cost as\ndetermined by the metric and service cost $c_t(x_{r_t})$, where $x_{r_t}$ is\nthe fraction of the resource at $r_t$ at the end of time $t$. For example, when\nthe cost functions are $c_t(x)=\\alpha x$, this is equivalent to randomized MTS,\nand when the cost functions are $c_t(x)=\\infty\\cdot 1_{x<1/k}$, this is\nequivalent to fractional $k$-server.\nWe give an $O(\\log n)$-competitive algorithm for weighted star metrics. Due\nto the generality of allowed cost functions, classical multiplicative update\nalgorithms do not work for the metric allocation problem. A key idea of our\nalgorithm is to decouple the rate at which a variable is updated from its\nvalue, resulting in interesting new dynamics. This can be viewed as running\nmirror descent with a time-varying regularizer, and we use this perspective to\nfurther refine the guarantees of our algorithm. The standard analysis\ntechniques run into multiple complications when the regularizer is\ntime-varying, and we show how to overcome these issues by making various\nmodifications to the default potential function.\nWe also consider the problem when cost functions are allowed to be\nnon-convex. In this case, we give tight bounds of $\\Theta(n)$ on tree metrics,\nwhich imply deterministic and randomized competitive ratios of $O(n^2)$ and\n$O(n\\log n)$ respectively on arbitrary metrics. Our algorithm is based on an\n$\\ell_2^2$-regularizer.",
    "descriptor": "",
    "authors": [
      "Nikhil Bansal",
      "Christian Coester"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.15169"
  },
  {
    "id": "arXiv:2111.15171",
    "title": "Generative Convolution Layer for Image Generation",
    "abstract": "This paper introduces a novel convolution method, called generative\nconvolution (GConv), which is simple yet effective for improving the generative\nadversarial network (GAN) performance. Unlike the standard convolution, GConv\nfirst selects useful kernels compatible with the given latent vector, and then\nlinearly combines the selected kernels to make latent-specific kernels. Using\nthe latent-specific kernels, the proposed method produces the latent-specific\nfeatures which encourage the generator to produce high-quality images. This\napproach is simple but surprisingly effective. First, the GAN performance is\nsignificantly improved with a little additional hardware cost. Second, GConv\ncan be employed to the existing state-of-the-art generators without modifying\nthe network architecture. To reveal the superiority of GConv, this paper\nprovides extensive experiments using various standard datasets including\nCIFAR-10, CIFAR-100, LSUN-Church, CelebA, and tiny-ImageNet. Quantitative\nevaluations prove that GConv significantly boosts the performances of the\nunconditional and conditional GANs in terms of Inception score (IS) and Frechet\ninception distance (FID). For example, the proposed method improves both FID\nand IS scores on the tiny-ImageNet dataset from 35.13 to 29.76 and 20.23 to\n22.64, respectively.",
    "descriptor": "\nComments: Submitted to Neural Networks\n",
    "authors": [
      "Seung Park",
      "Yong-Goo Shin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15171"
  },
  {
    "id": "arXiv:2111.15174",
    "title": "CRIS: CLIP-Driven Referring Image Segmentation",
    "abstract": "Referring image segmentation aims to segment a referent via a natural\nlinguistic expression.Due to the distinct data properties between text and\nimage, it is challenging for a network to well align text and pixel-level\nfeatures. Existing approaches use pretrained models to facilitate learning, yet\nseparately transfer the language/vision knowledge from pretrained models,\nignoring the multi-modal corresponding information. Inspired by the recent\nadvance in Contrastive Language-Image Pretraining (CLIP), in this paper, we\npropose an end-to-end CLIP-Driven Referring Image Segmentation framework\n(CRIS). To transfer the multi-modal knowledge effectively, CRIS resorts to\nvision-language decoding and contrastive learning for achieving the\ntext-to-pixel alignment. More specifically, we design a vision-language decoder\nto propagate fine-grained semantic information from textual representations to\neach pixel-level activation, which promotes consistency between the two\nmodalities. In addition, we present text-to-pixel contrastive learning to\nexplicitly enforce the text feature similar to the related pixel-level features\nand dissimilar to the irrelevances. The experimental results on three benchmark\ndatasets demonstrate that our proposed framework significantly outperforms the\nstate-of-the-art performance without any post-processing. The code will be\nreleased.",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Zhaoqing Wang",
      "Yu Lu",
      "Qiang Li",
      "Xunqiang Tao",
      "Yandong Guo",
      "Mingming Gong",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15174"
  },
  {
    "id": "arXiv:2111.15179",
    "title": "A Highly Effective Low-Rank Compression of Deep Neural Networks with  Modified Beam-Search and Modified Stable Rank",
    "abstract": "Compression has emerged as one of the essential deep learning research\ntopics, especially for the edge devices that have limited computation power and\nstorage capacity. Among the main compression techniques, low-rank compression\nvia matrix factorization has been known to have two problems. First, an\nextensive tuning is required. Second, the resulting compression performance is\ntypically not impressive. In this work, we propose a low-rank compression\nmethod that utilizes a modified beam-search for an automatic rank selection and\na modified stable rank for a compression-friendly training. The resulting BSR\n(Beam-search and Stable Rank) algorithm requires only a single hyperparameter\nto be tuned for the desired compression ratio. The performance of BSR in terms\nof accuracy and compression ratio trade-off curve turns out to be superior to\nthe previously known low-rank compression methods. Furthermore, BSR can perform\non par with or better than the state-of-the-art structured pruning methods. As\nwith pruning, BSR can be easily combined with quantization for an additional\ncompression.",
    "descriptor": "\nComments: 8 pages, 8 figures, 2 tables\n",
    "authors": [
      "Moonjung Eo",
      "Suhyun Kang",
      "Wonjong Rhee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15179"
  },
  {
    "id": "arXiv:2111.15181",
    "title": "Zero-Shot Semantic Segmentation via Spatial and Multi-Scale Aware Visual  Class Embedding",
    "abstract": "Fully supervised semantic segmentation technologies bring a paradigm shift in\nscene understanding. However, the burden of expensive labeling cost remains as\na challenge. To solve the cost problem, recent studies proposed language model\nbased zero-shot semantic segmentation (L-ZSSS) approaches. In this paper, we\naddress L-ZSSS has a limitation in generalization which is a virtue of\nzero-shot learning. Tackling the limitation, we propose a language-model-free\nzero-shot semantic segmentation framework, Spatial and Multi-scale aware Visual\nClass Embedding Network (SM-VCENet). Furthermore, leveraging vision-oriented\nclass embedding SM-VCENet enriches visual information of the class embedding by\nmulti-scale attention and spatial attention. We also propose a novel benchmark\n(PASCAL2COCO) for zero-shot semantic segmentation, which provides\ngeneralization evaluation by domain adaptation and contains visually\nchallenging samples. In experiments, our SM-VCENet outperforms zero-shot\nsemantic segmentation state-of-the-art by a relative margin in PASCAL-5i\nbenchmark and shows generalization-robustness in PASCAL2COCO benchmark.",
    "descriptor": "",
    "authors": [
      "Sungguk Cha",
      "Yooseung Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15181"
  },
  {
    "id": "arXiv:2111.15182",
    "title": "Easy Semantification of Bioassays",
    "abstract": "Biological data and knowledge bases increasingly rely on Semantic Web\ntechnologies and the use of knowledge graphs for data integration, retrieval\nand federated queries. We propose a solution for automatically semantifying\nbiological assays. Our solution juxtaposes the problem of automated\nsemantification as classification versus clustering where the two methods are\non opposite ends of the method complexity spectrum. Characteristically modeling\nour problem, we find the clustering solution significantly outperforms a deep\nneural network state-of-the-art classification approach. This novel\ncontribution is based on two factors: 1) a learning objective closely modeled\nafter the data outperforms an alternative approach with sophisticated semantic\nmodeling; 2) automatically semantifying biological assays achieves a high\nperformance F1 of nearly 83%, which to our knowledge is the first reported\nstandardized evaluation of the task offering a strong benchmark model.",
    "descriptor": "\nComments: 12 pages, 5 figures, Accepted for Publication in AIxIA 2021 (this https URL)\n",
    "authors": [
      "Marco Anteghini",
      "Jennifer D'Souza",
      "Vitor A.P. Martins dos Santos",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15182"
  },
  {
    "id": "arXiv:2111.15185",
    "title": "SamplingAug: On the Importance of Patch Sampling Augmentation for Single  Image Super-Resolution",
    "abstract": "With the development of Deep Neural Networks (DNNs), plenty of methods based\non DNNs have been proposed for Single Image Super-Resolution (SISR). However,\nexisting methods mostly train the DNNs on uniformly sampled LR-HR patch pairs,\nwhich makes them fail to fully exploit informative patches within the image. In\nthis paper, we present a simple yet effective data augmentation method. We\nfirst devise a heuristic metric to evaluate the informative importance of each\npatch pair. In order to reduce the computational cost for all patch pairs, we\nfurther propose to optimize the calculation of our metric by integral image,\nachieving about two orders of magnitude speedup. The training patch pairs are\nsampled according to their informative importance with our method. Extensive\nexperiments show our sampling augmentation can consistently improve the\nconvergence and boost the performance of various SISR architectures, including\nEDSR, RCAN, RDN, SRCNN and ESPCN across different scaling factors (x2, x3, x4).\nCode is available at https://github.com/littlepure2333/SamplingAug",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Shizun Wang",
      "Ming Lu",
      "Kaixin Chen",
      "Jiaming Liu",
      "Xiaoqi Li",
      "Chuang zhang",
      "Ming Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15185"
  },
  {
    "id": "arXiv:2111.15186",
    "title": "Automatic Synthesis of Diverse Weak Supervision Sources for Behavior  Analysis",
    "abstract": "Obtaining annotations for large training sets is expensive, especially in\nbehavior analysis settings where domain knowledge is required for accurate\nannotations. Weak supervision has been studied to reduce annotation costs by\nusing weak labels from task-level labeling functions to augment ground truth\nlabels. However, domain experts are still needed to hand-craft labeling\nfunctions for every studied task. To reduce expert effort, we present AutoSWAP:\na framework for automatically synthesizing data-efficient task-level labeling\nfunctions. The key to our approach is to efficiently represent expert knowledge\nin a reusable domain specific language and domain-level labeling functions,\nwith which we use state-of-the-art program synthesis techniques and a small\nlabeled dataset to generate labeling functions. Additionally, we propose a\nnovel structural diversity cost that allows for direct synthesis of diverse\nsets of labeling functions with minimal overhead, further improving labeling\nfunction data efficiency. We evaluate AutoSWAP in three behavior analysis\ndomains and demonstrate that AutoSWAP outperforms existing approaches using\nonly a fraction of the data. Our results suggest that AutoSWAP is an effective\nway to automatically generate labeling functions that can significantly reduce\nexpert effort for behavior analysis.",
    "descriptor": "",
    "authors": [
      "Albert Tseng",
      "Jennifer J. Sun",
      "Yisong Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15186"
  },
  {
    "id": "arXiv:2111.15192",
    "title": "PlantStereo: A Stereo Matching Benchmark for Plant Surface Dense  Reconstruction",
    "abstract": "Stereo matching is an important task in computer vision which has drawn\ntremendous research attention for decades. While in terms of disparity\naccuracy, density and data size, public stereo datasets are difficult to meet\nthe requirements of models. In this paper, we aim to address the issue between\ndatasets and models and propose a large scale stereo dataset with high accuracy\ndisparity ground truth named PlantStereo. We used a semi-automatic way to\nconstruct the dataset: after camera calibration and image registration, high\naccuracy disparity images can be obtained from the depth images. In total,\nPlantStereo contains 812 image pairs covering a diverse set of plants: spinach,\ntomato, pepper and pumpkin. We firstly evaluated our PlantStereo dataset on\nfour different stereo matching methods. Extensive experiments on different\nmodels and plants show that compared with ground truth in integer accuracy,\nhigh accuracy disparity images provided by PlantStereo can remarkably improve\nthe training effect of deep learning models. This paper provided a feasible and\nreliable method to realize plant surface dense reconstruction. The PlantStereo\ndataset and relative code are available at:\nhttps://www.github.com/wangqingyu985/PlantStereo",
    "descriptor": "",
    "authors": [
      "Qingyu Wang",
      "Baojian Ma",
      "Wei Liu",
      "Mingzhao Lou",
      "Mingchuan Zhou",
      "Huanyu Jiang",
      "Yibin Ying"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15192"
  },
  {
    "id": "arXiv:2111.15193",
    "title": "Shunted Self-Attention via Multi-Scale Token Aggregation",
    "abstract": "Recent Vision Transformer~(ViT) models have demonstrated encouraging results\nacross various computer vision tasks, thanks to their competence in modeling\nlong-range dependencies of image patches or tokens via self-attention. These\nmodels, however, usually designate the similar receptive fields of each token\nfeature within each layer. Such a constraint inevitably limits the ability of\neach self-attention layer in capturing multi-scale features, thereby leading to\nperformance degradation in handling images with multiple objects of different\nscales. To address this issue, we propose a novel and generic strategy, termed\nshunted self-attention~(SSA), that allows ViTs to model the attentions at\nhybrid scales per attention layer. The key idea of SSA is to inject\nheterogeneous receptive field sizes into tokens: before computing the\nself-attention matrix, it selectively merges tokens to represent larger object\nfeatures while keeping certain tokens to preserve fine-grained features. This\nnovel merging scheme enables the self-attention to learn relationships between\nobjects with different sizes and simultaneously reduces the token numbers and\nthe computational cost. Extensive experiments across various tasks demonstrate\nthe superiority of SSA. Specifically, the SSA-based transformer achieves 84.0\\%\nTop-1 accuracy and outperforms the state-of-the-art Focal Transformer on\nImageNet with only half of the model size and computation cost, and surpasses\nFocal Transformer by 1.3 mAP on COCO and 2.9 mIOU on ADE20K under similar\nparameter and computation cost. Code has been released at\nhttps://github.com/OliverRensu/Shunted-Transformer.",
    "descriptor": "",
    "authors": [
      "Sucheng Ren",
      "Daquan Zhou",
      "Shengfeng He",
      "Jiashi Feng",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15193"
  },
  {
    "id": "arXiv:2111.15199",
    "title": "Semi-Supervised 3D Hand Shape and Pose Estimation with Label Propagation",
    "abstract": "To obtain 3D annotations, we are restricted to controlled environments or\nsynthetic datasets, leading us to 3D datasets with less generalizability to\nreal-world scenarios. To tackle this issue in the context of semi-supervised 3D\nhand shape and pose estimation, we propose the Pose Alignment network to\npropagate 3D annotations from labelled frames to nearby unlabelled frames in\nsparsely annotated videos. We show that incorporating the alignment supervision\non pairs of labelled-unlabelled frames allows us to improve the pose estimation\naccuracy. Besides, we show that the proposed Pose Alignment network can\neffectively propagate annotations on unseen sparsely labelled videos without\nfine-tuning.",
    "descriptor": "\nComments: DICTA 2021\n",
    "authors": [
      "Samira Kaviani",
      "Amir Rahimi",
      "Richard Hartley"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15199"
  },
  {
    "id": "arXiv:2111.15205",
    "title": "New Datasets for Dynamic Malware Classification",
    "abstract": "Nowadays, malware and malware incidents are increasing daily, even with\nvarious anti-viruses systems and malware detection or classification\nmethodologies. Many static, dynamic, and hybrid techniques have been presented\nto detect malware and classify them into malware families. Dynamic and hybrid\nmalware classification methods have advantages over static malware\nclassification methods by being highly efficient. Since it is difficult to mask\nmalware behavior while executing than its underlying code in static malware\nclassification, machine learning techniques have been the main focus of the\nsecurity experts to detect malware and determine their families dynamically.\nThe rapid increase of malware also brings the necessity of recent and updated\ndatasets of malicious software. We introduce two new, updated datasets in this\nwork: One with 9,795 samples obtained and compiled from VirusSamples and the\none with 14,616 samples from VirusShare. This paper also analyzes multi-class\nmalware classification performance of the balanced and imbalanced version of\nthese two datasets by using Histogram-based gradient boosting, Random Forest,\nSupport Vector Machine, and XGBoost models with API call-based dynamic malware\nclassification. Results show that Support Vector Machine, achieves the highest\nscore of 94% in the imbalanced VirusSample dataset, whereas the same model has\n91% accuracy in the balanced VirusSample dataset. While XGBoost, one of the\nmost common gradient boosting-based models, achieves the highest score of 90%\nand 80%.in both versions of the VirusShare dataset. This paper also presents\nthe baseline results of VirusShare and VirusSample datasets by using the four\nmost widely known machine learning techniques in dynamic malware classification\nliterature. We believe that these two datasets and baseline results enable\nresearchers in this field to test and validate their methods and approaches.",
    "descriptor": "\nComments: 5 pages, 2 figures, 6 tables\n",
    "authors": [
      "Berkant D\u00fczg\u00fcn",
      "Aykut \u00c7ay\u0131r",
      "Ferhat Demirk\u0131ran",
      "Ceyda Nur Kayha",
      "Buket Gen\u00e7ayd\u0131n",
      "Hasan Da\u011f"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15205"
  },
  {
    "id": "arXiv:2111.15207",
    "title": "NeeDrop: Self-supervised Shape Representation from Sparse Point Clouds  using Needle Dropping",
    "abstract": "There has been recently a growing interest for implicit shape\nrepresentations. Contrary to explicit representations, they have no resolution\nlimitations and they easily deal with a wide variety of surface topologies. To\nlearn these implicit representations, current approaches rely on a certain\nlevel of shape supervision (e.g., inside/outside information or\ndistance-to-shape knowledge), or at least require a dense point cloud (to\napproximate well enough the distance-to-shape). In contrast, we introduce\n{\\method}, an self-supervised method for learning shape representations from\npossibly extremely sparse point clouds. Like in Buffon's needle problem, we\n\"drop\" (sample) needles on the point cloud and consider that, statistically,\nclose to the surface, the needle end points lie on opposite sides of the\nsurface. No shape knowledge is required and the point cloud can be highly\nsparse, e.g., as lidar point clouds acquired by vehicles. Previous\nself-supervised shape representation approaches fail to produce good-quality\nresults on this kind of data. We obtain quantitative results on par with\nexisting supervised approaches on shape reconstruction datasets and show\npromising qualitative results on hard autonomous driving datasets such as\nKITTI.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Alexandre Boulch",
      "Pierre-Alain Langlois",
      "Gilles Puy",
      "Renaud Marlet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15207"
  },
  {
    "id": "arXiv:2111.15208",
    "title": "HRNET: AI on Edge for mask detection and social distancing",
    "abstract": "The purpose of the paper is to provide innovative emerging technology\nframework for community to combat epidemic situations. The paper proposes a\nunique outbreak response system framework based on artificial intelligence and\nedge computing for citizen centric services to help track and trace people\neluding safety policies like mask detection and social distancing measure in\npublic or workplace setup. The framework further provides implementation\nguideline in industrial setup as well for governance and contact tracing tasks.\nThe adoption will thus lead in smart city planning and development focusing on\ncitizen health systems contributing to improved quality of life. The conceptual\nframework presented is validated through quantitative data analysis via\nsecondary data collection from researcher's public websites, GitHub\nrepositories and renowned journals and further benchmarking were conducted for\nexperimental results in Microsoft Azure cloud environment. The study includes\nselective AI-models for benchmark analysis and were assessed on performance and\naccuracy in edge computing environment for large scale societal setup. Overall\nYOLO model Outperforms in object detection task and is faster enough for mask\ndetection and HRNetV2 outperform semantic segmentation problem applied to solve\nsocial distancing task in AI-Edge inferencing environmental setup. The paper\nproposes new Edge-AI algorithm for building technology-oriented solutions for\ndetecting mask in human movement and social distance. The paper enriches the\ntechnological advancement in artificial intelligence and edge-computing applied\nto problems in society and healthcare systems. The framework further equips\ngovernment agency, system providers to design and constructs\ntechnology-oriented models in community setup to Increase the quality of life\nusing emerging technologies into smart urban environments.",
    "descriptor": "",
    "authors": [
      "Kinshuk Sengupta",
      "Praveen Ranjan Srivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15208"
  },
  {
    "id": "arXiv:2111.15210",
    "title": "Point Cloud Instance Segmentation with Semi-supervised Bounding-Box  Mining",
    "abstract": "Point cloud instance segmentation has achieved huge progress with the\nemergence of deep learning. However, these methods are usually data-hungry with\nexpensive and time-consuming dense point cloud annotations. To alleviate the\nannotation cost, unlabeled or weakly labeled data is still less explored in the\ntask. In this paper, we introduce the first semi-supervised point cloud\ninstance segmentation framework (SPIB) using both labeled and unlabelled\nbounding boxes as supervision. To be specific, our SPIB architecture involves a\ntwo-stage learning procedure. For stage one, a bounding box proposal generation\nnetwork is trained under a semi-supervised setting with perturbation\nconsistency regularization (SPCR). The regularization works by enforcing an\ninvariance of the bounding box predictions over different perturbations applied\nto the input point clouds, to provide self-supervision for network learning.\nFor stage two, the bounding box proposals with SPCR are grouped into some\nsubsets, and the instance masks are mined inside each subset with a novel\nsemantic propagation module and a property consistency graph module. Moreover,\nwe introduce a novel occupancy ratio guided refinement module to refine the\ninstance masks. Extensive experiments on the challenging ScanNet v2 dataset\ndemonstrate our method can achieve competitive performance compared with the\nrecent fully-supervised methods.",
    "descriptor": "\nComments: IEEE Trans on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Yongbin Liao",
      "Hongyuan Zhu",
      "Yanggang Zhang",
      "Chuangguan Ye",
      "Tao Chen",
      "Jiayuan Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15210"
  },
  {
    "id": "arXiv:2111.15213",
    "title": "Using a GAN to Generate Adversarial Examples to Facial Image Recognition",
    "abstract": "Images posted online present a privacy concern in that they may be used as\nreference examples for a facial recognition system. Such abuse of images is in\nviolation of privacy rights but is difficult to counter. It is well established\nthat adversarial example images can be created for recognition systems which\nare based on deep neural networks. These adversarial examples can be used to\ndisrupt the utility of the images as reference examples or training data. In\nthis work we use a Generative Adversarial Network (GAN) to create adversarial\nexamples to deceive facial recognition and we achieve an acceptable success\nrate in fooling the face recognition. Our results reduce the training time for\nthe GAN by removing the discriminator component. Furthermore, our results show\nknowledge distillation can be employed to drastically reduce the size of the\nresulting model without impacting performance indicating that our contribution\ncould run comfortably on a smartphone",
    "descriptor": "\nComments: 8 pages, to appear at the Media Watermarking, Security, and Forensics Conference at Electronic Imaging, January, 2022\n",
    "authors": [
      "Andrew Merrigan",
      "Alan F. Smeaton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15213"
  },
  {
    "id": "arXiv:2111.15222",
    "title": "SP-SEDT: Self-supervised Pre-training for Sound Event Detection  Transformer",
    "abstract": "Recently, an event-based end-to-end model (SEDT) has been proposed for sound\nevent detection (SED) and achieves competitive performance. However, compared\nwith the frame-based model, it requires more training data with temporal\nannotations to improve the localization ability. Synthetic data is an\nalternative, but it suffers from a great domain gap with real recordings.\nInspired by the great success of UP-DETR in object detection, we propose to\nself-supervisedly pre-train SEDT (SP-SEDT) by detecting random patches (only\ncropped along the time axis). Experiments on the DCASE2019 task4 dataset show\nthe proposed SP-SEDT can outperform fine-tuned frame-based model. The ablation\nstudy is also conducted to investigate the impact of different loss functions\nand patch size.",
    "descriptor": "",
    "authors": [
      "Zhirong Ye",
      "Xiangdong Wang",
      "Hong Liu",
      "Yueliang Qian",
      "Rui Tao",
      "Long Yan",
      "Kazushige Ouchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.15222"
  },
  {
    "id": "arXiv:2111.15228",
    "title": "Global Convergence Using Policy Gradient Methods for Model-free  Markovian Jump Linear Quadratic Control",
    "abstract": "Owing to the growth of interest in Reinforcement Learning in the last few\nyears, gradient based policy control methods have been gaining popularity for\nControl problems as well. And rightly so, since gradient policy methods have\nthe advantage of optimizing a metric of interest in an end-to-end manner, along\nwith being relatively easy to implement without complete knowledge of the\nunderlying system. In this paper, we study the global convergence of\ngradient-based policy optimization methods for quadratic control of\ndiscrete-time and model-free Markovian jump linear systems (MJLS). We surmount\nmyriad challenges that arise because of more than one states coupled with lack\nof knowledge of the system dynamics and show global convergence of the policy\nusing gradient descent and natural policy gradient methods. We also provide\nsimulation studies to corroborate our claims.",
    "descriptor": "\nComments: 42 pages, 3 figures\n",
    "authors": [
      "Santanu Rathod",
      "Manoj Bhadu",
      "Abir De"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.15228"
  },
  {
    "id": "arXiv:2111.15234",
    "title": "NeRFReN: Neural Radiance Fields with Reflections",
    "abstract": "Neural Radiance Fields (NeRF) has achieved unprecedented view synthesis\nquality using coordinate-based neural scene representations. However, NeRF's\nview dependency can only handle simple reflections like highlights but cannot\ndeal with complex reflections such as those from glass and mirrors. In these\nscenarios, NeRF models the virtual image as real geometries which leads to\ninaccurate depth estimation, and produces blurry renderings when the multi-view\nconsistency is violated as the reflected objects may only be seen under some of\nthe viewpoints. To overcome these issues, we introduce NeRFReN, which is built\nupon NeRF to model scenes with reflections. Specifically, we propose to split a\nscene into transmitted and reflected components, and model the two components\nwith separate neural radiance fields. Considering that this decomposition is\nhighly under-constrained, we exploit geometric priors and apply\ncarefully-designed training strategies to achieve reasonable decomposition\nresults. Experiments on various self-captured scenes show that our method\nachieves high-quality novel view synthesis and physically sound depth\nestimation results while enabling scene editing applications. Code and data\nwill be released.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yuan-Chen Guo",
      "Di Kang",
      "Linchao Bao",
      "Yu He",
      "Song-Hai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.15234"
  },
  {
    "id": "arXiv:2111.15240",
    "title": "Verifying and Optimizing Compact NUMA-Aware Locks on Weak Memory Models",
    "abstract": "Developing concurrent software is challenging, specially if it has to run on\nmodern architectures with Weak Memory Models (WMMs) such as Armv8 and RISC-V.\nFor the sake of performance, WMMs allow hardware and compilers to aggressively\nreorder memory accesses. To guarantee correctness, developers have to carefully\nplace memory barriers in the code to enforce ordering among critical memory\noperations.\nWhile WMM architectures are growing in popularity, it is notoriously\ndifficult to identify the necessary and sufficient barriers of complex\nsynchronization primitives. Unfortunately, recent publications often consider\nbarriers just implementation details and omit them. In this technical note, we\nreport our efforts in verifying the correctness of the Compact NUMA-Aware (CNA)\nlock algorithm on WMMs, inserting a correct and efficient set of barriers in\nthe implementation. The CNA lock is of special interest because it is being\nintegrated in Linux qspinlock, and this integration process has produced\nseveral reviews of the algorithm. We intend to contribute to this process by\nverifying the correctness of the latest patch (v15) on WMMs.",
    "descriptor": "",
    "authors": [
      "Antonio Paolillo",
      "Diogo Behrens",
      "Rafael Chehab",
      "Ming Fu"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2111.15240"
  },
  {
    "id": "arXiv:2111.15242",
    "title": "ConDA: Unsupervised Domain Adaptation for LiDAR Segmentation via  Regularized Domain Concatenation",
    "abstract": "Transferring knowledge learned from the labeled source domain to the raw\ntarget domain for unsupervised domain adaptation (UDA) is essential to the\nscalable deployment of an autonomous driving system. State-of-the-art\napproaches in UDA often employ a key concept: utilize joint supervision signals\nfrom both the source domain (with ground-truth) and the target domain (with\npseudo-labels) for self-training. In this work, we improve and extend on this\naspect. We present ConDA, a concatenation-based domain adaptation framework for\nLiDAR semantic segmentation that: (1) constructs an intermediate domain\nconsisting of fine-grained interchange signals from both source and target\ndomains without destabilizing the semantic coherency of objects and background\naround the ego-vehicle; and (2) utilizes the intermediate domain for\nself-training. Additionally, to improve both the network training on the source\ndomain and self-training on the intermediate domain, we propose an\nanti-aliasing regularizer and an entropy aggregator to reduce the detrimental\neffects of aliasing artifacts and noisy target predictions. Through extensive\nexperiments, we demonstrate that ConDA is significantly more effective in\nmitigating the domain gap compared to prior arts.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Lingdong Kong",
      "Niamul Quader",
      "Venice Erin Liong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.15242"
  },
  {
    "id": "arXiv:2111.15246",
    "title": "Hallucinated Neural Radiance Fields in the Wild",
    "abstract": "Neural Radiance Fields (NeRF) has recently gained popularity for its\nimpressive novel view synthesis ability. This paper studies the problem of\nhallucinated NeRF: i.e. recovering a realistic NeRF at a different time of day\nfrom a group of tourism images. Existing solutions adopt NeRF with a\ncontrollable appearance embedding to render novel views under various\nconditions, but cannot render view-consistent images with an unseen appearance.\nTo solve this problem, we present an end-to-end framework for constructing a\nhallucinated NeRF, dubbed as H-NeRF. Specifically, we propose an appearance\nhallucination module to handle time-varying appearances and transfer them to\nnovel views. Considering the complex occlusions of tourism images, an\nanti-occlusion module is introduced to decompose the static subjects for\nvisibility accurately. Experimental results on synthetic data and real tourism\nphoto collections demonstrate that our method can not only hallucinate the\ndesired appearances, but also render occlusion-free images from different\nviews. The project and supplementary materials are available at\nhttps://rover-xingyu.github.io/H-NeRF/.",
    "descriptor": "",
    "authors": [
      "Xingyu Chen",
      "Qi Zhang",
      "Xiaoyu Li",
      "Yue Chen",
      "Feng Ying",
      "Xuan Wang",
      "Jue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15246"
  },
  {
    "id": "arXiv:2111.15250",
    "title": "2D-Motion Detection using SNNs with Graphene-Insulator-Graphene  Memristive Synapses",
    "abstract": "The event-driven nature of spiking neural networks makes them biologically\nplausible and more energy-efficient than artificial neural networks. In this\nwork, we demonstrate motion detection of an object in a two-dimensional visual\nfield. The network architecture presented here is biologically plausible and\nuses CMOS analog leaky integrate-and-fire neurons and ultra-low power\nmulti-layer RRAM synapses. Detailed transistorlevel SPICE simulations show that\nthe proposed structure can accurately and reliably detect complex motions of an\nobject in a two-dimensional visual field.",
    "descriptor": "\nComments: Submitted to ISCAS 2022, 5 pages\n",
    "authors": [
      "Shubham Pande",
      "Karthi Srinivasan",
      "Suresh Balanethiram",
      "Bhaswar Chakrabarti",
      "Anjan Chakravorty"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.15250"
  },
  {
    "id": "arXiv:2111.15255",
    "title": "Double Fuzzy Probabilistic Interval Linguistic Term Set and a Dynamic  Fuzzy Decision Making Model based on Markov Process with tts Application in  Multiple Criteria Group Decision Making",
    "abstract": "The probabilistic linguistic term has been proposed to deal with probability\ndistributions in provided linguistic evaluations. However, because it has some\nfundamental defects, it is often difficult for decision-makers to get\nreasonable information of linguistic evaluations for group decision making. In\naddition, weight information plays a significant role in dynamic information\nfusion and decision making process. However, there are few research methods to\ndetermine the dynamic attribute weight with time. In this paper, I propose the\nconcept of double fuzzy probability interval linguistic term set (DFPILTS).\nFirstly, fuzzy semantic integration, DFPILTS definition, its preference\nrelationship, some basic algorithms and aggregation operators are defined.\nThen, a fuzzy linguistic Markov matrix with its network is developed. Then, a\nweight determination method based on distance measure and information entropy\nto reducing the inconsistency of DFPILPR and obtain collective priority vector\nbased on group consensus is developed. Finally, an aggregation-based approach\nis developed, and an optimal investment case from a financial risk is used to\nillustrate the application of DFPILTS and decision method in multi-criteria\ndecision making.",
    "descriptor": "\nComments: submitted to IEEE Transactions on Fuzzy Systems\n",
    "authors": [
      "Zongmin Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "General Economics (econ.GN)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.15255"
  },
  {
    "id": "arXiv:2111.15256",
    "title": "Approximate Spectral Decomposition of Fisher Information Matrix for  Simple ReLU Networks",
    "abstract": "We investigate the Fisher information matrix (FIM) of one hidden layer\nnetworks with the ReLU activation function and obtain an approximate spectral\ndecomposition of FIM under certain conditions. From this decomposition, we can\napproximate the main eigenvalues and eigenvectors. We confirmed by numerical\nsimulation that the obtained decomposition is approximately correct when the\nnumber of hidden nodes is about 10000.",
    "descriptor": "",
    "authors": [
      "Yoshinari Takeishi",
      "Masazumi Iida",
      "Jun'ichi Takeuchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15256"
  },
  {
    "id": "arXiv:2111.15257",
    "title": "ARTSeg: Employing Attention for Thermal images Semantic Segmentation",
    "abstract": "The research advancements have made the neural network algorithms deployed in\nthe autonomous vehicle to perceive the surrounding. The standard exteroceptive\nsensors that are utilized for the perception of the environment are cameras and\nLidar. Therefore, the neural network algorithms developed using these\nexteroceptive sensors have provided the necessary solution for the autonomous\nvehicle's perception. One major drawback of these exteroceptive sensors is\ntheir operability in adverse weather conditions, for instance, low illumination\nand night conditions. The useability and affordability of thermal cameras in\nthe sensor suite of the autonomous vehicle provide the necessary improvement in\nthe autonomous vehicle's perception in adverse weather conditions. The\nsemantics of the environment benefits the robust perception, which can be\nachieved by segmenting different objects in the scene. In this work, we have\nemployed the thermal camera for semantic segmentation. We have designed an\nattention-based Recurrent Convolution Network (RCNN) encoder-decoder\narchitecture named ARTSeg for thermal semantic segmentation. The main\ncontribution of this work is the design of encoder-decoder architecture, which\nemploy units of RCNN for each encoder and decoder block. Furthermore, additive\nattention is employed in the decoder module to retain high-resolution features\nand improve the localization of features. The efficacy of the proposed method\nis evaluated on the available public dataset, showing better performance with\nother state-of-the-art methods in mean intersection over union (IoU).",
    "descriptor": "",
    "authors": [
      "Farzeen Munir",
      "Shoaib Azam",
      "Unse Fatima",
      "Moongu Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15257"
  },
  {
    "id": "arXiv:2111.15258",
    "title": "DeepAL: Deep Active Learning in Python",
    "abstract": "We present DeepAL, a Python library that implements several common strategies\nfor active learning, with a particular emphasis on deep active learning. DeepAL\nprovides a simple and unified framework based on PyTorch that allows users to\neasily load custom datasets, build custom data handlers, and design custom\nstrategies without much modification of codes. DeepAL is open-source on Github\nand welcome any contribution.",
    "descriptor": "\nComments: project url: this https URL\n",
    "authors": [
      "Kuan-Hao Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15258"
  },
  {
    "id": "arXiv:2111.15259",
    "title": "Privacy-Preserving Decentralized Exchange Marketplaces",
    "abstract": "Decentralized exchange markets leveraging blockchain have been proposed\nrecently to provide open and equal access to traders, improve transparency and\nreduce systemic risk of centralized exchanges. However, they compromise on the\nprivacy of traders with respect to their asset ownership, account balance,\norder details and their identity. In this paper, we present Rialto, a fully\ndecentralized privacy-preserving exchange marketplace with support for matching\ntrade orders, on-chain settlement and market price discovery. Rialto provides\nconfidentiality of order rates and account balances and unlinkability between\ntraders and their trade orders, while retaining the desirable properties of a\ntraditional marketplace like front-running resilience and market fairness. We\ndefine formal security notions and present a security analysis of the\nmarketplace. We perform a detailed evaluation of our solution, demonstrate that\nit scales well and is suitable for a large class of goods and financial\ninstruments traded in modern exchange markets.",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Kavya Govindarajan",
      "Dhinakaran Vinayagamurthy",
      "Praveen Jayachandran",
      "Chester Rebeiro"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.15259"
  },
  {
    "id": "arXiv:2111.15263",
    "title": "Multi-modal Text Recognition Networks: Interactive Enhancements between  Visual and Semantic Features",
    "abstract": "Linguistic knowledge has brought great benefits to scene text recognition by\nproviding semantics to refine character sequences. However, since linguistic\nknowledge has been applied individually on the output sequence, previous\nmethods have not fully utilized the semantics to understand visual clues for\ntext recognition. This paper introduces a novel method, called Multi-modAl Text\nRecognition Network (MATRN), that enables interactions between visual and\nsemantic features for better recognition performances. Specifically, MATRN\nidentifies visual and semantic feature pairs and encodes spatial information\ninto semantic features. Based on the spatial encoding, visual and semantic\nfeatures are enhanced by referring to related features in the other modality.\nFurthermore, MATRN stimulates combining semantic features into visual features\nby hiding visual clues related to the character in the training phase. Our\nexperiments demonstrate that MATRN achieves state-of-the-art performances on\nseven benchmarks with large margins, while naive combinations of two modalities\nshow marginal improvements. Further ablative studies prove the effectiveness of\nour proposed components. Our implementation will be publicly available.",
    "descriptor": "",
    "authors": [
      "Byeonghu Na",
      "Yoonsik Kim",
      "Sungrae Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15263"
  },
  {
    "id": "arXiv:2111.15264",
    "title": "EdiBERT, a generative model for image editing",
    "abstract": "Advances in computer vision are pushing the limits of im-age manipulation,\nwith generative models sampling detailed images on various tasks. However, a\nspecialized model is often developed and trained for each specific task, even\nthough many image edition tasks share similarities. In denoising, inpainting,\nor image compositing, one always aims at generating a realistic image from a\nlow-quality one. In this paper, we aim at making a step towards a unified\napproach for image editing. To do so, we propose EdiBERT, a bi-directional\ntransformer trained in the discrete latent space built by a vector-quantized\nauto-encoder. We argue that such a bidirectional model is suited for image\nmanipulation since any patch can be re-sampled conditionally to the whole\nimage. Using this unique and straightforward training objective, we show that\nthe resulting model matches state-of-the-art performances on a wide variety of\ntasks: image denoising, image completion, and image composition.",
    "descriptor": "",
    "authors": [
      "Thibaut Issenhuth",
      "Ugo Tanielian",
      "J\u00e9r\u00e9mie Mary",
      "David Picard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15264"
  },
  {
    "id": "arXiv:2111.15266",
    "title": "Two-stage Temporal Modelling Framework for Video-based Depression  Recognition using Graph Representation",
    "abstract": "Video-based automatic depression analysis provides a fast, objective and\nrepeatable self-assessment solution, which has been widely developed in recent\nyears. While depression clues may be reflected by human facial behaviours of\nvarious temporal scales, most existing approaches either focused on modelling\ndepression from short-term or video-level facial behaviours. In this sense, we\npropose a two-stage framework that models depression severity from multi-scale\nshort-term and video-level facial behaviours. The short-term depressive\nbehaviour modelling stage first deep learns depression-related facial\nbehavioural features from multiple short temporal scales, where a Depression\nFeature Enhancement (DFE) module is proposed to enhance the depression-related\nclues for all temporal scales and remove non-depression noises. Then, the\nvideo-level depressive behaviour modelling stage proposes two novel graph\nencoding strategies, i.e., Sequential Graph Representation (SEG) and Spectral\nGraph Representation (SPG), to re-encode all short-term features of the target\nvideo into a video-level graph representation, summarizing depression-related\nmulti-scale video-level temporal information. As a result, the produced graph\nrepresentations predict depression severity using both short-term and long-term\nfacial beahviour patterns. The experimental results on AVEC 2013 and AVEC 2014\ndatasets show that the proposed DFE module constantly enhanced the depression\nseverity estimation performance for various CNN models while the SPG is\nsuperior than other video-level modelling methods. More importantly, the result\nachieved for the proposed two-stage framework shows its promising and solid\nperformance compared to widely-used one-stage modelling approaches.",
    "descriptor": "",
    "authors": [
      "Jiaqi Xu",
      "Siyang Song",
      "Keerthy Kusumam",
      "Hatice Gunes",
      "Michel Valstar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15266"
  },
  {
    "id": "arXiv:2111.15268",
    "title": "Towards automatic identification of linguistic politeness in Hindi texts",
    "abstract": "In this paper I present a classifier for automatic identification of\nlinguistic politeness in Hindi texts. I have used the manually annotated corpus\nof over 25,000 blog comments to train an SVM. Making use of the discursive and\ninteractional approaches to politeness the paper gives an exposition of the\nnormative, conventionalised politeness structures of Hindi. It is seen that\nusing these manually recognised structures as features in training the SVM\nsignificantly improves the performance of the classifier on the test set. The\ntrained system gives a significantly high accuracy of over 77% which is within\n2% of human accuracy.",
    "descriptor": "",
    "authors": [
      "Ritesh Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15268"
  },
  {
    "id": "arXiv:2111.15271",
    "title": "Affect-DML: Context-Aware One-Shot Recognition of Human Affect using  Deep Metric Learning",
    "abstract": "Human affect recognition is a well-established research area with numerous\napplications, e.g., in psychological care, but existing methods assume that all\nemotions-of-interest are given a priori as annotated training examples.\nHowever, the rising granularity and refinements of the human emotional spectrum\nthrough novel psychological theories and the increased consideration of\nemotions in context brings considerable pressure to data collection and\nlabeling work. In this paper, we conceptualize one-shot recognition of emotions\nin context -- a new problem aimed at recognizing human affect states in finer\nparticle level from a single support sample. To address this challenging task,\nwe follow the deep metric learning paradigm and introduce a multi-modal emotion\nembedding approach which minimizes the distance of the same-emotion embeddings\nby leveraging complementary information of human appearance and the semantic\nscene context obtained through a semantic segmentation network. All streams of\nour context-aware model are optimized jointly using weighted triplet loss and\nweighted cross entropy loss. We conduct thorough experiments on both,\ncategorical and numerical emotion recognition tasks of the Emotic dataset\nadapted to our one-shot recognition problem, revealing that categorizing human\naffect from a single example is a hard task. Still, all variants of our model\nclearly outperform the random baseline, while leveraging the semantic scene\ncontext consistently improves the learnt representations, setting\nstate-of-the-art results in one-shot emotion recognition. To foster research of\nmore universal representations of human affect states, we will make our\nbenchmark and models publicly available to the community under\nhttps://github.com/KPeng9510/Affect-DML.",
    "descriptor": "\nComments: Accepted to IEEE International Conference on Automatic Face and Gesture Recognition 2021 (FG2021). Benchmark, models, and code are at this https URL\n",
    "authors": [
      "Kunyu Peng",
      "Alina Roitberg",
      "David Schneider",
      "Marios Koulakis",
      "Kailun Yang",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15271"
  },
  {
    "id": "arXiv:2111.15276",
    "title": "COREATTACK: Breaking Up the Core Structure of Graphs",
    "abstract": "The concept of k-core in complex networks plays a key role in many\napplications, e.g., understanding the global structure, or identifying\ncentral/critical nodes, of a network. A malicious attacker with jamming ability\ncan exploit the vulnerability of the k-core structure to attack the network and\ninvalidate the network analysis methods, e.g., reducing the k-shell values of\nnodes can deceive graph algorithms, leading to the wrong decisions. In this\npaper, we investigate the robustness of the k-core structure under adversarial\nattacks by deleting edges, for the first time. Firstly, we give the general\ndefinition of targeted k-core attack, map it to the set cover problem which is\nNP-hard, and further introduce a series of evaluation metrics to measure the\nperformance of attack methods. Then, we propose $Q$ index theoretically as the\nprobability that the terminal node of an edge does not belong to the innermost\ncore, which is further used to guide the design of our heuristic attack\nmethods, namely COREATTACK and GreedyCOREATTACK. The experiments on a variety\nof real-world networks demonstrate that our methods behave much better than a\nseries of baselines, in terms of much smaller Edge Change Rate (ECR) and False\nAttack Rate (FAR), achieving state-of-the-art attack performance. More\nimpressively, for certain real-world networks, only deleting one edge from the\nk-core may lead to the collapse of the innermost core, even if this core\ncontains dozens of nodes. Such a phenomenon indicates that the k-core structure\ncould be extremely vulnerable under adversarial attacks, and its robustness\nthus should be carefully addressed to ensure the security of many graph\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Bo Zhou",
      "Yuqian Lv",
      "Jinhuan Wang",
      "Jian Zhang",
      "Qi Xuan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.15276"
  },
  {
    "id": "arXiv:2111.15278",
    "title": "Bilingual Topic Models for Comparable Corpora",
    "abstract": "Probabilistic topic models like Latent Dirichlet Allocation (LDA) have been\npreviously extended to the bilingual setting. A fundamental modeling assumption\nin several of these extensions is that the input corpora are in the form of\ndocument pairs whose constituent documents share a single topic distribution.\nHowever, this assumption is strong for comparable corpora that consist of\ndocuments thematically similar to an extent only, which are, in turn, the most\ncommonly available or easy to obtain. In this paper we relax this assumption by\nproposing for the paired documents to have separate, yet bound topic\ndistributions. % a binding mechanism between the distributions of the paired\ndocuments. We suggest that the strength of the bound should depend on each\npair's semantic similarity. To estimate the similarity of documents that are\nwritten in different languages we use cross-lingual word embeddings that are\nlearned with shallow neural networks. We evaluate the proposed binding\nmechanism by extending two topic models: a bilingual adaptation of LDA that\nassumes bag-of-words inputs and a model that incorporates part of the text\nstructure in the form of boundaries of semantically coherent segments. To\nassess the performance of the novel topic models we conduct intrinsic and\nextrinsic experiments on five bilingual, comparable corpora of English\ndocuments with French, German, Italian, Spanish and Portuguese documents. The\nresults demonstrate the efficiency of our approach in terms of both topic\ncoherence measured by the normalized point-wise mutual information, and\ngeneralization performance measured by perplexity and in terms of Mean\nReciprocal Rank in a cross-lingual document retrieval task for each of the\nlanguage pairs.",
    "descriptor": "\nComments: 32 pages, 2 figures\n",
    "authors": [
      "Georgios Balikas",
      "Massih-Reza Amini",
      "Marianne Clausel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15278"
  },
  {
    "id": "arXiv:2111.15285",
    "title": "Towards Automated Semantic Grouping in Workflows for Multi-Disciplinary  Analysis",
    "abstract": "When designing multidisciplinary tool workflows in visual development\nenvironments, researchers and engineers often combine simulation tools which\nserve a functional purpose and helper tools that merely ensure technical\ncompatibility by, e.g., converting between file formats. If the development\nenvironment does not offer native support for such groups of tools,\nmaintainability of the developed workflow quickly deteriorates with an increase\nin complexity.\nWe present an approach towards automatically identifying such groups of\nclosely related tools in multidisciplinary workflows implemented in RCE by\ntransforming the workflow into a graph and applying graph clustering algorithms\nto it. Further, we implement this approach and evaluate multiple clustering\nalgorithms. Our results strongly indicate that this approach can yield groups\nof closely related tools in RCE workflows, but also that solutions to this\nproblem will have to be tailor-made to each specific style of workflow design.",
    "descriptor": "",
    "authors": [
      "Dominik Schneider",
      "Alexander Weinert"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.15285"
  },
  {
    "id": "arXiv:2111.15286",
    "title": "PERCIVAL: Open-Source Posit RISC-V Core with Quire Capability",
    "abstract": "The posit representation for real numbers is an alternative to the ubiquitous\nIEEE 754 floating-point standard. In this work, we present PERCIVAL, an\napplication-level posit capable RISC-V core based on CVA6 that can execute all\nposit instructions, including the quire fused operations. This solves the\nobstacle encountered by previous works, which only included partial posit\nsupport or which had to emulate posits in software, thus limiting the scope or\nthe scalability of their applications. In addition, Xposit, a RISC-V extension\nfor posit instructions is incorporated into LLVM. Therefore, PERCIVAL is the\nfirst work that integrates the complete posit instruction set in hardware.\nThese elements allow for the native execution of posit instructions as well as\nthe standard floating-point ones, further permitting the comparison of these\nrepresentations. FPGA and ASIC synthesis show the hardware cost of implementing\n32-bit posits and highlight the significant overhead of including a quire\naccumulator. However, results comparing posits and IEEE floats show that the\nquire enables a more accurate execution of dot products. In general matrix\nmultiplications, the accuracy error is reduced up to 4 orders of magnitude when\ncompared with single-precision floats. Furthermore, performance comparisons\nshow that these accuracy improvements do not hinder their execution, as posits\nrun as fast as single-precision floats and exhibit better timing than\ndouble-precision floats, thus potentially providing an alternative\nrepresentation.",
    "descriptor": "",
    "authors": [
      "David Mallas\u00e9n",
      "Raul Murillo",
      "Alberto A. Del Barrio",
      "Guillermo Botella",
      "Luis Pi\u00f1uel",
      "Manuel Prieto"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2111.15286"
  },
  {
    "id": "arXiv:2111.15288",
    "title": "Revisiting Temporal Alignment for Video Restoration",
    "abstract": "Long-range temporal alignment is critical yet challenging for video\nrestoration tasks. Recently, some works attempt to divide the long-range\nalignment into several sub-alignments and handle them progressively. Although\nthis operation is helpful in modeling distant correspondences, error\naccumulation is inevitable due to the propagation mechanism. In this work, we\npresent a novel, generic iterative alignment module which employs a gradual\nrefinement scheme for sub-alignments, yielding more accurate motion\ncompensation. To further enhance the alignment accuracy and temporal\nconsistency, we develop a non-parametric re-weighting method, where the\nimportance of each neighboring frame is adaptively evaluated in a spatial-wise\nway for aggregation. By virtue of the proposed strategies, our model achieves\nstate-of-the-art performance on multiple benchmarks across a range of video\nrestoration tasks including video super-resolution, denoising and deblurring.\nOur project is available in\n\\url{https://github.com/redrock303/Revisiting-Temporal-Alignment-for-Video-Restoration.git}.",
    "descriptor": "\nComments: 15 pages. 17 figures, 10 tables/\n",
    "authors": [
      "Kun Zhou",
      "Wenbo Li",
      "Liying Lu",
      "Xiaoguang Han",
      "Jiangbo Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15288"
  },
  {
    "id": "arXiv:2111.15293",
    "title": "The Impact of Considering Human Values during Requirements Engineering  Activities",
    "abstract": "Human values, or what people hold important in their life, such as freedom,\nfairness, and social responsibility, often remain unnoticed and unattended\nduring software development. Ignoring values can lead to values violations in\nsoftware that can result in financial losses, reputation damage, and widespread\nsocial and legal implications. However, embedding human values in software is\nnot only non-trivial but also generally an unclear process. Commencing as early\nas during the Requirements Engineering (RE) activities promises to ensure\nfit-for-purpose and quality software products that adhere to human values. But\nwhat is the impact of considering human values explicitly during early RE\nactivities? To answer this question, we conducted a scenario-based survey where\n56 software practitioners contextualised requirements analysis towards a\nproposed mobile application for the homeless and suggested values-laden\nsoftware features accordingly. The suggested features were qualitatively\nanalysed. Results show that explicit considerations of values can help\npractitioners identify applicable values, associate purpose with the features\nthey develop, think outside-the-box, and build connections between software\nfeatures and human values. Finally, drawing from the results and experiences of\nthis study, we propose a scenario-based values elicitation process -- a simple\nfour-step takeaway as a practical implication of this study.",
    "descriptor": "\nComments: 17 pages, 8 images, 5 tables\n",
    "authors": [
      "Harsha Perera",
      "Rashina Hoda",
      "Rifat Ara Shams",
      "Arif Nurwidyantoro",
      "Mojtaba Shahin",
      "Waqar Hussain",
      "Jon Whittle"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.15293"
  },
  {
    "id": "arXiv:2111.15296",
    "title": "BrainScaleS Large Scale Spike Communication using Extoll",
    "abstract": "The BrainScaleS Neuromorphic Computing System is currently connected to a\ncompute cluster via Gigabit-Ethernet network technology. This is convenient for\nthe currently used experiment mode, where neuronal networks cover at most one\nwafer module. When modelling networks of larger size, as for example a full\nsized cortical microcircuit model, one has to think about connecting neurons\nacross wafer modules to larger networks. This can be done, using the Extoll\nnetworking technology, which provides high bandwidth and low latencies, as well\nas a low overhead packet protocol format.",
    "descriptor": "\nComments: 3 pages, 2 figures, submitted to the Neuro Inspired Computational Elements 2020 (NICE'2020) conference, accepted and presented as a poster in March 2021\n",
    "authors": [
      "Tobias Thommes",
      "Niels Buwen",
      "Andreas Gr\u00fcbl",
      "Eric M\u00fcller",
      "Ulrich Br\u00fcning",
      "Johannes Schemmel"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.15296"
  },
  {
    "id": "arXiv:2111.15298",
    "title": "Generating Rich Product Descriptions for Conversational E-commerce  Systems",
    "abstract": "Through recent advancements in speech technologies and introduction of smart\nassistants, such as Amazon Alexa, Apple Siri and Google Home, increasing number\nof users are interacting with various applications through voice commands.\nE-commerce companies typically display short product titles on their webpages,\neither human-curated or algorithmically generated, when brevity is required.\nHowever, these titles are dissimilar from natural spoken language. For example,\n\"Lucky Charms Gluten Free Break-fast Cereal, 20.5 oz a box Lucky Charms Gluten\nFree\" is acceptable to display on a webpage, while a similar title cannot be\nused in a voice based text-to-speech application. In such conversational\nsystems, an easy to comprehend sentence, such as \"a 20.5 ounce box of lucky\ncharms gluten free cereal\" is preferred. Compared to display devices, where\nimages and detailed product information can be presented to users, short titles\nfor products which convey the most important information, are necessary when\ninterfacing with voice assistants. We propose eBERT, a sequence-to-sequence\napproach by further pre-training the BERT embeddings on an e-commerce product\ndescription corpus, and then fine-tuning the resulting model to generate short,\nnatural, spoken language titles from input web titles. Our extensive\nexperiments on a real-world industry dataset, as well as human evaluation of\nmodel output, demonstrate that eBERT summarization outperforms comparable\nbaseline models. Owing to the efficacy of the model, a version of this model\nhas been deployed in real-world setting.",
    "descriptor": "\nComments: 8 pages, 1 figure. arXiv admin note: substantial text overlap with arXiv:2007.11768\n",
    "authors": [
      "Shashank Kedia",
      "Aditya Mantha",
      "Sneha Gupta",
      "Stephen Guo",
      "Kannan Achan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15298"
  },
  {
    "id": "arXiv:2111.15300",
    "title": "TridentAdapt: Learning Domain-invariance via Source-Target Confrontation  and Self-induced Cross-domain Augmentation",
    "abstract": "Due to the difficulty of obtaining ground-truth labels, learning from\nvirtual-world datasets is of great interest for real-world applications like\nsemantic segmentation. From domain adaptation perspective, the key challenge is\nto learn domain-agnostic representation of the inputs in order to benefit from\nvirtual data. In this paper, we propose a novel trident-like architecture that\nenforces a shared feature encoder to satisfy confrontational source and target\nconstraints simultaneously, thus learning a domain-invariant feature space.\nMoreover, we also introduce a novel training pipeline enabling self-induced\ncross-domain data augmentation during the forward pass. This contributes to a\nfurther reduction of the domain gap. Combined with a self-training process, we\nobtain state-of-the-art results on benchmark datasets (e.g. GTA5 or Synthia to\nCityscapes adaptation). Code and pre-trained models are available at\nhttps://github.com/HMRC-AEL/TridentAdapt",
    "descriptor": "\nComments: Accepted to BMVC2021\n",
    "authors": [
      "Fengyi Shen",
      "Akhil Gurram",
      "Ahmet Faruk Tuna",
      "Onay Urfalioglu",
      "Alois Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15300"
  },
  {
    "id": "arXiv:2111.15301",
    "title": "Optical Wireless Sytems for Spine and Leaf Data Center Downlinks",
    "abstract": "The continually growing demands for traffic as a result of advanced\ntechnologies in 5G and 6G systems offering services with intensive demands such\nas IoT and virtual reality applications has resulted in significant performance\nexpectations of data center networks (DCNs). More specifically, DCNs are\nexpected to meet high bandwidth connectivity, high throughput, low latency, and\nhigh scalability requirements. However, the current wired DCN architectures\nintroduce large cabling requirements and limit the ability to reconfigure data\ncentres as they expand. To that end, wireless technologies such as Optical\nWireless Communication (OWC) have been proposed as a viable and cost-effective\nsolution to meet the aforementioned requirements. This paper proposes the use\nof Infrared (IR) OWC systems that employ Wavelength Division Multiplexing (WDM)\nto enhance the DCN communication in the downlink direction; i.e. from Access\nPoints (APs) in the ceiling, connected to spine switches, to receivers attached\nto the top of the racks representing leaf switches. The proposed systems\nutilize Angle Diversity Transmitters (ADTs) mounted on the room ceiling to\nfacilitate inter-rack communication. Two different optical receiver types are\nconsidered, namely Angle Diversity Receivers (ADRs) and Wide Field-of-View\nReceivers (WFOVR). The simulation (i.e. channel modeling) results show that our\nproposed data center links achieve good data rates in the data centre up to 15\nGbps.",
    "descriptor": "",
    "authors": [
      "Abrar S. Alhazmi",
      "Sanaa H. Mohamed and",
      "T. E. H. El-Gorashi",
      "Jaafar M. H. Elmirghani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.15301"
  },
  {
    "id": "arXiv:2111.15307",
    "title": "Gaussian Mechanisms Against Statistical Inference: Synthesis Tools",
    "abstract": "In this manuscript, we provide a set of tools (in terms of semidefinite\nprograms) to synthesize Gaussian mechanisms to maximize privacy of databases.\nInformation about the database is disclosed through queries requested by\n(potentially) adversarial users. We aim to keep part of the database private\n(private sensitive information); however, disclosed data could be used to\nestimate private information. To avoid an accurate estimation by the\nadversaries, we pass the requested data through distorting (privacy-preserving)\nmechanisms before transmission and send the distorted data to the user. These\nmechanisms consist of a coordinate transformation and an additive dependent\nGaussian vector. We formulate the synthesis of distorting mechanisms in terms\nof semidefinite programs in which we seek to minimize the mutual information\n(our privacy metric) between private data and the disclosed distorted data\ngiven a desired distortion level -- how different actual and distorted data are\nallowed to be.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2108.01755\n",
    "authors": [
      "Haleh Hayati",
      "Carlos Murguia",
      "Nathan van de Wouw"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.15307"
  },
  {
    "id": "arXiv:2111.15309",
    "title": "Deep Auto-encoder with Neural Response",
    "abstract": "Artificial intelligence and neuroscience are deeply interactive. Artificial\nneural networks (ANNs) have been a versatile tool to study the neural\nrepresentation in the ventral visual stream, and the knowledge in neuroscience\nin return inspires ANN models to improve performance in the task. However, how\nto merge these two directions into a unified model has less studied. Here, we\npropose a hybrid model, called deep auto-encoder with the neural response\n(DAE-NR), which incorporates the information from the visual cortex into ANNs\nto achieve better image reconstruction and higher neural representation\nsimilarity between biological and artificial neurons. Specifically, the same\nvisual stimuli (i.e., natural images) are input to both the mice brain and\nDAE-NR. The DAE-NR jointly learns to map a specific layer of the encoder\nnetwork to the biological neural responses in the ventral visual stream by a\nmapping function and to reconstruct the visual input by the decoder. Our\nexperiments demonstrate that if and only if with the joint learning, DAE-NRs\ncan (i) improve the performance of image reconstruction and (ii) increase the\nrepresentational similarity between biological neurons and artificial neurons.\nThe DAE-NR offers a new perspective on the integration of computer vision and\nvisual neuroscience.",
    "descriptor": "",
    "authors": [
      "Xuming Ran",
      "Jie Zhang",
      "Ziyuan Ye",
      "Haiyan Wu",
      "Qi Xu",
      "Huihui Zhou",
      "Quanying Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15309"
  },
  {
    "id": "arXiv:2111.15317",
    "title": "AutoDrop: Training Deep Learning Models with Automatic Learning Rate  Drop",
    "abstract": "Modern deep learning (DL) architectures are trained using variants of the SGD\nalgorithm that is run with a $\\textit{manually}$ defined learning rate\nschedule, i.e., the learning rate is dropped at the pre-defined epochs,\ntypically when the training loss is expected to saturate. In this paper we\ndevelop an algorithm that realizes the learning rate drop\n$\\textit{automatically}$. The proposed method, that we refer to as AutoDrop, is\nmotivated by the observation that the angular velocity of the model parameters,\ni.e., the velocity of the changes of the convergence direction, for a fixed\nlearning rate initially increases rapidly and then progresses towards soft\nsaturation. At saturation the optimizer slows down thus the angular velocity\nsaturation is a good indicator for dropping the learning rate. After the drop,\nthe angular velocity \"resets\" and follows the previously described pattern - it\nincreases again until saturation. We show that our method improves over SOTA\ntraining approaches: it accelerates the training of DL models and leads to a\nbetter generalization. We also show that our method does not require any extra\nhyperparameter tuning. AutoDrop is furthermore extremely simple to implement\nand computationally cheap. Finally, we develop a theoretical framework for\nanalyzing our algorithm and provide convergence guarantees.",
    "descriptor": "\nComments: 12 figures, 23 pages\n",
    "authors": [
      "Yunfei Teng",
      "Jing Wang",
      "Anna Choromanska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.15317"
  },
  {
    "id": "arXiv:2111.15318",
    "title": "DiffSDFSim: Differentiable Rigid-Body Dynamics With Implicit Shapes",
    "abstract": "Differentiable physics is a powerful tool in computer vision and robotics for\nscene understanding and reasoning about interactions. Existing approaches have\nfrequently been limited to objects with simple shape or shapes that are known\nin advance. In this paper, we propose a novel approach to differentiable\nphysics with frictional contacts which represents object shapes implicitly\nusing signed distance fields (SDFs). Our simulation supports contact point\ncalculation even when the involved shapes are nonconvex. Moreover, we propose\nways for differentiating the dynamics for the object shape to facilitate shape\noptimization using gradient-based methods. In our experiments, we demonstrate\nthat our approach allows for model-based inference of physical parameters such\nas friction coefficients, mass, forces or shape parameters from trajectory and\ndepth image observations in several challenging synthetic scenarios and a real\nimage sequence.",
    "descriptor": "\nComments: 22 pages, 23 Figures. Accepted for 3DV 2021. Project website: this https URL\n",
    "authors": [
      "Michael Strecke",
      "Joerg Stueckler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.15318"
  },
  {
    "id": "arXiv:2111.15319",
    "title": "A framework to measure the robustness of programs in the unpredictable  environment",
    "abstract": "Due to the diffusion of IoT, modern software systems are often thought to\ncontrol and coordinate smart devices in order to manage assets and resources,\nand to guarantee efficient behaviours. For this class of systems, which\ninteract extensively with humans and with their environment, it is thus crucial\nto guarantee their correct behaviour in order to avoid unexpected and possibly\ndangerous situations. In this paper we will present a framework that allows us\nto measure the robustness of systems. This is the ability of a program to\ntolerate changes in the environmental conditions and preserving the original\nbehaviour. In the proposed framework, the interaction of a program with its\nenvironment is represented as a sequence of random variables describing how\nboth evolve in time. For this reason, the considered measures will be defined\namong probability distributions of observed data. The proposed framework will\nbe then used to define the notions of adaptability and reliability. The former\nindicates the ability of a program to absorb perturbation on environmental\nconditions after a given amount of time. The latter expresses the ability of a\nprogram to maintain its intended behaviour (up-to some reasonable tolerance)\ndespite the presence of perturbations in the environment. Moreover, an\nalgorithm, based on statistical inference, it proposed to evaluate the proposed\nmetric and the aforementioned properties. Throughout the paper, two case\nstudies are used to the describe and evaluate the proposed approach.",
    "descriptor": "",
    "authors": [
      "Valentina Castiglioni",
      "Michele Loreti",
      "Simone Tini"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.15319"
  },
  {
    "id": "arXiv:2111.15322",
    "title": "Challenges in Developing LRs for Non-Scheduled Languages: A Case of  Magahi",
    "abstract": "Magahi is an Indo-Aryan Language, spoken mainly in the Eastern parts of\nIndia. Despite having a significant number of speakers, there has been\nvirtually no language resource (LR) or language technology (LT) developed for\nthe language, mainly because of its status as a non-scheduled language. The\npresent paper describes an attempt to develop an annotated corpus of Magahi.\nThe data is mainly taken from a couple of blogs in Magahi, some collection of\nstories in Magahi and the recordings of conversation in Magahi and it is\nannotated at the POS level using BIS tagset.",
    "descriptor": "",
    "authors": [
      "Ritesh Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15322"
  },
  {
    "id": "arXiv:2111.15324",
    "title": "Uniform convergence for sequences of best L^{p} approximation",
    "abstract": "Let $f$ be a continuous monotone real function defined on a compact interval\n$[a,b]$ of the real line. Given a sequence of partitions of $[a,b]$, $%\n\\Delta_n $, $\\left\\Vert {\\Delta }_{n}\\right\\Vert \\rightarrow 0$, and given\n$l\\geq 0,m\\geq 1$, let $\\mathbf{S}_{m}^{l}(\\Delta _{n}) $ be the space of all\nfunctions with the same monotonicity of $f$ that are $% \\Delta_n$-piecewise\npolynomial of order $m$ and that belong to the smoothness class $C^{l}[a,b]$.\nIn this paper we show that, for any $m\\geq 2l+1$, $\\bullet$ sequences of best\n$L^p$-approximation in $\\mathbf{S}_{m}^{l}(\\Delta _{n})$ converge uniformly to\n$f$ on any compact subinterval of $(a,b)$; $\\bullet$ sequences of best\n$L^p$-approximation in $\\mathbf{S}_{m}^{0}(\\Delta _{n})$ converge uniformly to\n$f$ on the whole interval $[a,b] $.",
    "descriptor": "\nComments: 16 pages, not submitted to any journal at the moment\n",
    "authors": [
      "Donatella Bongiorno",
      "Lucian Coroianu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.15324"
  },
  {
    "id": "arXiv:2111.15330",
    "title": "Sublinear-time Reductions for Big Data Computing",
    "abstract": "With the rapid popularization of big data, the dichotomy between tractable\nand intractable problems in big data computing has been shifted. Sublinear\ntime, rather than polynomial time, has recently been regarded as the new\nstandard of tractability in big data computing. This change brings the demand\nfor new methodologies in computational complexity theory in the context of big\ndata. Based on the prior work for sublinear-time complexity classes\n\\cite{DBLP:journals/tcs/GaoLML20}, this paper focuses on sublinear-time\nreductions specialized for problems in big data computing. First, the\npseudo-sublinear-time reduction is proposed and the complexity classes\n\\Pproblem and \\PsT are proved to be closed under it. To establish\n\\PsT-intractability for certain problems in \\Pproblem, we find the first\nproblem in $\\Pproblem \\setminus \\PsT$. Using the pseudo-sublinear-time\nreduction, we prove that the nearest edge query is in \\PsT but the algebraic\nequation root problem is not. Then, the pseudo-polylog-time reduction is\nintroduced and the complexity class \\PsPL is proved to be closed under it. The\n\\PsT-completeness under it is regarded as an evidence that some problems can\nnot be solved in polylogarithmic time after a polynomial-time preprocessing,\nunless \\PsT = \\PsPL. We prove that all \\PsT-complete problems are also\n\\Pproblem-complete, which gives a further direction for identifying\n\\PsT-complete problems.",
    "descriptor": "",
    "authors": [
      "Xiangyu Gao",
      "Jianzhong Li",
      "Dongjing Miao"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.15330"
  },
  {
    "id": "arXiv:2111.15338",
    "title": "Towards Ontological Conversation Interpretation: A Method for Ontology  Creation from Medical Guidelines",
    "abstract": "The automated capturing and summarization of medical consultations aims to\nreduce the administrative burden in healthcare. Consultations are structured\nconversations that broadly follow a guideline with a systematic examination of\npredefined observations and symptoms to diagnose and treat well-defined\nconditions. While the administrative burden could be relieved via automated\nconversation summarization systems, the availability of medical ontologies for\nthe interpretation of the medical knowledge is still an obstacle. This paper\nintroduces ontological conversation summarization by formalizing the\nrepresentation of medical guidelines to develop a method for the systematic\nconstruction of ontologies from the human anatomy and medical guidelines. The\nwell-known SNOMED CT nomenclature and medical guidelines from a medical\nauthority in the Netherlands are used to develop: (i) a formalism for the\ntarget ontologies in the form of a Patient Medical Ontology (PMO), and (ii) a\nprocedural method to develop such ontologies expressed in the form of a\nProcess-Deliverable Diagram model. The PMO of the medical condition of ear\ncanal inflammation (Otitis Externa) is created to validate the method.",
    "descriptor": "",
    "authors": [
      "Omar ElAssy",
      "Rik de Vendt",
      "Fabiano Dalpiaz",
      "Sjaak Brinkkemper"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.15338"
  },
  {
    "id": "arXiv:2111.15339",
    "title": "RadioWeaves for Extreme Spatial Multiplexing in Indoor Environments",
    "abstract": "With the advances in virtual and augmented reality, gaming applications, and\nentertainment, certain indoor scenarios will require vastly higher capacity\nthan what can be delivered by 5G. In this paper, we focus on massive MIMO for\nindoor environments. We provide a case study of the distributed deployment of\nthe antenna elements over the walls of a room and not restricting the antenna\nseparation to be half the wavelength. This is a new paradigm of massive MIMO\nantenna deployment, introduced under the name RadioWeaves. We investigate\ndifferent antenna deployment scenarios in line of sight communication. We\nobserve that the RadioWeaves deployment can spatially separate users much\nbetter than a conventional co-located deployment, which outweighs the losses\ncaused by grating lobes and thus saves a lot on transmit power. Through\nsimulations, we show that the RadioWeaves technology can provide high rates to\nmultiple users by spending very little power at the transmitter compared to a\nco-located deployment.",
    "descriptor": "\nComments: 5 pages, 4 figures. Published in 2020 54th Asilomar Conference on Signals, Systems, and Computers\n",
    "authors": [
      "Unnikrishnan Kunnath Ganesan",
      "Emil Bj\u00f6rnson",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.15339"
  },
  {
    "id": "arXiv:2111.15340",
    "title": "MC-SSL0.0: Towards Multi-Concept Self-Supervised Learning",
    "abstract": "Self-supervised pretraining is the method of choice for natural language\nprocessing models and is rapidly gaining popularity in many vision tasks.\nRecently, self-supervised pretraining has shown to outperform supervised\npretraining for many downstream vision applications, marking a milestone in the\narea. This superiority is attributed to the negative impact of incomplete\nlabelling of the training images, which convey multiple concepts, but are\nannotated using a single dominant class label. Although Self-Supervised\nLearning (SSL), in principle, is free of this limitation, the choice of pretext\ntask facilitating SSL is perpetuating this shortcoming by driving the learning\nprocess towards a single concept output. This study aims to investigate the\npossibility of modelling all the concepts present in an image without using\nlabels. In this aspect the proposed SSL frame-work MC-SSL0.0 is a step towards\nMulti-Concept Self-Supervised Learning (MC-SSL) that goes beyond modelling\nsingle dominant label in an image to effectively utilise the information from\nall the concepts present in it. MC-SSL0.0 consists of two core design concepts,\ngroup masked model learning and learning of pseudo-concept for data token using\na momentum encoder (teacher-student) framework. The experimental results on\nmulti-label and multi-class image classification downstream tasks demonstrate\nthat MC-SSL0.0 not only surpasses existing SSL methods but also outperforms\nsupervised transfer learning. The source code will be made publicly available\nfor community to train on bigger corpus.",
    "descriptor": "",
    "authors": [
      "Sara Atito",
      "Muhammad Awais",
      "Ammarah Farooq",
      "Zhenhua Feng",
      "Josef Kittler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15340"
  },
  {
    "id": "arXiv:2111.15341",
    "title": "ZZ-Net: A Universal Rotation Equivariant Architecture for 2D Point  Clouds",
    "abstract": "In this paper, we are concerned with rotation equivariance on 2D point cloud\ndata. We describe a particular set of functions able to approximate any\ncontinuous rotation equivariant and permutation invariant function. Based on\nthis result, we propose a novel neural network architecture for processing 2D\npoint clouds and we prove its universality for approximating functions\nexhibiting these symmetries.\nWe also show how to extend the architecture to accept a set of 2D-2D\ncorrespondences as indata, while maintaining similar equivariance properties.\nExperiments are presented on the estimation of essential matrices in stereo\nvision.",
    "descriptor": "\nComments: 9 figures\n",
    "authors": [
      "Georg B\u00f6kman",
      "Fredrik Kahl",
      "Axel Flinth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15341"
  },
  {
    "id": "arXiv:2111.15342",
    "title": "SmartReviews: Towards Human- and Machine-actionable Representation of  Review Articles",
    "abstract": "Review articles are a means to structure state-of-the-art literature and to\norganize the growing number of scholarly publications. However, review articles\nare suffering from numerous limitations, weakening the impact the articles\ncould potentially have. A key limitation is the inability of machines to access\nand process knowledge presented within review articles. In this work, we\npresent SmartReviews, a review authoring and publishing tool, specifically\naddressing the limitations of review articles. The tool enables community-based\nauthoring of living articles, leveraging a scholarly knowledge graph to provide\nmachine-actionable knowledge. We evaluate the approach and tool by means of a\nSmartReview use case. The results indicate that the evaluated article is\nsuccessfully addressing the weaknesses of the current review practices.",
    "descriptor": "",
    "authors": [
      "Allard Oelen",
      "Markus Stocker",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2111.15342"
  },
  {
    "id": "arXiv:2111.15343",
    "title": "Fast and Real-time End to End Control in Autonomous Racing Cars Through  Representation Learning",
    "abstract": "The challenges presented in an autonomous racing situation are distinct from\nthose faced in regular autonomous driving and require faster end-to-end\nalgorithms and consideration of a longer horizon in determining optimal current\nactions keeping in mind upcoming maneuvers and situations. In this paper, we\npropose an end-to-end method for autonomous racing that takes in as inputs\nvideo information from an onboard camera and determines final steering and\nthrottle control actions. We use the following split to construct such a method\n(1) learning a low dimensional representation of the scene, (2) pre-generating\nthe optimal trajectory for the given scene, and (3) tracking the predicted\ntrajectory using a classical control method. In learning a low-dimensional\nrepresentation of the scene, we use intermediate representations with a novel\nunsupervised trajectory planner to generate expert trajectories, and hence\nutilize them to directly predict race lines from a given front-facing input\nimage. Thus, the proposed algorithm employs the best of two worlds - the\nrobustness of learning-based approaches to perception and the accuracy of\noptimization-based approaches for trajectory generation in an end-to-end\nlearning-based framework. We deploy and demonstrate our framework on CARLA, a\nphotorealistic simulator for testing self-driving cars in realistic\nenvironments.",
    "descriptor": "",
    "authors": [
      "Praveen Venkatesh",
      "Rwik Rana",
      "Harish PM"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.15343"
  },
  {
    "id": "arXiv:2111.15344",
    "title": "Material Classification Using Active Temperature Controllable Robotic  Gripper",
    "abstract": "Recognition techniques allow robots to make proper planning and control\nstrategies to manipulate various objects. Object recognition is more reliable\nwhen made by combining several percepts, e.g., vision and haptics. One of the\ndistinguishing features of each object's material is its heat properties, and\nclassification can exploit heat transfer, similarly to human thermal sensation.\nThermal-based recognition has the advantage of obtaining contact surface\ninformation in realtime by simply capturing temperature change using a tiny and\ncheap sensor. However, heat transfer between a robot surface and a contact\nobject is strongly affected by the initial temperature and environmental\nconditions. A given object's material cannot be recognized when its temperature\nis the same as the robotic grippertip. We present a material classification\nsystem using active temperature controllable robotic gripper to induce heat\nflow. Subsequently, our system can recognize materials independently from their\nambient temperature. The robotic gripper surface can be regulated to any\ntemperature that differentiates it from the touched object's surface. We\nconducted some experiments by integrating the temperature control system with\nthe Academic SCARA Robot, classifying them based on a long short-term memory\n(LSTM) using temperature data obtained from grasping target objects.",
    "descriptor": "",
    "authors": [
      "Yukiko Osawa",
      "Kei Kase",
      "Yukiyasu Domae",
      "Yoshiyuki Furukawa",
      "Abderrahmane Kheddar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15344"
  },
  {
    "id": "arXiv:2111.15347",
    "title": "Adversarial Factor Models for the Generation of Improved Autism  Diagnostic Biomarkers",
    "abstract": "Discovering reliable measures that inform on autism spectrum disorder (ASD)\ndiagnosis is critical for providing appropriate and timely treatment for this\nneurodevelopmental disorder. In this work we present applications of\nadversarial linear factor models in the creation of improved biomarkers for ASD\ndiagnosis. First, we demonstrate that an adversarial linear factor model can be\nused to remove confounding information from our biomarkers, ensuring that they\ncontain only pertinent information on ASD. Second, we show this same model can\nbe used to learn a disentangled representation of multimodal biomarkers that\nresults in an increase in predictive performance. These results demonstrate\nthat adversarial methods can address both biomarker confounds and improve\nbiomarker predictive performance.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "William E. Carson IV",
      "Dmitry Isaev",
      "Samatha Major",
      "Guillermo Sapiro",
      "Geraldine Dawson",
      "David Carlson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15347"
  },
  {
    "id": "arXiv:2111.15348",
    "title": "Overcoming limited battery data challenges: A coupled neural network  approach",
    "abstract": "The Electric Vehicle (EV) Industry has seen extraordinary growth in the last\nfew years. This is primarily due to an ever increasing awareness of the\ndetrimental environmental effects of fossil fuel powered vehicles and\navailability of inexpensive Lithium-ion batteries (LIBs). In order to safely\ndeploy these LIBs in Electric Vehicles, certain battery states need to be\nconstantly monitored to ensure safe and healthy operation. The use of Machine\nLearning to estimate battery states such as State-of-Charge and State-of-Health\nhave become an extremely active area of research. However, limited availability\nof open-source diverse datasets has stifled the growth of this field, and is a\nproblem largely ignored in literature. In this work, we propose a novel method\nof time-series battery data augmentation using deep neural networks. We\nintroduce and analyze the method of using two neural networks working together\nto alternatively produce synthetic charging and discharging battery profiles.\nOne model produces battery charging profiles, and another produces battery\ndischarging profiles. The proposed approach is evaluated using few public\nbattery datasets to illustrate its effectiveness, and our results show the\nefficacy of this approach to solve the challenges of limited battery data. We\nalso test this approach on dynamic Electric Vehicle drive cycles as well.",
    "descriptor": "\nComments: Published at International Journal of Energy Research\n",
    "authors": [
      "Aniruddh Herle",
      "Janamejaya Channegowda",
      "Dinakar Prabhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15348"
  },
  {
    "id": "arXiv:2111.15357",
    "title": "Induced betweenness in order-theoretic trees",
    "abstract": "The ternary relation $B(x,y,z)$ of betweenness states that an element $y$ is\nbetween the elements $x$ and $z$, in some sense depending on the considered\nstructure. In a partially ordered set $(N,\\leq)$, $B(x,y,z):\\Longleftrightarrow\nx<y<z\\vee z<y<x$. The corresponding betweenness structure is $(N,B)$. The class\nof betweenness structures of linear orders is first-order definable. That of\npartial orders is monadic second-order definable. An order-theoretic tree is a\npartial order such that the set of elements larger that any element is linearly\nordered and any two elements have an upper-bound. Finite or infinite rooted\ntrees ordered by the ancestor relation are order-theoretic trees. In an\norder-theoretic tree, we define $B(x,y,z)$ to mean that $x<y<z$ or $z<y<x$ or\n$x<y\\leq x\\sqcup z$ or $z<y\\leq x\\sqcup z$ provided the least upper-bound\n$x\\sqcup z$ of $x$ and $z$ is defined when $x$ and $z$ are incomparable. In a\nprevious article, we established that the corresponding class of betweenness\nstructures is monadic second-order definable.We prove here that the induced\nsubstructures of the betweenness structures of the countable order-theoretic\ntrees form a monadic second-order definable class, denoted by IBO. The proof\nuses a variant of cographs, the partitioned probe cographs, and their known six\nfinite minimal excluded induced subgraphs called the bounds of the class. This\nproof links two apparently unrelated topics: cographs and order-theoretic\ntrees.However, the class IBO has finitely many bounds, i.e., minimal excluded\nfinite induced substructures. Hence it is first-order definable. The proof of\nfiniteness uses well-quasi-orders and does not provide the finite list of\nbounds. Hence, the associated first-order defining sentence is not known.",
    "descriptor": "",
    "authors": [
      "Bruno Courcelle"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.15357"
  },
  {
    "id": "arXiv:2111.15361",
    "title": "Seeking Salient Facial Regions for Cross-Database Micro-Expression  Recognition",
    "abstract": "This paper focuses on the research of cross-database micro-expression\nrecognition, in which the training and test micro-expression samples belong to\ndifferent microexpression databases. Mismatched feature distributions between\nthe training and testing micro-expression feature degrade the performance of\nmost well-performing micro-expression methods. To deal with cross-database\nmicro-expression recognition, we propose a novel domain adaption method called\nTransfer Group Sparse Regression (TGSR). TGSR learns a sparse regression matrix\nfor selecting salient facial local regions and the corresponding relationship\nof the training set and test set. We evaluate our TGSR model in CASME II and\nSMIC databases. Experimental results show that the proposed TGSR achieves\nsatisfactory performance and outperforms most state-of-the-art subspace\nlearning-based domain adaption methods.",
    "descriptor": "",
    "authors": [
      "Xingxun Jiang",
      "Yuan Zong",
      "Wenming Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15361"
  },
  {
    "id": "arXiv:2111.15362",
    "title": "ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image  Prior",
    "abstract": "Recent works show that convolutional neural network (CNN) architectures have\na spectral bias towards lower frequencies, which has been leveraged for various\nimage restoration tasks in the Deep Image Prior (DIP) framework. The benefit of\nthe inductive bias the network imposes in the DIP framework depends on the\narchitecture. Therefore, researchers have studied how to automate the search to\ndetermine the best-performing model. However, common neural architecture search\n(NAS) techniques are resource and time-intensive. Moreover, best-performing\nmodels are determined for a whole dataset of images instead of for each image\nindependently, which would be prohibitively expensive. In this work, we first\nshow that optimal neural architectures in the DIP framework are\nimage-dependent. Leveraging this insight, we then propose an image-specific NAS\nstrategy for the DIP framework that requires substantially less training than\ntypical NAS approaches, effectively enabling image-specific NAS. For a given\nimage, noise is fed to a large set of untrained CNNs, and their outputs' power\nspectral densities (PSD) are compared to that of the corrupted image using\nvarious metrics. Based on this, a small cohort of image-specific architectures\nis chosen and trained to reconstruct the corrupted image. Among this cohort,\nthe model whose reconstruction is closest to the average of the reconstructed\nimages is chosen as the final model. We justify the proposed strategy's\neffectiveness by (1) demonstrating its performance on a NAS Dataset for DIP\nthat includes 500+ models from a particular search space (2) conducting\nextensive experiments on image denoising, inpainting, and super-resolution\ntasks. Our experiments show that image-specific metrics can reduce the search\nspace to a small cohort of models, of which the best model outperforms current\nNAS approaches for image restoration.",
    "descriptor": "",
    "authors": [
      "Metin Ersin Arican",
      "Ozgur Kara",
      "Gustav Bredell",
      "Ender Konukoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15362"
  },
  {
    "id": "arXiv:2111.15363",
    "title": "Voint Cloud: Multi-View Point Cloud Representation for 3D Understanding",
    "abstract": "Multi-view projection methods have demonstrated promising performance on 3D\nunderstanding tasks like 3D classification and segmentation. However, it\nremains unclear how to combine such multi-view methods with the widely\navailable 3D point clouds. Previous methods use unlearned heuristics to combine\nfeatures at the point level. To this end, we introduce the concept of the\nmulti-view point cloud (Voint cloud), representing each 3D point as a set of\nfeatures extracted from several view-points. This novel 3D Voint cloud\nrepresentation combines the compactness of 3D point cloud representation with\nthe natural view-awareness of multi-view representation. Naturally, we can\nequip this new representation with convolutional and pooling operations. We\ndeploy a Voint neural network (VointNet) with a theoretically established\nfunctional form to learn representations in the Voint space. Our novel\nrepresentation achieves state-of-the-art performance on 3D classification and\nretrieval on ScanObjectNN, ModelNet40, and ShapeNet Core55. Additionally, we\nachieve competitive performance for 3D semantic segmentation on ShapeNet Parts.\nFurther analysis shows that VointNet improves the robustness to rotation and\nocclusion compared to other methods.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Abdullah Hamdi",
      "Silvio Giancola",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15363"
  },
  {
    "id": "arXiv:2111.15366",
    "title": "AI and the Everything in the Whole Wide World Benchmark",
    "abstract": "There is a tendency across different subfields in AI to valorize a small\ncollection of influential benchmarks. These benchmarks operate as stand-ins for\na range of anointed common problems that are frequently framed as foundational\nmilestones on the path towards flexible and generalizable AI systems.\nState-of-the-art performance on these benchmarks is widely understood as\nindicative of progress towards these long-term goals. In this position paper,\nwe explore the limits of such benchmarks in order to reveal the construct\nvalidity issues in their framing as the functionally \"general\" broad measures\nof progress they are set up to be.",
    "descriptor": "\nComments: Accepted in NeurIPS 2021 Benchmarks and Datasets track\n",
    "authors": [
      "Inioluwa Deborah Raji",
      "Emily M. Bender",
      "Amandalynne Paullada",
      "Emily Denton",
      "Alex Hanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2111.15366"
  },
  {
    "id": "arXiv:2111.15373",
    "title": "ColibriDoc: An Eye-in-Hand Autonomous Trocar Docking System",
    "abstract": "Retinal surgery is a complex medical procedure that requires exceptional\nexpertise and dexterity. For this purpose, several robotic platforms are\ncurrently being developed to enable or improve the outcome of microsurgical\ntasks. Since the control of such robots is often designed for navigation inside\nthe eye in proximity to the retina, successful trocar docking and inserting the\ninstrument into the eye represents an additional cognitive effort, and is,\ntherefore, one of the open challenges in robotic retinal surgery. For this\npurpose, we present a platform for autonomous trocar docking that combines\ncomputer vision and a robotic setup. Inspired by the Cuban Colibri\n(hummingbird) aligning its beak to a flower using only vision, we mount a\ncamera onto the endeffector of a robotic system. By estimating the position and\npose of the trocar, the robot is able to autonomously align and navigate the\ninstrument towards the Trocar's Entry Point (TEP) and finally perform the\ninsertion. Our experiments show that the proposed method is able to accurately\nestimate the position and pose of the trocar and achieve repeatable autonomous\ndocking. The aim of this work is to reduce the complexity of robotic setup\npreparation prior to the surgical task and therefore, increase the\nintuitiveness of the system integration into the clinical workflow.",
    "descriptor": "",
    "authors": [
      "Shervin Dehghani",
      "Michael Sommersperger",
      "Junjie Yang",
      "Benjamin Busam",
      "Kai Huang",
      "Peter Gehlbach",
      "Iulian Iordachita",
      "Nassir Navab",
      "M. Ali Nasseri"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15373"
  },
  {
    "id": "arXiv:2111.15376",
    "title": "Reconstruction Student with Attention for Student-Teacher Pyramid  Matching",
    "abstract": "Anomaly detection and localization are important problems in computer vision.\nRecently, Convolutional Neural Network (CNN) has been used for visual\ninspection. In particular, the scarcity of anomalous samples increases the\ndifficulty of this task, and unsupervised leaning based methods are attracting\nattention. We focus on Student-Teacher Feature Pyramid Matching (STPM) which\ncan be trained from only normal images with small number of epochs. Here we\nproposed a powerful method which compensates for the shortcomings of STPM.\nProposed method consists of two students and two teachers that a pair of\nstudent-teacher network is the same as STPM. The other student-teacher network\nhas a role to reconstruct the features of normal products. By reconstructing\nthe features of normal products from an abnormal image, it is possible to\ndetect abnormalities with higher accuracy by taking the difference between\nthem. The new student-teacher network uses attention modules and different\nteacher network from the original STPM. Attention mechanism acts to\nsuccessfully reconstruct the normal regions in an input image. Different\nteacher network prevents looking at the same regions as the original STPM. Six\nanomaly maps obtained from the two student-teacher networks are used to\ncalculate the final anomaly map. Student-teacher network for reconstructing\nfeatures improved AUC scores for pixel level and image level in comparison with\nthe original STPM.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Shinji Yamada",
      "Kazuhiro Hotta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.15376"
  },
  {
    "id": "arXiv:2111.15377",
    "title": "Passivity of Electrical Transmission Networks modelled using Rectangular  and Polar D-Q variables",
    "abstract": "The increasing penetration of converter-interfaced distributed energy\nresources has brought out the need to develop decentralized criteria that would\nensure the small-signal stability of the inter-connected system. Passivity of\nthe D-Q admittance or impedance is a promising candidate for such an approach.\nIt is facilitated by the inherent passivity of the D-Q impedance of an\nelectrical network. However, the passivity conditions are generally restrictive\nand cannot be complied with in the low frequency range by the D-Q admittance of\ndevices that follow typical power control strategies. However, this does not\nimply that the system is unstable. Therefore, alternative formulations that use\npolar variables (magnitude/phase angle of voltages and real/reactive power\ninjection instead of the D-Q components of voltages and currents) are\ninvestigated. Passivity properties of the electrical network using these\ndifferent formulations are brought out in this paper through analytical results\nand illustrative examples.",
    "descriptor": "",
    "authors": [
      "Kaustav Dey",
      "A. M. Kulkarni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.15377"
  },
  {
    "id": "arXiv:2111.15378",
    "title": "Clustering-Based Activity Detection Algorithms for Grant-Free Random  Access in Cell-Free Massive MIMO",
    "abstract": "Future wireless networks need to support massive machine type communication\n(mMTC) where a massive number of devices accesses the network and massive MIMO\nis a promising enabling technology. Massive access schemes have been studied\nfor co-located massive MIMO arrays. In this paper, we investigate the activity\ndetection in grant-free random access for mMTC in cell-free massive MIMO\nnetworks using distributed arrays. Each active device transmits a\nnon-orthogonal pilot sequence to the access points (APs) and the APs send the\nreceived signals to a central processing unit (CPU) for joint activity\ndetection. The maximum likelihood device activity detection problem is\nformulated and algorithms for activity detection in cell-free massive MIMO are\nprovided to solve it. The simulation results show that the macro-diversity gain\nprovided by the cell-free architecture improves the activity detection\nperformance compared to co-located architecture when the coverage area is\nlarge.",
    "descriptor": "\nComments: 12 pages, 9 figures. Published in IEEE Transactions on Communications, Vol. 69, No. 11, pp. 7520 - 7530, November 2021\n",
    "authors": [
      "Unnikrishnan Kunnath Ganesan",
      "Emil Bj\u00f6rnson",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.15378"
  },
  {
    "id": "arXiv:2111.15379",
    "title": "Text classification problems via BERT embedding method and graph  convolutional neural network",
    "abstract": "This paper presents the novel way combining the BERT embedding method and the\ngraph convolutional neural network. This combination is employed to solve the\ntext classification problem. Initially, we apply the BERT embedding method to\nthe texts (in the BBC news dataset and the IMDB movie reviews dataset) in order\nto transform all the texts to numerical vector. Then, the graph convolutional\nneural network will be applied to these numerical vectors to classify these\ntexts into their ap-propriate classes/labels. Experiments show that the\nperformance of the graph convolutional neural network model is better than the\nperfor-mances of the combination of the BERT embedding method with clas-sical\nmachine learning models.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Loc Hoang Tran",
      "Tuan Tran",
      "An Mai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.15379"
  },
  {
    "id": "arXiv:2111.15380",
    "title": "Transient Stability of Low-Inertia Power Systems with Inverter-Based  Generation",
    "abstract": "This paper studies the transient stability of low-inertia power systems with\ninverter-based generation (IBG) and proposes a sufficient stability criterion.\nIn low-inertia grids, interactions are induced between electromagnetic dynamics\nof the IBG and electromechanical dynamics of the synchronous generator (SG)\nunder fault. For this, a hybrid IBG-SG system is established and a\ndelta-power-frequency model is developed. Based on the model, new mechanisms\ndifferent from conventional power systems are discovered from the energy\nperspective. Firstly, two types of loss of synchronization (LOS) are\nidentified, depending on the relative power imbalance due to the mismatch\nbetween the inertia of IBG and SG under fault. Secondly, the relative angle and\nfrequency will jump at the moment of a fault, thus affecting the energy of the\nsystem. Thirdly, the cosine damping coefficient results in a positive energy\ndissipation, therefore contributing to the stabilization of the system. A\nunified criterion for identifying both two types of LOS is proposed employing\nthe energy function method. The criterion is proved to be a sufficient\nstability condition in addressing the effects of the jumps and the cosine\ndamping. Simulation results are provided to verify the new mechanisms and\neffectiveness of the criterion.",
    "descriptor": "",
    "authors": [
      "Changjun He",
      "Xiuqiang He",
      "Hua Geng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.15380"
  },
  {
    "id": "arXiv:2111.15382",
    "title": "Continuous Control With Ensemble Deep Deterministic Policy Gradients",
    "abstract": "The growth of deep reinforcement learning (RL) has brought multiple exciting\ntools and methods to the field. This rapid expansion makes it important to\nunderstand the interplay between individual elements of the RL toolbox. We\napproach this task from an empirical perspective by conducting a study in the\ncontinuous control setting. We present multiple insights of fundamental nature,\nincluding: an average of multiple actors trained from the same data boosts\nperformance; the existing methods are unstable across training runs, epochs of\ntraining, and evaluation runs; a commonly used additive action noise is not\nrequired for effective training; a strategy based on posterior sampling\nexplores better than the approximated UCB combined with the weighted Bellman\nbackup; the weighted Bellman backup alone cannot replace the clipped double\nQ-Learning; the critics' initialization plays the major role in ensemble-based\nactor-critic exploration. As a conclusion, we show how existing tools can be\nbrought together in a novel way, giving rise to the Ensemble Deep Deterministic\nPolicy Gradients (ED2) method, to yield state-of-the-art results on continuous\ncontrol tasks from OpenAI Gym MuJoCo. From the practical side, ED2 is\nconceptually straightforward, easy to code, and does not require knowledge\noutside of the existing RL toolbox.",
    "descriptor": "",
    "authors": [
      "Piotr Januszewski",
      "Mateusz Olko",
      "Micha\u0142 Kr\u00f3likowski",
      "Jakub \u015awi\u0105tkowski",
      "Marcin Andrychowicz",
      "\u0141ukasz Kuci\u0144ski",
      "Piotr Mi\u0142o\u015b"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15382"
  },
  {
    "id": "arXiv:2111.15388",
    "title": "A Combinatorial Approach to Flag Codes",
    "abstract": "In network coding, a flag code is a collection of flags, that is, sequences\nof nested subspaces of a vector space over a finite field. Due to its\ndefinition as the sum of the corresponding subspace distances, the flag\ndistance parameter encloses a hidden combinatorial structure. To bring it to\nlight, in this paper, we interpret flag distances by means of distance paths\ndrawn in a convenient distance support. The shape of such a support allows us\nto create an ad hoc associated Ferrers diagram frame where we develop a\ncombinatorial approach to flag codes by relating the possible realizations of\ntheir minimum distance to different partitions of appropriate integers. This\nnovel viewpoint permits to establish noteworthy connections between the flag\ncode parameters and the ones of its projected codes in terms of well known\nconcepts coming from the classical partitions theory.",
    "descriptor": "",
    "authors": [
      "Clementa Alonso-Gonz\u00e1lez",
      "Miguel \u00c1ngel Navarro-P\u00e9rez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.15388"
  },
  {
    "id": "arXiv:2111.15397",
    "title": "NeuralProphet: Explainable Forecasting at Scale",
    "abstract": "We introduce NeuralProphet, a successor to Facebook Prophet, which set an\nindustry standard for explainable, scalable, and user-friendly forecasting\nframeworks. With the proliferation of time series data, explainable forecasting\nremains a challenging task for business and operational decision making. Hybrid\nsolutions are needed to bridge the gap between interpretable classical methods\nand scalable deep learning models. We view Prophet as a precursor to such a\nsolution. However, Prophet lacks local context, which is essential for\nforecasting the near-term future and is challenging to extend due to its Stan\nbackend.\nNeuralProphet is a hybrid forecasting framework based on PyTorch and trained\nwith standard deep learning methods, making it easy for developers to extend\nthe framework. Local context is introduced with auto-regression and covariate\nmodules, which can be configured as classical linear regression or as Neural\nNetworks. Otherwise, NeuralProphet retains the design philosophy of Prophet and\nprovides the same basic model components.\nOur results demonstrate that NeuralProphet produces interpretable forecast\ncomponents of equivalent or superior quality to Prophet on a set of generated\ntime series. NeuralProphet outperforms Prophet on a diverse collection of\nreal-world datasets. For short to medium-term forecasts, NeuralProphet improves\nforecast accuracy by 55 to 92 percent.",
    "descriptor": "\nComments: NeuralProphet can be installed with pip or from this https URL - Documentation is available at this https URL\n",
    "authors": [
      "Oskar Triebe",
      "Hansika Hewamalage",
      "Polina Pilyugina",
      "Nikolay Laptev",
      "Christoph Bergmeir",
      "Ram Rajagopal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.15397"
  },
  {
    "id": "arXiv:2111.15399",
    "title": "Evaluating Blockchain Application Requirements and their Satisfaction in  Hyperledger Fabric",
    "abstract": "Blockchain applications may offer better fault-tolerance, integrity,\ntraceability and transparency compared to centralized solutions. Despite these\nbenefits, few businesses switch to blockchain-based applications. Industries\nworry that the current blockchain implementations do not meet their\nrequirements, e.g., when it comes to scalability, throughput or latency.\nHyperledger Fabric (HLF) is a permissioned blockchain infrastructure that aims\nto meet enterprise needs and provides a highly modular and well-conceived\narchitecture. In this paper, we survey and analyse requirements of blockchain\napplications in respect to their underlying infrastructure by focusing mainly\non performance and resilience characteristics. Subsequently, we discuss to what\nextent Fabric's current design allows it to meet these requirements. We further\nevaluate the performance of Hyperledger Fabric 2.2 simulating different use\ncase scenarios by comparing single with multi ordering service performance and\nconducting an evaluation with mixed workloads.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Sadok Ben Toumia",
      "Christian Berger",
      "Hans P. Reiser"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.15399"
  },
  {
    "id": "arXiv:2111.15400",
    "title": "CT-block: a novel local and global features extractor for point cloud",
    "abstract": "Deep learning on the point cloud is increasingly developing. Grouping the\npoint with its neighbors and conducting convolution-like operation on them can\nlearn the local feature of the point cloud, but this method is weak to extract\nthe long-distance global feature. Performing the attention-based transformer on\nthe whole point cloud can effectively learn the global feature of it, but this\nmethod is hardly to extract the local detailed feature. In this paper, we\npropose a novel module that can simultaneously extract and fuse local and\nglobal features, which is named as CT-block. The CT-block is composed of two\nbranches, where the letter C represents the convolution-branch and the letter T\nrepresents the transformer-branch. The convolution-branch performs convolution\non the grouped neighbor points to extract the local feature. Meanwhile, the\ntransformer-branch performs offset-attention process on the whole point cloud\nto extract the global feature. Through the bridge constructed by the feature\ntransmission element in the CT-block, the local and global features guide each\nother during learning and are fused effectively. We apply the CT-block to\nconstruct point cloud classification and segmentation networks, and evaluate\nthe performance of them by several public datasets. The experimental results\nshow that, because the features learned by CT-block are much expressive, the\nperformance of the networks constructed by the CT-block on the point cloud\nclassification and segmentation tasks achieve state of the art.",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Shangwei Guo",
      "Jun Li",
      "Zhengchao Lai",
      "Xiantong Meng",
      "Shaokun Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15400"
  },
  {
    "id": "arXiv:2111.15404",
    "title": "Probabilistic Estimation of 3D Human Shape and Pose with a Semantic  Local Parametric Model",
    "abstract": "This paper addresses the problem of 3D human body shape and pose estimation\nfrom RGB images. Some recent approaches to this task predict probability\ndistributions over human body model parameters conditioned on the input images.\nThis is motivated by the ill-posed nature of the problem wherein multiple 3D\nreconstructions may match the image evidence, particularly when some parts of\nthe body are locally occluded. However, body shape parameters in widely-used\nbody models (e.g. SMPL) control global deformations over the whole body\nsurface. Distributions over these global shape parameters are unable to\nmeaningfully capture uncertainty in shape estimates associated with\nlocally-occluded body parts. In contrast, we present a method that (i) predicts\ndistributions over local body shape in the form of semantic body measurements\nand (ii) uses a linear mapping to transform a local distribution over body\nmeasurements to a global distribution over SMPL shape parameters. We show that\nour method outperforms the current state-of-the-art in terms of\nidentity-dependent body shape estimation accuracy on the SSP-3D dataset, and a\nprivate dataset of tape-measured humans, by probabilistically-combining local\nbody measurement distributions predicted from multiple images of a subject.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Akash Sengupta",
      "Ignas Budvytis",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15404"
  },
  {
    "id": "arXiv:2111.15407",
    "title": "Monotone one-port circuits",
    "abstract": "Maximal monotonicity is explored as a generalization of the linear theory of\npassivity, aiming at an algorithmic input/output analysis of physical models.\nThe theory is developed for maximal monotone one-port circuits, formed by the\nseries and parallel interconnection of basic elements. An algorithmic method is\npresented for solving the periodic output of a periodically driven circuit\nusing a maximal monotone splitting algorithm, which allows computation to be\nseparated for each circuit component. A new splitting algorithm is presented,\nwhich applies to any monotone circuit defined as a port interconnection of\nmonotone elements.",
    "descriptor": "",
    "authors": [
      "Thomas Chaffey",
      "Rodolphe Sepulchre"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.15407"
  },
  {
    "id": "arXiv:2111.15413",
    "title": "Minor changes make a difference: a case study on the consistency of  UD-based dependency parsers",
    "abstract": "Many downstream applications are using dependency trees, and are thus relying\non dependency parsers producing correct, or at least consistent, output.\nHowever, dependency parsers are trained using machine learning, and are\ntherefore susceptible to unwanted inconsistencies due to biases in the training\ndata. This paper explores the effects of such biases in four languages -\nEnglish, Swedish, Russian, and Ukrainian - though an experiment where we study\nthe effect of replacing numerals in sentences. We show that such seemingly\ninsignificant changes in the input can cause large differences in the output,\nand suggest that data augmentation can remedy the problems.",
    "descriptor": "\nComments: Accepted to the 5th Workshop on Universal Dependencies at SyntaxFest 2021\n",
    "authors": [
      "Dmytro Kalpakchi",
      "Johan Boye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15413"
  },
  {
    "id": "arXiv:2111.15414",
    "title": "Neuron with Steady Response Leads to Better Generalization",
    "abstract": "Regularization can mitigate the generalization gap between training and\ninference by introducing inductive bias. Existing works have already proposed\nvarious inductive biases from diverse perspectives. However, to the best of our\nknowledge, none of them explores inductive bias from the perspective of\nclass-dependent response distribution of individual neurons. In this paper, we\nconduct a substantial analysis of the characteristics of such distribution.\nBased on the analysis results, we articulate the Neuron Steadiness Hypothesis:\nthe neuron with similar responses to instances of the same class leads to\nbetter generalization. Accordingly, we propose a new regularization method\ncalled Neuron Steadiness Regularization to reduce neuron intra-class response\nvariance. We conduct extensive experiments on Multilayer Perceptron,\nConvolutional Neural Network, and Graph Neural Network with popular benchmark\ndatasets of diverse domains, which show that our Neuron Steadiness\nRegularization consistently outperforms the vanilla version of models with\nsignificant gain and low additional overhead.",
    "descriptor": "",
    "authors": [
      "Qiang Fu",
      "Lun Du",
      "Haitao Mao",
      "Xu Chen",
      "Wei Fang",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15414"
  },
  {
    "id": "arXiv:2111.15415",
    "title": "Establishing the Price of Privacy in Federated Data Trading",
    "abstract": "Personal data is becoming one of the most essential resources in today's\ninformation-based society. Accordingly, there is a growing interest in data\nmarkets, which operate data trading services between data providers and data\nconsumers. One issue the data markets have to address is that of the potential\nthreats to privacy. Usually some kind of protection must be provided, which\ngenerally comes to the detriment of utility. A correct pricing mechanism for\nprivate data should therefore depend on the level of privacy. In this paper, we\npropose a model of data federation in which data providers, who are, generally,\nless influential on the market than data consumers, form a coalition for\ntrading their data, simultaneously shielding against privacy threats by means\nof differential privacy. Additionally, we propose a technique to price private\ndata, and an revenue-distribution mechanism to distribute the revenue fairly in\nsuch federation data trading environments. Our model also motivates the data\nproviders to cooperate with their respective federations, facilitating a fair\nand swift private data trading process. We validate our result through various\nexperiments, showing that the proposed methods provide benefits to both data\nproviders and consumers.",
    "descriptor": "",
    "authors": [
      "Kangsoo Jung",
      "Sayan Biswas",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.15415"
  },
  {
    "id": "arXiv:2111.15416",
    "title": "A Face Recognition System's Worst Morph Nightmare, Theoretically",
    "abstract": "It has been shown that Face Recognition Systems (FRSs) are vulnerable to\nmorphing attacks, but most research focusses on landmark-based morphs. A second\nmethod for generating morphs uses Generative Adversarial Networks, which\nresults in convincingly real facial images that can be almost as challenging\nfor FRSs as landmark-based attacks. We propose a method to create a third,\ndifferent type of morph, that has the advantage of being easier to train. We\nintroduce the theoretical concept of \\textit{worst-case morphs}, which are\nthose morphs that are most challenging for a fixed FRS. For a set of images and\ncorresponding embeddings in an FRS's latent space, we generate images that\napproximate these worst-case morphs using a mapping from embedding space back\nto image space. While the resulting images are not yet as challenging as other\nmorphs, they can provide valuable information in future research on Morphing\nAttack Detection (MAD) methods and on weaknesses of FRSs. Methods for MAD need\nto be validated on more varied morph databases. Our proposed method contributes\nto achieving such variation.",
    "descriptor": "",
    "authors": [
      "Una M. Kelly",
      "Raymond Veldhuis",
      "Luuk Spreeuwers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15416"
  },
  {
    "id": "arXiv:2111.15417",
    "title": "A Comparative Study of Transformers on Word Sense Disambiguation",
    "abstract": "Recent years of research in Natural Language Processing (NLP) have witnessed\ndramatic growth in training large models for generating context-aware language\nrepresentations. In this regard, numerous NLP systems have leveraged the power\nof neural network-based architectures to incorporate sense information in\nembeddings, resulting in Contextualized Word Embeddings (CWEs). Despite this\nprogress, the NLP community has not witnessed any significant work performing a\ncomparative study on the contextualization power of such architectures. This\npaper presents a comparative study and an extensive analysis of nine widely\nadopted Transformer models. These models are BERT, CTRL, DistilBERT,\nOpenAI-GPT, OpenAI-GPT2, Transformer-XL, XLNet, ELECTRA, and ALBERT. We\nevaluate their contextualization power using two lexical sample Word Sense\nDisambiguation (WSD) tasks, SensEval-2 and SensEval-3. We adopt a simple yet\neffective approach to WSD that uses a k-Nearest Neighbor (kNN) classification\non CWEs. Experimental results show that the proposed techniques also achieve\nsuperior results over the current state-of-the-art on both the WSD tasks",
    "descriptor": "\nComments: 8 pages, 1 figure, 3 tables\n",
    "authors": [
      "Avi Chawla",
      "Nidhi Mulay",
      "Vikas Bishnoi",
      "Gaurav Dhama",
      "Dr. Anil Kumar Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15417"
  },
  {
    "id": "arXiv:2111.15418",
    "title": "A structure preserving front tracking finite element method for the  Mullins--Sekerka problem",
    "abstract": "We introduce and analyse a fully discrete approximation for a mathematical\nmodel for the solidification and liquidation of materials of negligible\nspecific heat. The model is a two-sided Mullins--Sekerka problem. The\ndiscretization uses finite elements in space and an independent\nparameterization of the moving free boundary. We prove unconditional stability\nand exact volume conservation for the introduced scheme. Several numerical\nsimulations, including for nearly crystalline surface energies, demonstrate the\npracticality and accuracy of the presented numerical method.",
    "descriptor": "\nComments: 24 pages, 9 figures\n",
    "authors": [
      "Robert N\u00fcrnberg"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.15418"
  },
  {
    "id": "arXiv:2111.15420",
    "title": "Undecidability in Finite Transducers, Defense Systems and Finite  Substitutions",
    "abstract": "In this manuscript we present a detailed proof for undecidability of the\nequivalence of finite substitutions on regular language $b\\{0,1\\}^*c$. The\nproof is based on the works of Leonid P. Lisovik.",
    "descriptor": "",
    "authors": [
      "Vesa Halava"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computation and Language (cs.CL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.15420"
  },
  {
    "id": "arXiv:2111.15422",
    "title": "Hierarchical Prototype Networks for Continual Graph Representation  Learning",
    "abstract": "Despite significant advances in graph representation learning, little\nattention has been paid to the more practical continual learning scenario in\nwhich new categories of nodes (e.g., new research areas in citation networks,\nor new types of products in co-purchasing networks) and their associated edges\nare continuously emerging, causing catastrophic forgetting on previous\ncategories. Existing methods either ignore the rich topological information or\nsacrifice plasticity for stability. To this end, we present Hierarchical\nPrototype Networks (HPNs) which extract different levels of abstract knowledge\nin the form of prototypes to represent the continuously expanded graphs.\nSpecifically, we first leverage a set of Atomic Feature Extractors (AFEs) to\nencode both the elemental attribute information and the topological structure\nof the target node. Next, we develop HPNs to adaptively select relevant AFEs\nand represent each node with three levels of prototypes. In this way, whenever\na new category of nodes is given, only the relevant AFEs and prototypes at each\nlevel will be activated and refined, while others remain uninterrupted to\nmaintain the performance over existing nodes. Theoretically, we first\ndemonstrate that the memory consumption of HPNs is bounded regardless of how\nmany tasks are encountered. Then, we prove that under mild constraints,\nlearning new tasks will not alter the prototypes matched to previous data,\nthereby eliminating the forgetting problem. The theoretical results are\nsupported by experiments on five datasets, showing that HPNs not only\noutperform state-of-the-art baseline techniques but also consume relatively\nless memory.",
    "descriptor": "",
    "authors": [
      "Xikun Zhang",
      "Dongjin Song",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15422"
  },
  {
    "id": "arXiv:2111.15425",
    "title": "Exploring rationality of self awareness in social networking for logical  modeling of unintentional insiders",
    "abstract": "Unawareness of privacy risks together with approval seeking motivations make\nhumans enter too much detail into the likes of Facebook, Twitter, and\nInstagram. To test whether the rationality principle applies, we construct a\ntool that shows to a user what is known publicly on social networking sites\nabout her. In our experiment, we check whether this revelation changes human\nbehaviour. To extrapolate and generalize, we use the insights gained by\npractical experimentation. Unaware users can become targeted by attackers. They\nthen become unintentional insiders. We demonstrate this by extending the\nIsabelle Insider framework to accommodate a formal model of unintentional\ninsiders, an open problem with long standing.",
    "descriptor": "",
    "authors": [
      "Florian Kamm\u00fcller",
      "Chelsea Mira Alvarado"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.15425"
  },
  {
    "id": "arXiv:2111.15430",
    "title": "The Devil is in the Margin: Margin-based Label Smoothing for Network  Calibration",
    "abstract": "In spite of the dominant performances of deep neural networks, recent works\nhave shown that they are poorly calibrated, resulting in over-confident\npredictions. Miscalibration can be exacerbated by overfitting due to the\nminimization of the cross-entropy during training, as it promotes the predicted\nsoftmax probabilities to match the one-hot label assignments. This yields a\npre-softmax activation of the correct class that is significantly larger than\nthe remaining activations. Recent evidence from the literature suggests that\nloss functions that embed implicit or explicit maximization of the entropy of\npredictions yield state-of-the-art calibration performances. We provide a\nunifying constrained-optimization perspective of current state-of-the-art\ncalibration losses. Specifically, these losses could be viewed as\napproximations of a linear penalty (or a Lagrangian) imposing equality\nconstraints on logit distances. This points to an important limitation of such\nunderlying equality constraints, whose ensuing gradients constantly push\ntowards a non-informative solution, which might prevent from reaching the best\ncompromise between the discriminative performance and calibration of the model\nduring gradient-based optimization. Following our observations, we propose a\nsimple and flexible generalization based on inequality constraints, which\nimposes a controllable margin on logit distances. Comprehensive experiments on\na variety of image classification, semantic segmentation and NLP benchmarks\ndemonstrate that our method sets novel state-of-the-art results on these tasks\nin terms of network calibration, without affecting the discriminative\nperformance. The code is available at https://github.com/by-liu/MbLS .",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Bingyuan Liu",
      "Ismail Ben Ayed",
      "Adrian Galdran",
      "Jose Dolz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15430"
  },
  {
    "id": "arXiv:2111.15431",
    "title": "Binary Independent Component Analysis via Non-stationarity",
    "abstract": "We consider independent component analysis of binary data. While fundamental\nin practice, this case has been much less developed than ICA for continuous\ndata. We start by assuming a linear mixing model in a continuous-valued latent\nspace, followed by a binary observation model. Importantly, we assume that the\nsources are non-stationary; this is necessary since any non-Gaussianity would\nessentially be destroyed by the binarization. Interestingly, the model allows\nfor closed-form likelihood by employing the cumulative distribution function of\nthe multivariate Gaussian distribution. In stark contrast to the\ncontinuous-valued case, we prove non-identifiability of the model with few\nobserved variables; our empirical results imply identifiability when the number\nof observed variables is higher. We present a practical method for binary ICA\nthat uses only pairwise marginals, which are faster to compute than the full\nmultivariate likelihood.",
    "descriptor": "",
    "authors": [
      "Antti Hyttinen",
      "Vit\u00f3ria Barin-Pacela",
      "Aapo Hyv\u00e4rinen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.15431"
  },
  {
    "id": "arXiv:2111.15432",
    "title": "TiWS-iForest: Isolation Forest in Weakly Supervised and Tiny ML  scenarios",
    "abstract": "Unsupervised anomaly detection tackles the problem of finding anomalies\ninside datasets without the labels availability; since data tagging is\ntypically hard or expensive to obtain, such approaches have seen huge\napplicability in recent years. In this context, Isolation Forest is a popular\nalgorithm able to define an anomaly score by means of an ensemble of peculiar\ntrees called isolation trees. These are built using a random partitioning\nprocedure that is extremely fast and cheap to train. However, we find that the\nstandard algorithm might be improved in terms of memory requirements, latency\nand performances; this is of particular importance in low resources scenarios\nand in TinyML implementations on ultra-constrained microprocessors. Moreover,\nAnomaly Detection approaches currently do not take advantage of weak\nsupervisions: being typically consumed in Decision Support Systems, feedback\nfrom the users, even if rare, can be a valuable source of information that is\ncurrently unexplored. Beside showing iForest training limitations, we propose\nhere TiWS-iForest, an approach that, by leveraging weak supervision is able to\nreduce Isolation Forest complexity and to enhance detection performances. We\nshowed the effectiveness of TiWS-iForest on real word datasets and we share the\ncode in a public repository to enhance reproducibility.",
    "descriptor": "",
    "authors": [
      "Tommaso Barbariol",
      "Gian Antonio Susto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15432"
  },
  {
    "id": "arXiv:2111.15434",
    "title": "Servicing Timed Requests on a Line",
    "abstract": "We consider an off-line optimisation problem where $k$ robots must service\n$n$ requests on a single line. A request $i$ has weight $w_i$ and takes place\nat time $t_i$ at location $d_i$ on the line. A robot can service a request and\ncollect the weight $w_i$, if it is present at $d_i$ at time $t_i$. The\nobjective is to find $k$ robot-schedules that maximize the total weight. The\noptimisation problem is motivated by a robotics application [Asahiro et al.\nDiscrete Applied Mathematics, 2006] and can be modeled as a minimum cost flow\nproblem with unit capacities in a flow network $\\mathcal{N}$. Consequently, we\nask for a collection of $k$ node-disjoint paths from the source $s$ to the sink\n$t$ in $\\mathcal{N}$, with minimum total weight. It was shown in [Asahiro et\nal. Discrete Applied Mathematics, 2006] that the flow network $\\mathcal{N}$ can\nbe implicitly represented by $n$ points on the plane which yields to an $O(n\n\\log n)$-time algorithm for $k=1$ and the special case where all requests have\nthe same weight. However, for $k \\geq 2$ the problem can be solved in $O(kn^2)$\ntime with the successive shortest path algorithm which does not use this\nimplicit representation. We consider arbitrary request weights and show a\nrecursive $O(k^{2k}n \\log^{2k} n)$-time algorithm which improves the previous\nbound if $k$ is considered constant. Our result also improves the running time\nof previous algorithms for other variants of the optimisation problem. Finally,\nwe show problem properties that may be useful within the context of\napplications that motivate the problem and may yield to more efficient\nalgorithms.",
    "descriptor": "\nComments: 35 pages, 13 figures\n",
    "authors": [
      "A. Gkikas",
      "T. Radzik"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.15434"
  },
  {
    "id": "arXiv:2111.15436",
    "title": "KARL-Trans-NER: Knowledge Aware Representation Learning for Named Entity  Recognition using Transformers",
    "abstract": "The inception of modeling contextual information using models such as BERT,\nELMo, and Flair has significantly improved representation learning for words.\nIt has also given SOTA results in almost every NLP task - Machine Translation,\nText Summarization and Named Entity Recognition, to name a few. In this work,\nin addition to using these dominant context-aware representations, we propose a\nKnowledge Aware Representation Learning (KARL) Network for Named Entity\nRecognition (NER). We discuss the challenges of using existing methods in\nincorporating world knowledge for NER and show how our proposed methods could\nbe leveraged to overcome those challenges. KARL is based on a Transformer\nEncoder that utilizes large knowledge bases represented as fact triplets,\nconverts them to a graph context, and extracts essential entity information\nresiding inside to generate contextualized triplet representation for feature\naugmentation. Experimental results show that the augmentation done using KARL\ncan considerably boost the performance of our NER system and achieve\nsignificantly better results than existing approaches in the literature on\nthree publicly available NER datasets, namely CoNLL 2003, CoNLL++, and\nOntoNotes v5. We also observe better generalization and application to a\nreal-world setting from KARL on unseen entities.",
    "descriptor": "\nComments: 9 pages, 2 figures, 4 Tables\n",
    "authors": [
      "Avi Chawla",
      "Nidhi Mulay",
      "Vikas Bishnoi",
      "Gaurav Dhama"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15436"
  },
  {
    "id": "arXiv:2111.15438",
    "title": "FMD-cGAN: Fast Motion Deblurring using Conditional Generative  Adversarial Networks",
    "abstract": "In this paper, we present a Fast Motion Deblurring-Conditional Generative\nAdversarial Network (FMD-cGAN) that helps in blind motion deblurring of a\nsingle image. FMD-cGAN delivers impressive structural similarity and visual\nappearance after deblurring an image. Like other deep neural network\narchitectures, GANs also suffer from large model size (parameters) and\ncomputations. It is not easy to deploy the model on resource constraint devices\nsuch as mobile and robotics. With the help of MobileNet based architecture that\nconsists of depthwise separable convolution, we reduce the model size and\ninference time, without losing the quality of the images. More specifically, we\nreduce the model size by 3-60x compare to the nearest competitor. The resulting\ncompressed Deblurring cGAN faster than its closest competitors and even\nqualitative and quantitative results outperform various recently proposed\nstate-of-the-art blind motion deblurring models. We can also use our model for\nreal-time image deblurring tasks. The current experiment on the standard\ndatasets shows the effectiveness of the proposed method.",
    "descriptor": "\nComments: International Conference on Computer Vision and Image Processing 2021\n",
    "authors": [
      "Jatin Kumar",
      "Indra Deep Mastan",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.15438"
  },
  {
    "id": "arXiv:2111.15445",
    "title": "Asymptotics for Pull on the Complete Graph",
    "abstract": "Consider the following model to study adversarial effects on opinion forming.\nA set of initially selected experts form their binary opinion while being\ninfluenced by an adversary, who may convince some of them of the falsehood. All\nother participants in the network then take the opinion of the majority of\ntheir neighbouring experts. Can the adversary influence the experts in such a\nway that the majority of the network believes the falsehood? Alon et al. [1]\nconjectured that in this context an iterative dissemination process will always\nbe beneficial to the adversary. This work provides a counterexample to that\nconjecture.\n[1] N. Alon, M. Feldman, O. Lev, and M. Tennenholtz. How Robust Is the Wisdom\nof the Crowds? In Proceedings of the 24th International Joint Conference on\nArtificial Intelligence (IJCAI 2015), pages 2055-2061, 2015.",
    "descriptor": "",
    "authors": [
      "Konstantinos Panagiotou",
      "Simon Reisser"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.15445"
  },
  {
    "id": "arXiv:2111.15446",
    "title": "TEGDetector: A Phishing Detector that Knows Evolving Transaction  Behaviors",
    "abstract": "Recently, phishing scams have posed a significant threat to blockchains.\nPhishing detectors direct their efforts in hunting phishing addresses. Most of\nthe detectors extract target addresses' transaction behavior features by random\nwalking or constructing static subgraphs. The random walking\nmethods,unfortunately, usually miss structural information due to limited\nsampling sequence length, while the static subgraph methods tend to ignore\ntemporal features lying in the evolving transaction behaviors. More\nimportantly, their performance undergoes severe degradation when the malicious\nusers intentionally hide phishing behaviors. To address these challenges, we\npropose TEGDetector, a dynamic graph classifier that learns the evolving\nbehavior features from transaction evolution graphs (TEGs). First, we cast the\ntransaction series into multiple time slices, capturing the target address's\ntransaction behaviors in different periods. Then, we provide a fast\nnon-parametric phishing detector to narrow down the search space of suspicious\naddresses. Finally, TEGDetector considers both the spatial and temporal\nevolutions towards a complete characterization of the evolving transaction\nbehaviors. Moreover, TEGDetector utilizes adaptively learnt time coefficient to\npay distinct attention to different periods, which provides several novel\ninsights. Extensive experiments on the large-scale Ethereum transaction dataset\ndemonstrate that the proposed method achieves state-of-the-art detection\nperformance.",
    "descriptor": "",
    "authors": [
      "Jinyin Chen",
      "Haiyang Xiong",
      "Dunjie Zhang",
      "Zhenguang Liu",
      "Jiajing Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15446"
  },
  {
    "id": "arXiv:2111.15449",
    "title": "A Softmax-free Loss Function Based on Predefined Optimal-distribution of  Latent Features for CNN Classifier",
    "abstract": "In the field of pattern classification, the training of convolutional neural\nnetwork classifiers is mostly end-to-end learning, and the loss function is the\nconstraint on the final output (posterior probability) of the network, so the\nexistence of Softmax is essential. In the case of end-to-end learning, there is\nusually no effective loss function that completely relies on the features of\nthe middle layer to restrict learning, resulting in the distribution of sample\nlatent features is not optimal, so there is still room for improvement in\nclassification accuracy. Based on the concept of Predefined Evenly-Distributed\nClass Centroids (PEDCC), this article proposes a Softmax-free loss function\n(POD Loss) based on predefined optimal-distribution of latent features. The\nloss function only restricts the latent features of the samples, including the\ncosine distance between the latent feature vector of the sample and the center\nof the predefined evenly-distributed class, and the correlation between the\nlatent features of the samples. Finally, cosine distance is used for\nclassification. Compared with the commonly used Softmax Loss and the typical\nSoftmax related AM-Softmax Loss, COT-Loss and PEDCC-Loss, experiments on\nseveral commonly used datasets on a typical network show that the\nclassification performance of POD Loss is always better and easier to converge.\nCode is available in https://github.com/TianYuZu/POD-Loss.",
    "descriptor": "",
    "authors": [
      "Qiuyu Zhu",
      "Xuewen Zu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15449"
  },
  {
    "id": "arXiv:2111.15451",
    "title": "Large-Scale Video Analytics through Object-Level Consolidation",
    "abstract": "As the number of installed cameras grows, so do the compute resources\nrequired to process and analyze all the images captured by these cameras. Video\nanalytics enables new use cases, such as smart cities or autonomous driving. At\nthe same time, it urges service providers to install additional compute\nresources to cope with the demand while the strict latency requirements push\ncompute towards the end of the network, forming a geographically distributed\nand heterogeneous set of compute locations, shared and resource-constrained.\nSuch landscape (shared and distributed locations) forces us to design new\ntechniques that can optimize and distribute work among all available locations\nand, ideally, make compute requirements grow sublinearly with respect to the\nnumber of cameras installed. In this paper, we present FoMO (Focus on Moving\nObjects). This method effectively optimizes multi-camera deployments by\npreprocessing images for scenes, filtering the empty regions out, and composing\nregions of interest from multiple cameras into a single image that serves as\ninput for a pre-trained object detection model. Results show that overall\nsystem performance can be increased by 8x while accuracy improves 40% as a\nby-product of the methodology, all using an off-the-shelf pre-trained model\nwith no additional training or fine-tuning.",
    "descriptor": "",
    "authors": [
      "Daniel Rivas",
      "Francesc Guim",
      "Jord\u00e0 Polo",
      "David Carrera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.15451"
  },
  {
    "id": "arXiv:2111.15452",
    "title": "On the Generalization of Agricultural Drought Classification from  Climate Data",
    "abstract": "Climate change is expected to increase the likelihood of drought events, with\nsevere implications for food security. Unlike other natural disasters, droughts\nhave a slow onset and depend on various external factors, making drought\ndetection in climate data difficult. In contrast to existing works that rely on\nsimple relative drought indices as ground-truth data, we build upon soil\nmoisture index (SMI) obtained from a hydrological model. This index is directly\nrelated to insufficiently available water to vegetation. Given ERA5-Land\nclimate input data of six months with land use information from MODIS satellite\nobservation, we compare different models with and without sequential inductive\nbias in classifying droughts based on SMI. We use PR-AUC as the evaluation\nmeasure to account for the class imbalance and obtain promising results despite\na challenging time-based split. We further show in an ablation study that the\nmodels retain their predictive capabilities given input data of coarser\nresolutions, as frequently encountered in climate models.",
    "descriptor": "",
    "authors": [
      "Julia Gottfriedsen",
      "Max Berrendorf",
      "Pierre Gentine",
      "Markus Reichstein",
      "Katja Weigel",
      "Birgit Hassler",
      "Veronika Eyring"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15452"
  },
  {
    "id": "arXiv:2111.15454",
    "title": "Boosting Discriminative Visual Representation Learning with  Scenario-Agnostic Mixup",
    "abstract": "Mixup is a popular data-dependent augmentation technique for deep neural\nnetworks, which contains two sub-tasks, mixup generation and classification.\nThe community typically confines mixup to supervised learning (SL) and the\nobjective of generation sub-task is fixed to the sampled pairs instead of\nconsidering the whole data manifold. To overcome such limitations, we\nsystematically study the objectives of two sub-tasks and propose\nScenario-Agostic Mixup for both SL and Self-supervised Learning (SSL)\nscenarios, named SAMix. Specifically, we hypothesize and verify the core\nobjective of mixup generation as optimizing the local smoothness between two\nclasses subject to global discrimination from other classes. Based on this\ndiscovery, $\\eta$-balanced mixup loss is proposed for complementary training of\nthe two sub-tasks. Meanwhile, the generation sub-task is parameterized as an\noptimizable module, Mixer, which utilizes an attention mechanism to generate\nmixed samples without label dependency. Extensive experiments on SL and SSL\ntasks demonstrate that SAMix consistently outperforms leading methods by a\nlarge margin.",
    "descriptor": "\nComments: Preprint under review. 8 pages main body, 6 pages appendix, 3 pages reference\n",
    "authors": [
      "Siyuan Li",
      "Zicheng Liu",
      "Di Wu",
      "Zihan Liu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15454"
  },
  {
    "id": "arXiv:2111.15456",
    "title": "Towards Denotational Semantics of AD for Higher-Order, Recursive,  Probabilistic Languages",
    "abstract": "Automatic differentiation (AD) aims to compute derivatives of user-defined\nfunctions, but in Turing-complete languages, this simple specification does not\nfully capture AD's behavior: AD sometimes disagrees with the true derivative of\na differentiable program, and when AD is applied to non-differentiable or\neffectful programs, it is unclear what guarantees (if any) hold of the\nresulting code. We study an expressive differentiable programming language,\nwith piecewise-analytic primitives, higher-order functions, and general\nrecursion. Our main result is that even in this general setting, a version of\nLee et al. [2020]'s correctness theorem (originally proven for a first-order\nlanguage without partiality or recursion) holds: all programs denote so-called\n$\\omega$PAP functions, and AD computes correct intensional derivatives of them.\nMazza and Pagani [2021]'s recent theorem, that AD disagrees with the true\nderivative of a differentiable recursive program at a measure-zero set of\ninputs, can be derived as a straightforward corollary of this fact. We also\napply the framework to study probabilistic programs, and recover a recent\nresult from Mak et al. [2021] via a novel denotational argument.",
    "descriptor": "\nComments: At the NeurIPS differentiable programming workshop 2021\n",
    "authors": [
      "Alexander K. Lew",
      "Mathieu Huot",
      "Vikash K. Mansinghka"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.15456"
  },
  {
    "id": "arXiv:2111.15463",
    "title": "Consensus Synergizes with Memory: A Simple Approach for Anomaly  Segmentation in Urban Scenes",
    "abstract": "Anomaly segmentation is a crucial task for safety-critical applications, such\nas autonomous driving in urban scenes, where the goal is to detect\nout-of-distribution (OOD) objects with categories which are unseen during\ntraining. The core challenge of this task is how to distinguish hard\nin-distribution samples from OOD samples, which has not been explicitly\ndiscussed yet. In this paper, we propose a novel and simple approach named\nConsensus Synergizes with Memory (CosMe) to address this challenge, inspired by\nthe psychology finding that groups perform better than individuals on memory\ntasks. The main idea is 1) building a memory bank which consists of seen\nprototypes extracted from multiple layers of the pre-trained segmentation model\nand 2) training an auxiliary model that mimics the behavior of the pre-trained\nmodel, and then measuring the consensus of their mid-level features as\ncomplementary cues that synergize with the memory bank. CosMe is good at\ndistinguishing between hard in-distribution examples and OOD samples.\nExperimental results on several urban scene anomaly segmentation datasets show\nthat CosMe outperforms previous approaches by large margins.",
    "descriptor": "",
    "authors": [
      "Jiazhong Cen",
      "Zenkun Jiang",
      "Lingxi Xie",
      "Qi Tian",
      "Xiaokang Yang",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15463"
  },
  {
    "id": "arXiv:2111.15464",
    "title": "Energy-Efficient Design for a NOMA assisted STAR-RIS Network with Deep  Reinforcement Learning",
    "abstract": "Simultaneous transmitting and reflecting reconfigurable intelligent surfaces\n(STAR-RISs) has been considered as a promising auxiliary device to enhance the\nperformance of the wireless network, where users located at the different sides\nof the surfaces can be simultaneously served by the transmitting and reflecting\nsignals. In this paper, the energy efficiency (EE) maximization problem for a\nnon-orthogonal multiple access (NOMA) assisted STAR-RIS downlink network is\ninvestigated. Due to the fractional form of the EE, it is challenging to solve\nthe EE maximization problem by the traditional convex optimization solutions.\nIn this work, a deep deterministic policy gradient (DDPG)-based algorithm is\nproposed to maximize the EE by jointly optimizing the transmission beamforming\nvectors at the base station and the coefficients matrices at the STAR-RIS.\nSimulation results demonstrate that the proposed algorithm can effectively\nmaximize the system EE considering the time-varying channels.",
    "descriptor": "",
    "authors": [
      "Yi Guo",
      "Fang Fang",
      "Donghong Cai",
      "Zhiguo Ding"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.15464"
  },
  {
    "id": "arXiv:2111.15466",
    "title": "Citation network applications in a scientific co-authorship recommender  system",
    "abstract": "The problem of co-authors selection in the area of scientific collaborations\nmight be a daunting one. In this paper, we propose a new pipeline that\neffectively utilizes citation data in the link prediction task on the\nco-authorship network. In particular, we explore the capabilities of a\nrecommender system based on data aggregation strategies on different graphs.\nSince graph neural networks proved their efficiency on a wide range of tasks\nrelated to recommendation systems, we leverage them as a relevant method for\nthe forecasting of potential collaborations in the scientific community.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Vladislav Tishin",
      "Artyom Sosedka",
      "Peter Ibragimov",
      "Vadim Porvatov"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15466"
  },
  {
    "id": "arXiv:2111.15467",
    "title": "Car drivers' privacy concerns and trust perceptions",
    "abstract": "Modern cars are evolving in many ways. Technologies such as infotainment\nsystems and companion mobile applications collect a variety of personal data\nfrom drivers to enhance the user experience. This paper investigates the extent\nto which car drivers understand the implications for their privacy, including\nthat car manufacturers must treat that data in compliance with the relevant\nregulations. It does so by distilling out drivers' concerns on privacy and\nrelating them to their perceptions of trust on car cyber-security. A\nquestionnaire is designed for such purposes to collect answers from a set of\n1101 participants, so that the results are statistically relevant. In short,\nprivacy concerns are modest, perhaps because there still is insufficient\ngeneral awareness on the personal data that are involved, both for in-vehicle\ntreatment and for transmission over the Internet. Trust perceptions on\ncyber-security are modest too (lower than those on car safety), a surprising\ncontradiction to our research hypothesis that privacy concerns and trust\nperceptions on car cyber-security are opponent. We interpret this as a clear\ndemand for information and awareness-building campaigns for car drivers, as\nwell as for technical cyber-security and privacy measures that are truly\nconsiderate of the human factor.",
    "descriptor": "",
    "authors": [
      "Giampaolo Bella",
      "Pietro Biondi",
      "Giuseppe Tudisco"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.15467"
  },
  {
    "id": "arXiv:2111.15468",
    "title": "VoIP Can Still Be Exploited -- Badly",
    "abstract": "VoIP phones are early representatives as well as present enhancers of the\nIoT. This paper observes that they are still widely used in a traditional,\nunsecured configuration and demonstrates the Phonejack family of attacks:\nPhonejack 1 conjectures the exploitation of phone vulnerabilities; Phonejack 2\ndemonstrates how to mount a denial-of-service attack on a network of phones;\nPhonejack 3 sniffs calls. It is reassuring, however, that inexpensive devices\nsuch as a Raspberry Pi can be configured and programmed as effective\ncountermeasures, thus supporting the approach of integrating both technologies.\nWe demonstrate both attacks and defence measures in a video clip. The\nconcluding evaluations argue that trusting the underlying network security\nmeasures may turn out overly optimistic; moreover, VoIP phones really ought to\nbe protected as laptops routinely are today",
    "descriptor": "",
    "authors": [
      "Pietro Biondi",
      "Stefano Bognanni",
      "Giampaolo Bella"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.15468"
  },
  {
    "id": "arXiv:2111.15473",
    "title": "New Approaches to Long Document Summarization: Fourier Transform Based  Attention in a Transformer Model",
    "abstract": "In this work, we extensively redesign the newly introduced method of token\nmixing using Fourier Transforms (FNET) to replace the computationally expensive\nself-attention mechanism in a full transformer implementation on a long\ndocument summarization task (> 512 tokens). As a baseline, we also carried out\nlong document summarization using established methods such as Longformer and\nBig Bird transformer models that are capable of processing over 8000 tokens and\nare currently the state of the art methods for these type of problems. The\noriginal FNET paper implemented this in an encoder only architecture while\nabstractive summarization requires both an encoder and a decoder. Since such a\npretrained transformer model does not currently exist in the public domain, we\ndecided to implement a full transformer based on this Fourier token mixing\napproach in an encoder/decoder architecture which we trained starting with\nGlove embeddings for the individual words in the corpus. We investigated a\nnumber of different extensions to the original FNET architecture and evaluated\nthem on their Rouge F1-score performance on a summarization task. All\nmodifications showed better performance on the summarization task than when\nusing the original FNET encoder in a transformer architecture.",
    "descriptor": "\nComments: 7 pages, 4 figures, 5 tables\n",
    "authors": [
      "Andrew Kiruluta",
      "Andreas Lemos",
      "Eric Lundy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15473"
  },
  {
    "id": "arXiv:2111.15475",
    "title": "Natural Scene Text Editing Based on AI",
    "abstract": "In a recorded situation, textual information is crucial for scene\ninterpretation and decision making. The ability to edit text directly on images\nhas a number of advantages, including error correction, text restoration, and\nimage reusability. This research shows how to change image text at the letter\nand digits level. I devised a two-part letters-digits network (LDN) to encode\nand decode digital images, as well as learn and transfer the font style of the\nsource characters to the target characters. This method allows you to update\nthe uppercase letters, lowercase letters and digits in the picture.",
    "descriptor": "",
    "authors": [
      "Yujie Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15475"
  },
  {
    "id": "arXiv:2111.15476",
    "title": "A Scheme of Channel Prediction Based on Artificial Neural Network",
    "abstract": "Accurate channel modeling is the foundation of communication system design.\nHowever, the traditional measurement-based modeling approach has increasing\nchallenges for the scenarios with insufficient measurement data. To obtain\nenough data for channel modeling, the Artificial Neural Network (ANN) is used\nin this paper to predict channel data. The high mobility railway channel is\nconsidered, which is a typical scenario where it is challenging to obtain\nenough data for modeling within a short sampling interval. Three types of ANNs,\nthe Back Propagation Network, Radial Basis Function Neural Network and Extreme\nLearning Machine, are considered to predict channel path loss and shadow\nfading. The Root-Mean-Square error is used to evaluate prediction accuracy. The\nfactors that may influence prediction accuracy are compared and discussed,\nincluding the type of network, number of neurons and proportion of training\ndata. It is found that a larger number of neurons can significantly reduce\nprediction error, whereas the influence of proportion of training data is\nrelatively small. The results can be used to improve modeling accuracy of path\nloss and shadow fading when measurement data is reduced.",
    "descriptor": "",
    "authors": [
      "Zirui Wen",
      "Ruisi He",
      "Bo Ai",
      "Chen Huang",
      "Mi Yang",
      "Zhangdui Zhong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.15476"
  },
  {
    "id": "arXiv:2111.15478",
    "title": "A new compressed cover tree guarantees a near linear parameterized  complexity for all $k$-nearest neighbors search in metric spaces",
    "abstract": "This paper studies the classical problem of finding all $k$ nearest neighbors\nto points of a query set $Q$ in another reference set $R$ within any metric\nspace. The well-known work by Beygelzimer, Kakade, and Langford in 2006\nintroduced cover trees and claimed to guarantee a near linear time complexity\nin the size $|R|$ of the reference set for $k=1$. Our previous work defined\ncompressed cover trees and corrected the key arguments for $k\\geq 1$ and\npreviously unknown challenging data cases. In 2009 Ram, Lee, March, and Gray\nattempted to improve the time complexity by using pairs of cover trees on the\nquery and reference sets. In 2015 Curtin with the above co-authors used extra\nparameters to finally prove a similar complexity for $k = 1$. Our work fills\nall previous gaps and substantially improves the neighbor search based on pairs\nof new compressed cover trees. The novel imbalance parameter of paired trees\nallowed us to prove a better time complexity for any number of neighbors $k\\geq\n1$.",
    "descriptor": "",
    "authors": [
      "Yury Elkin",
      "Vitaliy Kurlin"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.15478"
  },
  {
    "id": "arXiv:2111.15479",
    "title": "Analysis of Multiscale Wavelet-based Fractional Gradient-Anisotropic  Diffusion Fusion for single hazy and underwater image enhancement",
    "abstract": "This report presents the results of a multi-scale wavelet based scheme for\nsingle image de-hazing and underwater image enhancement. The scheme is fast and\nhighly localized in addition to global enhancement of hazy images. A PDE-based\nformulation enables additional versatility as the iterative nature allows more\nflexibility for various types of images. Visual and objective results from\nexperiments indicate that the proposed approach competes favourably or\nsurpasses most of the state-of-the-art approaches.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Uche A. Nnolim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15479"
  },
  {
    "id": "arXiv:2111.15480",
    "title": "Search by a Metamorphic Robotic System in a Finite 3D Cubic Grid",
    "abstract": "We consider search in a finite 3D cubic grid by a metamorphic robotic system\n(MRS), that consists of anonymous modules. A module can perform a sliding and\nrotation while the whole modules keep connectivity. As the number of modules\nincreases, the variety of actions that the MRS can perform increases. The\nsearch problem requires the MRS to find a target in a given finite field. Doi\net al. (SSS 2018) demonstrate a necessary and sufficient number of modules for\nsearch in a finite 2D square grid. We consider search in a finite 3D cubic grid\nand investigate the effect of common knowledge. We consider three different\nsettings. First, we show that three modules are necessary and sufficient when\nall modules are equipped with a common compass, i.e., they agree on the\ndirection and orientation of the $x$, $y$, and $z$ axes. Second, we show that\nfour modules are necessary and sufficient when all modules agree on the\ndirection and orientation of the vertical axis. Finally, we show that five\nmodules are necessary and sufficient when all modules are not equipped with a\ncommon compass. Our results show that the shapes of the MRS in the 3D cubic\ngrid have richer structure than those in the 2D square grid.",
    "descriptor": "",
    "authors": [
      "Ryonosuke Yamada",
      "Yukiko Yamauchi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.15480"
  },
  {
    "id": "arXiv:2111.15481",
    "title": "Energy-Efficient Inference on the Edge Exploiting TinyML Capabilities  for UAVs",
    "abstract": "In recent years, the proliferation of unmanned aerial vehicles (UAVs) has\nincreased dramatically. UAVs can accomplish complex or dangerous tasks in a\nreliable and cost-effective way but are still limited by power consumption\nproblems, which pose serious constraints on the flight duration and completion\nof energy-demanding tasks. The possibility of providing UAVs with advanced\ndecision-making capabilities in an energy-effective way would be extremely\nbeneficial. In this paper, we propose a practical solution to this problem that\nexploits deep learning on the edge. The developed system integrates an OpenMV\nmicrocontroller into a DJI Tello Micro Aerial Vehicle (MAV). The\nmicrocontroller hosts a set of machine learning-enabled inference tools that\ncooperate to control the navigation of the drone and complete a given mission\nobjective. The goal of this approach is to leverage the new opportunistic\nfeatures of TinyML through OpenMV including offline inference, low latency,\nenergy efficiency, and data security. The approach is successfully validated on\na practical application consisting of the onboard detection of people wearing\nprotection masks in a crowded environment.",
    "descriptor": "",
    "authors": [
      "Wamiq Raza",
      "Anas Osman",
      "Francesco Ferrini",
      "Francesco De Natale"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.15481"
  },
  {
    "id": "arXiv:2111.15483",
    "title": "Spatio-Temporal Multi-Flow Network for Video Frame Interpolation",
    "abstract": "Video frame interpolation (VFI) is currently a very active research topic,\nwith applications spanning computer vision, post production and video encoding.\nVFI can be extremely challenging, particularly in sequences containing large\nmotions, occlusions or dynamic textures, where existing approaches fail to\noffer perceptually robust interpolation performance. In this context, we\npresent a novel deep learning based VFI method, ST-MFNet, based on a\nSpatio-Temporal Multi-Flow architecture. ST-MFNet employs a new multi-scale\nmulti-flow predictor to estimate many-to-one intermediate flows, which are\ncombined with conventional one-to-one optical flows to capture both large and\ncomplex motions. In order to enhance interpolation performance for various\ntextures, a 3D CNN is also employed to model the content dynamics over an\nextended temporal window. Moreover, ST-MFNet has been trained within an ST-GAN\nframework, which was originally developed for texture synthesis, with the aim\nof further improving perceptual interpolation quality. Our approach has been\ncomprehensively evaluated -- compared with fourteen state-of-the-art VFI\nalgorithms -- clearly demonstrating that ST-MFNet consistently outperforms\nthese benchmarks on varied and representative test datasets, with significant\ngains up to 1.09dB in PSNR for cases including large motions and dynamic\ntextures. Project page: https://danielism97.github.io/ST-MFNet.",
    "descriptor": "",
    "authors": [
      "Duolikun Danier",
      "Fan Zhang",
      "David Bull"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.15483"
  },
  {
    "id": "arXiv:2111.15487",
    "title": "FROB: Few-shot ROBust Model for Classification and Out-of-Distribution  Detection",
    "abstract": "Nowadays, classification and Out-of-Distribution (OoD) detection in the\nfew-shot setting remain challenging aims due to rarity and the limited samples\nin the few-shot setting, and because of adversarial attacks. Accomplishing\nthese aims is important for critical systems in safety, security, and defence.\nIn parallel, OoD detection is challenging since deep neural network classifiers\nset high confidence to OoD samples away from the training data. To address such\nlimitations, we propose the Few-shot ROBust (FROB) model for classification and\nfew-shot OoD detection. We devise FROB for improved robustness and reliable\nconfidence prediction for few-shot OoD detection. We generate the support\nboundary of the normal class distribution and combine it with few-shot Outlier\nExposure (OE). We propose a self-supervised learning few-shot confidence\nboundary methodology based on generative and discriminative models. The\ncontribution of FROB is the combination of the generated boundary in a\nself-supervised learning manner and the imposition of low confidence at this\nlearned boundary. FROB implicitly generates strong adversarial samples on the\nboundary and forces samples from OoD, including our boundary, to be less\nconfident by the classifier. FROB achieves generalization to unseen OoD with\napplicability to unknown, in the wild, test sets that do not correlate to the\ntraining datasets. To improve robustness, FROB redesigns OE to work even for\nzero-shots. By including our boundary, FROB reduces the threshold linked to the\nmodel's few-shot robustness; it maintains the OoD performance approximately\nindependent of the number of few-shots. The few-shot robustness analysis\nevaluation of FROB on different sets and on One-Class Classification (OCC) data\nshows that FROB achieves competitive performance and outperforms benchmarks in\nterms of robustness to the outlier few-shot sample population and variability.",
    "descriptor": "\nComments: Paper, 22 pages, Figures, Tables\n",
    "authors": [
      "Nikolaos Dionelis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.15487"
  },
  {
    "id": "arXiv:2111.15490",
    "title": "FENeRF: Face Editing in Neural Radiance Fields",
    "abstract": "Previous portrait image generation methods roughly fall into two categories:\n2D GANs and 3D-aware GANs. 2D GANs can generate high fidelity portraits but\nwith low view consistency. 3D-aware GAN methods can maintain view consistency\nbut their generated images are not locally editable. To overcome these\nlimitations, we propose FENeRF, a 3D-aware generator that can produce\nview-consistent and locally-editable portrait images. Our method uses two\ndecoupled latent codes to generate corresponding facial semantics and texture\nin a spatial aligned 3D volume with shared geometry. Benefiting from such\nunderlying 3D representation, FENeRF can jointly render the boundary-aligned\nimage and semantic mask and use the semantic mask to edit the 3D volume via GAN\ninversion. We further show such 3D representation can be learned from widely\navailable monocular image and semantic mask pairs. Moreover, we reveal that\njoint learning semantics and texture helps to generate finer geometry. Our\nexperiments demonstrate that FENeRF outperforms state-of-the-art methods in\nvarious face editing tasks.",
    "descriptor": "",
    "authors": [
      "Jingxiang Sun",
      "Xuan Wang",
      "Yong Zhang",
      "Xiaoyu Li",
      "Qi Zhang",
      "Yebin Liu",
      "Jue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15490"
  },
  {
    "id": "arXiv:2111.15491",
    "title": "PolyWorld: Polygonal Building Extraction with Graph Neural Networks in  Satellite Images",
    "abstract": "Most state-of-the-art instance segmentation methods produce binary\nsegmentation masks, however, geographic and cartographic applications typically\nrequire precise vector polygons of extracted objects instead of rasterized\noutput. This paper introduces PolyWorld, a neural network that directly\nextracts building vertices from an image and connects them correctly to create\nprecise polygons. The model predicts the connection strength between each pair\nof vertices using a graph neural network and estimates the assignments by\nsolving a differentiable optimal transport problem. Moreover, the vertex\npositions are optimized by minimizing a combined segmentation and polygonal\nangle difference loss. PolyWorld significantly outperforms the state-of-the-art\nin building polygonization and achieves not only notable quantitative results,\nbut also produces visually pleasing building polygons. Code and trained weights\nwill be soon available on github.",
    "descriptor": "",
    "authors": [
      "Stefano Zorzi",
      "Shabab Bazrafkan",
      "Stefan Habenschuss",
      "Friedrich Fraundorfer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15491"
  },
  {
    "id": "arXiv:2111.15502",
    "title": "Popcorns-Pro: A Cooperative Network-Server Approach for Data Center  Energy Optimization",
    "abstract": "Data centers have become a popular computing platform for various\napplications, and they account for nearly 2% of total US energy consumption.\nTherefore, it has become important to optimize data center power, and reduce\ntheir energy footprint. Most existing work optimizes power in servers and\nnetworks independently and does not address them together in a holistic fashion\nthat has the potential to achieve greater power savings. In this article, we\npresent PopcornsPro, a cooperative server network framework for energy\noptimization. We present a comprehensive power model for heterogeneous data\ncenter switches along with low power mode designs in combination with the\nserver power model. We design job scheduling algorithms that place tasks onto\nservers in a power-aware manner, such that servers and network switches can\ntake effective advantage of low power state and available network link\ncapacities. Our experimental results show that we are able to achieve\nsignificantly higher savings up to 80% compared to the previously well-known\nserver and network power optimization policies.",
    "descriptor": "\nComments: Presubmission\n",
    "authors": [
      "Sai Santosh Dayapule",
      "Kathy Nguyen",
      "Gregory Kahl",
      "Suresh Subramaniam",
      "Guru Venkataramani"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.15502"
  },
  {
    "id": "arXiv:2111.15504",
    "title": "Linearisation of the Travel Time Functional in Porous Media Flows",
    "abstract": "The travel time functional measures the time taken for a particle trajectory\nto travel from a given initial position to the boundary of the domain. Such\nevaluation is paramount in the post-closure safety assessment of deep\ngeological storage facilities for radioactive waste where leaked, non-sorbing,\nsolutes can be transported to the surface of the site by the surrounding\ngroundwater. The accurate simulation of this transport can be attained using\nstandard dual-weighted-residual techniques to derive goal-oriented $a$\n$posteriori$ error bounds. This work provides a key aspect in obtaining a\nsuitable error estimate for the travel time functional: the evaluation of its\nG\\^ateaux derivative. A mixed finite element method is implemented to\napproximate Darcy's equations and numerical experiments are presented to test\nthe performance of the proposed error estimator. In particular, we consider a\ntest case inspired by the Sellafield site located in Cumbria, in the UK.",
    "descriptor": "\nComments: 25 pages, 11 figures\n",
    "authors": [
      "Paul Houston",
      "Connor J. Rourke",
      "Kristoffer G. Van der Zee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.15504"
  },
  {
    "id": "arXiv:2111.15505",
    "title": "Efficient Adaptive Computation of the Dynamics of Mott Transistors",
    "abstract": "We investigate time-adaptive Magnus-type integrators for the numerical\napproximation of a Mott transistor. The rapidly attenuating electromagnetic\nfield calls for adaptive choice of the time steps. As a basis for step\nselection, asymptotically correct defect-based estimators of the local error\nare employed. We analyze the error of the numerical approximation in the\npresence of the unsmooth external potential and demonstrate the advantages of\nthe adaptive approach.",
    "descriptor": "",
    "authors": [
      "Winfried Auzinger",
      "Lukas Einramhof",
      "Karsten Held",
      "Anna Kauch",
      "Othmar Koch",
      "Clemens Watzenb\u00f6ck",
      "Ewa Weinm\u00fcller"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.15505"
  },
  {
    "id": "arXiv:2111.15506",
    "title": "Towards a comprehensive visualization of structure in data",
    "abstract": "Dimensional data reduction methods are fundamental to explore and visualize\nlarge data sets. Basic requirements for unsupervised data exploration are\nsimplicity, flexibility and scalability. However, current methods show complex\nparameterizations and strong computational limitations when exploring large\ndata structures across scales. Here, we focus on the t-SNE algorithm and show\nthat a simplified parameter setup with a single control parameter, namely the\nperplexity, can effectively balance local and global data structure\nvisualization. We also designed a chunk\\&mix protocol to efficiently\nparallelize t-SNE and explore data structure across a much wide range of scales\nthan currently available. Our parallel version of the BH-tSNE, namely pt-SNE,\nconverges to good global embedding, comparable to state-of-the-art solutions,\nthough the chunk\\&mix protocol adds little noise and decreases the accuracy at\nthe local scale. Nonetheless, we show that simple post-processing can\nefficiently restore local scale visualization, without any loss of precision at\nthe global scales. We expect the same approach to apply to faster embedding\nalgorithms other than BH-tSNE, like FIt-SNE or UMAP, thus, extending the\nstate-of-the-art and leading to more comprehensive data structure visualization\nand analysis.",
    "descriptor": "\nComments: 32 pages, 11 figures\n",
    "authors": [
      "Joan Garriga",
      "Frederic Bartumeus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.15506"
  },
  {
    "id": "arXiv:2111.15509",
    "title": "Regularized directional representations for medical image registration",
    "abstract": "In image registration, many efforts have been devoted to the development of\nalternatives to the popular normalized mutual information criterion.\nConcurrently to these efforts, an increasing number of works have demonstrated\nthat substantial gains in registration accuracy can also be achieved by\naligning structural representations of images rather than images themselves.\nFollowing this research path, we propose a new method for mono- and multimodal\nimage registration based on the alignment of regularized vector fields derived\nfrom structural information such as gradient vector flow fields, a technique we\ncall \\textit{vector field similarity}. Our approach can be combined in a\nstraightforward fashion with any existing registration framework by\nsubstituting vector field similarity to intensity-based registration. In our\nexperiments, we show that the proposed approach compares favourably with\nconventional image alignment on several public image datasets using a diversity\nof imaging modalities and anatomical locations.",
    "descriptor": "",
    "authors": [
      "Vincent Jaouen",
      "Pierre-Henri Conze",
      "Guillaume Dardenne",
      "Julien Bert",
      "Dimitris Visvikis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15509"
  },
  {
    "id": "arXiv:2111.15510",
    "title": "ESL: Event-based Structured Light",
    "abstract": "Event cameras are bio-inspired sensors providing significant advantages over\nstandard cameras such as low latency, high temporal resolution, and high\ndynamic range. We propose a novel structured-light system using an event camera\nto tackle the problem of accurate and high-speed depth sensing. Our setup\nconsists of an event camera and a laser-point projector that uniformly\nilluminates the scene in a raster scanning pattern during 16 ms. Previous\nmethods match events independently of each other, and so they deliver noisy\ndepth estimates at high scanning speeds in the presence of signal latency and\njitter. In contrast, we optimize an energy function designed to exploit event\ncorrelations, called spatio-temporal consistency. The resulting method is\nrobust to event jitter and therefore performs better at higher scanning speeds.\nExperiments demonstrate that our method can deal with high-speed motion and\noutperform state-of-the-art 3D reconstruction methods based on event cameras,\nreducing the RMSE by 83% on average, for the same acquisition time.",
    "descriptor": "",
    "authors": [
      "Manasi Muglikar",
      "Guillermo Gallego",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15510"
  },
  {
    "id": "arXiv:2111.15512",
    "title": "What Do You See in this Patient? Behavioral Testing of Clinical NLP  Models",
    "abstract": "Decision support systems based on clinical notes have the potential to\nimprove patient care by pointing doctors towards overseen risks. Predicting a\npatient's outcome is an essential part of such systems, for which the use of\ndeep neural networks has shown promising results. However, the patterns learned\nby these networks are mostly opaque and previous work revealed flaws regarding\nthe reproduction of unintended biases. We thus introduce an extendable testing\nframework that evaluates the behavior of clinical outcome models regarding\nchanges of the input. The framework helps to understand learned patterns and\ntheir influence on model decisions. In this work, we apply it to analyse the\nchange in behavior with regard to the patient characteristics gender, age and\nethnicity. Our evaluation of three current clinical NLP models demonstrates the\nconcrete effects of these characteristics on the models' decisions. They show\nthat model behavior varies drastically even when fine-tuned on the same data\nand that allegedly best-performing models have not always learned the most\nmedically plausible patterns.",
    "descriptor": "\nComments: NeurIPS 2021 Research2Clinics Workshop, Bridging the Gap: From Machine Learning Research to Clinical Practice\n",
    "authors": [
      "Betty van Aken",
      "Sebastian Herrmann",
      "Alexander L\u00f6ser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15512"
  },
  {
    "id": "arXiv:2111.15513",
    "title": "RADU: Ray-Aligned Depth Update Convolutions for ToF Data Denoising",
    "abstract": "Time-of-Flight (ToF) cameras are subject to high levels of noise and\ndistortions due to Multi-Path-Interference (MPI). While recent research showed\nthat 2D neural networks are able to outperform previous traditional\nState-of-the-Art (SOTA) methods on denoising ToF-Data, little research on\nlearning-based approaches has been done to make direct use of the 3D\ninformation present in depth images. In this paper, we propose an iterative\ndenoising approach operating in 3D space, that is designed to learn on 2.5D\ndata by enabling 3D point convolutions to correct the points' positions along\nthe view direction. As labeled real world data is scarce for this task, we\nfurther train our network with a self-training approach on unlabeled real world\ndata to account for real world statistics. We demonstrate that our method is\nable to outperform SOTA methods on several datasets, including two real world\ndatasets and a new large-scale synthetic data set introduced in this paper.",
    "descriptor": "",
    "authors": [
      "Michael Schelling",
      "Pedro Hermosilla",
      "Timo Ropinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15513"
  },
  {
    "id": "arXiv:2111.15514",
    "title": "Nonlinear Intensity Underwater Sonar Image Matching Method Based on  Phase Information and Deep Convolution Features",
    "abstract": "In the field of deep-sea exploration, sonar is presently the only efficient\nlong-distance sensing device. The complicated underwater environment, such as\nnoise interference, low target intensity or background dynamics, has brought\nmany negative effects on sonar imaging. Among them, the problem of nonlinear\nintensity is extremely prevalent. It is also known as the anisotropy of\nacoustic sensor imaging, that is, when autonomous underwater vehicles (AUVs)\ncarry sonar to detect the same target from different angles, the intensity\nvariation between image pairs is sometimes very large, which makes the\ntraditional matching algorithm almost ineffective. However, image matching is\nthe basis of comprehensive tasks such as navigation, positioning, and mapping.\nTherefore, it is very valuable to obtain robust and accurate matching results.\nThis paper proposes a combined matching method based on phase information and\ndeep convolution features. It has two outstanding advantages: one is that the\ndeep convolution features could be used to measure the similarity of the local\nand global positions of the sonar image; the other is that local feature\nmatching could be performed at the key target position of the sonar image. This\nmethod does not need complex manual designs, and completes the matching task of\nnonlinear intensity sonar images in a close end-to-end manner. Feature matching\nexperiments are carried out on the deep-sea sonar images captured by AUVs, and\nthe results show that our proposal has preeminent matching accuracy and\nrobustness.",
    "descriptor": "\nComments: 6 pages, letters, 9 figures. arXiv admin note: substantial text overlap with arXiv:2111.08994\n",
    "authors": [
      "Xiaoteng Zhou",
      "Changli Yu",
      "Xin Yuan",
      "Haijun Feng",
      "Yang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15514"
  },
  {
    "id": "arXiv:2111.15518",
    "title": "Detecting Adversaries, yet Faltering to Noise? Leveraging Conditional  Variational AutoEncoders for Adversary Detection in the Presence of Noisy  Images",
    "abstract": "With the rapid advancement and increased use of deep learning models in image\nidentification, security becomes a major concern to their deployment in\nsafety-critical systems. Since the accuracy and robustness of deep learning\nmodels are primarily attributed from the purity of the training samples,\ntherefore the deep learning architectures are often susceptible to adversarial\nattacks. Adversarial attacks are often obtained by making subtle perturbations\nto normal images, which are mostly imperceptible to humans, but can seriously\nconfuse the state-of-the-art machine learning models. What is so special in the\nslightest intelligent perturbations or noise additions over normal images that\nit leads to catastrophic classifications by the deep neural networks? Using\nstatistical hypothesis testing, we find that Conditional Variational\nAutoEncoders (CVAE) are surprisingly good at detecting imperceptible image\nperturbations. In this paper, we show how CVAEs can be effectively used to\ndetect adversarial attacks on image classification networks. We demonstrate our\nresults over MNIST, CIFAR-10 dataset and show how our method gives comparable\nperformance to the state-of-the-art methods in detecting adversaries while not\ngetting confused with noisy images, where most of the existing methods falter.",
    "descriptor": "",
    "authors": [
      "Dvij Kalaria",
      "Aritra Hazra",
      "Partha Pratim Chakrabarti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15518"
  },
  {
    "id": "arXiv:2111.15521",
    "title": "Node-Level Differentially Private Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) are a popular technique for modelling\ngraph-structured data that compute node-level representations via aggregation\nof information from the local neighborhood of each node. However, this\naggregation implies increased risk of revealing sensitive information, as a\nnode can participate in the inference for multiple nodes. This implies that\nstandard privacy preserving machine learning techniques, such as differentially\nprivate stochastic gradient descent (DP-SGD) - which are designed for\nsituations where each data point participates in the inference for one point\nonly - either do not apply, or lead to inaccurate solutions. In this work, we\nformally define the problem of learning 1-layer GNNs with node-level privacy,\nand provide an algorithmic solution with a strong differential privacy\nguarantee. Even though each node can be involved in the inference for multiple\nnodes, by employing a careful sensitivity analysis anda non-trivial extension\nof the privacy-by-amplification technique, our method is able to provide\naccurate solutions with solid privacy parameters. Empirical evaluation on\nstandard benchmarks demonstrates that our method is indeed able to learn\naccurate privacy preserving GNNs, while still outperforming standard\nnon-private methods that completely ignore graph information.",
    "descriptor": "\nComments: 23 pages, 3 figures\n",
    "authors": [
      "Ameya Daigavane",
      "Gagan Madan",
      "Aditya Sinha",
      "Abhradeep Guha Thakurta",
      "Gaurav Aggarwal",
      "Prateek Jain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.15521"
  },
  {
    "id": "arXiv:2111.15525",
    "title": "A Sketch Based Game Theoretic Approach to Detect Anomalous Dense  Sub-Communities in Large Data Streams",
    "abstract": "Detecting anomalous subgraphs in a dynamic graph in an online or streaming\nfashion is an important requirement in industrial settings for intrusion\ndetection or denial of service attacks. While only detecting anomalousness in\nthe system by edge frequencies is an optimal approach, many latent information\ncan get unnoticed in the process, since as a characteristic of the network only\nedge frequencies are considered. We propose a game theoretic approach whereby\nusing the modularity function we try to estimate in a streaming graph\n\\emph{whether addition of a new edge in the current time tick results in a\ndense subgraph creation, thus indicating possible anomalous score}. Our\ncontributions are as follows: (a) We propose a novel game-theoretic framework\nfor detecting dense subcommunities in an online streaming environment; (b) We\ndetect such subcommunities using constant memory storage. Our results are\ncorroborated with empirical evaluation on real datasets.",
    "descriptor": "",
    "authors": [
      "Prateek Chanda",
      "Aadirupa Saha"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.15525"
  },
  {
    "id": "arXiv:2111.15527",
    "title": "Embedding Principle: a hierarchical structure of loss landscape of deep  neural networks",
    "abstract": "We prove a general Embedding Principle of loss landscape of deep neural\nnetworks (NNs) that unravels a hierarchical structure of the loss landscape of\nNNs, i.e., loss landscape of an NN contains all critical points of all the\nnarrower NNs. This result is obtained by constructing a class of critical\nembeddings which map any critical point of a narrower NN to a critical point of\nthe target NN with the same output function. By discovering a wide class of\ngeneral compatible critical embeddings, we provide a gross estimate of the\ndimension of critical submanifolds embedded from critical points of narrower\nNNs. We further prove an irreversiblility property of any critical embedding\nthat the number of negative/zero/positive eigenvalues of the Hessian matrix of\na critical point may increase but never decrease as an NN becomes wider through\nthe embedding. Using a special realization of general compatible critical\nembedding, we prove a stringent necessary condition for being a \"truly-bad\"\ncritical point that never becomes a strict-saddle point through any critical\nembedding. This result implies the commonplace of strict-saddle points in wide\nNNs, which may be an important reason underlying the easy optimization of wide\nNNs widely observed in practice.",
    "descriptor": "",
    "authors": [
      "Yaoyu Zhang",
      "Yuqing Li",
      "Zhongwang Zhang",
      "Tao Luo",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15527"
  },
  {
    "id": "arXiv:2111.15528",
    "title": "Facets of the Total Matching Polytope for bipartite graphs",
    "abstract": "The Total Matching Polytope generalizes the Stable Set Polytope and the\nMatching Polytope. In this paper, we give the perfect formulation for Trees and\nwe derive two new families of valid inequalities, the balanced biclique\ninequalities which are always facet-defining and the non-balanced lifted\nbiclique inequalities obtained by a lifting procedure, which are facet-defining\nfor bipartite graphs. Finally, we give a complete description for Complete\nBipartite Graphs.",
    "descriptor": "\nComments: 9 pages, 1 figure\n",
    "authors": [
      "Luca Ferrarini"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.15528"
  },
  {
    "id": "arXiv:2111.15534",
    "title": "\u0394-Conformity: Multi-scale Node Assortativity in Feature-rich  Stream Graphs",
    "abstract": "Heterogeneity is a key aspect of complex networks, often emerging by looking\nat the distribution of node properties, from the milestone observations on the\ndegree to the recent developments in mixing pattern estimation. Mixing\npatterns, in particular, refer to nodes' connectivity preferences with respect\nto an attribute label. Social networks are mostly characterized by\nassortative/homophilic behaviour, where nodes are more likely to be connected\nwith similar ones. Recently, assortative mixing is increasingly measured in a\nmulti-scale fashion to overcome well known limitations of classic scores. Such\nmulti-scale strategies can capture heterogeneous behaviors among node\nhomophily, but they ignore an important, often available, addendum in\nreal-world systems: the time when edges are present and the time-varying paths\nthey form accordingly. Hence, temporal homophily is still little understood in\ncomplex networks. In this work we aim to cover this gap by introducing the\n{\\Delta}-Conformity measure, a multiscale, path-aware, node homophily estimator\nwithin the new framework of feature-rich stream graphs. A rich experimental\nsection analyzes {\\Delta}-Conformity trends over time, spanning the analysis\nfrom real-life social interaction networks to a specific case-study about the\nBitcoin Transaction Network.",
    "descriptor": "\nComments: Submitted to \"International Journal of Data Science and Analytics\"\n",
    "authors": [
      "Salvatore Citraro",
      "Letizia Milli",
      "R\u00e9my Cazabet",
      "Giulio Rossetti"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.15534"
  },
  {
    "id": "arXiv:2111.15537",
    "title": "Model-Free $\u03bc$ Synthesis via Adversarial Reinforcement Learning",
    "abstract": "Motivated by the recent empirical success of policy-based reinforcement\nlearning (RL), there has been a research trend studying the performance of\npolicy-based RL methods on standard control benchmark problems. In this paper,\nwe examine the effectiveness of policy-based RL methods on an important robust\ncontrol problem, namely $\\mu$ synthesis. We build a connection between robust\nadversarial RL and $\\mu$ synthesis, and develop a model-free version of the\nwell-known $DK$-iteration for solving state-feedback $\\mu$ synthesis with\nstatic $D$-scaling. In the proposed algorithm, the $K$ step mimics the\nclassical central path algorithm via incorporating a recently-developed\ndouble-loop adversarial RL method as a subroutine, and the $D$ step is based on\nmodel-free finite difference approximation. Extensive numerical study is also\npresented to demonstrate the utility of our proposed model-free algorithm. Our\nstudy sheds new light on the connections between adversarial RL and robust\ncontrol.",
    "descriptor": "\nComments: Submitted to ACC 2022\n",
    "authors": [
      "Darioush Keivan",
      "Aaron Havens",
      "Peter Seiler",
      "Geir Dullerud",
      "Bin Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.15537"
  },
  {
    "id": "arXiv:2111.15542",
    "title": "Learning to Transfer for Traffic Forecasting via Multi-task Learning",
    "abstract": "Deep neural networks have demonstrated superior performance in short-term\ntraffic forecasting. However, most existing traffic forecasting systems assume\nthat the training and testing data are drawn from the same underlying\ndistribution, which limits their practical applicability. The NeurIPS 2021\nTraffic4cast challenge is the first of its kind dedicated to benchmarking the\nrobustness of traffic forecasting models towards domain shifts in space and\ntime. This technical report describes our solution to this challenge. In\nparticular, we present a multi-task learning framework for temporal and\nspatio-temporal domain adaptation of traffic forecasting models. Experimental\nresults demonstrate that our multi-task learning approach achieves strong\nempirical performance, outperforming a number of baseline domain adaptation\nmethods, while remaining highly efficient. The source code for this technical\nreport is available at https://github.com/YichaoLu/Traffic4cast2021.",
    "descriptor": "",
    "authors": [
      "Yichao Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15542"
  },
  {
    "id": "arXiv:2111.15546",
    "title": "Black box tests for algorithmic stability",
    "abstract": "Algorithmic stability is a concept from learning theory that expresses the\ndegree to which changes to the input data (e.g., removal of a single data\npoint) may affect the outputs of a regression algorithm. Knowing an algorithm's\nstability properties is often useful for many downstream applications -- for\nexample, stability is known to lead to desirable generalization properties and\npredictive inference guarantees. However, many modern algorithms currently used\nin practice are too complex for a theoretical analysis of their stability\nproperties, and thus we can only attempt to establish these properties through\nan empirical exploration of the algorithm's behavior on various data sets. In\nthis work, we lay out a formal statistical framework for this kind of \"black\nbox testing\" without any assumptions on the algorithm or the data distribution,\nand establish fundamental bounds on the ability of any black box test to\nidentify algorithmic stability.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Byol Kim",
      "Rina Foygel Barber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2111.15546"
  },
  {
    "id": "arXiv:2111.15552",
    "title": "NeuSample: Neural Sample Field for Efficient View Synthesis",
    "abstract": "Neural radiance fields (NeRF) have shown great potentials in representing 3D\nscenes and synthesizing novel views, but the computational overhead of NeRF at\nthe inference stage is still heavy. To alleviate the burden, we delve into the\ncoarse-to-fine, hierarchical sampling procedure of NeRF and point out that the\ncoarse stage can be replaced by a lightweight module which we name a neural\nsample field. The proposed sample field maps rays into sample distributions,\nwhich can be transformed into point coordinates and fed into radiance fields\nfor volume rendering. The overall framework is named as NeuSample. We perform\nexperiments on Realistic Synthetic 360$^{\\circ}$ and Real Forward-Facing, two\npopular 3D scene sets, and show that NeuSample achieves better rendering\nquality than NeRF while enjoying a faster inference speed. NeuSample is further\ncompressed with a proposed sample field extraction method towards a better\ntrade-off between quality and speed.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Jiemin Fang",
      "Lingxi Xie",
      "Xinggang Wang",
      "Xiaopeng Zhang",
      "Wenyu Liu",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.15552"
  },
  {
    "id": "arXiv:2111.15557",
    "title": "Low-light Image Enhancement via Breaking Down the Darkness",
    "abstract": "Images captured in low-light environment often suffer from complex\ndegradation. Simply adjusting light would inevitably result in burst of hidden\nnoise and color distortion. To seek results with satisfied lighting,\ncleanliness, and realism from degraded inputs, this paper presents a novel\nframework inspired by the divide-and-rule principle, greatly alleviating the\ndegradation entanglement. Assuming that an image can be decomposed into texture\n(with possible noise) and color components, one can specifically execute noise\nremoval and color correction along with light adjustment. Towards this purpose,\nwe propose to convert an image from the RGB space into a luminance-chrominance\none. An adjustable noise suppression network is designed to eliminate noise in\nthe brightened luminance, having the illumination map estimated to indicate\nnoise boosting levels. The enhanced luminance further serves as guidance for\nthe chrominance mapper to generate realistic colors. Extensive experiments are\nconducted to reveal the effectiveness of our design, and demonstrate its\nsuperiority over state-of-the-art alternatives both quantitatively and\nqualitatively on several benchmark datasets. Our code is publicly available at\nhttps://github.com/mingcv/Bread.",
    "descriptor": "\nComments: 9 pages, 9 figures\n",
    "authors": [
      "Qiming Hu",
      "Xiaojie Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15557"
  },
  {
    "id": "arXiv:2111.15568",
    "title": "Distributed Computation of A Posteriori Bit Likelihood Ratios in  Cell-Free Massive MIMO",
    "abstract": "This paper presents a novel strategy to decentralize the soft detection\nprocedure in an uplink cell-free massive multiple-input-multiple-output\nnetwork. We propose efficient approaches to compute the a posteriori\nprobability-per-bit, exactly or approximately when having a sequential\nfronthaul. More precisely, each access point (AP) in the network computes\npartial sufficient statistics locally, fuses it with received partial\nstatistics from another AP, and then forwards the result to the next AP. Once\nthe sufficient statistics reach the central processing unit, it performs the\nsoft demodulation by computing the log-likelihood ratio (LLR) per bit, and then\na channel decoding algorithm (e.g., a Turbo decoder) is utilized to decode the\nbits. We derive the distributed computation of LLR analytically.",
    "descriptor": "\nComments: 5 pages, 2 figures, accepted in 2021 29th European Signal Processing Conference (EUSIPCO)\n",
    "authors": [
      "Zakir Hussain Shaik",
      "Emil Bj\u00f6rnson",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.15568"
  },
  {
    "id": "arXiv:2111.15570",
    "title": "Discontinuous Galerkin discretization in time of systems of second-order  nonlinear hyperbolic equations",
    "abstract": "In this paper we study the finite element approximation of systems of\nsecond-order nonlinear hyperbolic equations. The proposed numerical method\ncombines a $hp$-version discontinuous Galerkin finite element approximation in\nthe time direction with an $H^1(\\Omega)$-conforming finite element\napproximation in the spatial variables. Error bounds at the temporal nodal\npoints are derived under a weak restriction on the temporal step size in terms\nof the spatial mesh size. Numerical experiments are presented to verify the\ntheoretical results.",
    "descriptor": "\nComments: 48 pages, 1 figure\n",
    "authors": [
      "Aili Shao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.15570"
  },
  {
    "id": "arXiv:2111.15581",
    "title": "Automated Damage Inspection of Power Transmission Towers from UAV Images",
    "abstract": "Infrastructure inspection is a very costly task, requiring technicians to\naccess remote or hard-to-reach places. This is the case for power transmission\ntowers, which are sparsely located and require trained workers to climb them to\nsearch for damages. Recently, the use of drones or helicopters for remote\nrecording is increasing in the industry, sparing the technicians this perilous\ntask. This, however, leaves the problem of analyzing big amounts of images,\nwhich has great potential for automation. This is a challenging task for\nseveral reasons. First, the lack of freely available training data and the\ndifficulty to collect it complicate this problem. Additionally, the boundaries\nof what constitutes a damage are fuzzy, introducing a degree of subjectivity in\nthe labelling of the data. The unbalanced class distribution in the images also\nplays a role in increasing the difficulty of the task. This paper tackles the\nproblem of structural damage detection in transmission towers, addressing these\nissues. Our main contributions are the development of a system for damage\ndetection on remotely acquired drone images, applying techniques to overcome\nthe issue of data scarcity and ambiguity, as well as the evaluation of the\nviability of such an approach to solve this particular problem.",
    "descriptor": "\nComments: 8 pages, 10 figures, accepted for VISAPP 2022\n",
    "authors": [
      "Aleixo Cambeiro Barreiro",
      "Clemens Seibold",
      "Anna Hilsmann",
      "Peter Eisert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15581"
  },
  {
    "id": "arXiv:2111.15588",
    "title": "Pureformer: Do We Even Need Attention?",
    "abstract": "In this paper we propose that the dot product pairwise matching attention\nlayer, which is widely used in transformer-based models, is redundant for the\nmodel performance. Attention in its original formulation has to be seen rather\nas a human-level tool to explore and/or visualize relevancy scores in the\nsequences. Instead, we present a simple and fast alternative without any\napproximation that, to the best of our knowledge, outperforms existing\nattention approximations on the text classification task from the Long-Range\nArena benchmark.",
    "descriptor": "",
    "authors": [
      "Uladzislau Yorsh",
      "Alexander Kovalenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15588"
  },
  {
    "id": "arXiv:2111.15592",
    "title": "MapReader: A Computer Vision Pipeline for the Semantic Exploration of  Maps at Scale",
    "abstract": "We present MapReader, a free, open-source software library written in Python\nfor analyzing large map collections (scanned or born-digital). This library\ntransforms the way historians can use maps by turning extensive, homogeneous\nmap sets into searchable primary sources. MapReader allows users with little or\nno computer vision expertise to i) retrieve maps via web-servers; ii)\npreprocess and divide them into patches; iii) annotate patches; iv) train,\nfine-tune, and evaluate deep neural network models; and v) create structured\ndata about map content. We demonstrate how MapReader enables historians to\ninterpret a collection of $\\approx$16K nineteenth-century Ordnance Survey map\nsheets ($\\approx$30.5M patches), foregrounding the challenge of translating\nvisual markers into machine-readable data. We present a case study focusing on\nBritish rail infrastructure and buildings as depicted on these maps. We also\nshow how the outputs from the MapReader pipeline can be linked to other,\nexternal datasets, which we use to evaluate as well as enrich and interpret the\nresults. We release $\\approx$62K manually annotated patches used here for\ntraining and evaluating the models.",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Kasra Hosseini",
      "Daniel C.S. Wilson",
      "Kaspar Beelen",
      "Katherine McDonough"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15592"
  },
  {
    "id": "arXiv:2111.15602",
    "title": "Fine-grained prediction of food insecurity using news streams",
    "abstract": "Anticipating the outbreak of a food crisis is crucial to efficiently allocate\nemergency relief and reduce human suffering. However, existing food insecurity\nearly warning systems rely on risk measures that are often delayed, outdated,\nor incomplete. Here, we leverage recent advances in deep learning to extract\nhigh-frequency precursors to food crises from the text of a large corpus of\nnews articles about fragile states published between 1980 and 2020. Our text\nfeatures are causally grounded, interpretable, validated by existing data, and\nallow us to predict 32% more food crises than existing models up to three\nmonths ahead of time at the district level across 15 fragile states. These\nresults could have profound implications on how humanitarian aid gets allocated\nand open new avenues for machine learning to improve decision making in\ndata-scarce environments.",
    "descriptor": "",
    "authors": [
      "Ananth Balashankar",
      "Lakshminarayanan Subramanian",
      "Samuel P. Fraiberger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15602"
  },
  {
    "id": "arXiv:2111.15603",
    "title": "Human Imperceptible Attacks and Applications to Improve Fairness",
    "abstract": "Modern neural networks are able to perform at least as well as humans in\nnumerous tasks involving object classification and image generation. However,\nsmall perturbations which are imperceptible to humans may significantly degrade\nthe performance of well-trained deep neural networks. We provide a\nDistributionally Robust Optimization (DRO) framework which integrates\nhuman-based image quality assessment methods to design optimal attacks that are\nimperceptible to humans but significantly damaging to deep neural networks.\nThrough extensive experiments, we show that our attack algorithm generates\nbetter-quality (less perceptible to humans) attacks than other state-of-the-art\nhuman imperceptible attack methods. Moreover, we demonstrate that DRO training\nusing our optimally designed human imperceptible attacks can improve group\nfairness in image classification. Towards the end, we provide an algorithmic\nimplementation to speed up DRO training significantly, which could be of\nindependent interest.",
    "descriptor": "",
    "authors": [
      "Xinru Hua",
      "Huanzhong Xu",
      "Jose Blanchet",
      "Viet Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15603"
  },
  {
    "id": "arXiv:2111.15606",
    "title": "Robust Partial-to-Partial Point Cloud Registration in a Full Range",
    "abstract": "Point cloud registration for 3D objects is very challenging due to sparse and\nnoisy measurements, incomplete observations and large transformations. In this\nwork, we propose Graph Matching Consensus Network (GMCNet), which estimates\npose-invariant correspondences for fullrange 1 Partial-to-Partial point cloud\nRegistration (PPR). To encode robust point descriptors, 1) we first\ncomprehensively investigate transformation-robustness and noiseresilience of\nvarious geometric features. 2) Then, we employ a novel Transformation-robust\nPoint Transformer (TPT) modules to adaptively aggregate local features\nregarding the structural relations, which takes advantage from both handcrafted\nrotation-invariant ($RI$) features and noise-resilient spatial coordinates. 3)\nBased on a synergy of hierarchical graph networks and graphical modeling, we\npropose the Hierarchical Graphical Modeling (HGM) architecture to encode robust\ndescriptors consisting of i) a unary term learned from $RI$ features; and ii)\nmultiple smoothness terms encoded from neighboring point relations at different\nscales through our TPT modules. Moreover, we construct a challenging PPR\ndataset (MVP-RG) with virtual scans. Extensive experiments show that GMCNet\noutperforms previous state-of-the-art methods for PPR. Remarkably, GMCNet\nencodes point descriptors for each point cloud individually without using\ncrosscontextual information, or ground truth correspondences for training. Our\ncode and datasets will be available at https://github.com/paul007pl/GMCNet.",
    "descriptor": "\nComments: 11 pages, 8 figures. Github Website: this https URL\n",
    "authors": [
      "Liang Pan",
      "Zhongang Cai",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15606"
  },
  {
    "id": "arXiv:2111.15611",
    "title": "The Power of Communication in a Distributed Multi-Agent System",
    "abstract": "Single-Agent (SA) Reinforcement Learning systems have shown outstanding\nre-sults on non-stationary problems. However, Multi-Agent Reinforcement\nLearning(MARL) can surpass SA systems generally and when scaling. Furthermore,\nMAsystems can be super-powered by collaboration, which can happen through\nob-serving others, or a communication system used to share information\nbetweencollaborators. Here, we developed a distributed MA learning mechanism\nwiththe ability to communicate based on decentralised partially observable\nMarkovdecision processes (Dec-POMDPs) and Graph Neural Networks (GNNs).\nMinimis-ing the time and energy consumed by training Machine Learning models\nwhileimproving performance can be achieved by collaborative MA mechanisms.\nWedemonstrate this in a real-world scenario, an offshore wind farm, including a\nset ofdistributed wind turbines, where the objective is to maximise collective\nefficiency.Compared to a SA system, MA collaboration has shown significantly\nreducedtraining time and higher cumulative rewards in unseen and scaled\nscenarios.",
    "descriptor": "\nComments: Cooperative AI Workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Philipp Dominic Siedler"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.15611"
  },
  {
    "id": "arXiv:2111.15613",
    "title": "The MIS Check-Dam Dataset for Object Detection and Instance Segmentation  Tasks",
    "abstract": "Deep learning has led to many recent advances in object detection and\ninstance segmentation, among other computer vision tasks. These advancements\nhave led to wide application of deep learning based methods and related\nmethodologies in object detection tasks for satellite imagery. In this paper,\nwe introduce MIS Check-Dam, a new dataset of check-dams from satellite imagery\nfor building an automated system for the detection and mapping of check-dams,\nfocusing on the importance of irrigation structures used for agriculture. We\nreview some of the most recent object detection and instance segmentation\nmethods and assess their performance on our new dataset. We evaluate several\nsingle stage, two-stage and attention based methods under various network\nconfigurations and backbone architectures. The dataset and the pre-trained\nmodels are available at https://www.cse.iitb.ac.in/gramdrishti/.",
    "descriptor": "",
    "authors": [
      "Chintan Tundia",
      "Rajiv Kumar",
      "Om Damani",
      "G. Sivakumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15613"
  },
  {
    "id": "arXiv:2111.15615",
    "title": "Semi-Local Convolutions for LiDAR Scan Processing",
    "abstract": "A number of applications, such as mobile robots or automated vehicles, use\nLiDAR sensors to obtain detailed information about their three-dimensional\nsurroundings. Many methods use image-like projections to efficiently process\nthese LiDAR measurements and use deep convolutional neural networks to predict\nsemantic classes for each point in the scan. The spatial stationary assumption\nenables the usage of convolutions. However, LiDAR scans exhibit large\ndifferences in appearance over the vertical axis. Therefore, we propose semi\nlocal convolution (SLC), a convolution layer with reduced amount of\nweight-sharing along the vertical dimension. We are first to investigate the\nusage of such a layer independent of any other model changes. Our experiments\ndid not show any improvement over traditional convolution layers in terms of\nsegmentation IoU or accuracy.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2004.11803\n",
    "authors": [
      "Larissa T. Triess",
      "David Peter",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15615"
  },
  {
    "id": "arXiv:2111.15617",
    "title": "Text Mining Drug/Chemical-Protein Interactions using an Ensemble of BERT  and T5 Based Models",
    "abstract": "In Track-1 of the BioCreative VII Challenge participants are asked to\nidentify interactions between drugs/chemicals and proteins. In-context named\nentity annotations for each drug/chemical and protein are provided and one of\nfourteen different interactions must be automatically predicted. For this\nrelation extraction task, we attempt both a BERT-based sentence classification\napproach, and a more novel text-to-text approach using a T5 model. We find that\nlarger BERT-based models perform better in general, with our BioMegatron-based\nmodel achieving the highest scores across all metrics, achieving 0.74 F1 score.\nThough our novel T5 text-to-text method did not perform as well as most of our\nBERT-based models, it outperformed those trained on similar data, showing\npromising results, achieving 0.65 F1 score. We believe a text-to-text approach\nto relation extraction has some competitive advantages and there is a lot of\nroom for research advancement.",
    "descriptor": "\nComments: Submission to the BioCreative VII challenge, Track-1\n",
    "authors": [
      "Virginia Adams",
      "Hoo-Chang Shin",
      "Carol Anderson",
      "Bo Liu",
      "Anas Abidin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15617"
  },
  {
    "id": "arXiv:2111.15620",
    "title": "Bayesian Level Set Approach for Inverse Problems with Piecewise Constant  Reconstructions",
    "abstract": "There are several challenges associated with inverse problems in which we\nseek to reconstruct a piecewise constant field, and which we model using\nmultiple level sets. Adopting a Bayesian viewpoint, we impose prior\ndistributions on both the level set functions that determine the piecewise\nconstant regions as well as the parameters that determine their magnitudes. We\ndevelop a Gauss-Newton approach with a backtracking line search to efficiently\ncompute the maximum a priori (MAP) estimate as a solution to the inverse\nproblem. We use the Gauss-Newton Laplace approximation to construct a Gaussian\napproximation of the posterior distribution and use preconditioned Krylov\nsubspace methods to sample from the resulting approximation. To visualize the\nuncertainty associated with the parameter reconstructions we compute the\napproximate posterior variance using a matrix-free Monte Carlo diagonal\nestimator, which we develop in this paper. We will demonstrate the benefits of\nour approach and solvers on synthetic test problems (photoacoustic and\nhydraulic tomography, respectively a linear and nonlinear inverse problem) as\nwell as an application to X-ray imaging with real data.",
    "descriptor": "",
    "authors": [
      "William Reese",
      "Arvind K. Saibaba",
      "Jonghyun Lee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.15620"
  },
  {
    "id": "arXiv:2111.15622",
    "title": "Chemical Identification and Indexing in PubMed Articles via BERT and  Text-to-Text Approaches",
    "abstract": "The Biocreative VII Track-2 challenge consists of named entity recognition,\nentity-linking (or entity-normalization), and topic indexing tasks -- with\nentities and topics limited to chemicals for this challenge. Named entity\nrecognition is a well-established problem and we achieve our best performance\nwith BERT-based BioMegatron models. We extend our BERT-based approach to the\nentity linking task. After the second stage of pretraining BioBERT with a\nmetric-learning loss strategy called self-alignment pretraining (SAP), we link\nentities based on the cosine similarity between their SAP-BioBERT word\nembeddings. Despite the success of our named entity recognition experiments, we\nfind the chemical indexing task generally more challenging.\nIn addition to conventional NER methods, we attempt both named entity\nrecognition and entity linking with a novel text-to-text or \"prompt\" based\nmethod that uses generative language models such as T5 and GPT. We achieve\nencouraging results with this new approach.",
    "descriptor": "\nComments: Submission to the BioCreative VII challenge - Track-2\n",
    "authors": [
      "Virginia Adams",
      "Hoo-Chang Shin",
      "Carol Anderson",
      "Bo Liu",
      "Anas Abidin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15622"
  },
  {
    "id": "arXiv:2111.15623",
    "title": "Towards Modularity Optimization Using Reinforcement Learning to  Community Detection in Dynamic Social Networks",
    "abstract": "The identification of community structure in a social network is an important\nproblem tackled in the literature of network analysis. There are many solutions\nto this problem using a static scenario, when facing a dynamic scenario some\nsolutions may be adapted but others simply do not fit, moreover when\nconsidering the demand to analyze constantly growing networks. In this context,\nwe propose an approach to the problem of community detection in dynamic\nnetworks based on a reinforcement learning strategy to deal with changes on big\nnetworks using a local optimization on the modularity score of the changed\nentities. An experiment using synthetic and real-world dynamic network data\nshows results comparable to static scenarios.",
    "descriptor": "",
    "authors": [
      "Aur\u00e9lio Ribeiro Costa"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15623"
  },
  {
    "id": "arXiv:2111.15624",
    "title": "Image Style Transfer and Content-Style Disentanglement",
    "abstract": "We propose a way of learning disentangled content-style representation of\nimage, allowing us to extrapolate images to any style as well as interpolate\nbetween any pair of styles. By augmenting data set in a supervised setting and\nimposing triplet loss, we ensure the separation of information encoded by\ncontent and style representation. We also make use of cycle-consistency loss to\nguarantee that images could be reconstructed faithfully by their\nrepresentation.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Sailun Xu",
      "Jiazhi Zhang",
      "Jiamei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15624"
  },
  {
    "id": "arXiv:2111.15629",
    "title": "DiPD: Disruptive event Prediction Dataset from Twitter",
    "abstract": "Riots and protests, if gone out of control, can cause havoc in a country. We\nhave seen examples of this, such as the BLM movement, climate strikes, CAA\nMovement, and many more, which caused disruption to a large extent. Our motive\nbehind creating this dataset was to use it to develop machine learning systems\nthat can give its users insight into the trending events going on and alert\nthem about the events that could lead to disruption in the nation. If any event\nstarts going out of control, it can be handled and mitigated by monitoring it\nbefore the matter escalates. This dataset collects tweets of past or ongoing\nevents known to have caused disruption and labels these tweets as 1. We also\ncollect tweets that are considered non-eventful and label them as 0 so that\nthey can also be used to train a classification system. The dataset contains\n94855 records of unique events and 168706 records of unique non-events, thus\ngiving the total dataset 263561 records. We extract multiple features from the\ntweets, such as the user's follower count and the user's location, to\nunderstand the impact and reach of the tweets. This dataset might be useful in\nvarious event related machine learning problems such as event classification,\nevent recognition, and so on.",
    "descriptor": "",
    "authors": [
      "Sanskar Soni",
      "Dev Mehta",
      "Vinush Vishwanath",
      "Aditi Seetha",
      "Satyendra Singh Chouhan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15629"
  },
  {
    "id": "arXiv:2111.15633",
    "title": "Scalable Community Extraction of Text Networks for Automated Grouping in  Medical Databases",
    "abstract": "Networks are ubiquitous in today's world. Community structure is a well-known\nfeature of many empirical networks, and a lot of statistical methods have been\ndeveloped for community detection. In this paper, we consider the problem of\ncommunity structure in text networks,which is greatly relevant in medical\nerrors and patient safety databases. We adapt a well-known community extraction\nmethod to develop a scalable algorithm for community extraction in large text\ndatabases. The application of our method on a real-world patient safety report\ndatabase demonstrates that the groups generated from community extraction are\nmuch more accurate than manual tagging by frontline workers.",
    "descriptor": "",
    "authors": [
      "Tomilayo Komolafe",
      "Allan Fong",
      "Srijan Sengupta"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.15633"
  },
  {
    "id": "arXiv:2111.15635",
    "title": "Improving random walk rankings with feature selection and imputation",
    "abstract": "The Science4cast Competition consists of predicting new links in a semantic\nnetwork, with each node representing a concept and each edge representing a\nlink proposed by a paper relating two concepts. This network contains\ninformation from 1994-2017, with a discretization of days (which represents the\npublication date of the underlying papers). Team Hash Brown's final submission,\n\\emph{ee5a}, achieved a score of 0.92738 on the test set. Our team's score\nranks \\emph{second place}, 0.01 below the winner's score. This paper details\nour model, its intuition, and the performance of its variations in the test\nset.",
    "descriptor": "",
    "authors": [
      "Ngoc Mai Tran",
      "Yangxinyu Xie"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15635"
  },
  {
    "id": "arXiv:2111.15637",
    "title": "BuildFormer: Automatic building extraction with vision transformer",
    "abstract": "Building extraction from fine-resolution remote sensing images plays a vital\nrole in numerous geospatial applications, such as urban planning, population\nstatistic, economic assessment and disaster management. With the advancement of\ndeep learning technology, deep convolutional neural networks (DCNNs) have\ndominated the automatic building extraction task for many years. However, the\nlocal property of DCNNs limits the extraction of global information, weakening\nthe ability of the network for recognizing the building instance. Recently, the\nTransformer comprises a hot topic in the computer vision domain and achieves\nstate-of-the-art performance in fundamental vision tasks, such as image\nclassification, semantic segmentation and object detection. Inspired by this,\nin this paper, we propose a novel transformer-based network for extracting\nbuildings from fine-resolution remote sensing images, namely BuildFormer. In\nComparision with the ResNet, the proposed method achieves an improvement of 2%\nin mIoU on the WHU building dataset.",
    "descriptor": "",
    "authors": [
      "Libo Wang",
      "Yuechi Yang",
      "Rui Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15637"
  },
  {
    "id": "arXiv:2111.15639",
    "title": "DeDUCE: Generating Counterfactual Explanations Efficiently",
    "abstract": "When an image classifier outputs a wrong class label, it can be helpful to\nsee what changes in the image would lead to a correct classification. This is\nthe aim of algorithms generating counterfactual explanations. However, there is\nno easily scalable method to generate such counterfactuals. We develop a new\nalgorithm providing counterfactual explanations for large image classifiers\ntrained with spectral normalisation at low computational cost. We empirically\ncompare this algorithm against baselines from the literature; our novel\nalgorithm consistently finds counterfactuals that are much closer to the\noriginal inputs. At the same time, the realism of these counterfactuals is\ncomparable to the baselines. The code for all experiments is available at\nhttps://github.com/benedikthoeltgen/DeDUCE.",
    "descriptor": "\nComments: Presented at the 1st Workshop on eXplainable AI approaches for debugging and diagnosis (XAI4Debugging@NeurIPS2021)\n",
    "authors": [
      "Benedikt H\u00f6ltgen",
      "Lisa Schut",
      "Jan M. Brauner",
      "Yarin Gal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.15639"
  },
  {
    "id": "arXiv:2111.15640",
    "title": "Diffusion Autoencoders: Toward a Meaningful and Decodable Representation",
    "abstract": "Diffusion probabilistic models (DPMs) have achieved remarkable quality in\nimage generation that rivals GANs'. But unlike GANs, DPMs use a set of latent\nvariables that lack semantic meaning and cannot serve as a useful\nrepresentation for other tasks. This paper explores the possibility of using\nDPMs for representation learning and seeks to extract a meaningful and\ndecodable representation of an input image via autoencoding. Our key idea is to\nuse a learnable encoder for discovering the high-level semantics, and a DPM as\nthe decoder for modeling the remaining stochastic variations. Our method can\nencode any image into a two-part latent code, where the first part is\nsemantically meaningful and linear, and the second part captures stochastic\ndetails, allowing near-exact reconstruction. This capability enables\nchallenging applications that currently foil GAN-based methods, such as\nattribute manipulation on real images. We also show that this two-level\nencoding improves denoising efficiency and naturally facil itates various\ndownstream tasks including few-shot conditional sampling.",
    "descriptor": "",
    "authors": [
      "Konpat Preechakul",
      "Nattanat Chatthee",
      "Suttisak Wizadwongsa",
      "Supasorn Suwajanakorn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15640"
  },
  {
    "id": "arXiv:2111.15641",
    "title": "Automatic Extraction of Medication Names in Tweets as Named Entity  Recognition",
    "abstract": "Social media posts contain potentially valuable information about medical\nconditions and health-related behavior. Biocreative VII Task 3 focuses on\nmining this information by recognizing mentions of medications and dietary\nsupplements in tweets. We approach this task by fine tuning multiple BERT-style\nlanguage models to perform token-level classification, and combining them into\nensembles to generate final predictions. Our best system consists of five\nMegatron-BERT-345M models and achieves a strict F1 score of 0.764 on unseen\ntest data.",
    "descriptor": "\nComments: Submission to the BioCreative VII challenge - Track-3\n",
    "authors": [
      "Carol Anderson",
      "Bo Liu",
      "Anas Abidin",
      "Hoo-Chang Shin",
      "Virginia Adams"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15641"
  },
  {
    "id": "arXiv:2111.15646",
    "title": "Exponentially Tilted Gaussian Prior for Variational Autoencoder",
    "abstract": "An important propertyfor deep neural networks to possess is the ability to\nperform robust out of distribution detection (OOD) on previously unseen data.\nThis property is essential for safety purposes when deploying models for real\nworld applications. Recent studies show that probabilistic generative models\ncan perform poorly on this task, which is surprising given that they seek to\nestimate the likelihood of training data. To alleviate this issue, we propose\nthe exponentially tilted Gaussian prior distribution for the Variational\nAutoencoder (VAE). With this prior, we are able to achieve state-of-the art\nresults using just the negative log likelihood that the VAE naturally assigns,\nwhile being orders of magnitude faster than some competitive methods. We also\nshow that our model produces high quality image samples which are more crisp\nthan that of a standard Gaussian VAE. The new prior distribution has a very\nsimple implementation which uses a Kullback Leibler divergence that compares\nthe difference between a latent vector's length, and the radius of a sphere.",
    "descriptor": "",
    "authors": [
      "Griffin Floto",
      "Stefan Kremer",
      "Mihai Nica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.15646"
  },
  {
    "id": "arXiv:2111.15651",
    "title": "Leveraging The Topological Consistencies of Learning in Deep Neural  Networks",
    "abstract": "Recently, methods have been developed to accurately predict the testing\nperformance of a Deep Neural Network (DNN) on a particular task, given\nstatistics of its underlying topological structure. However, further leveraging\nthis newly found insight for practical applications is intractable due to the\nhigh computational cost in terms of time and memory. In this work, we define a\nnew class of topological features that accurately characterize the progress of\nlearning while being quick to compute during running time. Additionally, our\nproposed topological features are readily equipped for backpropagation, meaning\nthat they can be incorporated in end-to-end training. Our newly developed\npractical topological characterization of DNNs allows for an additional set of\napplications. We first show we can predict the performance of a DNN without a\ntesting set and without the need for high-performance computing. We also\ndemonstrate our topological characterization of DNNs is effective in estimating\ntask similarity. Lastly, we show we can induce learning in DNNs by actively\nconstraining the DNN's topological structure. This opens up new avenues in\nconstricting the underlying structure of DNNs in a meta-learning framework.",
    "descriptor": "",
    "authors": [
      "Stuart Synakowski",
      "Fabian Benitez-Quiroz",
      "Aleix M. Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15651"
  },
  {
    "id": "arXiv:2111.15656",
    "title": "Attentive Prototypes for Source-free Unsupervised Domain Adaptive 3D  Object Detection",
    "abstract": "3D object detection networks tend to be biased towards the data they are\ntrained on. Evaluation on datasets captured in different locations, conditions\nor sensors than that of the training (source) data results in a drop in model\nperformance due to the gap in distribution with the test (or target) data.\nCurrent methods for domain adaptation either assume access to source data\nduring training, which may not be available due to privacy or memory concerns,\nor require a sequence of lidar frames as an input. We propose a single-frame\napproach for source-free, unsupervised domain adaptation of lidar-based 3D\nobject detectors that uses class prototypes to mitigate the effect pseudo-label\nnoise. Addressing the limitations of traditional feature aggregation methods\nfor prototype computation in the presence of noisy labels, we utilize a\ntransformer module to identify outlier ROI's that correspond to incorrect,\nover-confident annotations, and compute an attentive class prototype. Under an\niterative training strategy, the losses associated with noisy pseudo labels are\ndown-weighed and thus refined in the process of self-training. To validate the\neffectiveness of our proposed approach, we examine the domain shift associated\nwith networks trained on large, label-rich datasets (such as the Waymo Open\nDataset and nuScenes) and evaluate on smaller, label-poor datasets (such as\nKITTI) and vice-versa. We demonstrate our approach on two recent object\ndetectors and achieve results that out-perform the other domain adaptation\nworks.",
    "descriptor": "",
    "authors": [
      "Deepti Hegde",
      "Vishal Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15656"
  },
  {
    "id": "arXiv:2111.15657",
    "title": "Numerical solution of several second-order ordinary differential  equations containing logistic maps as nonlinear coefficients",
    "abstract": "This work is devoted to find the numerical solutions of several one\ndimensional second-order ordinary differential equations. In a heuristic way,\nin such equations the quadratic logistic maps regarded as a local function are\ninserted within the nonlinear coefficient of the function as well as within the\nindependent term. We apply the Numerov algorithm to solve these equations and\nwe discuss the role of the initial conditions of the logistic maps in such\nsolutions.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "J.L. Domenech-Garret",
      "C. Marin-Ferrer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2111.15657"
  },
  {
    "id": "arXiv:2111.15661",
    "title": "Open Data and Quantitative Techniques for Anthropology of Road Traffic",
    "abstract": "What kind of questions about human mobility can computational analysis help\nanswer? How to translate the findings into anthropology? We analyzed a publicly\navailable data set of road traffic counters in Slovenia to answer these\nquestions. The data reveals interesting information on how a nation drives, how\nit travels for tourism, which locations it prefers, what it does during the\nweek and the weekend, and how its habits change during the year. We conducted\nthe empirical analysis in two parts. First, we defined interesting traffic\nspots and designed computational methods to find them in a large data set. As\nshown in the paper, traffic counters hint at potential causes and effects in\ndriving practices that we can interpret anthropologically. Second, we used\nclustering to find groups of similar traffic counters as described by their\ndaily profiles. Clustering revealed the main features of road traffic in\nSlovenia. Using the two quantitative approaches, we outline the general\nproperties of road traffic in the country and identify and explain interesting\noutliers. We show that quantitative data analysis only partially answers\nanthropological questions, but it can be a valuable tool for preliminary\nresearch. We conclude that open data are a useful component in an\nanthropological analysis and that quantitative discovery of small local events\ncan help us pinpoint future fieldwork sites.",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "Ajda Pretnar \u017dagar",
      "Toma\u017e Ho\u010devar",
      "Toma\u017e Curk"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.15661"
  },
  {
    "id": "arXiv:2111.15662",
    "title": "HOTTBOX: Higher Order Tensor ToolBOX",
    "abstract": "HOTTBOX is a Python library for exploratory analysis and visualisation of\nmulti-dimensional arrays of data, also known as tensors. The library includes\nmethods ranging from standard multi-way operations and data manipulation\nthrough to multi-linear algebra based tensor decompositions. HOTTBOX also\ncomprises sophisticated algorithms for generalised multi-linear classification\nand data fusion, such as Support Tensor Machine (STM) and Tensor Ensemble\nLearning (TEL). For user convenience, HOTTBOX offers a unifying API which\nestablishes a self-sufficient ecosystem for various forms of efficient\nrepresentation of multi-way data and the corresponding decomposition and\nassociation algorithms. Particular emphasis is placed on scalability and\ninteractive visualisation, to support multidisciplinary data analysis\ncommunities working on big data and tensors. HOTTBOX also provides means for\nintegration with other popular data science libraries for visualisation and\ndata manipulation. The source code, examples and documentation ca be found at\nhttps://github.com/hottbox/hottbox.",
    "descriptor": "",
    "authors": [
      "Ilya Kisil",
      "Giuseppe G. Calvi",
      "Bruno S. Dees",
      "Danilo P. Mandic"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.15662"
  },
  {
    "id": "arXiv:2111.15664",
    "title": "Donut: Document Understanding Transformer without OCR",
    "abstract": "Understanding document images (e.g., invoices) has been an important research\ntopic and has many applications in document processing automation. Through the\nlatest advances in deep learning-based Optical Character Recognition (OCR),\ncurrent Visual Document Understanding (VDU) systems have come to be designed\nbased on OCR. Although such OCR-based approach promise reasonable performance,\nthey suffer from critical problems induced by the OCR, e.g., (1) expensive\ncomputational costs and (2) performance degradation due to the OCR error\npropagation. In this paper, we propose a novel VDU model that is end-to-end\ntrainable without underpinning OCR framework. To this end, we propose a new\ntask and a synthetic document image generator to pre-train the model to\nmitigate the dependencies on large-scale real document images. Our approach\nachieves state-of-the-art performance on various document understanding tasks\nin public benchmark datasets and private industrial service datasets. Through\nextensive experiments and analysis, we demonstrate the effectiveness of the\nproposed model especially with consideration for a real-world application.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Geewook Kim",
      "Teakgyu Hong",
      "Moonbin Yim",
      "Jinyoung Park",
      "Jinyeong Yim",
      "Wonseok Hwang",
      "Sangdoo Yun",
      "Dongyoon Han",
      "Seunghyun Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15664"
  },
  {
    "id": "arXiv:2111.15666",
    "title": "HyperStyle: StyleGAN Inversion with HyperNetworks for Real Image Editing",
    "abstract": "The inversion of real images into StyleGAN's latent space is a well-studied\nproblem. Nevertheless, applying existing approaches to real-world scenarios\nremains an open challenge, due to an inherent trade-off between reconstruction\nand editability: latent space regions which can accurately represent real\nimages typically suffer from degraded semantic control. Recent work proposes to\nmitigate this trade-off by fine-tuning the generator to add the target image to\nwell-behaved, editable regions of the latent space. While promising, this\nfine-tuning scheme is impractical for prevalent use as it requires a lengthy\ntraining phase for each new image. In this work, we introduce this approach\ninto the realm of encoder-based inversion. We propose HyperStyle, a\nhypernetwork that learns to modulate StyleGAN's weights to faithfully express a\ngiven image in editable regions of the latent space. A naive modulation\napproach would require training a hypernetwork with over three billion\nparameters. Through careful network design, we reduce this to be in line with\nexisting encoders. HyperStyle yields reconstructions comparable to those of\noptimization techniques with the near real-time inference capabilities of\nencoders. Lastly, we demonstrate HyperStyle's effectiveness on several\napplications beyond the inversion task, including the editing of out-of-domain\nimages which were never seen during training.",
    "descriptor": "\nComments: Project page available at this http URL\n",
    "authors": [
      "Yuval Alaluf",
      "Omer Tov",
      "Ron Mokady",
      "Rinon Gal",
      "Amit H. Bermano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15666"
  },
  {
    "id": "arXiv:2111.15667",
    "title": "ATS: Adaptive Token Sampling For Efficient Vision Transformers",
    "abstract": "While state-of-the-art vision transformer models achieve promising results\nfor image classification, they are computationally very expensive and require\nmany GFLOPs. Although the GFLOPs of a vision transformer can be decreased by\nreducing the number of tokens in the network, there is no setting that is\noptimal for all input images. In this work, we, therefore, introduce a\ndifferentiable parameter-free Adaptive Token Sampling (ATS) module, which can\nbe plugged into any existing vision transformer architecture. ATS empowers\nvision transformers by scoring and adaptively sampling significant tokens. As a\nresult, the number of tokens is not anymore static but it varies for each input\nimage. By integrating ATS as an additional layer within current transformer\nblocks, we can convert them into much more efficient vision transformers with\nan adaptive number of tokens. Since ATS is a parameter-free module, it can be\nadded to off-the-shelf pretrained vision transformers as a plug-and-play\nmodule, thus reducing their GFLOPs without any additional training. However,\ndue to its differentiable design, one can also train a vision transformer\nequipped with ATS. We evaluate our module on the ImageNet dataset by adding it\nto multiple state-of-the-art vision transformers. Our evaluations show that the\nproposed module improves the state-of-the-art by reducing the computational\ncost (GFLOPs) by 37% while preserving the accuracy.",
    "descriptor": "",
    "authors": [
      "Mohsen Fayyaz",
      "Soroush Abbasi Kouhpayegani",
      "Farnoush Rezaei Jafari",
      "Eric Sommerlade",
      "Hamid Reza Vaezi Joze",
      "Hamed Pirsiavash",
      "Juergen Gall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15667"
  },
  {
    "id": "arXiv:2111.15668",
    "title": "AdaViT: Adaptive Vision Transformers for Efficient Image Recognition",
    "abstract": "Built on top of self-attention mechanisms, vision transformers have\ndemonstrated remarkable performance on a variety of vision tasks recently.\nWhile achieving excellent performance, they still require relatively intensive\ncomputational cost that scales up drastically as the numbers of patches,\nself-attention heads and transformer blocks increase. In this paper, we argue\nthat due to the large variations among images, their need for modeling\nlong-range dependencies between patches differ. To this end, we introduce\nAdaViT, an adaptive computation framework that learns to derive usage policies\non which patches, self-attention heads and transformer blocks to use throughout\nthe backbone on a per-input basis, aiming to improve inference efficiency of\nvision transformers with a minimal drop of accuracy for image recognition.\nOptimized jointly with a transformer backbone in an end-to-end manner, a\nlight-weight decision network is attached to the backbone to produce decisions\non-the-fly. Extensive experiments on ImageNet demonstrate that our method\nobtains more than 2x improvement on efficiency compared to state-of-the-art\nvision transformers with only 0.8% drop of accuracy, achieving good\nefficiency/accuracy trade-offs conditioned on different computational budgets.\nWe further conduct quantitative and qualitative analysis on learned usage\npolices and provide more insights on the redundancy in vision transformers.",
    "descriptor": "",
    "authors": [
      "Lingchen Meng",
      "Hengduo Li",
      "Bor-Chun Chen",
      "Shiyi Lan",
      "Zuxuan Wu",
      "Yu-Gang Jiang",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15668"
  },
  {
    "id": "arXiv:2111.15669",
    "title": "360MonoDepth: High-Resolution 360\u00b0 Monocular Depth Estimation",
    "abstract": "360{\\deg} cameras can capture complete environments in a single shot, which\nmakes 360{\\deg} imagery alluring in many computer vision tasks. However,\nmonocular depth estimation remains a challenge for 360{\\deg} data, particularly\nfor high resolutions like 2K (2048$\\times$1024) that are important for\nnovel-view synthesis and virtual reality applications. Current CNN-based\nmethods do not support such high resolutions due to limited GPU memory. In this\nwork, we propose a flexible framework for monocular depth estimation from\nhigh-resolution 360{\\deg} images using tangent images. We project the 360{\\deg}\ninput image onto a set of tangent planes that produce perspective views, which\nare suitable for the latest, most accurate state-of-the-art perspective\nmonocular depth estimators. We recombine the individual depth estimates using\ndeformable multi-scale alignment followed by gradient-domain blending to\nimprove the consistency of disparity estimates. The result is a dense,\nhigh-resolution 360{\\deg} depth map with a high level of detail, also for\noutdoor scenes which are not supported by existing methods.",
    "descriptor": "",
    "authors": [
      "Manuel Rey-Area",
      "Mingze Yuan",
      "Christian Richardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15669"
  },
  {
    "id": "arXiv:2111.15672",
    "title": "Unsupervised Domain Adaptation: A Reality Check",
    "abstract": "Interest in unsupervised domain adaptation (UDA) has surged in recent years,\nresulting in a plethora of new algorithms. However, as is often the case in\nfast-moving fields, baseline algorithms are not tested to the extent that they\nshould be. Furthermore, little attention has been paid to validation methods,\ni.e. the methods for estimating the accuracy of a model in the absence of\ntarget domain labels. This is despite the fact that validation methods are a\ncrucial component of any UDA train/val pipeline. In this paper, we show via\nlarge-scale experimentation that 1) in the oracle setting, the difference in\naccuracy between UDA algorithms is smaller than previously thought, 2)\nstate-of-the-art validation methods are not well-correlated with accuracy, and\n3) differences between UDA algorithms are dwarfed by the drop in accuracy\ncaused by validation methods.",
    "descriptor": "",
    "authors": [
      "Kevin Musgrave",
      "Serge Belongie",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15672"
  },
  {
    "id": "arXiv:2106.00311",
    "title": "What's a good imputation to predict with missing values?",
    "abstract": "How to learn a good predictor on data with missing values? Most efforts focus\non first imputing as well as possible and second learning on the completed data\nto predict the outcome. Yet, this widespread practice has no theoretical\ngrounding. Here we show that for almost all imputation functions, an\nimpute-then-regress procedure with a powerful learner is Bayes optimal. This\nresult holds for all missing-values mechanisms, in contrast with the classic\nstatistical results that require missing-at-random settings to use imputation\nin probabilistic modeling. Moreover, it implies that perfect conditional\nimputation is not needed for good prediction asymptotically. In fact, we show\nthat on perfectly imputed data the best regression function will generally be\ndiscontinuous, which makes it hard to learn. Crafting instead the imputation so\nas to leave the regression function unchanged simply shifts the problem to\nlearning discontinuous imputations. Rather, we suggest that it is easier to\nlearn imputation and regression jointly. We propose such a procedure, adapting\nNeuMiss, a neural network capturing the conditional links across observed and\nunobserved variables whatever the missing-value pattern. Experiments confirm\nthat joint imputation and regression through NeuMiss is better than various two\nstep procedures in our experiments with finite number of samples.",
    "descriptor": "",
    "authors": [
      "Marine Le Morvan",
      "Julie Josse",
      "Erwan Scornet",
      "Ga\u00ebl Varoquaux"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00311"
  },
  {
    "id": "arXiv:2108.00670",
    "title": "Identify Light-Curve Signals with Deep Learning Based Object Detection  Algorithm. I. Transit Detection",
    "abstract": "Deep learning techniques have been well explored in the transiting exoplanet\nfield; however, previous work mainly focuses on classification and inspection.\nIn this work, we develop a novel detection algorithm based on a well proven\nobject detection framework in the computer vision field. Through training the\nnetwork on the light curves of the confirmed Kepler exoplanets, our model\nyields about 90% precision and recall for identifying transits with\nsignal-to-noise ratio higher than 6 (set the confidence threshold to 0.6).\nGiving a slightly lower confidence threshold, recall can reach higher than 95%.\nWe also transfer the trained model to the TESS data and obtain similar\nperformance. The results of our algorithm match the intuition of the human\nvisual perception and make it useful to find single-transiting candidates.\nMoreover, the parameters of the output bounding boxes can also help to find\nmultiplanet systems. Our network and detection functions are implemented in the\nDeep-Transit toolkit, which is an open-source Python package hosted on GitHub\nand PyPI.",
    "descriptor": "\nComments: 22 pages, 14 figures, 1 table, matches the version to be published in AJ\n",
    "authors": [
      "Kaiming Cui",
      "Junjie Liu",
      "Fabo Feng",
      "Jifeng Liu"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.00670"
  },
  {
    "id": "arXiv:2111.14842",
    "title": "Do We Still Need Automatic Speech Recognition for Spoken Language  Understanding?",
    "abstract": "Spoken language understanding (SLU) tasks are usually solved by first\ntranscribing an utterance with automatic speech recognition (ASR) and then\nfeeding the output to a text-based model. Recent advances in self-supervised\nrepresentation learning for speech data have focused on improving the ASR\ncomponent. We investigate whether representation learning for speech has\nmatured enough to replace ASR in SLU. We compare learned speech features from\nwav2vec 2.0, state-of-the-art ASR transcripts, and the ground truth text as\ninput for a novel speech-based named entity recognition task, a cardiac arrest\ndetection task on real-world emergency calls and two existing SLU benchmarks.\nWe show that learned speech features are superior to ASR transcripts on three\nclassification tasks. For machine translation, ASR transcripts are still the\nbetter choice. We highlight the intrinsic robustness of wav2vec 2.0\nrepresentations to out-of-vocabulary words as key to better performance.",
    "descriptor": "\nComments: Under review as a conference paper at ICASSP 2022\n",
    "authors": [
      "Lasse Borgholt",
      "Jakob Drachmann Havtorn",
      "Mostafa Abdou",
      "Joakim Edin",
      "Lars Maal\u00f8e",
      "Anders S\u00f8gaard",
      "Christian Igel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14842"
  },
  {
    "id": "arXiv:2111.14874",
    "title": "Weighing the Milky Way and Andromeda with Artificial Intelligence",
    "abstract": "We present new constraints on the masses of the halos hosting the Milky Way\nand Andromeda galaxies derived using graph neural networks. Our models, trained\non thousands of state-of-the-art hydrodynamic simulations of the CAMELS\nproject, only make use of the positions, velocities and stellar masses of the\ngalaxies belonging to the halos, and are able to perform likelihood-free\ninference on halo masses while accounting for both cosmological and\nastrophysical uncertainties. Our constraints are in agreement with estimates\nfrom other traditional methods.",
    "descriptor": "\nComments: 2 figures, 2 tables, 7 pages. Code publicly available at this https URL\n",
    "authors": [
      "Pablo Villanueva-Domingo",
      "Francisco Villaescusa-Navarro",
      "Shy Genel",
      "Daniel Angl\u00e9s-Alc\u00e1zar",
      "Lars Hernquist",
      "Federico Marinacci",
      "David N. Spergel",
      "Mark Vogelsberger",
      "Desika Narayanan"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14874"
  },
  {
    "id": "arXiv:2111.14916",
    "title": "High-Speed Light Focusing through Scattering Medium by Cooperatively  Accelerated Genetic Algorithm",
    "abstract": "We develop an accelerated Genetic Algorithm (GA) system constructed by the\ncooperation of field-programmable gate array (FPGA) and optimized parameters of\nthe GA. We found the enhanced decay of mutation rate makes convergence of the\nGA much faster, enabling the parameter-induced acceleration of the GA.\nFurthermore, the accelerated configuration of the GA is programmed in FPGA to\nboost processing speed at the hardware level without external computation\ndevices. This system has ability to focus light through scattering medium\nwithin 4 seconds with robust noise resistance and stable repetition\nperformance, which could be further reduced to millisecond level with advanced\nboard configuration. This study solves the long-term limitation of the GA, it\npromotes the applications of the GA in dynamic scattering mediums, with the\ncapability to tackle wavefront shaping in biological material.",
    "descriptor": "\nComments: 17 pages, 10 figures\n",
    "authors": [
      "Shu Guo",
      "Lin Pang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.14916"
  },
  {
    "id": "arXiv:2111.14953",
    "title": "Localized Perturbations For Weakly-Supervised Segmentation of Glioma  Brain Tumours",
    "abstract": "Deep convolutional neural networks (CNNs) have become an essential tool in\nthe medical imaging-based computer-aided diagnostic pipeline. However, training\naccurate and reliable CNNs requires large fine-grain annotated datasets. To\nalleviate this, weakly-supervised methods can be used to obtain local\ninformation from global labels. This work proposes the use of localized\nperturbations as a weakly-supervised solution to extract segmentation masks of\nbrain tumours from a pretrained 3D classification model. Furthermore, we\npropose a novel optimal perturbation method that exploits 3D superpixels to\nfind the most relevant area for a given classification using a U-net\narchitecture. Our method achieved a Dice similarity coefficient (DSC) of 0.44\nwhen compared with expert annotations. When compared against Grad-CAM, our\nmethod outperformed both in visualization and localization ability of the\ntumour region, with Grad-CAM only achieving 0.11 average DSC.",
    "descriptor": "",
    "authors": [
      "Sajith Rajapaksa",
      "Farzad Khalvati"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14953"
  },
  {
    "id": "arXiv:2111.14959",
    "title": "Improving the Segmentation of Pediatric Low-Grade Gliomas through  Multitask Learning",
    "abstract": "Brain tumor segmentation is a critical task for tumor volumetric analyses and\nAI algorithms. However, it is a time-consuming process and requires\nneuroradiology expertise. While there has been extensive research focused on\noptimizing brain tumor segmentation in the adult population, studies on AI\nguided pediatric tumor segmentation are scarce. Furthermore, MRI signal\ncharacteristics of pediatric and adult brain tumors differ, necessitating the\ndevelopment of segmentation algorithms specifically designed for pediatric\nbrain tumors. We developed a segmentation model trained on magnetic resonance\nimaging (MRI) of pediatric patients with low-grade gliomas (pLGGs) from The\nHospital for Sick Children (Toronto, Ontario, Canada). The proposed model\nutilizes deep Multitask Learning (dMTL) by adding tumor's genetic alteration\nclassifier as an auxiliary task to the main network, ultimately improving the\naccuracy of the segmentation results.",
    "descriptor": "",
    "authors": [
      "Partoo Vafaeikia",
      "Matthias W. Wagner",
      "Uri Tabori",
      "Birgit B. Ertl-Wagner",
      "Farzad Khalvati"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14959"
  },
  {
    "id": "arXiv:2111.14964",
    "title": "Fitness landscape adaptation in open replicator systems with  competition: application to cancer therapy",
    "abstract": "This study focuses on open quasispecies systems with competition and death\nflow, described by modified Eigen and Crow-Kimura models. We examine the\nevolutionary adaptation process as a reaction to changes in rates. One of the\nfundamental assumptions, which forms the basis of our mathematical model, is\nthe existence of two different timescales: internal dynamics time and\nevolutionary time. The latter is much slower and exhibits significant\nadaptation events. These conditions allow us to represent the whole\nevolutionary process through a series of steady-state equations, where all the\nelements continuously depend on the evolutionary parameter.",
    "descriptor": "",
    "authors": [
      "Igor Samokhin",
      "Tatiana Yakushkina",
      "Dmitry Markin",
      "Alexander S. Bratus"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.14964"
  },
  {
    "id": "arXiv:2111.14986",
    "title": "Feedback vertex sets in (directed) graphs of bounded degeneracy or  treewidth",
    "abstract": "We study the minimum size $f$ of a feedback vertex set in directed and\nundirected $n$-vertex graphs of given degeneracy or treewidth. In the\nundirected setting the bound $\\frac{k-1}{k+1}n$ is known to be tight for graphs\nwith bounded treewidth $k$ or bounded odd degeneracy $k$. We show that neither\nof the easy upper and lower bounds $\\frac{k-1}{k+1}n$ and $\\frac{k}{k+2}n$ can\nbe exact for the case of even degeneracy. More precisely, for even degeneracy\n$k$ we prove that $\\frac{3k-2}{3k+4}n\\leq f < \\frac{k}{k+2}n$.\nFor directed graphs of bounded degeneracy $k$, we prove that\n$f\\leq\\frac{k-1}{k+1}n$ and that this inequality is strict when $k$ is odd. For\ndirected graphs of bounded treewidth $k\\geq 2$, we show that\n$\\frac{k-2\\lfloor\\log_2(k)\\rfloor}{k+1}n\\leq f \\leq \\frac{k}{k+3}n$. Further,\nwe provide several constructions of low degeneracy or treewidth and large $f$.",
    "descriptor": "\nComments: 19 pages, 7 figures, 2 tables\n",
    "authors": [
      "Kolja Knauer",
      "Hoang La",
      "Petru Valicov"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.14986"
  },
  {
    "id": "arXiv:2111.14992",
    "title": "Network Traffic Shaping for Enhancing Privacy in IoT Systems",
    "abstract": "Motivated by privacy issues caused by inference attacks on user activities in\nthe packet sizes and timing information of Internet of Things (IoT) network\ntraffic, we establish a rigorous event-level differential privacy (DP) model on\ninfinite packet streams. We propose a memoryless traffic shaping mechanism\nsatisfying a first-come-first-served queuing discipline that outputs traffic\ndependent on the input using a DP mechanism. We show that in special cases the\nproposed mechanism recovers existing shapers which standardize the output\nindependently from the input. To find the optimal shapers for given levels of\nprivacy and transmission efficiency, we formulate the constrained problem of\nminimizing the expected delay per packet and propose using the expected queue\nsize across time as a proxy. We further show that the constrained minimization\nis a convex program. We demonstrate the effect of shapers on both synthetic\ndata and packet traces from actual IoT devices. The experimental results reveal\ninherent privacy-overhead tradeoffs: more shaping overhead provides better\nprivacy protection. Under the same privacy level, there naturally exists a\ntradeoff between dummy traffic and delay. When dealing with heavier or less\nbursty input traffic, all shapers become more overhead-efficient. We also show\nthat increased traffic from a larger number of IoT devices makes guaranteeing\nevent-level privacy easier. The DP shaper offers tunable privacy that is\ninvariant with the change in the input traffic distribution and has an\nadvantage in handling burstiness over traffic-independent shapers. This\napproach well accommodates heterogeneous network conditions and enables users\nto adapt to their privacy/overhead demands.",
    "descriptor": "\nComments: 18 pages, 10 figures, submitted to IEEE Transactions on Networking\n",
    "authors": [
      "Sijie Xiong",
      "Anand D. Sarwate",
      "Narayan B. Mandayam"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.14992"
  },
  {
    "id": "arXiv:2111.15040",
    "title": "X-ray Dissectography Enables Stereotography to Improve Diagnostic  Performance",
    "abstract": "X-ray imaging is the most popular medical imaging technology. While x-ray\nradiography is rather cost-effective, tissue structures are superimposed along\nthe x-ray paths. On the other hand, computed tomography (CT) reconstructs\ninternal structures but CT increases radiation dose, is complicated and\nexpensive. Here we propose \"x-ray dissectography\" to extract a target\norgan/tissue digitally from few radiographic projections for stereographic and\ntomographic analysis in the deep learning framework. As an exemplary\nembodiment, we propose a general X-ray dissectography network, a dedicated\nX-ray stereotography network, and the X-ray imaging systems to implement these\nfunctionalities. Our experiments show that x-ray stereography can be achieved\nof an isolated organ such as the lungs in this case, suggesting the feasibility\nof transforming conventional radiographic reading to the stereographic\nexamination of the isolated organ, which potentially allows higher sensitivity\nand specificity, and even tomographic visualization of the target. With further\nimprovements, x-ray dissectography promises to be a new x-ray imaging modality\nfor CT-grade diagnosis at radiation dose and system cost comparable to that of\nradiographic or tomosynthetic imaging.",
    "descriptor": "",
    "authors": [
      "Chuang Niu",
      "Ge Wang"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15040"
  },
  {
    "id": "arXiv:2111.15057",
    "title": "Multi-period facility location and capacity planning under  $\\infty$-Wasserstein joint chance constraints in humanitarian logistics",
    "abstract": "The key of the post-disaster humanitarian logistics (PD-HL) is to build a\ngood facility location and capacity planning (FLCP) model for delivering relief\nsupplies to affected areas in time. To fully exploit the historical PD data,\nthis paper adopts the data-driven distributionally robust (DR) approach and\nproposes a novel multi-period FLCP model under the $\\infty$-Wasserstein joint\nchance constraints (MFLCP-W). Specifically, we sequentially decide locations\nfrom a candidate set to build facilities with supply capacities, which are\nexpanded if more economical, and use a finite number of historical demand\nsamples in chance constraints to ensure a high probability of on-time delivery.\nTo solve the MFLCP-W model, we equivalently reformulate it as a mixed integer\nsecond-order cone program and then solve it by designing an effective outer\napproximation algorithm with two tailored valid cuts. Finally, a case study\nunder hurricane threats shows that MFLCP-W outperforms its counterparts in the\nterms of the cost and service quality, and that our algorithm converges\nsignificantly faster than the commercial solver CPLEX 12.8 with a better\noptimality gap.",
    "descriptor": "",
    "authors": [
      "Zhuolin Wang",
      "Keyou You",
      "Zhengli Wang",
      "Kanglin Liu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.15057"
  },
  {
    "id": "arXiv:2111.15058",
    "title": "Computing Generalized Rank invariant for 2-Parameter Persistence Modules  via Zigzag Persistence and its Applications",
    "abstract": "The notion of generalized rank invariant in the context of multiparameter\npersistence has become an important ingredient for defining interesting\nhomological structures such as generalized persistence diagrams. Naturally,\ncomputing these rank invariants efficiently is a prelude to computing any of\nthese derived structures efficiently. We show that the generalized rank\ninvariant over a finite interval $I$ of a $\\mathbb{Z}^2$-indexed persistence\nmodule $M$ is equal to the generalized rank invariant of the zigzag module that\nis induced on the boundary of $I$. Hence, we can compute the generalized rank\nover $I$ by computing the barcode of the zigzag module obtained by restricting\nthe bifiltration inducing $M$ to the boundary of $I$. If $I$ has $t$ points,\nthis computation takes $O(t^\\omega)$ time where $\\omega\\in[2,2.373)$ is the\nexponent for matrix multiplication. Among others, we apply this result to\nobtain an improved algorithm for the following problem. Given a bifiltration\ninducing a module $M$, determine whether $M$ is interval decomposable and, if\nso, compute all intervals supporting its summands. Our algorithm runs in time\n$O(t^{2\\omega})$ vastly improving upon existing algorithms for the problem.",
    "descriptor": "\nComments: 22 pages, 5 figures\n",
    "authors": [
      "Tamal K. Dey",
      "Woojin Kim",
      "Facundo M\u00e9moli"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2111.15058"
  },
  {
    "id": "arXiv:2111.15060",
    "title": "Second-order Approximation of Minimum Discrimination Information in  Independent Component Analysis",
    "abstract": "Independent Component Analysis (ICA) is intended to recover the mutually\nindependent sources from their linear mixtures, and F astICA is one of the most\nsuccessful ICA algorithms. Although it seems reasonable to improve the\nperformance of F astICA by introducing more nonlinear functions to the\nnegentropy estimation, the original fixed-point method (approximate Newton\nmethod) in F astICA degenerates under this circumstance. To alleviate this\nproblem, we propose a novel method based on the second-order approximation of\nminimum discrimination information (MDI). The joint maximization in our method\nis consisted of minimizing single weighted least squares and seeking unmixing\nmatrix by the fixed-point method. Experimental results validate its efficiency\ncompared with other popular ICA algorithms.",
    "descriptor": "",
    "authors": [
      "YunPeng Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.15060"
  },
  {
    "id": "arXiv:2111.15063",
    "title": "Online Robust Control of Linear Dynamical Systems with Prediction",
    "abstract": "We address the online robust control problem of a linear dynamical system\nwith adversarial cost functions and adversarial disturbances. The goal is to\nfind an online control policy that minimizes the disturbance gain, defined as\nthe ratio of the cumulative cost and the cumulative energy in the disturbances.\nThis problem is similar to the well-studied $\\mathcal{H}_{\\infty}$ problem in\nthe robust control literature. However, unlike the standard\n$\\mathcal{H}_{\\infty}$ problem, where the cost functions are quadratic and\nfully known, we consider a more challenging online control setting where the\ncost functions are general and unknown a priori. We first propose an online\nrobust control algorithm for the setting where the algorithm has access to an\n$N$-length preview of the future cost functions and future disturbances. We\nshow that, under standard system assumptions, with $N$ greater than a\nthreshold, the proposed algorithm can achieve a disturbance gain $(2+\\rho(N))\n\\overline{\\gamma}^2$, where $\\overline{\\gamma}^2$ is the best (minimum)\npossible disturbance gain for an oracle policy with full knowledge of the cost\nfunctions and disturbances, with $\\rho(N) = O(1/N)$. We then propose an online\nrobust control algorithm for a more challenging setting where only the preview\nof the cost functions is available. We show that under similar assumptions,\nwith $N$ greater than the same threshold, the proposed algorithm achieves a\ndisturbance gain of $6\\overline{\\gamma}^2$ with respect to the maximum\ncumulative energy in the disturbances.",
    "descriptor": "",
    "authors": [
      "Deepan Muthirayan",
      "Dileep Kalathil",
      "Pramod P. Khargonekar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.15063"
  },
  {
    "id": "arXiv:2111.15080",
    "title": "SurvODE: Extrapolating Gene Expression Distribution for Early Cancer  Identification",
    "abstract": "With the increasingly available large-scale cancer genomics datasets, machine\nlearning approaches have played an important role in revealing novel insights\ninto cancer development. Existing methods have shown encouraging performance in\nidentifying genes that are predictive for cancer survival, but are still\nlimited in modeling the distribution over genes. Here, we proposed a novel\nmethod that can simulate the gene expression distribution at any given time\npoint, including those that are out of the range of the observed time points.\nIn order to model the irregular time series where each patient is one\nobservation, we integrated a neural ordinary differential equation (neural ODE)\nwith cox regression into our framework. We evaluated our method on eight cancer\ntypes on TCGA and observed a substantial improvement over existing approaches.\nOur visualization results and further analysis indicate how our method can be\nused to simulate expression at the early cancer stage, offering the possibility\nfor early cancer identification.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Tong Chen",
      "Sheng Wang"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.15080"
  },
  {
    "id": "arXiv:2111.15144",
    "title": "Decoding the Protein-ligand Interactions Using Parallel Graph Neural  Networks",
    "abstract": "Protein-ligand interactions (PLIs) are fundamental to biochemical research\nand their identification is crucial for estimating biophysical and biochemical\nproperties for rational therapeutic design. Currently, experimental\ncharacterization of these properties is the most accurate method, however, this\nis very time-consuming and labor-intensive. A number of computational methods\nhave been developed in this context but most of the existing PLI prediction\nheavily depends on 2D protein sequence data. Here, we present a novel parallel\ngraph neural network (GNN) to integrate knowledge representation and reasoning\nfor PLI prediction to perform deep learning guided by expert knowledge and\ninformed by 3D structural data. We develop two distinct GNN architectures, GNNF\nis the base implementation that employs distinct featurization to enhance\ndomain-awareness, while GNNP is a novel implementation that can predict with no\nprior knowledge of the intermolecular interactions. The comprehensive\nevaluation demonstrated that GNN can successfully capture the binary\ninteractions between ligand and proteins 3D structure with 0.979 test accuracy\nfor GNNF and 0.958 for GNNP for predicting activity of a protein-ligand\ncomplex. These models are further adapted for regression tasks to predict\nexperimental binding affinities and pIC50 is crucial for drugs potency and\nefficacy. We achieve a Pearson correlation coefficient of 0.66 and 0.65 on\nexperimental affinity and 0.50 and 0.51 on pIC50 with GNNF and GNNP,\nrespectively, outperforming similar 2D sequence-based models. Our method can\nserve as an interpretable and explainable artificial intelligence (AI) tool for\npredicted activity, potency, and biophysical properties of lead candidates. To\nthis end, we show the utility of GNNP on SARS-Cov-2 protein targets by\nscreening a large compound library and comparing our prediction with the\nexperimentally measured data.",
    "descriptor": "",
    "authors": [
      "Carter Knutson",
      "Mridula Bontha",
      "Jenna A. Bilbrey",
      "Neeraj Kumar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.15144"
  },
  {
    "id": "arXiv:2111.15176",
    "title": "Learning Large-Time-Step Molecular Dynamics with Graph Neural Networks",
    "abstract": "Molecular dynamics (MD) simulation predicts the trajectory of atoms by\nsolving Newton's equation of motion with a numeric integrator. Due to physical\nconstraints, the time step of the integrator need to be small to maintain\nsufficient precision. This limits the efficiency of simulation. To this end, we\nintroduce a graph neural network (GNN) based model, MDNet, to predict the\nevolution of coordinates and momentum with large time steps. In addition, MDNet\ncan easily scale to a larger system, due to its linear complexity with respect\nto the system size. We demonstrate the performance of MDNet on a 4000-atom\nsystem with large time steps, and show that MDNet can predict good equilibrium\nand transport properties, well aligned with standard MD simulations.",
    "descriptor": "\nComments: 7 pages, 2 figures. NeurIPS 2021 AI for Science Workshop\n",
    "authors": [
      "Tianze Zheng",
      "Weihao Gao",
      "Chong Wang"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15176"
  },
  {
    "id": "arXiv:2111.15178",
    "title": "Sparse deep computer-generated holography for optical microscopy",
    "abstract": "Computer-generated holography (CGH) has broad applications such as\ndirect-view display, virtual and augmented reality, as well as optical\nmicroscopy. CGH usually utilizes a spatial light modulator that displays a\ncomputer-generated phase mask, modulating the phase of coherent light in order\nto generate customized patterns. The algorithm that computes the phase mask is\nthe core of CGH and is usually tailored to meet different applications. CGH for\noptical microscopy usually requires 3D accessibility (i.e., generating\noverlapping patterns along the $z$-axis) and micron-scale spatial precision.\nHere, we propose a CGH algorithm using an unsupervised generative model\ndesigned for optical microscopy to synthesize 3D selected illumination. The\nalgorithm, named sparse deep CGH, is able to generate sparsely distributed\npoints in a large 3D volume with higher contrast than conventional CGH\nalgorithms.",
    "descriptor": "\nComments: 5 pages, 4 figures, to be presented at NeurIPS 2021 Deep Learning and Inverse Problems workshop\n",
    "authors": [
      "Alex Liu",
      "Laura Waller",
      "Yi Xue"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15178"
  },
  {
    "id": "arXiv:2111.15187",
    "title": "HyperPCA: a Powerful Tool to Extract Elemental Maps from Noisy Data  Obtained in LIBS Mapping of Materials",
    "abstract": "Laser-induced breakdown spectroscopy is a preferred technique for fast and\ndirect multi-elemental mapping of samples under ambient pressure, without any\nlimitation on the targeted element. However, LIBS mapping data have two\npeculiarities: an intrinsically low signal-to-noise ratio due to single-shot\nmeasurements, and a high dimensionality due to the high number of spectra\nacquired for imaging. This is all the truer as lateral resolution gets higher:\nin this case, the ablation spot diameter is reduced, as well as the ablated\nmass and the emission signal, while the number of spectra for a given surface\nincreases. Therefore, efficient extraction of physico-chemical information from\na noisy and large dataset is a major issue. Multivariate approaches were\nintroduced by several authors as a means to cope with such data, particularly\nPrincipal Component Analysis. Yet, PCA is known to present theoretical\nconstraints for the consistent reconstruction of the dataset, and has therefore\nlimitations to efficient interpretation of LIBS mapping data. In this paper, we\nintroduce HyperPCA, a new analysis tool for hyperspectral images based on a\nsparse representation of the data using Discrete Wavelet Transform and\nkernel-based sparse PCA to reduce the impact of noise on the data and to\nconsistently reconstruct the spectroscopic signal, with a particular emphasis\non LIBS data. The method is first illustrated using simulated LIBS mapping\ndatasets to emphasize its performances with highly noisy and/or highly\ninterfered spectra. Comparisons to standard PCA and to traditional univariate\ndata analyses are provided. Finally, it is used to process real data in two\ncases that clearly illustrate the potential of the proposed algorithm. We show\nthat the method presents advantages both in quantity and quality of the\ninformation recovered, thus improving the physico-chemical characterisation of\nanalysed surfaces.",
    "descriptor": "\nComments: 20 pages, 8 pages of supplementary material\n",
    "authors": [
      "Riccardo Finotello",
      "Mohamed Tamaazousti",
      "Jean-Baptiste Sirven"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.15187"
  },
  {
    "id": "arXiv:2111.15191",
    "title": "Wideband Beamforming with Rainbow Beam Training using Reconfigurable  True-Time-Delay Arrays for Millimeter-Wave Wireless",
    "abstract": "The decadal research in integrated true-time-delay arrays have seen organic\ngrowth enabling realization of wideband beamformers for large arrays with wide\naperture widths. This article introduces highly reconfigurable delay elements\nimplementable at analog or digital baseband that enables multiple SSP functions\nincluding wideband beamforming, wideband interference cancellation, and fast\nbeam training. Details of the beam-training algorithm, system design\nconsiderations, system architecture and circuits with large delay\nrange-to-resolution ratios are presented leveraging integrated delay\ncompensation techniques. The article lays out the framework for true-time-delay\nbased arrays in next-generation network infrastructure supporting 3D beam\ntraining in planar arrays, low latency massive multiple access, and emerging\nwireless communications standards.",
    "descriptor": "",
    "authors": [
      "Chung-Ching Lin",
      "Veljko Boljanovic",
      "Han Yan",
      "Erfan Ghaderi",
      "Mohammad Ali Mokri",
      "Jayce Jeron Gaddis",
      "Aditya Wadaskar",
      "Chase Puglisi",
      "Soumen Mohapatra",
      "Qiuyan Xu",
      "Sreeni Poolakkal",
      "Deukhyoun Heo",
      "Subhanshu Gupta",
      "Danijela Cabric"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.15191"
  },
  {
    "id": "arXiv:2111.15196",
    "title": "PGNets: Planet mass prediction using convolutional neural networks for  radio continuum observations of protoplanetary disks",
    "abstract": "We developed Convolutional Neural Networks (CNNs) to rapidly and directly\ninfer the planet mass from radio dust continuum images. Substructures induced\nby young planets in protoplanetary disks can be used to infer the potential\nyoung planets' properties. Hydrodynamical simulations have been used to study\nthe relationships between the planet's properties and these disk features.\nHowever, these attempts either fine-tuned numerical simulations to fit one\nprotoplanetary disk at a time, which was time-consuming, or azimuthally\naveraged simulation results to derive some linear relationships between the gap\nwidth/depth and the planet mass, which lost information on asymmetric features\nin disks. To cope with these disadvantages, we developed Planet Gap neural\nNetworks (PGNets) to infer the planet mass from 2D images. We first fit the\ngridded data in Zhang et al. (2018) as a classification problem. Then, we\nquadrupled the data set by running additional simulations with near-randomly\nsampled parameters, and derived the planet mass and disk viscosity together as\na regression problem. The classification approach can reach an accuracy of\n92\\%, whereas the regression approach can reach 1$\\sigma$ as 0.16 dex for\nplanet mass and 0.23 dex for disk viscosity. We can reproduce the degeneracy\nscaling $\\alpha$ $\\propto$ $M_p^3$ found in the linear fitting method, which\nmeans that the CNN method can even be used to find degeneracy relationship. The\ngradient-weighted class activation mapping effectively confirms that PGNets use\nproper disk features to constrain the planet mass. We provide programs for\nPGNets and the traditional fitting method from Zhang et al. (2018), and discuss\neach method's advantages and disadvantages.",
    "descriptor": "\nComments: 12 pages, 7 figures, accepted to MNRAS\n",
    "authors": [
      "Shangjia Zhang",
      "Zhaohuan Zhu",
      "Mingon Kang"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15196"
  },
  {
    "id": "arXiv:2111.15200",
    "title": "Contrastive Learning for Local and Global Learning MRI Reconstruction",
    "abstract": "Magnetic Resonance Imaging (MRI) is an important medical imaging modality,\nwhile it requires a long acquisition time. To reduce the acquisition time,\nvarious methods have been proposed. However, these methods failed to\nreconstruct images with a clear structure for two main reasons. Firstly,\nsimilar patches widely exist in MR images, while most previous deep\nlearning-based methods ignore this property and only adopt CNN to learn local\ninformation. Secondly, the existing methods only use clear images to constrain\nthe upper bound of the solution space, while the lower bound is not\nconstrained, so that a better parameter of the network cannot be obtained. To\naddress these problems, we propose a Contrastive Learning for Local and Global\nLearning MRI Reconstruction Network (CLGNet). Specifically, according to the\nFourier theory, each value in the Fourier domain is calculated from all the\nvalues in Spatial domain. Therefore, we propose a Spatial and Fourier Layer\n(SFL) to simultaneously learn the local and global information in Spatial and\nFourier domains. Moreover, compared with self-attention and transformer, the\nSFL has a stronger learning ability and can achieve better performance in less\ntime. Based on the SFL, we design a Spatial and Fourier Residual block as the\nmain component of our model. Meanwhile, to constrain the lower bound and upper\nbound of the solution space, we introduce contrastive learning, which can pull\nthe result closer to the clear image and push the result further away from the\nundersampled image. Extensive experimental results on different datasets and\nacceleration rates demonstrate that the proposed CLGNet achieves new\nstate-of-the-art results.",
    "descriptor": "",
    "authors": [
      "Qiaosi Yi",
      "Jinhao Liu",
      "Le Hu",
      "Faming Fang",
      "Guixu Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15200"
  },
  {
    "id": "arXiv:2111.15275",
    "title": "Emotions as abstract evaluation criteria in biological and artificial  intelligences",
    "abstract": "Biological as well as advanced artificial intelligences (AIs) need to decide\nwhich goals to pursue. We review nature's solution to the time allocation\nproblem, which is based on a continuously readjusted categorical weighting\nmechanism we experience introspectively as emotions. One observes\nphylogenetically that the available number of emotional states increases hand\nin hand with the cognitive capabilities of animals and that raising levels of\nintelligence entail ever larger sets of behavioral options. Our ability to\nexperience a multitude of potentially conflicting feelings is in this view not\na leftover of a more primitive heritage, but a generic mechanism for\nattributing values to behavioral options that can not be specified at birth. In\nthis view, emotions are essential for understanding the mind.\nFor concreteness, we propose and discuss a framework which mimics emotions on\na functional level. Based on time allocation via emotional stationarity (TAES),\nemotions are implemented as abstract criteria, such as satisfaction, challenge\nand boredom, which serve to evaluate activities that have been carried out. The\nresulting timeline of experienced emotions is compared with the `character' of\nthe agent, which is defined in terms of a preferred distribution of emotional\nstates. The long-term goal of the agent, to align experience with character, is\nachieved by optimizing the frequency for selecting individual tasks. Upon\noptimization, the statistics of emotion experience becomes stationary.",
    "descriptor": "\nComments: Frontiers in Computational Neuroscience (in press). arXiv admin note: substantial text overlap with arXiv:1909.11700\n",
    "authors": [
      "Claudius Gros"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15275"
  },
  {
    "id": "arXiv:2111.15323",
    "title": "The signature and cusp geometry of hyperbolic knots",
    "abstract": "We introduce a new real-valued invariant called the natural slope of a\nhyperbolic knot in the 3-sphere, which is defined in terms of its cusp\ngeometry. We show that twice the knot signature and the natural slope differ by\nat most a constant times the hyperbolic volume divided by the cube of the\ninjectivity radius. This inequality was discovered using machine learning to\ndetect relationships between various knot invariants. It has applications to\nDehn surgery and to 4-ball genus. We also show a refined version of the\ninequality where the upper bound is a linear function of the volume, and the\nslope is corrected by terms corresponding to short geodesics that link the knot\nan odd number of times.",
    "descriptor": "\nComments: 26 pages, 12 figures\n",
    "authors": [
      "Alex Davies",
      "Andr\u00e1s Juh\u00e1sz",
      "Marc Lackenby",
      "Nenad Tomasev"
    ],
    "subjectives": [
      "Geometric Topology (math.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.15323"
  },
  {
    "id": "arXiv:2111.15365",
    "title": "Expert Aggregation for Financial Forecasting",
    "abstract": "Machine learning algorithms dedicated to financial time series forecasting\nhave gained a lot of interest over the last few years. One difficulty lies in\nthe choice between several algorithms, as their estimation accuracy may be\nunstable through time. In this paper, we propose to apply an online\naggregation-based forecasting model combining several machine learning\ntechniques to build a portfolio which dynamically adapts itself to market\nconditions. We apply this aggregation technique to the construction of a\nlong-short-portfolio of individual stocks ranked on their financial\ncharacteristics and we demonstrate how aggregation outperforms single\nalgorithms both in terms of performances and of stability.",
    "descriptor": "",
    "authors": [
      "Bri\u00e8re Marie",
      "Alasseur Cl\u00e9mence",
      "Joseph Mikael",
      "Carl Remlinger"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Portfolio Management (q-fin.PM)",
      "Risk Management (q-fin.RM)"
    ],
    "url": "https://arxiv.org/abs/2111.15365"
  },
  {
    "id": "arXiv:2111.15367",
    "title": "A Review on Graph Neural Network Methods in Financial Applications",
    "abstract": "Keeping the individual features and the complicated relations, graph data are\nwidely utilized and investigated. Being able to capture the structural\ninformation by updating and aggregating nodes' representations, graph neural\nnetwork (GNN) models are gaining popularity. In the financial context, the\ngraph is constructed based on real-world data, which leads to complex graph\nstructure and thus requires sophisticated methodology. In this work, we provide\na comprehensive review of GNN models in recent financial context. We first\ncategorize the commonly-used financial graphs and summarize the feature\nprocessing step for each node. Then we summarize the GNN methodology for each\ngraph type, application in each area, and propose some potential research\nareas.",
    "descriptor": "",
    "authors": [
      "Jianian Wang",
      "Sheng Zhang",
      "Yanghua Xiao",
      "Rui Song"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.15367"
  },
  {
    "id": "arXiv:2111.15409",
    "title": "Fully Automatic Deep Learning Framework for Pancreatic Ductal  Adenocarcinoma Detection on Computed Tomography",
    "abstract": "Early detection improves prognosis in pancreatic ductal adenocarcinoma (PDAC)\nbut is challenging as lesions are often small and poorly defined on\ncontrast-enhanced computed tomography scans (CE-CT). Deep learning can\nfacilitate PDAC diagnosis, however current models still fail to identify small\n(<2cm) lesions. In this study, state-of-the-art deep learning models were used\nto develop an automatic framework for PDAC detection, focusing on small\nlesions. Additionally, the impact of integrating surrounding anatomy was\ninvestigated. CE-CT scans from a cohort of 119 pathology-proven PDAC patients\nand a cohort of 123 patients without PDAC were used to train a nnUnet for\nautomatic lesion detection and segmentation (\\textit{nnUnet\\_T}). Two\nadditional nnUnets were trained to investigate the impact of anatomy\nintegration: (1) segmenting the pancreas and tumor (\\textit{nnUnet\\_TP}), (2)\nsegmenting the pancreas, tumor, and multiple surrounding anatomical structures\n(\\textit{nnUnet\\_MS}). An external, publicly available test set was used to\ncompare the performance of the three networks. The \\textit{nnUnet\\_MS} achieved\nthe best performance, with an area under the receiver operating characteristic\ncurve of 0.91 for the whole test set and 0.88 for tumors <2cm, showing that\nstate-of-the-art deep learning can detect small PDAC and benefits from anatomy\ninformation.",
    "descriptor": "",
    "authors": [
      "Nat\u00e1lia Alves",
      "Megan Schuurmans",
      "Geke Litjens",
      "Joeran S. Bosma",
      "John Hermans",
      "Henkjan Huisman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.15409"
  },
  {
    "id": "arXiv:2111.15426",
    "title": "Efficient and robust high-dimensional sparse logistic regression via  nonlinear primal-dual hybrid gradient algorithms",
    "abstract": "Logistic regression is a widely used statistical model to describe the\nrelationship between a binary response variable and predictor variables in data\nsets. It is often used in machine learning to identify important predictor\nvariables. This task, variable selection, typically amounts to fitting a\nlogistic regression model regularized by a convex combination of $\\ell_1$ and\n$\\ell_{2}^{2}$ penalties. Since modern big data sets can contain hundreds of\nthousands to billions of predictor variables, variable selection methods depend\non efficient and robust optimization algorithms to perform well.\nState-of-the-art algorithms for variable selection, however, were not\ntraditionally designed to handle big data sets; they either scale poorly in\nsize or are prone to produce unreliable numerical results. It therefore remains\nchallenging to perform variable selection on big data sets without access to\nadequate and costly computational resources. In this paper, we propose a\nnonlinear primal-dual algorithm that addresses these shortcomings.\nSpecifically, we propose an iterative algorithm that provably computes a\nsolution to a logistic regression problem regularized by an elastic net penalty\nin $O(T(m,n)\\log(1/\\epsilon))$ operations, where $\\epsilon \\in (0,1)$ denotes\nthe tolerance and $T(m,n)$ denotes the number of arithmetic operations required\nto perform matrix-vector multiplication on a data set with $m$ samples each\ncomprising $n$ features. This result improves on the known complexity bound of\n$O(\\min(m^2n,mn^2)\\log(1/\\epsilon))$ for first-order optimization methods such\nas the classic primal-dual hybrid gradient or forward-backward splitting\nmethods.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "J\u00e9r\u00f4me Darbon",
      "Gabriel P. Langlois"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15426"
  },
  {
    "id": "arXiv:2111.15471",
    "title": "Robust and Automated Method for Spike Detection and Removal in Magnetic  Resonance Imaging",
    "abstract": "Radio frequency (RF) spike noise is a common source of exogenous image\ncorruption in MRI. Spikes occur as point-like disturbances of $k$-space that\nlead to global sinusoidal intensity errors in the image domain. Depending on\nthe amplitude of the disturbances and their locations in $k$-space, the effect\nof a spike can be significant, often ruining the reconstructed images. Here we\npresent both a spike detection method and a related data correction method for\nautomatic correction of RF spike noise. To detect spikes, we found the\n$k$-space points that have the most significant effect on the total variation\nof the image. To replace the spikes, we used a compressed sensing\nreconstruction in which only the points thought to be corrupted are\nunconstrained. We demonstrated our technique in two cases: (1) in vivo gradient\necho brain data with artificially corrupted points and (2) actual, complex\nscanner data from a whole-body fat-water imaging gradient echo protocol\ncorrupted by spikes at uncertain locations. Our method allowed near-perfect\ndetection and correction with no human intervention. We calculated Matthews\ncorrelation coefficients and sensitivities above 0.95 for a maximum of 0.78\\%\ncorruption in synthetically corrupted in vivo brain data. We also found\nspecificities above 0.9994.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "David S. Smith",
      "Joel Kullberg",
      "Johan Berglund",
      "Malcolm J. Avison",
      "E. Brian Welch"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.15471"
  },
  {
    "id": "arXiv:2111.15486",
    "title": "Playing Ping Pong with Light: Directional Emission of White Light",
    "abstract": "Over the last decades, light-emitting diodes (LED) have replaced common light\nbulbs in almost every application, from flashlights in smartphones to\nautomotive headlights. Illuminating nightly streets requires LEDs to emit a\nlight spectrum that is perceived as pure white by the human eye. The power\nassociated with such a white light spectrum is not only distributed over the\ncontributing wavelengths but also over the angles of vision. For many\napplications, the usable light rays are required to exit the LED in forward\ndirection, namely under small angles to the perpendicular. In this work, we\ndemonstrate that a specifically designed multi-layer thin film on top of a\nwhite LED increases the power of pure white light emitted in forward direction.\nTherefore, the deduced multi-objective optimization problem is reformulated via\na real-valued physics-guided objective function that represents the\nhierarchical structure of our engineering problem. Variants of Bayesian\noptimization are employed to maximize this non-deterministic objective function\nbased on ray tracing simulations. Eventually, the investigation of optical\nproperties of suitable multi-layer thin films allowed to identify the mechanism\nbehind the increased directionality of white light: angle and wavelength\nselective filtering causes the multi-layer thin film to play ping pong with\nrays of light.",
    "descriptor": "\nComments: Under review for publication\n",
    "authors": [
      "Heribert Wankerl",
      "Christopher Wiesmann",
      "Laura Kreiner",
      "Rainer Butendeich",
      "Alexander Luce",
      "Sandra Sobczyk",
      "Maike Lorena Stern",
      "Elmar Wolfgang Lang"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2111.15486"
  },
  {
    "id": "arXiv:2111.15496",
    "title": "Bayesian Modelling of Multivalued Power Curves from an Operational Wind  Farm",
    "abstract": "Power curves capture the relationship between wind speed and output power for\na specific wind turbine. Accurate regression models of this function prove\nuseful in monitoring, maintenance, design, and planning. In practice, however,\nthe measurements do not always correspond to the ideal curve: power\ncurtailments will appear as (additional) functional components. Such\nmultivalued relationships cannot be modelled by conventional regression, and\nthe associated data are usually removed during pre-processing. The current work\nsuggests an alternative method to infer multivalued relationships in curtailed\npower data. Using a population-based approach, an overlapping mixture of\nprobabilistic regression models is applied to signals recorded from turbines\nwithin an operational wind farm. The model is shown to provide an accurate\nrepresentation of practical power data across the population.",
    "descriptor": "",
    "authors": [
      "L.A. Bull",
      "P.A. Gardner",
      "T.J. Rogers",
      "N. Dervilis",
      "E.J. Cross",
      "E. Papatheou",
      "A.E. Maguire",
      "C. Campos",
      "K. Worden"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15496"
  },
  {
    "id": "arXiv:2111.15498",
    "title": "Assessment of Data Consistency through Cascades of Independently  Recurrent Inference Machines for fast and robust accelerated MRI  reconstruction",
    "abstract": "Interpretability and robustness are imperative for integrating Machine\nLearning methods for accelerated Magnetic Resonance Imaging (MRI)\nreconstruction in clinical applications. Doing so would allow fast high-quality\nimaging of anatomy and pathology. Data Consistency (DC) is crucial for\ngeneralization in multi-modal data and robustness in detecting pathology. This\nwork proposes the Cascades of Independently Recurrent Inference Machines\n(CIRIM) to assess DC through unrolled optimization, implicitly by gradient\ndescent and explicitly by a designed term. We perform extensive comparison of\nthe CIRIM to other unrolled optimization methods, being the End-to-End\nVariational Network (E2EVN) and the RIM, and to the UNet and Compressed Sensing\n(CS). Evaluation is done in two stages. Firstly, learning on multiple trained\nMRI modalities is assessed, i.e., brain data with ${T_1}$-weighting and FLAIR\ncontrast, and ${T_2}$-weighted knee data. Secondly, robustness is tested on\nreconstructing pathology through white matter lesions in 3D FLAIR MRI data of\nrelapsing remitting Multiple Sclerosis (MS) patients. Results show that the\nCIRIM performs best when implicitly enforcing DC, while the E2EVN requires\nexplicitly formulated DC. The CIRIM shows the highest lesion contrast\nresolution in reconstructing the clinical MS data. Performance improves by\napproximately 11% compared to CS, while the reconstruction time is twenty times\nreduced.",
    "descriptor": "",
    "authors": [
      "D. Karkalousos",
      "S. Noteboom",
      "H. E. Hulst",
      "F.M. Vos",
      "M.W.A. Caan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.15498"
  },
  {
    "id": "arXiv:2111.15501",
    "title": "Hypergeometric Structures in Feynman Integrals",
    "abstract": "Hypergeometric structures in single and multiscale Feynman integrals emerge\nin a wide class of topologies. Using integration-by-parts relations, associated\nmaster or scalar integrals have to be calculated. For this purpose it appears\nuseful to devise an automated method which recognizes the respective (partial)\ndifferential equations related to the corresponding higher transcendental\nfunctions. We solve these equations through associated recursions of the\nexpansion coefficient of the multivalued formal Taylor series. The expansion\ncoefficients can be determined using either the package {\\tt Sigma} in the case\nof linear difference equations or by applying heuristic methods in the case of\npartial linear difference equations. In the present context a new type of sums\noccurs, the Hurwitz harmonic sums, and generalized versions of them. The code\n{\\tt HypSeries} transforming classes of differential equations into analytic\nseries expansions is described. Also partial difference equations having\nrational solutions and rational function solutions of Pochhammer symbols are\nconsidered, for which the code {\\tt solvePartialLDE} is designed. Generalized\nhypergeometric functions, Appell-,~Kamp\\'e de F\\'eriet-, Horn-,\nLauricella-Saran-, Srivasta-, and Exton--type functions are considered. We\nillustrate the algorithms by examples.",
    "descriptor": "\nComments: 55 pages, several anc. files\n",
    "authors": [
      "J. Bl\u00fcmlein",
      "M. Saragnese",
      "C. Schneider"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Symbolic Computation (cs.SC)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2111.15501"
  },
  {
    "id": "arXiv:2111.15519",
    "title": "Gram Barcodes for Histopathology Tissue Texture Retrieval",
    "abstract": "Recent advances in digital pathology have led to the need for Histopathology\nImage Retrieval (HIR) systems that search through databases of biopsy images to\nfind similar cases to a given query image. These HIR systems allow pathologists\nto effortlessly and efficiently access thousands of previously diagnosed cases\nin order to exploit the knowledge in the corresponding pathology reports. Since\nHIR systems may have to deal with millions of gigapixel images, the extraction\nof compact and expressive image features must be available to allow for\nefficient and accurate retrieval. In this paper, we propose the application of\nGram barcodes as image features for HIR systems. Unlike most feature generation\nschemes, Gram barcodes are based on high-order statistics that describe tissue\ntexture by summarizing the correlations between different feature maps in\nlayers of convolutional neural networks. We run HIR experiments on three public\ndatasets using a pre-trained VGG19 network for Gram barcode generation and\nshowcase highly competitive results.",
    "descriptor": "",
    "authors": [
      "Shalev Lifshitz",
      "Abtin Riasatian",
      "H.R. Tizhoosh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15519"
  },
  {
    "id": "arXiv:2111.15569",
    "title": "Scalable Machine Learning Architecture for Neonatal Seizure Detection on  Ultra-Edge Devices",
    "abstract": "Neonatal seizures are a commonly encountered neurological condition. They are\nthe first clinical signs of a serious neurological disorder. Thus, rapid\nrecognition and treatment are necessary to prevent serious fatalities. The use\nof electroencephalography (EEG) in the field of neurology allows precise\ndiagnosis of several medical conditions. However, interpreting EEG signals\nneeds the attention of highly specialized staff since the infant brain is\ndevelopmentally immature during the neonatal period. Detecting seizures on time\ncould potentially prevent the negative effects on the neurocognitive\ndevelopment of the infants. In recent years, neonatal seizure detection using\nmachine learning algorithms have been gaining traction. Since there is a need\nfor the classification of bio-signals to be computationally inexpensive in the\ncase of seizure detection, this research presents a machine learning (ML) based\narchitecture that operates with comparable predictive performance as previous\nmodels but with minimum level configuration. The proposed classifier was\ntrained and tested on a public dataset of NICU seizures recorded at the\nHelsinki University Hospital. Our architecture achieved a best sensitivity of\n87%, which is 6% more than that of the standard ML model chosen in this study.\nThe model size of the ML classifier is optimized to just 4.84 KB with minimum\nprediction time of 182.61 milliseconds, thus enabling it to be deployed on\nwearable ultra-edge devices for quick and accurate response and obviating the\nneed for cloud-based and other such exhaustive computational methods.",
    "descriptor": "\nComments: 6 pages, 5 figures, Accepted at 2nd International Conference on Artificial Intelligence and Signal Processing (AISP) 2022\n",
    "authors": [
      "Vishal Nagarajan",
      "Ashwini Muralidharan",
      "Deekshitha Sriraman",
      "Pravin Kumar S"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15569"
  },
  {
    "id": "arXiv:2111.15571",
    "title": "An Exact Algorithm for Semi-supervised Minimum Sum-of-Squares Clustering",
    "abstract": "The minimum sum-of-squares clustering (MSSC), or k-means type clustering, is\ntraditionally considered an unsupervised learning task. In recent years, the\nuse of background knowledge to improve the cluster quality and promote\ninterpretability of the clustering process has become a hot research topic at\nthe intersection of mathematical optimization and machine learning research.\nThe problem of taking advantage of background information in data clustering is\ncalled semi-supervised or constrained clustering. In this paper, we present a\nnew branch-and-bound algorithm for semi-supervised MSSC, where background\nknowledge is incorporated as pairwise must-link and cannot-link constraints.\nFor the lower bound procedure, we solve the semidefinite programming relaxation\nof the MSSC discrete optimization model, and we use a cutting-plane procedure\nfor strengthening the bound. For the upper bound, instead, by using integer\nprogramming tools, we propose an adaptation of the k-means algorithm to the\nconstrained case. For the first time, the proposed global optimization\nalgorithm efficiently manages to solve real-world instances up to 800 data\npoints with different combinations of must-link and cannot-link constraints and\nwith a generic number of features. This problem size is about four times larger\nthan the one of the instances solved by state-of-the-art exact algorithms.",
    "descriptor": "",
    "authors": [
      "Veronica Piccialli",
      "Anna Russo Russo",
      "Antonio M. Sudoso"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15571"
  },
  {
    "id": "arXiv:2111.15586",
    "title": "Homomorphic encoders of profinite abelian groups II",
    "abstract": "Let $\\{G_i :i\\in\\N\\}$ be a family of finite Abelian groups. We say that a\nsubgroup $G\\leq \\prod\\limits_{i\\in \\N}G_i$ is \\emph{order controllable} if for\nevery $i\\in \\mathbb{N}$ there is $n_i\\in \\mathbb{N}$ such that for each $c\\in\nG$, there exists $c_1\\in G$ satisfying that $c_{1|[1,i]}=c_{|[1,i]}$, $supp\n(c_1)\\subseteq [1,n_i]$, and order$(c_1)$ divides order$(c_{|[1,n_i]})$. In\nthis paper we investigate the structure of order controllable group codes. It\nis proved that if $G$ is an order controllable, shift invariant, group code\nover a finite abelian group $H$, then $G$ possesses a finite canonical\ngenerating set. Furthermore, our construction also yields that $G$ is\nalgebraically conjugate to a full group shift.",
    "descriptor": "\nComments: Portions of this work previously appeared as arXiv:2103.13135, which has been split\n",
    "authors": [
      "Mar\u00eda V. Ferrer",
      "Salvador Hern\u00e1ndez"
    ],
    "subjectives": [
      "General Topology (math.GN)",
      "Information Theory (cs.IT)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.15586"
  },
  {
    "id": "arXiv:2111.15589",
    "title": "The Quantum Multiple-Access Channel with Cribbing Encoders",
    "abstract": "Communication over a quantum multiple-access channel (MAC) with cribbing\nencoders is considered, whereby Transmitter 2 performs a measurement on a\nsystem that is entangled with Transmitter 1. Based on the no-cloning theorem,\nperfect cribbing is impossible. This leads to the introduction of a MAC model\nwith noisy cribbing. In the causal and non-causal cribbing scenarios,\nTransmitter 2 performs the measurement before the input of Transmitter 1 is\nsent through the channel. Hence, Transmitter 2's cribbing may inflict a \"state\ncollapse\" for Transmitter 1. Achievable regions are derived for each setting.\nFurthermore, a regularized capacity characterization is established for robust\ncribbing, i.e. when the cribbing system contains all the information of the\nchannel input. Building on the analogy between the noisy cribbing model and the\nrelay channel, a partial decode-forward region is derived for a quantum MAC\nwith non-robust cribbing. For the classical-quantum MAC with cribbing encoders,\nthe capacity region is determined with perfect cribbing of the classical input,\nand a cutset region is derived for noisy cribbing. In the special case of a\nclassical-quantum MAC with a deterministic cribbing channel, the inner and\nouter bounds coincide.",
    "descriptor": "",
    "authors": [
      "Uzi Pereg",
      "Christian Deppe",
      "Holger Boche"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.15589"
  },
  {
    "id": "arXiv:2111.15597",
    "title": "Surrogate-based optimization using an artificial neural network for a  parameter identification in a 3D marine ecosystem model",
    "abstract": "Parameter identification for marine ecosystem models is important for the\nassessment and validation of marine ecosystem models against observational\ndata. The surrogate-based optimization (SBO) is a computationally efficient\nmethod to optimize complex models. SBO replaces the computationally expensive\n(high-fidelity) model by a surrogate constructed from a less accurate but\ncomputationally cheaper (low-fidelity) model in combination with an appropriate\ncorrection approach, which improves the accuracy of the low-fidelity model. To\nconstruct a computationally cheap low-fidelity model, we tested three different\napproaches to compute an approximation of the annual periodic solution (i.e., a\nsteady annual cycle) of a marine ecosystem model: firstly, a reduced number of\nspin-up iterations (several decades instead of millennia), secondly, an\nartificial neural network (ANN) approximating the steady annual cycle and,\nfinally, a combination of both approaches. Except for the low-fidelity model\nusing only the ANN, the SBO yielded a solution close to the target and reduced\nthe computational effort significantly. If an ANN approximating appropriately a\nmarine ecosystem model is available, the SBO using this ANN as low-fidelity\nmodel presents a promising and computational efficient method for the\nvalidation.",
    "descriptor": "",
    "authors": [
      "Markus Pfeil",
      "Thomas Slawig"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2111.15597"
  },
  {
    "id": "arXiv:2111.15605",
    "title": "Synthetic weather radar using hybrid quantum-classical machine learning",
    "abstract": "The availability of high-resolution weather radar images underpins effective\nforecasting and decision-making. In regions beyond traditional radar coverage,\ngenerative models have emerged as an important synthetic capability, fusing\nmore ubiquitous data sources, such as satellite imagery and numerical weather\nmodels, into accurate radar-like products. Here, we demonstrate methods to\naugment conventional convolutional neural networks with quantum-assisted models\nfor generative tasks in global synthetic weather radar. We show that quantum\nkernels can, in principle, perform fundamentally more complex tasks than\nclassical learning machines on the relevant underlying data. Our results\nestablish synthetic weather radar as an effective heuristic benchmark for\nquantum computing capabilities and set the stage for detailed quantum advantage\nbenchmarking on a high-impact operationally relevant problem.",
    "descriptor": "",
    "authors": [
      "Graham R. Enos",
      "Matthew J. Reagor",
      "Maxwell P. Henderson",
      "Christina Young",
      "Kyle Horton",
      "Mandy Birch",
      "Chad Rigetti"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15605"
  },
  {
    "id": "arXiv:2111.15626",
    "title": "Variational Autoencoders for Studying the Manifold of Precoding Matrices  with High Spectral Efficiency",
    "abstract": "In multiple-input multiple-output (MIMO) wireless communications systems,\nneural networks have been employed for channel decoding, detection, channel\nestimation, and resource management. In this paper, we look at how to use a\nvariational autoencoder to find a precoding matrix with a high Spectral\nEfficiency (SE). To identify efficient precoding matrices, an optimization\napproach is used. Our objective is to create a less time-consuming algorithm\nwith minimum quality degradation. To build precoding matrices, we employed two\nforms of variational autoencoders: conventional variational autoencoders (VAE)\nand conditional variational autoencoders (CVAE). Both methods may be used to\nstudy a wide range of optimal precoding matrices. To the best of our knowledge,\nthe development of precoding matrices for the spectral efficiency objective\nfunction (SE) utilising VAE and CVAE methods is being published for the first\ntime.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Evgeny Bobrov",
      "Alexander Markov",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.15626"
  },
  {
    "id": "arXiv:2111.15631",
    "title": "Neural Symplectic Integrator with Hamiltonian Inductive Bias for the  Gravitational $N$-body Problem",
    "abstract": "The gravitational $N$-body problem, which is fundamentally important in\nastrophysics to predict the motion of $N$ celestial bodies under the mutual\ngravity of each other, is usually solved numerically because there is no known\ngeneral analytical solution for $N>2$. Can an $N$-body problem be solved\naccurately by a neural network (NN)? Can a NN observe long-term conservation of\nenergy and orbital angular momentum? Inspired by Wistom & Holman (1991)'s\nsymplectic map, we present a neural $N$-body integrator for splitting the\nHamiltonian into a two-body part, solvable analytically, and an interaction\npart that we approximate with a NN. Our neural symplectic $N$-body code\nintegrates a general three-body system for $10^{5}$ steps without diverting\nfrom the ground truth dynamics obtained from a traditional $N$-body integrator.\nMoreover, it exhibits good inductive bias by successfully predicting the\nevolution of $N$-body systems that are no part of the training set.",
    "descriptor": "\nComments: 7 pages, 2 figures, accepted for publication at the NeurIPS 2021 workshop \"Machine Learning and the Physical Sciences\"\n",
    "authors": [
      "Maxwell X. Cai",
      "Simon Portegies Zwart",
      "Damian Podareanu"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15631"
  },
  {
    "id": "arXiv:2111.15634",
    "title": "RPS: Portfolio Asset Selection using Graph based Representation Learning",
    "abstract": "Portfolio optimization is one of the essential fields of focus in finance.\nThere has been an increasing demand for novel computational methods in this\narea to compute portfolios with better returns and lower risks in recent years.\nWe present a novel computational method called Representation Portfolio\nSelection (RPS) by redefining the distance matrix of financial assets using\nRepresentation Learning and Clustering algorithms for portfolio selection to\nincrease diversification. RPS proposes a heuristic for getting closer to the\noptimal subset of assets. Using empirical results in this paper, we demonstrate\nthat widely used portfolio optimization algorithms, such as MVO, CLA, and HRP,\ncan benefit from our asset subset selection.",
    "descriptor": "",
    "authors": [
      "MohammadAmin Fazli",
      "Parsa Alian",
      "Ali Owfi",
      "Erfan Loghmani"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.15634"
  },
  {
    "id": "arXiv:2111.15636",
    "title": "Generating gapless land surface temperature with a high spatio-temporal  resolution by fusing multi-source satellite-observed and model-simulated data",
    "abstract": "Land surface temperature (LST) is a key parameter when monitoring land\nsurface processes. However, cloud contamination and the tradeoff between the\nspatial and temporal resolutions greatly impede the access to high-quality\nthermal infrared (TIR) remote sensing data. Despite the massive efforts made to\nsolve these dilemmas, it is still difficult to generate LST estimates with\nconcurrent spatial completeness and a high spatio-temporal resolution. Land\nsurface models (LSMs) can be used to simulate gapless LST with a high temporal\nresolution, but this usually comes with a low spatial resolution. In this\npaper, we present an integrated temperature fusion framework for\nsatellite-observed and LSM-simulated LST data to map gapless LST at a 60-m\nspatial resolution and half-hourly temporal resolution. The global linear model\n(GloLM) model and the diurnal land surface temperature cycle (DTC) model are\nrespectively performed as preprocessing steps for sensor and temporal\nnormalization between the different LST data. The Landsat LST, Moderate\nResolution Imaging Spectroradiometer (MODIS) LST, and Community Land Model\nVersion 5.0 (CLM 5.0)-simulated LST are then fused using a filter-based\nspatio-temporal integrated fusion model. Evaluations were implemented in an\nurban-dominated region (the city of Wuhan in China) and a natural-dominated\nregion (the Heihe River Basin in China), in terms of accuracy, spatial\nvariability, and diurnal temporal dynamics. Results indicate that the fused LST\nis highly consistent with actual Landsat LST data (in situ LST measurements),\nin terms of a Pearson correlation coefficient of 0.94 (0.97-0.99), a mean\nabsolute error of 0.71-0.98 K (0.82-3.17 K), and a root-mean-square error of\n0.97-1.26 K (1.09-3.97 K).",
    "descriptor": "",
    "authors": [
      "Jun Ma",
      "Huanfeng Shen",
      "Penghai Wu",
      "Jingan Wu",
      "Meiling Gao",
      "Chunlei Meng"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.15636"
  },
  {
    "id": "arXiv:2111.15638",
    "title": "Radio-Frequency Multi-Mode OAM Detection Based on UCA Samples Learning",
    "abstract": "Orbital angular momentum (OAM) at radio-frequency provides a novel approach\nof multiplexing a set of orthogonal modes on the same frequency channel to\nachieve high spectral efficiencies. However, classical phase gradient-based OAM\nmode detection methods require perfect alignment of transmit and receive\nantennas, which greatly challenges the practical application of OAM\ncommunications. In this paper, we first show the effect of non-parallel\nmisalignment on the OAM phase structure, and then propose the OAM mode\ndetection method based on uniform circular array (UCA) samples learning for the\nmore general alignment or non-parallel misalignment case. Specifically, we\napplied three classifiers: K-nearest neighbor (KNN), support vector machine\n(SVM), and back-propagation neural network (BPNN) to both single-mode and\nmulti-mode OAM detection. The simulation results validate that the proposed\nlearning-based OAM mode detection methods are robust to misalignment errors and\nespecially BPNN classifier has the best generalization performance.",
    "descriptor": "",
    "authors": [
      "Jiabei Fan",
      "Rui Chen",
      "Wen-Xuan Long",
      "Marco Moretti",
      "Jiandong Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15638"
  },
  {
    "id": "arXiv:2111.15645",
    "title": "Survey Descent: A Multipoint Generalization of Gradient Descent for  Nonsmooth Optimization",
    "abstract": "For strongly convex objectives that are smooth, the classical theory of\ngradient descent ensures linear convergence relative to the number of gradient\nevaluations. An analogous nonsmooth theory is challenging: even when the\nobjective is smooth at every iterate, the corresponding local models are\nunstable, and traditional remedies need unpredictably many cutting planes. We\ninstead propose a multipoint generalization of the gradient descent iteration\nfor local optimization. While designed with general objectives in mind, we are\nmotivated by a \"max-of-smooth\" model that captures subdifferential dimension at\noptimality. We prove linear convergence when the objective is itself\nmax-of-smooth, and experiments suggest a more general phenomenon.",
    "descriptor": "",
    "authors": [
      "X.Y. Han",
      "Adrian S. Lewis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.15645"
  },
  {
    "id": "arXiv:2111.15655",
    "title": "Studying Hadronization by Machine Learning Techniques",
    "abstract": "Hadronization is a non-perturbative process, which theoretical description\ncan not be deduced from first principles. Modeling hadron formation, requires\nseveral assumptions and various phenomenological approaches. Utilizing\nstate-of-the-art Computer Vision and Deep Learning algorithms, it is eventually\npossible to train neural networks to learn non-linear and non-perturbative\nfeatures of the physical processes. In this study, results of two ResNet\nnetworks are presented by investigating global and kinematical quantities,\nindeed jet- and event-shape variables. The widely used Lund string\nfragmentation model is applied as a baseline in $\\sqrt{s}= 7$ TeV proton-proton\ncollisions to predict the most relevant observables at further LHC energies.",
    "descriptor": "",
    "authors": [
      "G\u00e1bor B\u00edr\u00f3",
      "Bence Tank\u00f3-Bartalis",
      "Gergely G\u00e1bor Barnaf\u00f6ldi"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15655"
  },
  {
    "id": "arXiv:1603.03999",
    "title": "The Classification of Clifford Gates over Qubits",
    "abstract": "Comments: 47 pages; v3 - \"Stabilizer Operations\" is replaced by \"Clifford Gates\" in title. Improved writing and main decomposition theorem; v2 - Retracts claimed stabilizer ancilla for the Gamma gate",
    "descriptor": "\nComments: 47 pages; v3 - \"Stabilizer Operations\" is replaced by \"Clifford Gates\" in title. Improved writing and main decomposition theorem; v2 - Retracts claimed stabilizer ancilla for the Gamma gate\n",
    "authors": [
      "Daniel Grier",
      "Luke Schaeffer"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/1603.03999"
  },
  {
    "id": "arXiv:1705.04042",
    "title": "Robust Routing Made Easy",
    "abstract": "Robust Routing Made Easy",
    "descriptor": "",
    "authors": [
      "Christoph Lenzen",
      "Moti Medina",
      "Mehrdad Saberi",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/1705.04042"
  },
  {
    "id": "arXiv:1809.00964",
    "title": "Mathematical models for fake news",
    "abstract": "Comments: Version to appear as Chapter 18 in Financial Informatics: An Information-Based Approach to Asset Pricing. D. C. Brody, L. P. Hughston & A. Macrina (editors). Singapore: World Scientific Publishing Company (2022)",
    "descriptor": "\nComments: Version to appear as Chapter 18 in Financial Informatics: An Information-Based Approach to Asset Pricing. D. C. Brody, L. P. Hughston & A. Macrina (editors). Singapore: World Scientific Publishing Company (2022)\n",
    "authors": [
      "Dorje C. Brody",
      "David M. Meier"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1809.00964"
  },
  {
    "id": "arXiv:1810.02244",
    "title": "Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks",
    "abstract": "Comments: Extended version with proofs, accepted at AAAI 2019, added units of measurement of QM9 dataset into appendix, removed results from Wu et al., 2018 due to different units",
    "descriptor": "\nComments: Extended version with proofs, accepted at AAAI 2019, added units of measurement of QM9 dataset into appendix, removed results from Wu et al., 2018 due to different units\n",
    "authors": [
      "Christopher Morris",
      "Martin Ritzert",
      "Matthias Fey",
      "William L. Hamilton",
      "Jan Eric Lenssen",
      "Gaurav Rattan",
      "Martin Grohe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1810.02244"
  },
  {
    "id": "arXiv:1901.05750",
    "title": "TaDA Live: Compositional Reasoning for Termination of Fine-grained  Concurrent Programs",
    "abstract": "Comments: 84 pages, 131 pages including appendix",
    "descriptor": "\nComments: 84 pages, 131 pages including appendix\n",
    "authors": [
      "Emanuele D'Osualdo",
      "Azadeh Farzan",
      "Philippa Gardner",
      "Julian Sutherland"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1901.05750"
  },
  {
    "id": "arXiv:1903.02613",
    "title": "Security Issues in Language-based Software Ecosystems",
    "abstract": "Security Issues in Language-based Software Ecosystems",
    "descriptor": "",
    "authors": [
      "Ruturaj K. Vaidya",
      "Lorenzo De Carli",
      "Drew Davidson",
      "Vaibhav Rastogi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1903.02613"
  },
  {
    "id": "arXiv:1904.05014",
    "title": "Analysis of Beam Sweeping Techniques for Cell-Discovery in mm Wave  Systems",
    "abstract": "Analysis of Beam Sweeping Techniques for Cell-Discovery in mm Wave  Systems",
    "descriptor": "",
    "authors": [
      "Rashmi P",
      "Manoj A",
      "Arun Pachai Kannu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1904.05014"
  },
  {
    "id": "arXiv:1905.07135",
    "title": "Separating k-Player from t-Player One-Way Communication, with  Applications to Data Streams",
    "abstract": "Comments: Preliminary version appeared in ICALP 2019, submitted to ToC",
    "descriptor": "\nComments: Preliminary version appeared in ICALP 2019, submitted to ToC\n",
    "authors": [
      "Elbert Du",
      "Michael Mitzenmacher",
      "David P. Woodruff",
      "Guang Yang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/1905.07135"
  },
  {
    "id": "arXiv:2003.09166",
    "title": "TNT-KID: Transformer-based Neural Tagger for Keyword Identification",
    "abstract": "Comments: Accepted to Natural Language Engineering journal",
    "descriptor": "\nComments: Accepted to Natural Language Engineering journal\n",
    "authors": [
      "Matej Martinc",
      "Bla\u017e \u0160krlj",
      "Senja Pollak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2003.09166"
  },
  {
    "id": "arXiv:2005.02607",
    "title": "Towards quantum advantage via topological data analysis",
    "abstract": "Comments: 29 pages, 3 figures. New results added and improved exposition",
    "descriptor": "\nComments: 29 pages, 3 figures. New results added and improved exposition\n",
    "authors": [
      "Casper Gyurik",
      "Chris Cade",
      "Vedran Dunjko"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.02607"
  },
  {
    "id": "arXiv:2005.08551",
    "title": "Omni-supervised Facial Expression Recognition via Distilled Data",
    "abstract": "Omni-supervised Facial Expression Recognition via Distilled Data",
    "descriptor": "",
    "authors": [
      "Ping Liu",
      "Yunchao Wei",
      "Zibo Meng",
      "Weihong Deng",
      "Joey Tianyi Zhou",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.08551"
  },
  {
    "id": "arXiv:2006.00820",
    "title": "N 2 C : Neural Network Controller Design Using Behavioral Cloning",
    "abstract": "N 2 C : Neural Network Controller Design Using Behavioral Cloning",
    "descriptor": "",
    "authors": [
      "Shoaib Azam",
      "Farzeen Munir",
      "Muhammad Aasim Rafique",
      "Ahmad Muqeem Sheri",
      "Muhammad Ishfaq Hussain",
      "Moongu Jeon"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.00820"
  },
  {
    "id": "arXiv:2006.14551",
    "title": "Prediction with Approximated Gaussian Process Dynamical Models",
    "abstract": "Comments: This article has been accepted for publication by IEEE",
    "descriptor": "\nComments: This article has been accepted for publication by IEEE\n",
    "authors": [
      "Thomas Beckers",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.14551"
  },
  {
    "id": "arXiv:2007.01174",
    "title": "Robust Inverse Reinforcement Learning under Transition Dynamics Mismatch",
    "abstract": "Robust Inverse Reinforcement Learning under Transition Dynamics Mismatch",
    "descriptor": "",
    "authors": [
      "Luca Viano",
      "Yu-Ting Huang",
      "Parameswaran Kamalaruban",
      "Adrian Weller",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.01174"
  },
  {
    "id": "arXiv:2007.08806",
    "title": "Large random matrix approach for testing independence of a large number  of Gaussian time series",
    "abstract": "Comments: This version is identical to 2111.08047, but 2111.08047 should be deleted, only this repo 2007.08806 should exist",
    "descriptor": "\nComments: This version is identical to 2111.08047, but 2111.08047 should be deleted, only this repo 2007.08806 should exist\n",
    "authors": [
      "Philippe Loubaton",
      "Alexis Rosuel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2007.08806"
  },
  {
    "id": "arXiv:2007.11525",
    "title": "Analysis-aware defeaturing: problem setting and a posteriori estimation",
    "abstract": "Comments: 37 pages, 15 figures, 4 tables",
    "descriptor": "\nComments: 37 pages, 15 figures, 4 tables\n",
    "authors": [
      "Annalisa Buffa",
      "Ondine Chanon",
      "Rafael V\u00e1zquez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2007.11525"
  },
  {
    "id": "arXiv:2008.04145",
    "title": "A Full Second-Order Analysis of the Widely Linear MVDR Beamformer for  Noncircular Signals",
    "abstract": "A Full Second-Order Analysis of the Widely Linear MVDR Beamformer for  Noncircular Signals",
    "descriptor": "",
    "authors": [
      "Zhe Li",
      "Rui Pu",
      "Yili Xia",
      "Wenjiang Pei",
      "Danilo P. Mandic"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2008.04145"
  },
  {
    "id": "arXiv:2008.10582",
    "title": "A Unified and Fine-Grained Approach for Light Spanners",
    "abstract": "Comments: We split this paper into two papers: arXiv:2106.15596 and arXiv:2111.13748",
    "descriptor": "\nComments: We split this paper into two papers: arXiv:2106.15596 and arXiv:2111.13748\n",
    "authors": [
      "Hung Le",
      "Shay Solomon"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2008.10582"
  },
  {
    "id": "arXiv:2008.11047",
    "title": "Uncovering hidden dependency in weighted networks via information  entropy",
    "abstract": "Comments: 20 pages, 15 figures",
    "descriptor": "\nComments: 20 pages, 15 figures\n",
    "authors": [
      "Mi Jin Lee",
      "Eun Lee",
      "Byunghwee Lee",
      "Hawoong Jeong",
      "Deok-Sun Lee",
      "Sang Hoon Lee"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2008.11047"
  },
  {
    "id": "arXiv:2008.11520",
    "title": "A neural network multigrid solver for the Navier-Stokes equations",
    "abstract": "Comments: 32 pages, 15 figures",
    "descriptor": "\nComments: 32 pages, 15 figures\n",
    "authors": [
      "Nils Margenberg",
      "Dirk Hartmann",
      "Christian Lessig",
      "Thomas Richter"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.11520"
  },
  {
    "id": "arXiv:2009.03864",
    "title": "Contraction $\\mathcal{L}_1$-Adaptive Control using Gaussian Processes",
    "abstract": "Comments: Submitted to Learning for Dynamics and Control (L4DC) Conference, 2021",
    "descriptor": "\nComments: Submitted to Learning for Dynamics and Control (L4DC) Conference, 2021\n",
    "authors": [
      "Aditya Gahlawat",
      "Arun Lakshmanan",
      "Lin Song",
      "Andrew Patterson",
      "Zhuohuan Wu",
      "Naira Hovakimyan",
      "Evangelos Theodorou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2009.03864"
  },
  {
    "id": "arXiv:2009.07734",
    "title": "TreeGAN: Incorporating Class Hierarchy into Image Generation",
    "abstract": "TreeGAN: Incorporating Class Hierarchy into Image Generation",
    "descriptor": "",
    "authors": [
      "Ruisi Zhang",
      "Luntian Mou",
      "Pengtao Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.07734"
  },
  {
    "id": "arXiv:2009.08020",
    "title": "LDNet: End-to-End Lane Marking Detection Approach Using a Dynamic Vision  Sensor",
    "abstract": "LDNet: End-to-End Lane Marking Detection Approach Using a Dynamic Vision  Sensor",
    "descriptor": "",
    "authors": [
      "Farzeen Munir",
      "Shoaib Azam",
      "Moongu Jeon",
      "Byung-Geun Lee",
      "Witold Pedrycz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.08020"
  },
  {
    "id": "arXiv:2010.08233",
    "title": "Concurrent Process Histories and Resource Transducers",
    "abstract": "Comments: 22 pages. Many Figures. Extended version of this https URL",
    "descriptor": "\nComments: 22 pages. Many Figures. Extended version of this https URL\n",
    "authors": [
      "Chad Nester"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2010.08233"
  },
  {
    "id": "arXiv:2010.09470",
    "title": "Dos and Don'ts of Machine Learning in Computer Security",
    "abstract": "Comments: to appear at USENIX Security Symposium 2022",
    "descriptor": "\nComments: to appear at USENIX Security Symposium 2022\n",
    "authors": [
      "Daniel Arp",
      "Erwin Quiring",
      "Feargus Pendlebury",
      "Alexander Warnecke",
      "Fabio Pierazzi",
      "Christian Wressnegger",
      "Lorenzo Cavallaro",
      "Konrad Rieck"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.09470"
  },
  {
    "id": "arXiv:2011.00490",
    "title": "On the Distribution of SINR for Widely Linear MMSE MIMO Systems with  Rectilinear or Quasi-Rectilinear Signals",
    "abstract": "On the Distribution of SINR for Widely Linear MMSE MIMO Systems with  Rectilinear or Quasi-Rectilinear Signals",
    "descriptor": "",
    "authors": [
      "Wei Deng",
      "Yili Xia",
      "Zhe Li",
      "Wenjiang Pei"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2011.00490"
  },
  {
    "id": "arXiv:2011.04510",
    "title": "A posteriori verification of the positivity of solutions to elliptic  boundary value problems",
    "abstract": "Comments: 28 pages, 7 figures",
    "descriptor": "\nComments: 28 pages, 7 figures\n",
    "authors": [
      "Kazuaki Tanaka",
      "Taisei Asai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2011.04510"
  },
  {
    "id": "arXiv:2011.08045",
    "title": "A Novel Occupancy Mapping Framework for Risk-Aware Path Planning in  Unstructured Environments",
    "abstract": "Comments: Published in the Special Issue \"Frontiers in Mobile Robot Navigation\" of Sensors. this https URL",
    "descriptor": "\nComments: Published in the Special Issue \"Frontiers in Mobile Robot Navigation\" of Sensors. this https URL\n",
    "authors": [
      "Johann Laconte",
      "Abderrahim Kasmi",
      "Fran\u00e7ois Pomerleau",
      "Roland Chapuis",
      "Laurent Malaterre",
      "Christophe Debain",
      "Romuald Aufr\u00e8re"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.08045"
  },
  {
    "id": "arXiv:2011.12946",
    "title": "Exploratory LQG Mean Field Games with Entropy Regularization",
    "abstract": "Comments: To appear in Automatica",
    "descriptor": "\nComments: To appear in Automatica\n",
    "authors": [
      "Dena Firoozi",
      "Sebastian Jaimungal"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.12946"
  },
  {
    "id": "arXiv:2012.01867",
    "title": "Computational characteristics of feedforward neural networks for solving  a stiff differential equation",
    "abstract": "Computational characteristics of feedforward neural networks for solving  a stiff differential equation",
    "descriptor": "",
    "authors": [
      "Toni Schneidereit",
      "Michael Breu\u00df"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2012.01867"
  },
  {
    "id": "arXiv:2012.08868",
    "title": "Using Spatio-temporal Deep Learning for Forecasting Demand and  Supply-demand Gap in Ride-hailing System with Anonymised Spatial Adjacency  Information",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2012.15408",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2012.15408\n",
    "authors": [
      "M. H. Rahman",
      "S. M. Rifaat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.08868"
  },
  {
    "id": "arXiv:2012.09831",
    "title": "On Episodes, Prototypical Networks, and Few-shot Learning",
    "abstract": "Comments: 18 pages. To appear at NeurIPS 2021. A preliminary version of this work appeared as an oral presentation at the NeurIPS 2020 meta-learning workshop",
    "descriptor": "\nComments: 18 pages. To appear at NeurIPS 2021. A preliminary version of this work appeared as an oral presentation at the NeurIPS 2020 meta-learning workshop\n",
    "authors": [
      "Steinar Laenen",
      "Luca Bertinetto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.09831"
  },
  {
    "id": "arXiv:2101.00062",
    "title": "FGF-GAN: A Lightweight Generative Adversarial Network for Pansharpening  via Fast Guided Filter",
    "abstract": "Comments: Accepted by ICME 2021 (Oral)",
    "descriptor": "\nComments: Accepted by ICME 2021 (Oral)\n",
    "authors": [
      "Zixiang Zhao",
      "Jiangshe Zhang",
      "Shuang Xu",
      "Kai Sun",
      "Lu Huang",
      "Junmin Liu",
      "Chunxia Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2101.00062"
  },
  {
    "id": "arXiv:2101.00307",
    "title": "Quantifying Spatial Homogeneity of Urban Road Networks via Graph Neural  Networks",
    "abstract": "Comments: 17 pages, 5 figures",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Jiawei Xue",
      "Nan Jiang",
      "Senwei Liang",
      "Qiyuan Pang",
      "Takahiro Yabe",
      "Satish V. Ukkusuri",
      "Jianzhu Ma"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2101.00307"
  },
  {
    "id": "arXiv:2101.03531",
    "title": "Channel Boosting Feature Ensemble for Radar-based Object Detection",
    "abstract": "Channel Boosting Feature Ensemble for Radar-based Object Detection",
    "descriptor": "",
    "authors": [
      "Shoaib Azam",
      "Farzeen Munir",
      "Moongu Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.03531"
  },
  {
    "id": "arXiv:2101.03581",
    "title": "Curvature-based Feature Selection with Application in Classifying  Electronic Health Records",
    "abstract": "Comments: Accepted by Technological Forecasting and Social Change; Source code available",
    "descriptor": "\nComments: Accepted by Technological Forecasting and Social Change; Source code available\n",
    "authors": [
      "Zheming Zuo",
      "Jie Li",
      "Han Xu",
      "Noura Al Moubayed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.03581"
  },
  {
    "id": "arXiv:2101.03805",
    "title": "A Conflict-Based Search Framework for Multi-Objective Multi-Agent Path  Finding",
    "abstract": "Comments: 11 pages, preliminary version published in ICRA 2021, journal version submitted",
    "descriptor": "\nComments: 11 pages, preliminary version published in ICRA 2021, journal version submitted\n",
    "authors": [
      "Zhongqiang Ren",
      "Sivakumar Rathinam",
      "Howie Choset"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.03805"
  },
  {
    "id": "arXiv:2101.07711",
    "title": "Resource Bisimilarity in Petri Nets is Decidable",
    "abstract": "Comments: New version for submission to the journal",
    "descriptor": "\nComments: New version for submission to the journal\n",
    "authors": [
      "Irina Lomazova",
      "Vladimir Bashkin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2101.07711"
  },
  {
    "id": "arXiv:2101.09038",
    "title": "A Decentralized Analysis of Multiparty Protocols",
    "abstract": "Comments: revision following anonymous reviews",
    "descriptor": "\nComments: revision following anonymous reviews\n",
    "authors": [
      "Bas van den Heuvel",
      "Jorge A. P\u00e9rez"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2101.09038"
  },
  {
    "id": "arXiv:2101.10837",
    "title": "The Ikshana Hypothesis of Human Scene Understanding",
    "abstract": "Comments: 22 pages, 7 figures, Technical report",
    "descriptor": "\nComments: 22 pages, 7 figures, Technical report\n",
    "authors": [
      "Venkata Satya Sai Ajay Daliparthi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.10837"
  },
  {
    "id": "arXiv:2101.11174",
    "title": "Graph Neural Network for Traffic Forecasting: A Survey",
    "abstract": "Graph Neural Network for Traffic Forecasting: A Survey",
    "descriptor": "",
    "authors": [
      "Weiwei Jiang",
      "Jiayun Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.11174"
  },
  {
    "id": "arXiv:2101.11986",
    "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on  ImageNet",
    "abstract": "Comments: ICCV 2021, codes: this https URL",
    "descriptor": "\nComments: ICCV 2021, codes: this https URL\n",
    "authors": [
      "Li Yuan",
      "Yunpeng Chen",
      "Tao Wang",
      "Weihao Yu",
      "Yujun Shi",
      "Zihang Jiang",
      "Francis EH Tay",
      "Jiashi Feng",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.11986"
  },
  {
    "id": "arXiv:2102.07005",
    "title": "Clustering Interval-Censored Time-Series for Disease Phenotyping",
    "abstract": "Clustering Interval-Censored Time-Series for Disease Phenotyping",
    "descriptor": "",
    "authors": [
      "Irene Y. Chen",
      "Rahul G. Krishnan",
      "David Sontag"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07005"
  },
  {
    "id": "arXiv:2103.03150",
    "title": "SSTN: Self-Supervised Domain Adaptation Thermal Object Detection for  Autonomous Driving",
    "abstract": "SSTN: Self-Supervised Domain Adaptation Thermal Object Detection for  Autonomous Driving",
    "descriptor": "",
    "authors": [
      "Farzeen Munir",
      "Shoaib Azam",
      "Moongu Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03150"
  },
  {
    "id": "arXiv:2103.10366",
    "title": "Fast Consensus via the Unconstrained Undecided State Dynamics",
    "abstract": "Fast Consensus via the Unconstrained Undecided State Dynamics",
    "descriptor": "",
    "authors": [
      "Gregor Bankhamer",
      "Petra Berenbrink",
      "Felix Biermeier",
      "Robert Els\u00e4sser",
      "Hamed Hosseinpour",
      "Dominik Kaaser",
      "Peter Kling"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2103.10366"
  },
  {
    "id": "arXiv:2103.11093",
    "title": "Exploring The Effect of High-frequency Components in GANs Training",
    "abstract": "Exploring The Effect of High-frequency Components in GANs Training",
    "descriptor": "",
    "authors": [
      "Ziqiang Li",
      "Pengfei Xia",
      "Xue Rui",
      "Bin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11093"
  },
  {
    "id": "arXiv:2103.13135",
    "title": "Homomorphic encoders of profinite abelian groups I",
    "abstract": "Homomorphic encoders of profinite abelian groups I",
    "descriptor": "",
    "authors": [
      "Mar\u00eda V. Ferrer",
      "Salvador Hern\u00e1ndez"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Information Theory (cs.IT)",
      "General Topology (math.GN)"
    ],
    "url": "https://arxiv.org/abs/2103.13135"
  },
  {
    "id": "arXiv:2103.13998",
    "title": "GridDehazeNet+: An Enhanced Multi-Scale Network with Intra-Task  Knowledge Transfer for Single Image Dehazing",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1908.03245",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1908.03245\n",
    "authors": [
      "Xiaohong Liu",
      "Zhihao Shi",
      "Zijun Wu",
      "Jun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.13998"
  },
  {
    "id": "arXiv:2103.14400",
    "title": "Data-driven sparse skin stimulation can convey social touch information  to humans",
    "abstract": "Comments: Copyright 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: Copyright 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "M. Salvato",
      "Sophia R. Williams",
      "Cara M. Nunez",
      "Xin Zhu",
      "Ali Israr",
      "Frances Lau",
      "Keith Klumb",
      "Freddy Abnousi",
      "Allison M. Okamura",
      "Heather Culbertson"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2103.14400"
  },
  {
    "id": "arXiv:2103.15413",
    "title": "Collocation Polynomial Neural Forms and Domain Fragmentation for solving  Initial Value Problems",
    "abstract": "Collocation Polynomial Neural Forms and Domain Fragmentation for solving  Initial Value Problems",
    "descriptor": "",
    "authors": [
      "Toni Schneidereit",
      "Michael Breu\u00df"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2103.15413"
  },
  {
    "id": "arXiv:2104.02527",
    "title": "Vote from the Center: 6 DoF Pose Estimation in RGB-D Images by Radial  Keypoint Voting",
    "abstract": "Vote from the Center: 6 DoF Pose Estimation in RGB-D Images by Radial  Keypoint Voting",
    "descriptor": "",
    "authors": [
      "Yangzheng Wu",
      "Mohsen Zand",
      "Ali Etemad",
      "Michael Greenspan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.02527"
  },
  {
    "id": "arXiv:2104.04532",
    "title": "Neural RGB-D Surface Reconstruction",
    "abstract": "Comments: Project page: this https URL Video: this https URL",
    "descriptor": "\nComments: Project page: this https URL Video: this https URL\n",
    "authors": [
      "Dejan Azinovi\u0107",
      "Ricardo Martin-Brualla",
      "Dan B Goldman",
      "Matthias Nie\u00dfner",
      "Justus Thies"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.04532"
  },
  {
    "id": "arXiv:2104.06744",
    "title": "Defending Against Adversarial Denial-of-Service Data Poisoning Attacks",
    "abstract": "Comments: Published at ACSAC DYNAMICS 2020",
    "descriptor": "\nComments: Published at ACSAC DYNAMICS 2020\n",
    "authors": [
      "Nicolas M. M\u00fcller",
      "Simon Roschmann",
      "Konstantin B\u00f6ttinger"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.06744"
  },
  {
    "id": "arXiv:2104.06977",
    "title": "Discrete Cosine Transform Network for Guided Depth Map Super-Resolution",
    "abstract": "Discrete Cosine Transform Network for Guided Depth Map Super-Resolution",
    "descriptor": "",
    "authors": [
      "Zixiang Zhao",
      "Jiangshe Zhang",
      "Shuang Xu",
      "Zudi Lin",
      "Hanspeter Pfister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.06977"
  },
  {
    "id": "arXiv:2104.07200",
    "title": "A Novel Unified Framework for Solving Reachability, Viability and  Invariance Problems",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2101.09646",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2101.09646\n",
    "authors": [
      "Wei Liao",
      "Taotao Liang",
      "Xiaohui Wei",
      "Jizhou Lai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.07200"
  },
  {
    "id": "arXiv:2104.07639",
    "title": "Robust Optimization for Multilingual Translation with Imbalanced Data",
    "abstract": "Robust Optimization for Multilingual Translation with Imbalanced Data",
    "descriptor": "",
    "authors": [
      "Xian Li",
      "Hongyu Gong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07639"
  },
  {
    "id": "arXiv:2104.14042",
    "title": "Weather and Light Level Classification for Autonomous Driving: Dataset,  Baseline and Active Learning",
    "abstract": "Comments: Accepted for Oral Presentation at IEEE Intelligent Transportation Systems Conference (ITSC) 2021. Dataset is released in this https URL",
    "descriptor": "\nComments: Accepted for Oral Presentation at IEEE Intelligent Transportation Systems Conference (ITSC) 2021. Dataset is released in this https URL\n",
    "authors": [
      "Mahesh M Dhananjaya",
      "Varun Ravi Kumar",
      "Senthil Yogamani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.14042"
  },
  {
    "id": "arXiv:2104.14146",
    "title": "Compatibility of Partitions with Trees, Hierarchies, and Split Systems",
    "abstract": "Compatibility of Partitions with Trees, Hierarchies, and Split Systems",
    "descriptor": "",
    "authors": [
      "Marc Hellmuth",
      "David Schaller",
      "Peter F. Stadler"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2104.14146"
  },
  {
    "id": "arXiv:2105.02570",
    "title": "Capturing the diversity of multilingual societies",
    "abstract": "Comments: Main text: 12 pages, 6 figures, 51 references. Supplementary Information: 27 pages, 16 figures, 2 tables",
    "descriptor": "\nComments: Main text: 12 pages, 6 figures, 51 references. Supplementary Information: 27 pages, 16 figures, 2 tables\n",
    "authors": [
      "Thomas Louf",
      "David Sanchez",
      "Jose J. Ramasco"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.02570"
  },
  {
    "id": "arXiv:2105.02944",
    "title": "Semantics in Multi-objective Genetic Programming",
    "abstract": "Comments: 30 pages, 4 figures, 10 tables, journal article",
    "descriptor": "\nComments: 30 pages, 4 figures, 10 tables, journal article\n",
    "authors": [
      "Edgar Galv\u00e1n",
      "Leonardo Trujillo",
      "Fergal Stapleton"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.02944"
  },
  {
    "id": "arXiv:2105.03038",
    "title": "Lambek pregroups are Frobenius spiders in preorders",
    "abstract": "Comments: 21 pages, 16 diagrams. Accepted. Reviewers' suggestions implemented",
    "descriptor": "\nComments: 21 pages, 16 diagrams. Accepted. Reviewers' suggestions implemented\n",
    "authors": [
      "Dusko Pavlovic"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Computation and Language (cs.CL)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.03038"
  },
  {
    "id": "arXiv:2105.06068",
    "title": "On Sparsity Awareness in Distributed Computations",
    "abstract": "Comments: To appear in SPAA 2021",
    "descriptor": "\nComments: To appear in SPAA 2021\n",
    "authors": [
      "Keren Censor-Hillel",
      "Dean Leitersdorf",
      "Volodymyr Polosukhin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.06068"
  },
  {
    "id": "arXiv:2105.07147",
    "title": "FloorPlanCAD: A Large-Scale CAD Drawing Dataset for Panoptic Symbol  Spotting",
    "abstract": "Comments: v2, 17 pages, 16 figures",
    "descriptor": "\nComments: v2, 17 pages, 16 figures\n",
    "authors": [
      "Zhiwen Fan",
      "Lingjie Zhu",
      "Honghua Li",
      "Xiaohao Chen",
      "Siyu Zhu",
      "Ping Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07147"
  },
  {
    "id": "arXiv:2105.13086",
    "title": "Phone-Level Prosody Modelling with GMM-Based MDN for Diverse and  Controllable Speech Synthesis",
    "abstract": "Comments: Accepted to TASLP 2021",
    "descriptor": "\nComments: Accepted to TASLP 2021\n",
    "authors": [
      "Chenpeng Du",
      "Kai Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.13086"
  },
  {
    "id": "arXiv:2105.13381",
    "title": "Recent advances and clinical applications of deep learning in medical  image analysis",
    "abstract": "Comments: Added content: (1) Transformers in segmentation; (2) Unsupervised anomaly detection; (3) More backgrounds of self-supervised and semi-supervised learning; (4) Figure 1 (taxonomy). Other modifications: (1) Discussion was significantly expanded; (2) Attention mechanisms were introduced as one of the general strategies for performance boost; (3) The introduction of GANs was reduced",
    "descriptor": "\nComments: Added content: (1) Transformers in segmentation; (2) Unsupervised anomaly detection; (3) More backgrounds of self-supervised and semi-supervised learning; (4) Figure 1 (taxonomy). Other modifications: (1) Discussion was significantly expanded; (2) Attention mechanisms were introduced as one of the general strategies for performance boost; (3) The introduction of GANs was reduced\n",
    "authors": [
      "Xuxin Chen",
      "Ximin Wang",
      "Ke Zhang",
      "Roy Zhang",
      "Kar-Ming Fung",
      "Theresa C. Thai",
      "Kathleen Moore",
      "Robert S. Mannel",
      "Hong Liu",
      "Bin Zheng",
      "Yuchen Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.13381"
  },
  {
    "id": "arXiv:2105.14557",
    "title": "Robust Dynamic Network Embedding via Ensembles",
    "abstract": "Robust Dynamic Network Embedding via Ensembles",
    "descriptor": "",
    "authors": [
      "Chengbin Hou",
      "Guoji Fu",
      "Peng Yang",
      "Zheng Hu",
      "Shan He",
      "Ke Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14557"
  },
  {
    "id": "arXiv:2106.00311",
    "title": "What's a good imputation to predict with missing values?",
    "abstract": "What's a good imputation to predict with missing values?",
    "descriptor": "",
    "authors": [
      "Marine Le Morvan",
      "Julie Josse",
      "Erwan Scornet",
      "Ga\u00ebl Varoquaux"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00311"
  },
  {
    "id": "arXiv:2106.01099",
    "title": "Handling Non-Unitaries in Quantum Circuit Equivalence Checking",
    "abstract": "Comments: 7 pages, 4 figures, old title: \"Towards Verification of Dynamic Quantum Circuits\", revised manuscript, added experimental results",
    "descriptor": "\nComments: 7 pages, 4 figures, old title: \"Towards Verification of Dynamic Quantum Circuits\", revised manuscript, added experimental results\n",
    "authors": [
      "Lukas Burgholzer",
      "Robert Wille"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2106.01099"
  },
  {
    "id": "arXiv:2106.03135",
    "title": "Go with the Flows: Mixtures of Normalizing Flows for Point Cloud  Generation and Reconstruction",
    "abstract": "Go with the Flows: Mixtures of Normalizing Flows for Point Cloud  Generation and Reconstruction",
    "descriptor": "",
    "authors": [
      "Janis Postels",
      "Mengya Liu",
      "Riccardo Spezialetti",
      "Luc Van Gool",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03135"
  },
  {
    "id": "arXiv:2106.03987",
    "title": "Weakly Supervised Volumetric Image Segmentation with Deformed Templates",
    "abstract": "Comments: 13 Pages",
    "descriptor": "\nComments: 13 Pages\n",
    "authors": [
      "Udaranga Wickramasinghe",
      "Patrick M. Jensen",
      "Jiancheng Yang",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03987"
  },
  {
    "id": "arXiv:2106.04488",
    "title": "Low-Rank Subspaces in GANs",
    "abstract": "Low-Rank Subspaces in GANs",
    "descriptor": "",
    "authors": [
      "Jiapeng Zhu",
      "Ruili Feng",
      "Yujun Shen",
      "Deli Zhao",
      "Zhengjun Zha",
      "Jingren Zhou",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04488"
  },
  {
    "id": "arXiv:2106.07548",
    "title": "A scalable multi-step least squares method for network identification  with unknown disturbance topology",
    "abstract": "Comments: 17 pages, 4 figures, resubmitted to Automatica on 23 November 2021, provisionally accepted",
    "descriptor": "\nComments: 17 pages, 4 figures, resubmitted to Automatica on 23 November 2021, provisionally accepted\n",
    "authors": [
      "Stefanie J.M. Fonken",
      "Karthik R. Ramaswamy",
      "Paul M.J. Van den Hof"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07548"
  },
  {
    "id": "arXiv:2106.07996",
    "title": "Over-the-Air Equalization with Reconfigurable Intelligent Surfaces",
    "abstract": "Over-the-Air Equalization with Reconfigurable Intelligent Surfaces",
    "descriptor": "",
    "authors": [
      "Emre Arslan",
      "Ibrahim Yildirim",
      "Fatih Kilinc",
      "Ertugrul Basar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.07996"
  },
  {
    "id": "arXiv:2106.08138",
    "title": "Learning Full Configuration Interaction Electron Correlations with Deep  Learning",
    "abstract": "Comments: Accepted at Ml4Physical Sciences workshop at Neurips 2021",
    "descriptor": "\nComments: Accepted at Ml4Physical Sciences workshop at Neurips 2021\n",
    "authors": [
      "Hector H. Corzo",
      "Arijit Sehanobish",
      "Onur Kara"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08138"
  },
  {
    "id": "arXiv:2106.08601",
    "title": "Self-Supervised GANs with Label Augmentation",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Liang Hou",
      "Huawei Shen",
      "Qi Cao",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08601"
  },
  {
    "id": "arXiv:2106.08903",
    "title": "GemNet: Universal Directional Graph Neural Networks for Molecules",
    "abstract": "Comments: Published as a conference paper at NeurIPS 2021",
    "descriptor": "\nComments: Published as a conference paper at NeurIPS 2021\n",
    "authors": [
      "Johannes Klicpera",
      "Florian Becker",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08903"
  },
  {
    "id": "arXiv:2106.13700",
    "title": "ViTAS: Vision Transformer Architecture Search",
    "abstract": "ViTAS: Vision Transformer Architecture Search",
    "descriptor": "",
    "authors": [
      "Xiu Su",
      "Shan You",
      "Jiyang Xie",
      "Mingkai Zheng",
      "Fei Wang",
      "Chen Qian",
      "Changshui Zhang",
      "Xiaogang Wang",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13700"
  },
  {
    "id": "arXiv:2106.15535",
    "title": "Subgroup Generalization and Fairness of Graph Neural Networks",
    "abstract": "Comments: NeurIPS 2021 Spotlight",
    "descriptor": "\nComments: NeurIPS 2021 Spotlight\n",
    "authors": [
      "Jiaqi Ma",
      "Junwei Deng",
      "Qiaozhu Mei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15535"
  },
  {
    "id": "arXiv:2107.00389",
    "title": "Investigating the Reliability of Self-report Data in the Wild: The Quest  for Ground Truth",
    "abstract": "Investigating the Reliability of Self-report Data in the Wild: The Quest  for Ground Truth",
    "descriptor": "",
    "authors": [
      "Nan Gao",
      "Mohammad Saiedur Rahaman",
      "Wei Shao",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.00389"
  },
  {
    "id": "arXiv:2107.02170",
    "title": "On Model Calibration for Long-Tailed Object Detection and Instance  Segmentation",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Tai-Yu Pan",
      "Cheng Zhang",
      "Yandong Li",
      "Hexiang Hu",
      "Dong Xuan",
      "Soravit Changpinyo",
      "Boqing Gong",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02170"
  },
  {
    "id": "arXiv:2107.02233",
    "title": "End-to-End Weak Supervision",
    "abstract": "Comments: Code URL: this https URL",
    "descriptor": "\nComments: Code URL: this https URL\n",
    "authors": [
      "Salva R\u00fchling Cachay",
      "Benedikt Boecking",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.02233"
  },
  {
    "id": "arXiv:2107.02299",
    "title": "LightFuse: Lightweight CNN based Dual-exposure Fusion",
    "abstract": "LightFuse: Lightweight CNN based Dual-exposure Fusion",
    "descriptor": "",
    "authors": [
      "Ziyi Liu",
      "Jie Yang",
      "Svetlana Yanushkevich",
      "Orly Yadid-Pecht"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.02299"
  },
  {
    "id": "arXiv:2107.07103",
    "title": "Multilinear extension of $k$-submodular functions",
    "abstract": "Multilinear extension of $k$-submodular functions",
    "descriptor": "",
    "authors": [
      "Baoxiang Wang",
      "Huanjian Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.07103"
  },
  {
    "id": "arXiv:2107.07224",
    "title": "StyleVideoGAN: A Temporal Generative Model using a Pretrained StyleGAN",
    "abstract": "Comments: Final draft",
    "descriptor": "\nComments: Final draft\n",
    "authors": [
      "Gereon Fox",
      "Ayush Tewari",
      "Mohamed Elgharib",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07224"
  },
  {
    "id": "arXiv:2107.10224",
    "title": "CycleMLP: A MLP-like Architecture for Dense Prediction",
    "abstract": "Comments: Technical report. Code: this https URL",
    "descriptor": "\nComments: Technical report. Code: this https URL\n",
    "authors": [
      "Shoufa Chen",
      "Enze Xie",
      "Chongjian Ge",
      "Runjian Chen",
      "Ding Liang",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.10224"
  },
  {
    "id": "arXiv:2107.11472",
    "title": "Clipped Hyperbolic Classifiers Are Super-Hyperbolic Classifiers",
    "abstract": "Comments: 18 pages, 9 figures",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "Yunhui Guo",
      "Xudong Wang",
      "Yubei Chen",
      "Stella X. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.11472"
  },
  {
    "id": "arXiv:2107.11620",
    "title": "Joint Optimization of Wind Farm Layout Considering Optimal Control",
    "abstract": "Comments: Accepted by Renewable Energy",
    "descriptor": "\nComments: Accepted by Renewable Energy\n",
    "authors": [
      "Kaixuan Chen",
      "Jin Lin",
      "Yiwei Qiu",
      "Feng Liu",
      "Yonghua Song"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.11620"
  },
  {
    "id": "arXiv:2107.13576",
    "title": "Social Processes: Self-Supervised Meta-Learning over Conversational  Groups for Forecasting Nonverbal Social Cues",
    "abstract": "Comments: 12 pages, 8 pages Appendices, 10 figures, 8 tables",
    "descriptor": "\nComments: 12 pages, 8 pages Appendices, 10 figures, 8 tables\n",
    "authors": [
      "Chirag Raman",
      "Hayley Hung",
      "Marco Loog"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.13576"
  },
  {
    "id": "arXiv:2107.14228",
    "title": "Open-World Entity Segmentation",
    "abstract": "Comments: Project page: this http URL",
    "descriptor": "\nComments: Project page: this http URL\n",
    "authors": [
      "Lu Qi",
      "Jason Kuen",
      "Yi Wang",
      "Jiuxiang Gu",
      "Hengshuang Zhao",
      "Zhe Lin",
      "Philip Torr",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.14228"
  },
  {
    "id": "arXiv:2108.00213",
    "title": "Adversarial Robustness of Deep Code Comment Generation",
    "abstract": "Adversarial Robustness of Deep Code Comment Generation",
    "descriptor": "",
    "authors": [
      "Yu Zhou",
      "Xiaoqing Zhang",
      "Juanjuan Shen",
      "Tingting Han",
      "Taolue Chen",
      "Harald Gall"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2108.00213"
  },
  {
    "id": "arXiv:2108.01199",
    "title": "Neural Image Representations for Multi-Image Fusion and Layer Separation",
    "abstract": "Comments: Project page: this http URL",
    "descriptor": "\nComments: Project page: this http URL\n",
    "authors": [
      "Seonghyeon Nam",
      "Marcus A. Brubaker",
      "Michael S. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01199"
  },
  {
    "id": "arXiv:2108.01700",
    "title": "Parallel-in-time preconditioners for the Sinc-Nystr\u00f6m method",
    "abstract": "Comments: 23 pages, significantly revised from the first version",
    "descriptor": "\nComments: 23 pages, significantly revised from the first version\n",
    "authors": [
      "Jun Liu",
      "Shu-Lin Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.01700"
  },
  {
    "id": "arXiv:2108.06756",
    "title": "RLIBM-ALL: A Novel Polynomial Approximation Method to Produce Correctly  Rounded Results for Multiple Representations and Rounding Modes",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Jay P. Lim",
      "Santosh Nagarakatte"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2108.06756"
  },
  {
    "id": "arXiv:2108.06810",
    "title": "SCIDA: Self-Correction Integrated Domain Adaptation from Single- to  Multi-label Aerial Images",
    "abstract": "SCIDA: Self-Correction Integrated Domain Adaptation from Single- to  Multi-label Aerial Images",
    "descriptor": "",
    "authors": [
      "Tianze Yu",
      "Jianzhe Lin",
      "Lichao Mou",
      "Yuansheng Hua",
      "Xiaoxiang Zhu",
      "Z. Jane Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.06810"
  },
  {
    "id": "arXiv:2108.10048",
    "title": "How Transferable Are Self-supervised Features in Medical Image  Classification Tasks?",
    "abstract": "Comments: Accepted to Machine Learning for Health (ML4H) (ML4H 2021)",
    "descriptor": "\nComments: Accepted to Machine Learning for Health (ML4H) (ML4H 2021)\n",
    "authors": [
      "Tuan Truong",
      "Sadegh Mohammadi",
      "Matthias Lenga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.10048"
  },
  {
    "id": "arXiv:2108.12987",
    "title": "CAST: Enhancing Code Summarization with Hierarchical Splitting and  Reconstruction of Abstract Syntax Trees",
    "abstract": "Comments: Accepted by EMNLP 2021",
    "descriptor": "\nComments: Accepted by EMNLP 2021\n",
    "authors": [
      "Ensheng Shi",
      "Yanlin Wang",
      "Lun Du",
      "Hongyu Zhang",
      "Shi Han",
      "Dongmei Zhang",
      "Hongbin Sun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2108.12987"
  },
  {
    "id": "arXiv:2108.13341",
    "title": "Hire-MLP: Vision MLP via Hierarchical Rearrangement",
    "abstract": "Hire-MLP: Vision MLP via Hierarchical Rearrangement",
    "descriptor": "",
    "authors": [
      "Jianyuan Guo",
      "Yehui Tang",
      "Kai Han",
      "Xinghao Chen",
      "Han Wu",
      "Chao Xu",
      "Chang Xu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13341"
  },
  {
    "id": "arXiv:2109.01896",
    "title": "GamePlan: Game-Theoretic Multi-Agent Planning with Human Drivers at  Intersections, Roundabouts, and Merging",
    "abstract": "Comments: Added Appendix and Supplementary material",
    "descriptor": "\nComments: Added Appendix and Supplementary material\n",
    "authors": [
      "Rohan Chandra",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.01896"
  },
  {
    "id": "arXiv:2109.03159",
    "title": "Analysis of Regularized Learning in Banach Spaces",
    "abstract": "Comments: 30 pages, 1 figure",
    "descriptor": "\nComments: 30 pages, 1 figure\n",
    "authors": [
      "Qi Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.03159"
  },
  {
    "id": "arXiv:2109.05750",
    "title": "Spatial-Separated Curve Rendering Network for Efficient and  High-Resolution Image Harmonization",
    "abstract": "Spatial-Separated Curve Rendering Network for Efficient and  High-Resolution Image Harmonization",
    "descriptor": "",
    "authors": [
      "Jingtang Liang",
      "Xiaodong Cun",
      "Chi-Man Pun",
      "Jue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05750"
  },
  {
    "id": "arXiv:2109.06730",
    "title": "A Hierarchical Control Framework for Drift Maneuvering of Autonomous  Vehicles",
    "abstract": "A Hierarchical Control Framework for Drift Maneuvering of Autonomous  Vehicles",
    "descriptor": "",
    "authors": [
      "Bo Yang",
      "Yiwen Lu",
      "Xu Yang",
      "Yilin Mo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06730"
  },
  {
    "id": "arXiv:2109.07101",
    "title": "Delay-aware Robust Control for Safe Autonomous Driving",
    "abstract": "Comments: Under review at ICRA 2022",
    "descriptor": "\nComments: Under review at ICRA 2022\n",
    "authors": [
      "Dvij Kalaria",
      "Qin Lin",
      "John M. Dolan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07101"
  },
  {
    "id": "arXiv:2109.07270",
    "title": "Distract Your Attention: Multi-head Cross Attention Network for Facial  Expression Recognition",
    "abstract": "Distract Your Attention: Multi-head Cross Attention Network for Facial  Expression Recognition",
    "descriptor": "",
    "authors": [
      "Zhengyao Wen",
      "Wenzhong Lin",
      "Tao Wang",
      "Ge Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07270"
  },
  {
    "id": "arXiv:2109.12029",
    "title": "Identifying Distributional Differences in Convective Evolution Prior to  Rapid Intensification in Tropical Cyclones",
    "abstract": "Comments: 7 pages, 4 figures, Tackling Climate Change with Machine Learning: workshop at NeurIPS 2021",
    "descriptor": "\nComments: 7 pages, 4 figures, Tackling Climate Change with Machine Learning: workshop at NeurIPS 2021\n",
    "authors": [
      "Trey McNeely",
      "Galen Vincent",
      "Rafael Izbicki",
      "Kimberly M. Wood",
      "Ann B. Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.12029"
  },
  {
    "id": "arXiv:2109.13925",
    "title": "Fine-tuning Vision Transformers for the Prediction of State Variables in  Ising Models",
    "abstract": "Comments: Accepted at Ml4Physical Sciences Workshop at Neurips 2021",
    "descriptor": "\nComments: Accepted at Ml4Physical Sciences Workshop at Neurips 2021\n",
    "authors": [
      "Onur Kara",
      "Arijit Sehanobish",
      "Hector H Corzo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.13925"
  },
  {
    "id": "arXiv:2110.00351",
    "title": "Smooth Normalizing Flows",
    "abstract": "Comments: Neural Information Proceessing Systems (NeurIPS) 2021",
    "descriptor": "\nComments: Neural Information Proceessing Systems (NeurIPS) 2021\n",
    "authors": [
      "Jonas K\u00f6hler",
      "Andreas Kr\u00e4mer",
      "Frank No\u00e9"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.00351"
  },
  {
    "id": "arXiv:2110.00552",
    "title": "Stochastic Contrastive Learning",
    "abstract": "Comments: Accepted to 2nd Workshop on Self-Supervised Learning: Theory and Practice (NeurIPS 2021), Sydney, Australia",
    "descriptor": "\nComments: Accepted to 2nd Workshop on Self-Supervised Learning: Theory and Practice (NeurIPS 2021), Sydney, Australia\n",
    "authors": [
      "Jason Ramapuram",
      "Dan Busbridge",
      "Xavier Suau",
      "Russ Webb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00552"
  },
  {
    "id": "arXiv:2110.01318",
    "title": "Lumped circuit model for inductive antenna spin-wave transducers",
    "abstract": "Comments: This project has received funding from the European Union's Horizon 2020 research and innovation program under grant agreement No. 801055 \"Spin Wave Computing for Ultimately-Scaled Hybrid Low-Power Electronics\" CHIRON",
    "descriptor": "\nComments: This project has received funding from the European Union's Horizon 2020 research and innovation program under grant agreement No. 801055 \"Spin Wave Computing for Ultimately-Scaled Hybrid Low-Power Electronics\" CHIRON\n",
    "authors": [
      "Frederic Vanderveken",
      "Vasyl Tyberkevych",
      "Giacomo Talmelli",
      "Bart Sor\u00e9e",
      "Florin Ciubotaru",
      "Christoph Adelmann"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.01318"
  },
  {
    "id": "arXiv:2110.01343",
    "title": "Taming singular stochastic differential equations: A numerical method",
    "abstract": "Comments: 63 pages",
    "descriptor": "\nComments: 63 pages\n",
    "authors": [
      "Khoa L\u00ea",
      "Chengcheng Ling"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.01343"
  },
  {
    "id": "arXiv:2110.04507",
    "title": "TiKick: Towards Playing Multi-agent Football Full Games from  Single-agent Demonstrations",
    "abstract": "TiKick: Towards Playing Multi-agent Football Full Games from  Single-agent Demonstrations",
    "descriptor": "",
    "authors": [
      "Shiyu Huang",
      "Wenze Chen",
      "Longfei Zhang",
      "Shizhen Xu",
      "Ziyang Li",
      "Fengming Zhu",
      "Deheng Ye",
      "Ting Chen",
      "Jun Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04507"
  },
  {
    "id": "arXiv:2110.06915",
    "title": "Object-Region Video Transformers",
    "abstract": "Comments: Tech report",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Roei Herzig",
      "Elad Ben-Avraham",
      "Karttikeya Mangalam",
      "Amir Bar",
      "Gal Chechik",
      "Anna Rohrbach",
      "Trevor Darrell",
      "Amir Globerson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06915"
  },
  {
    "id": "arXiv:2110.07309",
    "title": "Cell-Free Massive MIMO for 6G Wireless Communication Networks",
    "abstract": "Comments: 28 pages, 4 figures, 4 tables, Accepted by Journal of Communications and Information Networks",
    "descriptor": "\nComments: 28 pages, 4 figures, 4 tables, Accepted by Journal of Communications and Information Networks\n",
    "authors": [
      "Hengtao He",
      "Xianghao Yu",
      "Jun Zhang",
      "S.H. Song",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.07309"
  },
  {
    "id": "arXiv:2110.09714",
    "title": "Black-box Adversarial Attacks on Commercial Speech Platforms with  Minimal Information",
    "abstract": "Comments: A version of this paper appears in the proceedings of the 28th ACM Conference on Computer and Communications Security (CCS 2021). The notes in Tables 1 and 4 have been updated",
    "descriptor": "\nComments: A version of this paper appears in the proceedings of the 28th ACM Conference on Computer and Communications Security (CCS 2021). The notes in Tables 1 and 4 have been updated\n",
    "authors": [
      "Baolin Zheng",
      "Peipei Jiang",
      "Qian Wang",
      "Qi Li",
      "Chao Shen",
      "Cong Wang",
      "Yunjie Ge",
      "Qingyang Teng",
      "Shenyi Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09714"
  },
  {
    "id": "arXiv:2110.11001",
    "title": "Pixel-Level Face Image Quality Assessment for Explainable Face  Recognition",
    "abstract": "Pixel-Level Face Image Quality Assessment for Explainable Face  Recognition",
    "descriptor": "",
    "authors": [
      "Philipp Terh\u00f6rst",
      "Marco Huber",
      "Naser Damer",
      "Florian Kirchbuchner",
      "Kiran Raja",
      "Arjan Kuijper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11001"
  },
  {
    "id": "arXiv:2110.11516",
    "title": "Contact Anticipation for Physical Human-Robot Interaction with Robotic  Manipulators using Onboard Proximity Sensors",
    "abstract": "Comments: 8 pages, 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) pages 7232 - 7239",
    "descriptor": "\nComments: 8 pages, 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) pages 7232 - 7239\n",
    "authors": [
      "Caleb Escobedo",
      "Matthew Strong",
      "Mary West",
      "Ander Aramburu",
      "Alessandro Roncone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11516"
  },
  {
    "id": "arXiv:2110.14717",
    "title": "An Efficient Reversible Algorithm for Linear Regression",
    "abstract": "Comments: 6 pages; matrix inversion proof corrected; Erik Demaine added as author",
    "descriptor": "\nComments: 6 pages; matrix inversion proof corrected; Erik Demaine added as author\n",
    "authors": [
      "Erik D. Demaine",
      "Jayson Lynch",
      "Jiaying Sun"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.14717"
  },
  {
    "id": "arXiv:2110.15160",
    "title": "Feature Learning for Neural-Network-Based Positioning with Channel State  Information",
    "abstract": "Comments: Presented at ASILOMAR 2021",
    "descriptor": "\nComments: Presented at ASILOMAR 2021\n",
    "authors": [
      "Emre G\u00f6n\u00fclta\u015f",
      "Sueda Taner",
      "Howard Huang",
      "Christoph Studer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.15160"
  },
  {
    "id": "arXiv:2110.15327",
    "title": "MEGAN: Memory Enhanced Graph Attention Network for Space-Time Video  Super-Resolution",
    "abstract": "MEGAN: Memory Enhanced Graph Attention Network for Space-Time Video  Super-Resolution",
    "descriptor": "",
    "authors": [
      "Chenyu You",
      "Lianyi Han",
      "Aosong Feng",
      "Ruihan Zhao",
      "Hui Tang",
      "Wei Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.15327"
  },
  {
    "id": "arXiv:2111.01177",
    "title": "Don't Generate Me: Training Differentially Private Generative Models  with Sinkhorn Divergence",
    "abstract": "Comments: Accepted to NeurIPS 2021. 13 pages, 7 pages of supplementary; 6 tables, 8 figures",
    "descriptor": "\nComments: Accepted to NeurIPS 2021. 13 pages, 7 pages of supplementary; 6 tables, 8 figures\n",
    "authors": [
      "Tianshi Cao",
      "Alex Bie",
      "Arash Vahdat",
      "Sanja Fidler",
      "Karsten Kreis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.01177"
  },
  {
    "id": "arXiv:2111.01215",
    "title": "Gradient Frequency Modulation for Visually Explaining Video  Understanding Models",
    "abstract": "Comments: Accepted by BMVC 2021",
    "descriptor": "\nComments: Accepted by BMVC 2021\n",
    "authors": [
      "Xinmiao Lin",
      "Wentao Bao",
      "Matthew Wright",
      "Yu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01215"
  },
  {
    "id": "arXiv:2111.02881",
    "title": "Defining Gaze Patterns for Process Model Literacy -- Exploring Visual  Routines in Process Models with Diverse Mappings",
    "abstract": "Defining Gaze Patterns for Process Model Literacy -- Exploring Visual  Routines in Process Models with Diverse Mappings",
    "descriptor": "",
    "authors": [
      "Michael Winter",
      "Heiko Neumann",
      "R\u00fcdiger Pryss",
      "Thomas Probst",
      "Manfred Reichert"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.02881"
  },
  {
    "id": "arXiv:2111.03039",
    "title": "Towards Panoptic 3D Parsing for Single Image in the Wild",
    "abstract": "Towards Panoptic 3D Parsing for Single Image in the Wild",
    "descriptor": "",
    "authors": [
      "Sainan Liu",
      "Vincent Nguyen",
      "Yuan Gao",
      "Subarna Tripathi",
      "Zhuowen Tu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.03039"
  },
  {
    "id": "arXiv:2111.03047",
    "title": "A deep ensemble approach to X-ray polarimetry",
    "abstract": "Comments: Fourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021)",
    "descriptor": "\nComments: Fourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021)\n",
    "authors": [
      "A.L.Peirson",
      "R.W.Romani"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03047"
  },
  {
    "id": "arXiv:2111.04178",
    "title": "Teamwork makes von Neumann work: Min-Max Optimization in Two-Team  Zero-Sum Games",
    "abstract": "Teamwork makes von Neumann work: Min-Max Optimization in Two-Team  Zero-Sum Games",
    "descriptor": "",
    "authors": [
      "Fivos Kalogiannis",
      "Ioannis Panageas",
      "Emmanouil-Vasileios Vlatakis-Gkaragkounis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.04178"
  },
  {
    "id": "arXiv:2111.04742",
    "title": "E(2) Equivariant Self-Attention for Radio Astronomy",
    "abstract": "Comments: Accepted in: Fourth Workshop on Machine Learning and the Physical Sciences (35th Conference on Neural Information Processing Systems; NeurIPS2021); final version; 7 pages, 3 figures",
    "descriptor": "\nComments: Accepted in: Fourth Workshop on Machine Learning and the Physical Sciences (35th Conference on Neural Information Processing Systems; NeurIPS2021); final version; 7 pages, 3 figures\n",
    "authors": [
      "Micah Bowles",
      "Matthew Bromley",
      "Max Allen",
      "Anna Scaife"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.04742"
  },
  {
    "id": "arXiv:2111.04958",
    "title": "Gomory-Hu Tree in Subcubic Time",
    "abstract": "Gomory-Hu Tree in Subcubic Time",
    "descriptor": "",
    "authors": [
      "Amir Abboud",
      "Robert Krauthgamer",
      "Jason Li",
      "Debmalya Panigrahi",
      "Thatchaphol Saranurak",
      "Ohad Trabelsi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.04958"
  },
  {
    "id": "arXiv:2111.05898",
    "title": "Beyond Importance Scores: Interpreting Tabular ML by Visualizing Feature  Semantics",
    "abstract": "Beyond Importance Scores: Interpreting Tabular ML by Visualizing Feature  Semantics",
    "descriptor": "",
    "authors": [
      "Amirata Ghorbani",
      "Dina Berenbaum",
      "Maor Ivgi",
      "Yuval Dafna",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05898"
  },
  {
    "id": "arXiv:2111.05978",
    "title": "Trustworthy Medical Segmentation with Uncertainty Estimation",
    "abstract": "Trustworthy Medical Segmentation with Uncertainty Estimation",
    "descriptor": "",
    "authors": [
      "Giuseppina Carannante",
      "Dimah Dera",
      "Nidhal C.Bouaynaya",
      "Ghulam Rasool",
      "Hassan M. Fathallah-Shaykh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05978"
  },
  {
    "id": "arXiv:2111.06206",
    "title": "Towards Axiomatic, Hierarchical, and Symbolic Explanation for Deep  Models",
    "abstract": "Towards Axiomatic, Hierarchical, and Symbolic Explanation for Deep  Models",
    "descriptor": "",
    "authors": [
      "Jie Ren",
      "Mingjie Li",
      "Qirui Chen",
      "Huiqi Deng",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06206"
  },
  {
    "id": "arXiv:2111.06959",
    "title": "Through-Foliage Tracking with Airborne Optical Sectioning",
    "abstract": "Comments: 9 Pages, 9 Figures, 1 Table and supplementary videos and material",
    "descriptor": "\nComments: 9 Pages, 9 Figures, 1 Table and supplementary videos and material\n",
    "authors": [
      "Rakesh John Amala Arokia Nathan",
      "Indrajit Kurmi",
      "David C. Schedl",
      "Oliver Bimber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06959"
  },
  {
    "id": "arXiv:2111.07130",
    "title": "Prediction of Listener Perception of Argumentative Speech in a  Crowdsourced Dataset Using (Psycho-)Linguistic and Fluency Features",
    "abstract": "Prediction of Listener Perception of Argumentative Speech in a  Crowdsourced Dataset Using (Psycho-)Linguistic and Fluency Features",
    "descriptor": "",
    "authors": [
      "Yu Qiao",
      "Sourabh Zanwar",
      "Rishab Bhattacharyya",
      "Daniel Wiechmann",
      "Wei Zhou",
      "Elma Kerz",
      "Ralf Schl\u00fcter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.07130"
  },
  {
    "id": "arXiv:2111.07819",
    "title": "Testing the Generalization of Neural Language Models for COVID-19  Misinformation Detection",
    "abstract": "Testing the Generalization of Neural Language Models for COVID-19  Misinformation Detection",
    "descriptor": "",
    "authors": [
      "Jan Philip Wahle",
      "Nischal Ashok",
      "Terry Ruas",
      "Norman Meuschke",
      "Tirthankar Ghosal",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.07819"
  },
  {
    "id": "arXiv:2111.08861",
    "title": "A label efficient two-sample test",
    "abstract": "A label efficient two-sample test",
    "descriptor": "",
    "authors": [
      "Weizhi Li",
      "Gautam Dasarathy",
      "Karthikeyan Natesan Ramamurthy",
      "Visar Berisha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08861"
  },
  {
    "id": "arXiv:2111.08974",
    "title": "Pedestrian Detection by Exemplar-Guided Contrastive Learning",
    "abstract": "Pedestrian Detection by Exemplar-Guided Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Zebin Lin",
      "Wenjie Pei",
      "Fanglin Chen",
      "David Zhang",
      "Guangming Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08974"
  },
  {
    "id": "arXiv:2111.09375",
    "title": "Hypercontractivity on High Dimensional Expanders: Approximate  Efron-Stein Decompositions for $\\varepsilon$-Product Spaces",
    "abstract": "Comments: New title to distinguish from independent work of Bafna, Hopkins, Kaufman, and Lovett",
    "descriptor": "\nComments: New title to distinguish from independent work of Bafna, Hopkins, Kaufman, and Lovett\n",
    "authors": [
      "Tom Gur",
      "Noam Lifshitz",
      "Siqi Liu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.09375"
  },
  {
    "id": "arXiv:2111.09380",
    "title": "Hybrid Feedback for Autonomous Navigation in Environments with Arbitrary  Convex Obstacles",
    "abstract": "Comments: 18 pages, 11 figures",
    "descriptor": "\nComments: 18 pages, 11 figures\n",
    "authors": [
      "Mayur Sawant",
      "Soulaimane Berkane",
      "Ilia Polusin",
      "Abdelhamid Tayebi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.09380"
  },
  {
    "id": "arXiv:2111.10007",
    "title": "FBNetV5: Neural Architecture Search for Multiple Tasks in One Run",
    "abstract": "FBNetV5: Neural Architecture Search for Multiple Tasks in One Run",
    "descriptor": "",
    "authors": [
      "Bichen Wu",
      "Chaojian Li",
      "Hang Zhang",
      "Xiaoliang Dai",
      "Peizhao Zhang",
      "Matthew Yu",
      "Jialiang Wang",
      "Yingyan Lin",
      "Peter Vajda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10007"
  },
  {
    "id": "arXiv:2111.10046",
    "title": "YMIR: A Rapid Data-centric Development Platform for Vision Applications",
    "abstract": "YMIR: A Rapid Data-centric Development Platform for Vision Applications",
    "descriptor": "",
    "authors": [
      "Phoenix X. Huang",
      "Wenze Hu",
      "William Brendel",
      "Manmohan Chandraker",
      "Li-Jia Li",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10046"
  },
  {
    "id": "arXiv:2111.10969",
    "title": "Medical Aegis: Robust adversarial protectors for medical images",
    "abstract": "Medical Aegis: Robust adversarial protectors for medical images",
    "descriptor": "",
    "authors": [
      "Qingsong Yao",
      "Zecheng He",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10969"
  },
  {
    "id": "arXiv:2111.10991",
    "title": "Backdoor Attack through Frequency Domain",
    "abstract": "Backdoor Attack through Frequency Domain",
    "descriptor": "",
    "authors": [
      "Tong Wang",
      "Yuan Yao",
      "Feng Xu",
      "Shengwei An",
      "Hanghang Tong",
      "Ting Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10991"
  },
  {
    "id": "arXiv:2111.11001",
    "title": "Easy representation of multivariate functions with low-dimensional terms  via Gaussian process regression kernel design: applications to machine  learning of potential energy surfaces and kinetic energy densities from  sparse data",
    "abstract": "Comments: 9 pages, 1 figure, 2 tables",
    "descriptor": "\nComments: 9 pages, 1 figure, 2 tables\n",
    "authors": [
      "Eita Sasaki",
      "Manabu Ihara",
      "Sergei Manzhos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2111.11001"
  },
  {
    "id": "arXiv:2111.11249",
    "title": "LeQua@CLEF2022: Learning to Quantify",
    "abstract": "LeQua@CLEF2022: Learning to Quantify",
    "descriptor": "",
    "authors": [
      "Andrea Esuli",
      "Alejandro Moreo",
      "Fabrizio Sebastiani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.11249"
  },
  {
    "id": "arXiv:2111.11303",
    "title": "Machine Learning of Thermodynamic Observables in the Presence of Mode  Collapse",
    "abstract": "Comments: 10 pages, 2 figures, Proceedings of the 38th International Symposium on Lattice Field Theory, 26th-30th July 2021, Zoom/Gather@Massachusetts Institute of Technology",
    "descriptor": "\nComments: 10 pages, 2 figures, Proceedings of the 38th International Symposium on Lattice Field Theory, 26th-30th July 2021, Zoom/Gather@Massachusetts Institute of Technology\n",
    "authors": [
      "Kim A. Nicoli",
      "Christopher Anders",
      "Lena Funcke",
      "Tobias Hartung",
      "Karl Jansen",
      "Pan Kessel",
      "Shinichi Nakajima",
      "Paolo Stornati"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11303"
  },
  {
    "id": "arXiv:2111.12126",
    "title": "Panoptic Segmentation Meets Remote Sensing",
    "abstract": "Comments: 40 pages, 10 figures, submitted to journal",
    "descriptor": "\nComments: 40 pages, 10 figures, submitted to journal\n",
    "authors": [
      "Osmar Luiz Ferreira de Carvalho",
      "Osmar Ab\u00edlio de Carvalho J\u00fanior",
      "Cristiano Rosa e Silva",
      "Anesmar Olino de Albuquerque",
      "Nickolas Castro Santana",
      "Dibio Leandro Borges",
      "Roberto Arnaldo Trancoso Gomes",
      "Renato Fontes Guimar\u00e3es"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.12126"
  },
  {
    "id": "arXiv:2111.12182",
    "title": "Identifying Terms and Conditions Important to Consumers using  Crowdsourcing",
    "abstract": "Identifying Terms and Conditions Important to Consumers using  Crowdsourcing",
    "descriptor": "",
    "authors": [
      "Xingyu Liu",
      "Annabel Sun",
      "Jason I. Hong"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.12182"
  },
  {
    "id": "arXiv:2111.12210",
    "title": "From Kepler to Newton: Explainable AI for Science Discovery",
    "abstract": "Comments: 14 pages, 8 figures, 6 tables",
    "descriptor": "\nComments: 14 pages, 8 figures, 6 tables\n",
    "authors": [
      "Zelong Li",
      "Jianchao Ji",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2111.12210"
  },
  {
    "id": "arXiv:2111.12221",
    "title": "Source-free unsupervised domain adaptation for cross-modality abdominal  multi-organ segmentation",
    "abstract": "Source-free unsupervised domain adaptation for cross-modality abdominal  multi-organ segmentation",
    "descriptor": "",
    "authors": [
      "Jin Hong",
      "Yu-Dong Zhang",
      "Weitian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12221"
  },
  {
    "id": "arXiv:2111.12447",
    "title": "Revisiting Contextual Toxicity Detection in Conversations",
    "abstract": "Revisiting Contextual Toxicity Detection in Conversations",
    "descriptor": "",
    "authors": [
      "Julia Ive",
      "Atijit Anuchitanukul",
      "Lucia Specia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.12447"
  },
  {
    "id": "arXiv:2111.12804",
    "title": "Evolution of honesty in higher-order social networks",
    "abstract": "Comments: 12 two-column pages, 5 figures, supplementary information; accepted for publication in Physical Review E",
    "descriptor": "\nComments: 12 two-column pages, 5 figures, supplementary information; accepted for publication in Physical Review E\n",
    "authors": [
      "Aanjaneya Kumar",
      "Sandeep Chowdhary",
      "Valerio Capraro",
      "Matjaz Perc"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.12804"
  },
  {
    "id": "arXiv:2111.12929",
    "title": "Unbiased Pairwise Learning to Rank in Recommender Systems",
    "abstract": "Unbiased Pairwise Learning to Rank in Recommender Systems",
    "descriptor": "",
    "authors": [
      "Yi Ren",
      "Hongyan Tang",
      "Siwen Zhu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12929"
  },
  {
    "id": "arXiv:2111.12961",
    "title": "Distributed Policy Gradient with Variance Reduction in Multi-Agent  Reinforcement Learning",
    "abstract": "Distributed Policy Gradient with Variance Reduction in Multi-Agent  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Xiaoxiao Zhao",
      "Jinlong Lei",
      "Li Li"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.12961"
  },
  {
    "id": "arXiv:2111.13058",
    "title": "STRETCH: Virtual Shared-Nothing Parallelism for Scalable and Elastic  Stream Processing",
    "abstract": "STRETCH: Virtual Shared-Nothing Parallelism for Scalable and Elastic  Stream Processing",
    "descriptor": "",
    "authors": [
      "Vincenzo Gulisano",
      "Hannaneh Najdataei",
      "Yiannis Nikolakopoulos",
      "Alessandro V. Papadopoulos",
      "Marina Papatriantafilou",
      "Philippas Tsigas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.13058"
  },
  {
    "id": "arXiv:2111.13295",
    "title": "Medial Spectral Coordinates for 3D Shape Analysis",
    "abstract": "Medial Spectral Coordinates for 3D Shape Analysis",
    "descriptor": "",
    "authors": [
      "Morteza Rezanejad",
      "Mohammad Khodadad",
      "Hamidreza Mahyar",
      "Herve Lombaert",
      "Michael Gruninger",
      "Dirk B. Walther",
      "Kaleem Siddiqi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.13295"
  },
  {
    "id": "arXiv:2111.13475",
    "title": "QMagFace: Simple and Accurate Quality-Aware Face Recognition",
    "abstract": "QMagFace: Simple and Accurate Quality-Aware Face Recognition",
    "descriptor": "",
    "authors": [
      "Philipp Terh\u00f6rst",
      "Malte Ihlefeld",
      "Marco Huber",
      "Naser Damer",
      "Florian Kirchbuchner",
      "Kiran Raja",
      "Arjan Kuijper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.13475"
  },
  {
    "id": "arXiv:2111.13495",
    "title": "In-painting Radiography Images for Unsupervised Anomaly Detection",
    "abstract": "Comments: Main paper with appendix",
    "descriptor": "\nComments: Main paper with appendix\n",
    "authors": [
      "Tiange Xiang",
      "Yongyi Lu",
      "Alan L. Yuille",
      "Chaoyi Zhang",
      "Weidong Cai",
      "Zongwei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13495"
  },
  {
    "id": "arXiv:2111.13670",
    "title": "Non-Convex Recovery from Phaseless Low-Resolution Blind Deconvolution  Measurements using Noisy Masked Patterns",
    "abstract": "Non-Convex Recovery from Phaseless Low-Resolution Blind Deconvolution  Measurements using Noisy Masked Patterns",
    "descriptor": "",
    "authors": [
      "Samuel Pinilla",
      "Kumar Vijay Mishra",
      "Brian Sadler"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.13670"
  },
  {
    "id": "arXiv:2111.13802",
    "title": "Factorized Fourier Neural Operators",
    "abstract": "Comments: To be presented at the Fourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021). Code is available at this https URL",
    "descriptor": "\nComments: To be presented at the Fourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021). Code is available at this https URL\n",
    "authors": [
      "Alasdair Tran",
      "Alexander Mathews",
      "Lexing Xie",
      "Cheng Soon Ong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.13802"
  },
  {
    "id": "arXiv:2111.13980",
    "title": "Forecasting Daily COVID-19 Related Calls in VA Health Care System:  Predictive Model Development",
    "abstract": "Forecasting Daily COVID-19 Related Calls in VA Health Care System:  Predictive Model Development",
    "descriptor": "",
    "authors": [
      "Weipeng Zhou",
      "Ryan J. Laundry",
      "Paul L. Hebert",
      "Gang Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.13980"
  },
  {
    "id": "arXiv:2111.14075",
    "title": "Image preprocessing and modified adaptive thresholding for improving OCR",
    "abstract": "Comments: 5 pages, 7 figues",
    "descriptor": "\nComments: 5 pages, 7 figues\n",
    "authors": [
      "Rohan Lal Kshetry"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14075"
  },
  {
    "id": "arXiv:2111.14106",
    "title": "Enhancing Keyphrase Extraction from Academic Articles with their  Reference Information",
    "abstract": "Enhancing Keyphrase Extraction from Academic Articles with their  Reference Information",
    "descriptor": "",
    "authors": [
      "Chengzhi Zhang",
      "Lei Zhao",
      "Mengyuan Zhao",
      "Yingyi Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2111.14106"
  },
  {
    "id": "arXiv:2111.14188",
    "title": "An Empirical Study of Topic Transition in Dialogue",
    "abstract": "Comments: 5 pages, 4 figures, 3 tables",
    "descriptor": "\nComments: 5 pages, 4 figures, 3 tables\n",
    "authors": [
      "Mayank Soni",
      "Brendan Spillane",
      "Emer Gilmartin",
      "Christian Saam",
      "Benjamin R. Cowan",
      "Vincent Wade"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.14188"
  },
  {
    "id": "arXiv:2111.14282",
    "title": "Customer Sentiment Analysis using Weak Supervision for Customer-Agent  Chat",
    "abstract": "Customer Sentiment Analysis using Weak Supervision for Customer-Agent  Chat",
    "descriptor": "",
    "authors": [
      "Navdeep Jain"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14282"
  },
  {
    "id": "arXiv:2111.14547",
    "title": "LiVLR: A Lightweight Visual-Linguistic Reasoning Framework for Video  Question Answering",
    "abstract": "Comments: 11 pages, 5 figures, Code: this https URL",
    "descriptor": "\nComments: 11 pages, 5 figures, Code: this https URL\n",
    "authors": [
      "Jingjing Jiang",
      "Ziyi Liu",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14547"
  },
  {
    "id": "arXiv:2111.14562",
    "title": "Instance-wise Occlusion and Depth Orders in Natural Scenes",
    "abstract": "Instance-wise Occlusion and Depth Orders in Natural Scenes",
    "descriptor": "",
    "authors": [
      "Hyunmin Lee",
      "Jaesik Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.14562"
  },
  {
    "id": "arXiv:2111.14580",
    "title": "Amortized Implicit Differentiation for Stochastic Bilevel Optimization",
    "abstract": "Amortized Implicit Differentiation for Stochastic Bilevel Optimization",
    "descriptor": "",
    "authors": [
      "Michael Arbel",
      "Julien Mairal"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14580"
  },
  {
    "id": "arXiv:2111.14605",
    "title": "Weakly-supervised Generative Adversarial Networks for medical image  classification",
    "abstract": "Weakly-supervised Generative Adversarial Networks for medical image  classification",
    "descriptor": "",
    "authors": [
      "Jiawei Mao",
      "Xuesong Yin",
      "Yuanqi Chang",
      "Qi Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14605"
  },
  {
    "id": "arXiv:2111.14672",
    "title": "Human Performance Capture from Monocular Video in the Wild",
    "abstract": "Human Performance Capture from Monocular Video in the Wild",
    "descriptor": "",
    "authors": [
      "Chen Guo",
      "Xu Chen",
      "Jie Song",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14672"
  },
  {
    "id": "arXiv:2111.14693",
    "title": "SAGCI-System: Towards Sample-Efficient, Generalizable, Compositional,  and Incremental Robot Learning",
    "abstract": "Comments: Submitted to IEEE International Conference on Robotics and Automation (ICRA) 2022",
    "descriptor": "\nComments: Submitted to IEEE International Conference on Robotics and Automation (ICRA) 2022\n",
    "authors": [
      "Jun Lv",
      "Qiaojun Yu",
      "Lin Shao",
      "Wenhai Liu",
      "Wenqiang Xu",
      "Cewu Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14693"
  },
  {
    "id": "arXiv:2111.14746",
    "title": "Dynamic Inference",
    "abstract": "Dynamic Inference",
    "descriptor": "",
    "authors": [
      "Aolin Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2111.14746"
  },
  {
    "id": "arXiv:2111.14799",
    "title": "UBoCo : Unsupervised Boundary Contrastive Learning for Generic Event  Boundary Detection",
    "abstract": "UBoCo : Unsupervised Boundary Contrastive Learning for Generic Event  Boundary Detection",
    "descriptor": "",
    "authors": [
      "Hyolim Kang",
      "Jinwoo Kim",
      "Taehyun Kim",
      "Seon Joo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.14799"
  }
]
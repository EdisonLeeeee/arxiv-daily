[
  {
    "id": "arXiv:2112.06916",
    "title": "Flow Metrics on Graphs",
    "abstract": "Given a graph with non-negative edge weights, there are various ways to\ninterpret the edge weights and induce a metric on the vertices of the graph. A\nfew examples are shortest-path, when interpreting the weights as lengths;\nresistance distance, when thinking of the graph as an electrical network and\nthe weights are resistances; and the inverse of minimum $st$-cut, when thinking\nof the weights as capacities.\nIt is known that the 3 above-mentioned metrics can all be derived from flows,\nwhen formalizing them as convex optimization problems. This key observation led\nus to studying a family of metrics that are derived from flows, which we call\nflow metrics, that gives a natural interpolation between the above metrics\nusing a parameter $p$.\nWe make the first steps in studying the flow metrics, and mainly focus on two\naspects: (a) understanding basic properties of the flow metrics, either as an\noptimization problem (e.g. finding relations between the flow problem and the\ndual potential problem) and as a metric function (e.g. understanding their\nstructure and geometry); and (b) considering methods for reducing the size of\ngraphs, either by removing vertices or edges while approximating the flow\nmetrics, and thus attaining a smaller instance that can be used to accelerate\nrunning time of algorithms and reduce their storage requirements.\nOur main result is a lower bound for the number of edges required for a\nresistance sparsifier in the worst case. Furthermore, we present a method for\nreducing the number of edges in a graph while approximating the flow metrics,\nby utilizing a method of [Cohen and Peng, 2015] for reducing the size of\nmatrices. In addition, we show that the flow metrics satisfy a stronger version\nof the triangle inequality, which gives some information about their structure\nand geometry.",
    "descriptor": "\nComments: MSc thesis of Lior Kalman at the Weizmann Institute\n",
    "authors": [
      "Lior Kalman",
      "Robert Krauthgamer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.06916"
  },
  {
    "id": "arXiv:2112.06917",
    "title": "Branching Strategy Selection Approach Based on Vivification Ratio",
    "abstract": "The two most effective branching strategies LRB and VSIDS perform differently\non different types of instances. Generally, LRB is more effective on crafted\ninstances, while VSIDS is more effective on application ones. However,\ndistinguishing the types of instances is difficult. To overcome this drawback,\nwe propose a branching strategy selection approach based on the vivification\nratio. This approach uses the LRB branching strategy more to solve the\ninstances with a very low vivification ratio. We tested the instances from the\nmain track of SAT competitions in recent years. The results show that the\nproposed approach is robust and it significantly increases the number of solved\ninstances. It is worth mentioning that, with the help of our approach, the\nsolver Maple\\_CM can solve more than 16 instances for the benchmark from the\n2020 SAT competition.",
    "descriptor": "",
    "authors": [
      "Mao Luo",
      "Chu-Min Li",
      "Xinyun Wu",
      "Shuolin Li",
      "Zhipeng L\u00fc"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.06917"
  },
  {
    "id": "arXiv:2112.06918",
    "title": "Automated Customization of On-Thing Inference for Quality-of-Experience  Enhancement",
    "abstract": "The rapid uptake of intelligent applications is pushing deep learning (DL)\ncapabilities to Internet-of-Things (IoT). Despite the emergence of new tools\nfor embedding deep neural networks (DNNs) into IoT devices, providing\nsatisfactory Quality of Experience (QoE) to users is still challenging due to\nthe heterogeneity in DNN architectures, IoT devices, and user preferences. This\npaper studies automated customization for DL inference on IoT devices (termed\nas on-thing inference), and our goal is to enhance user QoE by configuring the\non-thing inference with an appropriate DNN for users under different usage\nscenarios. The core of our method is a DNN selection module that learns user\nQoE patterns on-the-fly and identifies the best-fit DNN for on-thing inference\nwith the learned knowledge. It leverages a novel online learning algorithm,\nNeuralUCB, that has excellent generalization ability for handling various user\nQoE patterns. We also embed the knowledge transfer technique in NeuralUCB to\nexpedite the learning process. However, NeuralUCB frequently solicits QoE\nratings from users, which incurs non-negligible inconvenience. To address this\nproblem, we design feedback solicitation schemes to reduce the number of QoE\nsolicitations while maintaining the learning efficiency of NeuralUCB. A\npragmatic problem, aggregated QoE, is further investigated to improve the\npracticality of our framework. We conduct experiments on both synthetic and\nreal-world data. The results indicate that our method efficiently learns the\nuser QoE pattern with few solicitations and provides drastic QoE enhancement\nfor IoT devices.",
    "descriptor": "",
    "authors": [
      "Yang Bai",
      "Lixing Chen",
      "Shaolei Ren",
      "Jie Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.06918"
  },
  {
    "id": "arXiv:2112.06921",
    "title": "A Data- and Task- Oriented Design Framework for Bivariate Communication  of Uncertainty",
    "abstract": "The communication of uncertainty estimates, predictions and insights based on\nspatio-temporal models is important for decision-making as it impacts the\nutilisation and interpretation of information. Bivariate mapping is commonly\nused for communication of estimates and associated uncertainty; however, it is\nknown that different visual qualities resulting from choics of symbols and\nconsequent interaction between the display dimensions can lead to different\ninterpretations and consequently affect resultant decisions. Characteristics of\nthe data to be presented, such as spatial format, statistical level and\ncontinuousness, shape the range of available bivairate symbols. The subsequent\nutility of these bivariate symbols depends on their ability to achieve\nend-user's goals. In this paper we present a novel design framework, which,\nthrough consideration of both input data characteristics and potential\noperational tasks (as proxy to end-user goals), assists map designers in\nappropriate selection of bivariate symbols for the coincident presentation of\nspatio-temporal modelled data and associated uncertainty. The framework is\nshowcased through application to a case study pertaining to sediment pollution\nin the Great Barrier Reef.",
    "descriptor": "",
    "authors": [
      "Letitia Sabburg",
      "Alan Woodley",
      "Kerrie Mengersen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.06921"
  },
  {
    "id": "arXiv:2112.06922",
    "title": "Decoding High-level Imagined Speech using Attention-based Deep Neural  Networks",
    "abstract": "Brain-computer interface (BCI) is the technology that enables the\ncommunication between humans and devices by reflecting status and intentions of\nhumans. When conducting imagined speech, the users imagine the pronunciation as\nif actually speaking. In the case of decoding imagined speech-based EEG\nsignals, complex task can be conducted more intuitively, but decoding\nperformance is lower than that of other BCI paradigms. We modified our previous\nmodel for decoding imagined speech-based EEG signals. Ten subjects participated\nin the experiment. The average accuracy of our proposed method was 0.5648 for\nclassifying four words. In other words, our proposed method has significant\nstrength in learning local features. Hence, we demonstrated the feasibility of\ndecoding imagined speech-based EEG signals with robust performance.",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "Dae-Hyeok Lee",
      "Sung-Jin Kim",
      "Keon-Woo Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.06922"
  },
  {
    "id": "arXiv:2112.06924",
    "title": "Generating Fluent Fact Checking Explanations with Unsupervised  Post-Editing",
    "abstract": "Fact-checking systems have become important tools to verify fake and\nmisguiding news. These systems become more trustworthy when human-readable\nexplanations accompany the veracity labels. However, manual collection of such\nexplanations is expensive and time-consuming. Recent works frame explanation\ngeneration as extractive summarization, and propose to automatically select a\nsufficient subset of the most important facts from the ruling comments (RCs) of\na professional journalist to obtain fact-checking explanations. However, these\nexplanations lack fluency and sentence coherence. In this work, we present an\niterative edit-based algorithm that uses only phrase-level edits to perform\nunsupervised post-editing of disconnected RCs. To regulate our editing\nalgorithm, we use a scoring function with components including fluency and\nsemantic preservation. In addition, we show the applicability of our approach\nin a completely unsupervised setting. We experiment with two benchmark\ndatasets, LIAR-PLUS and PubHealth. We show that our model generates\nexplanations that are fluent, readable, non-redundant, and cover important\ninformation for the fact check.",
    "descriptor": "",
    "authors": [
      "Shailza Jolly",
      "Pepa Atanasova",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06924"
  },
  {
    "id": "arXiv:2112.06925",
    "title": "CGAN-EB: A Non-parametric Empirical Bayes Method for Crash Hotspot  Identification Using Conditional Generative Adversarial Networks: A Simulated  Crash Data Study",
    "abstract": "In this paper, a new non-parametric empirical Bayes approach called CGAN-EB\nis proposed for approximating empirical Bayes (EB) estimates in traffic\nlocations (e.g., road segments) which benefits from the modeling advantages of\ndeep neural networks, and its performance is compared in a simulation study\nwith the traditional approach based on negative binomial model (NB-EB). The\nNB-EB uses negative binomial model in order to model the crash data and is the\nmost common approach in practice. To model the crash data in the proposed\nCGAN-EB, conditional generative adversarial network is used, which is a\npowerful deep neural network based method that can model any types of\ndistributions. A number of simulation experiments are designed and conducted to\nevaluate the CGAN-EB performance in different conditions and compare it with\nthe NB-EB. The results show that CGAN-EB performs as well as NB-EB when\nconditions favor the NB-EB model (i.e. data conform to the assumptions of the\nNB model) and outperforms NB-EB in experiments reflecting conditions frequently\nencountered in practice, specifically low sample means, and when crash\nfrequency does not follow a log-linear relationship with covariates.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Mohammad Zarei",
      "Bruce Hellinga",
      "Pedram Izadpanah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06925"
  },
  {
    "id": "arXiv:2112.06926",
    "title": "Addressing Bias in Active Learning with Depth Uncertainty Networks... or  Not",
    "abstract": "Farquhar et al. [2021] show that correcting for active learning bias with\nunderparameterised models leads to improved downstream performance. For\noverparameterised models such as NNs, however, correction leads either to\ndecreased or unchanged performance. They suggest that this is due to an\n\"overfitting bias\" which offsets the active learning bias. We show that depth\nuncertainty networks operate in a low overfitting regime, much like\nunderparameterised models. They should therefore see an increase in performance\nwith bias correction. Surprisingly, they do not. We propose that this negative\nresult, as well as the results Farquhar et al. [2021], can be explained via the\nlens of the bias-variance decomposition of generalisation error.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2112.06796\n",
    "authors": [
      "Chelsea Murray",
      "James U. Allingham",
      "Javier Antor\u00e1n",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.06926"
  },
  {
    "id": "arXiv:2112.06953",
    "title": "Controlled Cue Generation for Play Scripts",
    "abstract": "In this paper, we use a large-scale play scripts dataset to propose the novel\ntask of theatrical cue generation from dialogues. Using over one million lines\nof dialogue and cues, we approach the problem of cue generation as a controlled\ntext generation task, and show how cues can be used to enhance the impact of\ndialogue using a language model conditioned on a dialogue/cue discriminator. In\naddition, we explore the use of topic keywords and emotions for controlled text\ngeneration. Extensive quantitative and qualitative experiments show that\nlanguage models can be successfully used to generate plausible and\nattribute-controlled texts in highly specialised domains such as play scripts.\nSupporting materials can be found at: https://catlab-team.github.io/cuegen.",
    "descriptor": "",
    "authors": [
      "Alara Dirik",
      "Hilal Donmez",
      "Pinar Yanardag"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06953"
  },
  {
    "id": "arXiv:2112.06963",
    "title": "Meterstick: Benchmarking Performance Variability in Cloud and  Self-hosted Minecraft-like Games Extended Technical Report",
    "abstract": "Due to increasing popularity and strict performance requirements, online\ngames have become a topic of interest for the performance engineering\ncommunity. One of the most popular types of online games is the modifiable\nvirtual environment (MVE), in which players can terraform the environment. The\nmost popular MVE, Minecraft, provides not only entertainment, but also\neducational support and social interaction, to over 130 million people\nworld-wide. MVEs currently support their many players by replicating isolated\ninstances that support each only up to a few hundred players under favorable\nconditions. In practice, as we show here, the real upper limit of supported\nplayers can be much lower. In this work, we posit that performance variability\nis a key cause for the lack of scalability in MVEs, investigate experimentally\ncauses of performance variability, and derive actionable insights. We propose\nan operational model for MVEs, which extends the state-of-the-art with\nessential aspects, e.g., through the consideration of environment-based\nworkloads, which are sizable workload components that do not depend on player\ninput (once set in action). Starting from this model, we design the first\nbenchmark that focuses on MVE performance variability, defining specialized\nworkloads, metrics, and processes. We conduct real-world benchmarking of\nMinecraft-like MVEs, both cloud-based and self-hosted. We find\nenvironment-based workloads and cloud deployment are significant sources of\nperformance variability: peak-latency degrades sharply to 20.7 times the\narithmetic mean and exceeds by a factor of 7.4 the performance requirements. We\nderive actionable insights for game-developers, game-operators, and other\nstakeholders to tame performance variability.",
    "descriptor": "",
    "authors": [
      "Jerrit Eickhoff",
      "Jesse Donkervliet",
      "Alexandru Iosup"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.06963"
  },
  {
    "id": "arXiv:2112.06978",
    "title": "Exploring Latent Dimensions of Crowd-sourced Creativity",
    "abstract": "Recently, the discovery of interpretable directions in the latent spaces of\npre-trained GANs has become a popular topic. While existing works mostly\nconsider directions for semantic image manipulations, we focus on an abstract\nproperty: creativity. Can we manipulate an image to be more or less creative?\nWe build our work on the largest AI-based creativity platform, Artbreeder,\nwhere users can generate images using pre-trained GAN models. We explore the\nlatent dimensions of images generated on this platform and present a novel\nframework for manipulating images to make them more creative. Our code and\ndataset are available at this http URL",
    "descriptor": "\nComments: 5th Workshop on Machine Learning for Creativity and Design (NeurIPS 2021), Sydney, Australia\n",
    "authors": [
      "Umut Kocasari",
      "Alperen Bag",
      "Efehan Atici",
      "Pinar Yanardag"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06978"
  },
  {
    "id": "arXiv:2112.06981",
    "title": "Public Release and Validation of SPEC CPU2017 PinPoints",
    "abstract": "Phase-based statistical sampling methods such as SimPoints have proven to be\neffective at dramatically reducing the long time for architectural simulators\nto run large workloads such as SPEC CPU2017. However, generating and validating\nthem is a long and tenuous process. While checkpoints of program phases, or\n\"pinballs\", of SPEC CPU2017 have been collected by other researchers and shared\nwith the research community, they are outdated and produce errors when used\nwith the latest versions of the Sniper architectural simulator. To facilitate\nour own research as well as contribute to the community, we collect and\nvalidate our own pinballs for the SPEC CPU2017 SPECspeed suite and release them\nto the public domain. In this work we document our methodology, the hardware\nand software details of the collection process, and our validation results. In\nterms of CPI, our pinballs have an average error rate of 12% when compared with\nthe native whole-program benchmark execution.",
    "descriptor": "\nComments: 4 pages, 4 figures\n",
    "authors": [
      "Haiyang Han",
      "Nikos Hardavellas"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.06981"
  },
  {
    "id": "arXiv:2112.06984",
    "title": "Implementing a Category-Theoretic Framework for Typed Abstract Syntax",
    "abstract": "In previous work (\"From signatures to monads in UniMath\"), we described a\ncategory-theoretic construction of abstract syntax from a signature, mechanized\nin the UniMath library based on the Coq proof assistant.\nIn the present work, we describe what was necessary to generalize that work\nto account for simply-typed languages. First, some definitions had to be\ngeneralized to account for the natural appearance of non-endofunctors in the\nsimply-typed case. As it turns out, in many cases our mechanized results\ncarried over to the generalized definitions without any code change. Second, an\nexisting mechanized library on $\\omega$-cocontinuous functors had to be\nextended by constructions and theorems necessary for constructing multi-sorted\nsyntax. Third, the theoretical framework for the semantical signatures had to\nbe generalized from a monoidal to a bicategorical setting, again to account for\nnon-endofunctors arising in the typed case. This uses actions of endofunctors\non functors with given source, and the corresponding notion of strong functors\nbetween actions, all formalized in UniMath using a recently developed library\nof bicategory theory. We explain what needed to be done to plug all of these\ningredients together, modularly.\nThe main result of our work is a general construction that, when fed with a\nsignature for a simply-typed language, returns an implementation of that\nlanguage together with suitable boilerplate code, in particular, a certified\nmonadic substitution operation.",
    "descriptor": "",
    "authors": [
      "Benedikt Ahrens",
      "Ralph Matthes",
      "Anders M\u00f6rtberg"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2112.06984"
  },
  {
    "id": "arXiv:2112.06986",
    "title": "On The Reliability Of Machine Learning Applications In Manufacturing  Environments",
    "abstract": "The increasing deployment of advanced digital technologies such as Internet\nof Things (IoT) devices and Cyber-Physical Systems (CPS) in industrial\nenvironments is enabling the productive use of machine learning (ML) algorithms\nin the manufacturing domain. As ML applications transcend from research to\nproductive use in real-world industrial environments, the question of\nreliability arises. Since the majority of ML models are trained and evaluated\non static datasets, continuous online monitoring of their performance is\nrequired to build reliable systems. Furthermore, concept and sensor drift can\nlead to degrading accuracy of the algorithm over time, thus compromising\nsafety, acceptance and economics if undetected and not properly addressed. In\nthis work, we exemplarily highlight the severity of the issue on a publicly\navailable industrial dataset which was recorded over the course of 36 months\nand explain possible sources of drift. We assess the robustness of ML\nalgorithms commonly used in manufacturing and show, that the accuracy strongly\ndeclines with increasing drift for all tested algorithms. We further\ninvestigate how uncertainty estimation may be leveraged for online performance\nestimation as well as drift detection as a first step towards continually\nlearning applications. The results indicate, that ensemble algorithms like\nrandom forests show the least decay of confidence calibration under drift.",
    "descriptor": "\nComments: Workshop on Distribution Shifts, 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Nicolas Jourdan",
      "Sagar Sen",
      "Erik Johannes Husom",
      "Enrique Garcia-Ceja",
      "Tobias Biegel",
      "Joachim Metternich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06986"
  },
  {
    "id": "arXiv:2112.06988",
    "title": "Event-guided Deblurring of Unknown Exposure Time Videos",
    "abstract": "Video deblurring is a highly ill-posed problem due to the loss of motion\ninformation in the blur degradation process. Since event cameras can capture\napparent motion with a high temporal resolution, several attempts have explored\nthe potential of events for guiding video deblurring. These methods generally\nassume that the exposure time is the same as the reciprocal of the video frame\nrate. However,this is not true in real situations, and the exposure time might\nbe unknown and dynamically varies depending on the video shooting\nenvironment(e.g., illumination condition). In this paper, we address the\nevent-guided video deblurring assuming dynamically variable unknown exposure\ntime of the frame-based camera. To this end, we first derive a new formulation\nfor event-guided video deblurring by considering the exposure and readout time\nin the video frame acquisition process. We then propose a novel end-toend\nlearning framework for event-guided video deblurring. In particular, we design\na novel Exposure Time-based Event Selection(ETES) module to selectively use\nevent features by estimating the cross-modal correlation between the features\nfrom blurred frames and the events. Moreover, we propose a feature fusion\nmodule to effectively fuse the selected features from events and blur frames.\nWe conduct extensive experiments on various datasets and demonstrate that our\nmethod achieves state-of-the-art performance. Our project code and pretrained\nmodels will be available.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Taewoo Kim",
      "Jungmin Lee",
      "Lin Wang",
      "Kuk-Jin Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06988"
  },
  {
    "id": "arXiv:2112.06989",
    "title": "Analyzing a Caching Model",
    "abstract": "Machine Learning has been successfully applied in systems applications such\nas memory prefetching and caching, where learned models have been shown to\noutperform heuristics. However, the lack of understanding the inner workings of\nthese models -- interpretability -- remains a major obstacle for adoption in\nreal-world deployments. Understanding a model's behavior can help system\nadministrators and developers gain confidence in the model, understand risks,\nand debug unexpected behavior in production. Interpretability for models used\nin computer systems poses a particular challenge: Unlike ML models trained on\nimages or text, the input domain (e.g., memory access patterns, program\ncounters) is not immediately interpretable. A major challenge is therefore to\nexplain the model in terms of concepts that are approachable to a human\npractitioner. By analyzing a state-of-the-art caching model, we provide\nevidence that the model has learned concepts beyond simple statistics that can\nbe leveraged for explanations. Our work provides a first step towards\nexplanability of system ML models and highlights both promises and challenges\nof this emerging research area.",
    "descriptor": "\nComments: Presented at the Neurips 2021 Workshop ML for System\n",
    "authors": [
      "Leon Sixt",
      "Evan Zheran Liu",
      "Marie Pellat",
      "James Wexler",
      "Milad Hashemi Been Kim",
      "Martin Maas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06989"
  },
  {
    "id": "arXiv:2112.06990",
    "title": "Factorization and pseudofactorization of weighted graphs",
    "abstract": "For unweighted graphs, finding isometric embeddings is closely related to\ndecompositions of $G$ into Cartesian products of smaller graphs. When $G$ is\nisomorphic to a Cartesian graph product, we call the factors of this product a\nfactorization of $G$. When $G$ is isomorphic to an isometric subgraph of a\nCartesian graph product, we call those factors a pseudofactorization of $G$.\nPrior work has shown that an unweighted graph's pseudofactorization can be used\nto generate a canonical isometric embedding into a product of the smallest\npossible pseudofactors. However, for arbitrary weighted graphs, which represent\na richer variety of metric spaces, methods for finding isometric embeddings or\ndetermining their existence remain elusive, and indeed pseudofactorization and\nfactorization have not previously been extended to this context. In this work,\nwe address the problem of finding the factorization and pseudofactorization of\na weighted graph $G$, where $G$ satisfies the property that every edge\nconstitutes a shortest path between its endpoints. We term such graphs minimal\ngraphs, noting that every graph can be made minimal by removing edges not\naffecting its path metric. We generalize pseudofactorization and factorization\nto minimal graphs and develop new proof techniques that extend the previously\nproposed algorithms due to Graham and Winkler [Graham and Winkler, '85] and\nFeder [Feder, '92] for pseudofactorization and factorization of unweighted\ngraphs. We show that any $m$-edge, $n$-vertex graph with positive integer edge\nweights can be factored in $O(m^2)$ time, plus the time to find all pairs\nshortest paths (APSP) distances in a weighted graph, resulting in an overall\nrunning time of $O(m^2+n^2\\log\\log n)$ time. We also show that a\npseudofactorization for such a graph can be computed in $O(mn)$ time, plus the\ntime to solve APSP, resulting in an $O(mn+n^2\\log\\log n)$ running time.",
    "descriptor": "\nComments: 37 pages, 10 figures\n",
    "authors": [
      "Kristin Sheridan",
      "Joseph Berleant",
      "Mark Bathe",
      "Anne Condon",
      "Virginia Vassilevska Williams"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.06990"
  },
  {
    "id": "arXiv:2112.06991",
    "title": "Biomorphic propulsion system diving thunniform robotic fish",
    "abstract": "A biomorphic propulsion systemfor underwater robotic fish is presented. The\nsystem is based on a combination of an elastic chord with a tail fin fixed on\nit. The tail fin is connected to servomotor by two symmetric movable thrusts\nsimulating muscle contraction. The propulsion system provides oscillatory tail\nmovement with controllable amplitude and frequency. Tail oscillations results\nin translational movement of the robotic fish implementing the thunniform\nprinciple of locomotion. The shape of the body of the robotic fish and the tail\nfin were designed using computational model simulating virtual body in an\naquatic medium. A prototype of robotic fish device was constructed and tested\nin experimental conditions. Dependencies of fish velocity on the amplitude and\nfrequency of tail oscillations were analyzed.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "I. V. Mitin",
      "R. A. Korotaev",
      "A. A. Ermolaev",
      "V. B. Kazantsev"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.06991"
  },
  {
    "id": "arXiv:2112.06993",
    "title": "On Control Schemes of Voltage Source Converters",
    "abstract": "This paper discusses some aspects of control schemes for voltage source\nconverters under abnormal conditions. The control schemes are developed\nspecifically for the situations when one or more system parameters vary\nsignificantly to the extent that the system becomes unstable with a\nconventional controller. The paper will present some recent works on control of\ngrid-interactive converters for parameter variations in weak grid. The paper\nwill also discuss some methods under abnormal dc-bus variation. Finally, the\npaper focuses on the control schemes suitable for ac-dc converters that\naddresses input frequency, voltage and load variation. All the discussed\ncontrol schemes have shown robust performance under abnormal conditions.",
    "descriptor": "\nComments: This work was supported in part by the Department of Energy, Office of Energy Efficiency and Renewable Energy (EERE), Solar Energy Technologies Office, under Award Number DE-EE0008767, and National Science Foundation, under Award Number ECCS 1920266\n",
    "authors": [
      "Fahmid Sadeque",
      "Tareq Hossen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.06993"
  },
  {
    "id": "arXiv:2112.06994",
    "title": "Isometric Hamming embeddings of weighted graphs",
    "abstract": "A mapping $\\alpha : V(G) \\to V(H)$ from the vertex set of one graph $G$ to\nanother graph $H$ is an isometric embedding if the shortest path distance\nbetween any two vertices in $G$ equals the distance between their images in\n$H$. Here, we consider isometric embeddings of a weighted graph $G$ into\nunweighted Hamming graphs, called Hamming embeddings, when $G$ satisfies the\nproperty that every edge is a shortest path between its endpoints. Using a\nCartesian product decomposition of $G$ called its pseudofactorization, we show\nthat every Hamming embedding of $G$ may be partitioned into Hamming embeddings\nfor each irreducible pseudofactor graph of $G$, which we call its canonical\npartition. This implies that $G$ permits a Hamming embedding if and only if\neach of its irreducible pseudofactors is Hamming embeddable. This result\nextends prior work on unweighted graphs that showed that an unweighted graph\npermits a Hamming embedding if and only if each irreducible pseudofactor is a\ncomplete graph. When a graph $G$ has nontrivial pseudofactors, determining\nwhether $G$ has a Hamming embedding can be simplified to checking embeddability\nof two or more smaller graphs.",
    "descriptor": "\nComments: 14 pages, 2 figures\n",
    "authors": [
      "Joseph Berleant",
      "Kristin Sheridan",
      "Anne Condon",
      "Virginia Vassilevska Williams",
      "Mark Bathe"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.06994"
  },
  {
    "id": "arXiv:2112.06997",
    "title": "ELF: Exact-Lipschitz Based Universal Density Approximator Flow",
    "abstract": "Normalizing flows have grown more popular over the last few years; however,\nthey continue to be computationally expensive, making them difficult to be\naccepted into the broader machine learning community. In this paper, we\nintroduce a simple one-dimensional one-layer network that has closed form\nLipschitz constants; using this, we introduce a new Exact-Lipschitz Flow (ELF)\nthat combines the ease of sampling from residual flows with the strong\nperformance of autoregressive flows. Further, we show that ELF is provably a\nuniversal density approximator, more computationally and parameter efficient\ncompared to a multitude of other flows, and achieves state-of-the-art\nperformance on multiple large-scale datasets.",
    "descriptor": "",
    "authors": [
      "Achintya Gopal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.06997"
  },
  {
    "id": "arXiv:2112.06999",
    "title": "Designing weighted and multiplex networks for deep learning user  geolocation in Twitter",
    "abstract": "Predicting the geographical location of users of social media like Twitter\nhas found several applications in health surveillance, emergency monitoring,\ncontent personalization, and social studies in general. In this work we\ncontribute to the research in this area by designing and evaluating new methods\nbased on the literature of weighted multigraphs combined with state-of-the-art\ndeep learning techniques. The explored methods depart from a similar underlying\nstructure (that of an extended mention and/or follower network) but use\ndifferent information processing strategies, e.g., information diffusion\nthrough transductive and inductive algorithms -- RGCNs and GraphSAGE,\nrespectively -- and node embeddings with Node2vec+. These graphs are then\ncombined with attention mechanisms to incorporate the users' text view into the\nmodels. We assess the performance of each of these methods and compare them to\nbaseline models in the publicly available Twitter-US dataset; we also make a\nnew dataset available based on a large Twitter capture in Latin America.\nFinally, our work discusses the limitations and validity of the comparisons\namong methods in the context of different label definitions and metrics.",
    "descriptor": "",
    "authors": [
      "Federico M. Funes",
      "Jos\u00e9 Ignacio Alvarez-Hamelin",
      "Mariano G. Beir\u00f3"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06999"
  },
  {
    "id": "arXiv:2112.07007",
    "title": "Acceleration techniques for optimization over trained neural network  ensembles",
    "abstract": "We study optimization problems where the objective function is modeled\nthrough feedforward neural networks with rectified linear unit (ReLU)\nactivation. Recent literature has explored the use of a single neural network\nto model either uncertain or complex elements within an objective function.\nHowever, it is well known that ensembles of neural networks produce more stable\npredictions and have better generalizability than models with single neural\nnetworks, which suggests the application of ensembles of neural networks in a\ndecision-making pipeline. We study how to incorporate a neural network ensemble\nas the objective function of an optimization model and explore computational\napproaches for the ensuing problem. We present a mixed-integer linear program\nbased on existing popular big-$M$ formulations for optimizing over a single\nneural network. We develop two acceleration techniques for our model, the first\none is a preprocessing procedure to tighten bounds for critical neurons in the\nneural network while the second one is a set of valid inequalities based on\nBenders decomposition. Experimental evaluations of our solution methods are\nconducted on one global optimization problem and two real-world data sets; the\nresults suggest that our optimization algorithm outperforms the adaption of an\nstate-of-the-art approach in terms of computational time and optimality gaps.",
    "descriptor": "\nComments: 17 pages, 4 tables, 2 figures\n",
    "authors": [
      "Keliang Wang",
      "Leonardo Lozano",
      "Carlos Cardonha",
      "David Bergman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.07007"
  },
  {
    "id": "arXiv:2112.07010",
    "title": "Slowing Down for Performance and Energy: An OS-Centric Study in Network  Driven Workloads",
    "abstract": "This paper studies three fundamental aspects of an OS that impact the\nperformance and energy efficiency of network processing: 1) batching, 2)\nprocessor energy settings, and 3) the logic and instructions of the OS\nnetworking paths. A network device's interrupt delay feature is used to induce\nbatching and processor frequency is manipulated to control the speed of\ninstruction execution. A baremetal library OS is used to explore OS path\nspecialization. This study shows how careful use of batching and interrupt\ndelay results in 2X energy and performance improvements across different\nworkloads. Surprisingly, we find polling can be made energy efficient and can\nresult in gains up to 11X over baseline Linux. We developed a methodology and a\nset of tools to collect system data in order to understand how energy is\nimpacted at a fine-grained granularity. This paper identifies a number of other\nnovel findings that have implications in OS design for networked applications\nand suggests a path forward to consider energy as a focal point of systems\nresearch.",
    "descriptor": "",
    "authors": [
      "Han Dong",
      "Sanjay Arora",
      "Yara Awad",
      "Tommy Unger",
      "Orran Krieger",
      "Jonathan Appavoo"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2112.07010"
  },
  {
    "id": "arXiv:2112.07011",
    "title": "Event Based Time-Vectors for auditory features extraction: a  neuromorphic approach for low power audio recognition",
    "abstract": "In recent years tremendous efforts have been done to advance the state of the\nart for Natural Language Processing (NLP) and audio recognition. However, these\nefforts often translated in increased power consumption and memory requirements\nfor bigger and more complex models. These solutions falls short of the\nconstraints of IoT devices which need low power, low memory efficient\ncomputation, and therefore they fail to meet the growing demand of efficient\nedge computing. Neuromorphic systems have proved to be excellent candidates for\nlow-power low-latency computation in a multitude of applications. For this\nreason we present a neuromorphic architecture, capable of unsupervised auditory\nfeature recognition. We then validate the network on a subset of Google's\nSpeech Commands dataset.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Marco Rasetto",
      "Juan P. Dominguez-Morales",
      "Angel Jimenez-Fernandez",
      "Ryad Benosman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.07011"
  },
  {
    "id": "arXiv:2112.07013",
    "title": "PantheonRL: A MARL Library for Dynamic Training Interactions",
    "abstract": "We present PantheonRL, a multiagent reinforcement learning software package\nfor dynamic training interactions such as round-robin, adaptive, and ad-hoc\ntraining. Our package is designed around flexible agent objects that can be\neasily configured to support different training interactions, and handles fully\ngeneral multiagent environments with mixed rewards and n agents. Built on top\nof StableBaselines3, our package works directly with existing powerful deep RL\nalgorithms. Finally, PantheonRL comes with an intuitive yet functional web user\ninterface for configuring experiments and launching multiple asynchronous jobs.\nOur package can be found at https://github.com/Stanford-ILIAD/PantheonRL.",
    "descriptor": "\nComments: 3 pages, 3 figures. Published in Proceedings of the 36th AAAI Conference on Artificial Intelligence (Demo Track) 2022\n",
    "authors": [
      "Bidipta Sarkar",
      "Aditi Talati",
      "Andy Shih",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07013"
  },
  {
    "id": "arXiv:2112.07015",
    "title": "Multi-Expert Human Action Recognition with Hierarchical Super-Class  Learning",
    "abstract": "In still image human action recognition, existing studies have mainly\nleveraged extra bounding box information along with class labels to mitigate\nthe lack of temporal information in still images; however, preparing extra data\nwith manual annotation is time-consuming and also prone to human errors.\nMoreover, the existing studies have not addressed action recognition with\nlong-tailed distribution. In this paper, we propose a two-phase multi-expert\nclassification method for human action recognition to cope with long-tailed\ndistribution by means of super-class learning and without any extra\ninformation. To choose the best configuration for each super-class and\ncharacterize inter-class dependency between different action classes, we\npropose a novel Graph-Based Class Selection (GCS) algorithm. In the proposed\napproach, a coarse-grained phase selects the most relevant fine-grained\nexperts. Then, the fine-grained experts encode the intricate details within\neach super-class so that the inter-class variation increases. Extensive\nexperimental evaluations are conducted on various public human action\nrecognition datasets, including Stanford40, Pascal VOC 2012 Action, BU101+, and\nIHAR datasets. The experimental results demonstrate that the proposed method\nyields promising improvements. To be more specific, in IHAR, Sanford40, Pascal\nVOC 2012 Action, and BU101+ benchmarks, the proposed approach outperforms the\nstate-of-the-art studies by 8.92%, 0.41%, 0.66%, and 2.11 % with much less\ncomputational cost and without any auxiliary annotation information. Besides,\nit is proven that in addressing action recognition with long-tailed\ndistribution, the proposed method outperforms its counterparts by a significant\nmargin.",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Hojat Asgarian Dehkordi",
      "Ali Soltani Nezhad",
      "Hossein Kashiani",
      "Shahriar Baradaran Shokouhi",
      "Ahmad Ayatollahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.07015"
  },
  {
    "id": "arXiv:2112.07018",
    "title": "On Exact and Approximate Policies for Linear Tape Scheduling in Data  Centers",
    "abstract": "This paper investigates scheduling policies for file retrieval in linear\nstorage devices, such as magnetic tapes. Tapes are the technology of choice for\nlong-term storage in data centers due to their low cost per capacity,\nreliability, and data security. While scheduling problems associated with data\nretrieval in tapes are classical, existing works focus on more straightforward\nheuristic approaches due to limited computational times imposed by standard\ntape specifications. Our first contribution is a theoretical investigation of\nthree standard policies, presenting their worst-case performance and special\ncases of practical relevance for which they are optimal. Next, we show that the\nproblem is polynomially solvable via two interleaved recursive models, albeit\nwith high computational complexity. We leverage our previous results to develop\ntwo new scheduling policies with constant-ratio performance and low\ncomputational cost. Finally, we investigate properties associated with the\nonline variant of the problem, presenting a new constant-factor competitive\nalgorithm. Our numerical analysis on synthetic and real-world tapes from an\nindustry partner provides insights into dataset configurations where each\npolicy is more effective, which is of relevance to data center managers. In\nparticular, our new best-performing policy is practical for large datasets and\nsignificantly improves upon standard algorithms in the area.",
    "descriptor": "\nComments: 32 pages, 6 tables, 8 figures\n",
    "authors": [
      "Carlos H. Cardonha",
      "Andre A. Cire",
      "Lucas C. Villa Real"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.07018"
  },
  {
    "id": "arXiv:2112.07019",
    "title": "Synapse Compression for Event-Based Convolutional-Neural-Network  Accelerators",
    "abstract": "Manufacturing-viable neuromorphic chips require novel computer architectures\nto achieve the massively parallel and efficient information processing the\nbrain supports so effortlessly. Emerging event-based architectures are making\nthis dream a reality. However, the large memory requirements for synaptic\nconnectivity are a showstopper for the execution of modern convolutional neural\nnetworks (CNNs) on massively parallel, event-based (spiking) architectures.\nThis work overcomes this roadblock by contributing a lightweight hardware\nscheme to compress the synaptic memory requirements by several thousand times,\nenabling the execution of complex CNNs on a single chip of small form factor. A\nsilicon implementation in a 12-nm technology shows that the technique increases\nthe system's implementation cost by only 2%, despite achieving a total\nmemory-footprint reduction of up to 374x compared to the best previously\npublished technique.",
    "descriptor": "\nComments: Preprint submitted to IEEE Transactions on Parallel and Distributed Systems\n",
    "authors": [
      "Lennart Bamberg",
      "Arash Pourtaherian",
      "Luc Waeijen",
      "Anupam Chahar",
      "Orlando Moreira"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07019"
  },
  {
    "id": "arXiv:2112.07022",
    "title": "Learning Body-Aware 3D Shape Generative Models",
    "abstract": "The shape of many objects in the built environment is dictated by their\nrelationships to the human body: how will a person interact with this object?\nExisting data-driven generative models of 3D shapes produce plausible objects\nbut do not reason about the relationship of those objects to the human body. In\nthis paper, we learn body-aware generative models of 3D shapes. Specifically,\nwe train generative models of chairs, an ubiquitous shape category, which can\nbe conditioned on a given body shape or sitting pose. The\nbody-shape-conditioned models produce chairs which will be comfortable for a\nperson with the given body shape; the pose-conditioned models produce chairs\nwhich accommodate the given sitting pose. To train these models, we define a\n\"sitting pose matching\" metric and a novel \"sitting comfort\" metric.\nCalculating these metrics requires an expensive optimization to sit the body\ninto the chair, which is too slow to be used as a loss function for training a\ngenerative model. Thus, we train neural networks to efficiently approximate\nthese metrics. We use our approach to train three body-aware generative shape\nmodels: a structured part-based generator, a point cloud generator, and an\nimplicit surface generator. In all cases, our approach produces models which\nadapt their output chair shapes to input human body specifications.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Bryce Blinn",
      "Alexander Ding",
      "Daniel Ritchie",
      "R. Kenny Jones",
      "Srinath Sridhar",
      "Manolis Savva"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07022"
  },
  {
    "id": "arXiv:2112.07030",
    "title": "A parameterized approximation algorithm for $k$-median with lower-bound  constraints",
    "abstract": "We study a variant of the classical $k$-median problem known as\ndiversity-aware $k$-median (introduced by Thejaswi et al. 2021), where we are\ngiven a collection of facility subsets, and a solution must contain at least a\nspecified number of facilities from each subset.We investigate the\nfixed-parameter tractability of this problem and show several negative hardness\nand inapproximability results, even when we afford exponential running time\nwith respect to some parameters of the problem.\nMotivated by these results we present a fixed parameter approximation\nalgorithm with approximation ratio $(1 + \\frac{2}{e} +\\epsilon)$, and argue\nthat this ratio is essentially tight assuming the gap-exponential time\nhypothesis. We also present a simple, practical local-search algorithm that\ngives a bicriteria $(2k, 3+\\epsilon)$ approximation with better running time\nbounds.",
    "descriptor": "",
    "authors": [
      "Ameet Gadekar",
      "Bruno Ordozgoiti",
      "Suhas Thejaswi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.07030"
  },
  {
    "id": "arXiv:2112.07031",
    "title": "Teaching a Robot to Walk Using Reinforcement Learning",
    "abstract": "Classical control techniques such as PID and LQR have been used effectively\nin maintaining a system state, but these techniques become more difficult to\nimplement when the model dynamics increase in complexity and sensitivity. For\nadaptive robotic locomotion tasks with several degrees of freedom, this task\nbecomes infeasible with classical control techniques. Instead, reinforcement\nlearning can train optimal walking policies with ease. We apply deep Q-learning\nand augmented random search (ARS) to teach a simulated two-dimensional bipedal\nrobot how to walk using the OpenAI Gym BipedalWalker-v3 environment. Deep\nQ-learning did not yield a high reward policy, often prematurely converging to\nsuboptimal local maxima likely due to the coarsely discretized action space.\nARS, however, resulted in a better trained robot, and produced an optimal\npolicy which officially \"solves\" the BipedalWalker-v3 problem. Various naive\npolicies, including a random policy, a manually encoded inch forward policy,\nand a stay still policy, were used as benchmarks to evaluate the proficiency of\nthe learning algorithm results.",
    "descriptor": "\nComments: 6 pages, 9 figures\n",
    "authors": [
      "Jack Dibachi",
      "Jacob Azoulay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.07031"
  },
  {
    "id": "arXiv:2112.07035",
    "title": "Framework para Caracterizar Fake News en Terminos de Emociones",
    "abstract": "Social networks have become one of the main information channels for human\nbeings due to the immediate and social interactivity they offer, allowing in\nsome cases to publish what each user considers relevant. This has brought with\nit the generation of false news or Fake News, publications that only seek to\ngenerate uncertainty, misinformation or skew the opinion of readers. It has\nbeen shown that the human being is not capable of fully identifying whether an\narticle is really a fact or a Fake News, due to this it is that models arise\nthat seek to characterize and identify articles based on data mining and\nmachine learning. This article proposes a three-layer framework, the main\nobjective of which is to characterize the emotions present in Fake News and to\nbe a tool for future work that identifies the emotional state and intentional\nstate of the public.",
    "descriptor": "\nComments: in Spanish\n",
    "authors": [
      "Luis Rojas Rubio",
      "Claudio Meneses Villegas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.07035"
  },
  {
    "id": "arXiv:2112.07041",
    "title": "Survey of Generative Methods for Social Media Analysis",
    "abstract": "This survey draws a broad-stroke, panoramic picture of the State of the Art\n(SoTA) of the research in generative methods for the analysis of social media\ndata. It fills a void, as the existing survey articles are either much narrower\nin their scope or are dated. We included two important aspects that currently\ngain importance in mining and modeling social media: dynamics and networks.\nSocial dynamics are important for understanding the spreading of influence or\ndiseases, formation of friendships, the productivity of teams, etc. Networks,\non the other hand, may capture various complex relationships providing\nadditional insight and identifying important patterns that would otherwise go\nunnoticed.",
    "descriptor": "",
    "authors": [
      "Stan Matwin",
      "Aristides Milios",
      "Pawe\u0142 Pra\u0142at",
      "Amilcar Soares",
      "Fran\u00e7ois Th\u00e9berge"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07041"
  },
  {
    "id": "arXiv:2112.07042",
    "title": "How to Learn when Data Gradually Reacts to Your Model",
    "abstract": "A recent line of work has focused on training machine learning (ML) models in\nthe performative setting, i.e. when the data distribution reacts to the\ndeployed model. The goal in this setting is to learn a model which both induces\na favorable data distribution and performs well on the induced distribution,\nthereby minimizing the test loss. Previous work on finding an optimal model\nassumes that the data distribution immediately adapts to the deployed model. In\npractice, however, this may not be the case, as the population may take time to\nadapt to the model. In many applications, the data distribution depends on both\nthe currently deployed ML model and on the \"state\" that the population was in\nbefore the model was deployed. In this work, we propose a new algorithm,\nStateful Performative Gradient Descent (Stateful PerfGD), for minimizing the\nperformative loss even in the presence of these effects. We provide theoretical\nguarantees for the convergence of Stateful PerfGD. Our experiments confirm that\nStateful PerfGD substantially outperforms previous state-of-the-art methods.",
    "descriptor": "\nComments: 40 pages, 8 figures\n",
    "authors": [
      "Zachary Izzo",
      "James Zou",
      "Lexing Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.07042"
  },
  {
    "id": "arXiv:2112.07045",
    "title": "Fuzzy Win-Win: A Novel Approach to Quantify Win-Win Using Fuzzy Logic",
    "abstract": "The classic win-win has a key flaw in that it cannot offer the parties the\nright amounts of winning because each party believes they are winners. In\nreality, one party may win more than the other. This strategy is not limited to\na single product or negotiation; it may be applied to a variety of situations\nin life. We present a novel way to measure the win-win situation in this paper.\nThe proposed method employs Fuzzy logic to create a mathematical model that\naids negotiators in quantifying their winning percentages. The model is put to\nthe test on real-life negotiations scenarios such as the Iranian uranium\nenrichment negotiations, the Iraqi-Jordanian oil deal, and the iron ore\nnegotiation (2005-2009). The presented model has shown to be a useful tool in\npractice and can be easily generalized to be utilized in other domains as well.",
    "descriptor": "\nComments: 25 pages, 5 figures\n",
    "authors": [
      "Ahmad B. Hassanat",
      "Ghada A. Altarawneh",
      "Ahmad S. Tarawneh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07045"
  },
  {
    "id": "arXiv:2112.07047",
    "title": "SoK: A Framework for Unifying At-Risk User Research",
    "abstract": "At-risk users are people who experience elevated digital security, privacy,\nand safety threats because of what they do, who they are, where they are, or\nwho they are with. In this systematization work, we present a framework for\nreasoning about at-risk users based on a wide-ranging meta-analysis of 85\npapers. Across the varied populations that we examined (e.g., children,\nactivists, women in developing regions), we identified 10 unifying contextual\nrisk factors--such as oppression or stigmatization and access to a sensitive\nresource--which augment or amplify digital-safety threats and their resulting\nharms. We also identified technical and non-technical practices that at-risk\nusers adopt to attempt to protect themselves from digital-safety threats. We\nuse this framework to discuss barriers that limit at-risk users' ability or\nwillingness to take protective actions. We believe that the security, privacy,\nand human-computer interaction research and practitioner communities can use\nour framework to identify and shape research investments to benefit at-risk\nusers, and to guide technology design to better support at-risk users.",
    "descriptor": "\nComments: 18 pages, 2 tables\n",
    "authors": [
      "Noel Warford",
      "Tara Matthews",
      "Kaitlyn Yang",
      "Omer Akgul",
      "Sunny Consolvo",
      "Patrick Gage Kelley",
      "Nathan Malkin",
      "Michelle L. Mazurek",
      "Manya Sleeper",
      "Kurt Thomas"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.07047"
  },
  {
    "id": "arXiv:2112.07048",
    "title": "Placement and Allocation of Communications Resources in Slicing-aware  Flying Networks",
    "abstract": "Network slicing emerged in 5G networks as a key component to enable the use\nof multiple services with different performance requirements on top of a shared\nphysical network infrastructure. A major challenge lies on ensuring wireless\ncoverage and enough communications resources to meet the target Quality of\nService (QoS) levels demanded by these services, including throughput and delay\nguarantees. The challenge is exacerbated in temporary events, such as disaster\nmanagement scenarios and outdoor festivities, where the existing wireless\ninfrastructures may collapse, fail to provide sufficient wireless coverage, or\nlack the required communications resources. Flying networks, composed of\nUnmanned Aerial Vehicles (UAVs), emerged as a solution to provide on-demand\nwireless coverage and communications resources anywhere, anytime. However,\nexisting solutions mostly rely on best-effort networks. The main contribution\nof this paper is SLICER, an algorithm enabling the placement and allocation of\ncommunications resources in slicing-aware flying networks. The evaluation\ncarried out by means of ns-3 simulations shows SLICER can meet the targeted QoS\nlevels, while using the minimum amount of communications resources.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Coelho",
      "Helder Fontes",
      "Rui Campos",
      "Manuel Ricardo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.07048"
  },
  {
    "id": "arXiv:2112.07049",
    "title": "The state of optics research in Colombia: a scientometric analysis",
    "abstract": "Although there is a perception in the community that the state of optics\nresearch in Colombia has reached a mature state with international recognition,\nto date, there is no study that supports this view quantitatively. We aimed to\nassess the state of optics research in Colombia based on international journal\npublications. Therefore, we determined scientometric indicators using the\nresearch articles published by authors with Colombian affiliation in journals\nindexed in the Scopus database belonging to the Atomic and Molecular Physics\nand Optics subject category. The research output has increased dramatically in\nthe past two decades, with an average of 169 articles per year since 2016. Most\nof these articles are published in high-impact journals. A little over 10\\% of\nthat research is in the top 10\\% most cited in the world. Over 25 higher\neducation institutions contribute significantly to this research with many\ninternational and national collaborations. The normalized citation impact for\nColombian optics research is 0.95, only five points below the world average,\nand ranked second in Latin America, only superseded by Chile (1.33). Our\nresults show that optics research is an established research area in Colombia\nwith high impact and many active groups from different institutions spread\nthroughout the country.",
    "descriptor": "\nComments: submitted to Optica Pura y Aplicada\n",
    "authors": [
      "Andres G. Marrugo",
      "Atilio Bustos-Gonzalez",
      "Edgar Ruerda"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2112.07049"
  },
  {
    "id": "arXiv:2112.07050",
    "title": "Optimal Fully Dynamic $k$-Centers Clustering",
    "abstract": "We present the first algorithm for fully dynamic $k$-centers clustering in an\narbitrary metric space that maintains an optimal $2+\\epsilon$ approximation in\n$O(k \\cdot \\operatorname{polylog}(n,\\Delta))$ amortized update time. Here, $n$\nis an upper bound on the number of active points at any time, and $\\Delta$ is\nthe aspect ratio of the data. Previously, the best known amortized update time\nwas $O(k^2\\cdot \\operatorname{polylog}(n,\\Delta))$, and is due to Chan,\nGourqin, and Sozio. We demonstrate that the runtime of our algorithm is optimal\nup to $\\operatorname{polylog}(n,\\Delta)$ factors, even for insertion-only\nstreams, which closes the complexity of fully dynamic $k$-centers clustering.\nIn particular, we prove that any algorithm for $k$-clustering tasks in\narbitrary metric spaces, including $k$-means, $k$-medians, and $k$-centers,\nmust make at least $\\Omega(n k)$ distance queries to achieve any non-trivial\napproximation factor.\nDespite the lower bound for arbitrary metrics, we demonstrate that an update\ntime sublinear in $k$ is possible for metric spaces which admit locally\nsensitive hash functions (LSH). Namely, we demonstrate a black-box\ntransformation which takes a locally sensitive hash family for a metric space\nand produces a faster fully dynamic $k$-centers algorithm for that space. In\nparticular, for a large class of metrics including Euclidean space, $\\ell_p$\nspaces, the Hamming Metric, and the Jaccard Metric, for any $c > 1$, our\nresults yield a $c(4+\\epsilon)$ approximate $k$-centers solution in $O(n^{1/c}\n\\cdot \\operatorname{polylog}(n,\\Delta))$ amortized update time, simultaneously\nfor all $k \\geq 1$. Previously, the only known comparable result was a $O(c\n\\log n)$ approximation for Euclidean space due to Schmidt and Sohler, running\nin the same amortized update time.",
    "descriptor": "",
    "authors": [
      "MohammadHossein Bateni",
      "Hossein Esfandiari",
      "Rajesh Jayaram",
      "Vahab Mirrokni"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.07050"
  },
  {
    "id": "arXiv:2112.07051",
    "title": "A Simple Standard for Sharing Ontological Mappings (SSSOM)",
    "abstract": "Despite progress in the development of standards for describing and\nexchanging scientific information, the lack of easy-to-use standards for\nmapping between different representations of the same or similar objects in\ndifferent databases poses a major impediment to data integration and\ninteroperability. Mappings often lack the metadata needed to be correctly\ninterpreted and applied. For example, are two terms equivalent or merely\nrelated? Are they narrow or broad matches? Are they associated in some other\nway? Such relationships between the mapped terms are often not documented,\nleading to incorrect assumptions and making them hard to use in scenarios that\nrequire a high degree of precision (such as diagnostics or risk prediction).\nAlso, the lack of descriptions of how mappings were done makes it hard to\ncombine and reconcile mappings, particularly curated and automated ones.\nThe Simple Standard for Sharing Ontological Mappings (SSSOM) addresses these\nproblems by: 1. Introducing a machine-readable and extensible vocabulary to\ndescribe metadata that makes imprecision, inaccuracy and incompleteness in\nmappings explicit. 2. Defining an easy to use table-based format that can be\nintegrated into existing data science pipelines without the need to parse or\nquery ontologies, and that integrates seamlessly with Linked Data standards. 3.\nImplementing open and community-driven collaborative workflows designed to\nevolve the standard continuously to address changing requirements and mapping\npractices. 4. Providing reference tools and software libraries for working with\nthe standard.\nIn this paper, we present the SSSOM standard, describe several use cases, and\nsurvey some existing work on standardizing the exchange of mappings, with the\ngoal of making mappings Findable, Accessible, Interoperable, and Reusable\n(FAIR). The SSSOM specification is at this http URL",
    "descriptor": "\nComments: Corresponding author: Christopher J. Mungall &lt;cjmungall@lbl.gov&gt;\n",
    "authors": [
      "Nicolas Matentzoglu",
      "James P. Balhoff",
      "Susan M. Bello",
      "Chris Bizon",
      "Matthew Brush",
      "Tiffany J. Callahan",
      "Christopher G Chute",
      "William D. Duncan",
      "Chris T. Evelo",
      "Davera Gabriel",
      "John Graybeal",
      "Alasdair Gray",
      "Benjamin M. Gyori",
      "Melissa Haendel",
      "Henriette Harmse",
      "Nomi L. Harris",
      "Ian Harrow",
      "Harshad Hegde",
      "Amelia L. Hoyt",
      "Charles T. Hoyt",
      "Dazhi Jiao",
      "Ernesto Jim\u00e9nez-Ruiz",
      "Simon Jupp",
      "Hyeongsik Kim",
      "Sebastian Koehler",
      "Thomas Liener",
      "Qinqin Long",
      "James Malone",
      "James A. McLaughlin",
      "Julie A. McMurry",
      "Sierra Moxon",
      "Monica C. Munoz-Torres",
      "David Osumi-Sutherland",
      "James A. Overton",
      "Bjoern Peters",
      "Tim Putman",
      "N\u00faria Queralt-Rosinach",
      "Kent Shefchek",
      "Harold Solbrig",
      "Anne Thessen",
      "Tania Tudorache",
      "Nicole Vasilevsky",
      "Alex H. Wagner",
      "Christopher J. Mungall"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.07051"
  },
  {
    "id": "arXiv:2112.07054",
    "title": "Graph network for simultaneous learning of forward and inverse physics",
    "abstract": "In this work, we propose an end-to-end graph network that learns forward and\ninverse models of particle-based physics using interpretable inductive biases.\nPhysics-informed neural networks are often engineered to solve specific\nproblems through problem-specific regularization and loss functions. Such\nexplicit learning biases the network to learn data specific patterns and may\nrequire a change in the loss function or neural network architecture hereby\nlimiting their generalizabiliy. While recent studies have proposed graph\nnetworks to study forward dynamics, they rely on particle specific parameters\nsuch as mass, etc. to approximate the dynamics of the system. Our graph network\nis implicitly biased by learning to solve several tasks, thereby sharing\nrepresentations between tasks in order to learn the forward dynamics as well as\ninfer the probability distribution of unknown particle specific properties. We\nevaluate our approach on one-step next state prediction tasks across diverse\ndatasets that feature different particle interactions. Our comparison against\nrelated data-driven physics learning approaches reveals that our model is able\nto predict the forward dynamics with at least an order of magnitude higher\naccuracy. We also show that our approach is able to recover multi-modal\nprobability distributions of unknown physical parameters using orders of\nmagnitude fewer samples.",
    "descriptor": "",
    "authors": [
      "Sakthi Kumar Arul Prakash",
      "Conrad Tucker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07054"
  },
  {
    "id": "arXiv:2112.07055",
    "title": "Language Models are not Models of Language",
    "abstract": "Natural Language Processing (NLP) has become one of the leading application\nareas in the current Artificial Intelligence boom. Transfer learning has\nenabled large deep learning neural networks trained on the language modeling\ntask to vastly improve performance in almost all language tasks. Interestingly,\nwhen the models are trained with data that includes software code, they\ndemonstrate remarkable abilities in generating functioning computer code from\nnatural language specifications. We argue that this creates a conundrum for\nclaims that neural models provide an alternative theory to generative phrase\nstructure grammars in explaining how language works. Since the syntax of\nprogramming languages is determined by phrase structure grammars, successful\nneural models are apparently uninformative about the theoretical foundations of\nprogramming languages, and by extension, natural languages. We argue that the\nterm language model is misleading because deep learning models are not\ntheoretical models of language and propose the adoption of corpus model\ninstead, which better reflects the genesis and contents of the model.",
    "descriptor": "",
    "authors": [
      "Csaba Veres"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07055"
  },
  {
    "id": "arXiv:2112.07057",
    "title": "NEORL: NeuroEvolution Optimization with Reinforcement Learning",
    "abstract": "We present an open-source Python framework for NeuroEvolution Optimization\nwith Reinforcement Learning (NEORL) developed at the Massachusetts Institute of\nTechnology. NEORL offers a global optimization interface of state-of-the-art\nalgorithms in the field of evolutionary computation, neural networks through\nreinforcement learning, and hybrid neuroevolution algorithms. NEORL features\ndiverse set of algorithms, user-friendly interface, parallel computing support,\nautomatic hyperparameter tuning, detailed documentation, and demonstration of\napplications in mathematical and real-world engineering optimization. NEORL\nencompasses various optimization problems from combinatorial, continuous, mixed\ndiscrete/continuous, to high-dimensional, expensive, and constrained\nengineering optimization. NEORL is tested in variety of engineering\napplications relevant to low carbon energy research in addressing solutions to\nclimate change. The examples include nuclear reactor control and fuel cell\npower production. The results demonstrate NEORL competitiveness against other\nalgorithms and optimization frameworks in the literature, and a potential tool\nto solve large-scale optimization problems. More examples and benchmarking of\nNEORL can be found here: https://neorl.readthedocs.io/en/latest/index.html",
    "descriptor": "\nComments: 23 pages, 6 figures, 7 tables\n",
    "authors": [
      "Majdi I. Radaideh",
      "Katelin Du",
      "Paul Seurin",
      "Devin Seyler",
      "Xubo Gu",
      "Haijia Wang",
      "Koroush Shirvan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07057"
  },
  {
    "id": "arXiv:2112.07061",
    "title": "Differentially Private Data Publication with Multi-level Data Utility",
    "abstract": "Conventional private data publication mechanisms aim to retain as much data\nutility as possible while ensuring sufficient privacy protection on sensitive\ndata. Such data publication schemes implicitly assume that all data analysts\nand users have the same data access privilege levels. However, it is not\napplicable for the scenario that data users often have different levels of\naccess to the same data, or different requirements of data utility. The\nmulti-level privacy requirements for different authorization levels pose new\nchallenges for private data publication. Traditional PPDP mechanisms only\npublish one perturbed and private data copy satisfying some privacy guarantee\nto provide relatively accurate analysis results. To find a good tradeoff\nbetween privacy preservation level and data utility itself is a hard problem,\nlet alone achieving multi-level data utility on this basis. In this paper, we\naddress this challenge in proposing a novel framework of data publication with\ncompressive sensing supporting multi-level utility-privacy tradeoffs, which\nprovides differential privacy. Specifically, we resort to compressive sensing\n(CS) method to project a $n$-dimensional vector representation of users' data\nto a lower $m$-dimensional space, and then add deliberately designed noise to\nsatisfy differential privacy. Then, we selectively obfuscate the measurement\nvector under compressive sensing by adding linearly encoded noise, and provide\ndifferent data reconstruction algorithms for users with different authorization\nlevels. Extensive experimental results demonstrate that ML-DPCS yields\nmulti-level of data utility for specific users at different authorization\nlevels.",
    "descriptor": "",
    "authors": [
      "Honglu Jiang",
      "S M Sarwar",
      "Haotian Yu",
      "Sheikh Ariful Islam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.07061"
  },
  {
    "id": "arXiv:2112.07062",
    "title": "Unconditional stability in 3d of a sparse grad-div approximation of the  Navier-Stokes equations",
    "abstract": "Inclusion of a grad-div term, $-\\gamma\\nabla\\nabla\\cdot u$, is an effective\ntool for improving mass conservation in discretizations of incompressible\nflows. However, the added term $-\\gamma\\nabla\\nabla\\cdot u$ couples all\nvelocity components, decreases sparsity and increases the condition number in\nthe linear systems that must be solved every time step. To address these three\nissues various sparse grad-div regularizations and a modular grad-div method\nhave been developed. Sparse grad-div discretizations have been previously\nproven to be stable in $2d$ but stability in $3d$ is unproven. Let $G^{\\ast\n}=-diag(\\partial_{x}^{2},\\partial_{y}^{2},\\partial_{z}^{2})$ denote the\ndiagonal of $G=-\\nabla\\nabla\\cdot$, and $\\alpha\\geq0$\\ an adjustable parameter.\nWe prove unconditional, nonlinear, long time stability in $3d$ (and $2d$) of\nthe (space discretization suppressed) sparse grad-div method% \\begin{gather*}\n\\frac{u^{n+1}-u^{n}}{k}+u^{n}\\cdot\\nabla u^{n+1}+\\nabla p^{n+1}-\\nu\\Delta\nu^{n+1}+\\\\ (\\gamma+\\alpha)G^{\\ast}u^{n+1}-[(\\gamma+\\alpha)G^{\\ast}-\\gamma\nG]u^{n}% =f{\\text{ .}}% \\end{gather*} The discretization error of the grad-div\nterms is first order, comparable to the implicit method used for the other\nterms. We prove unconditional stability of this method for free parameter\n$\\alpha\\geq0.5\\gamma$ and that the method controls the persistent size of\n$||\\nabla\\cdot u||$ in general and controls the transients in $||\\nabla\\cdot\nu||$ for a cold start. Consistent numerical tests are presented. This report\nalso presents and proves unconditional stability of a modular, sparse grad-div\nmethod.%",
    "descriptor": "",
    "authors": [
      "William Layton",
      "Shuxian Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07062"
  },
  {
    "id": "arXiv:2112.07064",
    "title": "Ergo -- a programming language for Smart Legal Contracts",
    "abstract": "We present a smart legal contract platform to support a wide range of smart\nlegal contract use cases. We see this as a step towards improving existing\napproaches to representing the complexity of legal agreements and executing\naspects of these agreements.",
    "descriptor": "",
    "authors": [
      "Niall Roche",
      "Walter Hernandez",
      "Eason Chen",
      "J\u00e9r\u00f4me Sim\u00e9on",
      "Dan Selman"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.07064"
  },
  {
    "id": "arXiv:2112.07065",
    "title": "Schmebulock's consensus",
    "abstract": "The strength of gnomes lies in their coordinated action. Being small and\nsubtle creatures themselves, the forest gnomes can form large swarms acting as\none giant creature. This unusual defense strategy required a lot of skill and\ntraining as directing a swarm is not an easy task! Initially, gnomes used\nleader-based control algorithms, although those have proven to be vulnerable to\nabuse and failure.\nAfter thorough research and study, gnomes developed their own leaderless\nconsensus algorithm based on very simple rules. It is based on local broadcast\n(gossip) in an open network of a known radius $r$. One of the gnomes proposes a\nplan which then spreads gnome to gnome. If there is agreement, all gnomes act\n\\emph{all at once}. If there are conflicting plans (an extreme rarity), they\ntry again. The resulting swarm reaction time is exactly the swarm round-trip\ntime $2rt$, where $t$ is the command relay time. The algorithm is\nnon-Byzantine; all gnomes must be sane and sober.",
    "descriptor": "",
    "authors": [
      "Victor Grishchenko",
      "Mikhail Patrakeev",
      "S.Q.Locke III"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.07065"
  },
  {
    "id": "arXiv:2112.07066",
    "title": "Continual Learning In Environments With Polynomial Mixing Times",
    "abstract": "The mixing time of the Markov chain induced by a policy limits performance in\nreal-world continual learning scenarios. Yet, the effect of mixing times on\nlearning in continual reinforcement learning (RL) remains underexplored. In\nthis paper, we characterize problems that are of long-term interest to the\ndevelopment of continual RL, which we call scalable MDPs, through the lens of\nmixing times. In particular, we establish that scalable MDPs have mixing times\nthat scale polynomially with the size of the problem. We go on to demonstrate\nthat polynomial mixing times present significant difficulties for existing\napproaches and propose a family of model-based algorithms that speed up\nlearning by directly optimizing for the average reward through a novel\nbootstrapping procedure. Finally, we perform empirical regret analysis of our\nproposed approaches, demonstrating clear improvements over baselines and also\nhow scalable MDPs can be used for analysis of RL algorithms as mixing times\nscale.",
    "descriptor": "\nComments: 2 Figures, 20 pages\n",
    "authors": [
      "Matthew Riemer",
      "Sharath Chandra Raparthy",
      "Ignacio Cases",
      "Gopeshh Subbaraj",
      "Maximilian Puelma Touzel",
      "Irina Rish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07066"
  },
  {
    "id": "arXiv:2112.07074",
    "title": "Towards a Unified Foundation Model: Jointly Pre-Training Transformers on  Unpaired Images and Text",
    "abstract": "In this paper, we explore the possibility of building a unified foundation\nmodel that can be adapted to both vision-only and text-only tasks. Starting\nfrom BERT and ViT, we design a unified transformer consisting of\nmodality-specific tokenizers, a shared transformer encoder, and task-specific\noutput heads. To efficiently pre-train the proposed model jointly on unpaired\nimages and text, we propose two novel techniques: (i) We employ the\nseparately-trained BERT and ViT models as teachers and apply knowledge\ndistillation to provide additional, accurate supervision signals for the joint\ntraining; (ii) We propose a novel gradient masking strategy to balance the\nparameter updates from the image and text pre-training losses. We evaluate the\njointly pre-trained transformer by fine-tuning it on image classification tasks\nand natural language understanding tasks, respectively. The experiments show\nthat the resultant unified foundation transformer works surprisingly well on\nboth the vision-only and text-only tasks, and the proposed knowledge\ndistillation and gradient masking strategy can effectively lift the performance\nto approach the level of separately-trained models.",
    "descriptor": "\nComments: preliminary work\n",
    "authors": [
      "Qing Li",
      "Boqing Gong",
      "Yin Cui",
      "Dan Kondratyuk",
      "Xianzhi Du",
      "Ming-Hsuan Yang",
      "Matthew Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07074"
  },
  {
    "id": "arXiv:2112.07075",
    "title": "Matrix-free approaches for GPU acceleration of a high-order finite  element hydrodynamics application using MFEM, Umpire, and RAJA",
    "abstract": "With the introduction of advanced heterogeneous computing architectures based\non GPU accelerators, large-scale production codes have had to rethink their\nnumerical algorithms and incorporate new programming models and memory\nmanagement strategies in order to run efficiently on the latest supercomputers.\nIn this work we discuss our co-design strategy to address these challenges and\nachieve performance and portability with MARBL, a next-generation multi-physics\ncode in development at Lawrence Livermore National Laboratory. We present a\ntwo-fold approach, wherein new hardware is used to motivate both new algorithms\nand new abstraction layers, resulting in a single source application code\nsuitable for a variety of platforms. Focusing on MARBL's ALE hydrodynamics\npackage, we demonstrate scalability on different platforms and highlight that\nmany of our innovations have been contributed back to open-source software\nlibraries, such as MFEM (finite element algorithms) and RAJA (kernel\nabstractions).",
    "descriptor": "\nComments: Submitted to The International Journal of High Performance Computing Applications\n",
    "authors": [
      "Arturo Vargas",
      "Thomas M. Stitt",
      "Kenneth Weiss",
      "Vladimir Z. Tomov",
      "Jean-Sylvain Camier",
      "Tzanio Kolev",
      "Robert N. Rieben"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2112.07075"
  },
  {
    "id": "arXiv:2112.07076",
    "title": "Real-Time Neural Voice Camouflage",
    "abstract": "Automatic speech recognition systems have created exciting possibilities for\napplications, however they also enable opportunities for systematic\neavesdropping. We propose a method to camouflage a person's voice over-the-air\nfrom these systems without inconveniencing the conversation between people in\nthe room. Standard adversarial attacks are not effective in real-time streaming\nsituations because the characteristics of the signal will have changed by the\ntime the attack is executed. We introduce predictive attacks, which achieve\nreal-time performance by forecasting the attack that will be the most effective\nin the future. Under real-time constraints, our method jams the established\nspeech recognition system DeepSpeech 4.17x more than baselines as measured\nthrough word error rate, and 7.27x more as measured through character error\nrate. We furthermore demonstrate our approach is practically effective in\nrealistic environments over physical distances.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Mia Chiquier",
      "Chengzhi Mao",
      "Carl Vondrick"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.07076"
  },
  {
    "id": "arXiv:2112.07080",
    "title": "Fast Footstep Planning on Uneven Terrain Using Deep Sequential Models",
    "abstract": "One of the fundamental challenges in realizing the potential of legged robots\nis generating plans to traverse challenging terrains. Control actions must be\ncarefully selected so the robot will not crash or slip. The high dimensionality\nof the joint space makes directly planning low-level actions from onboard\nperception difficult, and control stacks that do not consider the low-level\nmechanisms of the robot in planning are ill-suited to handle fine-grained\nobstacles. One method for dealing with this is selecting footstep locations\nbased on terrain characteristics. However, incorporating robot dynamics into\nfootstep planning requires significant computation, much more than in the\nquasi-static case. In this work, we present an LSTM-based planning framework\nthat learns probability distributions over likely footstep locations using both\nterrain lookahead and the robot's dynamics, and leverages the LSTM's sequential\nnature to find footsteps in linear time. Our framework can also be used as a\nmodule to speed up sampling-based planners. We validate our approach on a\nsimulated one-legged hopper over a variety of uneven terrains.",
    "descriptor": "\nComments: 6 pages, 4 figures, submitted to ICRA 2022\n",
    "authors": [
      "Hersh Sanghvi",
      "Camillo Jose Taylor"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.07080"
  },
  {
    "id": "arXiv:2112.07082",
    "title": "DeepDiffusion: Unsupervised Learning of Retrieval-adapted  Representations via Diffusion-based Ranking on Latent Feature Manifold",
    "abstract": "Unsupervised learning of feature representations is a challenging yet\nimportant problem for analyzing a large collection of multimedia data that do\nnot have semantic labels. Recently proposed neural network-based unsupervised\nlearning approaches have succeeded in obtaining features appropriate for\nclassification of multimedia data. However, unsupervised learning of feature\nrepresentations adapted to content-based matching, comparison, or retrieval of\nmultimedia data has not been explored well. To obtain such retrieval-adapted\nfeatures, we introduce the idea of combining diffusion distance on a feature\nmanifold with neural network-based unsupervised feature learning. This idea is\nrealized as a novel algorithm called DeepDiffusion (DD). DD simultaneously\noptimizes two components, a feature embedding by a deep neural network and a\ndistance metric that leverages diffusion on a latent feature manifold,\ntogether. DD relies on its loss function but not encoder architecture. It can\nthus be applied to diverse multimedia data types with their respective encoder\narchitectures. Experimental evaluation using 3D shapes and 2D images\ndemonstrates versatility as well as high accuracy of the DD algorithm. Code is\navailable at https://github.com/takahikof/DeepDiffusion",
    "descriptor": "\nComments: Currently under review\n",
    "authors": [
      "Takahiko Furuya",
      "Ryutarou Ohbuchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.07082"
  },
  {
    "id": "arXiv:2112.07085",
    "title": "Relative generalized Hamming weights of evaluation codes",
    "abstract": "The aim of this work is to algebraically describe the relative generalized\nHamming weights of evaluation codes. We give a lower bound for these weights in\nterms of a footprint bound. We prove that this bound can be sharp. We compute\nthe next-to-minimal weight of toric codes over hypersimplices of degree 1.",
    "descriptor": "",
    "authors": [
      "Delio Jaramillo-Velez",
      "Hiram H. L\u00f3pez",
      "Yuriko Pitones"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2112.07085"
  },
  {
    "id": "arXiv:2112.07086",
    "title": "Study of Linear Precoding and Power Allocation for Large  Multiple-Antenna Systems with Coarsely Quantized Signals",
    "abstract": "This work studies coarse quantization-aware BD\n(${\\scriptstyle\\mathrm{CQA-BD}}$) and coarse quantization-aware RBD\n(${\\scriptstyle\\mathrm{CQA-RBD}}$) precoding algorithms for large-scale MU-MIMO\nsystems with coarsely quantized signals and proposes the coarse-quantization\nmost advantageous allocation strategy (${\\scriptstyle\\mathrm{CQA-MAAS}}$) power\nallocation algorithm for linearly-precoded MU-MIMO systems. An analysis of the\nsum-rate along with studies of computational complexity is also carried out.\nFinally, comparisons between existing precoding and its power allocated version\nare followed by conclusions.",
    "descriptor": "\nComments: 7 pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2107.03969\n",
    "authors": [
      "S. F. Pinto",
      "R. C. de Lamare"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.07086"
  },
  {
    "id": "arXiv:2112.07087",
    "title": "Heuristic Hyperparameter Optimization for Convolutional Neural Networks  using Genetic Algorithm",
    "abstract": "In recent years, people from all over the world are suffering from one of the\nmost severe diseases in history, known as Coronavirus disease 2019, COVID-19\nfor short. When the virus reaches the lungs, it has a higher probability to\ncause lung pneumonia and sepsis. X-ray image is a powerful tool in identifying\nthe typical features of the infection for COVID-19 patients. The radiologists\nand pathologists observe that ground-glass opacity appears in the chest X-ray\nfor infected patient \\cite{cozzi2021ground}, and it could be used as one of the\ncriteria during the diagnosis process. In the past few years, deep learning has\nproven to be one of the most powerful methods in the field of image\nclassification. Due to significant differences in Chest X-Ray between normal\nand infected people \\cite{rousan2020chest}, deep models could be used to\nidentify the presence of the disease given a patient's Chest X-Ray. Many deep\nmodels are complex, and it evolves with lots of input parameters. Designers\nsometimes struggle with the tuning process for deep models, especially when\nthey build up the model from scratch. Genetic Algorithm, inspired by the\nbiological evolution process, plays a key role in solving such complex\nproblems. In this paper, I proposed a genetic-based approach to optimize the\nConvolutional Neural Network(CNN) for the Chest X-Ray classification task.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Meng Zhou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.07087"
  },
  {
    "id": "arXiv:2112.07088",
    "title": "ElePose: Unsupervised 3D Human Pose Estimation by Predicting Camera  Elevation and Learning Normalizing Flows on 2D Poses",
    "abstract": "Human pose estimation from single images is a challenging problem that is\ntypically solved by supervised learning. Unfortunately, labeled training data\ndoes not yet exist for many human activities since 3D annotation requires\ndedicated motion capture systems. Therefore, we propose an unsupervised\napproach that learns to predict a 3D human pose from a single image while only\nbeing trained with 2D pose data, which can be crowd-sourced and is already\nwidely available. To this end, we estimate the 3D pose that is most likely over\nrandom projections, with the likelihood estimated using normalizing flows on 2D\nposes. While previous work requires strong priors on camera rotations in the\ntraining data set, we learn the distribution of camera angles which\nsignificantly improves the performance. Another part of our contribution is to\nstabilize training with normalizing flows on high-dimensional 3D pose data by\nfirst projecting the 2D poses to a linear subspace. We outperform the\nstate-of-the-art unsupervised human pose estimation methods on the benchmark\ndatasets Human3.6M and MPI-INF-3DHP in many metrics.",
    "descriptor": "",
    "authors": [
      "Bastian Wandt",
      "James J. Little",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07088"
  },
  {
    "id": "arXiv:2112.07089",
    "title": "Building on Huang et al. GlossBERT for Word Sense Disambiguation",
    "abstract": "We propose to take on the problem ofWord Sense Disambiguation (WSD). In\nlanguage, words of the same form can take different meanings depending on\ncontext. While humans easily infer the meaning or gloss of such words by their\ncontext, machines stumble on this task.As such, we intend to replicated and\nexpand upon the results of Huang et al.GlossBERT, a model which they design to\ndisambiguate these words (Huang et al.,2019). Specifically, we propose the\nfollowing augmentations: data-set tweaking(alpha hyper-parameter), ensemble\nmethods, and replacement of BERT with BART andALBERT. The following GitHub\nrepository contains all code used in this report, which extends on the code\nmade available by Huang et al.",
    "descriptor": "",
    "authors": [
      "Nikhil Patel",
      "James Hale",
      "Kanika Jindal",
      "Apoorva Sharma",
      "Yichun Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07089"
  },
  {
    "id": "arXiv:2112.07096",
    "title": "Adaptive Projected Residual Networks for Learning Parametric Maps from  Sparse Data",
    "abstract": "We present a parsimonious surrogate framework for learning high dimensional\nparametric maps from limited training data. The need for parametric surrogates\narises in many applications that require repeated queries of complex\ncomputational models. These applications include such \"outer-loop\" problems as\nBayesian inverse problems, optimal experimental design, and optimal design and\ncontrol under uncertainty, as well as real time inference and control problems.\nMany high dimensional parametric mappings admit low dimensional structure,\nwhich can be exploited by mapping-informed reduced bases of the inputs and\noutputs. Exploiting this property, we develop a framework for learning low\ndimensional approximations of such maps by adaptively constructing ResNet\napproximations between reduced bases of their inputs and output. Motivated by\nrecent approximation theory for ResNets as discretizations of control flows, we\nprove a universal approximation property of our proposed adaptive projected\nResNet framework, which motivates a related iterative algorithm for the ResNet\nconstruction. This strategy represents a confluence of the approximation theory\nand the algorithm since both make use of sequentially minimizing flows. In\nnumerical examples we show that these parsimonious, mapping-informed\narchitectures are able to achieve remarkably high accuracy given few training\ndata, making them a desirable surrogate strategy to be implemented for minimal\ncomputational investment in training data generation.",
    "descriptor": "",
    "authors": [
      "Thomas O'Leary-Roseberry",
      "Xiaosong Du",
      "Anirban Chaudhuri",
      "Joaquim R. R. A. Martins",
      "Karen Willcox",
      "Omar Ghattas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07096"
  },
  {
    "id": "arXiv:2112.07097",
    "title": "Grant Free MIMO-NOMA with Differential Modulation for Machine Type  Communications",
    "abstract": "This paper considers a challenging scenario of machine type communications,\nwhere we assume internet of things (IoT) devices send short packets\nsporadically to an access point (AP) and the devices are not synchronized in\nthe packet level. High transmission efficiency and low latency are concerned.\nMotivated by the great potential of multiple-input multiple-output\nnon-orthogonal multiple access (MIMO-NOMA) in massive access, we design a\ngrant-free MIMO-NOMA scheme, and in particular differential modulation is used\nso that expensive channel estimation at the receiver (AP) can be bypassed. The\nreceiver at AP needs to carry out active device detection and multi-device data\ndetection. The active user detection is formulated as the estimation of the\ncommon support of sparse signals, and a message passing based sparse Bayesian\nlearning (SBL) algorithm is designed to solve the problem. Due to the use of\ndifferential modulation, we investigate the problem of non-coherent\nmulti-device data detection, and develop a message passing based Bayesian data\ndetector, where the constraint of differential modulation is exploited to\ndrastically improve the detection performance, compared to the conventional\nnon-coherent detection scheme. Simulation results demonstrate the effectiveness\nof the proposed active device detector and non-coherent multi-device data\ndetector.",
    "descriptor": "",
    "authors": [
      "Yuanyuan Zhang",
      "Zhengdao Yuan",
      "Qinghua Guo",
      "Zhongyong Wang",
      "Jiangtao Xi",
      "Yanguang Yu",
      "Yonghui Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.07097"
  },
  {
    "id": "arXiv:2112.07103",
    "title": "Hierarchical Stochastic Scheduling of Multi-Community Integrated Energy  Systems in Uncertain Environments via Stackelberg Game",
    "abstract": "An operating entity utilizing community-integrated energy systems with a\nlarge number of small-scale distributed energy sources can easily trade with\nexisting distribution markets. To solve the energy management and pricing\nproblem of multi-community integrated energy systems (MCIESs) with multi-energy\ninteraction, this study investigated a hierarchical stochastic optimal\nscheduling method for uncertain environments. To handle multiple uncertainties,\na Wasserstein generative adversarial network with a gradient penalty was used\nto generate renewable scenarios, and the Kmeans++ clustering algorithm was\nemployed to generate typical scenarios. A Stackelberg-based hierarchical\nstochastic schedule with an integrated demand response was constructed, where\nthe MCIES operator acted as the leader pursuing the maximum net profit by\nsetting energy prices, while the building users were followers who adjusted\ntheir energy consumption plans to minimize their total costs. Finally, a\ndistributed iterative solution method based on a metaheuristic was designed.\nThe effectiveness of the proposed method was verified using practical examples.",
    "descriptor": "\nComments: Accepted by Applied Energy\n",
    "authors": [
      "Yang Li",
      "Bin Wang",
      "Zhen Yang",
      "Jiazheng Li",
      "Chen Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.07103"
  },
  {
    "id": "arXiv:2112.07106",
    "title": "ES-CRF: Embedded Superpixel CRF for Semantic Segmentation",
    "abstract": "Modern semantic segmentation methods devote much attention to adjusting\nfeature representations to improve the segmentation performance in various\nways, such as metric learning, architecture design, etc. However, almost all\nthose methods neglect the particularity of boundary pixels. These pixels are\nprone to obtain confusing features from both sides due to the continuous\nexpansion of receptive fields in CNN networks. In this way, they will mislead\nthe model optimization direction and make the class weights of such categories\nthat tend to share many adjacent pixels lack discrimination, which will damage\nthe overall performance. In this work, we dive deep into this problem and\npropose a novel method named Embedded Superpixel CRF (ES-CRF) to address it.\nES-CRF involves two main aspects. On the one hand, ES-CRF innovatively fuses\nthe CRF mechanism into the CNN network as an organic whole for more effective\nend-to-end optimization. It utilizes CRF to guide the message passing between\npixels in high-level features to purify the feature representation of boundary\npixels, with the help of inner pixels belong to the same object. On the other\nhand, superpixel is integrated into ES-CRF to exploit the local object prior\nfor more reliable message passing. Finally, our proposed method yields new\nrecords on two challenging benchmarks, i.e., Cityscapes and ADE20K. Moreover,\nwe make detailed theoretical analysis to verify the superiority of ES-CRF.",
    "descriptor": "\nComments: 10 page 4 figures\n",
    "authors": [
      "Jie Zhu",
      "Huabin Huang",
      "Banghuai Li",
      "Leye Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07106"
  },
  {
    "id": "arXiv:2112.07108",
    "title": "Optimal Memory Scheme for Accelerated Consensus Over Multi-Agent  Networks",
    "abstract": "The consensus over multi-agent networks can be accelerated by introducing\nagent's memory to the control protocol. In this paper, a more general protocol\nwith the node memory and the state deviation memory is designed. We aim to\nprovide the optimal memory scheme to accelerate consensus. The contributions of\nthis paper are three: (i) For the one-tap memory scheme, we demonstrate that\nthe state deviation memory is useless for the optimal convergence. (ii) In the\nworst case, we prove that it is a vain to add any tap of the state deviation\nmemory, and the one-tap node memory is sufficient to achieve the optimal\nconvergence. (iii) We show that the two-tap state deviation memory is effective\non some special networks, such as star networks. Numerical examples are listed\nto illustrate the validity and correctness of the obtained results.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Jiahao Dai",
      "Jing-Wen Yi",
      "Li Chai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.07108"
  },
  {
    "id": "arXiv:2112.07111",
    "title": "EMDS-6: Environmental Microorganism Image Dataset Sixth Version for  Image Denoising, Segmentation, Feature Extraction, Classification and  Detection Methods Evaluation",
    "abstract": "Environmental microorganisms (EMs) are ubiquitous around us and have an\nimportant impact on the survival and development of human society. However, the\nhigh standards and strict requirements for the preparation of environmental\nmicroorganism (EM) data have led to the insufficient of existing related\ndatabases, not to mention the databases with GT images. This problem seriously\naffects the progress of related experiments. Therefore, This study develops the\nEnvironmental Microorganism Dataset Sixth Version (EMDS-6), which contains 21\ntypes of EMs. Each type of EM contains 40 original and 40 GT images, in total\n1680 EM images. In this study, in order to test the effectiveness of EMDS-6. We\nchoose the classic algorithms of image processing methods such as image\ndenoising, image segmentation and target detection. The experimental result\nshows that EMDS-6 can be used to evaluate the performance of image denoising,\nimage segmentation, image feature extraction, image classification, and object\ndetection methods.",
    "descriptor": "",
    "authors": [
      "Peng Zhao",
      "Chen Li",
      "Md Mamunur Rahaman",
      "Hao Xu",
      "Pingli Ma",
      "Hechen Yang",
      "Hongzan Sun",
      "Tao Jiang",
      "Ning Xu",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07111"
  },
  {
    "id": "arXiv:2112.07115",
    "title": "Dynamic Coherence-Based EM Ray Tracing Simulations in Vehicular  Environments",
    "abstract": "5G applications have become increasingly popular in recent years as the\nspread of 5G network deployment has grown. For vehicular networks, mmWave band\nsignals have been well studied and used for communication and sensing. In this\nwork, we propose a new dynamic ray tracing algorithm that exploits spatial and\ntemporal coherence. We evaluate the performance by comparing the results on\ntypical vehicular communication scenarios with NYUSIM, which builds on\nstochastic models, and Winprop, which utilizes the deterministic model for\nsimulations with given environment information. We compare the performance of\nour algorithm on complex, urban models and observe the reduction in computation\ntime by 60% compared to NYUSIM and 30% compared to Winprop, while maintaining\nsimilar prediction accuracy.",
    "descriptor": "\nComments: 6 pages, 14 figures, conference\n",
    "authors": [
      "Ruichen Wang",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.07115"
  },
  {
    "id": "arXiv:2112.07116",
    "title": "Joint 3D Object Detection and Tracking Using Spatio-Temporal  Representation of Camera Image and LiDAR Point Clouds",
    "abstract": "In this paper, we propose a new joint object detection and tracking (JoDT)\nframework for 3D object detection and tracking based on camera and LiDAR\nsensors. The proposed method, referred to as 3D DetecTrack, enables the\ndetector and tracker to cooperate to generate a spatio-temporal representation\nof the camera and LiDAR data, with which 3D object detection and tracking are\nthen performed. The detector constructs the spatio-temporal features via the\nweighted temporal aggregation of the spatial features obtained by the camera\nand LiDAR fusion. Then, the detector reconfigures the initial detection results\nusing information from the tracklets maintained up to the previous time step.\nBased on the spatio-temporal features generated by the detector, the tracker\nassociates the detected objects with previously tracked objects using a graph\nneural network (GNN). We devise a fully-connected GNN facilitated by a\ncombination of rule-based edge pruning and attention-based edge gating, which\nexploits both spatial and temporal object contexts to improve tracking\nperformance. The experiments conducted on both KITTI and nuScenes benchmarks\ndemonstrate that the proposed 3D DetecTrack achieves significant improvements\nin both detection and tracking performances over baseline methods and achieves\nstate-of-the-art performance among existing methods through collaboration\nbetween the detector and tracker.",
    "descriptor": "",
    "authors": [
      "Junho Koh",
      "Jaekyum Kim",
      "Jinhyuk Yoo",
      "Yecheol Kim",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07116"
  },
  {
    "id": "arXiv:2112.07120",
    "title": "Simple Coding Techniques for Many-Hop Relaying",
    "abstract": "In this paper, we study the problem of relaying a single bit of information\nacross a series of binary symmetric channels, and the associated trade-off\nbetween the number of hops $m$, the transmission time $n$, and the error\nprobability. We introduce a simple and efficient protocol that attains positive\ninformation velocity (i.e., a non-vanishing ratio $\\frac{m}{n}$ and small error\nprobability) and is significantly simpler than existing protocols that do so.\nIn addition, we characterize the optimal low-noise and high-noise scaling laws\nof the information velocity, and we adapt our 1-bit protocol to transmit $k$\nbits over $m$ hops with $O(m+k)$ transmission time.",
    "descriptor": "",
    "authors": [
      "Yan Hao Ling",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.07120"
  },
  {
    "id": "arXiv:2112.07123",
    "title": "Recognition of Tactile-related EEG Signals Generated by Self-touch",
    "abstract": "Touch is the first sense among human senses. Not only that, but it is also\none of the most important senses that are indispensable. However, compared to\nsight and hearing, it is often neglected. In particular, since humans use the\ntactile sense of the skin to recognize and manipulate objects, without tactile\nsensation, it is very difficult to recognize or skillfully manipulate objects.\nIn addition, the importance and interest of haptic technology related to touch\nare increasing with the development of technologies such as VR and AR in recent\nyears. So far, the focus is only on haptic technology based on mechanical\ndevices. Especially, there are not many studies on tactile sensation in the\nfield of brain-computer interface based on EEG. There have been some studies\nthat measured the surface roughness of artificial structures in relation to\nEEG-based tactile sensation. However, most studies have used passive contact\nmethods in which the object moves, while the human subject remains still.\nAdditionally, there have been no EEG-based tactile studies of active skin\ntouch. In reality, we directly move our hands to feel the sense of touch.\nTherefore, as a preliminary study for our future research, we collected EEG\nsignals for tactile sensation upon skin touch based on active touch and\ncompared and analyzed differences in brain changes during touch and movement\ntasks. Through time-frequency analysis and statistical analysis, significant\ndifferences in power changes in alpha, beta, gamma, and high-gamma regions were\nobserved. In addition, major spatial differences were observed in the\nsensory-motor region of the brain.",
    "descriptor": "\nComments: Submitted to 2022 10th IEEE International Winter Conference on Brain-Computer Interface\n",
    "authors": [
      "Myoung-Ki Kim",
      "Jeong-Hyun Cho",
      "Hye-Bin Shin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2112.07123"
  },
  {
    "id": "arXiv:2112.07128",
    "title": "Collaborating with communities: Citizen Science Flood Monitoring in  Urban Informal Settlements",
    "abstract": "Concerns regarding the impacts of climate change on marginalised communities\nin the Global South have led to calls for affected communities to be more\nactive as agents in the process of planning for climate change. While the value\nof involving communities in risk management is increasingly accepted, the\ndevelopment of appropriate tools to support community engagement in flood risk\nmanagement projects remains nascent. Using the Revitalising Informal\nSettlements and their Environment (RISE) Program as a case study, the article\ninterrogates the potential of citizen science to include disadvantaged urban\ncommunities in project-level flood risk reduction planning processes. This\nproject collected more than 5000 photos taken by 26 community members living in\n13 informal settlements in Fiji and Indonesia between 2018 and 2020. The case\nstudy documents the method used as well as the results achieved within this\n2-year project. It discusses the method developed and implemented, outlines the\nmain results, and provides lessons learned for others embarking on citizen\nscience environmental monitoring projects. The case study indicates that the\nengagement model and the technology used were key to the success of the\nflood-monitoring project. The experiences with the practice of monitoring\nfloods in collaboration with communities in Fiji and Indonesia provide insights\ninto how similar projects could advance more participatory risk management\npractices. The article identifies how this kind of approach can collect\nvaluable flood data while also promoting opportunities for local communities to\nbe heard in the arena of risk reduction and climate change adaptation.",
    "descriptor": "",
    "authors": [
      "Erich Wolff",
      "Matthew French",
      "Noor Ilhamsyah",
      "Mere Jane Sawailau",
      "Diego Ramirez-Lovering"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.07128"
  },
  {
    "id": "arXiv:2112.07129",
    "title": "Output fusion of MPC and PID and its application in intelligent layered  water injection of oilfield",
    "abstract": "To improve the dynamic response performance of wave code communication in\nintelligent layered water injection of oilfield, this paper proposes an output\noptimal fusion control method based on MPC-PID. Firstly, depending on the well\nstructure and the flow-pressure characteristics of the layer, the steady-state\nmodel between the differential pressure and flow of the whole well and\ndifferent layer sections is established for layered water injection, and the\ncorresponding wave code amplitude at the steady-state operating point of\ndifferent layer sections is solved, the numerical calculation verifies that the\nincrease of the nozzle opening in a single layer section will drive the\npressure and flow curve of the whole well downward. Secondly, combining the\ndynamic response characteristics and steady-state model of the whole-well water\ndistribution equipment, a dynamic model of layered intelligent water injection\nis established, and the generation process of the wave code is defined;\nFinally, the MPC-PID optimal fusion control algorithm structure is designed to\nderive the fusion control law that minimizes the cost function under fixed\nweights, , and the optimal weights are calculated by combining the internal\nmodel structure of controller, so the optimization performance of each\nalgorithm in the optimal fusion control is balanced. By analyzing the control\nsimulation results, the fast response characteristics of the fusion control\nmethod are verified. Meanwhile, the simulation comparison experiments of fast\nwave code communication under different methods are conducted with the actual\nworking conditions, the results show that the fusion control method has both\nfast tracking control capability and strong robustness, which effectively\nenhances the efficiency of wave code communication and shortens the wave code\noperation time.",
    "descriptor": "",
    "authors": [
      "Yuan-Long Yue",
      "Hao-Yang Wen",
      "Xin Zuo",
      "Mao Sheng",
      "Fu-Chao Sun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07129"
  },
  {
    "id": "arXiv:2112.07130",
    "title": "A code-based hybrid signcryption scheme",
    "abstract": "A key encapsulation mechanism (KEM) that takes as input an arbitrary string,\ni.e., a tag, is known as tag-KEM, while a scheme that combines signature and\nencryption is called signcryption. In this paper, we present a code-based\nsigncryption tag-KEM scheme. We utilize a code-based signature and a CCA2\n(adaptive chosen ciphertext attack) secure version of McEliece's {encryption}\nscheme. The proposed scheme uses an equivalent subcode as a public code for the\nreceiver, making the NP-completeness of the equivalent subcode problem be one\nof our main security assumptions. We then base the signcryption tag-KEM to\ndesign a code-based hybrid signcryption scheme. A hybrid scheme deploys an\nasymmetric- as well as a symmetric-key encryption. We give security analyses of\nboth our schemes in the standard model and prove that they are secure against\nIND-CCA2 (indistinguishability under adaptive chosen ciphertext attack) and\nSUF-CMA (strong existential unforgeability under chosen message attack).",
    "descriptor": "",
    "authors": [
      "Jean Belo Klamti",
      "M. Anwar Hasan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2112.07130"
  },
  {
    "id": "arXiv:2112.07131",
    "title": "VPVnet: a velocity-pressure-vorticity neural network method for the  Stokes' equations under reduced regularity",
    "abstract": "We present VPVnet, a deep neural network method for the Stokes' equations\nunder reduced regularity. Different with recently proposed deep learning\nmethods [40,51] which are based on the original form of PDEs, VPVnet uses the\nleast square functional of the first-order velocity-pressure-vorticity (VPV)\nformulation ([30]) as loss functions. As such, only first-order derivative is\nrequired in the loss functions, hence the method is applicable to a much larger\nclass of problems, e.g. problems with non-smooth solutions. Despite that\nseveral methods have been proposed recently to reduce the regularity\nrequirement by transforming the original problem into a corresponding\nvariational form, while for the Stokes' equations, the choice of approximating\nspaces for the velocity and the pressure has to satisfy the LBB condition\nadditionally. Here by making use of the VPV formulation, lower regularity\nrequirement is achieved with no need for considering the LBB condition.\nConvergence and error estimates have been established for the proposed method.\nIt is worth emphasizing that the VPVnet method is divergence-free and\npressure-robust, while classical inf-sup stable mixed finite elements for the\nStokes' equations are not pressure-robust. Various numerical experiments\nincluding 2D and 3D lid-driven cavity test cases are conducted to demonstrate\nits efficiency and accuracy.",
    "descriptor": "",
    "authors": [
      "Yujie Liu",
      "Chao Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07131"
  },
  {
    "id": "arXiv:2112.07133",
    "title": "CLIP-Lite: Information Efficient Visual Representation Learning from  Textual Annotations",
    "abstract": "We propose CLIP-Lite, an information efficient method for visual\nrepresentation learning by feature alignment with textual annotations. Compared\nto the previously proposed CLIP model, CLIP-Lite requires only one negative\nimage-text sample pair for every positive image-text sample during the\noptimization of its contrastive learning objective. We accomplish this by\ntaking advantage of an information efficient lower-bound to maximize the mutual\ninformation between the two input modalities. This allows CLIP-Lite to be\ntrained with significantly reduced amounts of data and batch sizes while\nobtaining better performance than CLIP. We evaluate CLIP-Lite by pretraining on\nthe COCO-Captions dataset and testing transfer learning to other datasets.\nCLIP-Lite obtains a +15.4% mAP absolute gain in performance on Pascal VOC\nclassification, and a +22.1% top-1 accuracy gain on ImageNet, while being\ncomparable or superior to other, more complex, text-supervised models.\nCLIP-Lite is also superior to CLIP on image and text retrieval, zero-shot\nclassification, and visual grounding. Finally, by performing explicit\nimage-text alignment during representation learning, we show that CLIP-Lite can\nleverage language semantics to encourage bias-free visual representations that\ncan be used in downstream tasks.",
    "descriptor": "",
    "authors": [
      "Aman Shrivastava",
      "Ramprasaath R. Selvaraju",
      "Nikhil Naik",
      "Vicente Ordonez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07133"
  },
  {
    "id": "arXiv:2112.07134",
    "title": "Explore Long-Range Context feature for Speaker Verification",
    "abstract": "Capturing long-range dependency and modeling long temporal contexts is proven\nto benefit speaker verification tasks. In this paper, we propose the\ncombination of the Hierarchical-Split block(HS-block) and the Depthwise\nSeparable Self-Attention(DSSA) module to capture richer multi-range context\nspeaker features from a local and global perspective respectively.\nSpecifically, the HS-block splits the feature map and filters into several\ngroups and stacks them in one block, which enlarges the receptive fields(RFs)\nlocally. The DSSA module improves the multi-head self-attention mechanism by\nthe depthwise-separable strategy and explicit sparse attention strategy to\nmodel the pairwise relations globally and captures effective long-range\ndependencies in each channel. Experiments are conducted on the Voxceleb and\nSITW. Our best system achieves 1.27% EER on the Voxceleb1 test set and 1.56% on\nSITW by applying the combination of HS-block and DSSA module.",
    "descriptor": "\nComments: rejected by interspeech2021\n",
    "authors": [
      "Zhuo Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.07134"
  },
  {
    "id": "arXiv:2112.07137",
    "title": "New Binary Quantum Codes Constructed from Quasi-Cyclic Codes",
    "abstract": "It is well known that quantum codes can be constructed by means of classical\nsymplectic dual-containing codes. This paper considers a family of\ntwo-generators quasi-cyclic codes and derives sufficient conditions for these\ncodes to be dual-containing. Then, a new method for constructing binary quantum\ncodes is proposed. As an application, we construct 11 binary quantum codes that\nexceed the beak-known results. Further, another 40 new binary quantum codes are\nobtained by propagation rules, all of which improve the lower bound on the\nminimum distance.",
    "descriptor": "",
    "authors": [
      "Chaofeng Guan",
      "Ruihu Li",
      "Liangdong Lu",
      "Yu Yao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.07137"
  },
  {
    "id": "arXiv:2112.07140",
    "title": "Secretary Matching With Vertex Arrivals and No Rejections",
    "abstract": "Most prior work on online matching problems has been with the flexibility of\nkeeping some vertices unmatched. We study three related online matching\nproblems with the constraint of matching every vertex, i.e., with no\nrejections. We adopt a model in which vertices arrive in uniformly random order\nand the non-negative edge-weights are arbitrary. For the capacitated online\nbipartite matching problem, in which the vertices of one side of the graph are\noffline and those of the other side arrive online, we give a 4.62-competitive\nalgorithm when the capacity of each offline vertex is 2. For the online general\n(non-bipartite) matching problem, where all vertices arrive online, we give a\n3.34-competitive algorithm. We also study the online roommate matching problem\n(Huzhang et al. 2017), in which each room (offline vertex) holds 2 persons\n(online vertices). Persons derive non-negative additive utilities from their\nroom as well as roommate. In this model, with the goal of maximizing the social\nwelfare, we give a 7.96-competitive algorithm. This is an improvement over the\n24.72 approximation factor in (Huzhang et al. 2017).",
    "descriptor": "",
    "authors": [
      "Mohak Goyal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.07140"
  },
  {
    "id": "arXiv:2112.07143",
    "title": "Better Pay Attention Whilst Fuzzing",
    "abstract": "Fuzzing is one of the prevailing methods for vulnerability detection.\nHowever, even state-of-the-art fuzzing methods become ineffective after some\nperiod of time, i.e., the coverage hardly improves as existing methods are\nineffective to focus the attention of fuzzing on covering the hard-to-trigger\nprogram paths. In other words, they cannot generate inputs that can break the\nbottleneck due to the fundamental difficulty in capturing the complex relations\nbetween the test inputs and program coverage. In particular, existing fuzzers\nsuffer from the following main limitations: 1) lacking an overall analysis of\nthe program to identify the most \"rewarding\" seeds, and 2) lacking an effective\nmutation strategy which could continuously select and mutates the more relevant\n\"bytes\" of the seeds.\nIn this work, we propose an approach called ATTuzz to address these two\nissues systematically. First, we propose a lightweight dynamic analysis\ntechnique which estimates the \"reward\" of covering each basic block and selects\nthe most rewarding seeds accordingly. Second, we mutate the selected seeds\naccording to a neural network model which predicts whether a certain\n\"rewarding\" block will be covered given certain mutation on certain bytes of a\nseed. The model is a deep learning model equipped with attention mechanism\nwhich is learned and updated periodically whilst fuzzing. Our evaluation shows\nthat ATTuzz significantly outperforms 5 state-of-the-art grey-box fuzzers on 13\npopular real-world programs at achieving higher edge coverage and finding new\nbugs. In particular, ATTuzz achieved 2X edge coverage and 4X bugs detected than\nAFL over 24-hour runs. Moreover, ATTuzz persistently improves the edge coverage\nin the long run, i.e., achieving 50% more coverage than AFL in 5 days.",
    "descriptor": "",
    "authors": [
      "Shunkai Zhu",
      "Jingyi Wang",
      "Jun Sun",
      "Jie Yang",
      "Xingwei Lin",
      "Liyi Zhang",
      "Peng Cheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.07143"
  },
  {
    "id": "arXiv:2112.07144",
    "title": "GEO-BLEU: Similarity Measure for Geospatial Sequences",
    "abstract": "In recent geospatial research, the importance of modeling large-scale human\nmobility data via self-supervised learning is rising, in parallel with progress\nin natural language processing driven by self-supervised approaches using\nlarge-scale corpora. Whereas there are already plenty of feasible approaches\napplicable to geospatial sequence modeling itself, there seems to be room to\nimprove with regard to evaluation, specifically about how to measure the\nsimilarity between generated and reference sequences. In this work, we propose\na novel similarity measure, GEO-BLEU, which can be especially useful in the\ncontext of geospatial sequence modeling and generation. As the name suggests,\nthis work is based on BLEU, one of the most popular measures used in machine\ntranslation research, while introducing spatial proximity to the idea of\nn-gram. We compare this measure with an established baseline, dynamic time\nwarping, applying it to actual generated geospatial sequences. Using\ncrowdsourced annotated data on the similarity between geospatial sequences\ncollected from over 12,000 cases, we quantitatively and qualitatively show the\nproposed method's superiority.",
    "descriptor": "",
    "authors": [
      "Toru Shimizu",
      "Kota Tsubouchi",
      "Takahiro Yabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07144"
  },
  {
    "id": "arXiv:2112.07146",
    "title": "PP-HumanSeg: Connectivity-Aware Portrait Segmentation with a Large-Scale  Teleconferencing Video Dataset",
    "abstract": "As the COVID-19 pandemic rampages across the world, the demands of video\nconferencing surge. To this end, real-time portrait segmentation becomes a\npopular feature to replace backgrounds of conferencing participants. While\nfeature-rich datasets, models and algorithms have been offered for segmentation\nthat extract body postures from life scenes, portrait segmentation has yet not\nbeen well covered in a video conferencing context. To facilitate the progress\nin this field, we introduce an open-source solution named PP-HumanSeg. This\nwork is the first to construct a large-scale video portrait dataset that\ncontains 291 videos from 23 conference scenes with 14K fine-labeled frames and\nextensions to multi-camera teleconferencing. Furthermore, we propose a novel\nSemantic Connectivity-aware Learning (SCL) for semantic segmentation, which\nintroduces a semantic connectivity-aware loss to improve the quality of\nsegmentation results from the perspective of connectivity. And we propose an\nultra-lightweight model with SCL for practical portrait segmentation, which\nachieves the best trade-off between IoU and the speed of inference. Extensive\nevaluations on our dataset demonstrate the superiority of SCL and our model.\nThe source code is available at https://github.com/PaddlePaddle/PaddleSeg.",
    "descriptor": "\nComments: Accepted by WACV workshop\n",
    "authors": [
      "Lutao Chu",
      "Yi Liu",
      "Zewu Wu",
      "Shiyu Tang",
      "Guowei Chen",
      "Yuying Hao",
      "Juncai Peng",
      "Zhiliang Yu",
      "Zeyu Chen",
      "Baohua Lai",
      "Haoyi Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07146"
  },
  {
    "id": "arXiv:2112.07148",
    "title": "Decoding 3D Representation of Visual Imagery EEG using Attention-based  Dual-Stream Convolutional Neural Network",
    "abstract": "A deep neural network has been successfully applied to an\nelectroencephalogram (EEG)-based brain-computer interface. However, in most\nstudies, the correlation between EEG channels and inter-region relationships\nare not well utilized, resulting in sub-optimized spatial feature extraction.\nIn this study, we propose an attention-based dual-stream 3D-convolutional\nneural network that can enhance spatial feature extraction by emphasizing the\nrelationship between channels with dot product-based channel attention and 3D\nconvolution. The proposed method showed superior performance than the\ncomparative models by achieving an accuracy of 0.58 for 4-class visual imagery\n(VI) EEG classification. Through statistical and neurophysiological analysis,\nvisual motion imagery showed higher alpha-power spectral density (PSD) over the\nvisual cortex than static VI. Also, the VI of swarm dispersion showed higher\nbeta-PSD over the pre-frontal cortex than the VI of swarm aggregation.",
    "descriptor": "\nComments: Submitted to 2022 10th IEEE International Winter Conference on Brain-Computer Interface\n",
    "authors": [
      "Hyung-Ju Ahn",
      "Dae-Hyeok Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.07148"
  },
  {
    "id": "arXiv:2112.07152",
    "title": "On the structure of the solutions to the matrix equation $G^*JG=J$",
    "abstract": "We study the mathematical structure of the solution set (and its tangent\nspace) to the matrix equation $G^*JG=J$ for a given square matrix $J$. In the\nlanguage of pure mathematics, this is a Lie group which is the isometry group\nfor a bilinear (or a sesquilinear) form. Generally these groups are described\nas intersections of a few special groups. The tangent space to $\\{G: G^*JG=J\n\\}$ consists of solutions to the linear matrix equation $X^*J+JX=0$. For the\ncomplex case, the solution set of this linear equation was computed by De\nTer{\\'a}n and Dopico. We found that on its own, the equation $X^*J+JX=0$ is\nhard to solve. By throwing into the mix the complementary linear equation\n$X^*J-JX=0$, we find that rather than increasing the complexity, we reduce the\ncomplexity. Not only is it possible to now solve the original problem, but we\ncan approach the broader algebraic and geometric structure. One implication is\nthat the two equations form an $\\mathfrak{h}$ and $\\mathfrak{m}$ pair familiar\nin the study of pseudo-Riemannian symmetric spaces. We explicitly demonstrate\nthe computation of the solutions to the equation $X^*J\\pm XJ=0$ for real and\ncomplex matrices. However, any real, complex or quaternionic case with an\narbitrary involution (e.g., transpose, conjugate transpose, and the various\nquaternion transposes) can be effectively solved with the same strategy. We\nprovide numerical examples and visualizations.",
    "descriptor": "\nComments: 26 pages, 4 figures\n",
    "authors": [
      "Alan Edelman",
      "Sungwoo Jeong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07152"
  },
  {
    "id": "arXiv:2112.07154",
    "title": "Sixth Order Compact Finite Difference Method for 2D Helmholtz Equations  with Singular Sources and Reduced Pollution Effect",
    "abstract": "Due to its highly oscillating solution, the Helmholtz equation is numerically\nchallenging to solve. To obtain a reasonable solution, a mesh size that is much\nsmaller than the reciprocal of the wavenumber is typically required (known as\nthe pollution effect). High order schemes are desirable, because they are\nbetter in mitigating the pollution effect. In this paper, we present a sixth\norder compact finite difference method for 2D Helmholtz equations with singular\nsources, which can also handle any possible combinations of boundary conditions\n(Dirichlet, Neumann, and impedance) on a rectangular domain. To reduce the\npollution effect, we propose a new pollution minimization strategy that is\nbased on the average truncation error of plane waves. Our numerical experiments\ndemonstrate the superiority of our proposed finite difference scheme with\nreduced pollution effect to several state-of-the-art finite difference schemes\nin the literature, particularly in the critical pre-asymptotic region where\n$\\textsf{k} h$ is near $1$ with $\\textsf{k}$ being the wavenumber and $h$ the\nmesh size.",
    "descriptor": "\nComments: 20 pages, 3 figures, 6 tables\n",
    "authors": [
      "Qiwei Feng",
      "Bin Han",
      "Michelle Michelle"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07154"
  },
  {
    "id": "arXiv:2112.07157",
    "title": "Federated Nearest Neighbor Classification with a Colony of Fruit-Flies:  With Supplement",
    "abstract": "The mathematical formalization of a neurological mechanism in the olfactory\ncircuit of a fruit-fly as a locality sensitive hash (Flyhash) and bloom filter\n(FBF) has been recently proposed and \"reprogrammed\" for various machine\nlearning tasks such as similarity search, outlier detection and text\nembeddings. We propose a novel reprogramming of this hash and bloom filter to\nemulate the canonical nearest neighbor classifier (NNC) in the challenging\nFederated Learning (FL) setup where training and test data are spread across\nparties and no data can leave their respective parties. Specifically, we\nutilize Flyhash and FBF to create the FlyNN classifier, and theoretically\nestablish conditions where FlyNN matches NNC. We show how FlyNN is trained\nexactly in a FL setup with low communication overhead to produce FlyNNFL, and\nhow it can be differentially private. Empirically, we demonstrate that (i)\nFlyNN matches NNC accuracy across 70 OpenML datasets, (ii) FlyNNFL training is\nhighly scalable with low communication overhead, providing up to $8\\times$\nspeedup with $16$ parties.",
    "descriptor": "\nComments: A extended version of the original paper with detailed supplementary materials (21 pages, 17 figures)\n",
    "authors": [
      "Parikshit Ram",
      "Kaushik Sinha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07157"
  },
  {
    "id": "arXiv:2112.07158",
    "title": "Hop-Spanners for Geometric Intersection Graphs",
    "abstract": "A $t$-spanner of a graph $G=(V,E)$ is a subgraph $H=(V,E')$ that contains a\n$uv$-path of length at most $t$ for every $uv\\in E$. It is known that every\n$n$-vertex graph admits a $(2k-1)$-spanner with $O(n^{1+1/k})$ edges for $k\\geq\n1$. This bound is the best possible for $1\\leq k\\leq 9$ and is conjectured to\nbe optimal due to Erd\\H{o}s' girth conjecture.\nWe study $t$-spanners for $t\\in \\{2,3\\}$ for geometric intersection graphs in\nthe plane. These spanners are also known as \\emph{$t$-hop spanners} to\nemphasize the use of graph-theoretic distances (as opposed to Euclidean\ndistances between the geometric objects or their centers). We obtain the\nfollowing results: (1) Every $n$-vertex unit disk graph (UDG) admits a 2-hop\nspanner with $O(n)$ edges; improving upon the previous bound of $O(n\\log n)$.\n(2) The intersection graph of $n$ axis-aligned fat rectangles admits a 2-hop\nspanner with $O(n\\log n)$ edges, and this bound is the best possible. (3) The\nintersection graph of $n$ fat convex bodies in the plane admits a 3-hop spanner\nwith $O(n\\log n)$ edges. (4) The intersection graph of $n$ axis-aligned\nrectangles admits a 3-hop spanner with $O(n\\log^2 n)$ edges.",
    "descriptor": "\nComments: 29 pages, 18 figures\n",
    "authors": [
      "Jonathan B. Conroy",
      "Csaba D. T\u00f3th"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.07158"
  },
  {
    "id": "arXiv:2112.07159",
    "title": "Birds Eye View Social Distancing Analysis System",
    "abstract": "Social distancing can reduce the infection rates in respiratory pandemics\nsuch as COVID-19. Traffic intersections are particularly suitable for\nmonitoring and evaluation of social distancing behavior in metropolises. We\npropose and evaluate a privacy-preserving social distancing analysis system\n(B-SDA), which uses bird's-eye view video recordings of pedestrians who cross\ntraffic intersections. We devise algorithms for video pre-processing, object\ndetection and tracking which are rooted in the known computer-vision and deep\nlearning techniques, but modified to address the problem of detecting very\nsmall objects/pedestrians captured by a highly elevated camera. We propose a\nmethod for incorporating pedestrian grouping for detection of social distancing\nviolations. B-SDA is used to compare pedestrian behavior based on pre-pandemic\nand pandemic videos in a major metropolitan area. The accomplished pedestrian\ndetection performance is $63.0\\%$ $AP_{50}$ and the tracking performance is\n$47.6\\%$ MOTA. The social distancing violation rate of $15.6\\%$ during the\npandemic is notably lower than $31.4\\%$ pre-pandemic baseline, indicating that\npedestrians followed CDC-prescribed social distancing recommendations. The\nproposed system is suitable for deployment in real-world applications.",
    "descriptor": "",
    "authors": [
      "Zhengye Yang",
      "Mingfei Sun",
      "Hongzhe Ye",
      "Zihao Xiong",
      "Gil Zussman",
      "Zoran Kostic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.07159"
  },
  {
    "id": "arXiv:2112.07160",
    "title": "Improving Spectral Graph Convolution for Learning Graph-level  Representation",
    "abstract": "From the original theoretically well-defined spectral graph convolution to\nthe subsequent spatial bassed message-passing model, spatial locality (in\nvertex domain) acts as a fundamental principle of most graph neural networks\n(GNNs). In the spectral graph convolution, the filter is approximated by\npolynomials, where a $k$-order polynomial covers $k$-hop neighbors. In the\nmessage-passing, various definitions of neighbors used in aggregations are\nactually an extensive exploration of the spatial locality information. For\nlearning node representations, the topological distance seems necessary since\nit characterizes the basic relations between nodes. However, for learning\nrepresentations of the entire graphs, is it still necessary to hold? In this\nwork, we show that such a principle is not necessary, it hinders most existing\nGNNs from efficiently encoding graph structures. By removing it, as well as the\nlimitation of polynomial filters, the resulting new architecture significantly\nboosts performance on learning graph representations. We also study the effects\nof graph spectrum on signals and interpret various existing improvements as\ndifferent spectrum smoothing techniques. It serves as a spatial understanding\nthat quantitatively measures the effects of the spectrum to input signals in\ncomparison to the well-known spectral understanding as high/low-pass filters.\nMore importantly, it sheds the light on developing powerful graph\nrepresentation models.",
    "descriptor": "",
    "authors": [
      "Mingqi Yang",
      "Rui Li",
      "Yanming Shen",
      "Heng Qi",
      "Baocai Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07160"
  },
  {
    "id": "arXiv:2112.07163",
    "title": "Minimization of Stochastic First-order Oracle Complexity of Adaptive  Methods for Nonconvex Optimization",
    "abstract": "Numerical evaluations have definitively shown that, for deep learning\noptimizers such as stochastic gradient descent, momentum, and adaptive methods,\nthe number of steps needed to train a deep neural network halves for each\ndoubling of the batch size and that there is a region of diminishing returns\nbeyond the critical batch size. In this paper, we determine the actual critical\nbatch size by using the global minimizer of the stochastic first-order oracle\n(SFO) complexity of the optimizer. To prove the existence of the actual\ncritical batch size, we set the lower and upper bounds of the SFO complexity\nand prove that there exist critical batch sizes in the sense of minimizing the\nlower and upper bounds. This proof implies that, if the SFO complexity fits the\nlower and upper bounds, then the existence of these critical batch sizes\ndemonstrates the existence of the actual critical batch size. We also discuss\nthe conditions needed for the SFO complexity to fit the lower and upper bounds\nand provide numerical results that support our theoretical results.",
    "descriptor": "",
    "authors": [
      "Hideaki Iiduka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.07163"
  },
  {
    "id": "arXiv:2112.07164",
    "title": "Contention Based Proportional Fairness (CBPF) Transmission Scheme for  Time Slotted Channel Hopping Networks",
    "abstract": "Time Slotted Channel Hopping (TSCH) is a Medium Access Control (MAC) protocol\nintroduced in IEEE802.15.4e standard, addressing low power requirements of the\nInternet of Things (IoT) and Low Power Lossy Networks (LLNs). The 6TiSCH\nOperation sublayer (6top) of IEEE802.15.4e defines the schedule that includes\nsleep, transmit and receive routines of the nodes. However, the design of\nschedule is not specified by the standard. In this paper, we propose a\ncontention based proportional fairness (CBPF) transmission scheme for TSCH\nnetworks to maximize the system throughput addressing fair allocation of\nresources to the nodes. We propose a convex programming based method to achieve\nthe fairness and throughput objectives. We model TSCH MAC as a multichannel\nslotted aloha and analyse it for a schedule given by the 6top layer.\nPerformance metrics like throughput, delay and energy spent per successful\ntransmission are derived and validated through simulations. The proposed CBPF\ntransmission scheme has been implemented in the IoT-LAB public testbed to\nevaluate its performance and to compare with the existing scheduling\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Lokesh Bommisetty",
      "TG Venkatesh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.07164"
  },
  {
    "id": "arXiv:2112.07165",
    "title": "Discovering Explanatory Sentences in Legal Case Decisions Using  Pre-trained Language Models",
    "abstract": "Legal texts routinely use concepts that are difficult to understand. Lawyers\nelaborate on the meaning of such concepts by, among other things, carefully\ninvestigating how have they been used in past. Finding text snippets that\nmention a particular concept in a useful way is tedious, time-consuming, and,\nhence, expensive. We assembled a data set of 26,959 sentences, coming from\nlegal case decisions, and labeled them in terms of their usefulness for\nexplaining selected legal concepts. Using the dataset we study the\neffectiveness of transformer-based models pre-trained on large language corpora\nto detect which of the sentences are useful. In light of models' predictions,\nwe analyze various linguistic properties of the explanatory sentences as well\nas their relationship to the legal concept that needs to be explained. We show\nthat the transformer-based models are capable of learning surprisingly\nsophisticated features and outperform the prior approaches to the task.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Jaromir Savelka",
      "Kevin D. Ashley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.07165"
  },
  {
    "id": "arXiv:2112.07170",
    "title": "Performance evaluation of the QOS provisioning ability of IEEE 802.11e  WLAN standard for multimedia traffic",
    "abstract": "This paper presents an analytical model for the average frame transmission\ndelay and the jitter for the different Access Categories (ACs) of the IEEE\n802.11e Enhanced Distributed Channel Access (EDCA) mechanism. Following are the\nsalient features of our model. As defined by the standard we consider (1) the\nvirtual collisions among different ACs inside each EDCA station in addition to\nexternal collisions. (2) the effect of priority parameters, such as minimum and\nmaximum values of Contention Window (CW) sizes, Arbitration Inter Frame Space\n(AIFS). (3) the role of Transmission Opportunity (TXOP) of different ACs. (4)\nthe finite number of retrials a packet experiences before being dropped. Our\nmodel and analytical results provide an in-depth understanding of the EDCA\nmechanism and the effect of Quality of Service (QoS) parameters in the\nperformance of IEEE 802.11e protocol.",
    "descriptor": "",
    "authors": [
      "Venkata Sitaram. A",
      "Venkatesh. T. G",
      "Arun George",
      "Manivasakan. R",
      "Bhasker Dappuri"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.07170"
  },
  {
    "id": "arXiv:2112.07173",
    "title": "On the use of Cortical Magnification and Saccades as Biological Proxies  for Data Augmentation",
    "abstract": "Self-supervised learning is a powerful way to learn useful representations\nfrom natural data. It has also been suggested as one possible means of building\nvisual representation in humans, but the specific objective and algorithm are\nunknown. Currently, most self-supervised methods encourage the system to learn\nan invariant representation of different transformations of the same image in\ncontrast to those of other images. However, such transformations are generally\nnon-biologically plausible, and often consist of contrived perceptual schemes\nsuch as random cropping and color jittering. In this paper, we attempt to\nreverse-engineer these augmentations to be more biologically or perceptually\nplausible while still conferring the same benefits for encouraging robust\nrepresentation. Critically, we find that random cropping can be substituted by\ncortical magnification, and saccade-like sampling of the image could also\nassist the representation learning. The feasibility of these transformations\nsuggests a potential way that biological visual systems could implement\nself-supervision. Further, they break the widely accepted spatially-uniform\nprocessing assumption used in many computer vision algorithms, suggesting a\nrole for spatially-adaptive computation in humans and machines alike. Our code\nand demo can be found here.",
    "descriptor": "\nComments: 14 pages, 6 figures, 2 tables. Published in NeurIPS 2021 Workshop, Shared Visual Representations in Human & Machine Intelligence (SVRHM). For code, see this https URL\n",
    "authors": [
      "Binxu Wang",
      "David Mayo",
      "Arturo Deza",
      "Andrei Barbu",
      "Colin Conwell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2112.07173"
  },
  {
    "id": "arXiv:2112.07174",
    "title": "Practical Distributed Reception for Wireless Body Area Networks Using  Supervised Learning",
    "abstract": "Medical applications have driven many areas of engineering to optimize\ndiagnostic capabilities and convenience. In the near future, wireless body area\nnetworks (WBANs) are expected to have widespread impact in medicine. To achieve\nthis impact, however, significant advances in research are needed to cope with\nthe changes of the human body's state, which make coherent communications\ndifficult or even impossible. In this paper, we consider a realistic\nnoncoherent WBAN system model where transmissions and receptions are conducted\nwithout any channel state information due to the fast-varying channels of the\nhuman body. Using distributed reception, we propose several symbol detection\napproaches where on-off keying (OOK) modulation is exploited, among which a\nsupervised-learning-based approach is developed to overcome the noncoherent\nsystem issue. Through simulation results, we compare and verify the performance\nof the proposed techniques for noncoherent WBANs with OOK transmissions. We\nshow that the well-defined detection techniques with a\nsupervised-learning-based approach enable robust communications for noncoherent\nWBAN systems.",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Jihoon Cha",
      "Junil Choi",
      "David J. Love"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.07174"
  },
  {
    "id": "arXiv:2112.07175",
    "title": "Co-training Transformer with Videos and Images Improves Action  Recognition",
    "abstract": "In learning action recognition, models are typically pre-trained on object\nrecognition with images, such as ImageNet, and later fine-tuned on target\naction recognition with videos. This approach has achieved good empirical\nperformance especially with recent transformer-based video architectures. While\nrecently many works aim to design more advanced transformer architectures for\naction recognition, less effort has been made on how to train video\ntransformers. In this work, we explore several training paradigms and present\ntwo findings. First, video transformers benefit from joint training on diverse\nvideo datasets and label spaces (e.g., Kinetics is appearance-focused while\nSomethingSomething is motion-focused). Second, by further co-training with\nimages (as single-frame videos), the video transformers learn even better video\nrepresentations. We term this approach as Co-training Videos and Images for\nAction Recognition (CoVeR). In particular, when pretrained on ImageNet-21K\nbased on the TimeSFormer architecture, CoVeR improves Kinetics-400 Top-1\nAccuracy by 2.4%, Kinetics-600 by 2.3%, and SomethingSomething-v2 by 2.3%. When\npretrained on larger-scale image datasets following previous state-of-the-art,\nCoVeR achieves best results on Kinetics-400 (87.2%), Kinetics-600 (87.9%),\nKinetics-700 (79.8%), SomethingSomething-v2 (70.9%), and Moments-in-Time\n(46.1%), with a simple spatio-temporal video transformer.",
    "descriptor": "",
    "authors": [
      "Bowen Zhang",
      "Jiahui Yu",
      "Christopher Fifty",
      "Wei Han",
      "Andrew M. Dai",
      "Ruoming Pang",
      "Fei Sha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07175"
  },
  {
    "id": "arXiv:2112.07176",
    "title": "ZUPT Aided GNSS Factor Graph with Inertial Navigation Integration for  Wheeled Robots",
    "abstract": "In this work, we demonstrate the importance of zero velocity information for\nglobal navigation satellite system (GNSS) based navigation. The effectiveness\nof using the zero velocity information with zero velocity update (ZUPT) for\ninertial navigation applications have been shown in the literature. Here we\nleverage this information and add it as a position constraint in a GNSS factor\ngraph. We also compare its performance to a GNSS/inertial navigation system\n(INS) coupled factor graph. We tested our ZUPT aided factor graph method on\nthree datasets and compared it with the GNSS-only factor graph.",
    "descriptor": "\nComments: 9 pages, 8 figures, Preprint Version. Published in ION GNSS+ 2021\n",
    "authors": [
      "Cagri Kilic",
      "Shounak Das",
      "Eduardo Gutierrez",
      "Ryan Watson",
      "Jason Gross"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.07176"
  },
  {
    "id": "arXiv:2112.07178",
    "title": "MuxLink: Circumventing Learning-Resilient MUX-Locking Using Graph Neural  Network-based Link Prediction",
    "abstract": "Logic locking has received considerable interest as a prominent technique for\nprotecting the design intellectual property from untrusted entities, especially\nthe foundry. Recently, machine learning (ML)-based attacks have questioned the\nsecurity guarantees of logic locking, and have demonstrated considerable\nsuccess in deciphering the secret key without relying on an oracle, hence,\nproving to be very useful for an adversary in the fab. Such ML-based attacks\nhave triggered the development of learning-resilient locking techniques. The\nmost advanced state-of-the-art deceptive MUX-based locking (D-MUX) and the\nsymmetric MUX-based locking techniques have recently demonstrated resilience\nagainst existing ML-based attacks. Both defense techniques obfuscate the design\nby inserting key-controlled MUX logic, ensuring that all the secret inputs to\nthe MUXes are equiprobable.\nIn this work, we show that these techniques primarily introduce local and\nlimited changes to the circuit without altering the global structure of the\ndesign. By leveraging this observation, we propose a novel graph neural network\n(GNN)-based link prediction attack, MuxLink, that successfully breaks both the\nD-MUX and symmetric MUX-locking techniques, relying only on the underlying\nstructure of the locked design, i.e., in an oracle-less setting. Our trained\nGNN model learns the structure of the given circuit and the composition of\ngates around the non-obfuscated wires, thereby generating meaningful link\nembeddings that help decipher the secret inputs to the MUXes. The proposed\nMuxLink achieves key prediction accuracy and precision up to 100% on D-MUX and\nsymmetric MUX-locked ISCAS-85 and ITC-99 benchmarks, fully unlocking the\ndesigns. We open-source MuxLink [1].",
    "descriptor": "\nComments: Will be published in Proc. Design, Automation and Test in Europe (DATE) 2022\n",
    "authors": [
      "Lilas Alrahis",
      "Satwik Patnaik",
      "Muhammad Shafique",
      "Ozgur Sinanoglu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.07178"
  },
  {
    "id": "arXiv:2112.07179",
    "title": "Blockchain Developments and Innovations",
    "abstract": "Blockchain has received expanding interest from various domains.\nInstitutions, enterprises, governments, and agencies are interested in\nBlockchain potential to augment their software systems. The unique requirements\nand characteristics of Blockchain platforms raise new challenges involving\nextensive enhancement to conventional software development processes to meet\nthe needs of these domains. Software engineering approaches supporting\nBlockchain-oriented developments have been slow to materialize, despite\nproposals in the literature, and they have yet to be objectively analyzed. A\ncritical appraisal of these innovations is crucial to identify their respective\nstrengths and weaknesses. We present an analytical evaluation of several\nprominent Blockchain-oriented methods through a comprehensive, criteria-based\nevaluation framework. The results can be used for comparing, adapting, and\ndeveloping a new generation of Blockchain-oriented software development\nprocesses and innovations.",
    "descriptor": "",
    "authors": [
      "Mahdi Fahmideh",
      "Anuradha Gunawardana",
      "Shiping Chen",
      "Jun Shen",
      "Brian Yecies"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.07179"
  },
  {
    "id": "arXiv:2112.07184",
    "title": "Calibrated and Sharp Uncertainties in Deep Learning via Simple Density  Estimation",
    "abstract": "Predictive uncertainties can be characterized by two properties--calibration\nand sharpness. This paper argues for reasoning about uncertainty in terms these\nproperties and proposes simple algorithms for enforcing them in deep learning.\nOur methods focus on the strongest notion of calibration--distribution\ncalibration--and enforce it by fitting a low-dimensional density or quantile\nfunction with a neural estimator. The resulting approach is much simpler and\nmore broadly applicable than previous methods across both classification and\nregression. Empirically, we find that our methods improve predictive\nuncertainties on several tasks with minimal computational and implementation\noverhead. Our insights suggest simple and improved ways of training deep\nlearning models that lead to accurate uncertainties that should be leveraged to\nimprove performance across downstream applications.",
    "descriptor": "",
    "authors": [
      "Volodymyr Kuleshov",
      "Shachi Deshpande"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07184"
  },
  {
    "id": "arXiv:2112.07187",
    "title": "Formal Estimation of Collision Risks for Autonomous Vehicles: A  Compositional Data-Driven Approach",
    "abstract": "In this work, we propose a compositional data-driven approach for the formal\nestimation of collision risks for autonomous vehicles (AVs) acting in a\nstochastic multi-agent framework. The proposed approach is based on the\nconstruction of sub-barrier certificates for each stochastic agent via a set of\ndata collected from its trajectories while providing a-priori guaranteed\nconfidence on the data-driven estimation. In our proposed setting, we first\ncast the original collision risk problem for each agent as a robust\noptimization program (ROP). Solving the acquired ROP is not tractable due to an\nunknown model that appears in one of its constraints. To tackle this\ndifficulty, we collect finite numbers of data from trajectories of each agent\nand provide a scenario optimization program (SOP) corresponding to the original\nROP. We then establish a probabilistic bridge between the optimal value of SOP\nand that of ROP, and accordingly, we formally construct the sub-barrier\ncertificate for each unknown agent based on the number of data and a required\nlevel of confidence. We then propose a compositional technique based on\nsmall-gain reasoning to quantify the collision risk for multi-agent AVs with\nsome desirable confidence based on sub-barrier certificates of individual\nagents constructed from data. For the case that the proposed compositionality\nconditions are not satisfied, we provide a relaxed version of compositional\nresults without requiring any compositionality conditions but at the cost of\nproviding a potentially conservative collision risk. Eventually, we develop our\napproaches for non-stochastic multi-agent AVs. We demonstrate the effectiveness\nof our proposed results by applying them to a vehicle platooning consisting of\n100 vehicles with 1 leader and 99 followers. We formally estimate the collision\nrisk for the whole network by collecting sampled data from trajectories of each\nagent.",
    "descriptor": "",
    "authors": [
      "Abolfazl Lavaei",
      "Luigi Di Lillo",
      "Andrea Censi",
      "Emilio Frazzoli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.07187"
  },
  {
    "id": "arXiv:2112.07191",
    "title": "An Adaptive Graph Pre-training Framework for Localized Collaborative  Filtering",
    "abstract": "Graph neural networks (GNNs) have been widely applied in the recommendation\ntasks and have obtained very appealing performance. However, most GNN-based\nrecommendation methods suffer from the problem of data sparsity in practice.\nMeanwhile, pre-training techniques have achieved great success in mitigating\ndata sparsity in various domains such as natural language processing (NLP) and\ncomputer vision (CV). Thus, graph pre-training has the great potential to\nalleviate data sparsity in GNN-based recommendations. However, pre-training\nGNNs for recommendations face unique challenges. For example, user-item\ninteraction graphs in different recommendation tasks have distinct sets of\nusers and items, and they often present different properties. Therefore, the\nsuccessful mechanisms commonly used in NLP and CV to transfer knowledge from\npre-training tasks to downstream tasks such as sharing learned embeddings or\nfeature extractors are not directly applicable to existing GNN-based\nrecommendations models. To tackle these challenges, we delicately design an\nadaptive graph pre-training framework for localized collaborative filtering\n(ADAPT). It does not require transferring user/item embeddings, and is able to\ncapture both the common knowledge across different graphs and the uniqueness\nfor each graph. Extensive experimental results have demonstrated the\neffectiveness and superiority of ADAPT.",
    "descriptor": "",
    "authors": [
      "Yiqi Wang",
      "Chaozhuo Li",
      "Zheng Liu",
      "Mingzheng Li",
      "Jiliang Tang",
      "Xing Xie",
      "Lei Chen",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07191"
  },
  {
    "id": "arXiv:2112.07192",
    "title": "Cross-modal Music Emotion Recognition Using Composite Loss-based  Embeddings",
    "abstract": "Most music emotion recognition approaches use one-way classification or\nregression that estimates a general emotion from a distribution of music\nsamples, but without considering emotional variations (e.g., happiness can be\nfurther categorised into much, moderate or little happiness). We propose a\ncross-modal music emotion recognition approach that associates music samples\nwith emotions in a common space by considering both of their general and\nspecific characteristics. Since the association of music samples with emotions\nis uncertain due to subjective human perceptions, we compute composite\nloss-based embeddings obtained to maximise two statistical characteristics, one\nbeing the correlation between music samples and emotions based on canonical\ncorrelation analysis, and the other being a probabilistic similarity between a\nmusic sample and an emotion with KL-divergence. Experiments on two benchmark\ndatasets demonstrate the superiority of our approach over one-way baselines. In\naddition, detailed analysis show that our approach can accomplish robust\ncross-modal music emotion recognition that not only identifies music samples\nmatching with a specific emotion but also detects emotions expressed in a\ncertain music sample.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Naoki Takashima",
      "Fr\u00e9d\u00e9ric Li",
      "Marcin Grzegorzek",
      "Kimiaki Shirahama"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.07192"
  },
  {
    "id": "arXiv:2112.07194",
    "title": "MDD-Eval: Self-Training on Augmented Data for Multi-Domain Dialogue  Evaluation",
    "abstract": "Chatbots are designed to carry out human-like conversations across different\ndomains, such as general chit-chat, knowledge exchange, and persona-grounded\nconversations. To measure the quality of such conversational agents, a dialogue\nevaluator is expected to conduct assessment across domains as well. However,\nmost of the state-of-the-art automatic dialogue evaluation metrics (ADMs) are\nnot designed for multi-domain evaluation. We are motivated to design a general\nand robust framework, MDD-Eval, to address the problem. Specifically, we first\ntrain a teacher evaluator with human-annotated data to acquire a rating skill\nto tell good dialogue responses from bad ones in a particular domain and then,\nadopt a self-training strategy to train a new evaluator with teacher-annotated\nmulti-domain data, that helps the new evaluator to generalize across multiple\ndomains. MDD-Eval is extensively assessed on six dialogue evaluation\nbenchmarks. Empirical results show that the MDD-Eval framework achieves a\nstrong performance with an absolute improvement of 7% over the state-of-the-art\nADMs in terms of mean Spearman correlation scores across all the evaluation\nbenchmarks.",
    "descriptor": "\nComments: Accepted to AAAI2022 (10 pages, 3 figures, Preprint version)\n",
    "authors": [
      "Chen Zhang",
      "Luis Fernando D'Haro",
      "Thomas Friedrichs",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07194"
  },
  {
    "id": "arXiv:2112.07197",
    "title": "Algorithms for enumerating connected induced subgraphs of a given order",
    "abstract": "Enumerating all connected subgraphs of a given order from graphs is a\ncomputationally challenging task. In this paper, we propose two algorithms for\nenumerating all connected induced subgraphs of a given order from connected\nundirected graphs. The first algorithm is a variant of a previous well-known\nalgorithm. The algorithm enumerates all connected induced subgraphs of order\n$k$ in a bottom-up manner. The data structures that leads to unit time element\nchecking and linear space are presented. Different from previous algorithms\nthat either work in a bottom-up manner or in a reverse search manner, an\nalgorithm that enumerates all connected induced subgraphs of order $k$ in a\ntop-down manner by recursively deleting vertices is proposed. The data\nstructures used in the implementation are also presented. The correctness and\ncomplexity of the top-down algorithm is analysed and proven. Experimental\nresult show that the variant bottom-up algorithm outperforms the other\nalgorithms for enumerating connected induced subgraphs of small order, and the\ntop-down algorithm is fastest among the state-of-the-art algorithms for\nenumerating connected induced subgraphs of large order.",
    "descriptor": "",
    "authors": [
      "Shanshan Wang",
      "Chenglong Xiao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.07197"
  },
  {
    "id": "arXiv:2112.07198",
    "title": "From Dense to Sparse: Contrastive Pruning for Better Pre-trained  Language Model Compression",
    "abstract": "Pre-trained Language Models (PLMs) have achieved great success in various\nNatural Language Processing (NLP) tasks under the pre-training and fine-tuning\nparadigm. With large quantities of parameters, PLMs are computation-intensive\nand resource-hungry. Hence, model pruning has been introduced to compress\nlarge-scale PLMs. However, most prior approaches only consider task-specific\nknowledge towards downstream tasks, but ignore the essential task-agnostic\nknowledge during pruning, which may cause catastrophic forgetting problem and\nlead to poor generalization ability. To maintain both task-agnostic and\ntask-specific knowledge in our pruned model, we propose ContrAstive Pruning\n(CAP) under the paradigm of pre-training and fine-tuning. It is designed as a\ngeneral framework, compatible with both structured and unstructured pruning.\nUnified in contrastive learning, CAP enables the pruned model to learn from the\npre-trained model for task-agnostic knowledge, and fine-tuned model for\ntask-specific knowledge. Besides, to better retain the performance of the\npruned model, the snapshots (i.e., the intermediate models at each pruning\niteration) also serve as effective supervisions for pruning. Our extensive\nexperiments show that adopting CAP consistently yields significant\nimprovements, especially in extremely high sparsity scenarios. With only 3%\nmodel parameters reserved (i.e., 97% sparsity), CAP successfully achieves 99.2%\nand 96.3% of the original BERT performance in QQP and MNLI tasks. In addition,\nour probing experiments demonstrate that the model pruned by CAP tends to\nachieve better generalization ability.",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Runxin Xu",
      "Fuli Luo",
      "Chengyu Wang",
      "Baobao Chang",
      "Jun Huang",
      "Songfang Huang",
      "Fei Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07198"
  },
  {
    "id": "arXiv:2112.07200",
    "title": "Weakly Supervised High-Fidelity Clothing Model Generation",
    "abstract": "The development of online economics arouses the demand of generating images\nof models on product clothes, to display new clothes and promote sales.\nHowever, the expensive proprietary model images challenge the existing image\nvirtual try-on methods in this scenario, as most of them need to be trained on\nconsiderable amounts of model images accompanied with paired clothes images. In\nthis paper, we propose a cheap yet scalable weakly-supervised method called\nDeep Generative Projection (DGP) to address this specific scenario. Lying in\nthe heart of the proposed method is to imitate the process of human predicting\nthe wearing effect, which is an unsupervised imagination based on life\nexperience rather than computation rules learned from supervisions. Here a\npretrained StyleGAN is used to capture the practical experience of wearing.\nExperiments show that projecting the rough alignment of clothing and body onto\nthe StyleGAN space can yield photo-realistic wearing results. Experiments on\nreal scene proprietary model images demonstrate the superiority of DGP over\nseveral state-of-the-art supervised methods when generating clothing model\nimages.",
    "descriptor": "",
    "authors": [
      "Ruili Feng",
      "Cheng Ma",
      "Chengji Shen",
      "Xin Gao",
      "Zhenjiang Liu",
      "Xiaobo Li",
      "Kairi Ou",
      "Zhengjun Zha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07200"
  },
  {
    "id": "arXiv:2112.07204",
    "title": "An algorithm with improved delay for enumerating connected induced  subgraphs of a large cardinality",
    "abstract": "Enumerating all connected induced subgraphs of a given order $k$ is a\ncomputationally difficult problem. Elbassioni has proposed an algorithm based\non reverse search with a delay of $O(k\\cdot\nmin\\{(n-k),k\\Delta\\}\\cdot(k(\\Delta+\\log{k})+\\log{n}))$, where $n$ is the number\nof vertices and $\\Delta$ is the maximum degree of input graph \\cite{6}. In this\nshort note, we present an algorithm with an improved delay of $O(k\\cdot\nmin\\{(n-k),k\\Delta\\}\\cdot(k\\log{\\Delta}+\\log{n}))$ by introducing a new\nneighborhood definition. This also improves upon the current best delay bound\n$O(k^2\\Delta)$\\cite{4} for this problem for large $k$.",
    "descriptor": "",
    "authors": [
      "Shanshan Wang",
      "Chenglong Xiao",
      "Emmanuel Casseau"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.07204"
  },
  {
    "id": "arXiv:2112.07207",
    "title": "Modeling Image Quantization Tradeoffs for Optimal Compression",
    "abstract": "All Lossy compression algorithms employ similar compression schemes --\nfrequency domain transform followed by quantization and lossless encoding\nschemes. They target tradeoffs by quantizating high frequency data to increase\ncompression rates which come at the cost of higher image distortion. We propose\na new method of optimizing quantization tables using Deep Learning and a\nminimax loss function that more accurately measures the tradeoffs between rate\nand distortion parameters (RD) than previous methods. We design a convolutional\nneural network (CNN) that learns a mapping between image blocks and\nquantization tables in an unsupervised manner. By processing images across all\nchannels at once, we can achieve stronger performance by also measuring\ntradeoffs in information loss between different channels. We initially target\noptimization on JPEG images but feel that this can be expanded to any lossy\ncompressor.",
    "descriptor": "",
    "authors": [
      "Johnathan Chiu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07207"
  },
  {
    "id": "arXiv:2112.07208",
    "title": "Interpretable Convolutional Neural Networks for Subject-Independent  Motor Imagery Classification",
    "abstract": "Deep learning frameworks have become increasingly popular in brain computer\ninterface (BCI) study thanks to their outstanding performance. However, in\nterms of the classification model alone, they are treated as black box as they\ndo not provide any information on what led them to reach a particular decision.\nIn other words, we cannot convince whether the high performance was aroused by\nthe neuro-physiological factors or simply noise. Because of this disadvantage,\nit is difficult to ensure adequate reliability compared to their high\nperformance. In this study, we propose an explainable deep learning model for\nBCI. Specifically, we aim to classify EEG signal which is obtained from the\nmotor-imagery (MI) task. In addition, we adopted layer-wise relevance\npropagation (LRP) to the model to interpret the reason that the model derived\ncertain classification output. We visualized the heatmap which indicates the\noutput of the LRP in form of topography to certify neuro-physiological factors.\nFurthermore, we classified EEG with the subject-independent manner to learn\nrobust and generalized EEG features by avoiding subject dependency. The\nmethodology also provides the advantage of avoiding the expense of building\ntraining data for each subject. With our proposed model, we obtained\ngeneralized heatmap patterns for all subjects. As a result, we can conclude\nthat our proposed model provides neuro-physiologically reliable interpretation.",
    "descriptor": "\nComments: Submitted to IEEE 10th International Winter Conference on Brain-Computer Interface (BCI 2022)\n",
    "authors": [
      "Ji-Seon Bang",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.07208"
  },
  {
    "id": "arXiv:2112.07209",
    "title": "ACE-BERT: Adversarial Cross-modal Enhanced BERT for E-commerce Retrieval",
    "abstract": "Nowadays on E-commerce platforms, products are presented to the customers\nwith multiple modalities. These multiple modalities are significant for a\nretrieval system while providing attracted products for customers. Therefore,\nhow to take into account those multiple modalities simultaneously to boost the\nretrieval performance is crucial. This problem is a huge challenge to us due to\nthe following reasons: (1) the way of extracting patch features with the\npre-trained image model (e.g., CNN-based model) has much inductive bias. It is\ndifficult to capture the efficient information from the product image in\nE-commerce. (2) The heterogeneity of multimodal data makes it challenging to\nconstruct the representations of query text and product including title and\nimage in a common subspace. We propose a novel Adversarial Cross-modal Enhanced\nBERT (ACE-BERT) for efficient E-commerce retrieval. In detail, ACE-BERT\nleverages the patch features and pixel features as image representation. Thus\nthe Transformer architecture can be applied directly to the raw image\nsequences. With the pre-trained enhanced BERT as the backbone network, ACE-BERT\nfurther adopts adversarial learning by adding a domain classifier to ensure the\ndistribution consistency of different modality representations for the purpose\nof narrowing down the representation gap between query and product.\nExperimental results demonstrate that ACE-BERT outperforms the state-of-the-art\napproaches on the retrieval task. It is remarkable that ACE-BERT has already\nbeen deployed in our E-commerce's search engine, leading to 1.46% increase in\nrevenue.",
    "descriptor": "",
    "authors": [
      "Boxuan Zhang",
      "Chao Wei",
      "Yan Jin",
      "Weiru Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07209"
  },
  {
    "id": "arXiv:2112.07210",
    "title": "Simple Local Attentions Remain Competitive for Long-Context Tasks",
    "abstract": "Many NLP tasks require processing long contexts beyond the length limit of\npretrained models. In order to scale these models to longer text sequences,\nmany efficient long-range attention variants have been proposed. Despite the\nabundance of research along this direction, it is still difficult to gauge the\nrelative effectiveness of these models in practical use cases, e.g., if we\napply these models following the pretrain-and-finetune paradigm. In this work,\nwe aim to conduct a thorough analysis of these emerging models with large-scale\nand controlled experiments. For each attention variant, we pretrain large-size\nmodels using the same long-doc corpus and then finetune these models for\nreal-world long-context tasks. Our findings reveal pitfalls of an existing\nwidely-used long-range benchmark and show none of the tested efficient\nattentions can beat a simple local window attention under standard pretraining\nparadigms. Further analysis on local attention variants suggests that even the\ncommonly used attention-window overlap is not necessary to achieve good\ndownstream results -- using disjoint local attentions, we are able to build a\nsimpler and more efficient long-doc QA model that matches the performance of\nLongformer~\\citep{longformer} with half of its pretraining compute.",
    "descriptor": "",
    "authors": [
      "Wenhan Xiong",
      "Barlas O\u011fuz",
      "Anchit Gupta",
      "Xilun Chen",
      "Diana Liskovich",
      "Omer Levy",
      "Wen-tau Yih",
      "Yashar Mehdad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07210"
  },
  {
    "id": "arXiv:2112.07213",
    "title": "In-Kernel Control-Flow Integrity on Commodity OSes using ARM Pointer  Authentication",
    "abstract": "This paper presents an in-kernel, hardware-based control-flow integrity (CFI)\nprotection, called PAL, that utilizes ARM's Pointer Authentication (PA). It\nprovides three important benefits over commercial, state-of-the-art PA-based\nCFIs like iOS's: 1) enhancing CFI precision via automated refinement\ntechniques, 2) addressing hindsight problems of PA for in kernel uses such as\npreemptive hijacking and brute-forcing attacks, and 3) assuring the algorithmic\nor implementation correctness via post validation. PAL achieves these goals in\nan OS-agnostic manner, so could be applied to commodity OSes like Linux and\nFreeBSD. The precision of the CFI protection can be adjusted for better\nperformance or improved for better security with minimal engineering efforts if\na user opts in to. Our evaluation shows that PAL incurs negligible performance\noverhead: e.g., <1% overhead for Apache benchmark and 3~5% overhead for Linux\nperf benchmark on the latest Mac mini (M1). Our post-validation approach helps\nus ensure the security invariant required for the safe uses of PA inside the\nkernel, which also reveals new attack vectors on the iOS kernel. PAL as well as\nthe CFI-protected kernels will be open sourced.",
    "descriptor": "",
    "authors": [
      "Sungbae Yoo",
      "Jinbum Park",
      "Seolheui Kim",
      "Yeji Kim",
      "Taesoo Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2112.07213"
  },
  {
    "id": "arXiv:2112.07214",
    "title": "Noise Reduction and Driving Event Extraction Method for Performance  Improvement on Driving Noise-based Surface Anomaly Detection",
    "abstract": "Foreign substances on the road surface, such as rainwater or black ice,\nreduce the friction between the tire and the surface. The above situation will\nreduce the braking performance and make difficult to control the vehicle body\nposture. In that case, there is a possibility of property damage at least. In\nthe worst case, personal damage will be occured. To avoid this problem, a road\nanomaly detection model is proposed based on vehicle driving noise. However,\nthe prior proposal does not consider the extra noise, mixed with driving noise,\nand skipping calculations for moments without vehicle driving. In this paper,\nwe propose a simple driving event extraction method and noise reduction method\nfor improving computational efficiency and anomaly detection performance.",
    "descriptor": "\nComments: 3 pages, 3 figures, 2 tables\n",
    "authors": [
      "YeongHyeon Park",
      "JoonSung Lee",
      "Myung Jin Kim",
      "Wonseok Park"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.07214"
  },
  {
    "id": "arXiv:2112.07217",
    "title": "On fully dynamic constant-factor approximation algorithms for clustering  problems",
    "abstract": "Clustering is an important task with applications in many fields of computer\nscience. We study the fully dynamic setting in which we want to maintain good\nclusters efficiently when input points (from a metric space) can be inserted\nand deleted. Many clustering problems are $\\mathsf{APX}$-hard but admit\npolynomial time $O(1)$-approximation algorithms. Thus, it is a natural question\nwhether we can maintain $O(1)$-approximate solutions for them in subpolynomial\nupdate time, against adaptive and oblivious adversaries. Only a few results are\nknown that give partial answers to this question. There are dynamic algorithms\nfor $k$-center, $k$-means, and $k$-median that maintain constant factor\napproximations in expected $\\tilde{O}(k^{2})$ update time against an oblivious\nadversary. However, for these problems there are no algorithms known with an\nupdate time that is subpolynomial in $k$, and against an adaptive adversary\nthere are even no (non-trivial) dynamic algorithms known at all.\nIn this paper, we complete the picture of the question above for all these\nclustering problems. 1. We show that there is no fully dynamic\n$O(1)$-approximation algorithm for any of the classic clustering problems above\nwith an update time in $n^{o(1)}h(k)$ against an adaptive adversary, for an\narbitrary function $h$. 2. We give a lower bound of $\\Omega(k)$ on the update\ntime for each of the above problems, even against an oblivious adversary. 3. We\ngive the first $O(1)$-approximate fully dynamic algorithms for $k$-sum-of-radii\nand for $k$-sum-of-diameters with expected update time of $\\tilde{O}(k^{O(1)})$\nagainst an oblivious adversary. 4. Finally, for $k$-center we present a fully\ndynamic $(6+\\epsilon)$-approximation algorithm with an expected update time of\n$\\tilde{O}(k)$ against an oblivious adversary.",
    "descriptor": "",
    "authors": [
      "Hendrik Fichtenberger",
      "Monika Henzinger",
      "Andreas Wiese"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.07217"
  },
  {
    "id": "arXiv:2112.07219",
    "title": "A real-time spatiotemporal AI model analyzes skill in open surgical  videos",
    "abstract": "Open procedures represent the dominant form of surgery worldwide. Artificial\nintelligence (AI) has the potential to optimize surgical practice and improve\npatient outcomes, but efforts have focused primarily on minimally invasive\ntechniques. Our work overcomes existing data limitations for training AI models\nby curating, from YouTube, the largest dataset of open surgical videos to date:\n1997 videos from 23 surgical procedures uploaded from 50 countries. Using this\ndataset, we developed a multi-task AI model capable of real-time understanding\nof surgical behaviors, hands, and tools - the building blocks of procedural\nflow and surgeon skill. We show that our model generalizes across diverse\nsurgery types and environments. Illustrating this generalizability, we directly\napplied our YouTube-trained model to analyze open surgeries prospectively\ncollected at an academic medical center and identified kinematic descriptors of\nsurgical skill related to efficiency of hand motion. Our Annotated Videos of\nOpen Surgery (AVOS) dataset and trained model will be made available for\nfurther development of surgical AI.",
    "descriptor": "\nComments: 22 pages, 4 main text figures, 7 extended data figures, 4 extended data tables\n",
    "authors": [
      "Emmett D. Goodman",
      "Krishna K. Patel",
      "Yilun Zhang",
      "William Locke",
      "Chris J. Kennedy",
      "Rohan Mehrotra",
      "Stephen Ren",
      "Melody Guan",
      "Maren Downing",
      "Hao Wei Chen",
      "Jevin Z. Clark",
      "Gabriel A. Brat",
      "Serena Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07219"
  },
  {
    "id": "arXiv:2112.07221",
    "title": "HET: Scaling out Huge Embedding Model Training via Cache-enabled  Distributed Framework",
    "abstract": "Embedding models have been an effective learning paradigm for\nhigh-dimensional data. However, one open issue of embedding models is that\ntheir representations (latent factors) often result in large parameter space.\nWe observe that existing distributed training frameworks face a scalability\nissue of embedding models since updating and retrieving the shared embedding\nparameters from servers usually dominates the training cycle. In this paper, we\npropose HET, a new system framework that significantly improves the scalability\nof huge embedding model training. We embrace skewed popularity distributions of\nembeddings as a performance opportunity and leverage it to address the\ncommunication bottleneck with an embedding cache. To ensure consistency across\nthe caches, we incorporate a new consistency model into HET design, which\nprovides fine-grained consistency guarantees on a per-embedding basis. Compared\nto previous work that only allows staleness for read operations, HET also\nutilizes staleness for write operations. Evaluations on six representative\ntasks show that HET achieves up to 88% embedding communication reductions and\nup to 20.68x performance speedup over the state-of-the-art baselines.",
    "descriptor": "",
    "authors": [
      "Xupeng Miao",
      "Hailin Zhang",
      "Yining Shi",
      "Xiaonan Nie",
      "Zhi Yang",
      "Yangyu Tao",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.07221"
  },
  {
    "id": "arXiv:2112.07222",
    "title": "Meta-CPR: Generalize to Unseen Large Number of Agents with Communication  Pattern Recognition Module",
    "abstract": "Designing an effective communication mechanism among agents in reinforcement\nlearning has been a challenging task, especially for real-world applications.\nThe number of agents can grow or an environment sometimes needs to interact\nwith a changing number of agents in real-world scenarios. To this end, a\nmulti-agent framework needs to handle various scenarios of agents, in terms of\nboth scales and dynamics, for being practical to real-world applications. We\nformulate the multi-agent environment with a different number of agents as a\nmulti-tasking problem and propose a meta reinforcement learning (meta-RL)\nframework to tackle this problem. The proposed framework employs a meta-learned\nCommunication Pattern Recognition (CPR) module to identify communication\nbehavior and extract information that facilitates the training process.\nExperimental results are poised to demonstrate that the proposed framework (a)\ngeneralizes to an unseen larger number of agents and (b) allows the number of\nagents to change between episodes. The ablation study is also provided to\nreason the proposed CPR design and show such design is effective.",
    "descriptor": "",
    "authors": [
      "Wei-Cheng Tseng",
      "Wei Wei",
      "Da-Chen Juan",
      "Min Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.07222"
  },
  {
    "id": "arXiv:2112.07224",
    "title": "Exploring Category-correlated Feature for Few-shot Image Classification",
    "abstract": "Few-shot classification aims to adapt classifiers to novel classes with a few\ntraining samples. However, the insufficiency of training data may cause a\nbiased estimation of feature distribution in a certain class. To alleviate this\nproblem, we present a simple yet effective feature rectification method by\nexploring the category correlation between novel and base classes as the prior\nknowledge. We explicitly capture such correlation by mapping features into a\nlatent vector with dimension matching the number of base classes, treating it\nas the logarithm probability of the feature over base classes. Based on this\nlatent vector, the rectified feature is directly constructed by a decoder,\nwhich we expect maintaining category-related information while removing other\nstochastic factors, and consequently being closer to its class centroid.\nFurthermore, by changing the temperature value in softmax, we can re-balance\nthe feature rectification and reconstruction for better performance. Our method\nis generic, flexible and agnostic to any feature extractor and classifier,\nreadily to be embedded into existing FSL approaches. Experiments verify that\nour method is capable of rectifying biased features, especially when the\nfeature is far from the class centroid. The proposed approach consistently\nobtains considerable performance gains on three widely used benchmarks,\nevaluated with different backbones and classifiers.\nThe code will be made public.",
    "descriptor": "\nComments: 10 pages, 9 figures\n",
    "authors": [
      "Jing Xu",
      "Xinglin Pan",
      "Xu Luo",
      "Wenjie Pei",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07224"
  },
  {
    "id": "arXiv:2112.07225",
    "title": "Margin Calibration for Long-Tailed Visual Recognition",
    "abstract": "The long-tailed class distribution in visual recognition tasks poses great\nchallenges for neural networks on how to handle the biased predictions between\nhead and tail classes, i.e., the model tends to classify tail classes as head\nclasses. While existing research focused on data resampling and loss function\nengineering, in this paper, we take a different perspective: the classification\nmargins. We study the relationship between the margins and logits\n(classification scores) and empirically observe the biased margins and the\nbiased logits are positively correlated. We propose MARC, a simple yet\neffective MARgin Calibration function to dynamically calibrate the biased\nmargins for unbiased logits. We validate MARC through extensive experiments on\ncommon long-tailed benchmarks including CIFAR-LT, ImageNet-LT, Places-LT, and\niNaturalist-LT. Experimental results demonstrate that our MARC achieves\nfavorable results on these benchmarks. In addition, MARC is extremely easy to\nimplement with just three lines of code. We hope this simple method will\nmotivate people to rethink the biased margins and biased logits in long-tailed\nvisual recognition.",
    "descriptor": "\nComments: Technical report; 9 pages\n",
    "authors": [
      "Yidong Wang",
      "Bowen Zhang",
      "Wenxin Hou",
      "Zhen Wu",
      "Jindong Wang",
      "Takahiro Shinozaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07225"
  },
  {
    "id": "arXiv:2112.07227",
    "title": "Unsupervised feature selection via self-paced learning and low-redundant  regularization",
    "abstract": "Much more attention has been paid to unsupervised feature selection nowadays\ndue to the emergence of massive unlabeled data. The distribution of samples and\nthe latent effect of training a learning method using samples in more effective\norder need to be considered so as to improve the robustness of the method.\nSelf-paced learning is an effective method considering the training order of\nsamples. In this study, an unsupervised feature selection is proposed by\nintegrating the framework of self-paced learning and subspace learning.\nMoreover, the local manifold structure is preserved and the redundancy of\nfeatures is constrained by two regularization terms. $L_{2,1/2}$-norm is\napplied to the projection matrix, which aims to retain discriminative features\nand further alleviate the effect of noise in the data. Then, an iterative\nmethod is presented to solve the optimization problem. The convergence of the\nmethod is proved theoretically and experimentally. The proposed method is\ncompared with other state of the art algorithms on nine real-world datasets.\nThe experimental results show that the proposed method can improve the\nperformance of clustering methods and outperform other compared algorithms.",
    "descriptor": "",
    "authors": [
      "Weiyi Li",
      "Hongmei Chen",
      "Tianrui Li",
      "Jihong Wan",
      "Binbin Sang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07227"
  },
  {
    "id": "arXiv:2112.07228",
    "title": "Online Matching with High Probability",
    "abstract": "We study the classical, randomized Ranking algorithm which is known to be $(1\n- \\frac{1}{e})$-competitive in expectation for the Online Bipartite Matching\nProblem. We give a tail inequality bound, namely that Ranking is $(1 -\n\\frac{1}{e} - \\alpha)$-competitive with probability at least $1 - e^{-2\n\\alpha^2 n}$ where $n$ is the size of the maximum matching in the instance.\nBuilding on this, we show similar concentration results for the Fully Online\nMatching Problem and for the Online Vertex-Weighted Bipartite Matching Problem.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Milena Mihail",
      "Thorben Tr\u00f6bst"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.07228"
  },
  {
    "id": "arXiv:2112.07230",
    "title": "Do you trust experts on Twitter?: Successful correction of  COVID-19-related misinformation",
    "abstract": "This study focuses on how scientifically-correct information is disseminated\nthrough social media, and how misinformation can be corrected. We have\nidentified examples on Twitter where scientific terms that have been misused\nhave been rectified and replaced by scientifically-correct terms through the\ninteraction of users. The results show that the percentage of correct terms\n(\"variant\" or \"COVID-19 variant\") being used instead of the incorrect terms\n(\"strain\") on Twitter has already increased since the end of December 2020.\nThis was about a month before the release of an official statement by the\nJapanese Association for Infectious Diseases regarding the correct terminology,\nand the use of terms on social media was faster than it was in television. Some\nTwitter users who quickly started using the correct term were more likely to\nretweet messages sent by leading influencers on Twitter, rather than messages\nsent by traditional media or portal sites. However, a few Twitter users\ncontinued to use wrong terms even after March 2021, even though the use of the\ncorrect terms was widespread. Further analysis of their tweets revealed that\nthey were quoting sources that differed from that of other users. This study\nempirically verified that self-correction occurs even on Twitter, which is\noften known as a \"hotbed for spreading rumors.\" The results of this study also\nsuggest that influencers with expertise can influence the direction of public\nopinion on social media and that the media that users usually cite can also\naffect the possibility of behavioral changes.",
    "descriptor": "\nComments: The 20th IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT '21)\n",
    "authors": [
      "Dongwoo Lim",
      "Fujio Toriumi",
      "Mitsuo Yoshida"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2112.07230"
  },
  {
    "id": "arXiv:2112.07236",
    "title": "Logics in fungal mycelium networks",
    "abstract": "The living mycelium networks are capable of efficient sensorial fusion over\nvery large areas and distributed decision making. The information processing in\nthe mycelium networks is implemented via propagation of electrical and chemical\nsignals en pair with morphological changes in the mycelium structure. These\ninformation processing mechanisms are manifested in experimental laboratory\nfindings that show that the mycelium networks exhibit rich dynamics of\nneuron-like spiking behaviour and a wide range of non-linear electrical\nproperties. On an example of a single real colony of \\emph{Aspergillus niger},\nwe demonstrate that the non-linear transformation of electrical signals and\ntrains of extracellular voltage spikes can be used to implement logical gates\nand circuits. The approaches adopted include numerical modelling of excitation\npropagation on the mycelium network, representation of the mycelium network as\na resistive and capacitive (RC) network and an experimental laboratory study on\nmining logical circuits in mycelium bound composites.",
    "descriptor": "\nComments: To be published in special issue of Logica Universalis --- \"Logic, Spatial Algorithms and Visual Reasoning\", edited by Andrew Schumann and Jerzy Kr\\'{o}l, 2022\n",
    "authors": [
      "Andrew Adamatzky",
      "Phil Ayres",
      "Alexander E. Beasley",
      "Nic Roberts",
      "Martin Tegelaar",
      "Michail-Antisthenis Tsompanas",
      "Han A. B. W\u00f6sten"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.07236"
  },
  {
    "id": "arXiv:2112.07238",
    "title": "Composing MPC with LQR and Neural Networks for Efficient and Stable  Control",
    "abstract": "Model predictive control (MPC) is a powerful control method that handles\ndynamical systems with constraints. However, solving MPC iteratively in real\ntime, i.e., implicit MPC, has been a challenge for 1) systems with low-latency\nrequirements, 2) systems with limited computational resources, and 3) systems\nwith fast and complex dynamics. To address this challenge, for low-dimensional\nlinear systems, a classical approach is explicit MPC; for high-dimensional or\nnonlinear systems, a common approach is function approximation using neural\nnetworks. Both methods, whenever applicable, may improve the computational\nefficiency of the original MPC by several orders of magnitude. The existing\nmethods have the following disadvantages: 1) explicit MPC does not apply to\nhigher-dimensional problems or most of the problems with nonlinear constraints;\nand 2) function approximation is not guaranteed to find an accurate surrogate\npolicy, the failure of which may lead to closed-loop instability. To address\nthese issues, we propose a triple-mode hybrid control scheme, named\nMemory-Augmented MPC, by combining an efficient linear quadratic regulator, an\nefficient neural network, and a costly, fail-safe MPC. From its standard form,\nwe derive two variants of such hybrid control scheme: one customized for\nchaotic systems and the other for slow systems. We prove stability of the\ncontrol scheme with any arbitrary neural networks and test its computational\nperformance in simulated numerical experiments.",
    "descriptor": "",
    "authors": [
      "Fangyu Wu",
      "Guanhua Wang",
      "Siyuan Zhuang",
      "Kehan Wang",
      "Alexander Keimer",
      "Ion Stoica",
      "Alexandre Bayen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07238"
  },
  {
    "id": "arXiv:2112.07239",
    "title": "Compensating trajectory bias for unsupervised patient stratification  using adversarial recurrent neural networks",
    "abstract": "Electronic healthcare records are an important source of information which\ncan be used in patient stratification to discover novel disease phenotypes.\nHowever, they can be challenging to work with as data is often sparse and\nirregularly sampled. One approach to solve these limitations is learning dense\nembeddings that represent individual patient trajectories using a recurrent\nneural network autoencoder (RNN-AE). This process can be susceptible to\nunwanted data biases. We show that patient embeddings and clusters using\npreviously proposed RNN-AE models might be impacted by a trajectory bias,\nmeaning that results are dominated by the amount of data contained in each\npatients trajectory, instead of clinically relevant details. We investigate\nthis bias on 2 datasets (from different hospitals) and 2 disease areas as well\nas using different parts of the patient trajectory. Our results using 2\npreviously published baseline methods indicate a particularly strong bias in\ncase of an event-to-end trajectory. We present a method that can overcome this\nissue using an adversarial training scheme on top of a RNN-AE. Our results show\nthat our approach can reduce the trajectory bias in all cases.",
    "descriptor": "",
    "authors": [
      "Avelino Javer",
      "Owen Parsons",
      "Oliver Carr",
      "Janie Baxter",
      "Christian Diedrich",
      "Eren El\u00e7i",
      "Steffen Schaper",
      "Katrin Coboeken",
      "Robert D\u00fcrichen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07239"
  },
  {
    "id": "arXiv:2112.07241",
    "title": "Static-Dynamic Co-Teaching for Class-Incremental 3D Object Detection",
    "abstract": "Deep learning-based approaches have shown remarkable performance in the 3D\nobject detection task. However, they suffer from a catastrophic performance\ndrop on the originally trained classes when incrementally learning new classes\nwithout revisiting the old data. This \"catastrophic forgetting\" phenomenon\nimpedes the deployment of 3D object detection approaches in real-world\nscenarios, where continuous learning systems are needed. In this paper, we\nstudy the unexplored yet important class-incremental 3D object detection\nproblem and present the first solution - SDCoT, a novel static-dynamic\nco-teaching method. Our SDCoT alleviates the catastrophic forgetting of old\nclasses via a static teacher, which provides pseudo annotations for old classes\nin the new samples and regularizes the current model by extracting previous\nknowledge with a distillation loss. At the same time, SDCoT consistently learns\nthe underlying knowledge from new data via a dynamic teacher. We conduct\nextensive experiments on two benchmark datasets and demonstrate the superior\nperformance of our SDCoT over baseline approaches in several incremental\nlearning scenarios.",
    "descriptor": "\nComments: Accepted at AAAI 2022\n",
    "authors": [
      "Na Zhao",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07241"
  },
  {
    "id": "arXiv:2112.07242",
    "title": "On the Impact of Channel Estimation on the Design and Analysis of IRSA  based Systems",
    "abstract": "Irregular repetition slotted aloha (IRSA) is a distributed grant-free random\naccess protocol where users transmit multiple replicas of their packets to a\nbase station (BS). The BS recovers the packets using successive interference\ncancellation. In this paper, we first derive channel estimates for IRSA,\nexploiting the sparsity structure of IRSA transmissions, when non-orthogonal\npilots are employed across users to facilitate channel estimation at the BS.\nAllowing for the use of non-orthogonal pilots is important, as the length of\northogonal pilots scales linearly with the total number of devices, leading to\nprohibitive overhead as the number of devices increases. Next, we present a\nnovel analysis of the throughput of IRSA under practical channel estimation\nerrors, with the use of multiple antennas at the BS. Finally, we theoretically\ncharacterize the asymptotic throughput performance of IRSA using a density\nevolution based analysis. Simulation results underline the importance of\naccounting for channel estimation errors in analyzing IRSA, which can even lead\nto 70% loss in performance in severely interference-limited regimes. We also\nprovide novel insights on the effect of parameters such as pilot length, SNR,\nnumber of antennas at the BS, etc, on the system throughput.",
    "descriptor": "\nComments: 16 pages, 11 figures\n",
    "authors": [
      "Chirag Ramesh Srivatsa",
      "Chandra R. Murthy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.07242"
  },
  {
    "id": "arXiv:2112.07244",
    "title": "Progressive Feature Transmission for Split Inference at the Wireless  Edge",
    "abstract": "In edge inference, an edge server provides remote-inference services to edge\ndevices. This requires the edge devices to upload high-dimensional features of\ndata samples over resource-constrained wireless channels, which creates a\ncommunication bottleneck. The conventional solution of feature pruning requires\nthat the device has access to the inference model, which is unavailable in the\ncurrent scenario of split inference. To address this issue, we propose the\nprogressive feature transmission (ProgressFTX) protocol, which minimizes the\noverhead by progressively transmitting features until a target confidence level\nis reached. The optimal control policy of the protocol to accelerate inference\nis derived and it comprises two key operations. The first is importance-aware\nfeature selection at the server, for which it is shown to be optimal to select\nthe most important features, characterized by the largest discriminant gains of\nthe corresponding feature dimensions. The second is transmission-termination\ncontrol by the server for which the optimal policy is shown to exhibit a\nthreshold structure. Specifically, the transmission is stopped when the\nincremental uncertainty reduction by further feature transmission is outweighed\nby its communication cost. The indices of the selected features and\ntransmission decision are fed back to the device in each slot. The optimal\npolicy is first derived for the tractable case of linear classification and\nthen extended to the more complex case of classification using a convolutional\nneural network. Both Gaussian and fading channels are considered. Experimental\nresults are obtained for both a statistical data model and a real dataset. It\nis seen that ProgressFTX can substantially reduce the communication latency\ncompared to conventional feature pruning and random feature transmission.",
    "descriptor": "",
    "authors": [
      "Qiao Lan",
      "Qunsong Zeng",
      "Petar Popovski",
      "Deniz G\u00fcnd\u00fcz",
      "Kaibin Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.07244"
  },
  {
    "id": "arXiv:2112.07246",
    "title": "Federated Learning for Face Recognition with Gradient Correction",
    "abstract": "With increasing appealing to privacy issues in face recognition, federated\nlearning has emerged as one of the most prevalent approaches to study the\nunconstrained face recognition problem with private decentralized data.\nHowever, conventional decentralized federated algorithm sharing whole\nparameters of networks among clients suffers from privacy leakage in face\nrecognition scene. In this work, we introduce a framework, FedGC, to tackle\nfederated learning for face recognition and guarantees higher privacy. We\nexplore a novel idea of correcting gradients from the perspective of backward\npropagation and propose a softmax-based regularizer to correct gradients of\nclass embeddings by precisely injecting a cross-client gradient term.\nTheoretically, we show that FedGC constitutes a valid loss function similar to\nstandard softmax. Extensive experiments have been conducted to validate the\nsuperiority of FedGC which can match the performance of conventional\ncentralized methods utilizing full training dataset on several popular\nbenchmark datasets.",
    "descriptor": "\nComments: accepted by AAAI2022\n",
    "authors": [
      "Yifan Niu",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07246"
  },
  {
    "id": "arXiv:2112.07255",
    "title": "Mechanism Design without Money for Fair Allocations",
    "abstract": "Fairness is well studied in the context of resource allocation. Researchers\nhave proposed various fairness notions like envy-freeness (EF), and its\nrelaxations, proportionality and max-min share (MMS). There is vast literature\non the existential and computational aspects of such notions. While computing\nfair allocations, any algorithm assumes agents' truthful reporting of their\nvaluations towards the resources. Whereas in real-world web-based applications\nfor fair division, the agents involved are strategic and may manipulate for\nindividual utility gain. In this paper, we study strategy-proof mechanisms\nwithout monetary transfer, which satisfies the various fairness criteria.\nWe know that for additive valuations, designing truthful mechanisms for EF,\nMMS and proportionality is impossible. Here we show that there cannot be a\ntruthful mechanism for EFX and the existing algorithms for EF1 are manipulable.\nWe then study the particular case of single-minded agents. For this case, we\nprovide a Serial Dictatorship Mechanism that is strategy-proof and satisfies\nall the fairness criteria except EF.",
    "descriptor": "",
    "authors": [
      "Manisha Padala",
      "Sujit Gujar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.07255"
  },
  {
    "id": "arXiv:2112.07259",
    "title": "TopNet: Learning from Neural Topic Model to Generate Long Stories",
    "abstract": "Long story generation (LSG) is one of the coveted goals in natural language\nprocessing. Different from most text generation tasks, LSG requires to output a\nlong story of rich content based on a much shorter text input, and often\nsuffers from information sparsity. In this paper, we propose \\emph{TopNet} to\nalleviate this problem, by leveraging the recent advances in neural topic\nmodeling to obtain high-quality skeleton words to complement the short input.\nIn particular, instead of directly generating a story, we first learn to map\nthe short text input to a low-dimensional topic distribution (which is\npre-assigned by a topic model). Based on this latent topic distribution, we can\nuse the reconstruction decoder of the topic model to sample a sequence of\ninter-related words as a skeleton for the story. Experiments on two benchmark\ndatasets show that our proposed framework is highly effective in skeleton word\nselection and significantly outperforms the state-of-the-art models in both\nautomatic evaluation and human evaluation.",
    "descriptor": "\nComments: KDD2021, 9 pages\n",
    "authors": [
      "Yazheng Yang",
      "Boyuan Pan",
      "Deng Cai",
      "Huan Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07259"
  },
  {
    "id": "arXiv:2112.07263",
    "title": "Quantifying Multimodality in World Models",
    "abstract": "Model-based Deep Reinforcement Learning (RL) assumes the availability of a\nmodel of an environment's underlying transition dynamics. This model can be\nused to predict future effects of an agent's possible actions. When no such\nmodel is available, it is possible to learn an approximation of the real\nenvironment, e.g. by using generative neural networks, sometimes also called\nWorld Models. As most real-world environments are stochastic in nature and the\ntransition dynamics are oftentimes multimodal, it is important to use a\nmodelling technique that is able to reflect this multimodal uncertainty. In\norder to safely deploy such learning systems in the real world, especially in\nan industrial context, it is paramount to consider these uncertainties. In this\nwork, we analyze existing and propose new metrics for the detection and\nquantification of multimodal uncertainty in RL based World Models. The correct\nmodelling & detection of uncertain future states lays the foundation for\nhandling critical situations in a safe way, which is a prerequisite for\ndeploying RL systems in real-world settings.",
    "descriptor": "",
    "authors": [
      "Andreas Sedlmeier",
      "Michael K\u00f6lle",
      "Robert M\u00fcller",
      "Leo Baudrexel",
      "Claudia Linnhoff-Popien"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07263"
  },
  {
    "id": "arXiv:2112.07269",
    "title": "MCDS: AI Augmented Workflow Scheduling in Mobile Edge Cloud Computing  Systems",
    "abstract": "Workflow scheduling is a long-studied problem in parallel and distributed\ncomputing (PDC), aiming to efficiently utilize compute resources to meet user's\nservice requirements. Recently proposed scheduling methods leverage the low\nresponse times of edge computing platforms to optimize application Quality of\nService (QoS). However, scheduling workflow applications in mobile edge-cloud\nsystems is challenging due to computational heterogeneity, changing latencies\nof mobile devices and the volatile nature of workload resource requirements. To\novercome these difficulties, it is essential, but at the same time challenging,\nto develop a long-sighted optimization scheme that efficiently models the QoS\nobjectives. In this work, we propose MCDS: Monte Carlo Learning using Deep\nSurrogate Models to efficiently schedule workflow applications in mobile\nedge-cloud computing systems. MCDS is an Artificial Intelligence (AI) based\nscheduling approach that uses a tree-based search strategy and a deep neural\nnetwork-based surrogate model to estimate the long-term QoS impact of immediate\nactions for robust optimization of scheduling decisions. Experiments on\nphysical and simulated edge-cloud testbeds show that MCDS can improve over the\nstate-of-the-art methods in terms of energy consumption, response time, SLA\nviolations and cost by at least 6.13, 4.56, 45.09 and 30.71 percent\nrespectively.",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Parallel and Distributed Systems (Special Issue on PDC for AI), 2022\n",
    "authors": [
      "Shreshth Tuli",
      "Giuliano Casale",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.07269"
  },
  {
    "id": "arXiv:2112.07270",
    "title": "Bilateral Cross-Modality Graph Matching Attention for Feature Fusion in  Visual Question Answering",
    "abstract": "Answering semantically-complicated questions according to an image is\nchallenging in Visual Question Answering (VQA) task. Although the image can be\nwell represented by deep learning, the question is always simply embedded and\ncannot well indicate its meaning. Besides, the visual and textual features have\na gap for different modalities, it is difficult to align and utilize the\ncross-modality information. In this paper, we focus on these two problems and\npropose a Graph Matching Attention (GMA) network. Firstly, it not only builds\ngraph for the image, but also constructs graph for the question in terms of\nboth syntactic and embedding information. Next, we explore the intra-modality\nrelationships by a dual-stage graph encoder and then present a bilateral\ncross-modality graph matching attention to infer the relationships between the\nimage and the question. The updated cross-modality features are then sent into\nthe answer prediction module for final answer prediction. Experiments\ndemonstrate that our network achieves state-of-the-art performance on the GQA\ndataset and the VQA 2.0 dataset. The ablation studies verify the effectiveness\nof each modules in our GMA network.",
    "descriptor": "\nComments: pre-print, TNNLS, 12 pages\n",
    "authors": [
      "JianJian Cao",
      "Xiameng Qin",
      "Sanyuan Zhao",
      "Jianbing Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07270"
  },
  {
    "id": "arXiv:2112.07279",
    "title": "The Interaction between Inputs and Configurations fed to Software  Systems: an Empirical Study",
    "abstract": "Widely used software systems such as video encoders are by necessity highly\nconfigurable, with hundreds or even thousands of options to choose from. Their\nusers often have a hard time finding suitable values for these options (i.e.\nfinding a proper configuration of the software system) to meet their goals for\nthe tasks at hand, e.g. compress a video down to a certain size. One dimension\nof the problem is of course that performance depends on the input data: a video\nas input to an encoder like x264 or a file system fed to a tool like xz. To\nachieve good performance, users should therefore take into account both\ndimensions of (1) software variability and (2) input data. In this\nproblem-statement paper, we conduct a large study over 8 configurable systems\nthat quantifies the existing interactions between input data and configurations\nof software systems. The results exhibit that (1) inputs fed to software\nsystems interact with their configuration options in non monotonous ways,\nsignificantly impacting their performance properties (2) tuning a software\nsystem for its input data makes it possible to multiply its performance by up\nto ten (3) input variability can jeopardize the relevance of performance\npredictive models for a field deployment.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Luc Lesoil",
      "Mathieu Acher",
      "Arnaud Blouin",
      "Jean-Marc J\u00e9z\u00e9quel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.07279"
  },
  {
    "id": "arXiv:2112.07282",
    "title": "SNF: Filter Pruning via Searching the Proper Number of Filters",
    "abstract": "Convolutional Neural Network (CNN) has an amount of parameter redundancy,\nfilter pruning aims to remove the redundant filters and provides the\npossibility for the application of CNN on terminal devices. However, previous\nworks pay more attention to designing evaluation criteria of filter importance\nand then prune less important filters with a fixed pruning rate or a fixed\nnumber to reduce convolutional neural networks' redundancy. It does not\nconsider how many filters to reserve for each layer is the most reasonable\nchoice. From this perspective, we propose a new filter pruning method by\nsearching the proper number of filters (SNF). SNF is dedicated to searching for\nthe most reasonable number of reserved filters for each layer and then pruning\nfilters with specific criteria. It can tailor the most suitable network\nstructure at different FLOPs. Filter pruning with our method leads to the\nstate-of-the-art (SOTA) accuracy on CIFAR-10 and achieves competitive\nperformance on ImageNet ILSVRC-2012.SNF based on the ResNet-56 network achieves\nan increase of 0.14% in Top-1 accuracy at 52.94% FLOPs reduction on CIFAR-10.\nPruning ResNet-110 on CIFAR-10 also improves the Top-1 accuracy of 0.03% when\nreducing 68.68% FLOPs. For ImageNet, we set the pruning rates as 52.10% FLOPs,\nand the Top-1 accuracy only has a drop of 0.74%. The codes can be available at\nhttps://github.com/pk-l/SNF.",
    "descriptor": "",
    "authors": [
      "Pengkun Liu",
      "Yaru Yue",
      "Yanjun Guo",
      "Xingxiang Tao",
      "Xiaoguang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07282"
  },
  {
    "id": "arXiv:2112.07285",
    "title": "Automatic COVID-19 disease diagnosis using 1D convolutional neural  network and augmentation with human respiratory sound based on parameters:  cough, breath, and voice",
    "abstract": "The issue in respiratory sound classification has attained good attention\nfrom the clinical scientists and medical researcher's group in the last year to\ndiagnosing COVID-19 disease. To date, various models of Artificial Intelligence\n(AI) entered into the real-world to detect the COVID-19 disease from\nhuman-generated sounds such as voice/speech, cough, and breath. The\nConvolutional Neural Network (CNN) model is implemented for solving a lot of\nreal-world problems on machines based on Artificial Intelligence (AI). In this\ncontext, one dimension (1D) CNN is suggested and implemented to diagnose\nrespiratory diseases of COVID-19 from human respiratory sounds such as a voice,\ncough, and breath. An augmentation-based mechanism is applied to improve the\npreprocessing performance of the COVID-19 sounds dataset and to automate\nCOVID-19 disease diagnosis using the 1D convolutional network. Furthermore, a\nDDAE (Data De-noising Auto Encoder) technique is used to generate deep sound\nfeatures such as the input function to the 1D CNN instead of adopting the\nstandard input of MFCC (Mel-frequency cepstral coefficient), and it is\nperformed better accuracy and performance than previous models.",
    "descriptor": "",
    "authors": [
      "Kranthi Kumar Lella",
      "Alphonse Pja"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.07285"
  },
  {
    "id": "arXiv:2112.07286",
    "title": "Levels of Autonomous Radiology",
    "abstract": "Radiology, being one of the younger disciplines of medicine with a history of\njust over a century, has witnessed tremendous technological advancements and\nhas revolutionized the way we practice medicine today. In the last few decades,\nmedical imaging modalities have generated seismic amounts of medical data. The\ndevelopment and adoption of Artificial Intelligence (AI) applications using\nthis data will lead to the next phase of evolution in radiology. It will\ninclude automating laborious manual tasks such as annotations,\nreport-generation, etc., along with the initial radiological assessment of\ncases to aid radiologists in their evaluation workflow. We propose a level-wise\nclassification for the progression of automation in radiology, explaining AI\nassistance at each level with corresponding challenges and solutions. We hope\nthat such discussions can help us address the challenges in a structured way\nand take the necessary steps to ensure the smooth adoption of new technologies\nin radiology.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Suraj Ghuwalewala",
      "Viraj Kulkarni",
      "Richa Pant",
      "Amit Kharat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07286"
  },
  {
    "id": "arXiv:2112.07289",
    "title": "Why you should learn functional basis",
    "abstract": "Efficient and practical representation of geometric data is a ubiquitous\nproblem for several applications in geometry processing. A widely used choice\nis to encode the 3D objects through their spectral embedding, associating to\neach surface point the values assumed at that point by a truncated subset of\nthe eigenfunctions of a differential operator (typically the Laplacian).\nSeveral attempts to define new, preferable embeddings for different\napplications have seen the light during the last decade. Still, the standard\nLaplacian eigenfunctions remain solidly at the top of the available solutions,\ndespite their limitations, such as being limited to near-isometries for shape\nmatching. Recently, a new trend shows advantages in learning substitutes for\nthe Laplacian eigenfunctions. At the same time, many research questions remain\nunsolved: are the new bases better than the LBO eigenfunctions, and how do they\nrelate to them? How do they act in the functional perspective? And how to\nexploit these bases in new configurations in conjunction with additional\nfeatures and descriptors? In this study, we properly pose these questions to\nimprove our understanding of this emerging research direction. We show their\napplicative relevance in different contexts revealing some of their insights\nand exciting future directions.",
    "descriptor": "",
    "authors": [
      "Riccardo Marin",
      "Souhaib Attaiki",
      "Simone Melzi",
      "Emanuele Rodol\u00e0",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07289"
  },
  {
    "id": "arXiv:2112.07292",
    "title": "Verifying a Minimalist Reverse-Mode AD Library",
    "abstract": "By exploiting a number of relatively subtle programming language features,\nincluding dynamically-allocated mutable state, first-class functions, and\neffect handlers, reverse-mode automatic differentiation can be implemented as a\nlibrary. One outstanding question, however, is: with which logical tools can\none specify what this code is expected to compute and verify that it behaves as\nexpected? We answer this question by using a modern variant of Separation Logic\nto specify and verify a minimalist (but concise and elegant) reverse-mode\nautomatic differentiation library. We view this result as an advanced exercise\nin program verification, with potential future applications to more realistic\nautomatic differentiation systems.",
    "descriptor": "",
    "authors": [
      "Paulo Em\u00edlio de Vilhena",
      "Fran\u00e7ois Pottier"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.07292"
  },
  {
    "id": "arXiv:2112.07303",
    "title": "MMO: Meta Multi-Objectivization for Software Configuration Tuning",
    "abstract": "Software configuration tuning is essential for optimizing a given performance\nobjective (e.g., minimizing latency). Yet, due to the software's intrinsically\ncomplex configuration landscape and expensive measurement, there has been a\nrather mild success, particularly in preventing the search from being trapped\nin local optima. To address this issue, in this paper we take a different\nperspective. Instead of focusing on improving the optimizer, we work on the\nlevel of optimization model and propose a meta multi-objectivization (MMO)\nmodel that considers an auxiliary performance objective (e.g., throughput in\naddition to latency). What makes this model unique is that we do not optimize\nthe auxiliary performance objective, but rather use it to make\nsimilarly-performing while different configurations less comparable (i.e.\nPareto nondominated to each other), thus preventing the search from being\ntrapped in local optima. Importantly, we show how to effectively use the MMO\nmodel without worrying about its weight -- the only yet highly sensitive\nparameter that can affect its effectiveness. Experiments on 22 cases from 11\nreal-world software systems/environments confirm that our MMO model with the\nnew normalization performs better than its state-of-the-art single-objective\ncounterparts on 82% cases while achieving up to 2.09x speedup. For 67% of the\ncases, the new normalization also enables the MMO model to outperform the\ninstance when using it with the normalization used in our prior FSE work under\npre-tuned best weights, saving a great amount of resources which would be\notherwise necessary to find a good weight. We also demonstrate that the MMO\nmodel with the new normalization can consolidate Flash, a recent model-based\ntuning tool, on 68% of the cases with 1.22x speedup in general.",
    "descriptor": "\nComments: 12 figures, 5 tables. arXiv admin note: text overlap with arXiv:2106.01331\n",
    "authors": [
      "Tao Chen",
      "Miqing Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.07303"
  },
  {
    "id": "arXiv:2112.07305",
    "title": "An unfitted finite element method using level set functions for  extrapolation into deformable diffuse interfaces",
    "abstract": "We explore a new way to handle flux boundary conditions imposed on level\nsets. The proposed approach is a diffuse interface version of the shifted\nboundary method (SBM) for continuous Galerkin discretizations of conservation\nlaws in embedded domains. We impose the interface conditions weakly and\napproximate surface integrals by volume integrals. The discretized weak form of\nthe governing equation has the structure of an immersed boundary finite element\nmethod. A ghost penalty term is included to extend the weak solution into the\nexternal subdomain. The calculation of interface forcing terms requires (i)\nconstruction of an approximate delta function and (ii) extrapolation of\nembedded boundary data into quadrature points. We accomplish these tasks using\na level set function, which is given analytically or evolved numerically. A\nglobally defined averaged gradient of this approximate signed distance function\nis used to construct a simple map to the closest point on the interface. The\nnormal and tangential derivatives of the numerical solution at that point are\ncalculated using the interface conditions and/or interpolation on uniform\nstencils. Similarly to SBM, extrapolation back to the quadrature points is\nperformed using Taylor expansions. The same strategy is used to construct ghost\npenalty functions and extension velocities. Computations that require\nextrapolation are restricted to a narrow band around the interface. Numerical\nresults are presented for elliptic, parabolic, and hyperbolic test problems,\nwhich are specifically designed to assess the error caused by the numerical\ntreatment of interface conditions on fixed and moving boundaries in 2D.",
    "descriptor": "",
    "authors": [
      "Dmitri Kuzmin",
      "Jan-Phillip B\u00e4cker"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07305"
  },
  {
    "id": "arXiv:2112.07308",
    "title": "Conversational Search with Mixed-Initiative -- Asking Good Clarification  Questions backed-up by Passage Retrieval",
    "abstract": "We deal with a scenario of conversational search with mixed-initiative:\nnamely user-asks system-answers, as well as system-asks (clarification\nquestions) and user-answers. We focus on the task of selecting the next\nclarification question, given conversation context. Our method leverages\npassage retrieval that is used both for an initial selection of relevant\ncandidate clarification questions, as well as for fine-tuning two deep-learning\nmodels for re-ranking these candidates. We evaluated our method on two\ndifferent use-cases. The first is an open domain conversational search in a\nlarge web collection. The second is a task-oriented customer-support setup. We\nshow that our method performs well on both use-cases.",
    "descriptor": "",
    "authors": [
      "Yosi Mass",
      "Doron Cohen",
      "Asaf Yehudai",
      "David Konopnicki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07308"
  },
  {
    "id": "arXiv:2112.07313",
    "title": "Autonomous Navigation and Configuration of Integrated Access Backhauling  for UAV Base Station Using Reinforcement Learning",
    "abstract": "Fast and reliable connectivity is essential to enhancing situational\nawareness and operational efficiency for public safety mission-critical (MC)\nusers. In emergency or disaster circumstances, where existing cellular network\ncoverage and capacity may not be available to meet MC communication demands,\ndeployable-network-based solutions such as cells-on-wheels/wings can be\nutilized swiftly to ensure reliable connection for MC users. In this paper, we\nconsider a scenario where a macro base station (BS) is destroyed due to a\nnatural disaster and an unmanned aerial vehicle carrying BS (UAV-BS) is set up\nto provide temporary coverage for users in the disaster area. The UAV-BS is\nintegrated into the mobile network using the 5G integrated access and backhaul\n(IAB) technology. We propose a framework and signalling procedure for applying\nmachine learning to this use case. A deep reinforcement learning algorithm is\ndesigned to jointly optimize the access and backhaul antenna tilt as well as\nthe three-dimensional location of the UAV-BS in order to best serve the\non-ground MC users while maintaining a good backhaul connection. Our result\nshows that the proposed algorithm can autonomously navigate and configure the\nUAV-BS to improve the throughput and reduce the drop rate of MC users.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Hongyi Zhang",
      "Jingya Li",
      "Zhiqiang Qi",
      "Xingqin Lin",
      "Anders Aronsson",
      "Jan Bosch",
      "Helena Holmstr\u00f6m Olsson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07313"
  },
  {
    "id": "arXiv:2112.07315",
    "title": "Kernel-aware Raw Burst Blind Super-Resolution",
    "abstract": "Burst super-resolution (SR) provides a possibility of restoring rich details\nfrom low-quality images. However, since low-resolution (LR) images in practical\napplications have multiple complicated and unknown degradations, existing\nnon-blind (e.g., bicubic) designed networks usually lead to a severe\nperformance drop in recovering high-resolution (HR) images. Moreover, handling\nmultiple misaligned noisy raw inputs is also challenging. In this paper, we\naddress the problem of reconstructing HR images from raw burst sequences\nacquired from modern handheld devices. The central idea is a kernel-guided\nstrategy which can solve the burst SR with two steps: kernel modeling and HR\nrestoring. The former estimates burst kernels from raw inputs, while the latter\npredicts the super-resolved image based on the estimated kernels. Furthermore,\nwe introduce a kernel-aware deformable alignment module which can effectively\nalign the raw images with consideration of the blurry priors. Extensive\nexperiments on synthetic and real-world datasets demonstrate that the proposed\nmethod can perform favorable state-of-the-art performance in the burst SR\nproblem.",
    "descriptor": "",
    "authors": [
      "Wenyi Lian",
      "Shanglian Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07315"
  },
  {
    "id": "arXiv:2112.07320",
    "title": "Sherman: A Write-Optimized Distributed B+Tree Index on Disaggregated  Memory",
    "abstract": "Memory disaggregation architecture physically separates CPU and memory into\nindependent components, which are connected via high-speed RDMA networks,\ngreatly improving resource utilization of databases. However, such an\narchitecture poses unique challenges to data indexing in databases due to\nlimited RDMA semantics and near-zero computation power at memory-side. Existing\nindexes supporting disaggregated memory either suffer from low write\nperformance, or require hardware modification.\nThis paper presents Sherman, a write-optimized distributed B+Tree index on\ndisaggregated memory that delivers high performance with commodity RDMA NICs.\nSherman combines RDMA hardware features and RDMA-friendly software techniques\nto boost index write performance from three angles. First, to reduce round\ntrips, Sherman coalesces dependent RDMA commands by leveraging in-order\ndelivery property of RDMA. Second, to accelerate concurrent accesses, Sherman\nintroduces a hierarchical lock that exploits on-chip memory of RDMA NICs.\nFinally, to mitigate write amplification, Sherman tailors the data structure\nlayout of B+Tree with a two-level version mechanism. Our evaluation shows that,\nSherman is one order of magnitude faster in terms of both throughput and 99th\npercentile latency on typical write-intensive workloads, compared with\nstate-of-the-art designs.",
    "descriptor": "\nComments: accepted to SIGMOD'22\n",
    "authors": [
      "Qing Wang",
      "Youyou Lu",
      "Jiwu Shu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.07320"
  },
  {
    "id": "arXiv:2112.07322",
    "title": "Right-hand side decoding of Gabidulin code and applications",
    "abstract": "We discuss the decoding of Gabidulin and interleaved Gabidulin codes. We give\nthe full presentation of a decoding algorithm for Gabidulin codes, which as\nLoidreau's seminal algorithm consists in localizing errors in the spirit of\nBerlekamp-Welch algorithm for Reed-Solomon codes. On the other hand, this\nalgorithm consists in acting on codewords on the right while Loidreau's\nalgorithm considers an action on the left. This right-hand side decoder was\nalready introduced by the authors in a previous work for cryptanalytic\napplications. We give here a generalised version which applies to the case of\nnon-full length Gabidulin codes. Finally, we show that this algorithm turns out\nto provide a very clear and natural approach for the decoding of interleaved\nGabidulin codes.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Maxime Bombar",
      "Alain Couvreur"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.07322"
  },
  {
    "id": "arXiv:2112.07323",
    "title": "Experimental Data-Driven Model Predictive Control of a Hospital HVAC  System During Regular Use",
    "abstract": "Herein we report a multi-zone, heating, ventilation and air-conditioning\n(HVAC) control case study of an industrial plant responsible for cooling a\nhospital surgery center. The adopted approach to guaranteeing thermal comfort\nand reducing electrical energy consumption is based on a statistical\nnon-parametric, non-linear regression technique named Gaussian processes. Our\nstudy aimed at assessing the suitability of the aforementioned technique to\nlearning the building dynamics and yielding models for our model predictive\ncontrol (MPC) scheme. Experimental results gathered while the building was\nunder regular use showcase the final controller performance while subject to a\nnumber of measured and unmeasured disturbances. Finally, we provide readers\nwith practical details and recommendations on how to manage the computational\ncomplexity of the on-line optimization problem and obtain high-quality\nsolutions from solvers.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Emilio T. Maddalena",
      "Silvio A. Muller",
      "Rafael M. dos Santos",
      "Christophe Salzmann",
      "Colin N. Jones"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07323"
  },
  {
    "id": "arXiv:2112.07324",
    "title": "On the Impact of Hard Adversarial Instances on Overfitting in  Adversarial Training",
    "abstract": "Adversarial training is a popular method to robustify models against\nadversarial attacks. However, it exhibits much more severe overfitting than\ntraining on clean inputs. In this work, we investigate this phenomenon from the\nperspective of training instances, i.e., training input-target pairs. Based on\na quantitative metric measuring instances' difficulty, we analyze the model's\nbehavior on training instances of different difficulty levels. This lets us\nshow that the decay in generalization performance of adversarial training is a\nresult of the model's attempt to fit hard adversarial instances. We\ntheoretically verify our observations for both linear and general nonlinear\nmodels, proving that models trained on hard instances have worse generalization\nperformance than ones trained on easy instances. Furthermore, we prove that the\ndifference in the generalization gap between models trained by instances of\ndifferent difficulty levels increases with the size of the adversarial budget.\nFinally, we conduct case studies on methods mitigating adversarial overfitting\nin several scenarios. Our analysis shows that methods successfully mitigating\nadversarial overfitting all avoid fitting hard adversarial instances, while\nones fitting hard adversarial instances do not achieve true robustness.",
    "descriptor": "",
    "authors": [
      "Chen Liu",
      "Zhichao Huang",
      "Mathieu Salzmann",
      "Tong Zhang",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07324"
  },
  {
    "id": "arXiv:2112.07327",
    "title": "Model Uncertainty-Aware Knowledge Amalgamation for Pre-Trained Language  Models",
    "abstract": "As many fine-tuned pre-trained language models~(PLMs) with promising\nperformance are generously released, investigating better ways to reuse these\nmodels is vital as it can greatly reduce the retraining computational cost and\nthe potential environmental side-effects. In this paper, we explore a novel\nmodel reuse paradigm, Knowledge Amalgamation~(KA) for PLMs. Without human\nannotations available, KA aims to merge the knowledge from different\nteacher-PLMs, each of which specializes in a different classification problem,\ninto a versatile student model. The achieve this, we design a Model\nUncertainty--aware Knowledge Amalgamation~(MUKA) framework, which identifies\nthe potential adequate teacher using Monte-Carlo Dropout for approximating the\ngolden supervision to guide the student. Experimental results demonstrate that\nMUKA achieves substantial improvements over baselines on benchmark datasets.\nFurther analysis shows that MUKA can generalize well under several complicate\nsettings with multiple teacher models, heterogeneous teachers, and even\ncross-dataset teachers.",
    "descriptor": "",
    "authors": [
      "Lei Li",
      "Yankai Lin",
      "Xuancheng Ren",
      "Guangxiang Zhao",
      "Peng Li",
      "Jie Zhou",
      "Xu Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07327"
  },
  {
    "id": "arXiv:2112.07328",
    "title": "Biased Gradient Estimate with Drastic Variance Reduction for Meta  Reinforcement Learning",
    "abstract": "Despite the empirical success of meta reinforcement learning (meta-RL), there\nare still a number poorly-understood discrepancies between theory and practice.\nCritically, biased gradient estimates are almost always implemented in\npractice, whereas prior theory on meta-RL only establishes convergence under\nunbiased gradient estimates. In this work, we investigate such a discrepancy.\nIn particular, (1) We show that unbiased gradient estimates have variance\n$\\Theta(N)$ which linearly depends on the sample size $N$ of the inner loop\nupdates; (2) We propose linearized score function (LSF) gradient estimates,\nwhich have bias $\\mathcal{O}(1/\\sqrt{N})$ and variance $\\mathcal{O}(1/N)$; (3)\nWe show that most empirical prior work in fact implements variants of the LSF\ngradient estimates. This implies that practical algorithms \"accidentally\"\nintroduce bias to achieve better performance; (4) We establish theoretical\nguarantees for the LSF gradient estimates in meta-RL regarding its convergence\nto stationary points, showing better dependency on $N$ than prior work when $N$\nis large.",
    "descriptor": "",
    "authors": [
      "Yunhao Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07328"
  },
  {
    "id": "arXiv:2112.07331",
    "title": "Non-Iterative Calculation of Quasi-Dynamic Energy Flow in the Heat and  Electricity Integrated Energy Systems",
    "abstract": "Energy flow calculation plays a vital role in the analysis, operation, and\ncontrol of heat and electricity integrated energy systems (HE-IESs). The\nquasi-dynamic energy flow models of HE-IESs are essentially partial\ndifferential equations (PDEs) (governing thermal inertia) and non-linear\nalgebraic equations (AEs) (governing temperature, hydraulics, and power flow),\nwhich present a complicated system of partial differential algebraic equations\n(PDAEs). To solve the non-linear PDAEs in an efficient, accurate and robust\nway, we propose a novel non-iterative semi-analytical method based on\ndifferential transformation (DT). Firstly, we define a new DT framework under\nper unit systems to avoid the numerical problems due to inconsistent base\nquantities of district heating systems and electrical power systems, and\ninappropriate base time. Secondly, we discretize the spatial derivative of the\nPDEs using a semi-discrete difference scheme which converts the PDEs into\nordinary differential equations (ODEs). The scheme has total variation\ndecreasing property and hence helps eliminate dissipative and dispersive errors\nthat are often overlooked in the existing literature. Then, we employ the newly\ndefined DT framework as the time-marching solver of the ODEs and further extend\nDT to non-linear AEs, deriving high-order explicit closed-form solutions of all\nthe variables. In addition, to further improve the convergence and computation\nefficiency, we propose an adaptive time window strategy based on local\ntruncation error estimation. Case studies in a real DHS and an HE-IES with 225\nheating nodes and 118 electrical buses show that the proposed method\noutperforms the finite-difference-based Newton-Raphson iterative solver in\nefficiency, accuracy, and robustness.",
    "descriptor": "",
    "authors": [
      "Ruizhi Yu",
      "Wei Gu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07331"
  },
  {
    "id": "arXiv:2112.07334",
    "title": "OMAD: Object Model with Articulated Deformations for Pose Estimation and  Retrieval",
    "abstract": "Articulated objects are pervasive in daily life. However, due to the\nintrinsic high-DoF structure, the joint states of the articulated objects are\nhard to be estimated. To model articulated objects, two kinds of shape\ndeformations namely the geometric and the pose deformation should be\nconsidered. In this work, we present a novel category-specific parametric\nrepresentation called Object Model with Articulated Deformations (OMAD) to\nexplicitly model the articulated objects. In OMAD, a category is associated\nwith a linear shape function with shared shape basis and a non-linear joint\nfunction. Both functions can be learned from a large-scale object model dataset\nand fixed as category-specific priors. Then we propose an OMADNet to predict\nthe shape parameters and the joint states from an object's single observation.\nWith the full representation of the object shape and joint states, we can\naddress several tasks including category-level object pose estimation and the\narticulated object retrieval. To evaluate these tasks, we create a synthetic\ndataset based on PartNet-Mobility. Extensive experiments show that our simple\nOMADNet can serve as a strong baseline for both tasks.",
    "descriptor": "",
    "authors": [
      "Han Xue",
      "Liu Liu",
      "Wenqiang Xu",
      "Haoyuan Fu",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07334"
  },
  {
    "id": "arXiv:2112.07337",
    "title": "Multi-Instance Training for Question Answering Across Table and Linked  Text",
    "abstract": "Answering natural language questions using information from tables (TableQA)\nis of considerable recent interest. In many applications, tables occur not in\nisolation, but embedded in, or linked to unstructured text. Often, a question\nis best answered by matching its parts to either table cell contents or\nunstructured text spans, and extracting answers from either source. This leads\nto a new space of TextTableQA problems that was introduced by the HybridQA\ndataset. Existing adaptations of table representation to transformer-based\nreading comprehension (RC) architectures fail to tackle the diverse modalities\nof the two representations through a single system. Training such systems is\nfurther challenged by the need for distant supervision. To reduce cognitive\nburden, training instances usually include just the question and answer, the\nlatter matching multiple table rows and text passages. This leads to a noisy\nmulti-instance training regime involving not only rows of the table, but also\nspans of linked text. We respond to these challenges by proposing MITQA, a new\nTextTableQA system that explicitly models the different but closely-related\nprobability spaces of table row selection and text span selection. Our\nexperiments indicate the superiority of our approach compared to recent\nbaselines. The proposed method is currently at the top of the HybridQA\nleaderboard with a held out test set, achieving 21 % absolute improvement on\nboth EM and F1 scores over previous published results.",
    "descriptor": "",
    "authors": [
      "Vishwajeet Kumar",
      "Saneem Chemmengath",
      "Yash Gupta",
      "Jaydeep Sen",
      "Samarth Bharadwaj",
      "Soumen Chakrabarti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07337"
  },
  {
    "id": "arXiv:2112.07338",
    "title": "Temporal Transformer Networks with Self-Supervision for Action  Recognition",
    "abstract": "In recent years, 2D Convolutional Networks-based video action recognition has\nencouragingly gained wide popularity; However, constrained by the lack of\nlong-range non-linear temporal relation modeling and reverse motion information\nmodeling, the performance of existing models is, therefore, undercut seriously.\nTo address this urgent problem, we introduce a startling Temporal Transformer\nNetwork with Self-supervision (TTSN). Our high-performance TTSN mainly consists\nof a temporal transformer module and a temporal sequence self-supervision\nmodule. Concisely speaking, we utilize the efficient temporal transformer\nmodule to model the non-linear temporal dependencies among non-local frames,\nwhich significantly enhances complex motion feature representations. The\ntemporal sequence self-supervision module we employ unprecedentedly adopts the\nstreamlined strategy of \"random batch random channel\" to reverse the sequence\nof video frames, allowing robust extractions of motion information\nrepresentation from inversed temporal dimensions and improving the\ngeneralization capability of the model. Extensive experiments on three widely\nused datasets (HMDB51, UCF101, and Something-something V1) have conclusively\ndemonstrated that our proposed TTSN is promising as it successfully achieves\nstate-of-the-art performance for action recognition.",
    "descriptor": "",
    "authors": [
      "Yongkang Zhang",
      "Jun Li",
      "Guoming Wu",
      "Han Zhang",
      "Zhiping Shi",
      "Zhaoxun Liu",
      "Zizhang Wu",
      "Na Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07338"
  },
  {
    "id": "arXiv:2112.07339",
    "title": "Speeding up enclave transitions for IO-intensive applications",
    "abstract": "Process-based confidential computing enclaves such as Intel SGX can be used\nto protect the confidentiality and integrity of workloads, without the overhead\nof virtualisation. However, they introduce a notable performance overhead,\nespecially when it comes to transitions in and out of the enclave context. Such\noverhead makes the use of enclaves impractical for running IO-intensive\napplications, such as network packet processing or biological sequence\nanalysis. We build on earlier approaches to improve the IO performance of\nwork-loads in Intel SGX enclaves and propose the SGX-Bundler library, which\nhelps reduce the cost of both individual single enclave transitions well as of\nthe total number of enclave transitions in trusted applications running in\nIntel SGX enclaves. We describe the implementation of the SGX-Bundler library,\nevaluate its performance and demonstrate its practicality using the case study\nof Open vSwitch, a widely used software switch implementation.",
    "descriptor": "",
    "authors": [
      "Jakob Svenningsson",
      "Nicolae Paladi",
      "Arash Vahidi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.07339"
  },
  {
    "id": "arXiv:2112.07342",
    "title": "Learning to Guide and to Be Guided in the Architect-Builder Problem",
    "abstract": "We are interested in interactive agents that learn to coordinate, namely, a\n$builder$ -- which performs actions but ignores the goal of the task -- and an\n$architect$ which guides the builder towards the goal of the task. We define\nand explore a formal setting where artificial agents are equipped with\nmechanisms that allow them to simultaneously learn a task while at the same\ntime evolving a shared communication protocol. The field of Experimental\nSemiotics has shown the extent of human proficiency at learning from a priori\nunknown instructions meanings. Therefore, we take inspiration from it and\npresent the Architect-Builder Problem (ABP): an asymmetrical setting in which\nan architect must learn to guide a builder towards constructing a specific\nstructure. The architect knows the target structure but cannot act in the\nenvironment and can only send arbitrary messages to the builder. The builder on\nthe other hand can act in the environment but has no knowledge about the task\nat hand and must learn to solve it relying only on the messages sent by the\narchitect. Crucially, the meaning of messages is initially not defined nor\nshared between the agents but must be negotiated throughout learning. Under\nthese constraints, we propose Architect-Builder Iterated Guiding (ABIG), a\nsolution to the Architect-Builder Problem where the architect leverages a\nlearned model of the builder to guide it while the builder uses self-imitation\nlearning to reinforce its guided behavior. We analyze the key learning\nmechanisms of ABIG and test it in a 2-dimensional instantiation of the ABP\nwhere tasks involve grasping cubes, placing them at a given location, or\nbuilding various shapes. In this environment, ABIG results in a low-level,\nhigh-frequency, guiding communication protocol that not only enables an\narchitect-builder pair to solve the task at hand, but that can also generalize\nto unseen tasks.",
    "descriptor": "",
    "authors": [
      "Barde Paul",
      "Karch Tristan",
      "Nowrouzezahrai Derek",
      "Moulin-Frier Cl\u00e9ment",
      "Pal Christopher",
      "Oudeyer Pierre-Yves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.07342"
  },
  {
    "id": "arXiv:2112.07343",
    "title": "Learning phase field mean curvature flows with neural networks",
    "abstract": "We introduce in this paper new, efficient numerical methods based on neural\nnetworks for the approximation of the mean curvature flow of either oriented or\nnon-orientable surfaces. To learn the correct interface evolution law, our\nneural networks are trained on phase field representations of exact evolving\ninterfaces. The structure of the networks draws inspiration from splitting\nschemes used for the discretization of the Allen-Cahn equation. But when the\nlatter approximates the mean curvature motion of oriented interfaces only, the\napproach we propose extends very naturally to the non-orientable case. In\naddition, although trained on smooth flows only, our networks can handle\nsingularities as well. Furthermore, they can be coupled easily with additional\nconstraints which allows us to show various applications illustrating the\nflexibility and efficiency of our approach: mean curvature flows with volume\nconstraint, multiphase mean curvature flows, numerical approximation of Steiner\ntrees, numerical approximation of minimal surfaces.",
    "descriptor": "\nComments: 27 pages, 20 figures\n",
    "authors": [
      "Elie Bretin",
      "Roland Denis",
      "Simon Masnou",
      "Garry Terii"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07343"
  },
  {
    "id": "arXiv:2112.07344",
    "title": "SC-Reg: Training Overparameterized Neural Networks under Self-Concordant  Regularization",
    "abstract": "In this paper we propose the SC-Reg (self-concordant regularization)\nframework for learning overparameterized feedforward neural networks by\nincorporating second-order information in the \\emph{Newton decrement} framework\nfor convex problems. We propose the generalized Gauss-Newton with\nSelf-Concordant Regularization (SCoRe-GGN) algorithm that updates the network\nparameters each time it receives a new input batch. The proposed algorithm\nexploits the structure of the second-order information in the Hessian matrix,\nthereby reducing the training computational overhead. Although our current\nanalysis considers only the convex case, numerical experiments show the\nefficiency of our method and its fast convergence under both convex and\nnon-convex settings, which compare favorably against baseline first-order\nmethods and a quasi-Newton method.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Adeyemi D. Adeoye",
      "Alberto Bemporad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.07344"
  },
  {
    "id": "arXiv:2112.07349",
    "title": "Supervised Learning for Multi Zone Sound Field Reproduction under Harsh  Environmental Conditions",
    "abstract": "This manuscript presents an approach for multi zone sound field reproduction\nusing supervised learning. Traditional multi zone sound field reproduction\nmethods assume constant speed of sound, neglecting nonlinear effects like wind\nand temperature stratification. We show how to overcome these restrictions\nusing supervised learning of transfer functions. The quality of the solution is\nmeasured by the acoustic contrast and the reproduction error. Our results show\nthat for the chosen setup, even with relatively small wind speeds, the acoustic\ncontrast and reproduction error can be improved by up to 16 dB, when wind is\nconsidered in the trained model.",
    "descriptor": "\nComments: Preprint submitted for publication\n",
    "authors": [
      "Henry Sallandt",
      "Philipp Krah",
      "Mathias Lemke"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2112.07349"
  },
  {
    "id": "arXiv:2112.07353",
    "title": "Machine Learning-based Prediction of Porosity for Concrete Containing  Supplementary Cementitious Materials",
    "abstract": "Porosity has been identified as the key indicator of the durability\nproperties of concrete exposed to aggressive environments. This paper applies\nensemble learning to predict porosity of high-performance concrete containing\nsupplementary cementitious materials. The concrete samples utilized in this\nstudy are characterized by eight composition features including w/b ratio,\nbinder content, fly ash, GGBS, superplasticizer, coarse/fine aggregate ratio,\ncuring condition and curing days. The assembled database consists of 240 data\nrecords, featuring 74 unique concrete mixture designs. The proposed machine\nlearning algorithms are trained on 180 observations (75%) chosen randomly from\nthe data set and then tested on the remaining 60 observations (25%). The\nnumerical experiments suggest that the regression tree ensembles can accurately\npredict the porosity of concrete from its mixture compositions. Gradient\nboosting trees generally outperforms random forests in terms of prediction\naccuracy. For random forests, the out-of-bag error based hyperparameter tuning\nstrategy is found to be much more efficient than k-Fold Cross-Validation.",
    "descriptor": "",
    "authors": [
      "Chong Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2112.07353"
  },
  {
    "id": "arXiv:2112.07356",
    "title": "Technical Language Supervision for Intelligent Fault Diagnosis in  Process Industry",
    "abstract": "In the process industry, condition monitoring systems with automated fault\ndiagnosis methods assisthuman experts and thereby improve maintenance\nefficiency, process sustainability, and workplace safety.Improving the\nautomated fault diagnosis methods using data and machine learning-based models\nis a centralaspect of intelligent fault diagnosis (IFD). A major challenge in\nIFD is to develop realistic datasets withaccurate labels needed to train and\nvalidate models, and to transfer models trained with labeled lab datato\nheterogeneous process industry environments. However, fault descriptions and\nwork-orders written bydomain experts are increasingly digitized in modern\ncondition monitoring systems, for example in the contextof rotating equipment\nmonitoring. Thus, domain-specific knowledge about fault characteristics and\nseveritiesexists as technical language annotations in industrial datasets.\nFurthermore, recent advances in naturallanguage processing enable weakly\nsupervised model optimization using natural language annotations, mostnotably\nin the form ofnatural language supervision(NLS). This creates a timely\nopportunity to developtechnical language supervision(TLS) solutions for IFD\nsystems grounded in industrial data, for exampleas a complement to pre-training\nwith lab data to address problems like overfitting and inaccurate out-of-sample\ngeneralisation. We surveyed the literature and identify a considerable\nimprovement in the maturityof NLS over the last two years, facilitating\napplications beyond natural language; a rapid development ofweak supervision\nmethods; and transfer learning as a current trend in IFD which can benefit from\nthesedevelopments. Finally, we describe a framework for integration of TLS in\nIFD which is inspired by recentNLS innovations.",
    "descriptor": "",
    "authors": [
      "Karl L\u00f6wenmark",
      "Cees Taal",
      "Stephan Schnabel",
      "Marcus Liwicki",
      "Fredrik Sandin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07356"
  },
  {
    "id": "arXiv:2112.07360",
    "title": "Electromagnetic Modeling of Lossy Interconnects From DC to High  Frequencies With a Potential-Based Boundary Element Formulation",
    "abstract": "The accurate electromagnetic modeling of both low- and high-frequency physics\nis crucial in the signal and power integrity analysis of electrical\ninterconnects. The boundary element method (BEM) is appealing for lossy\nconductor modeling because it can capture the frequency-dependent variation of\nskin depth with only a surface-based discretization of the structure.\nConventional BEM formulations rely on the mutual coupling of electric and\nmagnetic fields, and can become inaccurate or unstable at low frequencies. We\ndevelop a new full-wave BEM formulation based on potentials which can\naccurately model lossy conductors from exactly DC to very high frequencies. A\nnew set of simple boundary conditions is proposed along with a modified Lorenz\ngauge to ensure that the proposed formulation has a stable condition number\ndown to DC. Moreover, coupling the potential-based integral equations to a\ncircuit model allows the straightforward extraction of network parameters.\nRealistic numerical examples at both the chip and package level demonstrate the\naccuracy and stability of the proposed method from DC to high frequencies,\nbeyond the capabilities of state-of-the-art BEM formulations based on fields.",
    "descriptor": "\nComments: Submitted to the IEEE Transactions on Microwave Theory and Techniques\n",
    "authors": [
      "Shashwat Sharma",
      "Piero Triverio"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2112.07360"
  },
  {
    "id": "arXiv:2112.07363",
    "title": "An Advanced Parallel PageRank Algorithm",
    "abstract": "Initially used to rank web pages, PageRank has now been applied in many\nfields. In general case, there are plenty of special vertices such as dangling\nvertices and unreferenced vertices in the graph. Existing PageRank algorithms\nusually consider them as `bad` vertices since they may take troubles. However,\nin this paper, we propose a parallel PageRank algorithm which can take\nadvantage of these special vertices. For this end, we firstly interpret\nPageRank from the information transmitting perspective and give a constructive\ndefinition of PageRank. Then, based on the information transmitting\ninterpretation, a parallel PageRank algorithm which we call the Information\nTransmitting Algorithm(ITA) is proposed. We prove that the dangling vertices\ncan increase ITA's convergence rate and the unreferenced vertices and weak\nunreferenced vertices can decrease ITA's calculations. Compared with the MONTE\nCARLO method, ITA has lower bandwidth requirement. Compared with the power\nmethod, ITA has higher convergence rate and generates less calculations.\nFinally, experimental results on four data sets demonstrate that ITA is 1.5-4\ntimes faster than the power method and converges more uniformly.",
    "descriptor": "",
    "authors": [
      "Qi Zhang",
      "Zhengan Yao",
      "Jun Liang",
      "Zanbo Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.07363"
  },
  {
    "id": "arXiv:2112.07365",
    "title": "Extending the team with a project-specific bot",
    "abstract": "While every other software team is adopting off-the-shelf bots to automate\neveryday tasks, the Coq team has made a different choice by developing and\nmaintaining a project-specific bot from the ground up. In this article, we\ndescribe the reasons for this choice, what kind of automation this has allowed\nus to implement, how the many features of this custom bot have evolved based on\ninternal feedback, and the technology and architecture choices that have made\nit possible.",
    "descriptor": "",
    "authors": [
      "Th\u00e9o Zimmermann",
      "Julien Coolen",
      "Pierre-Marie P\u00e9drot",
      "Ga\u00ebtan Gilbert"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.07365"
  },
  {
    "id": "arXiv:2112.07368",
    "title": "Simple and Robust Loss Design for Multi-Label Learning with Missing  Labels",
    "abstract": "Multi-label learning in the presence of missing labels (MLML) is a\nchallenging problem. Existing methods mainly focus on the design of network\nstructures or training schemes, which increase the complexity of\nimplementation. This work seeks to fulfill the potential of loss function in\nMLML without increasing the procedure and complexity. Toward this end, we\npropose two simple yet effective methods via robust loss design based on an\nobservation that a model can identify missing labels during training with a\nhigh precision. The first is a novel robust loss for negatives, namely the Hill\nloss, which re-weights negatives in the shape of a hill to alleviate the effect\nof false negatives. The second is a self-paced loss correction (SPLC) method,\nwhich uses a loss derived from the maximum likelihood criterion under an\napproximate distribution of missing labels. Comprehensive experiments on a vast\nrange of multi-label image classification datasets demonstrate that our methods\ncan remarkably boost the performance of MLML and achieve new state-of-the-art\nloss functions in MLML.",
    "descriptor": "",
    "authors": [
      "Youcai Zhang",
      "Yuhao Cheng",
      "Xinyu Huang",
      "Fei Wen",
      "Rui Feng",
      "Yaqian Li",
      "Yandong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07368"
  },
  {
    "id": "arXiv:2112.07369",
    "title": "Convergence proof for stochastic gradient descent in the training of  deep neural networks with ReLU activation for constant target functions",
    "abstract": "In many numerical simulations stochastic gradient descent (SGD) type\noptimization methods perform very effectively in the training of deep neural\nnetworks (DNNs) but till this day it remains an open problem of research to\nprovide a mathematical convergence analysis which rigorously explains the\nsuccess of SGD type optimization methods in the training of DNNs. In this work\nwe study SGD type optimization methods in the training of fully-connected\nfeedforward DNNs with rectified linear unit (ReLU) activation. We first\nestablish general regularity properties for the risk functions and their\ngeneralized gradient functions appearing in the training of such DNNs and,\nthereafter, we investigate the plain vanilla SGD optimization method in the\ntraining of such DNNs under the assumption that the target function under\nconsideration is a constant function. Specifically, we prove under the\nassumption that the learning rates (the step sizes of the SGD optimization\nmethod) are sufficiently small but not $L^1$-summable and under the assumption\nthat the target function is a constant function that the expectation of the\nriskof the considered SGD process converges in the training of such DNNs to\nzero as the number of SGD steps increases to infinity.",
    "descriptor": "\nComments: 52 pages, 1 figure. arXiv admin note: text overlap with arXiv:2104.00277, arXiv:2107.04479\n",
    "authors": [
      "Martin Hutzenthaler",
      "Arnulf Jentzen",
      "Katharina Pohl",
      "Adrian Riekert",
      "Luca Scarpa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.07369"
  },
  {
    "id": "arXiv:2112.07373",
    "title": "Semi-Supervised Variational User Identity Linkage via Noise-Aware  Self-Learning",
    "abstract": "User identity linkage, which aims to link identities of a natural person\nacross different social platforms, has attracted increasing research interest\nrecently. Existing approaches usually first embed the identities as\ndeterministic vectors in a shared latent space, and then learn a classifier\nbased on the available annotations. However, the formation and characteristics\nof real-world social platforms are full of uncertainties, which makes these\ndeterministic embedding based methods sub-optimal. In addition, it is\nintractable to collect sufficient linkage annotations due to the tremendous\ngaps between different platforms. Semi-supervised models utilize the unlabeled\ndata to help capture the intrinsic data distribution, which are more promising\nin practical usage. However, the existing semi-supervised linkage methods\nheavily rely on the heuristically defined similarity measurements to\nincorporate the innate closeness between labeled and unlabeled samples. Such\nmanually designed assumptions may not be consistent with the actual linkage\nsignals and further introduce the noises. To address the mentioned limitations,\nin this paper we propose a novel Noise-aware Semi-supervised Variational User\nIdentity Linkage (NSVUIL) model. Specifically, we first propose a novel\nsupervised linkage module to incorporate the available annotations. Each social\nidentity is represented by a Gaussian distribution in the Wasserstein space to\nsimultaneously preserve the fine-grained social profiles and model the\nuncertainty of identities. Then, a noise-aware self-learning module is designed\nto faithfully augment the few available annotations, which is capable of\nfiltering noises from the pseudo-labels generated by the supervised module.",
    "descriptor": "",
    "authors": [
      "Chaozhuo Li",
      "Senzhang Wang",
      "Zheng Liu",
      "Xing Xie",
      "Lei Chen",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.07373"
  },
  {
    "id": "arXiv:2112.07374",
    "title": "Geometry-Contrastive Transformer for Generalized 3D Pose Transfer",
    "abstract": "We present a customized 3D mesh Transformer model for the pose transfer task.\nAs the 3D pose transfer essentially is a deformation procedure dependent on the\ngiven meshes, the intuition of this work is to perceive the geometric\ninconsistency between the given meshes with the powerful self-attention\nmechanism. Specifically, we propose a novel geometry-contrastive Transformer\nthat has an efficient 3D structured perceiving ability to the global geometric\ninconsistencies across the given meshes. Moreover, locally, a simple yet\nefficient central geodesic contrastive loss is further proposed to improve the\nregional geometric-inconsistency learning. At last, we present a latent\nisometric regularization module together with a novel semi-synthesized dataset\nfor the cross-dataset 3D pose transfer task towards unknown spaces. The massive\nexperimental results prove the efficacy of our approach by showing\nstate-of-the-art quantitative performances on SMPL-NPT, FAUST and our new\nproposed dataset SMG-3D datasets, as well as promising qualitative results on\nMG-cloth and SMAL datasets. It's demonstrated that our method can achieve\nrobust 3D pose transfer and be generalized to challenging meshes from unknown\nspaces on cross-dataset tasks. The code and dataset are made available. Code is\navailable: https://github.com/mikecheninoulu/CGT.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Haoyu Chen",
      "Hao Tang",
      "Zitong Yu",
      "Nicu Sebe",
      "Guoying Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07374"
  },
  {
    "id": "arXiv:2112.07376",
    "title": "Answering Queries with Negation over Existential Rules",
    "abstract": "Ontology-based query answering with existential rules is well understood and\nimplemented for positive queries, in particular conjunctive queries. The\nsituation changes drastically for queries with negation, where there is no\nagreed-upon semantics or standard implementation. Stratification, as used for\nDatalog, is not enough for existential rules, since the latter still admit\nmultiple universal models that can differ on negative queries. We therefore\npropose universal core models as a basis for a meaningful (non-monotonic)\nsemantics for queries with negation. Since cores are hard to compute, we\nidentify syntactic descriptions of queries that can equivalently be answered\nover other types of models. This leads to fragments of queries with negation\nthat can safely be evaluated by current chase implementations. We establish new\ntechniques to estimate how the core model differs from other universal models,\nand we incorporate our findings into a new reasoning approach for existential\nrules with negation.",
    "descriptor": "\nComments: Technical report of our AAAI 2022 paper\n",
    "authors": [
      "Stefan Ellmauthaler",
      "Markus Kr\u00f6tzsch",
      "Stephan Mennicke"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.07376"
  },
  {
    "id": "arXiv:2112.07377",
    "title": "A note on calculi for non-deterministic many-valued logics",
    "abstract": "We present two deductively equivalent calculi for non-deterministic\nmany-valued logics. One is defined by axioms and the other - by rules of\ninference. The two calculi are obtained from the truth tables of the logic\nunder consideration in a straightforward manner. We prove soundness and strong\ncompleteness theorems for both calculi and also prove the cut elimination\ntheorem for the calculi defined by rules of inference.",
    "descriptor": "",
    "authors": [
      "Michael Kaminski"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.07377"
  },
  {
    "id": "arXiv:2112.07380",
    "title": "TRACER: Extreme Attention Guided Salient Object Tracing Network",
    "abstract": "Existing studies on salient object detection (SOD) focus on extracting\ndistinct objects with edge information and aggregating multi-level features to\nimprove SOD performance. To achieve satisfactory performance, the methods\nemploy refined edge information and low multi-level discrepancy. However, both\nperformance gain and computational efficiency cannot be attained, which has\nmotivated us to study the inefficiencies in existing encoder-decoder structures\nto avoid this trade-off. We propose TRACER, which detects salient objects with\nexplicit edges by incorporating attention guided tracing modules. We employ a\nmasked edge attention module at the end of the first encoder using a fast\nFourier transform to propagate the refined edge information to the downstream\nfeature extraction. In the multi-level aggregation phase, the union attention\nmodule identifies the complementary channel and important spatial information.\nTo improve the decoder performance and computational efficiency, we minimize\nthe decoder block usage with object attention module. This module extracts\nundetected objects and edge information from refined channels and spatial\nrepresentations. Subsequently, we propose an adaptive pixel intensity loss\nfunction to deal with the relatively important pixels unlike conventional loss\nfunctions which treat all pixels equally. A comparison with 13 existing methods\nreveals that TRACER achieves state-of-the-art performance on five benchmark\ndatasets. In particular, TRACER-Efficient3 (TE3) outperforms LDF, an existing\nmethod while requiring 1.8x fewer learning parameters and less time; TE3 is 5x\nfaster.",
    "descriptor": "\nComments: AAAI 2022, SA poster session accepted paper\n",
    "authors": [
      "Min Seok Lee",
      "WooSeok Shin",
      "Sung Won Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07380"
  },
  {
    "id": "arXiv:2112.07381",
    "title": "You Only Need One Model for Open-domain Question Answering",
    "abstract": "Recent works for Open-domain Question Answering refer to an external\nknowledge base using a retriever model, optionally rerank the passages with a\nseparate reranker model and generate an answer using an another reader model.\nDespite performing related tasks, the models have separate parameters and are\nweakly-coupled during training. In this work, we propose casting the retriever\nand the reranker as hard-attention mechanisms applied sequentially within the\ntransformer architecture and feeding the resulting computed representations to\nthe reader. In this singular model architecture the hidden representations are\nprogressively refined from the retriever to the reranker to the reader, which\nis more efficient use of model capacity and also leads to better gradient flow\nwhen we train it in an end-to-end manner. We also propose a pre-training\nmethodology to effectively train this architecture. We evaluate our model on\nNatural Questions and TriviaQA open datasets and for a fixed parameter budget,\nour model outperforms the previous state-of-the-art model by 1.0 and 0.7 exact\nmatch scores.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Haejun Lee",
      "Akhil Kedia",
      "Jongwon Lee",
      "Ashwin Paranjape",
      "Christopher D. Manning",
      "Kyoung-Gu Woo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07381"
  },
  {
    "id": "arXiv:2112.07383",
    "title": "Improving Human-Object Interaction Detection via Phrase Learning and  Label Composition",
    "abstract": "Human-Object Interaction (HOI) detection is a fundamental task in high-level\nhuman-centric scene understanding. We propose PhraseHOI, containing a HOI\nbranch and a novel phrase branch, to leverage language prior and improve\nrelation expression. Specifically, the phrase branch is supervised by semantic\nembeddings, whose ground truths are automatically converted from the original\nHOI annotations without extra human efforts. Meanwhile, a novel label\ncomposition method is proposed to deal with the long-tailed problem in HOI,\nwhich composites novel phrase labels by semantic neighbors. Further, to\noptimize the phrase branch, a loss composed of a distilling loss and a balanced\ntriplet loss is proposed. Extensive experiments are conducted to prove the\neffectiveness of the proposed PhraseHOI, which achieves significant improvement\nover the baseline and surpasses previous state-of-the-art methods on Full and\nNonRare on the challenging HICO-DET benchmark.",
    "descriptor": "\nComments: Accepted to AAAI2022\n",
    "authors": [
      "Zhimin Li",
      "Cheng Zou",
      "Yu Zhao",
      "Boxun Li",
      "Sheng Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07383"
  },
  {
    "id": "arXiv:2112.07384",
    "title": "Identification of Biased Terms in News Articles by Comparison of  Outlet-specific Word Embeddings",
    "abstract": "Slanted news coverage, also called media bias, can heavily influence how news\nconsumers interpret and react to the news. To automatically identify biased\nlanguage, we present an exploratory approach that compares the context of\nrelated words. We train two word embedding models, one on texts of left-wing,\nthe other on right-wing news outlets. Our hypothesis is that a word's\nrepresentations in both word embedding spaces are more similar for non-biased\nwords than biased words. The underlying idea is that the context of biased\nwords in different news outlets varies more strongly than the one of non-biased\nwords, since the perception of a word as being biased differs depending on its\ncontext. While we do not find statistical significance to accept the\nhypothesis, the results show the effectiveness of the approach. For example,\nafter a linear mapping of both word embeddings spaces, 31% of the words with\nthe largest distances potentially induce bias. To improve the results, we find\nthat the dataset needs to be significantly larger, and we derive further\nmethodology as future research direction. To our knowledge, this paper presents\nthe first in-depth look at the context of bias words measured by word\nembeddings.",
    "descriptor": "",
    "authors": [
      "Timo Spinde",
      "Lada Rudnitckaia",
      "Felix Hamborg",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.07384"
  },
  {
    "id": "arXiv:2112.07391",
    "title": "TASSY -- A Text Annotation Survey System",
    "abstract": "We present a free and open-source tool for creating web-based surveys that\ninclude text annotation tasks. Existing tools offer either text annotation or\nsurvey functionality but not both. Combining the two input types is\nparticularly relevant for investigating a reader's perception of a text which\nalso depends on the reader's background, such as age, gender, and education.\nOur tool caters primarily to the needs of researchers in the Library and\nInformation Sciences, the Social Sciences, and the Humanities who apply Content\nAnalysis to investigate, e.g., media bias, political communication, or fake\nnews.",
    "descriptor": "",
    "authors": [
      "Timo Spinde",
      "Kanishka Sinha",
      "Norman Meuschke",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07391"
  },
  {
    "id": "arXiv:2112.07392",
    "title": "Do You Think It's Biased? How To Ask For The Perception Of Media Bias",
    "abstract": "Media coverage possesses a substantial effect on the public perception of\nevents. The way media frames events can significantly alter the beliefs and\nperceptions of our society. Nevertheless, nearly all media outlets are known to\nreport news in a biased way. While such bias can be introduced by altering the\nword choice or omitting information, the perception of bias also varies largely\ndepending on a reader's personal background. Therefore, media bias is a very\ncomplex construct to identify and analyze. Even though media bias has been the\nsubject of many studies, previous assessment strategies are oversimplified,\nlack overlap and empirical evaluation. Thus, this study aims to develop a scale\nthat can be used as a reliable standard to evaluate article bias. To name an\nexample: Intending to measure bias in a news article, should we ask, \"How\nbiased is the article?\" or should we instead ask, \"How did the article treat\nthe American president?\". We conducted a literature search to find 824 relevant\nquestions about text perception in previous research on the topic. In a\nmulti-iterative process, we summarized and condensed these questions\nsemantically to conclude a complete and representative set of possible question\ntypes about bias. The final set consisted of 25 questions with varying\nanswering formats, 17 questions using semantic differentials, and six ratings\nof feelings. We tested each of the questions on 190 articles with overall 663\nparticipants to identify how well the questions measure an article's perceived\nbias. Our results show that 21 final items are suitable and reliable for\nmeasuring the perception of media bias. We publish the final set of questions\non this http URL",
    "descriptor": "",
    "authors": [
      "Timo Spinde",
      "Christina Kreuter",
      "Wolfgang Gaissmaier",
      "Felix Hamborg",
      "Bela Gipp",
      "Helge Giese"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07392"
  },
  {
    "id": "arXiv:2112.07395",
    "title": "Handwritten text generation and strikethrough characters augmentation",
    "abstract": "We introduce two data augmentation techniques, which, used with a\nResnet-BiLSTM-CTC network, significantly reduce Word Error Rate (WER) and\nCharacter Error Rate (CER) beyond best-reported results on handwriting text\nrecognition (HTR) tasks. We apply a novel augmentation that simulates\nstrikethrough text (HandWritten Blots) and a handwritten text generation method\nbased on printed text (StackMix), which proved to be very effective in HTR\ntasks. StackMix uses weakly-supervised framework to get character boundaries.\nBecause these data augmentation techniques are independent of the network used,\nthey could also be applied to enhance the performance of other networks and\napproaches to HTR. Extensive experiments on ten handwritten text datasets show\nthat HandWritten Blots augmentation and StackMix significantly improve the\nquality of HTR models",
    "descriptor": "\nComments: 16 pages, 15 figures. arXiv admin note: substantial text overlap with arXiv:2108.11667\n",
    "authors": [
      "Alex Shonenkov",
      "Denis Karachev",
      "Max Novopoltsev",
      "Mark Potanin",
      "Denis Dimitrov",
      "Andrey Chertok"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07395"
  },
  {
    "id": "arXiv:2112.07397",
    "title": "Randomized Response Mechanisms for Differential Privacy Data Analysis:  Bounds and Applications",
    "abstract": "Randomized response, as a basic building-block for differentially private\nmechanism, has given rise to great interest and found various potential\napplications in science communities. In this work, we are concerned with\nthree-elements randomized response (RR$_{3}$) along with relevant applications\nto the analysis of weighted bipartite graph upon differentially private\nguarantee. We develop a principled framework for estimating statistics produced\nby RR$_{3}$-based mechanisms, and then prove the corresponding estimations to\nbe unbiased. At the same time, we study in detail several fundamental and\nsignificant members in RR$_{3}$ family, and derive the closed-form solutions to\nunbiased estimations. Next, we show potential applications of several\nRR$_{3}$-based mechanisms into the estimation of average degree and average\nweighted value on weighted bipartite graph when requiring local differential\nprivacy guarantee. In the meantime, we determine the lower bounds for choice of\nrelevant parameters by minimizing variance of statistics in order to design\noptimal RR$_{3}$-based local differential private mechanisms, with which we\noptimize previous protocols in the literature and put forward a version that\nachieves the tight bound. Last but most importantly, we observe that in the\nanalysis of relational data such as weighted bipartite graph, a portion of\nprivacy budget in local differential private mechanism is sometimes \"consumed\"\nby mechanism itself accidentally, resulting to a more stronger privacy\nguarantee than we would get by simply sequential compositions.",
    "descriptor": "",
    "authors": [
      "Fei Ma",
      "Ping Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.07397"
  },
  {
    "id": "arXiv:2112.07403",
    "title": "Stochastic Actor-Executor-Critic for Image-to-Image Translation",
    "abstract": "Training a model-free deep reinforcement learning model to solve\nimage-to-image translation is difficult since it involves high-dimensional\ncontinuous state and action spaces. In this paper, we draw inspiration from the\nrecent success of the maximum entropy reinforcement learning framework designed\nfor challenging continuous control problems to develop stochastic policies over\nhigh dimensional continuous spaces including image representation, generation,\nand control simultaneously. Central to this method is the Stochastic\nActor-Executor-Critic (SAEC) which is an off-policy actor-critic model with an\nadditional executor to generate realistic images. Specifically, the actor\nfocuses on the high-level representation and control policy by a stochastic\nlatent action, as well as explicitly directs the executor to generate low-level\nactions to manipulate the state. Experiments on several image-to-image\ntranslation tasks have demonstrated the effectiveness and robustness of the\nproposed SAEC when facing high-dimensional continuous space problems.",
    "descriptor": "",
    "authors": [
      "Ziwei Luo",
      "Jing Hu",
      "Xin Wang",
      "Siwei Lyu",
      "Bin Kong",
      "Youbing Yin",
      "Qi Song",
      "Xi Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07403"
  },
  {
    "id": "arXiv:2112.07406",
    "title": "Branching Time Active Inference with Bayesian Filtering",
    "abstract": "Branching Time Active Inference (Champion et al., 2021b,a) is a framework\nproposing to look at planning as a form of Bayesian model expansion. Its root\ncan be found in Active Inference (Friston et al., 2016; Da Costa et al., 2020;\nChampion et al., 2021c), a neuroscientific framework widely used for brain\nmodelling, as well as in Monte Carlo Tree Search (Browne et al., 2012), a\nmethod broadly applied in the Reinforcement Learning literature. Up to now, the\ninference of the latent variables was carried out by taking advantage of the\nflexibility offered by Variational Message Passing (Winn and Bishop, 2005), an\niterative process that can be understood as sending messages along the edges of\na factor graph (Forney, 2001). In this paper, we harness the efficiency of an\nalternative method for inference called Bayesian Filtering (Fox et al., 2003),\nwhich does not require the iteration of the update equations until convergence\nof the Variational Free Energy. Instead, this scheme alternates between two\nphases: integration of evidence and prediction of future states. Both of those\nphases can be performed efficiently and this provides a seventy times speed up\nover the state-of-the-art.",
    "descriptor": "\nComments: 16 pages, 2 figures, 2 tables. arXiv admin note: text overlap with arXiv:2111.11276\n",
    "authors": [
      "Th\u00e9ophile Champion",
      "Marek Grze\u015b",
      "Howard Bowman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07406"
  },
  {
    "id": "arXiv:2112.07408",
    "title": "Towards a Network Control Theory of Electroconvulsive Therapy Response",
    "abstract": "Electroconvulsive Therapy (ECT) is arguably the most effective intervention\nfor treatment-resistant depression. While large interindividual variability\nexists, a theory capable of predicting individual response to ECT remains\nelusive. To address this, we posit a quantitative, mechanistic framework of ECT\nresponse based on Network Control Theory (NCT). Then, we empirically test our\napproach and employ it to predict ECT treatment response. To this end, we\nderive a formal association between Postictal Suppression Index (PSI) - an ECT\nseizure quality index - and whole-brain modal and average controllability, NCT\nmetrics based on white matter brain network architecture, respectively.\nExploiting the known association of ECT response and PSI, we then hypothesized\nan association between our controllability metrics and ECT response mediated by\nPSI. We formally tested this conjecture in N=50 depressive patients undergoing\nECT. We show that whole-brain controllability metrics based on pre-ECT\nstructural connectome data predict ECT response in accordance with our\nhypotheses. In addition, we show the expected mediation effects via PSI.\nImportantly, our theoretically motivated metrics are at least on par with\nextensive machine learning models based on pre-ECT connectome data. In summary,\nwe derived and tested a control-theoretic framework capable of predicting ECT\nresponse based on individual brain network architecture. It makes testable,\nquantitative predictions regarding individual therapeutic response, which are\ncorroborated by strong empirical evidence. Our work might constitute a starting\npoint for a comprehensive, quantitative theory of personalized ECT\ninterventions rooted in control theory.",
    "descriptor": "",
    "authors": [
      "Tim Hahn",
      "Hamidreza Jamalabadi",
      "Erfan Nozari",
      "Nils R. Winter",
      "Jan Ernsting",
      "Marius Gruber",
      "Marco J. Mauritz",
      "Pascal Grumbach",
      "Lukas Fisch",
      "Ramona Leenings",
      "Kelvin Sarink",
      "Julian Blanke",
      "Leon Kleine Vennekate",
      "Daniel Emden",
      "Nils Opel",
      "Dominik Grotegerd",
      "Verena Enneking",
      "Susanne Meinert",
      "Tiana Borgers",
      "Melissa Klug",
      "Elisabeth J. Leehr",
      "Katharina Dohm",
      "Walter Heindel",
      "Joachim Gross",
      "Udo Dannlowski",
      "Ronny Redlich",
      "Jonathan Repple"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2112.07408"
  },
  {
    "id": "arXiv:2112.07411",
    "title": "INRU: A Quasigroup Based Lightweight Block Cipher",
    "abstract": "In this paper, we propose a quasigroup based block cipher design. The round\nfunctions of the encryption and decryption algorithms use quasigroup based\nstring transformations. We show the robustness of the design against the\nstandard differential, linear and algebraic cryptanalytic attacks. We also\nprovide detailed statistical analysis using NIST test suite in CBC, CFB, OFB,\nand CTR modes of operation. We compare the statistical experimental results\nwith the AES-128 in the same setup and conclude that the randomizing ability of\nour algorithm is equivalent to that of AES-128.",
    "descriptor": "",
    "authors": [
      "Sharwan K. Tiwari",
      "Ambrish Awasthi",
      "Sucheta Chkrabarti",
      "Sudha Yadav"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.07411"
  },
  {
    "id": "arXiv:2112.07414",
    "title": "Deep Sea Bubble Stream Characterization Using Wide-Baseline Stereo  Photogrammetry",
    "abstract": "Reliable quantification of natural and anthropogenic gas release (e.g.\\\nCO$_2$, methane) from the seafloor into the ocean, and ultimately, the\natmosphere, is a challenging task. While ship-based echo sounders allow\ndetection of free gas in the water even from a larger distance, exact\nquantification requires parameters such as rise speed and bubble size\ndistribution not obtainable by such sensors. Optical methods are complementary\nin the sense that they can provide high temporal and spatial resolution of\nsingle bubbles or bubble streams from close distance. In this contribution we\nintroduce a complete instrument and evaluation method for optical bubble stream\ncharacterization. The dedicated instrument employs a high-speed deep sea stereo\ncamera system that can record terabytes of bubble imagery when deployed at a\nseep site for later automated analysis. Bubble characteristics can be obtained\nfor short sequences of few minutes, then relocating the instrument to other\nlocations, or in autonomous mode of intervals up to several days, in order to\ncapture variations due to current and pressure changes and across tidal cycles.\nBeside reporting the steps to make bubble characterization robust and\nautonomous, we carefully evaluate the reachable accuracy and propose a novel\ncalibration procedure that, due to the lack of point correspondences, uses only\nthe silhouettes of bubbles. The system has been operated successfully in up to\n1000m water depth in the Pacific Ocean to assess methane fluxes. Besides sample\nresults we also report failure cases and lessons learnt during development.",
    "descriptor": "\nComments: 43 pages, 25 figures\n",
    "authors": [
      "Mengkun She",
      "Yifan Song",
      "Tim Wei\u00df",
      "Jens Greinert",
      "Kevin K\u00f6ser"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07414"
  },
  {
    "id": "arXiv:2112.07421",
    "title": "Towards A Reliable Ground-Truth For Biased Language Detection",
    "abstract": "Reference texts such as encyclopedias and news articles can manifest biased\nlanguage when objective reporting is substituted by subjective writing.\nExisting methods to detect bias mostly rely on annotated data to train machine\nlearning models. However, low annotator agreement and comparability is a\nsubstantial drawback in available media bias corpora. To evaluate data\ncollection options, we collect and compare labels obtained from two popular\ncrowdsourcing platforms. Our results demonstrate the existing crowdsourcing\napproaches' lack of data quality, underlining the need for a trained expert\nframework to gather a more reliable dataset. By creating such a framework and\ngathering a first dataset, we are able to improve Krippendorff's $\\alpha$ =\n0.144 (crowdsourcing labels) to $\\alpha$ = 0.419 (expert labels). We conclude\nthat detailed annotator training increases data quality, improving the\nperformance of existing bias detection systems. We will continue to extend our\ndataset in the future.",
    "descriptor": "",
    "authors": [
      "Timo Spinde",
      "David Krieger",
      "Manuel Plank",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07421"
  },
  {
    "id": "arXiv:2112.07423",
    "title": "Multi-Modal Perception Attention Network with Self-Supervised Learning  for Audio-Visual Speaker Tracking",
    "abstract": "Multi-modal fusion is proven to be an effective method to improve the\naccuracy and robustness of speaker tracking, especially in complex scenarios.\nHowever, how to combine the heterogeneous information and exploit the\ncomplementarity of multi-modal signals remains a challenging issue. In this\npaper, we propose a novel Multi-modal Perception Tracker (MPT) for speaker\ntracking using both audio and visual modalities. Specifically, a novel acoustic\nmap based on spatial-temporal Global Coherence Field (stGCF) is first\nconstructed for heterogeneous signal fusion, which employs a camera model to\nmap audio cues to the localization space consistent with the visual cues. Then\na multi-modal perception attention network is introduced to derive the\nperception weights that measure the reliability and effectiveness of\nintermittent audio and video streams disturbed by noise. Moreover, a unique\ncross-modal self-supervised learning method is presented to model the\nconfidence of audio and visual observations by leveraging the complementarity\nand consistency between different modalities. Experimental results show that\nthe proposed MPT achieves 98.6% and 78.3% tracking accuracy on the standard and\noccluded datasets, respectively, which demonstrates its robustness under\nadverse conditions and outperforms the current state-of-the-art methods.",
    "descriptor": "\nComments: Accepted by AAAI2022\n",
    "authors": [
      "Yidi Li",
      "Hong Liu",
      "Hao Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07423"
  },
  {
    "id": "arXiv:2112.07424",
    "title": "Conjugated Discrete Distributions for Distributional Reinforcement  Learning",
    "abstract": "In this work we continue to build upon recent advances in reinforcement\nlearning for finite Markov processes. A common approach among previous existing\nalgorithms, both single-actor and distributed, is to either clip rewards or to\napply a transformation method on Q-functions to handle a large variety of\nmagnitudes in real discounted returns. We theoretically show that one of the\nmost successful methods may not yield an optimal policy if we have a\nnon-deterministic process. As a solution, we argue that distributional\nreinforcement learning lends itself to remedy this situation completely. By the\nintroduction of a conjugated distributional operator we may handle a large\nclass of transformations for real returns with guaranteed theoretical\nconvergence. We propose an approximating single-actor algorithm based on this\noperator that trains agents directly on unaltered rewards using a proper\ndistributional metric given by the Cram\\'er distance. To evaluate its\nperformance in a stochastic setting we train agents on a suite of 55 Atari 2600\ngames using sticky-actions and obtain state-of-the-art performance compared to\nother well-known algorithms in the Dopamine framework.",
    "descriptor": "\nComments: 17 pages, 7 figures, conference\n",
    "authors": [
      "Bj\u00f6rn Lindenberg",
      "Jonas Nordqvist",
      "Karl-Olof Lindahl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.07424"
  },
  {
    "id": "arXiv:2112.07426",
    "title": "Direct Training via Backpropagation for Ultra-low Latency Spiking Neural  Networks with Multi-threshold",
    "abstract": "Spiking neural networks (SNNs) can utilize spatio-temporal information and\nhave a nature of energy efficiency which is a good alternative to deep neural\nnetworks(DNNs). The event-driven information processing makes SNNs can reduce\nthe expensive computation of DNNs and save a lot of energy consumption.\nHowever, high training and inference latency is a limitation of the development\nof deeper SNNs. SNNs usually need tens or even hundreds of time steps during\nthe training and inference process which causes not only the increase of\nlatency but also the waste of energy consumption. To overcome this problem, we\nproposed a novel training method based on backpropagation (BP) for ultra-low\nlatency(1-2 time steps) SNN with multi-threshold. In order to increase the\ninformation capacity of each spike, we introduce the multi-threshold Leaky\nIntegrate and Fired (LIF) model. In our proposed training method, we proposed\nthree approximated derivative for spike activity to solve the problem of the\nnon-differentiable issue which cause difficulties for direct training SNNs\nbased on BP. The experimental results show that our proposed method achieves an\naverage accuracy of 99.56%, 93.08%, and 87.90% on MNIST, FashionMNIST, and\nCIFAR10, respectively with only 2 time steps. For the CIFAR10 dataset, our\nproposed method achieve 1.12% accuracy improvement over the previously reported\ndirect trained SNNs with fewer time steps.",
    "descriptor": "",
    "authors": [
      "Changqing Xu",
      "Yi Liu",
      "Yintang Yang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07426"
  },
  {
    "id": "arXiv:2112.07428",
    "title": "Obtaining Calibrated Probabilities with Personalized Ranking Models",
    "abstract": "For personalized ranking models, the well-calibrated probability of an item\nbeing preferred by a user has great practical value. While existing work shows\npromising results in image classification, probability calibration has not been\nmuch explored for personalized ranking. In this paper, we aim to estimate the\ncalibrated probability of how likely a user will prefer an item. We investigate\nvarious parametric distributions and propose two parametric calibration\nmethods, namely Gaussian calibration and Gamma calibration. Each proposed\nmethod can be seen as a post-processing function that maps the ranking scores\nof pre-trained models to well-calibrated preference probabilities, without\naffecting the recommendation performance. We also design the unbiased empirical\nrisk minimization framework that guides the calibration methods to learning of\ntrue preference probability from the biased user-item interaction dataset.\nExtensive evaluations with various personalized ranking models on real-world\ndatasets show that both the proposed calibration methods and the unbiased\nempirical risk minimization significantly improve the calibration performance.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Wonbin Kweon",
      "SeongKu Kang",
      "Hwanjo Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07428"
  },
  {
    "id": "arXiv:2112.07431",
    "title": "Uncertainty Estimation via Response Scaling for Pseudo-mask Noise  Mitigation in Weakly-supervised Semantic Segmentation",
    "abstract": "Weakly-Supervised Semantic Segmentation (WSSS) segments objects without a\nheavy burden of dense annotation. While as a price, generated pseudo-masks\nexist obvious noisy pixels, which result in sub-optimal segmentation models\ntrained over these pseudo-masks. But rare studies notice or work on this\nproblem, even these noisy pixels are inevitable after their improvements on\npseudo-mask. So we try to improve WSSS in the aspect of noise mitigation. And\nwe observe that many noisy pixels are of high confidence, especially when the\nresponse range is too wide or narrow, presenting an uncertain status. Thus, in\nthis paper, we simulate noisy variations of response by scaling the prediction\nmap multiple times for uncertainty estimation. The uncertainty is then used to\nweight the segmentation loss to mitigate noisy supervision signals. We call\nthis method URN, abbreviated from Uncertainty estimation via Response scaling\nfor Noise mitigation. Experiments validate the benefits of URN, and our method\nachieves state-of-the-art results at 71.2% and 41.5% on PASCAL VOC 2012 and MS\nCOCO 2014 respectively, without extra models like saliency detection. Code is\navailable at https://github.com/XMed-Lab/URN.",
    "descriptor": "\nComments: Accept at AAAI 2022, Code is available at this https URL\n",
    "authors": [
      "Yi Li",
      "Yiqun Duan",
      "Zhanghui Kuang",
      "Yimin Chen",
      "Wayne Zhang",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07431"
  },
  {
    "id": "arXiv:2112.07434",
    "title": "Exploring the Limits of Natural Language Inference Based Setup for  Few-Shot Intent Detection",
    "abstract": "One of the core components of goal-oriented dialog systems is the task of\nIntent Detection. Few-shot Learning upon Intent Detection is challenging due to\nthe scarcity of available annotated utterances. Although recent works making\nuse of metric-based and optimization-based methods have been proposed, the task\nis still challenging in large label spaces and much smaller number of shots.\nGeneralized Few-shot learning is more difficult due to the presence of both\nnovel and seen classes during the testing phase. In this work, we propose a\nsimple and effective method based on Natural Language Inference that not only\ntackles the problem of few shot intent detection, but also proves useful in\nzero-shot and generalized few shot learning problems. Our extensive experiments\non a number of Natural Language Understanding (NLU) and Spoken Language\nUnderstanding (SLU) datasets show the effectiveness of our approach. In\naddition, we highlight the settings in which our NLI based method outperforms\nthe baselines by huge margins.",
    "descriptor": "",
    "authors": [
      "Vijit Malik",
      "Ayush Kumar",
      "Jithendra Veppa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07434"
  },
  {
    "id": "arXiv:2112.07435",
    "title": "Multi-Leader Congestion Games with an Adversary",
    "abstract": "We study a multi-leader single-follower congestion game where multiple users\n(leaders) choose one resource out of a set of resources and, after observing\nthe realized loads, an adversary (single-follower) attacks the resources with\nmaximum loads, causing additional costs for the leaders. For the resulting\nstrategic game among the leaders, we show that pure Nash equilibria may fail to\nexist and therefore, we consider approximate equilibria instead. As our first\nmain result, we show that the existence of a $K$-approximate equilibrium can\nalways be guaranteed, where $K \\approx 1.1974$ is the unique solution of a\ncubic polynomial equation. To this end, we give a polynomial time combinatorial\nalgorithm which computes a $K$-approximate equilibrium. The factor $K$ is\ntight, meaning that there is an instance that does not admit an\n$\\alpha$-approximate equilibrium for any $\\alpha<K$. Thus $\\alpha=K$ is the\nsmallest possible value of $\\alpha$ such that the existence of an\n$\\alpha$-approximate equilibrium can be guaranteed for any instance of the\nconsidered game. Secondly, we focus on approximate equilibria of a given fixed\ninstance. We show how to compute efficiently a best approximate equilibrium,\nthat is, with smallest possible $\\alpha$ among all $\\alpha$-approximate\nequilibria of the given instance.",
    "descriptor": "",
    "authors": [
      "Tobias Harks",
      "Mona Henle",
      "Max Klimm",
      "Jannik Matuschke",
      "Anja Schedel"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.07435"
  },
  {
    "id": "arXiv:2112.07436",
    "title": "Graph Kernel Neural Networks",
    "abstract": "The convolution operator at the core of many modern neural architectures can\neffectively be seen as performing a dot product between an input matrix and a\nfilter. While this is readily applicable to data such as images, which can be\nrepresented as regular grids in the Euclidean space, extending the convolution\noperator to work on graphs proves more challenging, due to their irregular\nstructure. In this paper, we propose to use graph kernels, i.e., kernel\nfunctions that compute an inner product on graphs, to extend the standard\nconvolution operator to the graph domain. This allows us to define an entirely\nstructural model that does not require computing the embedding of the input\ngraph. Our architecture allows to plug-in any type and number of graph kernels\nand has the added benefit of providing some interpretability in terms of the\nstructural masks that are learned during the training process, similarly to\nwhat happens for convolutional masks in traditional convolutional neural\nnetworks. We perform an extensive ablation study to investigate the impact of\nthe model hyper-parameters and we show that our model achieves competitive\nperformance on standard graph classification datasets.",
    "descriptor": "",
    "authors": [
      "Luca Cosmo",
      "Giorgia Minello",
      "Michael Bronstein",
      "Emanuele Rodol\u00e0",
      "Luca Rossi",
      "Andrea Torsello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07436"
  },
  {
    "id": "arXiv:2112.07437",
    "title": "Bayesian Learning of Play Styles in Multiplayer Video Games",
    "abstract": "The complexity of game play in online multiplayer games has generated strong\ninterest in modeling the different play styles or strategies used by players\nfor success. We develop a hierarchical Bayesian regression approach for the\nonline multiplayer game Battlefield 3 where performance is modeled as a\nfunction of the roles, game type, and map taken on by that player in each of\ntheir matches. We use a Dirichlet process prior that enables the clustering of\nplayers that have similar player-specific coefficients in our regression model,\nwhich allows us to discover common play styles amongst our sample of\nBattlefield 3 players. This Bayesian semi-parametric clustering approach has\nseveral advantages: the number of common play styles do not need to be\nspecified, players can move between multiple clusters, and the resulting\ngroupings often have a straight-forward interpretations. We examine the most\ncommon play styles among Battlefield 3 players in detail and find groups of\nplayers that exhibit overall high performance, as well as groupings of players\nthat perform particularly well in specific game types, maps and roles. We are\nalso able to differentiate between players that are stable members of a\nparticular play style from hybrid players that exhibit multiple play styles\nacross their matches. Modeling this landscape of different play styles will aid\ngame developers in developing specialized tutorials for new participants as\nwell as improving the construction of complementary teams in their online\nmatching queues.",
    "descriptor": "",
    "authors": [
      "Aline Normoyle",
      "Shane T. Jensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.07437"
  },
  {
    "id": "arXiv:2112.07441",
    "title": "An Interpretive Constrained Linear Model for ResNet and MgNet",
    "abstract": "We propose a constrained linear data-feature-mapping model as an\ninterpretable mathematical model for image classification using a convolutional\nneural network (CNN). From this viewpoint, we establish detailed connections\nbetween the traditional iterative schemes for linear systems and the\narchitectures of the basic blocks of ResNet- and MgNet-type models. Using these\nconnections, we present some modified ResNet models that compared with the\noriginal models have fewer parameters and yet can produce more accurate\nresults, thereby demonstrating the validity of this constrained learning\ndata-feature-mapping assumption. Based on this assumption, we further propose a\ngeneral data-feature iterative scheme to show the rationality of MgNet. We also\nprovide a systematic numerical study on MgNet to show its success and\nadvantages in image classification problems and demonstrate its advantages in\ncomparison with established networks.",
    "descriptor": "\nComments: 26 pages, 2 figures and 11 tables. arXiv admin note: text overlap with arXiv:1911.10428\n",
    "authors": [
      "Juncai He",
      "Jinchao Xu",
      "Lian Zhang",
      "Jianqing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07441"
  },
  {
    "id": "arXiv:2112.07443",
    "title": "Text Classification Models for Form Entity Linking",
    "abstract": "Forms are a widespread type of template-based document used in a great\nvariety of fields including, among others, administration, medicine, finance,\nor insurance. The automatic extraction of the information included in these\ndocuments is greatly demanded due to the increasing volume of forms that are\ngenerated in a daily basis. However, this is not a straightforward task when\nworking with scanned forms because of the great diversity of templates with\ndifferent location of form entities, and the quality of the scanned documents.\nIn this context, there is a feature that is shared by all forms: they contain a\ncollection of interlinked entities built as key-value (or label-value) pairs,\ntogether with other entities such as headers or images. In this work, we have\ntacked the problem of entity linking in forms by combining image processing\ntechniques and a text classification model based on the BERT architecture. This\napproach achieves state-of-the-art results with a F1-score of 0.80 on the FUNSD\ndataset, a 5% improvement regarding the best previous method. The code of this\nproject is available at https://github.com/mavillot/FUNSD-Entity-Linking.",
    "descriptor": "",
    "authors": [
      "Mar\u00eda Villota",
      "C\u00e9sar Dom\u00ednguez",
      "J\u00f3nathan Heras",
      "Eloy Mata",
      "Vico Pascual"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07443"
  },
  {
    "id": "arXiv:2112.07447",
    "title": "Measuring Fairness with Biased Rulers: A Survey on Quantifying Biases in  Pretrained Language Models",
    "abstract": "An increasing awareness of biased patterns in natural language processing\nresources, like BERT, has motivated many metrics to quantify `bias' and\n`fairness'. But comparing the results of different metrics and the works that\nevaluate with such metrics remains difficult, if not outright impossible. We\nsurvey the existing literature on fairness metrics for pretrained language\nmodels and experimentally evaluate compatibility, including both biases in\nlanguage models as in their downstream tasks. We do this by a mixture of\ntraditional literature survey and correlation analysis, as well as by running\nempirical evaluations. We find that many metrics are not compatible and highly\ndepend on (i) templates, (ii) attribute and target seeds and (iii) the choice\nof embeddings. These results indicate that fairness or bias evaluation remains\nchallenging for contextualized language models, if not at least highly\nsubjective. To improve future comparisons and fairness evaluations, we\nrecommend avoiding embedding-based metrics and focusing on fairness evaluations\nin downstream tasks.",
    "descriptor": "\nComments: 15 pages, 4 figures, 3 tables\n",
    "authors": [
      "Pieter Delobelle",
      "Ewoenam Kwaku Tokpo",
      "Toon Calders",
      "Bettina Berendt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07447"
  },
  {
    "id": "arXiv:2112.07449",
    "title": "A faster algorithm for Cops and Robbers",
    "abstract": "We present an algorithm of time complexity $O(kn^{k+2})$ deciding whether a\ngraph $G$ on $n$ vertices is $k$-copwin. The fastest algorithm thus far had\ntime complexity $O(n^{2k+2})$.",
    "descriptor": "",
    "authors": [
      "Jan Petr",
      "Julien Portier",
      "Leo Versteegen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.07449"
  },
  {
    "id": "arXiv:2112.07456",
    "title": "On the Necessity and Sufficiency of Discrete-Time O'Shea-Zames-Falb  Multipliers",
    "abstract": "This paper considers the robust stability of a discrete-time Lurye system\nconsisting of the feedback interconnection between a linear system and a\nbounded and monotone nonlinearity. It has been conjectured that the existence\nof a suitable linear time-invariant (LTI) O'Shea-Zames-Falb multiplier is not\nonly sufficient but also necessary. Roughly speaking, a successful proof of the\nconjecture would require: (a) a conic parameterization of a set of multipliers\nthat describes exactly the set of nonlinearities, (b) a lossless S-procedure to\nshow that the non-existence of a multiplier implies that the Lurye system is\nnot uniformly robustly stable over the set of nonlinearities, and (c) the\nexistence of a multiplier in the set of multipliers used in (a) implies the\nexistence of an LTI multiplier. We investigate these three steps, showing the\ncurrent bottlenecks for proving this conjecture. In addition, we provide an\nextension of the class of multipliers which may be used to disprove the\nconjecture.",
    "descriptor": "\nComments: 25 Pages\n",
    "authors": [
      "Lanlan Su",
      "Peter Seiler",
      "Joaquin Carrasco",
      "Sei Zhen Khong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07456"
  },
  {
    "id": "arXiv:2112.07459",
    "title": "Scale-Aware Neural Architecture Search for Multivariate Time Series  Forecasting",
    "abstract": "Multivariate time series (MTS) forecasting has attracted much attention in\nmany intelligent applications. It is not a trivial task, as we need to consider\nboth intra-variable dependencies and inter-variable dependencies. However,\nexisting works are designed for specific scenarios, and require much domain\nknowledge and expert efforts, which is difficult to transfer between different\nscenarios. In this paper, we propose a scale-aware neural architecture search\nframework for MTS forecasting (SNAS4MTF). A multi-scale decomposition module\ntransforms raw time series into multi-scale sub-series, which can preserve\nmulti-scale temporal patterns. An adaptive graph learning module infers the\ndifferent inter-variable dependencies under different time scales without any\nprior knowledge. For MTS forecasting, a search space is designed to capture\nboth intra-variable dependencies and inter-variable dependencies at each time\nscale. The multi-scale decomposition, adaptive graph learning, and neural\narchitecture search modules are jointly learned in an end-to-end framework.\nExtensive experiments on two real-world datasets demonstrate that SNAS4MTF\nachieves a promising performance compared with the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Donghui Chen",
      "Ling Chen",
      "Zongjiang Shang",
      "Youdong Zhang",
      "Bo Wen",
      "Chenghu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07459"
  },
  {
    "id": "arXiv:2112.07463",
    "title": "End-to-end speaker diarization with transformer",
    "abstract": "Speaker diarization is connected to semantic segmentation in computer vision.\nInspired from MaskFormer \\cite{cheng2021per} which treats semantic segmentation\nas a set-prediction problem, we propose an end-to-end approach to predict a set\nof targets consisting of binary masks, vocal activities and speaker vectors.\nOur model, which we coin \\textit{DiFormer}, is mainly based on a speaker\nencoder and a feature pyramid network (FPN) module to extract multi-scale\nspeaker features which are then fed into a transformer encoder-decoder to\npredict a set of diarization targets from learned query embedding. To account\nfor temporal characteristics of speech signal, bidirectional LSTMs are inserted\ninto the mask prediction module to improve temporal consistency. Our model\nhandles unknown number of speakers, speech overlaps, as well as vocal activity\ndetection in a unified way. Experiments on multimedia and meeting datasets\ndemonstrate the effectiveness of our approach.",
    "descriptor": "\nComments: submitted to icassp2022\n",
    "authors": [
      "Yongquan Lai",
      "Xin Tang",
      "Yuanyuan Fu",
      "Rui Fang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.07463"
  },
  {
    "id": "arXiv:2112.07467",
    "title": "AI Ethics Principles in Practice: Perspectives of Designers and  Developers",
    "abstract": "As consensus across the various published AI ethics principles is approached,\na gap remains between high-level principles and practical techniques that can\nbe readily adopted to design and develop responsible AI systems. We examine the\npractices and experiences of researchers and engineers from Australia's\nnational scientific research agency (CSIRO), who are involved in designing and\ndeveloping AI systems for a range of purposes. Semi-structured interviews were\nused to examine how the practices of the participants relate to and align with\na set of high-level AI ethics principles that are proposed by the Australian\nGovernment. The principles comprise: Privacy Protection & Security, Reliability\n& Safety, Transparency & Explainability, Fairness, Contestability,\nAccountability, Human-centred Values, and Human, Social & Environmental\nWellbeing. The insights of the researchers and engineers as well as the\nchallenges that arose for them in the practical application of the principles\nare examined. Finally, a set of organisational responses are provided to\nsupport the implementation of high-level AI ethics principles into practice.",
    "descriptor": "",
    "authors": [
      "Conrad Sanderson",
      "David Douglas",
      "Qinghua Lu",
      "Emma Schleiger",
      "Jon Whittle",
      "Justine Lacey",
      "Glenn Newnham",
      "Stefan Hajkowicz",
      "Cathy Robinson",
      "David Hansen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07467"
  },
  {
    "id": "arXiv:2112.07471",
    "title": "I M Avatar: Implicit Morphable Head Avatars from Videos",
    "abstract": "Traditional morphable face models provide fine-grained control over\nexpression but cannot easily capture geometric and appearance details. Neural\nvolumetric representations approach photo-realism but are hard to animate and\ndo not generalize well to unseen expressions. To tackle this problem, we\npropose IMavatar (Implicit Morphable avatar), a novel method for learning\nimplicit head avatars from monocular videos. Inspired by the fine-grained\ncontrol mechanisms afforded by conventional 3DMMs, we represent the expression-\nand pose-related deformations via learned blendshapes and skinning fields.\nThese attributes are pose-independent and can be used to morph the canonical\ngeometry and texture fields given novel expression and pose parameters. We\nemploy ray tracing and iterative root-finding to locate the canonical surface\nintersection for each pixel. A key contribution is our novel analytical\ngradient formulation that enables end-to-end training of IMavatars from videos.\nWe show quantitatively and qualitatively that our method improves geometry and\ncovers a more complete expression space compared to state-of-the-art methods.",
    "descriptor": "\nComments: Submitted to CVPR 2022\n",
    "authors": [
      "Yufeng Zheng",
      "Victoria Fern\u00e1ndez Abrevaya",
      "Xu Chen",
      "Marcel C. B\u00fchler",
      "Michael J. Black",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07471"
  },
  {
    "id": "arXiv:2112.07475",
    "title": "Two Contrasting Data Annotation Paradigms for Subjective NLP Tasks",
    "abstract": "Labelled data is the foundation of most natural language processing tasks.\nHowever, labelling data is difficult and there often are diverse valid beliefs\nabout what the correct data labels should be. So far, dataset creators have\nacknowledged annotator subjectivity, but not actively managed it in the\nannotation process. This has led to partly-subjective datasets that fail to\nserve a clear downstream use. To address this issue, we propose two contrasting\nparadigms for data annotation. The descriptive paradigm encourages annotator\nsubjectivity, whereas the prescriptive paradigm discourages it. Descriptive\nannotation allows for the surveying and modelling of different beliefs, whereas\nprescriptive annotation enables the training of models that consistently apply\none belief. We discuss benefits and challenges in implementing both paradigms,\nand argue that dataset creators should explicitly aim for one or the other to\nfacilitate the intended use of their dataset. Lastly, we design an annotation\nexperiment to illustrate the contrast between the two paradigms.",
    "descriptor": "",
    "authors": [
      "Paul R\u00f6ttger",
      "Bertie Vidgen",
      "Dirk Hovy",
      "Janet B. Pierrehumbert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07475"
  },
  {
    "id": "arXiv:2112.07485",
    "title": "Pruning Coherent Integrated Photonic Neural Networks Using the Lottery  Ticket Hypothesis",
    "abstract": "Singular-value-decomposition-based coherent integrated photonic neural\nnetworks (SC-IPNNs) have a large footprint, suffer from high static power\nconsumption for training and inference, and cannot be pruned using conventional\nDNN pruning techniques. We leverage the lottery ticket hypothesis to propose\nthe first hardware-aware pruning method for SC-IPNNs that alleviates these\nchallenges by minimizing the number of weight parameters. We prune a\nmulti-layer perceptron-based SC-IPNN and show that up to 89% of the phase\nangles, which correspond to weight parameters in SC-IPNNs, can be pruned with a\nnegligible accuracy loss (smaller than 5%) while reducing the static power\nconsumption by up to 86%.",
    "descriptor": "",
    "authors": [
      "Sanmitra Banerjee",
      "Mahdi Nikdast",
      "Sudeep Pasricha",
      "Krishnendu Chakrabarty"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2112.07485"
  },
  {
    "id": "arXiv:2112.07493",
    "title": "EABlock: A Declarative Entity Alignment Block for Knowledge Graph  Creation Pipelines",
    "abstract": "Despite encoding enormous amount of rich and valuable data, existing data\nsources are mostly created independently, being a significant challenge to\ntheir integration. Mapping languages, e.g., RML and R2RML, facilitate\ndeclarative specification of the process of applying meta-data and integrating\ndata into a knowledge graph. Mapping rules can also include knowledge\nextraction functions in addition to expressing correspondences among data\nsources and a unified schema. Combining mapping rules and functions represents\na powerful formalism to specify pipelines for integrating data into a knowledge\ngraph transparently. Surprisingly, these formalisms are not fully adapted, and\nmany knowledge graphs are created by executing ad-hoc programs to pre-process\nand integrate data. In this paper, we present EABlock, an approach integrating\nEntity Alignment (EA) as part of RML mapping rules. EABlock includes a block of\nfunctions performing entity recognition from textual attributes and link the\nrecognized entities to the corresponding resources in Wikidata, DBpedia, and\ndomain specific thesaurus, e.g., UMLS. EABlock provides agnostic and efficient\ntechniques to evaluate the functions and transfer the mappings to facilitate\nits application in any RML-compliant engine. We have empirically evaluated\nEABlock performance, and results indicate that EABlock speeds up knowledge\ngraph creation pipelines that require entity recognition and linking in\nstate-of-the-art RML-compliant engines. EABlock is also publicly available as a\ntool through a GitHub repository(https://github.com/SDM-TIB/EABlock) and a\nDOI(https://doi.org/10.5281/zenodo.5779773).",
    "descriptor": "",
    "authors": [
      "Samaneh Jozashoori",
      "Ahmad Sakor",
      "Enrique Iglesias",
      "Maria-Esther Vidal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07493"
  },
  {
    "id": "arXiv:2112.07497",
    "title": "Sentiment Dynamics of Success: Fractal Scaling of Story Arcs Predicts  Reader Preferences",
    "abstract": "We explore the correlation between the sentiment arcs of H. C. Andersen's\nfairy tales and their popularity, measured as their average score on the\nplatform GoodReads. Specifically, we do not conceive a story's overall\nsentimental trend as predictive \\textit{per se}, but we focus on its coherence\nand predictability over time as represented by the arc's Hurst exponent. We\nfind that degrading Hurst values tend to imply degrading quality scores, while\na Hurst exponent between .55 and .65 might indicate a \"sweet spot\" for literary\nappreciation.",
    "descriptor": "",
    "authors": [
      "Yuri Bizzoni",
      "Telma Peura",
      "Mads R. Thomsen",
      "Kristoffer Nielbo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07497"
  },
  {
    "id": "arXiv:2112.07498",
    "title": "Phishing in Organizations: Findings from a Large-Scale and Long-Term  Study",
    "abstract": "In this paper, we present findings from a large-scale and long-term phishing\nexperiment that we conducted in collaboration with a partner company. Our\nexperiment ran for 15 months during which time more than 14,000 study\nparticipants (employees of the company) received different simulated phishing\nemails in their normal working context. We also deployed a reporting button to\nthe company's email client which allowed the participants to report suspicious\nemails they received. We measured click rates for phishing emails, dangerous\nactions such as submitting credentials, and reported suspicious emails.\nThe results of our experiment provide three types of contributions. First,\nsome of our findings support previous literature with improved ecological\nvalidity. One example of such results is good effectiveness of warnings on\nemails. Second, some of our results contradict prior literature and common\nindustry practices. Surprisingly, we find that embedded training during\nsimulated phishing exercises, as commonly deployed in the industry today, does\nnot make employees more resilient to phishing, but instead it can have\nunexpected side effects that can make employees even more susceptible to\nphishing. And third, we report new findings. In particular, we are the first to\ndemonstrate that using the employees as a collective phishing detection\nmechanism is practical in large organizations. Our results show that such\ncrowd-sourcing allows fast detection of new phishing campaigns, the operational\nload for the organization is acceptable, and the employees remain active over\nlong periods of time.",
    "descriptor": "\nComments: To appear in IEEE S&P 2022\n",
    "authors": [
      "Daniele Lain",
      "Kari Kostiainen",
      "Srdjan Capkun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.07498"
  },
  {
    "id": "arXiv:2112.07499",
    "title": "Reconfiguring Shortest Paths in Graphs",
    "abstract": "Reconfiguring two shortest paths in a graph means modifying one shortest path\nto the other by changing one vertex at a time so that all the intermediate\npaths are also shortest paths. This problem has several natural applications,\nnamely: (a) revamping road networks, (b) rerouting data packets in synchronous\nmultiprocessing setting, (c) the shipping container stowage problem, and (d)\nthe train marshalling problem.\nWhen modelled as graph problems, (a) is the most general case while (b), (c)\nand (d) are restrictions to different graph classes. We show that (a) is\nintractable, even for relaxed variants of the problem. For (b), (c) and (d), we\npresent efficient algorithms to solve the respective problems. We also\ngeneralize the problem to when at most $k$ (for a fixed integer $k\\geq 2$)\ncontiguous vertices on a shortest path can be changed at a time.",
    "descriptor": "\nComments: 28 pages, 14 figures. To be presented at AAAI 2022\n",
    "authors": [
      "Kshitij Gajjar",
      "Agastya Vibhuti Jha",
      "Manish Kumar",
      "Abhiruk Lahiri"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.07499"
  },
  {
    "id": "arXiv:2112.07507",
    "title": "Towards Organic Distribution Systems -- The Vision of Self-Configuring,  Self-Organising, Self-Healing, and Self-Optimising Power Distribution  Management",
    "abstract": "Due to the decarbonisation of energy use, the power system is expected to\nbecome the backbone of all energy sectors and thus the basic critical\ninfrastructure. High penetration with distributed energy resources demands the\ncoordination of a large number of prosumers, partly controlled by home energy\nmanagement systems (HEMS), to be designed in such a way that the power system's\noperational limits are not violated. On the grid level, distribution management\nsystems (DMS) try to keep the power system in the normal operational state. On\nthe prosumer level, distributed HEMS optimise the internal power flows by using\nbatteries, photovoltaic generators, or flexible loads optimally. The vision of\nthe ODiS (Organic Distribution System) initiative is to develop an architecture\nto operate a distribution grid reliably, with high resiliency, and fully\nautonomously by developing \"organic\" HEMS and DMS which possess multiple self-*\ncapabilities. Thus, ODiS seeks answers to the following question: How can we\ncreate the most appropriate models, techniques, and algorithms to develop novel\nkinds of self-configuring, self-organising, self-healing, and self-optimising\nDMS that are integrally coupled with the distributed HEMS? In this article, the\nvision of ODiS is presented in detail based on a thorough review of the state\nof the art.",
    "descriptor": "\nComments: Preprint submitted to Energies\n",
    "authors": [
      "Inga Loeser",
      "Martin Braun",
      "Christian Gruhl",
      "Jan-Hendrik Menke",
      "Bernhard Sick",
      "Sven Tomforde"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07507"
  },
  {
    "id": "arXiv:2112.07508",
    "title": "Anti-Money Laundering Alert Optimization Using Machine Learning with  Graphs",
    "abstract": "Money laundering is a global problem that concerns legitimizing proceeds from\nserious felonies (1.7-4 trillion euros annually) such as drug dealing, human\ntrafficking, or corruption. The anti-money laundering systems deployed by\nfinancial institutions typically comprise rules aligned with regulatory\nframeworks. Human investigators review the alerts and report suspicious cases.\nSuch systems suffer from high false-positive rates, undermining their\neffectiveness and resulting in high operational costs. We propose a machine\nlearning triage model, which complements the rule-based system and learns to\npredict the risk of an alert accurately. Our model uses both entity-centric\nengineered features and attributes characterizing inter-entity relations in the\nform of graph-based features. We leverage time windows to construct the dynamic\ngraph, optimizing for time and space efficiency. We validate our model on a\nreal-world banking dataset and show how the triage model can reduce the number\nof false positives by 80% while detecting over 90% of true positives. In this\nway, our model can significantly improve anti-money laundering operations.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Ahmad Naser Eddin",
      "Jacopo Bono",
      "David Apar\u00edcio",
      "David Polido",
      "Jo\u00e3o Tiago Ascens\u00e3o",
      "Pedro Bizarro",
      "Pedro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07508"
  },
  {
    "id": "arXiv:2112.07509",
    "title": "Liquid Democracy with Ranked Delegations",
    "abstract": "Liquid democracy is a novel paradigm for collective decision-making that\ngives agents the choice between casting a direct vote or delegating their vote\nto another agent. We consider a generalization of the standard liquid democracy\nsetting by allowing agents to specify multiple potential delegates, together\nwith a preference ranking among them. This generalization increases the number\nof possible delegation paths and enables higher participation rates because\nfewer votes are lost due to delegation cycles or abstaining agents. In order to\nimplement this generalization of liquid democracy, we need to find a principled\nway of choosing between multiple delegation paths. In this paper, we provide a\nthorough axiomatic analysis of the space of delegation rules, i.e., functions\nassigning a feasible delegation path to each delegating agent. In particular,\nwe prove axiomatic characterizations as well as an impossibility result for\ndelegation rules. We also analyze requirements on delegation rules that have\nbeen suggested by practitioners, and introduce novel rules with attractive\nproperties. By performing an extensive experimental analysis on synthetic as\nwell as real-world data, we compare delegation rules with respect to several\nquantitative criteria relating to the chosen paths and the resulting\ndistribution of voting power. Our experiments reveal that delegation rules can\nbe aligned on a spectrum reflecting an inherent trade-off between competing\nobjectives.",
    "descriptor": "\nComments: Accepted at AAAI 2022\n",
    "authors": [
      "Markus Brill",
      "Th\u00e9o Delemazure",
      "Anne-Marie George",
      "Martin Lackner",
      "Ulrike Schmidt-Kraepelin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.07509"
  },
  {
    "id": "arXiv:2112.07512",
    "title": "Adversarial Examples for Extreme Multilabel Text Classification",
    "abstract": "Extreme Multilabel Text Classification (XMTC) is a text classification\nproblem in which, (i) the output space is extremely large, (ii) each data point\nmay have multiple positive labels, and (iii) the data follows a strongly\nimbalanced distribution. With applications in recommendation systems and\nautomatic tagging of web-scale documents, the research on XMTC has been focused\non improving prediction accuracy and dealing with imbalanced data. However, the\nrobustness of deep learning based XMTC models against adversarial examples has\nbeen largely underexplored.\nIn this paper, we investigate the behaviour of XMTC models under adversarial\nattacks. To this end, first, we define adversarial attacks in multilabel text\nclassification problems. We categorize attacking multilabel text classifiers as\n(a) positive-targeted, where the target positive label should fall out of top-k\npredicted labels, and (b) negative-targeted, where the target negative label\nshould be among the top-k predicted labels. Then, by experiments on APLC-XLNet\nand AttentionXML, we show that XMTC models are highly vulnerable to\npositive-targeted attacks but more robust to negative-targeted ones.\nFurthermore, our experiments show that the success rate of positive-targeted\nadversarial attacks has an imbalanced distribution. More precisely, tail\nclasses are highly vulnerable to adversarial attacks for which an attacker can\ngenerate adversarial samples with high similarity to the actual data-points. To\novercome this problem, we explore the effect of rebalanced loss functions in\nXMTC where not only do they increase accuracy on tail classes, but they also\nimprove the robustness of these classes against adversarial attacks. The code\nfor our experiments is available at https://github.com/xmc-aalto/adv-xmtc",
    "descriptor": "",
    "authors": [
      "Mohammadreza Qaraei",
      "Rohit Babbar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07512"
  },
  {
    "id": "arXiv:2112.07513",
    "title": "CORE-Text: Improving Scene Text Detection with Contrastive Relational  Reasoning",
    "abstract": "Localizing text instances in natural scenes is regarded as a fundamental\nchallenge in computer vision. Nevertheless, owing to the extremely varied\naspect ratios and scales of text instances in real scenes, most conventional\ntext detectors suffer from the sub-text problem that only localizes the\nfragments of text instance (i.e., sub-texts). In this work, we quantitatively\nanalyze the sub-text problem and present a simple yet effective design,\nCOntrastive RElation (CORE) module, to mitigate that issue. CORE first\nleverages a vanilla relation block to model the relations among all text\nproposals (sub-texts of multiple text instances) and further enhances\nrelational reasoning via instance-level sub-text discrimination in a\ncontrastive manner. Such way naturally learns instance-aware representations of\ntext proposals and thus facilitates scene text detection. We integrate the CORE\nmodule into a two-stage text detector of Mask R-CNN and devise our text\ndetector CORE-Text. Extensive experiments on four benchmarks demonstrate the\nsuperiority of CORE-Text. Code is available:\n\\url{https://github.com/jylins/CORE-Text}.",
    "descriptor": "\nComments: ICME 2021 (Oral); Code is publicly available at: this https URL\n",
    "authors": [
      "Jingyang Lin",
      "Yingwei Pan",
      "Rongfeng Lai",
      "Xuehang Yang",
      "Hongyang Chao",
      "Ting Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.07513"
  },
  {
    "id": "arXiv:2112.07515",
    "title": "CoCo-BERT: Improving Video-Language Pre-training with Contrastive  Cross-modal Matching and Denoising",
    "abstract": "BERT-type structure has led to the revolution of vision-language pre-training\nand the achievement of state-of-the-art results on numerous vision-language\ndownstream tasks. Existing solutions dominantly capitalize on the multi-modal\ninputs with mask tokens to trigger mask-based proxy pre-training tasks (e.g.,\nmasked language modeling and masked object/frame prediction). In this work, we\nargue that such masked inputs would inevitably introduce noise for cross-modal\nmatching proxy task, and thus leave the inherent vision-language association\nunder-explored. As an alternative, we derive a particular form of cross-modal\nproxy objective for video-language pre-training, i.e., Contrastive Cross-modal\nmatching and denoising (CoCo). By viewing the masked frame/word sequences as\nthe noisy augmentation of primary unmasked ones, CoCo strengthens\nvideo-language association by simultaneously pursuing inter-modal matching and\nintra-modal denoising between masked and unmasked inputs in a contrastive\nmanner. Our CoCo proxy objective can be further integrated into any BERT-type\nencoder-decoder structure for video-language pre-training, named as Contrastive\nCross-modal BERT (CoCo-BERT). We pre-train CoCo-BERT on TV dataset and a newly\ncollected large-scale GIF video dataset (ACTION). Through extensive experiments\nover a wide range of downstream tasks (e.g., cross-modal retrieval, video\nquestion answering, and video captioning), we demonstrate the superiority of\nCoCo-BERT as a pre-trained structure.",
    "descriptor": "\nComments: ACM Multimedia 2021\n",
    "authors": [
      "Jianjie Luo",
      "Yehao Li",
      "Yingwei Pan",
      "Ting Yao",
      "Hongyang Chao",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.07515"
  },
  {
    "id": "arXiv:2112.07516",
    "title": "Transferrable Contrastive Learning for Visual Domain Adaptation",
    "abstract": "Self-supervised learning (SSL) has recently become the favorite among feature\nlearning methodologies. It is therefore appealing for domain adaptation\napproaches to consider incorporating SSL. The intuition is to enforce\ninstance-level feature consistency such that the predictor becomes somehow\ninvariant across domains. However, most existing SSL methods in the regime of\ndomain adaptation usually are treated as standalone auxiliary components,\nleaving the signatures of domain adaptation unattended. Actually, the optimal\nregion where the domain gap vanishes and the instance level constraint that SSL\nperuses may not coincide at all. From this point, we present a particular\nparadigm of self-supervised learning tailored for domain adaptation, i.e.,\nTransferrable Contrastive Learning (TCL), which links the SSL and the desired\ncross-domain transferability congruently. We find contrastive learning\nintrinsically a suitable candidate for domain adaptation, as its instance\ninvariance assumption can be conveniently promoted to cross-domain class-level\ninvariance favored by domain adaptation tasks. Based on particular memory bank\nconstructions and pseudo label strategies, TCL then penalizes cross-domain\nintra-class domain discrepancy between source and target through a clean and\nnovel contrastive loss. The free lunch is, thanks to the incorporation of\ncontrastive learning, TCL relies on a moving-averaged key encoder that\nnaturally achieves a temporally ensembled version of pseudo labels for target\ndata, which avoids pseudo label error propagation at no extra cost. TCL\ntherefore efficiently reduces cross-domain gaps. Through extensive experiments\non benchmarks (Office-Home, VisDA-2017, Digits-five, PACS and DomainNet) for\nboth single-source and multi-source domain adaptation tasks, TCL has\ndemonstrated state-of-the-art performances.",
    "descriptor": "\nComments: ACM Multimedia 2021\n",
    "authors": [
      "Yang Chen",
      "Yingwei Pan",
      "Yu Wang",
      "Ting Yao",
      "Xinmei Tian",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.07516"
  },
  {
    "id": "arXiv:2112.07517",
    "title": "A Style and Semantic Memory Mechanism for Domain Generalization",
    "abstract": "Mainstream state-of-the-art domain generalization algorithms tend to\nprioritize the assumption on semantic invariance across domains. Meanwhile, the\ninherent intra-domain style invariance is usually underappreciated and put on\nthe shelf. In this paper, we reveal that leveraging intra-domain style\ninvariance is also of pivotal importance in improving the efficiency of domain\ngeneralization. We verify that it is critical for the network to be informative\non what domain features are invariant and shared among instances, so that the\nnetwork sharpens its understanding and improves its semantic discriminative\nability. Correspondingly, we also propose a novel \"jury\" mechanism, which is\nparticularly effective in learning useful semantic feature commonalities among\ndomains. Our complete model called STEAM can be interpreted as a novel\nprobabilistic graphical model, for which the implementation requires convenient\nconstructions of two kinds of memory banks: semantic feature bank and style\nfeature bank. Empirical results show that our proposed framework surpasses the\nstate-of-the-art methods by clear margins.",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Yang Chen",
      "Yu Wang",
      "Yingwei Pan",
      "Ting Yao",
      "Xinmei Tian",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07517"
  },
  {
    "id": "arXiv:2112.07522",
    "title": "LMTurk: Few-Shot Learners as Crowdsourcing Workers",
    "abstract": "Vast efforts have been devoted to creating high-performance few-shot\nlearners, i.e., models that perform well with little training data. Training\nlarge-scale pretrained language models (PLMs) has incurred significant cost,\nbut utilizing PLM-based few-shot learners is still challenging due to their\nenormous size. This work focuses on a crucial question: How to make effective\nuse of these few-shot learners? We propose LMTurk, a novel approach that treats\nfew-shot learners as crowdsourcing workers. The rationale is that crowdsourcing\nworkers are in fact few-shot learners: They are shown a few illustrative\nexamples to learn about a task and then start annotating. LMTurk employs\nfew-shot learners built upon PLMs as workers. We show that the resulting\nannotations can be utilized to train models that solve the task well and are\nsmall enough to be deployable in practical scenarios. Altogether, LMTurk is an\nimportant step towards making effective use of current PLM-based few-shot\nlearners.",
    "descriptor": "",
    "authors": [
      "Mengjie Zhao",
      "Fei Mi",
      "Yasheng Wang",
      "Minglei Li",
      "Xin Jiang",
      "Qun Liu",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07522"
  },
  {
    "id": "arXiv:2112.07524",
    "title": "Edge-trewidth: Algorithmic and combinatorial properties",
    "abstract": "We introduce the graph theoretical parameter of edge treewidth. This\nparameter occurs in a natural way as the tree-like analogue of cutwidth or,\nalternatively, as an edge-analogue of treewidth. We study the combinatorial\nproperties of edge-treewidth. We first observe that edge-treewidth does not\nenjoy any closeness properties under the known partial ordering relations on\ngraphs. We introduce a variant of the topological minor relation, namely, the\nweak topological minor relation and we prove that edge-treewidth is closed\nunder weak topological minors. Based on this new relation we are able to\nprovide universal obstructions for edge-treewidth. The proofs are based on the\nfact that edge-treewidth of a graph is parametetrically equivalent with the\nmaximum over the treewidth and the maximum degree of the blocks of the graph.\nWe also prove that deciding whether the edge-treewidth of a graph is at most k\nis an NP-complete problem.",
    "descriptor": "\nComments: 22 pages, 10 figures\n",
    "authors": [
      "Lo\u00efc Magne",
      "Christophe Paul",
      "Abhijat Sharma",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.07524"
  },
  {
    "id": "arXiv:2112.07525",
    "title": "On Improving Resource Allocations by Sharing",
    "abstract": "Given an initial resource allocation, where some agents may envy others or\nwhere a different distribution of resources might lead to higher social\nwelfare, our goal is to improve the allocation without reassigning resources.\nWe consider a sharing concept allowing resources being shared with social\nnetwork neighbors of the resource owners. To this end, we introduce a formal\nmodel that allows a central authority to compute an optimal sharing between\nneighbors based on an initial allocation. Advocating this point of view, we\nfocus on the most basic scenario where a resource may be shared by two\nneighbors in a social network and each agent can participate in a bounded\nnumber of sharings. We present algorithms for optimizing utilitarian and\negalitarian social welfare of allocations and for reducing the number of\nenvious agents. In particular, we examine the computational complexity with\nrespect to several natural parameters. Furthermore, we study cases with\nrestricted social network structures and, among others, devise polynomial-time\nalgorithms in path- and tree-like (hierarchical) social networks.",
    "descriptor": "\nComments: Accepted at the 36th AAAI Conference on Artificial Intelligence, AAAI-22\n",
    "authors": [
      "Robert Bredereck",
      "Andrzej Kaczmarczyk",
      "Junjie Luo",
      "Rolf Niedermeier",
      "Florian Sachse"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computers and Society (cs.CY)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.07525"
  },
  {
    "id": "arXiv:2112.07528",
    "title": "$n$-CPS: Generalising Cross Pseudo Supervision to $n$ networks for  Semi-Supervised Semantic Segmentation",
    "abstract": "We present $n$-CPS - a generalisation of the recent state-of-the-art cross\npseudo supervision (CPS) approach for the task of semi-supervised semantic\nsegmentation. In $n$-CPS, there are $n$ simultaneously trained subnetworks that\nlearn from each other through one-hot encoding perturbation and consistency\nregularisation. We also show that ensembling techniques applied to subnetworks\noutputs can significantly improve the performance. To the best of our\nknowledge, $n$-CPS paired with CutMix outperforms CPS and sets the new\nstate-of-the-art for Pascal VOC 2012 with (1/16, 1/8, 1/4, and 1/2 supervised\nregimes) and Cityscapes (1/16 supervised).",
    "descriptor": "",
    "authors": [
      "Dominik Filipiak",
      "Piotr Tempczyk",
      "Marek Cygan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07528"
  },
  {
    "id": "arXiv:2112.07532",
    "title": "Simulating Random Walks in Random Streams",
    "abstract": "The random order graph streaming model has received significant attention\nrecently, with problems such as matching size estimation, component counting,\nand the evaluation of bounded degree constant query testable properties shown\nto admit surprisingly space efficient algorithms.\nThe main result of this paper is a space efficient single pass random order\nstreaming algorithm for simulating nearly independent random walks that start\nat uniformly random vertices. We show that the distribution of $k$-step walks\nfrom $b$ vertices chosen uniformly at random can be approximated up to error\n$\\varepsilon$ per walk using $(1/\\varepsilon)^{O(k)} 2^{O(k^2)}\\cdot b$ words\nof space with a single pass over a randomly ordered stream of edges, solving an\nopen problem of Peng and Sohler [SODA `18]. Applications of our result include\nthe estimation of the average return probability of the $k$-step walk (the\ntrace of the $k^\\text{th}$ power of the random walk matrix) as well as the\nestimation of PageRank. We complement our algorithm with a strong impossibility\nresult for directed graphs.",
    "descriptor": "",
    "authors": [
      "John Kallaugher",
      "Michael Kapralov",
      "Eric Price"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.07532"
  },
  {
    "id": "arXiv:2112.07534",
    "title": "Reinforced Abstractive Summarization with Adaptive Length Controlling",
    "abstract": "Document summarization, as a fundamental task in natural language generation,\naims to generate a short and coherent summary for a given document.\nControllable summarization, especially of the length, is an important issue for\nsome practical applications, especially how to trade-off the length constraint\nand information integrity. In this paper, we propose an \\textbf{A}daptive\n\\textbf{L}ength \\textbf{C}ontrolling \\textbf{O}ptimization (\\textbf{ALCO})\nmethod to leverage two-stage abstractive summarization model via reinforcement\nlearning. ALCO incorporates length constraint into the stage of sentence\nextraction to penalize the overlength extracted sentences. Meanwhile, a\nsaliency estimation mechanism is designed to preserve the salient information\nin the generated sentences. A series of experiments have been conducted on a\nwildly-used benchmark dataset \\textit{CNN/Daily Mail}. The results have shown\nthat ALCO performs better than the popular baselines in terms of length\ncontrollability and content preservation.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Mingyang Song",
      "Yi Feng",
      "Liping Jing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07534"
  },
  {
    "id": "arXiv:2112.07535",
    "title": "Scientific Discovery and the Cost of Measurement -- Balancing  Information and Cost in Reinforcement Learning",
    "abstract": "The use of reinforcement learning (RL) in scientific applications, such as\nmaterials design and automated chemistry, is increasing. A major challenge,\nhowever, lies in fact that measuring the state of the system is often costly\nand time consuming in scientific applications, whereas policy learning with RL\nrequires a measurement after each time step. In this work, we make the\nmeasurement costs explicit in the form of a costed reward and propose a\nframework that enables off-the-shelf deep RL algorithms to learn a policy for\nboth selecting actions and determining whether or not to measure the current\nstate of the system at each time step. In this way, the agents learn to balance\nthe need for information with the cost of information. Our results show that\nwhen trained under this regime, the Dueling DQN and PPO agents can learn\noptimal action policies whilst making up to 50\\% fewer state measurements, and\nrecurrent neural networks can produce a greater than 50\\% reduction in\nmeasurements. We postulate the these reduction can help to lower the barrier to\napplying RL to real-world scientific applications.",
    "descriptor": "\nComments: To appear in: 1st Annual AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE)\n",
    "authors": [
      "Colin Bellinger",
      "Andriy Drozdyuk",
      "Mark Crowley",
      "Isaac Tamblyn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07535"
  },
  {
    "id": "arXiv:2112.07536",
    "title": "Scaling Up Query-Focused Summarization to Meet Open-Domain Question  Answering",
    "abstract": "Query-focused summarization (QFS) requires generating a textual summary given\na query using a set of relevant documents. However, in practice, such relevant\ndocuments are not readily available but should be first retrieved from a\ndocument collection. Therefore, we show how to extend this task to make it more\nrealistic. Thereby the task setup also resembles the settings of the\nopen-domain question answering task, where the answer is a summary of the\ntop-retrieved documents. To address this extended task, we combine passage\nretrieval with text generation to produce the summary of the retrieved passages\ngiven the input query. We demonstrate the first evaluation results on the\nproposed task and show that a few samples are sufficient to fine-tune a large\ngenerative model with retrieved passages.",
    "descriptor": "",
    "authors": [
      "Weijia Zhang",
      "Svitlana Vakulenko",
      "Thilina Rajapakse",
      "Evangelos Kanoulas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.07536"
  },
  {
    "id": "arXiv:2112.07537",
    "title": "MURPHY -- A scalable multiresolution framework for scientific computing  on 3D block-structured collocated grids",
    "abstract": "We present the derivation, implementation, and analysis of a multiresolution\nadaptive grid framework for numerical simulations on 3D block-structured\ncollocated grids with distributed computational architectures. Our approach\nprovides a consistent handling of non-lifted and lifted interpolating wavelets\nof arbitrary order demonstrated using second, fourth, and sixth order wavelets,\nand combines that with standard finite-difference based discretization\noperators. We first validate that the wavelet family used provides strict and\nexplicit error control when coarsening the grid, that lifting wavelets increase\nthe grid compression rate while conserving discrete moments across levels, and\nthat high-order PDE discretization schemes retain their convergence order even\nat resolution jumps when combined with sufficiently high order wavelets. We\nthen use a test case of the advection of a scalar to analyze convergence for\nthe temporal evolution of a PDE, which shows that our wavelet-based refinement\ncriterion is successful at controlling the overall error while the coarsening\ncriterion is effective at retaining the relevant information on a compressed\ngrid. Our software exploits the block-structured grid data structure for\nefficient multi-level operations, and the parallelization strategy relies on a\none-sided MPI-RMA communication approach with active PSCW synchronization\nleading to highly scalable performance on more than 7,000 cores.",
    "descriptor": "\nComments: submitted to SIAM Journal of Scientific Computing (SISC) on Dec 13\n",
    "authors": [
      "Thomas Gillis",
      "Wim M. van Rees"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.07537"
  },
  {
    "id": "arXiv:2112.07544",
    "title": "Modeling Strong and Human-Like Gameplay with KL-Regularized Search",
    "abstract": "We consider the task of building strong but human-like policies in\nmulti-agent decision-making problems, given examples of human behavior.\nImitation learning is effective at predicting human actions but may not match\nthe strength of expert humans, while self-play learning and search techniques\n(e.g. AlphaZero) lead to strong performance but may produce policies that are\ndifficult for humans to understand and coordinate with. We show in chess and Go\nthat regularizing search policies based on the KL divergence from an\nimitation-learned policy by applying Monte Carlo tree search produces policies\nthat have higher human prediction accuracy and are stronger than the imitation\npolicy. We then introduce a novel regret minimization algorithm that is\nregularized based on the KL divergence from an imitation-learned policy, and\nshow that applying this algorithm to no-press Diplomacy yields a policy that\nmaintains the same human prediction accuracy as imitation learning while being\nsubstantially stronger.",
    "descriptor": "",
    "authors": [
      "Athul Paul Jacob",
      "David J. Wu",
      "Gabriele Farina",
      "Adam Lerer",
      "Anton Bakhtin",
      "Jacob Andreas",
      "Noam Brown"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07544"
  },
  {
    "id": "arXiv:2112.07548",
    "title": "Parametric schedulability analysis of a launcher flight control system  under reactivity constraints",
    "abstract": "The next generation of space systems will have to achieve more and more\ncomplex missions. In order to master the development cost and duration of such\nsystems, an alternative to a manual design is to automatically synthesize the\nmain parameters of the system. In this paper, we present an approach for the\nspecific case of the scheduling of the flight control of a space launcher. The\napproach requires two successive steps: (1) the formalization of the problem to\nbe solved in a parametric formal model and (2) the synthesis of the model\nparameters with a tool. We first describe the problem of the scheduling of a\nlauncher flight control, then we show how this problem can be formalized with\nparametric stopwatch automata; we then present the results computed by the\nparametric timed model checker IMITATOR. We enhance our model by taking into\nconsideration the time for switching context, and we compare the results to\nthose obtained by other tools classically used in scheduling.",
    "descriptor": "\nComments: This manuscript is the author version of the manuscript of the same name published in Fundamenta Informatica 182(1). This is an extended version of the manuscript published in the proceedings of the 19th International Conference on Application of Concurrency to System Design (ACSD 2019). arXiv admin note: substantial text overlap with arXiv:1903.07217\n",
    "authors": [
      "\u00c9tienne Andr\u00e9",
      "Emmanuel Coquard",
      "Laurent Fribourg",
      "Jawher Jerray",
      "David Lesens"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07548"
  },
  {
    "id": "arXiv:2112.07549",
    "title": "Sequential Change Detection through Empirical Distribution and Universal  Codes",
    "abstract": "Universal compression algorithms have been studied in the past for sequential\nchange detection, where they have been used to estimate the post-change\ndistribution in the modified version of the Cumulative Sum (CUSUM) Test. In\nthis paper, we introduce a modified CUSUM test where the pre-change\ndistribution is also unknown and an empirical version of the pre-change\ndistribution is used to implement the algorithm. We present a study of various\ncharacteristics of this modified CUSUM Test and then prove its asymptotic\noptimality.",
    "descriptor": "",
    "authors": [
      "Vikrant Malik",
      "R. K. Bansal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.07549"
  },
  {
    "id": "arXiv:2112.07552",
    "title": "TCUDB: Accelerating Database with Tensor Processors",
    "abstract": "The emergence of novel hardware accelerators has powered the tremendous\ngrowth of machine learning in recent years. These accelerators deliver\nincomparable performance gains in processing high-volume matrix operators,\nparticularly matrix multiplication, a core component of neural network training\nand inference. In this work, we explored opportunities of accelerating database\nsystems using NVIDIA's Tensor Core Units (TCUs). We present TCUDB, a\nTCU-accelerated query engine processing a set of query operators including\nnatural joins and group-by aggregates as matrix operators within TCUs. Matrix\nmultiplication was considered inefficient in the past; however, this strategy\nhas remained largely unexplored in conventional GPU-based databases, which\nprimarily rely on vector or scalar processing. We demonstrate the significant\nperformance gain of TCUDB in a range of real-world applications including\nentity matching, graph query processing, and matrix-based data analytics. TCUDB\nachieves up to 288x speedup compared to a baseline GPU-based query engine.",
    "descriptor": "\nComments: 16 pages, 14 figures, to appear in the 2022 ACM SIGMOD/PODS International Conference on Management of Data (SIGMOD 2022)\n",
    "authors": [
      "Yu-Ching Hu",
      "Yuliang Li",
      "Hung-Wei Tseng"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.07552"
  },
  {
    "id": "arXiv:2112.07558",
    "title": "Multi-Modal Temporal Attention Models for Crop Mapping from Satellite  Time Series",
    "abstract": "Optical and radar satellite time series are synergetic: optical images\ncontain rich spectral information, while C-band radar captures useful\ngeometrical information and is immune to cloud cover. Motivated by the recent\nsuccess of temporal attention-based methods across multiple crop mapping tasks,\nwe propose to investigate how these models can be adapted to operate on several\nmodalities. We implement and evaluate multiple fusion schemes, including a\nnovel approach and simple adjustments to the training procedure, significantly\nimproving performance and efficiency with little added complexity. We show that\nmost fusion schemes have advantages and drawbacks, making them relevant for\nspecific settings. We then evaluate the benefit of multimodality across several\ntasks: parcel classification, pixel-based segmentation, and panoptic parcel\nsegmentation. We show that by leveraging both optical and radar time series,\nmultimodal temporal attention-based models can outmatch single-modality models\nin terms of performance and resilience to cloud cover. To conduct these\nexperiments, we augment the PASTIS dataset with spatially aligned radar image\ntime series. The resulting dataset, PASTIS-R, constitutes the first\nlarge-scale, multimodal, and open-access satellite time series dataset with\nsemantic and instance annotations.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Vivien Sainte Fare Garnot",
      "Loic Landrieu",
      "Nesrine Chehata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.07558"
  },
  {
    "id": "arXiv:2112.07566",
    "title": "VALSE: A Task-Independent Benchmark for Vision and Language Models  Centered on Linguistic Phenomena",
    "abstract": "We propose VALSE (Vision And Language Structured Evaluation), a novel\nbenchmark designed for testing general-purpose pretrained vision and language\n(V&L) models for their visio-linguistic grounding capabilities on specific\nlinguistic phenomena. VALSE offers a suite of six tests covering various\nlinguistic constructs. Solving these requires models to ground linguistic\nphenomena in the visual modality, allowing more fine-grained evaluations than\nhitherto possible. We build VALSE using methods that support the construction\nof valid foils, and report results from evaluating five widely-used V&L models.\nOur experiments suggest that current models have considerable difficulty\naddressing most phenomena. Hence, we expect VALSE to serve as an important\nbenchmark to measure future progress of pretrained V&L models from a linguistic\nperspective, complementing the canonical task-centred V&L evaluations.",
    "descriptor": "\nComments: 28 pages, 4 figures, 11 tables\n",
    "authors": [
      "Letitia Parcalabescu",
      "Michele Cafagna",
      "Lilitta Muradjan",
      "Anette Frank",
      "Iacer Calixto",
      "Albert Gatt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07566"
  },
  {
    "id": "arXiv:2112.07569",
    "title": "Cooperation for Scalable Supervision of Autonomy in Mixed Traffic",
    "abstract": "Improvements in autonomy offer the potential for positive outcomes in a\nnumber of domains, yet guaranteeing their safe deployment is difficult. This\nwork investigates how humans can intelligently supervise agents to achieve some\nlevel of safety even when performance guarantees are elusive. The motivating\nresearch question is: In safety-critical settings, can we avoid the need to\nhave one human supervise one machine at all times? The paper formalizes this\n'scaling supervision' problem, and investigates its application to the\nsafety-critical context of autonomous vehicles (AVs) merging into traffic. It\nproposes a conservative, reachability-based method to reduce the burden on the\nAVs' human supervisors, which allows for the establishment of high-confidence\nupper bounds on the supervision requirements in this setting. Order statistics\nand traffic simulations with deep reinforcement learning show analytically and\nnumerically that teaming of AVs enables supervision time sublinear in AV\nadoption. A key takeaway is that, despite present imperfections of AVs,\nsupervision becomes more tractable as AVs are deployed en masse. While this\nwork focuses on AVs, the scalable supervision framework is relevant to a\nbroader array of autonomous control challenges.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Cameron Hickert",
      "Sirui Li",
      "Cathy Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07569"
  },
  {
    "id": "arXiv:2112.07571",
    "title": "Epigenomic language models powered by Cerebras",
    "abstract": "Large scale self-supervised pre-training of Transformer language models has\nadvanced the field of Natural Language Processing and shown promise in\ncross-application to the biological `languages' of proteins and DNA. Learning\neffective representations of DNA sequences using large genomic sequence\ncorpuses may accelerate the development of models of gene regulation and\nfunction through transfer learning. However, to accurately model cell\ntype-specific gene regulation and function, it is necessary to consider not\nonly the information contained in DNA nucleotide sequences, which is mostly\ninvariant between cell types, but also how the local chemical and structural\n`epigenetic state' of chromosomes varies between cell types. Here, we introduce\na Bidirectional Encoder Representations from Transformers (BERT) model that\nlearns representations based on both DNA sequence and paired epigenetic state\ninputs, which we call Epigenomic BERT (or EBERT). We pre-train EBERT with a\nmasked language model objective across the entire human genome and across 127\ncell types. Training this complex model with a previously prohibitively large\ndataset was made possible for the first time by a partnership with Cerebras\nSystems, whose CS-1 system powered all pre-training experiments. We show\nEBERT's transfer learning potential by demonstrating strong performance on a\ncell type-specific transcription factor binding prediction task. Our fine-tuned\nmodel exceeds state of the art performance on 4 of 13 evaluation datasets from\nENCODE-DREAM benchmarks and earns an overall rank of 3rd on the challenge\nleaderboard. We explore how the inclusion of epigenetic data and task specific\nfeature augmentation impact transfer learning performance.",
    "descriptor": "\nComments: 18 pages, 5 figures, 3 tables\n",
    "authors": [
      "Meredith V. Trotter",
      "Cuong Q. Nguyen",
      "Stephen Young",
      "Rob T. Woodruff",
      "Kim M. Branson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2112.07571"
  },
  {
    "id": "arXiv:2112.07573",
    "title": "Simplicial approximation to CW complexes in practice",
    "abstract": "We describe an algorithm that takes as an input a CW complex and returns a\nsimplicial complex of the same homotopy type. This algorithm, although\nwell-known in the literature, requires some work to make it computationally\ntractable. We pay close attention to weak simplicial approximation, which we\nimplement for generalized barycentric and edgewise subdivisions. We also\npropose a new subdivision process, based on Delaunay complexes. In order to\nfacilitate the computation of a simplicial approximation, we introduce a\nsimplification step, based on edge contractions. We define a new version of\nsimplicial mapping cone, which requires less simplices. Last, we illustrate the\nalgorithm with the real projective spaces, the 3-dimensional lens spaces and\nthe Grassmannian of 2-planes in $\\mathbb{R}^4$.",
    "descriptor": "",
    "authors": [
      "Rapha\u00ebl Tinarrage"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2112.07573"
  },
  {
    "id": "arXiv:2112.07574",
    "title": "M3E2: Multi-gate Mixture-of-experts for Multi-treatment Effect  Estimation",
    "abstract": "This work proposes the M3E2, a multi-task learning neural network model to\nestimate the effect of multiple treatments. In contrast to existing methods,\nM3E2 is robust to multiple treatment effects applied simultaneously to the same\nunit, continuous and binary treatments, and many covariates. We compared M3E2\nwith three baselines in three synthetic benchmark datasets: two with multiple\ntreatments and one with one treatment. Our analysis showed that our method has\nsuperior performance, making more assertive estimations of the true treatment\neffects. The code is available at github.com/raquelaoki/M3E2.",
    "descriptor": "\nComments: 4 figures, 10 pages\n",
    "authors": [
      "Raquel Aoki",
      "Yizhou Chen",
      "Martin Ester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.07574"
  },
  {
    "id": "arXiv:2112.07575",
    "title": "Robust Graph Neural Networks via Probabilistic Lipschitz Constraints",
    "abstract": "Graph neural networks (GNNs) have recently been demonstrated to perform well\non a variety of network-based tasks such as decentralized control and resource\nallocation, and provide computationally efficient methods for these tasks which\nhave traditionally been challenging in that regard. However, like many\nneural-network based systems, GNNs are susceptible to shifts and perturbations\non their inputs, which can include both node attributes and graph structure. In\norder to make them more useful for real-world applications, it is important to\nensure their robustness post-deployment. Motivated by controlling the Lipschitz\nconstant of GNN filters with respect to the node attributes, we propose to\nconstrain the frequency response of the GNN's filter banks. We extend this\nformulation to the dynamic graph setting using a continuous frequency response\nconstraint, and solve a relaxed variant of the problem via the scenario\napproach. This allows for the use of the same computationally efficient\nalgorithm on sampled constraints, which provides PAC-style guarantees on the\nstability of the GNN using results in scenario optimization. We also highlight\nan important connection between this setup and GNN stability to graph\nperturbations, and provide experimental results which demonstrate the efficacy\nand broadness of our approach.",
    "descriptor": "",
    "authors": [
      "Raghu Arghal",
      "Eric Lei",
      "Shirin Saeedi Bidokhti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07575"
  },
  {
    "id": "arXiv:2112.07577",
    "title": "GPL: Generative Pseudo Labeling for Unsupervised Domain Adaptation of  Dense Retrieval",
    "abstract": "Dense retrieval approaches can overcome the lexical gap and lead to\nsignificantly improved search results. However, they require large amounts of\ntraining data which is not available for most domains. As shown in previous\nwork (Thakur et al., 2021b), the performance of dense retrievers severely\ndegrades under a domain shift. This limits the usage of dense retrieval\napproaches to only a few domains with large training datasets.\nIn this paper, we propose the novel unsupervised domain adaptation method\nGenerative Pseudo Labeling (GPL), which combines a query generator with pseudo\nlabeling from a cross-encoder. On six representative domain-specialized\ndatasets, we find the proposed GPL can outperform an out-of-the-box\nstate-of-the-art dense retrieval approach by up to 8.9 points nDCG@10. GPL\nrequires less (unlabeled) data from the target domain and is more robust in its\ntraining than previous methods.\nWe further investigate the role of six recent pre-training methods in the\nscenario of domain adaptation for retrieval tasks, where only three could yield\nimproved results. The best approach, TSDAE (Wang et al., 2021) can be combined\nwith GPL, yielding another average improvement of 1.0 points nDCG@10 across the\nsix tasks.",
    "descriptor": "",
    "authors": [
      "Kexin Wang",
      "Nandan Thakur",
      "Nils Reimers",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.07577"
  },
  {
    "id": "arXiv:2112.07583",
    "title": "Reinforcing Semantic-Symmetry for Document Summarization",
    "abstract": "Document summarization condenses a long document into a short version with\nsalient information and accurate semantic descriptions. The main issue is how\nto make the output summary semantically consistent with the input document. To\nreach this goal, recently, researchers have focused on supervised end-to-end\nhybrid approaches, which contain an extractor module and abstractor module.\nAmong them, the extractor identifies the salient sentences from the input\ndocument, and the abstractor generates a summary from the salient sentences.\nThis model successfully keeps the consistency between the generated summary and\nthe reference summary via various strategies (e.g., reinforcement learning).\nThere are two semantic gaps when training the hybrid model (one is between\ndocument and extracted sentences, and the other is between extracted sentences\nand summary). However, they are not explicitly considered in the existing\nmethods, which usually results in a semantic bias of summary. To mitigate the\nabove issue, in this paper, a new \\textbf{r}einforcing\ns\\textbf{e}mantic-\\textbf{sy}mmetry learning \\textbf{m}odel is proposed for\ndocument summarization (\\textbf{ReSyM}). ReSyM introduces a\nsemantic-consistency reward in the extractor to bridge the first gap. A\nsemantic dual-reward is designed to bridge the second gap in the abstractor.\nThe whole document summarization process is implemented via reinforcement\nlearning with a hybrid reward mechanism (combining the above two rewards).\nMoreover, a comprehensive sentence representation learning method is presented\nto sufficiently capture the information from the original document. A series of\nexperiments have been conducted on two wildly used benchmark datasets CNN/Daily\nMail and BigPatent. The results have shown the superiority of ReSyM by\ncomparing it with the state-of-the-art baselines in terms of various evaluation\nmetrics.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Mingyang Song",
      "Liping Jing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07583"
  },
  {
    "id": "arXiv:2112.07586",
    "title": "Real-time SIL Emulation Architecture for Cooperative Automated Vehicles",
    "abstract": "The development of safety applications for Connected Automated Vehicles\nrequires testing in many different scenarios. However, the recreation of test\nscenarios for evaluating safety applications is a very challenging task. This\nis mainly due to the randomness in communication, difficulty in recreating\nvehicle movements precisely, and safety concerns for certain scenarios. We\npropose to develop a standalone Remote Vehicle Emulator that can reproduce V2V\nmessages of remote vehicles from simulations or previous tests. This is\nexpected to accelerate the development cycle significantly. Remote Vehicle\nEmulator is a unique and easily configurable emulation cum simulation setup to\nallow Software in the Loop (SIL) testing of connected vehicle applications\nrealistically and safely. It will help in tailoring numerous test scenarios,\nexpediting algorithm development and validation, and increasing the probability\nof finding failure modes. This, in turn, will help improve the quality of\nsafety applications while saving testing time and reducing cost.",
    "descriptor": "\nComments: masters thesis\n",
    "authors": [
      "Nitish Gupta"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Networking and Internet Architecture (cs.NI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.07586"
  },
  {
    "id": "arXiv:2112.07588",
    "title": "A Game-Theoretical Self-Adaptation Framework for Securing  Software-Intensive Systems",
    "abstract": "The increasing prevalence of security attacks on software-intensive systems\ncalls for new, effective methods for detecting and responding to these attacks.\nAs one promising approach, game theory provides analytical tools for modeling\nthe interaction between the system and the adversarial environment and\ndesigning reliable defense. In this paper, we propose an approach for securing\nsoftware-intensive systems using a rigorous game-theoretical framework. First,\na self-adaptation framework is deployed on a component-based software intensive\nsystem, which periodically monitors the system for anomalous behaviors. A\nlearning-based method is proposed to detect possible on-going attacks on the\nsystem components and predict potential threats to components. Then, an\nalgorithm is designed to automatically build a \\emph{Bayesian game} based on\nthe system architecture (of which some components might have been compromised)\nonce an attack is detected, in which the system components are modeled as\nindependent players in the game. Finally, an optimal defensive policy is\ncomputed by solving the Bayesian game to achieve the best system utility, which\namounts to minimizing the impact of the attack. We conduct two sets of\nexperiments on two general benchmark tasks for security domain. Moreover, we\nsystematically present a case study on a real-world water treatment testbed,\ni.e. the Secure Water Treatment System. Experiment results show the\napplicability and the effectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Mingyue Zhang",
      "Nianyu Li",
      "Sridhar Adepu",
      "Eunsuk Kang",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.07588"
  },
  {
    "id": "arXiv:2112.07589",
    "title": "Mitigating Channel-wise Noise for Single Image Super Resolution",
    "abstract": "In practice, images can contain different amounts of noise for different\ncolor channels, which is not acknowledged by existing super-resolution\napproaches. In this paper, we propose to super-resolve noisy color images by\nconsidering the color channels jointly. Noise statistics are blindly estimated\nfrom the input low-resolution image and are used to assign different weights to\ndifferent color channels in the data cost. Implicit low-rank structure of\nvisual data is enforced via nuclear norm minimization in association with\nadaptive weights, which is added as a regularization term to the cost.\nAdditionally, multi-scale details of the image are added to the model through\nanother regularization term that involves projection onto PCA basis, which is\nconstructed using similar patches extracted across different scales of the\ninput image. The results demonstrate the super-resolving capability of the\napproach in real scenarios.",
    "descriptor": "",
    "authors": [
      "Srimanta Mandal",
      "Kuldeep Purohit",
      "A. N. Rajagopalan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.07589"
  },
  {
    "id": "arXiv:2112.07596",
    "title": "Rushing and Strolling among Answer Sets -- Navigation Made Easy",
    "abstract": "Answer set programming (ASP) is a popular declarative programming paradigm\nwith a wide range of applications in artificial intelligence. Oftentimes, when\nmodeling an AI problem with ASP, and in particular when we are interested\nbeyond simple search for optimal solutions, an actual solution, differences\nbetween solutions, or number of solutions of the ASP program matter. For\nexample, when a user aims to identify a specific answer set according to her\nneeds, or requires the total number of diverging solutions to comprehend\nprobabilistic applications such as reasoning in medical domains. Then, there\nare only certain problem specific and handcrafted encoding techniques available\nto navigate the solution space of ASP programs, which is oftentimes not enough.\nIn this paper, we propose a formal and general framework for interactive\nnavigation towards desired subsets of answer sets analogous to faceted\nbrowsing. Our approach enables the user to explore the solution space by\nconsciously zooming in or out of sub-spaces of solutions at a certain\nconfigurable pace. We illustrate that weighted faceted navigation is\ncomputationally hard. Finally, we provide an implementation of our approach\nthat demonstrates the feasibility of our framework for incomprehensible\nsolution spaces.",
    "descriptor": "",
    "authors": [
      "Johannes K. Fichte",
      "Sarah Alice Gaggl",
      "Dominik Rusovac"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.07596"
  },
  {
    "id": "arXiv:2112.07598",
    "title": "An Earth Mover's Distance Based Graph Distance Metric For Financial  Statements",
    "abstract": "Quantifying the similarity between a group of companies has proven to be\nuseful for several purposes, including company benchmarking, fraud detection,\nand searching for investment opportunities. This exercise can be done using a\nvariety of data sources, such as company activity data and financial data.\nHowever, ledger account data is widely available and is standardized to a large\nextent. Such ledger accounts within a financial statement can be represented by\nmeans of a tree, i.e. a special type of graph, representing both the values of\nthe ledger accounts and the relationships between them. Given their broad\navailability and rich information content, financial statements form a prime\ndata source based on which company similarities or distances could be computed.\nIn this paper, we present a graph distance metric that enables one to compute\nthe similarity between the financial statements of two companies. We conduct a\ncomprehensive experimental study using real-world financial data to demonstrate\nthe usefulness of our proposed distance metric. The experimental results show\npromising results on a number of use cases. This method may be useful for\ninvestors looking for investment opportunities, government officials attempting\nto identify fraudulent companies, and accountants looking to benchmark a group\nof companies based on their financial statements.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Sander Noels",
      "Benjamin Vandermarliere",
      "Ken Bastiaensen",
      "Tijl De Bie"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2112.07598"
  },
  {
    "id": "arXiv:2112.07599",
    "title": "Learning to Deblur and Rotate Motion-Blurred Faces",
    "abstract": "We propose a solution to the novel task of rendering sharp videos from new\nviewpoints from a single motion-blurred image of a face. Our method handles the\ncomplexity of face blur by implicitly learning the geometry and motion of faces\nthrough the joint training on three large datasets: FFHQ and 300VW, which are\npublicly available, and a new Bern Multi-View Face Dataset (BMFD) that we\nbuilt. The first two datasets provide a large variety of faces and allow our\nmodel to generalize better. BMFD instead allows us to introduce multi-view\nconstraints, which are crucial to synthesizing sharp videos from a new camera\nview. It consists of high frame rate synchronized videos from multiple views of\nseveral subjects displaying a wide range of facial expressions. We use the high\nframe rate videos to simulate realistic motion blur through averaging. Thanks\nto this dataset, we train a neural network to reconstruct a 3D video\nrepresentation from a single image and the corresponding face gaze. We then\nprovide a camera viewpoint relative to the estimated gaze and the blurry image\nas input to an encoder-decoder network to generate a video of sharp frames with\na novel camera viewpoint. We demonstrate our approach on test subjects of our\nmulti-view dataset and VIDTIMIT.",
    "descriptor": "\nComments: British Machine Vision Conference 2021\n",
    "authors": [
      "Givi Meishvili",
      "Attila Szab\u00f3",
      "Simon Jenni",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.07599"
  },
  {
    "id": "arXiv:2112.07605",
    "title": "The King is Naked: on the Notion of Robustness for Natural Language  Processing",
    "abstract": "There is growing evidence that the classical notion of adversarial robustness\noriginally introduced for images has been adopted as a de facto standard by a\nlarge part of the NLP research community. We show that this notion is\nproblematic in the context of NLP as it considers a narrow spectrum of\nlinguistic phenomena. In this paper, we argue for semantic robustness, which is\nbetter aligned with the human concept of linguistic fidelity. We characterize\nsemantic robustness in terms of biases that it is expected to induce in a\nmodel. We study semantic robustness of a range of vanilla and robustly trained\narchitectures using a template-based generative test bed. We complement the\nanalysis with empirical evidence that, despite being harder to implement,\nsemantic robustness can improve performance %gives guarantees for on complex\nlinguistic phenomena where models robust in the classical sense fail.",
    "descriptor": "\nComments: AAAI 2022 main-track (full-paper)\n",
    "authors": [
      "Emanuele La Malfa",
      "Marta Kwiatkowska"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07605"
  },
  {
    "id": "arXiv:2112.07606",
    "title": "Semantic Answer Type and Relation Prediction Task (SMART 2021)",
    "abstract": "Each year the International Semantic Web Conference organizes a set of\nSemantic Web Challenges to establish competitions that will advance\nstate-of-the-art solutions in some problem domains. The Semantic Answer Type\nand Relation Prediction Task (SMART) task is one of the ISWC 2021 Semantic Web\nchallenges. This is the second year of the challenge after a successful SMART\n2020 at ISWC 2020. This year's version focuses on two sub-tasks that are very\nimportant to Knowledge Base Question Answering (KBQA): Answer Type Prediction\nand Relation Prediction. Question type and answer type prediction can play a\nkey role in knowledge base question answering systems providing insights about\nthe expected answer that are helpful to generate correct queries or rank the\nanswer candidates. More concretely, given a question in natural language, the\nfirst task is, to predict the answer type using a target ontology (e.g.,\nDBpedia or Wikidata. Similarly, the second task is to identify relations in the\nnatural language query and link them to the relations in a target ontology.\nThis paper discusses the task descriptions, benchmark datasets, and evaluation\nmetrics. For more information, please visit https://smart-task.github.io/2021/.",
    "descriptor": "",
    "authors": [
      "Nandana Mihindukulasooriya",
      "Mohnish Dubey",
      "Alfio Gliozzo",
      "Jens Lehmann",
      "Axel-Cyrille Ngonga Ngomo",
      "Ricardo Usbeck",
      "Gaetano Rossiello",
      "Uttam Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07606"
  },
  {
    "id": "arXiv:2112.07610",
    "title": "Improving Compositional Generalization with Latent Structure and Data  Augmentation",
    "abstract": "Generic unstructured neural networks have been shown to struggle on\nout-of-distribution compositional generalization. Compositional data\naugmentation via example recombination has transferred some prior knowledge\nabout compositionality to such black-box neural models for several semantic\nparsing tasks, but this often required task-specific engineering or provided\nlimited gains.\nWe present a more powerful data recombination method using a model called\nCompositional Structure Learner (CSL). CSL is a generative model with a\nquasi-synchronous context-free grammar backbone, which we induce from the\ntraining data. We sample recombined examples from CSL and add them to the\nfine-tuning data of a pre-trained sequence-to-sequence model (T5). This\nprocedure effectively transfers most of CSL's compositional bias to T5 for\ndiagnostic tasks, and results in a model even stronger than a T5-CSL ensemble\non two real world compositional generalization tasks. This results in new\nstate-of-the-art performance for these challenging semantic parsing tasks\nrequiring generalization to both natural language variation and novel\ncompositions of elements.",
    "descriptor": "",
    "authors": [
      "Linlu Qiu",
      "Peter Shaw",
      "Panupong Pasupat",
      "Pawe\u0142 Krzysztof Nowak",
      "Tal Linzen",
      "Fei Sha",
      "Kristina Toutanova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07610"
  },
  {
    "id": "arXiv:2112.07615",
    "title": "Cold Item Integration in Deep Hybrid Recommenders via Tunable Stochastic  Gates",
    "abstract": "A major challenge in collaborative filtering methods is how to produce\nrecommendations for cold items (items with no ratings), or integrate cold item\ninto an existing catalog. Over the years, a variety of hybrid recommendation\nmodels have been proposed to address this problem by utilizing items' metadata\nand content along with their ratings or usage patterns. In this work, we wish\nto revisit the cold start problem in order to draw attention to an overlooked\nchallenge: the ability to integrate and balance between (regular) warm items\nand completely cold items. In this case, two different challenges arise: (1)\npreserving high quality performance on warm items, while (2) learning to\npromote cold items to relevant users. First, we show that these two objectives\nare in fact conflicting, and the balance between them depends on the business\nneeds and the application at hand. Next, we propose a novel hybrid\nrecommendation algorithm that bridges these two conflicting objectives and\nenables a harmonized balance between preserving high accuracy for warm items\nwhile effectively promoting completely cold items. We demonstrate the\neffectiveness of the proposed algorithm on movies, apps, and articles\nrecommendations, and provide an empirical analysis of the cold-warm trade-off.",
    "descriptor": "",
    "authors": [
      "Oren Barkan",
      "Roy Hirsch",
      "Ori Katz",
      "Avi Caciularu",
      "Jonathan Weill",
      "Noam Koenigstein"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07615"
  },
  {
    "id": "arXiv:2112.07616",
    "title": "DiPS: Differentiable Policy for Sketching in Recommender Systems",
    "abstract": "In sequential recommender system applications, it is important to develop\nmodels that can capture users' evolving interest over time to successfully\nrecommend future items that they are likely to interact with. For users with\nlong histories, typical models based on recurrent neural networks tend to\nforget important items in the distant past. Recent works have shown that\nstoring a small sketch of past items can improve sequential recommendation\ntasks. However, these works all rely on static sketching policies, i.e.,\nheuristics to select items to keep in the sketch, which are not necessarily\noptimal and cannot improve over time with more training data. In this paper, we\npropose a differentiable policy for sketching (DiPS), a framework that learns a\ndata-driven sketching policy in an end-to-end manner together with the\nrecommender system model to explicitly maximize recommendation quality in the\nfuture. We also propose an approximate estimator of the gradient for optimizing\nthe sketching algorithm parameters that is computationally efficient. We verify\nthe effectiveness of DiPS on real-world datasets under various practical\nsettings and show that it requires up to $50\\%$ fewer sketch items to reach the\nsame predictive quality than existing sketching policies.",
    "descriptor": "\nComments: AAAI 2022 with supplementary material\n",
    "authors": [
      "Aritra Ghosh",
      "Saayan Mitra",
      "Andrew Lan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.07616"
  },
  {
    "id": "arXiv:2112.07617",
    "title": "A cross-domain recommender system using deep coupled autoencoders",
    "abstract": "Long-standing data sparsity and cold-start constitute thorny and perplexing\nproblems for the recommendation systems. Cross-domain recommendation as a\ndomain adaptation framework has been utilized to efficiently address these\nchallenging issues, by exploiting information from multiple domains. In this\nstudy, an item-level relevance cross-domain recommendation task is explored,\nwhere two related domains, that is, the source and the target domain contain\ncommon items without sharing sensitive information regarding the users'\nbehavior, and thus avoiding the leak of user privacy. In light of this\nscenario, two novel coupled autoencoder-based deep learning methods are\nproposed for cross-domain recommendation. The first method aims to\nsimultaneously learn a pair of autoencoders in order to reveal the intrinsic\nrepresentations of the items in the source and target domains, along with a\ncoupled mapping function to model the non-linear relationships between these\nrepresentations, thus transferring beneficial information from the source to\nthe target domain. The second method is derived based on a new joint\nregularized optimization problem, which employs two autoencoders to generate in\na deep and non-linear manner the user and item-latent factors, while at the\nsame time a data-driven function is learnt to map the item-latent factors\nacross domains. Extensive numerical experiments on two publicly available\nbenchmark datasets are conducted illustrating the superior performance of our\nproposed methods compared to several state-of-the-art cross-domain\nrecommendation frameworks.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Alexandros Gkillas",
      "Dimitrios Kosmopoulos"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07617"
  },
  {
    "id": "arXiv:2112.07618",
    "title": "Robust Information Retrieval for False Claims with Distracting Entities  In Fact Extraction and Verification",
    "abstract": "Accurate evidence retrieval is essential for automated fact checking. Little\nprevious research has focused on the differences between true and false claims\nand how they affect evidence retrieval. This paper shows that, compared with\ntrue claims, false claims more frequently contain irrelevant entities which can\ndistract evidence retrieval model. A BERT-based retrieval model made more\nmistakes in retrieving refuting evidence for false claims than supporting\nevidence for true claims. When tested with adversarial false claims\n(synthetically generated) containing irrelevant entities, the recall of the\nretrieval model is significantly lower than that for original claims. These\nresults suggest that the vanilla BERT-based retrieval model is not robust to\nirrelevant entities in the false claims. By augmenting the training data with\nsynthetic false claims containing irrelevant entities, the trained model\nachieved higher evidence recall, including that of false claims with irrelevant\nentities. In addition, using separate models to retrieve refuting and\nsupporting evidence and then aggregating them can also increase the evidence\nrecall, including that of false claims with irrelevant entities. These results\nsuggest that we can increase the BERT-based retrieval model's robustness to\nfalse claims with irrelevant entities via data augmentation and model ensemble.",
    "descriptor": "",
    "authors": [
      "Mingwen Dong",
      "Christos Christodoulopoulos",
      "Sheng-Min Shih",
      "Xiaofei Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07618"
  },
  {
    "id": "arXiv:2112.07620",
    "title": "Tree-based Focused Web Crawling with Reinforcement Learning",
    "abstract": "A focused crawler aims at discovering as many web pages relevant to a target\ntopic as possible, while avoiding irrelevant ones; i.e. maximizing the harvest\nrate. Reinforcement Learning (RL) has been utilized to optimize the crawling\nprocess, yet it deals with huge state and action spaces, which can constitute a\nserious challenge. In this paper, we propose TRES, an end-to-end RL-empowered\nframework for focused crawling. Unlike other approaches, we properly model a\ncrawling environment as a Markov Decision Process, by representing the state as\na subgraph of the Web and actions as its expansion edges. TRES adopts a keyword\nexpansion strategy based on the cosine similarity of keyword embeddings. To\nlearn a reward function, we propose a deep neural network, called KwBiLSTM,\nleveraging the discovered keywords. To reduce the time complexity of selecting\na best action, we propose Tree-Frontier, a two-fold decision tree, which also\nspeeds up training by discretizing the state and action spaces. Experimentally,\nwe show that TRES outperforms state-of-the-art methods in terms of harvest rate\nby at least 58%, while it has competitive results in the domain maximization.\nOur implementation code can be found on https://github.com/ddaedalus/TRES.",
    "descriptor": "",
    "authors": [
      "Andreas Kontogiannis",
      "Dimitrios Kelesis",
      "Vasilis Pollatos",
      "Georgios Paliouras",
      "George Giannakopoulos"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07620"
  },
  {
    "id": "arXiv:2112.07621",
    "title": "Re-ranking With Constraints on Diversified Exposures for Homepage  Recommender System",
    "abstract": "The homepage recommendation on most E-commerce applications places items in a\nhierarchical manner, where different channels display items in different\nstyles. Existing algorithms usually optimize the performance of a single\nchannel. So designing the model to achieve the optimal recommendation list\nwhich maximize the Click-Through Rate (CTR) of whole homepage is a challenge\nproblem. Other than the accuracy objective, display diversity on the homepage\nis also important since homogeneous display usually hurts user experience. In\nthis paper, we propose a two-stage architecture of the homepage recommendation\nsystem. In the first stage, we develop efficient algorithms for recommending\nitems to proper channels while maintaining diversity. The two methods can be\ncombined: user-channel-item predictive model with diversity constraint. In the\nsecond stage, we provide an ordered list of items in each channel. Existing\nre-ranking models are hard to describe the mutual influence between items in\nboth intra-channel and inter-channel. Therefore, we propose a Deep \\&\nHierarchical Attention Network Re-ranking (DHANR) model for homepage\nrecommender systems. The Hierarchical Attention Network consists of an item\nencoder, an item-level attention layer, a channel encoder and a channel-level\nattention layer. Our method achieves a significant improvement in terms of\nprecision, intra-list average distance(ILAD) and channel-wise Precision@k in\noffline experiments and in terms of CTR and ILAD in our online systems.",
    "descriptor": "\nComments: 8pages,7figures\n",
    "authors": [
      "Qi Hao",
      "Tianze Luo",
      "Guangda Huzhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07621"
  },
  {
    "id": "arXiv:2112.07622",
    "title": "ISEEQ: Information Seeking Question Generation using Dynamic  Meta-Information Retrieval and Knowledge Graphs",
    "abstract": "Conversational Information Seeking (CIS) is a relatively new research area\nwithin conversational AI that attempts to seek information from end-users in\norder to understand and satisfy users' needs. If realized, such a system has\nfar-reaching benefits in the real world; for example, a CIS system can assist\nclinicians in pre-screening or triaging patients in healthcare. A key open\nsub-problem in CIS that remains unaddressed in the literature is generating\nInformation Seeking Questions (ISQs) based on a short initial query from the\nend-user. To address this open problem, we propose Information SEEking Question\ngenerator (ISEEQ), a novel approach for generating ISQs from just a short user\nquery, given a large text corpus relevant to the user query. Firstly, ISEEQ\nuses a knowledge graph to enrich the user query. Secondly, ISEEQ uses the\nknowledge-enriched query to retrieve relevant context passages to ask coherent\nISQs adhering to a conceptual flow. Thirdly, ISEEQ introduces a new deep\ngenerative-adversarial reinforcement learning-based approach for generating\nISQs. We show that ISEEQ can generate high-quality ISQs to promote the\ndevelopment of CIS agents. ISEEQ significantly outperforms comparable baselines\non five ISQ evaluation metrics across four datasets having user queries from\ndiverse domains. Further, we argue that ISEEQ is transferable across domains\nfor generating ISQs, as it shows the acceptable performance when trained and\ntested on different pairs of domains. The qualitative human evaluation confirms\nISEEQ-generated ISQs are comparable in quality to human-generated questions and\noutperform the best comparable baseline.",
    "descriptor": "\nComments: Accepted at AAAI 2022, preprint version. Supplementary materials are provided in the paper and alternatively can be found at this https URL\n",
    "authors": [
      "Manas Gaur",
      "Kalpa Gunaratna",
      "Vijay Srinivasan",
      "Hongxia Jin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07622"
  },
  {
    "id": "arXiv:2112.07623",
    "title": "D-LNBot: A Scalable, Cost-Free and Covert Hybrid Botnet on Bitcoin's  Lightning Network",
    "abstract": "While various covert botnets were proposed in the past, they still lack\ncomplete anonymization for their servers/botmasters or suffer from slow\ncommunication between the botmaster and the bots. In this paper, we first\npropose a new generation hybrid botnet that covertly and efficiently\ncommunicates over Bitcoin Lightning Network (LN), called LNBot. Exploiting\nvarious anonymity features of LN, we show the feasibility of a scalable\ntwo-layer botnet which completely anonymizes the identity of the botmaster. In\nthe first layer, the botmaster anonymously sends the commands to the command\nand control (C&C) servers through regular LN payments. Specifically, LNBot\nallows botmaster's commands to be sent in the form of surreptitious multi-hop\nLN payments, where the commands are either encoded with the payments or\nattached to the payments to provide covert communications. In the second layer,\nC&C servers further relay those commands to the bots in their mini-botnets to\nlaunch any type of attacks to victim machines. We further improve on this\ndesign by introducing D-LNBot; a distributed version of LNBot that generates\nits C&C servers by infecting users on the Internet and forms the C&C\nconnections by opening channels to the existing nodes on LN. In contrary to the\nLNBot, the whole botnet formation phase is distributed and the botmaster is\nnever involved in the process. By utilizing Bitcoin's Testnet and the new\nmessage attachment feature of LN, we show that D-LNBot can be run for free and\ncommands are propagated faster to all the C&C servers compared to LNBot. We\npresented proof-of-concept implementations for both LNBot and D-LNBot on the\nactual LN and extensively analyzed their delay and cost performance. Finally,\nwe also provide and discuss a list of potential countermeasures to detect LNBot\nand D-LNBot activities and minimize their impacts.",
    "descriptor": "\nComments: Journal extension of this https URL\n",
    "authors": [
      "Ahmet Kurt",
      "Enes Erdin",
      "Kemal Akkaya",
      "A. Selcuk Uluagac",
      "Mumin Cebe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.07623"
  },
  {
    "id": "arXiv:2112.07624",
    "title": "Interaction-Aware Trajectory Prediction and Planning for Autonomous  Vehicles in Forced Merge Scenarios",
    "abstract": "Merging is, in general, a challenging task for both human drivers and\nautonomous vehicles, especially in dense traffic, because the merging vehicle\ntypically needs to interact with other vehicles to identify or create a gap and\nsafely merge into. In this paper, we consider the problem of autonomous vehicle\ncontrol for forced merge scenarios. We propose a novel game-theoretic\ncontroller, called the Leader-Follower Game Controller (LFGC), in which the\ninteractions between the autonomous ego vehicle and other vehicles with a\npriori uncertain driving intentions is modeled as a partially observable\nleader-follower game. The LFGC estimates the other vehicles' intentions online\nbased on observed trajectories, and then predicts their future trajectories and\nplans the ego vehicle's own trajectory using Model Predictive Control (MPC) to\nsimultaneously achieve probabilistically guaranteed safety and merging\nobjectives. To verify the performance of LFGC, we test it in simulations and\nwith the NGSIM data, where the LFGC demonstrates a high success rate of 97.5%\nin merging.",
    "descriptor": "\nComments: 15 pages, 12 figures\n",
    "authors": [
      "Kaiwen Liu",
      "Nan Li",
      "H. Eric Tseng",
      "Ilya Kolmanovsky",
      "Anouck Girard"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.07624"
  },
  {
    "id": "arXiv:2112.07628",
    "title": "Training Multi-Layer Over-Parametrized Neural Network in Subquadratic  Time",
    "abstract": "We consider the problem of training a multi-layer over-parametrized neural\nnetworks to minimize the empirical risk induced by a loss function. In the\ntypical setting of over-parametrization, the network width $m$ is much larger\nthan the data dimension $d$ and number of training samples $n$\n($m=\\mathrm{poly}(n,d)$), which induces a prohibitive large weight matrix $W\\in\n\\mathbb{R}^{m\\times m}$ per layer. Naively, one has to pay $O(m^2)$ time to\nread the weight matrix and evaluate the neural network function in both forward\nand backward computation. In this work, we show how to reduce the training cost\nper iteration, specifically, we propose a framework that uses $m^2$ cost only\nin the initialization phase and achieves a truly subquadratic cost per\niteration in terms of $m$, i.e., $m^{2-\\Omega(1)}$ per iteration.\nTo obtain this result, we make use of various techniques, including a shifted\nReLU-based sparsifier, a lazy low rank maintenance data structure, fast\nrectangular matrix multiplication, tensor-based sketching techniques and\npreconditioning.",
    "descriptor": "",
    "authors": [
      "Zhao Song",
      "Lichen Zhang",
      "Ruizhe Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.07628"
  },
  {
    "id": "arXiv:2112.07636",
    "title": "Forwarders as Process Compatibility, Logically",
    "abstract": "Session types define protocols that processes must follow when communicating.\nThe special case of binary session types, i.e. type annotations of protocols\nbetween two parties, is known to be in a propositions-as-types correspondence\nwith linear logic. In previous work, we have shown that the generalization to\nmultiparty session types can be expressed either by coherence proofs or by\narbiters, processes that act as middleware by forwarding messages according to\nthe given protocol. In this paper, following the propositions-as-types fashion,\nwe generalize arbiters to a logic, which we call forwarder logic, a fragment of\nclassical linear logic still satisfying cut-elimination. Our main result is\nsummarized as follows: forwarders generalize coherence and give an elegant\nproof-theoretic characterization of multiparty compatibility, a property of\nconcurrent systems guaranteeing that all sent messages are eventually received\nand no deadlock ever occurs.",
    "descriptor": "",
    "authors": [
      "Marco Carbone",
      "Sonia Marin",
      "Carsten Sch\u00fcrmann"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.07636"
  },
  {
    "id": "arXiv:2112.07637",
    "title": "Exploring Neural Models for Query-Focused Summarization",
    "abstract": "Query-focused summarization (QFS) aims to produce summaries that answer\nparticular questions of interest, enabling greater user control and\npersonalization. While recently released datasets, such as QMSum or AQuaMuSe,\nfacilitate research efforts in QFS, the field lacks a comprehensive study of\nthe broad space of applicable modeling methods. In this paper we conduct a\nsystematic exploration of neural approaches to QFS, considering two general\nclasses of methods: two-stage extractive-abstractive solutions and end-to-end\nmodels. Within those categories, we investigate existing methods and present\ntwo model extensions that achieve state-of-the-art performance on the QMSum\ndataset by a margin of up to 3.38 ROUGE-1, 3.72 ROUGE-2, and 3.28 ROUGE-L.\nThrough quantitative experiments we highlight the trade-offs between different\nmodel configurations and explore the transfer abilities between summarization\ntasks. Code and checkpoints are made publicly available:\nhttps://github.com/salesforce/query-focused-sum.",
    "descriptor": "",
    "authors": [
      "Jesse Vig",
      "Alexander R. Fabbri",
      "Wojciech Kry\u015bci\u0144ski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07637"
  },
  {
    "id": "arXiv:2112.07640",
    "title": "How and Why to Manipulate Your Own Agent",
    "abstract": "We consider strategic settings where several users engage in a repeated\nonline interaction, assisted by regret-minimizing agents that repeatedly play a\n\"game\" on their behalf. We study the dynamics and average outcomes of the\nrepeated game of the agents, and view it as inducing a meta-game between the\nusers. Our main focus is on whether users can benefit in this meta-game from\n\"manipulating\" their own agent by mis-reporting their parameters to it. We\nformally define this \"user-agent meta-game\" model for general games, discuss\nits properties under different notions of convergence of the dynamics of the\nautomated agents and analyze the equilibria induced on the users in 2x2 games\nin which the dynamics converge to a single equilibrium.",
    "descriptor": "",
    "authors": [
      "Yoav Kolumbus",
      "Noam Nisan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.07640"
  },
  {
    "id": "arXiv:2112.07641",
    "title": "Regularized Orthogonal Nonnegative Matrix Factorization and $K$-means  Clustering",
    "abstract": "In this work, we focus on connections between $K$-means clustering approaches\nand Orthogonal Nonnegative Matrix Factorization (ONMF) methods. We present a\nnovel framework to extract the distance measure and the centroids of the\n$K$-means method based on first order conditions of the considered ONMF\nobjective function, which exploits the classical alternating minimization\nschemes of Nonnegative Matrix Factorization (NMF) algorithms. While this\ntechnique is characterized by a simple derivation procedure, it can also be\napplied to non-standard regularized ONMF models. Using this framework, we\nconsider in this work ONMF models with $\\ell_1$ and standard $\\ell_2$\ndiscrepancy terms with an additional elastic net regularization on both\nfactorization matrices and derive the corresponding distance measures and\ncentroids of the generalized $K$-means clustering model. Furthermore, we give\nan intuitive view of the obtained results, examine special cases and compare\nthem to the findings described in the literature.",
    "descriptor": "",
    "authors": [
      "Pascal Fernsel",
      "Peter Maass"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07641"
  },
  {
    "id": "arXiv:2112.07642",
    "title": "EgoBody: Human Body Shape, Motion and Social Interactions from  Head-Mounted Devices",
    "abstract": "Understanding social interactions from first-person views is crucial for many\napplications, ranging from assistive robotics to AR/VR. A first step for\nreasoning about interactions is to understand human pose and shape. However,\nresearch in this area is currently hindered by the lack of data. Existing\ndatasets are limited in terms of either size, annotations, ground-truth capture\nmodalities or the diversity of interactions. We address this shortcoming by\nproposing EgoBody, a novel large-scale dataset for social interactions in\ncomplex 3D scenes. We employ Microsoft HoloLens2 headsets to record rich\negocentric data streams (including RGB, depth, eye gaze, head and hand\ntracking). To obtain accurate 3D ground-truth, we calibrate the headset with a\nmulti-Kinect rig and fit expressive SMPL-X body meshes to multi-view RGB-D\nframes, reconstructing 3D human poses and shapes relative to the scene. We\ncollect 68 sequences, spanning diverse sociological interaction categories, and\npropose the first benchmark for 3D full-body pose and shape estimation from\negocentric views. Our dataset and code will be available for research at\nhttps://sanweiliti.github.io/egobody/egobody.html.",
    "descriptor": "",
    "authors": [
      "Siwei Zhang",
      "Qianli Ma",
      "Yan Zhang",
      "Zhiyin Qian",
      "Marc Pollefeys",
      "Federica Bogo",
      "Siyu Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07642"
  },
  {
    "id": "arXiv:2112.07647",
    "title": "A study on the Morris Worm",
    "abstract": "The Morris worm was one of the first worms spread via the internet. It was\nspread on November 2, 1988, and changed how computer security was viewed by\ncomputer professionals as well as general public. Since its inception the\nMorris worm has been studied extensively from the security point of view and is\nstill a point of interest. This paper summarizes the effects, impacts, and\nlessons learned from the episode. There are other copies of this paper present.\nHowever, I recommend using the arXiv version only.",
    "descriptor": "",
    "authors": [
      "Akshay Jajoo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.07647"
  },
  {
    "id": "arXiv:2112.07648",
    "title": "On the Use of External Data for Spoken Named Entity Recognition",
    "abstract": "Spoken language understanding (SLU) tasks involve mapping from speech audio\nsignals to semantic labels. Given the complexity of such tasks, good\nperformance might be expected to require large labeled datasets, which are\ndifficult to collect for each new task and domain. However, recent advances in\nself-supervised speech representations have made it feasible to consider\nlearning SLU models with limited labeled data. In this work we focus on\nlow-resource spoken named entity recognition (NER) and address the question:\nBeyond self-supervised pre-training, how can we use external speech and/or text\ndata that are not annotated for the task? We draw on a variety of approaches,\nincluding self-training, knowledge distillation, and transfer learning, and\nconsider their applicability to both end-to-end models and pipeline (speech\nrecognition followed by text NER model) approaches. We find that several of\nthese approaches improve performance in resource-constrained settings beyond\nthe benefits from pre-trained representations alone. Compared to prior work, we\nfind improved F1 scores of up to 16%. While the best baseline model is a\npipeline approach, the best performance when using external data is ultimately\nachieved by an end-to-end model. We provide detailed comparisons and analyses,\nshowing for example that end-to-end models are able to focus on the more\nNER-specific words.",
    "descriptor": "",
    "authors": [
      "Ankita Pasad",
      "Felix Wu",
      "Suwon Shon",
      "Karen Livescu",
      "Kyu J. Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.07648"
  },
  {
    "id": "arXiv:2112.07658",
    "title": "AdaViT: Adaptive Tokens for Efficient Vision Transformer",
    "abstract": "We introduce AdaViT, a method that adaptively adjusts the inference cost of\nvision transformer (ViT) for images of different complexity. AdaViT achieves\nthis by automatically reducing the number of tokens in vision transformers that\nare processed in the network as inference proceeds. We reformulate Adaptive\nComputation Time (ACT) for this task, extending halting to discard redundant\nspatial tokens. The appealing architectural properties of vision transformers\nenables our adaptive token reduction mechanism to speed up inference without\nmodifying the network architecture or inference hardware. We demonstrate that\nAdaViT requires no extra parameters or sub-network for halting, as we base the\nlearning of adaptive halting on the original network parameters. We further\nintroduce distributional prior regularization that stabilizes training compared\nto prior ACT approaches. On the image classification task (ImageNet1K), we show\nthat our proposed AdaViT yields high efficacy in filtering informative spatial\nfeatures and cutting down on the overall compute. The proposed method improves\nthe throughput of DeiT-Tiny by 62% and DeiT-Small by 38% with only 0.3%\naccuracy drop, outperforming prior art by a large margin.",
    "descriptor": "",
    "authors": [
      "Hongxu Yin",
      "Arash Vahdat",
      "Jose Alvarez",
      "Arun Mallya",
      "Jan Kautz",
      "Pavlo Molchanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07658"
  },
  {
    "id": "arXiv:2112.07660",
    "title": "Massive-scale Decoding for Text Generation using Lattices",
    "abstract": "Neural text generation models like those used for summarization and\ntranslation generate high-quality outputs, but often concentrate around a mode\nwhen what we really want is a diverse set of options. We present a search\nalgorithm to construct lattices encoding a massive number of generation\noptions. First, we restructure decoding as a best-first search, which explores\nthe space differently than beam search and improves efficiency by avoiding\npruning paths. Second, we revisit the idea of hypothesis recombination: we can\nidentify pairs of similar generation candidates during search and merge them as\nan approximation. On both document summarization and machine translation, we\nshow that our algorithm encodes hundreds to thousands of diverse options that\nremain grammatical and high-quality into one linear-sized lattice. This\nalgorithm provides a foundation for building downstream generation applications\non top of massive-scale diverse outputs.",
    "descriptor": "\nComments: 19 pages, 13 figures, see this https URL\n",
    "authors": [
      "Jiacheng Xu",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07660"
  },
  {
    "id": "arXiv:2112.07661",
    "title": "Approaches Toward Physical and General Video Anomaly Detection",
    "abstract": "In recent years, many works have addressed the problem of finding\nnever-seen-before anomalies in videos. Yet, most work has been focused on\ndetecting anomalous frames in surveillance videos taken from security cameras.\nMeanwhile, the task of anomaly detection (AD) in videos exhibiting anomalous\nmechanical behavior, has been mostly overlooked. Anomaly detection in such\nvideos is both of academic and practical interest, as they may enable automatic\ndetection of malfunctions in many manufacturing, maintenance, and real-life\nsettings. To assess the potential of the different approaches to detect such\nanomalies, we evaluate two simple baseline approaches: (i) Temporal-pooled\nimage AD techniques. (ii) Density estimation of videos represented with\nfeatures pretrained for video-classification.\nDevelopment of such methods calls for new benchmarks to allow evaluation of\ndifferent possible approaches. We introduce the Physical Anomalous Trajectory\nor Motion (PHANTOM) dataset, which contains six different video classes. Each\nclass consists of normal and anomalous videos. The classes differ in the\npresented phenomena, the normal class variability, and the kind of anomalies in\nthe videos. We also suggest an even harder benchmark where anomalous activities\nshould be spotted on highly variable scenes.",
    "descriptor": "",
    "authors": [
      "Laura Kart",
      "Niv Cohen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07661"
  },
  {
    "id": "arXiv:2112.07662",
    "title": "Out-of-Distribution Detection without Class Labels",
    "abstract": "Anomaly detection methods identify samples that deviate from the normal\nbehavior of the dataset. It is typically tackled either for training sets\ncontaining normal data from multiple labeled classes or a single unlabeled\nclass. Current methods struggle when faced with training data consisting of\nmultiple classes but no labels. In this work, we first discover that\nclassifiers learned by self-supervised image clustering methods provide a\nstrong baseline for anomaly detection on unlabeled multi-class datasets.\nPerhaps surprisingly, we find that initializing clustering methods with\npre-trained features does not improve over their self-supervised counterparts.\nThis is due to the phenomenon of catastrophic forgetting. Instead, we suggest a\ntwo stage approach. We first cluster images using self-supervised methods and\nobtain a cluster label for every image. We use the cluster labels as \"pseudo\nsupervision\" for out-of-distribution (OOD) methods. Specifically, we finetune\npretrained features on the task of classifying images by their cluster labels.\nWe provide extensive analyses of our method and demonstrate the necessity of\nour two-stage approach. We evaluate it against the state-of-the-art\nself-supervised and pretrained methods and demonstrate superior performance.",
    "descriptor": "",
    "authors": [
      "Niv Cohen",
      "Ron Abutbul",
      "Yedid Hoshen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07662"
  },
  {
    "id": "arXiv:2112.07663",
    "title": "Learning Connectivity-Maximizing Network Configurations",
    "abstract": "In this work we propose a data-driven approach to optimizing the algebraic\nconnectivity of a team of robots. While a considerable amount of research has\nbeen devoted to this problem, we lack a method that scales in a manner suitable\nfor online applications for more than a handful of agents. To that end, we\npropose a supervised learning approach with a convolutional neural network\n(CNN) that learns to place communication agents from an expert that uses an\noptimization-based strategy. We demonstrate the performance of our CNN on\ncanonical line and ring topologies, 105k randomly generated test cases, and\nlarger teams not seen during training. We also show how our system can be\napplied to dynamic robot teams through a Unity-based simulation. After\ntraining, our system produces connected configurations 2 orders of magnitude\nfaster than the optimization-based scheme for teams of 10-20 agents.",
    "descriptor": "",
    "authors": [
      "Daniel Mox",
      "Vijay Kumar",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.07663"
  },
  {
    "id": "arXiv:2112.07664",
    "title": "Adaptive Affinity for Associations in Multi-Target Multi-Camera Tracking",
    "abstract": "Data associations in multi-target multi-camera tracking (MTMCT) usually\nestimate affinity directly from re-identification (re-ID) feature distances.\nHowever, we argue that it might not be the best choice given the difference in\nmatching scopes between re-ID and MTMCT problems. Re-ID systems focus on global\nmatching, which retrieves targets from all cameras and all times. In contrast,\ndata association in tracking is a local matching problem, since its candidates\nonly come from neighboring locations and time frames. In this paper, we design\nexperiments to verify such misfit between global re-ID feature distances and\nlocal matching in tracking, and propose a simple yet effective approach to\nadapt affinity estimations to corresponding matching scopes in MTMCT. Instead\nof trying to deal with all appearance changes, we tailor the affinity metric to\nspecialize in ones that might emerge during data associations. To this end, we\nintroduce a new data sampling scheme with temporal windows originally used for\ndata associations in tracking. Minimizing the mismatch, the adaptive affinity\nmodule brings significant improvements over global re-ID distance, and produces\ncompetitive performance on CityFlow and DukeMTMC datasets.",
    "descriptor": "\nComments: This paper appears in: IEEE Transactions on Image Processing\n",
    "authors": [
      "Yunzhong Hou",
      "Zhongdao Wang",
      "Shengjin Wang",
      "Liang Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07664"
  },
  {
    "id": "arXiv:2112.07668",
    "title": "Dual-Key Multimodal Backdoors for Visual Question Answering",
    "abstract": "The success of deep learning has enabled advances in multimodal tasks that\nrequire non-trivial fusion of multiple input domains. Although multimodal\nmodels have shown potential in many problems, their increased complexity makes\nthem more vulnerable to attacks. A Backdoor (or Trojan) attack is a class of\nsecurity vulnerability wherein an attacker embeds a malicious secret behavior\ninto a network (e.g. targeted misclassification) that is activated when an\nattacker-specified trigger is added to an input. In this work, we show that\nmultimodal networks are vulnerable to a novel type of attack that we refer to\nas Dual-Key Multimodal Backdoors. This attack exploits the complex fusion\nmechanisms used by state-of-the-art networks to embed backdoors that are both\neffective and stealthy. Instead of using a single trigger, the proposed attack\nembeds a trigger in each of the input modalities and activates the malicious\nbehavior only when both the triggers are present. We present an extensive study\nof multimodal backdoors on the Visual Question Answering (VQA) task with\nmultiple architectures and visual feature backbones. A major challenge in\nembedding backdoors in VQA models is that most models use visual features\nextracted from a fixed pretrained object detector. This is challenging for the\nattacker as the detector can distort or ignore the visual trigger entirely,\nwhich leads to models where backdoors are over-reliant on the language trigger.\nWe tackle this problem by proposing a visual trigger optimization strategy\ndesigned for pretrained object detectors. Through this method, we create\nDual-Key Backdoors with over a 98% attack success rate while only poisoning 1%\nof the training data. Finally, we release TrojVQA, a large collection of clean\nand trojan VQA models to enable research in defending against multimodal\nbackdoors.",
    "descriptor": "\nComments: 22 pages, 11 figures, 12 tables\n",
    "authors": [
      "Matthew Walmer",
      "Karan Sikka",
      "Indranil Sur",
      "Abhinav Shrivastava",
      "Susmit Jha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07668"
  },
  {
    "id": "arXiv:2107.09961",
    "title": "Quantum Pattern Recognition in Photonic Circuits",
    "abstract": "This paper proposes a machine learning method to characterize photonic states\nvia a simple optical circuit and data processing of photon number\ndistributions, such as photonic patterns. The input states consist of two\ncoherent states used as references and a two-mode unknown state to be studied.\nWe successfully trained supervised learning algorithms that can predict the\ndegree of entanglement in the two-mode state as well as perform the full\ntomography of one photonic mode, obtaining satisfactory values in the\nconsidered regression metrics.",
    "descriptor": "\nComments: 7 pages + 2 figures\n",
    "authors": [
      "Rui Wang",
      "Carlos Hernani-Morales",
      "Jos\u00e9 D. Mart\u00edn-Guerrero",
      "Enrique Solano",
      "Francisco Albarr\u00e1n-Arriagada"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.09961"
  },
  {
    "id": "arXiv:2109.08612",
    "title": "Active Learning for the Optimal Design of Multinomial Classification in  Physics",
    "abstract": "Optimal design for model training is a critical topic in machine learning.\nActive Learning aims at obtaining improved models by querying samples with\nmaximum uncertainty according to the estimation model for artificially\nlabeling; this has the additional advantage of achieving successful\nperformances with a reduced number of labeled samples. We analyze its\ncapability as an assistant for the design of experiments, extracting maximum\ninformation for learning with the minimal cost in fidelity loss, or reducing\ntotal operation costs of labeling in the laboratory. We present two typical\napplications as quantum information retrieval in qutrits and phase boundary\nprediction in many-body physics. For an equivalent multinomial classification\nproblem, we achieve the correct rate of 99% with less than 2% samples labeled.\nWe reckon that active-learning-inspired physics experiments will remarkably\nsave budget without loss of accuracy.",
    "descriptor": "\nComments: 13 pages and 11 figures\n",
    "authors": [
      "Yongcheng Ding",
      "Jos\u00e9 D. Mart\u00edn-Guerrero",
      "Yujing Song",
      "Rafael Magdalena-Benedito",
      "Xi Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.08612"
  },
  {
    "id": "arXiv:2112.06628",
    "title": "Quantum Stream Learning",
    "abstract": "The exotic nature of quantum mechanics makes machine learning (ML) be\ndifferent in the quantum realm compared to classical applications. ML can be\nused for knowledge discovery using information continuously extracted from a\nquantum system in a broad range of tasks. The model receives streaming quantum\ninformation for learning and decision-making, resulting in instant feedback on\nthe quantum system. As a stream learning approach, we present a deep\nreinforcement learning on streaming data from a continuously measured qubit at\nthe presence of detuning, dephasing, and relaxation. We also investigate how\nthe agent adapts to another quantum noise pattern by transfer learning. Stream\nlearning provides a better understanding of closed-loop quantum control, which\nmay pave the way for advanced quantum technologies.",
    "descriptor": "\nComments: 7 pages, 3 figures, submitted to the special issue on stream learning, comments are welcomed\n",
    "authors": [
      "Yongcheng Ding",
      "Xi Chen",
      "Rafael Magdalena-Benedicto",
      "Jos\u00e9 D. Mart\u00edn-Guerrero"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06628"
  },
  {
    "id": "arXiv:2112.06920",
    "title": "Boosting Independent Component Analysis",
    "abstract": "Independent component analysis is intended to recover the unknown components\nas independent as possible from their linear mixtures. This technique has been\nwidely used in many fields, such as data analysis, signal processing, and\nmachine learning. In this paper, we present a novel boosting-based algorithm\nfor independent component analysis. Our algorithm fills the gap in the\nnonparametric independent component analysis by introducing boosting to maximum\nlikelihood estimation. A variety of experiments validate its performance\ncompared with many of the presently known algorithms.",
    "descriptor": "",
    "authors": [
      "Yunpeng Li",
      "ZhaoHui Ye"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.06920"
  },
  {
    "id": "arXiv:2112.06974",
    "title": "Control-Oriented Modeling of Pipe Flow through Intersecting Pipe  Geometries",
    "abstract": "We present control-oriented models for transient dynamics of isothermal\none-dimensional gas flow through multiple pipes in series and intersecting pipe\ngeometries. These composite models subsume algebraic constraints that would\notherwise appear due to boundary conditions, so that our linear state-space\nmodels are well-suited for model-based control design for gas flow in pipe\nnetworks with non-trivial geometries.",
    "descriptor": "",
    "authors": [
      "Sven Br\u00fcggemann",
      "Robert R. Bitmead"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.06974"
  },
  {
    "id": "arXiv:2112.06979",
    "title": "The Brain Tumor Sequence Registration Challenge: Establishing  Correspondence between Pre-Operative and Follow-up MRI scans of diffuse  glioma patients",
    "abstract": "Registration of longitudinal brain Magnetic Resonance Imaging (MRI) scans\ncontaining pathologies is challenging due to tissue appearance changes, and\nstill an unsolved problem. This paper describes the first Brain Tumor Sequence\nRegistration (BraTS-Reg) challenge, focusing on estimating correspondences\nbetween pre-operative and follow-up scans of the same patient diagnosed with a\nbrain diffuse glioma. The BraTS-Reg challenge intends to establish a public\nbenchmark environment for deformable registration algorithms. The associated\ndataset comprises de-identified multi-institutional multi-parametric MRI\n(mpMRI) data, curated for each scan's size and resolution, according to a\ncommon anatomical template. Clinical experts have generated extensive\nannotations of landmarks points within the scans, descriptive of distinct\nanatomical locations across the temporal domain. The training data along with\nthese ground truth annotations will be released to participants to design and\ndevelop their registration algorithms, whereas the annotations for the\nvalidation and the testing data will be withheld by the organizers and used to\nevaluate the containerized algorithms of the participants. Each submitted\nalgorithm will be quantitatively evaluated using several metrics, such as the\nMedian Absolute Error (MAE), Robustness, and the Jacobian determinant.",
    "descriptor": "",
    "authors": [
      "Bhakti Baheti",
      "Diana Waldmannstetter",
      "Satrajit Chakrabarty",
      "Hamed Akbari",
      "Michel Bilello",
      "Benedikt Wiestler",
      "Julian Schwarting",
      "Evan Calabrese",
      "Jeffrey Rudie",
      "Syed Abidi",
      "Mina Mousa",
      "Javier Villanueva-Meyer",
      "Daniel S. Marcus",
      "Christos Davatzikos",
      "Aristeidis Sotiras",
      "Bjoern Menze",
      "Spyridon Bakas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06979"
  },
  {
    "id": "arXiv:2112.07059",
    "title": "Self-induced emergence of consensus in social networks: Reddit and the  GameStop short squeeze",
    "abstract": "The short squeeze of GameStop (GME) shares in mid-January 2021, primarily\norchestrated by retail investors of the Reddit r/wallstreetbets community,\nrepresents a paramount example of collective coordination action on social\nmedia, resulting in large-scale consensus formation and significant market\nimpact. In this work we characterise the structure and time evolution of Reddit\nconversation data, showing that the occurrence and sentiment of GME-related\ncomments (representing how much users are engaged with GME) increased\nsignificantly much before the short squeeze actually took place. We then\nintroduce a model of opinion dynamics where user engagement can trigger a\nself-reinforcing mechanism leading to the emergence of consensus on the short\nsqueeze operation. We observe a clear phase transition from heterogeneous to\nhomogeneous opinions as engagement grows, with the presence of hubs easing the\nformation of diffuse consensus. Our results shed light on the increasingly\nimportant phenomenon of self-organized collective actions taking place on\nsocial networks.",
    "descriptor": "",
    "authors": [
      "Anna Mancini",
      "Antonio Desiderio",
      "Riccardo Di Clemente",
      "Giulio Cimini"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2112.07059"
  },
  {
    "id": "arXiv:2112.07067",
    "title": "Dynamic Learning of Correlation Potentials for a Time-Dependent  Kohn-Sham System",
    "abstract": "We develop methods to learn the correlation potential for a time-dependent\nKohn-Sham (TDKS) system in one spatial dimension. We start from a\nlow-dimensional two-electron system for which we can numerically solve the\ntime-dependent Schr\\\"odinger equation; this yields electron densities suitable\nfor training models of the correlation potential. We frame the learning problem\nas one of optimizing a least-squares objective subject to the constraint that\nthe dynamics obey the TDKS equation. Applying adjoints, we develop efficient\nmethods to compute gradients and thereby learn models of the correlation\npotential. Our results show that it is possible to learn values of the\ncorrelation potential such that the resulting electron densities match ground\ntruth densities. We also show how to learn correlation potential functionals\nwith memory, demonstrating one such model that yields reasonable results for\ntrajectories outside the training set.",
    "descriptor": "\nComments: 18 pages, 5 figures\n",
    "authors": [
      "Harish S. Bhat",
      "Kevin Collins",
      "Prachi Gupta",
      "Christine M. Isborn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.07067"
  },
  {
    "id": "arXiv:2112.07068",
    "title": "Score-Based Generative Modeling with Critically-Damped Langevin  Diffusion",
    "abstract": "Score-based generative models (SGMs) have demonstrated remarkable synthesis\nquality. SGMs rely on a diffusion process that gradually perturbs the data\ntowards a tractable distribution, while the generative model learns to denoise.\nThe complexity of this denoising task is, apart from the data distribution\nitself, uniquely determined by the diffusion process. We argue that current\nSGMs employ overly simplistic diffusions, leading to unnecessarily complex\ndenoising processes, which limit generative modeling performance. Based on\nconnections to statistical mechanics, we propose a novel critically-damped\nLangevin diffusion (CLD) and show that CLD-based SGMs achieve superior\nperformance. CLD can be interpreted as running a joint diffusion in an extended\nspace, where the auxiliary variables can be considered \"velocities\" that are\ncoupled to the data variables as in Hamiltonian dynamics. We derive a novel\nscore matching objective for CLD and show that the model only needs to learn\nthe score function of the conditional distribution of the velocity given data,\nan easier task than learning scores of the data directly. We also derive a new\nsampling scheme for efficient synthesis from CLD-based diffusion models. We\nfind that CLD outperforms previous SGMs in synthesis quality for similar\nnetwork architectures and sampling compute budgets. We show that our novel\nsampler for CLD significantly outperforms solvers such as Euler--Maruyama. Our\nframework provides new insights into score-based denoising diffusion models and\ncan be readily used for high-resolution image synthesis. Project page and code:\nhttps://nv-tlabs.github.io/CLD-SGM.",
    "descriptor": "",
    "authors": [
      "Tim Dockhorn",
      "Arash Vahdat",
      "Karsten Kreis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07068"
  },
  {
    "id": "arXiv:2112.07092",
    "title": "A Quantum Internet Architecture",
    "abstract": "Entangled quantum communication is advancing rapidly, with laboratory and\nmetropolitan testbeds under development, but to date there is no unifying\nQuantum Internet architecture. We propose a Quantum Internet architecture\ncentered around the Quantum Recursive Network Architecture (QRNA), using\nRuleSet-based connections established using a two-pass connection setup.\nScalability and internetworking (for both technological and administrative\nboundaries) are achieved using recursion in naming and connection control. In\nthe near term, this architecture will support end-to-end, two-party\nentanglement on minimal hardware, and it will extend smoothly to multi-party\nentanglement and the use of quantum error correction on advanced hardware in\nthe future. For a network internal gateway protocol, we recommend (but do not\nrequire) qDijkstra with seconds per Bell pair as link cost for routing; the\nexternal gateway protocol is designed to build recursively. The strength of our\narchitecture is shown by assessing extensibility and demonstrating how robust\nprotocol operation can be confirmed using the RuleSet paradigm.",
    "descriptor": "\nComments: 17 pages, 7 numbered figures\n",
    "authors": [
      "Rodney Van Meter",
      "Ryosuke Satoh",
      "Naphan Benchasattabuse",
      "Takaaki Matsuo",
      "Michal Hajdu\u0161ek",
      "Takahiko Satoh",
      "Shota Nagayama",
      "Shigeya Suzuki"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.07092"
  },
  {
    "id": "arXiv:2112.07093",
    "title": "QuISP: a Quantum Internet Simulation Package",
    "abstract": "We present an event-driven simulation package called QuISP for large-scale\nquantum networks built on top of the OMNeT++ discrete event simulation\nframework. Although the behavior of quantum networking devices have been\nrevealed by recent research, it is still an open question how they will work in\nnetworks of a practical size. QuISP is designed to simulate large-scale quantum\nnetworks to investigate their behavior under realistic, noisy and heterogeneous\nconfigurations. The protocol architecture we propose enables studies of\ndifferent choices for error management and other key decisions. Our confidence\nin the simulator is supported by comparing its output to analytic results for a\nsmall network. A key reason for simulation is to look for emergent behavior\nwhen large numbers of individually characterized devices are combined. QuISP\ncan handle thousands of qubits in dozens of nodes on a laptop computer,\npreparing for full Quantum Internet simulation. This simulator promotes the\ndevelopment of protocols for larger and more complex quantum networks.",
    "descriptor": "\nComments: 17 pages, 12 figures\n",
    "authors": [
      "Ryosuke Satoh",
      "Michal Hajdu\u0161ek",
      "Naphan Benchasattabuse",
      "Shota Nagayama",
      "Kentaro Teramoto",
      "Takaaki Matsuo",
      "Sara Ayman Metwalli",
      "Takahiko Satoh",
      "Shigeya Suzuki",
      "Rodney Van Meter"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.07093"
  },
  {
    "id": "arXiv:2112.07102",
    "title": "COVID-19 Pneumonia and Influenza Pneumonia Detection Using Convolutional  Neural Networks",
    "abstract": "In the research, we developed a computer vision solution to support\ndiagnostic radiology in differentiating between COVID-19 pneumonia, influenza\nvirus pneumonia, and normal biomarkers. The chest radiograph appearance of\nCOVID-19 pneumonia is thought to be nonspecific, having presented a challenge\nto identify an optimal architecture of a convolutional neural network (CNN)\nthat would classify with a high sensitivity among the pulmonary inflammation\nfeatures of COVID-19 and non-COVID-19 types of pneumonia. Rahman (2021) states\nthat COVID-19 radiography images observe unavailability and quality issues\nimpacting the diagnostic process and affecting the accuracy of the deep\nlearning detection models. A significant scarcity of COVID-19 radiography\nimages introduced an imbalance in data motivating us to use over-sampling\ntechniques. In the study, we include an extensive set of X-ray imaging of human\nlungs (CXR) with COVID-19 pneumonia, influenza virus pneumonia, and normal\nbiomarkers to achieve an extensible and accurate CNN model. In the\nexperimentation phase of the research, we evaluated a variety of convolutional\nnetwork architectures, selecting a sequential convolutional network with two\ntraditional convolutional layers and two pooling layers with maximum function.\nIn its classification performance, the best performing model demonstrated a\nvalidation accuracy of 93% and an F1 score of 0.95. We chose the Azure Machine\nLearning service to perform network experimentation and solution deployment.\nThe auto-scaling compute clusters offered a significant time reduction in\nnetwork training. We would like to see scientists across fields of artificial\nintelligence and human biology collaborating and expanding on the proposed\nsolution to provide rapid and comprehensive diagnostics, effectively mitigating\nthe spread of the virus",
    "descriptor": "\nComments: for associated Azure ML notebook code, see this https URL\n",
    "authors": [
      "Julianna Antonchuk",
      "Benjamin Prescott",
      "Philip Melanchthon",
      "Robin Singh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07102"
  },
  {
    "id": "arXiv:2112.07110",
    "title": "Non Asymptotic Bounds for Optimization via Online Multiplicative  Stochastic Gradient Descent",
    "abstract": "The gradient noise of Stochastic Gradient Descent (SGD) is considered to play\na key role in its properties (e.g. escaping low potential points and\nregularization). Past research has indicated that the covariance of the SGD\nerror done via minibatching plays a critical role in determining its\nregularization and escape from low potential points. It is however not much\nexplored how much the distribution of the error influences the behavior of the\nalgorithm. Motivated by some new research in this area, we prove universality\nresults by showing that noise classes that have the same mean and covariance\nstructure of SGD via minibatching have similar properties. We mainly consider\nthe Multiplicative Stochastic Gradient Descent (M-SGD) algorithm as introduced\nby Wu et al., which has a much more general noise class than the SGD algorithm\ndone via minibatching. We establish nonasymptotic bounds for the M-SGD\nalgorithm mainly with respect to the Stochastic Differential Equation\ncorresponding to SGD via minibatching. We also show that the M-SGD error is\napproximately a scaled Gaussian distribution with mean $0$ at any fixed point\nof the M-SGD algorithm.",
    "descriptor": "",
    "authors": [
      "Riddhiman Bhattacharya"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.07110"
  },
  {
    "id": "arXiv:2112.07114",
    "title": "Semilinear optimal control with Dirac measures",
    "abstract": "The purpose of this work is to analyze an optimal control problem for a\nsemilinear elliptic partial differential equation (PDE) involving Dirac\nmeasures; the control variable corresponds to the amplitude of forces modeled\nas point sources. We analyze the existence of optimal solutions and derive\nfirst and, necessary and sufficient, second order optimality conditions. We\ndevise a solution technique that discretizes the state and adjoint equations\nwith continuous piecewise linear finite elements; the control variable is\nalready discrete. We analyze convergence properties of discretizations and\nobtain an a priori error estimate for the underlying approximation of an\noptimal control variable.",
    "descriptor": "",
    "authors": [
      "Enrique Otarola"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07114"
  },
  {
    "id": "arXiv:2112.07124",
    "title": "Minimal controllability problem on linear structural descriptor systems  with forbidden nodes",
    "abstract": "We consider a minimal controllability problem (MCP), which determines the\nminimum number of input nodes for a descriptor system to be structurally\ncontrollable. We discuss the \"forbidden nodes\" of descriptor systems, which\ncannot be connected to inputs. The three main results of this work are as\nfollows. First, we show a solvability for the MCP with forbidden nodes using\ngraph theory such as a bipartite graph and its Dulmage--Mendelsohn\ndecomposition. Next, we derive the optimal value of the MCP with forbidden\nnodes. The optimal value is determined by an optimal solution for constrained\nmaximum matching, and this result includes that of the standard MCP in the\nprevious work. Finally, we provide an efficient algorithm for solving the MCP\nwith forbidden nodes based on an alternating path algorithm.",
    "descriptor": "",
    "authors": [
      "Shun Terasaki",
      "Kazuhiro Sato"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07124"
  },
  {
    "id": "arXiv:2112.07156",
    "title": "ImportantAug: a data augmentation agent for speech",
    "abstract": "We introduce ImportantAug, a technique to augment training data for speech\nclassification and recognition models by adding noise to unimportant regions of\nthe speech and not to important regions. Importance is predicted for each\nutterance by a data augmentation agent that is trained to maximize the amount\nof noise it adds while minimizing its impact on recognition performance. The\neffectiveness of our method is illustrated on version two of the Google Speech\nCommands (GSC) dataset. On the standard GSC test set, it achieves a 23.3%\nrelative error rate reduction compared to conventional noise augmentation which\napplies noise to speech without regard to where it might be most effective. It\nalso provides a 25.4% error rate reduction compared to a baseline without data\naugmentation. Additionally, the proposed ImportantAug outperforms the\nconventional noise augmentation and the baseline on two test sets with\nadditional noise added.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Viet Anh Trinh",
      "Hassan Salami Kavaki",
      "Michael I Mandel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.07156"
  },
  {
    "id": "arXiv:2112.07167",
    "title": "Moderate deviation expansion for fully quantum tasks",
    "abstract": "The moderate deviation regime is concerned with the finite block length\ntrade-off between communication cost and error for information processing tasks\nin the asymptotic regime, where the communication cost approaches a\ncapacity-like quantity and the error vanishes at the same time. We find exact\ncharacterisations of these trade-offs for a variety of fully quantum\ncommunication tasks, including quantum source coding, quantum state splitting,\nentanglement-assisted quantum channel coding, and entanglement-assisted quantum\nchannel simulation. The main technical tool we derive is a tight relation\nbetween the partially smoothed max-information and the hypothesis testing\nrelative entropy. This allows us to obtain the expansion of the partially\nsmoothed max-information for i.i.d. states in the moderate deviation regime.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Navneeth Ramakrishnan",
      "Marco Tomamichel",
      "Mario Berta"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.07167"
  },
  {
    "id": "arXiv:2112.07185",
    "title": "Towards End-to-End Error Management for a Quantum Internet",
    "abstract": "Error management in the quantum Internet requires stateful and stochastic\nprocessing across multiple nodes, which is a significant burden. In view of the\nhistory of the current Internet, the end-to-end principle was devised for error\nmanagement, simplifying the work inside the network and contributing\nsignificantly to the scalability of the Internet. In this paper, we propose to\nbring the end-to-end principle into the error management of quantum Internet to\nimprove the communication resource utilization efficiency of a quantum\nInternet. The simulation results show that the error management using the\nend-to-end principle and locality can be more resource-efficient than other\nsettings. In addition, when end-to-end error management is used, if the error\nprobability of qubits in the end node is sufficiently low, there is no problem\neven if the error probability on the network side is higher than that in the\nend node, and the load on the network can be reduced. Our proposal will\ncontribute to improving the communication capacity and scalability of the\nquantum Internet, as well as to improve the interoperability of quantum\nAutonomous Systems. In addition, existing studies on routing and other aspects\nof the quantum Internet may exclude error management from their scope due to\nits complexity. The results of this study provide validity to the assumptions\nof such studies.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Shota Nagayama"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.07185"
  },
  {
    "id": "arXiv:2112.07216",
    "title": "Spatiogram: A phase based directional angular measure and perceptual  weighting for ensemble source width",
    "abstract": "In concert hall studies, inter-aural cross-correlation (IACC), which is\nsignal dependent, is used as a measure of perceptual source width. The same\nmeasure is used for perceptual source width in the case of distributed sources\nalso. In this work, we examine the validity of IACC for both the cases and\ndevelop an improved measure for ensemble-like distributed sources. We decompose\nthe new objective measure for perceptual ensemble source width (ESW) into two\ncomponents (i) phase based directional angular measure, which is timbre\nindependent (spatial measure) and (ii) mean time-bandwidth energy (MTBE), a\nperceptual weight, (timbre measure). This combination of spatial and timbral\nmeasures can be extended as an alternate measure for determining auditory\nsource width (ASW) and listener envelopment (LEV) of arbitrary signals in\nconcert-hall and room acoustics.",
    "descriptor": "\nComments: 12 pages, 11 figures\n",
    "authors": [
      "Arthi S",
      "Sreenivas T V"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.07216"
  },
  {
    "id": "arXiv:2112.07232",
    "title": "Structure-Exploiting Newton-Type Method for Optimal Control of Switched  Systems",
    "abstract": "This study proposes an efficient Newton-type method for the optimal control\nof switched systems under a given mode sequence. A mesh-refinement-based\napproach is utilized to discretize continuous-time optimal control problems\n(OCPs) using the direct multiple-shooting method to formulate a nonlinear\nprogram (NLP), which guarantees the local convergence of a Newton-type method.\nA dedicated structure-exploiting algorithm (Riccati recursion) is proposed that\nefficiently performs a Newton-type method for the NLP because its sparsity\nstructure is different from a standard OCP. The proposed method computes each\nNewton step with linear time-complexity for the total number of discretization\ngrids as the standard Riccati recursion algorithm. Additionally, it can always\nsolve the Karush-Kuhn-Tucker (KKT) systems arising in the Newton-type method if\nthe solution is sufficiently close to a local minimum. Conversely, general\nquadratic programming (QP) solvers cannot accomplish this because the Hessian\nmatrix is inherently indefinite. Moreover, a modification on the reduced\nHessian matrix is proposed using the nature of the Riccati recursion algorithm\nas the dynamic programming for a QP subproblem to enhance the convergence. A\nnumerical comparison is conducted with off-the-shelf NLP solvers, which\ndemonstrates that the proposed method is up to two orders of magnitude faster.\nWhole-body optimal control of quadrupedal gaits is also demonstrated and shows\nthat the proposed method can achieve the whole-body model predictive control\n(MPC) of robotic systems with rigid contacts.",
    "descriptor": "\nComments: 15 pages, 6 figures, 2 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Sotaro Katayama",
      "Toshiyuki Ohtsuka"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07232"
  },
  {
    "id": "arXiv:2112.07252",
    "title": "A Deep Knowledge Distillation framework for EEG assisted enhancement of  single-lead ECG based sleep staging",
    "abstract": "Automatic Sleep Staging study is presently done with the help of\nElectroencephalogram (EEG) signals. Recently, Deep Learning (DL) based\napproaches have enabled significant progress in this area, allowing for\nnear-human accuracy in automated sleep staging. However, EEG based sleep\nstaging requires an extensive as well as an expensive clinical setup. Moreover,\nthe requirement of an expert for setup and the added inconvenience to the\nsubject under study renders it unfavourable in a point of care context.\nElectrocardiogram (ECG), an unobtrusive alternative to EEG, is more suitable,\nbut its performance, unsurprisingly, remains sub-par compared to EEG-based\nsleep staging. Naturally, it would be helpful to transfer knowledge from EEG to\nECG, ultimately enhancing the model's performance on ECG based inputs.\nKnowledge Distillation (KD) is a renowned concept in DL that looks to transfer\nknowledge from a better but potentially more cumbersome teacher model to a\ncompact student model. Building on this concept, we propose a cross-modal KD\nframework to improve ECG-based sleep staging performance with assistance from\nfeatures learned through models trained on EEG. Additionally, we also conducted\nmultiple experiments on the individual components of the proposed model to get\nbetter insight into the distillation approach. Data of 200 subjects from the\nMontreal Archive of Sleep Studies (MASS) was utilized for our study. The\nproposed model showed a 14.3\\% and 13.4\\% increase in weighted-F1-score in\n4-class and 3-class sleep staging, respectively. This demonstrates the\nviability of KD for performance improvement of single-channel ECG based sleep\nstaging in 4-class(W-L-D-R) and 3-class(W-N-R) classification.",
    "descriptor": "\nComments: Accepted for IEEE HI-POCT 2022\n",
    "authors": [
      "Vaibhav Joshi",
      "Sricharan Vijayarangan",
      "Preejith SP",
      "Mohanasankar Sivaprakasam"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07252"
  },
  {
    "id": "arXiv:2112.07254",
    "title": "Improving Hybrid CTC/Attention End-to-end Speech Recognition with  Pretrained Acoustic and Language Model",
    "abstract": "Recently, self-supervised pretraining has achieved impressive results in\nend-to-end (E2E) automatic speech recognition (ASR). However, the dominant\nsequence-to-sequence (S2S) E2E model is still hard to fully utilize the\nself-supervised pre-training methods because its decoder is conditioned on\nacoustic representation thus cannot be pretrained separately. In this paper, we\npropose a pretrained Transformer (Preformer) S2S ASR architecture based on\nhybrid CTC/attention E2E models to fully utilize the pretrained acoustic models\n(AMs) and language models (LMs). In our framework, the encoder is initialized\nwith a pretrained AM (wav2vec2.0). The Preformer leverages CTC as an auxiliary\ntask during training and inference. Furthermore, we design a one-cross decoder\n(OCD), which relaxes the dependence on acoustic representations so that it can\nbe initialized with pretrained LM (DistilGPT2). Experiments are conducted on\nthe AISHELL-1 corpus and achieve a $4.6\\%$ character error rate (CER) on the\ntest set. Compared with our vanilla hybrid CTC/attention Transformer baseline,\nour proposed CTC/attention-based Preformer yields $27\\%$ relative CER\nreduction. To the best of our knowledge, this is the first work to utilize both\npretrained AM and LM in a S2S ASR system.",
    "descriptor": "\nComments: ASRU2021\n",
    "authors": [
      "Keqi Deng",
      "Songjun Cao",
      "Yike Zhang",
      "Long Ma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.07254"
  },
  {
    "id": "arXiv:2112.07262",
    "title": "Inductive Semi-supervised Learning Through Optimal Transport",
    "abstract": "In this paper, we tackle the inductive semi-supervised learning problem that\naims to obtain label predictions for out-of-sample data. The proposed approach,\ncalled Optimal Transport Induction (OTI), extends efficiently an optimal\ntransport based transductive algorithm (OTP) to inductive tasks for both binary\nand multi-class settings. A series of experiments are conducted on several\ndatasets in order to compare the proposed approach with state-of-the-art\nmethods. Experiments demonstrate the effectiveness of our approach. We make our\ncode publicly available (Code is available at:\nhttps://github.com/MouradElHamri/OTI).",
    "descriptor": "",
    "authors": [
      "Mourad El Hamri",
      "Youn\u00e8s Bennani",
      "Issam Falih"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07262"
  },
  {
    "id": "arXiv:2112.07277",
    "title": "Modal equilibrium of a tradable credit scheme with a trip-based MFD and  logit-based decision-making",
    "abstract": "The literature about tradable credit schemes (TCS) as a demand management\nsystem alleviating congestion flourished in the past decade. Most proposed\nformulations are based on static models and thus do not account for the\ncongestion dynamics. This paper considers elastic demand and implements a TCS\nto foster modal shift by restricting the number of cars allowed in the network\nover the day. A trip-based Macroscopic Fundamental Diagram (MFD) model\nrepresents the traffic dynamics at the whole urban scale. We assume the users\nhave different OD pairs and choose between driving their car or riding the\ntransit following a logit model. We aim to compute the modal shares and credit\nprice at equilibrium under TCS. The travel times are linearized with respect to\nthe modal shares to improve the convergence. We then present a method to find\nthe credit charge minimizing the total travel time alone or combined with the\ncarbon emission. The proposed methodology is illustrated with a typical demand\nprofile from 7:00 to 10:00 for Lyon Metropolis. We show that traffic dynamics\nand trip heterogeneity matter when deriving the modal equilibrium under a TCS.\nA method is described to compute the linearization of the travel times and\ncompared against a classical descend method (MSA). The proposed linearization\nis a promising tool to circumvent the complexity of the implicit formulation of\nthe trip-based MFD. Under an optimized TCS, the total travel time decreases by\n17% and the carbon emission by 45% by increasing the PT share by 24 points.",
    "descriptor": "\nComments: Submitted to TR Part C\n",
    "authors": [
      "Louis Balzer",
      "Ludovic Leclercq"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07277"
  },
  {
    "id": "arXiv:2112.07297",
    "title": "Parameterized codes over graphs",
    "abstract": "In this article we review known results on parameterized linear codes over\ngraphs, introduced by Renter\\'ia, Simis and Villarreal in 2011. Very little is\nknown about their basic parameters and invariants. We review in detail the\nparameters dimension, regularity and minimum distance. As regards the parameter\ndimension, we explore the connection to Eulerian ideals in the ternary case and\nwe give new combinatorial formulas.",
    "descriptor": "",
    "authors": [
      "Jorge Neves",
      "Maria Vaz Pinto"
    ],
    "subjectives": [
      "Commutative Algebra (math.AC)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.07297"
  },
  {
    "id": "arXiv:2112.07400",
    "title": "Robustifying automatic speech recognition by extracting slowly varying  features",
    "abstract": "In the past few years, it has been shown that deep learning systems are\nhighly vulnerable under attacks with adversarial examples. Neural-network-based\nautomatic speech recognition (ASR) systems are no exception. Targeted and\nuntargeted attacks can modify an audio input signal in such a way that humans\nstill recognise the same words, while ASR systems are steered to predict a\ndifferent transcription. In this paper, we propose a defense mechanism against\ntargeted adversarial attacks consisting in removing fast-changing features from\nthe audio signals, either by applying slow feature analysis, a low-pass filter,\nor both, before feeding the input to the ASR system. We perform an empirical\nanalysis of hybrid ASR models trained on data pre-processed in such a way.\nWhile the resulting models perform quite well on benign data, they are\nsignificantly more robust against targeted adversarial attacks: Our final,\nproposed model shows a performance on clean data similar to the baseline model,\nwhile being more than four times more robust.",
    "descriptor": "",
    "authors": [
      "Matias Pizarro",
      "Dorothea Kolossa",
      "Asja Fischer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.07400"
  },
  {
    "id": "arXiv:2112.07415",
    "title": "Stochastic Planner-Actor-Critic for Unsupervised Deformable Image  Registration",
    "abstract": "Large deformations of organs, caused by diverse shapes and nonlinear shape\nchanges, pose a significant challenge for medical image registration.\nTraditional registration methods need to iteratively optimize an objective\nfunction via a specific deformation model along with meticulous parameter\ntuning, but which have limited capabilities in registering images with large\ndeformations. While deep learning-based methods can learn the complex mapping\nfrom input images to their respective deformation field, it is regression-based\nand is prone to be stuck at local minima, particularly when large deformations\nare involved. To this end, we present Stochastic Planner-Actor-Critic (SPAC), a\nnovel reinforcement learning-based framework that performs step-wise\nregistration. The key notion is warping a moving image successively by each\ntime step to finally align to a fixed image. Considering that it is challenging\nto handle high dimensional continuous action and state spaces in the\nconventional reinforcement learning (RL) framework, we introduce a new concept\n`Plan' to the standard Actor-Critic model, which is of low dimension and can\nfacilitate the actor to generate a tractable high dimensional action. The\nentire framework is based on unsupervised training and operates in an\nend-to-end manner. We evaluate our method on several 2D and 3D medical image\ndatasets, some of which contain large deformations. Our empirical results\nhighlight that our work achieves consistent, significant gains and outperforms\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted by AAAI'22\n",
    "authors": [
      "Ziwei Luo",
      "Jing Hu",
      "Xin Wang",
      "Shu Hu",
      "Bin Kong",
      "Youbing Yin",
      "Qi Song",
      "Xi Wu",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07415"
  },
  {
    "id": "arXiv:2112.07457",
    "title": "Triangulation candidates for Bayesian optimization",
    "abstract": "Bayesian optimization is a form of sequential design: idealize input-output\nrelationships with a suitably flexible nonlinear regression model; fit to data\nfrom an initial experimental campaign; devise and optimize a criterion for\nselecting the next experimental condition(s) under the fitted model (e.g., via\npredictive equations) to target outcomes of interest (say minima); repeat after\nacquiring output under those conditions and updating the fit. In many\nsituations this \"inner optimization\" over the new-data acquisition criterion is\ncumbersome because it is non-convex/highly multi-modal, may be\nnon-differentiable, or may otherwise thwart numerical optimizers, especially\nwhen inference requires Monte Carlo. In such cases it is not uncommon to\nreplace continuous search with a discrete one over random candidates. Here we\npropose using candidates based on a Delaunay triangulation of the existing\ninput design. In addition to detailing construction of these \"tricands\", based\non a simple wrapper around a conventional convex hull library, we promote\nseveral advantages based on properties of the geometric criterion involved. We\nthen demonstrate empirically how tricands can lead to better Bayesian\noptimization performance compared to both numerically optimized acquisitions\nand random candidate-based alternatives on benchmark problems.",
    "descriptor": "\nComments: 19 pages, 9 figures\n",
    "authors": [
      "Robert B. Gramacy",
      "Annie Sauer",
      "Nathan Wycoff"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.07457"
  },
  {
    "id": "arXiv:2112.07464",
    "title": "Efficient differentiable quadratic programming layers: an ADMM approach",
    "abstract": "Recent advances in neural-network architecture allow for seamless integration\nof convex optimization problems as differentiable layers in an end-to-end\ntrainable neural network. Integrating medium and large scale quadratic programs\ninto a deep neural network architecture, however, is challenging as solving\nquadratic programs exactly by interior-point methods has worst-case cubic\ncomplexity in the number of variables. In this paper, we present an alternative\nnetwork layer architecture based on the alternating direction method of\nmultipliers (ADMM) that is capable of scaling to problems with a moderately\nlarge number of variables. Backward differentiation is performed by implicit\ndifferentiation of the residual map of a modified fixed-point iteration.\nSimulated results demonstrate the computational advantage of the ADMM layer,\nwhich for medium scaled problems is approximately an order of magnitude faster\nthan the OptNet quadratic programming layer. Furthermore, our novel\nbackward-pass routine is efficient, from both a memory and computation\nstandpoint, in comparison to the standard approach based on unrolled\ndifferentiation or implicit differentiation of the KKT optimality conditions.\nWe conclude with examples from portfolio optimization in the integrated\nprediction and optimization paradigm.",
    "descriptor": "",
    "authors": [
      "Andrew Butler",
      "Roy Kwon"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Portfolio Management (q-fin.PM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.07464"
  },
  {
    "id": "arXiv:2112.07488",
    "title": "Imaginary Zeroth-Order Optimization",
    "abstract": "Zeroth-order optimization methods are developed to overcome the practical\nhurdle of having knowledge of explicit derivatives. Instead, these schemes work\nwith merely access to noisy functions evaluations. The predominant approach is\nto mimic first-order methods by means of some gradient estimator. The\ntheoretical limitations are well-understood, yet, as most of these methods rely\non finite-differencing for shrinking differences, numerical cancellation can be\ncatastrophic. The numerical community developed an efficient method to overcome\nthis by passing to the complex domain. This approach has been recently adopted\nby the optimization community and in this work we analyze the practically\nrelevant setting of dealing with computational noise. To exemplify the\npossibilities we focus on the strongly-convex optimization setting and provide\na variety of non-asymptotic results, corroborated by numerical experiments, and\nend with local non-convex optimization.",
    "descriptor": "\nComments: 33 pages, 14 figures\n",
    "authors": [
      "Wouter Jongeneel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07488"
  },
  {
    "id": "arXiv:2112.07503",
    "title": "The Game of Cops and Robber on (Claw, Even-hole)-free Graphs",
    "abstract": "In this paper, we study the game of cops and robber on the class of graphs\nwith no even hole (induced cycle of even length) and claw (a star with three\nleaves). The cop number of a graph $G$ is defined as the minimum number of cops\nneeded to capture the robber. Here, we prove that the cop number of all\nclaw-free even-hole-free graphs is at most two and, in addition, the capture\ntime is at most $2n$ rounds, where $n$ is the number of vertices of the graph.\nMoreover, our results can be viewed as a first step towards studying the\nstructure of claw-free even-hole-free graphs.",
    "descriptor": "",
    "authors": [
      "Ramin Javadi",
      "Ali Momeni"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.07503"
  },
  {
    "id": "arXiv:2112.07529",
    "title": "Improving COVID-19 CXR Detection with Synthetic Data Augmentation",
    "abstract": "Since the beginning of the COVID-19 pandemic, researchers have developed deep\nlearning models to classify COVID-19 induced pneumonia. As with many medical\nimaging tasks, the quality and quantity of the available data is often limited.\nIn this work we train a deep learning model on publicly available COVID-19\nimage data and evaluate the model on local hospital chest X-ray data. The data\nhas been reviewed and labeled by two radiologists to ensure a high quality\nestimation of the generalization capabilities of the model. Furthermore, we are\nusing a Generative Adversarial Network to generate synthetic X-ray images based\non this data. Our results show that using those synthetic images for data\naugmentation can improve the model's performance significantly. This can be a\npromising approach for many sparse data domains.",
    "descriptor": "\nComments: This paper has been accepted at the Upper-Rhine Artificial Intelligence Symposium 2021 arXiv:2112.05657\n",
    "authors": [
      "Daniel Schaudt",
      "Christopher Kloth",
      "Christian Spaete",
      "Andreas Hinteregger",
      "Meinrad Beer",
      "Reinhold von Schwerin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07529"
  },
  {
    "id": "arXiv:2112.07555",
    "title": "Classification of histopathology images using ConvNets to detect Lupus  Nephritis",
    "abstract": "Systemic lupus erythematosus (SLE) is an autoimmune disease in which the\nimmune system of the patient starts attacking healthy tissues of the body.\nLupus Nephritis (LN) refers to the inflammation of kidney tissues resulting in\nrenal failure due to these attacks. The International Society of\nNephrology/Renal Pathology Society (ISN/RPS) has released a classification\nsystem based on various patterns observed during renal injury in SLE.\nTraditional methods require meticulous pathological assessment of the renal\nbiopsy and are time-consuming. Recently, computational techniques have helped\nto alleviate this issue by using virtual microscopy or Whole Slide Imaging\n(WSI). With the use of deep learning and modern computer vision techniques, we\npropose a pipeline that is able to automate the process of 1) detection of\nvarious glomeruli patterns present in these whole slide images and 2)\nclassification of each image using the extracted glomeruli features.",
    "descriptor": "\nComments: Accepted in the 2021 Medical Imaging meets NeurIPS Workshop\n",
    "authors": [
      "Akash Gupta",
      "Anirudh Reddy",
      "CV Jawahar",
      "PK Vinod"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2112.07555"
  },
  {
    "id": "arXiv:2112.07564",
    "title": "Linear Quadratic Control with Risk Constraints",
    "abstract": "We propose a new risk-constrained formulation of the classical Linear\nQuadratic (LQ) stochastic control problem for general partially-observed\nsystems. Our framework is motivated by the fact that the risk-neutral LQ\ncontrollers, although optimal in expectation, might be ineffective under\nrelatively infrequent, yet statistically significant extreme events. To\neffectively trade between average and extreme event performance, we introduce a\nnew risk constraint, which explicitly restricts the total expected predictive\nvariance of the state penalty by a user-prescribed level. We show that, under\ncertain conditions on the process noise, the optimal risk-aware controller can\nbe evaluated explicitly and in closed form. In fact, it is affine relative to\nthe minimum mean square error (mmse) state estimate. The affine term pushes the\nstate away from directions where the noise exhibits heavy tails, by exploiting\nthe third-order moment~(skewness) of the noise. The linear term regulates the\nstate more strictly in riskier directions, where both the prediction error\n(conditional) covariance and the state penalty are simultaneously large; this\nis achieved by inflating the state penalty within a new filtered Riccati\ndifference equation. We also prove that the new risk-aware controller is\ninternally stable, regardless of parameter tuning, in the special cases of i)\nfully-observed systems, and ii) partially-observed systems with Gaussian noise.\nThe properties of the proposed risk-aware LQ framework are lastly illustrated\nvia indicative numerical examples.",
    "descriptor": "\nComments: 32 pages, under review. arXiv admin note: substantial text overlap with arXiv:2004.04685\n",
    "authors": [
      "Anastasios Tsiamis",
      "Dionysios S. Kalogerias",
      "Alejandro Ribeiro",
      "George J. Pappas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07564"
  },
  {
    "id": "arXiv:2112.07568",
    "title": "Local Output Feedback Stabilization of a Nonlinear Kuramoto-Sivashinsky  equation",
    "abstract": "This paper is concerned with the local output feedback stabilization of a\nnonlinear Kuramoto-Sivashinsky equation. The control is located at the boundary\nof the domain while the measurement is selected as a Neumann trace. This choice\nof system output requires the study of the system trajectories in $H^2$-norm.\nMoreover, the choice of the actuation/sensing scheme is discussed and adapted\nin function of the parameters of the plant in order to avoid the possible loss\nof controllability/observability property of certain eigenvalues of the\nunderlying operator. This leads in certain cases to a multi-input multi-output\ncontrol design procedure. The adopted control strategy is finite dimensional\nand relies on spectral reduction methods. We derive sufficient conditions\nensuring the local exponential stabilization of the plant. These control design\nconstraints are shown to be feasible provided the order of the controller is\nselected to be large enough, ensuring that the reported control design\nprocedure is systematic.",
    "descriptor": "",
    "authors": [
      "Hugo Lhachemi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07568"
  },
  {
    "id": "arXiv:2112.07611",
    "title": "Speeding up Learning Quantum States through Group Equivariant  Convolutional Quantum Ans{\u00e4}tze",
    "abstract": "We develop a theoretical framework for $S_n$-equivariant quantum\nconvolutional circuits, building on and significantly generalizing Jordan's\nPermutational Quantum Computing (PQC) formalism. We show that quantum circuits\nare a natural choice for Fourier space neural architectures affording a\nsuper-exponential speedup in computing the matrix elements of $S_n$-Fourier\ncoefficients compared to the best known classical Fast Fourier Transform (FFT)\nover the symmetric group. In particular, we utilize the Okounkov-Vershik\napproach to prove Harrow's statement (Ph.D. Thesis 2005 p.160) on the\nequivalence between $\\operatorname{SU}(d)$- and $S_n$-irrep bases and to\nestablish the $S_n$-equivariant Convolutional Quantum Alternating Ans{\\\"a}tze\n($S_n$-CQA) using Young-Jucys-Murphy (YJM) elements. We prove that $S_n$-CQA\nare dense, thus expressible within each $S_n$-irrep block, which may serve as a\nuniversal model for potential future quantum machine learning and optimization\napplications. Our method provides another way to prove the universality of\nQuantum Approximate Optimization Algorithm (QAOA), from the\nrepresentation-theoretical point of view. Our framework can be naturally\napplied to a wide array of problems with global $\\operatorname{SU}(d)$\nsymmetry. We present numerical simulations to showcase the effectiveness of the\nans{\\\"a}tze to find the sign structure of the ground state of the $J_1$--$J_2$\nantiferromagnetic Heisenberg model on the rectangular and Kagome lattices. Our\nwork identifies quantum advantage for a specific machine learning problem, and\nprovides the first application of the celebrated Okounkov-Vershik's\nrepresentation theory to machine learning and quantum physics.",
    "descriptor": "\nComments: 16 pages, 12 figures\n",
    "authors": [
      "Han Zheng",
      "Zimu Li",
      "Junyu Liu",
      "Sergii Strelchuk",
      "Risi Kondor"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.07611"
  },
  {
    "id": "arXiv:2112.07627",
    "title": "Visualizing Ensemble Predictions of Music Mood",
    "abstract": "Music mood classification has been a challenging problem in comparison with\nsome other classification problems (e.g., genre, composer, or period). One\nsolution for addressing this challenging is to use an of ensemble machine\nlearning models. In this paper, we show that visualization techniques can\neffectively convey the popular prediction as well as uncertainty at different\nmusic sections along the temporal axis, while enabling the analysis of\nindividual ML models in conjunction with their application to different musical\ndata. In addition to the traditional visual designs, such as stacked line\ngraph, ThemeRiver, and pixel-based visualization, we introduced a new variant\nof ThemeRiver, called \"dual-flux ThemeRiver\", which allows viewers to observe\nand measure the most popular prediction more easily than stacked line graph and\nThemeRiver. Testing indicates that visualizing ensemble predictions is helpful\nboth in model-development workflows and for annotating music using model\npredictions.",
    "descriptor": "\nComments: 10 pages, 7 figures, submitted to EuroVis 2022\n",
    "authors": [
      "Zelin Ye",
      "Min Chen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.07627"
  },
  {
    "id": "arXiv:2112.07632",
    "title": "Homological approximations in persistence theory",
    "abstract": "We define a class of invariants, which we call homological invariants, for\npersistence modules over a finite poset. Informally, a homological invariant is\none that respects some exact structure and takes values in the free abelian\ngroup generated by a finite set of indecomposable modules. We focus in\nparticular on groups generated by \"spread modules\", which are sometimes called\n\"interval modules\" in the persistence theory literature. We show that both the\ndimension vector and rank invariant are equivalent to homological invariants\ntaking values in groups generated by spread modules. We also show that that the\nfree abelian group generated by the \"single-source\" spread modules gives rise\nto a new invariant which is finer than the rank invariant.",
    "descriptor": "\nComments: 16 pages, comments welcome!\n",
    "authors": [
      "Benjamin Blanchette",
      "Thomas Br\u00fcstle",
      "Eric J. Hanson"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2112.07632"
  },
  {
    "id": "arXiv:1606.02433",
    "title": "Training Design and Two-stage Channel Estimation for Correlated Two-way  MIMO Relay Systems",
    "abstract": "Comments: paper needs more revisions",
    "descriptor": "\nComments: paper needs more revisions\n",
    "authors": [
      "Huiming Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1606.02433"
  },
  {
    "id": "arXiv:1606.04022",
    "title": "Joint Channel Estimation and Training Signal Design for Two-way MIMO  Relay Systems",
    "abstract": "Comments: paper needs more revisions",
    "descriptor": "\nComments: paper needs more revisions\n",
    "authors": [
      "Huiming Chen",
      "Xiaohan Zhong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1606.04022"
  },
  {
    "id": "arXiv:1812.08958",
    "title": "Expander Decomposition and Pruning: Faster, Stronger, and Simpler",
    "abstract": "Comments: Added more details and fixed typos in Appendix B about the cut-matching game",
    "descriptor": "\nComments: Added more details and fixed typos in Appendix B about the cut-matching game\n",
    "authors": [
      "Thatchaphol Saranurak",
      "Di Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1812.08958"
  },
  {
    "id": "arXiv:1902.05193",
    "title": "An application of parallel cut elimination in multiplicative linear  logic to the Taylor expansion of proof nets",
    "abstract": "An application of parallel cut elimination in multiplicative linear  logic to the Taylor expansion of proof nets",
    "descriptor": "",
    "authors": [
      "Jules Chouquet",
      "Lionel Vaux Auclair"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1902.05193"
  },
  {
    "id": "arXiv:1904.07668",
    "title": "Unification and combination of a class of traversal strategies made with  pattern matching and fixed-points",
    "abstract": "Comments: 67 pages",
    "descriptor": "\nComments: 67 pages\n",
    "authors": [
      "Walid Belkhir",
      "Nicolas Ratier",
      "Duy Duc Nguyen",
      "Michel Lenczner"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/1904.07668"
  },
  {
    "id": "arXiv:1905.10924",
    "title": "Naive probability",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Zalan Gyenis",
      "Andras Kornai"
    ],
    "subjectives": [
      "History and Overview (math.HO)",
      "Artificial Intelligence (cs.AI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1905.10924"
  },
  {
    "id": "arXiv:1909.06296",
    "title": "Bayesian parameter estimation using conditional variational autoencoders  for gravitational-wave astronomy",
    "abstract": "Comments: 13 pages, 5 figures",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Hunter Gabbard",
      "Chris Messenger",
      "Ik Siong Heng",
      "Francesco Tonolini",
      "Roderick Murray-Smith"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/1909.06296"
  },
  {
    "id": "arXiv:1910.09909",
    "title": "Word-level Embeddings for Cross-Task Transfer Learning in Speech  Processing",
    "abstract": "Comments: Published at EUSIPCO 2021",
    "descriptor": "\nComments: Published at EUSIPCO 2021\n",
    "authors": [
      "Pierre Beckmann",
      "Mikolaj Kegler",
      "Milos Cernak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/1910.09909"
  },
  {
    "id": "arXiv:1911.00569",
    "title": "Mitigating the Effects of Non-Identifiability on Inference for Bayesian  Neural Networks with Latent Variables",
    "abstract": "Comments: Accepted at ICML's Uncertainty and Robustness in Deep Learning Workshop 2019",
    "descriptor": "\nComments: Accepted at ICML's Uncertainty and Robustness in Deep Learning Workshop 2019\n",
    "authors": [
      "Yaniv Yacoby",
      "Weiwei Pan",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.00569"
  },
  {
    "id": "arXiv:1911.06722",
    "title": "Bayesian nonparametric discontinuity design",
    "abstract": "Comments: 15 pages, 6 figures. Parts of this work are published in 'Spectral discontinuity design: Interrupted time series with spectral mixture kernels' in the Machine Learning for Health workshop at NeurIPS 2020",
    "descriptor": "\nComments: 15 pages, 6 figures. Parts of this work are published in 'Spectral discontinuity design: Interrupted time series with spectral mixture kernels' in the Machine Learning for Health workshop at NeurIPS 2020\n",
    "authors": [
      "Max Hinne",
      "David Leeftink",
      "Marcel A.J. van Gerven",
      "Luca Ambrogioni"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.06722"
  },
  {
    "id": "arXiv:1912.05601",
    "title": "Is Sized Typing for Coq Practical?",
    "abstract": "Comments: 55 pages with 22 figures and 3 tables. Submitted to the Journal of Functional Programming. For associated artifact, see this https URL",
    "descriptor": "\nComments: 55 pages with 22 figures and 3 tables. Submitted to the Journal of Functional Programming. For associated artifact, see this https URL\n",
    "authors": [
      "Jonathan Chan",
      "Yufeng Li",
      "William J. Bowman"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/1912.05601"
  },
  {
    "id": "arXiv:2004.06493",
    "title": "Solving Newton's Equations of Motion with Large Timesteps using  Recurrent Neural Networks based Operators",
    "abstract": "Comments: 15 pages, 12 figures; updated content",
    "descriptor": "\nComments: 15 pages, 12 figures; updated content\n",
    "authors": [
      "JCS Kadupitiya",
      "Geoffrey C. Fox",
      "Vikram Jadhao"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.06493"
  },
  {
    "id": "arXiv:2004.07543",
    "title": "Classify and Generate: Using Classification Latent Space Representations  for Image Generations",
    "abstract": "Classify and Generate: Using Classification Latent Space Representations  for Image Generations",
    "descriptor": "",
    "authors": [
      "Saisubramaniam Gopalakrishnan",
      "Pranshu Ranjan Singh",
      "Yasin Yazici",
      "Chuan-Sheng Foo",
      "Vijay Chandrasekhar",
      "ArulMurugan Ambikapathi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.07543"
  },
  {
    "id": "arXiv:2004.11498",
    "title": "Mining self-similarity: Label super-resolution with epitomic  representations",
    "abstract": "Comments: ECCV 2020 final version",
    "descriptor": "\nComments: ECCV 2020 final version\n",
    "authors": [
      "Nikolay Malkin",
      "Anthony Ortiz",
      "Caleb Robinson",
      "Nebojsa Jojic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2004.11498"
  },
  {
    "id": "arXiv:2005.10379",
    "title": "Hierarchical Isometry Properties of Hierarchical Measurements",
    "abstract": "Comments: 22 pages, 5 figures. v3: Significant rework of previous version. Section on incoherent blocks added, as well as more numerical experiments. v4: Revision of the manuscript. Several previous mistakes have been corrected",
    "descriptor": "\nComments: 22 pages, 5 figures. v3: Significant rework of previous version. Section on incoherent blocks added, as well as more numerical experiments. v4: Revision of the manuscript. Several previous mistakes have been corrected\n",
    "authors": [
      "Axel Flinth",
      "Benedikt Gro\u00df",
      "Ingo Roth",
      "Jens Eisert",
      "Gerhard Wunder"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2005.10379"
  },
  {
    "id": "arXiv:2005.10711",
    "title": "Sequential Fundraising and Mutual Insurance",
    "abstract": "Sequential Fundraising and Mutual Insurance",
    "descriptor": "",
    "authors": [
      "Amir Ban",
      "Moran Koren"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2005.10711"
  },
  {
    "id": "arXiv:2005.12386",
    "title": "Customized Graph Neural Networks",
    "abstract": "Customized Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Yiqi Wang",
      "Yao Ma",
      "Wei Jin",
      "Chaozhuo Li",
      "Charu Aggarwal",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.12386"
  },
  {
    "id": "arXiv:2006.02708",
    "title": "Auto-Rectify Network for Unsupervised Indoor Depth Estimation",
    "abstract": "Comments: Accepted to TPAMI. Find code at this https URL",
    "descriptor": "\nComments: Accepted to TPAMI. Find code at this https URL\n",
    "authors": [
      "Jia-Wang Bian",
      "Huangying Zhan",
      "Naiyan Wang",
      "Tat-Jun Chin",
      "Chunhua Shen",
      "Ian Reid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2006.02708"
  },
  {
    "id": "arXiv:2006.04399",
    "title": "Completeness Theorems for First-Order Logic Analysed in Constructive  Type Theory (Extended Version)",
    "abstract": "Comments: extended version of this https URL",
    "descriptor": "\nComments: extended version of this https URL\n",
    "authors": [
      "Yannick Forster",
      "Dominik Kirst",
      "Dominik Wehr"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2006.04399"
  },
  {
    "id": "arXiv:2006.10175",
    "title": "An Empirical Comparison of GANs and Normalizing Flows for Density  Estimation",
    "abstract": "Comments: Accepted by the NeurIPS 2021 Bayesian Deep Learning workshop",
    "descriptor": "\nComments: Accepted by the NeurIPS 2021 Bayesian Deep Learning workshop\n",
    "authors": [
      "Tianci Liu",
      "Jeffrey Regier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10175"
  },
  {
    "id": "arXiv:2006.12465",
    "title": "Expressive Logics for Coinductive Predicates",
    "abstract": "Expressive Logics for Coinductive Predicates",
    "descriptor": "",
    "authors": [
      "Clemens Kupke",
      "Jurriaan Rot"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2006.12465"
  },
  {
    "id": "arXiv:2006.16375",
    "title": "Improving Calibration through the Relationship with Adversarial  Robustness",
    "abstract": "Comments: Published at NeurIPS-2021",
    "descriptor": "\nComments: Published at NeurIPS-2021\n",
    "authors": [
      "Yao Qin",
      "Xuezhi Wang",
      "Alex Beutel",
      "Ed H. Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.16375"
  },
  {
    "id": "arXiv:2007.02413",
    "title": "Elimination distance to bounded degree on planar graphs",
    "abstract": "Elimination distance to bounded degree on planar graphs",
    "descriptor": "",
    "authors": [
      "Alexander Lindermayr",
      "Sebastian Siebertz",
      "Alexandre Vigny"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2007.02413"
  },
  {
    "id": "arXiv:2007.03797",
    "title": "Personalized Cross-Silo Federated Learning on Non-IID Data",
    "abstract": "Comments: Accepted by AAAI 2021. The API of this work is available at Huawei Cloud (this https URL), free registration is required before use",
    "descriptor": "\nComments: Accepted by AAAI 2021. The API of this work is available at Huawei Cloud (this https URL), free registration is required before use\n",
    "authors": [
      "Yutao Huang",
      "Lingyang Chu",
      "Zirui Zhou",
      "Lanjun Wang",
      "Jiangchuan Liu",
      "Jian Pei",
      "Yong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.03797"
  },
  {
    "id": "arXiv:2007.08031",
    "title": "Optimal Coresets for Gaussian Kernel Density Estimates",
    "abstract": "Optimal Coresets for Gaussian Kernel Density Estimates",
    "descriptor": "",
    "authors": [
      "Wai Ming Tai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.08031"
  },
  {
    "id": "arXiv:2007.10675",
    "title": "Trade-off on Sim2Real Learning: Real-world Learning Faster than  Simulations",
    "abstract": "Comments: To be published in 2022 8th International Conference on Control, Automation and Robotics (ICCAR)",
    "descriptor": "\nComments: To be published in 2022 8th International Conference on Control, Automation and Robotics (ICCAR)\n",
    "authors": [
      "Jingyi Huang",
      "Fabio Giardina",
      "Andre Rosendo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.10675"
  },
  {
    "id": "arXiv:2007.12284",
    "title": "Energy-aware Relay Positioning in Flying Networks",
    "abstract": "Energy-aware Relay Positioning in Flying Networks",
    "descriptor": "",
    "authors": [
      "Hugo Rodrigues",
      "Andr\u00e9 Coelho",
      "Manuel Ricardo",
      "Rui Campos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2007.12284"
  },
  {
    "id": "arXiv:2009.05244",
    "title": "Defending Against Multiple and Unforeseen Adversarial Videos",
    "abstract": "Comments: Accepted in IEEE Transactions on Image Processing (TIP)",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Image Processing (TIP)\n",
    "authors": [
      "Shao-Yuan Lo",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.05244"
  },
  {
    "id": "arXiv:2010.01264",
    "title": "HeteroFL: Computation and Communication Efficient Federated Learning for  Heterogeneous Clients",
    "abstract": "Comments: ICLR 2021",
    "descriptor": "\nComments: ICLR 2021\n",
    "authors": [
      "Enmao Diao",
      "Jie Ding",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.01264"
  },
  {
    "id": "arXiv:2010.07047",
    "title": "A Predictive Visual Analytics System for Studying Neurodegenerative  Disease based on DTI Fiber Tracts",
    "abstract": "A Predictive Visual Analytics System for Studying Neurodegenerative  Disease based on DTI Fiber Tracts",
    "descriptor": "",
    "authors": [
      "Chaoqing Xu",
      "Tyson Neuroth",
      "Takanori Fujiwara",
      "Ronghua Liang",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2010.07047"
  },
  {
    "id": "arXiv:2010.16010",
    "title": "Loss re-scaling VQA: Revisiting the LanguagePrior Problem from a  Class-imbalance View",
    "abstract": "Loss re-scaling VQA: Revisiting the LanguagePrior Problem from a  Class-imbalance View",
    "descriptor": "",
    "authors": [
      "Yangyang Guo",
      "Liqiang Nie",
      "Zhiyong Cheng",
      "Qi Tian",
      "Min Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.16010"
  },
  {
    "id": "arXiv:2010.16310",
    "title": "Multiscale Fractal Analysis on EEG Signals for Music-Induced Emotion  Recognition",
    "abstract": "Comments: 5 pages, 3 figures, 3 tables, European Signal Processing Conference (EUSIPCO) 2021, Dublin, Ireland",
    "descriptor": "\nComments: 5 pages, 3 figures, 3 tables, European Signal Processing Conference (EUSIPCO) 2021, Dublin, Ireland\n",
    "authors": [
      "Kleanthis Avramidis",
      "Athanasia Zlatintsi",
      "Christos Garoufis",
      "Petros Maragos"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.16310"
  },
  {
    "id": "arXiv:2011.08772",
    "title": "KddRES: A Multi-level Knowledge-driven Dialogue Dataset for Restaurant  Towards Customized Dialogue System",
    "abstract": "Comments: 8 pages,2 figures",
    "descriptor": "\nComments: 8 pages,2 figures\n",
    "authors": [
      "Hongru Wang",
      "Min Li",
      "Zimo Zhou",
      "Gabriel Pui Cheong Fung",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.08772"
  },
  {
    "id": "arXiv:2011.09464",
    "title": "Counterfactual Credit Assignment in Model-Free Reinforcement Learning",
    "abstract": "Counterfactual Credit Assignment in Model-Free Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Thomas Mesnard",
      "Th\u00e9ophane Weber",
      "Fabio Viola",
      "Shantanu Thakoor",
      "Alaa Saade",
      "Anna Harutyunyan",
      "Will Dabney",
      "Tom Stepleton",
      "Nicolas Heess",
      "Arthur Guez",
      "\u00c9ric Moulines",
      "Marcus Hutter",
      "Lars Buesing",
      "R\u00e9mi Munos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.09464"
  },
  {
    "id": "arXiv:2011.12090",
    "title": "AI Discovering a Coordinate System of Chemical Elements: Dual  Representation by Variational Autoencoders",
    "abstract": "Comments: 18 pages, 15 figures, 5 tables",
    "descriptor": "\nComments: 18 pages, 15 figures, 5 tables\n",
    "authors": [
      "Alex Glushkovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2011.12090"
  },
  {
    "id": "arXiv:2012.01918",
    "title": "Multi-mode Core Tensor Factorization based Low-Rankness and Its  Applications to Tensor Completion",
    "abstract": "Multi-mode Core Tensor Factorization based Low-Rankness and Its  Applications to Tensor Completion",
    "descriptor": "",
    "authors": [
      "Haijin Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.01918"
  },
  {
    "id": "arXiv:2012.01986",
    "title": "An Improved Iterative Neural Network for High-Quality Image-Domain  Material Decomposition in Dual-Energy CT",
    "abstract": "An Improved Iterative Neural Network for High-Quality Image-Domain  Material Decomposition in Dual-Energy CT",
    "descriptor": "",
    "authors": [
      "Zhipeng Li",
      "Yong Long",
      "Il Yong Chun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.01986"
  },
  {
    "id": "arXiv:2012.06168",
    "title": "OpenHoldem: A Benchmark for Large-Scale Imperfect-Information Game  Research",
    "abstract": "OpenHoldem: A Benchmark for Large-Scale Imperfect-Information Game  Research",
    "descriptor": "",
    "authors": [
      "Kai Li",
      "Hang Xu",
      "Enmin Zhao",
      "Zhe Wu",
      "Junliang Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2012.06168"
  },
  {
    "id": "arXiv:2012.06441",
    "title": "Approach to the cellular automaton interpretation using deep learning",
    "abstract": "Comments: 12 pages, 7 figures",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Hyun Ju Go"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2012.06441"
  },
  {
    "id": "arXiv:2012.09830",
    "title": "Autotelic Agents with Intrinsically Motivated Goal-Conditioned  Reinforcement Learning: a Short Survey",
    "abstract": "Autotelic Agents with Intrinsically Motivated Goal-Conditioned  Reinforcement Learning: a Short Survey",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Colas",
      "Tristan Karch",
      "Olivier Sigaud",
      "Pierre-Yves Oudeyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.09830"
  },
  {
    "id": "arXiv:2101.08169",
    "title": "mt5se: An Open Source Framework for Building Autonomous Traders",
    "abstract": "Comments: This paper replaces an old version of the framework, called mt5b3, which is now deprecated",
    "descriptor": "\nComments: This paper replaces an old version of the framework, called mt5b3, which is now deprecated\n",
    "authors": [
      "Paulo Andr\u00e9 Lima de Castro"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.08169"
  },
  {
    "id": "arXiv:2101.08607",
    "title": "Path Loss Modeling and Measurements for Reconfigurable Intelligent  Surfaces in the Millimeter-Wave Frequency Band",
    "abstract": "Comments: Model refinements are introduced to previously proposed free-space path loss model for RISs in order to make it simpler and easier to use. The properties of a single unit cell are evaluated in terms of scattering performance, power, and area, as it is the basic element of an RIS. We report the world's first measurement campaign in the mmWave frequency band to validate the path loss model for RISs",
    "descriptor": "\nComments: Model refinements are introduced to previously proposed free-space path loss model for RISs in order to make it simpler and easier to use. The properties of a single unit cell are evaluated in terms of scattering performance, power, and area, as it is the basic element of an RIS. We report the world's first measurement campaign in the mmWave frequency band to validate the path loss model for RISs\n",
    "authors": [
      "Wankai Tang",
      "Xiangyu Chen",
      "Ming Zheng Chen",
      "Jun Yan Dai",
      "Yu Han",
      "Marco Di Renzo",
      "Shi Jin",
      "Qiang Cheng",
      "Tie Jun Cui"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.08607"
  },
  {
    "id": "arXiv:2102.08127",
    "title": "Learning curves of generic features maps for realistic datasets with a  teacher-student model",
    "abstract": "Comments: v3: NeurIPS camera-ready",
    "descriptor": "\nComments: v3: NeurIPS camera-ready\n",
    "authors": [
      "Bruno Loureiro",
      "C\u00e9dric Gerbelot",
      "Hugo Cui",
      "Sebastian Goldt",
      "Florent Krzakala",
      "Marc M\u00e9zard",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2102.08127"
  },
  {
    "id": "arXiv:2102.10283",
    "title": "Imitation Learning for Variable Speed Contact Motion for Operation up to  Control Bandwidth",
    "abstract": "Comments: 12 pages, 20 figures, submitted for IEEE Open Journal of the Industrial Electronics Society",
    "descriptor": "\nComments: 12 pages, 20 figures, submitted for IEEE Open Journal of the Industrial Electronics Society\n",
    "authors": [
      "Sho Sakaino",
      "Kazuki Fujimoto",
      "Yuki Saigusa",
      "Toshiaki Tsuji"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.10283"
  },
  {
    "id": "arXiv:2103.03864",
    "title": "Learning to Extend Molecular Scaffolds with Structural Motifs",
    "abstract": "Learning to Extend Molecular Scaffolds with Structural Motifs",
    "descriptor": "",
    "authors": [
      "Krzysztof Maziarz",
      "Henry Jackson-Flux",
      "Pashmina Cameron",
      "Finton Sirockin",
      "Nadine Schneider",
      "Nikolaus Stiefl",
      "Marwin Segler",
      "Marc Brockschmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2103.03864"
  },
  {
    "id": "arXiv:2103.10621",
    "title": "Degrade is Upgrade: Learning Degradation for Low-light Image Enhancement",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Kui Jiang",
      "Zhongyuan Wang",
      "Zheng Wang",
      "Chen Chen",
      "Peng Yi",
      "Tao Lu",
      "Chia-Wen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.10621"
  },
  {
    "id": "arXiv:2103.11399",
    "title": "Learning Calibrated-Guidance for Object Detection in Aerial Images",
    "abstract": "Learning Calibrated-Guidance for Object Detection in Aerial Images",
    "descriptor": "",
    "authors": [
      "Zongqi Wei",
      "Dong Liang",
      "Dong Zhang",
      "Qixiang Geng",
      "Liyan Zhang",
      "Han Sun",
      "Huiyu Zhou",
      "Mingqiang Wei",
      "Pan Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11399"
  },
  {
    "id": "arXiv:2103.12248",
    "title": "Multi-Modal Answer Validation for Knowledge-Based VQA",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Jialin Wu",
      "Jiasen Lu",
      "Ashish Sabharwal",
      "Roozbeh Mottaghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.12248"
  },
  {
    "id": "arXiv:2104.02677",
    "title": "Time-Robust Control for STL Specifications",
    "abstract": "Comments: Submitted to the Conference on Decision and Control 2021",
    "descriptor": "\nComments: Submitted to the Conference on Decision and Control 2021\n",
    "authors": [
      "Alena Rodionova",
      "Lars Lindemann",
      "Manfred Morari",
      "George J. Pappas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.02677"
  },
  {
    "id": "arXiv:2104.03690",
    "title": "Determinisability of register and timed automata",
    "abstract": "Comments: journal version of a CONCUR'20 paper. arXiv admin note: substantial text overlap with arXiv:2007.09340",
    "descriptor": "\nComments: journal version of a CONCUR'20 paper. arXiv admin note: substantial text overlap with arXiv:2007.09340\n",
    "authors": [
      "Lorenzo Clemente",
      "S\u0142awomir Lasota",
      "Rados\u0142aw Pi\u00f3rkowski"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2104.03690"
  },
  {
    "id": "arXiv:2104.05240",
    "title": "Factual Probing Is [MASK]: Learning vs. Learning to Recall",
    "abstract": "Comments: NAACL 2021. The code is publicly available at this https URL",
    "descriptor": "\nComments: NAACL 2021. The code is publicly available at this https URL\n",
    "authors": [
      "Zexuan Zhong",
      "Dan Friedman",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.05240"
  },
  {
    "id": "arXiv:2104.07175",
    "title": "Community-Based Fact-Checking on Twitter's Birdwatch Platform",
    "abstract": "Community-Based Fact-Checking on Twitter's Birdwatch Platform",
    "descriptor": "",
    "authors": [
      "Nicolas Pr\u00f6llochs"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2104.07175"
  },
  {
    "id": "arXiv:2104.08142",
    "title": "Supervising Model Attention with Human Explanations for Robust Natural  Language Inference",
    "abstract": "Comments: Accepted at AAAI 2022",
    "descriptor": "\nComments: Accepted at AAAI 2022\n",
    "authors": [
      "Joe Stacey",
      "Yonatan Belinkov",
      "Marek Rei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08142"
  },
  {
    "id": "arXiv:2104.08669",
    "title": "Fifty Three Matrix Factorizations: A systematic approach",
    "abstract": "Comments: 73 pages",
    "descriptor": "\nComments: 73 pages\n",
    "authors": [
      "Alan Edelman",
      "Sungwoo Jeong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.08669"
  },
  {
    "id": "arXiv:2104.09856",
    "title": "Permutation-Invariant Variational Autoencoder for Graph-Level  Representation Learning",
    "abstract": "Permutation-Invariant Variational Autoencoder for Graph-Level  Representation Learning",
    "descriptor": "",
    "authors": [
      "Robin Winter",
      "Frank No\u00e9",
      "Djork-Arn\u00e9 Clevert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09856"
  },
  {
    "id": "arXiv:2104.10939",
    "title": "HINT: A Hierarchical Index for Intervals in Main Memory",
    "abstract": "HINT: A Hierarchical Index for Intervals in Main Memory",
    "descriptor": "",
    "authors": [
      "George Christodoulou",
      "Panagiotis Bouros",
      "Nikos Mamoulis"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.10939"
  },
  {
    "id": "arXiv:2104.12114",
    "title": "Open Intent Discovery through Unsupervised Semantic Clustering and  Dependency Parsing",
    "abstract": "Comments: Published in IEEE CogInfoCom-2021",
    "descriptor": "\nComments: Published in IEEE CogInfoCom-2021\n",
    "authors": [
      "Pengfei Liu",
      "Youzhang Ning",
      "King Keung Wu",
      "Kun Li",
      "Helen Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.12114"
  },
  {
    "id": "arXiv:2104.14781",
    "title": "Out-of-Scope Domain and Intent Classification through Hierarchical Joint  Modeling",
    "abstract": "Comments: Published in the 12th International Workshop on Spoken Dialog System Technology (IWSDS),2021",
    "descriptor": "\nComments: Published in the 12th International Workshop on Spoken Dialog System Technology (IWSDS),2021\n",
    "authors": [
      "Pengfei Liu",
      "Kun Li",
      "Helen Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.14781"
  },
  {
    "id": "arXiv:2105.00642",
    "title": "One Model to Rule them All: Towards Zero-Shot Learning for Databases",
    "abstract": "One Model to Rule them All: Towards Zero-Shot Learning for Databases",
    "descriptor": "",
    "authors": [
      "Benjamin Hilprecht",
      "Carsten Binnig"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.00642"
  },
  {
    "id": "arXiv:2105.04385",
    "title": "Identifying Overly Restrictive Matching Patterns in SMT-based Program  Verifiers (extended version)",
    "abstract": "Identifying Overly Restrictive Matching Patterns in SMT-based Program  Verifiers (extended version)",
    "descriptor": "",
    "authors": [
      "Alexandra Bugariu",
      "Arshavir Ter-Gabrielyan",
      "Peter M\u00fcller"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.04385"
  },
  {
    "id": "arXiv:2105.04909",
    "title": "Accountability and Reconfiguration: Self-Healing Lattice Agreement",
    "abstract": "Accountability and Reconfiguration: Self-Healing Lattice Agreement",
    "descriptor": "",
    "authors": [
      "Luciano Freitas de Souza",
      "Petr Kuznetsov",
      "Thibault Rieutord",
      "Sara Tucci-Piergiovanni"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.04909"
  },
  {
    "id": "arXiv:2105.05903",
    "title": "Finite-time Koopman Identifier: A Unified Batch-online Learning  Framework for Joint Learning of Koopman Structure and Parameters",
    "abstract": "Finite-time Koopman Identifier: A Unified Batch-online Learning  Framework for Joint Learning of Koopman Structure and Parameters",
    "descriptor": "",
    "authors": [
      "Majid Mazouchi",
      "Subramanya Nageshrao",
      "Hamidreza Modares"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.05903"
  },
  {
    "id": "arXiv:2105.06165",
    "title": "PassFlow: Guessing Passwords with Generative Flows",
    "abstract": "Comments: 12 pages, 6 figures, 6 tables",
    "descriptor": "\nComments: 12 pages, 6 figures, 6 tables\n",
    "authors": [
      "Giulio Pagnotta",
      "Dorjan Hitaj",
      "Fabio De Gaspari",
      "Luigi V. Mancini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.06165"
  },
  {
    "id": "arXiv:2105.06813",
    "title": "A cost-benefit analysis of cross-lingual transfer methods",
    "abstract": "A cost-benefit analysis of cross-lingual transfer methods",
    "descriptor": "",
    "authors": [
      "Guilherme Moraes Rosa",
      "Luiz Henrique Bonifacio",
      "Leandro Rodrigues de Souza",
      "Roberto Lotufo",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.06813"
  },
  {
    "id": "arXiv:2105.07997",
    "title": "Compacting Squares: Input-Sensitive In-Place Reconfiguration of Sliding  Squares",
    "abstract": "Compacting Squares: Input-Sensitive In-Place Reconfiguration of Sliding  Squares",
    "descriptor": "",
    "authors": [
      "Hugo A. Akitaya",
      "Erik D. Demaine",
      "Matias Korman",
      "Irina Kostitsyna",
      "Irene Parada",
      "Willem Sonke",
      "Bettina Speckmann",
      "Ryuhei Uehara",
      "Jules Wulms"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.07997"
  },
  {
    "id": "arXiv:2105.08825",
    "title": "Multi-Person Extreme Motion Prediction",
    "abstract": "Multi-Person Extreme Motion Prediction",
    "descriptor": "",
    "authors": [
      "Wen Guo",
      "Xiaoyu Bie",
      "Xavier Alameda-Pineda",
      "Francesc Moreno-Noguer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.08825"
  },
  {
    "id": "arXiv:2105.10872",
    "title": "CMUA-Watermark: A Cross-Model Universal Adversarial Watermark for  Combating Deepfakes",
    "abstract": "Comments: 9 pages, 7 figures, Thirty-Sixth AAAI Conference on Artificial Intelligence, AAAI22",
    "descriptor": "\nComments: 9 pages, 7 figures, Thirty-Sixth AAAI Conference on Artificial Intelligence, AAAI22\n",
    "authors": [
      "Hao Huang",
      "Yongtao Wang",
      "Zhaoyu Chen",
      "Yuze Zhang",
      "Yuheng Li",
      "Zhi Tang",
      "Wei Chu",
      "Jingdong Chen",
      "Weisi Lin",
      "Kai-Kuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.10872"
  },
  {
    "id": "arXiv:2105.11668",
    "title": "BoundarySqueeze: Image Segmentation as Boundary Squeezing",
    "abstract": "BoundarySqueeze: Image Segmentation as Boundary Squeezing",
    "descriptor": "",
    "authors": [
      "Hao He",
      "Xiangtai Li",
      "Yibo Yang",
      "Guangliang Cheng",
      "Yunhai Tong",
      "Lubin Weng",
      "Zhouchen Lin",
      "Shiming Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11668"
  },
  {
    "id": "arXiv:2106.02156",
    "title": "Trading Throughput for Freshness: Freshness-Aware Traffic Engineering  and In-Network Freshness Control",
    "abstract": "Trading Throughput for Freshness: Freshness-Aware Traffic Engineering  and In-Network Freshness Control",
    "descriptor": "",
    "authors": [
      "Shih-Hao Tseng",
      "SooJean Han",
      "Adam Wierman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.02156"
  },
  {
    "id": "arXiv:2106.03090",
    "title": "Deep Matching Prior: Test-Time Optimization for Dense Correspondence",
    "abstract": "Comments: Accepted to ICCV 2021, Camera-ready version. The code will be made available at this https URL",
    "descriptor": "\nComments: Accepted to ICCV 2021, Camera-ready version. The code will be made available at this https URL\n",
    "authors": [
      "Sunghwan Hong",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03090"
  },
  {
    "id": "arXiv:2106.03791",
    "title": "Learning Gaussian Mixtures with Generalised Linear Models: Precise  Asymptotics in High-dimensions",
    "abstract": "Comments: 12 pages + 34 pages of Appendix, 10 figures",
    "descriptor": "\nComments: 12 pages + 34 pages of Appendix, 10 figures\n",
    "authors": [
      "Bruno Loureiro",
      "Gabriele Sicuro",
      "C\u00e9dric Gerbelot",
      "Alessandro Pacco",
      "Florent Krzakala",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03791"
  },
  {
    "id": "arXiv:2106.05639",
    "title": "C-GLISp: Preference-Based Global Optimization under Unknown Constraints  with Applications to Controller Calibration",
    "abstract": "Comments: A MATLAB and a Python implementation of C-GLISp is available at this http URL",
    "descriptor": "\nComments: A MATLAB and a Python implementation of C-GLISp is available at this http URL\n",
    "authors": [
      "Mengjia Zhu",
      "Dario Piga",
      "Alberto Bemporad"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.05639"
  },
  {
    "id": "arXiv:2106.05967",
    "title": "Revisiting Contrastive Methods for Unsupervised Learning of Visual  Representations",
    "abstract": "Comments: NeurIPS 2021. Code: this https URL",
    "descriptor": "\nComments: NeurIPS 2021. Code: this https URL\n",
    "authors": [
      "Wouter Van Gansbeke",
      "Simon Vandenhende",
      "Stamatios Georgoulis",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05967"
  },
  {
    "id": "arXiv:2106.07510",
    "title": "Computing the Cut Locus of a Riemannian Manifold via Optimal Transport",
    "abstract": "Computing the Cut Locus of a Riemannian Manifold via Optimal Transport",
    "descriptor": "",
    "authors": [
      "Enrico Facca",
      "Luca Berti",
      "Francesco Fass\u00f3",
      "Mario Putti"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Differential Geometry (math.DG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.07510"
  },
  {
    "id": "arXiv:2106.09675",
    "title": "Gone Fishing: Neural Active Learning with Fisher Embeddings",
    "abstract": "Gone Fishing: Neural Active Learning with Fisher Embeddings",
    "descriptor": "",
    "authors": [
      "Jordan T. Ash",
      "Surbhi Goel",
      "Akshay Krishnamurthy",
      "Sham Kakade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09675"
  },
  {
    "id": "arXiv:2106.10062",
    "title": "The ensemble Kalman filter for rare event estimation",
    "abstract": "The ensemble Kalman filter for rare event estimation",
    "descriptor": "",
    "authors": [
      "Fabian Wagner",
      "Iason Papaioannou",
      "Elisabeth Ullmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10062"
  },
  {
    "id": "arXiv:2106.11522",
    "title": "Total Least Squares for Optimal Pose Estimation",
    "abstract": "Total Least Squares for Optimal Pose Estimation",
    "descriptor": "",
    "authors": [
      "Saeed Maleki",
      "Yang Cheng",
      "John Crassidis",
      "Matthias Schmid"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11522"
  },
  {
    "id": "arXiv:2106.11653",
    "title": "Domain Adaptive Semantic Segmentation without Source Data: Align, Teach  and Propagate",
    "abstract": "Domain Adaptive Semantic Segmentation without Source Data: Align, Teach  and Propagate",
    "descriptor": "",
    "authors": [
      "Yuxi Wang",
      "Jian Liang",
      "Jun Xiao",
      "Yuran Yang",
      "Shuqi Mei",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11653"
  },
  {
    "id": "arXiv:2106.13139",
    "title": "FaDIV-Syn: Fast Depth-Independent View Synthesis",
    "abstract": "FaDIV-Syn: Fast Depth-Independent View Synthesis",
    "descriptor": "",
    "authors": [
      "Andre Rochow",
      "Max Schwarz",
      "Michael Weinmann",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13139"
  },
  {
    "id": "arXiv:2106.16172",
    "title": "Backgammon is Hard",
    "abstract": "Backgammon is Hard",
    "descriptor": "",
    "authors": [
      "R. Teal Witter"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.16172"
  },
  {
    "id": "arXiv:2107.01405",
    "title": "A Fuzzy Scheduling Strategy for Intelligent Workflow Decision Making in  Uncertain Edge-Cloud Environments",
    "abstract": "A Fuzzy Scheduling Strategy for Intelligent Workflow Decision Making in  Uncertain Edge-Cloud Environments",
    "descriptor": "",
    "authors": [
      "Bing Lin",
      "Chaowei Lin",
      "Xing Chen",
      "Neal N. Xiong",
      "Qiang Shen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.01405"
  },
  {
    "id": "arXiv:2107.02317",
    "title": "Robotic Endoscope Control via Autonomous Instrument Tracking",
    "abstract": "Comments: Caspar Gruijthuijsen and Luis C. Garcia-Peraza-Herrera have contributed equally to this work and share first authorship",
    "descriptor": "\nComments: Caspar Gruijthuijsen and Luis C. Garcia-Peraza-Herrera have contributed equally to this work and share first authorship\n",
    "authors": [
      "Caspar Gruijthuijsen",
      "Luis C. Garcia-Peraza-Herrera",
      "Gianni Borghesan",
      "Dominiek Reynaerts",
      "Jan Deprest",
      "Sebastien Ourselin",
      "Tom Vercauteren",
      "Emmanuel Vander Poorten"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.02317"
  },
  {
    "id": "arXiv:2107.02743",
    "title": "Submodular Order Functions and Assortment Optimization",
    "abstract": "Submodular Order Functions and Assortment Optimization",
    "descriptor": "",
    "authors": [
      "Rajan Udwani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.02743"
  },
  {
    "id": "arXiv:2107.04025",
    "title": "On the expressive power of non-deterministic and unambiguous Petri nets  over infinite words",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1712.07945",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1712.07945\n",
    "authors": [
      "Olivier Finkel",
      "Micha\u0142 Skrzypczak"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2107.04025"
  },
  {
    "id": "arXiv:2107.04069",
    "title": "Proof-of-Stake Mining Games with Perfect Randomness",
    "abstract": "Comments: 79 Pages, ACM EC 2021",
    "descriptor": "\nComments: 79 Pages, ACM EC 2021\n",
    "authors": [
      "Matheus V. X. Ferreira",
      "S. Matthew Weinberg"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2107.04069"
  },
  {
    "id": "arXiv:2107.04271",
    "title": "FedAdapt: Adaptive Offloading for IoT Devices in Federated Learning",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Di Wu",
      "Rehmat Ullah",
      "Paul Harvey",
      "Peter Kilpatrick",
      "Ivor Spence",
      "Blesson Varghese"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04271"
  },
  {
    "id": "arXiv:2107.04537",
    "title": "Modality specific U-Net variants for biomedical image segmentation: A  survey",
    "abstract": "Modality specific U-Net variants for biomedical image segmentation: A  survey",
    "descriptor": "",
    "authors": [
      "Narinder Singh Punn",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.04537"
  },
  {
    "id": "arXiv:2107.06617",
    "title": "Simulating transmission scenarios of the Delta variant of SARS-CoV-2 in  Australia",
    "abstract": "Comments: 30 pages, 14 figures",
    "descriptor": "\nComments: 30 pages, 14 figures\n",
    "authors": [
      "Sheryl L. Chang",
      "Oliver M. Cliff",
      "Cameron Zachreson",
      "Mikhail Prokopenko"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.06617"
  },
  {
    "id": "arXiv:2107.07695",
    "title": "Self-supervised Representation Learning Framework for Remote  Physiological Measurement Using Spatiotemporal Augmentation Loss",
    "abstract": "Comments: Accepted as AAAI22 paper. Code: this https URL",
    "descriptor": "\nComments: Accepted as AAAI22 paper. Code: this https URL\n",
    "authors": [
      "Hao Wang",
      "Euijoon Ahn",
      "Jinman Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07695"
  },
  {
    "id": "arXiv:2107.09518",
    "title": "Relay-Assisted Cooperative Federated Learning",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Zehong Lin",
      "Hang Liu",
      "Ying-Jun Angela Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.09518"
  },
  {
    "id": "arXiv:2107.10762",
    "title": "Super-Resolution on the Two-Dimensional Unit Sphere",
    "abstract": "Comments: 58 pages, 17 figures",
    "descriptor": "\nComments: 58 pages, 17 figures\n",
    "authors": [
      "Frank Filbir",
      "Kristof Schr\u00f6der",
      "Anna Veselovska"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.10762"
  },
  {
    "id": "arXiv:2107.11859",
    "title": "A family of second order convergent weakly-compressible SPH schemes",
    "abstract": "Comments: 63 pages, 26 figures, 9 tables",
    "descriptor": "\nComments: 63 pages, 26 figures, 9 tables\n",
    "authors": [
      "Pawan Negi",
      "Prabhu Ramachandran"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.11859"
  },
  {
    "id": "arXiv:2107.12698",
    "title": "Source-Agnostic Gravitational-Wave Detection with Recurrent Autoencoders",
    "abstract": "Comments: 16 pages, 6 figures. Updated version with new datasets, resulting from suggestions received in the MLST referee report",
    "descriptor": "\nComments: 16 pages, 6 figures. Updated version with new datasets, resulting from suggestions received in the MLST referee report\n",
    "authors": [
      "Eric A. Moreno",
      "Jean-Roch Vlimant",
      "Maria Spiropulu",
      "Bartlomiej Borzyszkowski",
      "Maurizio Pierini"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2107.12698"
  },
  {
    "id": "arXiv:2107.13862",
    "title": "Subsequent embedding in targeted image steganalysis: Theoretical  framework and practical applications",
    "abstract": "Subsequent embedding in targeted image steganalysis: Theoretical  framework and practical applications",
    "descriptor": "",
    "authors": [
      "David Meg\u00edas",
      "Daniel Lerch-Hostalot"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.13862"
  },
  {
    "id": "arXiv:2107.14443",
    "title": "Single image deep defocus estimation and its applications",
    "abstract": "Single image deep defocus estimation and its applications",
    "descriptor": "",
    "authors": [
      "Fernando J. Galetto",
      "Guang Deng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.14443"
  },
  {
    "id": "arXiv:2108.02508",
    "title": "RCA-IUnet: A residual cross-spatial attention guided inception U-Net  model for tumor segmentation in breast ultrasound imaging",
    "abstract": "RCA-IUnet: A residual cross-spatial attention guided inception U-Net  model for tumor segmentation in breast ultrasound imaging",
    "descriptor": "",
    "authors": [
      "Narinder Singh Punn",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.02508"
  },
  {
    "id": "arXiv:2108.03616",
    "title": "Circuit imbalance measures and linear programming",
    "abstract": "Circuit imbalance measures and linear programming",
    "descriptor": "",
    "authors": [
      "Farbod Ekbatani",
      "Bento Natura",
      "L\u00e1szl\u00f3 A. V\u00e9gh"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.03616"
  },
  {
    "id": "arXiv:2108.06230",
    "title": "Generative Zero-Shot Learning for Semantic Segmentation of 3D Point  Cloud",
    "abstract": "Comments: For the published code, see this https URL",
    "descriptor": "\nComments: For the published code, see this https URL\n",
    "authors": [
      "Bj\u00f6rn Michele",
      "Alexandre Boulch",
      "Gilles Puy",
      "Maxime Bucher",
      "Renaud Marlet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.06230"
  },
  {
    "id": "arXiv:2108.08877",
    "title": "Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text  Models",
    "abstract": "Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text  Models",
    "descriptor": "",
    "authors": [
      "Jianmo Ni",
      "Gustavo Hern\u00e1ndez \u00c1brego",
      "Noah Constant",
      "Ji Ma",
      "Keith B. Hall",
      "Daniel Cer",
      "Yinfei Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.08877"
  },
  {
    "id": "arXiv:2108.10260",
    "title": "Proportional-Integral Projected Gradient Method for Conic Optimization",
    "abstract": "Proportional-Integral Projected Gradient Method for Conic Optimization",
    "descriptor": "",
    "authors": [
      "Yue Yu",
      "Purnanand Elango",
      "Ufuk Topcu",
      "Beh\u00e7et A\u00e7\u0131kme\u015fe"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.10260"
  },
  {
    "id": "arXiv:2108.10949",
    "title": "Robustness Evaluation of Entity Disambiguation Using Prior Probes:the  Case of Entity Overshadowing",
    "abstract": "Robustness Evaluation of Entity Disambiguation Using Prior Probes:the  Case of Entity Overshadowing",
    "descriptor": "",
    "authors": [
      "Vera Provatorova",
      "Svitlana Vakulenko",
      "Samarth Bhargav",
      "Evangelos Kanoulas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.10949"
  },
  {
    "id": "arXiv:2109.03159",
    "title": "Analysis of Regularized Learning in Banach Spaces",
    "abstract": "Comments: 31 pages, 1 figure",
    "descriptor": "\nComments: 31 pages, 1 figure\n",
    "authors": [
      "Qi Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.03159"
  },
  {
    "id": "arXiv:2109.03179",
    "title": "Contest Design with Threshold Objectives",
    "abstract": "Comments: Presented at WINE 2021",
    "descriptor": "\nComments: Presented at WINE 2021\n",
    "authors": [
      "Edith Elkind",
      "Abheek Ghosh",
      "Paul Goldberg"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2109.03179"
  },
  {
    "id": "arXiv:2109.03658",
    "title": "Cost Problems for Parametric Time Petri Nets",
    "abstract": "Cost Problems for Parametric Time Petri Nets",
    "descriptor": "",
    "authors": [
      "Didier Lime",
      "Olivier H. Roux",
      "Charlotte Seidner"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2109.03658"
  },
  {
    "id": "arXiv:2109.04027",
    "title": "Taxim: An Example-based Simulation Model for GelSight Tactile Sensors",
    "abstract": "Taxim: An Example-based Simulation Model for GelSight Tactile Sensors",
    "descriptor": "",
    "authors": [
      "Zilin Si",
      "Wenzhen Yuan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04027"
  },
  {
    "id": "arXiv:2109.04911",
    "title": "RandSolomon: Optimally Resilient Random Number Generator with  Deterministic Termination",
    "abstract": "RandSolomon: Optimally Resilient Random Number Generator with  Deterministic Termination",
    "descriptor": "",
    "authors": [
      "Luciano Freitas de Souza",
      "Andrei Tonkikh",
      "Sara Tucci-Piergiovanni",
      "Renaud Sirdey",
      "Oana Stan",
      "Nicolas Quero",
      "Petr Kuznetsov"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.04911"
  },
  {
    "id": "arXiv:2109.06165",
    "title": "CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation",
    "abstract": "CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Tongkun Xu",
      "Weihua Chen",
      "Pichao Wang",
      "Fan Wang",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06165"
  },
  {
    "id": "arXiv:2109.08237",
    "title": "Subtle Data Crimes: Naively training machine learning algorithms could  lead to overly-optimistic results",
    "abstract": "Comments: 16 pages, 7 figures, two tables. Submitted to a journal",
    "descriptor": "\nComments: 16 pages, 7 figures, two tables. Submitted to a journal\n",
    "authors": [
      "Efrat Shimron",
      "Jonathan I. Tamir",
      "Ke Wang",
      "Michael Lustig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.08237"
  },
  {
    "id": "arXiv:2109.11136",
    "title": "Non-Parametric Online Learning from Human Feedback for Neural Machine  Translation",
    "abstract": "Comments: Accepted to the 36th AAAI Conference on Artificial Intelligence (AAAI 2022)",
    "descriptor": "\nComments: Accepted to the 36th AAAI Conference on Artificial Intelligence (AAAI 2022)\n",
    "authors": [
      "Dongqi Wang",
      "Haoran Wei",
      "Zhirui Zhang",
      "Shujian Huang",
      "Jun Xie",
      "Jiajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.11136"
  },
  {
    "id": "arXiv:2109.11679",
    "title": "Safe Policy Learning through Extrapolation: Application to Pre-trial  Risk Assessment",
    "abstract": "Safe Policy Learning through Extrapolation: Application to Pre-trial  Risk Assessment",
    "descriptor": "",
    "authors": [
      "Eli Ben-Michael",
      "D. James Greiner",
      "Kosuke Imai",
      "Zhichao Jiang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2109.11679"
  },
  {
    "id": "arXiv:2109.11867",
    "title": "The $f$-Divergence Reinforcement Learning Framework",
    "abstract": "Comments: 17 pages, 4 figures",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "Chen Gong",
      "Qiang He",
      "Yunpeng Bai",
      "Zhou Yang",
      "Xiaoyu Chen",
      "Xinwen Hou",
      "Xianjie Zhang",
      "Yu Liu",
      "Guoliang Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.11867"
  },
  {
    "id": "arXiv:2109.11896",
    "title": "A Model-Driven Approach to Reengineering Processes in Cloud Computing",
    "abstract": "Comments: NA",
    "descriptor": "\nComments: NA\n",
    "authors": [
      "Mahdi Fahmideh",
      "John Grundy",
      "Ghassan Beydoun",
      "Didar Zowghi",
      "Willy Susilo",
      "Davoud Mougouei"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.11896"
  },
  {
    "id": "arXiv:2109.12473",
    "title": "Statically Bounded-Memory Delayed Sampling for Probabilistic Streams",
    "abstract": "Comments: The following is a summary of the changes in each revision. [v2] corrected the URL for the code repository. [v3] corrected the definition of the m-consumed semantic property. [v4] fixed a typo. [v5] added this comment",
    "descriptor": "\nComments: The following is a summary of the changes in each revision. [v2] corrected the URL for the code repository. [v3] corrected the definition of the m-consumed semantic property. [v4] fixed a typo. [v5] added this comment\n",
    "authors": [
      "Eric Atkinson",
      "Guillaume Baudart",
      "Louis Mandel",
      "Charles Yuan",
      "Michael Carbin"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2109.12473"
  },
  {
    "id": "arXiv:2109.15047",
    "title": "Deep Contextual Video Compression",
    "abstract": "Comments: Accepted by NeurIPS 2021, codes are in this https URL",
    "descriptor": "\nComments: Accepted by NeurIPS 2021, codes are in this https URL\n",
    "authors": [
      "Jiahao Li",
      "Bin Li",
      "Yan Lu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2109.15047"
  },
  {
    "id": "arXiv:2110.00375",
    "title": "Fully Spiking Variational Autoencoder",
    "abstract": "Comments: Accepted to AAAI2022",
    "descriptor": "\nComments: Accepted to AAAI2022\n",
    "authors": [
      "Hiromichi Kamata",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00375"
  },
  {
    "id": "arXiv:2110.01179",
    "title": "BPFNet: A Unified Framework for Bimodal Palmprint Alignment and Fusion",
    "abstract": "Comments: Extended version of ICONIP 2021 paper",
    "descriptor": "\nComments: Extended version of ICONIP 2021 paper\n",
    "authors": [
      "Zhaoqun Li",
      "Xu Liang",
      "Dandan Fan",
      "Jinxing Li",
      "David Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.01179"
  },
  {
    "id": "arXiv:2110.03054",
    "title": "On the Privacy Risks of Deploying Recurrent Neural Networks in Machine  Learning",
    "abstract": "Comments: Under Double-Blind Review",
    "descriptor": "\nComments: Under Double-Blind Review\n",
    "authors": [
      "Yunhao Yang",
      "Parham Gohari",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03054"
  },
  {
    "id": "arXiv:2110.04764",
    "title": "Deep learning-based person re-identification methods: A survey and  outlook of recent works",
    "abstract": "Comments: 24 pages, 7 figures",
    "descriptor": "\nComments: 24 pages, 7 figures\n",
    "authors": [
      "Zhangqiang Ming",
      "Min Zhu",
      "Xiangkun Wang",
      "Jiamin Zhu",
      "Junlong Cheng",
      "Yong Yang",
      "Xiaoyong Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04764"
  },
  {
    "id": "arXiv:2110.07843",
    "title": "FOLD-R++: A Scalable Toolset for Automated Inductive Learning of Default  Theories from Mixed Data",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1909.09017 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1909.09017 by other authors\n",
    "authors": [
      "Huaduo Wang",
      "Gopal Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07843"
  },
  {
    "id": "arXiv:2110.09050",
    "title": "Strategizing University Rank Improvement using Interpretable Machine  Learning and Data Visualization",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Nishi Doshi",
      "Samhitha Gundam",
      "Bhaskar Chaudhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09050"
  },
  {
    "id": "arXiv:2110.09468",
    "title": "Improving Robustness using Generated Data",
    "abstract": "Comments: Accepted at NeurIPS 2021; Added ImageNet results",
    "descriptor": "\nComments: Accepted at NeurIPS 2021; Added ImageNet results\n",
    "authors": [
      "Sven Gowal",
      "Sylvestre-Alvise Rebuffi",
      "Olivia Wiles",
      "Florian Stimberg",
      "Dan Andrei Calian",
      "Timothy Mann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09468"
  },
  {
    "id": "arXiv:2110.10617",
    "title": "Colosseum: Large-Scale Wireless Experimentation Through  Hardware-in-the-Loop Network Emulation",
    "abstract": "Colosseum: Large-Scale Wireless Experimentation Through  Hardware-in-the-Loop Network Emulation",
    "descriptor": "",
    "authors": [
      "Leonardo Bonati",
      "Pedram Johari",
      "Michele Polese",
      "Salvatore D'Oro",
      "Subhramoy Mohanti",
      "Miead Tehrani-Moayyed",
      "Davide Villa",
      "Shweta Shrivastava",
      "Chinenye Tassie",
      "Kurt Yoder",
      "Ajeet Bagga",
      "Paresh Patel",
      "Ventz Petkov",
      "Michael Seltser",
      "Francesco Restuccia",
      "Abhimanyu Gosain",
      "Kaushik R. Chowdhury",
      "Stefano Basagni",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.10617"
  },
  {
    "id": "arXiv:2110.11802",
    "title": "Deep Convolutional Autoencoders as Generic Feature Extractors in  Seismological Applications",
    "abstract": "Deep Convolutional Autoencoders as Generic Feature Extractors in  Seismological Applications",
    "descriptor": "",
    "authors": [
      "Qingkai Kong",
      "Andrea Chiang",
      "Ana C. Aguiar",
      "M. Giselle Fern\u00e1ndez-Godino",
      "Stephen C. Myers",
      "Donald D. Lucas"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11802"
  },
  {
    "id": "arXiv:2110.12662",
    "title": "Sampling-Based Robust Control of Autonomous Systems with Non-Gaussian  Noise",
    "abstract": "Sampling-Based Robust Control of Autonomous Systems with Non-Gaussian  Noise",
    "descriptor": "",
    "authors": [
      "Thom S. Badings",
      "Alessandro Abate",
      "Nils Jansen",
      "David Parker",
      "Hasan A. Poonawala",
      "Marielle Stoelinga"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12662"
  },
  {
    "id": "arXiv:2110.13468",
    "title": "Enhanced User Grouping and Pairing Scheme for CoMP-NOMA-based Cellular  Networks",
    "abstract": "Comments: Submitted to COMSNETS 2022",
    "descriptor": "\nComments: Submitted to COMSNETS 2022\n",
    "authors": [
      "Akhileswar Chowdary",
      "Garima Chopra",
      "Abhinav Kumar",
      "Linga Reddy Cenkeramaddi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.13468"
  },
  {
    "id": "arXiv:2110.14615",
    "title": "Play to Grade: Testing Coding Games as Classifying Markov Decision  Process",
    "abstract": "Comments: NeurIPS 2021, 16 pages, 7 figures",
    "descriptor": "\nComments: NeurIPS 2021, 16 pages, 7 figures\n",
    "authors": [
      "Allen Nie",
      "Emma Brunskill",
      "Chris Piech"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14615"
  },
  {
    "id": "arXiv:2110.15644",
    "title": "Gabor filter incorporated CNN for compression",
    "abstract": "Gabor filter incorporated CNN for compression",
    "descriptor": "",
    "authors": [
      "Akihiro Imamura",
      "Nana Arizumi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15644"
  },
  {
    "id": "arXiv:2111.02273",
    "title": "Multi-Cue Adaptive Emotion Recognition Network",
    "abstract": "Multi-Cue Adaptive Emotion Recognition Network",
    "descriptor": "",
    "authors": [
      "Willams Costa",
      "David Mac\u00eado",
      "Cleber Zanchettin",
      "Lucas S. Figueiredo",
      "Veronica Teichrieb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2111.02273"
  },
  {
    "id": "arXiv:2111.06921",
    "title": "Outage Analysis over Correlated Fisher-Snedecor F Fading Multi-User  Channels",
    "abstract": "Outage Analysis over Correlated Fisher-Snedecor F Fading Multi-User  Channels",
    "descriptor": "",
    "authors": [
      "Farshad Rostami Ghadi",
      "Wei-Ping Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.06921"
  },
  {
    "id": "arXiv:2111.07529",
    "title": "Object Propagation via Inter-Frame Attentions for Temporally Stable  Video Instance Segmentation",
    "abstract": "Comments: Accepted at CVPR RVSU Workshop 2021",
    "descriptor": "\nComments: Accepted at CVPR RVSU Workshop 2021\n",
    "authors": [
      "Anirudh S Chakravarthy",
      "Won-Dong Jang",
      "Zudi Lin",
      "Donglai Wei",
      "Song Bai",
      "Hanspeter Pfister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.07529"
  },
  {
    "id": "arXiv:2111.10985",
    "title": "Efficient Non-Compression Auto-Encoder for Driving Noise-based Road  Surface Anomaly Detection",
    "abstract": "Comments: 8 pages, 4 figures, 6 tables",
    "descriptor": "\nComments: 8 pages, 4 figures, 6 tables\n",
    "authors": [
      "YeongHyeon Park",
      "JongHee Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.10985"
  },
  {
    "id": "arXiv:2111.11297",
    "title": "Teaching Humans When To Defer to a Classifier via Exemplars",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Hussein Mozannar",
      "Arvind Satyanarayan",
      "David Sontag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.11297"
  },
  {
    "id": "arXiv:2111.13198",
    "title": "The Implicit Graph Conjecture is False",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Hamed Hatami",
      "Pooya Hatami"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.13198"
  },
  {
    "id": "arXiv:2111.14039",
    "title": "Generalization Performance of Empirical Risk Minimization on  Over-parameterized Deep ReLU Nets",
    "abstract": "Comments: 24 pages, 2 figures",
    "descriptor": "\nComments: 24 pages, 2 figures\n",
    "authors": [
      "Shao-Bo Lin",
      "Yao Wang",
      "Ding-Xuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14039"
  },
  {
    "id": "arXiv:2111.15296",
    "title": "BrainScaleS Large Scale Spike Communication using Extoll",
    "abstract": "Comments: 3 pages, 2 figures, submitted to the Neuro Inspired Computational Elements 2020 (NICE'2020) conference, accepted and presented as a poster in March 2021; 1st replacement: add acknowledgement of DFG (German Research Foundation)",
    "descriptor": "\nComments: 3 pages, 2 figures, submitted to the Neuro Inspired Computational Elements 2020 (NICE'2020) conference, accepted and presented as a poster in March 2021; 1st replacement: add acknowledgement of DFG (German Research Foundation)\n",
    "authors": [
      "Tobias Thommes",
      "Niels Buwen",
      "Andreas Gr\u00fcbl",
      "Eric M\u00fcller",
      "Ulrich Br\u00fcning",
      "Johannes Schemmel"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.15296"
  },
  {
    "id": "arXiv:2112.01122",
    "title": "CEV Framework: A Central Bank Digital Currency Evaluation and  Verification Framework with Focus of Consensus Algorithms and Operating  Models",
    "abstract": "CEV Framework: A Central Bank Digital Currency Evaluation and  Verification Framework with Focus of Consensus Algorithms and Operating  Models",
    "descriptor": "",
    "authors": [
      "Si Yuan Jin",
      "Yong Xia"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2112.01122"
  },
  {
    "id": "arXiv:2112.01662",
    "title": "FP-Radar: Longitudinal Measurement and Early Detection of Browser  Fingerprinting",
    "abstract": "FP-Radar: Longitudinal Measurement and Early Detection of Browser  Fingerprinting",
    "descriptor": "",
    "authors": [
      "Pouneh Nikkhah Bahrami",
      "Umar Iqbal",
      "Zubair Shafiq"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.01662"
  },
  {
    "id": "arXiv:2112.01922",
    "title": "MetaQA: Combining Expert Agents for Multi-Skill Question Answering",
    "abstract": "MetaQA: Combining Expert Agents for Multi-Skill Question Answering",
    "descriptor": "",
    "authors": [
      "Haritz Puerto",
      "G\u00f6zde G\u00fcl \u015eahin",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01922"
  },
  {
    "id": "arXiv:2112.02905",
    "title": "Parameter Efficient Deep Probabilistic Forecasting",
    "abstract": "Comments: Accepted as journal paper to the International Journal of Forecasting",
    "descriptor": "\nComments: Accepted as journal paper to the International Journal of Forecasting\n",
    "authors": [
      "Olivier Sprangers",
      "Sebastian Schelter",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02905"
  },
  {
    "id": "arXiv:2112.02936",
    "title": "Pairwise Learning for Neural Link Prediction",
    "abstract": "Pairwise Learning for Neural Link Prediction",
    "descriptor": "",
    "authors": [
      "Zhitao Wang",
      "Yong Zhou",
      "Litao Hong",
      "Yuanhang Zou",
      "Hanjing Su",
      "Shouzhi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.02936"
  },
  {
    "id": "arXiv:2112.03266",
    "title": "Contrastive Cycle Adversarial Autoencoders for Single-cell Multi-omics  Alignment and Integration",
    "abstract": "Contrastive Cycle Adversarial Autoencoders for Single-cell Multi-omics  Alignment and Integration",
    "descriptor": "",
    "authors": [
      "Xuesong Wang",
      "Zhihang Hu",
      "Tingyang Yu",
      "Ruijie Wang",
      "Yumeng Wei",
      "Juan Shu",
      "Jianzhu Ma",
      "Yu Li"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03266"
  },
  {
    "id": "arXiv:2112.03444",
    "title": "GPU-Based Homotopy Continuation for Minimal Problems in Computer Vision",
    "abstract": "GPU-Based Homotopy Continuation for Minimal Problems in Computer Vision",
    "descriptor": "",
    "authors": [
      "Chiang-Heng Chien",
      "Hongyi Fan",
      "Ahmad Abdelfattah",
      "Elias Tsigaridas",
      "Stanimire Tomov",
      "Benjamin Kimia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03444"
  },
  {
    "id": "arXiv:2112.03806",
    "title": "OOD-GNN: Out-of-Distribution Generalized Graph Neural Network",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Haoyang Li",
      "Xin Wang",
      "Ziwei Zhang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03806"
  },
  {
    "id": "arXiv:2112.04121",
    "title": "Reverse image filtering using total derivative approximation and  accelerated gradient descent",
    "abstract": "Reverse image filtering using total derivative approximation and  accelerated gradient descent",
    "descriptor": "",
    "authors": [
      "Fernando J. Galetto",
      "Guang Deng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04121"
  },
  {
    "id": "arXiv:2112.04325",
    "title": "A PTAS for the Min-Max Euclidean Multiple TSP",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Mary Monroe",
      "David M. Mount"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.04325"
  },
  {
    "id": "arXiv:2112.04913",
    "title": "Identification of Twitter Bots Based on an Explainable Machine Learning  Framework: The US 2020 Elections Case Study",
    "abstract": "Identification of Twitter Bots Based on an Explainable Machine Learning  Framework: The US 2020 Elections Case Study",
    "descriptor": "",
    "authors": [
      "Alexander Shevtsov",
      "Christos Tzagkarakis",
      "Despoina Antonakaki",
      "Sotiris Ioannidis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04913"
  },
  {
    "id": "arXiv:2112.05534",
    "title": "An Embarrassingly Pragmatic Introduction to Vision-based Autonomous  Robots",
    "abstract": "Comments: CS Thesis. Lecture Notes in Computer Science",
    "descriptor": "\nComments: CS Thesis. Lecture Notes in Computer Science\n",
    "authors": [
      "Marcos V. Conde"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.05534"
  },
  {
    "id": "arXiv:2112.05648",
    "title": "Minimax detection of localized signals in statistical inverse problems",
    "abstract": "Minimax detection of localized signals in statistical inverse problems",
    "descriptor": "",
    "authors": [
      "Markus Pohlmann",
      "Frank Werner",
      "Axel Munk"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.05648"
  },
  {
    "id": "arXiv:2112.05682",
    "title": "Self-attention Does Not Need $O(n^2)$ Memory",
    "abstract": "Self-attention Does Not Need $O(n^2)$ Memory",
    "descriptor": "",
    "authors": [
      "Markus N. Rabe",
      "Charles Staats"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05682"
  },
  {
    "id": "arXiv:2112.05851",
    "title": "Short and Long Range Relation Based Spatio-Temporal Transformer for  Micro-Expression Recognition",
    "abstract": "Comments: 12 pages, 8 figures",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Liangfei Zhang",
      "Xiaopeng Hong",
      "Ognjen Arandjelovic",
      "Guoying Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.05851"
  },
  {
    "id": "arXiv:2112.05943",
    "title": "A strongly mass conservative method for the coupled Brinkman-Darcy flow  and transport",
    "abstract": "A strongly mass conservative method for the coupled Brinkman-Darcy flow  and transport",
    "descriptor": "",
    "authors": [
      "Lina Zhao",
      "Shuyu Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.05943"
  },
  {
    "id": "arXiv:2112.05958",
    "title": "You Only Need End-to-End Training for Long-Tailed Recognition",
    "abstract": "Comments: 16 pages, 11 figures, 8 tables",
    "descriptor": "\nComments: 16 pages, 11 figures, 8 tables\n",
    "authors": [
      "Zhiwei Zhang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05958"
  },
  {
    "id": "arXiv:2112.05964",
    "title": "Overcoming Restraint: Composing Verification of Foreign Functions with  Cogent",
    "abstract": "Comments: This paper should have been submitted as an update for arXiv:2102.09920",
    "descriptor": "\nComments: This paper should have been submitted as an update for arXiv:2102.09920\n",
    "authors": [
      "Louis Cheung",
      "Liam O'Connor",
      "Christine Rizkallah"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.05964"
  },
  {
    "id": "arXiv:2112.05994",
    "title": "The Price of Justified Representation",
    "abstract": "Comments: Appears in the 36th AAAI Conference on Artificial Intelligence (AAAI), 2022",
    "descriptor": "\nComments: Appears in the 36th AAAI Conference on Artificial Intelligence (AAAI), 2022\n",
    "authors": [
      "Edith Elkind",
      "Piotr Faliszewski",
      "Ayumi Igarashi",
      "Pasin Manurangsi",
      "Ulrike Schmidt-Kraepelin",
      "Warut Suksompong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.05994"
  },
  {
    "id": "arXiv:2112.06149",
    "title": "Two New Stenosis Detection Methods of Coronary Angiograms",
    "abstract": "Comments: We submitted the paper due to an operational error. This paper is a modified version of the original paper Two New Stenoses Detection Methods of Coronary Angiograms (arXiv:2108.01516). And we will update the revised paper to the original paper later",
    "descriptor": "\nComments: We submitted the paper due to an operational error. This paper is a modified version of the original paper Two New Stenoses Detection Methods of Coronary Angiograms (arXiv:2108.01516). And we will update the revised paper to the original paper later\n",
    "authors": [
      "Yaofang Liu",
      "Xinyue Zhang",
      "Wenlong Wan",
      "Shaoyu Liu",
      "Yingdi Liu",
      "Hu Liu",
      "Xueying Zeng",
      "Qing Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06149"
  },
  {
    "id": "arXiv:2112.06194",
    "title": "Improving Performance of Federated Learning based Medical Image Analysis  in Non-IID Settings using Image Augmentation",
    "abstract": "Improving Performance of Federated Learning based Medical Image Analysis  in Non-IID Settings using Image Augmentation",
    "descriptor": "",
    "authors": [
      "Alper Emin Cetinkaya",
      "Murat Akin",
      "Seref Sagiroglu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06194"
  },
  {
    "id": "arXiv:2112.06244",
    "title": "SHGNN: Structure-Aware Heterogeneous Graph Neural Network",
    "abstract": "SHGNN: Structure-Aware Heterogeneous Graph Neural Network",
    "descriptor": "",
    "authors": [
      "Wentao Xu",
      "Yingce Xia",
      "Weiqing Liu",
      "Jiang Bian",
      "Jian Yin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06244"
  },
  {
    "id": "arXiv:2112.06316",
    "title": "IFGF-accelerated integral equation solvers for acoustic scattering",
    "abstract": "IFGF-accelerated integral equation solvers for acoustic scattering",
    "descriptor": "",
    "authors": [
      "Edwin Jimenez",
      "Christoph Bauinger",
      "Oscar P. Bruno"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.06316"
  },
  {
    "id": "arXiv:2112.06320",
    "title": "Anomaly Crossing: A New Method for Video Anomaly Detection as  Cross-domain Few-shot Learning",
    "abstract": "Anomaly Crossing: A New Method for Video Anomaly Detection as  Cross-domain Few-shot Learning",
    "descriptor": "",
    "authors": [
      "Guangyu Sun",
      "Zhang Liu",
      "Lianggong Wen",
      "Jing Shi",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06320"
  },
  {
    "id": "arXiv:2112.06342",
    "title": "Faster-Than-Native Alternatives for x86 VP2INTERSECT Instructions",
    "abstract": "Faster-Than-Native Alternatives for x86 VP2INTERSECT Instructions",
    "descriptor": "",
    "authors": [
      "Guille D. Canas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.06342"
  },
  {
    "id": "arXiv:2112.06348",
    "title": "MedGraph: An experimental semantic information retrieval method using  knowledge graph embedding for the biomedical citations indexed in PubMed",
    "abstract": "Comments: Accepted at the 19th International Conference on Information Technology : New Generations (ITNG 2022)",
    "descriptor": "\nComments: Accepted at the 19th International Conference on Information Technology : New Generations (ITNG 2022)\n",
    "authors": [
      "Islam Akef Ebeid",
      "Elizabeth Pierce"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.06348"
  },
  {
    "id": "arXiv:2112.06410",
    "title": "How Good are Low-Rank Approximations in Gaussian Process Regression?",
    "abstract": "Comments: This submission should be an update of an older arxiv version and not a new one!",
    "descriptor": "\nComments: This submission should be an update of an older arxiv version and not a new one!\n",
    "authors": [
      "Constantinos Daskalakis",
      "Petros Dellaportas",
      "Aristeidis Panos"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.06410"
  },
  {
    "id": "arXiv:2112.06447",
    "title": "SVIP: Sequence VerIfication for Procedures in Videos",
    "abstract": "SVIP: Sequence VerIfication for Procedures in Videos",
    "descriptor": "",
    "authors": [
      "Yicheng Qian",
      "Weixin Luo",
      "Dongze Lian",
      "Xu Tang",
      "Peilin Zhao",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06447"
  },
  {
    "id": "arXiv:2112.06494",
    "title": "Native Chinese Reader: A Dataset Towards Native-Level Chinese Machine  Reading Comprehension",
    "abstract": "Comments: 17 pages, 1 fiugres, accepted by NeurIPS 2021 Track on Datasets and Benchmarks",
    "descriptor": "\nComments: 17 pages, 1 fiugres, accepted by NeurIPS 2021 Track on Datasets and Benchmarks\n",
    "authors": [
      "Shusheng Xu",
      "Yichen Liu",
      "Xiaoyu Yi",
      "Siyuan Zhou",
      "Huizi Li",
      "Yi Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.06494"
  },
  {
    "id": "arXiv:2112.06517",
    "title": "Top $K$ Ranking for Multi-Armed Bandit with Noisy Evaluations",
    "abstract": "Top $K$ Ranking for Multi-Armed Bandit with Noisy Evaluations",
    "descriptor": "",
    "authors": [
      "Evrard Garcelon",
      "Vashist Avadhanula",
      "Alessandro Lazaric",
      "Matteo Pirotta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.06517"
  },
  {
    "id": "arXiv:2112.06536",
    "title": "SphereSR: 360\u00b0 Image Super-Resolution with Arbitrary Projection via  Continuous Spherical Image Representation",
    "abstract": "SphereSR: 360\u00b0 Image Super-Resolution with Arbitrary Projection via  Continuous Spherical Image Representation",
    "descriptor": "",
    "authors": [
      "Youngho Yoon",
      "Inchul Chung",
      "Lin Wang",
      "Kuk-Jin Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06536"
  },
  {
    "id": "arXiv:2112.06560",
    "title": "HiClass: a Python library for local hierarchical classification  compatible with scikit-learn",
    "abstract": "Comments: 7 pages, 2 figures",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "F\u00e1bio M. Miranda",
      "Niklas K\u00f6ehnecke",
      "Bernhard Y. Renard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06560"
  },
  {
    "id": "arXiv:2112.06609",
    "title": "On Homotopy of Walks and Spherical Maps in Homotopy Type Theory",
    "abstract": "Comments: 14 pages. Part of the 11th ACM SIGPLAN International Conference on Certified Programs and Proofs CPP'22",
    "descriptor": "\nComments: 14 pages. Part of the 11th ACM SIGPLAN International Conference on Certified Programs and Proofs CPP'22\n",
    "authors": [
      "Jonathan Prieto-Cubides"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.06609"
  },
  {
    "id": "arXiv:2112.06881",
    "title": "Generalization Bounded Implicit Learning of Nearly Discontinuous  Functions",
    "abstract": "Comments: 22 pages, 3 figures",
    "descriptor": "\nComments: 22 pages, 3 figures\n",
    "authors": [
      "Bibit Bianchini",
      "Mathew Halm",
      "Nikolai Matni",
      "Michael Posa"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.06881"
  },
  {
    "id": "arXiv:2112.06887",
    "title": "Nonideality-Aware Training for Accurate and Robust Low-Power Memristive  Neural Networks",
    "abstract": "Comments: 25 pages, 17 figures, 5 tables",
    "descriptor": "\nComments: 25 pages, 17 figures, 5 tables\n",
    "authors": [
      "Dovydas Joksas",
      "Erwei Wang",
      "Nikolaos Barmpatsalos",
      "Wing H. Ng",
      "Anthony J. Kenyon",
      "George A. Constantinides",
      "Adnan Mehonic"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.06887"
  }
]
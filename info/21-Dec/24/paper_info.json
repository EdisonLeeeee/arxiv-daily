[
  {
    "id": "arXiv:2112.12163",
    "title": "Dual-Primal Isogeometric Tearing and Interconnecting methods for the  Stokes problem",
    "abstract": "We are interested in a fast solver for linear systems obtained by\ndiscretizing the Stokes problem with multi-patch Isogeometric Analysis. We use\nDual-Primal Isogeometric Tearing and Interconnecting (IETI-DP) methods. In\nresent years, IETI-DPand related methods have been studied extensively, mainly\nfor the Poisson problem. For the Stokes equations, several challenges arise\nsince the corresponding system is not positive definite, but has saddle point\nstructure. Moreover, the Stokes equations with Dirichlet boundary conditions\nhave a null-space, consisting of the constant pressure modes. This poses a\nchallenge when considering the scaled Dirichlet preconditioner. We test out two\ndifferent scaled Dirichlet preconditioners with different choices of primal\ndegrees of freedom. The tests are performed on rather simple domains (the unit\nsquare and a quarter annulus) and a more complicated domain (a Yeti-footprint).",
    "descriptor": "",
    "authors": [
      "Jarle Sogn",
      "Stefan Takacs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12163"
  },
  {
    "id": "arXiv:2112.12165",
    "title": "The Universal $\\ell^p$-Metric on Merge Trees",
    "abstract": "Adapting a definition given by Bjerkevik and Lesnick for multiparameter\npersistence modules, we introduce an $\\ell^p$-type extension of the\ninterleaving distance on merge trees. We show that our distance is a metric,\nand that it upper-bounds the $p$-Wasserstein distance between the associated\nbarcodes. For each $p\\in[1,\\infty]$, we prove that this distance is stable with\nrespect to cellular sublevel filtrations and that it is the universal (i.e.,\nlargest) distance satisfying this stability property. In the $p=\\infty$ case,\nthis gives a novel proof of universality for the interleaving distance on merge\ntrees.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Robert Cardona",
      "Justin Curry",
      "Tung Lam",
      "Michael Lesnick"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2112.12165"
  },
  {
    "id": "arXiv:2112.12166",
    "title": "Signaling Design for MIMO-NOMA with Different Security Requirements",
    "abstract": "Signaling design for secure transmission in two-user multiple-input\nmultiple-output (MIMO) non-orthogonal multiple access (NOMA) networks is\ninvestigated in this paper. The base station broadcasts multicast data to all\nusers and also integrates additional services, unicast data targeted to certain\nusers, and confidential data protected against eavesdroppers. We categorize the\nabove MIMO-NOMA with different security requirements into several communication\nscenarios. The associated problem in each scenario is nonconvex. We propose a\nunified approach, called the power splitting scheme, for optimizing the rate\nequations corresponding to the scenarios. The proposed method decomposes the\noptimization of the secure MIMO-NOMA channel into a set of simpler problems,\nincluding multicast, point-to-point, and wiretap MIMO problems, corresponding\nto the three basic messages: multicast, private/unicast, and confidential\nmessages. We then leverage existing solutions to design signaling for the above\nproblems such that the messages are transmitted with high security and\nreliability. Numerical results illustrate the efficacy of the proposed\ncovariance matrix design in secure MIMO-NOMA transmission. The proposed method\nalso outperforms existing solutions, when applicable.\nIn the case of no multicast messages, we also reformulate the nonconvex\nproblem into weighted sum rate (WSR) maximization problems by applying the\nblock successive maximization method and generalizing the zero duality gap. The\ntwo methods have their advantages and limitations. Power splitting is a general\ntool that can be applied to the MIMO-NOMA with any combination of the three\nmessages (multicast, private, and confidential) whereas WSR maximization shows\ngreater potential for secure MIMO-NOMA communication without multicasting. In\nsuch cases, WSR maximization provides a slightly better rate than the power\nsplitting method.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Yue Qi",
      "Mojtaba Vaezi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.12166"
  },
  {
    "id": "arXiv:2112.12171",
    "title": "Regularized boundary element/finite element coupling for a nonlinear  interface problem with nonmonotone set-valued transmission conditions",
    "abstract": "For the first time, a nonlinear interface problem on an unbounded domain with\nnonmonotone set-valued transmission conditions is analyzed. The investigated\nproblem involves a nonlinear monotone partial differential equation in the\ninterior domain and the Laplacian in the exterior domain. Such a scalar\ninterface problem models nonmonotone frictional contact of elastic infinite\nmedia. The variational formulation of the interface problem leads to a\nhemivariational inequality, which lives on the unbounded domain, and so cannot\nbe treated numerically in a direct way. By boundary integral methods the\nproblem is transformed and a novel hemivariational inequality (HVI) is obtained\nthat lives on the interior domain and on the coupling boundary, only. Thus for\ndiscretization the coupling of finite elements and boundary elements is the\nmethod of choice. In addition smoothing techniques of nondifferentiable\noptimization are adapted and the nonsmooth part in the HVI is regularized. Thus\nwe reduce the original variational problem to a finite dimensional problem that\ncan be solved by standard optimization tools. We establish not only convergence\nresults for the total approximation procedure, but also an asymptotic error\nestimate for the regularized HVI.",
    "descriptor": "",
    "authors": [
      "J. Gwinner",
      "N. Ovcharova"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12171"
  },
  {
    "id": "arXiv:2112.12175",
    "title": "Recur, Attend or Convolve? Frame Dependency Modeling Matters for  Cross-Domain Robustness in Action Recognition",
    "abstract": "Most action recognition models today are highly parameterized, and evaluated\non datasets with predominantly spatially distinct classes. Previous results for\nsingle images have shown that 2D Convolutional Neural Networks (CNNs) tend to\nbe biased toward texture rather than shape for various computer vision tasks\n(Geirhos et al., 2019), reducing generalization. Taken together, this raises\nsuspicion that large video models learn spurious correlations rather than to\ntrack relevant shapes over time and infer generalizable semantics from their\nmovement. A natural way to avoid parameter explosion when learning visual\npatterns over time is to make use of recurrence across the time-axis. In this\narticle, we empirically study the cross-domain robustness for recurrent,\nattention-based and convolutional video models, respectively, to investigate\nwhether this robustness is influenced by the frame dependency modeling. Our\nnovel Temporal Shape dataset is proposed as a light-weight dataset to assess\nthe ability to generalize across temporal shapes which are not revealed from\nsingle frames. We find that when controlling for performance and layer\nstructure, recurrent models show better out-of-domain generalization ability on\nthe Temporal Shape dataset than convolution- and attention-based models.\nMoreover, our experiments indicate that convolution- and attention-based models\nexhibit more texture bias on Diving48 than recurrent models.",
    "descriptor": "",
    "authors": [
      "Sofia Broom\u00e9",
      "Ernest Pokropek",
      "Boyu Li",
      "Hedvig Kjellstr\u00f6m"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12175"
  },
  {
    "id": "arXiv:2112.12177",
    "title": "Real-Time Multi-Convex Model Predictive Control for Occlusion Free  Target Tracking",
    "abstract": "This paper proposes a Model Predictive Control (MPC) algorithm for target\ntracking amongst static and dynamic obstacles. Our main contribution lies in\nimproving the computational tractability and reliability of the underlying\nnon-convex trajectory optimization. The result is an MPC algorithm that runs\nreal-time on laptops and embedded hardware devices such as Jetson TX2. Our\napproach relies on novel reformulations for the tracking, collision, and\nocclusion constraints that induce a multi-convex structure in the resulting\ntrajectory optimization. We exploit these mathematical structures using the\nsplit Bregman Iteration technique, eventually reducing our MPC to a series of\nconvex Quadratic Programs solvable in a few milliseconds. The fast re-planning\nof our MPC allows for occlusion and collision-free tracking in complex\nenvironments even while considering a simple constant-velocity prediction for\nthe target trajectory and dynamic obstacles. We perform extensive bench-marking\nin a realistic physics engine and show that our MPC outperforms the\nstate-of-the-art algorithms in visibility, smoothness, and computation-time\nmetrics.",
    "descriptor": "",
    "authors": [
      "Houman Masnavi",
      "Vivek Adajania",
      "Karl Kruusamae",
      "Arun Kumar Singh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.12177"
  },
  {
    "id": "arXiv:2112.12180",
    "title": "Multimodal Personality Recognition using Cross-Attention Transformer and  Behaviour Encoding",
    "abstract": "Personality computing and affective computing have gained recent interest in\nmany research areas. The datasets for the task generally have multiple\nmodalities like video, audio, language and bio-signals. In this paper, we\npropose a flexible model for the task which exploits all available data. The\ntask involves complex relations and to avoid using a large model for video\nprocessing specifically, we propose the use of behaviour encoding which boosts\nperformance with minimal change to the model. Cross-attention using\ntransformers has become popular in recent times and is utilised for fusion of\ndifferent modalities. Since long term relations may exist, breaking the input\ninto chunks is not desirable, thus the proposed model processes the entire\ninput together. Our experiments show the importance of each of the above\ncontributions",
    "descriptor": "\nComments: Preprint. Final paper accepted at the 17th International Conference on Computer Vision Theory and Applications, VISAPP 2021, Virtual, February 6-8, 2022. 8 pages\n",
    "authors": [
      "Tanay Agrawal",
      "Dhruv Agarwal",
      "Michal Balazia",
      "Neelabh Sinha",
      "Francois Bremond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12180"
  },
  {
    "id": "arXiv:2112.12181",
    "title": "Simple and near-optimal algorithms for hidden stratification and  multi-group learning",
    "abstract": "Multi-group agnostic learning is a formal learning criterion that is\nconcerned with the conditional risks of predictors within subgroups of a\npopulation. The criterion addresses recent practical concerns such as subgroup\nfairness and hidden stratification. This paper studies the structure of\nsolutions to the multi-group learning problem, and provides simple and\nnear-optimal algorithms for the learning problem.",
    "descriptor": "",
    "authors": [
      "Christopher Tosh",
      "Daniel Hsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.12181"
  },
  {
    "id": "arXiv:2112.12182",
    "title": "Fine-grained Multi-Modal Self-Supervised Learning",
    "abstract": "Multi-Modal Self-Supervised Learning from videos has been shown to improve\nmodel's performance on various downstream tasks. However, such Self-Supervised\npre-training requires large batch sizes and a large amount of computation\nresources due to the noise present in the uncurated data. This is partly due to\nthe fact that the prevalent training scheme is trained on coarse-grained\nsetting, in which vectors representing the whole video clips or natural\nlanguage sentences are used for computing similarity. Such scheme makes\ntraining noisy as part of the video clips can be totally not correlated with\nthe other-modality input such as text description. In this paper, we propose a\nfine-grained multi-modal self-supervised training scheme that computes the\nsimilarity between embeddings at finer-scale (such as individual feature map\nembeddings and embeddings of phrases), and uses attention mechanisms to reduce\nnoisy pairs' weighting in the loss function. We show that with the proposed\npre-training scheme, we can train smaller models, with smaller batch-size and\nmuch less computational resources to achieve downstream tasks performances\ncomparable to State-Of-The-Art, for tasks including action recognition and\ntext-image retrievals.",
    "descriptor": "\nComments: Accepted at BMVC 2021\n",
    "authors": [
      "Duo Wang",
      "Salah Karout"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12182"
  },
  {
    "id": "arXiv:2112.12191",
    "title": "Judging a book by its cover: Predicting the marginal impact of title on  Reddit post popularity",
    "abstract": "Several factors influence the popularity of content on social media,\nincluding the what, when, and who of a post. Of these factors, the what and\nwhen of content are easiest to customize in order to maximize viewership and\nreach. Further, the title of a post (part of the what) is the easiest to\ntailor, compared to the post's body, which is often fixed. So, in this paper,\nwe assess the impact of a post's title on its popularity while controlling for\nthe time of posting (the when) by proposing an interpretable attention-based\nmodel. Our approach achieves state-of-the-art performance in predicting the\npopularity of posts on multiple online communities of various sizes, topics,\nand formats while still being parsimonious. Interpretation of our model's\nattention weights sheds light on the heterogeneous patterns in how the specific\nwords in a post's title shape its popularity across different communities. Our\nresults highlight the power of sentiment alignment, personal storytelling, and\neven personality politics in propelling content to virality.",
    "descriptor": "\nComments: 11 pages. Accepted for publication at ICWSM 2022\n",
    "authors": [
      "Evan Weissburg",
      "Arya Kumar",
      "Paramveer Dhillon"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.12191"
  },
  {
    "id": "arXiv:2112.12193",
    "title": "Improved 2D Keypoint Detection in Out-of-Balance and Fall Situations --  combining input rotations and a kinematic model",
    "abstract": "Injury analysis may be one of the most beneficial applications of deep\nlearning based human pose estimation. To facilitate further research on this\ntopic, we provide an injury specific 2D dataset for alpine skiing, covering in\ntotal 533 images. We further propose a post processing routine, that combines\nrotational information with a simple kinematic model. We could improve\ndetection results in fall situations by up to 21% regarding the PCK@0.2 metric.",
    "descriptor": "\nComments: extended abstract, 4 pages, 3 figures, 2 tables\n",
    "authors": [
      "Michael Zw\u00f6lfer",
      "Dieter Heinrich",
      "Kurt Schindelwig",
      "Bastian Wandt",
      "Helge Rhodin",
      "Joerg Spoerri",
      "Werner Nachbauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12193"
  },
  {
    "id": "arXiv:2112.12197",
    "title": "Computable Model Discovery and High-Level-Programming Approximations to  Algorithmic Complexity",
    "abstract": "Motivated by algorithmic information theory, the problem of program discovery\ncan help find candidates of underlying generative mechanisms of natural and\nartificial phenomena. The uncomputability of such inverse problem, however,\nsignificantly restricts a wider application of exhaustive methods. Here we\npresent a proof of concept of an approach based on IMP, a high-level imperative\nprogramming language. Its main advantage is that conceptually complex\ncomputational routines are more succinctly expressed, unlike lower-level models\nsuch as Turing machines or cellular automata. We investigate if a more\nexpressive higher-level programming language can be more efficient at\ngenerating approximations to algorithmic complexity of recursive functions,\noften of particular mathematical interest.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Vladimir Lemusa",
      "Eduardo Acu\u00f1a",
      "V\u00edctor Zamora",
      "Francisco Hernandez-Quiroz",
      "Hector Zenil"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.12197"
  },
  {
    "id": "arXiv:2112.12205",
    "title": "Design guidelines for narrative maps in sensemaking tasks",
    "abstract": "Narrative sensemaking is a fundamental process to understand sequential\ninformation. Narrative maps are a visual representation framework that can aid\nanalysts in their narrative sensemaking process. Narrative maps allow analysts\nto understand the big picture of a narrative, uncover new relationships between\nevents, and model the connection between storylines. We seek to understand how\nanalysts create and use narrative maps in order to obtain design guidelines for\nan interactive visualization tool for narrative maps that can aid analysts in\nnarrative sensemaking. We perform two experiments with a data set of news\narticles. The insights extracted from our studies can be used to design\nnarrative maps, extraction algorithms, and visual analytics tools to support\nthe narrative sensemaking process. The contributions of this paper are\nthree-fold: (1) an analysis of how analysts construct narrative maps; (2) a\nuser evaluation of specific narrative map features; and (3) design guidelines\nfor narrative maps. Our findings suggest ways for designing narrative maps and\nextraction algorithms, as well as providing insights towards useful\ninteractions. We discuss these insights and design guidelines and reflect on\nthe potential challenges involved. As key highlights, we find that narrative\nmaps should avoid redundant connections that can be inferred by using the\ntransitive property of event connections, reducing the overall complexity of\nthe map. Moreover, narrative maps should use multiple types of cognitive\nconnections between events such as topical and causal connections, as this\nemulates the strategies that analysts use in the narrative sensemaking process.",
    "descriptor": "\nComments: Accepted paper in SAGE Information Visualization Journal, 20 pages, 8 tables, 9 figures. arXiv admin note: text overlap with arXiv:2108.06035\n",
    "authors": [
      "Brian Felipe Keith Norambuena",
      "Tanushree Mitra",
      "Chris North"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.12205"
  },
  {
    "id": "arXiv:2112.12210",
    "title": "ProBF: Learning Probabilistic Safety Certificates with Barrier Functions",
    "abstract": "Safety-critical applications require controllers/policies that can guarantee\nsafety with high confidence. The control barrier function is a useful tool to\nguarantee safety if we have access to the ground-truth system dynamics. In\npractice, we have inaccurate knowledge of the system dynamics, which can lead\nto unsafe behaviors due to unmodeled residual dynamics. Learning the residual\ndynamics with deterministic machine learning models can prevent the unsafe\nbehavior but can fail when the predictions are imperfect. In this situation, a\nprobabilistic learning method that reasons about the uncertainty of its\npredictions can help provide robust safety margins. In this work, we use a\nGaussian process to model the projection of the residual dynamics onto a\ncontrol barrier function. We propose a novel optimization procedure to generate\nsafe controls that can guarantee safety with high probability. The safety\nfilter is provided with the ability to reason about the uncertainty of the\npredictions from the GP. We show the efficacy of this method through\nexperiments on Segway and Quadrotor simulations. Our proposed probabilistic\napproach is able to reduce the number of safety violations significantly as\ncompared to the deterministic approach with a neural network.",
    "descriptor": "\nComments: Presented at NeurIPS 2021 workshop - Safe and Robust Control of Uncertain Systems\n",
    "authors": [
      "Sulin Liu",
      "Athindran Ramesh Kumar",
      "Jaime F. Fisac",
      "Ryan P. Adams",
      "Peter J. Ramadge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12210"
  },
  {
    "id": "arXiv:2112.12218",
    "title": "Maximum Entropy on Erroneous Predictions (MEEP): Improving model  calibration for medical image segmentation",
    "abstract": "Modern deep neural networks have achieved remarkable progress in medical\nimage segmentation tasks. However, it has recently been observed that they tend\nto produce overconfident estimates, even in situations of high uncertainty,\nleading to poorly calibrated and unreliable models. In this work we introduce\nMaximum Entropy on Erroneous Predictions (MEEP), a training strategy for\nsegmentation networks which selectively penalizes overconfident predictions,\nfocusing only on misclassified pixels. In particular, we design a\nregularization term that encourages high entropy posteriors for wrong\npredictions, increasing the network uncertainty in complex scenarios. Our\nmethod is agnostic to the neural architecture, does not increase model\ncomplexity and can be coupled with multiple segmentation loss functions. We\nbenchmark the proposed strategy in two challenging medical image segmentation\ntasks: white matter hyperintensity lesions in magnetic resonance images (MRI)\nof the brain, and atrial segmentation in cardiac MRI. The experimental results\ndemonstrate that coupling MEEP with standard segmentation losses leads to\nimprovements not only in terms of model calibration, but also in segmentation\nquality.",
    "descriptor": "",
    "authors": [
      "Agostina Larrazabal",
      "Cesar Martinez",
      "Jose Dolz",
      "Enzo Ferrante"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12218"
  },
  {
    "id": "arXiv:2112.12219",
    "title": "MC-DGCNN: A Novel DNN Architecture for Multi-Category Point Set  Classification",
    "abstract": "Point set classification aims to build a representation learning model that\ndistinguishes between spatial and categorical configurations of point set data.\nThis problem is societally important since in many applications domains such as\nimmunology, and microbial ecology. This problem is challenging since the\ninteractions between different categories of points are not always equal; as a\nresult, the representation learning model must selectively learn the most\nrelevant multi-categorical relationships. The related works are limited (1) in\nlearning the importance of different multi-categorical relationships,\nespecially for high-order interactions, and (2) do not fully exploit the\nspatial distribution of points beyond simply measuring relative distance or\napplying a feed-forward neural network to coordinates. To overcome these\nlimitations, we leverage the dynamic graph convolutional neural network (DGCNN)\narchitecture to design a novel multi-category DGCNN (MC-DGCNN), contributing\nlocation representation and point pair attention layers for multi-categorical\npoint set classification. MC-DGCNN has the ability to identify the categorical\nimportance of each point pair and extends this to N-way spatial relationships,\nwhile still preserving all the properties and benefits of DGCNN (e.g.,\ndifferentiability). Experimental results show that the proposed architecture is\ncomputationally efficient and significantly outperforms current deep learning\narchitectures on real-world datasets.",
    "descriptor": "",
    "authors": [
      "Majid Farhadloo",
      "Carl Molnar",
      "Gaoxiang Luo",
      "Yan Li",
      "Shashi Shekhar",
      "Rachel L. Maus",
      "Svetomir N. Markovic",
      "Raymond Moore",
      "Alexey Leontovich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12219"
  },
  {
    "id": "arXiv:2112.12224",
    "title": "Evolution and trade-off dynamics of functional load",
    "abstract": "Function Load (FL) quantifies the contributions by phonological contrasts to\ndistinctions made across the lexicon. Previous research has linked particularly\nlow values of FL to sound change. Here we broaden the scope of enquiry into FL,\nto its evolution at all values. We apply phylogenetic methods to examine the\ndiachronic evolution of FL across 90 languages of the Pama-Nyungan (PN) family\nof Australia. We find a high degree of phylogenetic signal in FL. Though\nphylogenetic signal has been reported for phonological structures, such as\nphonotactics, its detection in measures of phonological function is novel. We\nalso find a significant, negative correlation between the FL of vowel length\nand of the following consonant, that is, a deep-time historical trade-off\ndynamic, which we relate to known allophony in modern PN languages and\ncompensatory sound changes in their past. The finding reveals a historical\ndynamic, similar to transphonologization, which we characterize as a flow of\ncontrastiveness between subsystems of the phonology. Recurring across a\nlanguage family which spans a whole continent and many millennia of time depth,\nour finding provides one of the most compelling examples yet of Sapir's 'drift'\nhypothesis, of non-accidentally parallel development in historically related\nlanguages.",
    "descriptor": "",
    "authors": [
      "Erich Round",
      "Rikker Dockum",
      "Robin J. Ryder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.12224"
  },
  {
    "id": "arXiv:2112.12228",
    "title": "Direct Behavior Specification via Constrained Reinforcement Learning",
    "abstract": "The standard formulation of Reinforcement Learning lacks a practical way of\nspecifying what are admissible and forbidden behaviors. Most often,\npractitioners go about the task of behavior specification by manually\nengineering the reward function, a counter-intuitive process that requires\nseveral iterations and is prone to reward hacking by the agent. In this work,\nwe argue that constrained RL, which has almost exclusively been used for safe\nRL, also has the potential to significantly reduce the amount of work spent for\nreward specification in applied Reinforcement Learning projects. To this end,\nwe propose to specify behavioral preferences in the CMDP framework and to use\nLagrangian methods, which seek to solve a min-max problem between the agent's\npolicy and the Lagrangian multipliers, to automatically weigh each of the\nbehavioral constraints. Specifically, we investigate how CMDPs can be adapted\nin order to solve goal-based tasks while adhering to a set of behavioral\nconstraints and propose modifications to the SAC-Lagrangian algorithm to handle\nthe challenging case of several constraints. We evaluate this framework on a\nset of continuous control tasks relevant to the application of Reinforcement\nLearning for NPC design in video games.",
    "descriptor": "",
    "authors": [
      "Julien Roy",
      "Roger Girgis",
      "Joshua Romoff",
      "Pierre-Luc Bacon",
      "Christopher Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12228"
  },
  {
    "id": "arXiv:2112.12229",
    "title": "Data-driven Distributed and Localized Model Predictive Control",
    "abstract": "Motivated by large-scale but computationally constrained settings, e.g., the\nInternet of Things, we present a novel data-driven distributed control\nalgorithm that is synthesized directly from trajectory data. Our method,\ndata-driven Distributed and Localized Model Predictive Control (D$^3$LMPC),\nbuilds upon the data-driven System Level Synthesis (SLS) framework, which\nallows one to parameterize \\emph{closed-loop} system responses directly from\ncollected open-loop trajectories. The resulting model-predictive controller can\nbe implemented with distributed computation and only local information sharing.\nBy imposing locality constraints on the system response, we show that the\namount of data needed for our synthesis problem is independent of the size of\nthe global system. Moreover, we show that our algorithm enjoys theoretical\nguarantees for recursive feasibility and asymptotic stability. Finally, we also\ndemonstrate the optimality and scalability of our algorithm in a simulation\nexperiment.",
    "descriptor": "",
    "authors": [
      "Carmen Amo Alonso",
      "Fengjun Yang",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.12229"
  },
  {
    "id": "arXiv:2112.12232",
    "title": "Electromagnetic Side-Channel Attack Resilience against PRESENT  Lightweight Block Cipher",
    "abstract": "Lightweight cryptography is a novel diversion from conventional cryptography\nthat targets internet-of-things (IoT) platform due to resource constraints. In\ncomparison, it offers smaller cryptographic primitives such as shorter key\nsizes, block sizes and lesser energy drainage. The main focus can be seen in\nalgorithm developments in this emerging subject. Thus, verification is carried\nout based upon theoretical (mathematical) proofs mostly. Among the few\navailable side-channel analysis studies found in literature, the highest\npercentage is taken by power attacks. PRESENT is a promising lightweight block\ncipher to be included in IoT devices in the near future. Thus, the emphasis of\nthis paper is on lightweight cryptology, and our investigation shows\nunavailability of a correlation electromagnetic analysis (CEMA) of it. Hence,\nin an effort to fill in this research gap, we opted to investigate the\ncapabilities of CEMA against the PRESENT algorithm. This work aims to determine\nthe probability of secret key leakage with a minimum number of electromagnetic\n(EM) waveforms possible. The process initially started from a simple EM\nanalysis (SEMA) and gradually enhanced up to a CEMA. This paper presents our\nmethodology in attack modelling, current results that indicate a probability of\nleaking seven bytes of the key and upcoming plans for optimisation. In\naddition, introductions to lightweight cryptanalysis and theories of EMA are\nalso included.",
    "descriptor": "",
    "authors": [
      "Nilupulee A. Gunathilake",
      "Ahmed Al-Dubai",
      "William J. Buchanan",
      "Owen Lo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.12232"
  },
  {
    "id": "arXiv:2112.12240",
    "title": "A review of data-driven short-term voltage stability assessment of power  systems: Concept, principle, and challenges",
    "abstract": "With the rapid growth of power market reform and power demand, the power\ntransmission capacity of a power grid is approaching its limit, and the secure\nand stable operation of power systems becomes increasingly important. In\nparticular, in modern power grids, the proportion of dynamic loads with fast\nrecovery characteristics such as air conditioners, refrigerators, and\nindustrial motors is increasing. As well as the increasing proportion of\ndifferent forms of renewable energy in power systems. Therefore, short-term\nvoltage stability (STVS) of power systems cannot be ignored. This article\ncomprehensively sorts out the STVS problems of power systems from the\nperspective of data-driven methods and discusses existing challenges.",
    "descriptor": "\nComments: Accepted by Mathematical Problems in Engineering\n",
    "authors": [
      "Jiting Cao",
      "Meng Zhang",
      "Yang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.12240"
  },
  {
    "id": "arXiv:2112.12245",
    "title": "Combinations of Adaptive Filters",
    "abstract": "Adaptive filters are at the core of many signal processing applications,\nranging from acoustic noise supression to echo cancelation, array beamforming,\nchannel equalization, to more recent sensor network applications in\nsurveillance, target localization, and tracking. A trending approach in this\ndirection is to recur to in-network distributed processing in which individual\nnodes implement adaptation rules and diffuse their estimation to the network.\nWhen the a priori knowledge about the filtering scenario is limited or\nimprecise, selecting the most adequate filter structure and adjusting its\nparameters becomes a challenging task, and erroneous choices can lead to\ninadequate performance. To address this difficulty, one useful approach is to\nrely on combinations of adaptive structures.\nThe combination of adaptive filters exploits to some extent the same divide\nand conquer principle that has also been successfully exploited by the\nmachine-learning community (e.g., in bagging or boosting). In particular, the\nproblem of combining the outputs of several learning algorithms (mixture of\nexperts) has been studied in the computational learning field under a different\nperspective: rather than studying the expected performance of the mixture,\ndeterministic bounds are derived that apply to individual sequences and,\ntherefore, reflect worst-case scenarios. These bounds require assumptions\ndifferent from the ones typically used in adaptive filtering, which is the\nemphasis of this overview article. We review the key ideas and principles\nbehind these combination schemes, with emphasis on design rules. We also\nillustrate their performance with a variety of examples.",
    "descriptor": "",
    "authors": [
      "Jer\u00f3nimo Arenas-Garc\u00eda",
      "Luis A. Azpicueta-Ruiz",
      "Magno T.M. Silva",
      "Vitor H. Nascimento",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12245"
  },
  {
    "id": "arXiv:2112.12248",
    "title": "Safety assurance of an industrial robotic control system using  hardware/software co-verification",
    "abstract": "As a general trend in industrial robotics, an increasing number of safety\nfunctions are being developed or re-engineered to be handled in software rather\nthan by physical hardware such as safety relays or interlock circuits. This\ntrend reinforces the importance of supplementing traditional, input-based\ntesting and quality procedures which are widely used in industry today, with\nformal verification and model-checking methods. To this end, this paper focuses\non a representative safety-critical system in an ABB industrial paint robot,\nnamely the High-Voltage electrostatic Control system (HVC). The practical\nconvergence of the high-voltage produced by the HVC, essential for safe\noperation, is formally verified using a novel and general co-verification\nframework where hardware and software models are related via platform mappings.\nThis approach enables the pragmatic combination of highly diverse and\nspecialised tools. The paper's main contribution includes details on how\nhardware abstraction and verification results can be transferred between tools\nin order to verify system-level safety properties. It is noteworthy that the\nHVC application considered in this paper has a rather generic form of a\nfeedback controller. Hence, the co-verification framework and experiences\nreported here are also highly relevant for any cyber-physical system tracking a\nsetpoint reference.",
    "descriptor": "",
    "authors": [
      "Yvonne Murray",
      "Martin Sirev\u00e5g",
      "Pedro Ribeiro",
      "David A. Anisi",
      "Morten Mossige"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2112.12248"
  },
  {
    "id": "arXiv:2112.12249",
    "title": "Regularized Multivariate Analysis Framework for Interpretable  High-Dimensional Variable Selection",
    "abstract": "Multivariate Analysis (MVA) comprises a family of well-known methods for\nfeature extraction which exploit correlations among input variables\nrepresenting the data. One important property that is enjoyed by most such\nmethods is uncorrelation among the extracted features. Recently, regularized\nversions of MVA methods have appeared in the literature, mainly with the goal\nto gain interpretability of the solution. In these cases, the solutions can no\nlonger be obtained in a closed manner, and more complex optimization methods\nthat rely on the iteration of two steps are frequently used. This paper recurs\nto an alternative approach to solve efficiently this iterative problem. The\nmain novelty of this approach lies in preserving several properties of the\noriginal methods, most notably the uncorrelation of the extracted features.\nUnder this framework, we propose a novel method that takes advantage of the\nl-21 norm to perform variable selection during the feature extraction process.\nExperimental results over different problems corroborate the advantages of the\nproposed formulation in comparison to state of the art formulations.",
    "descriptor": "",
    "authors": [
      "Sergio Mu\u00f1oz-Romero",
      "Vanessa G\u00f3mez-Verdejo",
      "Jer\u00f3nimo Arenas-Garc\u00eda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12249"
  },
  {
    "id": "arXiv:2112.12251",
    "title": "ML4CO: Is GCNN All You Need? Graph Convolutional Neural Networks Produce  Strong Baselines For Combinatorial Optimization Problems, If Tuned and  Trained Properly, on Appropriate Data",
    "abstract": "The 2021 NeurIPS Machine Learning for Combinatorial Optimization (ML4CO)\ncompetition was designed with the goal of improving state-of-the-art\ncombinatorial optimization solvers by replacing key heuristic components with\nmachine learning models. The competition's main scientific question was the\nfollowing: is machine learning a viable option for improving traditional\ncombinatorial optimization solvers on specific problem distributions, when\nhistorical data is available? This was motivated by the fact that in many\npractical scenarios, the data changes only slightly between the repetitions of\na combinatorial optimization problem, and this is an area where machine\nlearning models are particularly powerful at. This paper summarizes the\nsolution and lessons learned by the Huawei EI-OROAS team in the dual task of\nthe competition. The submission of our team achieved the second place in the\nfinal ranking, with a very close distance to the first spot. In addition, our\nsolution was ranked first consistently for several weekly leaderboard updates\nbefore the final evaluation. We provide insights gained from a large number of\nexperiments, and argue that a simple Graph Convolutional Neural Network (GCNNs)\ncan achieve state-of-the-art results if trained and tuned properly.",
    "descriptor": "\nComments: Runner-up in the 2021 ML4CO NeurIPS Competition\n",
    "authors": [
      "Amin Banitalebi-Dehkordi",
      "Yong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.12251"
  },
  {
    "id": "arXiv:2112.12252",
    "title": "Leveraging Synthetic Data in Object Detection on Unmanned Aerial  Vehicles",
    "abstract": "Acquiring data to train deep learning-based object detectors on Unmanned\nAerial Vehicles (UAVs) is expensive, time-consuming and may even be prohibited\nby law in specific environments. On the other hand, synthetic data is fast and\ncheap to access. In this work, we explore the potential use of synthetic data\nin object detection from UAVs across various application environments. For\nthat, we extend the open-source framework DeepGTAV to work for UAV scenarios.\nWe capture various large-scale high-resolution synthetic data sets in several\ndomains to demonstrate their use in real-world object detection from UAVs by\nanalyzing multiple training strategies across several models. Furthermore, we\nanalyze several different data generation and sampling parameters to provide\nactionable engineering advice for further scientific research. The DeepGTAV\nframework is available at https://git.io/Jyf5j.",
    "descriptor": "\nComments: The first two authors contributed equally. Github repository will be made public soon\n",
    "authors": [
      "Benjamin Kiefer",
      "David Ott",
      "Andreas Zell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12252"
  },
  {
    "id": "arXiv:2112.12255",
    "title": "Entropy-Regularized Partially Observed Markov Decision Processes",
    "abstract": "We investigate partially observed Markov decision processes (POMDPs) with\ncost functions regularized by entropy terms describing state, observation, and\ncontrol uncertainty. Standard POMDP techniques are shown to offer bounded-error\nsolutions to these entropy-regularized POMDPs, with exact solutions when the\nregularization involves the joint entropy of the state, observation, and\ncontrol trajectories. Our joint-entropy result is particularly surprising since\nit constitutes a novel, tractable formulation of active state estimation.",
    "descriptor": "\nComments: 20 pages, 2 figures, submitted\n",
    "authors": [
      "Timothy L. Molloy",
      "Girish N. Nair"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.12255"
  },
  {
    "id": "arXiv:2112.12262",
    "title": "Morphological classifiers",
    "abstract": "This work proposes a new type of classifier called Morphological Classifier\n(MC). MCs aggregate concepts from mathematical morphology and supervised\nlearning. The outcomes of this aggregation are classifiers that may preserve\nshape characteristics of classes, subject to the choice of a stopping criterion\nand structuring element. MCs are fundamentally based on set theory, and their\nclassification model can be a mathematical set itself. Two types of\nmorphological classifiers are proposed in the current work, namely,\nMorphological k-NN (MkNN) and Morphological Dilation Classifier (MDC), which\ndemonstrate the feasibility of the approach. This work provides evidence\nregarding the advantages of MCs, e.g., very fast classification times as well\nas competitive accuracy rates. The performance of MkNN and MDC was tested using\np -dimensional datasets. MCs tied or outperformed 14 well established\nclassifiers in 5 out of 8 datasets. In all occasions, the obtained accuracies\nwere higher than the average accuracy obtained with all classifiers. Moreover,\nthe proposed implementations utilize the power of the Graphics Processing Units\n(GPUs) to speed up processing.",
    "descriptor": "\nComments: Pattern Recognition, 2018\n",
    "authors": [
      "\u00c9. O. Rodrigues",
      "A. Conci",
      "P. Liatsis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.12262"
  },
  {
    "id": "arXiv:2112.12263",
    "title": "Crash Data Augmentation Using Conditional Generative Adversarial  Networks (CGAN) for Improving Safety Performance Functions",
    "abstract": "In this paper, we present a crash frequency data augmentation method based on\nConditional Generative Adversarial Networks to improve crash frequency models.\nThe proposed method is evaluated by comparing the performance of Base SPFs\n(developed using original data) and Augmented SPFs (developed using original\ndata plus synthesised data) in terms of hotspot identification performance,\nmodel prediction accuracy, and dispersion parameter estimation accuracy. The\nexperiments are conducted using simulated and real-world crash data sets. The\nresults indicate that the synthesised crash data by CGAN have the same\ndistribution as the original data and the Augmented SPFs outperforms Base SPFs\nin almost all aspects especially when the dispersion parameter is low.",
    "descriptor": "",
    "authors": [
      "Mohammad Zarei",
      "Bruce Hellinga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.12263"
  },
  {
    "id": "arXiv:2112.12268",
    "title": "An algebraic attack on stream ciphers with application to nonlinear  filter generators and WG-PRNG",
    "abstract": "In this paper, we propose a new algebraic attack on stream ciphers. Starting\nfrom the well-known attack due to Courtois and Meier, we design an attack\nespecially effective against nonlinear filter generators. We test it on two toy\nstream ciphers and we show that the level of security of one of stream ciphers\nsubmitted to the NIST competition on Lightweight Cryptography, WG-PRNG, is less\nthan that stated before now.",
    "descriptor": "",
    "authors": [
      "Carla Mascia",
      "Enrico Piccione",
      "Massimiliano Sala"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2112.12268"
  },
  {
    "id": "arXiv:2112.12272",
    "title": "Human Activity Recognition on wrist-worn accelerometers using  self-supervised neural networks",
    "abstract": "Measures of Activity of Daily Living (ADL) are an important indicator of\noverall health but difficult to measure in-clinic. Automated and accurate human\nactivity recognition (HAR) using wrist-worn accelerometers enables practical\nand cost efficient remote monitoring of ADL. Key obstacles in developing high\nquality HAR is the lack of large labeled datasets and the performance loss when\napplying models trained on small curated datasets to the continuous stream of\nheterogeneous data in real-life. In this work we design a self-supervised\nlearning paradigm to create a robust representation of accelerometer data that\ncan generalize across devices and subjects. We demonstrate that this\nrepresentation can separate activities of daily living and achieve strong HAR\naccuracy (on multiple benchmark datasets) using very few labels. We also\npropose a segmentation algorithm which can identify segments of salient\nactivity and boost HAR accuracy on continuous real-life data.",
    "descriptor": "",
    "authors": [
      "Niranjan Sridhar",
      "Lance Myers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12272"
  },
  {
    "id": "arXiv:2112.12273",
    "title": "Perceptual Evaluation of 360 Audiovisual Quality and Machine Learning  Predictions",
    "abstract": "In an earlier study, we gathered perceptual evaluations of the audio, video,\nand audiovisual quality for 360 audiovisual content. This paper investigates\nperceived audiovisual quality prediction based on objective quality metrics and\nsubjective scores of 360 video and spatial audio content. Thirteen objective\nvideo quality metrics and three objective audio quality metrics were evaluated\nfor five stimuli for each coding parameter. Four regression-based machine\nlearning models were trained and tested here, i.e., multiple linear regression,\ndecision tree, random forest, and support vector machine. Each model was\nconstructed using a combination of audio and video quality metrics and two\ncross-validation methods (k-Fold and Leave-One-Out) were investigated and\nproduced 312 predictive models. The results indicate that the model based on\nthe evaluation of VMAF and AMBIQUAL is better than other combinations of\naudio-video quality metric. In this study, support vector machine provides\nhigher performance using k-Fold (PCC = 0.909, SROCC = 0.914, and RMSE = 0.416).\nThese results can provide insights for the design of multimedia quality metrics\nand the development of predictive models for audiovisual omnidirectional media.",
    "descriptor": "",
    "authors": [
      "Randy Frans Fela",
      "Nick Zacharov",
      "S\u00f8ren Forchhammer"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.12273"
  },
  {
    "id": "arXiv:2112.12275",
    "title": "Algorithmic Probability of Large Datasets and the Simplicity Bubble  Problem in Machine Learning",
    "abstract": "When mining large datasets in order to predict new data, limitations of the\nprinciples behind statistical machine learning pose a serious challenge not\nonly to the Big Data deluge, but also to the traditional assumptions that data\ngenerating processes are biased toward low algorithmic complexity. Even when\none assumes an underlying algorithmic-informational bias toward simplicity in\nfinite dataset generators, we show that fully automated, with or without access\nto pseudo-random generators, computable learning algorithms, in particular\nthose of statistical nature used in current approaches to machine learning\n(including deep learning), can always be deceived, naturally or artificially,\nby sufficiently large datasets. In particular, we demonstrate that, for every\nfinite learning algorithm, there is a sufficiently large dataset size above\nwhich the algorithmic probability of an unpredictable deceiver is an upper\nbound (up to a multiplicative constant that only depends on the learning\nalgorithm) for the algorithmic probability of any other larger dataset. In\nother words, very large and complex datasets are as likely to deceive learning\nalgorithms into a \"simplicity bubble\" as any other particular dataset. These\ndeceiving datasets guarantee that any prediction will diverge from the\nhigh-algorithmic-complexity globally optimal solution while converging toward\nthe low-algorithmic-complexity locally optimal solution. We discuss the\nframework and empirical conditions for circumventing this deceptive phenomenon,\nmoving away from statistical machine learning towards a stronger type of\nmachine learning based on, or motivated by, the intrinsic power of algorithmic\ninformation theory and computability theory.",
    "descriptor": "",
    "authors": [
      "Felipe S. Abrah\u00e3o",
      "Hector Zenil",
      "Fabio Porto",
      "Klaus Wehmuth"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.12275"
  },
  {
    "id": "arXiv:2112.12279",
    "title": "Randomize the Future: Asymptotically Optimal Locally Private Frequency  Estimation Protocol for Longitudinal Data",
    "abstract": "Longitudinal data tracking under Local Differential Privacy (LDP) is a\nchallenging task. Baseline solutions that repeatedly invoke a protocol designed\nfor one-time computation lead to linear decay in the privacy or utility\nguarantee with respect to the number of computations. To avoid this, the recent\napproach of Erlingsson et al. (2020) exploits the potential sparsity of user\ndata that changes only infrequently. Their protocol targets the fundamental\nproblem of frequency estimation protocol for longitudinal binary data, with\n$\\ell_\\infty$ error of $O ( (1 / \\epsilon) \\cdot (\\log d)^{3 / 2} \\cdot k \\cdot\n\\sqrt{ n \\cdot \\log ( d / \\beta ) } )$, where $\\epsilon$ is the privacy budget,\n$d$ is the number of time periods, $k$ is the maximum number of changes of user\ndata, and $\\beta$ is the failure probability. Notably, the error bound scales\npolylogarithmically with $d$, but linearly with $k$.\nIn this paper, we break through the linear dependence on $k$ in the\nestimation error. Our new protocol has error $O ( (1 / \\epsilon) \\cdot (\\log d)\n\\cdot \\sqrt{ k \\cdot n \\cdot \\log ( d / \\beta ) } )$, matching the lower bound\nup to a logarithmic factor. The protocol is an online one, that outputs an\nestimate at each time period. The key breakthrough is a new randomizer for\nsequential data, FutureRand, with two key features. The first is a composition\nstrategy that correlates the noise across the non-zero elements of the\nsequence. The second is a pre-computation technique which, by exploiting the\nsymmetry of input space, enables the randomizer to output the results on the\nfly, without knowing future inputs. Our protocol closes the error gap between\nexisting online and offline algorithms.",
    "descriptor": "",
    "authors": [
      "Olga Ohrimenko",
      "Anthony Wirth",
      "Hao Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.12279"
  },
  {
    "id": "arXiv:2112.12281",
    "title": "Improving the Efficiency of Off-Policy Reinforcement Learning by  Accounting for Past Decisions",
    "abstract": "Off-policy learning from multistep returns is crucial for sample-efficient\nreinforcement learning, particularly in the experience replay setting now\ncommonly used with deep neural networks. Classically, off-policy estimation\nbias is corrected in a per-decision manner: past temporal-difference errors are\nre-weighted by the instantaneous Importance Sampling (IS) ratio (via\neligibility traces) after each action. Many important off-policy algorithms\nsuch as Tree Backup and Retrace rely on this mechanism along with differing\nprotocols for truncating (\"cutting\") the ratios (\"traces\") to counteract the\nexcessive variance of the IS estimator. Unfortunately, cutting traces on a\nper-decision basis is not necessarily efficient; once a trace has been cut\naccording to local information, the effect cannot be reversed later,\npotentially resulting in the premature truncation of estimated returns and\nslower learning. In the interest of motivating efficient off-policy algorithms,\nwe propose a multistep operator that permits arbitrary past-dependent traces.\nWe prove that our operator is convergent for policy evaluation, and for optimal\ncontrol when targeting greedy-in-the-limit policies. Our theorems establish the\nfirst convergence guarantees for many existing algorithms including Truncated\nIS, Non-Markov Retrace, and history-dependent TD($\\lambda$). Our theoretical\nresults also provide guidance for the development of new algorithms that\njointly consider multiple past decisions for better credit assignment and\nfaster learning.",
    "descriptor": "\nComments: 12 pages, 0 figures\n",
    "authors": [
      "Brett Daley",
      "Christopher Amato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12281"
  },
  {
    "id": "arXiv:2112.12284",
    "title": "A Survey on Perceptually Optimized Video Coding",
    "abstract": "Videos are developing in the trends of Ultra High Definition (UHD), High\nFrame Rate (HFR), High Dynamic Range (HDR), Wide Color Gammut (WCG) and high\nfidelity, which provide users with more realistic visual experiences. However,\nthe amount of video data increases exponentially and requires high efficiency\nvideo compression for storage and network transmission. Perceptually optimized\nvideo coding aims to exploit visual redundancies in videos so as to maximize\ncompression efficiency. In this paper, we present a systematic survey on the\nrecent advances and challenges on perceptually optimized video coding. Firstly,\nwe present problem formulation and framework of perceptually optimized video\ncoding, which includes visual perception modelling, visual quality assessment\nand perception guided coding optimization. Secondly, the recent advances on\nvisual factors, key computational visual models and quality assessment models\nare presented. Thirdly, we do systematic review on perceptual video coding\noptimizations from four key aspects, which includes perceptually optimized bit\nallocation, rate-distortion optimization, transform and quantization, filtering\nand enhancement. In each part, problem formulation, working flow, recent\nadvances, advantages and challenges are presented. Fourthly, perceptual coding\nperformance of latest coding standards and tools are experimentally analyzed.\nFinally, challenging issues and future opportunities on perceptual video coding\nare identified.",
    "descriptor": "\nComments: 34 pages, 11 figures, 5 tables, submitted to ACM Computing Surveys\n",
    "authors": [
      "Yun Zhang",
      "Linwei Zhu",
      "Gangyi Jiang",
      "Sam Kwong",
      "C.-C.Jay Kuo"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.12284"
  },
  {
    "id": "arXiv:2112.12288",
    "title": "Safety and Liveness Guarantees through Reach-Avoid Reinforcement  Learning",
    "abstract": "Reach-avoid optimal control problems, in which the system must reach certain\ngoal conditions while staying clear of unacceptable failure modes, are central\nto safety and liveness assurance for autonomous robotic systems, but their\nexact solutions are intractable for complex dynamics and environments. Recent\nsuccesses in reinforcement learning methods to approximately solve optimal\ncontrol problems with performance objectives make their application to\ncertification problems attractive; however, the Lagrange-type objective used in\nreinforcement learning is not suitable to encode temporal logic requirements.\nRecent work has shown promise in extending the reinforcement learning machinery\nto safety-type problems, whose objective is not a sum, but a minimum (or\nmaximum) over time. In this work, we generalize the reinforcement learning\nformulation to handle all optimal control problems in the reach-avoid category.\nWe derive a time-discounted reach-avoid Bellman backup with contraction mapping\nproperties and prove that the resulting reach-avoid Q-learning algorithm\nconverges under analogous conditions to the traditional Lagrange-type problem,\nyielding an arbitrarily tight conservative approximation to the reach-avoid\nset. We further demonstrate the use of this formulation with deep reinforcement\nlearning methods, retaining zero-violation guarantees by treating the\napproximate solutions as untrusted oracles in a model-predictive supervisory\ncontrol framework. We evaluate our proposed framework on a range of nonlinear\nsystems, validating the results against analytic and numerical solutions, and\nthrough Monte Carlo simulation in previously intractable problems. Our results\nopen the door to a range of learning-based methods for safe-and-live autonomous\nbehavior, with applications across robotics and automation. See\nhttps://github.com/SafeRoboticsLab/safety_rl for code and supplementary\nmaterial.",
    "descriptor": "\nComments: Accepted in Robotics: Science and Systems (RSS), 2021\n",
    "authors": [
      "Kai-Chieh Hsu",
      "Vicen\u00e7 Rubies-Royo",
      "Claire J. Tomlin",
      "Jaime F. Fisac"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.12288"
  },
  {
    "id": "arXiv:2112.12294",
    "title": "Run-of-Mine Stockyard Recovery Scheduling and Optimisation for Multiple  Reclaimers",
    "abstract": "Stockpiles are essential in the mining value chain, assisting in maximising\nvalue and production. Quality control of taken minerals from the stockpiles is\na major concern for stockpile managers where failure to meet some requirements\ncan lead to losing money. This problem was recently investigated using a single\nreclaimer, and basic assumptions. This study extends the approach to consider\nmultiple reclaimers in preparing for short and long-term deliveries. The\nengagement of multiple reclaimers complicates the problem in terms of their\ninteraction in preparing a delivery simultaneously and safety distancing of\nreclaimers. We also consider more realistic settings, such as handling\ndifferent minerals with different types of reclaimers. We propose methods that\nconstruct a solution step by step to meet precedence constraints for all\nreclaimers in the stockyard. We study various instances of the problem using\ngreedy algorithms, Ant Colony Optimisation (ACO), and propose an integrated\nlocal search method determining an efficient schedule. We fine-tune and compare\nthe algorithms and show that the ACO combined with local search can yield\nefficient solutions.",
    "descriptor": "",
    "authors": [
      "Hirad Assimi",
      "Ben Koch",
      "Chris Garcia",
      "Markus Wagner",
      "Frank Neumann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.12294"
  },
  {
    "id": "arXiv:2112.12296",
    "title": "Sub-Chain Beam for mmWave Devices: A Trade-off between Power Saving and  Beam Correspondence",
    "abstract": "Beam correspondence, or downlink-uplink (DL-UL) beam reciprocity, refers to\nthe assumption that the best beams in the DL are also the best beams in the UL.\nThis is an important assumption that allows the existing beam management\nframework in 5G to rely heavily on DL beam sweeping and avoid UL beam sweeping:\nUL beams are inferred from the measurements of the DL reference signals. Beam\ncorrespondence holds when the radio configurations are symmetric in the DL and\nUL. However, as mmWave technology matures, the DL and the UL face different\nconstraints often breaking the beam correspondence. For example, power\nconstraints may require a UE to activate only a portion of its antenna array\nfor UL transmission, while still activating the full array for DL reception.\nMeanwhile, if the UL beam with sub-array, named as sub-chain beam in this\npaper, has a similar radiation pattern as the DL beam, the beam correspondence\ncan still hold. This paper proposes methods for sub-chain beam codebook design\nto achieve a trade-off between the power saving and beam correspondence.",
    "descriptor": "\nComments: 6 pages, 7 figures, accepted by Asilomar conference 2021\n",
    "authors": [
      "Jianhua Mo",
      "Daehee Park",
      "Boon Loong Ng",
      "Vutha Va",
      "Anum Ali",
      "Chonghwa Seo",
      "Jianzhong Charlie Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.12296"
  },
  {
    "id": "arXiv:2112.12297",
    "title": "Batch Processing and Data Streaming Fourier-based Convolutional Neural  Network Accelerator",
    "abstract": "Decision-making by artificial neural networks with minimal latency is\nparamount for numerous applications such as navigation, tracking, and real-time\nmachine action systems. This requires the machine learning hardware to handle\nmultidimensional data with a high throughput. Processing convolution operations\nbeing the major computational tool for data classification tasks,\nunfortunately, follows a challenging run-time complexity scaling law. However,\nimplementing the convolution theorem homomorphically in a Fourier-optic\ndisplay-light-processor enables a non-iterative O(1) runtime complexity for\ndata inputs beyond 1,000 x 1,000 large matrices. Following this approach, here\nwe demonstrate data streaming multi-kernel image batch-processing with a\nFourier Convolutional Neural Network (FCNN) accelerator. We show image batch\nprocessing of large-scale matrices as passive 2-million dot-product\nmultiplications performed by digital light-processing modules in the Fourier\ndomain. In addition, we parallelize this optical FCNN system further by\nutilizing multiple spatio-parallel diffraction orders, thus achieving a\n98-times throughput improvement over state-of-art FCNN accelerators. The\ncomprehensive discussion of the practical challenges related to working on the\nedge of the system's capabilities highlights issues of crosstalk in the Fourier\ndomain and resolution scaling laws. Accelerating convolutions by utilizing the\nmassive parallelism in display technology brings forth a non-van Neuman-based\nmachine learning acceleration.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Zibo Hu",
      "Shurui Li",
      "Russell L.T. Schwartz",
      "Maria Solyanik-Gorgone",
      "Mario Miscuglio",
      "Puneet Gupta",
      "Volker J. Sorger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2112.12297"
  },
  {
    "id": "arXiv:2112.12298",
    "title": "Analysis of ECG data to detect Atrial Fibrillation",
    "abstract": "Atrial fibrillation(termed as AF/Afib henceforth) is a discrete and often\nrapid heart rhythm that can lead to clots near the heart. We can detect Afib by\nECG signal by the absence of p and inconsistent intervals between R waves as\nshown in fig(1). Existing methods revolve around CNN that are used to detect\nafib but most of them work with 12 point lead ECG data where in our case the\nhealth gauge watch deals with single-point ECG data. Twelve-point lead ECG data\nis more accurate than a single point. Furthermore, the health gauge watch data\nis much noisier. Implementing a model to detect Afib for the watch is a test of\nhow the CNN is changed/modified to work with real life data",
    "descriptor": "",
    "authors": [
      "Arjun Sridharkumar",
      "Sai Bhargav",
      "Rahul Guntha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.12298"
  },
  {
    "id": "arXiv:2112.12299",
    "title": "A Robust Initialization of Residual Blocks for Effective ResNet Training  without Batch Normalization",
    "abstract": "Batch Normalization is an essential component of all state-of-the-art neural\nnetworks architectures. However, since it introduces many practical issues,\nmuch recent research has been devoted to designing normalization-free\narchitectures. In this paper, we show that weights initialization is key to\ntrain ResNet-like normalization-free networks. In particular, we propose a\nslight modification to the summation operation of a block output to the skip\nconnection branch, so that the whole network is correctly initialized. We show\nthat this modified architecture achieves competitive results on CIFAR-10\nwithout further regularization nor algorithmic modifications.",
    "descriptor": "\nComments: 13 pages (2 pages of supplementary material), 8 figures, 1 table\n",
    "authors": [
      "Enrico Civitelli",
      "Alessio Sortino",
      "Matteo Lapucci",
      "Francesco Bagattini",
      "Giulio Galvan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12299"
  },
  {
    "id": "arXiv:2112.12303",
    "title": "Learning with Proper Partial Labels",
    "abstract": "Partial-label learning is a kind of weakly-supervised learning with inexact\nlabels, where for each training example, we are given a set of candidate labels\ninstead of only one true label. Recently, various approaches on partial-label\nlearning have been proposed under different generation models of candidate\nlabel sets. However, these methods require relatively strong distributional\nassumptions on the generation models. When the assumptions do not hold, the\nperformance of the methods is not guaranteed theoretically. In this paper, we\npropose the notion of properness on partial labels. We show that this proper\npartial-label learning framework includes many previous partial-label learning\nsettings as special cases. We then derive a unified unbiased estimator of the\nclassification risk. We prove that our estimator is risk-consistent by\nobtaining its estimation error bound. Finally, we validate the effectiveness of\nour algorithm through experiments.",
    "descriptor": "",
    "authors": [
      "Zhenguo Wu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12303"
  },
  {
    "id": "arXiv:2112.12306",
    "title": "Selective Multiple Power Iteration: from Tensor PCA to gradient-based  exploration of landscapes",
    "abstract": "We propose Selective Multiple Power Iterations (SMPI), a new algorithm to\naddress the important Tensor PCA problem that consists in recovering a spike\n$\\bf{v_0}^{\\otimes k}$ corrupted by a Gaussian noise tensor $\\bf{Z} \\in\n(\\mathbb{R}^n)^{\\otimes k}$ such that $\\bf{T}=\\sqrt{n} \\beta \\bf{v_0}^{\\otimes\nk} + \\bf{Z}$ where $\\beta$ is the signal-to-noise ratio (SNR). SMPI consists in\ngenerating a polynomial number of random initializations, performing a\npolynomial number of symmetrized tensor power iterations on each\ninitialization, then selecting the one that maximizes $\\langle \\bf{T},\n\\bf{v}^{\\otimes k} \\rangle$. Various numerical simulations for $k=3$ in the\nconventionally considered range $n \\leq 1000$ show that the experimental\nperformances of SMPI improve drastically upon existent algorithms and becomes\ncomparable to the theoretical optimal recovery. We show that these unexpected\nperformances are due to a powerful mechanism in which the noise plays a key\nrole for the signal recovery and that takes place at low $\\beta$. Furthermore,\nthis mechanism results from five essential features of SMPI that distinguish it\nfrom previous algorithms based on power iteration. These remarkable results may\nhave strong impact on both practical and theoretical applications of Tensor\nPCA. (i) We provide a variant of this algorithm to tackle low-rank CP tensor\ndecomposition. These proposed algorithms also outperforms existent methods even\non real data which shows a huge potential impact for practical applications.\n(ii) We present new theoretical insights on the behavior of SMPI and gradient\ndescent methods for the optimization in high-dimensional non-convex landscapes\nthat are present in various machine learning problems. (iii) We expect that\nthese results may help the discussion concerning the existence of the\nconjectured statistical-algorithmic gap.",
    "descriptor": "",
    "authors": [
      "Mohamed Ouerfelli",
      "Mohamed Tamaazousti",
      "Vincent Rivasseau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.12306"
  },
  {
    "id": "arXiv:2112.12310",
    "title": "Adversarial Attacks against Windows PE Malware Detection: A Survey of  the State-of-the-Art",
    "abstract": "The malware has been being one of the most damaging threats to computers that\nspan across multiple operating systems and various file formats. To defend\nagainst the ever-increasing and ever-evolving threats of malware, tremendous\nefforts have been made to propose a variety of malware detection methods that\nattempt to effectively and efficiently detect malware. Recent studies have\nshown that, on the one hand, existing ML and DL enable the superior detection\nof newly emerging and previously unseen malware. However, on the other hand, ML\nand DL models are inherently vulnerable to adversarial attacks in the form of\nadversarial examples, which are maliciously generated by slightly and carefully\nperturbing the legitimate inputs to confuse the targeted models. Basically,\nadversarial attacks are initially extensively studied in the domain of computer\nvision, and some quickly expanded to other domains, including NLP, speech\nrecognition and even malware detection. In this paper, we focus on malware with\nthe file format of portable executable (PE) in the family of Windows operating\nsystems, namely Windows PE malware, as a representative case to study the\nadversarial attack methods in such adversarial settings. To be specific, we\nstart by first outlining the general learning framework of Windows PE malware\ndetection based on ML/DL and subsequently highlighting three unique challenges\nof performing adversarial attacks in the context of PE malware. We then conduct\na comprehensive and systematic review to categorize the state-of-the-art\nadversarial attacks against PE malware detection, as well as corresponding\ndefenses to increase the robustness of PE malware detection. We conclude the\npaper by first presenting other related attacks against Windows PE malware\ndetection beyond the adversarial attacks and then shedding light on future\nresearch directions and opportunities.",
    "descriptor": "",
    "authors": [
      "Xiang Ling",
      "Lingfei Wu",
      "Jiangyu Zhang",
      "Zhenqing Qu",
      "Wei Deng",
      "Xiang Chen",
      "Chunming Wu",
      "Shouling Ji",
      "Tianyue Luo",
      "Jingzheng Wu",
      "Yanjun Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12310"
  },
  {
    "id": "arXiv:2112.12315",
    "title": "A Multi-Objective Degree-Based Network Anonymization Approach",
    "abstract": "Enormous amounts of data collected from social networks or other online\nplatforms are being published for the sake of statistics, marketing, and\nresearch, among other objectives. The consequent privacy and data security\nconcerns have motivated the work on degree-based data anonymization. We propose\nand study a new multi-objective anonymization approach that generalizes the\nknown degree anonymization problem and attempts at improving it as a more\nrealistic model for data security/privacy. Our suggested model guarantees a\nconvenient privacy level based on modifying the degrees in a way that respects\nsome given local restrictions, per node, such that the total modifications at\nthe global level (in the whole graph/network) are bounded by some given value.\nThe corresponding multi-objective graph realization approach is solved using\nInteger Linear Programming to obtain the best possible solutions. Our\nexperimental studies provide empirical evidence of the effectiveness of the new\napproach; by specifically showing that the introduced anonymization algorithm\nhas a negligible effect on the way nodes are clustered, thereby preserving\nvaluable network information while significantly improving data privacy.",
    "descriptor": "",
    "authors": [
      "Ola N. Halawi",
      "Faisal N. Abu-Khzam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.12315"
  },
  {
    "id": "arXiv:2112.12316",
    "title": "Signed and Unsigned Partial Information Decompositions of Continuous  Network Interactions",
    "abstract": "We investigate the partial information decomposition (PID) framework as a\ntool for edge nomination. We consider both the $I_{\\cap}^{\\text{min}}$ and\n$I_{\\cap}^{\\text{PM}}$ PIDs, from arXiv:1004.2515 and arXiv:1801.09010\nrespectively, and we both numerically and analytically investigate the utility\nof these frameworks for discovering significant edge interactions. In the\ncourse of our work, we extend both the $I_{\\cap}^{\\text{min}}$ and\n$I_{\\cap}^{\\text{PM}}$ PIDs to a general class of continuous trivariate\nsystems. Moreover, we examine how each PID apportions information into\nredundant, synergistic, and unique information atoms within the\nsource-bivariate PID framework. Both our simulation experiments and analytic\ninquiry indicate that the atoms of the $I_{\\cap}^{\\text{PM}}$ PID have a\nnon-specific sensitivity to high predictor-target mutual information,\nregardless of whether or not the predictors are truly interacting. By contrast,\nthe $I_{\\cap}^{\\text{min}}$ PID is quite specific, although simulations suggest\nthat it lacks sensitivity.",
    "descriptor": "",
    "authors": [
      "Jesse Milzman",
      "Vince Lyzinski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.12316"
  },
  {
    "id": "arXiv:2112.12318",
    "title": "Investigating Effect of Dialogue History in Multilingual Task Oriented  Dialogue Systems",
    "abstract": "While the English virtual assistants have achieved exciting performance with\nan enormous amount of training resources, the needs of non-English-speakers\nhave not been satisfied well. Up to Dec 2021, Alexa, one of the most popular\nsmart speakers around the world, is able to support 9 different languages [1],\nwhile there are thousands of languages in the world, 91 of which are spoken by\nmore than 10 million people according to statistics published in 2019 [2].\nHowever, training a virtual assistant in other languages than English is often\nmore difficult, especially for those low-resource languages. The lack of\nhigh-quality training data restricts the performance of models, resulting in\npoor user satisfaction. Therefore, we devise an efficient and effective\ntraining solution for multilingual task-orientated dialogue systems, using the\nsame dataset generation pipeline and end-to-end dialogue system architecture as\nBiToD[5], which adopted some key design choices for a minimalistic natural\nlanguage design where formal dialogue states are used in place of natural\nlanguage inputs. This reduces the room for error brought by weaker natural\nlanguage models, and ensures the model can correctly extract the essential slot\nvalues needed to perform dialogue state tracking (DST). Our goal is to reduce\nthe amount of natural language encoded at each turn, and the key parameter we\ninvestigate is the number of turns (H) to feed as history to model. We first\nexplore the turning point where increasing H begins to yield limiting returns\non the overall performance. Then we examine whether the examples a model with\nsmall H gets wrong can be categorized in a way for the model to do few-shot\nfinetuning on. Lastly, will explore the limitations of this approach, and\nwhether there is a certain type of examples that this approach will not be able\nto resolve.",
    "descriptor": "",
    "authors": [
      "Michael Sun",
      "Kaili Huang",
      "Mehrad Moradshahi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12318"
  },
  {
    "id": "arXiv:2112.12320",
    "title": "Model Selection in Batch Policy Optimization",
    "abstract": "We study the problem of model selection in batch policy optimization: given a\nfixed, partial-feedback dataset and $M$ model classes, learn a policy with\nperformance that is competitive with the policy derived from the best model\nclass. We formalize the problem in the contextual bandit setting with linear\nmodel classes by identifying three sources of error that any model selection\nalgorithm should optimally trade-off in order to be competitive: (1)\napproximation error, (2) statistical complexity, and (3) coverage. The first\ntwo sources are common in model selection for supervised learning, where\noptimally trading-off these properties is well-studied. In contrast, the third\nsource is unique to batch policy optimization and is due to dataset shift\ninherent to the setting. We first show that no batch policy optimization\nalgorithm can achieve a guarantee addressing all three simultaneously,\nrevealing a stark contrast between difficulties in batch policy optimization\nand the positive results available in supervised learning. Despite this\nnegative result, we show that relaxing any one of the three error sources\nenables the design of algorithms achieving near-oracle inequalities for the\nremaining two. We conclude with experiments demonstrating the efficacy of these\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Jonathan N. Lee",
      "George Tucker",
      "Ofir Nachum",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.12320"
  },
  {
    "id": "arXiv:2112.12321",
    "title": "Physics Constrained Flow Neural Network for Short-Timescale Predictions  in Data Communications Networks",
    "abstract": "Machine learning is gaining growing momentum in various recent models for the\ndynamic analysis of information flows in data communications networks. These\npreliminary models often rely on off-the-shelf learning models to predict from\nhistorical statistics while disregarding the physics governing the generating\nbehaviors of these flows. This paper instead introduces Flow Neural Network\n(FlowNN) to improve the feature representation with learned physical bias. This\nis implemented by an induction layer, working upon the embedding layer, to\nimpose the physics connected data correlations, and a self-supervised learning\nstrategy with stop-gradient to make the learned physics universal. For the\nshort-timescale network prediction tasks, FlowNN achieves 17% - 71% of loss\ndecrease than the state-of-the-art baselines on both synthetic and real-world\nnetworking datasets, which shows the strength of this new approach. Code will\nbe made available.",
    "descriptor": "",
    "authors": [
      "Xiangle Cheng",
      "James He",
      "Shihan Xiao",
      "Yingxue Zhang",
      "Zhitang Chen",
      "Pascal Poupart",
      "Fenglin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.12321"
  },
  {
    "id": "arXiv:2112.12322",
    "title": "High-order tensor flow processing using integrated photonic circuits",
    "abstract": "Tensor analytics lays mathematical basis for the prosperous promotion of\nmultiway signal processing. To increase computing throughput, mainstream\nprocessors transform tensor convolutions to matrix multiplications to enhance\nparallelism of computing. However, such order-reducing transformation produces\ndata duplicates and consumes additional memory. Here, we demonstrate an\nintegrated photonic tensor flow processor without tensor-matrix transformation,\nwhich outputs the convolved tensor as the input tensor 'flows' through the\nprocessor. The hybrid manipulation of optical dimensions of wavelength, time,\nand space enables the direct representation and processing of high-order\ntensors in optical domain. In the proof-of-concept experiment, processing of\nmulti-channel images and videos is accomplished at the frequency of 20 GHz. A\nconvolutional neural network is demonstrated on the processor, which achieves\nan accuracy of 97.9 percent on action recognition.",
    "descriptor": "",
    "authors": [
      "Shaofu Xu",
      "Jing Wang",
      "Sicheng Yi",
      "Weiwen Zou"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2112.12322"
  },
  {
    "id": "arXiv:2112.12325",
    "title": "Globally convergent visual-feature range estimation with biased inertial  measurements",
    "abstract": "The design of a globally convergent position observer for feature points from\nvisual information is a challenging problem, especially for the case with only\ninertial measurements and without assumptions of uniform observability, which\nremained open for a long time. We give a solution to the problem in this paper\nassuming that only the bearing of a feature point, and biased linear\nacceleration and rotational velocity of a robot -- all in the body-fixed frame\n-- are available. Further, in contrast to existing related results, we do not\nneed the value of the gravitational constant either. The proposed approach\nbuilds upon the parameter estimation-based observer recently developed in\n(Ortega et al., Syst. Control. Lett., vol.85, 2015) and its extension to matrix\nLie groups in our previous work. Conditions on the robot trajectory under which\nthe observer converges are given, and these are strictly weaker than the\nstandard persistency of excitation and uniform complete observability\nconditions. Finally, we apply the proposed design to the visual inertial\nnavigation problem. Simulation results are also presented to illustrate our\nobserver design.",
    "descriptor": "",
    "authors": [
      "Bowen Yi",
      "Chi Jin",
      "Ian R. Manchester"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.12325"
  },
  {
    "id": "arXiv:2112.12326",
    "title": "Age of Information in Energy Harvesting Aided Massive Multiple Access  Networks",
    "abstract": "Given the proliferation of the massive machine type communication devices\n(MTCDs) in beyond 5G (B5G) wireless networks, energy harvesting (EH) aided next\ngeneration multiple access (NGMA) systems have drawn substantial attention in\nthe context of energy-efficient data sensing and transmission. However, without\nadaptive time slot (TS) and power allocation schemes, NGMA systems relying on\nstochastic sampling instants might lead to tardy actions associated both with\nhigh age of information (AoI) as well as high power consumption. For mitigating\nthe energy consumption, we exploit a pair of sleep-scheduling policies, namely\nthe multiple vacation (MV) policy and start-up threshold (ST) policy, which are\ncharacterized in the context of three typical multiple access protocols,\nincluding time-division multiple access (TDMA), frequency-division multiple\naccess (FDMA) and non-orthogonal multiple access (NOMA). Furthermore, we derive\nclosed-form expressions for the MTCD system's peak AoI, which are formulated as\nthe optimization objective under the constraints of EH power, status update\nrate and stability conditions. An exact linear search based algorithm is\nproposed for finding the optimal solution by fixing the status update rate. As\na design alternative, a low complexity concave-convex procedure (CCP) is also\nformulated for finding a near-optimal solution relying on the original\nproblem's transformation into a form represented by the difference of two\nconvex problems. Our simulation results show that the proposed algorithms are\nbeneficial in terms of yielding a lower peak AoI at a low power consumption in\nthe context of the multiple access protocols considered.",
    "descriptor": "",
    "authors": [
      "Zhengru Fang",
      "Jingjing Wang",
      "Yong Ren",
      "Zhu Han",
      "H. Vincent Poor",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.12326"
  },
  {
    "id": "arXiv:2112.12327",
    "title": "Making sense of electrical vehicle discussions using sentiment analysis  on closely related news and user comments",
    "abstract": "We used a token-wise and document-wise sentiment analysis using both\nunsupervised and supervised models applied to both news and user reviews\ndataset. And our token-wise sentiment analysis found a statistically\nsignificant difference in sentiment between the two groups (both of which were\nvery large N), our document-wise supervised sentiment analysis found no\nsignificant difference in sentiment.",
    "descriptor": "",
    "authors": [
      "Josh Everts",
      "Xuan Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12327"
  },
  {
    "id": "arXiv:2112.12328",
    "title": "Robust and Precise Facial Landmark Detection by Self-Calibrated Pose  Attention Network",
    "abstract": "Current fully-supervised facial landmark detection methods have progressed\nrapidly and achieved remarkable performance. However, they still suffer when\ncoping with faces under large poses and heavy occlusions for inaccurate facial\nshape constraints and insufficient labeled training samples. In this paper, we\npropose a semi-supervised framework, i.e., a Self-Calibrated Pose Attention\nNetwork (SCPAN) to achieve more robust and precise facial landmark detection in\nchallenging scenarios. To be specific, a Boundary-Aware Landmark Intensity\n(BALI) field is proposed to model more effective facial shape constraints by\nfusing boundary and landmark intensity field information. Moreover, a\nSelf-Calibrated Pose Attention (SCPA) model is designed to provide a\nself-learned objective function that enforces intermediate supervision without\nlabel information by introducing a self-calibrated mechanism and a pose\nattention mask. We show that by integrating the BALI fields and SCPA model into\na novel self-calibrated pose attention network, more facial prior knowledge can\nbe learned and the detection accuracy and robustness of our method for faces\nwith large poses and heavy occlusions have been improved. The experimental\nresults obtained for challenging benchmark datasets demonstrate that our\napproach outperforms state-of-the-art methods in the literature.",
    "descriptor": "\nComments: Accept by IEEE Transactions on Cybernetics, December 2021\n",
    "authors": [
      "Jun Wan",
      "Hui Xi",
      "Jie Zhou",
      "Zhihui Lai",
      "Witold Pedrycz",
      "Xu Wang",
      "Hang Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12328"
  },
  {
    "id": "arXiv:2112.12329",
    "title": "More is Better: A Novel Multi-view Framework for Domain Generalization",
    "abstract": "Aiming to generalize the model trained in source domains to unseen target\ndomains, domain generalization (DG) has attracted lots of attention recently.\nThe key issue of DG is how to prevent overfitting to the observed source\ndomains because target domain is unavailable during training. We investigate\nthat overfitting not only causes the inferior generalization ability to unseen\ntarget domains but also leads unstable prediction in the test stage. In this\npaper, we observe that both sampling multiple tasks in training stage and\ngenerating augmented images in test stage largely benefit generalization\nperformance. Thus, by treating tasks and images as different views, we propose\na novel multi-view DG framework. Specifically, in training stage, to enhance\ngeneralization ability, we develop a multi-view regularized meta-learning\nalgorithm that employs multiple tasks to produce a suitable optimization\ndirection during updating model. In test stage, to alleviate unstable\nprediction, we utilize multiple augmented images to yield multi-view\nprediction, which significantly promotes model reliability via fusing the\nresults of different views of a test image. Extensive experiments on three\nbenchmark datasets validate our method outperforms several state-of-the-art\napproaches.",
    "descriptor": "",
    "authors": [
      "Jian Zhang",
      "Lei Qi",
      "Yinghuan Shi",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12329"
  },
  {
    "id": "arXiv:2112.12331",
    "title": "Flakify: A Black-Box, Language Model-based Predictor for Flaky Tests",
    "abstract": "Software testing assures that code changes do not adversely affect existing\nfunctionality. However, a test case can be flaky, i.e., passing and failing\nacross executions, even for the same version of the source code. Flaky tests\nintroduce overhead to software development as they can lead to unnecessary\nattempts to debug production or testing code. Besides rerunning test cases\nmultiple times, which is time-consuming and computationally expensive, flaky\ntests can be predicted using machine learning (ML) models. However, the\nstate-of-the-art ML-based flaky test predictors rely on pre-defined sets of\nfeatures that are either project-specific, i.e., inapplicable to other\nprojects, or require access to production code, which is not always available\nto software test engineers. Moreover, given the non-deterministic behavior of\nflaky tests, it can be challenging to determine a complete set of features that\ncould potentially be associated with test flakiness. Therefore, in this paper,\nwe propose Flakify, a black-box, language model-based predictor for flaky\ntests. Flakify does not require to (a) rerun test cases, (b) pre-define\nfeatures, or (c) access to production code. To this end, we employ CodeBERT, a\npre-trained language model, and fine-tune it to predict flaky tests by relying\nexclusively on the source code of test cases. We evaluated Flakify on a\npublicly available dataset and compared our results with FlakeFlagger, the best\nstate-of-the-art ML-based, white-box predictor for flaky tests. Flakify\nsurpasses FlakeFlagger by 10 and 18 percentage points (pp) in terms of\nprecision and recall, respectively, thus reducing the effort bound to be wasted\non unnecessarily debugging test cases and production code by the same\npercentages, respectively. Our results further show that a black-box version of\nFlakeFlagger is not a viable option for predicting flaky tests.",
    "descriptor": "",
    "authors": [
      "Sakina Fatima",
      "Taher A. Ghaleb",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.12331"
  },
  {
    "id": "arXiv:2112.12340",
    "title": "Learning with distributional inverters",
    "abstract": "We generalize the \"indirect learning\" technique of Furst et. al., 1991 to\nreduce from learning a concept class over a samplable distribution $\\mu$ to\nlearning the same concept class over the uniform distribution. The reduction\nsucceeds when the sampler for $\\mu$ is both contained in the target concept\nclass and efficiently invertible in the sense of Impagliazzo & Luby, 1989. We\ngive two applications.\n- We show that AC0[q] is learnable over any succinctly-described product\ndistribution. AC0[q] is the class of constant-depth Boolean circuits of\npolynomial size with AND, OR, NOT, and counting modulo $q$ gates of unbounded\nfanins. Our algorithm runs in randomized quasi-polynomial time and uses\nmembership queries.\n- If there is a strongly useful natural property in the sense of Razborov &\nRudich 1997 -- an efficient algorithm that can distinguish between random\nstrings and strings of non-trivial circuit complexity -- then general\npolynomial-sized Boolean circuits are learnable over any efficiently samplable\ndistribution in randomized polynomial time, given membership queries to the\ntarget function",
    "descriptor": "",
    "authors": [
      "Eric Binnendyk",
      "Marco Carmosino",
      "Antonina Kolokolova",
      "Ramyaa Ramyaa",
      "Manuel Sabin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.12340"
  },
  {
    "id": "arXiv:2112.12342",
    "title": "Individual and Group-wise Classroom Seating Experience: Effects on  Student Engagement in Different Courses",
    "abstract": "Seating location in the classroom can affect student engagement, involvement,\nattention and academic performance by providing better visibility, improved\nmovement, and discussion participation. For example, sitting at the front of\nthe classroom is a popular choice for students pursuing good academic\nperformance. This research investigates how individual and group-wise classroom\nseating experiences affect student engagement using wearable physiological\nsensors. We have conducted an in-situ experiment in a high school and collected\nsurvey and wearable data from 23 students over 10 courses for four weeks. We\naim to answer the following research questions: How do the seating proximity\nbetween students relate to their perceived learning engagement? How do the\ngroup seating behaviours of students relate to their physiological-based\nengagement measurements (i.e., physiological arousal and physiological\nsynchrony)? The experiment results show that the individual and group-wise\nclassroom seating experience is associated with perceived student engagement\nand physiological-based engagement measured from electrodermal activity. We\nalso find that students sitting near each other are more likely to have similar\nlearning engagement and tend to have high physiological synchrony. This\nresearch opens up opportunities on exploring the implications of flexible\nseating arrangements and has great potential to maximize student engagement by\nsuggesting intelligent seating choices in the future.",
    "descriptor": "",
    "authors": [
      "Nan Gao",
      "Mohammad Saiedur Rahaman",
      "Wei Shao",
      "Kaixin Ji",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.12342"
  },
  {
    "id": "arXiv:2112.12343",
    "title": "Graph attentive feature aggregation for text-independent speaker  verification",
    "abstract": "The objective of this paper is to combine multiple frame-level features into\na single utterance-level representation considering pairwise relationship. For\nthis purpose, we propose a novel graph attentive feature aggregation module by\ninterpreting each frame-level feature as a node of a graph. The\ninter-relationship between all possible pairs of features, typically exploited\nindirectly, can be directly modeled using a graph. The module comprises a graph\nattention layer and a graph pooling layer followed by a readout operation. The\ngraph attention layer first models the non-Euclidean data manifold between\ndifferent nodes. Then, the graph pooling layer discards less informative nodes\nconsidering the significance of the nodes. Finally, the readout operation\ncombines the remaining nodes into a single representation. We employ two recent\nsystems, SE-ResNet and RawNet2, with different input features and architectures\nand demonstrate that the proposed feature aggregation module consistently shows\na relative improvement over 10%, compared to the baseline.",
    "descriptor": "\nComments: 5 pages, 1 figure, 6 tables, submitted to ICASSP 2022\n",
    "authors": [
      "Hye-jin Shim",
      "Jungwoo Heo",
      "Jae-han Park",
      "Ga-hui Lee",
      "Ha-Jin Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.12343"
  },
  {
    "id": "arXiv:2112.12344",
    "title": "Learning multiple regularization parameters for generalized Tikhonov  regularization using multiple data sets without true data",
    "abstract": "During the inversion of discrete linear systems, noise in data can be\namplified and result in meaningless solutions. To combat this effect,\ncharacteristics of solutions that are considered desirable are mathematically\nimplemented during inversion, which is a process called regularization. The\ninfluence of provided prior information is controlled by non-negative\nregularization parameter(s). There are a number of methods used to select\nappropriate regularization parameters, as well as a number of methods used for\ninversion. In this paper, we consider the unbiased risk estimator, generalized\ncross validation, and the discrepancy principle as the means of selecting\nregularization parameters. When multiple data sets describing the same physical\nphenomena are available, the use of multiple regularization parameters can\nenhance results. Here we demonstrate that it is possible to learn multiple\nparameter regularization parameters using regularization parameter estimators\nthat are modified to handle multiple parameters and multiple data. The results\ndemonstrate that these modified methods, which do not require the use of true\ndata for learning regularization parameters, are effective and efficient, and\nperform comparably to methods based on true data for learning the relevant\nparameters.",
    "descriptor": "",
    "authors": [
      "Michael J. Byrne",
      "Rosemary A. Renaut"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12344"
  },
  {
    "id": "arXiv:2112.12345",
    "title": "Revisiting Transformation Invariant Geometric Deep Learning: Are Initial  Representations All You Need?",
    "abstract": "Geometric deep learning, i.e., designing neural networks to handle the\nubiquitous geometric data such as point clouds and graphs, have achieved great\nsuccesses in the last decade. One critical inductive bias is that the model can\nmaintain invariance towards various transformations such as translation,\nrotation, and scaling. The existing graph neural network (GNN) approaches can\nonly maintain permutation-invariance, failing to guarantee invariance with\nrespect to other transformations. Besides GNNs, other works design\nsophisticated transformation-invariant layers, which are computationally\nexpensive and difficult to be extended. To solve this problem, we revisit why\nthe existing neural networks cannot maintain transformation invariance when\nhandling geometric data. Our findings show that transformation-invariant and\ndistance-preserving initial representations are sufficient to achieve\ntransformation invariance rather than needing sophisticated neural layer\ndesigns. Motivated by these findings, we propose Transformation Invariant\nNeural Networks (TinvNN), a straightforward and general framework for geometric\ndata. Specifically, we realize transformation-invariant and distance-preserving\ninitial point representations by modifying multi-dimensional scaling before\nfeeding the representations into neural networks. We prove that TinvNN can\nstrictly guarantee transformation invariance, being general and flexible enough\nto be combined with the existing neural networks. Extensive experimental\nresults on point cloud analysis and combinatorial optimization demonstrate the\neffectiveness and general applicability of our proposed method. Based on the\nexperimental results, we advocate that TinvNN should be considered a new\nstarting point and an essential baseline for further studies of\ntransformation-invariant geometric deep learning.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Ziwei Zhang",
      "Xin Wang",
      "Zeyang Zhang",
      "Peng Cui",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12345"
  },
  {
    "id": "arXiv:2112.12346",
    "title": "Statistical Feature-based Personal Information Detection in Mobile  Network Traffic",
    "abstract": "With the popularity of smartphones, mobile applications (apps) have\npenetrated the daily life of people. Although apps provide rich\nfunctionalities, they also access a large amount of personal information\nsimultaneously. As a result, privacy concerns are raised. To understand what\npersonal information the apps collect, many solutions are presented to detect\nprivacy leaks in apps. Recently, the traffic monitoring-based privacy leak\ndetection method has shown promising performance and strong scalability.\nHowever, it still has some shortcomings. Firstly, it suffers from detecting the\nleakage of personal information with obfuscation. Secondly, it cannot discover\nthe privacy leaks of undefined type. Aiming at solving the above problems, a\nnew personal information detection method based on traffic monitoring is\nproposed in this paper. In this paper, statistical features of personal\ninformation are designed to depict the occurrence patterns of personal\ninformation in the traffic, including local patterns and global patterns. Then\na detector is trained based on machine learning algorithms to discover\npotential personal information with similar patterns. Since the statistical\nfeatures are independent of the value and type of personal information, the\ntrained detector is capable of identifying various types of privacy leaks and\nobfuscated privacy leaks. As far as we know, this is the first work that\ndetects personal information based on statistical features. Finally, the\nexperimental results show that the proposed method could achieve better\nperformance than the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Shuang Zhao",
      "Shuhui Chen",
      "Ziling Wei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12346"
  },
  {
    "id": "arXiv:2112.12349",
    "title": "Learning Hierarchical Attention for Weakly-supervised Chest X-Ray  Abnormality Localization and Diagnosis",
    "abstract": "We consider the problem of abnormality localization for clinical\napplications. While deep learning has driven much recent progress in medical\nimaging, many clinical challenges are not fully addressed, limiting its broader\nusage. While recent methods report high diagnostic accuracies, physicians have\nconcerns trusting these algorithm results for diagnostic decision-making\npurposes because of a general lack of algorithm decision reasoning and\ninterpretability. One potential way to address this problem is to further train\nthese models to localize abnormalities in addition to just classifying them.\nHowever, doing this accurately will require a large amount of disease\nlocalization annotations by clinical experts, a task that is prohibitively\nexpensive to accomplish for most applications. In this work, we take a step\ntowards addressing these issues by means of a new attention-driven weakly\nsupervised algorithm comprising a hierarchical attention mining framework that\nunifies activation- and gradient-based visual attention in a holistic manner.\nOur key algorithmic innovations include the design of explicit ordinal\nattention constraints, enabling principled model training in a\nweakly-supervised fashion, while also facilitating the generation of\nvisual-attention-driven model explanations by means of localization cues. On\ntwo large-scale chest X-ray datasets (NIH ChestX-ray14 and CheXpert), we\ndemonstrate significant localization performance improvements over the current\nstate of the art while also achieving competitive classification performance.\nOur code is available on https://github.com/oyxhust/HAM.",
    "descriptor": "",
    "authors": [
      "Xi Ouyang",
      "Srikrishna Karanam",
      "Ziyan Wu",
      "Terrence Chen",
      "Jiayu Huo",
      "Xiang Sean Zhou",
      "Qian Wang",
      "Jie-Zhi Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12349"
  },
  {
    "id": "arXiv:2112.12350",
    "title": "Approximating Multiplicatively Weighted Voronoi Diagrams: Efficient  Construction with Linear Size",
    "abstract": "Given a set of $n$ sites from $\\mathbb{R}^d$, each having some positive\nweight factor, the Multiplicative Weighted Voronoi Diagram is a subdivision of\nspace that associates each cell to the site whose weighted Euclidean distance\nis minimal for its points.\nWe give an approximation algorithm that outputs a subdivision such that the\nweighted distance of a point with respect to the associated site is at most\n$(1+\\varepsilon)$ times the minimum weighted distance, for any fixed parameter\n$\\varepsilon \\in (0,1)$. The diagram size is ${\\cal O}(n\n\\log(1/\\varepsilon)/\\varepsilon^{d-1})$ and the construction time is within a\nfactor ${\\cal O} (1/\\varepsilon^{(d+1)d} +\\log(n)/\\varepsilon^{d+2} )$ of the\noutput size. As a by-product, we obtain ${\\cal O}(\\log( n/\\varepsilon))$\npoint-location query time in the subdivision.\nThe key ingredients of the proposed method are the study of convex regions\nthat we call cores, an adaptive refinement algorithm to obtain small output\nsize, and a combination of Semi-Separated Pair Decompositions and conic space\npartitions to obtain efficient runtime.",
    "descriptor": "",
    "authors": [
      "Joachim Gudmundsson",
      "Martin P. Seybold",
      "Sampson Wong"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.12350"
  },
  {
    "id": "arXiv:2112.12353",
    "title": "LAME: Layout Aware Metadata Extraction Approach for Research Articles",
    "abstract": "The volume of academic literature, such as academic conference papers and\njournals, has increased rapidly worldwide, and research on metadata extraction\nis ongoing. However, high-performing metadata extraction is still challenging\ndue to diverse layout formats according to journal publishers. To accommodate\nthe diversity of the layouts of academic journals, we propose a novel\nLAyout-aware Metadata Extraction (LAME) framework equipped with the three\ncharacteristics (e.g., design of an automatic layout analysis, construction of\na large meta-data training set, and construction of Layout-MetaBERT). We\ndesigned an automatic layout analysis using PDFMiner. Based on the layout\nanalysis, a large volume of metadata-separated training data, including the\ntitle, abstract, author name, author affiliated organization, and keywords,\nwere automatically extracted. Moreover, we constructed Layout-MetaBERT to\nextract the metadata from academic journals with varying layout formats. The\nexperimental results with Layout-MetaBERT exhibited robust performance\n(Macro-F1, 93.27%) in metadata extraction for unseen journals with different\nlayout formats.",
    "descriptor": "",
    "authors": [
      "Jongyun Choi",
      "Hyesoo Kong",
      "Hwamook Yoon",
      "Heung-Seon Oh",
      "Yuchul Jung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.12353"
  },
  {
    "id": "arXiv:2112.12355",
    "title": "A Random Point Initialization Approach to Image Segmentation with  Variational Level-sets",
    "abstract": "Image segmentation is an essential component in many image processing and\ncomputer vision tasks. The primary goal of image segmentation is to simplify an\nimage for easier analysis, and there are two broad approaches for achieving\nthis: edge based methods, which extract the boundaries of specific known\nobjects, and region based methods, which partition the image into regions that\nare statistically homogeneous. One of the more prominent edge finding methods,\nknown as the level set method, evolves a zero-level contour in the image plane\nwith gradient descent until the contour has converged to the object boundaries.\nWhile the classical level set method and its variants have proved successful in\nsegmenting real images, they are susceptible to becoming stuck in noisy regions\nof the image plane without a priori knowledge of the image and they are unable\nto provide details beyond object outer boundary locations. We propose a\nmodification to the variational level set image segmentation method that can\nquickly detect object boundaries by making use of random point initialization.\nWe demonstrate the efficacy of our approach by comparing the performance of our\nmethod on real images to that of the prominent Canny Method.",
    "descriptor": "\nComments: 17 pages, 27 figures\n",
    "authors": [
      "J.N. Mueller",
      "J.N. Corcoran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12355"
  },
  {
    "id": "arXiv:2112.12356",
    "title": "Do Multi-Lingual Pre-trained Language Models Reveal Consistent Token  Attributions in Different Languages?",
    "abstract": "During the past several years, a surge of multi-lingual Pre-trained Language\nModels (PLMs) has been proposed to achieve state-of-the-art performance in many\ncross-lingual downstream tasks. However, the understanding of why multi-lingual\nPLMs perform well is still an open domain. For example, it is unclear whether\nmulti-Lingual PLMs reveal consistent token attributions in different languages.\nTo address this, in this paper, we propose a Cross-lingual Consistency of Token\nAttributions (CCTA) evaluation framework. Extensive experiments in three\ndownstream tasks demonstrate that multi-lingual PLMs assign significantly\ndifferent attributions to multi-lingual synonyms. Moreover, we have the\nfollowing observations: 1) the Spanish achieves the most consistent token\nattributions in different languages when it is used for training PLMs; 2) the\nconsistency of token attributions strongly correlates with performance in\ndownstream tasks.",
    "descriptor": "",
    "authors": [
      "Junxiang Wang",
      "Xuchao Zhang",
      "Bo Zong",
      "Yanchi Liu",
      "Wei Cheng",
      "Jingchao Ni",
      "Haifeng Chen",
      "Liang Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.12356"
  },
  {
    "id": "arXiv:2112.12359",
    "title": "Dual Path Structural Contrastive Embeddings for Learning Novel Objects",
    "abstract": "Learning novel classes from a very few labeled samples has attracted\nincreasing attention in machine learning areas. Recent research on either\nmeta-learning based or transfer-learning based paradigm demonstrates that\ngaining information on a good feature space can be an effective solution to\nachieve favorable performance on few-shot tasks. In this paper, we propose a\nsimple but effective paradigm that decouples the tasks of learning feature\nrepresentations and classifiers and only learns the feature embedding\narchitecture from base classes via the typical transfer-learning training\nstrategy. To maintain both the generalization ability across base and novel\nclasses and discrimination ability within each class, we propose a dual path\nfeature learning scheme that effectively combines structural similarity with\ncontrastive feature construction. In this way, both inner-class alignment and\ninter-class uniformity can be well balanced, and result in improved\nperformance. Experiments on three popular benchmarks show that when\nincorporated with a simple prototype based classifier, our method can still\nachieve promising results for both standard and generalized few-shot problems\nin either an inductive or transductive inference setting.",
    "descriptor": "",
    "authors": [
      "Bingbin Li",
      "Elvis Han Cui",
      "Yanan Li",
      "Donghui Wang",
      "Weng Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12359"
  },
  {
    "id": "arXiv:2112.12360",
    "title": "A Weighted State Redistribution Algorithm for Embedded Boundary Grids",
    "abstract": "State redistribution is an algorithm that stabilizes cut cells for embedded\nboundary grid methods. This work extends the earlier algorithm in several\nimportant ways. First, state redistribution is extended to three spatial\ndimensions. Second, we discuss several algorithmic changes and improvements\nmotivated by the more complicated cut cell geometries that can occur in higher\ndimensions. In particular, we introduce a weighted version with less\ndissipation. Third, we demonstrate that state redistribution can also stabilize\na solution update that includes both advective and diffusive contributions. The\nstabilization algorithm is shown to be effective for incompressible as well as\ncompressible reacting flows. Finally, we discuss the implementation of the\nalgorithm for several exascale-ready simulation codes based on AMReX,\ndemonstrating ease of use in combination with domain decomposition, hybrid\nparallelism and complex physics.",
    "descriptor": "",
    "authors": [
      "Andrew Giuliani",
      "Ann S. Almgren",
      "John B. Bell",
      "Marsha J. Berger",
      "Marc T. Henry de Frahan",
      "Deepak Rangarajan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12360"
  },
  {
    "id": "arXiv:2112.12364",
    "title": "Explaining with Examples: Lessons Learned from Crowdsourced Introductory  Description of Information Visualizations",
    "abstract": "Data visualizations have been increasingly used in oral presentations to\ncommunicate data patterns to the general public. Clear verbal introductions of\nvisualizations to explain how to interpret the visually encoded information are\nessential to convey the takeaways and avoid misunderstandings. We contribute a\nseries of studies to investigate how to effectively introduce visualizations to\nthe audience with varying degrees of visualization literacy. We begin with\nunderstanding how people are introducing visualizations. We crowdsource 110\nintroductions of visualizations and categorize them based on their content and\nstructures. From these crowdsourced introductions, we identify different\nintroduction strategies and generate a set of introductions for evaluation. We\nconduct experiments to systematically compare the effectiveness of different\nintroduction strategies across four visualizations with 1,080 participants. We\nfind that introductions explaining visual encodings with concrete examples are\nthe most effective. Our study provides both qualitative and quantitative\ninsights into how to construct effective verbal introductions of visualizations\nin presentations, inspiring further research in data storytelling.",
    "descriptor": "\nComments: 12 pages, 5 figures, accepted to IEEE Transaction on Visualization and Graphics\n",
    "authors": [
      "Leni Yang",
      "Cindy Xiong",
      "Jason K. Wong",
      "Aoyu Wu",
      "Huamin Qu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.12364"
  },
  {
    "id": "arXiv:2112.12371",
    "title": "A Practical Data-Free Approach to One-shot Federated Learning with  Heterogeneity",
    "abstract": "One-shot Federated Learning (FL) has recently emerged as a promising\napproach, which allows the central server to learn a model in a single\ncommunication round. Despite the low communication cost, existing one-shot FL\nmethods are mostly impractical or face inherent limitations, e.g., a public\ndataset is required, clients' models are homogeneous, need to upload additional\ndata/model information. To overcome these issues, we propose a more practical\ndata-free approach named FedSyn for one-shot FL framework with heterogeneity.\nOur FedSyn trains the global model by a data generation stage and a model\ndistillation stage. To the best of our knowledge, FedSyn is the first method\nthat can be practically applied to various real-world applications due to the\nfollowing advantages: (1) FedSyn requires no additional information (except the\nmodel parameters) to be transferred between clients and the server; (2) FedSyn\ndoes not require any auxiliary dataset for training; (3) FedSyn is the first to\nconsider both model and statistical heterogeneities in FL, i.e., the clients'\ndata are non-iid and different clients may have different model architectures.\nExperiments on a variety of real-world datasets demonstrate the superiority of\nour FedSyn. For example, FedSyn outperforms the best baseline method Fed-ADI by\n5.08% on CIFAR10 dataset when data are non-iid.",
    "descriptor": "",
    "authors": [
      "Jie Zhang",
      "Chen Chen",
      "Bo Li",
      "Lingjuan Lyu",
      "Shuang Wu",
      "Jianghe Xu",
      "Shouhong Ding",
      "Chao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12371"
  },
  {
    "id": "arXiv:2112.12376",
    "title": "Revisiting and Advancing Fast Adversarial Training Through The Lens of  Bi-Level Optimization",
    "abstract": "Adversarial training (AT) has become a widely recognized defense mechanism to\nimprove the robustness of deep neural networks against adversarial attacks. It\nsolves a min-max optimization problem, where the minimizer (i.e., defender)\nseeks a robust model to minimize the worst-case training loss in the presence\nof adversarial examples crafted by the maximizer (i.e., attacker). However, the\nmin-max nature makes AT computationally intensive and thus difficult to scale.\nMeanwhile, the FAST-AT algorithm, and in fact many recent algorithms that\nimprove AT, simplify the min-max based AT by replacing its maximization step\nwith the simple one-shot gradient sign based attack generation step. Although\neasy to implement, FAST-AT lacks theoretical guarantees, and its practical\nperformance can be unsatisfactory, suffering from the robustness catastrophic\noverfitting when training with strong adversaries.\nIn this paper, we propose to design FAST-AT from the perspective of bi-level\noptimization (BLO). We first make the key observation that the most\ncommonly-used algorithmic specification of FAST-AT is equivalent to using some\ngradient descent-type algorithm to solve a bi-level problem involving a sign\noperation. However, the discrete nature of the sign operation makes it\ndifficult to understand the algorithm performance. Based on the above\nobservation, we propose a new tractable bi-level optimization problem, design\nand analyze a new set of algorithms termed Fast Bi-level AT (FAST-BAT).\nFAST-BAT is capable of defending sign-based projected gradient descent (PGD)\nattacks without calling any gradient sign method and explicit robust\nregularization. Furthermore, we empirically show that our method outperforms\nstate-of-the-art FAST-AT baselines, by achieving superior model robustness\nwithout inducing robustness catastrophic overfitting, or suffering from any\nloss of standard accuracy.",
    "descriptor": "",
    "authors": [
      "Yihua Zhang",
      "Guanhuan Zhang",
      "Prashant Khanduri",
      "Mingyi Hong",
      "Shiyu Chang",
      "Sijia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12376"
  },
  {
    "id": "arXiv:2112.12378",
    "title": "Density Evolution Analysis of the Iterative Joint Ordered-Statistics  Decoding for NOMA",
    "abstract": "In this paper, we develop a density evolution (DE) framework for analyzing\nthe iterative joint decoding (JD) for non-orthogonal multiple access (NOMA)\nsystems, where the ordered-statistics decoding (OSD) is applied to decode short\nblock codes. We first investigate the density-transform feature of the\nsoft-output OSD (SOSD), by deriving the density of the extrinsic log-likelihood\nratio (LLR) with known densities of the priori LLR. Then, we represent the\nOSD-based JD by bipartite graphs (BGs), and develop the DE framework by\ncharacterizing the density-transform features of nodes over the BG. Numerical\nexamples show that the proposed DE framework accurately tracks the evolution of\nLLRs during the iterative decoding, especially at moderate-to-high SNRs. Based\non the DE framework, we further analyze the BER performance of the OSD-based\nJD, and the convergence points of the two-user and equal-power systems.",
    "descriptor": "\nComments: 30 Pages, 12 Figures\n",
    "authors": [
      "Chentao Yue",
      "Mahyar Shirvanimoghaddam",
      "Alva Kosasih",
      "Giyoon Park",
      "Ok-Sun Park",
      "Wibowo Hardjawana",
      "Branka Vucetic",
      "Yonghui Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.12378"
  },
  {
    "id": "arXiv:2112.12385",
    "title": "DILF-EN framework for Class-Incremental Learning",
    "abstract": "Deep learning models suffer from catastrophic forgetting of the classes in\nthe older phases as they get trained on the classes introduced in the new phase\nin the class-incremental learning setting. In this work, we show that the\neffect of catastrophic forgetting on the model prediction varies with the\nchange in orientation of the same image, which is a novel finding. Based on\nthis, we propose a novel data-ensemble approach that combines the predictions\nfor the different orientations of the image to help the model retain further\ninformation regarding the previously seen classes and thereby reduce the effect\nof forgetting on the model predictions. However, we cannot directly use the\ndata-ensemble approach if the model is trained using traditional techniques.\nTherefore, we also propose a novel dual-incremental learning framework that\ninvolves jointly training the network with two incremental learning objectives,\ni.e., the class-incremental learning objective and our proposed\ndata-incremental learning objective. In the dual-incremental learning\nframework, each image belongs to two classes, i.e., the image class (for\nclass-incremental learning) and the orientation class (for data-incremental\nlearning). In class-incremental learning, each new phase introduces a new set\nof classes, and the model cannot access the complete training data from the\nolder phases. In our proposed data-incremental learning, the orientation\nclasses remain the same across all the phases, and the data introduced by the\nnew phase in class-incremental learning acts as new training data for these\norientation classes. We empirically demonstrate that the dual-incremental\nlearning framework is vital to the data-ensemble approach. We apply our\nproposed approach to state-of-the-art class-incremental learning methods and\nempirically show that our framework significantly improves the performance of\nthese methods.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Mohammed Asad Karim",
      "Indu Joshi",
      "Pratik Mazumder",
      "Pravendra Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12385"
  },
  {
    "id": "arXiv:2112.12387",
    "title": "Human-AI Collaboration for UX Evaluation: Effects of Explanation and  Synchronization",
    "abstract": "Analyzing usability test videos is arduous. Although recent research showed\nthe promise of AI in assisting with such tasks, it remains largely unknown how\nAI should be designed to facilitate effective collaboration between user\nexperience (UX) evaluators and AI. Inspired by the concepts of agency and work\ncontext in human and AI collaboration literature, we studied two corresponding\ndesign factors for AI-assisted UX evaluation: explanations and synchronization.\nExplanations allow AI to further inform humans how it identifies UX problems\nfrom a usability test session; synchronization refers to the two ways humans\nand AI collaborate: synchronously and asynchronously. We iteratively designed a\ntool, AI Assistant, with four versions of UIs corresponding to the two levels\nof explanations (with/without) and synchronization (sync/async). By adopting a\nhybrid wizard-of-oz approach to simulating an AI with reasonable performance,\nwe conducted a mixed-method study with 24 UX evaluators identifying UX problems\nfrom usability test videos using AI Assistant. Our quantitative and qualitative\nresults show that AI with explanations, regardless of being presented\nsynchronously or asynchronously, provided better support for UX evaluators'\nanalysis and was perceived more positively; when without explanations,\nsynchronous AI better improved UX evaluators' performance and engagement\ncompared to the asynchronous AI. Lastly, we present the design implications for\nAI-assisted UX evaluation and facilitating more effective human-AI\ncollaboration.",
    "descriptor": "\nComments: Proceedings of the ACM on Human-Computer Interaction (PACM HCI), CSCW, 2022\n",
    "authors": [
      "Mingming Fan",
      "Xianyou Yang",
      "Tsz Tung Yu",
      "Vera Q. Liao",
      "Jian Zhao"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.12387"
  },
  {
    "id": "arXiv:2112.12388",
    "title": "Reservoir: Named Data for Pervasive Computation Reuse at the Network  Edge",
    "abstract": "In edge computing use cases (e.g., smart cities), where several users and\ndevices may be in close proximity to each other, computational tasks with\nsimilar input data for the same services (e.g., image or video annotation) may\nbe offloaded to the edge. The execution of such tasks often yields the same\nresults (output) and thus duplicate (redundant) computation. Based on this\nobservation, prior work has advocated for \"computation reuse\", a paradigm where\nthe results of previously executed tasks are stored at the edge and are reused\nto satisfy incoming tasks with similar input data, instead of executing these\nincoming tasks from scratch. However, realizing computation reuse in practical\nedge computing deployments, where services may be offered by multiple\n(distributed) edge nodes (servers) for scalability and fault tolerance, is\nstill largely unexplored. To tackle this challenge, in this paper, we present\nReservoir, a framework to enable pervasive computation reuse at the edge, while\nimposing marginal overheads on user devices and the operation of the edge\nnetwork infrastructure. Reservoir takes advantage of Locality Sensitive Hashing\n(LSH) and runs on top of Named-Data Networking (NDN), extending the NDN\narchitecture for the realization of the computation reuse semantics in the\nnetwork. Our evaluation demonstrated that Reservoir can reuse computation with\nup to an almost perfect accuracy, achieving 4.25-21.34x lower task completion\ntimes compared to cases without computation reuse.",
    "descriptor": "\nComments: This paper has been accepted for publication by the 20th International Conference on Pervasive Computing and Communications (PerCom 2022)\n",
    "authors": [
      "Md Washik Al Azad",
      "Spyridon Mastorakis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.12388"
  },
  {
    "id": "arXiv:2112.12389",
    "title": "S+PAGE: A Speaker and Position-Aware Graph Neural Network Model for  Emotion Recognition in Conversation",
    "abstract": "Emotion recognition in conversation (ERC) has attracted much attention in\nrecent years for its necessity in widespread applications. Existing ERC methods\nmostly model the self and inter-speaker context separately, posing a major\nissue for lacking enough interaction between them. In this paper, we propose a\nnovel Speaker and Position-Aware Graph neural network model for ERC (S+PAGE),\nwhich contains three stages to combine the benefits of both Transformer and\nrelational graph convolution network (R-GCN) for better contextual modeling.\nFirstly, a two-stream conversational Transformer is presented to extract the\ncoarse self and inter-speaker contextual features for each utterance. Then, a\nspeaker and position-aware conversation graph is constructed, and we propose an\nenhanced R-GCN model, called PAG, to refine the coarse features guided by a\nrelative positional encoding. Finally, both of the features from the former two\nstages are input into a conditional random field layer to model the emotion\ntransfer.",
    "descriptor": "",
    "authors": [
      "Chen Liang",
      "Chong Yang",
      "Jing Xu",
      "Juyang Huang",
      "Yongliang Wang",
      "Yang Dong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.12389"
  },
  {
    "id": "arXiv:2112.12390",
    "title": "DD-NeRF: Double-Diffusion Neural Radiance Field as a Generalizable  Implicit Body Representation",
    "abstract": "We present DD-NeRF, a novel generalizable implicit field for representing\nhuman body geometry and appearance from arbitrary input views. The core\ncontribution is a double diffusion mechanism, which leverages the sparse\nconvolutional neural network to build two volumes that represent a human body\nat different levels: a coarse body volume takes advantage of unclothed\ndeformable mesh to provide the large-scale geometric guidance, and a detail\nfeature volume learns the intricate geometry from local image features. We also\nemploy a transformer network to aggregate image features and raw pixels across\nviews, for computing the final high-fidelity radiance field. Experiments on\nvarious datasets show that the proposed approach outperforms previous works in\nboth geometry reconstruction and novel view synthesis quality.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Guangming Yao",
      "Hongzhi Wu",
      "Yi Yuan",
      "Kun Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12390"
  },
  {
    "id": "arXiv:2112.12397",
    "title": "A scalable preconditioning framework for stabilized contact mechanics  with hydraulically active fractures",
    "abstract": "A preconditioning framework for the coupled problem of frictional contact\nmechanics and fluid flow in the fracture network is presented. The porous\nmedium is discretized using low-order continuous finite elements, with\ncell-centered Lagrange multipliers and pressure unknowns used to impose the\nconstraints and solve the fluid flow in the fractures, respectively. This\nformulation does not require any interpolation between different fields, but is\nnot uniformly inf-sup stable and requires a stabilization. For the resulting 3\nx 3 block Jacobian matrix, we design scalable preconditioning strategies, based\non the physically-informed block partitioning of the unknowns and\nstate-of-the-art multigrid preconditioners. The key idea is to restrict the\nsystem to a single-physics problem, approximately solve it by an inner\nalgebraic multigrid approach, and finally prolong it back to the fully-coupled\nproblem. Two different techniques are presented, analyzed and compared by\nchanging the ordering of the restrictions. Numerical results illustrate the\nalgorithmic scalability, the impact of the relative number of fracture-based\nunknowns, and the performance on a real-world problem.",
    "descriptor": "\nComments: 25 pages, 11 figures, 7 tables\n",
    "authors": [
      "Andrea Franceschini",
      "Laura Gazzola",
      "Massimiliano Ferronato"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12397"
  },
  {
    "id": "arXiv:2112.12398",
    "title": "Towards Fully Declarative Program Analysis via Source Code  Transformation",
    "abstract": "Advances in logic programming and increasing industrial uptake of\nDatalog-inspired approaches demonstrate the emerging need to express powerful\ncode analyses more easily. Declarative program analysis frameworks (e.g., using\nlogic programming like Datalog) significantly ease defining analyses compared\nto imperative implementations. However, the declarative benefits of these\nframeworks only materialize after parsing and translating source code to\ngenerate facts. Fact generation remains a non-declarative precursor to analysis\nwhere imperative implementations first parse and interpret program structures\n(e.g., abstract syntax trees and control-flow graphs). The procedure of fact\ngeneration thus remains opaque and difficult for non-experts to understand or\nmodify. We present a new perspective on this analysis workflow by proposing\ndeclarative fact generation to ease specification and exploration of\nlightweight declarative analyses. Our approach demonstrates the first venture\ntowards fully declarative analysis specification across multiple languages. The\nkey idea is to translate source code directly to Datalog facts in the analysis\ndomain using declarative syntax transformation. We then reuse existing Datalog\nanalyses over generated facts, yielding an end-to-end declarative pipeline. As\na first approximation we pursue a syntax-driven approach and demonstrate the\nfeasibility of generating and using lightweight versions of liveness and call\ngraph reachability properties. We then discuss the workability of extending\ndeclarative fact generation to also incorporate semantic information.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Rijnard van Tonder"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.12398"
  },
  {
    "id": "arXiv:2112.12399",
    "title": "Towards identifying optimal biased feedback for various user states and  traits in motor imagery BCI",
    "abstract": "Objective. Neural self-regulation is necessary for achieving control over\nbrain-computer interfaces (BCIs). This can be an arduous learning process\nespecially for motor imagery BCI. Various training methods were proposed to\nassist users in accomplishing BCI control and increase performance. Notably the\nuse of biased feedback, i.e. non-realistic representation of performance.\nBenefits of biased feedback on performance and learning vary between users\n(e.g. depending on their initial level of BCI control) and remain speculative.\nTo disentangle the speculations, we investigate what personality type, initial\nstate and calibration performance (CP) could benefit from a biased feedback.\nMethods. We conduct an experiment (n=30 for 2 sessions). The feedback provided\nto each group (n=10) is either positively, negatively or not biased. Results.\nStatistical analyses suggest that interactions between bias and: 1) workload,\n2) anxiety, and 3) self-control significantly affect online performance. For\ninstance, low initial workload paired with negative bias is associated to\nhigher peak performances (86%) than without any bias (69%). High anxiety\nrelates negatively to performance no matter the bias (60%), while low anxiety\nmatches best with negative bias (76%). For low CP, learning rate (LR) increases\nwith negative bias only short term (LR=2%) as during the second session it\nseverely drops (LR=-1%). Conclusion. We unveil many interactions between said\nhuman factors and bias. Additionally, we use prediction models to confirm and\nreveal even more interactions. Significance. This paper is a first step towards\nidentifying optimal biased feedback for a personality type, state, and CP in\norder to maximize BCI performance and learning.",
    "descriptor": "\nComments: IEEE Transactions on Biomedical Engineering, Institute of Electrical and Electronics Engineers, 2021\n",
    "authors": [
      "Jelena Mladenovi\u0107",
      "Jeremy Frey",
      "Smeety Pramij",
      "Jeremie Mattout",
      "Fabien Lotte"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.12399"
  },
  {
    "id": "arXiv:2112.12402",
    "title": "Iteratively Selecting an Easy Reference Frame Makes Unsupervised Video  Object Segmentation Easier",
    "abstract": "Unsupervised video object segmentation (UVOS) is a per-pixel binary labeling\nproblem which aims at separating the foreground object from the background in\nthe video without using the ground truth (GT) mask of the foreground object.\nMost of the previous UVOS models use the first frame or the entire video as a\nreference frame to specify the mask of the foreground object. Our question is\nwhy the first frame should be selected as a reference frame or why the entire\nvideo should be used to specify the mask. We believe that we can select a\nbetter reference frame to achieve the better UVOS performance than using only\nthe first frame or the entire video as a reference frame. In our paper, we\npropose Easy Frame Selector (EFS). The EFS enables us to select an 'easy'\nreference frame that makes the subsequent VOS become easy, thereby improving\nthe VOS performance. Furthermore, we propose a new framework named as Iterative\nMask Prediction (IMP). In the framework, we repeat applying EFS to the given\nvideo and selecting an 'easier' reference frame from the video than the\nprevious iteration, increasing the VOS performance incrementally. The IMP\nconsists of EFS, Bi-directional Mask Prediction (BMP), and Temporal Information\nUpdating (TIU). From the proposed framework, we achieve state-of-the-art\nperformance in three UVOS benchmark sets: DAVIS16, FBMS, and SegTrack-V2.",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Youngjo Lee",
      "Hongje Seong",
      "Euntai Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12402"
  },
  {
    "id": "arXiv:2112.12409",
    "title": "InstaIndoor and Multi-modal Deep Learning for Indoor Scene Recognition",
    "abstract": "Indoor scene recognition is a growing field with great potential for\nbehaviour understanding, robot localization, and elderly monitoring, among\nothers. In this study, we approach the task of scene recognition from a novel\nstandpoint, using multi-modal learning and video data gathered from social\nmedia. The accessibility and variety of social media videos can provide\nrealistic data for modern scene recognition techniques and applications. We\npropose a model based on fusion of transcribed speech to text and visual\nfeatures, which is used for classification on a novel dataset of social media\nvideos of indoor scenes named InstaIndoor. Our model achieves up to 70%\naccuracy and 0.7 F1-Score. Furthermore, we highlight the potential of our\napproach by benchmarking on a YouTube-8M subset of indoor scenes as well, where\nit achieves 74% accuracy and 0.74 F1-Score. We hope the contributions of this\nwork pave the way to novel research in the challenging field of indoor scene\nrecognition.",
    "descriptor": "",
    "authors": [
      "Andreea Glavan",
      "Estefania Talavera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12409"
  },
  {
    "id": "arXiv:2112.12411",
    "title": "Mitigating Leakage from Data Dependent Communications in Decentralized  Computing using Differential Privacy",
    "abstract": "Imagine a group of citizens willing to collectively contribute their personal\ndata for the common good to produce socially useful information, resulting from\ndata analytics or machine learning computations. Sharing raw personal data with\na centralized server performing the computation could raise concerns about\nprivacy and a perceived risk of mass surveillance. Instead, citizens may trust\neach other and their own devices to engage into a decentralized computation to\ncollaboratively produce an aggregate data release to be shared. In the context\nof secure computing nodes exchanging messages over secure channels at runtime,\na key security issue is to protect against external attackers observing the\ntraffic, whose dependence on data may reveal personal information. Existing\nsolutions are designed for the cloud setting, with the goal of hiding all\nproperties of the underlying dataset, and do not address the specific privacy\nand efficiency challenges that arise in the above context. In this paper, we\ndefine a general execution model to control the data-dependence of\ncommunications in user-side decentralized computations, in which differential\nprivacy guarantees for communication patterns in global execution plans can be\nanalyzed by combining guarantees obtained on local clusters of nodes. We\npropose a set of algorithms which allow to trade-off between privacy, utility\nand efficiency. Our formal privacy guarantees leverage and extend recent\nresults on privacy amplification by shuffling. We illustrate the usefulness of\nour proposal on two representative examples of decentralized execution plans\nwith data-dependent communications.",
    "descriptor": "",
    "authors": [
      "Riad Ladjel",
      "Nicolas Anciaux",
      "Aur\u00e9lien Bellet",
      "Guillaume Scerri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12411"
  },
  {
    "id": "arXiv:2112.12414",
    "title": "Optimal Error Estimates of a Discontinuous Galerkin Method for the  Navier-Stokes Equations",
    "abstract": "In this paper, we apply discontinuous finite element Galerkin method to the\ntime-dependent $2D$ incompressible Navier-Stokes model. We derive optimal error\nestimates in $L^\\infty(\\textbf{L}^2)$-norm for the velocity and in\n$L^\\infty(L^2)$-norm for the pressure with the initial data $\\textbf{u}_0\\in\n\\textbf{H}_0^1\\cap \\textbf{H}^2$ and the source function $\\textbf{f}$ in\n$L^\\infty(\\textbf{L}^2)$ space. These estimates are established with the help\nof a new $L^2$-projection and modified Stokes operator on appropriate broken\nSobolev space and with standard parabolic or elliptic duality arguments.\nEstimates are shown to be uniform under the smallness assumption on data. Then,\na completely discrete scheme based on the backward Euler method is analyzed,\nand fully discrete error estimates are derived. We would like to highlight here\nthat the estiablished semi-discrete error estimates related to the\n$L^\\infty(\\textbf{L}^2)$-norm of velocity and $L^\\infty(L^2)$-norm of pressure\nare optimal and sharper than those derived in the earlier articles. Finally,\nnumerical examples validate our theoretical findings.",
    "descriptor": "",
    "authors": [
      "Saumya Bajpai",
      "Deepjyoti Goswami",
      "Kallol Ray"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12414"
  },
  {
    "id": "arXiv:2112.12415",
    "title": "In-storage Processing of I/O Intensive Applications on Computational  Storage Drives",
    "abstract": "Computational storage drives (CSD) are solid-state drives (SSD) empowered by\ngeneral-purpose processors that can perform in-storage processing. They have\nthe potential to improve both performance and energy significantly for big-data\nanalytics by bringing compute to data, thereby eliminating costly data transfer\nwhile offering better privacy. In this work, we introduce Solana, the\nfirst-ever high-capacity(12-TB) CSD in E1.S form factor, and present an actual\nprototype for evaluation. To demonstrate the benefits of in-storage processing\non CSD, we deploy several natural language processing (NLP) applications on\ndatacenter-grade storage servers comprised of clusters of the Solana.\nExperimental results show up to 3.1x speedup in processing while reducing the\nenergy consumption and data transfer by 67% and 68%, respectively, compared to\nregular enterprise SSDs.",
    "descriptor": "\nComments: Accepted for the 23rd International Symposium on Quality Electronic Design (ISQED'22)\n",
    "authors": [
      "Ali HeydariGorji",
      "Mahdi Torabzadehkashi",
      "Siavash Rezaei",
      "Hossein Bobarshad",
      "Vladimir Alves",
      "Pai H. Chou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.12415"
  },
  {
    "id": "arXiv:2112.12421",
    "title": "Multiphysics mixed finite element method with Nitsche's technique for  Stokes poroelasticity problem",
    "abstract": "In this paper, we propose a multiphysics mixed finite element method with\nNitsche's technique for Stokes-poroelasticity problem. Firstly, we present a\nmultiphysics reformulation of poroelasticity part of the original problem by\nintroducing two pseudo-pressures to reveal the underlying deformation and\ndiffusion multi physical processes in the Stokes-poroelasticity problem. Then,\nwe prove the existence and uniqueness of weak solution of the reformulated and\noriginal problem. And we use Nitsche's technique to approximate the coupling\ncondition at the interface to propose a loosely-coupled time-stepping method --\nmultiphysics mixed finite element method for space variables, and we decouple\nthe reformulated problem into three sub-problems at each time step -- a Stokes\nproblem, a generalized Stokes problem and a mixed diffusion problem. Also, we\ngive the stability analysis and error estimates of the loosely-coupled\ntime-stepping method.",
    "descriptor": "\nComments: 37 pages, 11 figures. arXiv admin note: text overlap with arXiv:1403.5707 by other authors\n",
    "authors": [
      "Zhihao Ge",
      "Jin'ge Pang",
      "Jiwei Cao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.12421"
  },
  {
    "id": "arXiv:2112.12430",
    "title": "Lower Bounds on Intermediate Results in Bottom-Up Knowledge Compilation",
    "abstract": "Bottom-up knowledge compilation is a paradigm for generating representations\nof functions by iteratively conjoining constraints using a so-called apply\nfunction. When the input is not efficiently compilable into a language -\ngenerally a class of circuits - because optimal compiled representations are\nprovably large, the problem is not the compilation algorithm as much as the\nchoice of a language too restrictive for the input. In contrast, in this paper,\nwe look at CNF formulas for which very small circuits exists and look at the\nefficiency of their bottom-up compilation in one of the most general languages,\nnamely that of structured decomposable negation normal forms (str-DNNF). We\nprove that, while the inputs have constant size representations as str-DNNF,\nany bottom-up compilation in the general setting where conjunction and\nstructure modification are allowed takes exponential time and space, since\nlarge intermediate results have to be produced. This unconditionally proves\nthat the inefficiency of bottom-up compilation resides in the bottom-up\nparadigm itself.",
    "descriptor": "\nComments: 14 pages including references and appendices\n",
    "authors": [
      "Alexis de Colnet",
      "Stefan Mengel"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.12430"
  },
  {
    "id": "arXiv:2112.12431",
    "title": "Adaptive Modeling Against Adversarial Attacks",
    "abstract": "Adversarial training, the process of training a deep learning model with\nadversarial data, is one of the most successful adversarial defense methods for\ndeep learning models. We have found that the robustness to white-box attack of\nan adversarially trained model can be further improved if we fine tune this\nmodel in inference stage to adapt to the adversarial input, with the extra\ninformation in it. We introduce an algorithm that \"post trains\" the model at\ninference stage between the original output class and a \"neighbor\" class, with\nexisting training data. The accuracy of pre-trained Fast-FGSM CIFAR10\nclassifier base model against white-box projected gradient attack (PGD) can be\nsignificantly improved from 46.8% to 64.5% with our algorithm.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Zhiwen Yan",
      "Teck Khim Ng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12431"
  },
  {
    "id": "arXiv:2112.12433",
    "title": "Sparse-softmax: A Simpler and Faster Alternative Softmax Transformation",
    "abstract": "The softmax function is widely used in artificial neural networks for the\nmulticlass classification problems, where the softmax transformation enforces\nthe output to be positive and sum to one, and the corresponding loss function\nallows to use maximum likelihood principle to optimize the model. However,\nsoftmax leaves a large margin for loss function to conduct optimizing operation\nwhen it comes to high-dimensional classification, which results in\nlow-performance to some extent. In this paper, we provide an empirical study on\na simple and concise softmax variant, namely sparse-softmax, to alleviate the\nproblem that occurred in traditional softmax in terms of high-dimensional\nclassification problems. We evaluate our approach in several interdisciplinary\ntasks, the experimental results show that sparse-softmax is simpler, faster,\nand produces better results than the baseline models.",
    "descriptor": "",
    "authors": [
      "Shaoshi Sun",
      "Zhenyuan Zhang",
      "BoCheng Huang",
      "Pengbin Lei",
      "Jianlin Su",
      "Shengfeng Pan",
      "Jiarun Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.12433"
  },
  {
    "id": "arXiv:2112.12438",
    "title": "Using Sequential Statistical Tests to Improve the Performance of Random  Search in hyperparameter Tuning",
    "abstract": "Hyperparamter tuning is one of the the most time-consuming parts in machine\nlearning: The performance of a large number of different hyperparameter\nsettings has to be evaluated to find the best one. Although modern optimization\nalgorithms exist that minimize the number of evaluations needed, the evaluation\nof a single setting is still expensive: Using a resampling technique, the\nmachine learning method has to be fitted a fixed number of $K$ times on\ndifferent training data sets. As an estimator for the performance of the\nsetting the respective mean value of the $K$ fits is used. Many hyperparameter\nsettings could be discarded after less than $K$ resampling iterations, because\nthey already are clearly inferior to high performing settings. However, in\npractice, the resampling is often performed until the very end, wasting a lot\nof computational effort.\nWe propose to use a sequential testing procedure to minimize the number of\nresampling iterations to detect inferior parameter setting. To do so, we first\nanalyze the distribution of resampling errors, we will find out, that a\nlog-normal distribution is promising. Afterwards, we build a sequential testing\nprocedure assuming this distribution. This sequential test procedure is\nutilized within a random search algorithm.\nWe compare a standard random search with our enhanced sequential random\nsearch in some realistic data situation. It can be shown that the sequential\nrandom search is able to find comparably good hyperparameter settings, however,\nthe computational time needed to find those settings is roughly halved.",
    "descriptor": "",
    "authors": [
      "Philip Buczak",
      "Daniel Horn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.12438"
  },
  {
    "id": "arXiv:2112.12441",
    "title": "TOD-DA: Towards Boosting the Robustness of Task-oriented Dialogue  Modeling on Spoken Conversations",
    "abstract": "Task-oriented dialogue systems have been plagued by the difficulties of\nobtaining large-scale and high-quality annotated conversations. Furthermore,\nmost of the publicly available datasets only include written conversations,\nwhich are insufficient to reflect actual human behaviors in practical spoken\ndialogue systems. In this paper, we propose Task-oriented Dialogue Data\nAugmentation (TOD-DA), a novel model-agnostic data augmentation paradigm to\nboost the robustness of task-oriented dialogue modeling on spoken\nconversations. The TOD-DA consists of two modules: 1) Dialogue Enrichment to\nexpand training data on task-oriented conversations for easing data sparsity\nand 2) Spoken Conversation Simulator to imitate oral style expressions and\nspeech recognition errors in diverse granularities for bridging the gap between\nwritten and spoken conversations. With such designs, our approach ranked first\nin both tasks of DSTC10 Track2, a benchmark for task-oriented dialogue modeling\non spoken conversations, demonstrating the superiority and effectiveness of our\nproposed TOD-DA.",
    "descriptor": "\nComments: Accepted to the AAAI-22 DSTC10 Workshop. First three authors contributed equally to this work\n",
    "authors": [
      "Xin Tian",
      "Xinxian Huang",
      "Dongfeng He",
      "Yingzhan Lin",
      "Siqi Bao",
      "Huang He",
      "Liankai Huang",
      "Qiang Ju",
      "Xiyuan Zhang",
      "Jian Xie",
      "Shuqi Sun",
      "Fan Wang",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.12441"
  },
  {
    "id": "arXiv:2112.12444",
    "title": "More Than Words: Towards Better Quality Interpretations of Text  Classifiers",
    "abstract": "The large size and complex decision mechanisms of state-of-the-art text\nclassifiers make it difficult for humans to understand their predictions,\nleading to a potential lack of trust by the users. These issues have led to the\nadoption of methods like SHAP and Integrated Gradients to explain\nclassification decisions by assigning importance scores to input tokens.\nHowever, prior work, using different randomization tests, has shown that\ninterpretations generated by these methods may not be robust. For instance,\nmodels making the same predictions on the test set may still lead to different\nfeature importance rankings. In order to address the lack of robustness of\ntoken-based interpretability, we explore explanations at higher semantic levels\nlike sentences. We use computational metrics and human subject studies to\ncompare the quality of sentence-based interpretations against token-based ones.\nOur experiments show that higher-level feature attributions offer several\nadvantages: 1) they are more robust as measured by the randomization tests, 2)\nthey lead to lower variability when using approximation-based methods like\nSHAP, and 3) they are more intelligible to humans in situations where the\nlinguistic coherence resides at a higher granularity level. Based on these\nfindings, we show that token-based interpretability, while being a convenient\nfirst choice given the input interfaces of the ML models, is not the most\neffective one in all situations.",
    "descriptor": "",
    "authors": [
      "Muhammad Bilal Zafar",
      "Philipp Schmidt",
      "Michele Donini",
      "C\u00e9dric Archambeau",
      "Felix Biessmann",
      "Sanjiv Ranjan Das",
      "Krishnaram Kenthapadi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.12444"
  },
  {
    "id": "arXiv:2112.12445",
    "title": "An analysis of Coggia-Couvreur attack on Loidreau's rank-metric public  key encryption scheme in the general case",
    "abstract": "In this paper we show that in the case where the public-key can be\ndistinguished from a random code in Loidreau's encryption scheme, then\nCoggia-Couvreur attack can be extended to recover an equivalent secret key.\nThis attack can be conducted in polynomial-time if the masking vector space has\ndimension 3, thus recovering the results of Ghatak.",
    "descriptor": "\nComments: Long version of an article submitted at the conference WCC 2022\n",
    "authors": [
      "Pierre Loidreau",
      "Ba-Duc Pham"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.12445"
  },
  {
    "id": "arXiv:2112.12446",
    "title": "Robust error bounds for the Navier-Stokes equations using  implicit-explicit second order BDF method with variable steps",
    "abstract": "This paper studies fully discrete finite element approximations to the\nNavier-Stokes equations using inf-sup stable elements and grad-div\nstabilization. For the time integration two implicit-explicit second order\nbackward differentiation formulae (BDF2) schemes are applied. In both the\nlaplacian is implicit while the nonlinear term is explicit, in the first one,\nand semi-implicit, in the second one. The grad-div stabilization allow us to\nprove error bounds in which the constants are independent of inverse powers of\nthe viscosity. Error bounds of order $r$ in space are obtained for the $L^2$\nerror of the velocity using piecewise polynomials of degree $r$ to approximate\nthe velocity together with second order bounds in time, both for fixed time\nstep methods and for methods with variable time steps. A CFL-type condition is\nneeded for the method in which the nonlinear term is explicit relating time\nstep and spatial mesh sizes parameters.",
    "descriptor": "",
    "authors": [
      "Bosco Garcia-Archilla",
      "Julia Novo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12446"
  },
  {
    "id": "arXiv:2112.12455",
    "title": "Your Face Mirrors Your Deepest Beliefs-Predicting Personality and Morals  through Facial Emotion Recognition",
    "abstract": "Can we really \"read the mind in the eyes\"? Moreover, can AI assist us in this\ntask? This paper answers these two questions by introducing a machine learning\nsystem that predicts personality characteristics of individuals on the basis of\ntheir face. It does so by tracking the emotional response of the individual's\nface through facial emotion recognition (FER) while watching a series of 15\nshort videos of different genres. To calibrate the system, we invited 85 people\nto watch the videos, while their emotional responses were analyzed through\ntheir facial expression. At the same time, these individuals also took four\nwell-validated surveys of personality characteristics and moral values: the\nrevised NEO FFI personality inventory, the Haidt moral foundations test, the\nSchwartz personal value system, and the domain-specific risk-taking scale\n(DOSPERT). We found that personality characteristics and moral values of an\nindividual can be predicted through their emotional response to the videos as\nshown in their face, with an accuracy of up to 86% using gradient-boosted\ntrees. We also found that different personality characteristics are better\npredicted by different videos, in other words, there is no single video that\nwill provide accurate predictions for all personality characteristics, but it\nis the response to the mix of different videos that allows for accurate\nprediction.",
    "descriptor": "",
    "authors": [
      "P. A. Gloor",
      "A. Fronzetti Colladon",
      "E. Altuntas",
      "C. Cetinkaya",
      "M. F. Kaiser",
      "L. Ripperger",
      "T. Schaefer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12455"
  },
  {
    "id": "arXiv:2112.12458",
    "title": "Local Advantage Networks for Cooperative Multi-Agent Reinforcement  Learning",
    "abstract": "Multi-agent reinforcement learning (MARL) enables us to create adaptive\nagents in challenging environments, even when the agents have limited\nobservation. Modern MARL methods have hitherto focused on finding factorized\nvalue functions. While this approach has proven successful, the resulting\nmethods have convoluted network structures. We take a radically different\napproach, and build on the structure of independent Q-learners. Inspired by\ninfluence-based abstraction, we start from the observation that compact\nrepresentations of the observation-action histories can be sufficient to learn\nclose to optimal decentralized policies. Combining this observation with a\ndueling architecture, our algorithm, LAN, represents these policies as separate\nindividual advantage functions w.r.t. a centralized critic. These local\nadvantage networks condition only on a single agent's local observation-action\nhistory. The centralized value function conditions on the agents'\nrepresentations as well as the full state of the environment. The value\nfunction, which is cast aside before execution, serves as a stabilizer that\ncoordinates the learning and to formulate DQN targets during learning. In\ncontrast with other methods, this enables LAN to keep the number of network\nparameters of its centralized network independent in the number of agents,\nwithout imposing additional constraints like monotonic value functions. When\nevaluated on the StarCraft multi-agent challenge benchmark, LAN shows\nstate-of-the-art performance and scores more than 80% wins in two previously\nunsolved maps `corridor' and `3s5z_vs_3s6z', leading to an improvement of 10%\nover QPLEX on average performance on the 14 maps. Moreover when the number of\nagents becomes large, LAN uses significantly fewer parameters than QPLEX or\neven QMIX. We thus show that LAN's structure forms a key improvement that helps\nMARL methods remain scalable.",
    "descriptor": "",
    "authors": [
      "Rapha\u00ebl Avalos",
      "Mathieu Reymond",
      "Ann Now\u00e9",
      "Diederik M. Roijers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12458"
  },
  {
    "id": "arXiv:2112.12463",
    "title": "Comprehensive Movie Recommendation System",
    "abstract": "A recommender system, also known as a recommendation system, is a type of\ninformation filtering system that attempts to forecast a user's rating or\npreference for an item. This article designs and implements a complete movie\nrecommendation system prototype based on the Genre, Pearson Correlation\nCoefficient, Cosine Similarity, KNN-Based, Content-Based Filtering using TFIDF\nand SVD, Collaborative Filtering using TFIDF and SVD, Surprise Library based\nrecommendation system technology. Apart from that in this paper, we present a\nnovel idea that applies machine learning techniques to construct a cluster for\nthe movie based on genres and then observes the inertia value number of\nclusters were defined. The constraints of the approaches discussed in this work\nhave been described, as well as how one strategy overcomes the disadvantages of\nanother. The whole work has been done on the dataset Movie Lens present at the\ngroup lens website which contains 100836 ratings and 3683 tag applications\nacross 9742 movies. These data were created by 610 users between March 29,\n1996, and September 24, 2018.",
    "descriptor": "\nComments: The paper was presented in the 8th International Conference on Business Analytics and Intelligence (ICBAI'21), December 20-22, 2021, Bangalore, India. This is the pre=print of the published version that appears in the conference proceedings. It is eight pages long, and it consists of nine tables\n",
    "authors": [
      "Hrisav Bhowmick",
      "Ananda Chatterjee",
      "Jaydip Sen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12463"
  },
  {
    "id": "arXiv:2112.12465",
    "title": "The Impact of Missing Velocity Information in Dynamic Obstacle Avoidance  based on Deep Reinforcement Learning",
    "abstract": "We introduce a novel approach to dynamic obstacle avoidance based on Deep\nReinforcement Learning by defining a traffic type independent environment with\nvariable complexity. Filling a gap in the current literature, we thoroughly\ninvestigate the effect of missing velocity information on an agent's\nperformance in obstacle avoidance tasks. This is a crucial issue in practice\nsince several sensors yield only positional information of objects or vehicles.\nWe evaluate frequently-applied approaches in scenarios of partial\nobservability, namely the incorporation of recurrency in the deep neural\nnetworks and simple frame-stacking. For our analysis, we rely on\nstate-of-the-art model-free deep RL algorithms. The lack of velocity\ninformation is found to significantly impact the performance of an agent. Both\napproaches - recurrency and frame-stacking - cannot consistently replace\nmissing velocity information in the observation space. However, in simplified\nscenarios, they can significantly boost performance and stabilize the overall\ntraining procedure.",
    "descriptor": "",
    "authors": [
      "Fabian Hart",
      "Martin Waltz",
      "Ostap Okhrin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12465"
  },
  {
    "id": "arXiv:2112.12466",
    "title": "Real-Time Generation of Leg Animation for Walking-in-Place Techniques",
    "abstract": "Generating forward-backward self-representation leg animation in virtual\nenvironments for walking-in-place (WIP) techniques is an underexplored research\ntopic. A challenging aspect of the problem is to find an appropriate mapping\nfrom tracked vertical foot motion to natural cyclical movements of real\nwalking. In this work, we present a kinematic approach based on animation\nrigging to generating real-time leg animation. Our method works by tracking\nvertical in-place foot movements of a user with a Kinect v2 sensor and mapping\ntracked foot height to Inverse Kinematics (IK) targets. These IK targets were\naligned with an avatar's feet to guide the virtual feet to perform cyclic\nwalking motions. We conducted a user study to evaluate our approach. Results\nshowed that the proposed method produced compelling forward-backward leg\nanimation during walking. The proposed technique can be easily integrated into\nexisting WIP techniques.",
    "descriptor": "\nComments: Under publication consideration\n",
    "authors": [
      "Jingbo Zhao",
      "Zhetao Wang",
      "Yiqin Peng",
      "Yaojun Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.12466"
  },
  {
    "id": "arXiv:2112.12478",
    "title": "Hierarchical Multi-Building And Multi-Floor Indoor Localization Based On  Recurrent Neural Networks",
    "abstract": "There has been an increasing tendency to move from outdoor to indoor\nlifestyle in modern cities. The emergence of big shopping malls, indoor sports\ncomplexes, factories, and warehouses is accelerating this tendency. In such an\nenvironment, indoor localization becomes one of the essential services, and the\nindoor localization systems to be deployed should be scalable enough to cover\nthe expected expansion of those indoor facilities. One of the most economical\nand practical approaches to indoor localization is Wi-Fi fingerprinting, which\nexploits the widely-deployed Wi-Fi networks using mobile devices (e.g.,\nsmartphones) without any modification of the existing infrastructure.\nTraditional Wi-Fi fingerprinting schemes rely on complicated data\npre/post-processing and time-consuming manual parameter tuning. In this paper,\nwe propose hierarchical multi-building and multi-floor indoor localization\nbased on a recurrent neural network (RNN) using Wi-Fi fingerprinting,\neliminating the need of complicated data pre/post-processing and with less\nparameter tuning. The RNN in the proposed scheme estimates locations in a\nsequential manner from a general to a specific one (e.g.,\nbuilding->floor->location) in order to exploit the hierarchical nature of the\nlocalization in multi-building and multi-floor environments. The experimental\nresults with the UJIIndoorLoc dataset demonstrate that the proposed scheme\nestimates building and floor with 100% and 95.24% accuracy, respectively, and\nprovides three-dimensional positioning error of 8.62 m, which outperforms\nexisting deep neural network-based schemes.",
    "descriptor": "\nComments: 4 pages, 3 figures, the 6th International Workshop on GPU Computing and AI (GCA'21)\n",
    "authors": [
      "Abdalla Elmokhtar Ahmed Elesawi",
      "Kyeong Soo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.12478"
  },
  {
    "id": "arXiv:2112.12480",
    "title": "Space-time error control using a partition-of-unity dual-weighted  residual method applied to low mach number combustion",
    "abstract": "In this work, a space-time scheme for goal-oriented a posteriori error\nestimation is proposed. The error estimator is evaluated using a\npartition-of-unity dual-weighted residual method. As application, a low mach\nnumber combustion equation is considered. In some numerical tests, different\ninterpolation variants are investigated, while observing convergence orders and\neffectivity indices between true errors (obtained on a sufficiently refined\nmesh) and the error estimator.",
    "descriptor": "",
    "authors": [
      "Jan Philipp Thiele",
      "Thomas Wick"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.12480"
  },
  {
    "id": "arXiv:2112.12484",
    "title": "Pose Adaptive Dual Mixup for Few-Shot Single-View 3D Reconstruction",
    "abstract": "We present a pose adaptive few-shot learning procedure and a two-stage data\ninterpolation regularization, termed Pose Adaptive Dual Mixup (PADMix), for\nsingle-image 3D reconstruction. While augmentations via interpolating\nfeature-label pairs are effective in classification tasks, they fall short in\nshape predictions potentially due to inconsistencies between interpolated\nproducts of two images and volumes when rendering viewpoints are unknown.\nPADMix targets this issue with two sets of mixup procedures performed\nsequentially. We first perform an input mixup which, combined with a pose\nadaptive learning procedure, is helpful in learning 2D feature extraction and\npose adaptive latent encoding. The stagewise training allows us to build upon\nthe pose invariant representations to perform a follow-up latent mixup under\none-to-one correspondences between features and ground-truth volumes. PADMix\nsignificantly outperforms previous literature on few-shot settings over the\nShapeNet dataset and sets new benchmarks on the more challenging real-world\nPix3D dataset.",
    "descriptor": "\nComments: To appear in the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI), February 2022\n",
    "authors": [
      "Ta-Ying Cheng",
      "Hsuan-Ru Yang",
      "Niki Trigoni",
      "Hwann-Tzong Chen",
      "Tyng-Luh Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12484"
  },
  {
    "id": "arXiv:2112.12485",
    "title": "On the Reception Process of Molecular Communication-Based Drug Delivery",
    "abstract": "One of the important applications of molecular communication is the targeted\ndrug delivery process in which the drug molecules are released toward the\ntarget (receiver) in a way that the side effects are minimized in the human\nbody. As the total number of released molecules increases, the receiver cannot\nreceive all of the transmitted drug molecules. Therefore, the molecules would\nbe accumulated in the system which results in side effects in the body. In\norder to diagnose the appropriate transmission rate of the drug molecules, it\nis important to investigate the reception process of the receiver. In this\npaper, a reception model is studied using queuing theory. In the proposed\nmodel, the rejection rate of the drug molecules due to different reasons, such\nas random movement of the molecules, as well as the rejection rate due to\nactive receptors are taken into account. Moreover, an interval consisting of\nthe lower and upper bounds for the number of released molecules is presented\nbased on the proposed model in order to determine the range of allowable dosage\nof the drug molecules. It is shown that the queuing theory can be successfully\nemployed in accurate modeling of the reception process of the receiver in drug\ndelivery applications.",
    "descriptor": "",
    "authors": [
      "Roya Paridar",
      "Nader Mokari",
      "Eduard Jorswieck",
      "Mohammad Reza Javan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.12485"
  },
  {
    "id": "arXiv:2112.12489",
    "title": "TFW2V: An Enhanced Document Similarity Method for the Morphologically  Rich Finnish Language",
    "abstract": "Measuring the semantic similarity of different texts has many important\napplications in Digital Humanities research such as information retrieval,\ndocument clustering and text summarization. The performance of different\nmethods depends on the length of the text, the domain and the language. This\nstudy focuses on experimenting with some of the current approaches to Finnish,\nwhich is a morphologically rich language. At the same time, we propose a simple\nmethod, TFW2V, which shows high efficiency in handling both long text documents\nand limited amounts of data. Furthermore, we design an objective evaluation\nmethod which can be used as a framework for benchmarking text similarity\napproaches.",
    "descriptor": "\nComments: Workshop on Natural Language Processing for Digital Humanities (NLP4DH)\n",
    "authors": [
      "Quan Duong",
      "Mika H\u00e4m\u00e4l\u00e4inen",
      "Khalid Alnajjar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.12489"
  },
  {
    "id": "arXiv:2112.12490",
    "title": "Curriculum Learning for Safe Mapless Navigation",
    "abstract": "This work investigates the effects of Curriculum Learning (CL)-based\napproaches on the agent's performance. In particular, we focus on the safety\naspect of robotic mapless navigation, comparing over a standard end-to-end\n(E2E) training strategy. To this end, we present a CL approach that leverages\nTransfer of Learning (ToL) and fine-tuning in a Unity-based simulation with the\nRobotnik Kairos as a robotic agent. For a fair comparison, our evaluation\nconsiders an equal computational demand for every learning approach (i.e., the\nsame number of interactions and difficulty of the environments) and confirms\nthat our CL-based method that uses ToL outperforms the E2E methodology. In\nparticular, we improve the average success rate and the safety of the trained\npolicy, resulting in 10% fewer collisions in unseen testing scenarios. To\nfurther confirm these results, we employ a formal verification tool to quantify\nthe number of correct behaviors of Reinforcement Learning policies over desired\nspecifications.",
    "descriptor": "\nComments: 8 pages, 5 figures. The poster version of this paper has been accepted by The 37th ACM/SIGAPP Symposium on Applied Computing Proceedings (SAC IRMAS 2022)\n",
    "authors": [
      "Luca Marzari",
      "Davide Corsi",
      "Enrico Marchesini",
      "Alessandro Farinelli"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.12490"
  },
  {
    "id": "arXiv:2112.12494",
    "title": "LaTr: Layout-Aware Transformer for Scene-Text VQA",
    "abstract": "We propose a novel multimodal architecture for Scene Text Visual Question\nAnswering (STVQA), named Layout-Aware Transformer (LaTr). The task of STVQA\nrequires models to reason over different modalities. Thus, we first investigate\nthe impact of each modality, and reveal the importance of the language module,\nespecially when enriched with layout information. Accounting for this, we\npropose a single objective pre-training scheme that requires only text and\nspatial cues. We show that applying this pre-training scheme on scanned\ndocuments has certain advantages over using natural images, despite the domain\ngap. Scanned documents are easy to procure, text-dense and have a variety of\nlayouts, helping the model learn various spatial cues (e.g. left-of, below\netc.) by tying together language and layout information. Compared to existing\napproaches, our method performs vocabulary-free decoding and, as shown,\ngeneralizes well beyond the training vocabulary. We further demonstrate that\nLaTr improves robustness towards OCR errors, a common reason for failure cases\nin STVQA. In addition, by leveraging a vision transformer, we eliminate the\nneed for an external object detector. LaTr outperforms state-of-the-art STVQA\nmethods on multiple datasets. In particular, +7.6% on TextVQA, +10.8% on ST-VQA\nand +4.0% on OCR-VQA (all absolute accuracy numbers).",
    "descriptor": "",
    "authors": [
      "Ali Furkan Biten",
      "Ron Litman",
      "Yusheng Xie",
      "Srikar Appalaraju",
      "R. Manmatha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12494"
  },
  {
    "id": "arXiv:2112.12495",
    "title": "Polar codes do not have many affine automorphisms",
    "abstract": "Arikan's polar codes are invariant under lower-triangular affine permutations\namongst others. However, those permutations are not useful in the context of\npermutation decoding. We show that, unfortunately, the group of affine\nautomorphisms of Arikan's polar codes asymptotically cannot be much bigger than\nthe group of lower-triangular permutations.",
    "descriptor": "\nComments: Submitted to IEEE Communications Letters\n",
    "authors": [
      "Kirill Ivanov",
      "R\u00fcdiger Urbanke"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.12495"
  },
  {
    "id": "arXiv:2112.12496",
    "title": "FedFR: Joint Optimization Federated Framework for Generic and  Personalized Face Recognition",
    "abstract": "Current state-of-the-art deep learning based face recognition (FR) models\nrequire a large number of face identities for central training. However, due to\nthe growing privacy awareness, it is prohibited to access the face images on\nuser devices to continually improve face recognition models. Federated Learning\n(FL) is a technique to address the privacy issue, which can collaboratively\noptimize the model without sharing the data between clients. In this work, we\npropose a FL based framework called FedFR to improve the generic face\nrepresentation in a privacy-aware manner. Besides, the framework jointly\noptimizes personalized models for the corresponding clients via the proposed\nDecoupled Feature Customization module. The client-specific personalized model\ncan serve the need of optimized face recognition experience for registered\nidentities at the local device. To the best of our knowledge, we are the first\nto explore the personalized face recognition in FL setup. The proposed\nframework is validated to be superior to previous approaches on several generic\nand personalized face recognition benchmarks with diverse FL scenarios. The\nsource codes and our proposed personalized FR benchmark under FL setup are\navailable at https://github.com/jackie840129/FedFR.",
    "descriptor": "\nComments: This paper was accepted by AAAI 2022 Conference on Artificial Intelligence\n",
    "authors": [
      "Chih-Ting Liu",
      "Chien-Yi Wang",
      "Shao-Yi Chien",
      "Shang-Hong Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12496"
  },
  {
    "id": "arXiv:2112.12500",
    "title": "Heuristic Random Designs for Exact Identification of Defectives Using  Single Round Non-adaptive Group Testing and Compressed Sensing",
    "abstract": "Among the challenges that the COVID-19 pandemic outbreak revealed is the\nproblem to reduce the number of tests required for identifying the virus\ncarriers in order to contain the viral spread while preserving the tests\nreliability. To cope with this issue, a prevalence testing paradigm based on\ngroup testing and compressive sensing approach or GTCS was examined. In these\nsettings, a non-adaptive group testing algorithm is designed to rule out\nsure-negative samples. Then, on the reduced problem, a compressive sensing\nalgorithm is applied to decode the positives without requiring any further\ntesting besides the initial test matrix designed for the group testing phase.\nThe result is a single-round non-adaptive group testing - compressive sensing\nalgorithm to identify the positive samples.\nIn this paper, we propose a heuristic random method to construct the test\ndesign called $\\alpha-$random row design or $\\alpha-$RRD. In the $\\alpha-$RRD,\na random test matrix is constructed such that each test aggregates at most\n$\\alpha$ samples in one group test or pool. The pooled tests are heuristically\nselected one by one such that samples that were previously selected in the same\ntest are less likely to be aggregated together in a new test. We examined the\nperformance of the $\\alpha-$RRD design within the GTCS paradigm for several\nvalues of $\\alpha$. The experiments were conducted on synthetic data. Our\nresults show that, for some values of $\\alpha$, a reduction of up to 10 fold in\nthe tests number can be achieved when $\\alpha-$RRD design is applied in the\nGTCS paradigm.",
    "descriptor": "",
    "authors": [
      "Catherine A. Haddad-Zaaknoon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.12500"
  },
  {
    "id": "arXiv:2112.12506",
    "title": "Attentive Multi-View Deep Subspace Clustering Net",
    "abstract": "In this paper, we propose a novel Attentive Multi-View Deep Subspace Nets\n(AMVDSN), which deeply explores underlying consistent and view-specific\ninformation from multiple views and fuse them by considering each view's\ndynamic contribution obtained by attention mechanism. Unlike most multi-view\nsubspace learning methods that they directly reconstruct data points on raw\ndata or only consider consistency or complementarity when learning\nrepresentation in deep or shallow space, our proposed method seeks to find a\njoint latent representation that explicitly considers both consensus and\nview-specific information among multiple views, and then performs subspace\nclustering on learned joint latent representation.Besides, different views\ncontribute differently to representation learning, we therefore introduce\nattention mechanism to derive dynamic weight for each view, which performs much\nbetter than previous fusion methods in the field of multi-view subspace\nclustering. The proposed algorithm is intuitive and can be easily optimized\njust by using Stochastic Gradient Descent (SGD) because of the neural network\nframework, which also provides strong non-linear characterization capability\ncompared with traditional subspace clustering approaches. The experimental\nresults on seven real-world data sets have demonstrated the effectiveness of\nour proposed algorithm against some state-of-the-art subspace learning\napproaches.",
    "descriptor": "",
    "authors": [
      "Run-kun Lu",
      "Jian-wei Liu",
      "Xin Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12506"
  },
  {
    "id": "arXiv:2112.12508",
    "title": "From Procedures, Objects, Actors, Components, Services, to Agents -- A  Comparative Analysis of the History and Evolution of Programming Abstractions",
    "abstract": "The objective of this chapter is to propose some retrospective analysis of\nthe evolution of programming abstractions, from {\\em procedures}, {\\em\nobjects}, {\\em actors}, {\\em components}, {\\em services}, up to {\\em agents},\n%have some compare concepts of software component and of agent (and multi-agent\nsystem), %The method chosen is to by replacing them within a general historical\nperspective. Some common referential with three axes/dimensions is chosen: {\\em\naction selection} at the level of one entity, {\\em coupling flexibility}\nbetween entities, and {\\em abstraction level}. We indeed may observe some\ncontinuous quest for higher flexibility (through notions such as {\\em late\nbinding}, or {\\em reification} of {\\em connections}) and higher level of {\\em\nabstraction}. Concepts of components, services and agents have some common\nobjectives (notably, {\\em software modularity and reconfigurability}), with\nmulti-agent systems raising further concepts of {\\em autonomy} and {\\em\ncoordination}. notably through the notion of {\\em auto-organization} and the\nuse of {\\em knowledge}. We hope that this analysis helps at highlighting some\nof the basic forces motivating the progress of programming abstractions and\ntherefore that it may provide some seeds for the reflection about future\nprogramming abstractions.",
    "descriptor": "\nComments: This article has been submitted to a project of book about the French school of programming, coordinated by Bertrand Meyer\n",
    "authors": [
      "Jean-Pierre Briot"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.12508"
  },
  {
    "id": "arXiv:2112.12510",
    "title": "Neuroevolution deep learning architecture search for estimation of river  surface elevation from photogrammetric Digital Surface Models",
    "abstract": "Development of the new methods of surface water observation is crucial in the\nperspective of increasingly frequent extreme hydrological events related to\nglobal warming and increasing demand for water. Orthophotos and digital surface\nmodels (DSMs) obtained using UAV photogrammetry can be used to determine the\nWater Surface Elevation (WSE) of a river. However, this task is difficult due\nto disturbances of the water surface on DSMs caused by limitations of\nphotogrammetric algorithms. In this study, machine learning was used to extract\na WSE value from disturbed photogrammetric data. A brand new dataset has been\nprepared specifically for this purpose by hydrology and photogrammetry experts.\nThe new method is an important step toward automating water surface level\nmeasurements with high spatial and temporal resolution. Such data can be used\nto validate and calibrate of hydrological, hydraulic and hydrodynamic models\nmaking hydrological forecasts more accurate, in particular predicting extreme\nand dangerous events such as floods or droughts. For our knowledge this is the\nfirst approach in which dataset was created for this purpose and deep learning\nmodels were used for this task. Additionally, neuroevolution algorithm was set\nto explore different architectures to find local optimal models and\nnon-gradient search was performed to fine-tune the model parameters. The\nachieved results have better accuracy compared to manual methods of determining\nWSE from photogrammetric DSMs.",
    "descriptor": "\nComments: extended version of NeurIPS 2021 Workshop paper - ML4PhysicalSciences\n",
    "authors": [
      "Rados\u0142aw Szostak",
      "Marcin Pietro\u0144",
      "Miros\u0142aw Zimnoch",
      "Przemys\u0142aw Wachniew",
      "Pawe\u0142 \u0106wi\u0105ka\u0142a",
      "Edyta Puniach"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12510"
  },
  {
    "id": "arXiv:2112.12517",
    "title": "Adaptive Neural Domain Refinement for Solving Time-Dependent  Differential Equations",
    "abstract": "A classic approach for solving differential equations with neural networks\nbuilds upon neural forms, in which a cost function can be constructed directly\nusing the differential equation with a discretisation of the solution domain.\nMaking use of neural forms for time-dependent differential equations, one can\napply the recently developed method of domain fragmentation. That is, the\ndomain may be split into several subdomains, on which the optimisation problem\nis solved. In classic adaptive numerical methods for solving differential\nequations, the mesh as well as the domain may be refined or decomposed,\nrespectively, in order to improve accuracy. Also the degree of approximation\naccuracy may be adapted. It would be desirable to transfer such important and\nsuccessful strategies to the field of neural network based solutions. In the\npresent work, we propose a novel adaptive neural approach to meet this aim for\nsolving time-dependent problems. To this end, each subdomain is reduced in size\nuntil the optimisation is resolved up to a predefined training accuracy. In\naddition, while the neural networks employed are by default small, the number\nof neurons may also be adjusted in an adaptive way. We introduce conditions to\nautomatically confirm the solution reliability and optimise computational\nparameters whenever it is necessary. We provide results for three carefully\nchosen example initial value problems and illustrate important properties of\nthe method alongside.",
    "descriptor": "",
    "authors": [
      "Toni Schneidereit",
      "Michael Breu\u00df"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.12517"
  },
  {
    "id": "arXiv:2112.12520",
    "title": "Dependability Analysis of Data Storage Systems in Presence of Soft  Errors",
    "abstract": "In recent years, high availability and reliability of Data Storage Systems\n(DSS) have been significantly threatened by soft errors occurring in storage\ncontrollers. Due to their specific functionality and hardware-software stack,\nerror propagation and manifestation in DSS is quite different from\ngeneral-purpose computing architectures. To our knowledge, no previous study\nhas examined the system-level effects of soft errors on the availability and\nreliability of data storage systems. In this paper, we first analyze the\neffects of soft errors occurring in the server processors of storage\ncontrollers on the entire storage system dependability. To this end, we\nimplemented the major functions of a typical data storage system controller,\nrunning on a full stack of storage system operating system, and developed a\nframework to perform fault injection experiments using a full system simulator.\nWe then propose a new metric, Storage System Vulnerability Factor (SSVF), to\naccurately capture the impact of soft errors in storage systems. By conducting\nextensive experiments, it is revealed that depending on the controller\nconfiguration, up to 40% of cache memory contains end-user data where any\nunrecoverable soft errors in this part will result in Data Loss (DL) in an\nirreversible manner. However, soft errors in the rest of cache memory filled by\nOperating System (OS) and storage applications will result in Data\nUnavailability (DU) at the storage system level. Our analysis also shows that\nDetectable Unrecoverable Errors (DUEs) on the cache data field are the major\ncause of DU in storage systems, while Silent Data Corruptions (SDCs) in the\ncache tag and data field are mainly the cause of DL in storage systems.",
    "descriptor": "",
    "authors": [
      "Mostafa Kishani",
      "Mehdi Tahoori",
      "Hossein Asadi"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Hardware Architecture (cs.AR)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.12520"
  },
  {
    "id": "arXiv:2112.12522",
    "title": "Data Augmentation based Consistency Contrastive Pre-training for  Automatic Speech Recognition",
    "abstract": "Self-supervised acoustic pre-training has achieved amazing results on the\nautomatic speech recognition (ASR) task. Most of the successful acoustic\npre-training methods use contrastive learning to learn the acoustic\nrepresentations by distinguish the representations from different time steps,\nignoring the speaker and environment robustness. As a result, the pre-trained\nmodel could show poor performance when meeting out-of-domain data during\nfine-tuning. In this letter, we design a novel consistency contrastive learning\n(CCL) method by utilizing data augmentation for acoustic pre-training.\nDifferent kinds of augmentation are applied on the original audios and then the\naugmented audios are fed into an encoder. The encoder should not only contrast\nthe representations within one audio but also maximize the measurement of the\nrepresentations across different augmented audios. By this way, the pre-trained\nmodel can learn a text-related representation method which is more robust with\nthe change of the speaker or the environment.Experiments show that by applying\nthe CCL method on the Wav2Vec2.0, better results can be realized both on the\nin-domain data and the out-of-domain data. Especially for noisy out-of-domain\ndata, more than 15% relative improvement can be obtained.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Changfeng Gao",
      "Gaofeng Cheng",
      "Yifan Guo",
      "Qingwei Zhao",
      "Pengyuan Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.12522"
  },
  {
    "id": "arXiv:2112.12524",
    "title": "Emulation of greenhouse-gas sensitivities using variational autoencoders",
    "abstract": "Flux inversion is the process by which sources and sinks of a gas are\nidentified from observations of gas mole fraction. The inversion often involves\nrunning a Lagrangian particle dispersion model (LPDM) to generate sensitivities\nbetween observations and fluxes over a spatial domain of interest. The LPDM\nmust be run backward in time for every gas measurement, and this can be\ncomputationally prohibitive. To address this problem, here we develop a novel\nspatio-temporal emulator for LPDM sensitivities that is built using a\nconvolutional variational autoencoder (CVAE). With the encoder segment of the\nCVAE, we obtain approximate (variational) posterior distributions over latent\nvariables in a low-dimensional space. We then use a spatio-temporal Gaussian\nprocess emulator on the low-dimensional space to emulate new variables at\nprediction locations and time points. Emulated variables are then passed\nthrough the decoder segment of the CVAE to yield emulated sensitivities. We\nshow that our CVAE-based emulator outperforms the more traditional emulator\nbuilt using empirical orthogonal functions and that it can be used with\ndifferent LPDMs. We conclude that our emulation-based approach can be used to\nreliably reduce the computing time needed to generate LPDM outputs for use in\nhigh-resolution flux inversions.",
    "descriptor": "\nComments: 25 pages, 8 figures, 2 tables, data & code available\n",
    "authors": [
      "Laura Cartwright",
      "Andrew Zammit-Mangion",
      "Nicholas M. Deutscher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.12524"
  },
  {
    "id": "arXiv:2112.12530",
    "title": "Long-Term Optimal Delivery Planning for Replacing the Liquefied  Petroleum Gas Cylinder",
    "abstract": "This study proposes a method for efficient delivery of liquefied petroleum\ngas cylinders based on demand forecasts of gas usage. To maintain a liquefied\npetroleum gas service, gas providers visit each customer to check the gas meter\nand replace the gas cylinder depending on the remaining amount of gas. These\nvisits can be categorized into three patterns: non-replacement visit,\nreplacement before the customer runs out of gas, and replacement after the\ncustomer runs out of gas. The last pattern is a crucial problem in sustaining a\nliquefied petroleum gas service, and it must be reduced. By contrast, frequent\nnon-replacement visits are required to prevent the customer from running out of\ngas, but it requires considerable effort. One of the most severe difficulties\nof this problem is acquiring the gas usages of each customer only by visiting.\nHowever, with the recent spread of smart sensors, the daily gas consumption of\neach house can be monitored without having to visit customers. Our main idea is\nto categorize all customers into three groups: high-risk, moderate-risk, and\nlow-risk by focusing on an urgent need for cylinder replacement based on the\ndemand forecast. Based on this idea, we construct an algorithm to maximize the\ndelivery for moderate-risk customers while ensuring delivery to high-risk\ncustomers. Long-term optimal delivery planning is realized by achieving\nworkload balancing per day. The verification experiment in Chiba prefecture in\nJapan showed the effectiveness of our algorithm in reducing the number of\nout-of-gas cylinders. Moreover, the proposed model is a new generic framework\nfor building an optimal vehicle routing plan, consisting of a complementary\nalgorithm, demand forecast, delivery list optimization, and delivery route\noptimization for realizing a long-term optimal delivery plan by setting the\npriority.",
    "descriptor": "\nComments: 46 pages\n",
    "authors": [
      "Akihiro Yoshida",
      "Haruki Sato",
      "Shiori Uchiumi",
      "Nariaki Tateiwa",
      "Daisuke Kataoka",
      "Akira Tanaka",
      "Nozomi Hata",
      "Yousuke Yatsushiro",
      "Ayano Ide",
      "Hiroki Ishikura",
      "Shingo Egi",
      "Miyu Fujii",
      "Hiroki Kai",
      "Katsuki Fujisawa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.12530"
  },
  {
    "id": "arXiv:2112.12533",
    "title": "PyCIL: A Python Toolbox for Class-Incremental Learning",
    "abstract": "Traditional machine learning systems are deployed under the closed-world\nsetting, which requires the entire training data before the offline training\nprocess. However, real-world applications often face the incoming new classes,\nand a model should incorporate them continually. The learning paradigm is\ncalled Class-Incremental Learning (CIL). We propose a Python toolbox that\nimplements several key algorithms for class-incremental learning to ease the\nburden of researchers in the machine learning community. The toolbox contains\nimplementations of a number of founding works of CIL such as EWC and iCaRL, but\nalso provides current state-of-the-art algorithms that can be used for\nconducting novel fundamental research. This toolbox, named PyCIL for Python\nClass-Incremental Learning, is available at https://github.com/G-U-N/PyCIL",
    "descriptor": "\nComments: Technical report. Code is available at this https URL\n",
    "authors": [
      "Da-Wei Zhou",
      "Fu-Yun Wang",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12533"
  },
  {
    "id": "arXiv:2112.12535",
    "title": "FourierMask: Instance Segmentation using Fourier Mapping in Implicit  Neural Networks",
    "abstract": "We present FourierMask, which employs Fourier series combined with implicit\nneural representations to generate instance segmentation masks. We apply a\nFourier mapping (FM) to the coordinate locations and utilize the mapped\nfeatures as inputs to an implicit representation (coordinate-based multi-layer\nperceptron (MLP)). FourierMask learns to predict the coefficients of the FM for\na particular instance, and therefore adapts the FM to a specific object. This\nallows FourierMask to be generalized to predict instance segmentation masks\nfrom natural images. Since implicit functions are continuous in the domain of\ninput coordinates, we illustrate that by sub-sampling the input pixel\ncoordinates, we can generate higher resolution masks during inference.\nFurthermore, we train a renderer MLP (FourierRend) on the uncertain predictions\nof FourierMask and illustrate that it significantly improves the quality of the\nmasks. FourierMask shows competitive results on the MS COCO dataset compared to\nthe baseline Mask R-CNN at the same output resolution and surpasses it on\nhigher resolution.",
    "descriptor": "",
    "authors": [
      "Hamd ul Moqeet Riaz",
      "Nuri Benbarka",
      "Timon Hoeffer",
      "Andreas Zell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12535"
  },
  {
    "id": "arXiv:2112.12542",
    "title": "How Much of the Chemical Space Has Been Covered? Measuring and Improving  the Variety of Candidate Set in Molecular Generation",
    "abstract": "Forming a high-quality molecular candidate set that contains a wide range of\ndissimilar compounds is crucial to the success of drug discovery. However,\ncomparing to the research aiming at optimizing chemical properties, how to\nmeasure and improve the variety of drug candidates is relatively understudied.\nIn this paper, we first investigate the problem of properly measuring the\nmolecular variety through both an axiomatic analysis framework and an empirical\nstudy. Our analysis suggests that many existing measures are not suitable for\nevaluating the variety of molecules. We also propose new variety measures based\non our analysis. We further explicitly integrate the proposed variety measures\ninto the optimization objective of molecular generation models. Our experiment\nresults demonstrate that this new optimization objective can guide molecular\ngeneration models to find compounds that cover a lager chemical space,\nproviding the downstream phases with more distinctive drug candidate choices.",
    "descriptor": "",
    "authors": [
      "Yutong Xie",
      "Ziqiao Xu",
      "Jiaqi Ma",
      "Qiaozhu Mei"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12542"
  },
  {
    "id": "arXiv:2112.12544",
    "title": "Newsvendor Model with Deep Reinforcement Learning",
    "abstract": "I present a deep reinforcement learning (RL) solution to the mathematical\nproblem known as the Newsvendor model, which seeks to optimize profit given a\nprobabilistic demand distribution. To reflect a more realistic and complex\nsituation, the demand distribution can change for different days of the week,\nthus changing the optimum behavior. I used a Twin-Delayed Deep Deterministic\nPolicy Gradient agent (written as completely original code) with both an actor\nand critic network to solve this problem. The agent was able to learn optimal\nbehavior consistent with the analytical solution of the problem, and could\nidentify separate probability distributions for different days of the week and\nbehave accordingly.",
    "descriptor": "\nComments: 10 pages with 4 figures\n",
    "authors": [
      "Dylan K. Goetting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12544"
  },
  {
    "id": "arXiv:2112.12546",
    "title": "Collaborative adversary nodes learning on the logs of IoT devices in an  IoT network",
    "abstract": "Artificial Intelligence (AI) development has encouraged many new research\nareas, including AI-enabled Internet of Things (IoT) network. AI analytics and\nintelligent paradigms greatly improve learning efficiency and accuracy.\nApplying these learning paradigms to network scenarios provide technical\nadvantages of new networking solutions. In this paper, we propose an improved\napproach for IoT security from data perspective. The network traffic of IoT\ndevices can be analyzed using AI techniques. The Adversary Learning (AdLIoTLog)\nmodel is proposed using Recurrent Neural Network (RNN) with attention mechanism\non sequences of network events in the network traffic. We define network events\nas a sequence of the time series packets of protocols captured in the log. We\nhave considered different packets TCP packets, UDP packets, and HTTP packets in\nthe network log to make the algorithm robust. The distributed IoT devices can\ncollaborate to cripple our world which is extending to Internet of\nIntelligence. The time series packets are converted into structured data by\nremoving noise and adding timestamps. The resulting data set is trained by RNN\nand can detect the node pairs collaborating with each other. We used the BLEU\nscore to evaluate the model performance. Our results show that the predicting\nperformance of the AdLIoTLog model trained by our method degrades by 3-4% in\nthe presence of attack in comparison to the scenario when the network is not\nunder attack. AdLIoTLog can detect adversaries because when adversaries are\npresent the model gets duped by the collaborative events and therefore predicts\nthe next event with a biased event rather than a benign event. We conclude that\nAI can provision ubiquitous learning for the new generation of Internet of\nThings.",
    "descriptor": "",
    "authors": [
      "Sandhya Aneja",
      "Melanie Ang Xuan En",
      "Nagender Aneja"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.12546"
  },
  {
    "id": "arXiv:2112.12549",
    "title": "Combining Minkowski and Chebyshev: New distance proposal and survey of  distance metrics using k-nearest neighbours classifier",
    "abstract": "This work proposes a distance that combines Minkowski and Chebyshev distances\nand can be seen as an intermediary distance. This combination not only achieves\nefficient run times in neighbourhood iteration tasks in Z^2, but also obtains\ngood accuracies when coupled with the k-Nearest Neighbours (k-NN) classifier.\nThe proposed distance is approximately 1.3 times faster than Manhattan distance\nand 329.5 times faster than Euclidean distance in discrete neighbourhood\niterations. An accuracy analysis of the k-NN classifier using a total of 33\ndatasets from the UCI repository, 15 distances and values assigned to k that\nvary from 1 to 200 is presented. In this experiment, the proposed distance\nobtained accuracies that were better than the average more often than its\ncounterparts (in 26 cases out of 33), and also obtained the best accuracy more\nfrequently (in 9 out of 33 cases).",
    "descriptor": "\nComments: Pattern Recognition Letters, 2018\n",
    "authors": [
      "\u00c9rick Oliveira Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12549"
  },
  {
    "id": "arXiv:2112.12551",
    "title": "Preprocessing in Inductive Logic Programming",
    "abstract": "Inductive logic programming is a type of machine learning in which logic\nprograms are learned from examples. This learning typically occurs relative to\nsome background knowledge provided as a logic program. This dissertation\nintroduces bottom preprocessing, a method for generating initial constraints on\nthe programs an ILP system must consider. Bottom preprocessing applies ideas\nfrom inverse entailment to modern ILP systems. Inverse entailment is an\ninfluential early ILP approach introduced with Progol. This dissertation also\npresents $\\bot$-Popper, an implementation of bottom preprocessing for the\nmodern ILP system Popper. It is shown experimentally that bottom preprocessing\ncan reduce learning times of ILP systems on hard problems. This reduction can\nbe especially significant when the amount of background knowledge in the\nproblem is large.",
    "descriptor": "\nComments: 91 pages, 6 figures, Masters thesis\n",
    "authors": [
      "Brad Hunter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.12551"
  },
  {
    "id": "arXiv:2112.12559",
    "title": "Multigrid solvers for isogeometric discretizations of the second  biharmonic problem",
    "abstract": "We develop a multigrid solver for the second biharmonic problem in the\ncontext of Isogeometric Analysis (IgA), where we also allow a zero-order term.\nIn a previous paper, the authors have developed an analysis for the first\nbiharmonic problem based on Hackbusch's framework. This analysis can only be\nextended to the second biharmonic problem if one assumes uniform grids. In this\npaper, we prove a multigrid convergence estimate using Bramble's framework for\nmultigrid analysis without regularity assumptions. We show that the bound for\nthe convergence rate is independent of the scaling of the zero-order term and\nthe spline degree. It only depends linearly on the number of levels, thus\nlogarithmically on the grid size. Numerical experiments are provided which\nillustrate the convergence theory and the efficiency of the proposed multigrid\napproaches.",
    "descriptor": "",
    "authors": [
      "Jarle Sogn",
      "Stefan Takacs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12559"
  },
  {
    "id": "arXiv:2112.12566",
    "title": "Integrating Material Selection with Design Optimization via Neural  Networks",
    "abstract": "The engineering design process often entails optimizing the underlying\ngeometry while simultaneously selecting a suitable material. For a certain\nclass of simple problems, the two are separable where, for example, one can\nfirst select an optimal material, and then optimize the geometry. However, in\ngeneral, the two are not separable. Furthermore, the discrete nature of\nmaterial selection is not compatible with gradient-based geometry optimization,\nmaking simultaneous optimization challenging.\nIn this paper, we propose the use of variational autoencoders (VAE) for\nsimultaneous optimization. First, a data-driven VAE is used to project the\ndiscrete material database onto a continuous and differentiable latent space.\nThis is then coupled with a fully-connected neural network, embedded with a\nfinite-element solver, to simultaneously optimize the material and geometry.\nThe neural-network's built-in gradient optimizer and back-propagation are\nexploited during optimization.\nThe proposed framework is demonstrated using trusses, where an optimal\nmaterial needs to be chosen from a database, while simultaneously optimizing\nthe cross-sectional areas of the truss members. Several numerical examples\nillustrate the efficacy of the proposed framework. The Python code used in\nthese experiments is available at github.com/UW-ERSL/MaTruss",
    "descriptor": "\nComments: 16 pages, submitted to Structural and Multidisciplinary Optimization\n",
    "authors": [
      "Aaditya Chandrasekhar",
      "Saketh Sridhara",
      "Krishnan Suresh"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12566"
  },
  {
    "id": "arXiv:2112.12573",
    "title": "Boosting Generative Zero-Shot Learning by Synthesizing Diverse Features  with Attribute Augmentation",
    "abstract": "The recent advance in deep generative models outlines a promising perspective\nin the realm of Zero-Shot Learning (ZSL). Most generative ZSL methods use\ncategory semantic attributes plus a Gaussian noise to generate visual features.\nAfter generating unseen samples, this family of approaches effectively\ntransforms the ZSL problem into a supervised classification scheme. However,\nthe existing models use a single semantic attribute, which contains the\ncomplete attribute information of the category. The generated data also carry\nthe complete attribute information, but in reality, visual samples usually have\nlimited attributes. Therefore, the generated data from attribute could have\nincomplete semantics. Based on this fact, we propose a novel framework to boost\nZSL by synthesizing diverse features. This method uses augmented semantic\nattributes to train the generative model, so as to simulate the real\ndistribution of visual features. We evaluate the proposed model on four\nbenchmark datasets, observing significant performance improvement against the\nstate-of-the-art.",
    "descriptor": "\nComments: Accepted by AAAI2022\n",
    "authors": [
      "Xiaojie Zhao",
      "Yuming Shen",
      "Shidong Wang",
      "Haofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12573"
  },
  {
    "id": "arXiv:2112.12575",
    "title": "A Modeling Framework for Reliability of Erasure Codes in SSD Arrays",
    "abstract": "To help reliability of SSD arrays, Redundant Array of Independent Disks\n(RAID) are commonly employed. However, the conventional reliability models of\nHDD RAID cannot be applied to SSD arrays, as the nature of failures in SSDs are\ndifferent from HDDs. Previous studies on the reliability of SSD arrays are\nbased on the deprecated SSD failure data, and only focus on limited failure\ntypes, device failures, and page failures caused by the bit errors, while\nrecent field studies have reported other failure types including bad blocks and\nbad chips, and a high correlation between failures. In this paper, we explore\nthe reliability of SSD arrays using field storage traces and real-system\nimplementation of conventional and emerging erasure codes. The reliability is\nevaluated by statistical fault injections that post-process the usage logs from\nthe real-system implementation, while the fault/failure attributes are obtained\nfrom field data. As a case study, we examine conventional and emerging erasure\ncodes in terms of both reliability and performance using Linux MD RAID and\ncommercial SSDs. Our analysis shows that a) emerging erasure codes fail to\nreplace RAID6 in terms of reliability, b) row-wise erasure codes are the most\nefficient choices for contemporary SSD devices, and c) previous models\noverestimate the SSD array reliability by up to six orders of magnitude, as\nthey focus on the coincidence of bad pages and bad chips that roots the\nminority of Data Loss (DL) in SSD arrays. Our experiments show that the\ncombination of bad chips with bad blocks is the major source of DL in RAID5 and\nemerging codes (contributing more than 54% and 90% of DL in RAID5 and emerging\ncodes, respectively), while RAID6 remains robust under these failure\ncombinations. Finally, the fault injection results show that SSD array\nreliability, as well as the failure breakdown is significantly correlated with\nSSD type.",
    "descriptor": "",
    "authors": [
      "Mostafa Kishani",
      "Saba Ahmadian",
      "Hossein Asadi"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.12575"
  },
  {
    "id": "arXiv:2112.12577",
    "title": "NVS-MonoDepth: Improving Monocular Depth Prediction with Novel View  Synthesis",
    "abstract": "Building upon the recent progress in novel view synthesis, we propose its\napplication to improve monocular depth estimation. In particular, we propose a\nnovel training method split in three main steps. First, the prediction results\nof a monocular depth network are warped to an additional view point. Second, we\napply an additional image synthesis network, which corrects and improves the\nquality of the warped RGB image. The output of this network is required to look\nas similar as possible to the ground-truth view by minimizing the pixel-wise\nRGB reconstruction error. Third, we reapply the same monocular depth estimation\nonto the synthesized second view point and ensure that the depth predictions\nare consistent with the associated ground truth depth. Experimental results\nprove that our method achieves state-of-the-art or comparable performance on\nthe KITTI and NYU-Depth-v2 datasets with a lightweight and simple vanilla U-Net\narchitecture.",
    "descriptor": "\nComments: 8 pages (main paper), 9 pages (supplementary material), 14 figures, 4 tables\n",
    "authors": [
      "Zuria Bauer",
      "Zuoyue Li",
      "Sergio Orts-Escolano",
      "Miguel Cazorla",
      "Marc Pollefeys",
      "Martin R. Oswald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12577"
  },
  {
    "id": "arXiv:2112.12579",
    "title": "Data-efficient learning for 3D mirror symmetry detection",
    "abstract": "We introduce a geometry-inspired deep learning method for detecting 3D mirror\nplane from single-view images. We reduce the demand for massive training data\nby explicitly adding 3D mirror geometry into learning as an inductive prior. We\nextract semantic features, calculate intra-pixel correlations, and build a 3D\ncorrelation volume for each plane. The correlation volume indicates the extent\nto which the input resembles its mirrors at various depth, allowing us to\nidentify the likelihood of the given plane being a mirror plane. Subsequently,\nwe treat the correlation volumes as feature descriptors for sampled planes and\nmap them to a unit hemisphere where the normal of sampled planes lies. Lastly,\nwe design multi-stage spherical convolutions to identify the optimal mirror\nplane in a coarse-to-fine manner. Experiments on both synthetic and real-world\ndatasets show the benefit of 3D mirror geometry in improving data efficiency\nand inference speed (up to 25 FPS).",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Yancong Lin",
      "Silvia-Laura Pintea",
      "Jan van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12579"
  },
  {
    "id": "arXiv:2112.12580",
    "title": "Long-Term Productivity Based on Science, not Preference",
    "abstract": "This position paper argues that decisions on processes, tools, techniques and\nsoftware artifacts (such as user manuals, unit tests, design documents and\ncode) for scientific software development should be driven by science, not by\npersonal preference. Decisions should not be based on anecdotal evidence, gut\ninstinct or the path of least resistance. Moreover, decisions should vary\ndepending on the users and the context. In most cases of interest, this means\nthat a longer term view should be adopted. We need to use a scientific approach\nbased on unambiguous definitions, empirical evidence, hypothesis testing and\nrigorous processes. By developing an understanding of where input hours are\nspent, what most contributes to user satisfaction, and how to leverage\nknowledge produced, we can determine what interventions have the greatest value\nrelative to the invested effort. We will be able to recommend software\nproduction processes that justify their value because the long-term output\nbenefits are high compared to the required input resources. A preliminary\ndefinition of productivity is presented, along with ideas on how to potentially\nmeasure this quality. We briefly explore the idea of improving productivity via\nan approach where all artifacts are generated from codified knowledge.",
    "descriptor": "\nComments: 2 pages\n",
    "authors": [
      "Spencer Smith",
      "Jacques Carette"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.12580"
  },
  {
    "id": "arXiv:2112.12583",
    "title": "Calculating Nash equilibrium and Nash bargaining solution on quantum  annealers",
    "abstract": "Adiabatic quantum computing is implemented on specialized hardware using\nheuristics of the quantum annealing algorithm. This set up requires that the\nproblems to be solved are formatted as discrete quadratic functions without\nconstraints, and the variables taking binary values only. The problem of\nfinding Nash equilibrium in two player, non-cooperative games is a two-fold\nquadratic optimization problem, with constraints. This problem was formatted as\na single quadratic function optimization in 1964 by Mangasarian and Stone.\nSimilarly, the Nash bargaining problem is a constrained polynomial optimization\nproblem of degree higher than 2. Here, I show that adding penalty terms to the\nquadratic function formulation of Nash equilibrium, and reducing the higher\npowers of the polynomial expression for the Nash bargaining problem, together\nwith addition of penalty terms, gives QUBO formulation of these problems for\nexecution on quantum annealers.",
    "descriptor": "",
    "authors": [
      "Faisal Shah Khan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.12583"
  },
  {
    "id": "arXiv:2112.12584",
    "title": "Attention Based Communication and Control for Multi-UAV Path Planning",
    "abstract": "Inspired by the multi-head attention (MHA) mechanism in natural language\nprocessing, this letter proposes an iterative single-head attention (ISHA)\nmechanism for multi-UAV path planning. The ISHA mechanism is run by a\ncommunication helper collecting the state embeddings of UAVs and distributing\nan attention score vector to each UAV. The attention scores computed by ISHA\nidentify how many interactions with other UAVs should be considered in each\nUAV's control decision-making. Simulation results corroborate that the\nISHA-based communication and control framework achieves faster travel with\nlower inter-UAV collision risks than an MHA-aided baseline, particularly under\nlimited communication resources.",
    "descriptor": "\nComments: 6 pages, 6 figures, submitted for possible publication\n",
    "authors": [
      "Hamid Shiri",
      "Hyowoon Seo",
      "Jihong Park",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.12584"
  },
  {
    "id": "arXiv:2112.12589",
    "title": "A deep reinforcement learning model for predictive maintenance planning  of road assets: Integrating LCA and LCCA",
    "abstract": "Road maintenance planning is an integral part of road asset management. One\nof the main challenges in Maintenance and Rehabilitation (M&R) practices is to\ndetermine maintenance type and timing. This research proposes a framework using\nReinforcement Learning (RL) based on the Long Term Pavement Performance (LTPP)\ndatabase to determine the type and timing of M&R practices. A predictive DNN\nmodel is first developed in the proposed algorithm, which serves as the\nEnvironment for the RL algorithm. For the Policy estimation of the RL model,\nboth DQN and PPO models are developed. However, PPO has been selected in the\nend due to better convergence and higher sample efficiency. Indicators used in\nthis study are International Roughness Index (IRI) and Rutting Depth (RD).\nInitially, we considered Cracking Metric (CM) as the third indicator, but it\nwas then excluded due to the much fewer data compared to other indicators,\nwhich resulted in lower accuracy of the results. Furthermore, in\ncost-effectiveness calculation (reward), we considered both the economic and\nenvironmental impacts of M&R treatments. Costs and environmental impacts have\nbeen evaluated with paLATE 2.0 software. Our method is tested on a hypothetical\ncase study of a six-lane highway with 23 kilometers length located in Texas,\nwhich has a warm and wet climate. The results propose a 20-year M&R plan in\nwhich road condition remains in an excellent condition range. Because the early\nstate of the road is at a good level of service, there is no need for heavy\nmaintenance practices in the first years. Later, after heavy M&R actions, there\nare several 1-2 years of no need for treatments. All of these show that the\nproposed plan has a logical result. Decision-makers and transportation agencies\ncan use this scheme to conduct better maintenance practices that can prevent\nbudget waste and, at the same time, minimize the environmental impacts.",
    "descriptor": "",
    "authors": [
      "Fateme Golivand Darvishvand",
      "Moen Latifi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12589"
  },
  {
    "id": "arXiv:2112.12590",
    "title": "Exploration of Overlap Volumes for Radiotherapy Plan Evaluation with the  Aim of Healthy Tissue Sparing",
    "abstract": "Purpose: Development of a novel interactive visualization approach for the\nexploration of radiotherapy treatment plans with a focus on overlap volumes\nwith the aim of healthy tissue sparing. Methods: We propose a visualization\napproach to include overlap volumes in the radiotherapy treatment plan\nevaluation process. Quantitative properties can be interactively explored to\nidentify critical regions and used to steer the visualization for a detailed\ninspection of candidates. We evaluated our approach with a user study covering\nthe individual visualizations and their interactions regarding helpfulness,\ncomprehensibility, intuitiveness, decision-making and speed. Results: A user\nstudy with three domain experts was conducted using our software and evaluating\nfive data sets each representing a different type of cancer and location by\nperforming a set of tasks and filling out a questionnaire. The results show\nthat the visualizations and interactions help to identify and evaluate overlap\nvolumes according to their physical and dose properties. Furthermore, the task\nof finding dose hots spots can also benefit from our approach. Conclusions: The\nresults indicate the potential to enhance the current treatment plan evaluation\nprocess in terms of healthy tissue sparing.",
    "descriptor": "",
    "authors": [
      "Matthias Schlachter",
      "Samuel Peters",
      "Daniel Camenisch",
      "Paul Martin Putora",
      "Katja B\u00fchler"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.12590"
  },
  {
    "id": "arXiv:2112.12591",
    "title": "Black-Box Testing of Deep Neural Networks through Test Case Diversity",
    "abstract": "Deep Neural Networks (DNNs) have been extensively used in many areas\nincluding image processing, medical diagnostics, and autonomous driving.\nHowever, DNNs can exhibit erroneous behaviours that may lead to critical\nerrors, especially when used in safety-critical systems. Inspired by testing\ntechniques for traditional software systems, researchers have proposed neuron\ncoverage criteria, as an analogy to source code coverage, to guide the testing\nof DNN models. Despite very active research on DNN coverage, several recent\nstudies have questioned the usefulness of such criteria in guiding DNN testing.\nFurther, from a practical standpoint, these criteria are white-box as they\nrequire access to the internals or training data of DNN models, which is in\nmany contexts not feasible or convenient. In this paper, we investigate\nblack-box input diversity metrics as an alternative to white-box coverage\ncriteria. To this end, we first select and adapt three diversity metrics and\nstudy, in a controlled manner, their capacity to measure actual diversity in\ninput sets. We then analyse their statistical association with fault detection\nusing two datasets and three DNN models. We further compare diversity with\nstate-of-the-art white-box coverage criteria. Our experiments show that relying\non the diversity of image features embedded in test input sets is a more\nreliable indicator than coverage criteria to effectively guide the testing of\nDNNs. Indeed, we found that one of our selected black-box diversity metrics far\noutperforms existing coverage criteria in terms of fault-revealing capability\nand computational time. Results also confirm the suspicions that\nstate-of-the-art coverage metrics are not adequate to guide the construction of\ntest input sets to detect as many faults as possible with natural inputs.",
    "descriptor": "",
    "authors": [
      "Zohreh Aghababaeyan",
      "Manel Abdellatif",
      "Lionel Briand",
      "Ramesh S",
      "Mojtaba Bagherzadeh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12591"
  },
  {
    "id": "arXiv:2112.12592",
    "title": "Flow and Transport in Three-Dimensional Discrete Fracture Matrix Models  using Mimetic Finite Difference on a Conforming Multi-Dimensional Mesh",
    "abstract": "We present a comprehensive workflow to simulate single-phase flow and\ntransport in fractured porous media using the discrete fracture matrix\napproach. The workflow has three primary parts: (1) a method for conforming\nmesh generation of and around a three-dimensional fracture network, (2) the\ndiscretization of the governing equations using a second-order mimetic finite\ndifference method, and (3) implementation of numerical methods for\nhigh-performance computing environments. A method to create a conforming\nDelaunay tetrahedralization of the volume surrounding the fracture network,\nwhere the triangular cells of the fracture mesh are faces in the volume mesh,\nthat addresses pathological cases which commonly arise and degrade mesh quality\nis also provided. Our open-source subsurface simulator uses a hierarchy of\nprocess kernels (one kernel per physical process) that allows for both strong\nand weak coupling of the fracture and matrix domains. We provide verification\ntests based on analytic solutions for flow and transport, as well as numerical\nconvergence. We also provide multiple expositions of the method in complex\nfracture networks. In the first example, we demonstrate that the method is\nrobust by considering two scenarios where the fracture network acts as a\nbarrier to flow, as the primary pathway, or offers the same resistance as the\nsurrounding matrix. In the second test, flow and transport through a\nthree-dimensional stochastically generated network containing 257 fractures is\npresented.",
    "descriptor": "",
    "authors": [
      "Jeffrey D. Hyman",
      "Matthew R. Sweeney",
      "Carl W. Gable",
      "Daniil Svyatsky",
      "Konstantin Lipnikov",
      "J. David Moulton"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12592"
  },
  {
    "id": "arXiv:2112.12594",
    "title": "Continual Depth-limited Responses for Computing Counter-strategies in  Extensive-form Games",
    "abstract": "In real-world applications, game-theoretic algorithms often interact with\nimperfect opponents, and incorporating opponent models into the algorithms can\nsignificantly improve performance. Opponent exploitation approaches often use\nthe best response or robust response to compute counter-strategy to an opponent\nmodel updated during the game-play or to build a portfolio of exploitative\nstrategies beforehand. However, in massive games with imperfect information,\ncomputing exact responses is intractable. Existing approaches for best response\napproximation are either domain-specific or require an extensive computation\nfor every opponent model. Furthermore, there is no approach that can compute\nrobust responses in massive games. We propose using depth-limited solving with\noptimal value function to approximate the best response and restricted Nash\nresponse. Both approaches require computing the value function beforehand, but\nthen allow computing the responses quickly even to previously unseen opponents.\nFurthermore, we provide a utility lower bound for both approaches and a safety\nguarantee for the robust response. Our best response approach can also be used\nfor evaluating the quality of strategies computed by novel algorithms through\napproximating exploitability. We empirically evaluate the approaches in terms\nof gain and exploitability, compare the depth-limited responses with the\npoker-specific local best response, and show the robust response indeed has an\nupper bound on exploitability.",
    "descriptor": "\nComments: 12 pages, 16 figures\n",
    "authors": [
      "David Milec",
      "Viliam Lis\u00fd"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.12594"
  },
  {
    "id": "arXiv:2112.12595",
    "title": "KGSecConfig: A Knowledge Graph Based Approach for Secured Container  Orchestrator Configuration",
    "abstract": "Container Orchestrator (CO) is a vital technology for managing clusters of\ncontainers, which may form a virtualized infrastructure for developing and\noperating software systems. Like any other software system, securing CO is\ncritical, but can be quite challenging task due to large number of configurable\noptions. Manual configuration is not only knowledge intensive and time\nconsuming, but also is error prone. For automating security configuration of\nCO, we propose a novel Knowledge Graph based Security Configuration,\nKGSecConfig, approach. Our solution leverages keyword and learning models to\nsystematically capture, link, and correlate heterogeneous and multi-vendor\nconfiguration space in a unified structure for supporting automation of\nsecurity configuration of CO. We implement KGSecConfig on Kubernetes, Docker,\nAzure, and VMWare to build secured configuration knowledge graph. Our\nevaluation results show 0.98 and 0.94 accuracy for keyword and learning-based\nsecured configuration option and concept extraction, respectively. We also\ndemonstrate the utilization of the knowledge graph for automated\nmisconfiguration mitigation in a Kubernetes cluster. We assert that our\nknowledge graph based approach can help in addressing several challenges, e.g.,\nmisconfiguration of security, associated with manually configuring the security\nof CO.",
    "descriptor": "",
    "authors": [
      "Mubin Ul Haque",
      "M. Mehdi Kholoosi",
      "M. Ali Babar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.12595"
  },
  {
    "id": "arXiv:2112.12596",
    "title": "INTRPRT: A Systematic Review of and Guidelines for Designing and  Validating Transparent AI in Medical Image Analysis",
    "abstract": "Transparency in Machine Learning (ML), attempts to reveal the working\nmechanisms of complex models. Transparent ML promises to advance human factors\nengineering goals of human-centered AI in the target users. From a\nhuman-centered design perspective, transparency is not a property of the ML\nmodel but an affordance, i.e. a relationship between algorithm and user; as a\nresult, iterative prototyping and evaluation with users is critical to\nattaining adequate solutions that afford transparency. However, following\nhuman-centered design principles in healthcare and medical image analysis is\nchallenging due to the limited availability of and access to end users. To\ninvestigate the state of transparent ML in medical image analysis, we conducted\na systematic review of the literature. Our review reveals multiple severe\nshortcomings in the design and validation of transparent ML for medical image\nanalysis applications. We find that most studies to date approach transparency\nas a property of the model itself, similar to task performance, without\nconsidering end users during neither development nor evaluation. Additionally,\nthe lack of user research, and the sporadic validation of transparency claims\nput contemporary research on transparent ML for medical image analysis at risk\nof being incomprehensible to users, and thus, clinically irrelevant. To\nalleviate these shortcomings in forthcoming research while acknowledging the\nchallenges of human-centered design in healthcare, we introduce the INTRPRT\nguideline, a systematic design directive for transparent ML systems in medical\nimage analysis. The INTRPRT guideline suggests formative user research as the\nfirst step of transparent model design to understand user needs and domain\nrequirements. Following this process produces evidence to support design\nchoices, and ultimately, increases the likelihood that the algorithms afford\ntransparency.",
    "descriptor": "",
    "authors": [
      "Haomin Chen",
      "Catalina Gomez",
      "Chien-Ming Huang",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.12596"
  },
  {
    "id": "arXiv:2112.12597",
    "title": "Well Begun is Half Done: An Empirical Study of Exploitability & Impact  of Base-Image Vulnerabilities",
    "abstract": "Container technology, (e.g., Docker) is being widely adopted for deploying\nsoftware infrastructures or applications in the form of container images.\nSecurity vulnerabilities in the container images are a primary concern for\ndeveloping containerized software. Exploitation of the vulnerabilities could\nresult in disastrous impact, such as loss of confidentiality, integrity, and\navailability of containerized software. Understanding the exploitability and\nimpact characteristics of vulnerabilities can help in securing the\nconfiguration of containerized software. However, there is a lack of research\naimed at empirically identifying and understanding the exploitability and\nimpact of vulnerabilities in container images. We carried out an empirical\nstudy to investigate the exploitability and impact of security vulnerabilities\nin base-images and their prevalence in open-source containerized software. We\nconsidered base-images since container images are built from base-images that\nprovide all the core functionalities to build and operate containerized\nsoftware. We discovered and characterized the exploitability and impact of\nsecurity vulnerabilities in 261 base-images, which are the origin of 4,681\nactively maintained official container images in the largest container\nregistry, i.e., Docker Hub. To characterize the prevalence of vulnerable\nbase-images in real-world projects, we analysed 64,579 containerized software\nfrom GitHub. Our analysis of a set of $1,983$ unique base-image security\nvulnerabilities revealed 13 novel findings. These findings are expected to help\ndevelopers to understand the potential security problems related to base-images\nand encourage them to investigate base-images from security perspective before\ndeveloping their applications.",
    "descriptor": "",
    "authors": [
      "Mubin Ul Haque",
      "M. Ali Babar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.12597"
  },
  {
    "id": "arXiv:2112.12606",
    "title": "Towards Universal GAN Image Detection",
    "abstract": "The ever higher quality and wide diffusion of fake images have spawn a quest\nfor reliable forensic tools. Many GAN image detectors have been proposed,\nrecently. In real world scenarios, however, most of them show limited\nrobustness and generalization ability. Moreover, they often rely on side\ninformation not available at test time, that is, they are not universal. We\ninvestigate these problems and propose a new GAN image detector based on a\nlimited sub-sampling architecture and a suitable contrastive learning paradigm.\nExperiments carried out in challenging conditions prove the proposed method to\nbe a first step towards universal GAN image detection, ensuring also good\nrobustness to common image impairments, and good generalization to unseen\narchitectures.",
    "descriptor": "",
    "authors": [
      "Davide Cozzolino",
      "Diego Gragnaniello",
      "Giovanni Poggi",
      "Luisa Verdoliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12606"
  },
  {
    "id": "arXiv:2112.12610",
    "title": "PandaSet: Advanced Sensor Suite Dataset for Autonomous Driving",
    "abstract": "The accelerating development of autonomous driving technology has placed\ngreater demands on obtaining large amounts of high-quality data.\nRepresentative, labeled, real world data serves as the fuel for training deep\nlearning networks, critical for improving self-driving perception algorithms.\nIn this paper, we introduce PandaSet, the first dataset produced by a complete,\nhigh-precision autonomous vehicle sensor kit with a no-cost commercial license.\nThe dataset was collected using one 360{\\deg} mechanical spinning LiDAR, one\nforward-facing, long-range LiDAR, and 6 cameras. The dataset contains more than\n100 scenes, each of which is 8 seconds long, and provides 28 types of labels\nfor object classification and 37 types of labels for semantic segmentation. We\nprovide baselines for LiDAR-only 3D object detection, LiDAR-camera fusion 3D\nobject detection and LiDAR point cloud segmentation. For more details about\nPandaSet and the development kit, see https://scale.com/open-datasets/pandaset.",
    "descriptor": "\nComments: This paper has been published on ITSC'2021, please check the website of the PandaSet for more information: this https URL\n",
    "authors": [
      "Pengchuan Xiao",
      "Zhenlei Shao",
      "Steven Hao",
      "Zishuo Zhang",
      "Xiaolin Chai",
      "Judy Jiao",
      "Zesong Li",
      "Jian Wu",
      "Kai Sun",
      "Kun Jiang",
      "Yunlong Wang",
      "Diange Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.12610"
  },
  {
    "id": "arXiv:2112.12612",
    "title": "Towards Disturbance-Free Visual Mobile Manipulation",
    "abstract": "Embodied AI has shown promising results on an abundance of robotic tasks in\nsimulation, including visual navigation and manipulation. The prior work\ngenerally pursues high success rates with shortest paths while largely ignoring\nthe problems caused by collision during interaction. This lack of\nprioritization is understandable: in simulated environments there is no\ninherent cost to breaking virtual objects. As a result, well-trained agents\nfrequently have catastrophic collision with objects despite final success. In\nthe robotics community, where the cost of collision is large, collision\navoidance is a long-standing and crucial topic to ensure that robots can be\nsafely deployed in the real world. In this work, we take the first step towards\ncollision/disturbance-free embodied AI agents for visual mobile manipulation,\nfacilitating safe deployment in real robots. We develop a new\ndisturbance-avoidance methodology at the heart of which is the auxiliary task\nof disturbance prediction. When combined with a disturbance penalty, our\nauxiliary task greatly enhances sample efficiency and final performance by\nknowledge distillation of disturbance into the agent. Our experiments on\nManipulaTHOR show that, on testing scenes with novel objects, our method\nimproves the success rate from 61.7% to 85.6% and the success rate without\ndisturbance from 29.8% to 50.2% over the original baseline. Extensive ablation\nstudies show the value of our pipelined approach. Project site is at\nhttps://sites.google.com/view/disturb-free",
    "descriptor": "",
    "authors": [
      "Tianwei Ni",
      "Kiana Ehsani",
      "Luca Weihs",
      "Jordi Salvador"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12612"
  },
  {
    "id": "arXiv:2112.12618",
    "title": "Manifold Learning Benefits GANs",
    "abstract": "In this paper, we improve Generative Adversarial Networks by incorporating a\nmanifold learning step into the discriminator. We consider locality-constrained\nlinear and subspace-based manifolds, and locality-constrained non-linear\nmanifolds. In our design, the manifold learning and coding steps are\nintertwined with layers of the discriminator, with the goal of attracting\nintermediate feature representations onto manifolds. We adaptively balance the\ndiscrepancy between feature representations and their manifold view, which\nrepresents a trade-off between denoising on the manifold and refining the\nmanifold. We conclude that locality-constrained non-linear manifolds have the\nupper hand over linear manifolds due to their non-uniform density and\nsmoothness. We show substantial improvements over different recent\nstate-of-the-art baselines.",
    "descriptor": "\nComments: 30 pages full version\n",
    "authors": [
      "Yao Ni",
      "Piotr Koniusz",
      "Richard Hartley",
      "Richard Nock"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12618"
  },
  {
    "id": "arXiv:2112.12619",
    "title": "Variational integration of learned dynamical systems",
    "abstract": "The principle of least action is one of the most fundamental physical\nprinciple. It says that among all possible motions connecting two points in a\nphase space, the system will exhibit those motions which extremise an action\nfunctional. Many qualitative features of dynamical systems, such as the\npresence of conservation laws and energy balance equations, are related to the\nexistence of an action functional. Incorporating variational structure into\nlearning algorithms for dynamical systems is, therefore, crucial in order to\nmake sure that the learned model shares important features with the exact\nphysical system. In this paper we show how to incorporate variational\nprinciples into trajectory predictions of learned dynamical systems. The\nnovelty of this work is that (1) our technique relies only on discrete position\ndata of observed trajectories. Velocities or conjugate momenta do {\\em not}\nneed to be observed or approximated and {\\em no} prior knowledge about the form\nof the variational principle is assumed. Instead, they are recovered using\nbackward error analysis. (2) Moreover, our technique compensates discretisation\nerrors when trajectories are computed from the learned system. This is\nimportant when moderate to large step-sizes are used and high accuracy is\nrequired. For this, we introduce and rigorously analyse the concept of inverse\nmodified Lagrangians by developing an inverse version of variational backward\nerror analysis. (3) Finally, we introduce a method to perform system\nidentification from position observations only, based on variational backward\nerror analysis.",
    "descriptor": "",
    "authors": [
      "Sina Ober-Bl\u00f6baum",
      "Christian Offen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12619"
  },
  {
    "id": "arXiv:2112.12625",
    "title": "Comparison and Analysis of Image-to-Image Generative Adversarial  Networks: A Survey",
    "abstract": "Generative Adversarial Networks (GANs) have recently introduced effective\nmethods of performing Image-to-Image translations. These models can be applied\nand generalized to a variety of domains in Image-to-Image translation without\nchanging any parameters. In this paper, we survey and analyze eight\nImage-to-Image Generative Adversarial Networks: Pix2Px, CycleGAN, CoGAN,\nStarGAN, MUNIT, StarGAN2, DA-GAN, and Self Attention GAN. Each of these models\npresented state-of-the-art results and introduced new techniques to build\nImage-to-Image GANs. In addition to a survey of the models, we also survey the\n18 datasets they were trained on and the 9 metrics they were evaluated on.\nFinally, we present results of a controlled experiment for 6 of these models on\na common set of metrics and datasets. The results were mixed and showed that on\ncertain datasets, tasks, and metrics some models outperformed others. The last\nsection of this paper discusses those results and establishes areas of future\nresearch. As researchers continue to innovate new Image-to-Image GANs, it is\nimportant that they gain a good understanding of the existing methods,\ndatasets, and metrics. This paper provides a comprehensive overview and\ndiscussion to help build this foundation.",
    "descriptor": "\nComments: 22 pages, 22 figures, Preprint, Under review at IJCV\n",
    "authors": [
      "Sagar Saxena",
      "Mohammad Nayeem Teli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12625"
  },
  {
    "id": "arXiv:2112.12630",
    "title": "A Survey of Near-Data Processing Architectures for Neural Networks",
    "abstract": "Data-intensive workloads and applications, such as machine learning (ML), are\nfundamentally limited by traditional computing systems based on the von-Neumann\narchitecture. As data movement operations and energy consumption become key\nbottlenecks in the design of computing systems, the interest in unconventional\napproaches such as Near-Data Processing (NDP), machine learning, and especially\nneural network (NN)-based accelerators has grown significantly. Emerging memory\ntechnologies, such as ReRAM and 3D-stacked, are promising for efficiently\narchitecting NDP-based accelerators for NN due to their capabilities to work as\nboth: High-density/low-energy storage and in/near-memory computation/search\nengine. In this paper, we present a survey of techniques for designing NDP\narchitectures for NN. By classifying the techniques based on the memory\ntechnology employed, we underscore their similarities and differences. Finally,\nwe discuss open challenges and future perspectives that need to be explored in\norder to improve and extend the adoption of NDP architectures for future\ncomputing platforms. This paper will be valuable for computer architects, chip\ndesigners and researchers in the area of machine learning.",
    "descriptor": "",
    "authors": [
      "Mehdi Hassanpour",
      "Marc Riera",
      "Antonio Gonz\u00e1lez"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12630"
  },
  {
    "id": "arXiv:2112.12635",
    "title": "AcME -- Accelerated Model-agnostic Explanations: Fast Whitening of the  Machine-Learning Black Box",
    "abstract": "In the context of human-in-the-loop Machine Learning applications, like\nDecision Support Systems, interpretability approaches should provide actionable\ninsights without making the users wait. In this paper, we propose Accelerated\nModel-agnostic Explanations (AcME), an interpretability approach that quickly\nprovides feature importance scores both at the global and the local level. AcME\ncan be applied a posteriori to each regression or classification model. Not\nonly does AcME compute feature ranking, but it also provides a what-if analysis\ntool to assess how changes in features values would affect model predictions.\nWe evaluated the proposed approach on synthetic and real-world datasets, also\nin comparison with SHapley Additive exPlanations (SHAP), the approach we drew\ninspiration from, which is currently one of the state-of-the-art model-agnostic\ninterpretability approaches. We achieved comparable results in terms of quality\nof produced explanations while reducing dramatically the computational time and\nproviding consistent visualization for global and local interpretations. To\nfoster research in this field, and for the sake of reproducibility, we also\nprovide a repository with the code used for the experiments.",
    "descriptor": "",
    "authors": [
      "David Dandolo",
      "Chiara Masiero",
      "Mattia Carletti",
      "Davide Dalle Pezze",
      "Gian Antonio Susto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12635"
  },
  {
    "id": "arXiv:2112.12636",
    "title": "SemParser: A Semantic Parser for Log Analysis",
    "abstract": "Logs, being run-time information automatically generated by software, record\nsystem events and activities with their timestamps. Before obtaining more\ninsights about the run-time status of the software, a fundamental step of log\nanalysis, called log parsing, is employed to extract structured templates and\nparameters from the semi-structured raw log messages. However, current log\nparsers regard each message as a character string, ignoring the semantic\ninformation included in parameters and templates. Thus, we propose the semantic\nparser SemParser to unlock the critical bottleneck of mining semantics from log\nmessages. It contains two steps, an end-to-end semantic miner and a joint\nparser. Specifically, the first step aims to identify explicit semantics inside\na single log, and the second step is responsible for jointly inferring implicit\nsemantics and computing structural outputs based on the contextual knowledge\nbase. To analyze the effectiveness of our semantic parser, we first demonstrate\nthat it can derive rich semantics from log messages collected from seven\nwidely-applied systems with an average F1 score of 0.987. Then, we conduct two\nrepresentative downstream tasks, showing that current downstream techniques\nimprove their performance with appropriately extracted semantics by 11.7% and\n8.65% in anomaly detection and failure diagnosis tasks, respectively. We\nbelieve these findings provide insights into semantically understanding log\nmessages for the log analysis community.",
    "descriptor": "",
    "authors": [
      "Yintong Huo",
      "Yuxin Su",
      "Baitong Li",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.12636"
  },
  {
    "id": "arXiv:2112.12638",
    "title": "RumbleML: program the lakehouse with JSONiq",
    "abstract": "Lakehouse systems have reached in the past few years unprecedented size and\nheterogeneity and have been embraced by many industry players. However, they\nare often difficult to use as they lack the declarative language and\noptimization possibilities of relational engines. This paper introduces\nRumbleML, a high-level, declarative library integrated into the RumbleDB engine\nand with the JSONiq language. RumbleML allows using a single platform for data\ncleaning, data preparation, training, and inference, as well as management of\nmodels and results. It does it using a purely declarative language (JSONiq) for\nall these tasks and without any performance loss over existing platforms (e.g.\nSpark). The key insights of the design of RumbleML are that training sets,\nevaluation sets, and test sets can be represented as homogeneous sequences of\nflat objects; that models can be seamlessly embodied in function items mapping\ninput test sets into prediction-augmented result sets; and that estimators can\nbe seamlessly embodied in function items mapping input training sets to models.\nWe argue that this makes JSONiq a viable and seamless programming language for\ndata lakehouses across all their features, whether database-related or\nmachine-learning-related. While lakehouses bring Machine Learning and Data\nWrangling on the same platform, RumbleML also brings them to the same language,\nJSONiq. In the paper, we present the first prototype and compare its\nperformance to Spark showing the benefit of a huge functionality and\nproductivity gain for cleaning up, normalizing, validating data, feeding it\ninto Machine Learning pipelines, and analyzing the output, all within the same\nsystem and language and at scale.",
    "descriptor": "\nComments: 8 pages + references\n",
    "authors": [
      "Ghislain Fourny",
      "David Dao",
      "Can Berker Cikis",
      "Ce Zhang",
      "Gustavo Alonso"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.12638"
  },
  {
    "id": "arXiv:2112.12641",
    "title": "Prolog-based agnostic explanation module for structured pattern  classification",
    "abstract": "This paper presents a Prolog-based reasoning module to generate\ncounterfactual explanations given the predictions computed by a black-box\nclassifier. The proposed symbolic reasoning module can also resolve what-if\nqueries using the ground-truth labels instead of the predicted ones. Overall,\nour approach comprises four well-defined stages that can be applied to any\nstructured pattern classification problem. Firstly, we pre-process the given\ndataset by imputing missing values and normalizing the numerical features.\nSecondly, we transform numerical features into symbolic ones using fuzzy\nclustering such that extracted fuzzy clusters are mapped to an ordered set of\npredefined symbols. Thirdly, we encode instances as a Prolog rule using the\nnominal values, the predefined symbols, the decision classes, and the\nconfidence values. Fourthly, we compute the overall confidence of each Prolog\nrule using fuzzy-rough set theory to handle the uncertainty caused by\ntransforming numerical quantities into symbols. This step comes with an\nadditional theoretical contribution to a new similarity function to compare the\npreviously defined Prolog rules involving confidence values. Finally, we\nimplement a chatbot as a proxy between human beings and the Prolog-based\nreasoning module to resolve natural language queries and generate\ncounterfactual explanations. During the numerical simulations using synthetic\ndatasets, we study the performance of our system when using different fuzzy\noperators and similarity functions. Towards the end, we illustrate how our\nreasoning module works using different use cases.",
    "descriptor": "",
    "authors": [
      "Gonzalo N\u00e1poles",
      "Fabian Hoitsma",
      "Andreas Knoben",
      "Agnieszka Jastrzebska",
      "Maikel Leon Espinosa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12641"
  },
  {
    "id": "arXiv:2112.12650",
    "title": "Distilling the Knowledge of Romanian BERTs Using Multiple Teachers",
    "abstract": "As transfer learning from large-scale pre-trained language models has become\nprevalent in Natural Language Processing, running these models in\ncomputationally constrained environments remains a challenging problem yet to\naddress. Several solutions including knowledge distillation, network\nquantization or network pruning have been proposed; however, these approaches\nfocus mostly on the English language, thus widening the gap when considering\nlow-resource languages. In this work, we introduce three light and fast\nversions of distilled BERT models for the Romanian language:\nDistil-BERT-base-ro, Distil-RoBERT-base and DistilMulti-BERT-base-ro. The first\ntwo models resulted from individually distilling the knowledge of the two base\nversions of Romanian BERTs available in literature, while the last one was\nobtained by distilling their ensemble. To our knowledge, this is the first\nattempt to create publicly available Romanian distilled BERT models, which were\nthoroughly evaluated on five tasks: part-of-speech tagging, named entity\nrecognition, sentiment analysis, semantic textual similarity and dialect\nidentification. The experimental results on these benchmarks proved that our\nthree distilled models maintain most performance in terms of accuracy with\ntheir teachers, while being twice as fast on a GPU and ~35\\% smaller. In\naddition, we further test the similarity between our students and their\nteachers prediction by measuring their label and probability loyalty, together\nwith regression loyalty - a new metric introduced in this work.",
    "descriptor": "",
    "authors": [
      "Andrei-Marius Avram",
      "Darius Catrina",
      "Dumitru-Clementin Cercel",
      "Mihai Dasc\u0103lu",
      "Traian Rebedea",
      "Vasile P\u0103i\u015f",
      "Dan Tufi\u015f"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12650"
  },
  {
    "id": "arXiv:2112.12653",
    "title": "Revisiting, Benchmarking and Exploring API Recommendation: How Far Are  We?",
    "abstract": "Application Programming Interfaces (APIs), which encapsulate the\nimplementation of specific functions as interfaces, greatly improve the\nefficiency of modern software development. As numbers of APIs spring up\nnowadays, developers can hardly be familiar with all the APIs, and usually need\nto search for appropriate APIs for usage. So lots of efforts have been devoted\nto improving the API recommendation task. However, it has been increasingly\ndifficult to gauge the performance of new models due to the lack of a uniform\ndefinition of the task and a standardized benchmark. For example, some studies\nregard the task as a code completion problem; while others recommend relative\nAPIs given natural language queries. To reduce the challenges and better\nfacilitate future research, in this paper, we revisit the API recommendation\ntask and aim at benchmarking the approaches. Specifically, the paper groups the\napproaches into two categories according to the task definition, i.e.,\nquery-based API recommendation and code-based API recommendation. We study 11\nrecently-proposed approaches along with 4 widely-used IDEs. One benchmark named\nas APIBench is then built for the two respective categories of approaches.\nBased on APIBench, we distill some actionable insights and challenges for API\nrecommendation. We also achieve some implications and directions for improving\nthe performance of recommending APIs, including data source selection,\nappropriate query reformulation, low resource setting, and cross-domain\nadaptation.",
    "descriptor": "",
    "authors": [
      "Yun Peng",
      "Shuqing Li",
      "Wenwei Gu",
      "Yichen Li",
      "Wenxuan Wang",
      "Cuiyun Gao",
      "Michael Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.12653"
  },
  {
    "id": "arXiv:2112.12661",
    "title": "Capacity Bounds under Imperfect Polarization Tracking",
    "abstract": "In optical fiber communication, due to the random variation of the\nenvironment, the state of polarization (SOP) fluctuates randomly with time\nleading to distortion and performance degradation. The memory-less SOP\nfluctuations can be regarded as a two-by-two random unitary matrix. In this\npaper, for what we believe to be the first time, the capacity of the\npolarization drift channel under an average power constraint with imperfect\nchannel knowledge is characterized. An achievable information rate (AIR) is\nderived when imperfect channel knowledge is available and is shown to be highly\ndependent on the channel estimation technique. It is also shown that a tighter\nlower bound can be achieved when a unitary estimation of the channel is\navailable. However, the conventional estimation algorithms do not guarantee a\nunitary channel estimation. Therefore, by considering the unitary constraint of\nthe channel, a data-aided channel estimator based on the Kabsch algorithm is\nproposed, and its performance is numerically evaluated in terms of AIR. Monte\nCarlo simulations show that Kabsch outperforms the least-square error\nalgorithm. In particular, with complex, Gaussian inputs and eight pilot symbols\nper block, Kabsch improves the AIR by 0:2 to 0:35 bits/symbol throughout the\nrange of studied signal-to-noise ratios.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Mohammad Farsi",
      "Magnus Karlsson",
      "Erik Agrell"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.12661"
  },
  {
    "id": "arXiv:2112.12664",
    "title": "Data-driven design of safe control for polynomial systems",
    "abstract": "We consider the problem of designing an invariant set using only a finite set\nof input-state data collected from an unknown polynomial system in continuous\ntime. We consider noisy data, i.e., corrupted by an unknown-but-bounded\ndisturbance. We derive a data-dependent sum-of-squares program that enforces\ninvariance of a set and also optimizes the size of the invariant set while\nkeeping it within a set of user-defined safety constraints; the solution of\nthis program directly provides a polynomial invariant set and a state-feedback\ncontroller. We numerically test the design on a system of two platooning cars.",
    "descriptor": "",
    "authors": [
      "Alessandro Luppi",
      "Andrea Bisoffi",
      "Claudio De Persis",
      "Pietro Tesi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.12664"
  },
  {
    "id": "arXiv:2112.12667",
    "title": "Using Silent Writes in Low-Power Traffic-Aware ECC",
    "abstract": "Using Error Detection Code (EDC) and Error Correction Code (ECC) is a\nnoteworthy way to increase cache memories robustness against soft errors. EDC\nenables detecting errors in cache memory while ECC is used to correct erroneous\ncache blocks. ECCs are often costly as they impose considerable area and energy\noverhead on cache memory. Reducing this overhead has been the subject of many\nstudies. In particular, a previous study has suggested mapping ECC to the main\nmemory at the expense of high cache traffic and energy. A major source of this\nexcessive traffic and energy is the high frequency of cache writes. In this\nwork, we show that a significant portion of cache writes are silent, i.e., they\nwrite the same data already existing. We build on this observation and\nintroduce Traffic-aware ECC (or simply TCC). TCC detects silent writes by an\nefficient mechanism. Once such writes are detected updating their ECC is\navoided effectively reducing L2 cache traffic and access frequency. Using our\nsolution, we reduce L2 cache access frequency by 8% while maintaining\nperformance. We reduce L2 cache dynamic and overall cache energy by up to 32%\nand 8%, respectively. Furthermore, TCC reduces L2 cache miss rate by 3%.",
    "descriptor": "",
    "authors": [
      "Mostafa Kishani",
      "Amirali Baniasadi",
      "Hossein Pedram"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.12667"
  },
  {
    "id": "arXiv:2112.12668",
    "title": "3D Skeleton-based Few-shot Action Recognition with JEANIE is not so  Na\u00efve",
    "abstract": "In this paper, we propose a Few-shot Learning pipeline for 3D skeleton-based\naction recognition by Joint tEmporal and cAmera viewpoiNt alIgnmEnt (JEANIE).\nTo factor out misalignment between query and support sequences of 3D body\njoints, we propose an advanced variant of Dynamic Time Warping which jointly\nmodels each smooth path between the query and support frames to achieve\nsimultaneously the best alignment in the temporal and simulated camera\nviewpoint spaces for end-to-end learning under the limited few-shot training\ndata. Sequences are encoded with a temporal block encoder based on Simple\nSpectral Graph Convolution, a lightweight linear Graph Neural Network backbone\n(we also include a setting with a transformer). Finally, we propose a\nsimilarity-based loss which encourages the alignment of sequences of the same\nclass while preventing the alignment of unrelated sequences. We demonstrate\nstate-of-the-art results on NTU-60, NTU-120, Kinetics-skeleton and UWA3D\nMultiview Activity II.",
    "descriptor": "\nComments: Full 17 page version\n",
    "authors": [
      "Lei Wang",
      "Jun Liu",
      "Piotr Koniusz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12668"
  },
  {
    "id": "arXiv:2112.12670",
    "title": "The interplay between ranking and communities in networks",
    "abstract": "Community detection and hierarchy extraction are usually thought of as\nseparate inference tasks on networks. Considering only one of the two when\nstudying real-world data can be an oversimplification. In this work, we present\na generative model based on an interplay between community and hierarchical\nstructures. It assumes that each node has a preference in the interaction\nmechanism and nodes with the same preference are more likely to interact, while\nheterogeneous interactions are still allowed. The algorithmic implementation is\nefficient, as it exploits the sparsity of network datasets. We demonstrate our\nmethod on synthetic and real-world data and compare performance with two\nstandard approaches for community detection and ranking extraction. We find\nthat the algorithm accurately retrieves each node's preference in different\nscenarios and we show that it can distinguish small subsets of nodes that\nbehave differently than the majority. As a consequence, the model can recognise\nwhether a network has an overall preferred interaction mechanism. This is\nrelevant in situations where there is no clear \"a priori\" information about\nwhat structure explains the observed network datasets well. Our model allows\npractitioners to learn this automatically from the data.",
    "descriptor": "",
    "authors": [
      "Laura Iacovissi",
      "Caterina De Bacco"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.12670"
  },
  {
    "id": "arXiv:2112.12672",
    "title": "Towards more patient friendly clinical notes through language models and  ontologies",
    "abstract": "Clinical notes are an efficient way to record patient information but are\nnotoriously hard to decipher for non-experts. Automatically simplifying medical\ntext can empower patients with valuable information about their health, while\nsaving clinicians time. We present a novel approach to automated simplification\nof medical text based on word frequencies and language modelling, grounded on\nmedical ontologies enriched with layman terms. We release a new dataset of\npairs of publicly available medical sentences and a version of them simplified\nby clinicians. Also, we define a novel text simplification metric and\nevaluation framework, which we use to conduct a large-scale human evaluation of\nour method against the state of the art. Our method based on a language model\ntrained on medical forum data generates simpler sentences while preserving both\ngrammar and the original meaning, surpassing the current state of the art.",
    "descriptor": "",
    "authors": [
      "Francesco Moramarco",
      "Damir Juric",
      "Aleksandar Savkov",
      "Jack Flann",
      "Maria Lehl",
      "Kristian Boda",
      "Tessa Grafen",
      "Vitalii Zhelezniak",
      "Sunir Gohil",
      "Alex Papadopoulos Korfiatis",
      "Nils Hammerla"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.12672"
  },
  {
    "id": "arXiv:2112.12678",
    "title": "Dynamic Suffix Array with Sub-linear update time and Poly-logarithmic  Lookup Time",
    "abstract": "The Suffix Array $SA_S[1\\ldots n]$ of an $n$-length string $S$ is a\nlexicographically sorted array of the suffixes of $S$. The suffix array is one\nof the most well known and widely used data structures in string algorithms. We\npresent a data structure for maintaining a representation of the suffix array\nof a dynamic string which undergoes symbol substitutions, deletions, and\ninsertions.\nFor every string manipulation, our data structure can be updated in\n$O(n^{\\frac{2}{3}})$ time (ignoring multiplicative polylogarithmic factors)\nwith $n$ being the current length of the string. For an input query $i\\in\n[1\\ldots n]$, our data structure reports $SA_S[i]$ in $O(\\log^5(n))$ time.\nWe also present a faster data structure, with $O(\\sqrt{n})$ update time\n(ignoring multiplicative polylogarithmic factors), for maintaining the Inverted\nSuffix Array of a dynamic string undergoing symbol substitutions updates. For\nan input query $i\\in [1\\ldots n]$, our data structure reports the $i$'th entry\nin the inverted suffix array in $O(\\log^4(n))$ time.\nOur data structures can be used to obtain sub-linear dynamic algorithms for\nseveral classical string problems for which efficient dynamic solutions were\nnot previously known.",
    "descriptor": "",
    "authors": [
      "Amihood Amir",
      "Itai Boneh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.12678"
  },
  {
    "id": "arXiv:2112.12685",
    "title": "Dynamic Page Placement on Real Persistent Memory Systems",
    "abstract": "As persistent memory (PM) technologies emerge, hybrid memory architectures\ncombining DRAM with PM bring the potential to provide a tiered,\nbyte-addressable main memory of unprecedented capacity. Nearly a decade after\nthe first proposals for these hybrid architectures, the real technology has\nfinally reached commercial availability with Intel Optane(TM) DC Persistent\nMemory (DCPMM). This raises the challenge of designing systems that realize\nthis potential in practice, namely through effective approaches that\ndynamically decide at which memory tier should pages be placed. In this paper,\nwe are the first, to our knowledge, to systematically analyze tiered page\nplacement on real DCPMM-based systems. To this end, we start by revisiting the\nassumptions of state-of-the-art proposals, and confronting them with the\nidiosyncrasies of today's off-the-shelf DCPMM-equipped architectures. This\nempirical study reveals that some of the key design choices in the literature\nrely on important assumptions that are not verified in present-day DRAM-DCPMM\nmemory architectures. Based on the lessons from this study, we design and\nimplement HyPlacer, a tool for tiered page placement in off-the-shelf\nLinux-based systems equipped with DRAM+DCPMM. In contrast to previous\nproposals, HyPlacer follows an approach guided by two main practicality\nprinciples: 1) it is tailored to the performance idiosyncrasies of off-theshelf\nDRAM+DCPMM systems; and 2) it can be seamlessly integrated into Linux with\nminimal kernel-mode components, while ensuring extensibility to other HMAs and\nother data placement policies. Our experimental evaluation of HyPlacer shows\nthat it outperforms both solutions proposed in past literature and placement\noptions that are currently available in off-the-shelf DCPMM-equipped Linux\nsystems, reaching an improvement of up to 11x when compared to the default\nmemory policy in Linux.",
    "descriptor": "",
    "authors": [
      "Miguel Marques",
      "Ilia Kuzmin",
      "Jo\u00e3o Barreto",
      "Jos\u00e9 Monteiro",
      "Rodrigo Rodrigues"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.12685"
  },
  {
    "id": "arXiv:2112.12692",
    "title": "XDWM: A 2D Domain Wall Memory",
    "abstract": "Domain-Wall Memory (DWM) structures typically bundle nanowires shifted\ntogether for parallel access. Ironically, this organization does not allow the\nnatural shifting of DWM to realize \\textit{logical shifting} within data\nelements. We describe a novel 2-D DWM cross-point (X-Cell) that allows two\nindividual nanowires placed orthogonally to share the X-Cell. Each nanowire can\noperate independently while sharing the value at the X-Cell. Using X-Cells, we\npropose an orthogonal nanowire in the Y dimension overlaid on a bundle of X\ndimension nanowires for a cross-DWM or XDWM. We demonstrate that the bundle\nshifts correctly in the X-Direction, and that data can be logically shifted in\nthe Y-direction providing novel data movement and supporting\nprocessing-in-memory. We conducted studies on the requirements for physical\ncell dimensions and shift currents for XDWM. Due to the non-standard domain,\nour micro-magnetic studies demonstrate that XDWM introduces a shift current\npenalty of 6.25% while shifting happens in one nanowire compared to a standard\nnanowire. We also demonstrate correct shifting using nanowire bundles in both\nthe X- and Y- dimensions. Using magnetic simulation to derive the values for\nSPICE simulation we show the maximum leakage current between nanowires when\nshifting the bundle together is $\\le3$% indicating that sneak paths are not\nproblematic for XDWM.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Arifa Hoque",
      "Alex K. Jones",
      "Sanjukta Bhanja"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.12692"
  },
  {
    "id": "arXiv:2112.12693",
    "title": "Deadlock-free asynchronous message reordering in Rust with multiparty  session types",
    "abstract": "Rust is a modern systems language focused on performance and reliability.\nComplementing Rust's promise to provide \"fearless concurrency\", developers\nfrequently exploit asynchronous message passing. Unfortunately, arbitrarily\nordering sending and receiving messages to maximise computation-communication\noverlap (a popular optimisation to message-passing applications) opens up a\nPandora's box of further subtle concurrency bugs.\nTo guarantee deadlock-freedom by construction, we present Rumpsteak: a new\nRust framework based on multiparty session types. Previous session type\nimplementations in Rust are either built upon synchronous and blocking\ncommunication and/or limited to two-party interactions. Crucially, none support\nthe arbitrary ordering of messages for efficiency.\nRumpsteak instead targets asynchronous async/await code. Its unique ability\nis allowing developers to arbitrarily order send/receive messages while\npreserving deadlock-freedom. For this, Rumpsteak incorporates two recent\nadvanced session type theories: (1) k-multiparty compatibility (kmc), which\nglobally verifies the safety of a set of participants, and (2) asynchronous\nmultiparty session subtyping, which locally verifies optimisations in the\ncontext of a single participant. Specifically, we propose a novel algorithm for\nasynchronous subtyping that is both sound and decidable.\nWe first evaluate the performance and expressiveness of Rumpsteak against\nthree previous Rust implementations. We discover that Rumpsteak is around\n1.7--8.6x more efficient and can safely express many more examples by virtue of\noffering arbitrary message ordering. Secondly, we analyse the complexity of our\nnew algorithm and benchmark it against kmc and a binary session subtyping\nalgorithm. We find they are exponentially slower than Rumpsteak's.",
    "descriptor": "\nComments: Full-version, 24 pages. Short version to appear in PPoPP 2022\n",
    "authors": [
      "Zak Cutner",
      "Nobuko Yoshida",
      "Martin Vassor"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.12693"
  },
  {
    "id": "arXiv:2112.12702",
    "title": "TagLab: A human-centric AI system for interactive semantic segmentation",
    "abstract": "Fully automatic semantic segmentation of highly specific semantic classes and\ncomplex shapes may not meet the accuracy standards demanded by scientists. In\nsuch cases, human-centered AI solutions, able to assist operators while\npreserving human control over complex tasks, are a good trade-off to speed up\nimage labeling while maintaining high accuracy levels. TagLab is an open-source\nAI-assisted software for annotating large orthoimages which takes advantage of\ndifferent degrees of automation; it speeds up image annotation from scratch\nthrough assisted tools, creates custom fully automatic semantic segmentation\nmodels, and, finally, allows the quick edits of automatic predictions. Since\nthe orthoimages analysis applies to several scientific disciplines, TagLab has\nbeen designed with a flexible labeling pipeline. We report our results in two\ndifferent scenarios, marine ecology, and architectural heritage.",
    "descriptor": "\nComments: Accepted at Human Centered AI workshop at NeurIPS 2021, this https URL\n",
    "authors": [
      "Gaia Pavoni",
      "Massimiliano Corsini",
      "Federico Ponchio",
      "Alessandro Muntoni",
      "Paolo Cignoni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.12702"
  },
  {
    "id": "arXiv:2112.12703",
    "title": "Digital Editions as Distant Supervision for Layout Analysis of Printed  Books",
    "abstract": "Archivists, textual scholars, and historians often produce digital editions\nof historical documents. Using markup schemes such as those of the Text\nEncoding Initiative and EpiDoc, these digital editions often record documents'\nsemantic regions (such as notes and figures) and physical features (such as\npage and line breaks) as well as transcribing their textual content. We\ndescribe methods for exploiting this semantic markup as distant supervision for\ntraining and evaluating layout analysis models. In experiments with several\nmodel architectures on the half-million pages of the Deutsches Textarchiv\n(DTA), we find a high correlation of these region-level evaluation methods with\npixel-level and word-level metrics. We discuss the possibilities for improving\naccuracy with self-training and the ability of models trained on the DTA to\ngeneralize to other historical printed books.",
    "descriptor": "\nComments: 15 pages, 2 figures. International Conference on Document Analysis and Recognition. Springer, Cham, 2021\n",
    "authors": [
      "Alejandro H. Toselli",
      "Si Wu",
      "David A. Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12703"
  },
  {
    "id": "arXiv:2112.12704",
    "title": "Deterministic Parallel Hypergraph Partitioning",
    "abstract": "Balanced hypergraph partitioning is a classical NP-hard optimization problem\nwith applications in various domains such as VLSI design, simulating quantum\ncircuits, optimizing data placement in distributed databases or minimizing\ncommunication volume in high-performance computing. Engineering parallel\nheuristics for this problem is a topic of recent research. Most of them are\nnon-deterministic though. In this work, we design and implement a highly\nscalable deterministic algorithm in the state-of-the-art parallel partitioning\nframework Mt-KaHyPar. On our extensive set of benchmark instances, it achieves\nsimilar partition quality and performance as a comparable but non-deterministic\nconfiguration of Mt-KaHyPar and outperforms the only other existing parallel\ndeterministic algorithm BiPart regarding partition quality, running time and\nparallel speedups.",
    "descriptor": "",
    "authors": [
      "Lars Gottesb\u00fcren",
      "Michael Hamann"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.12704"
  },
  {
    "id": "arXiv:2112.12705",
    "title": "Explainable Artificial Intelligence Methods in Combating Pandemics: A  Systematic Review",
    "abstract": "Despite the myriad peer-reviewed papers demonstrating novel Artificial\nIntelligence (AI)-based solutions to COVID-19 challenges during the pandemic,\nfew have made significant clinical impact. The impact of artificial\nintelligence during the COVID-19 pandemic was greatly limited by lack of model\ntransparency. This systematic review examines the use of Explainable Artificial\nIntelligence (XAI) during the pandemic and how its use could overcome barriers\nto real-world success. We find that successful use of XAI can improve model\nperformance, instill trust in the end-user, and provide the value needed to\naffect user decision-making. We introduce the reader to common XAI techniques,\ntheir utility, and specific examples of their application. Evaluation of XAI\nresults is also discussed as an important step to maximize the value of\nAI-based clinical decision support systems. We illustrate the classical,\nmodern, and potential future trends of XAI to elucidate the evolution of novel\nXAI techniques. Finally, we provide a checklist of suggestions during the\nexperimental design process supported by recent publications. Common challenges\nduring the implementation of AI solutions are also addressed with specific\nexamples of potential solutions. We hope this review may serve as a guide to\nimprove the clinical impact of future AI-based solutions.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: text overlap with arXiv:2006.11371 by other authors\n",
    "authors": [
      "Felipe Giuste",
      "Wenqi Shi",
      "Yuanda Zhu",
      "Tarun Naren",
      "Monica Isgut",
      "Ying Sha",
      "Li Tong",
      "Mitali Gupte",
      "May D. Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12705"
  },
  {
    "id": "arXiv:2112.12707",
    "title": "Improving Robustness and Uncertainty Modelling in Neural Ordinary  Differential Equations",
    "abstract": "Neural ordinary differential equations (NODE) have been proposed as a\ncontinuous depth generalization to popular deep learning models such as\nResidual networks (ResNets). They provide parameter efficiency and automate the\nmodel selection process in deep learning models to some extent. However, they\nlack the much-required uncertainty modelling and robustness capabilities which\nare crucial for their use in several real-world applications such as autonomous\ndriving and healthcare. We propose a novel and unique approach to model\nuncertainty in NODE by considering a distribution over the end-time $T$ of the\nODE solver. The proposed approach, latent time NODE (LT-NODE), treats $T$ as a\nlatent variable and apply Bayesian learning to obtain a posterior distribution\nover $T$ from the data. In particular, we use variational inference to learn an\napproximate posterior and the model parameters. Prediction is done by\nconsidering the NODE representations from different samples of the posterior\nand can be done efficiently using a single forward pass. As $T$ implicitly\ndefines the depth of a NODE, posterior distribution over $T$ would also help in\nmodel selection in NODE. We also propose, adaptive latent time NODE (ALT-NODE),\nwhich allow each data point to have a distinct posterior distribution over\nend-times. ALT-NODE uses amortized variational inference to learn an\napproximate posterior using inference networks. We demonstrate the\neffectiveness of the proposed approaches in modelling uncertainty and\nrobustness through experiments on synthetic and several real-world image\nclassification data.",
    "descriptor": "\nComments: Winter Conference on Applications of Computer Vision, 2021\n",
    "authors": [
      "Srinivas Anumasa",
      "P.K. Srijith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12707"
  },
  {
    "id": "arXiv:2112.12709",
    "title": "Data-driven Safety Verification of Stochastic Systems via Barrier  Certificates",
    "abstract": "In this paper, we propose a data-driven approach to formally verify the\nsafety of (potentially) unknown discrete-time continuous-space stochastic\nsystems. The proposed framework is based on a notion of barrier certificates\ntogether with data collected from trajectories of unknown systems. We first\nreformulate the barrier-based safety verification as a robust convex problem\n(RCP). Solving the acquired RCP is hard in general because not only the state\nof the system lives in a continuous set, but also and more problematic, the\nunknown model appears in one of the constraints of RCP. Instead, we leverage a\nfinite number of data, and accordingly, the RCP is casted as a scenario convex\nproblem (SCP). We then relate the optimizer of the SCP to that of the RCP, and\nconsequently, we provide a safety guarantee over the unknown stochastic system\nwith a priori guaranteed confidence. We apply our approach to an unknown room\ntemperature system by collecting sampled data from trajectories of the system\nand verify formally that temperature of the room lies in a comfort zone for a\nfinite time horizon with a desired confidence.",
    "descriptor": "",
    "authors": [
      "Ali Salamati",
      "Abolfazl Lavaei",
      "Sadegh Soudjani",
      "Majid Zamani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.12709"
  },
  {
    "id": "arXiv:2112.12713",
    "title": "Modeling Implicit Bias with Fuzzy Cognitive Maps",
    "abstract": "This paper presents a Fuzzy Cognitive Map model to quantify implicit bias in\nstructured datasets where features can be numeric or discrete. In our proposal,\nproblem features are mapped to neural concepts that are initially activated by\nexperts when running what-if simulations, whereas weights connecting the neural\nconcepts represent absolute correlation/association patterns between features.\nIn addition, we introduce a new reasoning mechanism equipped with a\nnormalization-like transfer function that prevents neurons from saturating.\nAnother advantage of this new reasoning mechanism is that it can easily be\ncontrolled by regulating nonlinearity when updating neurons' activation values\nin each iteration. Finally, we study the convergence of our model and derive\nanalytical conditions concerning the existence and unicity of fixed-point\nattractors.",
    "descriptor": "",
    "authors": [
      "Gonzalo N\u00e1poles",
      "Isel Grau",
      "Leonardo Concepci\u00f3n",
      "Lisa Koutsoviti Koumeri",
      "Jo\u00e3o Paulo Papa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12713"
  },
  {
    "id": "arXiv:2112.12714",
    "title": "Second-order accurate normal reconstruction from volume fractions on  unstructured meshes with arbitrary polyhedral cells",
    "abstract": "This paper introduces a novel method for the efficient second-order accurate\ncomputation of normal fields from volume fractions on unstructured polyhedral\nmeshes. Locally, i.e. in each mesh cell, an averaged normal is reconstructed by\nfitting a plane in a least squares sense to the volume fraction data of\nneighboring cells while implicitly accounting for volume conservation in the\ncell at hand. The resulting minimization problem is solved approximately by\nemploying a Newton-type method. Moreover, applying the Reynolds transport\ntheorem allows to assess the regularity of the derivatives. Since the\ndivergence theorem implies that the volume fraction can be cast as a sum of\nface-based quantities, our method considerably simplifies the numerical\nprocedure for applications in three spatial dimensions while demonstrating an\ninherent ability to robustly deal with unstructured meshes. We discuss the\ntheoretical foundations, regularity and appropriate error measures, along with\nthe details of the numerical algorithm. Finally, numerical results for convex\nand non-convex hypersurfaces embedded in cuboidal and tetrahedral meshes are\npresented, where we obtain second-order convergence for the normal alignment\nand symmetric volume difference. Moreover, the findings are substantiated by\ncompletely new deep insights into the minimization procedure.",
    "descriptor": "",
    "authors": [
      "Johannes Kromer",
      "Fabio Leotta",
      "Dieter Bothe"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.12714"
  },
  {
    "id": "arXiv:2112.12717",
    "title": "Forward Composition Propagation for Explainable Neural Reasoning",
    "abstract": "This paper proposes an algorithm called Forward Composition Propagation (FCP)\nto explain the predictions of feed-forward neural networks operating on\nstructured pattern recognition problems. In the proposed FCP algorithm, each\nneuron is described by a composition vector indicating the role of each problem\nfeature in that neuron. Composition vectors are initialized using a given input\ninstance and subsequently propagated through the whole network until we reach\nthe output layer. It is worth mentioning that the algorithm is executed once\nthe network's training network is done. The sign of each composition value\nindicates whether the corresponding feature excites or inhibits the neuron,\nwhile the absolute value quantifies such an impact. Aiming to validate the FCP\nalgorithm's correctness, we develop a case study concerning bias detection in a\nstate-of-the-art problem in which the ground truth is known. The simulation\nresults show that the composition values closely align with the expected\nbehavior of protected features.",
    "descriptor": "",
    "authors": [
      "Isel Grau",
      "Gonzalo N\u00e1poles",
      "Marilyn Bello",
      "Yamisleydi Salgueiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12717"
  },
  {
    "id": "arXiv:2112.12727",
    "title": "EIFFeL: Ensuring Integrity for Federated Learning",
    "abstract": "Federated learning (FL) enables clients to collaborate with a server to train\na machine learning model. To ensure privacy, the server performs secure\naggregation of updates from the clients. Unfortunately, this prevents\nverification of the well-formedness (integrity) of the updates as the updates\nare masked. Consequently, malformed updates designed to poison the model can be\ninjected without detection. In this paper, we formalize the problem of ensuring\n\\textit{both} update privacy and integrity in FL and present a new system,\n\\textsf{EIFFeL}, that enables secure aggregation of \\textit{verified} updates.\n\\textsf{EIFFeL} is a general framework that can enforce \\textit{arbitrary}\nintegrity checks and remove malformed updates from the aggregate, without\nviolating privacy. Our empirical evaluation demonstrates the practicality of\n\\textsf{EIFFeL}. For instance, with $100$ clients and $10\\%$ poisoning,\n\\textsf{EIFFeL} can train an MNIST classification model to the same accuracy as\nthat of a non-poisoned federated learner in just $2.4$ seconds per iteration.",
    "descriptor": "",
    "authors": [
      "Amrita Roy Chowdhury",
      "Chuan Guo",
      "Somesh Jha",
      "Laurens van der Maaten"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.12727"
  },
  {
    "id": "arXiv:2112.12728",
    "title": "Latent Time Neural Ordinary Differential Equations",
    "abstract": "Neural ordinary differential equations (NODE) have been proposed as a\ncontinuous depth generalization to popular deep learning models such as\nResidual networks (ResNets). They provide parameter efficiency and automate the\nmodel selection process in deep learning models to some extent. However, they\nlack the much-required uncertainty modelling and robustness capabilities which\nare crucial for their use in several real-world applications such as autonomous\ndriving and healthcare. We propose a novel and unique approach to model\nuncertainty in NODE by considering a distribution over the end-time $T$ of the\nODE solver. The proposed approach, latent time NODE (LT-NODE), treats $T$ as a\nlatent variable and apply Bayesian learning to obtain a posterior distribution\nover $T$ from the data. In particular, we use variational inference to learn an\napproximate posterior and the model parameters. Prediction is done by\nconsidering the NODE representations from different samples of the posterior\nand can be done efficiently using a single forward pass. As $T$ implicitly\ndefines the depth of a NODE, posterior distribution over $T$ would also help in\nmodel selection in NODE. We also propose, adaptive latent time NODE (ALT-NODE),\nwhich allow each data point to have a distinct posterior distribution over\nend-times. ALT-NODE uses amortized variational inference to learn an\napproximate posterior using inference networks. We demonstrate the\neffectiveness of the proposed approaches in modelling uncertainty and\nrobustness through experiments on synthetic and several real-world image\nclassification data.",
    "descriptor": "\nComments: Accepted at AAAI-2022\n",
    "authors": [
      "Srinivas Anumasa",
      "P.K. Srijith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.12728"
  },
  {
    "id": "arXiv:2112.12731",
    "title": "ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training  for Language Understanding and Generation",
    "abstract": "Pre-trained language models have achieved state-of-the-art results in various\nNatural Language Processing (NLP) tasks. GPT-3 has shown that scaling up\npre-trained language models can further exploit their enormous potential. A\nunified framework named ERNIE 3.0 was recently proposed for pre-training\nlarge-scale knowledge enhanced models and trained a model with 10 billion\nparameters. ERNIE 3.0 outperformed the state-of-the-art models on various NLP\ntasks. In order to explore the performance of scaling up ERNIE 3.0, we train a\nhundred-billion-parameter model called ERNIE 3.0 Titan with up to 260 billion\nparameters on the PaddlePaddle platform. Furthermore, we design a\nself-supervised adversarial loss and a controllable language modeling loss to\nmake ERNIE 3.0 Titan generate credible and controllable texts. To reduce the\ncomputation overhead and carbon emission, we propose an online distillation\nframework for ERNIE 3.0 Titan, where the teacher model will teach students and\ntrain itself simultaneously. ERNIE 3.0 Titan is the largest Chinese dense\npre-trained model so far. Empirical results show that the ERNIE 3.0 Titan\noutperforms the state-of-the-art models on 68 NLP datasets.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.02137\n",
    "authors": [
      "Shuohuan Wang",
      "Yu Sun",
      "Yang Xiang",
      "Zhihua Wu",
      "Siyu Ding",
      "Weibao Gong",
      "Shikun Feng",
      "Junyuan Shang",
      "Yanbin Zhao",
      "Chao Pang",
      "Jiaxiang Liu",
      "Xuyi Chen",
      "Yuxiang Lu",
      "Weixin Liu",
      "Xi Wang",
      "Yangfan Bai",
      "Qiuliang Chen",
      "Li Zhao",
      "Shiyong Li",
      "Peng Sun",
      "Dianhai Yu",
      "Yanjun Ma",
      "Hao Tian",
      "Hua Wu",
      "Tian Wu",
      "Wei Zeng",
      "Ge Li",
      "Wen Gao",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.12731"
  },
  {
    "id": "arXiv:2112.12740",
    "title": "Learning Cooperative Multi-Agent Policies with Partial Reward Decoupling",
    "abstract": "One of the preeminent obstacles to scaling multi-agent reinforcement learning\nto large numbers of agents is assigning credit to individual agents' actions.\nIn this paper, we address this credit assignment problem with an approach that\nwe call \\textit{partial reward decoupling} (PRD), which attempts to decompose\nlarge cooperative multi-agent RL problems into decoupled subproblems involving\nsubsets of agents, thereby simplifying credit assignment. We empirically\ndemonstrate that decomposing the RL problem using PRD in an actor-critic\nalgorithm results in lower variance policy gradient estimates, which improves\ndata efficiency, learning stability, and asymptotic performance across a wide\narray of multi-agent RL tasks, compared to various other actor-critic\napproaches. Additionally, we relate our approach to counterfactual multi-agent\npolicy gradient (COMA), a state-of-the-art MARL algorithm, and empirically show\nthat our approach outperforms COMA by making better use of information in\nagents' reward streams, and by enabling recent advances in advantage estimation\nto be used.",
    "descriptor": "\nComments: in IEEE Robotics and Automation Letters\n",
    "authors": [
      "Benjamin Freed",
      "Aditya Kapoor",
      "Ian Abraham",
      "Jeff Schneider",
      "Howie Choset"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.12740"
  },
  {
    "id": "arXiv:2112.12742",
    "title": "Determinacy of Real Conjunctive Queries. The Boolean Case",
    "abstract": "In their classical 1993 paper [CV93] Chaudhuri and Vardi notice that some\nfundamental database theory results and techniques fail to survive when we try\nto see query answers as bags (multisets) of tuples rather than as sets of\ntuples.\nBut disappointingly, almost 30 years after [CV93], the bag-semantics based\ndatabase theory is still in its infancy. We do not even know whether\nconjunctive query containment is decidable. And this is not due to lack of\ninterest, but because, in the multiset world, everything suddenly gets\ndiscouragingly complicated.\nIn this paper, we try to re-examine, in the bag semantics scenario, the query\ndeterminacy problem, which has recently been intensively studied in the set\nsemantics scenario. We show that query determinacy (under bag semantics) is\ndecidable for boolean conjunctive queries and undecidable for unions of such\nqueries (in contrast to the set semantics scenario, where the UCQ case remains\ndecidable even for unary queries). We also show that -- surprisingly -- for\npath queries determinacy under bag semantics coincides with determinacy under\nset semantics (and thus it is decidable).",
    "descriptor": "",
    "authors": [
      "Jaros\u0142aw Kwiecie\u0144",
      "Jerzy Marcinkowski",
      "Piotr Ostropolski-Nalewaja"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.12742"
  },
  {
    "id": "arXiv:2112.12748",
    "title": "Assessing the Impact of Attention and Self-Attention Mechanisms on the  Classification of Skin Lesions",
    "abstract": "Attention mechanisms have raised significant interest in the research\ncommunity, since they promise significant improvements in the performance of\nneural network architectures. However, in any specific problem, we still lack a\nprincipled way to choose specific mechanisms and hyper-parameters that lead to\nguaranteed improvements. More recently, self-attention has been proposed and\nwidely used in transformer-like architectures, leading to significant\nbreakthroughs in some applications. In this work we focus on two forms of\nattention mechanisms: attention modules and self-attention. Attention modules\nare used to reweight the features of each layer input tensor. Different modules\nhave different ways to perform this reweighting in fully connected or\nconvolutional layers. The attention models studied are completely modular and\nin this work they will be used with the popular ResNet architecture.\nSelf-Attention, originally proposed in the area of Natural Language Processing\nmakes it possible to relate all the items in an input sequence. Self-Attention\nis becoming increasingly popular in Computer Vision, where it is sometimes\ncombined with convolutional layers, although some recent architectures do away\nentirely with convolutions. In this work, we study and perform an objective\ncomparison of a number of different attention mechanisms in a specific computer\nvision task, the classification of samples in the widely used Skin Cancer MNIST\ndataset. The results show that attention modules do sometimes improve the\nperformance of convolutional neural network architectures, but also that this\nimprovement, although noticeable and statistically significant, is not\nconsistent in different settings. The results obtained with self-attention\nmechanisms, on the other hand, show consistent and significant improvements,\nleading to the best results even in architectures with a reduced number of\nparameters.",
    "descriptor": "",
    "authors": [
      "Rafael Pedro",
      "Arlindo L. Oliveira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12748"
  },
  {
    "id": "arXiv:2112.12750",
    "title": "SLIP: Self-supervision meets Language-Image Pre-training",
    "abstract": "Recent work has shown that self-supervised pre-training leads to improvements\nover supervised learning on challenging visual recognition tasks. CLIP, an\nexciting new approach to learning with language supervision, demonstrates\npromising performance on a wide variety of benchmarks. In this work, we explore\nwhether self-supervised learning can aid in the use of language supervision for\nvisual representation learning. We introduce SLIP, a multi-task learning\nframework for combining self-supervised learning and CLIP pre-training. After\npre-training with Vision Transformers, we thoroughly evaluate representation\nquality and compare performance to both CLIP and self-supervised learning under\nthree distinct settings: zero-shot transfer, linear classification, and\nend-to-end finetuning. Across ImageNet and a battery of additional datasets, we\nfind that SLIP improves accuracy by a large margin. We validate our results\nfurther with experiments on different model sizes, training schedules, and\npre-training datasets. Our findings show that SLIP enjoys the best of both\nworlds: better performance than self-supervision (+8.1% linear accuracy) and\nlanguage supervision (+5.2% zero-shot accuracy).",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Norman Mu",
      "Alexander Kirillov",
      "David Wagner",
      "Saining Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12750"
  },
  {
    "id": "arXiv:2112.12754",
    "title": "Toward a New Science of Common Sense",
    "abstract": "Common sense has always been of interest in AI, but has rarely taken center\nstage. Despite its mention in one of John McCarthy's earliest papers and years\nof work by dedicated researchers, arguably no AI system with a serious amount\nof general common sense has ever emerged. Why is that? What's missing? Examples\nof AI systems' failures of common sense abound, and they point to AI's frequent\nfocus on expertise as the cause. Those attempting to break the brittleness\nbarrier, even in the context of modern deep learning, have tended to invest\ntheir energy in large numbers of small bits of commonsense knowledge. But all\nthe commonsense knowledge fragments in the world don't add up to a system that\nactually demonstrates common sense in a human-like way. We advocate examining\ncommon sense from a broader perspective than in the past. Common sense is more\ncomplex than it has been taken to be and is worthy of its own scientific\nexploration.",
    "descriptor": "\nComments: To be published in Proceedings of AAAI-22, 36th AAAI Conference on Artificial Intelligence\n",
    "authors": [
      "Ronald J. Brachman",
      "Hector J. Levesque"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12754"
  },
  {
    "id": "arXiv:2112.12758",
    "title": "A Manifesto for Applicable Formal Methods",
    "abstract": "Formal methods were frequently shown to be effective and, perhaps because of\nthat, practitioners are interested in using them more often. Still, these\nmethods are far less applied than expected, particularly, in critical domains\nwhere they are strongly recommended and where they have the greatest potential.\nOur hypothesis is that formal methods still seem not to be applicable enough or\nready for their intended use. In critical software engineering, what do we mean\nwhen we speak of a formal method? And what does it mean for such a method to be\napplicable both from a scientific and practical viewpoint? Based on what the\nliterature tells about the first question, with this manifesto, we lay out a\nset of principles that when followed by a formal method give rise to its mature\napplicability in a given scope. Rather than exercising criticism of past\ndevelopments, this manifesto strives to foster an increased use of formal\nmethods to the maximum benefit.",
    "descriptor": "",
    "authors": [
      "Mario Gleirscher",
      "Jaco van de Pol",
      "Jim Woodcock"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.12758"
  },
  {
    "id": "arXiv:2112.12761",
    "title": "BANMo: Building Animatable 3D Neural Models from Many Casual Videos",
    "abstract": "Prior work for articulated 3D shape reconstruction often relies on\nspecialized sensors (e.g., synchronized multi-camera systems), or pre-built 3D\ndeformable models (e.g., SMAL or SMPL). Such methods are not able to scale to\ndiverse sets of objects in the wild. We present BANMo, a method that requires\nneither a specialized sensor nor a pre-defined template shape. BANMo builds\nhigh-fidelity, articulated 3D models (including shape and animatable skinning\nweights) from many monocular casual videos in a differentiable rendering\nframework. While the use of many videos provides more coverage of camera views\nand object articulations, they introduce significant challenges in establishing\ncorrespondence across scenes with different backgrounds, illumination\nconditions, etc. Our key insight is to merge three schools of thought; (1)\nclassic deformable shape models that make use of articulated bones and blend\nskinning, (2) volumetric neural radiance fields (NeRFs) that are amenable to\ngradient-based optimization, and (3) canonical embeddings that generate\ncorrespondences between pixels and an articulated model. We introduce neural\nblend skinning models that allow for differentiable and invertible articulated\ndeformations. When combined with canonical embeddings, such models allow us to\nestablish dense correspondences across videos that can be self-supervised with\ncycle consistency. On real and synthetic datasets, BANMo shows higher-fidelity\n3D reconstructions than prior works for humans and animals, with the ability to\nrender realistic images from novel viewpoints and poses. Project webpage:\nbanmo-www.github.io .",
    "descriptor": "",
    "authors": [
      "Gengshan Yang",
      "Minh Vo",
      "Natalia Neverova",
      "Deva Ramanan",
      "Andrea Vedaldi",
      "Hanbyul Joo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.12761"
  },
  {
    "id": "arXiv:2112.12768",
    "title": "An Ontological Knowledge Representation for Smart Agriculture",
    "abstract": "In order to provide the agricultural industry with the infrastructure it\nneeds to take advantage of advanced technology, such as big data, the cloud,\nand the internet of things (IoT); smart farming is a management concept that\nfocuses on providing the infrastructure necessary to track, monitor, automate,\nand analyse operations. To represent the knowledge extracted from the primary\ndata collected is of utmost importance. An agricultural ontology framework for\nsmart agriculture systems is presented in this study. The knowledge graph is\nrepresented as a lattice to capture and perform reasoning on spatio-temporal\nagricultural data.",
    "descriptor": "",
    "authors": [
      "Bikram Pratim Bhuyan",
      "Ravi Tomar",
      "Maanak Gupta",
      "Amar Ramdane-Cherif"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12768"
  },
  {
    "id": "arXiv:2112.12773",
    "title": "Customising Ranking Models for Enterprise Search on Bilingual  Click-Through Dataset",
    "abstract": "In this work, we provide the details about the process of establishing an\nend-to-end system for enterprise search on bilingual click-through dataset. The\nfirst part of the paper will be about the high-level workflow of the system.\nThen, in the second part we will elaborately mention about the ranking models\nto improve the search results in the vertical search of the technical documents\nin enterprise domain. Throughout the paper, we will mention the way which we\ncombine the methods in IR literature. Finally, in the last part of the paper we\nwill report our results using different ranking algorithms with $NDCG@k$ where\nk is the cut-off value.",
    "descriptor": "",
    "authors": [
      "Gizem Gezici"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.12773"
  },
  {
    "id": "arXiv:2112.12777",
    "title": "Cross Modal Retrieval with Querybank Normalisation",
    "abstract": "Profiting from large-scale training datasets, advances in neural architecture\ndesign and efficient inference, joint embeddings have become the dominant\napproach for tackling cross-modal retrieval. In this work we first show that,\ndespite their effectiveness, state-of-the-art joint embeddings suffer\nsignificantly from the longstanding hubness problem in which a small number of\ngallery embeddings form the nearest neighbours of many queries. Drawing\ninspiration from the NLP literature, we formulate a simple but effective\nframework called Querybank Normalisation (QB-Norm) that re-normalises query\nsimilarities to account for hubs in the embedding space. QB-Norm improves\nretrieval performance without requiring retraining. Differently from prior\nwork, we show that QB-Norm works effectively without concurrent access to any\ntest set queries. Within the QB-Norm framework, we also propose a novel\nsimilarity normalisation method, the Dynamic Inverted Softmax, that is\nsignificantly more robust than existing approaches. We showcase QB-Norm across\na range of cross modal retrieval models and benchmarks where it consistently\nenhances strong baselines beyond the state of the art. Code is available at\nhttps://vladbogo.github.io/QB-Norm/.",
    "descriptor": "",
    "authors": [
      "Simion-Vlad Bogolin",
      "Ioana Croitoru",
      "Hailin Jin",
      "Yang Liu",
      "Samuel Albanie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12777"
  },
  {
    "id": "arXiv:2112.12782",
    "title": "SeMask: Semantically Masked Transformers for Semantic Segmentation",
    "abstract": "Finetuning a pretrained backbone in the encoder part of an image transformer\nnetwork has been the traditional approach for the semantic segmentation task.\nHowever, such an approach leaves out the semantic context that an image\nprovides during the encoding stage. This paper argues that incorporating\nsemantic information of the image into pretrained hierarchical\ntransformer-based backbones while finetuning improves the performance\nconsiderably. To achieve this, we propose SeMask, a simple and effective\nframework that incorporates semantic information into the encoder with the help\nof a semantic attention operation. In addition, we use a lightweight semantic\ndecoder during training to provide supervision to the intermediate semantic\nprior maps at every stage. Our experiments demonstrate that incorporating\nsemantic priors enhances the performance of the established hierarchical\nencoders with a slight increase in the number of FLOPs. We provide empirical\nproof by integrating SeMask into each variant of the Swin-Transformer as our\nencoder paired with different decoders. Our framework achieves a new\nstate-of-the-art of 58.22% mIoU on the ADE20K dataset and improvements of over\n3% in the mIoU metric on the Cityscapes dataset. The code and checkpoints are\npublicly available at\nhttps://github.com/Picsart-AI-Research/SeMask-Segmentation .",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Jitesh Jain",
      "Anukriti Singh",
      "Nikita Orlov",
      "Zilong Huang",
      "Jiachen Li",
      "Steven Walton",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12782"
  },
  {
    "id": "arXiv:2112.12785",
    "title": "NinjaDesc: Content-Concealing Visual Descriptors via Adversarial  Learning",
    "abstract": "In the light of recent analyses on privacy-concerning scene revelation from\nvisual descriptors, we develop descriptors that conceal the input image\ncontent. In particular, we propose an adversarial learning framework for\ntraining visual descriptors that prevent image reconstruction, while\nmaintaining the matching accuracy. We let a feature encoding network and image\nreconstruction network compete with each other, such that the feature encoder\ntries to impede the image reconstruction with its generated descriptors, while\nthe reconstructor tries to recover the input image from the descriptors. The\nexperimental results demonstrate that the visual descriptors obtained with our\nmethod significantly deteriorate the image reconstruction quality with minimal\nimpact on correspondence matching and camera localization performance.",
    "descriptor": "",
    "authors": [
      "Tony Ng",
      "Hyo Jin Kim",
      "Vincent Lee",
      "Daniel Detone",
      "Tsun-Yi Yang",
      "Tianwei Shen",
      "Eddy Ilg",
      "Vassileios Balntas",
      "Krystian Mikolajczyk",
      "Chris Sweeney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12785"
  },
  {
    "id": "arXiv:2112.12786",
    "title": "ELSA: Enhanced Local Self-Attention for Vision Transformer",
    "abstract": "Self-attention is powerful in modeling long-range dependencies, but it is\nweak in local finer-level feature learning. The performance of local\nself-attention (LSA) is just on par with convolution and inferior to dynamic\nfilters, which puzzles researchers on whether to use LSA or its counterparts,\nwhich one is better, and what makes LSA mediocre. To clarify these, we\ncomprehensively investigate LSA and its counterparts from two sides:\n\\emph{channel setting} and \\emph{spatial processing}. We find that the devil\nlies in the generation and application of spatial attention, where relative\nposition embeddings and the neighboring filter application are key factors.\nBased on these findings, we propose the enhanced local self-attention (ELSA)\nwith Hadamard attention and the ghost head. Hadamard attention introduces the\nHadamard product to efficiently generate attention in the neighboring case,\nwhile maintaining the high-order mapping. The ghost head combines attention\nmaps with static matrices to increase channel capacity. Experiments demonstrate\nthe effectiveness of ELSA. Without architecture / hyperparameter modification,\ndrop-in replacing LSA with ELSA boosts Swin Transformer \\cite{swin} by up to\n+1.4 on top-1 accuracy. ELSA also consistently benefits VOLO \\cite{volo} from\nD1 to D5, where ELSA-VOLO-D5 achieves 87.2 on the ImageNet-1K without extra\ntraining images. In addition, we evaluate ELSA in downstream tasks. ELSA\nsignificantly improves the baseline by up to +1.9 box Ap / +1.3 mask Ap on the\nCOCO, and by up to +1.9 mIoU on the ADE20K. Code is available at\n\\url{https://github.com/damo-cv/ELSA}.",
    "descriptor": "\nComments: Project at \\url{this https URL}\n",
    "authors": [
      "Jingkai Zhou",
      "Pichao Wang",
      "Fan Wang",
      "Qiong Liu",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.12786"
  },
  {
    "id": "arXiv:2112.10872",
    "title": "Calabi-Yau Metrics, Energy Functionals and Machine-Learning",
    "abstract": "We apply machine learning to the problem of finding numerical Calabi-Yau\nmetrics. We extend previous work on learning approximate Ricci-flat metrics\ncalculated using Donaldson's algorithm to the much more accurate \"optimal\"\nmetrics of Headrick and Nassar. We show that machine learning is able to\npredict the K\\\"ahler potential of a Calabi-Yau metric having seen only a small\nsample of training data.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Anthony Ashmore",
      "Lucille Calmon",
      "Yang-Hui He",
      "Burt A. Ovrut"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (cs.LG)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2112.10872"
  },
  {
    "id": "arXiv:2112.12173",
    "title": "Conflict-free coloring on open neighborhoods of claw-free graphs",
    "abstract": "The `Conflict-Free Open (Closed) Neighborhood coloring', abbreviated CFON\n(CFCN) coloring, of a graph $G$ using $r$ colors is a coloring of the vertices\nof $G$ such that every vertex sees some color exactly once in its open (closed)\nneighborhood. The minimum $r$ such that $G$ has a CFON (CFCN) coloring using\n$r$ colors is called the `CFON chromatic number' (`CFCN chromatic number') of\n$G$. This is denoted by $\\chi_{CF}^{ON}(G)$ ($\\chi_{CF}^{CN}(G)$). D\\k ebski\nand Przyby\\l{}o in [J. Graph Theory, 2021] showed that if $G$ is a line graph\nwith maximum degree $\\Delta$, then $\\chi_{CF}^{CN}(G) = O(\\ln \\Delta)$. As an\nopen question, they asked if the result could be extended to claw-free\n($K_{1,3}$-free) graphs, which are a superclass of line graphs. For $k\\geq 3$,\nwe show that if $G$ is $K_{1,k}$-free, then $\\chi_{CF}^{ON}(G) = O(k^2\\ln\n\\Delta)$. Since it is known that the CFCN chromatic number of a graph is at\nmost twice its CFON chromatic number, this answers the question posed by\nD\\k{e}bski and Przyby\\l{}o.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Sriram Bhyravarapu",
      "Subrahmanyam Kalyanasundaram",
      "Rogers Mathew"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.12173"
  },
  {
    "id": "arXiv:2112.12185",
    "title": "Dimension-independent Markov chain Monte Carlo on the sphere",
    "abstract": "We consider Bayesian analysis on high-dimensional spheres with angular\ncentral Gaussian priors. These priors model antipodally-symmetric directional\ndata, are easily defined in Hilbert spaces and occur, for instance, in Bayesian\nbinary classification and level set inversion. In this paper we derive\nefficient Markov chain Monte Carlo methods for approximate sampling of\nposteriors with respect to these priors. Our approaches rely on lifting the\nsampling problem to the ambient Hilbert space and exploit existing\ndimension-independent samplers in linear spaces. By a push-forward Markov\nkernel construction we then obtain Markov chains on the sphere, which inherit\nreversibility and spectral gap properties from samplers in linear spaces.\nMoreover, our proposed algorithms show dimension-independent efficiency in\nnumerical experiments.",
    "descriptor": "\nComments: 35 pages, 7 figures\n",
    "authors": [
      "H. C. Lie",
      "D. Rudolf",
      "B. Sprungk",
      "T. J. Sullivan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.12185"
  },
  {
    "id": "arXiv:2112.12194",
    "title": "Surrogate Likelihoods for Variational Annealed Importance Sampling",
    "abstract": "Variational inference is a powerful paradigm for approximate Bayesian\ninference with a number of appealing properties, including support for model\nlearning and data subsampling. By contrast MCMC methods like Hamiltonian Monte\nCarlo do not share these properties but remain attractive since, contrary to\nparametric methods, MCMC is asymptotically unbiased. For these reasons\nresearchers have sought to combine the strengths of both classes of algorithms,\nwith recent approaches coming closer to realizing this vision in practice.\nHowever, supporting data subsampling in these hybrid methods can be a\nchallenge, a shortcoming that we address by introducing a surrogate likelihood\nthat can be learned jointly with other variational parameters. We argue\ntheoretically that the resulting algorithm permits the user to make an\nintuitive trade-off between inference fidelity and computational cost. In an\nextensive empirical comparison we show that our method performs well in\npractice and that it is well-suited for black-box inference in probabilistic\nprogramming frameworks.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Martin Jankowiak",
      "Du Phan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12194"
  },
  {
    "id": "arXiv:2112.12204",
    "title": "On the performance and programming of reversible molecular computers",
    "abstract": "If the 20th century was known for the computational revolution, what will the\n21st be known for? Perhaps the recent strides in the nascent fields of\nmolecular programming and biological computation will help bring about the\n'Coming Era of Nanotechnology' promised in Drexler's 'Engines of Creation'.\nThough there is still far to go, there is much reason for optimism. This thesis\nexamines the underlying principles needed to realise the computational aspects\nof such 'engines' in a performant way. Its main body focusses on the ways in\nwhich thermodynamics constrains the operation and design of such systems, and\nit ends with the proposal of a model of computation appropriate for exploiting\nthese constraints.\nThese thermodynamic constraints are approached from three different\ndirections. The first considers the maximum possible aggregate performance of a\nsystem of computers of given volume, $V$, with a given supply of free energy.\nFrom this perspective, reversible computing is imperative in order to\ncircumvent the Landauer limit. A result of Frank is refined and strengthened,\nshowing that the adiabatic regime reversible computer performance is the best\npossible for any computer - quantum or classical. This therefore shows a\nuniversal scaling law governing the performance of compact computers of $\\sim\nV^{5/6}$, compared to $\\sim V^{2/3}$ for conventional computers. For the case\nof molecular computers, it is shown how to attain this bound. The second\ndirection extends this performance analysis to the case where individual\ncomputational particles or sub-units can interact with one another. The third\nextends it to interactions with shared, non-computational parts of the system.\nIt is found that accommodating these interactions in molecular computers\nimposes a performance penalty that undermines the earlier scaling result.\nNonetheless, scaling superior to that of irreversible computers can be...",
    "descriptor": "\nComments: 195 pages, 26 figures, 24 listings, PhD thesis at University of Cambridge\n",
    "authors": [
      "Hannah Amelie Earley"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.12204"
  },
  {
    "id": "arXiv:2112.12221",
    "title": "Nonlinear regimes of the electron cyclotron drift instability in Vlasov  simulations",
    "abstract": "We report on a novel investigation of the nonlinear regime of the electron\ncyclotron drift instability, using a grid-based Vlasov simulation. It is shown\nthat the instability occurs as a series of cyclotron resonances with the\nelectron beam mode due to the $E\\times B$ drift. In the nonlinear regime, we\nobserve condensation of fluctuations energy toward the lowest resonance mode\nand below, i.e., an inverse energy cascade. It is shown that the\ncharacteristics of the nonlinear saturation state remain far from the ion-sound\nregime.",
    "descriptor": "",
    "authors": [
      "Arash Tavassoli",
      "Andrei Smolyakov",
      "Magdi Shoucri",
      "Raymond J. Spiteri"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.12221"
  },
  {
    "id": "arXiv:2112.12280",
    "title": "Nonnegative OPLS for Supervised Design of Filter Banks: Application to  Image and Audio Feature Extraction",
    "abstract": "Audio or visual data analysis tasks usually have to deal with\nhigh-dimensional and nonnegative signals. However, most data analysis methods\nsuffer from overfitting and numerical problems when data have more than a few\ndimensions needing a dimensionality reduction preprocessing. Moreover,\ninterpretability about how and why filters work for audio or visual\napplications is a desired property, especially when energy or spectral signals\nare involved. In these cases, due to the nature of these signals, the\nnonnegativity of the filter weights is a desired property to better understand\nits working. Because of these two necessities, we propose different methods to\nreduce the dimensionality of data while the nonnegativity and interpretability\nof the solution are assured. In particular, we propose a generalized\nmethodology to design filter banks in a supervised way for applications dealing\nwith nonnegative data, and we explore different ways of solving the proposed\nobjective function consisting of a nonnegative version of the orthonormalized\npartial least-squares method. We analyze the discriminative power of the\nfeatures obtained with the proposed methods for two different and widely\nstudied applications: texture and music genre classification. Furthermore, we\ncompare the filter banks achieved by our methods with other state-of-the-art\nmethods specifically designed for feature extraction.",
    "descriptor": "",
    "authors": [
      "Sergio Mu\u00f1oz-Romero",
      "Jer\u00f3nimo Arenas Garc\u00eda",
      "Vanessa G\u00f3mez-Verdejo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.12280"
  },
  {
    "id": "arXiv:2112.12313",
    "title": "Mean field game for modeling of COVID-19 spread",
    "abstract": "The paper presents the one of possible approach to model the epidemic\npropagation. The proposed model is based on the mean-field control inside\nseparate groups of population, namely, suspectable (S), infected (I), removed\n(R) and cross-immune (C). In the paper the numerical algorithm to solve such a\nproblem is presented, which ensures the conservation the total mass of\npopulation during timeline. Numerical experiments demonstrate the result of\nmodelling the propagation of COVID-19 virus during two 100 day periods in\nNovosibirsk (Russia).",
    "descriptor": "",
    "authors": [
      "Viktoriya Petrakova",
      "Olga Krivorotko"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.12313"
  },
  {
    "id": "arXiv:2112.12354",
    "title": "A Riemann--Hilbert approach to the perturbation theory for orthogonal  polynomials: Applications to numerical linear algebra and random matrix  theory",
    "abstract": "We establish a new perturbation theory for orthogonal polynomials using a\nRiemann-Hilbert approach and consider applications in numerical linear algebra\nand random matrix theory. We show that the orthogonal polynomials with respect\nto two measures can be effectively compared using the difference of their\nStieltjes transforms on a suitably chosen contour. Moreover, when two measures\nare close and satisfy some regularity conditions, we use the theta functions of\na hyperelliptic Riemann surface to derive explicit and accurate expansion\nformulae for the perturbed orthogonal polynomials. The leading error terms can\nbe fully characterized by the difference of the Stieltjes transforms on the\ncontour. The results are applied to analyze several numerical algorithms from\nlinear algebra, including the Lanczos tridiagonalization procedure, the\nCholesky factorization and the conjugate gradient algorithm (CGA). As a case\nstudy, we investigate these algorithms applied to a general spiked sample\ncovariance matrix model by considering the eigenvector empirical spectral\ndistribution and its limit, allowing for precise estimates on the algorithms as\nthe number of iterations diverges. For this concrete random matrix model,\nbeyond the first order expansion, we derive a mesoscopic central limit theorem\nfor the associated orthogonal polynomials and other quantities relevant to\nnumerical algorithms.",
    "descriptor": "",
    "authors": [
      "Xiucai Ding",
      "Thomas Trogdon"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12354"
  },
  {
    "id": "arXiv:2112.12373",
    "title": "Decentralized Multi-Task Stochastic Optimization With Compressed  Communications",
    "abstract": "We consider a multi-agent network where each node has a stochastic (local)\ncost function that depends on the decision variable of that node and a random\nvariable, and further the decision variables of neighboring nodes are pairwise\nconstrained. There is an aggregate objective function for the network, composed\nadditively of the expected values of the local cost functions at the nodes, and\nthe overall goal of the network is to obtain the minimizing solution to this\naggregate objective function subject to all the pairwise constraints. This is\nto be achieved at the node level using decentralized information and local\ncomputation, with exchanges of only compressed information allowed by\nneighboring nodes. The paper develops algorithms and obtains performance bounds\nfor two different models of local information availability at the nodes: (i)\nsample feedback, where each node has direct access to samples of the local\nrandom variable to evaluate its local cost, and (ii) bandit feedback, where\nsamples of the random variables are not available, but only the values of the\nlocal cost functions at two random points close to the decision are available\nto each node. For both models, with compressed communication between neighbors,\nwe have developed decentralized saddle-point algorithms that deliver\nperformances no different (in order sense) from those without communication\ncompression; specifically, we show that deviation from the global minimum value\nand violations of the constraints are upper-bounded by\n$\\mathcal{O}(T^{-\\frac{1}{2}})$ and $\\mathcal{O}(T^{-\\frac{1}{4}})$,\nrespectively, where $T$ is the number of iterations. Numerical examples\nprovided in the paper corroborate these bounds and demonstrate the\ncommunication efficiency of the proposed method.",
    "descriptor": "\nComments: 31 pages, 4 figures\n",
    "authors": [
      "Navjot Singh",
      "Xuanyu Cao",
      "Suhas Diggavi",
      "Tamer Basar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12373"
  },
  {
    "id": "arXiv:2112.12386",
    "title": "KFWC: A Knowledge-Driven Deep Learning Model for Fine-grained  Classification of Wet-AMD",
    "abstract": "Automated diagnosis using deep neural networks can help ophthalmologists\ndetect the blinding eye disease wet Age-related Macular Degeneration (AMD).\nWet-AMD has two similar subtypes, Neovascular AMD and Polypoidal Choroidal\nVessels (PCV). However, due to the difficulty in data collection and the\nsimilarity between images, most studies have only achieved the coarse-grained\nclassification of wet-AMD rather than a finer-grained one of wet-AMD subtypes.\nTo solve this issue, in this paper we propose a Knowledge-driven Fine-grained\nWet-AMD Classification Model (KFWC), to classify fine-grained diseases with\ninsufficient data. With the introduction of a priori knowledge of 10 lesion\nsigns of input images into the KFWC, we aim to accelerate the KFWC by means of\nmulti-label classification pre-training, to locate the decisive image features\nin the fine-grained disease classification task and therefore achieve better\nclassification. Simultaneously, the KFWC can also provide good interpretability\nand effectively alleviate the pressure of data collection and annotation in the\nfield of fine-grained disease classification for wet-AMD. The experiments\ndemonstrate the effectiveness of the KFWC which reaches 99.71% in AU-ROC\nscores, and its considerable improvements over the data-driven w/o Knowledge\nand ophthalmologists, with the rates of 6.69% over the strongest baseline and\n4.14% over ophthalmologists.",
    "descriptor": "",
    "authors": [
      "Haihong E",
      "Jiawen He",
      "Tianyi Hu",
      "Lifei Wang",
      "Lifei Yuan",
      "Ruru Zhang",
      "Meina Song"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12386"
  },
  {
    "id": "arXiv:2112.12425",
    "title": "Well-posedness of weak solution for a nonlinear poroelasticity model",
    "abstract": "In this paper, we study the existence and uniqueness of weak solution of a\nnonlinear poroelasticity model. To better describe the proccess of deformation\nand diffusion underlying in the original model, we firstly reformulate the\nnonlinear poroelasticity by a multiphysics approach. Then, we adopt the similar\ntechnique of proving the well-posedness of nonlinear Stokes equations to prove\nthe existence and uniqueness of weak solution of a nonlinear poroelasticity\nmodel. And we strictly prove the growth, coercivity and monotonicity of the\nnonlinear stress-strain relation, give the energy estimates and use Schauder's\nfixed point theorem to show the existence and uniqueness of weak solution of\nthe nonlinear poroelasticity model.",
    "descriptor": "\nComments: 20 pages. arXiv admin note: text overlap with arXiv:1411.7464\n",
    "authors": [
      "Zhihao Ge",
      "Wenlong He"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12425"
  },
  {
    "id": "arXiv:2112.12435",
    "title": "A Divide-and-Conquer Approach to Dicke State Preparation",
    "abstract": "We present a divide-and-conquer approach to deterministically prepare Dicke\nstates $|D_k^n>$ (i.e. equal-weight superpositions of all $n$-qubit states with\nHamming Weight $k$) on quantum computers. In an experimental evaluation for up\nto $n = 6$ qubits on IBM Quantum Sydney and Montreal devices, we achieve\nsignificantly higher state fidelity compared to previous results [Mukherjee\net.al. TQE'2020, Cruz et.al. QuTe'2019].\nThe fidelity gains are achieved through several techniques: Our circuits\nfirst \"divide\" the Hamming weight between blocks of $n/2$ qubits, and then\n\"conquer\" those blocks with improved versions of Dicke state unitaries\n[B\\\"artschi et.al. FCT'2019]. Due to the sparse connectivity on IBM's\nheavy-hex-architectures, these circuits are implemented for linear nearest\nneighbor topologies. Further gains in (estimating) the state fidelity are due\nto our use of measurement error mitigation and hardware progress.",
    "descriptor": "",
    "authors": [
      "Shamminuj Aktar",
      "Andreas B\u00e4rtschi",
      "Abdel-Hameed A. Badawy",
      "Stephan Eidenbenz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.12435"
  },
  {
    "id": "arXiv:2112.12454",
    "title": "Cardinality-constrained Distributionally Robust Portfolio Optimization",
    "abstract": "This paper studies a distributionally robust portfolio optimization model\nwith a cardinality constraint for limiting the number of invested assets. We\nformulate this model as a mixed-integer semidefinite optimization (MISDO)\nproblem by means of the moment-based uncertainty set of probability\ndistributions of asset returns. To exactly solve large-scale problems, we\npropose a specialized cutting-plane algorithm that is based on bilevel\noptimization reformulation. We prove the finite convergence of the algorithm.\nWe also apply a matrix completion technique to lower-level SDO problems to make\ntheir problem sizes much smaller. Numerical experiments demonstrate that our\ncutting-plane algorithm is significantly faster than the state-of-the-art MISDO\nsolver SCIP-SDP. We also show that our portfolio optimization model can achieve\ngood investment performance compared with the conventional mean-variance model.",
    "descriptor": "",
    "authors": [
      "Ken Kobayashi",
      "Yuichi Takano",
      "Kazuhide Nakata"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.12454"
  },
  {
    "id": "arXiv:2112.12474",
    "title": "Generalization capabilities of neural networks in lattice applications",
    "abstract": "In recent years, the use of machine learning has become increasingly popular\nin the context of lattice field theories. An essential element of such theories\nis represented by symmetries, whose inclusion in the neural network properties\ncan lead to high reward in terms of performance and generalizability. A\nfundamental symmetry that usually characterizes physical systems on a lattice\nwith periodic boundary conditions is equivariance under spacetime translations.\nHere we investigate the advantages of adopting translationally equivariant\nneural networks in favor of non-equivariant ones. The system we consider is a\ncomplex scalar field with quartic interaction on a two-dimensional lattice in\nthe flux representation, on which the networks carry out various regression and\nclassification tasks. Promising equivariant and non-equivariant architectures\nare identified with a systematic search. We demonstrate that in most of these\ntasks our best equivariant architectures can perform and generalize\nsignificantly better than their non-equivariant counterparts, which applies not\nonly to physical parameters beyond those represented in the training set, but\nalso to different lattice sizes.",
    "descriptor": "\nComments: 10 pages, 7 figures, proceedings for the 38th International Symposium on Lattice Field Theory (LATTICE21)\n",
    "authors": [
      "Srinath Bulusu",
      "Matteo Favoni",
      "Andreas Ipp",
      "David I. M\u00fcller",
      "Daniel Schuh"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.12474"
  },
  {
    "id": "arXiv:2112.12482",
    "title": "Self-supervised Representation Learning of Neuronal Morphologies",
    "abstract": "Understanding the diversity of cell types and their function in the brain is\none of the key challenges in neuroscience. The advent of large-scale datasets\nhas given rise to the need of unbiased and quantitative approaches to cell type\nclassification. We present GraphDINO, a purely data-driven approach to learning\na low dimensional representation of the 3D morphology of neurons. GraphDINO is\na novel graph representation learning method for spatial graphs utilizing\nself-supervised learning on transformer models. It smoothly interpolates\nbetween attention-based global interaction between nodes and classic graph\nconvolutional processing. We show that this method is able to yield\nmorphological cell type clustering that is comparable to manual feature-based\nclassification and shows a good correspondence to expert-labeled cell types in\ntwo different species and cortical areas. Our method is applicable beyond\nneuroscience in settings where samples in a dataset are graphs and graph-level\nembeddings are desired.",
    "descriptor": "",
    "authors": [
      "Marissa A. Weis",
      "Laura Pede",
      "Timo L\u00fcddecke",
      "Alexander S. Ecker"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2112.12482"
  },
  {
    "id": "arXiv:2112.12493",
    "title": "Equivariance and generalization in neural networks",
    "abstract": "The crucial role played by the underlying symmetries of high energy physics\nand lattice field theories calls for the implementation of such symmetries in\nthe neural network architectures that are applied to the physical system under\nconsideration. In these proceedings, we focus on the consequences of\nincorporating translational equivariance among the network properties,\nparticularly in terms of performance and generalization. The benefits of\nequivariant networks are exemplified by studying a complex scalar field theory,\non which various regression and classification tasks are examined. For a\nmeaningful comparison, promising equivariant and non-equivariant architectures\nare identified by means of a systematic search. The results indicate that in\nmost of the tasks our best equivariant architectures can perform and generalize\nsignificantly better than their non-equivariant counterparts, which applies not\nonly to physical parameters beyond those represented in the training set, but\nalso to different lattice sizes.",
    "descriptor": "\nComments: 8 pages, 7 figures, proceedings for the 14th Quark Confinement and the Hadron Spectrum Conference (vConf2021)\n",
    "authors": [
      "Srinath Bulusu",
      "Matteo Favoni",
      "Andreas Ipp",
      "David I. M\u00fcller",
      "Daniel Schuh"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.12493"
  },
  {
    "id": "arXiv:2112.12509",
    "title": "Integrating Quantum Processor Device and Control Optimization in a  Gradient-based Framework",
    "abstract": "In a quantum processor, the device design and external controls together\ncontribute to the quality of the target quantum operations. As we continuously\nseek better alternative qubit platforms, we explore the increasingly large\ndevice and control design space. Thus, optimization becomes more and more\nchallenging. In this work, we demonstrate that the figure of merit reflecting a\ndesign goal can be made differentiable with respect to the device and control\nparameters. In addition, we can compute the gradient of the design objective\nefficiently in a similar manner to the back-propagation algorithm and then\nutilize the gradient to optimize the device and the control parameters jointly\nand efficiently. This extends the scope of the quantum optimal control to\nsuperconducting device design. We also demonstrate the viability of\ngradient-based joint optimization over the device and control parameters\nthrough a few examples.",
    "descriptor": "",
    "authors": [
      "Xiaotong Ni",
      "Hui-Hai Zhao",
      "Lei Wang",
      "Feng Wu",
      "Jianxin Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12509"
  },
  {
    "id": "arXiv:2112.12521",
    "title": "Biases in human mobility data impact epidemic modeling",
    "abstract": "Large-scale human mobility data is a key resource in data-driven policy\nmaking and across many scientific fields. Most recently, mobility data was\nextensively used during the COVID-19 pandemic to study the effects of\ngovernmental policies and to inform epidemic models. Large-scale mobility is\noften measured using digital tools such as mobile phones. However, it remains\nan open question how truthfully these digital proxies represent the actual\ntravel behavior of the general population. Here, we examine mobility datasets\nfrom multiple countries and identify two fundamentally different types of bias\ncaused by unequal access to, and unequal usage of mobile phones. We introduce\nthe concept of data generation bias, a previously overlooked type of bias,\nwhich is present when the amount of data that an individual produces influences\ntheir representation in the dataset. We find evidence for data generation bias\nin all examined datasets in that high-wealth individuals are overrepresented,\nwith the richest 20% contributing over 50% of all recorded trips, substantially\nskewing the datasets. This inequality is consequential, as we find mobility\npatterns of different wealth groups to be structurally different, where the\nmobility networks of high-wealth users are denser and contain more long-range\nconnections. To mitigate the skew, we present a framework to debias data and\nshow how simple techniques can be used to increase representativeness. Using\nour approach we show how biases can severely impact outcomes of dynamic\nprocesses such as epidemic simulations, where biased data incorrectly estimates\nthe severity and speed of disease transmission. Overall, we show that a failure\nto account for biases can have detrimental effects on the results of studies\nand urge researchers and practitioners to account for data-fairness in all\nfuture studies of human mobility.",
    "descriptor": "",
    "authors": [
      "Frank Schlosser",
      "Vedran Sekara",
      "Dirk Brockmann",
      "Manuel Garcia-Herranz"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2112.12521"
  },
  {
    "id": "arXiv:2112.12545",
    "title": "A Deep Reinforcement Learning Approach for Solving the Traveling  Salesman Problem with Drone",
    "abstract": "Reinforcement learning has recently shown promise in learning quality\nsolutions in many combinatorial optimization problems. In particular, the\nattention-based encoder-decoder models show high effectiveness on various\nrouting problems, including the Traveling Salesman Problem (TSP).\nUnfortunately, they perform poorly for the TSP with Drone (TSP-D), requiring\nrouting a heterogeneous fleet of vehicles in coordination -- a truck and a\ndrone. In TSP-D, the two vehicles are moving in tandem and may need to wait at\na node for the other vehicle to join. State-less attention-based decoder fails\nto make such coordination between vehicles. We propose an attention\nencoder-LSTM decoder hybrid model, in which the decoder's hidden state can\nrepresent the sequence of actions made. We empirically demonstrate that such a\nhybrid model improves upon a purely attention-based model for both solution\nquality and computational efficiency. Our experiments on the min-max\nCapacitated Vehicle Routing Problem (mmCVRP) also confirm that the hybrid model\nis more suitable for coordinated routing of multiple vehicles than the\nattention-based model.",
    "descriptor": "",
    "authors": [
      "Aigerim Bogyrbayeva. Taehyun Yoon",
      "Hanbum Ko",
      "Sungbin Lim",
      "Hyokun Yun",
      "Changhyun Kwon"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12545"
  },
  {
    "id": "arXiv:2112.12554",
    "title": "Beyond Low Earth Orbit: Biomonitoring, Artificial Intelligence, and  Precision Space Health",
    "abstract": "Human space exploration beyond low Earth orbit will involve missions of\nsignificant distance and duration. To effectively mitigate myriad space health\nhazards, paradigm shifts in data and space health systems are necessary to\nenable Earth-independence, rather than Earth-reliance. Promising developments\nin the fields of artificial intelligence and machine learning for biology and\nhealth can address these needs. We propose an appropriately autonomous and\nintelligent Precision Space Health system that will monitor, aggregate, and\nassess biomedical statuses; analyze and predict personalized adverse health\noutcomes; adapt and respond to newly accumulated data; and provide preventive,\nactionable, and timely insights to individual deep space crew members and\niterative decision support to their crew medical officer. Here we present a\nsummary of recommendations from a workshop organized by the National\nAeronautics and Space Administration, on future applications of artificial\nintelligence in space biology and health. In the next decade, biomonitoring\ntechnology, biomarker science, spacecraft hardware, intelligent software, and\nstreamlined data management must mature and be woven together into a Precision\nSpace Health system to enable humanity to thrive in deep space.",
    "descriptor": "\nComments: 31 pages, 4 figures\n",
    "authors": [
      "Ryan T. Scott",
      "Erik L. Antonsen",
      "Lauren M. Sanders",
      "Jaden J.A. Hastings",
      "Seung-min Park",
      "Graham Mackintosh",
      "Robert J. Reynolds",
      "Adrienne L. Hoarfrost",
      "Aenor Sawyer",
      "Casey S. Greene",
      "Benjamin S. Glicksberg",
      "Corey A. Theriot",
      "Daniel C. Berrios",
      "Jack Miller",
      "Joel Babdor",
      "Richard Barker",
      "Sergio E. Baranzini",
      "Afshin Beheshti",
      "Stuart Chalk",
      "Guillermo M. Delgado-Aparicio",
      "Melissa Haendel",
      "Arif A. Hamid",
      "Philip Heller",
      "Daniel Jamieson",
      "Katelyn J. Jarvis",
      "John Kalantari",
      "Kia Khezeli",
      "Svetlana V. Komarova",
      "Matthieu Komorowski",
      "Prachi Kothiyal",
      "Ashish Mahabal",
      "Uri Manor",
      "Hector Garcia Martin",
      "Christopher E. Mason",
      "Mona Matar"
    ],
    "subjectives": [
      "Other Quantitative Biology (q-bio.OT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12554"
  },
  {
    "id": "arXiv:2112.12555",
    "title": "Optimal learning of high-dimensional classification problems using deep  neural networks",
    "abstract": "We study the problem of learning classification functions from noiseless\ntraining samples, under the assumption that the decision boundary is of a\ncertain regularity. We establish universal lower bounds for this estimation\nproblem, for general classes of continuous decision boundaries. For the class\nof locally Barron-regular decision boundaries, we find that the optimal\nestimation rates are essentially independent of the underlying dimension and\ncan be realized by empirical risk minimization methods over a suitable class of\ndeep neural networks. These results are based on novel estimates of the $L^1$\nand $L^\\infty$ entropies of the class of Barron-regular functions.",
    "descriptor": "",
    "authors": [
      "Philipp Petersen",
      "Felix Voigtlaender"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.12555"
  },
  {
    "id": "arXiv:2112.12560",
    "title": "On the relationship between calibrated predictors and unbiased volume  estimation",
    "abstract": "Machine learning driven medical image segmentation has become standard in\nmedical image analysis. However, deep learning models are prone to\noverconfident predictions. This has led to a renewed focus on calibrated\npredictions in the medical imaging and broader machine learning communities.\nCalibrated predictions are estimates of the probability of a label that\ncorrespond to the true expected value of the label conditioned on the\nconfidence. Such calibrated predictions have utility in a range of medical\nimaging applications, including surgical planning under uncertainty and active\nlearning systems. At the same time it is often an accurate volume measurement\nthat is of real importance for many medical applications. This work\ninvestigates the relationship between model calibration and volume estimation.\nWe demonstrate both mathematically and empirically that if the predictor is\ncalibrated per image, we can obtain the correct volume by taking an expectation\nof the probability scores per pixel/voxel of the image. Furthermore, we show\nthat convex combinations of calibrated classifiers preserve volume estimation,\nbut do not preserve calibration. Therefore, we conclude that having a\ncalibrated predictor is a sufficient, but not necessary condition for obtaining\nan unbiased estimate of the volume. We validate our theoretical findings\nempirically on a collection of 18 different (calibrated) training strategies on\nthe tasks of glioma volume estimation on BraTS 2018, and ischemic stroke lesion\nvolume estimation on ISLES 2018 datasets.",
    "descriptor": "\nComments: Published at MICCAI 2021\n",
    "authors": [
      "Teodora Popordanoska",
      "Jeroen Bertels",
      "Dirk Vandermeulen",
      "Frederik Maes",
      "Matthew B. Blaschko"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12560"
  },
  {
    "id": "arXiv:2112.12563",
    "title": "Scalable Variational Quantum Circuits for Autoencoder-based Drug  Discovery",
    "abstract": "The de novo design of drug molecules is recognized as a time-consuming and\ncostly process, and computational approaches have been applied in each stage of\nthe drug discovery pipeline. Variational autoencoder is one of the\ncomputer-aided design methods which explores the chemical space based on\nexisting molecular dataset. Quantum machine learning has emerged as an atypical\nlearning method that may speed up some classical learning tasks because of its\nstrong expressive power. However, near-term quantum computers suffer from\nlimited number of qubits which hinders the representation learning in high\ndimensional spaces. We present a scalable quantum generative autoencoder\n(SQ-VAE) for simultaneously reconstructing and sampling drug molecules, and a\ncorresponding vanilla variant (SQ-AE) for better reconstruction. The\narchitectural strategies in hybrid quantum classical networks such as,\nadjustable quantum layer depth, heterogeneous learning rates, and patched\nquantum circuits are proposed to learn high dimensional dataset such as,\nligand-targeted drugs. Extensive experimental results are reported for\ndifferent dimensions including 8x8 and 32x32 after choosing suitable\narchitectural strategies. The performance of quantum generative autoencoder is\ncompared with the corresponding classical counterpart throughout all\nexperiments. The results show that quantum computing advantages can be achieved\nfor normalized low-dimension molecules, and that high-dimension molecules\ngenerated from quantum generative autoencoders have better drug properties\nwithin the same learning period.",
    "descriptor": "\nComments: Accepted at DATE 2022\n",
    "authors": [
      "Junde Li",
      "Swaroop Ghosh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12563"
  },
  {
    "id": "arXiv:2112.12572",
    "title": "Are E2E ASR models ready for an industrial usage?",
    "abstract": "The Automated Speech Recognition (ASR) community experiences a major turning\npoint with the rise of the fully-neural (End-to-End, E2E) approaches. At the\nsame time, the conventional hybrid model remains the standard choice for the\npractical usage of ASR. According to previous studies, the adoption of E2E ASR\nin real-world applications was hindered by two main limitations: their ability\nto generalize on unseen domains and their high operational cost. In this paper,\nwe investigate both above-mentioned drawbacks by performing a comprehensive\nmulti-domain benchmark of several contemporary E2E models and a hybrid\nbaseline. Our experiments demonstrate that E2E models are viable alternatives\nfor the hybrid approach, and even outperform the baseline both in accuracy and\nin operational efficiency. As a result, our study shows that the generalization\nand complexity issues are no longer the major obstacle for industrial\nintegration, and draws the community's attention to other potential limitations\nof the E2E approaches in some specific use-cases.",
    "descriptor": "",
    "authors": [
      "Valentin Vielzeuf",
      "Grigory Antipov"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.12572"
  },
  {
    "id": "arXiv:2112.12582",
    "title": "Beyond Low Earth Orbit: Biological Research, Artificial Intelligence,  and Self-Driving Labs",
    "abstract": "Space biology research aims to understand fundamental effects of spaceflight\non organisms, develop foundational knowledge to support deep space exploration,\nand ultimately bioengineer spacecraft and habitats to stabilize the ecosystem\nof plants, crops, microbes, animals, and humans for sustained multi-planetary\nlife. To advance these aims, the field leverages experiments, platforms, data,\nand model organisms from both spaceborne and ground-analog studies. As research\nis extended beyond low Earth orbit, experiments and platforms must be maximally\nautonomous, light, agile, and intelligent to expedite knowledge discovery. Here\nwe present a summary of recommendations from a workshop organized by the\nNational Aeronautics and Space Administration on artificial intelligence,\nmachine learning, and modeling applications which offer key solutions toward\nthese space biology challenges. In the next decade, the synthesis of artificial\nintelligence into the field of space biology will deepen the biological\nunderstanding of spaceflight effects, facilitate predictive modeling and\nanalytics, support maximally autonomous and reproducible experiments, and\nefficiently manage spaceborne data and metadata, all with the goal to enable\nlife to thrive in deep space.",
    "descriptor": "\nComments: 28 pages, 4 figures\n",
    "authors": [
      "Lauren M. Sanders",
      "Jason H. Yang",
      "Ryan T. Scott",
      "Amina Ann Qutub",
      "Hector Garcia Martin",
      "Daniel C. Berrios",
      "Jaden J.A. Hastings",
      "Jon Rask",
      "Graham Mackintosh",
      "Adrienne L. Hoarfrost",
      "Stuart Chalk",
      "John Kalantari",
      "Kia Khezeli",
      "Erik L. Antonsen",
      "Joel Babdor",
      "Richard Barker",
      "Sergio E. Baranzini",
      "Afshin Beheshti",
      "Guillermo M. Delgado-Aparicio",
      "Benjamin S. Glicksberg",
      "Casey S. Greene",
      "Melissa Haendel",
      "Arif A. Hamid",
      "Philip Heller",
      "Daniel Jamieson",
      "Katelyn J. Jarvis",
      "Svetlana V. Komarova",
      "Matthieu Komorowski",
      "Prachi Kothiyal",
      "Ashish Mahabal",
      "Uri Manor",
      "Christopher E. Mason",
      "Mona Matar",
      "George I. Mias",
      "Jack Miller",
      "Jerry G. Myers Jr."
    ],
    "subjectives": [
      "Other Quantitative Biology (q-bio.OT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12582"
  },
  {
    "id": "arXiv:2112.12601",
    "title": "Hermite--Pad\u00e9 approximations with Pfaffian structures: Novikov  peakon equation and integrable lattices",
    "abstract": "Motivated by the Novikov equation and its peakon problem, we propose a new\nmixed type Hermite--Pad\\'{e} approximation whose unique solution is a sequence\nof polynomials constructed with the help of Pfaffians. These polynomials belong\nto the family of recently proposed partial-skew-orthogonal polynomials. The\nrelevance of partial-skew-orthogonal polynomials is especially visible in the\napproximation problem germane to the Novikov peakon problem so that we obtain\nexplicit inverse formulae in terms of Pfaffians by reformulating the inverse\nspectral problem for the Novikov multipeakons. Furthermore, we investigate two\nHermite--Pad\\'{e} approximations for the related spectral problem of the\ndiscrete dual cubic string, and show that these approximation problems can also\nbe solved in terms of partial-skew-orthogonal polynomials and nonsymmetric\nCauchy biorthogonal polynomials. This formulation results in a new\ncorrespondence among several integrable lattices.",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Xiang-Ke Chang"
    ],
    "subjectives": [
      "Exactly Solvable and Integrable Systems (nlin.SI)",
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12601"
  },
  {
    "id": "arXiv:2112.12609",
    "title": "Predi\u00e7\u00e3o da Idade Cerebral a partir de Imagens de Resson\u00e2ncia  Magn\u00e9tica utilizando Redes Neurais Convolucionais",
    "abstract": "In this work, deep learning techniques for brain age prediction from magnetic\nresonance images are investigated, aiming to assist in the identification of\nbiomarkers of the natural aging process. The identification of biomarkers is\nuseful for detecting an early-stage neurodegenerative process, as well as for\npredicting age-related or non-age-related cognitive decline. Two techniques are\nimplemented and compared in this work: a 3D Convolutional Neural Network\napplied to the volumetric image and a 2D Convolutional Neural Network applied\nto slices from the axial plane, with subsequent fusion of individual\npredictions. The best result was obtained by the 2D model, which achieved a\nmean absolute error of 3.83 years.\n--\nNeste trabalho s\\~ao investigadas t\\'ecnicas de aprendizado profundo para a\npredi\\c{c}\\~ao da idade cerebral a partir de imagens de resson\\^ancia\nmagn\\'etica, visando auxiliar na identifica\\c{c}\\~ao de biomarcadores do\nprocesso natural de envelhecimento. A identifica\\c{c}\\~ao de biomarcadores \\'e\n\\'util para a detec\\c{c}\\~ao de um processo neurodegenerativo em est\\'agio\ninicial, al\\'em de possibilitar prever um decl\\'inio cognitivo relacionado ou\nn\\~ao \\`a idade. Duas t\\'ecnicas s\\~ao implementadas e comparadas neste\ntrabalho: uma Rede Neural Convolucional 3D aplicada na imagem volum\\'etrica e\numa Rede Neural Convolucional 2D aplicada a fatias do plano axial, com\nposterior fus\\~ao das predi\\c{c}\\~oes individuais. O melhor resultado foi\nobtido pelo modelo 2D, que alcan\\c{c}ou um erro m\\'edio absoluto de 3.83 anos.",
    "descriptor": "\nComments: 3 pages, 3 figures, in Portuguese, accepted at XVIII Congresso Brasileiro de Inform\\'atica em Sa\\'ude (CBIS 2021)\n",
    "authors": [
      "Victor H. R. Oliveira",
      "Augusto Antunes",
      "Alexandre S. Soares",
      "Arthur D. Reys",
      "Robson Z. J\u00fanior",
      "Saulo D. S. Pedro",
      "Danilo Silva"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12609"
  },
  {
    "id": "arXiv:2112.12616",
    "title": "Deep Filtering with DNN, CNN and RNN",
    "abstract": "This paper is about a deep learning approach for linear and nonlinear\nfiltering. The idea is to train a neural network with Monte Carlo samples\ngenerated from a nominal dynamic model. Then the network weights are applied to\nMonte Carlo samples from an actual dynamic model. A main focus of this paper is\non the deep filters with three major neural network architectures (DNN, CNN,\nRNN). Our deep filter compares favorably to the traditional Kalman filter in\nlinear cases and outperform the extended Kalman filter in nonlinear cases. Then\na switching model with jumps is studied to show the adaptiveness and power of\nour deep filtering. Among the three major NNs, the CNN outperform the others on\naverage. while the RNN does not seem to be suitable for the filtering problem.\nOne advantage of the deep filter is its robustness when the nominal model and\nactual model differ. The other advantage of deep filtering is real data can be\nused directly to train the deep neutral network. Therefore, model calibration\ncan be by-passed all together.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2008.03878\n",
    "authors": [
      "Bin Xie",
      "Qing Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.12616"
  },
  {
    "id": "arXiv:2112.12660",
    "title": "InDuDoNet+: A Model-Driven Interpretable Dual Domain Network for Metal  Artifact Reduction in CT Images",
    "abstract": "During the computed tomography (CT) imaging process, metallic implants within\npatients always cause harmful artifacts, which adversely degrade the visual\nquality of reconstructed CT images and negatively affect the subsequent\nclinical diagnosis. For the metal artifact reduction (MAR) task, current deep\nlearning based methods have achieved promising performance. However, most of\nthem share two main common limitations: 1) the CT physical imaging geometry\nconstraint is not comprehensively incorporated into deep network structures; 2)\nthe entire framework has weak interpretability for the specific MAR task;\nhence, the role of every network module is difficult to be evaluated. To\nalleviate these issues, in the paper, we construct a novel interpretable dual\ndomain network, termed InDuDoNet+, into which CT imaging process is finely\nembedded. Concretely, we derive a joint spatial and Radon domain reconstruction\nmodel and propose an optimization algorithm with only simple operators for\nsolving it. By unfolding the iterative steps involved in the proposed algorithm\ninto the corresponding network modules, we easily build the InDuDoNet+ with\nclear interpretability. Furthermore, we analyze the CT values among different\ntissues, and merge the prior observations into a prior network for our\nInDuDoNet+, which significantly improve its generalization performance.\nComprehensive experiments on synthesized data and clinical data substantiate\nthe superiority of the proposed methods as well as the superior generalization\nperformance beyond the current state-of-the-art (SOTA) MAR methods. Code is\navailable at \\url{https://github.com/hongwang01/InDuDoNet_plus}.",
    "descriptor": "",
    "authors": [
      "Hong Wang",
      "Yuexiang Li",
      "Haimiao Zhang",
      "Deyu Meng",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12660"
  },
  {
    "id": "arXiv:2112.12665",
    "title": "Omni-Seg: A Single Dynamic Network for Multi-label Renal Pathology Image  Segmentation using Partially Labeled Data",
    "abstract": "Computer-assisted quantitative analysis on Giga-pixel pathology images has\nprovided a new avenue in precision medicine. The innovations have been largely\nfocused on cancer pathology (i.e., tumor segmentation and characterization). In\nnon-cancer pathology, the learning algorithms can be asked to examine more\ncomprehensive tissue types simultaneously, as a multi-label setting. The prior\narts typically needed to train multiple segmentation networks in order to match\nthe domain-specific knowledge for heterogeneous tissue types (e.g., glomerular\ntuft, glomerular unit, proximal tubular, distal tubular, peritubular\ncapillaries, and arteries). In this paper, we propose a dynamic single\nsegmentation network (Omni-Seg) that learns to segment multiple tissue types\nusing partially labeled images (i.e., only one tissue type is labeled for each\ntraining image) for renal pathology. By learning from ~150,000 patch-wise\npathological images from six tissue types, the proposed Omni-Seg network\nachieved superior segmentation accuracy and less resource consumption when\ncompared to the previous the multiple-network and multi-head design. In the\ntesting stage, the proposed method obtains \"completely labeled\" tissue\nsegmentation results using only \"partially labeled\" training images. The source\ncode is available at https://github.com/ddrrnn123/Omni-Seg.",
    "descriptor": "",
    "authors": [
      "Ruining Deng",
      "Quan Liu",
      "Can Cui",
      "Zuhayr Asad",
      "Haichun Yang",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12665"
  },
  {
    "id": "arXiv:2112.12681",
    "title": "A Point-free Perspective on Lax extensions and Predicate liftings",
    "abstract": "In this paper we have a fresh look at the connection between lax extensions\nand predicate liftings of a functor from the point of view of quantale-enriched\nrelations. Using this perspective, in particular we show that various\nfundamental concepts and results arise naturally and their proofs become very\nelementary. Ultimately, we prove that every lax extension is represented by a\nclass of predicate liftings and discuss several implications of this result.",
    "descriptor": "",
    "authors": [
      "Sergey Goncharov",
      "Dirk Hofmann",
      "Pedro Nora",
      "Lutz Schr\u00f6der",
      "Paul Wild"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.12681"
  },
  {
    "id": "arXiv:2112.12697",
    "title": "The role of noise in PIC and Vlasov simulations of the Buneman  instability",
    "abstract": "The effects of noise in particle-in-cell (PIC) and Vlasov simulations of the\nBuneman instability in unmagnetized plasmas are studied. It is found that, in\nthe regime of low drift velocity, the linear stage of the instability in PIC\nsimulations differs significantly from the theoretical predictions, whereas in\nthe Vlasov simulations it does not. A series of highly resolved PIC simulations\nwith increasingly large numbers of macroparticles per cell is performed using a\nnumber of different PIC codes.\nAll the simulations predict highly similar growth rates that are several\ntimes larger than those calculated from the linear theory. As a result, we find\nthat the true convergence of the PIC simulations in the linear regime is\nelusive to achieve in practice and can easily be misidentified.\nThe discrepancy between the theoretical and observed growth rates is\nattributed to the initial noise inherently present in PIC simulations, but not\nin Vlasov simulations, that causes particle trapping even though the fraction\nof trapped particles is low. We show analytically that even weak distortions of\nthe electron velocity distribution function (such as flattening due to particle\ntrapping) result in significant modifications of the growth rates. It is also\nfound that the common quiet-start method for PIC simulations leads to more\naccurate growth rates but only if the maximum growth rate mode is perturbed\ninitially. We demonstrate that the quiet-start method does not completely\nremedy the noise problem because the simulations generally exhibit\ninconsistencies with the linear theory.",
    "descriptor": "",
    "authors": [
      "Arash Tavassoli",
      "Oleksandr Chapurin",
      "Marilyn Jimenez",
      "Mina Papahn Zadeh",
      "Trevor Zinte",
      "Meghraj Sengupta",
      "L\u00e9na\u00efc Cou\u00ebdel",
      "Raymond J. Spiteri",
      "Magdi Shoucri",
      "Andrei Smolyakov"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.12697"
  },
  {
    "id": "arXiv:2112.12743",
    "title": "Multi-speaker Multi-style Text-to-speech Synthesis With Single-speaker  Single-style Training Data Scenarios",
    "abstract": "In the existing cross-speaker style transfer task, a source speaker with\nmulti-style recordings is necessary to provide the style for a target speaker.\nHowever, it is hard for one speaker to express all expected styles. In this\npaper, a more general task, which is to produce expressive speech by combining\nany styles and timbres from a multi-speaker corpus in which each speaker has a\nunique style, is proposed. To realize this task, a novel method is proposed.\nThis method is a Tacotron2-based framework but with a fine-grained text-based\nprosody predicting module and a speaker identity controller. Experiments\ndemonstrate that the proposed method can successfully express a style of one\nspeaker with the timber of another speaker bypassing the dependency on a single\nspeaker's multi-style corpus. Moreover, the explicit prosody features used in\nthe prosody predicting module can increase the diversity of synthetic speech by\nadjusting the value of prosody features.",
    "descriptor": "\nComments: submitted to icassp2022\n",
    "authors": [
      "Qicong Xie",
      "Tao Li",
      "Xinsheng Wang",
      "Zhichao Wang",
      "Lei Xie",
      "Guoqiao Yu",
      "Guanglu Wan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.12743"
  },
  {
    "id": "arXiv:2112.12744",
    "title": "AI-based Reconstruction for Fast MRI -- A Systematic Review and  Meta-analysis",
    "abstract": "Compressed sensing (CS) has been playing a key role in accelerating the\nmagnetic resonance imaging (MRI) acquisition process. With the resurgence of\nartificial intelligence, deep neural networks and CS algorithms are being\nintegrated to redefine the state of the art of fast MRI. The past several years\nhave witnessed substantial growth in the complexity, diversity, and performance\nof deep learning-based CS techniques that are dedicated to fast MRI. In this\nmeta-analysis, we systematically review the deep learning-based CS techniques\nfor fast MRI, describe key model designs, highlight breakthroughs, and discuss\npromising directions. We have also introduced a comprehensive analysis\nframework and a classification system to assess the pivotal role of deep\nlearning in CS-based acceleration for MRI.",
    "descriptor": "\nComments: 42 pages, 5 figures, Proceedings of the IEEE\n",
    "authors": [
      "Yutong Chen",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Pietro Li\u00f2",
      "Tim Leiner",
      "Pier Luigi Dragotti",
      "Ge Wang",
      "Daniel Rueckert",
      "David Firmin",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.12744"
  },
  {
    "id": "arXiv:2112.12746",
    "title": "Quadratic speedup for spatial search by continuous-time quantum walk",
    "abstract": "Continuous-time quantum walks provide a natural framework to tackle the\nfundamental problem of finding a node among a set of marked nodes in a graph,\nknown as spatial search. Whether spatial search by continuous-time quantum walk\nprovides a quadratic advantage over classical random walks has been an\noutstanding problem. Thus far, this advantage is obtained only for specific\ngraphs or when a single node of the underlying graph is marked. In this\narticle, we provide a new continuous-time quantum walk search algorithm that\ncompletely resolves this: our algorithm can find a marked node in any graph\nwith any number of marked nodes, in a time that is quadratically faster than\nclassical random walks. The overall algorithm is quite simple, requiring time\nevolution of the quantum walk Hamiltonian followed by a projective measurement.\nA key component of our algorithm is a purely analog procedure to perform\noperations on a state of the form $e^{-tH^2}|\\psi\\rangle$, for a given\nHamiltonian $H$: it only requires evolving $H$ for time scaling as $\\sqrt{t}$.\nThis allows us to quadratically fast-forward the dynamics of a continuous-time\nclassical random walk. The applications of our work thus go beyond the realm of\nquantum walks and can lead to new analog quantum algorithms for preparing\nground states of Hamiltonians or solving optimization problems.",
    "descriptor": "",
    "authors": [
      "Simon Apers",
      "Shantanav Chakraborty",
      "Leonardo Novo",
      "J\u00e9r\u00e9mie Roland"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.12746"
  },
  {
    "id": "arXiv:2112.12770",
    "title": "Optimal and instance-dependent guarantees for Markovian linear  stochastic approximation",
    "abstract": "We study stochastic approximation procedures for approximately solving a\n$d$-dimensional linear fixed point equation based on observing a trajectory of\nlength $n$ from an ergodic Markov chain. We first exhibit a non-asymptotic\nbound of the order $t_{\\mathrm{mix}} \\tfrac{d}{n}$ on the squared error of the\nlast iterate of a standard scheme, where $t_{\\mathrm{mix}}$ is a mixing time.\nWe then prove a non-asymptotic instance-dependent bound on a suitably averaged\nsequence of iterates, with a leading term that matches the local asymptotic\nminimax limit, including sharp dependence on the parameters $(d,\nt_{\\mathrm{mix}})$ in the higher order terms. We complement these upper bounds\nwith a non-asymptotic minimax lower bound that establishes the\ninstance-optimality of the averaged SA estimator. We derive corollaries of\nthese results for policy evaluation with Markov noise -- covering the\nTD($\\lambda$) family of algorithms for all $\\lambda \\in [0, 1)$ -- and linear\nautoregressive models. Our instance-dependent characterizations open the door\nto the design of fine-grained model selection procedures for hyperparameter\ntuning (e.g., choosing the value of $\\lambda$ when running the TD($\\lambda$)\nalgorithm).",
    "descriptor": "",
    "authors": [
      "Wenlong Mou",
      "Ashwin Pananjady",
      "Martin J. Wainwright",
      "Peter L. Bartlett"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.12770"
  },
  {
    "id": "arXiv:1802.07382",
    "title": "Generic Coreset for Scalable Learning of Monotonic Kernels: Logistic  Regression, Sigmoid and more",
    "abstract": "Generic Coreset for Scalable Learning of Monotonic Kernels: Logistic  Regression, Sigmoid and more",
    "descriptor": "",
    "authors": [
      "Elad Tolochinsky",
      "Ibrahim Jubran",
      "Dan Feldman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1802.07382"
  },
  {
    "id": "arXiv:1810.07567",
    "title": "Measures of path-based nonlinear expansion rates and Lagrangian  uncertainty in stochastic flows",
    "abstract": "Measures of path-based nonlinear expansion rates and Lagrangian  uncertainty in stochastic flows",
    "descriptor": "",
    "authors": [
      "Michal Branicki",
      "Kenneth Uda"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1810.07567"
  },
  {
    "id": "arXiv:1901.06786",
    "title": "On the Capacity Region of Bipartite and Tripartite Entanglement  Switching",
    "abstract": "On the Capacity Region of Bipartite and Tripartite Entanglement  Switching",
    "descriptor": "",
    "authors": [
      "Gayane Vardoyan",
      "Philippe Nain",
      "Saikat Guha",
      "Don Towsley"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/1901.06786"
  },
  {
    "id": "arXiv:1904.06480",
    "title": "Dynamic scheduling in a partially fluid, partially lossy queueing system",
    "abstract": "Dynamic scheduling in a partially fluid, partially lossy queueing system",
    "descriptor": "",
    "authors": [
      "Kiran Chaudhary",
      "Veeraruna Kavitha",
      "Jayakrishnan Nair"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1904.06480"
  },
  {
    "id": "arXiv:1905.11027",
    "title": "A Geometric Modeling of Occam's Razor in Deep Learning",
    "abstract": "Comments: This work first appeared under the former title \"Lightlike Neuromanifolds, Occam's Razor and Deep Learning\"",
    "descriptor": "\nComments: This work first appeared under the former title \"Lightlike Neuromanifolds, Occam's Razor and Deep Learning\"\n",
    "authors": [
      "Ke Sun",
      "Frank Nielsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.11027"
  },
  {
    "id": "arXiv:1911.01858",
    "title": "A GenEO Domain Decomposition method for Saddle Point problems",
    "abstract": "A GenEO Domain Decomposition method for Saddle Point problems",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Nataf",
      "Pierre-Henri Tournier"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1911.01858"
  },
  {
    "id": "arXiv:1912.01566",
    "title": "On the central levels problem",
    "abstract": "On the central levels problem",
    "descriptor": "",
    "authors": [
      "Petr Gregor",
      "Ond\u0159ej Mi\u010dka",
      "Torsten M\u00fctze"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1912.01566"
  },
  {
    "id": "arXiv:1912.01639",
    "title": "Optimal Algorithms for Geometric Centers and Depth",
    "abstract": "Comments: This paper is a merge of two conference papers that were published sixteen years apart. The first paper appeared in SODA 2004, and the second paper (which can be viewed as an applications paper of the first paper) appeared in SoCG 2020",
    "descriptor": "\nComments: This paper is a merge of two conference papers that were published sixteen years apart. The first paper appeared in SODA 2004, and the second paper (which can be viewed as an applications paper of the first paper) appeared in SoCG 2020\n",
    "authors": [
      "Timothy M. Chan",
      "Sariel Har-Peled",
      "Mitchell Jones"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1912.01639"
  },
  {
    "id": "arXiv:2004.11847",
    "title": "Age of Information for Single Buffer Systems with Vacation Server",
    "abstract": "Age of Information for Single Buffer Systems with Vacation Server",
    "descriptor": "",
    "authors": [
      "Jin Xu",
      "I-Hong Hou",
      "Natarajan Gautam"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2004.11847"
  },
  {
    "id": "arXiv:2004.11860",
    "title": "Near optimal sparsity-constrained group testing: improved bounds and  algorithms",
    "abstract": "Comments: Accepted for publication at IEEE Transactions on Information Theory",
    "descriptor": "\nComments: Accepted for publication at IEEE Transactions on Information Theory\n",
    "authors": [
      "Oliver Gebhard",
      "Max Hahn-Klimroth",
      "Olaf Parczyk",
      "Manuel Penschuck",
      "Maurice Rolvien",
      "Jonathan Scarlett",
      "Nelvin Tan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2004.11860"
  },
  {
    "id": "arXiv:2006.04043",
    "title": "SVGA-Net: Sparse Voxel-Graph Attention Network for 3D Object Detection  from Point Clouds",
    "abstract": "Comments: 9 pages, 4 figures",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Qingdong He",
      "Zhengning Wang",
      "Hao Zeng",
      "Yi Zeng",
      "Yijun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2006.04043"
  },
  {
    "id": "arXiv:2006.14514",
    "title": "Taming neural networks with TUSLA: Non-convex learning via adaptive  stochastic gradient Langevin algorithms",
    "abstract": "Taming neural networks with TUSLA: Non-convex learning via adaptive  stochastic gradient Langevin algorithms",
    "descriptor": "",
    "authors": [
      "Attila Lovas",
      "Iosif Lytras",
      "Mikl\u00f3s R\u00e1sonyi",
      "Sotirios Sabanis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.14514"
  },
  {
    "id": "arXiv:2007.09541",
    "title": "Same-Day Delivery with Fairness",
    "abstract": "Same-Day Delivery with Fairness",
    "descriptor": "",
    "authors": [
      "Xinwei Chen",
      "Tong Wang",
      "Barrett W. Thomas",
      "Marlin W. Ulmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.09541"
  },
  {
    "id": "arXiv:2009.02400",
    "title": "The Area Under the ROC Curve as a Measure of Clustering Quality",
    "abstract": "Comments: 37 pages, 5 figures, submitted for publication",
    "descriptor": "\nComments: 37 pages, 5 figures, submitted for publication\n",
    "authors": [
      "Pablo Andretta Jaskowiak",
      "Ivan Gesteira Costa",
      "Ricardo Jos\u00e9 Gabrielli Barreto Campello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.02400"
  },
  {
    "id": "arXiv:2009.04683",
    "title": "Optimal Eco-driving Control of Autonomous and Electric Trucks in  Adaptation to Highway Topography: Energy Minimization and Battery Life  Extension",
    "abstract": "Optimal Eco-driving Control of Autonomous and Electric Trucks in  Adaptation to Highway Topography: Energy Minimization and Battery Life  Extension",
    "descriptor": "",
    "authors": [
      "Yongzhi Zhang",
      "Xiaobo Qu",
      "Lang Tong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.04683"
  },
  {
    "id": "arXiv:2011.03376",
    "title": "Epidemic Plateau: A Phenomenon under Adaptive Prevention Strategies",
    "abstract": "Epidemic Plateau: A Phenomenon under Adaptive Prevention Strategies",
    "descriptor": "",
    "authors": [
      "Ziqiang Wu",
      "Hao Liao",
      "Alexandre Vidmer",
      "Mingyang Zhou",
      "Wei Chen"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2011.03376"
  },
  {
    "id": "arXiv:2011.07252",
    "title": "Ego2Hands: A Dataset for Egocentric Two-hand Segmentation and Detection",
    "abstract": "Ego2Hands: A Dataset for Egocentric Two-hand Segmentation and Detection",
    "descriptor": "",
    "authors": [
      "Fanqing Lin",
      "Brian Price",
      "Tony Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.07252"
  },
  {
    "id": "arXiv:2012.00467",
    "title": "A Survey on ML4VIS: Applying Machine Learning Advances to Data  Visualization",
    "abstract": "Comments: 19 pages, 12 figures, 4 tables",
    "descriptor": "\nComments: 19 pages, 12 figures, 4 tables\n",
    "authors": [
      "Qianwen Wang",
      "Zhutian Chen",
      "Yong Wang",
      "Huamin Qu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2012.00467"
  },
  {
    "id": "arXiv:2012.10231",
    "title": "Controlling conditional expectations by zero-determinant strategies",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Masahiko Ueda"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.10231"
  },
  {
    "id": "arXiv:2012.13635",
    "title": "Logic Tensor Networks",
    "abstract": "Comments: 68 pages, 28 figures, 6 tables",
    "descriptor": "\nComments: 68 pages, 28 figures, 6 tables\n",
    "authors": [
      "Samy Badreddine",
      "Artur d'Avila Garcez",
      "Luciano Serafini",
      "Michael Spranger"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.13635"
  },
  {
    "id": "arXiv:2101.00058",
    "title": "Conflict-driven Inductive Logic Programming",
    "abstract": "Comments: Under consideration in Theory and Practice of Logic Programming (TPLP)",
    "descriptor": "\nComments: Under consideration in Theory and Practice of Logic Programming (TPLP)\n",
    "authors": [
      "Mark Law"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.00058"
  },
  {
    "id": "arXiv:2101.04357",
    "title": "On the Differential Private Data Market: Endogenous Evolution, Dynamic  Pricing, and Incentive Compatibility",
    "abstract": "On the Differential Private Data Market: Endogenous Evolution, Dynamic  Pricing, and Incentive Compatibility",
    "descriptor": "",
    "authors": [
      "Tao Zhang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.04357"
  },
  {
    "id": "arXiv:2102.06757",
    "title": "Multimodal Data Visualization and Denoising with Integrated Diffusion",
    "abstract": "Multimodal Data Visualization and Denoising with Integrated Diffusion",
    "descriptor": "",
    "authors": [
      "Manik Kuchroo",
      "Abhinav Godavarthi",
      "Guy Wolf",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2102.06757"
  },
  {
    "id": "arXiv:2102.08360",
    "title": "Interpretable COVID-19 Chest X-Ray Classification via Orthogonality  Constraint",
    "abstract": "Comments: Accepted in the 2021 ACM CHIL Workshop track. An extended version of this work is under consideration at Pattern Recognition Letters",
    "descriptor": "\nComments: Accepted in the 2021 ACM CHIL Workshop track. An extended version of this work is under consideration at Pattern Recognition Letters\n",
    "authors": [
      "Ella Y. Wang",
      "Anirudh Som",
      "Ankita Shukla",
      "Hongjun Choi",
      "Pavan Turaga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.08360"
  },
  {
    "id": "arXiv:2102.09920",
    "title": "Overcoming Restraint: Composing Verification of Foreign Functions with  Cogent",
    "abstract": "Overcoming Restraint: Composing Verification of Foreign Functions with  Cogent",
    "descriptor": "",
    "authors": [
      "Louis Cheung",
      "Liam O'Connor",
      "Christine Rizkallah"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2102.09920"
  },
  {
    "id": "arXiv:2102.13203",
    "title": "Recovery of regular ridge functions on the ball",
    "abstract": "Recovery of regular ridge functions on the ball",
    "descriptor": "",
    "authors": [
      "Tatyana Zaitseva",
      "Yuri Malykhin",
      "Konstantin Ryutin"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.13203"
  },
  {
    "id": "arXiv:2103.07344",
    "title": "Search of fractal space-filling curves with minimal dilation",
    "abstract": "Search of fractal space-filling curves with minimal dilation",
    "descriptor": "",
    "authors": [
      "Yuri Malykhin",
      "Evgeny Shchepin"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2103.07344"
  },
  {
    "id": "arXiv:2103.07863",
    "title": "Imperative process algebra with abstraction",
    "abstract": "Comments: 33 pages, revision of v3 with explanatory remarks and examples added",
    "descriptor": "\nComments: 33 pages, revision of v3 with explanatory remarks and examples added\n",
    "authors": [
      "C.A. Middelburg"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2103.07863"
  },
  {
    "id": "arXiv:2103.10810",
    "title": "Zero-Delay Lossy Coding of Linear Vector Markov Sources: Optimality of  Stationary Codes and Near Optimality of Finite Memory Codes",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Meysam Ghomi",
      "Tamas Linder",
      "Serdar Yuksel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.10810"
  },
  {
    "id": "arXiv:2103.13173",
    "title": "PureGaze: Purifying Gaze Feature for Generalizable Gaze Estimation",
    "abstract": "Comments: Paper is accepted by AAAI 2022",
    "descriptor": "\nComments: Paper is accepted by AAAI 2022\n",
    "authors": [
      "Yihua Cheng",
      "Yiwei Bao",
      "Feng Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.13173"
  },
  {
    "id": "arXiv:2104.07001",
    "title": "Burling graphs revisited, part I: New characterizations",
    "abstract": "Comments: 35 pages, 20 figures",
    "descriptor": "\nComments: 35 pages, 20 figures\n",
    "authors": [
      "Pegah Pournajafi",
      "Nicolas Trotignon"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2104.07001"
  },
  {
    "id": "arXiv:2104.07213",
    "title": "Attentive max feature map and joint training for acoustic scene  classification",
    "abstract": "Comments: 5 pages, 2 figures, 5 tables, submitted to ICASSP 2022",
    "descriptor": "\nComments: 5 pages, 2 figures, 5 tables, submitted to ICASSP 2022\n",
    "authors": [
      "Hye-jin Shim",
      "Jee-weon Jung",
      "Ju-ho Kim",
      "Ha-Jin Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.07213"
  },
  {
    "id": "arXiv:2104.13175",
    "title": "C-Ports: a proposal for a comprehensive standardization and  implementation plan of digital services offered by the \"Port of the Future\"",
    "abstract": "Comments: 28 pages, 3 equations, 12 figures, 3 tables",
    "descriptor": "\nComments: 28 pages, 3 equations, 12 figures, 3 tables\n",
    "authors": [
      "P. Pagano",
      "S. Antonelli",
      "A. Tardo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2104.13175"
  },
  {
    "id": "arXiv:2105.04660",
    "title": "Deletion to Scattered Graph Classes I -- case of finite number of graph  classes",
    "abstract": "Comments: An extended abstract of the paper appeared in IPEC 2020. This version has a new co-author Jari J. H. de Kroon and an extension of our main result for the case when forbidden subgraphs of each class can be infinite, under certain other conditions",
    "descriptor": "\nComments: An extended abstract of the paper appeared in IPEC 2020. This version has a new co-author Jari J. H. de Kroon and an extension of our main result for the case when forbidden subgraphs of each class can be infinite, under certain other conditions\n",
    "authors": [
      "Ashwin Jacob",
      "Jari J. H. de Kroon",
      "Diptapriyo Majumdar",
      "Venkatesh Raman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.04660"
  },
  {
    "id": "arXiv:2105.09016",
    "title": "E(n) Equivariant Normalizing Flows",
    "abstract": "Comments: Accepted at Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: Accepted at Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Victor Garcia Satorras",
      "Emiel Hoogeboom",
      "Fabian B. Fuchs",
      "Ingmar Posner",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.09016"
  },
  {
    "id": "arXiv:2105.14217",
    "title": "Less is More: Pay Less Attention in Vision Transformers",
    "abstract": "Comments: Accepted to AAAI 2022",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Zizheng Pan",
      "Bohan Zhuang",
      "Haoyu He",
      "Jing Liu",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14217"
  },
  {
    "id": "arXiv:2106.00400",
    "title": "Sub-Character Tokenization for Chinese Pretrained Language Models",
    "abstract": "Comments: This draft supersedes the previous version named \"SHUOWEN-JIEZI: Linguistically Informed Tokenizers For Chinese Language Model Pretraining\"",
    "descriptor": "\nComments: This draft supersedes the previous version named \"SHUOWEN-JIEZI: Linguistically Informed Tokenizers For Chinese Language Model Pretraining\"\n",
    "authors": [
      "Chenglei Si",
      "Zhengyan Zhang",
      "Yingfa Chen",
      "Fanchao Qi",
      "Xiaozhi Wang",
      "Zhiyuan Liu",
      "Yasheng Wang",
      "Qun Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00400"
  },
  {
    "id": "arXiv:2106.00776",
    "title": "On Optimizing the Conditional Value-at-Risk of a Maximum Cost for  Risk-Averse Safety Analysis",
    "abstract": "Comments: A shorter version is under review for IEEE Transactions on Automatic Control, submitted December 2021",
    "descriptor": "\nComments: A shorter version is under review for IEEE Transactions on Automatic Control, submitted December 2021\n",
    "authors": [
      "Margaret P. Chapman",
      "Michael Fauss",
      "Kevin M. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00776"
  },
  {
    "id": "arXiv:2106.01870",
    "title": "Maximizing Extractable Value from Automated Market Makers",
    "abstract": "Comments: To appear in FC'22",
    "descriptor": "\nComments: To appear in FC'22\n",
    "authors": [
      "Massimo Bartoletti",
      "James Hsin-yu Chiang",
      "Alberto Lluch-Lafuente"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01870"
  },
  {
    "id": "arXiv:2106.03287",
    "title": "Stein ICP for Uncertainty Estimation in Point Cloud Matching",
    "abstract": "Comments: 8 pages, 7 figures, Robotics and Automation Letters",
    "descriptor": "\nComments: 8 pages, 7 figures, Robotics and Automation Letters\n",
    "authors": [
      "Fahira Afzal Maken",
      "Fabio Ramos",
      "Lionel Ott"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03287"
  },
  {
    "id": "arXiv:2106.03898",
    "title": "SPANet: Generalized Permutationless Set Assignment for Particle Physics  using Symmetry Preserving Attention",
    "abstract": "Comments: minor editorial edits; submitted to SciPost",
    "descriptor": "\nComments: minor editorial edits; submitted to SciPost\n",
    "authors": [
      "Alexander Shmakov",
      "Michael James Fenton",
      "Ta-Wei Ho",
      "Shih-Chieh Hsu",
      "Daniel Whiteson",
      "Pierre Baldi"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.03898"
  },
  {
    "id": "arXiv:2106.06044",
    "title": "Convergence and Alignment of Gradient Descent with Random  Backpropagation Weights",
    "abstract": "Comments: 35 pages",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Ganlin Song",
      "Ruitu Xu",
      "John Lafferty"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06044"
  },
  {
    "id": "arXiv:2106.09565",
    "title": "Interval Privacy: A Framework for Privacy-Preserving Data Collection",
    "abstract": "Interval Privacy: A Framework for Privacy-Preserving Data Collection",
    "descriptor": "",
    "authors": [
      "Jie Ding",
      "Bangjun Ding"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09565"
  },
  {
    "id": "arXiv:2106.10180",
    "title": "Determining when a truncated generalised Reed-Solomon code is Hermitian  self-orthogonal",
    "abstract": "Determining when a truncated generalised Reed-Solomon code is Hermitian  self-orthogonal",
    "descriptor": "",
    "authors": [
      "Simeon Ball",
      "Ricard Vilar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10180"
  },
  {
    "id": "arXiv:2106.13142",
    "title": "Solving large linear least squares problems with linear equality  constraints",
    "abstract": "Solving large linear least squares problems with linear equality  constraints",
    "descriptor": "",
    "authors": [
      "Jennifer Scott",
      "Miroslav Tuma"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13142"
  },
  {
    "id": "arXiv:2107.00606",
    "title": "Action Transformer: A Self-Attention Model for Short-Time Human Action  Recognition",
    "abstract": "Comments: Published by Pattern Recognition, Elsevier",
    "descriptor": "\nComments: Published by Pattern Recognition, Elsevier\n",
    "authors": [
      "Vittorio Mazzia",
      "Simone Angarano",
      "Francesco Salvetti",
      "Federico Angelini",
      "Marcello Chiaberge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00606"
  },
  {
    "id": "arXiv:2107.00676",
    "title": "A Primer on Pretrained Multilingual Language Models",
    "abstract": "A Primer on Pretrained Multilingual Language Models",
    "descriptor": "",
    "authors": [
      "Sumanth Doddapaneni",
      "Gowtham Ramesh",
      "Mitesh M. Khapra",
      "Anoop Kunchukuttan",
      "Pratyush Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00676"
  },
  {
    "id": "arXiv:2107.01125",
    "title": "On Measuring and Controlling the Spectral Bias of the Deep Image Prior",
    "abstract": "Comments: IJCV 2022; Spectral bias; Deep image prior; 24 pages",
    "descriptor": "\nComments: IJCV 2022; Spectral bias; Deep image prior; 24 pages\n",
    "authors": [
      "Zenglin Shi",
      "Pascal Mettes",
      "Subhransu Maji",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01125"
  },
  {
    "id": "arXiv:2107.03423",
    "title": "Recurrence-Aware Long-Term Cognitive Network for Explainable Pattern  Classification",
    "abstract": "Recurrence-Aware Long-Term Cognitive Network for Explainable Pattern  Classification",
    "descriptor": "",
    "authors": [
      "Gonzalo N\u00e1poles",
      "Yamisleydi Salgueiro",
      "Isel Grau",
      "Maikel Leon Espinosa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.03423"
  },
  {
    "id": "arXiv:2107.08408",
    "title": "Pre-trained Language Models as Prior Knowledge for Playing Text-based  Games",
    "abstract": "Comments: 40 Pages (8 Pages main content + 1 Page references + 31 Pages Appendix). Some new results added",
    "descriptor": "\nComments: 40 Pages (8 Pages main content + 1 Page references + 31 Pages Appendix). Some new results added\n",
    "authors": [
      "Ishika Singh",
      "Gargi Singh",
      "Ashutosh Modi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.08408"
  },
  {
    "id": "arXiv:2107.09137",
    "title": "Eigenvector Centrality and Uniform Dominant Eigenvalue of Graph  Components",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Collins Anguzu",
      "Christopher Engstr\u00f6m",
      "John Magero Mango",
      "Henry Kasumba",
      "Sergei Silvestrov",
      "Benard Abola"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.09137"
  },
  {
    "id": "arXiv:2107.11513",
    "title": "Distributed stochastic inertial-accelerated methods with delayed  derivatives for nonconvex problems",
    "abstract": "Comments: Accepted in SIAM Journal on Imaging Sciences",
    "descriptor": "\nComments: Accepted in SIAM Journal on Imaging Sciences\n",
    "authors": [
      "Yangyang Xu",
      "Yibo Xu",
      "Yonggui Yan",
      "Jie Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.11513"
  },
  {
    "id": "arXiv:2107.12246",
    "title": "On the Quantum Performance Evaluation of Two Distributed Quantum  Architectures",
    "abstract": "On the Quantum Performance Evaluation of Two Distributed Quantum  Architectures",
    "descriptor": "",
    "authors": [
      "Gayane Vardoyan",
      "Matthew Skrzypczyk",
      "Stephanie Wehner"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.12246"
  },
  {
    "id": "arXiv:2108.00559",
    "title": "A Machine-Learning-Based Direction-of-Origin Filter for the  Identification of Radio Frequency Interference in the Search for  Technosignatures",
    "abstract": "Comments: 25 pages, 14 figures, in press at the Astronomical Journal (submitted July 28, 2021; review received October 21, 2021; resubmitted October 25, 2021; accepted December 7, 2021)",
    "descriptor": "\nComments: 25 pages, 14 figures, in press at the Astronomical Journal (submitted July 28, 2021; review received October 21, 2021; resubmitted October 25, 2021; accepted December 7, 2021)\n",
    "authors": [
      "Pavlo Pinchuk",
      "Jean-Luc Margot"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.00559"
  },
  {
    "id": "arXiv:2108.02230",
    "title": "Nonholonomic dynamics and control of road vehicles: moving toward  automation",
    "abstract": "Comments: 40 pages, 23 figures, 5 tables, submitted to Nonlinear Dynamics, Springer",
    "descriptor": "\nComments: 40 pages, 23 figures, 5 tables, submitted to Nonlinear Dynamics, Springer\n",
    "authors": [
      "Wubing B. Qin",
      "Yiming Zhang",
      "D\u00e9nes Tak\u00e1cs",
      "G\u00e1bor St\u00e9p\u00e1n",
      "G\u00e1bor Orosz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.02230"
  },
  {
    "id": "arXiv:2108.04976",
    "title": "Deep Pairwise Learning To Rank For Search Autocomplete",
    "abstract": "Deep Pairwise Learning To Rank For Search Autocomplete",
    "descriptor": "",
    "authors": [
      "Kai Yuan",
      "Da Kuang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04976"
  },
  {
    "id": "arXiv:2108.07470",
    "title": "Two linear, unconditionally stable, second order decoupling methods for  the Allen--Cahn--Navier--Stokes phase field model",
    "abstract": "Comments: 21 pages, 7 figures, 2 tables",
    "descriptor": "\nComments: 21 pages, 7 figures, 2 tables\n",
    "authors": [
      "Ruonan Cao",
      "Nan Jiang",
      "Huanhuan Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2108.07470"
  },
  {
    "id": "arXiv:2108.07481",
    "title": "RRLFSOR: An Efficient Self-Supervised Learning Strategy of Graph  Convolutional Networks",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Feng Sun",
      "Ajith Kumar V",
      "Guanci Yang",
      "Qikui Zhu",
      "Yiyun Zhang",
      "Ansi Zhang",
      "Dhruv Makwana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.07481"
  },
  {
    "id": "arXiv:2108.12604",
    "title": "New Pruning Method Based on DenseNet Network for Image Classification",
    "abstract": "Comments: 5 pages, 3 figures, Technologies and Applications of Artificial Intelligence 2021",
    "descriptor": "\nComments: 5 pages, 3 figures, Technologies and Applications of Artificial Intelligence 2021\n",
    "authors": [
      "Rui-Yang Ju",
      "Ting-Yu Lin",
      "Jen-Shiun Chiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.12604"
  },
  {
    "id": "arXiv:2109.02245",
    "title": "An Approach to Detecting Bugs in Pattern-Based Bug Detectors",
    "abstract": "An Approach to Detecting Bugs in Pattern-Based Bug Detectors",
    "descriptor": "",
    "authors": [
      "Junjie Wang",
      "Yuchao Huang",
      "Song Wang",
      "Qing Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.02245"
  },
  {
    "id": "arXiv:2109.03962",
    "title": "Learning-based Moving Horizon Estimation through Differentiable Convex  Optimization Layers",
    "abstract": "Learning-based Moving Horizon Estimation through Differentiable Convex  Optimization Layers",
    "descriptor": "",
    "authors": [
      "Simon Muntwiler",
      "Kim P. Wabersich",
      "Melanie N. Zeilinger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.03962"
  },
  {
    "id": "arXiv:2109.04564",
    "title": "Characterization of Constrained Continuous Multiobjective Optimization  Problems: A Feature Space Perspective",
    "abstract": "Characterization of Constrained Continuous Multiobjective Optimization  Problems: A Feature Space Perspective",
    "descriptor": "",
    "authors": [
      "Aljo\u0161a Vodopija",
      "Tea Tu\u0161ar",
      "Bogdan Filipi\u010d"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.04564"
  },
  {
    "id": "arXiv:2109.05413",
    "title": "Learning Selective Communication for Multi-Agent Path Finding",
    "abstract": "Comments: IEEE Robotics and Automation Letters (RA-L)",
    "descriptor": "\nComments: IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Ziyuan Ma",
      "Yudong Luo",
      "Jia Pan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.05413"
  },
  {
    "id": "arXiv:2109.12409",
    "title": "Motivating Learners in Multi-Orchestrator Mobile Edge Learning: A  Stackelberg Game Approach",
    "abstract": "Comments: Modifying some equations",
    "descriptor": "\nComments: Modifying some equations\n",
    "authors": [
      "Mhd Saria Allahham",
      "Sameh Sorour",
      "Amr Mohamed",
      "Aiman Erbad",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.12409"
  },
  {
    "id": "arXiv:2109.13419",
    "title": "The Role of Lookahead and Approximate Policy Evaluation in Policy  Iteration with Linear Value Function Approximation",
    "abstract": "Comments: 18 pages, 4 figures",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Anna Winnicki",
      "Joseph Lubars",
      "Michael Livesay",
      "R. Srikant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.13419"
  },
  {
    "id": "arXiv:2110.01101",
    "title": "Parallel Actors and Learners: A Framework for Generating Scalable RL  Implementations",
    "abstract": "Comments: 10 pages. HiPC21",
    "descriptor": "\nComments: 10 pages. HiPC21\n",
    "authors": [
      "Chi Zhang",
      "Sanmukh Rao Kuppannagari",
      "Viktor K Prasanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.01101"
  },
  {
    "id": "arXiv:2110.01191",
    "title": "3D-Transformer: Molecular Representation with Transformer in 3D Space",
    "abstract": "3D-Transformer: Molecular Representation with Transformer in 3D Space",
    "descriptor": "",
    "authors": [
      "Fang Wu",
      "Qiang Zhang",
      "Dragomir Radev",
      "Jiyu Cui",
      "Wen Zhang",
      "Huabin Xing",
      "Ningyu Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01191"
  },
  {
    "id": "arXiv:2110.03006",
    "title": "Unsupervised Data Selection for Data-Centric Semi-Supervised Learning",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Xudong Wang",
      "Long Lian",
      "Stella X. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03006"
  },
  {
    "id": "arXiv:2110.03374",
    "title": "Model Adaptation: Historical Contrastive Learning for Unsupervised  Domain Adaptation without Source Data",
    "abstract": "Comments: Preliminary version release",
    "descriptor": "\nComments: Preliminary version release\n",
    "authors": [
      "Jiaxing Huang",
      "Dayan Guan",
      "Aoran Xiao",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03374"
  },
  {
    "id": "arXiv:2110.03979",
    "title": "MilliTRACE-IR: Contact Tracing and Temperature Screening via mm-Wave and  Infrared Sensing",
    "abstract": "Comments: 16 pages, 18 figures, 7 tables",
    "descriptor": "\nComments: 16 pages, 18 figures, 7 tables\n",
    "authors": [
      "Marco Canil",
      "Jacopo Pegoraro",
      "Michele Rossi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03979"
  },
  {
    "id": "arXiv:2110.07348",
    "title": "A Framework for Risk Assessment and Optimal Line Upgrade Selection to  Mitigate Wildfire Risk",
    "abstract": "Comments: 7 pages, 10 figures; fixed math typo on page 2",
    "descriptor": "\nComments: 7 pages, 10 figures; fixed math typo on page 2\n",
    "authors": [
      "Sofia Taylor",
      "Line A. Roald"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.07348"
  },
  {
    "id": "arXiv:2110.07472",
    "title": "Capacity of Group-invariant Linear Readouts from Equivariant  Representations: How Many Objects can be Linearly Classified Under All  Possible Views?",
    "abstract": "Comments: v3: Updated acknowledgements and revisions based on ICLR reviews",
    "descriptor": "\nComments: v3: Updated acknowledgements and revisions based on ICLR reviews\n",
    "authors": [
      "Matthew Farrell",
      "Blake Bordelon",
      "Shubhendu Trivedi",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.07472"
  },
  {
    "id": "arXiv:2110.09638",
    "title": "Repeated Games, Optimal Channel Capture, and Open Problems for Slotted  Multiple Access",
    "abstract": "Comments: 20 pages. This version includes new references and fixes a mis-reported number in Fig. 5, the beta cell of 3-state",
    "descriptor": "\nComments: 20 pages. This version includes new references and fixes a mis-reported number in Fig. 5, the beta cell of 3-state\n",
    "authors": [
      "Michael J. Neely"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.09638"
  },
  {
    "id": "arXiv:2110.10927",
    "title": "SecureBoost+ : A High Performance Gradient Boosting Tree Framework for  Large Scale Vertical Federated Learning",
    "abstract": "SecureBoost+ : A High Performance Gradient Boosting Tree Framework for  Large Scale Vertical Federated Learning",
    "descriptor": "",
    "authors": [
      "Weijing Chen",
      "Guoqiang Ma",
      "Tao Fan",
      "Yan Kang",
      "Qian Xu",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10927"
  },
  {
    "id": "arXiv:2110.12478",
    "title": "Deep Asymmetric Hashing with Dual Semantic Regression and Class  Structure Quantization",
    "abstract": "Deep Asymmetric Hashing with Dual Semantic Regression and Class  Structure Quantization",
    "descriptor": "",
    "authors": [
      "Jianglin Lu",
      "Hailing Wang",
      "Jie Zhou",
      "Mengfan Yan",
      "Jiajun Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.12478"
  },
  {
    "id": "arXiv:2110.12827",
    "title": "Novel coronavirus pneumonia lesion segmentation in CT images",
    "abstract": "Novel coronavirus pneumonia lesion segmentation in CT images",
    "descriptor": "",
    "authors": [
      "Yuanyuan Peng",
      "Zixu Zhang",
      "Hongbin Tu",
      "Xiong Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12827"
  },
  {
    "id": "arXiv:2110.12981",
    "title": "Neural ODE and DAE Modules for Power System Dynamic Component Modeling",
    "abstract": "Comments: 10 pages, 8 figures, 3 table",
    "descriptor": "\nComments: 10 pages, 8 figures, 3 table\n",
    "authors": [
      "Tannan Xiao",
      "Ying Chen",
      "Tirui He",
      "Huizhe Guan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12981"
  },
  {
    "id": "arXiv:2110.15064",
    "title": "Towards Fine-Grained Reasoning for Fake News Detection",
    "abstract": "Comments: Published as a conference paper at AAAI 2022",
    "descriptor": "\nComments: Published as a conference paper at AAAI 2022\n",
    "authors": [
      "Yiqiao Jin",
      "Xiting Wang",
      "Ruichao Yang",
      "Yizhou Sun",
      "Wei Wang",
      "Hao Liao",
      "Xing Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15064"
  },
  {
    "id": "arXiv:2111.00698",
    "title": "Influential Prototypical Networks for Few Shot Learning: A  Dermatological Case Study",
    "abstract": "Comments: Paper needs revision on data so want to withdraw",
    "descriptor": "\nComments: Paper needs revision on data so want to withdraw\n",
    "authors": [
      "Ranjana Roy Chowdhury",
      "Deepti R. Bathula"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00698"
  },
  {
    "id": "arXiv:2111.03941",
    "title": "Time Discretization-Invariant Safe Action Repetition for Policy Gradient  Methods",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Seohong Park",
      "Jaekyeom Kim",
      "Gunhee Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.03941"
  },
  {
    "id": "arXiv:2111.07764",
    "title": "Fidelity-Guarantee Entanglement Routing in Quantum Networks",
    "abstract": "Fidelity-Guarantee Entanglement Routing in Quantum Networks",
    "descriptor": "",
    "authors": [
      "Jian Li",
      "Mingjun Wang",
      "Qidong Jia",
      "Kaiping Xue",
      "Nenghai Yu",
      "Qibin Sun",
      "Jun Lu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.07764"
  },
  {
    "id": "arXiv:2111.12493",
    "title": "Time and Memory Efficient Parallel Algorithm for Structural Graph  Summaries and two Extensions to Incremental Summarization and  $k$-Bisimulation for Long $k$-Chaining",
    "abstract": "Time and Memory Efficient Parallel Algorithm for Structural Graph  Summaries and two Extensions to Incremental Summarization and  $k$-Bisimulation for Long $k$-Chaining",
    "descriptor": "",
    "authors": [
      "Till Blume",
      "Jannik Rau",
      "David Richerby",
      "Ansgar Scherp"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.12493"
  },
  {
    "id": "arXiv:2111.14377",
    "title": "Collective Intelligence for Deep Learning: A Survey of Recent  Developments",
    "abstract": "Collective Intelligence for Deep Learning: A Survey of Recent  Developments",
    "descriptor": "",
    "authors": [
      "David Ha",
      "Yujin Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.14377"
  },
  {
    "id": "arXiv:2111.14938",
    "title": "Distribution Shift in Airline Customer Behavior during COVID-19",
    "abstract": "Comments: 6 pages, 5 figures, NeurIPS 2021 Workshop on Distribution Shifts: connecting methods and applications (DistShift)",
    "descriptor": "\nComments: 6 pages, 5 figures, NeurIPS 2021 Workshop on Distribution Shifts: connecting methods and applications (DistShift)\n",
    "authors": [
      "Abhinav Garg",
      "Naman Shukla",
      "Lavanya Marla",
      "Sriram Somanchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2111.14938"
  },
  {
    "id": "arXiv:2112.01176",
    "title": "Overcoming the Domain Gap in Neural Action Representations",
    "abstract": "Overcoming the Domain Gap in Neural Action Representations",
    "descriptor": "",
    "authors": [
      "Semih G\u00fcnel",
      "Florian Aymanns",
      "Sina Honari",
      "Pavan Ramdya",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01176"
  },
  {
    "id": "arXiv:2112.02248",
    "title": "Algorithms for Maximum Internal Spanning Tree Problem for Some Graph  Classes",
    "abstract": "Algorithms for Maximum Internal Spanning Tree Problem for Some Graph  Classes",
    "descriptor": "",
    "authors": [
      "Gopika Sharma",
      "Arti Pandey",
      "Michael C. Wigal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.02248"
  },
  {
    "id": "arXiv:2112.02335",
    "title": "Per-Link Parallel and Distributed Hybrid Beamforming for Multi-Cell MIMO  Millimeter Wave Full Duplex",
    "abstract": "Per-Link Parallel and Distributed Hybrid Beamforming for Multi-Cell MIMO  Millimeter Wave Full Duplex",
    "descriptor": "",
    "authors": [
      "Chandan Kumar Sheemar",
      "Dirk Slock"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.02335"
  },
  {
    "id": "arXiv:2112.02682",
    "title": "BERTMap: A BERT-based Ontology Alignment System",
    "abstract": "Comments: Full version (with appendix) of the accepted paper in 36th AAAI Conference on Artificial Intelligence 2022",
    "descriptor": "\nComments: Full version (with appendix) of the accepted paper in 36th AAAI Conference on Artificial Intelligence 2022\n",
    "authors": [
      "Yuan He",
      "Jiaoyan Chen",
      "Denvar Antonyrajah",
      "Ian Horrocks"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02682"
  },
  {
    "id": "arXiv:2112.03518",
    "title": "Genetic Algorithm for Constrained Molecular Inverse Design",
    "abstract": "Genetic Algorithm for Constrained Molecular Inverse Design",
    "descriptor": "",
    "authors": [
      "Yurim Lee",
      "Gydam Choi",
      "Minsung Yoon",
      "Cheongwon Kim"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03518"
  },
  {
    "id": "arXiv:2112.04489",
    "title": "Learn2Reg: comprehensive multi-task medical image registration  challenge, dataset and evaluation in the era of deep learning",
    "abstract": "Learn2Reg: comprehensive multi-task medical image registration  challenge, dataset and evaluation in the era of deep learning",
    "descriptor": "",
    "authors": [
      "Alessa Hering",
      "Lasse Hansen",
      "Tony C. W. Mok",
      "Albert C. S. Chung",
      "Hanna Siebert",
      "Stephanie H\u00e4ger",
      "Annkristin Lange",
      "Sven Kuckertz",
      "Stefan Heldmann",
      "Wei Shao",
      "Sulaiman Vesal",
      "Mirabela Rusu",
      "Geoffrey Sonn",
      "Th\u00e9o Estienne",
      "Maria Vakalopoulou",
      "Luyi Han",
      "Yunzhi Huang",
      "Mikael Brudfors",
      "Ya\u00ebl Balbastre",
      "SamuelJ outard",
      "Marc Modat",
      "Gal Lifshitz",
      "Dan Raviv",
      "Jinxin Lv",
      "Qiang Li",
      "Vincent Jaouen",
      "Dimitris Visvikis",
      "Constance Fourcade",
      "Mathieu Rubeaux",
      "Wentao Pan",
      "Zhe Xu",
      "Bailiang Jian",
      "Francesca De Benetti",
      "Marek Wodzinski",
      "Niklas Gunnarsson",
      "Jens Sj\u00f6lund",
      "Huaqi Qiu",
      "Zeju Li",
      "Christoph Gro\u00dfbr\u00f6hmer",
      "Andrew Hoopes",
      "Ingerid Reinertsen",
      "Yiming Xiao",
      "Bennett Landman",
      "Yuankai Huo",
      "Keelin Murphy",
      "Nikolas Lessmann",
      "Bram van Ginneken",
      "Adrian V. Dalca",
      "Mattias P. Heinrich"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04489"
  },
  {
    "id": "arXiv:2112.04766",
    "title": "Adaptive Methods for Aggregated Domain Generalization",
    "abstract": "Adaptive Methods for Aggregated Domain Generalization",
    "descriptor": "",
    "authors": [
      "Xavier Thomas",
      "Dhruv Mahajan",
      "Alex Pentland",
      "Abhimanyu Dubey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04766"
  },
  {
    "id": "arXiv:2112.04846",
    "title": "ScaleNet: A Shallow Architecture for Scale Estimation",
    "abstract": "ScaleNet: A Shallow Architecture for Scale Estimation",
    "descriptor": "",
    "authors": [
      "Axel Barroso-Laguna",
      "Yurun Tian",
      "Krystian Mikolajczyk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04846"
  },
  {
    "id": "arXiv:2112.06455",
    "title": "Self-Paced Deep Regression Forests with Consideration on Ranking  Fairness",
    "abstract": "Comments: 14 pages, 9 figures. The paper has been submitted to TIP and is currently under review. arXiv admin note: text overlap with arXiv:2004.01459",
    "descriptor": "\nComments: 14 pages, 9 figures. The paper has been submitted to TIP and is currently under review. arXiv admin note: text overlap with arXiv:2004.01459\n",
    "authors": [
      "Lili Pan",
      "Mingming Meng",
      "Yazhou Ren",
      "Yali Zheng",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06455"
  },
  {
    "id": "arXiv:2112.07064",
    "title": "Ergo -- a programming language for Smart Legal Contracts",
    "abstract": "Ergo -- a programming language for Smart Legal Contracts",
    "descriptor": "",
    "authors": [
      "Niall Roche",
      "Walter Hernandez",
      "Eason Chen",
      "J\u00e9r\u00f4me Sim\u00e9on",
      "Dan Selman"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.07064"
  },
  {
    "id": "arXiv:2112.08782",
    "title": "Improved YOLOv5 network for real-time multi-scale traffic sign detection",
    "abstract": "Improved YOLOv5 network for real-time multi-scale traffic sign detection",
    "descriptor": "",
    "authors": [
      "Junfan Wang",
      "Yi Chen",
      "Mingyu Gao",
      "Zhekang Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08782"
  },
  {
    "id": "arXiv:2112.08954",
    "title": "Advancing Residual Learning towards Powerful Deep Spiking Neural  Networks",
    "abstract": "Advancing Residual Learning towards Powerful Deep Spiking Neural  Networks",
    "descriptor": "",
    "authors": [
      "Yifan Hu",
      "Yujie Wu",
      "Lei Deng",
      "Guoqi Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08954"
  },
  {
    "id": "arXiv:2112.09384",
    "title": "An Exact Algorithm for the Linear Tape Scheduling Problem",
    "abstract": "An Exact Algorithm for the Linear Tape Scheduling Problem",
    "descriptor": "",
    "authors": [
      "Valentin Honor\u00e9",
      "Bertrand Simon",
      "Fr\u00e9d\u00e9ric Suter"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.09384"
  },
  {
    "id": "arXiv:2112.09583",
    "title": "Align and Prompt: Video-and-Language Pre-training with Entity Prompts",
    "abstract": "Align and Prompt: Video-and-Language Pre-training with Entity Prompts",
    "descriptor": "",
    "authors": [
      "Dongxu Li",
      "Junnan Li",
      "Hongdong Li",
      "Juan Carlos Niebles",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09583"
  },
  {
    "id": "arXiv:2112.09641",
    "title": "Embedding Graph Convolutional Networks in Recurrent Neural Networks for  Predictive Monitoring",
    "abstract": "Embedding Graph Convolutional Networks in Recurrent Neural Networks for  Predictive Monitoring",
    "descriptor": "",
    "authors": [
      "Efr\u00e9n Rama-Maneiro",
      "Juan C. Vidal",
      "Manuel Lama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09641"
  },
  {
    "id": "arXiv:2112.09891",
    "title": "Equilibrated Zeroth-Order Unrolled Deep Networks for Accelerated MRI",
    "abstract": "Comments: 11 figures",
    "descriptor": "\nComments: 11 figures\n",
    "authors": [
      "Zhuo-Xu Cui",
      "Jing Cheng",
      "Qingyong Zhu",
      "Yuanyuan Liu",
      "Sen Jia",
      "Kankan Zhao",
      "Ziwen Ke",
      "Wenqi Huang",
      "Haifeng Wang",
      "Yanjie Zhu",
      "Dong Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.09891"
  },
  {
    "id": "arXiv:2112.09988",
    "title": "Derivative Action Control: Smooth Model Predictive Path Integral Control  without Smoothing",
    "abstract": "Comments: 7 pages, 5 figures",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Taekyung Kim",
      "Gyuhyun Park",
      "Jihwan Bae",
      "Wonsuk Lee"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.09988"
  },
  {
    "id": "arXiv:2112.10006",
    "title": "Low-resource Learning with Knowledge Graphs: A Comprehensive Survey",
    "abstract": "Comments: A survey on Low-resource Learning with Knowledge Graph. It has collected 96 papers on this topic, with over 230 citations in total",
    "descriptor": "\nComments: A survey on Low-resource Learning with Knowledge Graph. It has collected 96 papers on this topic, with over 230 citations in total\n",
    "authors": [
      "Jiaoyan Chen",
      "Yuxia Geng",
      "Zhuo Chen",
      "Jeff Z. Pan",
      "Yuan He",
      "Wen Zhang",
      "Ian Horrocks",
      "Huajun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.10006"
  },
  {
    "id": "arXiv:2112.10308",
    "title": "Approximating distribution functions and densities using quasi-Monte  Carlo methods after smoothing by preintegration",
    "abstract": "Approximating distribution functions and densities using quasi-Monte  Carlo methods after smoothing by preintegration",
    "descriptor": "",
    "authors": [
      "Alexander D. Gilbert",
      "Frances Y. Kuo",
      "Ian H. Sloan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.10308"
  },
  {
    "id": "arXiv:2112.10692",
    "title": "Space-time upscaling of reactive transport in porous media",
    "abstract": "Space-time upscaling of reactive transport in porous media",
    "descriptor": "",
    "authors": [
      "Nicolae Suciu",
      "Florin A. Radu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.10692"
  },
  {
    "id": "arXiv:2112.10767",
    "title": "GCN-Geo: A Graph Convolution Network-based Fine-grained IP Geolocation  Framework",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Shichang Ding",
      "Xiangyang Luo",
      "Jinwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.10767"
  },
  {
    "id": "arXiv:2112.10944",
    "title": "Reinforcement Learning based Sequential Batch-sampling for Bayesian  Optimal Experimental Design",
    "abstract": "Reinforcement Learning based Sequential Batch-sampling for Bayesian  Optimal Experimental Design",
    "descriptor": "",
    "authors": [
      "Yonatan Ashenafi",
      "Piyush Pandita",
      "Sayan Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.10944"
  },
  {
    "id": "arXiv:2112.11037",
    "title": "SOIT: Segmenting Objects with Instance-Aware Transformers",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Xiaodong Yu",
      "Dahu Shi",
      "Xing Wei",
      "Ye Ren",
      "Tingqun Ye",
      "Wenming Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11037"
  },
  {
    "id": "arXiv:2112.11324",
    "title": "Satellite-Based Communications Security: A Survey of Threats, Solutions,  and Research Challenges",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Pietro Tedeschi",
      "Savio Sciancalepore",
      "Roberto Di Pietro"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.11324"
  },
  {
    "id": "arXiv:2112.11806",
    "title": "Lifting Symmetry Breaking Constraints with Inductive Logic Programming",
    "abstract": "Comments: to appear in Machine Learning Journal",
    "descriptor": "\nComments: to appear in Machine Learning Journal\n",
    "authors": [
      "Alice Tarzariol",
      "Martin Gebser",
      "Konstantin Schekotihin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.11806"
  },
  {
    "id": "arXiv:2112.11896",
    "title": "The Grassl-R\u00f6tteler cyclic and consta-cyclic MDS codes are generalised  Reed-Solomon codes",
    "abstract": "The Grassl-R\u00f6tteler cyclic and consta-cyclic MDS codes are generalised  Reed-Solomon codes",
    "descriptor": "",
    "authors": [
      "Simeon Ball"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.11896"
  },
  {
    "id": "arXiv:2112.11970",
    "title": "Burling graphs revisited, part III: Applications to $\u03c7$-boundedness",
    "abstract": "Comments: 24 pages, 15 figures Some typos fixed in this new version",
    "descriptor": "\nComments: 24 pages, 15 figures Some typos fixed in this new version\n",
    "authors": [
      "Pegah Pournajafi",
      "Nicolas Trotignon"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.11970"
  },
  {
    "id": "arXiv:2112.12063",
    "title": "Investigating Opinion Dynamics Models in Agent-Based Simulation of  Energy Eco-Feedback Programs",
    "abstract": "Investigating Opinion Dynamics Models in Agent-Based Simulation of  Energy Eco-Feedback Programs",
    "descriptor": "",
    "authors": [
      "Mohammad Zarei",
      "Mojtaba Maghrebi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.12063"
  },
  {
    "id": "arXiv:2112.12142",
    "title": "Survey the storage systems used in HPC and BDA ecosystems",
    "abstract": "Comments: 13 pages, 10 figures, 7 tables",
    "descriptor": "\nComments: 13 pages, 10 figures, 7 tables\n",
    "authors": [
      "Priyam Shah",
      "Jie Ye",
      "Xian-He Sun"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.12142"
  }
]
[
  {
    "id": "arXiv:2112.07670",
    "title": "A literature review on COVID-19 disease diagnosis from respiratory sound  data",
    "abstract": "The World Health Organization (WHO) has announced a COVID-19 was a global\npandemic in March 2020. It was initially started in china in the year 2019\nDecember and affected an expanding number of nations in various countries in\nthe last few months. In this particular situation, many techniques, methods,\nand AI-based classification algorithms are put in the spotlight in reacting to\nfight against it and reduce the rate of such a global health crisis. COVID-19's\nmain signs are heavy temperature, different cough, cold, breathing shortness,\nand a combination of loss of sense of smell and chest tightness. The digital\nworld is growing day by day, in this context digital stethoscope can read all\nof these symptoms and diagnose respiratory disease. In this study, we majorly\nfocus on literature reviews of how SARS-CoV-2 is spreading and in-depth\nanalysis of the diagnosis of COVID-19 disease from human respiratory sounds\nlike cough, voice, and breath by analyzing the respiratory sound parameters. We\nhope this review will provide an initiative for the clinical scientists and\nresearcher's community to initiate open access, scalable, and accessible work\nin the collective battle against COVID-19.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.07285\n",
    "authors": [
      "Kranthi Kumar Lella",
      "Alphonse PJA"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.07670"
  },
  {
    "id": "arXiv:2112.07701",
    "title": "Conservative and Adaptive Penalty for Model-Based Safe Reinforcement  Learning",
    "abstract": "Reinforcement Learning (RL) agents in the real world must satisfy safety\nconstraints in addition to maximizing a reward objective. Model-based RL\nalgorithms hold promise for reducing unsafe real-world actions: they may\nsynthesize policies that obey all constraints using simulated samples from a\nlearned model. However, imperfect models can result in real-world constraint\nviolations even for actions that are predicted to satisfy all constraints. We\npropose Conservative and Adaptive Penalty (CAP), a model-based safe RL\nframework that accounts for potential modeling errors by capturing model\nuncertainty and adaptively exploiting it to balance the reward and the cost\nobjectives. First, CAP inflates predicted costs using an uncertainty-based\npenalty. Theoretically, we show that policies that satisfy this conservative\ncost constraint are guaranteed to also be feasible in the true environment. We\nfurther show that this guarantees the safety of all intermediate solutions\nduring RL training. Further, CAP adaptively tunes this penalty during training\nusing true cost feedback from the environment. We evaluate this conservative\nand adaptive penalty-based approach for model-based safe RL extensively on\nstate and image-based environments. Our results demonstrate substantial gains\nin sample-efficiency while incurring fewer violations than prior safe RL\nalgorithms. Code is available at: https://github.com/Redrew/CAP",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Yecheng Jason Ma",
      "Andrew Shen",
      "Osbert Bastani",
      "Dinesh Jayaraman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07701"
  },
  {
    "id": "arXiv:2112.07708",
    "title": "Learning to Retrieve Passages without Supervision",
    "abstract": "Dense retrievers for open-domain question answering (ODQA) have been shown to\nachieve impressive performance by training on large datasets of\nquestion-passage pairs. We investigate whether dense retrievers can be learned\nin a self-supervised fashion, and applied effectively without any annotations.\nWe observe that existing pretrained models for retrieval struggle in this\nscenario, and propose a new pretraining scheme designed for retrieval:\nrecurring span retrieval. We use recurring spans across passages in a document\nto create pseudo examples for contrastive learning. The resulting model --\nSpider -- performs surprisingly well without any examples on a wide range of\nODQA datasets, and is competitive with BM25, a strong sparse baseline. In\naddition, Spider often outperforms strong baselines like DPR trained on Natural\nQuestions, when evaluated on questions from other datasets. Our hybrid\nretriever, which combines Spider with BM25, improves over its components across\nall datasets, and is often competitive with in-domain DPR models, which are\ntrained on tens of thousands of examples.",
    "descriptor": "",
    "authors": [
      "Ori Ram",
      "Gal Shachaf",
      "Omer Levy",
      "Jonathan Berant",
      "Amir Globerson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.07708"
  },
  {
    "id": "arXiv:2112.07711",
    "title": "Representing Inferences and their Lexicalization",
    "abstract": "We have recently begun a project to develop a more effective and efficient\nway to marshal inferences from background knowledge to facilitate deep natural\nlanguage understanding. The meaning of a word is taken to be the entities,\npredications, presuppositions, and potential inferences that it adds to an\nongoing situation. As words compose, the minimal model in the situation evolves\nto limit and direct inference. At this point we have developed our\ncomputational architecture and implemented it on real text. Our focus has been\non proving the feasibility of our design.",
    "descriptor": "\nComments: 20 pages, 1 figure\n",
    "authors": [
      "David McDonald",
      "James Pustejovsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07711"
  },
  {
    "id": "arXiv:2112.07718",
    "title": "Scatterbrained: A flexible and expandable pattern for decentralized  machine learning",
    "abstract": "Federated machine learning is a technique for training a model across\nmultiple devices without exchanging data between them. Because data remains\nlocal to each compute node, federated learning is well-suited for use-cases in\nfields where data is carefully controlled, such as medicine, or in domains with\nbandwidth constraints. One weakness of this approach is that most federated\nlearning tools rely upon a central server to perform workload delegation and to\nproduce a single shared model. Here, we suggest a flexible framework for\ndecentralizing the federated learning pattern, and provide an open-source,\nreference implementation compatible with PyTorch.",
    "descriptor": "\nComments: Code and documentation is available at this https URL\n",
    "authors": [
      "Miller Wilt",
      "Jordan K. Matelsky",
      "Andrew S. Gearhart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07718"
  },
  {
    "id": "arXiv:2112.07719",
    "title": "Identifying Class Specific Filters with L1 Norm Frequency Histograms in  Deep CNNs",
    "abstract": "Interpretability of Deep Neural Networks has become a major area of\nexploration. Although these networks have achieved state of the art accuracy in\nmany tasks, it is extremely difficult to interpret and explain their decisions.\nIn this work we analyze the final and penultimate layers of Deep Convolutional\nNetworks and provide an efficient method for identifying subsets of features\nthat contribute most towards the network's decision for a class. We demonstrate\nthat the number of such features per class is much lower in comparison to the\ndimension of the final layer and therefore the decision surface of Deep CNNs\nlies on a low dimensional manifold and is proportional to the network depth.\nOur methods allow to decompose the final layer into separate subspaces which is\nfar more interpretable and has a lower computational cost as compared to the\nfinal layer of the full network.",
    "descriptor": "\nComments: 19 pages, 5 figures, github repo: this https URL\n",
    "authors": [
      "Akshay Badola",
      "Cherian Roy",
      "Vineet Padmanabhan",
      "Rajendra Lal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07719"
  },
  {
    "id": "arXiv:2112.07723",
    "title": "Autonomous Navigation System from Simultaneous Localization and Mapping",
    "abstract": "This paper presents the development of a Simultaneous Localization and\nMapping (SLAM) based Autonomous Navigation system. The motivation for this\nstudy was to find a solution for navigating interior spaces autonomously.\nInterior navigation is challenging as it can be forever evolving. Solving this\nissue is necessary for multitude of services, like cleaning, the health\nindustry, and in manufacturing industries. The focus of this paper is the\ndescription of the SLAM-based software architecture developed for this proposed\nautonomous system. A potential application of this system, oriented to a smart\nwheelchair, was evaluated. Current interior navigation solutions require some\nsort of guiding line, like a black line on the floor. With this proposed\nsolution, interiors do not require renovation to accommodate this solution. The\nsource code of this application has been made open source so that it could be\nre-purposed for a similar application. Also, this open-source project is\nenvisioned to be improved by the broad open-source community upon past its\ncurrent state.",
    "descriptor": "",
    "authors": [
      "Micheal Caracciolo",
      "Owen Casciotti",
      "Christopher Lloyd",
      "Ernesto Sola-Thomas",
      "Matthew Weaver",
      "Kyle Bielby",
      "Md Abdul Baset Sarker",
      "Masudul H. Imtiaz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07723"
  },
  {
    "id": "arXiv:2112.07742",
    "title": "Classifying Emails into Human vs Machine Category",
    "abstract": "It is an essential product requirement of Yahoo Mail to distinguish between\npersonal and machine-generated emails. The old production classifier in Yahoo\nMail was based on a simple logistic regression model. That model was trained by\naggregating features at the SMTP address level. We propose building deep\nlearning models at the message level. We built and trained four individual CNN\nmodels: (1) a content model with subject and content as input; (2) a sender\nmodel with sender email address and name as input; (3) an action model by\nanalyzing email recipients' action patterns and correspondingly generating\ntarget labels based on senders' opening/deleting behaviors; (4) a salutation\nmodel by utilizing senders' \"explicit salutation\" signal as positive labels.\nNext, we built a final full model after exploring different combinations of the\nabove four models. Experimental results on editorial data show that our full\nmodel improves the adjusted-recall from 70.5% to 78.8% compared to the old\nproduction model, while at the same time lifts the precision from 94.7% to\n96.0%. Our full model also significantly beats the state-of-the-art Bert model\nat this task. This full model has been deployed into the current production\nsystem (Yahoo Mail 6).",
    "descriptor": "\nComments: This paper is accepted by AAAI'22\n",
    "authors": [
      "Changsung Kang",
      "Hongwei Shang",
      "Jean-Marc Langlois"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07742"
  },
  {
    "id": "arXiv:2112.07743",
    "title": "Neighborhood Random Walk Graph Sampling for Regularized Bayesian Graph  Convolutional Neural Networks",
    "abstract": "In the modern age of social media and networks, graph representations of\nreal-world phenomena have become an incredibly useful source to mine insights.\nOften, we are interested in understanding how entities in a graph are\ninterconnected. The Graph Neural Network (GNN) has proven to be a very useful\ntool in a variety of graph learning tasks including node classification, link\nprediction, and edge classification. However, in most of these tasks, the graph\ndata we are working with may be noisy and may contain spurious edges. That is,\nthere is a lot of uncertainty associated with the underlying graph structure.\nRecent approaches to modeling uncertainty have been to use a Bayesian framework\nand view the graph as a random variable with probabilities associated with\nmodel parameters. Introducing the Bayesian paradigm to graph-based models,\nspecifically for semi-supervised node classification, has been shown to yield\nhigher classification accuracies. However, the method of graph inference\nproposed in recent work does not take into account the structure of the graph.\nIn this paper, we propose a novel algorithm called Bayesian Graph Convolutional\nNetwork using Neighborhood Random Walk Sampling (BGCN-NRWS), which uses a\nMarkov Chain Monte Carlo (MCMC) based graph sampling algorithm utilizing graph\nstructure, reduces overfitting by using a variational inference layer, and\nyields consistently competitive classification results compared to the\nstate-of-the-art in semi-supervised node classification.",
    "descriptor": "\nComments: Accepted for publication at the 20th IEEE International Conference on Machine Learning and Applications (ICMLA 2021)\n",
    "authors": [
      "Aneesh Komanduri",
      "Justin Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.07743"
  },
  {
    "id": "arXiv:2112.07745",
    "title": "Learning to track environment state via predictive autoencoding",
    "abstract": "This work introduces a neural architecture for learning forward models of\nstochastic environments. The task is achieved solely through learning from\ntemporal unstructured observations in the form of images. Once trained, the\nmodel allows for tracking of the environment state in the presence of noise or\nwith new percepts arriving intermittently. Additionally, the state estimate can\nbe propagated in observation-blind mode, thus allowing for long-term\npredictions. The network can output both expectation over future observations\nand samples from belief distribution. The resulting functionalities are similar\nto those of a Particle Filter (PF). The architecture is evaluated in an\nenvironment where we simulate objects moving. As the forward and sensor models\nare available, we implement a PF to gauge the quality of the models learnt from\nthe data.",
    "descriptor": "\nComments: 10 pages. Written in March 2018. Not published\n",
    "authors": [
      "Marian Andrecki",
      "Nicholas K. Taylor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07745"
  },
  {
    "id": "arXiv:2112.07746",
    "title": "CEM-GD: Cross-Entropy Method with Gradient Descent Planner for  Model-Based Reinforcement Learning",
    "abstract": "Current state-of-the-art model-based reinforcement learning algorithms use\ntrajectory sampling methods, such as the Cross-Entropy Method (CEM), for\nplanning in continuous control settings. These zeroth-order optimizers require\nsampling a large number of trajectory rollouts to select an optimal action,\nwhich scales poorly for large prediction horizons or high dimensional action\nspaces. First-order methods that use the gradients of the rewards with respect\nto the actions as an update can mitigate this issue, but suffer from local\noptima due to the non-convex optimization landscape. To overcome these issues\nand achieve the best of both worlds, we propose a novel planner, Cross-Entropy\nMethod with Gradient Descent (CEM-GD), that combines first-order methods with\nCEM. At the beginning of execution, CEM-GD uses CEM to sample a significant\namount of trajectory rollouts to explore the optimization landscape and avoid\npoor local minima. It then uses the top trajectories as initialization for\ngradient descent and applies gradient updates to each of these trajectories to\nfind the optimal action sequence. At each subsequent time step, however, CEM-GD\nsamples much fewer trajectories from CEM before applying gradient updates. We\nshow that as the dimensionality of the planning problem increases, CEM-GD\nmaintains desirable performance with a constant small number of samples by\nusing the gradient information, while avoiding local optima using initially\nwell-sampled trajectories. Furthermore, CEM-GD achieves better performance than\nCEM on a variety of continuous control benchmarks in MuJoCo with 100x fewer\nsamples per time step, resulting in around 25% less computation time and 10%\nless memory usage. The implementation of CEM-GD is available at\n$\\href{https://github.com/KevinHuang8/CEM-GD}{\\text{https://github.com/KevinHuang8/CEM-GD}}$.",
    "descriptor": "",
    "authors": [
      "Kevin Huang",
      "Sahin Lale",
      "Ugo Rosolia",
      "Yuanyuan Shi",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.07746"
  },
  {
    "id": "arXiv:2112.07749",
    "title": "Entropy stable discontinuous Galerkin methods for the shallow water  equations with subcell positivity preservation",
    "abstract": "High order schemes are known to be unstable in the presence of shock\ndiscontinuities or under-resolved solution features, and have traditionally\nrequired additional filtering, limiting, or artificial viscosity to avoid\nsolution blow up. Entropy stable schemes address this instability by ensuring\nthat physically relevant solutions satisfy a semi-discrete entropy inequality\nindependently of discretization parameters. However, additional measures must\nbe taken to ensure that solutions satisfy physical constraints such as\npositivity. In this work, we present a high order entropy stable discontinuous\nGalerkin (ESDG) method for the nonlinear shallow water equations (SWE) on\ntwo-dimensional (2D) triangular meshes which preserves the positivity of the\nwater heights. The scheme combines a low order positivity preserving method\nwith a high order entropy stable method using convex limiting. This method is\nentropy stable and well-balanced for fitted meshes with continuous bathymetry\nprofiles.",
    "descriptor": "",
    "authors": [
      "Xinhui Wu",
      "Nathaniel Trask",
      "Jesse Chan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07749"
  },
  {
    "id": "arXiv:2112.07751",
    "title": "Learn bifurcations of nonlinear parametric systems via equation-driven  neural networks",
    "abstract": "Nonlinear parametric systems have been widely used in modeling nonlinear\ndynamics in science and engineering. Bifurcation analysis of these nonlinear\nsystems on the parameter space are usually used to study the solution structure\nsuch as the number of solutions and the stability. In this paper, we develop a\nnew machine learning approach to compute the bifurcations via so-called\nequation-driven neural networks (EDNNs). The EDNNs consist of a two-step\noptimization: the first step is to approximate the solution function of the\nparameter by training empirical solution data; the second step is to compute\nbifurcations by using the approximated neural network obtained in the first\nstep. Both theoretical convergence analysis and numerical implementation on\nseveral examples have been performed to demonstrate the feasibility of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Wenrui Hao",
      "Chunyue Zheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07751"
  },
  {
    "id": "arXiv:2112.07752",
    "title": "Representation and Invariance in Reinforcement Learning",
    "abstract": "If we changed the rules, would the wise trade places with the fools?\nDifferent groups formalize reinforcement learning (RL) in different ways. If an\nagent in one RL formalization is to run within another RL formalization's\nenvironment, the agent must first be converted, or mapped. A criterion of\nadequacy for any such mapping is that it preserves relative intelligence. This\npaper investigates the formulation and properties of this criterion of\nadequacy. However, prior to the problem of formulation is, we argue, the\nproblem of comparative intelligence. We compare intelligence using\nultrafilters, motivated by viewing agents as candidates in intelligence\nelections where voters are environments. These comparators are\ncounterintuitive, but we prove an impossibility theorem about RL intelligence\nmeasurement, suggesting such counterintuitions are unavoidable. Given a mapping\nbetween RL frameworks, we establish sufficient conditions to ensure that, for\nany ultrafilter-based intelligence comparator in the destination framework,\nthere exists an ultrafilter-based intelligence comparator in the source\nframework such that the mapping preserves relative intelligence. We consider\nthree concrete mappings between various RL frameworks and show that they\nsatisfy these sufficient conditions and therefore preserve suitably-measured\nrelative intelligence.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Samuel Alexander",
      "Arthur Paul Pedersen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07752"
  },
  {
    "id": "arXiv:2112.07761",
    "title": "Split Moves for Monte-Carlo Tree Search",
    "abstract": "In many games, moves consist of several decisions made by the player. These\ndecisions can be viewed as separate moves, which is already a common practice\nin multi-action games for efficiency reasons. Such division of a player move\ninto a sequence of simpler / lower level moves is called \\emph{splitting}. So\nfar, split moves have been applied only in forementioned straightforward cases,\nand furthermore, there was almost no study revealing its impact on agents'\nplaying strength. Taking the knowledge-free perspective, we aim to answer how\nto effectively use split moves within Monte-Carlo Tree Search (MCTS) and what\nis the practical impact of split design on agents' strength. This paper\nproposes a generalization of MCTS that works with arbitrarily split moves. We\ndesign several variations of the algorithm and try to measure the impact of\nsplit moves separately on efficiency, quality of MCTS, simulations, and\naction-based heuristics. The tests are carried out on a set of board games and\nperformed using the Regular Boardgames General Game Playing formalism, where\nsplit strategies of different granularity can be automatically derived based on\nan abstract description of the game. The results give an overview of the\nbehavior of agents using split design in different ways. We conclude that split\ndesign can be greatly beneficial for single- as well as multi-action games.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Jakub Kowalski",
      "Maksymilian Mika",
      "Wojciech Pawlik",
      "Jakub Sutowicz",
      "Marek Szyku\u0142a",
      "Mark H. M. Winands"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07761"
  },
  {
    "id": "arXiv:2112.07765",
    "title": "Nonlinear Discrete-time Systems' Identification without Persistence of  Excitation: A Finite-time Concurrent Learning",
    "abstract": "This paper deals with the problem of finite-time learning for unknown\ndiscrete-time nonlinear systems' dynamics, without the requirement of the\npersistence of excitation. A finite-time concurrent learning approach is\npresented to approximate the uncertainties of the discrete-time nonlinear\nsystems in an on-line fashion by employing current data along with recorded\nexperienced data satisfying an easy-to-check rank condition on the richness of\nthe recorded data which is less restrictive in comparison with persistence of\nexcitation condition. Rigorous proofs guarantee the finite-time convergence of\nthe estimated parameters to their optimal values based on a discrete-time\nLyapunov analysis. Compared with the existing work in the literature,\nsimulation results illustrate that the proposed method can timely and precisely\napproximate the uncertainties.",
    "descriptor": "",
    "authors": [
      "Farzaneh Tatari",
      "Chiristos Panayiotou",
      "Marios Polycarpou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.07765"
  },
  {
    "id": "arXiv:2112.07768",
    "title": "Efficient Dynamic Graph Representation Learning at Scale",
    "abstract": "Dynamic graphs with ordered sequences of events between nodes are prevalent\nin real-world industrial applications such as e-commerce and social platforms.\nHowever, representation learning for dynamic graphs has posed great\ncomputational challenges due to the time and structure dependency and irregular\nnature of the data, preventing such models from being deployed to real-world\napplications. To tackle this challenge, we propose an efficient algorithm,\nEfficient Dynamic Graph lEarning (EDGE), which selectively expresses certain\ntemporal dependency via training loss to improve the parallelism in\ncomputations. We show that EDGE can scale to dynamic graphs with millions of\nnodes and hundreds of millions of temporal events and achieve new\nstate-of-the-art (SOTA) performance.",
    "descriptor": "",
    "authors": [
      "Xinshi Chen",
      "Yan Zhu",
      "Haowen Xu",
      "Mengyang Liu",
      "Liang Xiong",
      "Muhan Zhang",
      "Le Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07768"
  },
  {
    "id": "arXiv:2112.07771",
    "title": "Boosted Dense Retriever",
    "abstract": "We propose DrBoost, a dense retrieval ensemble inspired by boosting. DrBoost\nis trained in stages: each component model is learned sequentially and\nspecialized by focusing only on retrieval mistakes made by the current\nensemble. The final representation is the concatenation of the output vectors\nof all the component models, making it a drop-in replacement for standard dense\nretrievers at test time. DrBoost enjoys several advantages compared to standard\ndense retrieval models. It produces representations which are 4x more compact,\nwhile delivering comparable retrieval results. It also performs surprisingly\nwell under approximate search with coarse quantization, reducing latency and\nbandwidth needs by another 4x. In practice, this can make the difference\nbetween serving indices from disk versus from memory, paving the way for much\ncheaper deployments.",
    "descriptor": "",
    "authors": [
      "Patrick Lewis",
      "Barlas O\u011fuz",
      "Wenhan Xiong",
      "Fabio Petroni",
      "Wen-tau Yih",
      "Sebastian Riedel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.07771"
  },
  {
    "id": "arXiv:2112.07772",
    "title": "Do Answers to Boolean Questions Need Explanations? Yes",
    "abstract": "Existing datasets that contain boolean questions, such as BoolQ and TYDI QA ,\nprovide the user with a YES/NO response to the question. However, a one word\nresponse is not sufficient for an explainable system. We promote explainability\nby releasing a new set of annotations marking the evidence in existing TyDi QA\nand BoolQ datasets. We show that our annotations can be used to train a model\nthat extracts improved evidence spans compared to models that rely on existing\nresources. We confirm our findings with a user study which shows that our\nextracted evidence spans enhance the user experience. We also provide further\ninsight into the challenges of answering boolean questions, such as passages\ncontaining conflicting YES and NO answers, and varying degrees of relevance of\nthe predicted evidence.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Sara Rosenthal",
      "Mihaela Bornea",
      "Avirup Sil",
      "Radu Florian",
      "Scott McCarley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07772"
  },
  {
    "id": "arXiv:2112.07773",
    "title": "Filling gaps in trustworthy development of AI",
    "abstract": "The range of application of artificial intelligence (AI) is vast, as is the\npotential for harm. Growing awareness of potential risks from AI systems has\nspurred action to address those risks, while eroding confidence in AI systems\nand the organizations that develop them. A 2019 study found over 80\norganizations that published and adopted \"AI ethics principles'', and more have\njoined since. But the principles often leave a gap between the \"what\" and the\n\"how\" of trustworthy AI development. Such gaps have enabled questionable or\nethically dubious behavior, which casts doubts on the trustworthiness of\nspecific organizations, and the field more broadly. There is thus an urgent\nneed for concrete methods that both enable AI developers to prevent harm and\nallow them to demonstrate their trustworthiness through verifiable behavior.\nBelow, we explore mechanisms (drawn from arXiv:2004.07213) for creating an\necosystem where AI developers can earn trust - if they are trustworthy. Better\nassessment of developer trustworthiness could inform user choice, employee\nactions, investment decisions, legal recourse, and emerging governance regimes.",
    "descriptor": "",
    "authors": [
      "Shahar Avin",
      "Haydn Belfield",
      "Miles Brundage",
      "Gretchen Krueger",
      "Jasmine Wang",
      "Adrian Weller",
      "Markus Anderljung",
      "Igor Krawczuk",
      "David Krueger",
      "Jonathan Lebensold",
      "Tegan Maharaj",
      "Noa Zilberman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.07773"
  },
  {
    "id": "arXiv:2112.07774",
    "title": "Assessing Human Interaction in Virtual Reality With Continually Learning  Prediction Agents Based on Reinforcement Learning Algorithms: A Pilot Study",
    "abstract": "Artificial intelligence systems increasingly involve continual learning to\nenable flexibility in general situations that are not encountered during system\ntraining. Human interaction with autonomous systems is broadly studied, but\nresearch has hitherto under-explored interactions that occur while the system\nis actively learning, and can noticeably change its behaviour in minutes. In\nthis pilot study, we investigate how the interaction between a human and a\ncontinually learning prediction agent develops as the agent develops\ncompetency. Additionally, we compare two different agent architectures to\nassess how representational choices in agent design affect the human-agent\ninteraction. We develop a virtual reality environment and a time-based\nprediction task wherein learned predictions from a reinforcement learning (RL)\nalgorithm augment human predictions. We assess how a participant's performance\nand behaviour in this task differs across agent types, using both quantitative\nand qualitative analyses. Our findings suggest that human trust of the system\nmay be influenced by early interactions with the agent, and that trust in turn\naffects strategic behaviour, but limitations of the pilot study rule out any\nconclusive statement. We identify trust as a key feature of interaction to\nfocus on when considering RL-based technologies, and make several\nrecommendations for modification to this study in preparation for a\nlarger-scale investigation. A video summary of this paper can be found at\nhttps://youtu.be/oVYJdnBqTwQ .",
    "descriptor": "",
    "authors": [
      "Dylan J. A. Brenneis",
      "Adam S. Parker",
      "Michael Bradley Johanson",
      "Andrew Butcher",
      "Elnaz Davoodi",
      "Leslie Acker",
      "Matthew M. Botvinick",
      "Joseph Modayil",
      "Adam White",
      "Patrick M. Pilarski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.07774"
  },
  {
    "id": "arXiv:2112.07779",
    "title": "Learning Rigidity-based Flocking Control with Gaussian Processes",
    "abstract": "Flocking control of multi-agents system is challenging for agents with\npartially unknown dynamics. This paper proposes an online learning-based\ncontroller to stabilize flocking motion of double-integrator agents with\nadditional unknown nonlinear dynamics by using Gaussian processes (GP). Agents\ninteraction is described by a time-invariant infinitesimally minimally rigid\nundirected graph. We provide a decentralized control law that exponentially\nstabilizes the motion of the agents and captures Reynolds boids motion for\nswarms by using GPs as an online learning-based oracle for the prediction of\nthe unknown dynamics. In particular the presented approach guarantees a\nprobabilistic bounded tracking error with high probability.",
    "descriptor": "",
    "authors": [
      "Manuela Gamonal",
      "Thomas Beckers",
      "George J. Pappas",
      "Leonardo J. Colombo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07779"
  },
  {
    "id": "arXiv:2112.07783",
    "title": "Online anti-Semitism across platforms",
    "abstract": "We created a fine-grained AI system for the detection of anti-Semitism. This\nExplainable AI will identify English and German anti-Semitic expressions of\ndehumanization, verbal aggression and conspiracies in online social media\nmessages across platforms, to support high-level decision making.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Tom De Smedt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07783"
  },
  {
    "id": "arXiv:2112.07787",
    "title": "Revisiting 3D Object Detection From an Egocentric Perspective",
    "abstract": "3D object detection is a key module for safety-critical robotics applications\nsuch as autonomous driving. For these applications, we care most about how the\ndetections affect the ego-agent's behavior and safety (the egocentric\nperspective). Intuitively, we seek more accurate descriptions of object\ngeometry when it's more likely to interfere with the ego-agent's motion\ntrajectory. However, current detection metrics, based on box\nIntersection-over-Union (IoU), are object-centric and aren't designed to\ncapture the spatio-temporal relationship between objects and the ego-agent. To\naddress this issue, we propose a new egocentric measure to evaluate 3D object\ndetection, namely Support Distance Error (SDE). Our analysis based on SDE\nreveals that the egocentric detection quality is bounded by the coarse geometry\nof the bounding boxes. Given the insight that SDE would benefit from more\naccurate geometry descriptions, we propose to represent objects as amodal\ncontours, specifically amodal star-shaped polygons, and devise a simple model,\nStarPoly, to predict such contours. Our experiments on the large-scale Waymo\nOpen Dataset show that SDE better reflects the impact of detection quality on\nthe ego-agent's safety compared to IoU; and the estimated contours from\nStarPoly consistently improve the egocentric detection quality over recent 3D\nobject detectors.",
    "descriptor": "\nComments: Published in NeurIPS 2021\n",
    "authors": [
      "Boyang Deng",
      "Charles R. Qi",
      "Mahyar Najibi",
      "Thomas Funkhouser",
      "Yin Zhou",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.07787"
  },
  {
    "id": "arXiv:2112.07789",
    "title": "FLOWER: A comprehensive dataflow compiler for high-level synthesis",
    "abstract": "FPGAs have found their way into data centers as accelerator cards, making\nreconfigurable computing more accessible for high-performance applications. At\nthe same time, new high-level synthesis compilers like Xilinx Vitis and runtime\nlibraries such as XRT attract software programmers into the reconfigurable\ndomain. While software programmers are familiar with task-level and\ndata-parallel programming, FPGAs often require different types of parallelism.\nFor example, data-driven parallelism is mandatory to obtain satisfactory\nhardware designs for pipelined dataflow architectures. However, software\nprogrammers are often not acquainted with dataflow architectures - resulting in\npoor hardware designs.\nIn this work we present FLOWER, a comprehensive compiler infrastructure that\nprovides automatic canonical transformations for high-level synthesis from a\ndomain-specific library. This allows programmers to focus on algorithm\nimplementations rather than low-level optimizations for dataflow architectures.\nWe show that FLOWER allows to synthesize efficient implementations for\nhigh-performance streaming applications targeting System-on-Chip and FPGA\naccelerator cards, in the context of image processing and computer vision.",
    "descriptor": "",
    "authors": [
      "Puya Amiri",
      "Ars\u00e8ne P\u00e9rard-Gayot",
      "Richard Membarth",
      "Philipp Slusallek",
      "Roland Lei\u00dfa",
      "Sebastian Hack"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.07789"
  },
  {
    "id": "arXiv:2112.07790",
    "title": "Maximum Bayes Smatch Ensemble Distillation for AMR Parsing",
    "abstract": "AMR parsing has experienced an unprecendented increase in performance in the\nlast three years, due to a mixture of effects including architecture\nimprovements and transfer learning. Self-learning techniques have also played a\nrole in pushing performance forward. However, for most recent high performant\nparsers, the effect of self-learning and silver data generation seems to be\nfading. In this paper we show that it is possible to overcome this diminishing\nreturns of silver data by combining Smatch-based ensembling techniques with\nensemble distillation. In an extensive experimental setup, we push single model\nEnglish parser performance above 85 Smatch for the first time and return to\nsubstantial gains. We also attain a new state-of-the-art for cross-lingual AMR\nparsing for Chinese, German, Italian and Spanish. Finally we explore the impact\nof the proposed distillation technique on domain adaptation, and show that it\ncan produce gains rivaling those of human annotated data for QALD-9 and achieve\na new state-of-the-art for BioAMR.",
    "descriptor": "",
    "authors": [
      "Young-Suk Lee",
      "Ramon Fernandez Astudillo",
      "Thanh Lam Hoang",
      "Tahira Naseem",
      "Radu Florian",
      "Salim Roukos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07790"
  },
  {
    "id": "arXiv:2112.07791",
    "title": "A Simple But Powerful Graph Encoder for Temporal Knowledge Graph  Completion",
    "abstract": "While knowledge graphs contain rich semantic knowledge of various entities\nand the relational information among them, temporal knowledge graphs (TKGs)\nfurther indicate the interactions of the entities over time. To study how to\nbetter model TKGs, automatic temporal knowledge graph completion (TKGC) has\ngained great interest. Recent TKGC methods aim to integrate advanced deep\nlearning techniques, e.g., attention mechanism and Transformer, to boost model\nperformance. However, we find that compared to adopting various kinds of\ncomplex modules, it is more beneficial to better utilize the whole amount of\ntemporal information along the time axis. In this paper, we propose a simple\nbut powerful graph encoder TARGCN for TKGC. TARGCN is parameter-efficient, and\nit extensively utilizes the information from the whole temporal context. We\nperform experiments on three benchmark datasets. Our model can achieve a more\nthan 42% relative improvement on GDELT dataset compared with the\nstate-of-the-art model. Meanwhile, it outperforms the strongest baseline on\nICEWS05-15 dataset with around 18.5% fewer parameters.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Zifeng Ding",
      "Yunpu Ma",
      "Bailan He",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07791"
  },
  {
    "id": "arXiv:2112.07794",
    "title": "Review of Factor Graphs for Robust GNSS Applications",
    "abstract": "Factor graphs have recently emerged as an alternative solution method for\nGNSS positioning. In this article, we review how factor graphs are implemented\nin GNSS, some of their advantages over Kalman Filters, and their importance in\nmaking positioning solutions more robust to degraded measurements. We also talk\nabout how factor graphs can be an important tool for the field radio-navigation\ncommunity.",
    "descriptor": "",
    "authors": [
      "Shounak Das",
      "Ryan Watson",
      "Jason Gross"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.07794"
  },
  {
    "id": "arXiv:2112.07798",
    "title": "Public key cryptography based on twisted dihedral group algebras",
    "abstract": "In this paper, we propose to use a twisted dihedral group algebra for\npublic-key cryptography. For this, we introduce a new $2$-cocycle\n$\\alpha_{\\lambda}$ to twist the dihedral group algebra. Using the ambient space\n$\\mathbb{F}^{\\alpha_{\\lambda}} D_{2n}$, we then introduce a key exchange\nprotocol and present an analysis of its security. Moreover, we explore the\nproperties of the resulting twisted algebra\n$\\mathbb{F}^{\\alpha_{\\lambda}}D_{2n}$, exploiting them to enhance our key\nexchange protocol. We also introduce a probabilistic public-key scheme derived\nfrom our key-exchange protocol and obtain a key encapsulation mechanism (KEM)\nby applying a well-known generic transformation to our public-key scheme.\nFinally, we present a proof-of-concept implementation of the resulting key\nencapsulation mechanism.",
    "descriptor": "",
    "authors": [
      "Javier de la Cruz",
      "Ricardo Villanueva-Polanco"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2112.07798"
  },
  {
    "id": "arXiv:2112.07804",
    "title": "Tackling the Generative Learning Trilemma with Denoising Diffusion GANs",
    "abstract": "A wide variety of deep generative models has been developed in the past\ndecade. Yet, these models often struggle with simultaneously addressing three\nkey requirements including: high sample quality, mode coverage, and fast\nsampling. We call the challenge imposed by these requirements the generative\nlearning trilemma, as the existing models often trade some of them for others.\nParticularly, denoising diffusion models have shown impressive sample quality\nand diversity, but their expensive sampling does not yet allow them to be\napplied in many real-world applications. In this paper, we argue that slow\nsampling in these models is fundamentally attributed to the Gaussian assumption\nin the denoising step which is justified only for small step sizes. To enable\ndenoising with large steps, and hence, to reduce the total number of denoising\nsteps, we propose to model the denoising distribution using a complex\nmultimodal distribution. We introduce denoising diffusion generative\nadversarial networks (denoising diffusion GANs) that model each denoising step\nusing a multimodal conditional GAN. Through extensive evaluations, we show that\ndenoising diffusion GANs obtain sample quality and diversity competitive with\noriginal diffusion models while being 2000$\\times$ faster on the CIFAR-10\ndataset. Compared to traditional GANs, our model exhibits better mode coverage\nand sample diversity. To the best of our knowledge, denoising diffusion GAN is\nthe first model that reduces sampling cost in diffusion models to an extent\nthat allows them to be applied to real-world applications inexpensively.\nProject page and code: https://nvlabs.github.io/denoising-diffusion-gan",
    "descriptor": "",
    "authors": [
      "Zhisheng Xiao",
      "Karsten Kreis",
      "Arash Vahdat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.07804"
  },
  {
    "id": "arXiv:2112.07805",
    "title": "Network Graph Based Neural Architecture Search",
    "abstract": "Neural architecture search enables automation of architecture design. Despite\nits success, it is computationally costly and does not provide an insight on\nhow to design a desirable architecture. Here we propose a new way of searching\nneural network where we search neural architecture by rewiring the\ncorresponding graph and predict the architecture performance by graph\nproperties. Because we do not perform machine learning over the entire graph\nspace and use predicted architecture performance to search architecture, the\nsearching process is remarkably efficient. We find graph based search can give\na reasonably good prediction of desirable architecture. In addition, we find\ngraph properties that are effective to predict architecture performance. Our\nwork proposes a new way of searching neural architecture and provides insights\non neural architecture design.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Zhenhan Huang",
      "Chunheng Jiang",
      "Pin-Yu Chen",
      "Jianxi Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07805"
  },
  {
    "id": "arXiv:2112.07806",
    "title": "Understanding Feature Transfer Through Representation Alignment",
    "abstract": "Training with the true labels of a dataset as opposed to randomized labels\nleads to faster optimization and better generalization. This difference is\nattributed to a notion of alignment between inputs and labels in natural\ndatasets. We find that training neural networks with different architectures\nand optimizers on random or true labels enforces the same relationship between\nthe hidden representations and the training labels, elucidating why neural\nnetwork representations have been so successful for transfer. We first\nhighlight why aligned features promote transfer and show in a classic synthetic\ntransfer problem that alignment is the determining factor for positive and\nnegative transfer to similar and dissimilar tasks. We then investigate a\nvariety of neural network architectures and find that (a) alignment emerges\nacross a variety of different architectures and optimizers, with more alignment\narising from depth (b) alignment increases for layers closer to the output and\n(c) existing high-performance deep CNNs exhibit high levels of alignment.",
    "descriptor": "\nComments: 13 pages, 16 figures\n",
    "authors": [
      "Ehsan Imani",
      "Wei Hu",
      "Martha White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07806"
  },
  {
    "id": "arXiv:2112.07812",
    "title": "Image Segmentation with Homotopy Warping",
    "abstract": "Besides per-pixel accuracy, topological correctness is also crucial for the\nsegmentation of images with fine-scale structures, e.g., satellite images and\nbiomedical images. In this paper, by leveraging the theory of digital topology,\nwe identify locations in an image that are critical for topology. By focusing\non these critical locations, we propose a new homotopy warping loss to train\ndeep image segmentation networks for better topological accuracy. To\nefficiently identity these topologically critical locations, we propose a new\nalgorithm exploiting the distance transform. The proposed algorithm, as well as\nthe loss function, naturally generalize to different topological structures in\nboth 2D and 3D settings. The proposed loss function helps deep nets achieve\nbetter performance in terms of topology-aware metrics, outperforming\nstate-of-the-art topology-preserving segmentation methods.",
    "descriptor": "\nComments: 13 pages, 11 figures\n",
    "authors": [
      "Xiaoling Hu",
      "Chao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.07812"
  },
  {
    "id": "arXiv:2112.07814",
    "title": "Analytical and numerical investigation on the tempered time-fractional  operator with application to the Bloch equation and the two-layered problem",
    "abstract": "In the continuous time random walk model, the time-fractional operator\nusually expresses an infinite waiting time probability density. Different from\nthat usual setting, this work considers the tempered time-fractional operator,\nwhich reflects a finite waiting time probability density. Firstly, we analyse\nthe solution of a tempered benchmark problem, which shows a weak singularity\nnear the initial time. The L1 scheme on graded mesh and the WSGL formula with\ncorrection terms are adapted to deal with the non-smooth solution, in which we\ncompare these two methods systematically in terms of the convergence and\nconsumed CPU time. Furthermore, a fast calculation for the time tempered Caputo\nfractional derivative is developed based on a sum-of-exponentials\napproximation, which significantly reduces the running time. Moreover, the\ntempered operator is applied to the Bloch equation in nuclear magnetic\nresonance and a two-layered problem with composite material exhibiting distinct\nmemory effects, for which both the analytical (or semi-analytical) and\nnumerical solutions are derived using transform techniques and finite\ndifference methods. Data fitting results verify that the tempered\ntime-fractional model is much effective to describe the MRI data. An important\nfinding is that, compared with the fractional index, the tempered operator\nparameter could further accelerate the diffusion. The tempered model with two\nparameters $\\alpha$ and $\\rho$ are more flexible, which can avoid choosing a\ntoo small fractional index leading to low regularity and strong heterogeneity.",
    "descriptor": "\nComments: 23 pages, 9 figures, 6 tables\n",
    "authors": [
      "Libo Feng",
      "Fawang Liu",
      "Vo V. Anh",
      "Shanlin Qin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07814"
  },
  {
    "id": "arXiv:2112.07817",
    "title": "Simulating Large Eliminations in Cedille",
    "abstract": "Large eliminations provide an expressive mechanism for arity- and\ntype-generic programming. However, as large eliminations are closely tied to a\ntype theory's primitive notion of inductive type, this expressivity is not\nexpected within polymorphic lambda calculi in which datatypes are encoded using\nimpredicative quantification. We report progress on simulating large\neliminations for datatype encodings in one such type theory, the calculus of\ndependent lambda eliminations (CDLE). Specifically, we show that the expected\ncomputation rules for large eliminations, expressed using a derived type of\nextensional equality of types, can be proven within CDLE. We present several\ncase studies, demonstrating the adequacy of this simulation for a variety of\ngeneric programming tasks, and a generic formulation of the simulation allowing\nits use for any datatype. All results have been mechanically checked by\nCedille, an implementation of CDLE.",
    "descriptor": "",
    "authors": [
      "Christopher Jenkins",
      "Andrew Marmaduke",
      "Aaron Stump"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.07817"
  },
  {
    "id": "arXiv:2112.07819",
    "title": "Weed Recognition using Deep Learning Techniques on Class-imbalanced  Imagery",
    "abstract": "Most weed species can adversely impact agricultural productivity by competing\nfor nutrients required by high-value crops. Manual weeding is not practical for\nlarge cropping areas. Many studies have been undertaken to develop automatic\nweed management systems for agricultural crops. In this process, one of the\nmajor tasks is to recognise the weeds from images. However, weed recognition is\na challenging task. It is because weed and crop plants can be similar in\ncolour, texture and shape which can be exacerbated further by the imaging\nconditions, geographic or weather conditions when the images are recorded.\nAdvanced machine learning techniques can be used to recognise weeds from\nimagery. In this paper, we have investigated five state-of-the-art deep neural\nnetworks, namely VGG16, ResNet-50, Inception-V3, Inception-ResNet-v2 and\nMobileNetV2, and evaluated their performance for weed recognition. We have used\nseveral experimental settings and multiple dataset combinations. In particular,\nwe constructed a large weed-crop dataset by combining several smaller datasets,\nmitigating class imbalance by data augmentation, and using this dataset in\nbenchmarking the deep neural networks. We investigated the use of transfer\nlearning techniques by preserving the pre-trained weights for extracting the\nfeatures and fine-tuning them using the images of crop and weed datasets. We\nfound that VGG16 performed better than others on small-scale datasets, while\nResNet-50 performed better than other deep networks on the large combined\ndataset.",
    "descriptor": "\nComments: The paper is accepted by Crop and Pasture Science journal (this https URL)\n",
    "authors": [
      "A S M Mahmudul Hasan",
      "Ferdous Sohel",
      "Dean Diepeveen",
      "Hamid Laga",
      "Michael G.K. Jones"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07819"
  },
  {
    "id": "arXiv:2112.07820",
    "title": "Value Retrieval with Arbitrary Queries for Form-like Documents",
    "abstract": "We propose value retrieval with arbitrary queries for form-like documents to\nreduce human effort of processing forms. Unlike previous methods that only\naddress a fixed set of field items, our method predicts target value for an\narbitrary query based on the understanding of layout and semantics of a form.\nTo further boost model performance, we propose a simple document language\nmodeling (simpleDLM) strategy to improve document understanding on large-scale\nmodel pre-training. Experimental results show that our method outperforms our\nbaselines significantly and the simpleDLM further improves our performance on\nvalue retrieval by around 17\\% F1 score compared with the state-of-the-art\npre-training method. Code will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Mingfei Gao",
      "Le Xue",
      "Chetan Ramaiah",
      "Chen Xing",
      "Ran Xu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07820"
  },
  {
    "id": "arXiv:2112.07823",
    "title": "Bayesian Graph Contrastive Learning",
    "abstract": "Contrastive learning has become a key component of self-supervised learning\napproaches for graph-structured data. However, despite their success, existing\ngraph contrastive learning methods are incapable of uncertainty quantification\nfor node representations or their downstream tasks, limiting their application\nin high-stakes domains. In this paper, we propose a novel Bayesian perspective\nof graph contrastive learning methods showing random augmentations leads to\nstochastic encoders. As a result, our proposed method represents each node by a\ndistribution in the latent space in contrast to existing techniques which embed\neach node to a deterministic vector. By learning distributional\nrepresentations, we provide uncertainty estimates in downstream graph analytics\ntasks and increase the expressive power of the predictive model. In addition,\nwe propose a Bayesian framework to infer the probability of perturbations in\neach view of the contrastive model, eliminating the need for a computationally\nexpensive search for hyperparameter tuning. We empirically show a considerable\nimprovement in performance compared to existing state-of-the-art methods on\nseveral benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Arman Hasanzadeh",
      "Mohammadreza Armandpour",
      "Ehsan Hajiramezanali",
      "Mingyuan Zhou",
      "Nick Duffield",
      "Krishna Narayanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.07823"
  },
  {
    "id": "arXiv:2112.07824",
    "title": "Analog/Mixed-Signal Circuit Synthesis Enabled by the Advancements of  Circuit Architectures and Machine Learning Algorithms",
    "abstract": "Analog mixed-signal (AMS) circuit architecture has evolved towards more\ndigital friendly due to technology scaling and demand for higher\nflexibility/reconfigurability. Meanwhile, the design complexity and cost of AMS\ncircuits has substantially increased due to the necessity of optimizing the\ncircuit sizing, layout, and verification of a complex AMS circuit. On the other\nhand, machine learning (ML) algorithms have been under exponential growth over\nthe past decade and actively exploited by the electronic design automation\n(EDA) community. This paper will identify the opportunities and challenges\nbrought about by this trend and overview several emerging AMS design\nmethodologies that are enabled by the recent evolution of AMS circuit\narchitectures and machine learning algorithms. Specifically, we will focus on\nusing neural-network-based surrogate models to expedite the circuit design\nparameter search and layout iterations. Lastly, we will demonstrate the rapid\nsynthesis of several AMS circuit examples from specification to silicon\nprototype, with significantly reduced human intervention.",
    "descriptor": "\nComments: PREPRINT - accepted at IEEE/ACM Asia and South Pacific Design Automation Conference (ASP-DAC), 2022\n",
    "authors": [
      "Shiyu Su",
      "Qiaochu Zhang",
      "Mohsen Hassanpourghadi",
      "Juzheng Liu",
      "Rezwan A Rasul",
      "Mike Shuo-Wei Chen"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07824"
  },
  {
    "id": "arXiv:2112.07825",
    "title": "TAFA: Design Automation of Analog Mixed-Signal FIR Filters Using Time  Approximation Architecture",
    "abstract": "A digital finite impulse response (FIR) filter design is fully synthesizable,\nthanks to the mature CAD support of digital circuitry. On the contrary, analog\nmixed-signal (AMS) filter design is mostly a manual process, including\narchitecture selection, schematic design, and layout. This work presents a\nsystematic design methodology to automate AMS FIR filter design using a time\napproximation architecture without any tunable passive component, such as\nswitched capacitor or resistor. It not only enhances the flexibility of the\nfilter but also facilitates design automation with reduced analog complexity.\nThe proposed design flow features a hybrid approximation scheme that\nautomatically optimize the filter's impulse response in light of time\nquantization effects, which shows significant performance improvement with\nminimum designer's efforts in the loop. Additionally, a layout-aware regression\nmodel based on an artificial neural network (ANN), in combination with\ngradient-based search algorithm, is used to automate and expedite the filter\ndesign. With the proposed framework, we demonstrate rapid synthesis of AMS FIR\nfilters in 65nm process from specification to layout.",
    "descriptor": "\nComments: PREPRINT - accepted at IEEE/ACM Asia and South Pacific Design Automation Conference (ASP-DAC), 2022\n",
    "authors": [
      "Shiyu Su",
      "Qiaochu Zhang",
      "Juzheng Liu",
      "Mohsen Hassanpourghadi",
      "Rezwan Rasul",
      "Mike Shuo-Wei Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07825"
  },
  {
    "id": "arXiv:2112.07826",
    "title": "Quantifying Cybersecurity Effectiveness of Dynamic Network Diversity",
    "abstract": "The deployment of monoculture software stacks can have devastating\nconsequences because a single attack can compromise all of the vulnerable\ncomputers in cyberspace. This one-vulnerability-affects-all phenomenon will\ncontinue until after software stacks are diversified, which is well recognized\nby the research community. However, existing studies mainly focused on\ninvestigating the effectiveness of software diversity at the building-block\nlevel (e.g., whether two independent implementations indeed exhibit independent\nvulnerabilities); the effectiveness of enforcing network-wide software\ndiversity is little understood, despite its importance in possibly helping\njustify investment in software diversification. As a first step towards\nultimately tackling this problem, we propose a systematic framework for\nmodeling and quantifying the cybersecurity effectiveness of network diversity,\nincluding a suite of cybersecurity metrics. We also present an agent-based\nsimulation to empirically demonstrate the usefulness of the framework. We draw\na number of insights, including the surprising result that proactive diversity\nis effective under very special circumstances, but reactive-adaptive diversity\nis much more effective in most cases.",
    "descriptor": "",
    "authors": [
      "Huashan Chen",
      "Hasan Cam",
      "Shouhuai Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.07826"
  },
  {
    "id": "arXiv:2112.07828",
    "title": "On Recursive State Estimation for Linear State-Space Models Having  Quantized Output Data",
    "abstract": "In this paper, we study the problem of estimating the state of a dynamic\nstate-space system where the output is subject to quantization. We compare some\nclassical approaches and a new development in the literature to obtain the\nfiltering and smoothing distributions of the state conditioned to quantized\ndata. The classical approaches include the Extended Kalman filter/smoother in\nwhich we consider an approximation of the quantizer non-linearity based on the\narctan function, the quantized Kalman filter/smoother, the Unscented Kalman\nfilter/smoother, and the Sequential Monte Carlo sampling method also called\nparticle filter/smoother. We consider a new approach based on the Gaussian sum\nfilter/smoother where the probability mass function of the quantized data given\nthe state is modeled as an integral equation and approximated using\nGauss-Legendre quadrature. The Particle filter is addressed considering some\nresampling methods used to deal with the degeneracy problem. Also, the sample\nimpoverishment caused by the resampling method is addressed by introducing\ndiversity in the samples set using the Markov Chain Monte Carlo method. In this\npaper, we discuss the implementation of the aforementioned algorithms and the\nParticle filter/smoother implementation is studied by using different\nresampling methods combined with two Markov Chain algorithms. A numerical\nsimulation is presented to analyze the accuracy of the estimation and the\ncomputational cost.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Angel L. Cede\u00f1o",
      "Ricardo Albornoz",
      "Boris I. Godoy",
      "Rodrigo Carvajal",
      "Juan C. Ag\u00fcero"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.07828"
  },
  {
    "id": "arXiv:2112.07831",
    "title": "Optimal Slot Size under Various Bandwidth Distributions in the  Flexible-grid Optical Networks",
    "abstract": "Flexible grid Optical Networks are efficient mechanism to provide flexibility\nin the optical spectrum utilization. For such networks, the slot width size as\nspecified by the ITU-T G.694.1 is 12.5 GHz. However, one should question if it\nis the optimal grid size? In this paper, under different bandwidth distribution\nscenarios, we review which slot size give appropriate spectrum efficiency.\nMoreover, we present a study of the slot sizes with varying incoming traffic\nhaving some bandwidth requirement under different scenarios.",
    "descriptor": "",
    "authors": [
      "Varsha Lohani",
      "Anjali Sharma",
      "Yatindra Nath Singh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.07831"
  },
  {
    "id": "arXiv:2112.07833",
    "title": "Reconfigurable Intelligent Surface-Empowered Self-Interference  Cancellation for 6G Full-Duplex MIMO Communication Systems",
    "abstract": "With the advent of sixth-generation (6G) wireless communication networks, it\nrequires substantially increasing wireless traffic and extending serving\ncoverage. Reconfigurable intelligent surface (RIS) is widely considered as a\npromising technique which is capable of improving the system data rate, energy\nefficiency and coverage extension as well as the benefit of low power\nconsumption. Moreover, full-duplex (FD) transmission provides simultaneous\ntransmit and received signals, which theoretically enhances twice spectrum\nefficiency. However, the self-interference (SI) in FD is a challenging task\nrequiring complex and high-overhead cancellation, which can be resolved by\nconfiguring appropriate phase of RIS elements. This paper has proposed an\nRIS-empowered full-duplex self-interference cancellation (RFSC) scheme to\nalleviate the severe SI in an RIS-FD system. We consider the SI minimization of\nRIS-FD uplink (UL) while guaranteeing quality-of-service (QoS) of UL users. The\nclosed-form solution is theoretically derived by exploiting Lagrangian method\nunder different numbers of RIS elements and receiving antennas. Simulation\nresults reveal that the proposed RFSC scheme outperforms the scenario without\nRIS deployment in terms of higher signal-to-interference-plus-noise ratio\n(SINR). Due to effective interference mitigation, the proposed RFSC can achieve\nthe highest SINR compared to other existing schemes in open literatures.",
    "descriptor": "",
    "authors": [
      "Chia-Jou Ku",
      "Li-Hsiang Shen",
      "Kai-Ten Feng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.07833"
  },
  {
    "id": "arXiv:2112.07835",
    "title": "Mining Minority-class Examples With Uncertainty Estimates",
    "abstract": "In the real world, the frequency of occurrence of objects is naturally skewed\nforming long-tail class distributions, which results in poor performance on the\nstatistically rare classes. A promising solution is to mine tail-class examples\nto balance the training dataset. However, mining tail-class examples is a very\nchallenging task. For instance, most of the otherwise successful\nuncertainty-based mining approaches struggle due to distortion of class\nprobabilities resulting from skewness in data. In this work, we propose an\neffective, yet simple, approach to overcome these challenges. Our framework\nenhances the subdued tail-class activations and, thereafter, uses a one-class\ndata-centric approach to effectively identify tail-class examples. We carry out\nan exhaustive evaluation of our framework on three datasets spanning over two\ncomputer vision tasks. Substantial improvements in the minority-class mining\nand fine-tuned model's performance strongly corroborate the value of our\nproposed solution.",
    "descriptor": "",
    "authors": [
      "Gursimran Singh",
      "Lingyang Chu",
      "Lanjun Wang",
      "Jian Pei",
      "Qi Tian",
      "Yong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07835"
  },
  {
    "id": "arXiv:2112.07837",
    "title": "CentSmoothie: Central-Smoothing Hypergraph Neural Networks for  Predicting Drug-Drug Interactions",
    "abstract": "Predicting drug-drug interactions (DDI) is the problem of predicting side\neffects (unwanted outcomes) of a pair of drugs using drug information and known\nside effects of many pairs. This problem can be formulated as predicting labels\n(i.e. side effects) for each pair of nodes in a DDI graph, of which nodes are\ndrugs and edges are interacting drugs with known labels. State-of-the-art\nmethods for this problem are graph neural networks (GNNs), which leverage\nneighborhood information in the graph to learn node representations. For DDI,\nhowever, there are many labels with complicated relationships due to the nature\nof side effects. Usual GNNs often fix labels as one-hot vectors that do not\nreflect label relationships and potentially do not obtain the highest\nperformance in the difficult cases of infrequent labels. In this paper, we\nformulate DDI as a hypergraph where each hyperedge is a triple: two nodes for\ndrugs and one node for a label. We then present CentSmoothie, a hypergraph\nneural network that learns representations of nodes and labels altogether with\na novel central-smoothing formulation. We empirically demonstrate the\nperformance advantages of CentSmoothie in simulations as well as real datasets.",
    "descriptor": "",
    "authors": [
      "Duc Anh Nguyen",
      "Canh Hao Nguyen",
      "Hiroshi Mamitsuka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.07837"
  },
  {
    "id": "arXiv:2112.07839",
    "title": "LoSAC: An Efficient Local Stochastic Average Control Method for  Federated Optimization",
    "abstract": "Federated optimization (FedOpt), which targets at collaboratively training a\nlearning model across a large number of distributed clients, is vital for\nfederated learning. The primary concerns in FedOpt can be attributed to the\nmodel divergence and communication efficiency, which significantly affect the\nperformance. In this paper, we propose a new method, i.e., LoSAC, to learn from\nheterogeneous distributed data more efficiently. Its key algorithmic insight is\nto locally update the estimate for the global full gradient after {each}\nregular local model update. Thus, LoSAC can keep clients' information refreshed\nin a more compact way. In particular, we have studied the convergence result\nfor LoSAC. Besides, the bonus of LoSAC is the ability to defend the information\nleakage from the recent technique Deep Leakage Gradients (DLG). Finally,\nexperiments have verified the superiority of LoSAC comparing with\nstate-of-the-art FedOpt algorithms. Specifically, LoSAC significantly improves\ncommunication efficiency by more than $100\\%$ on average, mitigates the model\ndivergence problem and equips with the defense ability against DLG.",
    "descriptor": "",
    "authors": [
      "Huiming Chen",
      "Huandong Wang",
      "Quanming Yao",
      "Yong Li",
      "Depeng Jin",
      "Qiang Yang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07839"
  },
  {
    "id": "arXiv:2112.07840",
    "title": "A Predictive Online Transient Stability Assessment with Hierarchical  Generative Adversarial Networks",
    "abstract": "Online transient stability assessment (TSA) is essential for secure and\nstable power system operations. The growing number of Phasor Measurement Units\n(PMUs) brings about massive sources of data that can enhance online TSA.\nHowever, conventional data-driven methods require large amounts of transient\ndata to correctly assess the transient stability state of a system. In this\npaper, a new data-driven TSA approach is developed for TSA with fewer data\ncompared to the conventional methods. The data reduction is enabled by learning\nthe dynamic behaviors of the historical transient data using generative and\nadversarial networks (GAN). This knowledge is used online to predict the\nvoltage time series data after a transient event. A classifier embedded in the\ngenerative network deploys the predicted post-contingency data to determine the\nstability of the system following a fault. The developed GAN-based TSA approach\npreserves the spatial and temporal correlations that exist in multivariate PMU\ntime series data. Hence, in comparison with the state-of-the-art TSA methods,\nit achieves a higher assessment accuracy using only one sample of the measured\ndata and a shorter response time. Case studies conducted on the IEEE 118-bus\nsystem demonstrate the superior performance of the GAN-based method compared to\nthe conventional data-driven techniques.",
    "descriptor": "",
    "authors": [
      "Rui Ma",
      "Sara Eftekharnejad",
      "Chen Zhong",
      "Mustafa Cenk Gursoy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07840"
  },
  {
    "id": "arXiv:2112.07844",
    "title": "Fix your Models by Fixing your Datasets",
    "abstract": "The quality of underlying training data is very crucial for building\nperformant machine learning models with wider generalizabilty. However, current\nmachine learning (ML) tools lack streamlined processes for improving the data\nquality. So, getting data quality insights and iteratively pruning the errors\nto obtain a dataset which is most representative of downstream use cases is\nstill an ad-hoc manual process. Our work addresses this data tooling gap,\nrequired to build improved ML workflows purely through data-centric techniques.\nMore specifically, we introduce a systematic framework for (1) finding noisy or\nmislabelled samples in the dataset and, (2) identifying the most informative\nsamples, which when included in training would provide maximal model\nperformance lift. We demonstrate the efficacy of our framework on public as\nwell as private enterprise datasets of two Fortune 500 companies, and are\nconfident this work will form the basis for ML teams to perform more\nintelligent data discovery and pruning.",
    "descriptor": "",
    "authors": [
      "Atindriyo Sanyal",
      "Vikram Chatterji",
      "Nidhi Vyas",
      "Ben Epstein",
      "Nikita Demir",
      "Anthony Corletti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07844"
  },
  {
    "id": "arXiv:2112.07846",
    "title": "Probabilistic Logic Gate in Asynchronous Game of Life with Critical  Property",
    "abstract": "Metaheuristic and self-organizing criticality (SOC) could contribute to\nrobust computation under perturbed environments. Implementing a logic gate in a\ncomputing system in a critical state is one of the intriguing ways to study the\nrole of metaheuristics and SOCs. Here, we study the behavior of cellular\nautomaton, game of life (GL), in asynchronous updating and implement\nprobabilistic logic gates by using asynchronous GL. We find that asynchronous\nGL shows a phase transition, that the density of the state of 1 decays with the\npower law at the critical point, and that systems at the critical point have\nthe most computability in asynchronous GL. We implement AND and OR gates in\nasynchronous GL with criticality, which shows good performance. Since tuning\nperturbations play an essential role in operating logic gates, our study\nreveals the interference between manipulation and perturbation in probabilistic\nlogic gates.",
    "descriptor": "\nComments: 22 pages, 12 figures\n",
    "authors": [
      "Yukio-Pegio Gunji",
      "Yoshihiko Ohzawa",
      "Terutaka Tanaka"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.07846"
  },
  {
    "id": "arXiv:2112.07850",
    "title": "HyObscure: Hybrid Obscuring for Privacy-Preserving Data Publishing",
    "abstract": "Minimizing privacy leakage while ensuring data utility is a critical problem\nto data holders in a privacy-preserving data publishing task. Most prior\nresearch concerns only with one type of data and resorts to a single obscuring\nmethod, \\eg, obfuscation or generalization, to achieve a privacy-utility\ntradeoff, which is inadequate for protecting real-life heterogeneous data and\nis hard to defend ever-growing machine learning based inference attacks. This\nwork takes a pilot study on privacy-preserving data publishing when both\ngeneralization and obfuscation operations are employed for heterogeneous data\nprotection. To this end, we first propose novel measures for privacy and\nutility quantification and formulate the hybrid privacy-preserving data\nobscuring problem to account for the joint effect of generalization and\nobfuscation. We then design a novel hybrid protection mechanism called\nHyObscure, to cross-iteratively optimize the generalization and obfuscation\noperations for maximum privacy protection under a certain utility guarantee.\nThe convergence of the iterative process and the privacy leakage bound of\nHyObscure are also provided in theory. Extensive experiments demonstrate that\nHyObscure significantly outperforms a variety of state-of-the-art baseline\nmethods when facing various inference attacks under different scenarios.\nHyObscure also scales linearly to the data size and behaves robustly with\nvarying key parameters.",
    "descriptor": "",
    "authors": [
      "Xiao Han",
      "Yuncong Yang",
      "Junjie Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07850"
  },
  {
    "id": "arXiv:2112.07858",
    "title": "EDAssistant: Supporting Exploratory Data Analysis in Computational  Notebooks with In-Situ Code Search and Recommendation",
    "abstract": "Using computational notebooks (e.g., Jupyter Notebook), data scientists\nrationalize their exploratory data analysis (EDA) based on their prior\nexperience and external knowledge such as online examples. For novices or data\nscientists who lack specific knowledge about the dataset or problem to\ninvestigate, effectively obtaining and understanding the external information\nis critical to carry out EDA. This paper presents EDAssistant, a JupyterLab\nextension that supports EDA with in-situ search of example notebooks and\nrecommendation of useful APIs, powered by novel interactive visualization of\nsearch results. The code search and recommendation are enabled by\nstate-of-the-art machine learning models, trained on a large corpus of EDA\nnotebooks collected online. A user study is conducted to investigate both\nEDAssistant and data scientists' current practice (i.e., using external search\nengines). The results demonstrate the effectiveness and usefulness of\nEDAssistant, and participants appreciated its smooth and in-context support of\nEDA. We also report several design implications regarding code recommendation\ntools.",
    "descriptor": "",
    "authors": [
      "Xingjun Li",
      "Yizhi Zhang",
      "Justin Leung",
      "Chengnian Sun",
      "Jian Zhao"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07858"
  },
  {
    "id": "arXiv:2112.07859",
    "title": "Finite-Sample Analysis of Decentralized Q-Learning for Stochastic Games",
    "abstract": "Learning in stochastic games is arguably the most standard and fundamental\nsetting in multi-agent reinforcement learning (MARL). In this paper, we\nconsider decentralized MARL in stochastic games in the non-asymptotic regime.\nIn particular, we establish the finite-sample complexity of fully decentralized\nQ-learning algorithms in a significant class of general-sum stochastic games\n(SGs) - weakly acyclic SGs, which includes the common cooperative MARL setting\nwith an identical reward to all agents (a Markov team problem) as a special\ncase. We focus on the practical while challenging setting of fully\ndecentralized MARL, where neither the rewards nor the actions of other agents\ncan be observed by each agent. In fact, each agent is completely oblivious to\nthe presence of other decision makers. Both the tabular and the linear function\napproximation cases have been considered. In the tabular setting, we analyze\nthe sample complexity for the decentralized Q-learning algorithm to converge to\na Markov perfect equilibrium (Nash equilibrium). With linear function\napproximation, the results are for convergence to a linear approximated\nequilibrium - a new notion of equilibrium that we propose - which describes\nthat each agent's policy is a best reply (to other agents) within a linear\nspace. Numerical experiments are also provided for both settings to demonstrate\nthe results.",
    "descriptor": "",
    "authors": [
      "Zuguang Gao",
      "Qianqian Ma",
      "Tamer Ba\u015far",
      "John R. Birge"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.07859"
  },
  {
    "id": "arXiv:2112.07867",
    "title": "Interscript: A dataset for interactive learning of scripts through error  feedback",
    "abstract": "How can an end-user provide feedback if a deployed structured prediction\nmodel generates inconsistent output, ignoring the structural complexity of\nhuman language? This is an emerging topic with recent progress in synthetic or\nconstrained settings, and the next big leap would require testing and tuning\nmodels in real-world settings. We present a new dataset, Interscript,\ncontaining user feedback on a deployed model that generates complex everyday\ntasks. Interscript contains 8,466 data points -- the input is a possibly\nerroneous script and a user feedback, and the output is a modified script. We\nposit two use-cases of \\ours that might significantly advance the\nstate-of-the-art in interactive learning. The dataset is available at:\nhttps://github.com/allenai/interscript.",
    "descriptor": "\nComments: AAAI'22-Workshop on Interactive Machine Learning\n",
    "authors": [
      "Niket Tandon",
      "Aman Madaan",
      "Peter Clark",
      "Keisuke Sakaguchi",
      "Yiming Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07867"
  },
  {
    "id": "arXiv:2112.07868",
    "title": "Few-shot Instruction Prompts for Pretrained Language Models to Detect  Social Biases",
    "abstract": "Detecting social bias in text is challenging due to nuance, subjectivity, and\ndifficulty in obtaining good quality labeled datasets at scale, especially\ngiven the evolving nature of social biases and society. To address these\nchallenges, we propose a few-shot instruction-based method for prompting\npre-trained language models (LMs). We select a few label-balanced exemplars\nfrom a small support repository that are closest to the query to be labeled in\nthe embedding space. We then provide the LM with instruction that consists of\nthis subset of labeled exemplars, the query text to be classified, a definition\nof bias, and prompt it to make a decision. We demonstrate that large LMs used\nin a few-shot context can detect different types of fine-grained biases with\nsimilar and sometimes superior accuracy to fine-tuned models. We observe that\nthe largest 530B parameter model is significantly more effective in detecting\nsocial bias compared to smaller models (achieving at least 20% improvement in\nAUC metric compared to other models). It also maintains a high AUC (dropping\nless than 5%) in a few-shot setting with a labeled repository reduced to as few\nas 100 samples. Large pretrained language models thus make it easier and\nquicker to build new bias detectors.",
    "descriptor": "",
    "authors": [
      "Shrimai Prabhumoye",
      "Rafal Kocielnik",
      "Mohammad Shoeybi",
      "Anima Anandkumar",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07868"
  },
  {
    "id": "arXiv:2112.07869",
    "title": "Fine-Tuning Large Neural Language Models for Biomedical Natural Language  Processing",
    "abstract": "Motivation: A perennial challenge for biomedical researchers and clinical\npractitioners is to stay abreast with the rapid growth of publications and\nmedical notes. Natural language processing (NLP) has emerged as a promising\ndirection for taming information overload. In particular, large neural language\nmodels facilitate transfer learning by pretraining on unlabeled text, as\nexemplified by the successes of BERT models in various NLP applications.\nHowever, fine-tuning such models for an end task remains challenging,\nespecially with small labeled datasets, which are common in biomedical NLP.\nResults: We conduct a systematic study on fine-tuning stability in biomedical\nNLP. We show that finetuning performance may be sensitive to pretraining\nsettings, especially in low-resource domains. Large models have potential to\nattain better performance, but increasing model size also exacerbates\nfinetuning instability. We thus conduct a comprehensive exploration of\ntechniques for addressing fine-tuning instability. We show that these\ntechniques can substantially improve fine-tuning performance for lowresource\nbiomedical NLP applications. Specifically, freezing lower layers is helpful for\nstandard BERT-BASE models, while layerwise decay is more effective for\nBERT-LARGE and ELECTRA models. For low-resource text similarity tasks such as\nBIOSSES, reinitializing the top layer is the optimal strategy. Overall,\ndomainspecific vocabulary and pretraining facilitate more robust models for\nfine-tuning. Based on these findings, we establish new state of the art on a\nwide range of biomedical NLP applications.\nAvailability and implementation: To facilitate progress in biomedical NLP, we\nrelease our state-of-the-art pretrained and fine-tuned models:\nhttps://aka.ms/BLURB.",
    "descriptor": "",
    "authors": [
      "Robert Tinn",
      "Hao Cheng",
      "Yu Gu",
      "Naoto Usuyama",
      "Xiaodong Liu",
      "Tristan Naumann",
      "Jianfeng Gao",
      "Hoifung Poon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07869"
  },
  {
    "id": "arXiv:2112.07870",
    "title": "Cross-Domain Generalization and Knowledge Transfer in Transformers  Trained on Legal Data",
    "abstract": "We analyze the ability of pre-trained language models to transfer knowledge\namong datasets annotated with different type systems and to generalize beyond\nthe domain and dataset they were trained on. We create a meta task, over\nmultiple datasets focused on the prediction of rhetorical roles. Prediction of\nthe rhetorical role a sentence plays in a case decision is an important and\noften studied task in AI & Law. Typically, it requires the annotation of a\nlarge number of sentences to train a model, which can be time-consuming and\nexpensive. Further, the application of the models is restrained to the same\ndataset it was trained on. We fine-tune language models and evaluate their\nperformance across datasets, to investigate the models' ability to generalize\nacross domains. Our results suggest that the approach could be helpful in\novercoming the cold-start problem in active or interactvie learning, and shows\nthe ability of the models to generalize across datasets and domains.",
    "descriptor": "\nComments: 11 pages, In ASAIL@ JURIX. 2020\n",
    "authors": [
      "Jaromir Savelka",
      "Hannes Westermann",
      "Karim Benyekhlef"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07870"
  },
  {
    "id": "arXiv:2112.07872",
    "title": "A Comparison of Robust Kalman Filters for Improving Wheel-Inertial  Odometry in Planetary Rovers",
    "abstract": "This paper compares the performance of adaptive and robust Kalman filter\nalgorithms in improving wheel-inertial odometry on low featured rough terrain.\nApproaches include classical adaptive and robust methods as well as variational\nmethods, which are evaluated experimentally on a wheeled rover in terrain\nsimilar to what would be encountered in planetary exploration. Variational\nfilters show improved solution accuracy compared to the classical adaptive\nfilters and are able to handle erroneous wheel odometry measurements and keep\ngood localization for longer distances without significant drift. We also show\nhow varying the parameters affects localization performance.",
    "descriptor": "",
    "authors": [
      "Shounak Das",
      "Cagri Kilic",
      "Ryan Watson",
      "Jason Gross"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.07872"
  },
  {
    "id": "arXiv:2112.07873",
    "title": "Tracing Text Provenance via Context-Aware Lexical Substitution",
    "abstract": "Text content created by humans or language models is often stolen or misused\nby adversaries. Tracing text provenance can help claim the ownership of text\ncontent or identify the malicious users who distribute misleading content like\nmachine-generated fake news. There have been some attempts to achieve this,\nmainly based on watermarking techniques. Specifically, traditional text\nwatermarking methods embed watermarks by slightly altering text format like\nline spacing and font, which, however, are fragile to cross-media transmissions\nlike OCR. Considering this, natural language watermarking methods represent\nwatermarks by replacing words in original sentences with synonyms from\nhandcrafted lexical resources (e.g., WordNet), but they do not consider the\nsubstitution's impact on the overall sentence's meaning. Recently, a\ntransformer-based network was proposed to embed watermarks by modifying the\nunobtrusive words (e.g., function words), which also impair the sentence's\nlogical and semantic coherence. Besides, one well-trained network fails on\nother different types of text content. To address the limitations mentioned\nabove, we propose a natural language watermarking scheme based on context-aware\nlexical substitution (LS). Specifically, we employ BERT to suggest LS\ncandidates by inferring the semantic relatedness between the candidates and the\noriginal sentence. Based on this, a selection strategy in terms of\nsynchronicity and substitutability is further designed to test whether a word\nis exactly suitable for carrying the watermark signal. Extensive experiments\ndemonstrate that, under both objective and subjective metrics, our watermarking\nscheme can well preserve the semantic integrity of original sentences and has a\nbetter transferability than existing methods. Besides, the proposed LS approach\noutperforms the state-of-the-art approach on the Stanford Word Substitution\nBenchmark.",
    "descriptor": "\nComments: Accepted by AAAI-2022\n",
    "authors": [
      "Xi Yang",
      "Jie Zhang",
      "Kejiang Chen",
      "Weiming Zhang",
      "Zehua Ma",
      "Feng Wang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07873"
  },
  {
    "id": "arXiv:2112.07874",
    "title": "Oracle Linguistic Graphs Complement a Pretrained Transformer Language  Model: A Cross-formalism Comparison",
    "abstract": "We examine the extent to which, in principle, linguistic graph\nrepresentations can complement and improve neural language modeling. With an\nensemble setup consisting of a pretrained Transformer and ground-truth graphs\nfrom one of 7 different formalisms, we find that, overall, semantic\nconstituency structures are most useful to language modeling performance --\noutpacing syntactic constituency structures as well as syntactic and semantic\ndependency structures. Further, effects vary greatly depending on\npart-of-speech class. In sum, our findings point to promising tendencies in\nneuro-symbolic language modeling and invite future research quantifying the\ndesign choices made by different formalisms.",
    "descriptor": "",
    "authors": [
      "Jakob Prange",
      "Nathan Schneider",
      "Lingpeng Kong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07874"
  },
  {
    "id": "arXiv:2112.07875",
    "title": "Novelty-Driven Binary Particle Swarm Optimisation for Truss Optimisation  Problems",
    "abstract": "Topology optimisation of trusses can be formulated as a combinatorial and\nmulti-modal problem in which locating distinct optimal designs allows\npractitioners to choose the best design based on their preferences. Bilevel\noptimisation has been successfully applied to truss optimisation to consider\ntopology and sizing in upper and lower levels, respectively. We introduce exact\nenumeration to rigorously analyse the topology search space and remove\nrandomness for small problems. We also propose novelty-driven binary particle\nswarm optimisation for bigger problems to discover new designs at the upper\nlevel by maximising novelty. For the lower level, we employ a reliable\nevolutionary optimiser to tackle the layout configuration aspect of the\nproblem. We consider truss optimisation problem instances where designers need\nto select the size of bars from a discrete set with respect to practice code\nconstraints. Our experimental investigations show that our approach outperforms\nthe current state-of-the-art methods and it obtains multiple high-quality\nsolutions.",
    "descriptor": "",
    "authors": [
      "Hirad Assimi",
      "Frank Neumann",
      "Markus Wagner",
      "Xiaodong Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.07875"
  },
  {
    "id": "arXiv:2112.07877",
    "title": "Learning to Transpile AMR into SPARQL",
    "abstract": "We propose a transition-based system to transpile Abstract Meaning\nRepresentation (AMR) into SPARQL for Knowledge Base Question Answering (KBQA).\nThis allows to delegate part of the abstraction problem to a strongly\npre-trained semantic parser, while learning transpiling with small amount of\npaired data. We departure from recent work relating AMR and SPARQL constructs,\nbut rather than applying a set of rules, we teach the BART model to selectively\nuse these relations. Further, we avoid explicitly encoding AMR but rather\nencode the parser state in the attention mechanism of BART, following recent\nsemantic parsing works. The resulting model is simple, provides supporting text\nfor its decisions, and outperforms recent progress in AMR-based KBQA in LC-QuAD\n(F1 53.4), matching it in QALD (F1 30.8), while exploiting the same inductive\nbiases.",
    "descriptor": "",
    "authors": [
      "Mihaela Bornea",
      "Ramon Fernandez Astudillo",
      "Tahira Naseem",
      "Nandana Mihindukulasooriya",
      "Ibrahim Abdelaziz",
      "Pavan Kapanipathi",
      "Radu Florian",
      "Salim Roukos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07877"
  },
  {
    "id": "arXiv:2112.07878",
    "title": "Gaze Estimation with Eye Region Segmentation and Self-Supervised  Multistream Learning",
    "abstract": "We present a novel multistream network that learns robust eye representations\nfor gaze estimation. We first create a synthetic dataset containing eye region\nmasks detailing the visible eyeball and iris using a simulator. We then perform\neye region segmentation with a U-Net type model which we later use to generate\neye region masks for real-world eye images. Next, we pretrain an eye image\nencoder in the real domain with self-supervised contrastive learning to learn\ngeneralized eye representations. Finally, this pretrained eye encoder, along\nwith two additional encoders for visible eyeball region and iris, are used in\nparallel in our multistream framework to extract salient features for gaze\nestimation from real-world images. We demonstrate the performance of our method\non the EYEDIAP dataset in two different evaluation settings and achieve\nstate-of-the-art results, outperforming all the existing benchmarks on this\ndataset. We also conduct additional experiments to validate the robustness of\nour self-supervised network with respect to different amounts of labeled data\nused for training.",
    "descriptor": "\nComments: 5 pages, 1 figure, 3 tables, Accepted in AAAI-22 Workshop on Human-Centric Self-Supervised Learning\n",
    "authors": [
      "Zunayed Mahmud",
      "Paul Hungler",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07878"
  },
  {
    "id": "arXiv:2112.07879",
    "title": "Does a Face Mask Protect my Privacy?: Deep Learning to Predict Protected  Attributes from Masked Face Images",
    "abstract": "Contactless and efficient systems are implemented rapidly to advocate\npreventive methods in the fight against the COVID-19 pandemic. Despite the\npositive benefits of such systems, there is potential for exploitation by\ninvading user privacy. In this work, we analyse the privacy invasiveness of\nface biometric systems by predicting privacy-sensitive soft-biometrics using\nmasked face images. We train and apply a CNN based on the ResNet-50\narchitecture with 20,003 synthetic masked images and measure the privacy\ninvasiveness. Despite the popular belief of the privacy benefits of wearing a\nmask among people, we show that there is no significant difference to privacy\ninvasiveness when a mask is worn. In our experiments we were able to accurately\npredict sex (94.7%),race (83.1%) and age (MAE 6.21 and RMSE 8.33) from masked\nface images. Our proposed approach can serve as a baseline utility to evaluate\nthe privacy-invasiveness of artificial intelligence systems that make use of\nprivacy-sensitive information. We open-source all contributions for\nre-producibility and broader use by the research community.",
    "descriptor": "\nComments: Accepted to AJCAI 2021 - 34th Australasian Joint Conference on Artificial Intelligence, Feb 2022, Sydney, Australia\n",
    "authors": [
      "Sachith Seneviratne",
      "Nuran Kasthuriarachchi",
      "Sanka Rasnayaka",
      "Danula Hettiachchi",
      "Ridwan Shariffdeen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.07879"
  },
  {
    "id": "arXiv:2112.07880",
    "title": "An Empirical Lower Bound on the Overheads of Production Garbage  Collectors",
    "abstract": "Despite the long history of garbage collection (GC) and its prevalence in\nmodern programming languages, there is surprisingly little clarity about its\ntrue overheads. Even when evaluated using modern, well-established\nmethodologies, crucial tradeoffs made by GCs can go unnoticed, which leads to\nmisinterpretation of evaluation results. In this paper, we 1) develop a\nmethodology that allows us to place a lower bound on the absolute overhead\n(LBO) of GCs, and 2) expose key performance tradeoffs of five production GCs in\nOpenJDK 17, a high-performance Java runtime. We find that with a modest heap\nsize and across a diverse suite of modern benchmarks, production GCs incur\nsubstantial overheads, spending 7-82% more wall-clock time and 6-92% more CPU\ncycles relative to a zero-cost GC scheme. We show that these overheads can be\nmasked by concurrency and generous provision of memory/compute. In addition, we\nfind that newer low-pause GCs are significantly more expensive than older GCs,\nand sometimes even deliver worse application latency than stop-the-world GCs.\nOur findings reaffirm that GC is by no means a solved problem and that a\nlow-cost, low-latency GC remains elusive. We recommend adopting the LBO\nmethodology and using a wider range of cost metrics for future GC evaluations.\nThis will not only help the community more comprehensively understand the\nperformance characteristics of different GCs, but also reveal opportunities for\nfuture GC optimizations.",
    "descriptor": "\nComments: Under submission\n",
    "authors": [
      "Zixian Cai",
      "Stephen M. Blackburn",
      "Michael D. Bond",
      "Martin Maas"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.07880"
  },
  {
    "id": "arXiv:2112.07882",
    "title": "Lex Rosetta: Transfer of Predictive Models Across Languages,  Jurisdictions, and Legal Domains",
    "abstract": "In this paper, we examine the use of multi-lingual sentence embeddings to\ntransfer predictive models for functional segmentation of adjudicatory\ndecisions across jurisdictions, legal systems (common and civil law),\nlanguages, and domains (i.e. contexts). Mechanisms for utilizing linguistic\nresources outside of their original context have significant potential benefits\nin AI & Law because differences between legal systems, languages, or traditions\noften block wider adoption of research outcomes. We analyze the use of\nLanguage-Agnostic Sentence Representations in sequence labeling models using\nGated Recurrent Units (GRUs) that are transferable across languages. To\ninvestigate transfer between different contexts we developed an annotation\nscheme for functional segmentation of adjudicatory decisions. We found that\nmodels generalize beyond the contexts on which they were trained (e.g., a model\ntrained on administrative decisions from the US can be applied to criminal law\ndecisions from Italy). Further, we found that training the models on multiple\ncontexts increases robustness and improves overall performance when evaluating\non previously unseen contexts. Finally, we found that pooling the training data\nfrom all the contexts enhances the models' in-context performance.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Jaromir Savelka",
      "Hannes Westermann",
      "Karim Benyekhlef",
      "Charlotte S. Alexander",
      "Jayla C. Grant",
      "David Restrepo Amariles",
      "Rajaa El Hamdani",
      "S\u00e9bastien Mee\u00f9s",
      "Micha\u0142 Araszkiewicz",
      "Kevin D. Ashley",
      "Alexandra Ashley",
      "Karl Branting",
      "Mattia Falduti",
      "Matthias Grabmair",
      "Jakub Hara\u0161ta",
      "Tereza Novotn\u00e1",
      "Elizabeth Tippett",
      "Shiwanni Johnson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07882"
  },
  {
    "id": "arXiv:2112.07887",
    "title": "Knowledge-Rich Self-Supervised Entity Linking",
    "abstract": "Entity linking faces significant challenges, such as prolific variations and\nprevalent ambiguities, especially in high-value domains with myriad entities.\nStandard classification approaches suffer from the annotation bottleneck and\ncannot effectively handle unseen entities. Zero-shot entity linking has emerged\nas a promising direction for generalizing to new entities, but it still\nrequires example gold entity mentions during training and canonical\ndescriptions for all entities, both of which are rarely available outside of\nWikipedia. In this paper, we explore Knowledge-RIch Self-Supervision ($\\tt\nKRISS$) for entity linking, by leveraging readily available domain knowledge.\nIn training, it generates self-supervised mention examples on unlabeled text\nusing a domain ontology and trains a contextual encoder using contrastive\nlearning. For inference, it samples self-supervised mentions as prototypes for\neach entity and conducts linking by mapping the test mention to the most\nsimilar prototype. Our approach subsumes zero-shot and few-shot methods, and\ncan easily incorporate entity descriptions and gold mention labels if\navailable. Using biomedicine as a case study, we conducted extensive\nexperiments on seven standard datasets spanning biomedical literature and\nclinical notes. Without using any labeled information, our method produces $\\tt\nKRISSBERT$, a universal entity linker for four million UMLS entities, which\nattains new state of the art, outperforming prior self-supervised methods by as\nmuch as over 20 absolute points in accuracy.",
    "descriptor": "",
    "authors": [
      "Sheng Zhang",
      "Hao Cheng",
      "Shikhar Vashishth",
      "Cliff Wong",
      "Jinfeng Xiao",
      "Xiaodong Liu",
      "Tristan Naumann",
      "Jianfeng Gao",
      "Hoifung Poon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07887"
  },
  {
    "id": "arXiv:2112.07888",
    "title": "Event Linking: Grounding Event Mentions to Wikipedia",
    "abstract": "Comprehending an article requires understanding its constituent events.\nHowever, the context where an event is mentioned often lacks the details of\nthis event. Then, where can we obtain more knowledge of this particular event\nin addition to its context? This work defines Event Linking, a new natural\nlanguage understanding task at the event level. Event linking tries to link an\nevent mention, appearing in a news article for example, to the most appropriate\nWikipedia page. This page is expected to provide rich knowledge about what the\nevent refers to. To standardize the research of this new problem, we contribute\nin three-fold. First, this is the first work in the community that formally\ndefines event linking task. Second, we collect a dataset for this new task. In\nspecific, we first gather training set automatically from Wikipedia, then\ncreate two evaluation sets: one from the Wikipedia domain as well, reporting\nthe in-domain performance; the other from the real-world news domain, testing\nthe out-of-domain performance. Third, we propose EveLINK, the first-ever Event\nLinking approach. Overall, event linking is a considerably challenging task\nrequiring more effort from the community. Data and code are available here:\nhttps://github.com/CogComp/event-linking.",
    "descriptor": "\nComments: 9 pages, 9 tables, 1 figure\n",
    "authors": [
      "Xiaodong Yu",
      "Wenpeng Yin",
      "Nitish Gupta",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07888"
  },
  {
    "id": "arXiv:2112.07890",
    "title": "Investigating myocardial infarction and its effects in patients with  urgent medical problems using advanced data mining tools",
    "abstract": "In medical science, it is very important to gather multiple data on different\ndiseases and one of the most important objectives of the data is to investigate\nthe diseases. Myocardial infarction is a serious risk factor in mortality and\nin previous studies, the main emphasis has been on people with heart disease\nand measuring the likelihood of myocardial infarction in them through\ndemographic features, echocardiography, and electrocardiogram. In contrast, the\npurpose of the present study is to utilize data analysis algorithms and compare\ntheir accuracy in patients with a heart attack in order to identify the heart\nmuscle strength during myocardial infarction by taking into account emergency\noperations and consequently predict myocardial infarction. For this purpose,\n105 medical records of myocardial infarction patients with fourteen features\nincluding age, the time of emergency operation, Creatine Phosphokinase (CPK)\ntest, heart rate, blood sugar, and vein are gathered and investigated through\nclassification techniques of data analysis including random decision forests,\ndecision tree, support vector machine (SVM), k-nearest neighbor, and ordinal\nlogistic regression. Finally, the model of random decision forests with an\naccuracy of 76% is selected as the best model in terms of the mean evaluation\nindicator. Also, seven features of the creatine Phosphokinase test, urea, white\nand red blood cell count, blood sugar, time, and hemoglobin are identified as\nthe most effective features of the ejection fraction variable.",
    "descriptor": "",
    "authors": [
      "Tanya Aghazadeh",
      "Mostafa Bagheri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07890"
  },
  {
    "id": "arXiv:2112.07891",
    "title": "Zero-shot Audio Source Separation through Query-based Learning from  Weakly-labeled Data",
    "abstract": "Deep learning techniques for separating audio into different sound sources\nface several challenges. Standard architectures require training separate\nmodels for different types of audio sources. Although some universal separators\nemploy a single model to target multiple sources, they have difficulty\ngeneralizing to unseen sources. In this paper, we propose a three-component\npipeline to train a universal audio source separator from a large, but\nweakly-labeled dataset: AudioSet. First, we propose a transformer-based sound\nevent detection system for processing weakly-labeled training data. Second, we\ndevise a query-based audio separation model that leverages this data for model\ntraining. Third, we design a latent embedding processor to encode queries that\nspecify audio targets for separation, allowing for zero-shot generalization.\nOur approach uses a single model for source separation of multiple sound types,\nand relies solely on weakly-labeled data for training. In addition, the\nproposed audio separator can be used in a zero-shot setting, learning to\nseparate types of audio sources that were never seen in training. To evaluate\nthe separation performance, we test our model on MUSDB18, while training on the\ndisjoint AudioSet. We further verify the zero-shot performance by conducting\nanother experiment on audio source types that are held-out from training. The\nmodel achieves comparable Source-to-Distortion Ratio (SDR) performance to\ncurrent supervised models in both cases.",
    "descriptor": "\nComments: 9 pages, 3 figures, 5 tables, preprint version for Association for the Advancement of Artificial Intelligence Conference, AAAI 2022\n",
    "authors": [
      "Ke Chen",
      "Xingjian Du",
      "Bilei Zhu",
      "Zejun Ma",
      "Taylor Berg-kirkpatrick",
      "Shlomo Dubnov"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.07891"
  },
  {
    "id": "arXiv:2112.07893",
    "title": "Graph-based Ensemble Machine Learning for Student Performance Prediction",
    "abstract": "Student performance prediction is a critical research problem to understand\nthe students' needs, present proper learning opportunities/resources, and\ndevelop the teaching quality. However, traditional machine learning methods\nfail to produce stable and accurate prediction results. In this paper, we\npropose a graph-based ensemble machine learning method that aims to improve the\nstability of single machine learning methods via the consensus of multiple\nmethods. To be specific, we leverage both supervised prediction methods and\nunsupervised clustering methods, build an iterative approach that propagates in\na bipartite graph as well as converges to more stable and accurate prediction\nresults. Extensive experiments demonstrate the effectiveness of our proposed\nmethod in predicting more accurate student performance. Specifically, our model\noutperforms the best traditional machine learning algorithms by up to 14.8% in\nprediction accuracy.",
    "descriptor": "\nComments: 5 pages, 3 figures and 3 tables\n",
    "authors": [
      "Yinkai Wang",
      "Aowei Ding",
      "Kaiyi Guan",
      "Shixi Wu",
      "Yuanqi Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.07893"
  },
  {
    "id": "arXiv:2112.07894",
    "title": "Forgiveness is an Adaptation in Iterated Prisoner's Dilemma with Memory",
    "abstract": "The Prisoner's Dilemma is used to represent many real life phenomena whether\nfrom the civilized world of humans or from the wild life of the other living.\nResearchers working on iterated prisoner's dilemma (IPD) with limited memory\ninspected the outcome of different forgetting strategies in homogeneous\nenvironment, within which all agents adopt the same forgetting strategy at a\ntime. In this work, with the intention to represent real life more\nrealistically, we improve existing forgetting strategies, offer new ones, and\nconduct experiments in heterogeneous environment that contains mixed agents and\ncompare the results with previous research as well as homogeneous environment.\nOur findings show that the outcome depends on the type of the environment, and\nis just the opposite for homogeneous and heterogeneous ones, opposing the\nexisting literature in IPD. Consequently, forgetting and forgiving defectors is\nthe supreme memory management strategy in a competitive, heterogeneous\nenvironment. Therefore, forgiveness is an adaptation.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Meliksah Turker",
      "Haluk O. Bingol"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.07894"
  },
  {
    "id": "arXiv:2112.07895",
    "title": "Robust Depth Completion with Uncertainty-Driven Loss Functions",
    "abstract": "Recovering a dense depth image from sparse LiDAR scans is a challenging task.\nDespite the popularity of color-guided methods for sparse-to-dense depth\ncompletion, they treated pixels equally during optimization, ignoring the\nuneven distribution characteristics in the sparse depth map and the accumulated\noutliers in the synthesized ground truth. In this work, we introduce\nuncertainty-driven loss functions to improve the robustness of depth completion\nand handle the uncertainty in depth completion. Specifically, we propose an\nexplicit uncertainty formulation for robust depth completion with Jeffrey's\nprior. A parametric uncertain-driven loss is introduced and translated to new\nloss functions that are robust to noisy or missing data. Meanwhile, we propose\na multiscale joint prediction model that can simultaneously predict depth and\nuncertainty maps. The estimated uncertainty map is also used to perform\nadaptive prediction on the pixels with high uncertainty, leading to a residual\nmap for refining the completion results. Our method has been tested on KITTI\nDepth Completion Benchmark and achieved the state-of-the-art robustness\nperformance in terms of MAE, IMAE, and IRMSE metrics.",
    "descriptor": "\nComments: accepted by AAAI2022\n",
    "authors": [
      "Yufan Zhu",
      "Weisheng Dong",
      "Leida Li",
      "Jinjian Wu",
      "Xin Li",
      "Guangming Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07895"
  },
  {
    "id": "arXiv:2112.07897",
    "title": "Learning Graph Partitions",
    "abstract": "Given a partition of a graph into connected components, the membership oracle\nasserts whether any two vertices of the graph lie in the same component or not.\nWe prove that for $n\\ge k\\ge 2$, learning the components of an $n$-vertex\nhidden graph with $k$ components requires at least $\\frac{1}{2}(n-k)(k-1)$\nmembership queries. This proves the optimality of the $O(nk)$ algorithm\nproposed by Reyzin and Srivastava (2007) for this problem, improving on the\nbest known information-theoretic bound of $\\Omega(n\\log k)$ queries. Further,\nwe construct an oracle that can learn the number of components of $G$ in\nasymptotically fewer queries than learning the full partition, thus answering\nanother question posed by the same authors. Lastly, we introduce a more\napplicable version of this oracle, and prove asymptotically tight bounds of\n$\\widetilde\\Theta(m)$ queries for both learning and verifying an $m$-edge\nhidden graph $G$ using this oracle.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Sayan Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.07897"
  },
  {
    "id": "arXiv:2112.07899",
    "title": "Large Dual Encoders Are Generalizable Retrievers",
    "abstract": "It has been shown that dual encoders trained on one domain often fail to\ngeneralize to other domains for retrieval tasks. One widespread belief is that\nthe bottleneck layer of a dual encoder, where the final score is simply a\ndot-product between a query vector and a passage vector, is too limited to make\ndual encoders an effective retrieval model for out-of-domain generalization. In\nthis paper, we challenge this belief by scaling up the size of the dual encoder\nmodel {\\em while keeping the bottleneck embedding size fixed.} With multi-stage\ntraining, surprisingly, scaling up the model size brings significant\nimprovement on a variety of retrieval tasks, especially for out-of-domain\ngeneralization. Experimental results show that our dual encoders,\n\\textbf{G}eneralizable \\textbf{T}5-based dense \\textbf{R}etrievers (GTR),\noutperform %ColBERT~\\cite{khattab2020colbert} and existing sparse and dense\nretrievers on the BEIR dataset~\\cite{thakur2021beir} significantly. Most\nsurprisingly, our ablation study finds that GTR is very data efficient, as it\nonly needs 10\\% of MS Marco supervised data to achieve the best out-of-domain\nperformance. All the GTR models are released at\nhttps://tfhub.dev/google/collections/gtr/1.",
    "descriptor": "",
    "authors": [
      "Jianmo Ni",
      "Chen Qu",
      "Jing Lu",
      "Zhuyun Dai",
      "Gustavo Hern\u00e1ndez \u00c1brego",
      "Ji Ma",
      "Vincent Y. Zhao",
      "Yi Luan",
      "Keith B. Hall",
      "Ming-Wei Chang",
      "Yinfei Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07899"
  },
  {
    "id": "arXiv:2112.07900",
    "title": "Environmental force sensing enables robots to traverse cluttered  obstacles with interaction",
    "abstract": "Many applications require robots to move through terrain with large\nobstacles, such as self-driving, search and rescue, and extraterrestrial\nexploration. Although robots are already excellent at avoiding sparse\nobstacles, they still struggle in traversing cluttered obstacles. Inspired by\ncockroaches that use and respond to physical interaction with obstacles in\nvarious ways to traverse grass-like beams with different stiffness, here we\ndeveloped a physics model of a minimalistic robot capable of environmental\nforce sensing propelled forward to traverse two beams to simulate and\nunderstand the traversal of cluttered obstacles. Beam properties like stiffness\nand deflection locations could be estimated from the noisy beam contact forces\nmeasured, whose fidelity increased with sensing time. Using these estimates,\nthe model predicted the cost of traversal defined using potential energy\nbarriers and used it to plan and control the robot to generate and track a\ntrajectory to traverse with minimal cost. When encountering stiff beams, the\nsimulation robot transitioned from a more costly pitch mode to a less costly\nroll mode to traverse. When encountering flimsy beams, it chose to push cross\nbeams with less energy cost than avoiding beams. Finally, we developed a\nphysical robot and demonstrated the usefulness of the estimation method.",
    "descriptor": "",
    "authors": [
      "Qihan Xuan",
      "Yaqing Wang",
      "Chen Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.07900"
  },
  {
    "id": "arXiv:2112.07903",
    "title": "Optimal Combinatorial Neural Codes with Matched Metric $\u03b4_{r}$:  Characterization and Constructions",
    "abstract": "Based on the theoretical neuroscience, G. Cotardo and A. Ravagnavi in\n\\cite{CR} introduced a kind of asymmetric binary codes called combinatorial\nneural codes (CN codes for short), with a \"matched metric\" $\\delta_{r}$ called\nasymmetric discrepancy, instead of the Hamming distance $d_{H}$ for usual\nerror-correcting codes. They also presented the Hamming, Singleton and Plotkin\nbounds for CN codes with respect to $\\delta_{r}$ and asked how to construct the\nCN codes $\\cC$ with large size $|\\cC|$ and $\\delta_{r}(\\cC).$ In this paper we\nfirstly show that a binary code $\\cC$ reaches one of the above bounds for\n$\\delta_{r}(\\cC)$ if and only if $\\cC$ reaches the corresponding bounds for\n$d_H$ and $r$ is sufficiently closed to 1. This means that all optimal CN codes\ncome from the usual optimal codes. %(perfect codes, MDS codes or the codes meet\nthe usual Plotkin bound). Secondly we present several constructions of CN codes\nwith nice and flexible parameters $(n,K, \\delta_r(\\cC))$ by using bent\nfunctions.",
    "descriptor": "\nComments: 19pages,two figures,regular paper\n",
    "authors": [
      "Aixian Zhang",
      "Xiaoyan Jin",
      "Keqin Feng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.07903"
  },
  {
    "id": "arXiv:2112.07909",
    "title": "Homography Decomposition Networks for Planar Object Tracking",
    "abstract": "Planar object tracking plays an important role in AI applications, such as\nrobotics, visual servoing, and visual SLAM. Although the previous planar\ntrackers work well in most scenarios, it is still a challenging task due to the\nrapid motion and large transformation between two consecutive frames. The\nessential reason behind this problem is that the condition number of such a\nnon-linear system changes unstably when the searching range of the homography\nparameter space becomes larger. To this end, we propose a novel Homography\nDecomposition Networks~(HDN) approach that drastically reduces and stabilizes\nthe condition number by decomposing the homography transformation into two\ngroups. Specifically, a similarity transformation estimator is designed to\npredict the first group robustly by a deep convolution equivariant network. By\ntaking advantage of the scale and rotation estimation with high confidence, a\nresidual transformation is estimated by a simple regression model. Furthermore,\nthe proposed end-to-end network is trained in a semi-supervised fashion.\nExtensive experiments show that our proposed approach outperforms the\nstate-of-the-art planar tracking methods at a large margin on the challenging\nPOT, UCSB and POIC datasets.",
    "descriptor": "\nComments: Accepted at AAAI 2022, preprint version\n",
    "authors": [
      "Xinrui Zhan",
      "Yueran Liu",
      "Jianke Zhu",
      "Yang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.07909"
  },
  {
    "id": "arXiv:2112.07910",
    "title": "Decoupling Zero-Shot Semantic Segmentation",
    "abstract": "Zero-shot semantic segmentation (ZS3) aims to segment the novel categories\nthat have not been seen in the training. Existing works formulate ZS3 as a\npixel-level zero-shot classification problem, and transfer semantic knowledge\nfrom seen classes to unseen ones with the help of language models pre-trained\nonly with texts. While simple, the pixel-level ZS3 formulation shows the\nlimited capability to integrate vision-language models that are often\npre-trained with image-text pairs and currently demonstrate great potential for\nvision tasks. Inspired by the observation that humans often perform\nsegment-level semantic labeling, we propose to decouple the ZS3 into two\nsub-tasks: 1) a class-agnostic grouping task to group the pixels into segments.\n2) a zero-shot classification task on segments. The former sub-task does not\ninvolve category information and can be directly transferred to group pixels\nfor unseen classes. The latter subtask performs at segment-level and provides a\nnatural way to leverage large-scale vision-language models pre-trained with\nimage-text pairs (e.g. CLIP) for ZS3. Based on the decoupling formulation, we\npropose a simple and effective zero-shot semantic segmentation model, called\nZegFormer, which outperforms the previous methods on ZS3 standard benchmarks by\nlarge margins, e.g., 35 points on the PASCAL VOC and 3 points on the COCO-Stuff\nin terms of mIoU for unseen classes. Code will be released at\nhttps://github.com/dingjiansw101/ZegFormer.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Jian Ding",
      "Nan Xue",
      "Gui-Song Xia",
      "Dengxin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07910"
  },
  {
    "id": "arXiv:2112.07913",
    "title": "A Comparative Analysis of Machine Learning Approaches for Automated Face  Mask Detection During COVID-19",
    "abstract": "The World Health Organization (WHO) has recommended wearing face masks as one\nof the most effective measures to prevent COVID-19 transmission. In many\ncountries, it is now mandatory to wear face masks, specially in public places.\nSince manual monitoring of face masks is often infeasible in the middle of the\ncrowd, automatic detection can be beneficial. To facilitate that, we explored a\nnumber of deep learning models (i.e., VGG1, VGG19, ResNet50) for face-mask\ndetection and evaluated them on two benchmark datasets. We also evaluated\ntransfer learning (i.e., VGG19, ResNet50 pre-trained on ImageNet) in this\ncontext. We find that while the performances of all the models are quite good,\ntransfer learning models achieve the best performance. Transfer learning\nimproves the performance by 0.10\\%--0.40\\% with 30\\% less training time. Our\nexperiment also shows these high-performing models are not quite robust for\nreal-world cases where the test dataset comes from a different distribution.\nWithout any fine-tuning, the performance of these models drops by 47\\% in\ncross-domain settings.",
    "descriptor": "",
    "authors": [
      "Junaed Younus Khan",
      "Md Abdullah Al Alamin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07913"
  },
  {
    "id": "arXiv:2112.07914",
    "title": "ZHED is NP-complete",
    "abstract": "We prove that the 2017 puzzle game ZHED is NP-complete, even with just 1\ntiles. Such a puzzle is defined by a set of unit-square 1 tiles in a square\ngrid, and a target square of the grid. A move consists of selecting an\nunselected 1 tile and then filling the next unfilled square in a chosen\ndirection from that tile (similar to Tipover and Cross Purposes). We prove\nNP-completeness of deciding whether the target square can be filled, by a\nreduction from rectilinear planar monotone 3SAT.",
    "descriptor": "",
    "authors": [
      "Sagnik Saha",
      "Erik D. Demaine"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.07914"
  },
  {
    "id": "arXiv:2112.07916",
    "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences",
    "abstract": "Recent work has shown that either (1) increasing the input length or (2)\nincreasing model size can improve the performance of Transformer-based neural\nmodels. In this paper, we present a new model, called LongT5, with which we\nexplore the effects of scaling both the input length and model size at the same\ntime. Specifically, we integrated attention ideas from long-input transformers\n(ETC), and adopted pre-training strategies from summarization pre-training\n(PEGASUS) into the scalable T5 architecture. The result is a new attention\nmechanism we call {\\em Transient Global} (TGlobal), which mimics ETC's\nlocal/global attention mechanism, but without requiring additional side-inputs.\nWe are able to achieve state-of-the-art results on several summarization tasks\nand outperform the original T5 models on question answering tasks.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Mandy Guo",
      "Joshua Ainslie",
      "David Uthus",
      "Santiago Ontanon",
      "Jianmo Ni",
      "Yun-Hsuan Sung",
      "Yinfei Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07916"
  },
  {
    "id": "arXiv:2112.07917",
    "title": "SPTS: Single-Point Text Spotting",
    "abstract": "Almost all scene text spotting (detection and recognition) methods rely on\ncostly box annotation (e.g., text-line box, word-level box, and character-level\nbox). For the first time, we demonstrate that training scene text spotting\nmodels can be achieved with an extremely low-cost annotation of a single-point\nfor each instance. We propose an end-to-end scene text spotting method that\ntackles scene text spotting as a sequence prediction task, like language\nmodeling. Given an image as input, we formulate the desired detection and\nrecognition results as a sequence of discrete tokens and use an auto-regressive\ntransformer to predict the sequence. We achieve promising results on several\nhorizontal, multi-oriented, and arbitrarily shaped scene text benchmarks. Most\nsignificantly, we show that the performance is not very sensitive to the\npositions of the point annotation, meaning that it can be much easier to be\nannotated and automatically generated than the bounding box that requires\nprecise positions. We believe that such a pioneer attempt indicates a\nsignificant opportunity for scene text spotting applications of a much larger\nscale than previously possible.",
    "descriptor": "",
    "authors": [
      "Dezhi Peng",
      "Xinyu Wang",
      "Yuliang Liu",
      "Jiaxin Zhang",
      "Mingxin Huang",
      "Songxuan Lai",
      "Shenggao Zhu",
      "Jing Li",
      "Dahua Lin",
      "Chunhua Shen",
      "Lianwen Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07917"
  },
  {
    "id": "arXiv:2112.07918",
    "title": "M-FasterSeg: An Efficient Semantic Segmentation Network Based on Neural  Architecture Search",
    "abstract": "Image semantic segmentation technology is one of the key technologies for\nintelligent systems to understand natural scenes. As one of the important\nresearch directions in the field of visual intelligence, this technology has\nbroad application scenarios in the fields of mobile robots, drones, smart\ndriving, and smart security. However, in the actual application of mobile\nrobots, problems such as inaccurate segmentation semantic label prediction and\nloss of edge information of segmented objects and background may occur. This\npaper proposes an improved structure of a semantic segmentation network based\non a deep learning network that combines self-attention neural network and\nneural network architecture search methods. First, a neural network search\nmethod NAS (Neural Architecture Search) is used to find a semantic segmentation\nnetwork with multiple resolution branches. In the search process, combine the\nself-attention network structure module to adjust the searched neural network\nstructure, and then combine the semantic segmentation network searched by\ndifferent branches to form a fast semantic segmentation network structure, and\ninput the picture into the network structure to get the final forecast result.\nThe experimental results on the Cityscapes dataset show that the accuracy of\nthe algorithm is 69.8%, and the segmentation speed is 48/s. It achieves a good\nbalance between real-time and accuracy, can optimize edge segmentation, and has\na better performance in complex scenes. Good robustness is suitable for\npractical application.",
    "descriptor": "",
    "authors": [
      "Huiyu Kuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07918"
  },
  {
    "id": "arXiv:2112.07919",
    "title": "Sample-Efficient Sparse Phase Retrieval via Stochastic Alternating  Minimization",
    "abstract": "In this work we propose a nonconvex two-stage \\underline{s}tochastic\n\\underline{a}lternating \\underline{m}inimizing (SAM) method for sparse phase\nretrieval. The proposed algorithm is guaranteed to have an exact recovery from\n$O(s\\log n)$ samples if provided the initial guess is in a local neighbour of\nthe ground truth. Thus, the proposed algorithm is two-stage, first we estimate\na desired initial guess (e.g. via a spectral method), and then we introduce a\nrandomized alternating minimization strategy for local refinement. Also, the\nhard-thresholding pursuit algorithm is employed to solve the sparse constraint\nleast square subproblems. We give the theoretical justifications that SAM find\nthe underlying signal exactly in a finite number of iterations (no more than\n$O(\\log m)$ steps) with high probability. Further, numerical experiments\nillustrates that SAM requires less measurements than state-of-the-art\nalgorithms for sparse phase retrieval problem.",
    "descriptor": "",
    "authors": [
      "Jian-Feng Cai",
      "Yuling Jiao",
      "Xiliang Lu",
      "Juntao You"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07919"
  },
  {
    "id": "arXiv:2112.07921",
    "title": "Temporal Shuffling for Defending Deep Action Recognition Models against  Adversarial Attacks",
    "abstract": "Recently, video-based action recognition methods using convolutional neural\nnetworks (CNNs) achieve remarkable recognition performance. However, there is\nstill lack of understanding about the generalization mechanism of action\nrecognition models. In this paper, we suggest that action recognition models\nrely on the motion information less than expected, and thus they are robust to\nrandomization of frame orders. Based on this observation, we develop a novel\ndefense method using temporal shuffling of input videos against adversarial\nattacks for action recognition models. Another observation enabling our defense\nmethod is that adversarial perturbations on videos are sensitive to temporal\ndestruction. To the best of our knowledge, this is the first attempt to design\na defense method specific to video-based action recognition models.",
    "descriptor": "",
    "authors": [
      "Jaehui Hwang",
      "Huan Zhang",
      "Jun-Ho Choi",
      "Cho-Jui Hsieh",
      "Jong-Seok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07921"
  },
  {
    "id": "arXiv:2112.07922",
    "title": "Ten years of image analysis and machine learning competitions in  dementia",
    "abstract": "Machine learning methods exploiting multi-parametric biomarkers, especially\nbased on neuroimaging, have huge potential to improve early diagnosis of\ndementia and to predict which individuals are at-risk of developing dementia.\nTo benchmark algorithms in the field of machine learning and neuroimaging in\ndementia and assess their potential for use in clinical practice and clinical\ntrials, seven grand challenges have been organized in the last decade: MIRIAD,\nAlzheimer's Disease Big Data DREAM, CADDementia, Machine Learning Challenge,\nMCI Neuroimaging, TADPOLE, and the Predictive Analytics Competition. Based on\ntwo challenge evaluation frameworks, we analyzed how these grand challenges are\ncomplementing each other regarding research questions, datasets, validation\napproaches, results and impact. The seven grand challenges addressed questions\nrelated to screening, diagnosis, prediction and monitoring in (pre-clinical)\ndementia. There was little overlap in clinical questions, tasks and performance\nmetrics. Whereas this has the advantage of providing insight on a broad range\nof questions, it also limits the validation of results across challenges. In\ngeneral, winning algorithms performed rigorous data pre-processing and combined\na wide range of input features. Despite high state-of-the-art performances,\nmost of the methods evaluated by the challenges are not clinically used. To\nincrease impact, future challenges could pay more attention to statistical\nanalysis of which factors (i.e., features, models) relate to higher\nperformance, to clinical questions beyond Alzheimer's disease, and to using\ntesting data beyond the Alzheimer's Disease Neuroimaging Initiative. Given the\npotential and lessons learned in the past ten years, we are excited by the\nprospects of grand challenges in machine learning and neuroimaging for the next\nten years and beyond.",
    "descriptor": "\nComments: 12 pages, 4 tables\n",
    "authors": [
      "Esther E. Bron",
      "Stefan Klein",
      "Annika Reinke",
      "Janne M. Papma",
      "Lena Maier-Hein",
      "Daniel C. Alexander",
      "Neil P. Oxtoby"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07922"
  },
  {
    "id": "arXiv:2112.07924",
    "title": "Knowledge-Grounded Dialogue Generation with a Unified Knowledge  Representation",
    "abstract": "Knowledge-grounded dialogue systems are challenging to build due to the lack\nof training data and heterogeneous knowledge sources. Existing systems perform\npoorly on unseen topics due to limited topics covered in the training data. In\naddition, heterogeneous knowledge sources make it challenging for systems to\ngeneralize to other tasks because knowledge sources in different knowledge\nrepresentations require different knowledge encoders. To address these\nchallenges, we present PLUG, a language model that homogenizes different\nknowledge sources to a unified knowledge representation for knowledge-grounded\ndialogue generation tasks. PLUG is pre-trained on a dialogue generation task\nconditioned on a unified essential knowledge representation. It can generalize\nto different downstream knowledge-grounded dialogue generation tasks with a few\ntraining examples. The empirical evaluation on two benchmarks shows that our\nmodel generalizes well across different knowledge-grounded tasks. It can\nachieve comparable performance with state-of-the-art methods under a\nfully-supervised setting and significantly outperforms other methods in\nzero-shot and few-shot settings.",
    "descriptor": "",
    "authors": [
      "Yu Li",
      "Baolin Peng",
      "Yelong Shen",
      "Yi Mao",
      "Lars Liden",
      "Zhou Yu",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07924"
  },
  {
    "id": "arXiv:2112.07928",
    "title": "Imagine by Reasoning: A Reasoning-Based Implicit Semantic Data  Augmentation for Long-Tailed Classification",
    "abstract": "Real-world data often follows a long-tailed distribution, which makes the\nperformance of existing classification algorithms degrade heavily. A key issue\nis that samples in tail categories fail to depict their intra-class diversity.\nHumans can imagine a sample in new poses, scenes, and view angles with their\nprior knowledge even if it is the first time to see this category. Inspired by\nthis, we propose a novel reasoning-based implicit semantic data augmentation\nmethod to borrow transformation directions from other classes. Since the\ncovariance matrix of each category represents the feature transformation\ndirections, we can sample new directions from similar categories to generate\ndefinitely different instances. Specifically, the long-tailed distributed data\nis first adopted to train a backbone and a classifier. Then, a covariance\nmatrix for each category is estimated, and a knowledge graph is constructed to\nstore the relations of any two categories. Finally, tail samples are adaptively\nenhanced via propagating information from all the similar categories in the\nknowledge graph. Experimental results on CIFAR-100-LT, ImageNet-LT, and\niNaturalist 2018 have demonstrated the effectiveness of our proposed method\ncompared with the state-of-the-art methods.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Xiaohua Chen",
      "Yucan Zhou",
      "Dayan Wu",
      "Wanqian Zhang",
      "Yu Zhou",
      "Bo Li",
      "Weiping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07928"
  },
  {
    "id": "arXiv:2112.07931",
    "title": "From Noise to Feature: Exploiting Intensity Distribution as a Novel Soft  Biometric Trait for Finger Vein Recognition",
    "abstract": "Most finger vein feature extraction algorithms achieve satisfactory\nperformance due to their texture representation abilities, despite\nsimultaneously ignoring the intensity distribution that is formed by the finger\ntissue, and in some cases, processing it as background noise. In this paper, we\nexploit this kind of noise as a novel soft biometric trait for achieving better\nfinger vein recognition performance. First, a detailed analysis of the finger\nvein imaging principle and the characteristics of the image are presented to\nshow that the intensity distribution that is formed by the finger tissue in the\nbackground can be extracted as a soft biometric trait for recognition. Then,\ntwo finger vein background layer extraction algorithms and three soft biometric\ntrait extraction algorithms are proposed for intensity distribution feature\nextraction. Finally, a hybrid matching strategy is proposed to solve the issue\nof dimension difference between the primary and soft biometric traits on the\nscore level. A series of rigorous contrast experiments on three open-access\ndatabases demonstrates that our proposed method is feasible and effective for\nfinger vein recognition.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Wenxiong Kang",
      "Yuting Lu",
      "Dejian Li",
      "Wei Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07931"
  },
  {
    "id": "arXiv:2112.07934",
    "title": "Graph Representation Learning via Contrasting Cluster Assignments",
    "abstract": "With the rise of contrastive learning, unsupervised graph representation\nlearning has been booming recently, even surpassing the supervised counterparts\nin some machine learning tasks. Most of existing contrastive models for graph\nrepresentation learning either focus on maximizing mutual information between\nlocal and global embeddings, or primarily depend on contrasting embeddings at\nnode level. However, they are still not exquisite enough to comprehensively\nexplore the local and global views of network topology. Although the former\nconsiders local-global relationship, its coarse global information leads to\ngrudging cooperation between local and global views. The latter pays attention\nto node-level feature alignment, so that the role of global view appears\ninconspicuous. To avoid falling into these two extreme cases, we propose a\nnovel unsupervised graph representation model by contrasting cluster\nassignments, called as GRCCA. It is motivated to make good use of local and\nglobal information synthetically through combining clustering algorithms and\ncontrastive learning. This not only facilitates the contrastive effect, but\nalso provides the more high-quality graph information. Meanwhile, GRCCA further\nexcavates cluster-level information, which make it get insight to the elusive\nassociation between nodes beyond graph topology. Specifically, we first\ngenerate two augmented graphs with distinct graph augmentation strategies, then\nemploy clustering algorithms to obtain their cluster assignments and prototypes\nrespectively. The proposed GRCCA further compels the identical nodes from\ndifferent augmented graphs to recognize their cluster assignments mutually by\nminimizing a cross entropy loss. To demonstrate its effectiveness, we compare\nwith the state-of-the-art models in three different downstream tasks. The\nexperimental results show that GRCCA has strong competitiveness in most tasks.",
    "descriptor": "",
    "authors": [
      "Chunyang Zhang",
      "Hongyu Yao",
      "C. L. Philip Chen",
      "Yuena Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07934"
  },
  {
    "id": "arXiv:2112.07938",
    "title": "Blockchain-enabled Server-less Federated Learning",
    "abstract": "Motivated by the heterogeneous nature of devices participating in large-scale\nFederated Learning (FL) optimization, we focus on an asynchronous server-less\nFL solution empowered by Blockchain (BC) technology. In contrast to mostly\nadopted FL approaches, which assume synchronous operation, we advocate an\nasynchronous method whereby model aggregation is done as clients submit their\nlocal updates. The asynchronous setting fits well with the federated\noptimization idea in practical large-scale settings with heterogeneous clients.\nThus, it potentially leads to higher efficiency in terms of communication\noverhead and idle periods. To evaluate the learning completion delay of\nBC-enabled FL, we provide an analytical model based on batch service queue\ntheory. Furthermore, we provide simulation results to assess the performance of\nboth synchronous and asynchronous mechanisms. Important aspects involved in the\nBC-enabled FL optimization, such as the network size, link capacity, or user\nrequirements, are put together and analyzed. As our results show, the\nsynchronous setting leads to higher prediction accuracy than the asynchronous\ncase. Nevertheless, asynchronous federated optimization provides much lower\nlatency in many cases, thus becoming an appealing FL solution when dealing with\nlarge data sets, tough timing constraints (e.g., near-real-time applications),\nor highly varying training data.",
    "descriptor": "",
    "authors": [
      "Francesc Wilhelmi",
      "Lorenza Giupponi",
      "Paolo Dini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.07938"
  },
  {
    "id": "arXiv:2112.07940",
    "title": "The exploitation of Multiple Feature Extraction Techniques for Speaker  Identification in Emotional States under Disguised Voices",
    "abstract": "Due to improvements in artificial intelligence, speaker identification (SI)\ntechnologies have brought a great direction and are now widely used in a\nvariety of sectors. One of the most important components of SI is feature\nextraction, which has a substantial impact on the SI process and performance.\nAs a result, numerous feature extraction strategies are thoroughly\ninvestigated, contrasted, and analyzed. This article exploits five distinct\nfeature extraction methods for speaker identification in disguised voices under\nemotional environments. To evaluate this work significantly, three effects are\nused: high-pitched, low-pitched, and Electronic Voice Conversion (EVC).\nExperimental results reported that the concatenated Mel-Frequency Cepstral\nCoefficients (MFCCs), MFCCs-delta, and MFCCs-delta-delta is the best feature\nextraction method.",
    "descriptor": "\nComments: 5 pages, 1 figure, accepted in the 14th International Conference on Developments in eSystems Engineering, 7-10 December, 2021\n",
    "authors": [
      "Noor Ahmad Al Hindawi",
      "Ismail Shahin",
      "Ali Bou Nassif"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.07940"
  },
  {
    "id": "arXiv:2112.07941",
    "title": "DRaGon: Mining Latent Radio Channel Information from Geographical Data  Leveraging Deep Learning",
    "abstract": "Radio channel modeling is one of the most fundamental aspects in the process\nof designing, optimizing, and simulating wireless communication networks. In\nthis field, long-established approaches such as analytical channel models and\nray tracing techniques represent the de-facto standard methodologies. However,\nas demonstrated by recent results, there remains an untapped potential to\ninnovate this research field by enriching model-based approaches with machine\nlearning techniques. In this paper, we present Deep RAdio channel modeling from\nGeOinformatioN (DRaGon) as a novel machine learning-enabled method for\nautomatic generation of Radio Environmental Maps (REMs) from geographical data.\nFor achieving accurate path loss prediction results, DRaGon combines\ndetermining features extracted from a three-dimensional model of the radio\npropagation environment with raw images of the receiver area within a deep\nlearning model. In a comprehensive performance evaluation and validation\ncampaign, we compare the accuracy of the proposed approach with real world\nmeasurements, ray tracing analyses, and well-known channel models. It is found\nthat the combination of expert knowledge from the communications domain and the\ndata analysis capabilities of deep learning allows to achieve a significantly\nhigher prediction accuracy than the reference methods.",
    "descriptor": "",
    "authors": [
      "Benjamin Sliwa",
      "Melina Geis",
      "Caner Bektas",
      "Melisa Lop\u00e9z",
      "Preben Mogensen",
      "Christian Wietfeld"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.07941"
  },
  {
    "id": "arXiv:2112.07943",
    "title": "Decoding Continual Muscle Movements Related to Complex Hand Grasping  from EEG Signals",
    "abstract": "Brain-computer interface (BCI) is a practical pathway to interpret users'\nintentions by decoding motor execution (ME) or motor imagery (MI) from\nelectroencephalogram (EEG) signals. However, developing a BCI system driven by\nME or MI is challenging, particularly in the case of containing continual and\ncompound muscles movements. This study analyzes three grasping actions from EEG\nunder both ME and MI paradigms. We also investigate the classification\nperformance in offline and pseudo-online experiments. We propose a novel\napproach that uses muscle activity pattern (MAP) images for the convolutional\nneural network (CNN) to improve classification accuracy. We record the EEG and\nelectromyogram (EMG) signals simultaneously and create the MAP images by\ndecoding both signals to estimate specific hand grasping. As a result, we\nobtained an average classification accuracy of 63.6($\\pm$6.7)% in ME and\n45.8($\\pm$4.4)% in MI across all fifteen subjects for four classes. Also, we\nperformed pseudo-online experiments and obtained classification accuracies of\n60.5($\\pm$8.4)% in ME and 42.7($\\pm$6.8)% in MI. The proposed method MAP-CNN,\nshows stable classification performance, even in the pseudo-online experiment.\nWe expect that MAP-CNN could be used in various BCI applications in the future.",
    "descriptor": "\nComments: Submitted to 2022 10th IEEE International Winter Conference on Brain-Computer Interface\n",
    "authors": [
      "Jeong-Hyun Cho",
      "Byoung-Hee Kwon",
      "Byeong-Hoo Lee",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.07943"
  },
  {
    "id": "arXiv:2112.07945",
    "title": "Efficient Geometry-aware 3D Generative Adversarial Networks",
    "abstract": "Unsupervised generation of high-quality multi-view-consistent images and 3D\nshapes using only collections of single-view 2D photographs has been a\nlong-standing challenge. Existing 3D GANs are either compute-intensive or make\napproximations that are not 3D-consistent; the former limits quality and\nresolution of the generated images and the latter adversely affects multi-view\nconsistency and shape quality. In this work, we improve the computational\nefficiency and image quality of 3D GANs without overly relying on these\napproximations. For this purpose, we introduce an expressive hybrid\nexplicit-implicit network architecture that, together with other design\nchoices, synthesizes not only high-resolution multi-view-consistent images in\nreal time but also produces high-quality 3D geometry. By decoupling feature\ngeneration and neural rendering, our framework is able to leverage\nstate-of-the-art 2D CNN generators, such as StyleGAN2, and inherit their\nefficiency and expressiveness. We demonstrate state-of-the-art 3D-aware\nsynthesis with FFHQ and AFHQ Cats, among other experiments.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Eric R. Chan",
      "Connor Z. Lin",
      "Matthew A. Chan",
      "Koki Nagano",
      "Boxiao Pan",
      "Shalini De Mello",
      "Orazio Gallo",
      "Leonidas Guibas",
      "Jonathan Tremblay",
      "Sameh Khamis",
      "Tero Karras",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07945"
  },
  {
    "id": "arXiv:2112.07948",
    "title": "Transcoded Video Restoration by Temporal Spatial Auxiliary Network",
    "abstract": "In most video platforms, such as Youtube, and TikTok, the played videos\nusually have undergone multiple video encodings such as hardware encoding by\nrecording devices, software encoding by video editing apps, and single/multiple\nvideo transcoding by video application servers. Previous works in compressed\nvideo restoration typically assume the compression artifacts are caused by\none-time encoding. Thus, the derived solution usually does not work very well\nin practice. In this paper, we propose a new method, temporal spatial auxiliary\nnetwork (TSAN), for transcoded video restoration. Our method considers the\nunique traits between video encoding and transcoding, and we consider the\ninitial shallow encoded videos as the intermediate labels to assist the network\nto conduct self-supervised attention training. In addition, we employ adjacent\nmulti-frame information and propose the temporal deformable alignment and\npyramidal spatial fusion for transcoded video restoration. The experimental\nresults demonstrate that the performance of the proposed method is superior to\nthat of the previous techniques. The code is available at\nhttps://github.com/icecherylXuli/TSAN.",
    "descriptor": "\nComments: Accepted by AAAI2022\n",
    "authors": [
      "Li Xu",
      "Gang He",
      "Jinjia Zhou",
      "Jie Lei",
      "Weiying Xie",
      "Yunsong Li",
      "Yu-Wing Tai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.07948"
  },
  {
    "id": "arXiv:2112.07949",
    "title": "An Operator-Splitting Finite Element Method for the Numerical Solution  of Radiative Transfer Equation",
    "abstract": "An operator-splitting finite element scheme for the time-dependent,\nhigh-dimensional radiative transfer equation is presented in this paper. The\nstreamline upwind Petrov-Galerkin finite element method and discontinuous\nGalerkin finite element method are used for the spatial-angular discretization\nof the radiative transfer equation, whereas the implicit backward Euler scheme\nis used for temporal discretization. Error analysis of the proposed numerical\nscheme for the fully discrete radiative transfer equation is presented. The\nstability and convergence estimates for the fully discrete problem are derived.\nMoreover, an operator-splitting algorithm for numerical simulation of\nhigh-dimensional equations is also presented. The validation of the derived\nestimates and implementation is demonstrated with appropriate numerical\nexperiments.",
    "descriptor": "\nComments: 22 pages, 2 tables\n",
    "authors": [
      "Sashikumaar Ganesan",
      "Maneesh Kumar Singh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07949"
  },
  {
    "id": "arXiv:2112.07954",
    "title": "Object Pursuit: Building a Space of Objects via Discriminative Weight  Generation",
    "abstract": "We propose a framework to continuously learn object-centric representations\nfor visual learning and understanding. Existing object-centric representations\neither rely on supervisions that individualize objects in the scene, or perform\nunsupervised disentanglement that can hardly deal with complex scenes in the\nreal world. To mitigate the annotation burden and relax the constraints on the\nstatistical complexity of the data, our method leverages interactions to\neffectively sample diverse variations of an object and the corresponding\ntraining signals while learning the object-centric representations. Throughout\nlearning, objects are streamed one by one in random order with unknown\nidentities, and are associated with latent codes that can synthesize\ndiscriminative weights for each object through a convolutional hypernetwork.\nMoreover, re-identification of learned objects and forgetting prevention are\nemployed to make the learning process efficient and robust. We perform an\nextensive study of the key features of the proposed framework and analyze the\ncharacteristics of the learned representations. Furthermore, we demonstrate the\ncapability of the proposed framework in learning representations that can\nimprove label efficiency in downstream tasks. Our code and trained models will\nbe made publicly available.",
    "descriptor": "",
    "authors": [
      "Chuanyu Pan",
      "Yanchao Yang",
      "Kaichun Mo",
      "Yueqi Duan",
      "Leonidas Guibas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07954"
  },
  {
    "id": "arXiv:2112.07955",
    "title": "Channel Parameter Estimation in the Presence of Phase Noise Based on  Maximum Correntropy Criterion",
    "abstract": "Oscillator output generally has phase noise causing the output power spectral\ndensity (PSD) to disperse around a Dirac delta function. In this paper, the\nAWGN channel is considered, where the sent signal accompanying with phase noise\nis added to the channel Gaussian noise and received at the receiver.\nConventional channel estimation algorithms such as least mean square (LMS) and\nmean MSE criterion are not suitable for this channel estimation. We (i) analyze\nthis phase noise channel estimation with information theoretic learning (ITL)\ncriterion, i.e., maximum correntropy criterion (MCC), leading to robustness in\nthe channel estimator's steady state behavior; and (ii) improve the convergence\nrate by combining MSE and MCC as a novel mixed-LMS algorithm.",
    "descriptor": "\nComments: 5 pages, 5 figures, under revision by the journal of IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Amir Alizadeh",
      "Ghosheh Abed Hodtani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.07955"
  },
  {
    "id": "arXiv:2112.07957",
    "title": "FEAR: Fast, Efficient, Accurate and Robust Visual Tracker",
    "abstract": "We present FEAR, a novel, fast, efficient, accurate, and robust Siamese\nvisual tracker. We introduce an architecture block for object model adaption,\ncalled dual-template representation, and a pixel-wise fusion block to achieve\nextra flexibility and efficiency of the model. The dual-template module\nincorporates temporal information with only a single learnable parameter, while\nthe pixel-wise fusion block encodes more discriminative features with fewer\nparameters compared to standard correlation modules. By plugging-in\nsophisticated backbones with the novel modules, FEAR-M and FEAR-L trackers\nsurpass most Siamesetrackers on several academic benchmarks in both accuracy\nand efficiencies. Employed with the lightweight backbone, the optimized version\nFEAR-XS offers more than 10 times faster tracking than current Siamese trackers\nwhile maintaining near state-of-the-art results. FEAR-XS tracker is 2.4x\nsmaller and 4.3x faster than LightTrack [62] with superior accuracy. In\naddition, we expand the definition of the model efficiency by introducing a\nbenchmark on energy consumption and execution speed. Source code, pre-trained\nmodels, and evaluation protocol will be made available upon request",
    "descriptor": "",
    "authors": [
      "Vasyl Borsuk",
      "Roman Vei",
      "Orest Kupyn",
      "Tetiana Martyniuk",
      "Igor Krashenyi",
      "Ji\u0159i Matas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07957"
  },
  {
    "id": "arXiv:2112.07962",
    "title": "A learning-based approach to feature recognition of Engineering shapes",
    "abstract": "In this paper, we propose a machine learning approach to recognise\nengineering shape features such as holes, slots, etc. in a CAD mesh model. With\nthe advent of digital archiving, newer manufacturing techniques such as 3D\nprinting, scanning of components and reverse engineering, CAD data is\nproliferated in the form of mesh model representation. As the number of nodes\nand edges become larger in a mesh model as well as the possibility of presence\nof noise, direct application of graph-based approaches would not only be\nexpensive but also difficult to be tuned for noisy data. Hence, this calls for\nnewer approaches to be devised for feature recognition for CAD models\nrepresented in the form of mesh. Here, we show that a discrete version of Gauss\nmap can be used as a signature for a feature learning. We show that this\napproach not only requires fewer memory requirements but also the training time\nis quite less. As no network architecture is involved, the number of\nhyperparameters are much lesser and can be tuned in a much faster time. The\nrecognition accuracy is also very similar to that of the one obtained using 3D\nconvolutional neural networks (CNN) but in much lesser running time and storage\nrequirements. A comparison has been done with other non-network based machine\nlearning approaches to show that our approach has the highest accuracy. We also\nshow the recognition results for CAD models having multiple features as well as\ncomplex/interacting features obtained from public benchmarks. The ability to\nhandle noisy data has also been demonstrated.",
    "descriptor": "",
    "authors": [
      "Lakshmi Priya Muraleedharan",
      "Ramanathan Muthuganapathy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07962"
  },
  {
    "id": "arXiv:2112.07963",
    "title": "Towards General and Efficient Active Learning",
    "abstract": "Active learning aims to select the most informative samples to exploit\nlimited annotation budgets. Most existing work follows a cumbersome pipeline by\nrepeating the time-consuming model training and batch data selection multiple\ntimes on each dataset separately. We challenge this status quo by proposing a\nnovel general and efficient active learning (GEAL) method in this paper.\nUtilizing a publicly available model pre-trained on a large dataset, our method\ncan conduct data selection processes on different datasets with a single-pass\ninference of the same model. To capture the subtle local information inside\nimages, we propose knowledge clusters that are easily extracted from the\nintermediate features of the pre-trained network. Instead of the troublesome\nbatch selection strategy, all data samples are selected in one go by performing\nK-Center-Greedy in the fine-grained knowledge cluster level. The entire\nprocedure only requires single-pass model inference without training or\nsupervision, making our method notably superior to prior arts in terms of time\ncomplexity by up to hundreds of times. Extensive experiments widely demonstrate\nthe promising performance of our method on object detection, semantic\nsegmentation, depth estimation, and image classification.",
    "descriptor": "",
    "authors": [
      "Yichen Xie",
      "Masayoshi Tomizuka",
      "Wei Zhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07963"
  },
  {
    "id": "arXiv:2112.07966",
    "title": "Modality-Aware Triplet Hard Mining for Zero-shot Sketch-Based Image  Retrieval",
    "abstract": "This paper tackles the Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR)\nproblem from the viewpoint of cross-modality metric learning. This task has two\ncharacteristics: 1) the zero-shot setting requires a metric space with good\nwithin-class compactness and the between-class discrepancy for recognizing the\nnovel classes and 2) the sketch query and the photo gallery are in different\nmodalities. The metric learning viewpoint benefits ZS-SBIR from two aspects.\nFirst, it facilitates improvement through recent good practices in deep metric\nlearning (DML). By combining two fundamental learning approaches in DML, e.g.,\nclassification training and pairwise training, we set up a strong baseline for\nZS-SBIR. Without bells and whistles, this baseline achieves competitive\nretrieval accuracy. Second, it provides an insight that properly suppressing\nthe modality gap is critical. To this end, we design a novel method named\nModality-Aware Triplet Hard Mining (MATHM). MATHM enhances the baseline with\nthree types of pairwise learning, e.g., a cross-modality sample pair, a\nwithin-modality sample pair, and their combination.\\We also design an adaptive\nweighting method to balance these three components during training dynamically.\nExperimental results confirm that MATHM brings another round of significant\nimprovement based on the strong baseline and sets up new state-of-the-art\nperformance. For example, on the TU-Berlin dataset, we achieve 47.88+2.94%\nmAP@all and 58.28+2.34% Prec@100. Code will be publicly available at:\nhttps://github.com/huangzongheng/MATHM.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Zongheng Huang",
      "YiFan Sun",
      "Chuchu Han",
      "Changxin Gao",
      "Nong Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07966"
  },
  {
    "id": "arXiv:2112.07968",
    "title": "Science Factionalism: How Group Identity Language Affects Public  Engagement with Misinformation and Debunking Narratives on a Popular Q&A  Platform in China",
    "abstract": "Misinformation and intergroup bias are two pathologies challenging informed\ncitizenship. This paper examines how identity language is used in\nmisinformation and debunking messages about controversial science on Chinese\ndigital public sphere, and their impact on how the public engage with science.\nWe collected an eight-year time series dataset of public discussion (N=6039) on\none of the most controversial science issues in China (GMO) from a popular Q&A\nplatform, Zhihu. We found that both misinformation and debunking messages use a\nsubstantial amount of group identity languages when discussing the\ncontroversial science issue, which we define as science factionalism --\ndiscussion about science is divided by factions that are formed upon science\nattitudes. We found that posts that use science factionalism receive more\ndigital votes and comments, even among the science-savvy community in China.\nScience factionalism also increases the use of negativity in public discourse.\nWe discussed the implications of how science factionalism interacts with the\ndigital attention economy to affect public engagement with science\nmisinformation.",
    "descriptor": "",
    "authors": [
      "Kaiping Chen",
      "Yepeng Jin",
      "Anqi Shao"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.07968"
  },
  {
    "id": "arXiv:2112.07969",
    "title": "Predicting Media Memorability: Comparing Visual, Textual and Auditory  Features",
    "abstract": "This paper describes our approach to the Predicting Media Memorability task\nin MediaEval 2021, which aims to address the question of media memorability by\nsetting the task of automatically predicting video memorability. This year we\ntackle the task from a comparative standpoint, looking to gain deeper insights\ninto each of three explored modalities, and using our results from last year's\nsubmission (2020) as a point of reference. Our best performing short-term\nmemorability model (0.132) tested on the TRECVid2019 dataset -- just like last\nyear -- was a frame based CNN that was not trained on any TRECVid data, and our\nbest short-term memorability model (0.524) tested on the Memento10k dataset,\nwas a Bayesian Ride Regressor fit with DenseNet121 visual features.",
    "descriptor": "\nComments: 3 pages\n",
    "authors": [
      "Lorin Sweeney",
      "Graham Healy",
      "Alan F. Smeaton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07969"
  },
  {
    "id": "arXiv:2112.07974",
    "title": "Detail-aware Deep Clothing Animations Infused with Multi-source  Attributes",
    "abstract": "This paper presents a novel learning-based clothing deformation method to\ngenerate rich and reasonable detailed deformations for garments worn by bodies\nof various shapes in various animations. In contrast to existing learning-based\nmethods, which require numerous trained models for different garment topologies\nor poses and are unable to easily realize rich details, we use a unified\nframework to produce high fidelity deformations efficiently and easily. To\naddress the challenging issue of predicting deformations influenced by\nmulti-source attributes, we propose three strategies from novel perspectives.\nSpecifically, we first found that the fit between the garment and the body has\nan important impact on the degree of folds. We then designed an attribute\nparser to generate detail-aware encodings and infused them into the graph\nneural network, therefore enhancing the discrimination of details under diverse\nattributes. Furthermore, to achieve better convergence and avoid overly smooth\ndeformations, we proposed output reconstruction to mitigate the complexity of\nthe learning task. Experiment results show that our proposed deformation method\nachieves better performance over existing methods in terms of generalization\nability and quality of details.",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Tianxing Li",
      "Rui Shi",
      "Takashi Kanai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.07974"
  },
  {
    "id": "arXiv:2112.07980",
    "title": "Data Placement for Multi-Tenant Data Federation on the Cloud",
    "abstract": "Due to privacy concerns of users and law enforcement in data security and\nprivacy, it becomes more and more difficult to share data among organizations.\nData federation brings new opportunities to the data-related cooperation among\norganizations by providing abstract data interfaces. With the development of\ncloud computing, organizations store data on the cloud to achieve elasticity\nand scalability for data processing. The existing data placement approaches\ngenerally only consider one aspect, which is either execution time or monetary\ncost, and do not consider data partitioning for hard constraints. In this\npaper, we propose an approach to enable data processing on the cloud with the\ndata from different organizations. The approach consists of a data federation\nplatform named FedCube and a Lyapunov-based data placement algorithm. FedCube\nenables data processing on the cloud. We use the data placement algorithm to\ncreate a plan in order to partition and store data on the cloud so as to\nachieve multiple objectives while satisfying the constraints based on a\nmulti-objective cost model. The cost model is composed of two objectives, i.e.,\nreducing monetary cost and execution time. We present an experimental\nevaluation to show our proposed algorithm significantly reduces the total cost\n(up to 69.8\\%) compared with existing approaches.",
    "descriptor": "\nComments: 15 pages, 8 figures, 4 tables\n",
    "authors": [
      "Ji Liu",
      "Lei Mo",
      "Sijia Yang",
      "Jingbo Zhou",
      "Shilei Ji",
      "Haoyi Xiong",
      "Dejing Dou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.07980"
  },
  {
    "id": "arXiv:2112.07983",
    "title": "Data-Driven Models for Control Engineering Applications Using the  Koopman Operator",
    "abstract": "Within this work, we investigate how data-driven numerical approximation\nmethods of the Koopman operator can be used in practical control engineering\napplications. We refer to the method Extended Dynamic Mode Decomposition\n(EDMD), which approximates a nonlinear dynamical system as a linear model. This\nmakes the method ideal for control engineering applications, because a linear\nsystem description is often assumed for this purpose. Using academic examples,\nwe simulatively analyze the prediction performance of the learned EDMD models\nand show how relevant system properties like stability, controllability, and\nobservability are reflected by the EDMD model, which is a critical requirement\nfor a successful control design process. Subsequently, we present our\nexperimental results on a mechatronic test bench and evaluate the applicability\nto the control engineering design process. As a result, the investigated\nmethods are suitable as a low-effort alternative for the design steps of model\nbuilding and adaptation in the classical model-based controller design method.",
    "descriptor": "\nComments: accepted for: 2022 3rd International Conference on Artificial Intelligence, Robotics and Control (AIRC 2022)\n",
    "authors": [
      "Annika Junker",
      "Julia Timmermann",
      "Ansgar Tr\u00e4chtler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.07983"
  },
  {
    "id": "arXiv:2112.07984",
    "title": "Temporal Action Proposal Generation with Background Constraint",
    "abstract": "Temporal action proposal generation (TAPG) is a challenging task that aims to\nlocate action instances in untrimmed videos with temporal boundaries. To\nevaluate the confidence of proposals, the existing works typically predict\naction score of proposals that are supervised by the temporal\nIntersection-over-Union (tIoU) between proposal and the ground-truth. In this\npaper, we innovatively propose a general auxiliary Background Constraint idea\nto further suppress low-quality proposals, by utilizing the background\nprediction score to restrict the confidence of proposals. In this way, the\nBackground Constraint concept can be easily plug-and-played into existing TAPG\nmethods (e.g., BMN, GTAD). From this perspective, we propose the Background\nConstraint Network (BCNet) to further take advantage of the rich information of\naction and background. Specifically, we introduce an Action-Background\nInteraction module for reliable confidence evaluation, which models the\ninconsistency between action and background by attention mechanisms at the\nframe and clip levels. Extensive experiments are conducted on two popular\nbenchmarks, i.e., ActivityNet-1.3 and THUMOS14. The results demonstrate that\nour method outperforms state-of-the-art methods. Equipped with the existing\naction classifier, our method also achieves remarkable performance on the\ntemporal action localization task.",
    "descriptor": "\nComments: Accepted by AAAI2022. arXiv admin note: text overlap with arXiv:2105.12043\n",
    "authors": [
      "Haosen Yang",
      "Wenhao Wu",
      "Lining Wang",
      "Sheng Jin",
      "Boyang Xia",
      "Hongxun Yao",
      "Hujie Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07984"
  },
  {
    "id": "arXiv:2112.07985",
    "title": "Solving the Data Sparsity Problem in Predicting the Success of the  Startups with Machine Learning Methods",
    "abstract": "Predicting the success of startup companies is of great importance for both\nstartup companies and investors. It is difficult due to the lack of available\ndata and appropriate general methods. With data platforms like Crunchbase\naggregating the information of startup companies, it is possible to predict\nwith machine learning algorithms. Existing research suffers from the data\nsparsity problem as most early-stage startup companies do not have much data\navailable to the public. We try to leverage the recent algorithms to solve this\nproblem. We investigate several machine learning algorithms with a large\ndataset from Crunchbase. The results suggest that LightGBM and XGBoost perform\nbest and achieve 53.03% and 52.96% F1 scores. We interpret the predictions from\nthe perspective of feature contribution. We construct portfolios based on the\nmodels and achieve high success rates. These findings have substantial\nimplications on how machine learning methods can help startup companies and\ninvestors.",
    "descriptor": "",
    "authors": [
      "Dafei Yin",
      "Jing Li",
      "Gaosheng Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2112.07985"
  },
  {
    "id": "arXiv:2112.07993",
    "title": "The global landscape of phase retrieval I: perturbed amplitude models",
    "abstract": "A fundamental task in phase retrieval is to recover an unknown signal $\\vx\\in\n\\Rn$ from a set of magnitude-only measurements $y_i=\\abs{\\nj{\\va_i,\\vx}}, \\;\ni=1,\\ldots,m$. In this paper, we propose two novel perturbed amplitude models\n(PAMs) which have non-convex and quadratic-type loss function. When the\nmeasurements $ \\va_i \\in \\Rn$ are Gaussian random vectors and the number of\nmeasurements $m\\ge Cn$, we rigorously prove that the PAMs admit no spurious\nlocal minimizers with high probability, i.e., the target solution $ \\vx$ is the\nunique global minimizer (up to a global phase) and the loss function has a\nnegative directional curvature around each saddle point. Thanks to the\nwell-tamed benign geometric landscape, one can employ the vanilla gradient\ndescent method to locate the global minimizer $\\vx$ (up to a global phase)\nwithout spectral initialization. We carry out extensive numerical experiments\nto show that the gradient descent algorithm with random initialization\noutperforms state-of-the-art algorithms with spectral initialization in\nempirical success rate and convergence speed.",
    "descriptor": "\nComments: 60 pages\n",
    "authors": [
      "Jian-Feng Cai",
      "Meng Huang",
      "Dong Li",
      "Yang Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.07993"
  },
  {
    "id": "arXiv:2112.07997",
    "title": "The global landscape of phase retrieval II: quotient intensity models",
    "abstract": "A fundamental problem in phase retrieval is to reconstruct an unknown signal\nfrom a set of magnitude-only measurements. In this work we introduce three\nnovel quotient intensity-based models (QIMs) based a deep modification of the\ntraditional intensity-based models. A remarkable feature of the new loss\nfunctions is that the corresponding geometric landscape is benign under the\noptimal sampling complexity. When the measurements $ a_i\\in \\Rn$ are Gaussian\nrandom vectors and the number of measurements $m\\ge Cn$, the QIMs admit no\nspurious local minimizers with high probability, i.e., the target solution $ x$\nis the unique global minimizer (up to a global phase) and the loss function has\na negative directional curvature around each saddle point. Such benign\ngeometric landscape allows the gradient descent methods to find the global\nsolution $x$ (up to a global phase) without spectral initialization.",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Jian-Feng Cai",
      "Meng Huang",
      "Dong Li",
      "Yang Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.07997"
  },
  {
    "id": "arXiv:2112.07998",
    "title": "Multi-modal Networks Reveal Patterns of Operational Similarity of  Terrorist Organizations",
    "abstract": "Capturing dynamics of operational similarity among terrorist groups is\ncritical to provide actionable insights for counter-terrorism and intelligence\nmonitoring. Yet, in spite of its theoretical and practical relevance, research\naddressing this problem is currently lacking. We tackle this problem proposing\na novel computational framework for detecting clusters of terrorist groups\nsharing similar behaviors, focusing on groups' yearly repertoire of deployed\ntactics, attacked targets, and utilized weapons. Specifically considering those\norganizations that have plotted at least 50 attacks from 1997 to 2018,\naccounting for a total of 105 groups responsible for more than 42,000 events\nworldwide, we offer three sets of results. First, we show that over the years\nglobal terrorism has been characterized by increasing operational cohesiveness.\nSecond, we highlight that year-to-year stability in co-clustering among groups\nhas been particularly high from 2009 to 2018, indicating temporal consistency\nof similarity patterns in the last decade. Third, we demonstrate that\noperational similarity between two organizations is driven by three factors:\n(a) their overall activity; (b) the difference in the diversity of their\noperational repertoires; (c) the difference in a combined measure of diversity\nand activity. Groups' operational preferences, geographical homophily and\nideological affinity have no consistent role in determining operational\nsimilarity.",
    "descriptor": "\nComments: 42 pages, 19 figures\n",
    "authors": [
      "Gian Maria Campedelli",
      "Iain J. Cruickshank",
      "Kathleen M. Carley"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.07998"
  },
  {
    "id": "arXiv:2112.07999",
    "title": "Self-Ensembling GAN for Cross-Domain Semantic Segmentation",
    "abstract": "Deep neural networks (DNNs) have greatly contributed to the performance gains\nin semantic segmentation. Nevertheless, training DNNs generally requires large\namounts of pixel-level labeled data, which is expensive and time-consuming to\ncollect in practice. To mitigate the annotation burden, this paper proposes a\nself-ensembling generative adversarial network (SE-GAN) exploiting cross-domain\ndata for semantic segmentation. In SE-GAN, a teacher network and a student\nnetwork constitute a self-ensembling model for generating semantic segmentation\nmaps, which together with a discriminator, forms a GAN. Despite its simplicity,\nwe find SE-GAN can significantly boost the performance of adversarial training\nand enhance the stability of the model, the latter of which is a common barrier\nshared by most adversarial training-based methods. We theoretically analyze\nSE-GAN and provide an $\\mathcal O(1/\\sqrt{N})$ generalization bound ($N$ is the\ntraining sample size), which suggests controlling the discriminator's\nhypothesis complexity to enhance the generalizability. Accordingly, we choose a\nsimple network as the discriminator. Extensive and systematic experiments in\ntwo standard settings demonstrate that the proposed method significantly\noutperforms current state-of-the-art approaches. The source code of our model\nwill be available soon.",
    "descriptor": "",
    "authors": [
      "Yonghao Xu",
      "Fengxiang He",
      "Bo Du",
      "Liangpei Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07999"
  },
  {
    "id": "arXiv:2112.08000",
    "title": "Learning Submodular Objectives for Team Environmental Monitoring",
    "abstract": "In this paper, we study the well-known team orienteering problem where a\nfleet of robots collects rewards by visiting locations. Usually, the rewards\nare assumed to be known to the robots; however, in applications such as\nenvironmental monitoring or scene reconstruction, the rewards are often\nsubjective and specifying them is challenging. We propose a framework to learn\nthe unknown preferences of the user by presenting alternative solutions to\nthem, and the user provides a ranking on the proposed alternative solutions. We\nconsider the two cases for the user: 1) a deterministic user which provides the\noptimal ranking for the alternative solutions, and 2) a noisy user which\nprovides the optimal ranking according to an unknown probability distribution.\nFor the deterministic user we propose a framework to minimize a bound on the\nmaximum deviation from the optimal solution, namely regret. We adapt the\napproach to capture the noisy user and minimize the expected regret. Finally,\nwe demonstrate the importance of learning user preferences and the performance\nof the proposed methods in an extensive set of experimental results using real\nworld datasets for environmental monitoring problems.",
    "descriptor": "",
    "authors": [
      "Nils Wilde",
      "Armin Sadeghi",
      "Stephen L. Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08000"
  },
  {
    "id": "arXiv:2112.08001",
    "title": "Autoencoder-based background reconstruction and foreground segmentation  with background noise estimation",
    "abstract": "Even after decades of research, dynamic scene background reconstruction and\nforeground object segmentation are still considered as open problems due\nvarious challenges such as illumination changes, camera movements, or\nbackground noise caused by air turbulence or moving trees. We propose in this\npaper to model the background of a video sequence as a low dimensional manifold\nusing an autoencoder and to compare the reconstructed background provided by\nthis autoencoder with the original image to compute the foreground/background\nsegmentation masks. The main novelty of the proposed model is that the\nautoencoder is also trained to predict the background noise, which allows to\ncompute for each frame a pixel-dependent threshold to perform the\nbackground/foreground segmentation. Although the proposed model does not use\nany temporal or motion information, it exceeds the state of the art for\nunsupervised background subtraction on the CDnet 2014 and LASIESTA datasets,\nwith a significant improvement on videos where the camera is moving.",
    "descriptor": "",
    "authors": [
      "Bruno Sauvalle",
      "Arnaud de La Fortelle"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08001"
  },
  {
    "id": "arXiv:2112.08006",
    "title": "Consistent Depth Prediction under Various Illuminations using Dilated  Cross Attention",
    "abstract": "In this paper, we aim to solve the problem of consistent depth prediction in\ncomplex scenes under various illumination conditions. The existing indoor\ndatasets based on RGB-D sensors or virtual rendering have two critical\nlimitations - sparse depth maps (NYU Depth V2) and non-realistic illumination\n(SUN CG, SceneNet RGB-D). We propose to use internet 3D indoor scenes and\nmanually tune their illuminations to render photo-realistic RGB photos and\ntheir corresponding depth and BRDF maps, obtaining a new indoor depth dataset\ncalled Vari dataset. We propose a simple convolutional block named DCA by\napplying depthwise separable dilated convolution on encoded features to process\nglobal information and reduce parameters. We perform cross attention on these\ndilated features to retain the consistency of depth prediction under different\nilluminations. Our method is evaluated by comparing it with current\nstate-of-the-art methods on Vari dataset and a significant improvement is\nobserved in our experiments. We also conduct the ablation study, finetune our\nmodel on NYU Depth V2 and also evaluate on real-world data to further validate\nthe effectiveness of our DCA block. The code, pre-trained weights and Vari\ndataset are open-sourced.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Zitian Zhang",
      "Chuhua Xian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08006"
  },
  {
    "id": "arXiv:2112.08010",
    "title": "XCheck: a Simple, Effective and Extensible Bug Finder using  micro-grammar",
    "abstract": "We propose a simple and effective bug finder, XCheck, which is a proof of\nconcept bug-finder based on the so-called \"micro-grammar\".The key advantage of\nXCheck is its extreme simplicity and surprising effectiveness. It only consists\nof a few hundred lines of code but is capable of checking many complicated\nsoftware systems like Linux, LLVM, OpenJDK, which are written in various\ndifferent languages (e.g., C, C++, Java).",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Hanwen Zhu",
      "Junyoung Jang",
      "Xujie Si"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.08010"
  },
  {
    "id": "arXiv:2112.08012",
    "title": "Service Oriented Architecture in Enterprise Application",
    "abstract": "At present organizations try to achieve competitive advantages using\ninformation technology (IT). Organizations not only use Information technology\nto manage their internal operations but also to collaborate with their\ncustomers and suppliers. For these organizations use enterprise applications.\nAlso, organizations expect IT to address their shifting needs in on demand\nenvironment. So currently IT face challenges in integrating the various system\ninto a function that can address the organization's on-demand needs and span\nover the organizational boundaries. Now Service-Oriented Architecture (SOA)\nimagine as an architectural framework that addresses the issues on previous\nenterprise applications. This paper represents the Service-Oriented\nArchitecture in Enterprise Applications. The enterprise application gives a\nbrief idea about enterprise applications. Afterward, this paper addresses the\nmain problems faced by enterprise applications on the evolution of enterprise\napplications and the needs of service-oriented architecture in enterprise\napplications. Afterward, discuss Service Oriented Architecture and challenges\non Service Oriented Architecture.",
    "descriptor": "",
    "authors": [
      "MS. Faathima Fayaza"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.08012"
  },
  {
    "id": "arXiv:2112.08014",
    "title": "On LL(k) linear conjunctive grammars",
    "abstract": "Linear conjunctive grammars are a family of formal grammars with an explicit\nconjunction operation allowed in the rules, which is notable for its\ncomputational equivalence fo one-way real-time cellular automata, also known as\ntrellis automata. This paper investigates the LL($k$) subclass of linear\nconjunctive grammars, defined by analogy with the classical LL($k$) grammars:\nthese are grammars that admit top-down linear-time parsing with $k$-symbol\nlookahead. Two results are presented. First, every LL($k$) linear conjunctive\ngrammar can be transformed to an LL(1) linear conjunctive grammar, and,\naccordingly, the hierarchy with respect to $k$ collapses. Secondly, a parser\nfor these grammars that works in linear time and uses logarithmic space is\nconstructed, showing that the family of LL($k$) linear conjunctive languages is\ncontained in the complexity class $L$.",
    "descriptor": "",
    "authors": [
      "Ilya Olkhovsky",
      "Alexander Okhotin"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2112.08014"
  },
  {
    "id": "arXiv:2112.08018",
    "title": "MissMarple : A Novel Socio-inspired Feature-transfer Learning Deep  Network for Image Splicing Detection",
    "abstract": "In this paper we propose a novel socio-inspired convolutional neural network\n(CNN) deep learning model for image splicing detection. Based on the premise\nthat learning from the detection of coarsely spliced image regions can improve\nthe detection of visually imperceptible finely spliced image forgeries, the\nproposed model referred to as, MissMarple, is a twin CNN network involving\nfeature-transfer learning. Results obtained from training and testing the\nproposed model using the benchmark datasets like Columbia splicing, WildWeb,\nDSO1 and a proposed dataset titled AbhAS consisting of realistic splicing\nforgeries revealed improvement in detection accuracy over the existing deep\nlearning models.",
    "descriptor": "\nComments: 27 pages, 6 figures and 15 tables\n",
    "authors": [
      "Angelina L. Gokhale",
      "Dhanya Pramod",
      "Sudeep D. Thepade",
      "Ravi Kulkarni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08018"
  },
  {
    "id": "arXiv:2112.08022",
    "title": "Segmentation-Reconstruction-Guided Facial Image De-occlusion",
    "abstract": "Occlusions are very common in face images in the wild, leading to the\ndegraded performance of face-related tasks. Although much effort has been\ndevoted to removing occlusions from face images, the varying shapes and\ntextures of occlusions still challenge the robustness of current methods. As a\nresult, current methods either rely on manual occlusion masks or only apply to\nspecific occlusions. This paper proposes a novel face de-occlusion model based\non face segmentation and 3D face reconstruction, which automatically removes\nall kinds of face occlusions with even blurred boundaries,e.g., hairs. The\nproposed model consists of a 3D face reconstruction module, a face segmentation\nmodule, and an image generation module. With the face prior and the occlusion\nmask predicted by the first two, respectively, the image generation module can\nfaithfully recover the missing facial textures. To supervise the training, we\nfurther build a large occlusion dataset, with both manually labeled and\nsynthetic occlusions. Qualitative and quantitative results demonstrate the\neffectiveness and robustness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Xiangnan Yin",
      "Di Huang",
      "Zehua Fu",
      "Yunhong Wang",
      "Liming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08022"
  },
  {
    "id": "arXiv:2112.08024",
    "title": "Visually Guided UGV for Autonomous Mobile Manipulation in Dynamic and  Unstructured GPS Denied Environments",
    "abstract": "A robotic solution for the unmanned ground vehicles (UGVs) to execute the\nhighly complex task of object manipulation in an autonomous mode is presented.\nThis paper primarily focuses on developing an autonomous robotic system capable\nof assembling elementary blocks to build the large 3D structures in GPS-denied\nenvironments. The key contributions of this system paper are i) Designing of a\ndeep learning-based unified multi-task visual perception system for object\ndetection, part-detection, instance segmentation, and tracking, ii) an\nelectromagnetic gripper design for robust grasping, and iii) system integration\nin which multiple system components are integrated to develop an optimized\nsoftware stack. The entire mechatronic and algorithmic design of UGV for the\nabove application is detailed in this work. The performance and efficacy of the\noverall system are reported through several rigorous experiments.",
    "descriptor": "\nComments: Paper has been accepted for publication in International Conference On Computational Intelligence - ICCI 2021\n",
    "authors": [
      "Mohit Vohra",
      "Laxmidhar Behera"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08024"
  },
  {
    "id": "arXiv:2112.08025",
    "title": "TLogic: Temporal Logical Rules for Explainable Link Forecasting on  Temporal Knowledge Graphs",
    "abstract": "Conventional static knowledge graphs model entities in relational data as\nnodes, connected by edges of specific relation types. However, information and\nknowledge evolve continuously, and temporal dynamics emerge, which are expected\nto influence future situations. In temporal knowledge graphs, time information\nis integrated into the graph by equipping each edge with a timestamp or a time\nrange. Embedding-based methods have been introduced for link prediction on\ntemporal knowledge graphs, but they mostly lack explainability and\ncomprehensible reasoning chains. Particularly, they are usually not designed to\ndeal with link forecasting -- event prediction involving future timestamps. We\naddress the task of link forecasting on temporal knowledge graphs and introduce\nTLogic, an explainable framework that is based on temporal logical rules\nextracted via temporal random walks. We compare TLogic with state-of-the-art\nbaselines on three benchmark datasets and show better overall performance while\nour method also provides explanations that preserve time consistency.\nFurthermore, in contrast to most state-of-the-art embedding-based methods,\nTLogic works well in the inductive setting where already learned rules are\ntransferred to related datasets with a common vocabulary.",
    "descriptor": "\nComments: Accepted at AAAI 2022 (36th AAAI Conference on Artificial Intelligence)\n",
    "authors": [
      "Yushan Liu",
      "Yunpu Ma",
      "Marcel Hildebrandt",
      "Mitchell Joblin",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08025"
  },
  {
    "id": "arXiv:2112.08027",
    "title": "Speech frame implementation for speech analysis and recognition",
    "abstract": "Distinctive features of the created speech frame are: the ability to take\ninto account the emotional state of the speaker, sup-port for working with\ndiseases of the speech-forming tract of speakers and the presence of manual\nsegmentation of a num-ber of speech signals. In addition, the system is focused\non Russian-language speech material, unlike most analogs.",
    "descriptor": "\nComments: 7 pages, 27 tables\n",
    "authors": [
      "A.A. Konev",
      "V.S. Khlebnikov",
      "A. Yu. Yakimuk"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.08027"
  },
  {
    "id": "arXiv:2112.08033",
    "title": "Named entity recognition architecture combining contextual and global  features",
    "abstract": "Named entity recognition (NER) is an information extraction technique that\naims to locate and classify named entities (e.g., organizations, locations,...)\nwithin a document into predefined categories. Correctly identifying these\nphrases plays a significant role in simplifying information access. However, it\nremains a difficult task because named entities (NEs) have multiple forms and\nthey are context-dependent. While the context can be represented by contextual\nfeatures, global relations are often misrepresented by those models. In this\npaper, we propose the combination of contextual features from XLNet and global\nfeatures from Graph Convolution Network (GCN) to enhance NER performance.\nExperiments over a widely-used dataset, CoNLL 2003, show the benefits of our\nstrategy, with results competitive with the state of the art (SOTA).",
    "descriptor": "",
    "authors": [
      "Tran Thi Hong Hanh",
      "Antoine Doucet",
      "Nicolas Sidere",
      "Jose G. Moreno",
      "Senja Pollak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08033"
  },
  {
    "id": "arXiv:2112.08035",
    "title": "Meshless Monte Carlo Radiation Transfer Method for Curved Geometries  using Signed Distance Functions",
    "abstract": "Significance: Monte Carlo radiation transfer (MCRT) is the gold standard of\nmodeling light transport in turbid media. Typical MCRT models use voxels or\nmeshes to approximate experimental geometry. A voxel based geometry does not\nallow for the accurate modeling of smooth curved surfaces, such as may be found\nin biological systems or food and drink packaging.\nAim: We present our algorithm which we term signedMCRT (sMCRT), a new\ngeometry-based method which uses signed distance functions (SDF) to represent\nthe geometry of the model. SDFs are capable of modeling smooth curved surfaces\naccurately whilst also modeling complex geometries.\nApproach: We show that using SDFs to represent the problem's geometry is more\naccurate and can be faster than voxel based methods. sMCRT, can easily be\nincorporated into existing voxel based models.\nResults: sMCRT is validated against theoretical expressions, and other voxel\nbased MCRT codes. We show that sMCRT can accurately model arbitrary complex\ngeometries such as microvascular vessel network using SDFs. In comparison to\nthe current state-of-the-art in MCRT methods specifically for curved surfaces,\nsMCRT is up-to forty-five times more accurate.\nConclusions: sMCRT is a highly accurate, fast MCRT method that outperforms\ncomparable voxel based models due to its ability to model smooth curved\nsurfaces. sMCRT is up-to three times faster than a voxel model for equivalent\nscenarios. sMCRT is publicly available at\nhttps://github.com/lewisfish/signedMCRT",
    "descriptor": "",
    "authors": [
      "Lewis McMillan",
      "Graham D. Bruce",
      "Kishan Dholakia"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Physics (physics.comp-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2112.08035"
  },
  {
    "id": "arXiv:2112.08037",
    "title": "LookinGood^\u03c0: Real-time Person-independent Neural Re-rendering for  High-quality Human Performance Capture",
    "abstract": "We propose LookinGood^{\\pi}, a novel neural re-rendering approach that is\naimed to (1) improve the rendering quality of the low-quality reconstructed\nresults from human performance capture system in real-time; (2) improve the\ngeneralization ability of the neural rendering network on unseen people. Our\nkey idea is to utilize the rendered image of reconstructed geometry as the\nguidance to assist the prediction of person-specific details from few reference\nimages, thus enhancing the re-rendered result. In light of this, we design a\ntwo-branch network. A coarse branch is designed to fix some artifacts (i.e.\nholes, noise) and obtain a coarse version of the rendered input, while a detail\nbranch is designed to predict \"correct\" details from the warped references. The\nguidance of the rendered image is realized by blending features from two\nbranches effectively in the training of the detail branch, which improves both\nthe warping accuracy and the details' fidelity. We demonstrate that our method\noutperforms state-of-the-art methods at producing high-fidelity images on\nunseen people.",
    "descriptor": "",
    "authors": [
      "Xiqi Yang",
      "Kewei Yang",
      "Kang Chen",
      "Weidong Zhang",
      "Weiwei Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08037"
  },
  {
    "id": "arXiv:2112.08048",
    "title": "Dynamic Human Evaluation for Relative Model Comparisons",
    "abstract": "Collecting human judgements is currently the most reliable evaluation method\nfor natural language generation systems. Automatic metrics have reported flaws\nwhen applied to measure quality aspects of generated text and have been shown\nto correlate poorly with human judgements. However, human evaluation is time\nand cost-intensive, and we lack consensus on designing and conducting human\nevaluation experiments. Thus there is a need for streamlined approaches for\nefficient collection of human judgements when evaluating natural language\ngeneration systems. Therefore, we present a dynamic approach to measure the\nrequired number of human annotations when evaluating generated outputs in\nrelative comparison settings. We propose an agent-based framework of human\nevaluation to assess multiple labelling strategies and methods to decide the\nbetter model in a simulation and a crowdsourcing case study. The main results\nindicate that a decision about the superior model can be made with high\nprobability across different labelling strategies, where assigning a single\nrandom worker per task requires the least overall labelling effort and thus the\nleast cost.",
    "descriptor": "",
    "authors": [
      "Th\u00f3rhildur Thorleiksd\u00f3ttir",
      "Cedric Renggli",
      "Nora Hollenstein",
      "Ce Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08048"
  },
  {
    "id": "arXiv:2112.08050",
    "title": "Exploring the Asynchronous of the Frequency Spectra of GAN-generated  Facial Images",
    "abstract": "The rapid progression of Generative Adversarial Networks (GANs) has raised a\nconcern of their misuse for malicious purposes, especially in creating fake\nface images. Although many proposed methods succeed in detecting GAN-based\nsynthetic images, they are still limited by the need for large quantities of\nthe training fake image dataset and challenges for the detector's\ngeneralizability to unknown facial images. In this paper, we propose a new\napproach that explores the asynchronous frequency spectra of color channels,\nwhich is simple but effective for training both unsupervised and supervised\nlearning models to distinguish GAN-based synthetic images. We further\ninvestigate the transferability of a training model that learns from our\nsuggested features in one source domain and validates on another target domains\nwith prior knowledge of the features' distribution. Our experimental results\nshow that the discrepancy of spectra in the frequency domain is a practical\nartifact to effectively detect various types of GAN-based generated images.",
    "descriptor": "\nComments: International Workshop on Safety and Security of Deep Learning IJCAI, 2021\n",
    "authors": [
      "Binh M. Le",
      "Simon S. Woo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.08050"
  },
  {
    "id": "arXiv:2112.08052",
    "title": "Optimal Latent Space Forecasting for Large Collections of Short Time  Series Using Temporal Matrix Factorization",
    "abstract": "In the context of time series forecasting, it is a common practice to\nevaluate multiple methods and choose one of these methods or an ensemble for\nproducing the best forecasts. However, choosing among different ensembles over\nmultiple methods remains a challenging task that undergoes a combinatorial\nexplosion as the number of methods increases. In the context of demand\nforecasting or revenue forecasting, this challenge is further exacerbated by a\nlarge number of time series as well as limited historical data points available\ndue to changing business context. Although deep learning forecasting methods\naim to simultaneously forecast large collections of time series, they become\nchallenging to apply in such scenarios due to the limited history available and\nmight not yield desirable results. We propose a framework for forecasting short\nhigh-dimensional time series data by combining low-rank temporal matrix\nfactorization and optimal model selection on latent time series using\ncross-validation. We demonstrate that forecasting the latent factors leads to\nsignificant performance gains as compared to directly applying different\nuni-variate models on time series. Performance has been validated on a\ntruncated version of the M4 monthly dataset which contains time series data\nfrom multiple domains showing the general applicability of the method.\nMoreover, it is amenable to incorporating the analyst view of the future owing\nto the low number of latent factors which is usually impractical when applying\nforecasting methods directly to high dimensional datasets.",
    "descriptor": "",
    "authors": [
      "Himanshi Charotia",
      "Abhishek Garg",
      "Gaurav Dhama",
      "Naman Maheshwari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08052"
  },
  {
    "id": "arXiv:2112.08060",
    "title": "Leveraging Image-based Generative Adversarial Networks for Time Series  Generation",
    "abstract": "Generative models synthesize image data with great success regarding sampling\nquality, diversity and feature disentanglement. Generative models for time\nseries lack these benefits due to a missing representation, which captures\ntemporal dynamics and allows inversion for sampling. The paper proposes the\nintertemporal return plot (IRP) representation to facilitate the use of\nimage-based generative adversarial networks for time series generation. The\nrepresentation proves effective in capturing time series characteristics and,\ncompared to alternative representations, benefits from invertibility and\nscale-invariance. Empirical benchmarks confirm these features and demonstrate\nthat the IRP enables an off-the-shelf Wasserstein GAN with gradient penalty to\nsample realistic time series, which outperform a specialized RNN-based GAN,\nwhile simultaneously reducing model complexity.",
    "descriptor": "",
    "authors": [
      "Justin Hellermann",
      "Stefan Lessmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08060"
  },
  {
    "id": "arXiv:2112.08068",
    "title": "Head Matters: Explainable Human-centered Trait Prediction from Head  Motion Dynamics",
    "abstract": "We demonstrate the utility of elementary head-motion units termed kinemes for\nbehavioral analytics to predict personality and interview traits. Transforming\nhead-motion patterns into a sequence of kinemes facilitates discovery of latent\ntemporal signatures characterizing the targeted traits, thereby enabling both\nefficient and explainable trait prediction. Utilizing Kinemes and Facial Action\nCoding System (FACS) features to predict (a) OCEAN personality traits on the\nFirst Impressions Candidate Screening videos, and (b) Interview traits on the\nMIT dataset, we note that: (1) A Long-Short Term Memory (LSTM) network trained\nwith kineme sequences performs better than or similar to a Convolutional Neural\nNetwork (CNN) trained with facial images; (2) Accurate predictions and\nexplanations are achieved on combining FACS action units (AUs) with kinemes,\nand (3) Prediction performance is affected by the time-length over which head\nand facial movements are observed.",
    "descriptor": "\nComments: 10 pages, 10 figures, 6 tables. This paper is published in ICMI 2021\n",
    "authors": [
      "Surbhi Madan",
      "Monika Gahalawat",
      "Tanaya Guha",
      "Ramanathan Subramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08068"
  },
  {
    "id": "arXiv:2112.08069",
    "title": "Funnels: Exact maximum likelihood with dimensionality reduction",
    "abstract": "Normalizing flows are diffeomorphic, typically dimension-preserving, models\ntrained using the likelihood of the model. We use the SurVAE framework to\nconstruct dimension reducing surjective flows via a new layer, known as the\nfunnel. We demonstrate its efficacy on a variety of datasets, and show it\nimproves upon or matches the performance of existing flows while having a\nreduced latent space size. The funnel layer can be constructed from a wide\nrange of transformations including restricted convolution and feed forward\nlayers.",
    "descriptor": "\nComments: 16 pages, 5 figures, 8 tables\n",
    "authors": [
      "Samuel Klein",
      "John A. Raine",
      "Sebastian Pina-Otey",
      "Slava Voloshynovskiy",
      "Tobias Golling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08069"
  },
  {
    "id": "arXiv:2112.08070",
    "title": "Depth Refinement for Improved Stereo Reconstruction",
    "abstract": "Depth estimation is a cornerstone of a vast number of applications requiring\n3D assessment of the environment, such as robotics, augmented reality, and\nautonomous driving to name a few. One prominent technique for depth estimation\nis stereo matching which has several advantages: it is considered more\naccessible than other depth-sensing technologies, can produce dense depth\nestimates in real-time, and has benefited greatly from the advances of deep\nlearning in recent years. However, current techniques for depth estimation from\nstereoscopic images still suffer from a built-in drawback. To reconstruct\ndepth, a stereo matching algorithm first estimates the disparity map between\nthe left and right images before applying a geometric triangulation. A simple\nanalysis reveals that the depth error is quadratically proportional to the\nobject's distance. Therefore, constant disparity errors are translated to large\ndepth errors for objects far from the camera. To mitigate this quadratic\nrelation, we propose a simple but effective method that uses a refinement\nnetwork for depth estimation. We show analytical and empirical results\nsuggesting that the proposed learning procedure reduces this quadratic\nrelation. We evaluate the proposed refinement procedure on well-known\nbenchmarks and datasets, like Sceneflow and KITTI datasets, and demonstrate\nsignificant improvements in the depth accuracy metric.",
    "descriptor": "",
    "authors": [
      "Amit Bracha",
      "Noam Rotstein",
      "David Bensa\u00efd",
      "Ron Slossberg",
      "Ron Kimmel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08070"
  },
  {
    "id": "arXiv:2112.08073",
    "title": "Analysis of Leading Communities Contributing to arXiv Information  Distribution on Twitter",
    "abstract": "To analyze the impact that arXiv is having on the world, in this paper we\npropose an arXiv information distribution model on Twitter, which has a\nthree-layer structure: arXiv papers, information spreaders, and information\ncollectors. First, we use the HITS algorithm to analyze the arXiv information\ndiffusion network with users as nodes, which is created from three types of\nbehavior on Twitter regarding arXiv papers: tweeting, retweeting, and liking.\nNext, we extract communities from the network of information spreaders with\npositive authority and hub degrees using the Louvain method, and analyze the\nrelationship and roles of information spreaders in communities using research\nfield, linguistic, and temporal characteristics. From our analysis using the\ntweet and arXiv datasets, we found that information about arXiv papers\ncirculates on Twitter from information spreaders to information collectors, and\nthat multiple communities of information spreaders are formed according to\ntheir research fields. It was also found that different communities were formed\nin the same research field, depending on the research or cultural background of\nthe information spreaders. We were able to identify two types of key persons:\ninformation spreaders who lead the relevant field in the international\ncommunity and information spreaders who bridge the regional and international\ncommunities using English and their native language. In addition, we found that\nit takes some time to gain trust as an information spreader.",
    "descriptor": "\nComments: The 20th IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT '21)\n",
    "authors": [
      "Kyosuke Shimada",
      "Kazuhiro Kazama",
      "Mitsuo Yoshida",
      "Ikki Ohmukai",
      "Sho Sato"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.08073"
  },
  {
    "id": "arXiv:2112.08075",
    "title": "Fast characterization of inducible regions of atrial fibrillation models  with multi-fidelity Gaussian process classification",
    "abstract": "Computational models of atrial fibrillation have successfully been used to\npredict optimal ablation sites. A critical step to assess the effect of an\nablation pattern is to pace the model from different, potentially random,\nlocations to determine whether arrhythmias can be induced in the atria. In this\nwork, we propose to use multi-fidelity Gaussian process classification on\nRiemannian manifolds to efficiently determine the regions in the atria where\narrhythmias are inducible. We build a probabilistic classifier that operates\ndirectly on the atrial surface. We take advantage of lower resolution models to\nexplore the atrial surface and combine seamlessly with high-resolution models\nto identify regions of inducibility. When trained with 40 samples, our\nmulti-fidelity classifier shows a balanced accuracy that is 10% higher than a\nnearest neighbor classifier used as a baseline atrial fibrillation model, and\n9% higher in presence of atrial fibrillation with ablations. We hope that this\nnew technique will allow faster and more precise clinical applications of\ncomputational models for atrial fibrillation.",
    "descriptor": "\nComments: 22 pages, 7 figures\n",
    "authors": [
      "Lia Gandera",
      "Simone Pezzutoa",
      "Ali Gharaviri",
      "Rolf Krause",
      "Paris Perdikaris",
      "Francisco Sahli Costabal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2112.08075"
  },
  {
    "id": "arXiv:2112.08078",
    "title": "Joint Demand Prediction for Multimodal Systems: A Multi-task  Multi-relational Spatiotemporal Graph Neural Network Approach",
    "abstract": "Dynamic demand prediction is crucial for the efficient operation and\nmanagement of urban transportation systems. Extensive research has been\nconducted on single-mode demand prediction, ignoring the fact that the demands\nfor different transportation modes can be correlated with each other. Despite\nsome recent efforts, existing approaches to multimodal demand prediction are\ngenerally not flexible enough to account for multiplex networks with diverse\nspatial units and heterogeneous spatiotemporal correlations across different\nmodes. To tackle these issues, this study proposes a multi-relational\nspatiotemporal graph neural network (ST-MRGNN) for multimodal demand\nprediction. Specifically, the spatial dependencies across modes are encoded\nwith multiple intra- and inter-modal relation graphs. A multi-relational graph\nneural network (MRGNN) is introduced to capture cross-mode heterogeneous\nspatial dependencies, consisting of generalized graph convolution networks to\nlearn the message passing mechanisms within relation graphs and an\nattention-based aggregation module to summarize different relations. We further\nintegrate MRGNNs with temporal gated convolution layers to jointly model\nheterogeneous spatiotemporal correlations. Extensive experiments are conducted\nusing real-world subway and ride-hailing datasets from New York City, and the\nresults verify the improved performance of our proposed approach over existing\nmethods across modes. The improvement is particularly large for demand-sparse\nlocations. Further analysis of the attention mechanisms of ST-MRGNN also\ndemonstrates its good interpretability for understanding cross-mode\ninteractions.",
    "descriptor": "",
    "authors": [
      "Yuebing Liang",
      "Guan Huang",
      "Zhan Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08078"
  },
  {
    "id": "arXiv:2112.08086",
    "title": "Photonic neuromorphic computing using vertical cavity semiconductor  lasers",
    "abstract": "Photonic realizations of neural network computing hardware are a promising\napproach to enable future scalability of neuromorphic computing. In this review\nwe provide an overview on vertical-cavity surface-emitting lasers (VCSELs) and\nhow these high-performance electro-optical components either implement or are\ncombined with additional photonic hardware to demonstrate points (i-iii). In\nthe neurmorphic photonics' context, VCSELs are of exceptional interest as they\nare compatible with CMOS fabrication, readily achieve 30\\% wall-plug efficiency\nand >30~GHz modulation bandwidth and hence are highly energy efficient and\nultra-fast. Crucially, they react highly nonlinear to optical injection as well\nas to electrical modulation, making them highly suitable as all-optical as well\nas electro-optical photonic neurons. Their optical cavities are\nwavelength-limited, and standard semiconductor growth and lithography enables\nnon-classical cavity configurations and geometries. This enables excitable\nVCSELs (i.e. spiking VCSELs) to finely control their temporal and spatial\ncoherence, to unlock Terahertz bandwidths through spin-flip effects, and even\nto leverage cavity quantum electrodynamics to further boost their efficiency.\nFinally, as VCSEL arrays they are compatible with standard 2D photonic\nintegration, but their emission vertical to the substrate makes them ideally\nsuited for scalable integrated networks leveraging 3D photonic waveguides.\nHere, we discuss the implementation of spatially as well as temporally\nmultiplexed VCSEL neural networks and reservoirs, computation on the basis of\nexcitable VCSELs as photonic spiking neurons, as well as concepts and advances\nin the fabrication of VCSELs and microlasers.",
    "descriptor": "",
    "authors": [
      "Anas Skalli",
      "Joshua Robertson",
      "Dafydd Owen-Newns",
      "Matej Hejda",
      "Xavier Porte",
      "Stephan Reitzenstein",
      "Antonio Hurtado",
      "D. Brunner"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2112.08086"
  },
  {
    "id": "arXiv:2112.08087",
    "title": "Cognition-aware Cognate Detection",
    "abstract": "Automatic detection of cognates helps downstream NLP tasks of Machine\nTranslation, Cross-lingual Information Retrieval, Computational Phylogenetics\nand Cross-lingual Named Entity Recognition. Previous approaches for the task of\ncognate detection use orthographic, phonetic and semantic similarity based\nfeatures sets. In this paper, we propose a novel method for enriching the\nfeature sets, with cognitive features extracted from human readers' gaze\nbehaviour. We collect gaze behaviour data for a small sample of cognates and\nshow that extracted cognitive features help the task of cognate detection.\nHowever, gaze data collection and annotation is a costly task. We use the\ncollected gaze behaviour data to predict cognitive features for a larger sample\nand show that predicted cognitive features, also, significantly improve the\ntask performance. We report improvements of 10% with the collected gaze\nfeatures, and 12% using the predicted gaze features, over the previously\nproposed approaches. Furthermore, we release the collected gaze behaviour data\nalong with our code and cross-lingual models.",
    "descriptor": "\nComments: Published at EACL 2021\n",
    "authors": [
      "Diptesh Kanojia",
      "Prashant Sharma",
      "Sayali Ghodekar",
      "Pushpak Bhattacharyya",
      "Gholamreza Haffari",
      "Malhar Kulkarni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08087"
  },
  {
    "id": "arXiv:2112.08088",
    "title": "Image-Adaptive YOLO for Object Detection in Adverse Weather Conditions",
    "abstract": "Though deep learning-based object detection methods have achieved promising\nresults on the conventional datasets, it is still challenging to locate objects\nfrom the low-quality images captured in adverse weather conditions. The\nexisting methods either have difficulties in balancing the tasks of image\nenhancement and object detection, or often ignore the latent information\nbeneficial for detection. To alleviate this problem, we propose a novel\nImage-Adaptive YOLO (IA-YOLO) framework, where each image can be adaptively\nenhanced for better detection performance. Specifically, a differentiable image\nprocessing (DIP) module is presented to take into account the adverse weather\nconditions for YOLO detector, whose parameters are predicted by a small\nconvolutional neural net-work (CNN-PP). We learn CNN-PP and YOLOv3 jointly in\nan end-to-end fashion, which ensures that CNN-PP can learn an appropriate DIP\nto enhance the image for detection in a weakly supervised manner. Our proposed\nIA-YOLO approach can adaptively process images in both normal and adverse\nweather conditions. The experimental results are very encouraging,\ndemonstrating the effectiveness of our proposed IA-YOLO method in both foggy\nand low-light scenarios.",
    "descriptor": "\nComments: Accepted by AAAI 2022, Preprint version with Appendix\n",
    "authors": [
      "Wenyu Liu",
      "Gaofeng Ren",
      "Runsheng Yu",
      "Shi Guo",
      "Jianke Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08088"
  },
  {
    "id": "arXiv:2112.08091",
    "title": "Ensuring DNN Solution Feasibility for Optimization Problems with Convex  Constraints and Its Application to DC Optimal Power Flow Problems",
    "abstract": "Ensuring solution feasibility is a key challenge in developing Deep Neural\nNetwork (DNN) schemes for solving constrained optimization problems, due to\ninherent DNN prediction errors. In this paper, we propose a \"preventive\nlearning'\" framework to systematically guarantee DNN solution feasibility for\nproblems with convex constraints and general objective functions. We first\napply a predict-and-reconstruct design to not only guarantee equality\nconstraints but also exploit them to reduce the number of variables to be\npredicted by DNN. Then, as a key methodological contribution, we systematically\ncalibrate inequality constraints used in DNN training, thereby anticipating\nprediction errors and ensuring the resulting solutions remain feasible. We\ncharacterize the calibration magnitudes and the DNN size sufficient for\nensuring universal feasibility. We propose a new Adversary-Sample Aware\ntraining algorithm to improve DNN's optimality performance without sacrificing\nfeasibility guarantee. Overall, the framework provides two DNNs. The first one\nfrom characterizing the sufficient DNN size can guarantee universal feasibility\nwhile the other from the proposed training algorithm further improves\noptimality and maintains DNN's universal feasibility simultaneously. We apply\nthe preventive learning framework to develop DeepOPF+ for solving the essential\nDC optimal power flow problem in grid operation. It improves over existing\nDNN-based schemes in ensuring feasibility and attaining consistent desirable\nspeedup performance in both light-load and heavy-load regimes. Simulation\nresults over IEEE Case-30/118/300 test cases show that DeepOPF+ generates\n$100\\%$ feasible solutions with $<$0.5% optimality loss and up to two orders of\nmagnitude computational speedup, as compared to a state-of-the-art iterative\nsolver.",
    "descriptor": "\nComments: 43pages, 9 figures. In submission\n",
    "authors": [
      "Tianyu Zhao",
      "Xiang Pan",
      "Minghua Chen",
      "Steven H. Low"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.08091"
  },
  {
    "id": "arXiv:2112.08093",
    "title": "Towards Controllable Agent in MOBA Games with Generative Modeling",
    "abstract": "We propose novel methods to develop action controllable agent that behaves\nlike a human and has the ability to align with human players in Multiplayer\nOnline Battle Arena (MOBA) games. By modeling the control problem as an action\ngeneration process, we devise a deep latent alignment neural network model for\ntraining agent, and a corresponding sampling algorithm for controlling an\nagent's action. Particularly, we propose deterministic and stochastic attention\nimplementations of the core latent alignment model. Both simulated and online\nexperiments in the game Honor of Kings demonstrate the efficacy of the proposed\nmethods.",
    "descriptor": "\nComments: Human-Compatible AI; Human-AI Cooperation; AI control; AI Alignment\n",
    "authors": [
      "Shubao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08093"
  },
  {
    "id": "arXiv:2112.08094",
    "title": "Automatic tuning of hyper-parameters of reinforcement learning  algorithms using Bayesian optimization with behavioral cloning",
    "abstract": "Optimal setting of several hyper-parameters in machine learning algorithms is\nkey to make the most of available data. To this aim, several methods such as\nevolutionary strategies, random search, Bayesian optimization and heuristic\nrules of thumb have been proposed. In reinforcement learning (RL), the\ninformation content of data gathered by the learning agent while interacting\nwith its environment is heavily dependent on the setting of many\nhyper-parameters. Therefore, the user of an RL algorithm has to rely on\nsearch-based optimization methods, such as grid search or the Nelder-Mead\nsimplex algorithm, that are very inefficient for most RL tasks, slows down\nsignificantly the learning curve and leaves to the user the burden of\npurposefully biasing data gathering. In this work, in order to make an RL\nalgorithm more user-independent, a novel approach for autonomous\nhyper-parameter setting using Bayesian optimization is proposed. Data from past\nepisodes and different hyper-parameter values are used at a meta-learning level\nby performing behavioral cloning which helps improving the effectiveness in\nmaximizing a reinforcement learning variant of an acquisition function. Also,\nby tightly integrating Bayesian optimization in a reinforcement learning agent\ndesign, the number of state transitions needed to converge to the optimal\npolicy for a given task is reduced. Computational experiments reveal promising\nresults compared to other manual tweaking and optimization-based approaches\nwhich highlights the benefits of changing the algorithm hyper-parameters to\nincrease the information content of generated data.",
    "descriptor": "\nComments: Under review at Computational Intelligence\n",
    "authors": [
      "Juan Cruz Barsce",
      "Jorge A. Palombarini",
      "Ernesto C. Mart\u00ednez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08094"
  },
  {
    "id": "arXiv:2112.08098",
    "title": "Mask-combine Decoding and Classification Approach for Punctuation  Prediction with real-time Inference Constraints",
    "abstract": "In this work, we unify several existing decoding strategies for punctuation\nprediction in one framework and introduce a novel strategy which utilises\nmultiple predictions at each word across different windows. We show that\nsignificant improvements can be achieved by optimising these strategies after\ntraining a model, only leading to a potential increase in inference time, with\nno requirement for retraining. We further use our decoding strategy framework\nfor the first comparison of tagging and classification approaches for\npunctuation prediction in a real-time setting. Our results show that a\nclassification approach for punctuation prediction can be beneficial when\nlittle or no right-side context is available.",
    "descriptor": "\nComments: 4 pages, 3 figures, to appear in ICASSP2022\n",
    "authors": [
      "Christoph Minixhofer",
      "Ond\u0159ej Klejch",
      "Peter Bell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08098"
  },
  {
    "id": "arXiv:2112.08099",
    "title": "Encoding Individual Source Sequences for the Wiretap Channel",
    "abstract": "We consider the problem of encoding a deterministic source sequence (a.k.a.\\\nindividual sequence) for the degraded wiretap channel by means of an encoder\nand decoder that can both be implemented as finite--state machines. Our first\nmain result is a necessary condition for both reliable and secure transmission\nin terms of the given source sequence, the bandwidth expansion factor, the\nsecrecy capacity, the number of states of the encoder and the number of states\nof the decoder. Equivalently, this necessary condition can be presented as a\nconverse bound (i.e., a lower bound) on the smallest achievable bandwidth\nexpansion factor. The bound is asymptotically achievable by Lempel-Ziv\ncompression followed by good channel coding for the wiretap channel. Given that\nthe lower bound is saturated, we also derive a lower bound on the minimum\nnecessary rate of purely random bits needed for local randomness at the encoder\nin order to meet the security constraint. This bound too is achieved by the\nsame achievability scheme. Finally, we extend the main results to the case\nwhere the legitimate decoder has access to a side information sequence, which\nis another individual sequence that may be related to the source sequence, and\na noisy version of the side information sequence leaks to the wiretapper.",
    "descriptor": "\nComments: 34 pages, submitted for publication\n",
    "authors": [
      "Neri Merhav"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.08099"
  },
  {
    "id": "arXiv:2112.08100",
    "title": "Tensor Codes and their Invariants",
    "abstract": "In 1991, Roth introduced a natural generalization of rank metric codes,\nnamely tensor codes. The latter are defined to be subspaces of $r$-tensors\nwhere the ambient space is endowed with the tensor rank as a distance function.\nIn this work, we describe the general class of tensor codes and we study their\ninvariants that correspond to different families of anticodes. In our context,\nan anticode is a perfect space that has some additional properties. A perfect\nspace is one that is spanned by tensors of rank 1. Our use of the anticode\nconcept is motivated by an interest in capturing structural properties of\ntensor codes. In particular, we indentify four different classes of tensor\nanticodes and show how these gives different information on the codes they\ndescribe. We also define the generalized tensor binomial moments and the\ngeneralized tensor weight distribution of a code and establish a bijection\nbetween these invariants. We use the generalized tensor binomial moments to\ndefine the concept of an $i$-tensor BMD code, which is an extremal code in\nrelation to an inequality arising from them. Finally, we give MacWilliams\nidentities for generalized tensor binomial moments.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Eimear Byrne",
      "Giuseppe Cotardo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.08100"
  },
  {
    "id": "arXiv:2112.08106",
    "title": "Enhance Connectivity of Promising Regions for Sampling-based Path  Planning",
    "abstract": "Sampling-based path planning algorithms usually implement uniform sampling\nmethods to search the state space. However, uniform sampling may lead to\nunnecessary exploration in many scenarios, such as the environment with a few\ndead ends. Our previous work proposes to use the promising region to guide the\nsampling process to address the issue. However, the predicted promising regions\nare often disconnected, which means they cannot connect the start and goal\nstate, resulting in a lack of probabilistic completeness. This work focuses on\nenhancing the connectivity of predicted promising regions. Our proposed method\nregresses the connectivity probability of the edges in the x and y directions.\nIn addition, it calculates the weight of the promising edges in loss to guide\nthe neural network to pay more attention to the connectivity of the promising\nregions. We conduct a series of simulation experiments, and the results show\nthat the connectivity of promising regions improves significantly. Furthermore,\nwe analyze the effect of connectivity on sampling-based path planning\nalgorithms and conclude that connectivity plays an essential role in\nmaintaining algorithm performance.",
    "descriptor": "",
    "authors": [
      "Han Ma",
      "Chenming Li",
      "Jianbang Liu",
      "Jiankun Wang",
      "Max Q.-H. Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08106"
  },
  {
    "id": "arXiv:2112.08110",
    "title": "Academic Storage Cluster",
    "abstract": "Decentralized storage is still rarely used in an academic and educational\nenvironment, although it offers better availability than conventional systems.\nIt still happens that data is not available at a certain time due to heavy load\nor maintenance on university servers. A decentralized solution can help keep\nthe data available and distribute the load among several peers. In our\nexperiment, we created a cluster of containers in Docker to evaluate a private\nIPFS cluster for an academic data store focusing on availability, GET/PUT\nperformance, and storage needs. As sample data, we used PDF files to analyze\nthe data transport in our peer-to-peer network with Wireshark. We found that a\nbandwidth of at least 100 kbit/s is required for IPFS to function but recommend\nat least 1000 kbit/s for smooth operation. Also, the hard disk and memory size\nshould be adapted to the data. Other limiting factors such as CPU power and\ndelay in the internet connection did not affect the operation of the IPFS\ncluster.",
    "descriptor": "\nComments: 2 pages, 2 figures, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL), poster paper,\n",
    "authors": [
      "Alexander von Tottleben",
      "Cornelius Ihle",
      "Moritz Schubotz",
      "Bela Gipp"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.08110"
  },
  {
    "id": "arXiv:2112.08117",
    "title": "Vision Transformer Based Video Hashing Retrieval for Tracing the Source  of Fake Videos",
    "abstract": "Conventional fake video detection methods outputs a possibility value or a\nsuspected mask of tampering images. However, such unexplainable results cannot\nbe used as convincing evidence. So it is better to trace the sources of fake\nvideos. The traditional hashing methods are used to retrieve semantic-similar\nimages, which can't discriminate the nuances of the image. Specifically, the\nsources tracing compared with traditional video retrieval. It is a challenge to\nfind the real one from similar source videos. We designed a novel loss Hash\nTriplet Loss to solve the problem that the videos of people are very similar:\nthe same scene with different angles, similar scenes with the same person. We\npropose Vision Transformer based models named Video Tracing and Tampering\nLocalization (VTL). In the first stage, we train the hash centers by ViTHash\n(VTL-T). Then, a fake video is inputted to ViTHash, which outputs a hash code.\nThe hash code is used to retrieve the source video from hash centers. In the\nsecond stage, the source video and fake video are inputted to generator\n(VTL-L). Then, the suspect regions are masked to provide auxiliary information.\nMoreover, we constructed two datasets: DFTL and DAVIS2016-TL. Experiments on\nDFTL clearly show the superiority of our framework in sources tracing of\nsimilar videos. In particular, the VTL also achieved comparable performance\nwith state-of-the-art methods on DAVIS2016-TL. Our source code and datasets\nhave been released on GitHub: \\url{https://github.com/lajlksdf/vtl}.",
    "descriptor": "",
    "authors": [
      "Pengfei Pei",
      "Xianfeng Zhao",
      "Jinchuan Li",
      "Yun Cao",
      "Xiaowei Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08117"
  },
  {
    "id": "arXiv:2112.08121",
    "title": "Information-Weighted Consensus Filter with Partial Information Exchange",
    "abstract": "In this paper, the information-weighted consensus filter (ICF) with partial\ninformation exchange is proposed to reduce the bandwidth of the signals\ntransmitted between the sensor nodes and guarantee its convergence to the\ncentralized Kalman filter (CKF). In the proposed algorithm, a part of\ninformation chosen with the entry selection matrix is transmitted to the sensor\nnodes in the neighborhood at each consensus step, and consensus averaging is\nconducted at each sensor node with the partial and the local information. This\nensures that the proposed distributed estimation algorithm converges to the\ncentralized algorithm, while allowing the proposed algorithm to achieve\nbandwidth reduction of the signals transmitted between the sensors. With the\nproposed algorithm, the stability of the estimation error dynamics is proven\nand the convergence to the centralized algorithm is mathematically shown using\nthe property of the average consensus. Simulations are conducted to validate\nthe proposed ICF with partial information exchange and the related theoretical\nfindings.",
    "descriptor": "\nComments: Submitted to IEEE\n",
    "authors": [
      "Byoung-Ju Jeon",
      "Shaoming He"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.08121"
  },
  {
    "id": "arXiv:2112.08122",
    "title": "Self-Supervised Monocular Depth and Ego-Motion Estimation in Endoscopy:  Appearance Flow to the Rescue",
    "abstract": "Recently, self-supervised learning technology has been applied to calculate\ndepth and ego-motion from monocular videos, achieving remarkable performance in\nautonomous driving scenarios. One widely adopted assumption of depth and\nego-motion self-supervised learning is that the image brightness remains\nconstant within nearby frames. Unfortunately, the endoscopic scene does not\nmeet this assumption because there are severe brightness fluctuations induced\nby illumination variations, non-Lambertian reflections and interreflections\nduring data collection, and these brightness fluctuations inevitably\ndeteriorate the depth and ego-motion estimation accuracy. In this work, we\nintroduce a novel concept referred to as appearance flow to address the\nbrightness inconsistency problem. The appearance flow takes into consideration\nany variations in the brightness pattern and enables us to develop a\ngeneralized dynamic image constraint. Furthermore, we build a unified\nself-supervised framework to estimate monocular depth and ego-motion\nsimultaneously in endoscopic scenes, which comprises a structure module, a\nmotion module, an appearance module and a correspondence module, to accurately\nreconstruct the appearance and calibrate the image brightness. Extensive\nexperiments are conducted on the SCARED dataset and EndoSLAM dataset, and the\nproposed unified framework exceeds other self-supervised approaches by a large\nmargin. To validate our framework's generalization ability on different\npatients and cameras, we train our model on SCARED but test it on the SERV-CT\nand Hamlyn datasets without any fine-tuning, and the superior results reveal\nits strong generalization ability. Code will be available at:\n\\url{https://github.com/ShuweiShao/AF-SfMLearner}.",
    "descriptor": "\nComments: Accepted by Medical Image Analysis\n",
    "authors": [
      "Shuwei Shao",
      "Zhongcai Pei",
      "Weihai Chen",
      "Wentao Zhu",
      "Xingming Wu",
      "Dianmin Sun",
      "Baochang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08122"
  },
  {
    "id": "arXiv:2112.08125",
    "title": "Exponential Convergence of Deep Operator Networks for Elliptic Partial  Differential Equations",
    "abstract": "We construct deep operator networks (ONets) between infinite-dimensional\nspaces that emulate with an exponential rate of convergence the\ncoefficient-to-solution map of elliptic second-order PDEs. In particular, we\nconsider problems set in $d$-dimensional periodic domains, $d=1, 2, \\dots$, and\nwith analytic right-hand sides and coefficients. Our analysis covers\ndiffusion-reaction problems, parametric diffusion equations, and elliptic\nsystems such as linear isotropic elastostatics in heterogeneous materials.\nWe leverage the exponential convergence of spectral collocation methods for\nboundary value problems whose solutions are analytic. In the present periodic\nand analytic setting, this follows from classical elliptic regularity. Within\nthe ONet branch and trunk construction of [Chen and Chen, 1993] and of [Lu et\nal., 2021], we show the existence of deep ONets which emulate the\ncoefficient-to-solution map to accuracy $\\varepsilon>0$ in the $H^1$ norm,\nuniformly over the coefficient set. We prove that the neural networks in the\nONet have size $\\mathcal{O}(\\left|\\log(\\varepsilon)\\right|^\\kappa)$ for some\n$\\kappa>0$ depending on the physical space dimension.",
    "descriptor": "",
    "authors": [
      "Carlo Marcati",
      "Christoph Schwab"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.08125"
  },
  {
    "id": "arXiv:2112.08132",
    "title": "Improving Self-supervised Learning with Automated Unsupervised Outlier  Arbitration",
    "abstract": "Our work reveals a structured shortcoming of the existing mainstream\nself-supervised learning methods. Whereas self-supervised learning frameworks\nusually take the prevailing perfect instance level invariance hypothesis for\ngranted, we carefully investigate the pitfalls behind. Particularly, we argue\nthat the existing augmentation pipeline for generating multiple positive views\nnaturally introduces out-of-distribution (OOD) samples that undermine the\nlearning of the downstream tasks. Generating diverse positive augmentations on\nthe input does not always pay off in benefiting downstream tasks. To overcome\nthis inherent deficiency, we introduce a lightweight latent variable model\nUOTA, targeting the view sampling issue for self-supervised learning. UOTA\nadaptively searches for the most important sampling region to produce views,\nand provides viable choice for outlier-robust self-supervised learning\napproaches. Our method directly generalizes to many mainstream self-supervised\nlearning approaches, regardless of the loss's nature contrastive or not. We\nempirically show UOTA's advantage over the state-of-the-art self-supervised\nparadigms with evident margin, which well justifies the existence of the OOD\nsample issue embedded in the existing approaches. Especially, we theoretically\nprove that the merits of the proposal boil down to guaranteed estimator\nvariance and bias reduction. Code is available: at\nhttps://github.com/ssl-codelab/uota.",
    "descriptor": "\nComments: NeurIPS 2021; Code is publicly available at: this https URL\n",
    "authors": [
      "Yu Wang",
      "Jingyang Lin",
      "Jingjing Zou",
      "Yingwei Pan",
      "Ting Yao",
      "Tao Mei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08132"
  },
  {
    "id": "arXiv:2112.08136",
    "title": "Characterizing the Program Expressive Power of Existential Rule  Languages",
    "abstract": "Existential rule languages are a family of ontology languages that have been\nwidely used in ontology-mediated query answering (OMQA). However, for most of\nthem, the expressive power of representing domain knowledge for OMQA, known as\nthe program expressive power, is not well-understood yet. In this paper, we\nestablish a number of novel characterizations for the program expressive power\nof several important existential rule languages, including tuple-generating\ndependencies (TGDs), linear TGDs, as well as disjunctive TGDs. The\ncharacterizations employ natural model-theoretic properties, and\nautomata-theoretic properties sometimes, which thus provide powerful tools for\nidentifying the definability of domain knowledge for OMQA in these languages.",
    "descriptor": "\nComments: To be published in AAAI-22\n",
    "authors": [
      "Heng Zhang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.08136"
  },
  {
    "id": "arXiv:2112.08140",
    "title": "Improving Conversational Recommendation Systems' Quality with  Context-Aware Item Meta Information",
    "abstract": "Conversational recommendation systems (CRS) engage with users by inferring\nuser preferences from dialog history, providing accurate recommendations, and\ngenerating appropriate responses. Previous CRSs use knowledge graph (KG) based\nrecommendation modules and integrate KG with language models for response\ngeneration. Although KG-based approaches prove effective, two issues remain to\nbe solved. First, KG-based approaches ignore the information in the\nconversational context but only rely on entity relations and bag of words to\nrecommend items. Second, it requires substantial engineering efforts to\nmaintain KGs that model domain-specific relations, thus leading to less\nflexibility. In this paper, we propose a simple yet effective architecture\ncomprising a pre-trained language model (PLM) and an item metadata encoder. The\nencoder learns to map item metadata to embeddings that can reflect the semantic\ninformation in the dialog context. The PLM then consumes the semantic-aligned\nitem embeddings together with dialog context to generate high-quality\nrecommendations and responses. Instead of modeling entity relations with KGs,\nour model reduces engineering complexity by directly converting each item to an\nembedding. Experimental results on the benchmark dataset ReDial show that our\nmodel obtains state-of-the-art results on both recommendation and response\ngeneration tasks.",
    "descriptor": "",
    "authors": [
      "Bowen Yang",
      "Cong Han",
      "Yu Li",
      "Lei Zuo",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.08140"
  },
  {
    "id": "arXiv:2112.08152",
    "title": "Faster Nearest Neighbor Machine Translation",
    "abstract": "$k$NN based neural machine translation ($k$NN-MT) has achieved\nstate-of-the-art results in a variety of MT tasks. One significant shortcoming\nof $k$NN-MT lies in its inefficiency in identifying the $k$ nearest neighbors\nof the query representation from the entire datastore, which is prohibitively\ntime-intensive when the datastore size is large. In this work, we propose\n\\textbf{Faster $k$NN-MT} to address this issue. The core idea of Faster\n$k$NN-MT is to use a hierarchical clustering strategy to approximate the\ndistance between the query and a data point in the datastore, which is\ndecomposed into two parts: the distance between the query and the center of the\ncluster that the data point belongs to, and the distance between the data point\nand the cluster center. We propose practical ways to compute these two parts in\na significantly faster manner. Through extensive experiments on different MT\nbenchmarks, we show that \\textbf{Faster $k$NN-MT} is faster than Fast $k$NN-MT\n\\citep{meng2021fast} and only slightly (1.2 times) slower than its vanilla\ncounterpart while preserving model performance as $k$NN-MT. Faster $k$NN-MT\nenables the deployment of $k$NN-MT models on real-world MT services.",
    "descriptor": "",
    "authors": [
      "Shuhe Wang",
      "Jiwei Li",
      "Yuxian Meng",
      "Rongbin Ouyang",
      "Guoyin Wang",
      "Xiaoya Li",
      "Tianwei Zhang",
      "Shi Zong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08152"
  },
  {
    "id": "arXiv:2112.08159",
    "title": "One size does not fit all: Investigating strategies for  differentially-private learning across NLP tasks",
    "abstract": "Preserving privacy in training modern NLP models comes at a cost. We know\nthat stricter privacy guarantees in differentially-private stochastic gradient\ndescent (DP-SGD) generally degrade model performance. However, previous\nresearch on the efficiency of DP-SGD in NLP is inconclusive or even\ncounter-intuitive. In this short paper, we provide a thorough analysis of\ndifferent privacy preserving strategies on seven downstream datasets in five\ndifferent `typical' NLP tasks with varying complexity using modern neural\nmodels. We show that unlike standard non-private approaches to solving NLP\ntasks, where bigger is usually better, privacy-preserving strategies do not\nexhibit a winning pattern, and each task and privacy regime requires a special\ntreatment to achieve adequate performance.",
    "descriptor": "",
    "authors": [
      "Manuel Senge",
      "Timour Igamberdiev",
      "Ivan Habernal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08159"
  },
  {
    "id": "arXiv:2112.08162",
    "title": "EXT-TAURUM P2T: an Extended Secure CAN-FD Architecture for Road Vehicles",
    "abstract": "The automobile industry is no longer relying on pure mechanical systems;\ninstead, it benefits from advanced Electronic Control Units (ECUs) in order to\nprovide new and complex functionalities in the effort to move toward fully\nconnected cars. However, connected cars provide a dangerous playground for\nhackers. Vehicles are becoming increasingly vulnerable to cyber attacks as they\ncome equipped with more connected features and control systems. This situation\nmay expose strategic assets in the automotive value chain. In this scenario,\nthe Controller Area Network (CAN) is the most widely used communication\nprotocol in the automotive domain. However, this protocol lacks encryption and\nauthentication. Consequently, any malicious/hijacked node can cause\ncatastrophic accidents and financial loss. Starting from the analysis of the\nvulnerability connected to the CAN communication protocol in the automotive\ndomain, this paper proposes EXT-TAURUM P2T a new low-cost secure CAN-FD\narchitecture for the automotive domain implementing secure communication among\nECUs, a novel key provisioning strategy, intelligent throughput management, and\nhardware signature mechanisms. The proposed architecture has been implemented,\nresorting to a commercial Multi-Protocol Vehicle Interface module, and the\nobtained results experimentally demonstrate the approach's feasibility.",
    "descriptor": "",
    "authors": [
      "Franco Oberti",
      "Alessandro Savino",
      "Ernesto Sanchez",
      "Filippo Parisi",
      "Stefano Di Carlo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.08162"
  },
  {
    "id": "arXiv:2112.08165",
    "title": "Chimpanzee voice prints? Insights from transfer learning experiments  from human voices",
    "abstract": "Individual vocal differences are ubiquitous in the animal kingdom. In humans,\nthese differences pervade the entire vocal repertoire and constitute a \"voice\nprint\". Apes, our closest-living relatives, possess individual signatures\nwithin specific call types, but the potential for a unique voice print has been\nlittle investigated. This is partially attributed to the limitations associated\nwith extracting meaningful features from small data sets. Advances in machine\nlearning have highlighted an alternative to traditional acoustic features,\nnamely pre-trained learnt extractors. Here, we present an approach building on\nthese developments: leveraging a feature extractor based on a deep neural\nnetwork trained on over 10,000 human voice prints to provide an informative\nspace over which we identify chimpanzee voice prints. We compare our results\nwith those obtained by using traditional acoustic features and discuss the\nbenefits of our methodology and the significance of our findings for the\nidentification of \"voice prints\" in non-human animals.",
    "descriptor": "",
    "authors": [
      "Mael Leroux",
      "Orestes Gutierrez Al-Khudhairy",
      "Nicolas Perony",
      "Simon W. Townsend"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.08165"
  },
  {
    "id": "arXiv:2112.08171",
    "title": "Text Gestalt: Stroke-Aware Scene Text Image Super-Resolution",
    "abstract": "In the last decade, the blossom of deep learning has witnessed the rapid\ndevelopment of scene text recognition. However, the recognition of\nlow-resolution scene text images remains a challenge. Even though some\nsuper-resolution methods have been proposed to tackle this problem, they\nusually treat text images as general images while ignoring the fact that the\nvisual quality of strokes (the atomic unit of text) plays an essential role for\ntext recognition. According to Gestalt Psychology, humans are capable of\ncomposing parts of details into the most similar objects guided by prior\nknowledge. Likewise, when humans observe a low-resolution text image, they will\ninherently use partial stroke-level details to recover the appearance of\nholistic characters. Inspired by Gestalt Psychology, we put forward a\nStroke-Aware Scene Text Image Super-Resolution method containing a\nStroke-Focused Module (SFM) to concentrate on stroke-level internal structures\nof characters in text images. Specifically, we attempt to design rules for\ndecomposing English characters and digits at stroke-level, then pre-train a\ntext recognizer to provide stroke-level attention maps as positional clues with\nthe purpose of controlling the consistency between the generated\nsuper-resolution image and high-resolution ground truth. The extensive\nexperimental results validate that the proposed method can indeed generate more\ndistinguishable images on TextZoom and manually constructed Chinese character\ndataset Degraded-IC13. Furthermore, since the proposed SFM is only used to\nprovide stroke-level guidance when training, it will not bring any time\noverhead during the test phase. Code is available at\nhttps://github.com/FudanVI/FudanOCR/tree/main/text-gestalt.",
    "descriptor": "\nComments: Accepted to AAAI2022. Code is available at this https URL\n",
    "authors": [
      "Jingye Chen",
      "Haiyang Yu",
      "Jianqi Ma",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08171"
  },
  {
    "id": "arXiv:2112.08172",
    "title": "Binary Polarization Shift Keying with Reconfigurable Intelligent  Surfaces",
    "abstract": "We propose a novel binary polarization shift keying modulation scheme for a\nline-of-sight environment by exploiting the polarization control ability of the\nreconfigurable intelligent surface (RIS). The RIS encodes the information data\nin terms of the polarization states of either the reflected wave from the RIS\nor the composite wireless channel between an RF source and receiver. In the\nfirst case, polarization mismatch correction becomes essential at the receiver.\nIn the second case, the RIS pre-codes the reflected wave to compensate for the\npolarization mismatch which allows non-coherent demodulation at the receiver.",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to IEEE Wireless Communication Letters\n",
    "authors": [
      "Emad Ibrahim",
      "Rickard Nilsson",
      "Jaap van de Beek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.08172"
  },
  {
    "id": "arXiv:2112.08175",
    "title": "A Factorization Approach for Motor Imagery Classification",
    "abstract": "Brain-computer interface uses brain signals to communicate with external\ndevices without actual control. Many studies have been conducted to classify\nmotor imagery based on machine learning. However, classifying imagery data with\nsparse spatial characteristics, such as single-arm motor imagery, remains a\nchallenge. In this paper, we proposed a method to factorize EEG signals into\ntwo groups to classify motor imagery even if spatial features are sparse. Based\non adversarial learning, we focused on extracting common features of EEG\nsignals which are robust to noise and extracting only signal features. In\naddition, class-specific features were extracted which are specialized for\nclass classification. Finally, the proposed method classifies the classes by\nrepresenting the features of the two groups as one embedding space. Through\nexperiments, we confirmed the feasibility that extracting features into two\ngroups is advantageous for datasets that contain sparse spatial features.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Byeong-Hoo Lee",
      "Jeong-Hyun Cho",
      "Byung-Hee Kwon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08175"
  },
  {
    "id": "arXiv:2112.08176",
    "title": "AMSER: Adaptive Multi-modal Sensing for Energy Efficient and Resilient  eHealth Systems",
    "abstract": "eHealth systems deliver critical digital healthcare and wellness services for\nusers by continuously monitoring physiological and contextual data. eHealth\napplications use multi-modal machine learning kernels to analyze data from\ndifferent sensor modalities and automate decision-making. Noisy inputs and\nmotion artifacts during sensory data acquisition affect the i) prediction\naccuracy and resilience of eHealth services and ii) energy efficiency in\nprocessing garbage data. Monitoring raw sensory inputs to identify and drop\ndata and features from noisy modalities can improve prediction accuracy and\nenergy efficiency. We propose a closed-loop monitoring and control framework\nfor multi-modal eHealth applications, AMSER, that can mitigate garbage-in\ngarbage-out by i) monitoring input modalities, ii) analyzing raw input to\nselectively drop noisy data and features, and iii) choosing appropriate machine\nlearning models that fit the configured data and feature vector - to improve\nprediction accuracy and energy efficiency. We evaluate our AMSER approach using\nmulti-modal eHealth applications of pain assessment and stress monitoring over\ndifferent levels and types of noisy components incurred via different sensor\nmodalities. Our approach achieves up to 22\\% improvement in prediction accuracy\nand 5.6$\\times$ energy consumption reduction in the sensing phase against the\nstate-of-the-art multi-modal monitoring application.",
    "descriptor": "",
    "authors": [
      "Emad Kasaeyan Naeini",
      "Sina Shahhosseini",
      "Anil Kanduri",
      "Pasi Liljeberg",
      "Amir M. Rahmani",
      "Nikil Dutt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08176"
  },
  {
    "id": "arXiv:2112.08177",
    "title": "Multi-View Depth Estimation by Fusing Single-View Depth Probability with  Multi-View Geometry",
    "abstract": "Multi-view depth estimation methods typically require the computation of a\nmulti-view cost-volume, which leads to huge memory consumption and slow\ninference. Furthermore, multi-view matching can fail for texture-less surfaces,\nreflective surfaces and moving objects. For such failure modes, single-view\ndepth estimation methods are often more reliable. To this end, we propose\nMaGNet, a novel framework for fusing single-view depth probability with\nmulti-view geometry, to improve the accuracy, robustness and efficiency of\nmulti-view depth estimation. For each frame, MaGNet estimates a single-view\ndepth probability distribution, parameterized as a pixel-wise Gaussian. The\ndistribution estimated for the reference frame is then used to sample per-pixel\ndepth candidates. Such probabilistic sampling enables the network to achieve\nhigher accuracy while evaluating fewer depth candidates. We also propose depth\nconsistency weighting for the multi-view matching score, to ensure that the\nmulti-view depth is consistent with the single-view predictions. The proposed\nmethod achieves state-of-the-art performance on ScanNet, 7-Scenes and KITTI.\nQualitative evaluation demonstrates that our method is more robust against\nchallenging artifacts such as texture-less/reflective surfaces and moving\nobjects.",
    "descriptor": "",
    "authors": [
      "Gwangbin Bae",
      "Ignas Budvytis",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08177"
  },
  {
    "id": "arXiv:2112.08178",
    "title": "Interpretable Feature Learning Framework for Smoking Behavior Detection",
    "abstract": "Smoking in public has been proven to be more harmful to nonsmokers, making it\na huge public health concern with urgent need for proactive measures and\nattention by authorities. With the world moving towards the 4th Industrial\nRevolution, there is a need for reliable eco-friendly detective measures\ntowards this harmful intoxicating behavior to public health in and out of smart\ncities. We developed an Interpretable feature learning framework for smoking\nbehavior detection which utilizes a Deep Learning VGG-16 pretrained network to\npredict and classify the input Image class and a Layer-wise Relevance\nPropagation (LRP) to explain the network detection or prediction of smoking\nbehavior based on the most relevant learned features or pixels or neurons. The\nnetwork's classification decision is based mainly on features located at the\nmouth especially the smoke seems to be of high importance to the network's\ndecision. The outline of the smoke is highlighted as evidence for the\ncorresponding class. Some elements are seen as having a negative effect on the\nsmoke neuron and are consequently highlighted differently. It is interesting to\nsee that the network distinguishes important from unimportant features based on\nthe image regions. The technology can also detect other smokeable drugs like\nweed, shisha, marijuana etc. The framework allows for reliable identification\nof action-based smokers in unsafe zones like schools, shopping malls, bus\nstops, railway compartments or other violated places for smoking as per the\ngovernment's regulatory health policies. With installation clearly defined in\nsmoking zones, this technology can detect smokers out of range.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Nakayiza Hellen",
      "Ggaliwango Marvin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08178"
  },
  {
    "id": "arXiv:2112.08181",
    "title": "Hierarchical Variational Memory for Few-shot Learning Across Domains",
    "abstract": "Neural memory enables fast adaptation to new tasks with just a few training\nsamples. Existing memory models store features only from the single last layer,\nwhich does not generalize well in presence of a domain shift between training\nand test distributions. Rather than relying on a flat memory, we propose a\nhierarchical alternative that stores features at different semantic levels. We\nintroduce a hierarchical prototype model, where each level of the prototype\nfetches corresponding information from the hierarchical memory. The model is\nendowed with the ability to flexibly rely on features at different semantic\nlevels if the domain shift circumstances so demand. We meta-learn the model by\na newly derived hierarchical variational inference framework, where\nhierarchical memory and prototypes are jointly optimized. To explore and\nexploit the importance of different semantic levels, we further propose to\nlearn the weights associated with the prototype at each level in a data-driven\nway, which enables the model to adaptively choose the most generalizable\nfeatures. We conduct thorough ablation studies to demonstrate the effectiveness\nof each component in our model. The new state-of-the-art performance on\ncross-domain and competitive performance on traditional few-shot classification\nfurther substantiates the benefit of hierarchical variational memory.",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Yingjun Du",
      "Xiantong Zhen",
      "Ling Shao",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08181"
  },
  {
    "id": "arXiv:2112.08184",
    "title": "Interactive Visualization and Representation Analysis Applied to Glacier  Segmentation",
    "abstract": "Interpretability has attracted increasing attention in earth observation\nproblems. We apply interactive visualization and representation analysis to\nguide interpretation of glacier segmentation models. We visualize the\nactivations from a U-Net to understand and evaluate the model performance. We\nbuild an online interface using the Shiny R package to provide comprehensive\nerror analysis of the predictions. Users can interact with the panels and\ndiscover model failure modes. Further, we discuss how visualization can provide\nsanity checks during data preprocessing and model training.",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Minxing Zheng",
      "Xinran Miao",
      "Kris Sankaran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08184"
  },
  {
    "id": "arXiv:2112.08185",
    "title": "Learning Cross-Lingual IR from an English Retriever",
    "abstract": "We present a new cross-lingual information retrieval (CLIR) model trained\nusing multi-stage knowledge distillation (KD). The teacher and the student are\nheterogeneous systems-the former is a pipeline that relies on machine\ntranslation and monolingual IR, while the latter executes a single CLIR\noperation. We show that the student can learn both multilingual representations\nand CLIR by optimizing two corresponding KD objectives. Learning multilingual\nrepresentations from an English-only retriever is accomplished using a novel\ncross-lingual alignment algorithm that greedily re-positions the teacher tokens\nfor alignment. Evaluation on the XOR-TyDi benchmark shows that the proposed\nmodel is far more effective than the existing approach of fine-tuning with\ncross-lingual labeled IR data, with a gain in accuracy of 25.4 Recall@5kt.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Yulong Li",
      "Martin Franz",
      "Md Arafat Sultan",
      "Bhavani Iyer",
      "Young-Suk Lee",
      "Avirup Sil"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08185"
  },
  {
    "id": "arXiv:2112.08186",
    "title": "Planning with Biological Neurons and Synapses",
    "abstract": "We revisit the planning problem in the blocks world, and we implement a known\nheuristic for this task. Importantly, our implementation is biologically\nplausible, in the sense that it is carried out exclusively through the spiking\nof neurons. Even though much has been accomplished in the blocks world over the\npast five decades, we believe that this is the first algorithm of its kind. The\ninput is a sequence of symbols encoding an initial set of block stacks as well\nas a target set, and the output is a sequence of motion commands such as ``put\nthe top block in stack 1 on the table''. The program is written in the Assembly\nCalculus, a recently proposed computational framework meant to model\ncomputation in the brain by bridging the gap between neural activity and\ncognitive function. Its elementary objects are assemblies of neurons (stable\nsets of neurons whose simultaneous firing signifies that the subject is\nthinking of an object, concept, word, etc.), its commands include project and\nmerge, and its execution model is based on widely accepted tenets of\nneuroscience. A program in this framework essentially sets up a dynamical\nsystem of neurons and synapses that eventually, with high probability,\naccomplishes the task. The purpose of this work is to establish empirically\nthat reasonably large programs in the Assembly Calculus can execute correctly\nand reliably; and that rather realistic -- if idealized -- higher cognitive\nfunctions, such as planning in the blocks world, can be implemented\nsuccessfully by such programs.",
    "descriptor": "",
    "authors": [
      "Francesco d'Amore",
      "Daniel Mitropolsky",
      "Pierluigi Crescenzi",
      "Emanuele Natale",
      "Christos H. Papadimitriou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.08186"
  },
  {
    "id": "arXiv:2112.08189",
    "title": "ST-MTL: Spatio-Temporal Multitask Learning Model to Predict Scanpath  While Tracking Instruments in Robotic Surgery",
    "abstract": "Representation learning of the task-oriented attention while tracking\ninstrument holds vast potential in image-guided robotic surgery. Incorporating\ncognitive ability to automate the camera control enables the surgeon to\nconcentrate more on dealing with surgical instruments. The objective is to\nreduce the operation time and facilitate the surgery for both surgeons and\npatients. We propose an end-to-end trainable Spatio-Temporal Multi-Task\nLearning (ST-MTL) model with a shared encoder and spatio-temporal decoders for\nthe real-time surgical instrument segmentation and task-oriented saliency\ndetection. In the MTL model of shared parameters, optimizing multiple loss\nfunctions into a convergence point is still an open challenge. We tackle the\nproblem with a novel asynchronous spatio-temporal optimization (ASTO) technique\nby calculating independent gradients for each decoder. We also design a\ncompetitive squeeze and excitation unit by casting a skip connection that\nretains weak features, excites strong features, and performs dynamic spatial\nand channel-wise feature recalibration. To capture better long term\nspatio-temporal dependencies, we enhance the long-short term memory (LSTM)\nmodule by concatenating high-level encoder features of consecutive frames. We\nalso introduce Sinkhorn regularized loss to enhance task-oriented saliency\ndetection by preserving computational efficiency. We generate the task-aware\nsaliency maps and scanpath of the instruments on the dataset of the MICCAI 2017\nrobotic instrument segmentation challenge. Compared to the state-of-the-art\nsegmentation and saliency methods, our model outperforms most of the evaluation\nmetrics and produces an outstanding performance in the challenge.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Mobarakol Islam",
      "Vibashan VS",
      "Chwee Ming Lim",
      "Hongliang Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.08189"
  },
  {
    "id": "arXiv:2112.08191",
    "title": "Lesan -- Machine Translation for Low Resource Languages",
    "abstract": "Millions of people around the world can not access content on the Web because\nmost of the content is not readily available in their language. Machine\ntranslation (MT) systems have the potential to change this for many languages.\nCurrent MT systems provide very accurate results for high resource language\npairs, e.g., German and English. However, for many low resource languages, MT\nis still under active research. The key challenge is lack of datasets to build\nthese systems. We present Lesan, an MT system for low resource languages. Our\npipeline solves the key bottleneck to low resource MT by leveraging online and\noffline sources, a custom OCR system for Ethiopic and an automatic alignment\nmodule. The final step in the pipeline is a sequence to sequence model that\ntakes parallel corpus as input and gives us a translation model. Lesan's\ntranslation model is based on the Transformer architecture. After constructing\na base model, back translation, is used to leverage monolingual corpora.\nCurrently Lesan supports translation to and from Tigrinya, Amharic and English.\nWe perform extensive human evaluation and show that Lesan outperforms\nstate-of-the-art systems such as Google Translate and Microsoft Translator\nacross all six pairs. Lesan is freely available and has served more than 10\nmillion translations so far. At the moment, there are only 217 Tigrinya and\n15,009 Amharic Wikipedia articles. We believe that Lesan will contribute\ntowards democratizing access to the Web through MT for millions of people.",
    "descriptor": "\nComments: 4 pages, 2 figures, 35th Conference on Neural Information Processing Systems (NeurIPS 2021) demonstrations track\n",
    "authors": [
      "Asmelash Teka Hadgu",
      "Abel Aregawi",
      "Adam Beaudoin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08191"
  },
  {
    "id": "arXiv:2112.08193",
    "title": "N3H-Core: Neuron-designed Neural Network Accelerator via FPGA-based  Heterogeneous Computing Cores",
    "abstract": "Accelerating the neural network inference by FPGA has emerged as a popular\noption, since the reconfigurability and high performance computing capability\nof FPGA intrinsically satisfies the computation demand of the fast-evolving\nneural algorithms. However, the popular neural accelerators on FPGA (e.g.,\nXilinx DPU) mainly utilize the DSP resources for constructing their processing\nunits, while the rich LUT resources are not well exploited. Via the\nsoftware-hardware co-design approach, in this work, we develop an FPGA-based\nheterogeneous computing system for neural network acceleration. From the\nhardware perspective, the proposed accelerator consists of DSP- and LUT-based\nGEneral Matrix-Multiplication (GEMM) computing cores, which forms the entire\ncomputing system in a heterogeneous fashion. The DSP- and LUT-based GEMM cores\nare computed w.r.t a unified Instruction Set Architecture (ISA) and unified\nbuffers. Along the data flow of the neural network inference path, the\ncomputation of the convolution/fully-connected layer is split into two\nportions, handled by the DSP- and LUT-based GEMM cores asynchronously. From the\nsoftware perspective, we mathematically and systematically model the latency\nand resource utilization of the proposed heterogeneous accelerator, regarding\nvarying system design configurations. Through leveraging the reinforcement\nlearning technique, we construct a framework to achieve end-to-end selection\nand optimization of the design specification of target heterogeneous\naccelerator, including workload split strategy, mixed-precision quantization\nscheme, and resource allocation of DSP- and LUT-core. In virtue of the proposed\ndesign framework and heterogeneous computing system, our design outperforms the\nstate-of-the-art Mix&Match design with latency reduced by 1.12-1.32x with\nhigher inference accuracy. The N3H-core is open-sourced at:\nhttps://github.com/elliothe/N3H_Core.",
    "descriptor": "\nComments: 11 pages, 12 figures, In Proceedings of the 2022 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA'22), February 27-March 1, 2022, Virtual Event, CA, USA\n",
    "authors": [
      "Yu Gong",
      "Zhihan Xu",
      "Zhezhi He",
      "Weifeng Zhang",
      "Xiaobing Tu",
      "Xiaoyao Liang",
      "Li Jiang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.08193"
  },
  {
    "id": "arXiv:2112.08195",
    "title": "Generative Adversarial Networks for Labelled Vibration Data Generation",
    "abstract": "As Structural Health Monitoring (SHM) being implemented more over the years,\nthe use of operational modal analysis of civil structures has become more\nsignificant for the assessment and evaluation of engineering structures.\nMachine Learning (ML) and Deep Learning (DL) algorithms have been in use for\nstructural damage diagnostics of civil structures in the last couple of\ndecades. While collecting vibration data from civil structures is a challenging\nand expensive task for both undamaged and damaged cases, in this paper, the\nauthors are introducing Generative Adversarial Networks (GAN) that is built on\nthe Deep Convolutional Neural Network (DCNN) and using Wasserstein Distance for\ngenerating artificial labelled data to be used for structural damage diagnostic\npurposes. The authors named the developed model 1D W-DCGAN and successfully\ngenerated vibration data which is very similar to the input. The methodology\npresented in this paper will pave the way for vibration data generation for\nnumerous future applications in the SHM domain.",
    "descriptor": "",
    "authors": [
      "Furkan Luleci",
      "F. Necati Catbas",
      "Onur Avci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08195"
  },
  {
    "id": "arXiv:2112.08196",
    "title": "Generative Adversarial Networks for Data Generation in Structural Health  Monitoring",
    "abstract": "Structural Health Monitoring (SHM) has been continuously benefiting from the\nadvancements in the field of data science. Various types of Artificial\nIntelligence (AI) methods have been utilized for the assessment and evaluation\nof civil structures. In AI, Machine Learning (ML) and Deep Learning (DL)\nalgorithms require plenty of datasets to train; particularly, the more data DL\nmodels are trained with, the better output it yields. Yet, in SHM applications,\ncollecting data from civil structures through sensors is expensive and\nobtaining useful data (damage associated data) is challenging. In this paper,\n1-D Wasserstein loss Deep Convolutional Generative Adversarial Networks using\nGradient Penalty (1-D WDCGAN-GP) is utilized to generate damage associated\nvibration datasets that are similar to the input. For the purpose of\nvibration-based damage diagnostics, a 1-D Deep Convolutional Neural Network\n(1-D DCNN) is built, trained, and tested on both real and generated datasets.\nThe classification results from the 1-D DCNN on both datasets resulted to be\nvery similar to each other. The presented work in this paper shows that for the\ncases of insufficient data in DL or ML-based damage diagnostics, 1-D WDCGAN-GP\ncan successfully generate data for the model to be trained on. Keywords: 1-D\nGenerative Adversarial Networks (GAN), Deep Convolutional Generative\nAdversarial Networks (DCGAN), Wasserstein Generative Adversarial Networks with\nGradient Penalty (WGAN-GP), 1-D Convolutional Neural Networks (CNN), Structural\nHealth Monitoring (SHM), Structural Damage Diagnostics, Structural Damage\nDetection",
    "descriptor": "",
    "authors": [
      "Furkan Luleci",
      "F. Necati Catbas",
      "Onur Avci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.08196"
  },
  {
    "id": "arXiv:2112.08198",
    "title": "Single Image Automatic Radial Distortion Compensation Using Deep  Convolutional Network",
    "abstract": "In many computer vision domains, the input images must conform with the\npinhole camera model, where straight lines in the real world are projected as\nstraight lines in the image. Performing computer vision tasks on live sports\nbroadcast footage imposes challenging requirements where the algorithms cannot\nrely on a specific calibration pattern must be able to cope with unknown and\nuncalibrated cameras, radial distortion originating from complex television\nlenses, few visual clues to compensate distortion by, and the necessity for\nreal-time performance. We present a novel method for single-image automatic\nlens distortion compensation based on deep convolutional neural networks,\ncapable of real-time performance and accuracy using two highest-order\ncoefficients of the polynomial distortion model operating in the application\ndomain of sports broadcast. Keywords: Deep Convolutional Neural Network, Radial\nDistortion, Single Image Rectification",
    "descriptor": "",
    "authors": [
      "Igor Janos",
      "Wanda Benesova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08198"
  },
  {
    "id": "arXiv:2112.08200",
    "title": "Taming Overconfident Prediction on Unlabeled Data from Hindsight",
    "abstract": "Minimizing prediction uncertainty on unlabeled data is a key factor to\nachieve good performance in semi-supervised learning (SSL). The prediction\nuncertainty is typically expressed as the \\emph{entropy} computed by the\ntransformed probabilities in output space. Most existing works distill\nlow-entropy prediction by either accepting the determining class (with the\nlargest probability) as the true label or suppressing subtle predictions (with\nthe smaller probabilities). Unarguably, these distillation strategies are\nusually heuristic and less informative for model training. From this\ndiscernment, this paper proposes a dual mechanism, named ADaptive Sharpening\n(\\ADS), which first applies a soft-threshold to adaptively mask out determinate\nand negligible predictions, and then seamlessly sharpens the informed\npredictions, distilling certain predictions with the informed ones only. More\nimportantly, we theoretically analyze the traits of \\ADS by comparing with\nvarious distillation strategies. Numerous experiments verify that \\ADS\nsignificantly improves the state-of-the-art SSL methods by making it a plug-in.\nOur proposed \\ADS forges a cornerstone for future distillation-based SSL\nresearch.",
    "descriptor": "",
    "authors": [
      "Jing Li",
      "Yuangang Pan",
      "Ivor W. Tsang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08200"
  },
  {
    "id": "arXiv:2112.08207",
    "title": "Using the DELPHI Method for Model for Role Assignment in the Software  Industry",
    "abstract": "Over the past two decades, there has been a growing interest in modeling the\nelements that need to be considered when assigning people to roles in software\nprojects, as evidenced by the number of available publications related to the\ntopic. However, for the most part, these studies, have taken only a partial\napproach to the issue. Some have focused on the target roles competency\nprofile, while others have tried to understand the preferences of software\ndevelopers for activities linked to certain roles and the relationship between\nthese preferences and the candidates personal traits, to mention only two\nexamples. Our research aims to find elements that can be integrated into an\nallocation model that complements current approaches by including competencies,\npersonal traits, and project team building theories. To do so we performed an\nexperts consultation exercise using the DELPHI method; which allowed us to\nvalidate a set of patterns related to different candidates personal traits, and\nthe link between the teams motivational motors and their roles within the\nsoftware development.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Daniel Varona",
      "Luiz Fernando Capretz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.08207"
  },
  {
    "id": "arXiv:2112.08209",
    "title": "Modelling fatigue crack growth in Shape Memory Alloys",
    "abstract": "We present a phase field-based framework for modelling fatigue damage in\nShape Memory Alloys (SMAs). The model combines, for the first time: (i) a\ngeneralised phase field description of fracture, incorporating multiple phase\nfield formulations, (ii) a constitutive model for SMAs, based on a\nDrucker-Prager form of the transformation surface, and (iii) a fatigue\ndegradation function, with damage driven by both elastic and transformation\nstrains. The theoretical framework is numerically implemented, and the\nresulting linearised system is solved using a robust monolithic scheme, based\non quasi-Newton methods. Several paradigmatic boundary value problems are\naddressed to gain insight into the role of transformation stresses,\nstress-strain hysteresis and temperature. Namely, we compute $\\Delta\n\\varepsilon-N$ curves, quantify Paris law parameters and predict fatigue crack\ngrowth rates in several geometries. In addition, the potential of the model for\nsolving large-scale problems is demonstrated by simulating the fatigue failure\nof a 3D lattice structure.",
    "descriptor": "",
    "authors": [
      "M. Simoes",
      "C. Braithwaite",
      "A. Makaya",
      "E. Mart\u00ednez-Pa\u00f1eda"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.08209"
  },
  {
    "id": "arXiv:2112.08215",
    "title": "Two-Price Equilibrium",
    "abstract": "Walrasian equilibrium is a prominent market equilibrium notion, but rarely\nexists in markets with indivisible items. We introduce a new market equilibrium\nnotion, called two-price equilibrium (2PE). A 2PE is a relaxation of Walrasian\nequilibrium, where instead of a single price per item, every item has two\nprices: one for the item's owner and a (possibly) higher one for all other\nbuyers. Thus, a 2PE is given by a tuple\n$(\\textbf{S},\\mathbf{\\hat{p}},\\mathbf{\\check{p}})$ of an allocation\n$\\textbf{S}$ and two price vectors $\\mathbf{\\hat{p}},\\mathbf{\\check{p}}$, where\nevery buyer $i$ is maximally happy with her bundle $S_i$, given prices\n$\\mathbf{\\check{p}}$ for items in $S_i$ and prices $\\mathbf{\\hat{p}}$ for all\nother items. 2PE generalizes previous market equilibrium notions, such as\nconditional equilibrium, and is related to relaxed equilibrium notions like\nendowment equilibrium. We define the {\\em discrepancy} of a 2PE -- a measure of\ndistance from Walrasian equilibrium -- as the sum of differences\n$\\hat{p}_j-\\check{p}_j$ over all items (normalized by social welfare). We show\nthat the social welfare degrades gracefully with the discrepancy; namely, the\nsocial welfare of a 2PE with discrepancy $d$ is at least a fraction\n$\\frac{1}{d+1}$ of the optimal welfare. We use this to establish welfare\nguarantees for markets with subadditive valuations over identical items. In\nparticular, we show that every such market admits a 2PE with at least $1/7$ of\nthe optimal welfare. This is in contrast to Walrasian equilibrium or\nconditional equilibrium which may not even exist. Our techniques provide new\ninsights regarding valuation functions over identical items, which we also use\nto characterize instances that admit a WE.",
    "descriptor": "",
    "authors": [
      "Michal Feldman",
      "Galia Shabtai",
      "Aner Wolfenfeld"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.08215"
  },
  {
    "id": "arXiv:2112.08219",
    "title": "Quantitative analysis of visual representation of sign elements in  COVID-19 context",
    "abstract": "Representation is the way in which human beings re-present the reality of\nwhat is happening, both externally and internally. Thus, visual representation\nas a means of communication uses elements to build a narrative, just as spoken\nand written language do. We propose using computer analysis to perform a\nquantitative analysis of the elements used in the visual creations that have\nbeen produced in reference to the epidemic, using the images compiled in The\nCovid Art Museum's Instagram account to analyze the different elements used to\nrepresent subjective experiences with regard to a global event. This process\nhas been carried out with techniques based on machine learning to detect\nobjects in the images so that the algorithm can be capable of learning and\ndetecting the objects contained in each study image. This research reveals that\nthe elements that are repeated in images to create narratives and the relations\nof association that are established in the sample, concluding that, despite the\nsubjectivity that all creation entails, there are certain parameters of shared\nand reduced decisions when it comes to selecting objects to be included in\nvisual representations",
    "descriptor": "",
    "authors": [
      "Mar\u00eda Jes\u00fas Cano-Mart\u00ednez",
      "Miguel Carrasco",
      "Joaqu\u00edn Sandoval",
      "C\u00e9sar Gonz\u00e1lez-Mart\u00edn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.08219"
  },
  {
    "id": "arXiv:2112.08222",
    "title": "Guaranteed Contraction Control in the Presence of Imperfectly Learned  Dynamics",
    "abstract": "This paper presents an approach for trajectory-centric learning control based\non contraction metrics and disturbance estimation for nonlinear systems subject\nto matched uncertainties. The approach allows for the use of a broad class of\nmodel learning tools including deep neural networks to learn uncertain dynamics\nwhile still providing guarantees of transient tracking performance throughout\nthe learning phase, including the special case of no learning. Within the\nproposed approach, a disturbance estimation law is proposed to estimate the\npointwise value of the uncertainty, with pre-computable estimation error bounds\n(EEBs). The learned dynamics, the estimated disturbances, and the EEBs are then\nincorporated in a robust Riemannian energy condition to compute the control law\nthat guarantees exponential convergence of actual trajectories to desired ones\nthroughout the learning phase, even when the learned model is poor. On the\nother hand, with improved accuracy, the learned model can be incorporated in a\nhigh-level planner to plan better trajectories with improved performance, e.g.,\nlower energy consumption and shorter travel time. The proposed framework is\nvalidated on a planar quadrotor navigation example.",
    "descriptor": "\nComments: Shorter version submitted to L4DC 2022. 22 pages, 8 figures\n",
    "authors": [
      "Pan Zhao",
      "Ziyao Guo",
      "Yikun Cheng",
      "Aditya Gahlawat",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08222"
  },
  {
    "id": "arXiv:2112.08224",
    "title": "Disparities in Social Determinants among Performances of Mortality  Prediction with Machine Learning for Sepsis Patients",
    "abstract": "Background Sepsis is one of the most life-threatening circumstances for\ncritically ill patients in the US, while a standardized criteria for sepsis\nidentification is still under development. Disparities in social determinants\nof sepsis patients can interfere with the risk prediction performances using\nmachine learning. Methods Disparities in social determinants, including race,\ngender, marital status, insurance types and languages, among patients\nidentified by six available sepsis criteria were revealed by forest plots.\nSixteen machine learning classifiers were trained to predict in-hospital\nmortality for sepsis patients. The performance of the trained model was tested\non the entire randomly conducted test set and each sub-population built based\non each of the following social determinants: race, gender, marital status,\ninsurance type, and language. Results We analyzed a total of 11,791 critical\ncare patients from the MIMIC-III database. Within the population identified by\neach sepsis identification method, significant differences were observed among\nsub-populations regarding race, marital status, insurance type, and language.\nOn the 5,783 sepsis patients identified by the Sepsis-3 criteria statistically\nsignificant performance decreases for mortality prediction were observed when\napplying the trained machine learning model on Asian and Hispanic patients.\nWith pairwise comparison, we detected performance discrepancies in mortality\nprediction between Asian and White patients, Asians and patients of other\nraces, as well as English-speaking and Spanish-speaking patients. Conclusions\nDisparities in proportions of patients identified by various sepsis criteria\nwere detected among the different social determinant groups. To achieve\naccurate diagnosis, a versatile diagnostic system for sepsis is needed to\novercome the social determinant disparities of patients.",
    "descriptor": "",
    "authors": [
      "Hanyin Wang",
      "Yikuan Li",
      "Andrew Naidech",
      "Yuan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08224"
  },
  {
    "id": "arXiv:2112.08225",
    "title": "Inverse Optimal Safety Filters",
    "abstract": "CBF-QP safety filters are pointwise minimizers of the control effort at a\ngiven state vector, i.e., myopically optimal at each time instant. But are they\noptimal over the entire infinite time horizon? What does it even mean for a\ncontrolled dynamic systems to be \"optimally safe\" as opposed to, conventionally\n\"optimally stable\"? When disturbances, deterministic and stochastic, have\nunknown upper bounds, how should safety be defined to allow a graceful\ndegradation under disturbances? Can safety filters be designed to guarantee\nsuch weaker safety properties as well as the optimality of safety over the\ninfinite time horizon? We pose and answer these questions for general systems\naffine in control and disturbances and illustrate the answers using several\nexamples. In the process, using the existing QP safety filters, as well as more\ngeneral safety-ensuring feedbacks, we generate entire families of safety\nfilters which are optimal over the infinite horizon though they are\nconservative (favoring safety over `alertness') relative to the standard QP.",
    "descriptor": "",
    "authors": [
      "Miroslav Krstic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.08225"
  },
  {
    "id": "arXiv:2112.08227",
    "title": "An Experimental Study of the Impact of Pre-training on the Pruning of a  Convolutional Neural Network",
    "abstract": "In recent years, deep neural networks have known a wide success in various\napplication domains. However, they require important computational and memory\nresources, which severely hinders their deployment, notably on mobile devices\nor for real-time applications. Neural networks usually involve a large number\nof parameters, which correspond to the weights of the network. Such parameters,\nobtained with the help of a training process, are determinant for the\nperformance of the network. However, they are also highly redundant. The\npruning methods notably attempt to reduce the size of the parameter set, by\nidentifying and removing the irrelevant weights. In this paper, we examine the\nimpact of the training strategy on the pruning efficiency. Two training\nmodalities are considered and compared: (1) fine-tuned and (2) from scratch.\nThe experimental results obtained on four datasets (CIFAR10, CIFAR100, SVHN and\nCaltech101) and for two different CNNs (VGG16 and MobileNet) demonstrate that a\nnetwork that has been pre-trained on a large corpus (e.g. ImageNet) and then\nfine-tuned on a particular dataset can be pruned much more efficiently (up to\n80% of parameter reduction) than the same network trained from scratch.",
    "descriptor": "\nComments: 7 pages, published at APPIS 2020\n",
    "authors": [
      "Nathan Hubens",
      "Matei Mancas",
      "Bernard Gosselin",
      "Marius Preda",
      "Titus Zaharia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08227"
  },
  {
    "id": "arXiv:2112.08237",
    "title": "Exposure Inequality in People Recommender Systems: The Long-Term Effects",
    "abstract": "People recommender systems may affect the exposure that users receive in\nsocial networking platforms, influencing attention dynamics and potentially\nstrengthening pre-existing inequalities that disproportionately affect certain\ngroups.\nIn this paper we introduce a model to simulate the feedback loop created by\nmultiple rounds of interactions between users and a link recommender in a\nsocial network. This allows us to study the long-term consequences of those\nparticular recommendation algorithms. Our model is equipped with several\nparameters to control (i) the level of homophily in the network, (ii) the\nrelative size of the groups, (iii) the choice among several state-of-the-art\nlink recommenders, and (iv) the choice among three different user behavior\nmodels, that decide which recommendations are accepted or rejected.\nOur extensive experimentation with the proposed model shows that a minority\ngroup, if homophilic enough, can get a disproportionate advantage in exposure\nfrom all link recommenders. Instead, when it is heterophilic, it gets\nunder-exposed. Moreover, while the homophily level of the minority affects the\nspeed of the growth of the disparate exposure, the relative size of the\nminority affects the magnitude of the effect. Finally, link recommenders\nstrengthen exposure inequalities at the individual level, exacerbating the\n\"rich-get-richer\" effect: this happens for both the minority and the majority\nclass and independently of their level of homophily.",
    "descriptor": "\nComments: To appear in ICWSM 2022\n",
    "authors": [
      "Francesco Fabbri",
      "Maria Luisa Croci",
      "Francesco Bonchi",
      "Carlos Castillo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.08237"
  },
  {
    "id": "arXiv:2112.08250",
    "title": "Predicting the utility of search spaces for black-box optimization:a  simple, budget-aware approach",
    "abstract": "Black box optimization requires specifying a search space to explore for\nsolutions, e.g. a d-dimensional compact space, and this choice is critical for\ngetting the best results at a reasonable budget. Unfortunately, determining a\nhigh quality search space can be challenging in many applications. For example,\nwhen tuning hyperparameters for machine learning pipelines on a new problem\ngiven a limited budget, one must strike a balance between excluding potentially\npromising regions and keeping the search space small enough to be tractable.\nThe goal of this work is to motivate -- through example applications in tuning\ndeep neural networks -- the problem of predicting the quality of search spaces\nconditioned on budgets, as well as to provide a simple scoring method based on\na utility function applied to a probabilistic response surface model, similar\nto Bayesian optimization. We show that the method we present can compute\nmeaningful budget-conditional scores in a variety of situations. We also\nprovide experimental evidence that accurate scores can be useful in\nconstructing and pruning search spaces. Ultimately, we believe scoring search\nspaces should become standard practice in the experimental workflow for deep\nlearning.",
    "descriptor": "",
    "authors": [
      "Setareh Ariafar",
      "Justin Gilmer",
      "Zack Nado",
      "Jasper Snoek",
      "Rodolphe Jenatton",
      "George E. Dahl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08250"
  },
  {
    "id": "arXiv:2112.08253",
    "title": "Online Feature Selection for Efficient Learning in Networked Systems",
    "abstract": "Current AI/ML methods for data-driven engineering use models that are mostly\ntrained offline. Such models can be expensive to build in terms of\ncommunication and computing cost, and they rely on data that is collected over\nextended periods of time. Further, they become out-of-date when changes in the\nsystem occur. To address these challenges, we investigate online learning\ntechniques that automatically reduce the number of available data sources for\nmodel training. We present an online algorithm called Online Stable Feature Set\nAlgorithm (OSFS), which selects a small feature set from a large number of\navailable data sources after receiving a small number of measurements. The\nalgorithm is initialized with a feature ranking algorithm, a feature set\nstability metric, and a search policy. We perform an extensive experimental\nevaluation of this algorithm using traces from an in-house testbed and from a\ndata center in operation. We find that OSFS achieves a massive reduction in the\nsize of the feature set by 1-3 orders of magnitude on all investigated\ndatasets. Most importantly, we find that the accuracy of a predictor trained on\na OSFS-produced feature set is somewhat better than when the predictor is\ntrained on a feature set obtained through offline feature selection. OSFS is\nthus shown to be effective as an online feature selection algorithm and robust\nregarding the sample interval used for feature selection. We also find that,\nwhen concept drift in the data underlying the model occurs, its effect can be\nmitigated by recomputing the feature set and retraining the prediction model.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2010.14907\n",
    "authors": [
      "Xiaoxuan Wang",
      "Rolf Stadler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08253"
  },
  {
    "id": "arXiv:2112.08256",
    "title": "Est-ce que vous compute? Code-switching, cultural identity, and AI",
    "abstract": "Cultural code-switching concerns how we adjust our overall behaviours,\nmanners of speaking, and appearance in response to a perceived change in our\nsocial environment. We defend the need to investigate cultural code-switching\ncapacities in artificial intelligence systems. We explore a series of ethical\nand epistemic issues that arise when bringing cultural code-switching to bear\non artificial intelligence. Building upon Dotson's (2014) analysis of\ntestimonial smothering, we discuss how emerging technologies in AI can give\nrise to epistemic oppression, and specifically, a form of self-silencing that\nwe call 'cultural smothering'. By leaving the socio-dynamic features of\ncultural code-switching unaddressed, AI systems risk negatively impacting\nalready-marginalised social groups by widening opportunity gaps and further\nentrenching social inequalities.",
    "descriptor": "\nComments: 19 pages. Under Review. Please cite published version, if available\n",
    "authors": [
      "Arianna Falbo",
      "Travis LaCroix"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08256"
  },
  {
    "id": "arXiv:2112.08259",
    "title": "or2yw: Modeling and Visualizing OpenRefineHistories as YesWorkflow  Diagrams",
    "abstract": "OpenRefine is a popular open-source data cleaning tool. It allows users to\nexport a previously executed data cleaning workflow in a JSON format for\npossible reuse on other datasets. We have developed or2yw, a novel tool that\nmaps a JSON-formatted OpenRefine operation history to a YesWorkflow (YW) model,\nwhich then can be visualized and queried using the YW tool. The latter was\noriginally developed to allow researchers a simple way to annotate their\nprogram scripts in order to reveal the workflow steps and dataflow dependencies\nimplicit in those scripts. With or2yw the user can automatically generate YW\nmodels from OpenRefine operation histories, thus providing a 'workflow view' on\na previously executed sequence of data cleaning operations.\nThe or2yw tool can generate different types of YesWorkflow models, e.g., a\nlinear model which mirrors the sequential execution order of operations in\nOpenRefine, and a \\emph{parallel model} which reveals independent workflow\nbranches, based on a simple analysis of dependencies between steps: if two\noperations are independent of each other (e.g., when the columns they read and\nwrite do not overlap) then these can be viewed as parallel steps in the data\ncleaning workflow. The resulting YW models can be understood as a form of\nprospective provenance, i.e., knowledge artifacts that can be queried and\nvisualized (i) to help authors document their own data cleaning workflows,\nthereby increasing transparency, and (ii) to help other users, who might want\nto reuse such workflows, to understand them better.",
    "descriptor": "",
    "authors": [
      "Nikolaus Nova Parulian",
      "Lan Li",
      "Bertram Ludaescher"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.08259"
  },
  {
    "id": "arXiv:2112.08261",
    "title": "One System to Rule them All: a Universal Intent Recognition System for  Customer Service Chatbots",
    "abstract": "Customer service chatbots are conversational systems designed to provide\ninformation to customers about products/services offered by different\ncompanies. Particularly, intent recognition is one of the core components in\nthe natural language understating capabilities of a chatbot system. Among the\ndifferent intents that a chatbot is trained to recognize, there is a set of\nthem that is universal to any customer service chatbot. Universal intents may\ninclude salutation, switch the conversation to a human agent, farewells, among\nothers. A system to recognize those universal intents will be very helpful to\noptimize the training process of specific customer service chatbots. We propose\nthe development of a universal intent recognition system, which is trained to\nrecognize a selected group of 11 intents that are common in 28 different\nchatbots. The proposed system is trained considering state-of-the-art\nword-embedding models such as word2vec and BERT, and deep classifiers based on\nconvolutional and recurrent neural networks. The proposed model is able to\ndiscriminate between those universal intents with a balanced accuracy up to\n80.4\\%. In addition, the proposed system is equally accurate to recognize\nintents expressed both in short and long text requests. At the same time,\nmisclassification errors often occurs between intents with very similar\nsemantic fields such as farewells and positive comments. The proposed system\nwill be very helpful to optimize the training process of a customer service\nchatbot because some of the intents will be already available and detected by\nour system. At the same time, the proposed approach will be a suitable base\nmodel to train more specific chatbots by applying transfer learning strategies.",
    "descriptor": "",
    "authors": [
      "Juan Camilo Vasquez-Correa",
      "Juan Carlos Guerrero-Sierra",
      "Jose Luis Pemberty-Tamayo",
      "Juan Esteban Jaramillo",
      "Andres Felipe Tejada-Castro"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08261"
  },
  {
    "id": "arXiv:2112.08265",
    "title": "Causality in Requirements Artifacts: Prevalence, Detection, and Impact",
    "abstract": "Background: Causal relations in natural language (NL) requirements convey\nstrong, semantic information. Automatically extracting such causal information\nenables multiple use cases, such as test case generation, but it also requires\nto reliably detect causal relations in the first place. Currently, this is\nstill a cumbersome task as causality in NL requirements is still barely\nunderstood and, thus, barely detectable. Objective: In our empirically informed\nresearch, we aim at better understanding the notion of causality and supporting\nthe automatic extraction of causal relations in NL requirements. Method: In a\nfirst case study, we investigate 14.983 sentences from 53 requirements\ndocuments to understand the extent and form in which causality occurs. Second,\nwe present and evaluate a tool-supported approach, called CiRA, for causality\ndetection. We conclude with a second case study where we demonstrate the\napplicability of our tool and investigate the impact of causality on NL\nrequirements. Results: The first case study shows that causality constitutes\naround 28% of all NL requirements sentences. We then demonstrate that our\ndetection tool achieves a macro-F1 score of 82% on real-world data and that it\noutperforms related approaches with an average gain of 11.06% in macro-Recall\nand 11.43% in macro-Precision. Finally, our second case study corroborates the\npositive correlations of causality with features of NL requirements.\nConclusion: The results strengthen our confidence in the eligibility of causal\nrelations for downstream reuse, while our tool and publicly available data\nconstitute a first step in the ongoing endeavors of utilizing causality in RE\nand beyond.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2101.10766\n",
    "authors": [
      "Julian Frattini",
      "Jannik Fischbach",
      "Daniel Mendez",
      "Michael Unterkalmsteiner",
      "Andreas Vogelsang",
      "Krzystof Wnuk"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.08265"
  },
  {
    "id": "arXiv:2112.08266",
    "title": "KGR^4: Retrieval, Retrospect, Refine and Rethink for Commonsense  Generation",
    "abstract": "Generative commonsense reasoning requires machines to generate sentences\ndescribing an everyday scenario given several concepts, which has attracted\nmuch attention recently. However, existing models cannot perform as well as\nhumans, since sentences they produce are often implausible and grammatically\nincorrect. In this paper, inspired by the process of humans creating sentences,\nwe propose a novel Knowledge-enhanced Commonsense Generation framework, termed\nKGR^4, consisting of four stages: Retrieval, Retrospect, Refine, Rethink. Under\nthis framework, we first perform retrieval to search for relevant sentences\nfrom external corpus as the prototypes. Then, we train the generator that\neither edits or copies these prototypes to generate candidate sentences, of\nwhich potential errors will be fixed by an autoencoder-based refiner. Finally,\nwe select the output sentence from candidate sentences produced by generators\nwith different hyper-parameters. Experimental results and in-depth analysis on\nthe CommonGen benchmark strongly demonstrate the effectiveness of our\nframework. Particularly, KGR^4 obtains 33.56 SPICE points in the official\nleaderboard, outperforming the previously-reported best result by 2.49 SPICE\npoints and achieving state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Xin Liu",
      "Dayiheng Liu",
      "Baosong Yang",
      "Haibo Zhang",
      "Junwei Ding",
      "Wenqing Yao",
      "Weihua Luo",
      "Haiying Zhang",
      "Jinsong Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08266"
  },
  {
    "id": "arXiv:2112.08267",
    "title": "Harvesting Production GraphQL Queries to Detect Schema Faults",
    "abstract": "GraphQL is a new paradigm to design web APIs. Despite its growing popularity,\nthere are few techniques to verify the implementation of a GraphQL API. We\npresent a new testing approach based on GraphQL queries that are logged while\nusers interact with an application in production. Our core motivation is that\nproduction queries capture real usages of the application, and are known to\ntrigger behavior that may not be tested by developers. For each logged query, a\ntest is generated to assert the validity of the GraphQL response with respect\nto the schema. We implement our approach in a tool called AutoGraphQL, and\nevaluate it on two real-world case studies that are diverse in their domain and\ntechnology stack: an open-source e-commerce application implemented in Python\ncalled Saleor, and an industrial case study which is a PHP-based finance\nwebsite called Frontapp. AutoGraphQL successfully generates test cases for the\ntwo applications. The generated tests cover 26.9% of the Saleor schema,\nincluding parts of the API not exercised by the original test suite, as well as\n48.7% of the Frontapp schema, detecting 8 schema faults, thanks to production\nqueries.",
    "descriptor": "",
    "authors": [
      "Louise Zetterlund",
      "Deepika Tiwari",
      "Martin Monperrus",
      "Benoit Baudry"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.08267"
  },
  {
    "id": "arXiv:2112.08268",
    "title": "Prescriptive Machine Learning for Automated Decision Making: Challenges  and Opportunities",
    "abstract": "Recent applications of machine learning (ML) reveal a noticeable shift from\nits use for predictive modeling in the sense of a data-driven construction of\nmodels mainly used for the purpose of prediction (of ground-truth facts) to its\nuse for prescriptive modeling. What is meant by this is the task of learning a\nmodel that stipulates appropriate decisions about the right course of action in\nreal-world scenarios: Which medical therapy should be applied? Should this\nperson be hired for the job? As argued in this article, prescriptive modeling\ncomes with new technical conditions for learning and new demands regarding\nreliability, responsibility, and the ethics of decision making. Therefore, to\nsupport the data-driven design of decision-making agents that act in a rational\nbut at the same time responsible manner, a rigorous methodological foundation\nof prescriptive ML is needed. The purpose of this short paper is to elaborate\non specific characteristics of prescriptive ML and to highlight some key\nchallenges it implies. Besides, drawing connections to other branches of\ncontemporary AI research, the grounding of prescriptive ML in a (generalized)\ndecision-theoretic framework is advocated.",
    "descriptor": "",
    "authors": [
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.08268"
  },
  {
    "id": "arXiv:2112.08270",
    "title": "Next-generation Web Applications with WebAssembly and TruffleWasm",
    "abstract": "In modern software development, the JavaScript ecosystem of various\nframeworks and libraries used to develop contemporary web applications presents\nmany advantages. JavaScript is a widely known interpreted programming language,\nsimple to learn and start development, and with numerous third-party libraries\nand extensions. However, with the rise of highly user-interactive websites and\nbrowser-based games, in some cases, JavaScripts executable engine could lack in\nperformance. Therefore, developers could combine several other programming\nlanguages to create a polyglot user-interactive interoperable system to develop\nefficient modern web applications. The interoperability modules offer\nsignificant advantages but also present challenges in the execution due to high\ncomplexity and longer compilation times. This paper explores WebAssembly, a\nbinary format compilation target with a low-level assembly-like language used\nfor targeting from other programming languages. The binary format allows\nnear-native performance level due to its compactness, as it prioritizes usage\nof low-level languages. Moreover, as a continuation of our previous research of\nthe GraalVM ecosystem, we analyzed a guest language implementation of a\nWebAssembly based system, TruffleWasm, hosted on GraalVM and Truffle Java\nframework. This paper presents the architecture and review of the TruffleWasm\nwithin the GraalVM-based ecosystem as well as from performance test results\nwithin our academic environment.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "M. Sipek",
      "D. Muharemagic",
      "B. Mihaljevic",
      "A. Radovan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.08270"
  },
  {
    "id": "arXiv:2112.08272",
    "title": "Reflective Metagraph Rewriting as a Foundation for an AGI \"Language of  Thought\"",
    "abstract": "MeTTa (Meta Type Talk) is a novel programming language created for use in the\nOpenCog Hyperon AGI system. It is designed as a meta-language with very basic\nand general facilities for handling symbols, groundings, variables, types,\nsubstitutions and pattern matching. Primitives exist for creating new type\nsystems and associated DSLs. IInformally, MeTTa is Hyperon's lowest-level\n\"language of thought\" -- the meta-language in which algorithms for learning\nmore particular knowledge representations, will operate, and in which these\nalgorithms themselves may be represented. Here we explain how one might go\nabout formalizing the MeTTa language as a system of metagraph rewrite rules, an\napproach that fits in naturally to the Hyperon framework given that the\nlatter's core component is a distributed metagraph knowledge store (the\nAtomspace). The metagraph rewrite rules constituting MeTTa programs can also be\nrepresented as metagraphs, giving a natural model for MeTTa reflection and\nself-modifying code. Considering MeTTa programs that compute equivalences\nbetween execution traces of other MeTTa programs allows us to model spaces of\nMeTTa execution traces using Homotopy Type Theory. Considering the limit of\nMeTTa programs mapping between execution traces of MeTTa programs that map\nbetween execution traces of MeTTa programs that ..., we find that a given MeTTa\ncodebase is effectively modeled as an infinity-groupoid, and the space of all\nMeTTa codebases as an (infinity,1)-topis This topos is basically the same as\nthe so-called \"Ruliad\" previously derived from rewrite rules on hypergraphs, in\na discrete physics context. The formalization of MeTTA as metagraph rewrite\nrules may also provide a useful framework for structuring the implementation of\nefficient methods for pattern matching and equality inference within the MeTTa\ninterpreter.",
    "descriptor": "",
    "authors": [
      "Ben Goertzel"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.08272"
  },
  {
    "id": "arXiv:2112.08273",
    "title": "Programming Knowledge Tracing: A Comprehensive Dataset and A New Model",
    "abstract": "In this paper, we study knowledge tracing in the domain of programming\neducation and make two important contributions. First, we harvest and publish\nso far the most comprehensive dataset, namely BePKT, which covers various\nonline behaviors in an OJ system, including programming text problems,\nknowledge annotations, user-submitted code and system-logged events. Second, we\npropose a new model PDKT to exploit the enriched context for accurate student\nbehavior prediction. More specifically, we construct a bipartite graph for\nprogramming problem embedding, and design an improved pre-training model\nPLCodeBERT for code embedding, as well as a double-sequence RNN model with\nexponential decay attention for effective feature fusion. Experimental results\non the new dataset BePKT show that our proposed model establishes\nstate-of-the-art performance in programming knowledge tracing. In addition, we\nverify that our code embedding strategy based on PLCodeBERT is complementary to\nexisting knowledge tracing models to further enhance their accuracy. As a side\nproduct, PLCodeBERT also results in better performance in other\nprogramming-related tasks such as code clone detection.",
    "descriptor": "",
    "authors": [
      "Renyu Zhu",
      "Dongxiang Zhang",
      "Chengcheng Han",
      "Ming Gao",
      "Xuesong Lu",
      "Weining Qian",
      "Aoying Zhou"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08273"
  },
  {
    "id": "arXiv:2112.08274",
    "title": "Putting People in their Place: Monocular Regression of 3D People in  Depth",
    "abstract": "Given an image with multiple people, our goal is to directly regress the pose\nand shape of all the people as well as their relative depth. Inferring the\ndepth of a person in an image, however, is fundamentally ambiguous without\nknowing their height. This is particularly problematic when the scene contains\npeople of very different sizes, e.g. from infants to adults. To solve this, we\nneed several things. First, we develop a novel method to infer the poses and\ndepth of multiple people in a single image. While previous work that estimates\nmultiple people does so by reasoning in the image plane, our method, called\nBEV, adds an additional imaginary Bird's-Eye-View representation to explicitly\nreason about depth. BEV reasons simultaneously about body centers in the image\nand in depth and, by combing these, estimates 3D body position. Unlike prior\nwork, BEV is a single-shot method that is end-to-end differentiable. Second,\nheight varies with age, making it impossible to resolve depth without also\nestimating the age of people in the image. To do so, we exploit a 3D body model\nspace that lets BEV infer shapes from infants to adults. Third, to train BEV,\nwe need a new dataset. Specifically, we create a \"Relative Human\" (RH) dataset\nthat includes age labels and relative depth relationships between the people in\nthe images. Extensive experiments on RH and AGORA demonstrate the effectiveness\nof the model and training scheme. BEV outperforms existing methods on depth\nreasoning, child shape estimation, and robustness to occlusion. The code and\ndataset will be released for research purposes.",
    "descriptor": "\nComments: Code will be available at this https URL\n",
    "authors": [
      "Yu Sun",
      "Wu Liu",
      "Qian Bao",
      "Yili Fu",
      "Tao Mei",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08274"
  },
  {
    "id": "arXiv:2112.08275",
    "title": "SeqFormer: a Frustratingly Simple Model for Video Instance Segmentation",
    "abstract": "In this work, we present SeqFormer, a frustratingly simple model for video\ninstance segmentation. SeqFormer follows the principle of vision transformer\nthat models instance relationships among video frames. Nevertheless, we observe\nthat a stand-alone instance query suffices for capturing a time sequence of\ninstances in a video, but attention mechanisms should be done with each frame\nindependently. To achieve this, SeqFormer locates an instance in each frame and\naggregates temporal information to learn a powerful representation of a\nvideo-level instance, which is used to predict the mask sequences on each frame\ndynamically. Instance tracking is achieved naturally without tracking branches\nor post-processing. On the YouTube-VIS dataset, SeqFormer achieves 47.4 AP with\na ResNet-50 backbone and 49.0 AP with a ResNet-101 backbone without bells and\nwhistles. Such achievement significantly exceeds the previous state-of-the-art\nperformance by 4.6 and 4.4, respectively. In addition, integrated with the\nrecently-proposed Swin transformer, SeqFormer achieves a much higher AP of\n59.3. We hope SeqFormer could be a strong baseline that fosters future research\nin video instance segmentation, and in the meantime, advances this field with a\nmore robust, accurate, neat model. The code and the pre-trained models are\npublicly available at https://github.com/wjf5203/SeqFormer.",
    "descriptor": "",
    "authors": [
      "Junfeng Wu",
      "Yi Jiang",
      "Wenqing Zhang",
      "Xiang Bai",
      "Song Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08275"
  },
  {
    "id": "arXiv:2112.08279",
    "title": "Crowdsourcing County-Level Data on Early COVID-19 Policy Interventions  in the United States: Technical Report",
    "abstract": "Beginning in April 2020, we gathered partial county-level data on\nnon-pharmaceutical interventions (NPIs) implemented in response to the COVID-19\npandemic in the United States, using both volunteer and paid crowdsourcing. In\nthis report, we document the data collection process and summarize our results,\nto increase the utility of our open data and inform the design of future rapid\ncrowdsourcing data collection efforts.",
    "descriptor": "\nComments: Includes survey instrument\n",
    "authors": [
      "Jacob Ritchie",
      "Mark Whiting",
      "Sorathan Chaturapruek",
      "J.D. Zamfirescu-Pereira",
      "Madhav Marathe",
      "Achla Marathe",
      "Stephen Eubank",
      "Michael S. Bernstein"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.08279"
  },
  {
    "id": "arXiv:2112.08281",
    "title": "Detecting Object States vs Detecting Objects: A New Dataset and a  Quantitative Experimental Study",
    "abstract": "The detection of object states in images (State Detection - SD) is a problem\nof both theoretical and practical importance and it is tightly interwoven with\nother important computer vision problems, such as action recognition and\naffordance detection. It is also highly relevant to any entity that needs to\nreason and act in dynamic domains, such as robotic systems and intelligent\nagents. Despite its importance, up to now, the research on this problem has\nbeen limited. In this paper, we attempt a systematic study of the SD problem.\nFirst, we introduce the Object State Detection Dataset (OSDD), a new publicly\navailable dataset consisting of more than 19,000 annotations for 18 object\ncategories and 9 state classes. Second, using a standard deep learning\nframework used for Object Detection (OD), we conduct a number of appropriately\ndesigned experiments, towards an in-depth study of the behavior of the SD\nproblem. This study enables the setup of a baseline on the performance of SD,\nas well as its relative performance in comparison to OD, in a variety of\nscenarios. Overall, the experimental outcomes confirm that SD is harder than OD\nand that tailored SD methods need to be developed for addressing effectively\nthis significant problem.",
    "descriptor": "",
    "authors": [
      "Filippos Gouidis",
      "Theodoris Patkos",
      "Antonis Argyros",
      "Dimitris Plexousakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08281"
  },
  {
    "id": "arXiv:2112.08282",
    "title": "Distributed Applications in Gamification of the Learning Process",
    "abstract": "Driven by the fact that many of us experienced softer or not-so-soft\nlockdown, the intention of a couple of instructors at our university was to\ndevelop a collaborative tool that could help in online delivery and\ngamification on two courses that are delivered in the Business and IT\ncurriculums we are offering to our students. That tool could be described as a\ndecentralized web application that simulates Internet marketing principles and\nhelps in gamification of the learning process for our students. We planned our\nweb application for Internet marketing simulation as the gamification of the\nlearning process, which is one of the basics for active learning for Internet\nMarketing course for International Business students, to gain new class\nactivities by online simulation competing in the field of Internet marketing\nprinciples; and for IT students in developing the Web application and also on\nadopting Blockchain technologies for the distributed reports which need to have\na consensus of all teams included in the simulation. The proposed solution\nincludes the design of business logic simulation and using four main digital\nmarketing tools social networking, content creating and sharing, search engine\nmarketing, and display advertising in use of such application for hands-on\nonline class exercises.",
    "descriptor": "\nComments: 5 pages, 3 figures, 1 table\n",
    "authors": [
      "M. Zagar",
      "M. Sipek",
      "N. Draskovic",
      "B. Mihaljevic"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.08282"
  },
  {
    "id": "arXiv:2112.08283",
    "title": "Guarantees for existence of a best canonical polyadic approximation of a  noisy low-rank tensor",
    "abstract": "The canonical polyadic decomposition (CPD) of a low rank tensor plays a major\nrole in data analysis and signal processing by allowing for unique recovery of\nunderlying factors. However, it is well known that the low rank CPD\napproximation problem is ill-posed. That is, a tensor may fail to have a best\nrank $R$ CPD approximation when $R>1$.\nThis article gives deterministic bounds for the existence of best low rank\ntensor approximations over $\\mathbb{K}=\\mathbb{R}$ or $\\mathbb{K}=\\mathbb{C}$.\nMore precisely, given a tensor $\\mathcal{T} \\in \\mathbb{K}^{I \\times I \\times\nI}$ of rank $R \\leq I$, we compute the radius of a Frobenius norm ball centered\nat $\\mathcal{T}$ in which best $\\mathbb{K}$-rank $R$ approximations are\nguaranteed to exist. In addition we show that every $\\mathbb{K}$-rank $R$\ntensor inside of this ball has a unique canonical polyadic decomposition. This\nneighborhood may be interpreted as a neighborhood of \"mathematical truth\" in\nwith CPD approximation and computation is well-posed.\nIn pursuit of these bounds, we describe low rank tensor decomposition as a\n``joint generalized eigenvalue\" problem. Using this framework, we show that,\nunder mild assumptions, a low rank tensor which has rank strictly greater than\nborder rank is defective in the sense of algebraic and geometric multiplicities\nfor joint generalized eigenvalues. Bounds for existence of best low rank\napproximations are then obtained by establishing perturbation theoretic results\nfor the joint generalized eigenvalue problem. In this way we establish a\nconnection between existence of best low rank approximations and the tensor\nspectral norm. In addition we solve a \"tensor Procrustes problem\" which\nexamines orthogonal compressions for pairs of tensors.\nThe main results of the article are illustrated by a variety of numerical\nexperiments.",
    "descriptor": "\nComments: 46 pages. 8 Figures. Includes supplementary proofs. To appear in SIAM J. Matrix Anal. Appl\n",
    "authors": [
      "Eric Evert",
      "Lieven De Lathauwer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2112.08283"
  },
  {
    "id": "arXiv:2112.08288",
    "title": "Improving both domain robustness and domain adaptability in machine  translation",
    "abstract": "We address two problems of domain adaptation in neural machine translation.\nFirst, we want to reach domain robustness, i.e., good quality of both domains\nfrom the training data, and domains unseen in the training data. Second, we\nwant our systems to be adaptive, i.e., making it possible to finetune systems\nwith just hundreds of in-domain parallel sentences. In this paper, we introduce\na novel combination of two previous approaches, word adaptive modelling, which\naddresses domain robustness, and meta-learning, which addresses domain\nadaptability, and we present empirical results showing that our new combination\nimproves both of these properties.",
    "descriptor": "",
    "authors": [
      "Wen Lai",
      "Jind\u0159ich Libovick\u00fd",
      "Alexander Fraser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08288"
  },
  {
    "id": "arXiv:2112.08289",
    "title": "Decomposing Natural Logic Inferences in Neural NLI",
    "abstract": "In the interest of interpreting neural NLI models and their reasoning\nstrategies, we carry out a systematic probing study which investigates whether\nthese models capture the crucial semantic features central to natural logic:\nmonotonicity and concept inclusion. Correctly identifying valid inferences in\ndownward-monotone contexts is a known stumbling block for NLI performance,\nsubsuming linguistic phenomena such as negation scope and generalized\nquantifiers. To understand this difficulty, we emphasize monotonicity as a\nproperty of a context and examine the extent to which models capture\nmonotonicity information in the contextual embeddings which are intermediate to\ntheir decision making process. Drawing on the recent advancement of the probing\nparadigm, we compare the presence of monotonicity features across various\nmodels. We find that monotonicity information is notably weak in the\nrepresentations of popular NLI models which achieve high scores on benchmarks,\nand observe that previous improvements to these models based on fine-tuning\nstrategies have introduced stronger monotonicity features together with their\nimproved performance on challenge sets.",
    "descriptor": "",
    "authors": [
      "Julia Rozanova",
      "Deborah Ferreira",
      "Marco Valentino",
      "Mokanrarangan Thayaparan",
      "Andre Freitas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08289"
  },
  {
    "id": "arXiv:2112.08292",
    "title": "Verification of Component-based Systems with Recursive Architectures",
    "abstract": "We study a sound verification method for parametric component-based systems.\nThe method uses a resource logic, a new formal specification language for\ndistributed systems consisting of a finite yet unbounded number of components.\nThe logic allows the description of architecture configurations coordinating\ninstances of a finite number of types of components, by means of inductive\ndefinitions similar to the ones used to describe algebraic data types or\nrecursive data structures. For parametric systems specified in this logic, we\nshow that decision problems such as reaching deadlock or violating critical\nsection are undecidable, in general. Despite this negative result, we provide\nfor these decision problems practical semi-algorithms relying on the automatic\nsynthesis of structural invariants allowing the proof of general safety\nproperties. The invariants are defined using the WSkS fragment of the monadic\nsecond order logic, known to be decidable by a classical automata-logic\nconnection, thus reducing a verification problem to checking satisfiability of\na WSkS formula.",
    "descriptor": "",
    "authors": [
      "Marius Bozga",
      "Radu Iosif",
      "Joseph Sifakis"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.08292"
  },
  {
    "id": "arXiv:2112.08295",
    "title": "Advice Complexity of Online Non-Crossing Matching",
    "abstract": "We study online matching in the Euclidean $2$-dimesional plane with\nnon-crossing constraint. The offline version was introduced by Atallah in 1985\nand the online version was introduced and studied more recently by Bose et al.\nThe input to the problem consists of a sequence of points, and upon arrival of\na point an algorithm can match it with a previously unmatched point provided\nthat line segments corresponding to the matched edges do not intersect. The\ndecisions are irrevocable, and while an optimal offline solution always matches\nall the points, an online algorithm cannot match all the points in the worst\ncase, unless it is given some side information, i.e., advice. We study two\nversions of this problem -- monomchromatic (MNM) and bichromatic (BNM).\nWe show that advice complexity of solving BNM optimally on a circle (or, more\ngenerally, on inputs in a convex position) is tightly bounded by the logarithm\nof the $n^\\text{th}$ Catalan number from above and below. This result corrects\nthe previous claim of Bose et al. that the advice complexity is $\\log(n!)$. At\nthe heart of the result is a connection between non-crossing constraint in\nonline inputs and $231$-avoiding property of permutations of $n$ elements We\nalso show a lower bound of $n/3-1$ and an upper bound of $3n$ on the advice\ncomplexity for MNM on a plane. This gives an exponential improvement over the\npreviously best known lower bound and an improvement in the constant of the\nleading term in the upper bound. In addition, we establish a lower bound of\n$\\frac{\\alpha}{2}\\infdiv{\\frac{2(1-\\alpha)}{\\alpha}}{1/4}n$ on the advice\ncomplexity for achieving competitive ratio $\\alpha$ for MNM on a circle.\nStandard tools from advice complexity, such as partition trees and reductions\nfrom string guessing problem, do not seem to apply to MNM/BNM, so we have to\ndesign our lower bounds from first principles.",
    "descriptor": "",
    "authors": [
      "Ali Mohammad Lavasani",
      "Denis Pankratov"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.08295"
  },
  {
    "id": "arXiv:2112.08297",
    "title": "Rethinking Influence Functions of Neural Networks in the  Over-parameterized Regime",
    "abstract": "Understanding the black-box prediction for neural networks is challenging. To\nachieve this, early studies have designed influence function (IF) to measure\nthe effect of removing a single training point on neural networks. However, the\nclassic implicit Hessian-vector product (IHVP) method for calculating IF is\nfragile, and theoretical analysis of IF in the context of neural networks is\nstill lacking. To this end, we utilize the neural tangent kernel (NTK) theory\nto calculate IF for the neural network trained with regularized mean-square\nloss, and prove that the approximation error can be arbitrarily small when the\nwidth is sufficiently large for two-layer ReLU networks. We analyze the error\nbound for the classic IHVP method in the over-parameterized regime to\nunderstand when and why it fails or not. In detail, our theoretical analysis\nreveals that (1) the accuracy of IHVP depends on the regularization term, and\nis pretty low under weak regularization; (2) the accuracy of IHVP has a\nsignificant correlation with the probability density of corresponding training\npoints. We further borrow the theory from NTK to understand the IFs better,\nincluding quantifying the complexity for influential samples and depicting the\nvariation of IFs during the training dynamics. Numerical experiments on\nreal-world data confirm our theoretical results and demonstrate our findings.",
    "descriptor": "\nComments: To appear in AAAI 2022\n",
    "authors": [
      "Rui Zhang",
      "Shihua Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08297"
  },
  {
    "id": "arXiv:2112.08303",
    "title": "A recursive eigenspace computation for the Canonical Polyadic  decomposition",
    "abstract": "The canonical polyadic decomposition (CPD) is a compact decomposition which\nexpresses a tensor as a sum of its rank-1 components. A common step in the\ncomputation of a CPD is computing a generalized eigenvalue decomposition (GEVD)\nof the tensor. A GEVD provides an algebraic approximation of the CPD which can\nthen be used as an initialization in optimization routines.\nWhile in the noiseless setting GEVD exactly recovers the CPD, it has recently\nbeen shown that pencil-based computations such as GEVD are not stable. In this\narticle we present an algebraic method for approximation of a CPD which greatly\nimproves on the accuracy of GEVD. Our method is still fundamentally\npencil-based; however, rather than using a single pencil and computing all of\nits generalized eigenvectors, we use many different pencils and in each pencil\ncompute generalized eigenspaces corresponding to sufficiently well-separated\ngeneralized eigenvalues. The resulting \"generalized eigenspace decomposition\"\nis significantly more robust to noise than the classical GEVD.\nAccuracy of the generalized eigenspace decomposition is examined both\nempirically and theoretically. In particular, we provide a deterministic\nperturbation theoretic bound which is predictive of error in the computed\nfactorization.",
    "descriptor": "\nComments: 27 pages. 8 Figures. To appear in SIAM J. Matrix Anal. Appl\n",
    "authors": [
      "Eric Evert",
      "Michiel Vandecappelle",
      "Lieven De Lathauwer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08303"
  },
  {
    "id": "arXiv:2112.08304",
    "title": "On the Convergence and Robustness of Adversarial Training",
    "abstract": "Improving the robustness of deep neural networks (DNNs) to adversarial\nexamples is an important yet challenging problem for secure deep learning.\nAcross existing defense techniques, adversarial training with Projected\nGradient Decent (PGD) is amongst the most effective. Adversarial training\nsolves a min-max optimization problem, with the \\textit{inner maximization}\ngenerating adversarial examples by maximizing the classification loss, and the\n\\textit{outer minimization} finding model parameters by minimizing the loss on\nadversarial examples generated from the inner maximization. A criterion that\nmeasures how well the inner maximization is solved is therefore crucial for\nadversarial training. In this paper, we propose such a criterion, namely\nFirst-Order Stationary Condition for constrained optimization (FOSC), to\nquantitatively evaluate the convergence quality of adversarial examples found\nin the inner maximization. With FOSC, we find that to ensure better robustness,\nit is essential to use adversarial examples with better convergence quality at\nthe \\textit{later stages} of training. Yet at the early stages, high\nconvergence quality adversarial examples are not necessary and may even lead to\npoor robustness. Based on these observations, we propose a \\textit{dynamic}\ntraining strategy to gradually increase the convergence quality of the\ngenerated adversarial examples, which significantly improves the robustness of\nadversarial training. Our theoretical and empirical results show the\neffectiveness of the proposed method.",
    "descriptor": "\nComments: ICML 2019 Long Talk. Fixing bugs in the proof of Theorem 1\n",
    "authors": [
      "Yisen Wang",
      "Xingjun Ma",
      "James Bailey",
      "Jinfeng Yi",
      "Bowen Zhou",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08304"
  },
  {
    "id": "arXiv:2112.08306",
    "title": "Optimized numerical inverse Laplace transformation",
    "abstract": "Among the numerical inverse Laplace transformation (NILT) methods, those that\nbelong to the Abate-Whitt framework (AWF) are considered to be the most\nefficient ones currently. It is a characteristic feature of the AWF NILT\nprocedures that they are independent of the transform function and the time\npoint of interest.\nIn this work we propose an NILT procedure that goes beyond this limitation\nand optimize the accuracy of the NILT utilizing also the transform function and\nthe time point of interest.",
    "descriptor": "",
    "authors": [
      "Illes Horvath",
      "Andras Meszaros",
      "Miklos Telek"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08306"
  },
  {
    "id": "arXiv:2112.08313",
    "title": "Measure and Improve Robustness in NLP Models: A Survey",
    "abstract": "As NLP models achieved state-of-the-art performances over benchmarks and\ngained wide applications, it has been increasingly important to ensure the safe\ndeployment of these models in the real world, e.g., making sure the models are\nrobust against unseen or challenging scenarios. Despite robustness being an\nincreasingly studied topic, it has been separately explored in applications\nlike vision and NLP, with various definitions, evaluation and mitigation\nstrategies in multiple lines of research. In this paper, we aim to provide a\nunifying survey of how to define, measure and improve robustness in NLP. We\nfirst connect multiple definitions of robustness, then unify various lines of\nwork on identifying robustness failures and evaluating models' robustness.\nCorrespondingly, we present mitigation strategies that are data-driven,\nmodel-driven, and inductive-prior-based, with a more systematic view of how to\neffectively improve robustness in NLP models. Finally, we conclude by outlining\nopen challenges and future directions to motivate further research in this\narea.",
    "descriptor": "",
    "authors": [
      "Xuezhi Wang",
      "Haohan Wang",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08313"
  },
  {
    "id": "arXiv:2112.08315",
    "title": "Nirikshak: An Autonomous Testing Framework",
    "abstract": "Quality Assurance (QA) is an important part of any product. But even with\nautomated methods of software testing, QA is mostly a set of repetitive tasks.\nA lot of time, energy, and resources are spent in writing tests than in\nrealizing the bugs themselves and the traditional process does not scale well\nto changes in the software. With advances in data science, it is theoretically\npossible to have an autonomous testing framework. Such a framework would need\nminimal user input and will be able to perform the complete testing process by\nitself. This project is an effort to make such a framework.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Yash Mahalwal",
      "Pawel Pratyush",
      "Yogesh Poonia"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.08315"
  },
  {
    "id": "arXiv:2112.08321",
    "title": "CheckDST: Measuring Real-World Generalization of Dialogue State Tracking  Performance",
    "abstract": "Recent neural models that extend the pretrain-then-finetune paradigm continue\nto achieve new state-of-the-art results on joint goal accuracy (JGA) for\ndialogue state tracking (DST) benchmarks. However, we call into question their\nrobustness as they show sharp drops in JGA for conversations containing\nutterances or dialog flows with realistic perturbations. Inspired by CheckList\n(Ribeiro et al., 2020), we design a collection of metrics called CheckDST that\nfacilitate comparisons of DST models on comprehensive dimensions of robustness\nby testing well-known weaknesses with augmented test sets. We evaluate recent\nDST models with CheckDST and argue that models should be assessed more\nholistically rather than pursuing state-of-the-art on JGA since a higher JGA\ndoes not guarantee better overall robustness. We find that span-based\nclassification models are resilient to unseen named entities but not robust to\nlanguage variety, whereas those based on autoregressive language models\ngeneralize better to language variety but tend to memorize named entities and\noften hallucinate. Due to their respective weaknesses, neither approach is yet\nsuitable for real-world deployment. We believe CheckDST is a useful guide for\nfuture research to develop task-oriented dialogue models that embody the\nstrengths of various methods.",
    "descriptor": "",
    "authors": [
      "Hyundong Cho",
      "Chinnadhurai Sankar",
      "Christopher Lin",
      "Kaushik Ram Sadagopan",
      "Shahin Shayandeh",
      "Asli Celikyilmaz",
      "Jonathan May",
      "Ahmad Beirami"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08321"
  },
  {
    "id": "arXiv:2112.08325",
    "title": "ForgeryNet -- Face Forgery Analysis Challenge 2021: Methods and Results",
    "abstract": "The rapid progress of photorealistic synthesis techniques has reached a\ncritical point where the boundary between real and manipulated images starts to\nblur. Recently, a mega-scale deep face forgery dataset, ForgeryNet which\ncomprised of 2.9 million images and 221,247 videos has been released. It is by\nfar the largest publicly available in terms of data-scale, manipulations (7\nimage-level approaches, 8 video-level approaches), perturbations (36\nindependent and more mixed perturbations), and annotations (6.3 million\nclassification labels, 2.9 million manipulated area annotations, and 221,247\ntemporal forgery segment labels). This paper reports methods and results in the\nForgeryNet - Face Forgery Analysis Challenge 2021, which employs the ForgeryNet\nbenchmark. The model evaluation is conducted offline on the private test set. A\ntotal of 186 participants registered for the competition, and 11 teams made\nvalid submissions. We will analyze the top-ranked solutions and present some\ndiscussion on future work directions.",
    "descriptor": "\nComments: Technical report. Challenge website: this https URL\n",
    "authors": [
      "Yinan He",
      "Lu Sheng",
      "Jing Shao",
      "Ziwei Liu",
      "Zhaofan Zou",
      "Zhizhi Guo",
      "Shan Jiang",
      "Curitis Sun",
      "Guosheng Zhang",
      "Keyao Wang",
      "Haixiao Yue",
      "Zhibin Hong",
      "Wanguo Wang",
      "Zhenyu Li",
      "Qi Wang",
      "Zhenli Wang",
      "Ronghao Xu",
      "Mingwen Zhang",
      "Zhiheng Wang",
      "Zhenhang Huang",
      "Tianming Zhang",
      "Ningning Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08325"
  },
  {
    "id": "arXiv:2112.08326",
    "title": "Is \"my favorite new movie\" my favorite movie? Probing the Understanding  of Recursive Noun Phrases",
    "abstract": "Recursive noun phrases (NPs) have interesting semantic properties. For\nexample, \"my favorite new movie\" is not necessarily \"my favorite movie\",\nwhereas \"my new favorite movie\" is. This is common sense to humans, yet it is\nunknown whether pre-trained language models have such knowledge. We introduce\nthe Recursive Noun Phrase Challenge (RNPC), a challenge set targeting the\nunderstanding of recursive NPs. When evaluated on our dataset, state-of-the-art\nTransformer models only achieve around chance performance. Still, we show that\nsuch knowledge is learnable with appropriate data. We further probe the models\nfor relevant linguistic features that can be learned from our tasks, including\nmodifier semantic category and modifier scope. Finally, models trained on RNPC\nachieve strong zero-shot performance on an extrinsic Harm Detection task,\nshowing the usefulness of the understanding of recursive NPs in downstream\napplications. All code and data will be released at\nhttps://github.com/veronica320/Recursive-NPs.",
    "descriptor": "",
    "authors": [
      "Qing Lyu",
      "Hua Zheng",
      "Daoxin Li",
      "Li Zhang",
      "Marianna Apidianaki",
      "Chris Callison-Burch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08326"
  },
  {
    "id": "arXiv:2112.08327",
    "title": "Evaluating Pretrained Transformer Models for Entity Linking in  Task-Oriented Dialog",
    "abstract": "The wide applicability of pretrained transformer models (PTMs) for natural\nlanguage tasks is well demonstrated, but their ability to comprehend short\nphrases of text is less explored. To this end, we evaluate different PTMs from\nthe lens of unsupervised Entity Linking in task-oriented dialog across 5\ncharacteristics -- syntactic, semantic, short-forms, numeric and phonetic. Our\nresults demonstrate that several of the PTMs produce sub-par results when\ncompared to traditional techniques, albeit competitive to other neural\nbaselines. We find that some of their shortcomings can be addressed by using\nPTMs fine-tuned for text-similarity tasks, which illustrate an improved ability\nin comprehending semantic and syntactic correspondences, as well as some\nimprovements for short-forms, numeric and phonetic variations in entity\nmentions. We perform qualitative analysis to understand nuances in their\npredictions and discuss scope for further improvements. Code can be found at\nhttps://github.com/murali1996/el_tod",
    "descriptor": "\nComments: Accepted as short paper at ICON 2021\n",
    "authors": [
      "Sai Muralidhar Jayanthi",
      "Varsha Embar",
      "Karthik Raghunathan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08327"
  },
  {
    "id": "arXiv:2112.08331",
    "title": "Model Stealing Attacks Against Inductive Graph Neural Networks",
    "abstract": "Many real-world data come in the form of graphs. Graph neural networks\n(GNNs), a new family of machine learning (ML) models, have been proposed to\nfully leverage graph data to build powerful applications. In particular, the\ninductive GNNs, which can generalize to unseen data, become mainstream in this\ndirection. Machine learning models have shown great potential in various tasks\nand have been deployed in many real-world scenarios. To train a good model, a\nlarge amount of data as well as computational resources are needed, leading to\nvaluable intellectual property. Previous research has shown that ML models are\nprone to model stealing attacks, which aim to steal the functionality of the\ntarget models. However, most of them focus on the models trained with images\nand texts. On the other hand, little attention has been paid to models trained\nwith graph data, i.e., GNNs. In this paper, we fill the gap by proposing the\nfirst model stealing attacks against inductive GNNs. We systematically define\nthe threat model and propose six attacks based on the adversary's background\nknowledge and the responses of the target models. Our evaluation on six\nbenchmark datasets shows that the proposed model stealing attacks against GNNs\nachieve promising performance.",
    "descriptor": "\nComments: To Appear in the 43rd IEEE Symposium on Security and Privacy, May 22-26, 2022\n",
    "authors": [
      "Yun Shen",
      "Xinlei He",
      "Yufei Han",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08331"
  },
  {
    "id": "arXiv:2112.08333",
    "title": "AllWOZ: Towards Multilingual Task-Oriented Dialog Systems for All",
    "abstract": "A commonly observed problem of the state-of-the-art natural language\ntechnologies, such as Amazon Alexa and Apple Siri, is that their services do\nnot extend to most developing countries' citizens due to language barriers.\nSuch populations suffer due to the lack of available resources in their\nlanguages to build NLP products. This paper presents AllWOZ, a multilingual\nmulti-domain task-oriented customer service dialog dataset covering eight\nlanguages: English, Mandarin, Korean, Vietnamese, Hindi, French, Portuguese,\nand Thai. Furthermore, we create a benchmark for our multilingual dataset by\napplying mT5 with meta-learning.",
    "descriptor": "",
    "authors": [
      "Lei Zuo",
      "Kun Qian",
      "Bowen Yang",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08333"
  },
  {
    "id": "arXiv:2112.08338",
    "title": "Application of Blockchain Technology for Educational Platform",
    "abstract": "Nowadays, huge amounts of data are generated every second, and a quantity of\nthat data can be defined as sensitive. Blockchain technology has private,\nsecure, transparent and decentralized exchange of data as native. It is\nadaptable and can be used in a wide range of Internet-based interactive systems\nin academic and industrial settings. The essential part of programmable\ndistributed ledgers such as Ethereum, Polkadot, Cardano and other Web 3.0\ntechnologies are smart contracts. Smart contracts are programs executed on the\nglobal blockchain, the code is public as well as all of the data managed within\nthe transactions, thus creating a system that is reliable and cannot be cheated\nif designed properly. In this paper, in order to make the educational system\nmore transparent and versatile we will describe an educational learning\nplatform designed as a distributed system.",
    "descriptor": "\nComments: 6 pages, 1 figure\n",
    "authors": [
      "M. Sipek",
      "M. Zagar",
      "B. Mihaljevic",
      "N. Draskovic"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.08338"
  },
  {
    "id": "arXiv:2112.08340",
    "title": "GenIE: Generative Information Extraction",
    "abstract": "Structured and grounded representation of text is typically formalized by\nclosed information extraction, the problem of extracting an exhaustive set of\n(subject, relation, object) triplets that are consistent with a predefined set\nof entities and relations from a knowledge base schema. Most existing works are\npipelines prone to error accumulation, and all approaches are only applicable\nto unrealistically small numbers of entities and relations. We introduce GenIE\n(generative information extraction), the first end-to-end autoregressive\nformulation of closed information extraction. GenIE naturally exploits the\nlanguage knowledge from the pre-trained transformer by autoregressively\ngenerating relations and entities in textual form. Thanks to a new bi-level\nconstrained generation strategy, only triplets consistent with the predefined\nknowledge base schema are produced. Our experiments show that GenIE is\nstate-of-the-art on closed information extraction, generalizes from fewer\ntraining data points than baselines, and scales to a previously unmanageable\nnumber of entities and relations. With this work, closed information extraction\nbecomes practical in realistic scenarios, providing new opportunities for\ndownstream tasks. Finally, this work paves the way towards a unified end-to-end\napproach to the core tasks of information extraction. Code and models available\nat https://github.com/epfl-dlab/GenIE.",
    "descriptor": "",
    "authors": [
      "Martin Josifoski",
      "Nicola De Cao",
      "Maxime Peyrard",
      "Robert West"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08340"
  },
  {
    "id": "arXiv:2112.08342",
    "title": "DG2: Data Augmentation Through Document Grounded Dialogue Generation",
    "abstract": "Collecting data for training dialog systems can be extremely expensive due to\nthe involvement of human participants and need for extensive annotation.\nEspecially in document-grounded dialog systems, human experts need to carefully\nread the unstructured documents to answer the users' questions. As a result,\nexisting document-grounded dialog datasets are relatively small-scale and\nobstruct the effective training of dialogue systems. In this paper, we propose\nan automatic data augmentation technique grounded on documents through a\ngenerative dialogue model. The dialogue model consists of a user bot and agent\nbot that can synthesize diverse dialogues given an input document, which are\nthen used to train a downstream model. When supplementing the original dataset,\nour method achieves significant improvement over traditional data augmentation\nmethods. We also achieve great performance in the low-resource setting.",
    "descriptor": "",
    "authors": [
      "Qingyang Wu",
      "Song Feng",
      "Derek Chen",
      "Sachindra Joshi",
      "Luis A. Lastras",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08342"
  },
  {
    "id": "arXiv:2112.08345",
    "title": "Reliable Multi-Object Tracking in the Presence of Unreliable Detections",
    "abstract": "Recent multi-object tracking (MOT) systems have leveraged highly accurate\nobject detectors; however, training such detectors requires large amounts of\nlabeled data. Although such data is widely available for humans and vehicles,\nit is significantly more scarce for other animal species. We present Robust\nConfidence Tracking (RCT), an algorithm designed to maintain robust performance\neven when detection quality is poor. In contrast to prior methods which discard\ndetection confidence information, RCT takes a fundamentally different approach,\nrelying on the exact detection confidence values to initialize tracks, extend\ntracks, and filter tracks. In particular, RCT is able to minimize identity\nswitches by efficiently using low-confidence detections (along with a single\nobject tracker) to keep continuous track of objects. To evaluate trackers in\nthe presence of unreliable detections, we present a challenging real-world\nunderwater fish tracking dataset, FISHTRAC. In an evaluation on FISHTRAC as\nwell as the UA-DETRAC dataset, we find that RCT outperforms other algorithms\nwhen provided with imperfect detections, including state-of-the-art deep single\nand multi-object trackers as well as more classic approaches. Specifically, RCT\nhas the best average HOTA across methods that successfully return results for\nall sequences, and has significantly less identity switches than other methods.",
    "descriptor": "\nComments: 12 pages, 5 figures, 6 tables\n",
    "authors": [
      "Travis Mandel",
      "Mark Jimenez",
      "Emily Risley",
      "Taishi Nammoto",
      "Rebekka Williams",
      "Max Panoff",
      "Meynard Ballesteros",
      "Bobbie Suarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08345"
  },
  {
    "id": "arXiv:2112.08346",
    "title": "Simple Text Detoxification by Identifying a Linear Toxic Subspace in  Language Model Embeddings",
    "abstract": "Large pre-trained language models are often trained on large volumes of\ninternet data, some of which may contain toxic or abusive language.\nConsequently, language models encode toxic information, which makes the\nreal-world usage of these language models limited. Current methods aim to\nprevent toxic features from appearing generated text. We hypothesize the\nexistence of a low-dimensional toxic subspace in the latent space of\npre-trained language models, the existence of which suggests that toxic\nfeatures follow some underlying pattern and are thus removable. To construct\nthis toxic subspace, we propose a method to generalize toxic directions in the\nlatent space. We also provide a methodology for constructing parallel datasets\nusing a context based word masking system. Through our experiments, we show\nthat when the toxic subspace is removed from a set of sentence representations,\nalmost no toxic representations remain in the result. We demonstrate\nempirically that the subspace found using our method generalizes to multiple\ntoxicity corpora, indicating the existence of a low-dimensional toxic subspace.",
    "descriptor": "",
    "authors": [
      "Andrew Wang",
      "Mohit Sudhakar",
      "Yangfeng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08346"
  },
  {
    "id": "arXiv:2112.08348",
    "title": "PROMPT WAYWARDNESS: The Curious Case of Discretized Interpretation of  Continuous Prompts",
    "abstract": "Fine-tuning continuous prompts for target tasks has recently emerged as a\ncompact alternative to full model fine-tuning. Motivated by these promising\nresults, we investigate the feasibility of extracting a discrete (textual)\ninterpretation of continuous prompts that is faithful to the problem they\nsolve. In practice, we observe a \"wayward\" behavior between the task solved by\ncontinuous prompts and their nearest neighbor discrete projections: We can find\ncontinuous prompts that solve a task while being projected to an arbitrary text\n(e.g., definition of a different or even a contradictory task), while being\nwithin a very small (2%) margin of the best continuous prompt of the same size\nfor the task. We provide intuitions behind this odd and surprising behavior, as\nwell as extensive empirical analyses quantifying the effect of various\nparameters. For instance, for larger model sizes we observe higher waywardness,\ni.e, we can find prompts that more closely map to any arbitrary text with a\nsmaller drop in accuracy. These findings have important implications relating\nto the difficulty of faithfully interpreting continuous prompts and their\ngeneralization across models and tasks, providing guidance for future progress\nin prompting language models.",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Daniel Khashabi",
      "Shane Lyu",
      "Sewon Min",
      "Lianhui Qin",
      "Kyle Richardson",
      "Sameer Singh",
      "Sean Welleck",
      "Hannaneh Hajishirzi",
      "Tushar Khot",
      "Ashish Sabharwal",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08348"
  },
  {
    "id": "arXiv:2112.08351",
    "title": "Database Search Results Disambiguation for Task-Oriented Dialog Systems",
    "abstract": "As task-oriented dialog systems are becoming increasingly popular in our\nlives, more realistic tasks have been proposed and explored. However, new\npractical challenges arise. For instance, current dialog systems cannot\neffectively handle multiple search results when querying a database, due to the\nlack of such scenarios in existing public datasets. In this paper, we propose\nDatabase Search Result (DSR) Disambiguation, a novel task that focuses on\ndisambiguating database search results, which enhances user experience by\nallowing them to choose from multiple options instead of just one. To study\nthis task, we augment the popular task-oriented dialog datasets (MultiWOZ and\nSGD) with turns that resolve ambiguities by (a) synthetically generating turns\nthrough a pre-defined grammar, and (b) collecting human paraphrases for a\nsubset. We find that training on our augmented dialog data improves the model's\nability to deal with ambiguous scenarios, without sacrificing performance on\nunmodified turns. Furthermore, pre-fine tuning and multi-task learning help our\nmodel to improve performance on DSR-disambiguation even in the absence of\nin-domain data, suggesting that it can be learned as a universal dialog skill.\nOur data and code will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Kun Qian",
      "Ahmad Beirami",
      "Satwik Kottur",
      "Shahin Shayandeh",
      "Paul Crook",
      "Alborz Geramifard",
      "Zhou Yu",
      "Chinnadhurai Sankar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08351"
  },
  {
    "id": "arXiv:2112.08352",
    "title": "Textless Speech-to-Speech Translation on Real Data",
    "abstract": "We present a textless speech-to-speech translation (S2ST) system that can\ntranslate speech from one language into another language and can be built\nwithout the need of any text data. Different from existing work in the\nliterature, we tackle the challenge in modeling multi-speaker target speech and\ntrain the systems with real-world S2ST data. The key to our approach is a\nself-supervised unit-based speech normalization technique, which finetunes a\npre-trained speech encoder with paired audios from multiple speakers and a\nsingle reference speaker to reduce the variations due to accents, while\npreserving the lexical content. With only 10 minutes of paired data for speech\nnormalization, we obtain on average 3.2 BLEU gain when training the S2ST model\non the \\vp~S2ST dataset, compared to a baseline trained on un-normalized speech\ntarget. We also incorporate automatically mined S2ST data and show an\nadditional 2.0 BLEU gain. To our knowledge, we are the first to establish a\ntextless S2ST technique that can be trained with real-world data and works for\nmultiple language pairs.",
    "descriptor": "",
    "authors": [
      "Ann Lee",
      "Hongyu Gong",
      "Paul-Ambroise Duquenne",
      "Holger Schwenk",
      "Peng-Jen Chen",
      "Changhan Wang",
      "Sravya Popuri",
      "Juan Pino",
      "Jiatao Gu",
      "Wei-Ning Hsu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.08352"
  },
  {
    "id": "arXiv:2112.08355",
    "title": "Estimating Uncertainty For Vehicle Motion Prediction on Yandex Shifts  Dataset",
    "abstract": "Motion prediction of surrounding agents is an important task in context of\nautonomous driving since it is closely related to driver's safety. Vehicle\nMotion Prediction (VMP) track of Shifts Challenge focuses on developing models\nwhich are robust to distributional shift and able to measure uncertainty of\ntheir predictions. In this work we present the approach that significantly\nimproved provided benchmark and took 2nd place on the leaderboard.",
    "descriptor": "\nComments: Bayesian Deep Learning Workshop, NeurIPS 2021\n",
    "authors": [
      "Alexey Pustynnikov",
      "Dmitry Eremeev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08355"
  },
  {
    "id": "arXiv:2112.08357",
    "title": "Design Challenges for a Multi-Perspective Search Engine",
    "abstract": "Many users turn to document retrieval systems (e.g. search engines) to seek\nanswers to controversial questions. Answering such user queries usually require\nidentifying responses within web documents, and aggregating the responses based\non their different perspectives.\nClassical document retrieval systems fall short at delivering a set of direct\nand diverse responses to the users. Naturally, identifying such responses\nwithin a document is a natural language understanding task. In this paper, we\nexamine the challenges of synthesizing such language understanding objectives\nwith document retrieval, and study a new perspective-oriented document\nretrieval paradigm. We discuss and assess the inherent natural language\nunderstanding challenges in order to achieve the goal. Following the design\nchallenges and principles, we demonstrate and evaluate a practical prototype\npipeline system. We use the prototype system to conduct a user survey in order\nto assess the utility of our paradigm, as well as understanding the user\ninformation needs for controversial queries.",
    "descriptor": "",
    "authors": [
      "Sihao Chen",
      "Siyi Liu",
      "Xander Uyttendaele",
      "Yi Zhang",
      "William Bruno",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.08357"
  },
  {
    "id": "arXiv:2112.08359",
    "title": "3D Question Answering",
    "abstract": "Visual Question Answering (VQA) has witnessed tremendous progress in recent\nyears. However, most efforts only focus on the 2D image question answering\ntasks. In this paper, we present the first attempt at extending VQA to the 3D\ndomain, which can facilitate artificial intelligence's perception of 3D\nreal-world scenarios. Different from image based VQA, 3D Question Answering\n(3DQA) takes the color point cloud as input and requires both appearance and 3D\ngeometry comprehension ability to answer the 3D-related questions. To this end,\nwe propose a novel transformer-based 3DQA framework \\textbf{``3DQA-TR\"}, which\nconsists of two encoders for exploiting the appearance and geometry\ninformation, respectively. The multi-modal information of appearance, geometry,\nand the linguistic question can finally attend to each other via a\n3D-Linguistic Bert to predict the target answers. To verify the effectiveness\nof our proposed 3DQA framework, we further develop the first 3DQA dataset\n\\textbf{``ScanQA\"}, which builds on the ScanNet dataset and contains $\\sim$6K\nquestions, $\\sim$30K answers for $806$ scenes. Extensive experiments on this\ndataset demonstrate the obvious superiority of our proposed 3DQA framework over\nexisting VQA frameworks, and the effectiveness of our major designs. Our code\nand dataset will be made publicly available to facilitate the research in this\ndirection.",
    "descriptor": "",
    "authors": [
      "Shuquan Ye",
      "Dongdong Chen",
      "Songfang Han",
      "Jing Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08359"
  },
  {
    "id": "arXiv:2112.07669",
    "title": "AI and extreme scale computing to learn and infer the physics of higher  order gravitational wave modes of quasi-circular, spinning, non-precessing  binary black hole mergers",
    "abstract": "We use artificial intelligence (AI) to learn and infer the physics of higher\norder gravitational wave modes of quasi-circular, spinning, non precessing\nbinary black hole mergers. We trained AI models using 14 million waveforms,\nproduced with the surrogate model NRHybSur3dq8, that include modes up to $\\ell\n\\leq 4$ and $(5,5)$, except for $(4,0)$ and $(4,1)$, that describe binaries\nwith mass-ratios $q\\leq8$ and individual spins $s^z_{\\{1,2\\}}\\in[-0.8, 0.8]$.\nWe use our AI models to obtain deterministic and probabilistic estimates of the\nmass-ratio, individual spins, effective spin, and inclination angle of\nnumerical relativity waveforms that describe such signal manifold. Our studies\nindicate that AI provides informative estimates for these physical parameters.\nThis work marks the first time AI is capable of characterizing this\nhigh-dimensional signal manifold. Our AI models were trained within 3.4 hours\nusing distributed training on 256 nodes (1,536 NVIDIA V100 GPUs) in the Summit\nsupercomputer.",
    "descriptor": "\nComments: 21 pages, 12 figures\n",
    "authors": [
      "Asad Khan",
      "E.A. Huerta"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/2112.07669"
  },
  {
    "id": "arXiv:2112.07673",
    "title": "Machine learning a manifold",
    "abstract": "We propose a simple method to identify a continuous Lie algebra symmetry in a\ndataset through regression by an artificial neural network. Our proposal takes\nadvantage of the $ \\mathcal{O}(\\epsilon^2)$ scaling of the output variable\nunder infinitesimal symmetry transformations on the input variables. As\nsymmetry transformations are generated post-training, the methodology does not\nrely on sampling of the full representation space or binning of the dataset,\nand the possibility of false identification is minimised. We demonstrate our\nmethod in the SU(3)-symmetric (non-) linear $\\Sigma$ model.",
    "descriptor": "\nComments: 7 pages, 2 figures. (SC+RH) + DC^2 propose mape + epsilon^2\n",
    "authors": [
      "Sean Craven",
      "Djuna Croon",
      "Daniel Cutting",
      "Rachel Houtz"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07673"
  },
  {
    "id": "arXiv:2112.07782",
    "title": "Deciphering antibody affinity maturation with language models and weakly  supervised learning",
    "abstract": "In response to pathogens, the adaptive immune system generates specific\nantibodies that bind and neutralize foreign antigens. Understanding the\ncomposition of an individual's immune repertoire can provide insights into this\nprocess and reveal potential therapeutic antibodies. In this work, we explore\nthe application of antibody-specific language models to aid understanding of\nimmune repertoires. We introduce AntiBERTy, a language model trained on 558M\nnatural antibody sequences. We find that within repertoires, our model clusters\nantibodies into trajectories resembling affinity maturation. Importantly, we\nshow that models trained to predict highly redundant sequences under a multiple\ninstance learning framework identify key binding residues in the process. With\nfurther development, the methods presented here will provide new insights into\nantigen binding from repertoire sequences alone.",
    "descriptor": "\nComments: Presented at Machine Learning for Structural Biology Workshop, NeurIPS 2021\n",
    "authors": [
      "Jeffrey A. Ruffolo",
      "Jeffrey J. Gray",
      "Jeremias Sulam"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07782"
  },
  {
    "id": "arXiv:2112.07785",
    "title": "Variable Selection and Regularization via Arbitrary Rectangle-range  Generalized Elastic Net",
    "abstract": "We introduce the arbitrary rectangle-range generalized elastic net penalty\nmethod, abbreviated to ARGEN, for performing constrained variable selection and\nregularization in high-dimensional sparse linear models. As a natural extension\nof the nonnegative elastic net penalty method, ARGEN is proved to have variable\nselection consistency and estimation consistency under some conditions. The\nasymptotic behavior in distribution of the ARGEN estimators have been studied.\nWe also propose an algorithm called MU-QP-RR-W-$l_1$ to efficiently solve\nARGEN. By conducting simulation study we show that ARGEN outperforms the\nelastic net in a number of settings. Finally an application of S&P 500 index\ntracking with constraints on the stock allocations is performed to provide\ngeneral guidance for adapting ARGEN to solve real-world problems.",
    "descriptor": "\nComments: 25 pages, 2 figures\n",
    "authors": [
      "Yujia Ding",
      "Qidi Peng",
      "Zhengming Song",
      "Hansen Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07785"
  },
  {
    "id": "arXiv:2112.07815",
    "title": "Snake robot traversing large obstacles using vertical bending with force  feedback",
    "abstract": "Snake robots hold the promise as a versatile platform to traverse complex\nenvironments. Previous snake robots often used lateral bending to push against\nvertical structures on flat surfaces. Recent animal experiments revealed that\nvertical bending is also important for generating propulsion during traversal\nof terrain with large height variation. Although snake robots can propagate a\nvertical bending shape to passively push to traverse such terrain, it is\npossible that active pushing modulated by contact force and internal torque\nsensing can further help control propulsion. Here, we explore this question by\ntesting a previously developed robot with contact forces sensors added. We\ntested the robot using vertical bending to traverse a large obstacle and\ncompared five controllers without and with various sensory feedback using\nvarious force and torque information, as well as various load and terrain\nconditions to perturb the system. Feedforward propagation of vertical bending\nthat conforms to the terrain a priori can produce propulsion but fails with\nterrain perturbation that breaks conformation. In general, sensory feedback\nhelps better maintain or regain contact and propulsion, but different types of\nfeedback displayed different tradeoffs and varied performance. We also\nidentified issues that needs improvement in further development.",
    "descriptor": "\nComments: 8 pages, 10 figures; submitted to ICRA 2022\n",
    "authors": [
      "Qiyuan Fu",
      "Chen Li"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07815"
  },
  {
    "id": "arXiv:2112.07836",
    "title": "Communication-Efficient Distributed SGD with Compressed Sensing",
    "abstract": "We consider large scale distributed optimization over a set of edge devices\nconnected to a central server, where the limited communication bandwidth\nbetween the server and edge devices imposes a significant bottleneck for the\noptimization procedure. Inspired by recent advances in federated learning, we\npropose a distributed stochastic gradient descent (SGD) type algorithm that\nexploits the sparsity of the gradient, when possible, to reduce communication\nburden. At the heart of the algorithm is to use compressed sensing techniques\nfor the compression of the local stochastic gradients at the device side; and\nat the server side, a sparse approximation of the global stochastic gradient is\nrecovered from the noisy aggregated compressed local gradients. We conduct\ntheoretical analysis on the convergence of our algorithm in the presence of\nnoise perturbation incurred by the communication channels, and also conduct\nnumerical experiments to corroborate its effectiveness.",
    "descriptor": "",
    "authors": [
      "Yujie Tang",
      "Vikram Ramanathan",
      "Junshan Zhang",
      "Na Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.07836"
  },
  {
    "id": "arXiv:2112.07854",
    "title": "A terrain treadmill to study animal locomotion through large obstacles",
    "abstract": "A major challenge to understanding locomotion in complex 3-D terrain with\nlarge obstacles is to create tools for controlled, systematic lab experiments.\nExisting terrain arenas only allow observations at small spatiotemporal scales\n(~10 body length, ~10 stride cycles). Here, we create a terrain treadmill to\nenable high-resolution observations of animal locomotion through large\nobstacles over large spatiotemporal scales. An animal moves through modular\nobstacles on an inner sphere, while a rigidly-attached, concentric, transparent\nouter sphere rotated with the opposite velocity via closed-loop feedback to\nkeep the animal on top. During sustained locomotion, a discoid cockroach moved\nthrough pillar obstacles for 25 minutes ($\\approx$2500 strides) over 67 m\n($\\approx$1500 body lengths), and was contained within a radius of 4 cm (0.9\nbody length) for 83% of the duration, even at speeds of up to 10 body length/s.\nThe treadmill enabled observation of diverse locomotor behaviors and\nquantification of animal-obstacle interaction.",
    "descriptor": "",
    "authors": [
      "Ratan Othayoth",
      "Blake Strebel",
      "Yuanfeng Han",
      "Evains Francois",
      "Chen Li"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Systems and Control (eess.SY)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.07854"
  },
  {
    "id": "arXiv:2112.07862",
    "title": "Fast Computation of Generalized Eigenvectors for Manifold Graph  Embedding",
    "abstract": "Our goal is to efficiently compute low-dimensional latent coordinates for\nnodes in an input graph -- known as graph embedding -- for subsequent data\nprocessing such as clustering. Focusing on finite graphs that are interpreted\nas uniformly samples on continuous manifolds (called manifold graphs), we\nleverage existing fast extreme eigenvector computation algorithms for speedy\nexecution. We first pose a generalized eigenvalue problem for sparse matrix\npair $(\\A,\\B)$, where $\\A = \\L - \\mu \\Q + \\epsilon \\I$ is a sum of graph\nLaplacian $\\L$ and disconnected two-hop difference matrix $\\Q$. Eigenvector\n$\\v$ minimizing Rayleigh quotient $\\frac{\\v^{\\top} \\A \\v}{\\v^{\\top} \\v}$ thus\nminimizes $1$-hop neighbor distances while maximizing distances between\ndisconnected $2$-hop neighbors, preserving graph structure. Matrix $\\B =\n\\text{diag}(\\{\\b_i\\})$ that defines eigenvector orthogonality is then chosen so\nthat boundary / interior nodes in the sampling domain have the same generalized\ndegrees. $K$-dimensional latent vectors for the $N$ graph nodes are the first\n$K$ generalized eigenvectors for $(\\A,\\B)$, computed in $\\cO(N)$ using LOBPCG,\nwhere $K \\ll N$. Experiments show that our embedding is among the fastest in\nthe literature, while producing the best clustering performance for manifold\ngraphs.",
    "descriptor": "",
    "authors": [
      "Fei Chen",
      "Gene Cheung",
      "Xue Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07862"
  },
  {
    "id": "arXiv:2112.07884",
    "title": "Experimental quantum advantage with quantum coupon collector",
    "abstract": "An increasing number of communication and computational schemes with quantum\nadvantages have recently been proposed, which implies that quantum technology\nhas fertile application prospects. However, demonstrating these schemes\nexperimentally continues to be a central challenge because of the difficulty in\npreparing high-dimensional states or highly entangled states. In this study, we\nintroduce and analyse a quantum coupon collector protocol by employing coherent\nstates and simple linear optical elements, which was successfully demonstrated\nusing realistic experimental equipment. We showed that our protocol can\nsignificantly reduce the number of samples needed to learn a specific set\ncompared with the classical limit of the coupon collector problem. We also\ndiscuss the potential values and expansions of the quantum coupon collector by\nconstructing a quantum blind box game. The information transmitted by the\nproposed game also broke the classical limit. These results strongly prove the\nadvantages of quantum mechanics in machine learning and communication\ncomplexity.",
    "descriptor": "\nComments: 11 pages, 6 figures, 4 tables\n",
    "authors": [
      "Min-Gang Zhou",
      "Xiao-Yu Cao",
      "Yu-Shuo Lu",
      "Yang Wang",
      "Yu Bao",
      "Zhao-Ying Jia",
      "Yao Fu",
      "Hua-Lei Yin",
      "Zeng-Bing Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07884"
  },
  {
    "id": "arXiv:2112.07896",
    "title": "Invisibility enables super-visibility in electromagnetic imaging",
    "abstract": "This paper is concerned with the inverse electromagnetic scattering problem\nfor anisotropic media. We use the interior resonant modes to develop an inverse\nscattering scheme for imaging the scatterer. The whole procedure consists of\nthree phases. First, we determine the interior Maxwell transmission eigenvalues\nof the scatterer from a family of far-field data by the mechanism of the linear\nsampling method. Next, we determine the corresponding transmission\neigenfunctions by solving a constrained optimization problem. Finally, based on\nboth global and local geometric properties of the transmission eigenfunctions,\nwe design an imaging functional which can be used to determine the shape of the\nmedium scatterer. We provide rigorous theoretical basis for our method.\nNumerical experiments verify the effectiveness, better accuracy and\nsuper-resolution results of the proposed scheme.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Youzi He",
      "Hongyu Liu",
      "Xianchao Wang"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07896"
  },
  {
    "id": "arXiv:2112.07901",
    "title": "Energy-Efficient Real-Time Heart Monitoring on Edge-Fog-Cloud  Internet-of-Medical-Things",
    "abstract": "The recent developments in wearable devices and the Internet of Medical\nThings (IoMT) allow real-time monitoring and recording of electrocardiogram\n(ECG) signals. However, continuous monitoring of ECG signals is challenging in\nlow-power wearable devices due to energy and memory constraints. Therefore, in\nthis paper, we present a novel and energy-efficient methodology for\ncontinuously monitoring the heart for low-power wearable devices. The proposed\nmethodology is composed of three different layers: 1) a Noise/Artifact\ndetection layer to grade the quality of the ECG signals; 2) a Normal/Abnormal\nbeat classification layer to detect the anomalies in the ECG signals, and 3) an\nAbnormal beat classification layer to detect diseases from ECG signals.\nMoreover, a distributed multi-output Convolutional Neural Network (CNN)\narchitecture is used to decrease the energy consumption and latency between the\nedge-fog/cloud. Our methodology reaches an accuracy of 99.2% on the well-known\nMIT-BIH Arrhythmia dataset. Evaluation on real hardware shows that our\nmethodology is suitable for devices having a minimum RAM of 32KB. Moreover, the\nproposed methodology achieves $7\\times$ more energy efficiency compared to\nstate-of-the-art works.",
    "descriptor": "\nComments: To be appeared at IEEE Internet of Things (IoT) Journal\n",
    "authors": [
      "Berken Utku Demirel",
      "Islam Abdelsalam Bayoumy",
      "Mohammad Abdullah Al Faruque"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.07901"
  },
  {
    "id": "arXiv:2112.07995",
    "title": "Domain-informed neural networks for interaction localization within  astroparticle experiments",
    "abstract": "This work proposes a domain-informed neural network architecture for\nexperimental particle physics, using particle interaction localization with the\ntime-projection chamber (TPC) technology for dark matter research as an example\napplication. A key feature of the signals generated within the TPC is that they\nallow localization of particle interactions through a process called\nreconstruction. While multilayer perceptrons (MLPs) have emerged as a leading\ncontender for reconstruction in TPCs, such a black-box approach does not\nreflect prior knowledge of the underlying scientific processes. This paper\nlooks anew at neural network-based interaction localization and encodes prior\ndetector knowledge, in terms of both signal characteristics and detector\ngeometry, into the feature encoding and the output layers of a multilayer\nneural network. The resulting Domain-informed Neural Network (DiNN limits the\nreceptive fields of the neurons in the initial feature encoding layers in order\nto account for the spatially localized nature of the signals produced within\nthe TPC. This aspect of the DiNN, which has similarities with the emerging area\nof graph neural networks in that the neurons in the initial layers only connect\nto a handful of neurons in their succeeding layer, significantly reduces the\nnumber of parameters in the network in comparison to an MLP. In addition, in\norder to account for the detector geometry, the output layers of the network\nare modified using two geometric transformations to ensure the DiNN produces\nlocalizations within the interior of the detector. The end result is a neural\nnetwork architecture that has 60% fewer parameters than an MLP, but that still\nachieves similar localization performance and provides a path to future\narchitectural developments with improved performance because of their ability\nto encode additional domain knowledge into the architecture.",
    "descriptor": "\nComments: Submitted to journal. Data and simulation referenced in paper\n",
    "authors": [
      "Shixiao Liang",
      "Aaron Higuera",
      "Christina Peters",
      "Venkat Roy",
      "Waheed U. Bajwa",
      "Hagit Shatkay",
      "Christopher D. Tunnell"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07995"
  },
  {
    "id": "arXiv:2112.08011",
    "title": "Generalized Difference Coder: A Novel Conditional Autoencoder Structure  for Video Compression",
    "abstract": "Motion compensated inter prediction is a common component of all video\ncoders. The concept was established in traditional hybrid coding and\nsuccessfully transferred to learning-based video compression. To compress the\nresidual signal after prediction, usually the difference of the two signals is\ncompressed using a standard autoencoder. However, information theory tells us\nthat a general conditional coder is more efficient. In this paper, we provide a\nsolid foundation based on information theory and Shannon entropy to show the\npotentials but also the limits of conditional coding. Building on those\nresults, we then propose the generalized difference coder, a special case of a\nconditional coder designed to avoid limiting bottlenecks. With this coder, we\nare able to achieve average rate savings of 27.8% compared to a standard\nautoencoder, by only adding a moderate complexity overhead of less than 7%.",
    "descriptor": "",
    "authors": [
      "Fabian Brand",
      "J\u00fcrgen Seiler",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.08011"
  },
  {
    "id": "arXiv:2112.08055",
    "title": "Building separable approximations for quantum states via neural networks",
    "abstract": "Finding the closest separable state to a given target state is a notoriously\ndifficult task, even more difficult than deciding whether a state is entangled\nor separable. To tackle this task, we parametrize separable states with a\nneural network and train it to minimize the distance to a given target state,\nwith respect to a differentiable distance, such as the trace distance or\nHilbert-Schmidt distance. By examining the output of the algorithm, we can\ndeduce whether the target state is entangled or not, and construct an\napproximation for its closest separable state. We benchmark the method on a\nvariety of well-known classes of bipartite states and find excellent agreement,\neven up to local dimension of $d=10$. Moreover, we show our method to be\nefficient in the multipartite case, considering different notions of\nseparability. Examining three and four-party GHZ and W states we recover known\nbounds and obtain novel ones, for instance for triseparability. Finally, we\nshow how to use the neural network's results to gain analytic insight.",
    "descriptor": "\nComments: 11 pages, 5 figures We welcome any comments on references for Tables 1 and 2\n",
    "authors": [
      "Antoine Girardin",
      "Nicolas Brunner",
      "Tam\u00e1s Kriv\u00e1chy"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08055"
  },
  {
    "id": "arXiv:2112.08102",
    "title": "Robust Neural Network Classification via Double Regularization",
    "abstract": "The presence of mislabeled observations in data is a notoriously challenging\nproblem in statistics and machine learning, associated with poor generalization\nproperties for both traditional classifiers and, perhaps even more so, flexible\nclassifiers like neural networks. Here we propose a novel double regularization\nof the neural network training loss that combines a penalty on the complexity\nof the classification model and an optimal reweighting of training\nobservations. The combined penalties result in improved generalization\nproperties and strong robustness against overfitting in different settings of\nmislabeled training data and also against variation in initial parameter values\nwhen training. We provide a theoretical justification for our proposed method\nderived for a simple case of logistic regression. We demonstrate the double\nregularization model, here denoted by DRFit, for neural net classification of\n(i) MNIST and (ii) CIFAR-10, in both cases with simulated mislabeling. We also\nillustrate that DRFit identifies mislabeled data points with very good\nprecision. This provides strong support for DRFit as a practical of-the-shelf\nclassifier, since, without any sacrifice in performance, we get a classifier\nthat simultaneously reduces overfitting against mislabeling and gives an\naccurate measure of the trustworthiness of the labels.",
    "descriptor": "\nComments: 23 pages, 12 figures\n",
    "authors": [
      "Olof Zetterqvist",
      "Rebecka J\u00f6rnsten",
      "Johan Jonasson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.08102"
  },
  {
    "id": "arXiv:2112.08148",
    "title": "Composed Physics- and Data-driven System Identification for  Non-autonomous Systems in Control Engineering",
    "abstract": "In control design most control strategies are model-based and require\naccurate models to be applied successfully. Due to simplifications and the\nmodel-reality-gap physics-derived models frequently exhibit deviations from\nreal-world-systems. Likewise, purely data-driven methods often do not\ngeneralise well enough and may violate physical laws. Recently Physics-Guided\nNeural Networks (PGNN) and physics-inspired loss functions separately have\nshown promising results to conquer these drawbacks. In this contribution we\nextend existing methods towards the identification of non-autonomous systems\nand propose a combined approach PGNN-L, which uses a PGNN and a\nphysics-inspired loss term (-L) to successfully identify the system's dynamics,\nwhile maintaining the consistency with physical laws. The proposed method is\ndemonstrated on two real-world nonlinear systems and outperforms existing\ntechniques regarding complexity and reliability.",
    "descriptor": "\nComments: accepted for: 2022 3rd International Conference on Artificial Intelligence, Robotics and Control (AIRC 2022)\n",
    "authors": [
      "Ricarda-Samantha G\u00f6tte",
      "Julia Timmermann"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.08148"
  },
  {
    "id": "arXiv:2112.08151",
    "title": "Weighted analytic regularity for the integral fractional Laplacian in  polygons",
    "abstract": "We prove weighted analytic regularity of solutions to the Dirichlet problem\nfor the integral fractional Laplacian in polygons with analytic right-hand\nside. We localize the problem through the Caffarelli-Silvestre extension and\nstudy the tangential differentiability of the extended solutions, followed by\nbootstrapping based on Caccioppoli inequalities on dyadic decompositions of\nvertex, edge, and edge-vertex neighborhoods.",
    "descriptor": "",
    "authors": [
      "Markus Faustmann",
      "Carlo Marcati",
      "Jens Markus Melenk",
      "Christoph Schwab"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08151"
  },
  {
    "id": "arXiv:2112.08211",
    "title": "TrialGraph: Machine Intelligence Enabled Insight from Graph Modelling of  Clinical Trials",
    "abstract": "A major impediment to successful drug development is the complexity, cost,\nand scale of clinical trials. The detailed internal structure of clinical trial\ndata can make conventional optimization difficult to achieve. Recent advances\nin machine learning, specifically graph-structured data analysis, have the\npotential to enable significant progress in improving the clinical trial\ndesign. TrialGraph seeks to apply these methodologies to produce a\nproof-of-concept framework for developing models which can aid drug development\nand benefit patients. In this work, we first introduce a curated clinical trial\ndata set compiled from the CT.gov, AACT and TrialTrove databases (n=1191\ntrials; representing one million patients) and describe the conversion of this\ndata to graph-structured formats. We then detail the mathematical basis and\nimplementation of a selection of graph machine learning algorithms, which\ntypically use standard machine classifiers on graph data embedded in a\nlow-dimensional feature space. We trained these models to predict side effect\ninformation for a clinical trial given information on the disease, existing\nmedical conditions, and treatment. The MetaPath2Vec algorithm performed\nexceptionally well, with standard Logistic Regression, Decision Tree, Random\nForest, Support Vector, and Neural Network classifiers exhibiting typical\nROC-AUC scores of 0.85, 0.68, 0.86, 0.80, and 0.77, respectively. Remarkably,\nthe best performing classifiers could only produce typical ROC-AUC scores of\n0.70 when trained on equivalent array-structured data. Our work demonstrates\nthat graph modelling can significantly improve prediction accuracy on\nappropriate datasets. Successive versions of the project that refine modelling\nassumptions and incorporate more data types can produce excellent predictors\nwith real-world applications in drug development.",
    "descriptor": "\nComments: 17 pages (Manuscript); 3 pages (Supplemental Data); 9 figures\n",
    "authors": [
      "Christopher Yacoumatos",
      "Stefano Bragaglia",
      "Anshul Kanakia",
      "Nils Svang\u00e5rd",
      "Jonathan Mangion",
      "Claire Donoghue",
      "Jim Weatherall",
      "Faisal M. Khan",
      "Khader Shameer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.08211"
  },
  {
    "id": "arXiv:2112.08213",
    "title": "Enhancing operations management through smart sensors: measuring and  improving well-being, interaction and performance of logistics workers",
    "abstract": "Purpose The purpose of the research is to conduct an exploratory\ninvestigation of the material handling activities of an Italian logistics hub.\nWearable sensors and other smart tools were used for collecting human and\nenvironmental features during working activities. These factors were correlated\nwith workers' performance and well-being.\nDesign/methodology/approach Human and environmental factors play an important\nrole in operations management activities since they significantly influence\nemployees' performance, well-being and safety. Surprisingly, empirical studies\nabout the impact of such aspects on logistics operations are still very\nlimited. Trying to fill this gap, the research empirically explores human and\nenvironmental factors affecting the performance of logistics workers exploiting\nsmart tools.\nFindings Results suggest that human attitudes, interactions, emotions and\nenvironmental conditions remarkably influence workers' performance and\nwell-being, however, showing different relationships depending on individual\ncharacteristics of each worker.\nPractical implications The authors' research opens up new avenues for\nprofiling employees and adopting an individualized human resource management,\nproviding managers with an operational system capable to potentially check and\nimprove workers' well-being and performance.\nOriginality/value The originality of the study comes from the in-depth\nexploration of human and environmental factors using body-worn sensors during\nwork activities, by recording individual, collaborative and environmental data\nin real-time. To the best of the authors' knowledge, the current paper is the\nfirst time that such a detailed analysis has been carried out in real-world\nlogistics operations.",
    "descriptor": "\nComments: in press\n",
    "authors": [
      "D. Aloini",
      "A. Fronzetti Colladon",
      "P. Gloor",
      "E. Guerrazzi",
      "A. Stefanini"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08213"
  },
  {
    "id": "arXiv:2112.08217",
    "title": "Probabilistic Forecasting with Conditional Generative Networks via  Scoring Rule Minimization",
    "abstract": "Probabilistic forecasting consists of stating a probability distribution for\na future outcome based on past observations. In meteorology, ensembles of\nphysics-based numerical models are run to get such distribution. Usually,\nperformance is evaluated with scoring rules, functions of the forecast\ndistribution and the observed outcome. With some scoring rules, calibration and\nsharpness of the forecast can be assessed at the same time.\nIn deep learning, generative neural networks parametrize distributions on\nhigh-dimensional spaces and easily allow sampling by transforming draws from a\nlatent variable. Conditional generative networks additionally constrain the\ndistribution on an input variable. In this manuscript, we perform probabilistic\nforecasting with conditional generative networks trained to minimize scoring\nrule values. In contrast to Generative Adversarial Networks (GANs), no\ndiscriminator is required and training is stable. We perform experiments on two\nchaotic models and a global dataset of weather observations; results are\nsatisfactory and better calibrated than what achieved by GANs.",
    "descriptor": "",
    "authors": [
      "Lorenzo Pacchiardi",
      "Rilwan Adewoyin",
      "Peter Dueben",
      "Ritabrata Dutta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08217"
  },
  {
    "id": "arXiv:2112.08220",
    "title": "On the optimal consensus of crab submarines in one dimension",
    "abstract": "We consider the problem of computing the optimal meeting point of a set of N\ncrab submarines. First, we analyze the case where the submarines are allowed\nany position on the real line: we provide a constructive proof of optimality\nand we use it to provide a linear-time algorithm to find the optimal meeting\npoint. Second, we use the results for the continuous case to solve the case\nwhere the crab submarines are restricted to integer locations: we show that,\ngiven the solution of the corresponding continuous problem, we can find the\noptimal integer solution in linear time.",
    "descriptor": "\nComments: 8 pages, 3 figures, working paper\n",
    "authors": [
      "Riccardo Sven Risuleo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.08220"
  },
  {
    "id": "arXiv:2112.08232",
    "title": "RA V-Net: Deep learning network for automated liver segmentation",
    "abstract": "Accurate segmentation of the liver is a prerequisite for the diagnosis of\ndisease. Automated segmentation is an important application of computer-aided\ndetection and diagnosis of liver disease. In recent years, automated processing\nof medical images has gained breakthroughs. However, the low contrast of\nabdominal scan CT images and the complexity of liver morphology make accurate\nautomatic segmentation challenging. In this paper, we propose RA V-Net, which\nis an improved medical image automatic segmentation model based on U-Net. It\nhas the following three main innovations. CofRes Module (Composite Original\nFeature Residual Module) is proposed. With more complex convolution layers and\nskip connections to make it obtain a higher level of image feature extraction\ncapability and prevent gradient disappearance or explosion. AR Module\n(Attention Recovery Module) is proposed to reduce the computational effort of\nthe model. In addition, the spatial features between the data pixels of the\nencoding and decoding modules are sensed by adjusting the channels and LSTM\nconvolution. Finally, the image features are effectively retained. CA Module\n(Channel Attention Module) is introduced, which used to extract relevant\nchannels with dependencies and strengthen them by matrix dot product, while\nweakening irrelevant channels without dependencies. The purpose of channel\nattention is achieved. The attention mechanism provided by LSTM convolution and\nCA Module are strong guarantees for the performance of the neural network. The\naccuracy of U-Net network: 0.9862, precision: 0.9118, DSC: 0.8547, JSC: 0.82.\nThe evaluation metrics of RA V-Net, accuracy: 0.9968, precision: 0.9597, DSC:\n0.9654, JSC: 0.9414. The most representative metric for the segmentation effect\nis DSC, which improves 0.1107 over U-Net, and JSC improves 0.1214.",
    "descriptor": "",
    "authors": [
      "Zhiqi Lee",
      "Sumin Qi",
      "Chongchong Fan",
      "Ziwei Xie"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08232"
  },
  {
    "id": "arXiv:2112.08300",
    "title": "Community Detection in Electrical Grids Using Quantum Annealing",
    "abstract": "With the increase of intermittent renewable generation resources feeding into\nthe electrical grid, Distribution System Operators (DSOs) must find ways to\nincorporate these new actors and adapt the grid to ensure stability and enable\nflexibility. Dividing the grid into logical clusters entails several\norganization and technical benefits, helping overcome these challenges.However,\nfinding the optimal grid partitioning remains a challenging task due to its\ncomplexity. At the same time, a new technology has gained traction in the last\ndecades for its promising speed-up potential in solving non-trivial\ncombinatorial optimization problems: quantum computing. This work explores its\napplication in Graph Partitioning using electrical modularity. We benchmarked\nseveral quantum annealing and hybrid methods on IEEE well-known test cases. The\nresults obtained for the IEEE 14-bus test case show that quantum annealing\nDWaveSampler brings equal solutions or, for the optimal number partitions, a 1%\nimprovement. For the more significant test cases, hybrid quantum annealing\nshows a relative error of less than 0.02% compared to the classical benchmark\nand for IEEE 118-bus test case shows time performance speed-up. The increment\nin performance would enable real time planning and operations of electrical\ngrids in real time. This work intends to be the first step to showcase the\npotentials of quantum computing towards the modernization and adaption of\nelectrical grids to the decentralized future of energy systems.",
    "descriptor": "\nComments: 7 pages, 5 figures, conference\n",
    "authors": [
      "Marina Fern\u00e1ndez-Campoamor",
      "Corey O'Meara",
      "Giorgio Cortiana",
      "Vedran Peric",
      "Juan Bernab\u00e9-Moreno"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.08300"
  },
  {
    "id": "arXiv:1611.07466",
    "title": "Depth of vertices with high degree in random recursive trees",
    "abstract": "Comments: 19 pages, 2 figures",
    "descriptor": "\nComments: 19 pages, 2 figures\n",
    "authors": [
      "Laura Eslava"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1611.07466"
  },
  {
    "id": "arXiv:1701.04786",
    "title": "On Higher-Order Probabilistic Subrecursion",
    "abstract": "On Higher-Order Probabilistic Subrecursion",
    "descriptor": "",
    "authors": [
      "Flavien Breuvart",
      "Ugo Dal Lago",
      "Agathe Herrou"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1701.04786"
  },
  {
    "id": "arXiv:1812.02353",
    "title": "Top-K Off-Policy Correction for a REINFORCE Recommender System",
    "abstract": "Top-K Off-Policy Correction for a REINFORCE Recommender System",
    "descriptor": "",
    "authors": [
      "Minmin Chen",
      "Alex Beutel",
      "Paul Covington",
      "Sagar Jain",
      "Francois Belletti",
      "Ed Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1812.02353"
  },
  {
    "id": "arXiv:1904.11416",
    "title": "Bayesian Search for Robust Optima",
    "abstract": "Comments: Submitted to ACM Transactions on Evolutionary Learning and Optimization. 26 pages, 15 figures",
    "descriptor": "\nComments: Submitted to ACM Transactions on Evolutionary Learning and Optimization. 26 pages, 15 figures\n",
    "authors": [
      "Nicholas D. Sanders",
      "Richard M. Everson",
      "Jonathan E. Fieldsend",
      "Alma A. M. Rahat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1904.11416"
  },
  {
    "id": "arXiv:1907.02005",
    "title": "Virtual Energy Storage Sharing and Capacity Allocation",
    "abstract": "Comments: This is the online appendix for the paper published in IEEE Transactions on Smart Grid",
    "descriptor": "\nComments: This is the online appendix for the paper published in IEEE Transactions on Smart Grid\n",
    "authors": [
      "Dongwei Zhao",
      "Hao Wang",
      "Jianwei Huang",
      "Xiaojun Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1907.02005"
  },
  {
    "id": "arXiv:1908.02366",
    "title": "SaSTL: Spatial Aggregation Signal Temporal Logic for Runtime Monitoring  in Smart Cities",
    "abstract": "Comments: 12 pages, 7 figures, 5 tables",
    "descriptor": "\nComments: 12 pages, 7 figures, 5 tables\n",
    "authors": [
      "Meiyi Ma",
      "Ezio Bartocci",
      "Eli Lifland",
      "John Stankovic",
      "Lu Feng"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1908.02366"
  },
  {
    "id": "arXiv:1909.02746",
    "title": "NEAR: Neighborhood Edge AggregatoR for Graph Classification",
    "abstract": "Comments: 15 pages, 15 figures, 3 tables",
    "descriptor": "\nComments: 15 pages, 15 figures, 3 tables\n",
    "authors": [
      "Cheolhyeong Kim",
      "Haeseong Moon",
      "Hyung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.02746"
  },
  {
    "id": "arXiv:2003.08798",
    "title": "Incremental Object Detection via Meta-Learning",
    "abstract": "Comments: Published in IEEE Transactions on Pattern Analysis & Machine Intelligence, Nov 2021. Code is available in this https URL",
    "descriptor": "\nComments: Published in IEEE Transactions on Pattern Analysis & Machine Intelligence, Nov 2021. Code is available in this https URL\n",
    "authors": [
      "K J Joseph",
      "Jathushan Rajasegaran",
      "Salman Khan",
      "Fahad Shahbaz Khan",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.08798"
  },
  {
    "id": "arXiv:2004.01584",
    "title": "How Good are Low-Rank Approximations in Gaussian Process Regression?",
    "abstract": "How Good are Low-Rank Approximations in Gaussian Process Regression?",
    "descriptor": "",
    "authors": [
      "Constantinos Daskalakis",
      "Petros Dellaportas",
      "Aristeidis Panos"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2004.01584"
  },
  {
    "id": "arXiv:2004.12088",
    "title": "SplitFed: When Federated Learning Meets Split Learning",
    "abstract": "Comments: Accepted at AAAI 2022, Authors preprint version, 14 pages",
    "descriptor": "\nComments: Accepted at AAAI 2022, Authors preprint version, 14 pages\n",
    "authors": [
      "Chandra Thapa",
      "M.A.P. Chamikara",
      "Seyit Camtepe",
      "Lichao Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2004.12088"
  },
  {
    "id": "arXiv:2005.01185",
    "title": "Multivariate Time Series Forecasting with Transfer Entropy Graph",
    "abstract": "Multivariate Time Series Forecasting with Transfer Entropy Graph",
    "descriptor": "",
    "authors": [
      "Ziheng Duan",
      "Haoyan Xu",
      "Yida Huang",
      "Jie Feng",
      "Yueyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2005.01185"
  },
  {
    "id": "arXiv:2005.03950",
    "title": "RetinaFaceMask: A Single Stage Face Mask Detector for Assisting Control  of the COVID-19 Pandemic",
    "abstract": "Comments: This paper is accepted by IEEE SMC 2021",
    "descriptor": "\nComments: This paper is accepted by IEEE SMC 2021\n",
    "authors": [
      "Xinqi Fan",
      "Mingjie Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.03950"
  },
  {
    "id": "arXiv:2005.07609",
    "title": "An invertible crystallographic representation for general inverse design  of inorganic crystals with targeted properties",
    "abstract": "An invertible crystallographic representation for general inverse design  of inorganic crystals with targeted properties",
    "descriptor": "",
    "authors": [
      "Zekun Ren",
      "Siyu Isaac Parker Tian",
      "Juhwan Noh",
      "Felipe Oviedo",
      "Guangzong Xing",
      "Jiali Li",
      "Qiaohao Liang",
      "Ruiming Zhu",
      "Armin G.Aberle",
      "Shijing Sun",
      "Xiaonan Wang",
      "Yi Liu",
      "Qianxiao Li",
      "Senthilnath Jayavelu",
      "Kedar Hippalgaonkar",
      "Yousung Jung",
      "Tonio Buonassisi"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.07609"
  },
  {
    "id": "arXiv:2005.11052",
    "title": "VDO-SLAM: A Visual Dynamic Object-aware SLAM System",
    "abstract": "Comments: 15 pages, 11 figures, 5 tables",
    "descriptor": "\nComments: 15 pages, 11 figures, 5 tables\n",
    "authors": [
      "Jun Zhang",
      "Mina Henein",
      "Robert Mahony",
      "Viorela Ila"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2005.11052"
  },
  {
    "id": "arXiv:2005.11098",
    "title": "Deep Learning Based Detection and Localization of Intracranial Aneurysms  in Computed Tomography Angiography",
    "abstract": "Deep Learning Based Detection and Localization of Intracranial Aneurysms  in Computed Tomography Angiography",
    "descriptor": "",
    "authors": [
      "Dufan Wu",
      "Daniel Montes",
      "Ziheng Duan",
      "Yangsibo Huang",
      "Javier M. Romero",
      "Ramon Gilberto Gonzalez",
      "Quanzheng Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.11098"
  },
  {
    "id": "arXiv:2006.03814",
    "title": "The Impact of Global Structural Information in Graph Neural Networks  Applications",
    "abstract": "The Impact of Global Structural Information in Graph Neural Networks  Applications",
    "descriptor": "",
    "authors": [
      "Davide Buffelli",
      "Fabio Vandin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.03814"
  },
  {
    "id": "arXiv:2006.06285",
    "title": "An improved constant factor for the unit distance problem",
    "abstract": "An improved constant factor for the unit distance problem",
    "descriptor": "",
    "authors": [
      "P\u00e9ter \u00c1goston",
      "D\u00f6m\u00f6t\u00f6r P\u00e1lv\u00f6lgyi"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2006.06285"
  },
  {
    "id": "arXiv:2006.06581",
    "title": "Asymptotic Errors for Teacher-Student Convex Generalized Linear Models  (or : How to Prove Kabashima's Replica Formula)",
    "abstract": "Comments: 19 pages,25 appendix,4 figures",
    "descriptor": "\nComments: 19 pages,25 appendix,4 figures\n",
    "authors": [
      "Cedric Gerbelot",
      "Alia Abbara",
      "Florent Krzakala"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2006.06581"
  },
  {
    "id": "arXiv:2007.05447",
    "title": "Generalized Maximum Entropy for Supervised Classification",
    "abstract": "Generalized Maximum Entropy for Supervised Classification",
    "descriptor": "",
    "authors": [
      "Santiago Mazuelas",
      "Yuan Shen",
      "Aritz P\u00e9rez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.05447"
  },
  {
    "id": "arXiv:2008.05449",
    "title": "Profiling Gas Consumption in Solidity Smart Contracts",
    "abstract": "Profiling Gas Consumption in Solidity Smart Contracts",
    "descriptor": "",
    "authors": [
      "Andrea Di Sorbo",
      "Sonia Laudanna",
      "Anna Vacca",
      "Corrado A. Visaggio",
      "Gerardo Canfora"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2008.05449"
  },
  {
    "id": "arXiv:2008.08617",
    "title": "MTHetGNN: A Heterogeneous Graph Embedding Framework for Multivariate  Time Series Forecasting",
    "abstract": "MTHetGNN: A Heterogeneous Graph Embedding Framework for Multivariate  Time Series Forecasting",
    "descriptor": "",
    "authors": [
      "Yueyang Wang",
      "Ziheng Duan",
      "Yida Huang",
      "Haoyan Xu",
      "Jie Feng",
      "Anni Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.08617"
  },
  {
    "id": "arXiv:2008.09870",
    "title": "Fast ORB-SLAM Method without Keypoint Descriptors",
    "abstract": "Comments: Keypoint Matching, Optical Flow, Motion Model, ORB SLAM, Pose, Estimation, Visual SLAM",
    "descriptor": "\nComments: Keypoint Matching, Optical Flow, Motion Model, ORB SLAM, Pose, Estimation, Visual SLAM\n",
    "authors": [
      "Qiang Fu",
      "Hongshan Yu",
      "Xiaolong Wang",
      "Zhengeng Yang",
      "Yong He",
      "Hong Zhang",
      "Ajmal Mian"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2008.09870"
  },
  {
    "id": "arXiv:2009.00736",
    "title": "Error estimates for a pointwise tracking optimal control problem of a  semilinear elliptic equation",
    "abstract": "Error estimates for a pointwise tracking optimal control problem of a  semilinear elliptic equation",
    "descriptor": "",
    "authors": [
      "Alejandro Allendes",
      "Francisco Fuica",
      "Enrique Otarola"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2009.00736"
  },
  {
    "id": "arXiv:2009.00934",
    "title": "SAIL: Self-Augmented Graph Contrastive Learning",
    "abstract": "Comments: Accepted by AAAI2022, 10 pages, 3 figures",
    "descriptor": "\nComments: Accepted by AAAI2022, 10 pages, 3 figures\n",
    "authors": [
      "Lu Yu",
      "Shichao Pei",
      "Lizhong Ding",
      "Jun Zhou",
      "Longfei Li",
      "Chuxu Zhang",
      "Xiangliang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.00934"
  },
  {
    "id": "arXiv:2009.01219",
    "title": "Weak error rates for option pricing under linear rough volatility",
    "abstract": "Comments: 28 pages, 4 figures",
    "descriptor": "\nComments: 28 pages, 4 figures\n",
    "authors": [
      "Christian Bayer",
      "Eric Joseph Hall",
      "Ra\u00fal Tempone"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Mathematical Finance (q-fin.MF)"
    ],
    "url": "https://arxiv.org/abs/2009.01219"
  },
  {
    "id": "arXiv:2009.14754",
    "title": "Enhanced Standard Compatible Image Compression Framework based on  Auxiliary Codec Networks",
    "abstract": "Comments: Accepted by IEEE Transactions on image processing",
    "descriptor": "\nComments: Accepted by IEEE Transactions on image processing\n",
    "authors": [
      "Hanbin Son",
      "Taeoh Kim",
      "Hyeongmin Lee",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.14754"
  },
  {
    "id": "arXiv:2010.03090",
    "title": "Validating UTF-8 In Less Than One Instruction Per Byte",
    "abstract": "Validating UTF-8 In Less Than One Instruction Per Byte",
    "descriptor": "",
    "authors": [
      "John Keiser",
      "Daniel Lemire"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2010.03090"
  },
  {
    "id": "arXiv:2010.03478",
    "title": "The Gaussian Wave Packet Transform via Quadrature Rules",
    "abstract": "Comments: Version 2: Additional references, extension of the theoretical results to dimensions d&gt;1 and some corrections to version 1",
    "descriptor": "\nComments: Version 2: Additional references, extension of the theoretical results to dimensions d&gt;1 and some corrections to version 1\n",
    "authors": [
      "Paul Bergold",
      "Caroline Lasser"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.03478"
  },
  {
    "id": "arXiv:2010.04855",
    "title": "Generalized Kernel Ridge Regression for Nonparametric Structural  Functions and Semiparametric Treatment Effects",
    "abstract": "Comments: Formerly \"Kernel Methods for Policy Evaluation: Treatment Effects, Mediation Analysis, and Off-Policy Planning\" (2020)",
    "descriptor": "\nComments: Formerly \"Kernel Methods for Policy Evaluation: Treatment Effects, Mediation Analysis, and Off-Policy Planning\" (2020)\n",
    "authors": [
      "Rahul Singh",
      "Liyuan Xu",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.04855"
  },
  {
    "id": "arXiv:2010.09536",
    "title": "What About Inputing Policy in Value Function: Policy Representation and  Policy-extended Value Function Approximator",
    "abstract": "Comments: Accepted as a conference paper on AAAI 2022",
    "descriptor": "\nComments: Accepted as a conference paper on AAAI 2022\n",
    "authors": [
      "Hongyao Tang",
      "Zhaopeng Meng",
      "Jianye Hao",
      "Chen Chen",
      "Daniel Graves",
      "Dong Li",
      "Changmin Yu",
      "Hangyu Mao",
      "Wulong Liu",
      "Yaodong Yang",
      "Wenyuan Tao",
      "Li Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.09536"
  },
  {
    "id": "arXiv:2010.15571",
    "title": "Learning Sub-Patterns in Piecewise Continuous Functions",
    "abstract": "Comments: 16 Pages + 7 Page Appendix, 9 Figures, and 6 Tables",
    "descriptor": "\nComments: 16 Pages + 7 Page Appendix, 9 Figures, and 6 Tables\n",
    "authors": [
      "Anastasis Kratsios",
      "Behnoosh Zamanlooy"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.15571"
  },
  {
    "id": "arXiv:2011.00132",
    "title": "A mixed elasticity formulation for fluid-poroelastic structure  interaction",
    "abstract": "A mixed elasticity formulation for fluid-poroelastic structure  interaction",
    "descriptor": "",
    "authors": [
      "Tongtong Li",
      "Ivan Yotov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.00132"
  },
  {
    "id": "arXiv:2011.03885",
    "title": "Performative Prediction in a Stateful World",
    "abstract": "Comments: An earlier version of this paper appeared at the Workshop on Consequential Decision Making in Dynamic Environments, NeurIPS 2020",
    "descriptor": "\nComments: An earlier version of this paper appeared at the Workshop on Consequential Decision Making in Dynamic Environments, NeurIPS 2020\n",
    "authors": [
      "Gavin Brown",
      "Shlomi Hod",
      "Iden Kalemaj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2011.03885"
  },
  {
    "id": "arXiv:2011.06236",
    "title": "Adaptive Force-based Control for Legged Robots",
    "abstract": "Adaptive Force-based Control for Legged Robots",
    "descriptor": "",
    "authors": [
      "Mohsen Sombolestan",
      "Yiyu Chen",
      "Quan Nguyen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.06236"
  },
  {
    "id": "arXiv:2012.01850",
    "title": "Mathematical Game Theory",
    "abstract": "Mathematical Game Theory",
    "descriptor": "",
    "authors": [
      "Ulrich Faigle"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2012.01850"
  },
  {
    "id": "arXiv:2012.06261",
    "title": "Reconfigurable Intelligent Surface Based Hybrid Precoding for THz  Communications",
    "abstract": "Comments: 26 pages, 7 figures",
    "descriptor": "\nComments: 26 pages, 7 figures\n",
    "authors": [
      "Yu Lu",
      "Mo Hao",
      "Richard MAcKenzie"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2012.06261"
  },
  {
    "id": "arXiv:2012.06264",
    "title": "A Comprehensive Study of Code-removal Patches in Automated Program  Repair",
    "abstract": "Comments: New version of the manuscript",
    "descriptor": "\nComments: New version of the manuscript\n",
    "authors": [
      "Davide Ginelli",
      "Matias Martinez",
      "Leonardo Mariani",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2012.06264"
  },
  {
    "id": "arXiv:2012.14843",
    "title": "Learning Adversarial Markov Decision Processes with Delayed Feedback",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Tal Lancewicki",
      "Aviv Rosenberg",
      "Yishay Mansour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.14843"
  },
  {
    "id": "arXiv:2101.07243",
    "title": "Gauge Invariant Autoregressive Neural Networks for Quantum Lattice  Models",
    "abstract": "Gauge Invariant Autoregressive Neural Networks for Quantum Lattice  Models",
    "descriptor": "",
    "authors": [
      "Di Luo",
      "Zhuo Chen",
      "Kaiwen Hu",
      "Zhizhen Zhao",
      "Vera Mikyoung Hur",
      "Bryan K. Clark"
    ],
    "subjectives": [
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Lattice (hep-lat)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2101.07243"
  },
  {
    "id": "arXiv:2101.12497",
    "title": "One-parameter robust global frequency estimator for slowly varying  amplitude and noisy oscillations",
    "abstract": "Comments: 8 pages, 10 figures",
    "descriptor": "\nComments: 8 pages, 10 figures\n",
    "authors": [
      "Michael Ruderman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.12497"
  },
  {
    "id": "arXiv:2102.00487",
    "title": "Nonlinear Evolutionary PDE-Based Refinement of Optical Flow",
    "abstract": "Nonlinear Evolutionary PDE-Based Refinement of Optical Flow",
    "descriptor": "",
    "authors": [
      "Hirak Doshi",
      "N. Uday Kiran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2102.00487"
  },
  {
    "id": "arXiv:2102.03285",
    "title": "Unsupervised Novel View Synthesis from a Single Image",
    "abstract": "Comments: Submitted to Computer Vision and Image Understanding (CVIU)",
    "descriptor": "\nComments: Submitted to Computer Vision and Image Understanding (CVIU)\n",
    "authors": [
      "Pierluigi Zama Ramirez",
      "Diego Martin Arroyo",
      "Alessio Tonioni",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.03285"
  },
  {
    "id": "arXiv:2102.07515",
    "title": "Sequence Types and Infinitary Semantics",
    "abstract": "Comments: 68 pages, 18 figures",
    "descriptor": "\nComments: 68 pages, 18 figures\n",
    "authors": [
      "Pierre Vial"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2102.07515"
  },
  {
    "id": "arXiv:2102.08340",
    "title": "Convergence of Nonlinear Observers on R^n with a Riemannian Metric (Part  III)",
    "abstract": "Comments: 96 pages, Version submitted for review",
    "descriptor": "\nComments: 96 pages, Version submitted for review\n",
    "authors": [
      "Ricardo G. Sanfelice",
      "Laurent Praly"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2102.08340"
  },
  {
    "id": "arXiv:2102.10809",
    "title": "Local Calibration: Metrics and Recalibration",
    "abstract": "Local Calibration: Metrics and Recalibration",
    "descriptor": "",
    "authors": [
      "Rachel Luo",
      "Aadyot Bhatnagar",
      "Yu Bai",
      "Shengjia Zhao",
      "Huan Wang",
      "Caiming Xiong",
      "Silvio Savarese",
      "Stefano Ermon",
      "Edward Schmerling",
      "Marco Pavone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.10809"
  },
  {
    "id": "arXiv:2102.11717",
    "title": "Greedy-Step Off-Policy Reinforcement Learning",
    "abstract": "Greedy-Step Off-Policy Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Yuhui Wang",
      "Qingyuan Wu",
      "Pengcheng He",
      "Xiaoyang Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2102.11717"
  },
  {
    "id": "arXiv:2103.03510",
    "title": "Variational Structured Attention Networks for Deep Visual Representation  Learning",
    "abstract": "Comments: Accepted at IEEE Transactions on Image Processing (TIP)",
    "descriptor": "\nComments: Accepted at IEEE Transactions on Image Processing (TIP)\n",
    "authors": [
      "Guanglei Yang",
      "Paolo Rota",
      "Xavier Alameda-Pineda",
      "Dan Xu",
      "Mingli Ding",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03510"
  },
  {
    "id": "arXiv:2103.03547",
    "title": "Structure-Enhanced Meta-Learning For Few-Shot Graph Classification",
    "abstract": "Comments: AI Open Journal Volume 2, 2021, Pages 160-167",
    "descriptor": "\nComments: AI Open Journal Volume 2, 2021, Pages 160-167\n",
    "authors": [
      "Shunyu Jiang",
      "Fuli Feng",
      "Weijian Chen",
      "Xiang Li",
      "Xiangnan He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.03547"
  },
  {
    "id": "arXiv:2103.03594",
    "title": "Fast Barycentric-Based Evaluation Over Spectral/hp Elements",
    "abstract": "Comments: 28 pages, 9 figures, 2 tables, submitted to Journal of Scientific Computing",
    "descriptor": "\nComments: 28 pages, 9 figures, 2 tables, submitted to Journal of Scientific Computing\n",
    "authors": [
      "Edward Laughton",
      "Vidhi Zala",
      "Akil Narayan",
      "Robert M. Kirby",
      "David Moxey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.03594"
  },
  {
    "id": "arXiv:2103.04537",
    "title": "Multimodal Representation Learning via Maximization of Local Mutual  Information",
    "abstract": "Comments: In Proceedings of International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2021",
    "descriptor": "\nComments: In Proceedings of International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2021\n",
    "authors": [
      "Ruizhi Liao",
      "Daniel Moyer",
      "Miriam Cha",
      "Keegan Quigley",
      "Seth Berkowitz",
      "Steven Horng",
      "Polina Golland",
      "William M. Wells"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.04537"
  },
  {
    "id": "arXiv:2103.07292",
    "title": "VDSM: Unsupervised Video Disentanglement with State-Space Modeling and  Deep Mixtures of Experts",
    "abstract": "VDSM: Unsupervised Video Disentanglement with State-Space Modeling and  Deep Mixtures of Experts",
    "descriptor": "",
    "authors": [
      "Matthew J. Vowels",
      "Necati Cihan Camgoz",
      "Richard Bowden"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.07292"
  },
  {
    "id": "arXiv:2103.07397",
    "title": "An extensible equality checking algorithm for dependent type theories",
    "abstract": "Comments: Adheres to LMCS style guide, added .bib file as requested, typos corrected",
    "descriptor": "\nComments: Adheres to LMCS style guide, added .bib file as requested, typos corrected\n",
    "authors": [
      "Andrej Bauer",
      "Anja Petkovi\u0107 Komel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2103.07397"
  },
  {
    "id": "arXiv:2103.11181",
    "title": "Adaptive deep density approximation for Fokker-Planck equations",
    "abstract": "Adaptive deep density approximation for Fokker-Planck equations",
    "descriptor": "",
    "authors": [
      "Kejun Tang",
      "Xiaoliang Wan",
      "Qifeng Liao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.11181"
  },
  {
    "id": "arXiv:2103.17055",
    "title": "A Neighbourhood Framework for Resource-Lean Content Flagging",
    "abstract": "Comments: Accepted to appear in Transactions of the Association for Computational Linguistics (TACL) -- this is a pre-MIT Press publication version",
    "descriptor": "\nComments: Accepted to appear in Transactions of the Association for Computational Linguistics (TACL) -- this is a pre-MIT Press publication version\n",
    "authors": [
      "Sheikh Muhammad Sarwar",
      "Dimitrina Zlatkova",
      "Momchil Hardalov",
      "Yoan Dinkov",
      "Isabelle Augenstein",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.17055"
  },
  {
    "id": "arXiv:2104.08728",
    "title": "Revealing Persona Biases in Dialogue Systems",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Emily Sheng",
      "Josh Arnold",
      "Zhou Yu",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08728"
  },
  {
    "id": "arXiv:2104.11522",
    "title": "Conditional super-network weights",
    "abstract": "Comments: 7 pages, 7 figures, 1 table, further figures and tables in the appendix",
    "descriptor": "\nComments: 7 pages, 7 figures, 1 table, further figures and tables in the appendix\n",
    "authors": [
      "Kevin Alexander Laube",
      "Andreas Zell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.11522"
  },
  {
    "id": "arXiv:2104.11832",
    "title": "Playing Lottery Tickets with Vision and Language",
    "abstract": "Comments: Accepted to AAAI 2022",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Zhe Gan",
      "Yen-Chun Chen",
      "Linjie Li",
      "Tianlong Chen",
      "Yu Cheng",
      "Shuohang Wang",
      "Jingjing Liu",
      "Lijuan Wang",
      "Zicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.11832"
  },
  {
    "id": "arXiv:2104.14202",
    "title": "Bayesian Deep Neural Networks for Supervised Learning of Single-View  Depth",
    "abstract": "Bayesian Deep Neural Networks for Supervised Learning of Single-View  Depth",
    "descriptor": "",
    "authors": [
      "Javier Rodr\u00edguez-Puigvert",
      "Rub\u00e9n Mart\u00ednez-Cant\u00edn",
      "Javier Civera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.14202"
  },
  {
    "id": "arXiv:2104.14403",
    "title": "Do Feature Attribution Methods Correctly Attribute Features?",
    "abstract": "Comments: AAAI 2022. Video summary at this https URL",
    "descriptor": "\nComments: AAAI 2022. Video summary at this https URL\n",
    "authors": [
      "Yilun Zhou",
      "Serena Booth",
      "Marco Tulio Ribeiro",
      "Julie Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.14403"
  },
  {
    "id": "arXiv:2104.14527",
    "title": "Online certification of preference-based fairness for personalized  recommender systems",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Virginie Do",
      "Sam Corbett-Davies",
      "Jamal Atif",
      "Nicolas Usunier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.14527"
  },
  {
    "id": "arXiv:2105.01767",
    "title": "Challenges and Outlook in Robotic Manipulation of Deformable Objects",
    "abstract": "Challenges and Outlook in Robotic Manipulation of Deformable Objects",
    "descriptor": "",
    "authors": [
      "Jihong Zhu",
      "Andrea Cherubini",
      "Claire Dune",
      "David Navarro-Alarcon",
      "Farshid Alambeigi",
      "Dmitry Berenson",
      "Fanny Ficuciello",
      "Kensuke Harada",
      "Jens Kober",
      "Xiang Li",
      "Jia Pan",
      "Wenzhen Yuan",
      "Michael Gienger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.01767"
  },
  {
    "id": "arXiv:2105.02556",
    "title": "Metric Entropy Limits on Recurrent Neural Network Learning of Linear  Dynamical Systems",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Clemens Hutter",
      "Recep G\u00fcl",
      "Helmut B\u00f6lcskei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.02556"
  },
  {
    "id": "arXiv:2105.06145",
    "title": "Efficient Stepping Algorithms and Implementations for Parallel Shortest  Paths",
    "abstract": "Efficient Stepping Algorithms and Implementations for Parallel Shortest  Paths",
    "descriptor": "",
    "authors": [
      "Xiaojun Dong",
      "Yan Gu",
      "Yihan Sun",
      "Yunming Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.06145"
  },
  {
    "id": "arXiv:2105.07329",
    "title": "Dynamic Spatial Matching",
    "abstract": "Dynamic Spatial Matching",
    "descriptor": "",
    "authors": [
      "Yash Kanoria"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Theoretical Economics (econ.TH)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.07329"
  },
  {
    "id": "arXiv:2105.08007",
    "title": "Understanding and Improvement of Adversarial Training for Network  Embedding from an Optimization Perspective",
    "abstract": "Comments: 11 pages, 0 figures, accepted by WSDM'22",
    "descriptor": "\nComments: 11 pages, 0 figures, accepted by WSDM'22\n",
    "authors": [
      "Lun Du",
      "Xu Chen",
      "Fei Gao",
      "Qiang Fu",
      "Kunqing Xie",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.08007"
  },
  {
    "id": "arXiv:2105.09418",
    "title": "iTelos -- Purpose Driven Knowledge Graph Generation",
    "abstract": "iTelos -- Purpose Driven Knowledge Graph Generation",
    "descriptor": "",
    "authors": [
      "Fausto Giunchiglia",
      "Simone Bocca",
      "Mattia Fumagalli",
      "Mayukh Bagchi",
      "Alessio Zamboni"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.09418"
  },
  {
    "id": "arXiv:2105.10699",
    "title": "Denoising Noisy Neural Networks: A Bayesian Approach with Compensation",
    "abstract": "Comments: Keywords: Noisy neural network, denoiser, wireless transmission of neural networks, federated edge learning, analog device. 17 pages, 9 figures",
    "descriptor": "\nComments: Keywords: Noisy neural network, denoiser, wireless transmission of neural networks, federated edge learning, analog device. 17 pages, 9 figures\n",
    "authors": [
      "Yulin Shao",
      "Soung Chang Liew",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.10699"
  },
  {
    "id": "arXiv:2105.12122",
    "title": "Optical coherent dot-product chip for sophisticated deep learning  regression",
    "abstract": "Optical coherent dot-product chip for sophisticated deep learning  regression",
    "descriptor": "",
    "authors": [
      "Shaofu Xu",
      "Jing Wang",
      "Haowen Shu",
      "Zhike Zhang",
      "Sicheng Yi",
      "Bowen Bai",
      "Xingjun Wang",
      "Jianguo Liu",
      "Weiwen Zou"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2105.12122"
  },
  {
    "id": "arXiv:2105.15004",
    "title": "Generalization Error Rates in Kernel Regression: The Crossover from the  Noiseless to Noisy Regime",
    "abstract": "Comments: 22 pages, 10 figures, 2 tables",
    "descriptor": "\nComments: 22 pages, 10 figures, 2 tables\n",
    "authors": [
      "Hugo Cui",
      "Bruno Loureiro",
      "Florent Krzakala",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15004"
  },
  {
    "id": "arXiv:2106.01088",
    "title": "TSI: Temporal Saliency Integration for Video Action Recognition",
    "abstract": "Comments: Submitted to CVPR 2022",
    "descriptor": "\nComments: Submitted to CVPR 2022\n",
    "authors": [
      "Haisheng Su",
      "Kunchang Li",
      "Jinyuan Feng",
      "Dongliang Wang",
      "Weihao Gan",
      "Wei Wu",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01088"
  },
  {
    "id": "arXiv:2106.01613",
    "title": "NODE-GAM: Neural Generalized Additive Model for Interpretable Deep  Learning",
    "abstract": "NODE-GAM: Neural Generalized Additive Model for Interpretable Deep  Learning",
    "descriptor": "",
    "authors": [
      "Chun-Hao Chang",
      "Rich Caruana",
      "Anna Goldenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01613"
  },
  {
    "id": "arXiv:2106.02520",
    "title": "CATs: Cost Aggregation Transformers for Visual Correspondence",
    "abstract": "Comments: Code and trained models are available at this https URL",
    "descriptor": "\nComments: Code and trained models are available at this https URL\n",
    "authors": [
      "Seokju Cho",
      "Sunghwan Hong",
      "Sangryul Jeon",
      "Yunsung Lee",
      "Kwanghoon Sohn",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02520"
  },
  {
    "id": "arXiv:2106.02538",
    "title": "Bottleneck Profiles and Discrete Prokhorov Metrics for Persistence  Diagrams",
    "abstract": "Comments: 31 pages, 12 figures; improved exposition, fixed various inaccuracies, added another experiment",
    "descriptor": "\nComments: 31 pages, 12 figures; improved exposition, fixed various inaccuracies, added another experiment\n",
    "authors": [
      "Pawe\u0142 D\u0142otko",
      "Niklas Hellmer"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2106.02538"
  },
  {
    "id": "arXiv:2106.03090",
    "title": "Deep Matching Prior: Test-Time Optimization for Dense Correspondence",
    "abstract": "Comments: Accepted to ICCV 2021, Camera-ready version. Project page : this https URL",
    "descriptor": "\nComments: Accepted to ICCV 2021, Camera-ready version. Project page : this https URL\n",
    "authors": [
      "Sunghwan Hong",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03090"
  },
  {
    "id": "arXiv:2106.03589",
    "title": "Nonparametric adaptive control and prediction: theory and randomized  algorithms",
    "abstract": "Comments: v2: Significant updates. Introduction of nonparametric methods",
    "descriptor": "\nComments: v2: Significant updates. Introduction of nonparametric methods\n",
    "authors": [
      "Nicholas M. Boffi",
      "Stephen Tu",
      "Jean-Jacques E. Slotine"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03589"
  },
  {
    "id": "arXiv:2106.03922",
    "title": "Interactive Label Cleaning with Example-based Explanations",
    "abstract": "Comments: main article + supplementary material, Advances in Neural Information Processing Systems 34 (NeurIPS 2021)",
    "descriptor": "\nComments: main article + supplementary material, Advances in Neural Information Processing Systems 34 (NeurIPS 2021)\n",
    "authors": [
      "Stefano Teso",
      "Andrea Bontempelli",
      "Fausto Giunchiglia",
      "Andrea Passerini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03922"
  },
  {
    "id": "arXiv:2106.05498",
    "title": "It's COMPASlicated: The Messy Relationship between RAI Datasets and  Algorithmic Fairness Benchmarks",
    "abstract": "It's COMPASlicated: The Messy Relationship between RAI Datasets and  Algorithmic Fairness Benchmarks",
    "descriptor": "",
    "authors": [
      "Michelle Bao",
      "Angela Zhou",
      "Samantha Zottola",
      "Brian Brubach",
      "Sarah Desmarais",
      "Aaron Horowitz",
      "Kristian Lum",
      "Suresh Venkatasubramanian"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.05498"
  },
  {
    "id": "arXiv:2106.06345",
    "title": "Proximal Optimal Transport Modeling of Population Dynamics",
    "abstract": "Proximal Optimal Transport Modeling of Population Dynamics",
    "descriptor": "",
    "authors": [
      "Charlotte Bunne",
      "Laetitia Meng-Papaxanthos",
      "Andreas Krause",
      "Marco Cuturi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06345"
  },
  {
    "id": "arXiv:2106.06742",
    "title": "Task Transformer Network for Joint MRI Reconstruction and  Super-Resolution",
    "abstract": "Task Transformer Network for Joint MRI Reconstruction and  Super-Resolution",
    "descriptor": "",
    "authors": [
      "Chun-Mei Feng",
      "Yunlu Yan",
      "Huazhu Fu",
      "Li Chen",
      "Yong Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06742"
  },
  {
    "id": "arXiv:2106.08085",
    "title": "Natural continual learning: success is a journey, not (just) a  destination",
    "abstract": "Comments: NeurIPS 2021 camera-ready version",
    "descriptor": "\nComments: NeurIPS 2021 camera-ready version\n",
    "authors": [
      "Ta-Chu Kao",
      "Kristopher T. Jensen",
      "Gido M. van de Ven",
      "Alberto Bernacchia",
      "Guillaume Hennequin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.08085"
  },
  {
    "id": "arXiv:2106.08497",
    "title": "GKNet: grasp keypoint network for grasp candidates detection",
    "abstract": "Comments: 25 pages, 12 figures, 14 tables",
    "descriptor": "\nComments: 25 pages, 12 figures, 14 tables\n",
    "authors": [
      "Ruinian Xu",
      "Fu-Jen Chu",
      "Patricio A. Vela"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08497"
  },
  {
    "id": "arXiv:2106.08759",
    "title": "OpenSSLNTRU: Faster post-quantum TLS key exchange",
    "abstract": "Comments: 20 pages, 5 figures; accepted at USENIX Security 2022; added Artifact Evaluation badges and final Artifact Appendix",
    "descriptor": "\nComments: 20 pages, 5 figures; accepted at USENIX Security 2022; added Artifact Evaluation badges and final Artifact Appendix\n",
    "authors": [
      "Daniel J. Bernstein",
      "Billy Bob Brumley",
      "Ming-Shing Chen",
      "Nicola Tuveri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08759"
  },
  {
    "id": "arXiv:2106.11173",
    "title": "TNT: Text-Conditioned Network with Transductive Inference for Few-Shot  Video Classification",
    "abstract": "Comments: 18 pages including references, 6 figures, and 3 tables",
    "descriptor": "\nComments: 18 pages including references, 6 figures, and 3 tables\n",
    "authors": [
      "Andr\u00e9s Villa",
      "Juan-Manuel Perez-Rua",
      "Victor Escorcia",
      "Vladimir Araujo",
      "Juan Carlos Niebles",
      "Alvaro Soto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11173"
  },
  {
    "id": "arXiv:2106.12379",
    "title": "AC/DC: Alternating Compressed/DeCompressed Training of Deep Neural  Networks",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Alexandra Peste",
      "Eugenia Iofinova",
      "Adrian Vladu",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.12379"
  },
  {
    "id": "arXiv:2107.01275",
    "title": "Relaxed Attention: A Simple Method to Boost Performance of End-to-End  Automatic Speech Recognition",
    "abstract": "Comments: Accepted at ASRU 2021, code contributed to this http URL",
    "descriptor": "\nComments: Accepted at ASRU 2021, code contributed to this http URL\n",
    "authors": [
      "Timo Lohrenz",
      "Patrick Schwarz",
      "Zhengyang Li",
      "Tim Fingscheidt"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.01275"
  },
  {
    "id": "arXiv:2107.02794",
    "title": "Improving Coherence and Consistency in Neural Sequence Models with  Dual-System, Neuro-Symbolic Reasoning",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Maxwell Nye",
      "Michael Henry Tessler",
      "Joshua B. Tenenbaum",
      "Brenden M. Lake"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02794"
  },
  {
    "id": "arXiv:2107.05045",
    "title": "Positive-Unlabeled Classification under Class-Prior Shift: A  Prior-invariant Approach Based on Density Ratio Estimation",
    "abstract": "Comments: 36 pages, 4 figures",
    "descriptor": "\nComments: 36 pages, 4 figures\n",
    "authors": [
      "Shota Nakajima",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05045"
  },
  {
    "id": "arXiv:2107.10941",
    "title": "Graph-Based Learning for Stock Movement Prediction with Textual and  Relational Data",
    "abstract": "Comments: 10 pages, 3 figures, 5 tables",
    "descriptor": "\nComments: 10 pages, 3 figures, 5 tables\n",
    "authors": [
      "Qinkai Chen",
      "Christian-Yann Robert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.10941"
  },
  {
    "id": "arXiv:2107.11253",
    "title": "State, global and local parameter estimation using local ensemble Kalman  filters: applications to online machine learning of chaotic dynamics",
    "abstract": "State, global and local parameter estimation using local ensemble Kalman  filters: applications to online machine learning of chaotic dynamics",
    "descriptor": "",
    "authors": [
      "Quentin Malartic",
      "Alban Farchi",
      "Marc Bocquet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2107.11253"
  },
  {
    "id": "arXiv:2107.13967",
    "title": "PPT Fusion: Pyramid Patch Transformerfor a Case Study in Image Fusion",
    "abstract": "Comments: We have added more experiments and are improving the article, and will submit it to the journal. It will be updated",
    "descriptor": "\nComments: We have added more experiments and are improving the article, and will submit it to the journal. It will be updated\n",
    "authors": [
      "Yu Fu",
      "TianYang Xu",
      "XiaoJun Wu",
      "Josef Kittler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.13967"
  },
  {
    "id": "arXiv:2108.00351",
    "title": "LASOR: Learning Accurate 3D Human Pose and Shape Via Synthetic  Occlusion-Aware Data and Neural Mesh Rendering",
    "abstract": "LASOR: Learning Accurate 3D Human Pose and Shape Via Synthetic  Occlusion-Aware Data and Neural Mesh Rendering",
    "descriptor": "",
    "authors": [
      "Kaibing Yang",
      "Renshu Gu",
      "Maoyu Wang",
      "Masahiro Toyoura",
      "Gang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.00351"
  },
  {
    "id": "arXiv:2108.00815",
    "title": "Estimating the Peer Degree of Reachable Peers in the Bitcoin P2P Network",
    "abstract": "Estimating the Peer Degree of Reachable Peers in the Bitcoin P2P Network",
    "descriptor": "",
    "authors": [
      "Matthias Grundmann",
      "Max Baumstark",
      "Hannes Hartenstein"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.00815"
  },
  {
    "id": "arXiv:2108.01516",
    "title": "Two New Stenosis Detection Methods of Coronary Angiograms",
    "abstract": "Comments: Correspondence should be addressed to Qing Zhang",
    "descriptor": "\nComments: Correspondence should be addressed to Qing Zhang\n",
    "authors": [
      "Yaofang Liu",
      "Xinyue Zhang",
      "Wenlong Wan",
      "Shaoyu Liu",
      "Yingdi Liu",
      "Hu Liu",
      "Xueying Zeng",
      "Qing Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01516"
  },
  {
    "id": "arXiv:2108.04108",
    "title": "Team Power Dynamics and Team Impact: New Perspectives on Scientific  Collaboration using Career Age as a Proxy for Team Power",
    "abstract": "Team Power Dynamics and Team Impact: New Perspectives on Scientific  Collaboration using Career Age as a Proxy for Team Power",
    "descriptor": "",
    "authors": [
      "Huimin Xu",
      "Yi Bu",
      "Meijun Liu",
      "Chenwei Zhang",
      "Mengyi Sun",
      "Yi Zhang",
      "Eric Meyer",
      "Eduardo Salas",
      "Ying Ding"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.04108"
  },
  {
    "id": "arXiv:2108.06552",
    "title": "Continual Semi-Supervised Learning through Contrastive Interpolation  Consistency",
    "abstract": "Comments: 7 pages, 2 figures",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Matteo Boschini",
      "Pietro Buzzega",
      "Lorenzo Bonicelli",
      "Angelo Porrello",
      "Simone Calderara"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.06552"
  },
  {
    "id": "arXiv:2108.10403",
    "title": "Robust Risk-Aware Reinforcement Learning",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Sebastian Jaimungal",
      "Silvana Pesenti",
      "Ye Sheng Wang",
      "Hariom Tatsat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Portfolio Management (q-fin.PM)",
      "Risk Management (q-fin.RM)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2108.10403"
  },
  {
    "id": "arXiv:2109.01156",
    "title": "Challenges in Generalization in Open Domain Question Answering",
    "abstract": "Challenges in Generalization in Open Domain Question Answering",
    "descriptor": "",
    "authors": [
      "Linqing Liu",
      "Patrick Lewis",
      "Sebastian Riedel",
      "Pontus Stenetorp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.01156"
  },
  {
    "id": "arXiv:2109.01991",
    "title": "Optimal transport weights for causal inference",
    "abstract": "Optimal transport weights for causal inference",
    "descriptor": "",
    "authors": [
      "Eric Dunipace"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.01991"
  },
  {
    "id": "arXiv:2109.02705",
    "title": "A Virtual Reality-based Training and Assessment System for Bridge  Inspectors with an Assistant Drone",
    "abstract": "Comments: 23 pages, 10 figures. Received first review and submitted this revision version that submitted to IEEE Transactions on Human-Machine Systems on Nov 12th, 2021. Current state: Under second round review",
    "descriptor": "\nComments: 23 pages, 10 figures. Received first review and submitted this revision version that submitted to IEEE Transactions on Human-Machine Systems on Nov 12th, 2021. Current state: Under second round review\n",
    "authors": [
      "Yu Li",
      "Muhammad Monjurul Karim",
      "Ruwen Qin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.02705"
  },
  {
    "id": "arXiv:2109.04381",
    "title": "Copy-Move Image Forgery Detection Based on Evolving Circular Domains  Coverage",
    "abstract": "Copy-Move Image Forgery Detection Based on Evolving Circular Domains  Coverage",
    "descriptor": "",
    "authors": [
      "Shilin Lu",
      "Xinghong Hu",
      "Chengyou Wang",
      "Lu Chen",
      "Shulu Han",
      "Yuejia Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04381"
  },
  {
    "id": "arXiv:2109.04636",
    "title": "STL2vec: Signal Temporal Logic Embeddings for Control Synthesis With  Recurrent Neural Networks",
    "abstract": "Comments: submitted for publication",
    "descriptor": "\nComments: submitted for publication\n",
    "authors": [
      "Wataru Hashimoto",
      "Kazumune Hashimoto",
      "Shigemasa Takai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04636"
  },
  {
    "id": "arXiv:2109.04872",
    "title": "Negative Sample Matters: A Renaissance of Metric Learning for Temporal  Grounding",
    "abstract": "Comments: AAAI 2022 Camera Ready Version",
    "descriptor": "\nComments: AAAI 2022 Camera Ready Version\n",
    "authors": [
      "Zhenzhi Wang",
      "Limin Wang",
      "Tao Wu",
      "Tianhao Li",
      "Gangshan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2109.04872"
  },
  {
    "id": "arXiv:2109.05666",
    "title": "AMI-FML: A Privacy-Preserving Federated Machine Learning Framework for  AMI",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Milan Biswal",
      "Abu Saleh Md Tayeen",
      "Satyajayant Misra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.05666"
  },
  {
    "id": "arXiv:2109.06827",
    "title": "Types of Out-of-Distribution Texts and How to Detect Them",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Udit Arora",
      "William Huang",
      "He He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06827"
  },
  {
    "id": "arXiv:2109.07606",
    "title": "Graph skeletonization of high-dimensional point cloud data via  topological method",
    "abstract": "Graph skeletonization of high-dimensional point cloud data via  topological method",
    "descriptor": "",
    "authors": [
      "Lucas Magee",
      "Yusu Wang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2109.07606"
  },
  {
    "id": "arXiv:2109.10408",
    "title": "Non-intrusive Balancing Transformation of Highly Stiff Systems with  Lightly-damped Impulse Response",
    "abstract": "Non-intrusive Balancing Transformation of Highly Stiff Systems with  Lightly-damped Impulse Response",
    "descriptor": "",
    "authors": [
      "Elnaz Rezaian",
      "Cheng Huang",
      "Karthik Duraisamy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.10408"
  },
  {
    "id": "arXiv:2109.13722",
    "title": "Are iPhones Really Better for Privacy? Comparative Study of iOS and  Android Apps",
    "abstract": "Comments: Accepted for publication by the Proceedings on Privacy Enhancing Technologies (PoPETs) 2022",
    "descriptor": "\nComments: Accepted for publication by the Proceedings on Privacy Enhancing Technologies (PoPETs) 2022\n",
    "authors": [
      "Konrad Kollnig",
      "Anastasia Shuba",
      "Reuben Binns",
      "Max Van Kleek",
      "Nigel Shadbolt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.13722"
  },
  {
    "id": "arXiv:2109.14534",
    "title": "A verified algebraic representation of Cairo program execution",
    "abstract": "A verified algebraic representation of Cairo program execution",
    "descriptor": "",
    "authors": [
      "Jeremy Avigad",
      "Lior Goldberg",
      "David Levit",
      "Yoav Seginer",
      "Alon Titelman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2109.14534"
  },
  {
    "id": "arXiv:2110.01346",
    "title": "Clustering with Respect to the Information Distance",
    "abstract": "Comments: 10 pages; 2 figures",
    "descriptor": "\nComments: 10 pages; 2 figures\n",
    "authors": [
      "Andrei Romashchenko"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.01346"
  },
  {
    "id": "arXiv:2110.03431",
    "title": "Cloud Failure Prediction with Hierarchical Temporal Memory: An Empirical  Assessment",
    "abstract": "Comments: For associated video presentation, see this https URL , for associated slides, see this https URL . In Proc. of the IEEE International Conference on Machine Learning and Applications (ICMLA 2021)",
    "descriptor": "\nComments: For associated video presentation, see this https URL , for associated slides, see this https URL . In Proc. of the IEEE International Conference on Machine Learning and Applications (ICMLA 2021)\n",
    "authors": [
      "Oliviero Riganelli",
      "Paolo Saltarel",
      "Alessandro Tundo",
      "Marco Mobilio",
      "Leonardo Mariani"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03431"
  },
  {
    "id": "arXiv:2110.04865",
    "title": "Parallel Minimum Spanning Forest Computation using Sparse Matrix Kernels",
    "abstract": "Parallel Minimum Spanning Forest Computation using Sparse Matrix Kernels",
    "descriptor": "",
    "authors": [
      "Tim Baer",
      "Raghavendra Kanakagiri",
      "Edgar Solomonik"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.04865"
  },
  {
    "id": "arXiv:2110.08350",
    "title": "Differentiable Network Pruning for Microcontrollers",
    "abstract": "Differentiable Network Pruning for Microcontrollers",
    "descriptor": "",
    "authors": [
      "Edgar Liberis",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08350"
  },
  {
    "id": "arXiv:2110.08998",
    "title": "Using Structure-Behavior Coalescence Method for Systems Definition 2.0",
    "abstract": "Using Structure-Behavior Coalescence Method for Systems Definition 2.0",
    "descriptor": "",
    "authors": [
      "William S. Chao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.08998"
  },
  {
    "id": "arXiv:2110.12823",
    "title": "Raw Bayer Pattern Image Synthesis for Computer Vision-oriented Image  Signal Processing Pipeline Design",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Wei Zhou",
      "Xiangyu Zhang",
      "Hongyu Wang",
      "Shenghua Gao",
      "Xin Lou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12823"
  },
  {
    "id": "arXiv:2110.13892",
    "title": "HR-RCNN: Hierarchical Relational Reasoning for Object Detection",
    "abstract": "Comments: To appear at BMVC 2021",
    "descriptor": "\nComments: To appear at BMVC 2021\n",
    "authors": [
      "Hao Chen",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13892"
  },
  {
    "id": "arXiv:2110.14451",
    "title": "Validation Methods for Energy Time Series Scenarios from Deep Generative  Models",
    "abstract": "Comments: 20 pages, 8 figures, 2 tables",
    "descriptor": "\nComments: 20 pages, 8 figures, 2 tables\n",
    "authors": [
      "Eike Cramer",
      "Leonardo Rydin Gorj\u00e3o",
      "Alexander Mitsos",
      "Benjamin Sch\u00e4fer",
      "Dirk Witthaut",
      "Manuel Dahmen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.14451"
  },
  {
    "id": "arXiv:2111.00086",
    "title": "Measuring a Texts Fairness Dimensions Using Machine Learning Based on  Social Psychological Factors",
    "abstract": "Comments: 38 pages, 9 figures Change in Author details. Added acknowledgment section",
    "descriptor": "\nComments: 38 pages, 9 figures Change in Author details. Added acknowledgment section\n",
    "authors": [
      "Ahmed Izzidien",
      "David Stillwell"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.00086"
  },
  {
    "id": "arXiv:2111.00107",
    "title": "The Golden Rule as a Heuristic to Measure the Fairness of Texts Using  Machine Learning",
    "abstract": "Comments: 32 pages, 4 figures, Author details changed. Added acknowledgments on page 18",
    "descriptor": "\nComments: 32 pages, 4 figures, Author details changed. Added acknowledgments on page 18\n",
    "authors": [
      "Ahmed Izzidien",
      "David Stillwell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00107"
  },
  {
    "id": "arXiv:2111.03470",
    "title": "ParsiNorm: A Persian Toolkit for Speech Processing Normalization",
    "abstract": "ParsiNorm: A Persian Toolkit for Speech Processing Normalization",
    "descriptor": "",
    "authors": [
      "Romina Oji",
      "Seyedeh Fatemeh Razavi",
      "Sajjad Abdi Dehsorkh",
      "Alireza Hariri",
      "Hadi Asheri",
      "Reshad Hosseini"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03470"
  },
  {
    "id": "arXiv:2111.05011",
    "title": "RAVE: A variational autoencoder for fast and high-quality neural audio  synthesis",
    "abstract": "RAVE: A variational autoencoder for fast and high-quality neural audio  synthesis",
    "descriptor": "",
    "authors": [
      "Antoine Caillon",
      "Philippe Esling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.05011"
  },
  {
    "id": "arXiv:2111.08008",
    "title": "SPLDExtraTrees: Robust machine learning approach for predicting kinase  inhibitor resistance",
    "abstract": "Comments: 13 pages, 5 figures",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Ziyi Yang",
      "Zhaofeng Ye",
      "Yijia Xiao",
      "Changyu Hsieh"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08008"
  },
  {
    "id": "arXiv:2111.08994",
    "title": "Nonlinear Intensity Sonar Image Matching based on Deep Convolution  Features",
    "abstract": "Comments: 5 pages, 9 figures. The final manuscript we submitted is a research under the original title. Compared with the previous papers, we adopted a more novel research method and experimental design",
    "descriptor": "\nComments: 5 pages, 9 figures. The final manuscript we submitted is a research under the original title. Compared with the previous papers, we adopted a more novel research method and experimental design\n",
    "authors": [
      "Xiaoteng Zhou",
      "Changli Yu",
      "Xin Yuan",
      "Yi Wu",
      "Haijun Feng",
      "Citong Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08994"
  },
  {
    "id": "arXiv:2111.09098",
    "title": "Unifying Heterogenous Electronic Health Records Systems via Text-Based  Code Embedding",
    "abstract": "Comments: Machine Learning for Health (ML4H) at NeurIPS 2021 - Extended Abstract. This is a condensed version of arXiv:2108.03625. arXiv admin note: substantial text overlap with arXiv:2108.03625",
    "descriptor": "\nComments: Machine Learning for Health (ML4H) at NeurIPS 2021 - Extended Abstract. This is a condensed version of arXiv:2108.03625. arXiv admin note: substantial text overlap with arXiv:2108.03625\n",
    "authors": [
      "Kyunghoon Hur",
      "Jiyoung Lee",
      "Jungwoo Oh",
      "Wesley Price",
      "Young-Hak Kim",
      "Edward Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09098"
  },
  {
    "id": "arXiv:2111.09823",
    "title": "NetQASM -- A low-level instruction set architecture for hybrid  quantum-classical programs in a quantum internet",
    "abstract": "Comments: 22 pages, 13 figures, supplementary materials. v2: added references, fixed typos",
    "descriptor": "\nComments: 22 pages, 13 figures, supplementary materials. v2: added references, fixed typos\n",
    "authors": [
      "Axel Dahlberg",
      "Bart van der Vecht",
      "Carlo Delle Donne",
      "Matthew Skrzypczyk",
      "Ingmar te Raa",
      "Wojciech Kozlowski",
      "Stephanie Wehner"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.09823"
  },
  {
    "id": "arXiv:2111.10291",
    "title": "Meta Adversarial Perturbations",
    "abstract": "Comments: Published in AAAI 2022 Workshop",
    "descriptor": "\nComments: Published in AAAI 2022 Workshop\n",
    "authors": [
      "Chia-Hung Yuan",
      "Pin-Yu Chen",
      "Chia-Mu Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10291"
  },
  {
    "id": "arXiv:2111.10553",
    "title": "Degree-Corrected Distribution-Free Model for Community Detection in  weighted networks",
    "abstract": "Comments: 10 pages, 2 figures, 1 table, comments are welcome",
    "descriptor": "\nComments: 10 pages, 2 figures, 1 table, comments are welcome\n",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.10553"
  },
  {
    "id": "arXiv:2111.10776",
    "title": "Is Speech Emotion Recognition Language-Independent? Analysis of English  and Bangla Languages using Language-Independent Vocal Features",
    "abstract": "Comments: 9 pages, 7 figures, [currently under review]",
    "descriptor": "\nComments: 9 pages, 7 figures, [currently under review]\n",
    "authors": [
      "Fardin Saad",
      "Hasan Mahmud",
      "Md. Alamin Shaheen",
      "Md. Kamrul Hasan",
      "Paresha Farastu",
      "Mohammad Ridwan Kabir"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10776"
  },
  {
    "id": "arXiv:2111.11532",
    "title": "Forbidden Substructures for Tractable Conjunctive Query Answering with  Degree 2",
    "abstract": "Forbidden Substructures for Tractable Conjunctive Query Answering with  Degree 2",
    "descriptor": "",
    "authors": [
      "Matthias Lanzinger"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.11532"
  },
  {
    "id": "arXiv:2111.12541",
    "title": "Rethinking the modeling of the instrumental response of telescopes with  a differentiable optical model",
    "abstract": "Comments: 10 pages. Accepted for the Fourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021)",
    "descriptor": "\nComments: 10 pages. Accepted for the Fourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021)\n",
    "authors": [
      "Tobias Liaudat",
      "Jean-Luc Starck",
      "Martin Kilbinger",
      "Pierre-Antoine Frugier"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2111.12541"
  },
  {
    "id": "arXiv:2111.15414",
    "title": "Neuron with Steady Response Leads to Better Generalization",
    "abstract": "Neuron with Steady Response Leads to Better Generalization",
    "descriptor": "",
    "authors": [
      "Qiang Fu",
      "Lun Du",
      "Haitao Mao",
      "Xu Chen",
      "Wei Fang",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15414"
  },
  {
    "id": "arXiv:2111.15611",
    "title": "The Power of Communication in a Distributed Multi-Agent System",
    "abstract": "Comments: Cooperative AI Workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia",
    "descriptor": "\nComments: Cooperative AI Workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia\n",
    "authors": [
      "Philipp Dominic Siedler"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.15611"
  },
  {
    "id": "arXiv:2112.01030",
    "title": "TransMEF: A Transformer-Based Multi-Exposure Image Fusion Framework  using Self-Supervised Multi-Task Learning",
    "abstract": "Comments: Accepted by the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI2022)",
    "descriptor": "\nComments: Accepted by the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI2022)\n",
    "authors": [
      "Linhao Qu",
      "Shaolei Liu",
      "Manning Wang",
      "Zhijian Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01030"
  },
  {
    "id": "arXiv:2112.01304",
    "title": "The voice of few, the opinions of many: evidence of social biases in  Twitter COVID-19 fake news sharing",
    "abstract": "Comments: 5 figures, added Acknowledgments",
    "descriptor": "\nComments: 5 figures, added Acknowledgments\n",
    "authors": [
      "Piergiorgio Castioni",
      "Giulia Andrighetto",
      "Riccardo Gallotti",
      "Eugenia Polizzi",
      "Manlio De Domenico"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.01304"
  },
  {
    "id": "arXiv:2112.02581",
    "title": "Long-Tail Session-based Recommendation from Calibration",
    "abstract": "Long-Tail Session-based Recommendation from Calibration",
    "descriptor": "",
    "authors": [
      "Jiayi Chen",
      "Wen Wu",
      "Wei Zheng",
      "Liang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.02581"
  },
  {
    "id": "arXiv:2112.02719",
    "title": "A Survey on Deep learning based Document Image Enhancement",
    "abstract": "A Survey on Deep learning based Document Image Enhancement",
    "descriptor": "",
    "authors": [
      "Zahra Anvari",
      "Vassilis Athitsos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02719"
  },
  {
    "id": "arXiv:2112.02789",
    "title": "HumanNeRF: Generalizable Neural Human Radiance Field from Sparse Inputs",
    "abstract": "HumanNeRF: Generalizable Neural Human Radiance Field from Sparse Inputs",
    "descriptor": "",
    "authors": [
      "Fuqiang Zhao",
      "Wei Yang",
      "Jiakai Zhang",
      "Pei Lin",
      "Yingliang Zhang",
      "Jingyi Yu",
      "Lan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.02789"
  },
  {
    "id": "arXiv:2112.02863",
    "title": "Eager Functions as Processes",
    "abstract": "Comments: the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS), Jul 2018, Oxford, United Kingdom",
    "descriptor": "\nComments: the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS), Jul 2018, Oxford, United Kingdom\n",
    "authors": [
      "Adrien Durier",
      "Daniel Hirschkoff",
      "Davide Sangiorgi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.02863"
  },
  {
    "id": "arXiv:2112.03203",
    "title": "An unsupervised extractive summarization method based on multi-round  computation",
    "abstract": "An unsupervised extractive summarization method based on multi-round  computation",
    "descriptor": "",
    "authors": [
      "Dehao Tao",
      "Yingzhu Xiong",
      "Jin He",
      "Skevin",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03203"
  },
  {
    "id": "arXiv:2112.03254",
    "title": "Human Parity on CommonsenseQA: Augmenting Self-Attention with External  Attention",
    "abstract": "Comments: 11 pages, 1 figure, 7 tables",
    "descriptor": "\nComments: 11 pages, 1 figure, 7 tables\n",
    "authors": [
      "Yichong Xu",
      "Chenguang Zhu",
      "Shuohang Wang",
      "Siqi Sun",
      "Hao Cheng",
      "Xiaodong Liu",
      "Jianfeng Gao",
      "Pengcheng He",
      "Michael Zeng",
      "Xuedong Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03254"
  },
  {
    "id": "arXiv:2112.03449",
    "title": "Locally Differentially Private Sparse Vector Aggregation",
    "abstract": "Locally Differentially Private Sparse Vector Aggregation",
    "descriptor": "",
    "authors": [
      "Mingxun Zhou",
      "Tianhao Wang",
      "T-H. Hubert Chan",
      "Giulia Fanti",
      "Elaine Shi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.03449"
  },
  {
    "id": "arXiv:2112.04128",
    "title": "GIFdroid: Automated Replay of Visual Bug Reports for Android Apps",
    "abstract": "Comments: Accepted to 44th International Conference on Software Engineering (ICSE 2022)",
    "descriptor": "\nComments: Accepted to 44th International Conference on Software Engineering (ICSE 2022)\n",
    "authors": [
      "Sidong Feng",
      "Chunyang Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.04128"
  },
  {
    "id": "arXiv:2112.04187",
    "title": "Pretrained Cost Model for Distributed Constraint Optimization Problems",
    "abstract": "Comments: Accepted by AAAI-22",
    "descriptor": "\nComments: Accepted by AAAI-22\n",
    "authors": [
      "Yanchen Deng",
      "Shufeng Kong",
      "Bo An"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04187"
  },
  {
    "id": "arXiv:2112.04953",
    "title": "Machine Learning for Utility Prediction in Argument-Based Computational  Persuasion",
    "abstract": "Comments: Updated: disclose fundings, remove unused files from source",
    "descriptor": "\nComments: Updated: disclose fundings, remove unused files from source\n",
    "authors": [
      "Ivan Donadello",
      "Anthony Hunter",
      "Stefano Teso",
      "Mauro Dragoni"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04953"
  },
  {
    "id": "arXiv:2112.05239",
    "title": "On multivariate randomized classification trees: $l_0$-based sparsity,  VC~dimension and decomposition methods",
    "abstract": "On multivariate randomized classification trees: $l_0$-based sparsity,  VC~dimension and decomposition methods",
    "descriptor": "",
    "authors": [
      "Edoardo Amaldi",
      "Antonio Consolo",
      "Andrea Manno"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05239"
  },
  {
    "id": "arXiv:2112.05403",
    "title": "Computing Diverse Shortest Paths Efficiently: A Theoretical and  Experimental Study",
    "abstract": "Computing Diverse Shortest Paths Efficiently: A Theoretical and  Experimental Study",
    "descriptor": "",
    "authors": [
      "Tesshu Hanaka",
      "Yasuaki Kobayashi",
      "Kazuhiro Kurita",
      "See Woo Lee",
      "Yota Otachi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.05403"
  },
  {
    "id": "arXiv:2112.05489",
    "title": "Surrogate-data-enriched Physics-Aware Neural Networks",
    "abstract": "Surrogate-data-enriched Physics-Aware Neural Networks",
    "descriptor": "",
    "authors": [
      "Raphael Leiteritz",
      "Patrick Buchfink",
      "Bernard Haasdonk",
      "Dirk Pfl\u00fcger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05489"
  },
  {
    "id": "arXiv:2112.05587",
    "title": "Unified Multimodal Pre-training and Prompt-based Tuning for  Vision-Language Understanding and Generation",
    "abstract": "Unified Multimodal Pre-training and Prompt-based Tuning for  Vision-Language Understanding and Generation",
    "descriptor": "",
    "authors": [
      "Tianyi Liu",
      "Zuxuan Wu",
      "Wenhan Xiong",
      "Jingjing Chen",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05587"
  },
  {
    "id": "arXiv:2112.05615",
    "title": "Intelligent Transportation Systems With The Use of External  Infrastructure: A Literature Survey",
    "abstract": "Comments: 14 pages, 4 tables, 4 figures",
    "descriptor": "\nComments: 14 pages, 4 tables, 4 figures\n",
    "authors": [
      "Christian Cre\u00df",
      "Alois C. Knoll"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.05615"
  },
  {
    "id": "arXiv:2112.05744",
    "title": "More Control for Free! Image Synthesis with Semantic Diffusion Guidance",
    "abstract": "Comments: Project page this https URL",
    "descriptor": "\nComments: Project page this https URL\n",
    "authors": [
      "Xihui Liu",
      "Dong Huk Park",
      "Samaneh Azadi",
      "Gong Zhang",
      "Arman Chopikyan",
      "Yuxiao Hu",
      "Humphrey Shi",
      "Anna Rohrbach",
      "Trevor Darrell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.05744"
  },
  {
    "id": "arXiv:2112.05820",
    "title": "Building a great multi-lingual teacher with sparsely-gated mixture of  experts for speech recognition",
    "abstract": "Building a great multi-lingual teacher with sparsely-gated mixture of  experts for speech recognition",
    "descriptor": "",
    "authors": [
      "Kenichi Kumatani",
      "Robert Gmyr",
      "Felipe Cruz Salinas",
      "Linquan Liu",
      "Wei Zuo",
      "Devang Patel",
      "Eric Sun",
      "Yu Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.05820"
  },
  {
    "id": "arXiv:2112.05928",
    "title": "Efficient Device Scheduling with Multi-Job Federated Learning",
    "abstract": "Comments: 14 pages, 7 figures, 6 tables",
    "descriptor": "\nComments: 14 pages, 7 figures, 6 tables\n",
    "authors": [
      "Chendi Zhou",
      "Ji Liu",
      "Juncheng Jia",
      "Jingbo Zhou",
      "Yang Zhou",
      "Huaiyu Dai",
      "Dejing Dou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.05928"
  },
  {
    "id": "arXiv:2112.05958",
    "title": "You Only Need End-to-End Training for Long-Tailed Recognition",
    "abstract": "Comments: 16 pages, 11 figures, 8 tables",
    "descriptor": "\nComments: 16 pages, 11 figures, 8 tables\n",
    "authors": [
      "Zhiwei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05958"
  },
  {
    "id": "arXiv:2112.06226",
    "title": "Attention based Broadly Self-guided Network for Low light Image  Enhancement",
    "abstract": "Comments: 10 Pages,8 Figures,4 Tables",
    "descriptor": "\nComments: 10 Pages,8 Figures,4 Tables\n",
    "authors": [
      "Zilong Chen",
      "Yaling Liang",
      "Minghui Du"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06226"
  },
  {
    "id": "arXiv:2112.06396",
    "title": "Does Fully Homomorphic Encryption Need Compute Acceleration?",
    "abstract": "Does Fully Homomorphic Encryption Need Compute Acceleration?",
    "descriptor": "",
    "authors": [
      "Leo de Castro",
      "Rashmi Agrawal",
      "Rabia Yazicigil",
      "Anantha Chandrakasan",
      "Vinod Vaikuntanathan",
      "Chiraag Juvekar",
      "Ajay Joshi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.06396"
  },
  {
    "id": "arXiv:2112.06455",
    "title": "Self-Paced Deep Regression Forests with Consideration on Ranking  Fairness",
    "abstract": "Comments: 14 pages, 9 figures. The paper has been submitted to TIP and is currently under review",
    "descriptor": "\nComments: 14 pages, 9 figures. The paper has been submitted to TIP and is currently under review\n",
    "authors": [
      "Lili Pan",
      "Mingming Meng",
      "Yazhou Ren",
      "Yali Zheng",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06455"
  },
  {
    "id": "arXiv:2112.06560",
    "title": "HiClass: a Python library for local hierarchical classification  compatible with scikit-learn",
    "abstract": "Comments: 9 pages, 2 figures, 1 table",
    "descriptor": "\nComments: 9 pages, 2 figures, 1 table\n",
    "authors": [
      "F\u00e1bio M. Miranda",
      "Niklas K\u00f6ehnecke",
      "Bernhard Y. Renard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06560"
  },
  {
    "id": "arXiv:2112.06899",
    "title": "Locally Fair Partitioning",
    "abstract": "Locally Fair Partitioning",
    "descriptor": "",
    "authors": [
      "Pankaj K. Agarwal",
      "Shao-Heng Ko",
      "Kamesh Munagala",
      "Erin Taylor"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.06899"
  },
  {
    "id": "arXiv:2112.06904",
    "title": "HVH: Learning a Hybrid Neural Volumetric Representation for Dynamic Hair  Performance Capture",
    "abstract": "HVH: Learning a Hybrid Neural Volumetric Representation for Dynamic Hair  Performance Capture",
    "descriptor": "",
    "authors": [
      "Ziyan Wang",
      "Giljoo Nam",
      "Tuur Stuyck",
      "Stephen Lombardi",
      "Michael Zollhoefer",
      "Jessica Hodgins",
      "Christoph Lassner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.06904"
  },
  {
    "id": "arXiv:2112.07030",
    "title": "Approximation algorithms for $k$-median with lower-bound constraints",
    "abstract": "Approximation algorithms for $k$-median with lower-bound constraints",
    "descriptor": "",
    "authors": [
      "Ameet Gadekar",
      "Bruno Ordozgoiti",
      "Suhas Thejaswi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.07030"
  },
  {
    "id": "arXiv:2112.07110",
    "title": "Non Asymptotic Bounds for Optimization via Online Multiplicative  Stochastic Gradient Descent",
    "abstract": "Non Asymptotic Bounds for Optimization via Online Multiplicative  Stochastic Gradient Descent",
    "descriptor": "",
    "authors": [
      "Riddhiman Bhattacharya"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.07110"
  },
  {
    "id": "arXiv:2112.07116",
    "title": "Joint 3D Object Detection and Tracking Using Spatio-Temporal  Representation of Camera Image and LiDAR Point Clouds",
    "abstract": "Joint 3D Object Detection and Tracking Using Spatio-Temporal  Representation of Camera Image and LiDAR Point Clouds",
    "descriptor": "",
    "authors": [
      "Junho Koh",
      "Jaekyum Kim",
      "Jinhyuk Yoo",
      "Yecheol Kim",
      "Dongsuk Kum",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07116"
  },
  {
    "id": "arXiv:2112.07152",
    "title": "On the structure of the solutions to the matrix equation $G^*JG=J$",
    "abstract": "Comments: 26 pages, 4 figures",
    "descriptor": "\nComments: 26 pages, 4 figures\n",
    "authors": [
      "Alan Edelman",
      "Sungwoo Jeong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07152"
  },
  {
    "id": "arXiv:2112.07222",
    "title": "Meta-CPR: Generalize to Unseen Large Number of Agents with Communication  Pattern Recognition Module",
    "abstract": "Meta-CPR: Generalize to Unseen Large Number of Agents with Communication  Pattern Recognition Module",
    "descriptor": "",
    "authors": [
      "Wei-Cheng Tseng",
      "Wei Wei",
      "Da-Chen Juan",
      "Min Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.07222"
  },
  {
    "id": "arXiv:2112.07303",
    "title": "MMO: Meta Multi-Objectivization for Software Configuration Tuning",
    "abstract": "Comments: 12 figures, 5 tables. journal extension from arXiv:2106.01331",
    "descriptor": "\nComments: 12 figures, 5 tables. journal extension from arXiv:2106.01331\n",
    "authors": [
      "Tao Chen",
      "Miqing Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.07303"
  },
  {
    "id": "arXiv:2112.07471",
    "title": "I M Avatar: Implicit Morphable Head Avatars from Videos",
    "abstract": "I M Avatar: Implicit Morphable Head Avatars from Videos",
    "descriptor": "",
    "authors": [
      "Yufeng Zheng",
      "Victoria Fern\u00e1ndez Abrevaya",
      "Xu Chen",
      "Marcel C. B\u00fchler",
      "Michael J. Black",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07471"
  },
  {
    "id": "arXiv:2112.07493",
    "title": "EABlock: A Declarative Entity Alignment Block for Knowledge Graph  Creation Pipelines",
    "abstract": "EABlock: A Declarative Entity Alignment Block for Knowledge Graph  Creation Pipelines",
    "descriptor": "",
    "authors": [
      "Samaneh Jozashoori",
      "Ahmad Sakor",
      "Enrique Iglesias",
      "Maria-Esther Vidal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07493"
  },
  {
    "id": "arXiv:2112.07528",
    "title": "n-CPS: Generalising Cross Pseudo Supervision to n networks for  Semi-Supervised Semantic Segmentation",
    "abstract": "n-CPS: Generalising Cross Pseudo Supervision to n networks for  Semi-Supervised Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Dominik Filipiak",
      "Piotr Tempczyk",
      "Marek Cygan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07528"
  }
]
[
  {
    "id": "arXiv:2112.08360",
    "title": "How to Learn and Represent Abstractions: An Investigation using Symbolic  Alchemy",
    "abstract": "Alchemy is a new meta-learning environment rich enough to contain interesting\nabstractions, yet simple enough to make fine-grained analysis tractable.\nFurther, Alchemy provides an optional symbolic interface that enables meta-RL\nresearch without a large compute budget. In this work, we take the first steps\ntoward using Symbolic Alchemy to identify design choices that enable deep-RL\nagents to learn various types of abstraction. Then, using a variety of\nbehavioral and introspective analyses we investigate how our trained agents use\nand represent abstract task variables, and find intriguing connections to the\nneuroscience of abstraction. We conclude by discussing the next steps for using\nmeta-RL and Alchemy to better understand the representation of abstract\nvariables in the brain.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Badr AlKhamissi",
      "Akshay Srinivasan",
      "Zeb-Kurth Nelson",
      "Sam Ritter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08360"
  },
  {
    "id": "arXiv:2112.08361",
    "title": "Deep Generative Models for Vehicle Speed Trajectories",
    "abstract": "Generating realistic vehicle speed trajectories is a crucial component in\nevaluating vehicle fuel economy and in predictive control of self-driving cars.\nTraditional generative models rely on Markov chain methods and can produce\naccurate synthetic trajectories but are subject to the curse of dimensionality.\nThey do not allow to include conditional input variables into the generation\nprocess. In this paper, we show how extensions to deep generative models allow\naccurate and scalable generation. Proposed architectures involve recurrent and\nfeed-forward layers and are trained using adversarial techniques. Our models\nare shown to perform well on generating vehicle trajectories using a model\ntrained on GPS data from Chicago metropolitan area.",
    "descriptor": "",
    "authors": [
      "Farnaz Behnia",
      "Dominik Karbowski",
      "Vadim Sokolov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.08361"
  },
  {
    "id": "arXiv:2112.08363",
    "title": "Performance or Trust? Why Not Both. Deep AUC Maximization with  Self-Supervised Learning for COVID-19 Chest X-ray Classifications",
    "abstract": "Effective representation learning is the key in improving model performance\nfor medical image analysis. In training deep learning models, a compromise\noften must be made between performance and trust, both of which are essential\nfor medical applications. Moreover, models optimized with cross-entropy loss\ntend to suffer from unwarranted overconfidence in the majority class and\nover-cautiousness in the minority class. In this work, we integrate a new\nsurrogate loss with self-supervised learning for computer-aided screening of\nCOVID-19 patients using radiography images. In addition, we adopt a new\nquantification score to measure a model's trustworthiness. Ablation study is\nconducted for both the performance and the trust on feature learning methods\nand loss functions. Comparisons show that leveraging the new surrogate loss on\nself-supervised models can produce label-efficient networks that are both\nhigh-performing and trustworthy.",
    "descriptor": "\nComments: 3 pages\n",
    "authors": [
      "Siyuan He",
      "Pengcheng Xi",
      "Ashkan Ebadi",
      "Stephane Tremblay",
      "Alexander Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.08363"
  },
  {
    "id": "arXiv:2112.08364",
    "title": "Data Valuation for Vertical Federated Learning: An Information-Theoretic  Approach",
    "abstract": "Federated learning (FL) is a promising machine learning paradigm that enables\ncross-party data collaboration for real-world AI applications in a\nprivacy-preserving and law-regulated way. How to valuate parties' data is a\ncritical but challenging FL issue. In the literature, data valuation either\nrelies on running specific models for a given task or is just task irrelevant;\nhowever, it is often requisite for party selection given a specific task when\nFL models have not been determined yet. This work thus fills the gap and\nproposes \\emph{FedValue}, to our best knowledge, the first privacy-preserving,\ntask-specific but model-free data valuation method for vertical FL tasks.\nSpecifically, FedValue incorporates a novel information-theoretic metric termed\nShapley-CMI to assess data values of multiple parties from a game-theoretic\nperspective. Moreover, a novel server-aided federated computation mechanism is\ndesigned to compute Shapley-CMI and meanwhile protects each party from data\nleakage. We also propose several techniques to accelerate Shapley-CMI\ncomputation in practice. Extensive experiments on six open datasets validate\nthe effectiveness and efficiency of FedValue for data valuation of vertical FL\ntasks. In particular, Shapley-CMI as a model-free metric performs comparably\nwith the measures that depend on running an ensemble of well-performing models.",
    "descriptor": "",
    "authors": [
      "Xiao Han",
      "Leye Wang",
      "Junjie Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08364"
  },
  {
    "id": "arXiv:2112.08369",
    "title": "Feature-Attending Recurrent Modules for Generalization in Reinforcement  Learning",
    "abstract": "Deep reinforcement learning (Deep RL) has recently seen significant progress\nin developing algorithms for generalization. However, most algorithms target a\nsingle type of generalization setting. In this work, we study generalization\nacross three disparate task structures: (a) tasks composed of spatial and\ntemporal compositions of regularly occurring object motions; (b) tasks composed\nof active perception of and navigation towards regularly occurring 3D objects;\nand (c) tasks composed of remembering goal-information over sequences of\nregularly occurring object-configurations. These diverse task structures all\nshare an underlying idea of compositionality: task completion always involves\ncombining recurring segments of task-oriented perception and behavior. We\nhypothesize that an agent can generalize within a task structure if it can\ndiscover representations that capture these recurring task-segments. For our\ntasks, this corresponds to representations for recognizing individual object\nmotions, for navigation towards 3D objects, and for navigating through\nobject-configurations. Taking inspiration from cognitive science, we term\nrepresentations for recurring segments of an agent's experience, \"perceptual\nschemas\". We propose Feature Attending Recurrent Modules (FARM), which learns a\nstate representation where perceptual schemas are distributed across multiple,\nrelatively small recurrent modules. We compare FARM to recurrent architectures\nthat leverage spatial attention, which reduces observation features to a\nweighted average over spatial positions. Our experiments indicate that our\nfeature-attention mechanism better enables FARM to generalize across the\ndiverse object-centric domains we study.",
    "descriptor": "",
    "authors": [
      "Wilka Carvalho",
      "Andrew Lampinen",
      "Kyriacos Nikiforou",
      "Felix Hill",
      "Murray Shanahan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08369"
  },
  {
    "id": "arXiv:2112.08370",
    "title": "Lifelong Generative Modelling Using Dynamic Expansion Graph Model",
    "abstract": "Variational Autoencoders (VAEs) suffer from degenerated performance, when\nlearning several successive tasks. This is caused by catastrophic forgetting.\nIn order to address the knowledge loss, VAEs are using either Generative Replay\n(GR) mechanisms or Expanding Network Architectures (ENA). In this paper we\nstudy the forgetting behaviour of VAEs using a joint GR and ENA methodology, by\nderiving an upper bound on the negative marginal log-likelihood. This\ntheoretical analysis provides new insights into how VAEs forget the previously\nlearnt knowledge during lifelong learning. The analysis indicates the best\nperformance achieved when considering model mixtures, under the ENA framework,\nwhere there are no restrictions on the number of components. However, an\nENA-based approach may require an excessive number of parameters. This\nmotivates us to propose a novel Dynamic Expansion Graph Model (DEGM). DEGM\nexpands its architecture, according to the novelty associated with each new\ndatabases, when compared to the information already learnt by the network from\nprevious tasks. DEGM training optimizes knowledge structuring, characterizing\nthe joint probabilistic representations corresponding to the past and more\nrecently learned tasks. We demonstrate that DEGM guarantees optimal performance\nfor each task while also minimizing the required number of parameters.\nSupplementary materials (SM) and source code are available in\nhttps://github.com/dtuzi123/Expansion-Graph-Model.",
    "descriptor": "\nComments: Accepted in Proceedings of the 36th AAAI Conference on Artificial Intelligence (AAAI 2022)\n",
    "authors": [
      "Fei Ye",
      "Adrian G. Bors"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08370"
  },
  {
    "id": "arXiv:2112.08371",
    "title": "Blockchain as an IoT intermediary",
    "abstract": "Blockchain technology provides a private, secure, transparent decentralized\nexchange of data. Also, blockchain is not limited to a particular area, but it\nhas a wide range of applications and can be integrated into a variety of\nInternet interactive systems. For example, the Internet of Things (IoT), supply\nchain tracking, Electronic Health Records (EHR), digital forensics, identity\nmanagement, trustless payments, and other key business elements will all\nbenefit from its implementation. Next layer solutions such as Ethereum 2.0,\nPolkadot, Cardano, and other Web 3.0 technologies provide developers\nversatility. Moreover, these platforms utilize smart contracts which are\nsimilar to standard, traditionalized software during development but offer key\nutilities to end-users such as online wallets, secure data with transparent\nrules. Blockchain is receiving a lot of attention in educational technology\n(EduTech) as it aims to achieve a more transparent and multipurpose educational\nsystem. In addition to smart contract technology which defines how data should\nbe registered, gathered and processed, blockchain can be used as an IoT\nintermediary for mobile usage. Therefore, we implemented an educational\nlearning platform powered by blockchain technology to examine feasibility in\nindustry and academic environment. In essence, this is a web application which\nis adapted to mobile platform and connected to blockchain for crucial data\nexchanges. In this paper we want to emphasize the potential of blockchain\ntechnology in multiple sectors as well as the need to really understand the\nunderlying principles which are allowing disruptability of traditional\ncentralized software solutions.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "M. Sipek",
      "M. Zagar",
      "B. Mihaljevic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.08371"
  },
  {
    "id": "arXiv:2112.08414",
    "title": "DSGPT: Domain-Specific Generative Pre-Training of Transformers for Text  Generation in E-commerce Title and Review Summarization",
    "abstract": "We propose a novel domain-specific generative pre-training (DS-GPT) method\nfor text generation and apply it to the product titleand review summarization\nproblems on E-commerce mobile display.First, we adopt a decoder-only\ntransformer architecture, which fitswell for fine-tuning tasks by combining\ninput and output all to-gether. Second, we demonstrate utilizing only small\namount of pre-training data in related domains is powerful. Pre-training a\nlanguagemodel from a general corpus such as Wikipedia or the CommonCrawl\nrequires tremendous time and resource commitment, andcan be wasteful if the\ndownstream tasks are limited in variety. OurDSGPT is pre-trained on a limited\ndataset, the Chinese short textsummarization dataset (LCSTS). Third, our model\ndoes not requireproduct-related human-labeled data. For title summarization\ntask,the state of art explicitly uses additional background knowledgein\ntraining and predicting stages. In contrast, our model implic-itly captures\nthis knowledge and achieves significant improvementover other methods, after\nfine-tuning on the public Taobao.comdataset. For review summarization task, we\nutilize JD.com in-housedataset, and observe similar improvement over standard\nmachinetranslation methods which lack the flexibility of fine-tuning.\nOurproposed work can be simply extended to other domains for a widerange of\ntext generation tasks.",
    "descriptor": "",
    "authors": [
      "Xueying Zhang",
      "Yunjiang Jiang",
      "Yue Shang",
      "Zhaomeng Cheng",
      "Chi Zhang",
      "Xiaochuan Fan",
      "Yun Xiao",
      "Bo Long"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08414"
  },
  {
    "id": "arXiv:2112.08415",
    "title": "Real-time Detection of Anomalies in Multivariate Time Series of  Astronomical Data",
    "abstract": "Astronomical transients are stellar objects that become temporarily brighter\non various timescales and have led to some of the most significant discoveries\nin cosmology and astronomy. Some of these transients are the explosive deaths\nof stars known as supernovae while others are rare, exotic, or entirely new\nkinds of exciting stellar explosions. New astronomical sky surveys are\nobserving unprecedented numbers of multi-wavelength transients, making standard\napproaches of visually identifying new and interesting transients infeasible.\nTo meet this demand, we present two novel methods that aim to quickly and\nautomatically detect anomalous transient light curves in real-time. Both\nmethods are based on the simple idea that if the light curves from a known\npopulation of transients can be accurately modelled, any deviations from model\npredictions are likely anomalies. The first approach is a probabilistic neural\nnetwork built using Temporal Convolutional Networks (TCNs) and the second is an\ninterpretable Bayesian parametric model of a transient. We show that the\nflexibility of neural networks, the attribute that makes them such a powerful\ntool for many regression tasks, is what makes them less suitable for anomaly\ndetection when compared with our parametric model.",
    "descriptor": "\nComments: 9 pages, 5 figures, Accepted at the NeurIPS 2021 workshop on Machine Learning and the Physical Sciences\n",
    "authors": [
      "Daniel Muthukrishna",
      "Kaisey S. Mandel",
      "Michelle Lochner",
      "Sara Webb",
      "Gautham Narayan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.08415"
  },
  {
    "id": "arXiv:2112.08418",
    "title": "Neural Network-based Power Flow Model",
    "abstract": "Power flow analysis is used to evaluate the flow of electricity in the power\nsystem network. Power flow calculation is used to determine the steady-state\nvariables of the system, such as the voltage magnitude /phase angle of each bus\nand the active/reactive power flow on each branch. The DC power flow model is a\npopular linear power flow model that is widely used in the power industry.\nAlthough it is fast and robust, it may lead to inaccurate line flow results for\nsome critical transmission lines. This drawback can be partially addressed by\ndata-driven methods that take advantage of historical grid profiles. In this\npaper, a neural network (NN) model is trained to predict power flow results\nusing historical power system data. Although the training process may take\ntime, once trained, it is very fast to estimate line flows. A comprehensive\nperformance analysis between the proposed NN-based power flow model and the\ntraditional DC power flow model is conducted. It can be concluded that the\nproposed NN-based power flow model can find solutions quickly and more\naccurately than DC power flow model.",
    "descriptor": "",
    "authors": [
      "Thuan Pham",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08418"
  },
  {
    "id": "arXiv:2112.08421",
    "title": "A White-Box SVM Framework and its Swarm-Based Optimization for  Supervision of Toothed Milling Cutter through Characterization of Spindle  Vibrations",
    "abstract": "In this paper, a white-Box support vector machine (SVM) framework and its\nswarm-based optimization is presented for supervision of toothed milling cutter\nthrough characterization of real-time spindle vibrations. The anomalous moments\nof vibration evolved due to in-process tool failures (i.e., flank and nose\nwear, crater and notch wear, edge fracture) have been investigated through\ntime-domain response of acceleration and statistical features. The Recursive\nFeature Elimination with Cross-Validation (RFECV) with decision trees as the\nestimator has been implemented for feature selection. Further, the competence\nof standard SVM has been examined for tool health monitoring followed by its\noptimization through application of swarm based algorithms. The comparative\nanalysis of performance of five meta-heuristic algorithms (Elephant Herding\nOptimization, Monarch Butterfly Optimization, Harris Hawks Optimization, Slime\nMould Algorithm, and Moth Search Algorithm) has been carried out. The white-box\napproach has been presented considering global and local representation that\nprovides insight into the performance of machine learning models in tool\ncondition monitoring.",
    "descriptor": "",
    "authors": [
      "Tejas Y. Deo",
      "Abhishek D. Patange",
      "Sujit S. Pardeshi",
      "R. Jegadeeshwaran",
      "Apoorva N. Khairnar",
      "Hrushikesh S. Khade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.08421"
  },
  {
    "id": "arXiv:2112.08426",
    "title": "Contact simulation of a 2D Bipedal Robot kicking a ball",
    "abstract": "This report describes an approach for simulating multi-body contacts of\nactively-controlled systems. In this work, we focus on the controls and contact\nsimulation of a 2-dimensional bipedal robot kicking a circular ball.",
    "descriptor": "",
    "authors": [
      "Alphonsus Adu-Bredu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08426"
  },
  {
    "id": "arXiv:2112.08428",
    "title": "An approach for the aggregation of power system controllers with  different topologies",
    "abstract": "This paper proposes an approach to aggregate nonstructured power system\ncontrollers preserving the dynamical characteristics of the original devices.\nThe method is based on linear operations that use the frequency response of the\nelements, resulting in an accurate input-output description of the equivalent\ncontroller when compared to the original ones. The developed method was applied\nto a model of the future interconnected Paraguayan-Argentinean power system to\nproduce a dynamic equivalent used in a real-time simulator to test the special\nprotection scheme needed for the safe operation of the this future system.\nTransient and small-signal stability studies presented matching simulation\nresults in the time domain with significantly reduced computational burden and\nprocessing time.",
    "descriptor": "\nComments: Preprint submitted to the 22nd Power Systems Computation Conference (PSCC 2022)\n",
    "authors": [
      "Jonas Pesente",
      "Paulo Galassi",
      "Leonardo Rodrigues",
      "Felipe Crestani",
      "Guilherme Justino",
      "Rodrigo Ramos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.08428"
  },
  {
    "id": "arXiv:2112.08429",
    "title": "torch.fx: Practical Program Capture and Transformation for Deep Learning  in Python",
    "abstract": "Modern deep learning frameworks provide imperative, eager execution\nprogramming interfaces embedded in Python to provide a productive development\nexperience. However, deep learning practitioners sometimes need to capture and\ntransform program structure for performance optimization, visualization,\nanalysis, and hardware integration. We study the different designs for program\ncapture and transformation used in deep learning. By designing for typical deep\nlearning use cases rather than long tail ones, it is possible to create a\nsimpler framework for program capture and transformation. We apply this\nprinciple in torch.fx, a program capture and transformation library for PyTorch\nwritten entirely in Python and optimized for high developer productivity by ML\npractitioners. We present case studies showing how torch.fx enables workflows\npreviously inaccessible in the PyTorch ecosystem.",
    "descriptor": "\nComments: 14 pages, 8 figures, Submitted to MLSys 2022\n",
    "authors": [
      "James K. Reed",
      "Zachary DeVito",
      "Horace He",
      "Ansley Ussery",
      "Jason Ansel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08429"
  },
  {
    "id": "arXiv:2112.08431",
    "title": "Cybersecurity Revisited: Honeytokens meet Google Authenticator",
    "abstract": "Although sufficient authentication mechanisms were enhanced by the use of two\nor more factors that resulted in new multi factor authentication schemes, more\nsophisticated and targeted attacks have shown they are also vulnerable. This\nresearch work proposes a novel two factor authentication system that\nincorporates honeytokens into the two factor authentication process. The\ncurrent implementation collaborates with Google authenticator. The novelty and\nsimplicity of the presented approach aims at providing additional layers of\nsecurity and protection into a system and thus making it more secure through a\nstronger and more efficient authentication mechanism.",
    "descriptor": "\nComments: 6 pages, 1 figure\n",
    "authors": [
      "Vasilis Papaspirou",
      "Maria Papathanasaki",
      "Leandros Maglaras",
      "Ioanna Kantzavelou",
      "Christos Douligeris",
      "Mohamed Amine Ferrag",
      "Helge Janicke"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.08431"
  },
  {
    "id": "arXiv:2112.08432",
    "title": "Expert and Crowd-Guided Affect Annotation and Prediction",
    "abstract": "We employ crowdsourcing to acquire time-continuous affective annotations for\nmovie clips, and refine noisy models trained from these crowd annotations\nincorporating expert information within a Multi-task Learning (MTL) framework.\nWe propose a novel \\textbf{e}xpert \\textbf{g}uided MTL (EG-MTL) algorithm,\nwhich minimizes the loss with respect to both crowd and expert labels to learn\na set of weights corresponding to each movie clip for which crowd annotations\nare acquired. We employ EG-MTL to solve two problems, namely,\n\\textbf{\\texttt{P1}}: where dynamic annotations acquired from both experts and\ncrowdworkers for the \\textbf{Validation} set are used to train a regression\nmodel with audio-visual clip descriptors as features, and predict dynamic\narousal and valence levels on 5--15 second snippets derived from the clips; and\n\\textbf{\\texttt{P2}}: where a classification model trained on the\n\\textbf{Validation} set using dynamic crowd and expert annotations (as\nfeatures) and static affective clip labels is used for binary emotion\nrecognition on the \\textbf{Evaluation} set for which only dynamic crowd\nannotations are available. Observed experimental results confirm the\neffectiveness of the EG-MTL algorithm, which is reflected via improved arousal\nand valence estimation for \\textbf{\\texttt{P1}}, and higher recognition\naccuracy for \\textbf{\\texttt{P2}}.",
    "descriptor": "\nComments: Manuscript submitted for review to IEEE Transactions on Affective Computing\n",
    "authors": [
      "Ramanathan Subramanian",
      "Yan Yan",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.08432"
  },
  {
    "id": "arXiv:2112.08438",
    "title": "Programmatic Reward Design by Example",
    "abstract": "Reward design is a fundamental problem in reinforcement learning (RL). A\nmisspecified or poorly designed reward can result in low sample efficiency and\nundesired behaviors. In this paper, we propose the idea of \\textit{programmatic\nreward design}, i.e. using programs to specify the reward functions in RL\nenvironments. Programs allow human engineers to express sub-goals and complex\ntask scenarios in a structured and interpretable way. The challenge of\nprogrammatic reward design, however, is that while humans can provide the\nhigh-level structures, properly setting the low-level details, such as the\nright amount of reward for a specific sub-task, remains difficult. A major\ncontribution of this paper is a probabilistic framework that can infer the best\ncandidate programmatic reward function from expert demonstrations. Inspired by\nrecent generative-adversarial approaches, our framework {searches for the most\nlikely programmatic reward function under which the optimally generated\ntrajectories cannot be differentiated from the demonstrated trajectories}.\nExperimental results show that programmatic reward functions learned using this\nframework can significantly outperform those learned using existing reward\nlearning algorithms, and enable RL agents to achieve state-of-the-art\nperformance on highly complex tasks.",
    "descriptor": "",
    "authors": [
      "Weichao Zhou",
      "Wenchao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.08438"
  },
  {
    "id": "arXiv:2112.08439",
    "title": "Generalization Bounds for Stochastic Gradient Langevin Dynamics: A  Unified View via Information Leakage Analysis",
    "abstract": "Recently, generalization bounds of the non-convex empirical risk minimization\nparadigm using Stochastic Gradient Langevin Dynamics (SGLD) have been\nextensively studied. Several theoretical frameworks have been presented to\nstudy this problem from different perspectives, such as information theory and\nstability. In this paper, we present a unified view from privacy leakage\nanalysis to investigate the generalization bounds of SGLD, along with a\ntheoretical framework for re-deriving previous results in a succinct manner.\nAside from theoretical findings, we conduct various numerical studies to\nempirically assess the information leakage issue of SGLD. Additionally, our\ntheoretical and empirical results provide explanations for prior works that\nstudy the membership privacy of SGLD.",
    "descriptor": "",
    "authors": [
      "Bingzhe Wu",
      "Zhicong Liang",
      "Yatao Bian",
      "ChaoChao Chen",
      "Junzhou Huang",
      "Yuan Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08439"
  },
  {
    "id": "arXiv:2112.08440",
    "title": "Climate-Invariant Machine Learning",
    "abstract": "Data-driven algorithms, in particular neural networks, can emulate the\neffects of unresolved processes in coarse-resolution climate models when\ntrained on high-resolution simulation data; however, they often make large\ngeneralization errors when evaluated in conditions they were not trained on.\nHere, we propose to physically rescale the inputs and outputs of machine\nlearning algorithms to help them generalize to unseen climates. Applied to\noffline parameterizations of subgrid-scale thermodynamics in three distinct\nclimate models, we show that rescaled or \"climate-invariant\" neural networks\nmake accurate predictions in test climates that are 4K and 8K warmer than their\ntraining climates. Additionally, \"climate-invariant\" neural nets facilitate\ngeneralization between Aquaplanet and Earth-like simulations. Through\nvisualization and attribution methods, we show that compared to standard\nmachine learning models, \"climate-invariant\" algorithms learn more local and\nrobust relations between storm-scale convection, radiation, and their synoptic\nthermodynamic environment. Overall, these results suggest that explicitly\nincorporating physical knowledge into data-driven models of Earth system\nprocesses can improve their consistency and ability to generalize across\nclimate regimes.",
    "descriptor": "\nComments: 12+18 pages, 8+12 figures, 2+2 tables in the main text + supplementary information. Submitted to PNAS on December 14th, 2021\n",
    "authors": [
      "Tom Beucler",
      "Michael Pritchard",
      "Janni Yuval",
      "Ankitesh Gupta",
      "Liran Peng",
      "Stephan Rasp",
      "Fiaz Ahmed",
      "Paul A. O'Gorman",
      "J. David Neelin",
      "Nicholas J. Lutsko",
      "Pierre Gentine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.08440"
  },
  {
    "id": "arXiv:2112.08441",
    "title": "Towards Explainable Artificial Intelligence in Banking and Financial  Services",
    "abstract": "Artificial intelligence (AI) enables machines to learn from human experience,\nadjust to new inputs, and perform human-like tasks. AI is progressing rapidly\nand is transforming the way businesses operate, from process automation to\ncognitive augmentation of tasks and intelligent process/data analytics.\nHowever, the main challenge for human users would be to understand and\nappropriately trust the result of AI algorithms and methods. In this paper, to\naddress this challenge, we study and analyze the recent work done in\nExplainable Artificial Intelligence (XAI) methods and tools. We introduce a\nnovel XAI process, which facilitates producing explainable models while\nmaintaining a high level of learning performance. We present an interactive\nevidence-based approach to assist human users in comprehending and trusting the\nresults and output created by AI-enabled algorithms. We adopt a typical\nscenario in the Banking domain for analyzing customer transactions. We develop\na digital dashboard to facilitate interacting with the algorithm results and\ndiscuss how the proposed XAI method can significantly improve the confidence of\ndata scientists in understanding the result of AI-enabled algorithms.",
    "descriptor": "",
    "authors": [
      "Ambreen Hanif"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08441"
  },
  {
    "id": "arXiv:2112.08442",
    "title": "Utilizing XAI technique to improve autoencoder based model for computer  network anomaly detection with shapley additive explanation(SHAP)",
    "abstract": "Machine learning (ML) and Deep Learning (DL) methods are being adopted\nrapidly, especially in computer network security, such as fraud detection,\nnetwork anomaly detection, intrusion detection, and much more. However, the\nlack of transparency of ML and DL based models is a major obstacle to their\nimplementation and criticized due to its black-box nature, even with such\ntremendous results. Explainable Artificial Intelligence (XAI) is a promising\narea that can improve the trustworthiness of these models by giving\nexplanations and interpreting its output. If the internal working of the ML and\nDL based models is understandable, then it can further help to improve its\nperformance. The objective of this paper is to show that how XAI can be used to\ninterpret the results of the DL model, the autoencoder in this case. And, based\non the interpretation, we improved its performance for computer network anomaly\ndetection. The kernel SHAP method, which is based on the shapley values, is\nused as a novel feature selection technique. This method is used to identify\nonly those features that are actually causing the anomalous behaviour of the\nset of attack/anomaly instances. Later, these feature sets are used to train\nand validate the autoencoder but on benign data only. Finally, the built\nSHAP_Model outperformed the other two models proposed based on the feature\nselection method. This whole experiment is conducted on the subset of the\nlatest CICIDS2017 network dataset. The overall accuracy and AUC of SHAP_Model\nis 94% and 0.969, respectively.",
    "descriptor": "\nComments: 20 pages, 12 figures, 4 tables, journal article\n",
    "authors": [
      "Khushnaseeb Roshan",
      "Aasim Zafar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.08442"
  },
  {
    "id": "arXiv:2112.08443",
    "title": "Event-Aware Multimodal Mobility Nowcasting",
    "abstract": "As a decisive part in the success of Mobility-as-a-Service (MaaS),\nspatio-temporal predictive modeling for crowd movements is a challenging task\nparticularly considering scenarios where societal events drive mobility\nbehavior deviated from the normality. While tremendous progress has been made\nto model high-level spatio-temporal regularities with deep learning, most, if\nnot all of the existing methods are neither aware of the dynamic interactions\namong multiple transport modes nor adaptive to unprecedented volatility brought\nby potential societal events. In this paper, we are therefore motivated to\nimprove the canonical spatio-temporal network (ST-Net) from two perspectives:\n(1) design a heterogeneous mobility information network (HMIN) to explicitly\nrepresent intermodality in multimodal mobility; (2) propose a memory-augmented\ndynamic filter generator (MDFG) to generate sequence-specific parameters in an\non-the-fly fashion for various scenarios. The enhanced event-aware\nspatio-temporal network, namely EAST-Net, is evaluated on several real-world\ndatasets with a wide variety and coverage of societal events. Both quantitative\nand qualitative experimental results verify the superiority of our approach\ncompared with the state-of-the-art baselines. Code and data are published on\nhttps://github.com/underdoc-wang/EAST-Net.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Zhaonan Wang",
      "Renhe Jiang",
      "Hao Xue",
      "Flora D. Salim",
      "Xuan Song",
      "Ryosuke Shibasaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08443"
  },
  {
    "id": "arXiv:2112.08444",
    "title": "Combating Collusion Rings is Hard but Possible",
    "abstract": "A recent report of Littmann [Commun. ACM '21] outlines the existence and the\nfatal impact of collusion rings in academic peer reviewing. We introduce and\nanalyze the problem Cycle-Free Reviewing that aims at finding a review\nassignment without the following kind of collusion ring: A sequence of\nreviewers each reviewing a paper authored by the next reviewer in the sequence\n(with the last reviewer reviewing a paper of the first), thus creating a review\ncycle where each reviewer gives favorable reviews. As a result, all papers in\nthat cycle have a high chance of acceptance independent of their respective\nscientific merit.\nWe observe that review assignments computed using a standard Linear\nProgramming approach typically admit many short review cycles. On the negative\nside, we show that Cycle-Free Reviewing is NP-hard in various restricted cases\n(i.e., when every author is qualified to review all papers and one wants to\nprevent that authors review each other's or their own papers or when every\nauthor has only one paper and is only qualified to review few papers). On the\npositive side, among others, we show that, in some realistic settings, an\nassignment without any review cycles of small length always exists. This result\nalso gives rise to an efficient heuristic for computing (weighted) cycle-free\nreview assignments, which we show to be of excellent quality in practice.",
    "descriptor": "\nComments: Accepted to AAAI'22\n",
    "authors": [
      "Niclas Boehmer",
      "Robert Bredereck",
      "Andr\u00e9 Nichterlein"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.08444"
  },
  {
    "id": "arXiv:2112.08445",
    "title": "Safety-Critical Control with Input Delay in Dynamic Environment",
    "abstract": "Endowing nonlinear systems with safe behavior is increasingly important in\nmodern control. This task is particularly challenging for real-life control\nsystems that must operate safely in dynamically changing environments. This\npaper develops a framework for safety-critical control in dynamic environments,\nby establishing the notion of environmental control barrier functions (ECBFs).\nThe framework is able to guarantee safety even in the presence of input delay,\nby accounting for the evolution of the environment during the delayed response\nof the system. The underlying control synthesis relies on predicting the future\nstate of the system and the environment over the delay interval, with robust\nsafety guarantees against prediction errors. The efficacy of the proposed\nmethod is demonstrated by a simple adaptive cruise control problem and a more\ncomplex robotics application on a Segway platform.",
    "descriptor": "\nComments: Submitted to the IEEE Transactions on Control Systems Technology (TCST). 14 pages, 7 figures\n",
    "authors": [
      "Tamas G. Molnar",
      "Adam K. Kiss",
      "Aaron D. Ames",
      "G\u00e1bor Orosz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.08445"
  },
  {
    "id": "arXiv:2112.08447",
    "title": "Positional Encoding Augmented GAN for the Assessment of Wind Flow for  Pedestrian Comfort in Urban Areas",
    "abstract": "Approximating wind flows using computational fluid dynamics (CFD) methods can\nbe time-consuming. Creating a tool for interactively designing prototypes while\nobserving the wind flow change requires simpler models to simulate faster.\nInstead of running numerical approximations resulting in detailed calculations,\ndata-driven methods in deep learning might be able to give similar results in a\nfraction of the time. This work rephrases the problem from computing 3D flow\nfields using CFD to a 2D image-to-image translation-based problem on the\nbuilding footprints to predict the flow field at pedestrian height level. We\ninvestigate the use of generative adversarial networks (GAN), such as Pix2Pix\n[1] and CycleGAN [2] representing state-of-the-art for image-to-image\ntranslation task in various domains as well as U-Net autoencoder [3]. The\nmodels can learn the underlying distribution of a dataset in a data-driven\nmanner, which we argue can help the model learn the underlying\nReynolds-averaged Navier-Stokes (RANS) equations from CFD. We experiment on\nnovel simulated datasets on various three-dimensional bluff-shaped buildings\nwith and without height information. Moreover, we present an extensive\nqualitative and quantitative evaluation of the generated images for a selection\nof models and compare their performance with the simulations delivered by CFD.\nWe then show that adding positional data to the input can produce more accurate\nresults by proposing a general framework for injecting such information on the\ndifferent architectures. Furthermore, we show that the models performances\nimprove by applying attention mechanisms and spectral normalization to\nfacilitate stable training.",
    "descriptor": "",
    "authors": [
      "Henrik H\u00f8iness",
      "Kristoffer Gjerde",
      "Luca Oggiano",
      "Knut Erik Teigen Giljarhus",
      "Massimiliano Ruocco"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08447"
  },
  {
    "id": "arXiv:2112.08453",
    "title": "The Need for Ethical, Responsible, and Trustworthy Artificial  Intelligence for Environmental Sciences",
    "abstract": "Given the growing use of Artificial Intelligence (AI) and machine learning\n(ML) methods across all aspects of environmental sciences, it is imperative\nthat we initiate a discussion about the ethical and responsible use of AI. In\nfact, much can be learned from other domains where AI was introduced, often\nwith the best of intentions, yet often led to unintended societal consequences,\nsuch as hard coding racial bias in the criminal justice system or increasing\neconomic inequality through the financial system. A common misconception is\nthat the environmental sciences are immune to such unintended consequences when\nAI is being used, as most data come from observations, and AI algorithms are\nbased on mathematical formulas, which are often seen as objective. In this\narticle, we argue the opposite can be the case. Using specific examples, we\ndemonstrate many ways in which the use of AI can introduce similar consequences\nin the environmental sciences. This article will stimulate discussion and\nresearch efforts in this direction. As a community, we should avoid repeating\nany foreseeable mistakes made in other domains through the introduction of AI.\nIn fact, with proper precautions, AI can be a great tool to help {\\it reduce}\nclimate and environmental injustice. We primarily focus on weather and climate\nexamples but the conclusions apply broadly across the environmental sciences.",
    "descriptor": "",
    "authors": [
      "Amy McGovern",
      "Imme Ebert-Uphoff",
      "David John Gagne II",
      "Ann Bostrom"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08453"
  },
  {
    "id": "arXiv:2112.08454",
    "title": "Approximating the Longest Common Subsequence problem within a  sub-polynomial factor in linear time",
    "abstract": "The Longest Common Subsequence (LCS) of two strings is a fundamental string\nsimilarity measure with a classical dynamic programming solution taking\nquadratic time. Despite significant efforts, little progress was made in\nimproving the runtime. Even in the realm of approximation, not much was known\nfor linear time algorithms beyond the trivial $\\sqrt{n}$-approximation. Recent\nbreakthrough result provided a $n^{0.497}$-factor approximation algorithm\n[HSSS19], which was more recently improved to a $n^{0.4}$-factor one [BCD21].\nThe latter paper also showed a $n^{2-2.5\\alpha}$ time algorithm which outputs a\n$n^{\\alpha}$ approximation to the LCS, but so far no sub-polynomial\napproximation is known in truly subquadratic time.\nIn this work, we show an algorithm which runs in $O(n)$ time, and outputs a\n$n^{o(1)}$-factor approximation to LCS$(x,y)$, with high probability, for any\npair of length $n$ input strings.\nOur entire algorithm is merely an efficient black-box reduction to the\nBlock-LIS problem, introduced very recently in [ANSS21], and solving the\nBlock-LIS problem directly.",
    "descriptor": "",
    "authors": [
      "Negev Shekel Nosatzki"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.08454"
  },
  {
    "id": "arXiv:2112.08455",
    "title": "Dense Video Captioning Using Unsupervised Semantic Information",
    "abstract": "We introduce a method to learn unsupervised semantic visual information based\non the premise that complex events (e.g., minutes) can be decomposed into\nsimpler events (e.g., a few seconds), and that these simple events are shared\nacross several complex events. We split a long video into short frame sequences\nto extract their latent representation with three-dimensional convolutional\nneural networks. A clustering method is used to group representations producing\na visual codebook (i.e., a long video is represented by a sequence of integers\ngiven by the cluster labels). A dense representation is learned by encoding the\nco-occurrence probability matrix for the codebook entries. We demonstrate how\nthis representation can leverage the performance of the dense video captioning\ntask in a scenario with only visual features. As a result of this approach, we\nare able to replace the audio signal in the Bi-Modal Transformer (BMT) method\nand produce temporal proposals with comparable performance. Furthermore, we\nconcatenate the visual signal with our descriptor in a vanilla transformer\nmethod to achieve state-of-the-art performance in captioning compared to the\nmethods that explore only visual features, as well as a competitive performance\nwith multi-modal methods. Our code is available at\nhttps://github.com/valterlej/dvcusi.",
    "descriptor": "",
    "authors": [
      "Valter Estevam",
      "Rayson Laroca",
      "Helio Pedrini",
      "David Menotti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08455"
  },
  {
    "id": "arXiv:2112.08458",
    "title": "Leveraging the structure of dynamical systems for data-driven modeling",
    "abstract": "The reliable prediction of the temporal behavior of complex systems is\nrequired in numerous scientific fields. This strong interest is however\nhindered by modeling issues: often, the governing equations describing the\nphysics of the system under consideration are not accessible or, when known,\ntheir solution might require a computational time incompatible with the\nprediction time constraints.\nNowadays, approximating complex systems at hand in a generic functional\nformat and informing it ex nihilo from available observations has become a\ncommon practice, as illustrated by the enormous amount of scientific work\nappeared in the last years. Numerous successful examples based on deep neural\nnetworks are already available, although generalizability of the models and\nmargins of guarantee are often overlooked. Here, we consider Long-Short Term\nMemory neural networks and thoroughly investigate the impact of the training\nset and its structure on the quality of the long-term prediction. Leveraging\nergodic theory, we analyze the amount of data sufficient for a priori\nguaranteeing a faithful model of the physical system.\nWe show how an informed design of the training set, based on invariants of\nthe system and the structure of the underlying attractor, significantly\nimproves the resulting models, opening up avenues for research within the\ncontext of active learning. Further, the non-trivial effects of the memory\ninitializations when relying on memory-capable models will be illustrated. Our\nfindings provide evidence-based good-practice on the amount and the choice of\ndata required for an effective data-driven modeling of any complex dynamical\nsystem.",
    "descriptor": "",
    "authors": [
      "Alessandro Bucci",
      "Onofrio Semeraro",
      "Alexandre Allauzen",
      "Sergio Chibbaro",
      "Lionel Mathelin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2112.08458"
  },
  {
    "id": "arXiv:2112.08459",
    "title": "Rethinking Nearest Neighbors for Visual Classification",
    "abstract": "Neural network classifiers have become the de-facto choice for current\n\"pre-train then fine-tune\" paradigms of visual classification. In this paper,\nwe investigate $k$-Nearest-Neighbor (k-NN) classifiers, a classical model-free\nlearning method from the pre-deep learning era, as an augmentation to modern\nneural network based approaches. As a lazy learning method, k-NN simply\naggregates the distance between the test image and top-k neighbors in a\ntraining set. We adopt k-NN with pre-trained visual representations produced by\neither supervised or self-supervised methods in two steps: (1) Leverage k-NN\npredicted probabilities as indications for easy \\vs~hard examples during\ntraining. (2) Linearly interpolate the k-NN predicted distribution with that of\nthe augmented classifier. Via extensive experiments on a wide range of\nclassification tasks, our study reveals the generality and flexibility of k-NN\nintegration with additional insights: (1) k-NN achieves competitive results,\nsometimes even outperforming a standard linear classifier. (2) Incorporating\nk-NN is especially beneficial for tasks where parametric classifiers perform\npoorly and / or in low-data regimes. We hope these discoveries will encourage\npeople to rethink the role of pre-deep learning, classical methods in computer\nvision. Our code is available at: https://github.com/KMnP/nn-revisit.",
    "descriptor": "",
    "authors": [
      "Menglin Jia",
      "Bor-Chun Chen",
      "Zuxuan Wu",
      "Claire Cardie",
      "Serge Belongie",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08459"
  },
  {
    "id": "arXiv:2112.08460",
    "title": "Friendscope: Exploring In-the-Moment Experience Sharing on Camera  Glasses via a Shared Camera",
    "abstract": "We introduce Friendscope, an instant, in-the-moment experience sharing system\nfor lightweight commercial camera glasses. Friendscope explores a new concept\ncalled a shared camera. This concept allows a wearer to share control of their\ncamera with a remote friend, making it possible for both people to capture\nphotos/videos from the camera in the moment. Through a user study with 48\nparticipants, we found that users felt connected to each other, describing the\nshared camera as a more intimate form of livestreaming. Moreover, even\nprivacy-sensitive users were able to retain their sense of privacy and control\nwith the shared camera. Friendscope's different shared camera configurations\ngive wearers ultimate control over who they share the camera with and what\nphotos/videos they share. We conclude with design implications for future\nexperience sharing systems.",
    "descriptor": "\nComments: ACM CSCW 2022\n",
    "authors": [
      "Molly Jane Nicholas",
      "Brian A. Smith",
      "Rajan Vaish"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.08460"
  },
  {
    "id": "arXiv:2112.08462",
    "title": "Applying SoftTriple Loss for Supervised Language Model Fine Tuning",
    "abstract": "We introduce a new loss function TripleEntropy, to improve classification\nperformance for fine-tuning general knowledge pre-trained language models based\non cross-entropy and SoftTriple loss. This loss function can improve the robust\nRoBERTa baseline model fine-tuned with cross-entropy loss by about (0.02% -\n2.29%). Thorough tests on popular datasets indicate a steady gain. The fewer\nsamples in the training dataset, the higher gain -- thus, for small-sized\ndataset it is 0.78%, for medium-sized -- 0.86% for large -- 0.20% and for\nextra-large 0.04%.",
    "descriptor": "",
    "authors": [
      "Witold Sosnowski",
      "Anna Wroblewska",
      "Piotr Gawrysiak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08462"
  },
  {
    "id": "arXiv:2112.08466",
    "title": "ErAConD : Error Annotated Conversational Dialog Dataset for Grammatical  Error Correction",
    "abstract": "Currently available grammatical error correction (GEC) datasets are compiled\nusing well-formed written text, limiting the applicability of these datasets to\nother domains such as informal writing and dialog. In this paper, we present a\nnovel parallel GEC dataset drawn from open-domain chatbot conversations; this\ndataset is, to our knowledge, the first GEC dataset targeted to a\nconversational setting. To demonstrate the utility of the dataset, we use our\nannotated data to fine-tune a state-of-the-art GEC model, resulting in a 16\npoint increase in model precision. This is of particular importance in a GEC\nmodel, as model precision is considered more important than recall in GEC tasks\nsince false positives could lead to serious confusion in language learners. We\nalso present a detailed annotation scheme which ranks errors by perceived\nimpact on comprehensibility, making our dataset both reproducible and\nextensible. Experimental results show the effectiveness of our data in\nimproving GEC model performance in conversational scenario.",
    "descriptor": "",
    "authors": [
      "Xun Yuan",
      "Derek Pham",
      "Sam Davidson",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08466"
  },
  {
    "id": "arXiv:2112.08470",
    "title": "Insta-VAX: A Multimodal Benchmark for Anti-Vaccine and Misinformation  Posts Detection on Social Media",
    "abstract": "Sharing of anti-vaccine posts on social media, including misinformation\nposts, has been shown to create confusion and reduce the publics confidence in\nvaccines, leading to vaccine hesitancy and resistance. Recent years have\nwitnessed the fast rise of such anti-vaccine posts in a variety of linguistic\nand visual forms in online networks, posing a great challenge for effective\ncontent moderation and tracking. Extending previous work on leveraging textual\ninformation to understand vaccine information, this paper presents Insta-VAX, a\nnew multi-modal dataset consisting of a sample of 64,957 Instagram posts\nrelated to human vaccines. We applied a crowdsourced annotation procedure\nverified by two trained expert judges to this dataset. We then bench-marked\nseveral state-of-the-art NLP and computer vision classifiers to detect whether\nthe posts show anti-vaccine attitude and whether they contain misinformation.\nExtensive experiments and analyses demonstrate the multimodal models can\nclassify the posts more accurately than the uni-modal models, but still need\nimprovement especially on visual context understanding and external knowledge\ncooperation. The dataset and classifiers contribute to monitoring and tracking\nof vaccine discussions for social scientific and public health efforts in\ncombating the problem of vaccine misinformation.",
    "descriptor": "",
    "authors": [
      "Mingyang Zhou",
      "Mahasweta Chakraborti",
      "Sijia Qian",
      "Zhou Yu",
      "Jingwen Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08470"
  },
  {
    "id": "arXiv:2112.08472",
    "title": "Connecting Scientometrics: Dimensions as a route to broadening context  for analyses",
    "abstract": "Modern cloud-based data infrastructures open new vistas for the deployment of\nscientometric data into the hands of practitioners. These infrastructures lower\nbarriers to entry by making data more available and compute capacity more\naffordable. In addition, if data are prepared appropriately, with unique\nidentifiers, it is possible to connect many different types of data. Bringing\nbroader world data into the hands of practitioners (policymakers, strategists\nand others) who use scientometrics as a tool can extend their capabilities.\nThese ideas are explored through connecting Dimensions and World Bank data on\nGoogle BigQuery to study international collaboration between countries of\ndifferent economic classification.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Simon J Porter",
      "Daniel W Hook"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2112.08472"
  },
  {
    "id": "arXiv:2112.08473",
    "title": "IoT Security and Safety Testing Toolkits for Water Distribution Systems",
    "abstract": "Due to the critical importance of Industrial Control Systems (ICS) to the\noperations of cities and countries, research into the security of critical\ninfrastructure has become increasingly relevant and necessary. As a component\nof both the research and application sides of smart city development, accurate\nand precise modeling, simulation, and verification are key parts of a robust\ndesign and development tools that provide critical assistance in the\nprevention, detection, and recovery from abnormal behavior in the sensors,\ncontrollers, and actuators which make up a modern ICS system. However, while\nthese tools have potential, there is currently a need for helper-tools to\nassist with their setup and configuration, if they are to be utilized widely.\nExisting state-of-the-art tools are often technically complex and difficult to\ncustomize for any given IoT/ICS processes. This is a serious barrier to entry\nfor most technicians, engineers, researchers, and smart city planners, while\nslowing down the critical aspects of safety and security verification. To\nremedy this issue, we take a case study of existing simulation toolkits within\nthe field of water management and expand on existing tools and algorithms with\nsimplistic automated retrieval functionality using a much more in-depth and\nusable customization interface to accelerate simulation scenario design and\nimplementation, allowing for customization of the cyber-physical network\ninfrastructure and cyber attack scenarios. We additionally provide a novel\nin-tool-assessment of network's resilience according to graph theory path\ndiversity. Further, we lay out a roadmap for future development and application\nof the proposed tool, including expansions on resiliency and potential\nvulnerability model checking, and discuss applications of our work to other\nfields relevant to the design and operation of smart cities.",
    "descriptor": "\nComments: 8 pages, 13 figures, 1 table\n",
    "authors": [
      "Sean O'Toole",
      "Cameron Sewell",
      "Hoda Mehrpouyan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.08473"
  },
  {
    "id": "arXiv:2112.08481",
    "title": "Maximum likelihood estimation for randomized shortest paths with  trajectory data",
    "abstract": "Randomized shortest paths (RSP) are a tool developed in recent years for\ndifferent graph and network analysis applications, such as modelling movement\nor flow in networks. In essence, the RSP framework considers the\ntemperature-dependent Gibbs-Boltzmann distribution over paths in the network.\nAt low temperatures, the distribution focuses solely on the shortest or\nleast-cost paths, while with increasing temperature, the distribution spreads\nover random walks on the network. Many relevant quantities can be computed\nconveniently from this distribution, and these often generalize traditional\nnetwork measures in a sensible way. However, when modelling real phenomena with\nRSPs, one needs a principled way of estimating the parameters from data. In\nthis work, we develop methods for computing the maximum likelihood estimate of\nthe model parameters, with focus on the temperature parameter, when modelling\nphenomena based on movement, flow, or spreading processes. We test the validity\nof the derived methods with trajectories generated on artificial networks as\nwell as with real data on the movement of wild reindeer in a geographic\nlandscape, used for estimating the degree of randomness in the movement of the\nanimals. These examples demonstrate the attractiveness of the RSP framework as\na generic model to be used in diverse applications.",
    "descriptor": "",
    "authors": [
      "Ilkka Kivim\u00e4ki",
      "Bram Van Moorter",
      "Manuela Panzacchi",
      "Jari Saram\u00e4ki",
      "Marco Saerens"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.08481"
  },
  {
    "id": "arXiv:2112.08485",
    "title": "On optimal convergence rates for discrete minimizers of the  Gross-Pitaevskii energy in LOD spaces",
    "abstract": "In this paper we revisit a two-level discretization based on the Localized\nOrthogonal Decomposition (LOD). It was originally proposed in [P.Henning,\nA.M{\\aa}lqvist, D.Peterseim. SIAM J. Numer. Anal.52-4:1525-1550, 2014] to\ncompute ground states of Bose-Einstein condensates by finding discrete\nminimizers of the Gross-Pitaevskii energy functional. The established\nconvergence rates for the method appeared however suboptimal compared to\nnumerical observations and a proof of optimal rates in this setting remained\nopen. In this paper we shall close this gap by proving optimal order error\nestimates for the $L^2$- and $H^1$-error between the exact ground state and\ndiscrete minimizers, as well as error estimates for the ground state energy and\nthe ground state eigenvalue. In particular, the achieved convergence rates for\nthe energy and the eigenvalue are of $6$th order with respect to the mesh size\non which the discrete LOD space is based, without making any additional\nregularity assumptions. These high rates justify the use of very coarse meshes,\nwhich significantly reduces the computational effort for finding accurate\napproximations of ground states. In addition, we include numerical experiments\nthat confirm the optimality of the new theoretical convergence rates, both for\nsmooth and discontinuous potentials.",
    "descriptor": "",
    "authors": [
      "Patrick Henning",
      "Anna Persson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08485"
  },
  {
    "id": "arXiv:2112.08486",
    "title": "Text Mining Through Label Induction Grouping Algorithm Based Method",
    "abstract": "The main focus of information retrieval methods is to provide accurate and\nefficient results which are cost-effective too. LINGO (Label Induction Grouping\nAlgorithm) is a clustering algorithm that aims to provide search results in\nform of quality clusters but also has a few limitations. In this paper, our\nfocus is based on achieving results that are more meaningful and improving the\noverall performance of the algorithm. LINGO works on two main steps; Cluster\nLabel Induction by using Latent Semantic Indexing technique (LSI) and Cluster\ncontent discovery by using the Vector Space Model (VSM). As LINGO uses VSM in\ncluster content discovery, our task is to replace VSM with LSI for cluster\ncontent discovery and to analyze the feasibility of using LSI with Okapi BM25.\nThe next task is to compare the results of a modified method with the LINGO\noriginal method. The research is applied to five different text-based data sets\nto get more reliable results for every method. Research results show that LINGO\nproduces 40-50% better results when using LSI for content Discovery. From\ntheoretical evidence using Okapi BM25 for scoring method in LSI (LSI+Okapi\nBM25) for cluster content discovery instead of VSM, also results in better\nclusters generation in terms of scalability and performance when compares to\nboth VSM and LSI's Results.",
    "descriptor": "\nComments: Presented in 5th International. Multidisciplinary Conference, 29-31 Oct., at, ICBS, Lahore\n",
    "authors": [
      "Gulshan Saleem",
      "Nisar Ahmed",
      "Usman Qamar"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08486"
  },
  {
    "id": "arXiv:2112.08487",
    "title": "Adaptive Differential Privacy Mechanism for Aggregated Mobility Dataset",
    "abstract": "Location data is collected from users continuously to acquire user mobility\npatterns. Releasing the user trajectories may compromise user privacy.\nTherefore, the general practice is to release aggregated location datasets.\nHowever, private information may still be inferred from an aggregated version\nof location trajectories. Differential privacy (DP) protects the query output\nagainst inference attacks regardless of background knowledge. This paper\npresents a differential privacy-based privacy model that protects the user's\norigins and destinations at the aggregated level. This is achieved by injecting\nPlanar Laplace noise to the user origin and destination GPS points. The noisy\nGPS points are then transformed to a link representation using a link-matching\nalgorithm. Finally, the link trajectories form an aggregated mobility network.\nThe injected noise level is selected adaptively, by considering the link\ndensity of the location and the functional category of the localized links.\nCompared to the different baseline models, including a k-anonymity method, our\ndifferential privacy-based aggregation model offers closer query responses to\nthe raw data in terms of aggregate statistics at both the network and\ntrajectory-levels with max 4% deviation from the baseline. Beyond link\naggregation and spatial noise injection, temporal aggregation can also provide\na degree of privacy and a discussion of temporal aggregation requirements is\npresented.",
    "descriptor": "\nComments: 14 pages, 19 figures\n",
    "authors": [
      "Ammar Haydari",
      "Michael Zhang",
      "Chen-Nee Chuah",
      "Jane Macfarlane",
      "Sean Peisert"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.08487"
  },
  {
    "id": "arXiv:2112.08491",
    "title": "Human Languages with Greater Information Density Increase Communication  Speed, but Decrease Conversation Breadth",
    "abstract": "Language is the primary medium through which human information is\ncommunicated and coordination is achieved. One of the most important language\nfunctions is to categorize the world so messages can be communicated through\nconversation. While we know a great deal about how human languages vary in\ntheir encoding of information within semantic domains such as color, sound,\nnumber, locomotion, time, space, human activities, gender, body parts and\nbiology, little is known about the global structure of semantic information and\nits effect on human communication. Using large-scale computation, artificial\nintelligence techniques, and massive, parallel corpora across 15 subject\nareas--including religion, economics, medicine, entertainment, politics, and\ntechnology--in 999 languages, here we show substantial variation in the\ninformation and semantic density of languages and their consequences for human\ncommunication and coordination. In contrast to prior work, we demonstrate that\nhigher density languages communicate information much more quickly relative to\nlower density languages. Then, using over 9,000 real-life conversations across\n14 languages and 90,000 Wikipedia articles across 140 languages, we show that\nbecause there are more ways to discuss any given topic in denser languages,\nconversations and articles retrace and cycle over a narrower conceptual\nterrain. These results demonstrate an important source of variation across the\nhuman communicative channel, suggesting that the structure of language shapes\nthe nature and texture of conversation, with important consequences for the\nbehavior of groups, organizations, markets, and societies.",
    "descriptor": "",
    "authors": [
      "Pedro Aceves",
      "James A. Evans"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08491"
  },
  {
    "id": "arXiv:2112.08493",
    "title": "StyleMC: Multi-Channel Based Fast Text-Guided Image Generation and  Manipulation",
    "abstract": "Discovering meaningful directions in the latent space of GANs to manipulate\nsemantic attributes typically requires large amounts of labeled data. Recent\nwork aims to overcome this limitation by leveraging the power of Contrastive\nLanguage-Image Pre-training (CLIP), a joint text-image model. While promising,\nthese methods require several hours of preprocessing or training to achieve the\ndesired manipulations. In this paper, we present StyleMC, a fast and efficient\nmethod for text-driven image generation and manipulation. StyleMC uses a\nCLIP-based loss and an identity loss to manipulate images via a single text\nprompt without significantly affecting other attributes. Unlike prior work,\nStyleMC requires only a few seconds of training per text prompt to find stable\nglobal directions, does not require prompt engineering and can be used with any\npre-trained StyleGAN2 model. We demonstrate the effectiveness of our method and\ncompare it to state-of-the-art methods. Our code can be found at\nthis http URL",
    "descriptor": "\nComments: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2022)\n",
    "authors": [
      "Umut Kocasari",
      "Alara Dirik",
      "Mert Tiftikci",
      "Pinar Yanardag"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08493"
  },
  {
    "id": "arXiv:2112.08496",
    "title": "A Framework for Prescribed-Time Control Design via Time-Scale  Transformation",
    "abstract": "This letter presents a unified framework for the design of prescribed-time\ncontrollers under time-varying input and state constraints for normal-form\nunknown nonlinear systems with uncertain input gain. The proposed approach is\nbased on a time-domain mapping method by which any infinite-time system can be\ncorresponded to a prescribed-time system and vice versa. It is shown that the\ndesign of a constrained nonasymptotic prescribed-time controller can be reduced\nto the asymptotic control design for an associated constrained infinite-time\nsystem. Fa\\`a di Bruno's formula and Bell polynomials are used for a\nconstructive representation of the associated infinite-time system. The\npresented results are not confined to a particular mapping function, which adds\nto the flexibility of the proposed scheme. It is shown that necessary and\nsufficient conditions on the uniform (practical) prescribed-time stability and\nattractivity can be obtained as corollaries of the main result.",
    "descriptor": "\nComments: 6 pages, 1 figure, accepted for publication in IEEE Control Systems Letters\n",
    "authors": [
      "Amir Shakouri",
      "Nima Assadian"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.08496"
  },
  {
    "id": "arXiv:2112.08497",
    "title": "Predicting Levels of Household Electricity Consumption in Low-Access  Settings",
    "abstract": "In low-income settings, the most critical piece of information for electric\nutilities is the anticipated consumption of a customer. Electricity consumption\nassessment is difficult to do in settings where a significant fraction of\nhouseholds do not yet have an electricity connection. In such settings the\nabsolute levels of anticipated consumption can range from 5-100 kWh/month,\nleading to high variability amongst these customers. Precious resources are at\nstake if a significant fraction of low consumers are connected over those with\nhigher consumption.\nThis is the first study of it's kind in low-income settings that attempts to\npredict a building's consumption and not that of an aggregate administrative\narea. We train a Convolutional Neural Network (CNN) over pre-electrification\ndaytime satellite imagery with a sample of utility bills from 20,000\ngeo-referenced electricity customers in Kenya (0.01% of Kenya's residential\ncustomers). This is made possible with a two-stage approach that uses a novel\nbuilding segmentation approach to leverage much larger volumes of no-cost\nsatellite imagery to make the most of scarce and expensive customer data. Our\nmethod shows that competitive accuracies can be achieved at the building level,\naddressing the challenge of consumption variability. This work shows that the\nbuilding's characteristics and it's surrounding context are both important in\npredicting consumption levels. We also evaluate the addition of lower\nresolution geospatial datasets into the training process, including nighttime\nlights and census-derived data. The results are already helping inform site\nselection and distribution-level planning, through granular predictions at the\nlevel of individual structures in Kenya and there is no reason this cannot be\nextended to other countries.",
    "descriptor": "\nComments: Accepted to be published in Proceedings of IEEE Winter Conference on Applications of Computer Vision (WACV) 2022\n",
    "authors": [
      "Simone Fobi",
      "Joel Mugyenyi",
      "Nathaniel J. Williams",
      "Vijay Modi",
      "Jay Taneja"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08497"
  },
  {
    "id": "arXiv:2112.08501",
    "title": "Optimal Grain Mixing is NP-Complete",
    "abstract": "Protein content in wheat plays a significant role when determining the price\nof wheat production. The Grain mixing problem aims to find the optimal bin pair\ncombination with an appropriate mixing ratio to load each truck that will yield\na maximum profit when sold to a set of local grain elevators. In this paper, we\npresented two complexity proofs for the grain mixing problem and showed that\nfinding the optimal solutions for the grain mixing problem remains hard. These\nproofs follow a reduction from the $3$-dimensional matching ($3$-DM) problem\nand a more restricted version of the $3$-DM known as planar $3$-DM problem\nrespectively. The complexity proofs do suggest that the exact algorithm to find\nthe optimal solution for the grain mixing problem may be infeasible.",
    "descriptor": "",
    "authors": [
      "Md Asaduzzaman Noor",
      "Sean Yaw",
      "Binhai Zhu",
      "John W. Sheppard"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.08501"
  },
  {
    "id": "arXiv:2112.08507",
    "title": "Algorithms for Adaptive Experiments that Trade-off Statistical Analysis  with Reward: Combining Uniform Random Assignment and Reward Maximization",
    "abstract": "Multi-armed bandit algorithms like Thompson Sampling can be used to conduct\nadaptive experiments, in which maximizing reward means that data is used to\nprogressively assign more participants to more effective arms. Such assignment\nstrategies increase the risk of statistical hypothesis tests identifying a\ndifference between arms when there is not one, and failing to conclude there is\na difference in arms when there truly is one. We present simulations for 2-arm\nexperiments that explore two algorithms that combine the benefits of uniform\nrandomization for statistical analysis, with the benefits of reward\nmaximization achieved by Thompson Sampling (TS). First, Top-Two Thompson\nSampling adds a fixed amount of uniform random allocation (UR) spread evenly\nover time. Second, a novel heuristic algorithm, called TS PostDiff (Posterior\nProbability of Difference). TS PostDiff takes a Bayesian approach to mixing TS\nand UR: the probability a participant is assigned using UR allocation is the\nposterior probability that the difference between two arms is `small' (below a\ncertain threshold), allowing for more UR exploration when there is little or no\nreward to be gained. We find that TS PostDiff method performs well across\nmultiple effect sizes, and thus does not require tuning based on a guess for\nthe true effect size.",
    "descriptor": "",
    "authors": [
      "Jacob Nogas",
      "Tong Li",
      "Fernando J. Yanez",
      "Arghavan Modiri",
      "Nina Deliu",
      "Ben Prystawski",
      "Sofia S. Villar",
      "Anna Rafferty",
      "Joseph J. Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08507"
  },
  {
    "id": "arXiv:2112.08511",
    "title": "OptABC: an Optimal Hyperparameter Tuning Approach for Machine Learning  Algorithms",
    "abstract": "Hyperparameter tuning in machine learning algorithms is a computationally\nchallenging task due to the large-scale nature of the problem. In order to\ndevelop an efficient strategy for hyper-parameter tuning, one promising\nsolution is to use swarm intelligence algorithms. Artificial Bee Colony (ABC)\noptimization lends itself as a promising and efficient optimization algorithm\nfor this purpose. However, in some cases, ABC can suffer from a slow\nconvergence rate or execution time due to the poor initial population of\nsolutions and expensive objective functions. To address these concerns, a novel\nalgorithm, OptABC, is proposed to help ABC algorithm in faster convergence\ntoward a near-optimum solution. OptABC integrates artificial bee colony\nalgorithm, K-Means clustering, greedy algorithm, and opposition-based learning\nstrategy for tuning the hyper-parameters of different machine learning models.\nOptABC employs these techniques in an attempt to diversify the initial\npopulation, and hence enhance the convergence ability without significantly\ndecreasing the accuracy. In order to validate the performance of the proposed\nmethod, we compare the results with previous state-of-the-art approaches.\nExperimental results demonstrate the effectiveness of the OptABC compared to\nexisting approaches in the literature.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Leila Zahedi",
      "Farid Ghareh Mohammadi",
      "M. Hadi Amini"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08511"
  },
  {
    "id": "arXiv:2112.08512",
    "title": "ELight: Enabling Efficient Photonic In-Memory Neurocomputing with Life  Enhancement",
    "abstract": "With the recent advances in optical phase change material (PCM), photonic\nin-memory neurocomputing has demonstrated its superiority in optical neural\nnetwork (ONN) designs with near-zero static power consumption, time-of-light\nlatency, and compact footprint. However, photonic tensor cores require massive\nhardware reuse to implement large matrix multiplication due to the limited\nsingle-core scale. The resultant large number of PCM writes leads to serious\ndynamic power and overwhelms the fragile PCM with limited write endurance. In\nthis work, we propose a synergistic optimization framework, ELight, to minimize\nthe overall write efforts for efficient and reliable optical in-memory\nneurocomputing. We first propose write-aware training to encourage the\nsimilarity among weight blocks, and combine it with a post-training\noptimization method to reduce programming efforts by eliminating redundant\nwrites. Experiments show that ELight can achieve over 20X reduction in the\ntotal number of writes and dynamic power with comparable accuracy. With our\nELight, photonic in-memory neurocomputing will step forward towards viable\napplications in machine learning with preserved accuracy, order-of-magnitude\nlonger lifetime, and lower programming energy.",
    "descriptor": "\nComments: 7 pages, 8 figures, accepted by ASPDAC 2022\n",
    "authors": [
      "Hanqing Zhu",
      "Jiaqi Gu",
      "Chenghao Feng",
      "Mingjie Liu",
      "Zixuan Jiang",
      "Ray T. Chen",
      "David Z. Pan"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2112.08512"
  },
  {
    "id": "arXiv:2112.08513",
    "title": "DocAMR: Multi-Sentence AMR Representation and Evaluation",
    "abstract": "Despite extensive research on parsing of English sentences into Abstraction\nMeaning Representation (AMR) graphs, which are compared to gold graphs via the\nSmatch metric, full-document parsing into a unified graph representation lacks\nwell-defined representation and evaluation. Taking advantage of a\nsuper-sentential level of coreference annotation from previous work, we\nintroduce a simple algorithm for deriving a unified graph representation,\navoiding the pitfalls of information loss from over-merging and lack of\ncoherence from under-merging. Next, we describe improvements to the Smatch\nmetric to make it tractable for comparing document-level graphs, and use it to\nre-evaluate the best published document-level AMR parser. We also present a\npipeline approach combining the top performing AMR parser and coreference\nresolution systems, providing a strong baseline for future research.",
    "descriptor": "",
    "authors": [
      "Tahira Naseem",
      "Austin Blodgett",
      "Sadhana Kumaravel",
      "Tim O'Gorman",
      "Young-Suk Lee",
      "Jeffrey Flanigan",
      "Ram\u00f3n Fernandez Astudillo",
      "Radu Florian",
      "Salim Roukos",
      "Nathan Schneider"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08513"
  },
  {
    "id": "arXiv:2112.08515",
    "title": "Interpolation Operator on negative Sobolev Spaces",
    "abstract": "We introduce a Scott--Zhang type projection operator mapping to Lagrange\nelements for arbitrary polynomial order. In addition to the usual properties,\nthis operator is compatible with duals of first order Sobolev spaces. More\nspecifically, it is stable in the corresponding negative norms and allows for\noptimal rates of convergence. We discuss alternative operators with similar\nproperties. As applications of the operator we prove interpolation error\nestimates for parabolic problems and smoothen rough right-hand sides in a least\nsquares finite element method.",
    "descriptor": "",
    "authors": [
      "Lars Diening",
      "Johannes Storn",
      "Tabea Tscherpel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08515"
  },
  {
    "id": "arXiv:2112.08516",
    "title": "Safety-Aware Preference-Based Learning for Safety-Critical Control",
    "abstract": "Bringing dynamic robots into the wild requires a tenuous balance between\nperformance and safety. Yet controllers designed to provide robust safety\nguarantees often result in conservative behavior, and tuning these controllers\nto find the ideal trade-off between performance and safety typically requires\ndomain expertise or a carefully constructed reward function. This work presents\na design paradigm for systematically achieving behaviors that balance\nperformance and robust safety by integrating safety-aware Preference-Based\nLearning (PBL) with Control Barrier Functions (CBFs). Fusing these concepts --\nsafety-aware learning and safety-critical control -- gives a robust means to\nachieve safe behaviors on complex robotic systems in practice. We demonstrate\nthe capability of this design paradigm to achieve safe and performant\nperception-based autonomous operation of a quadrupedal robot both in simulation\nand experimentally on hardware.",
    "descriptor": "",
    "authors": [
      "Ryan K. Cosner",
      "Maegan Tucker",
      "Andrew J. Taylor",
      "Kejun Li",
      "Tam\u00e1s G. Moln\u00e1r",
      "Wyatt Ubellacker",
      "Anil Alan",
      "G\u00e1bor Orosz",
      "Yisong Yue",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.08516"
  },
  {
    "id": "arXiv:2112.08518",
    "title": "About some aspects of function interpolation by trigonometric splines",
    "abstract": "Interpolation of classes of differentiated functions given on a finite\ninterval by trigonometric splines using the phantom node method is considered.\nThis method consists in supplementing a given sequence of values of an\napproximate function with an even number of values of a phantom function, which\nis constructed in such a way as to eliminate gaps in both the function itself\nand its derivatives up to and including a certain order; in the General case,\nthese gaps occur with the periodic continuation of the function given at a\nfinite interval. The results of calculations on test examples for trigonometric\nsplines of the third order are given; these calculations illustrate the high\nefficiency of the proposed method.",
    "descriptor": "",
    "authors": [
      "Volodymyr Denysiuk",
      "Olena Hryshko"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08518"
  },
  {
    "id": "arXiv:2112.08520",
    "title": "FirmwareDroid: Security Analysis of the Android Firmware EcoSystem",
    "abstract": "The Android Open Source Project (AOSP) is probably the most used and\ncustomized operating system for smartphones and IoT devices worldwide. Its\nmarket share and high adaptability makes Android an interesting operating\nsystem for many developers. Nowadays, we use Android firmware in smartphones,\nTVs, smartwatches, cars, and other devices by various vendors and\nmanufacturers. The sheer amount of customized Android firmware and devices\nmakes it hard for security analysts to detect potentially harmful applications.\nAnother fact is that many vendors include apps from 3rd party developers. Such\nbloatware usually has more privileges than standard apps and cannot be removed\nby the user without rooting the device. In recent years several cases were\nreported where 3rd party developers could include malicious apps into the\nAndroid built chain. Media reports claim that pre-installed malware like\nChamois and Triade we able to infect several million devices. Such cases\ndemonstrate the need for better strategies for analyzing Android firmware. In\nour study, we analyze the Android firmware eco-system in various ways. We\ncollected a dataset with several thousand Android firmware archives and show\nthat several terabytes of firmware data are waiting on the web to be analyzed.\nWe develop a web service called FirmwareDroid for analyzing Android firmware\narchives and pre-installed apps and create a dataset of firmware samples.\nFocusing on Android apps, we automated the process of extracting and scanning\npre-installed apps with state of the art open-source tools. We demonstrate on\nreal data that pre-installed apps are, in fact, a a threat to Android's users,\nand we can detect several hundred malware samples using scanners like\nVirusTotal, AndroGuard, and APKiD. With state of the art tools, we could scan\nmore than 900000 apps during our research and give unique insights into Android\ncustom ROMs.",
    "descriptor": "\nComments: 124 pages, Master thesis, Zurich University of Applied Sciences\n",
    "authors": [
      "Thomas Sutter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.08520"
  },
  {
    "id": "arXiv:2112.08524",
    "title": "FLoRA: Single-shot Hyper-parameter Optimization for Federated Learning",
    "abstract": "We address the relatively unexplored problem of hyper-parameter optimization\n(HPO) for federated learning (FL-HPO). We introduce Federated Loss suRface\nAggregation (FLoRA), the first FL-HPO solution framework that can address use\ncases of tabular data and gradient boosting training algorithms in addition to\nstochastic gradient descent/neural networks commonly addressed in the FL\nliterature. The framework enables single-shot FL-HPO, by first identifying a\ngood set of hyper-parameters that are used in a **single** FL training. Thus,\nit enables FL-HPO solutions with minimal additional communication overhead\ncompared to FL training without HPO. Our empirical evaluation of FLoRA for\nGradient Boosted Decision Trees on seven OpenML data sets demonstrates\nsignificant model accuracy improvements over the considered baseline, and\nrobustness to increasing number of parties involved in FL-HPO training.",
    "descriptor": "",
    "authors": [
      "Yi Zhou",
      "Parikshit Ram",
      "Theodoros Salonidis",
      "Nathalie Baracaldo",
      "Horst Samulowitz",
      "Heiko Ludwig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.08524"
  },
  {
    "id": "arXiv:2112.08526",
    "title": "Invariance Through Inference",
    "abstract": "We introduce a general approach, called Invariance through Inference, for\nimproving the test-time performance of an agent in deployment environments with\nunknown perceptual variations. Instead of producing invariant visual features\nthrough interpolation, invariance through inference turns adaptation at\ndeployment-time into an unsupervised learning problem. This is achieved in\npractice by deploying a straightforward algorithm that tries to match the\ndistribution of latent features to the agent's prior experience, without\nrelying on paired data. Although simple, we show that this idea leads to\nsurprising improvements on a variety of adaptation scenarios without access to\ndeployment-time rewards, including changes in camera poses and lighting\nconditions. Results are presented on challenging distractor control suite, a\nrobotics environment with image-based observations.",
    "descriptor": "\nComments: In submission to ICLR2022. Here's our project page: this https URL\n",
    "authors": [
      "Takuma Yoneda",
      "Ge Yang",
      "Matthew R. Walter",
      "Bradly Stadie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08526"
  },
  {
    "id": "arXiv:2112.08529",
    "title": "A Higerh Order Resolvent-positive Finite Difference Approximation for  Fractional Derivatives",
    "abstract": "We develop a finite difference approximation of order $\\alpha$ for the\n$\\alpha$-fractional derivative. The weights of the approximation scheme have\nthe same rate-matrix type properties as the popular Gr\\\"unwald scheme. In\nparticular, approximate solutions to fractional diffusion equations preserve\npositivity. Furthermore, for the approximation of the solution to the skewed\nfractional heat equation on a bounded domain the new approximation scheme keeps\nits order $\\alpha$ whereas the order of the Gr\\\"unwald scheme reduces to order\n$\\alpha-1$, contradicting the convergence rate results by Meerschaert and\nTadjeran.",
    "descriptor": "",
    "authors": [
      "Boris Baeumer",
      "Mihaly Kovacs",
      "Matthew Parry"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.08529"
  },
  {
    "id": "arXiv:2112.08532",
    "title": "Penn-Helsinki Parsed Corpus of Early Modern English: First Parsing  Results and Analysis",
    "abstract": "We present the first parsing results on the Penn-Helsinki Parsed Corpus of\nEarly Modern English (PPCEME), a 1.9 million word treebank that is an important\nresource for research in syntactic change. We describe key features of PPCEME\nthat make it challenging for parsing, including a larger and more varied set of\nfunction tags than in the Penn Treebank. We present results for this corpus\nusing a modified version of the Berkeley Neural Parser and the approach to\nfunction tag recovery of Gabbard et al (2006). Despite its simplicity, this\napproach works surprisingly well, suggesting it is possible to recover the\noriginal structure with sufficient accuracy to support linguistic applications\n(e.g., searching for syntactic structures of interest). However, for a subset\nof function tags (e.g., the tag indicating direct speech), additional work is\nneeded, and we discuss some further limits of this approach. The resulting\nparser will be used to parse Early English Books Online, a 1.1 billion word\ncorpus whose utility for the study of syntactic change will be greatly\nincreased with the addition of accurate parse trees.",
    "descriptor": "",
    "authors": [
      "Seth Kulick",
      "Neville Ryant",
      "Beatrice Santorini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08532"
  },
  {
    "id": "arXiv:2112.08534",
    "title": "Trading with the Momentum Transformer: An Intelligent and Interpretable  Architecture",
    "abstract": "Deep learning architectures, specifically Deep Momentum Networks (DMNs)\n[1904.04912], have been found to be an effective approach to momentum and\nmean-reversion trading. However, some of the key challenges in recent years\ninvolve learning long-term dependencies, degradation of performance when\nconsidering returns net of transaction costs and adapting to new market\nregimes, notably during the SARS-CoV-2 crisis. Attention mechanisms, or\nTransformer-based architectures, are a solution to such challenges because they\nallow the network to focus on significant time steps in the past and\nlonger-term patterns. We introduce the Momentum Transformer, an attention-based\narchitecture which outperforms the benchmarks, and is inherently interpretable,\nproviding us with greater insights into our deep learning trading strategy. Our\nmodel is an extension to the LSTM-based DMN, which directly outputs position\nsizing by optimising the network on a risk-adjusted performance metric, such as\nSharpe ratio. We find an attention-LSTM hybrid Decoder-Only Temporal Fusion\nTransformer (TFT) style architecture is the best performing model. In terms of\ninterpretability, we observe remarkable structure in the attention patterns,\nwith significant peaks of importance at momentum turning points. The time\nseries is thus segmented into regimes and the model tends to focus on previous\ntime-steps in alike regimes. We find changepoint detection (CPD) [2105.13727],\nanother technique for responding to regime change, can complement multi-headed\nattention, especially when we run CPD at multiple timescales. Through the\naddition of an interpretable variable selection network, we observe how CPD\nhelps our model to move away from trading predominantly on daily returns data.\nWe note that the model can intelligently switch between, and blend, classical\nstrategies - basing its decision on patterns in the data.",
    "descriptor": "",
    "authors": [
      "Kieran Wood",
      "Sven Giegerich",
      "Stephen Roberts",
      "Stefan Zohren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08534"
  },
  {
    "id": "arXiv:2112.08538",
    "title": "Visualizing the Loss Landscape of Winning Lottery Tickets",
    "abstract": "The underlying loss landscapes of deep neural networks have a great impact on\ntheir training, but they have mainly been studied theoretically due to\ncomputational constraints. This work vastly reduces the time required to\ncompute such loss landscapes, and uses them to study winning lottery tickets\nfound via iterative magnitude pruning. We also share results that contradict\npreviously claimed correlations between certain loss landscape projection\nmethods and model trainability and generalization error.",
    "descriptor": "\nComments: 7 pages, 7 figures, 1 algorithm/pseudocode\n",
    "authors": [
      "Robert Bain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08538"
  },
  {
    "id": "arXiv:2112.08539",
    "title": "Implicit Neural Representations for Deconvolving SAS Images",
    "abstract": "Synthetic aperture sonar (SAS) image resolution is constrained by waveform\nbandwidth and array geometry. Specifically, the waveform bandwidth determines a\npoint spread function (PSF) that blurs the locations of point scatterers in the\nscene. In theory, deconvolving the reconstructed SAS image with the scene PSF\nrestores the original distribution of scatterers and yields sharper\nreconstructions. However, deconvolution is an ill-posed operation that is\nhighly sensitive to noise. In this work, we leverage implicit neural\nrepresentations (INRs), shown to be strong priors for the natural image space,\nto deconvolve SAS images. Importantly, our method does not require training\ndata, as we perform our deconvolution through an analysis-bysynthesis\noptimization in a self-supervised fashion. We validate our method on simulated\nSAS data created with a point scattering model and real data captured with an\nin-air circular SAS. This work is an important first step towards applying\nneural networks for SAS image deconvolution.",
    "descriptor": "",
    "authors": [
      "Albert Reed",
      "Thomas Blanford",
      "Daniel C. Brown",
      "Suren Jayasuriya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.08539"
  },
  {
    "id": "arXiv:2112.08540",
    "title": "Integrated Guidance and Control for Lunar Landing using a Stabilized  Seeker",
    "abstract": "We develop an integrated guidance and control system that in conjunction with\na stabilized seeker and landing site detection software can achieve precise and\nsafe planetary landing. The seeker tracks the designated landing site by\nadjusting seeker elevation and azimuth angles to center the designated landing\nsite in the sensor field of view. The seeker angles, closing speed, and range\nto the designated landing site are used to formulate a velocity field that is\nused by the guidance and control system to achieve a safe landing at the\ndesignated landing site. The guidance and control system maps this velocity\nfield, attitude, and rotational velocity directly to a commanded thrust vector\nfor the lander's four engines. The guidance and control system is implemented\nas a policy optimized using reinforcement meta learning. We demonstrate that\nthe guidance and control system is compatible with multiple diverts during the\npowered descent phase, and is robust to seeker lag, actuator lag and\ndegradation, and center of mass variation induced by fuel consumption. We\noutline several concepts of operations, including an approach using a preplaced\nlanding beacon.",
    "descriptor": "\nComments: Accepted for 2022 AIAA Scitech GN&C. arXiv admin note: text overlap with arXiv:2107.14764, arXiv:2004.09978, arXiv:2110.00634, arXiv:2109.03880\n",
    "authors": [
      "Brian Gaudet",
      "Roberto Furfaro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08540"
  },
  {
    "id": "arXiv:2112.08541",
    "title": "BGL: GPU-Efficient GNN Training by Optimizing Graph Data I/O and  Preprocessing",
    "abstract": "Graph neural networks (GNNs) have extended the success of deep neural\nnetworks (DNNs) to non-Euclidean graph data, achieving ground-breaking\nperformance on various tasks such as node classification and graph property\nprediction. Nonetheless, existing systems are inefficient to train large graphs\nwith billions of nodes and edges with GPUs. The main bottlenecks are the\nprocess of preparing data for GPUs - subgraph sampling and feature retrieving.\nThis paper proposes BGL, a distributed GNN training system designed to address\nthe bottlenecks with a few key ideas. First, we propose a dynamic cache engine\nto minimize feature retrieving traffic. By a co-design of caching policy and\nthe order of sampling, we find a sweet spot of low overhead and high cache hit\nratio. Second, we improve the graph partition algorithm to reduce\ncross-partition communication during subgraph sampling. Finally, careful\nresource isolation reduces contention between different data preprocessing\nstages. Extensive experiments on various GNN models and large graph datasets\nshow that BGL significantly outperforms existing GNN training systems by 20.68x\non average.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Tianfeng Liu",
      "Yangrui Chen",
      "Dan Li",
      "Chuan Wu",
      "Yibo Zhu",
      "Jun He",
      "Yanghua Peng",
      "Hongzheng Chen",
      "Hongzhi Chen",
      "Chuanxiong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.08541"
  },
  {
    "id": "arXiv:2112.08542",
    "title": "QAFactEval: Improved QA-Based Factual Consistency Evaluation for  Summarization",
    "abstract": "Factual consistency is an essential quality of text summarization models in\npractical settings. Existing work in evaluating this dimension can be broadly\ncategorized into two lines of research, entailment-based metrics and question\nanswering (QA)-based metrics. However, differing experimental setups presented\nin recent work lead to contrasting conclusions as to which paradigm performs\nbest. In this work, we conduct an extensive comparison of entailment and\nQA-based metrics, demonstrating that carefully choosing the components of a\nQA-based metric is critical to performance. Building on those insights, we\npropose an optimized metric, which we call QAFactEval, that leads to a 15%\naverage improvement over previous QA-based metrics on the SummaC factual\nconsistency benchmark. Our solution improves upon the best-performing\nentailment-based metric and achieves state-of-the-art performance on this\nbenchmark. Furthermore, we find that QA-based and entailment-based metrics\noffer complementary signals and combine the two into a single, learned metric\nfor further performance boost. Through qualitative and quantitative analyses,\nwe point to question generation and answerability classification as two\ncritical components for future work in QA-based metrics.",
    "descriptor": "",
    "authors": [
      "Alexander R. Fabbri",
      "Chien-Sheng Wu",
      "Wenhao Liu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08542"
  },
  {
    "id": "arXiv:2112.08543",
    "title": "A framework for syntactic and semantic quality evaluation of ontologies",
    "abstract": "The increasing focus on Web 3.0 is leading to automated creation and\nenrichment of ontologies and other linked datasets. Alongside automation,\nquality evaluation of enriched ontologies can impact software reliability and\nreuse. Current quality evaluation approaches oftentimes seek to evaluate\nontologies in either syntactic (degree of following ontology development\nguidelines) or semantic (degree of semantic validity of enriched\nconcepts/relations) aspects. This paper proposes an ontology quality evaluation\nframework consisting of: (a) SynEvaluator and (b) SemValidator for evaluating\nsyntactic and semantic aspects of ontologies respectively. SynEvaluator allows\ndynamic task-specific creation and updation of syntactic rules at run-time\nwithout any need for programming. SemValidator uses Twitter-based expertise of\nvalidators for semantic evaluation. The efficacy and validity of the framework\nis shown empirically on multiple ontologies.",
    "descriptor": "\nComments: Accepted at International Conference on Secure Knowledge Management in the Artificial Intelligence Era (SKM) 2021 (Long Paper)\n",
    "authors": [
      "Vivek Iyer",
      "Lalit Mohan Sanagavarapu",
      "Raghu Reddy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.08543"
  },
  {
    "id": "arXiv:2112.08544",
    "title": "NewsClaims: A New Benchmark for Claim Detection from News with  Background Knowledge",
    "abstract": "Claim detection and verification are crucial for news understanding and have\nemerged as promising technologies for mitigating misinformation in news.\nHowever, most existing work focus on analysis of claim sentences while\noverlooking crucial background attributes, such as the claimer, claim objects,\nand other knowledge connected to the claim. In this work, we present NewsClaims\n, a new benchmark for knowledge-aware claim detection in the news domain. We\nre-define the claim detection problem to include extraction of additional\nbackground attributes related to the claim and release 529 claims annotated\nover 103 news articles. In addition, NewsClaims aims to benchmark claim\ndetection systems in emerging scenarios, comprising unseen topics with little\nor no training data. Finally, we provide a comprehensive evaluation of various\nzero-shot and prompt-based baselines for this new benchmark.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Revanth Gangi Reddy",
      "Sai Chinthakindi",
      "Zhenhailong Wang",
      "Yi R. Fung",
      "Kathryn S. Conger",
      "Ahmed S. Elsayed",
      "Martha Palmer",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08544"
  },
  {
    "id": "arXiv:2112.08547",
    "title": "Learning Rich Representation of Keyphrases from Text",
    "abstract": "In this work, we explore how to learn task-specific language models aimed\ntowards learning rich representation of keyphrases from text documents. We\nexperiment with different masking strategies for pre-training transformer\nlanguage models (LMs) in discriminative as well as generative settings. In the\ndiscriminative setting, we introduce a new pre-training objective - Keyphrase\nBoundary Infilling with Replacement (KBIR), showing large gains in performance\n(upto 9.26 points in F1) over SOTA, when LM pre-trained using KBIR is\nfine-tuned for the task of keyphrase extraction. In the generative setting, we\nintroduce a new pre-training setup for BART - KeyBART, that reproduces the\nkeyphrases related to the input text in the CatSeq format, instead of the\ndenoised original input. This also led to gains in performance (upto 4.33\npoints in F1@M) over SOTA for keyphrase generation. Additionally, we also\nfine-tune the pre-trained language models on named entity recognition (NER),\nquestion answering (QA), relation extraction (RE), abstractive summarization\nand achieve comparable performance with that of the SOTA, showing that learning\nrich representation of keyphrases is indeed beneficial for many other\nfundamental NLP tasks.",
    "descriptor": "",
    "authors": [
      "Mayank Kulkarni",
      "Debanjan Mahata",
      "Ravneet Arora",
      "Rajarshi Bhowmik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08547"
  },
  {
    "id": "arXiv:2112.08548",
    "title": "Prosody-Aware Neural Machine Translation for Dubbing",
    "abstract": "We introduce the task of prosody-aware machine translation which aims at\ngenerating translations suitable for dubbing. Dubbing of a spoken sentence\nrequires transferring the content as well as the prosodic structure of the\nsource into the target language to preserve timing information. Practically,\nthis implies correctly projecting pauses from the source to the target and\nensuring that target speech segments have roughly the same duration of the\ncorresponding source segments. In this work, we propose an implicit and\nexplicit modeling approaches to integrate prosody information into neural\nmachine translation. Experiments on English-German/French with automatic\nmetrics show that the simplest of the considered approaches works best. Results\nare confirmed by human evaluations of translations and dubbed videos.",
    "descriptor": "\nComments: Submitted to IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2022\n",
    "authors": [
      "Derek Tam",
      "Surafel M. Lakew",
      "Yogesh Virkar",
      "Prashant Mathur",
      "Marcello Federico"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08548"
  },
  {
    "id": "arXiv:2112.08549",
    "title": "A prediction-based approach for online dynamic radiotherapy scheduling",
    "abstract": "Patient scheduling is a difficult task as it involves dealing with stochastic\nfactors such as an unknown arrival flow of patients. Scheduling radiotherapy\ntreatments for cancer patients faces a similar problem. Curative patients need\nto start their treatment within the recommended deadlines, i.e., 14 or 28 days\nafter their admission while reserving treatment capacity for palliative\npatients who require urgent treatments within 1 to 3 days after their\nadmission. Most cancer centers solve the problem by reserving a fixed number of\ntreatment slots for emergency patients. However, this flat-reservation approach\nis not ideal and can cause overdue treatments for emergency patients on some\ndays while not fully exploiting treatment capacity on some other days, which\nalso leads to delaying treatment for curative patients. This problem is\nespecially severe in large and crowded hospitals. In this paper, we propose a\nprediction-based approach for online dynamic radiotherapy scheduling. An\noffline problem where all future patient arrivals are known in advance is\nsolved to optimality using Integer Programming. A regression model is then\ntrained to recognize the links between patients' arrival patterns and their\nideal waiting time. The trained regression model is then embedded in a\nprediction-based approach that schedules a patient based on their\ncharacteristics and the present state of the calendar. The numerical results\nshow that our prediction-based approach efficiently prevents overdue treatments\nfor emergency patients while maintaining a good waiting time compared to other\nscheduling approaches based on a flat-reservation policy.",
    "descriptor": "",
    "authors": [
      "Tu-San Pham",
      "Antoine Legrain",
      "Patrick De Causmaecker",
      "Louis-Martin Rousseau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08549"
  },
  {
    "id": "arXiv:2112.08550",
    "title": "Neural Content Extraction for Poster Generation of Scientific Papers",
    "abstract": "The problem of poster generation for scientific papers is under-investigated.\nPosters often present the most important information of papers, and the task\ncan be considered as a special form of document summarization. Previous studies\nfocus mainly on poster layout and panel composition, while neglecting the\nimportance of content extraction. Besides, their datasets are not publicly\navailable, which hinders further research. In this paper, we construct a\nbenchmark dataset from scratch for this task. Then we propose a three-step\nframework to tackle this task and focus on the content extraction step in this\nstudy. To get both textual and visual elements of a poster panel, a neural\nextractive model is proposed to extract text, figures and tables of a paper\nsection simultaneously. We conduct experiments on the dataset and also perform\nablation study. Results demonstrate the efficacy of our proposed model. The\ndataset and code will be released.",
    "descriptor": "",
    "authors": [
      "Sheng Xu",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08550"
  },
  {
    "id": "arXiv:2112.08553",
    "title": "UMAD: Universal Model Adaptation under Domain and Category Shift",
    "abstract": "Learning to reject unknown samples (not present in the source classes) in the\ntarget domain is fairly important for unsupervised domain adaptation (UDA).\nThere exist two typical UDA scenarios, i.e., open-set, and open-partial-set,\nand the latter assumes that not all source classes appear in the target domain.\nHowever, most prior methods are designed for one UDA scenario and always\nperform badly on the other UDA scenario. Moreover, they also require the\nlabeled source data during adaptation, limiting their usability in data\nprivacy-sensitive applications. To address these issues, this paper proposes a\nUniversal Model ADaptation (UMAD) framework which handles both UDA scenarios\nwithout access to the source data nor prior knowledge about the category shift\nbetween domains. Specifically, we aim to learn a source model with an elegantly\ndesigned two-head classifier and provide it to the target domain. During\nadaptation, we develop an informative consistency score to help distinguish\nunknown samples from known samples. To achieve bilateral adaptation in the\ntarget domain, we further maximize localized mutual information to align known\nsamples with the source classifier and employ an entropic loss to push unknown\nsamples far away from the source classification boundary, respectively.\nExperiments on open-set and open-partial-set UDA scenarios demonstrate that\nUMAD, as a unified approach without access to source data, exhibits comparable,\nif not superior, performance to state-of-the-art data-dependent methods.",
    "descriptor": "",
    "authors": [
      "Jian Liang",
      "Dapeng Hu",
      "Jiashi Feng",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08553"
  },
  {
    "id": "arXiv:2112.08554",
    "title": "A Deep Learning Approach for Ontology Enrichment from Unstructured Text",
    "abstract": "Information Security in the cyber world is a major cause for concern, with a\nsignificant increase in the number of attack surfaces. Existing information on\nvulnerabilities, attacks, controls, and advisories available on the web\nprovides an opportunity to represent knowledge and perform security analytics\nto mitigate some of the concerns. Representing security knowledge in the form\nof ontology facilitates anomaly detection, threat intelligence, reasoning and\nrelevance attribution of attacks, and many more. This necessitates dynamic and\nautomated enrichment of information security ontologies. However, existing\nontology enrichment algorithms based on natural language processing and ML\nmodels have issues with contextual extraction of concepts in words, phrases,\nand sentences. This motivates the need for sequential Deep Learning\narchitectures that traverse through dependency paths in text and extract\nembedded vulnerabilities, threats, controls, products, and other\nsecurity-related concepts and instances from learned path representations. In\nthe proposed approach, Bidirectional LSTMs trained on a large DBpedia dataset\nand Wikipedia corpus of 2.8 GB along with Universal Sentence Encoder is\ndeployed to enrich ISO 27001-based information security ontology. The model is\ntrained and tested on a high-performance computing (HPC) environment to handle\nWiki text dimensionality. The approach yielded a test accuracy of over 80% when\ntested with knocked-out concepts from ontology and web page instances to\nvalidate the robustness.",
    "descriptor": "\nComments: Accepted as a book chapter in \"Cybersecurity & High-Performance Computing Environments: Integrated Innovations, Practices, and Applications\", published by Taylor and Francis. arXiv admin note: substantial text overlap with arXiv:2102.04081\n",
    "authors": [
      "Lalit Mohan Sanagavarapu",
      "Vivek Iyer",
      "Raghu Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08554"
  },
  {
    "id": "arXiv:2112.08557",
    "title": "Protograph-based Bit-Interleaved Coded Modulation: A Promising  Bandwidth-Efficient Design Paradigm",
    "abstract": "As an established bandwidth-efficient coded modulation technique,\nbit-interleaved coded modulation (BICM) can achieve very desirable error\nperformance with relatively low implementation complexity for a large number of\ncommunication and storage systems. It attracted considerable attention from the\nresearch community in the past three decades. The BICM is able to approach\nShannon capacity limits over various channels with the use of powerful\nforward-error-correction (FEC) codes, bit mappers (i.e., interleavers), and\nhigh-order modulations. Based on the natural serially-concatenated structure of\nBICM, iterative demapping and decoding (ID) can be adopted to boost the system\nperformance. Due to the tremendous error-correction capability and simple\nstructures, protograph low-density parity-check (PLDPC) codes and their\nspatially-coupled (SC) variants have emerged to be a pragmatic and promising\nFEC solution for BICM systems, and found widespread applications such as\ndeep-space communication, satellite communication, wireless communication,\noptical communication, and flash-memory-based data storage in recent years.\nThis article offers a comprehensive survey on the state-of-the-art development\nof PLDPC-coded BICM and its innovative SC variants over a variety of channel\nmodels, e.g., additive white Gaussian noise (AWGN) channels, fading channels,\nPoisson pulse position modulation (PPM) channels, and NAND flash-memory\nchannels. Of particular interest is code construction, constellation shaping,\nas well as bit-mapper design, where the receiver is formulated as a\nserially-concatenated decoding framework consisting of a soft-decision demapper\nand a belief-propagation decoder. In addition, several promising research\ndirections are discussed, which have not been adequately addressed in the\ncurrent literature.",
    "descriptor": "",
    "authors": [
      "Yi Fang",
      "Pingping Chen",
      "Yong Liang Guan",
      "Francis C. M. Lau",
      "Yonghui Li",
      "Guanrong Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.08557"
  },
  {
    "id": "arXiv:2112.08558",
    "title": "CONQRR: Conversational Query Rewriting for Retrieval with Reinforcement  Learning",
    "abstract": "For open-domain conversational question answering (CQA), it is important to\nretrieve the most relevant passages to answer a question, but this is\nchallenging compared with standard passage retrieval because it requires\nunderstanding the full dialogue context rather than a single query. Moreover,\nit can be expensive to re-train well-established retrievers such as search\nengines that are originally developed for non-conversational queries. To\nfacilitate their use, we develop a query rewriting model CONQRR that rewrites a\nconversational question in context into a standalone question. It is trained\nwith a novel reward function to directly optimize towards retrieval and can be\nadapted to any fixed blackbox retriever using reinforcement learning. We show\nthat CONQRR achieves state-of-the-art results on a recent open-domain CQA\ndataset, a combination of conversations from three different sources. We also\nconduct extensive experiments to show the effectiveness of CONQRR for any given\nfixed retriever.",
    "descriptor": "",
    "authors": [
      "Zeqiu Wu",
      "Yi Luan",
      "Hannah Rashkin",
      "David Reitter",
      "Gaurav Singh Tomar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08558"
  },
  {
    "id": "arXiv:2112.08560",
    "title": "Block-Skim: Efficient Question Answering for Transformer",
    "abstract": "Transformer models have achieved promising results on natural language\nprocessing (NLP) tasks including extractive question answering (QA). Common\nTransformer encoders used in NLP tasks process the hidden states of all input\ntokens in the context paragraph throughout all layers. However, different from\nother tasks such as sequence classification, answering the raised question does\nnot necessarily need all the tokens in the context paragraph. Following this\nmotivation, we propose Block-skim, which learns to skim unnecessary context in\nhigher hidden layers to improve and accelerate the Transformer performance. The\nkey idea of Block-Skim is to identify the context that must be further\nprocessed and those that could be safely discarded early on during inference.\nCritically, we find that such information could be sufficiently derived from\nthe self-attention weights inside the Transformer model. We further prune the\nhidden states corresponding to the unnecessary positions early in lower layers,\nachieving significant inference-time speedup. To our surprise, we observe that\nmodels pruned in this way outperform their full-size counterparts. Block-Skim\nimproves QA models' accuracy on different datasets and achieves 3 times speedup\non BERT-base model.",
    "descriptor": "\nComments: Published as a conference paper at AAAI 2022\n",
    "authors": [
      "Yue Guan",
      "Zhengyi Li",
      "Jingwen Leng",
      "Zhouhan Lin",
      "Minyi Guo",
      "Yuhao Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08560"
  },
  {
    "id": "arXiv:2112.08561",
    "title": "EmotionBox: a music-element-driven emotional music generation system  using Recurrent Neural Network",
    "abstract": "With the development of deep neural networks, automatic music composition has\nmade great progress. Although emotional music can evoke listeners' different\nemotions and it is important for artistic expression, only few researches have\nfocused on generating emotional music. This paper presents EmotionBox -an\nmusic-element-driven emotional music generator that is capable of composing\nmusic given a specific emotion, where this model does not require a music\ndataset labeled with emotions. Instead, pitch histogram and note density are\nextracted as features that represent mode and tempo respectively to control\nmusic emotions. The subjective listening tests show that the Emotionbox has a\nmore competitive and balanced performance in arousing a specified emotion than\nthe emotion-label-based method.",
    "descriptor": "",
    "authors": [
      "Kaitong Zheng",
      "Ruijie Meng",
      "Chengshi Zheng",
      "Xiaodong Li",
      "Jinqiu Sang",
      "Juanjuan Cai",
      "Jie Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.08561"
  },
  {
    "id": "arXiv:2112.08563",
    "title": "Rail Vehicle Localization and Mapping with LiDAR-Vision-Inertial-GNSS  Fusion",
    "abstract": "In this paper, we present a global navigation satellite system (GNSS) aided\nLiDAR-visual-inertial scheme, RailLoMer-V, for accurate and robust rail vehicle\nlocalization and mapping. RailLoMer-V is formulated atop a factor graph and\nconsists of two subsystems: an odometer assisted LiDAR-inertial system (OLIS)\nand an odometer integrated Visual-inertial system (OVIS). Both the subsystem\nexploits the typical geometry structure on the railroads. The plane constraints\nfrom extracted rail tracks are used to complement the rotation and vertical\nerrors in OLIS. Besides, the line features and vanishing points are leveraged\nto constrain rotation drifts in OVIS. The proposed framework is extensively\nevaluated on datasets over 800 km, gathered for more than a year on both\ngeneral-speed and high-speed railways, day and night. Taking advantage of the\ntightly-coupled integration of all measurements from individual sensors, our\nframework is accurate to long-during tasks and robust enough to grievously\ndegenerated scenarios (railway tunnels). In addition, the real-time performance\ncan be achieved with an onboard computer.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2111.15043\n",
    "authors": [
      "Yusheng Wang",
      "Weiwei Song",
      "Yidong Lou",
      "Yi Zhang",
      "Fei Huang",
      "Zhiyong Tu",
      "Qiangsheng Liang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08563"
  },
  {
    "id": "arXiv:2112.08565",
    "title": "An adaptive finite element method for two-dimensional elliptic equations  with line Dirac sources",
    "abstract": "In this paper, we study an adaptive finite element method for the elliptic\nequation with line Dirac delta functions as a source term.We investigate the\nregularity of the solution and the corresponding transmission problem to obtain\nthe jump of normal derivative of the solution on line fractures. To handle the\nsingularity of the solution, we adopt the meshes that conform to line\nfractures, and propose a novel a posteriori error estimator, in which the edge\njump residual essentially use the jump of the normal derivative of the solution\non line fractures. The error estimator is proven to be both reliable and\nefficient, finally an adaptive finite element algorithm is proposed based on\nthe error estimator and the bisection refinement method. Numerical tests are\npresented to justify the theoretical findings.",
    "descriptor": "\nComments: 24 pages, 20 figures\n",
    "authors": [
      "Huihui Cao",
      "Hengguang Li",
      "Nianyu Yi",
      "Peimeng Yin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08565"
  },
  {
    "id": "arXiv:2112.08566",
    "title": "Randomized regularized extended Kaczmarz algorithms for tensor recovery",
    "abstract": "Randomized regularized Kaczmarz algorithms have recently been proposed to\nsolve tensor recovery models with {\\it consistent} linear measurements. In this\nwork, we propose a novel algorithm based on the randomized extended Kaczmarz\nalgorithm (which converges linearly in expectation to the unique minimum norm\nleast squares solution of a linear system) for tensor recovery models with {\\it\ninconsistent} linear measurements. We prove the linear convergence in\nexpectation of our algorithm. Numerical experiments on a tensor least squares\nproblem and a sparse tensor recovery problem are given to illustrate the\ntheoretical results.",
    "descriptor": "\nComments: 17 pages, 2 figures\n",
    "authors": [
      "Kui Du",
      "Xiao-Hui Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.08566"
  },
  {
    "id": "arXiv:2112.08567",
    "title": "HampDTI: a heterogeneous graph automatic meta-path learning method for  drug-target interaction prediction",
    "abstract": "Motivation: Identifying drug-target interactions (DTIs) is a key step in drug\nrepositioning. In recent years, the accumulation of a large number of genomics\nand pharmacology data has formed mass drug and target related heterogeneous\nnetworks (HNs), which provides new opportunities of developing HN-based\ncomputational models to accurately predict DTIs. The HN implies lots of useful\ninformation about DTIs but also contains irrelevant data, and how to make the\nbest of heterogeneous networks remains a challenge. Results: In this paper, we\npropose a heterogeneous graph automatic meta-path learning based DTI prediction\nmethod (HampDTI). HampDTI automatically learns the important meta-paths between\ndrugs and targets from the HN, and generates meta-path graphs. For each\nmeta-path graph, the features learned from drug molecule graphs and target\nprotein sequences serve as the node attributes, and then a node-type specific\ngraph convolutional network (NSGCN) which efficiently considers node type\ninformation (drugs or targets) is designed to learn embeddings of drugs and\ntargets. Finally, the embeddings from multiple meta-path graphs are combined to\npredict novel DTIs. The experiments on benchmark datasets show that our\nproposed HampDTI achieves superior performance compared with state-of-the-art\nDTI prediction methods. More importantly, HampDTI identifies the important\nmeta-paths for DTI prediction, which could explain how drugs connect with\ntargets in HNs.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Hongzhun Wang",
      "Feng Huang",
      "Wen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2112.08567"
  },
  {
    "id": "arXiv:2112.08569",
    "title": "Toward Imagined Speech based Smart Communication System: Potential  Applications on Metaverse Conditions",
    "abstract": "Recently, brain-computer interface (BCI) system is aiming to provide\nuser-friendly and intuitive means of communication. Imagined speech has become\nan alternative neuro-paradigm for communicative BCI since it relies directly on\na person's speech production process, rather than using speech-unrelated neural\nactivity as the method of communication. Together with the current trends on\nBCI, we suggest a brain-to-speech (BTS) system that operates by real-time\ndecoding of multi-class imagined speech electroencephalography (EEG). Using the\nthirteen-class imagined speech data of nine subjects, we performed\npseudo-online analysis in order to investigate the potential use of virtual BTS\nsystem in the real-world. Average accuracy of 46.54 % (chance level = 7.7 %)\nand 75.56 % (chance level = 50 %) was acquired in the thirteen-class and binary\npseudo-online analysis, respectively. Together with the pseudo-online analysis\nof imagined speech decoding, we suggest possible form of future applications of\nimagined speech BCI as means of intuitive BCI communication. We provide\npotential applications on virtual smart home system and virtual assistant\ncontrolled by imagined speech. The virtual BTS system in this paper displays\nthe possible form of real-world application and online training platform.",
    "descriptor": "\nComments: Submitted to 2022 10th IEEE International Winter Conference on Brain-Computer Interface\n",
    "authors": [
      "Seo-Hyun Lee",
      "Young-Eun Lee",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.08569"
  },
  {
    "id": "arXiv:2112.08570",
    "title": "Can Multilinguality benefit Non-autoregressive Machine Translation?",
    "abstract": "Non-autoregressive (NAR) machine translation has recently achieved\nsignificant improvements, and now outperforms autoregressive (AR) models on\nsome benchmarks, providing an efficient alternative to AR inference. However,\nwhile AR translation is often implemented using multilingual models that\nbenefit from transfer between languages and from improved serving efficiency,\nmultilingual NAR models remain relatively unexplored. Taking Connectionist\nTemporal Classification (CTC) as an example NAR model and Imputer as a semi-NAR\nmodel, we present a comprehensive empirical study of multilingual NAR. We test\nits capabilities with respect to positive transfer between related languages\nand negative transfer under capacity constraints. As NAR models require\ndistilled training sets, we carefully study the impact of bilingual versus\nmultilingual teachers. Finally, we fit a scaling law for multilingual NAR,\nwhich quantifies its performance relative to the AR model as model scale\nincreases.",
    "descriptor": "",
    "authors": [
      "Sweta Agrawal",
      "Julia Kreutzer",
      "Colin Cherry"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08570"
  },
  {
    "id": "arXiv:2112.08572",
    "title": "Predictive Price-Performance Optimization for Serverless Query  Processing",
    "abstract": "We present an efficient, parametric modeling framework for predictive\nresource allocations, focusing on the amount of computational resources, that\ncan optimize for a range of price-performance objectives for data analytics in\nserverless query processing settings. We discuss and evaluate in depth how our\nsystem, AutoExecutor, can use this framework to automatically select\nnear-optimal executor and core counts for Spark SQL queries running on Azure\nSynapse. Our techniques improve upon Spark's in-built, reactive, dynamic\nexecutor allocation capabilities by substantially reducing the total executors\nallocated and executor occupancy while running queries, thereby freeing up\nexecutors that can potentially be used by other concurrent queries or in\nreducing the overall cluster provisioning needs. In contrast with\npost-execution analysis tools such as Sparklens, we predict resource\nallocations for queries before executing them and can also account for changes\nin input data sizes for predicting the desired allocations.",
    "descriptor": "",
    "authors": [
      "Rathijit Sen",
      "Abhishek Roy",
      "Alekh Jindal"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08572"
  },
  {
    "id": "arXiv:2112.08576",
    "title": "Geometric continuous-stage exponential energy-preserving integrators for  charged-particle dynamics in a magnetic field from normal to strong regimes",
    "abstract": "This paper is concerned with geometric exponential energy-preserving\nintegrators for solving charged-particle dynamics in a magnetic field from\nnormal to strong regimes. We firstly formulate the scheme of the methods for\nthe system in a uniform magnetic field by using the idea of continuous-stage\nmethods, and then discuss its energy-preserving property. Moreover, symmetric\nconditions and order conditions are analysed. Based on those conditions, we\npropose two practical symmetric continuous-stage exponential energy-preserving\nintegrators of order up to four. Then we extend the obtained methods to the\nsystem in a nonuniform magnetic field and derive their properties including the\nsymmetry, convergence and energy conservation. Numerical experiments\ndemonstrate the efficiency of the proposed methods in comparison with some\nexisting schemes in the literature.",
    "descriptor": "\nComments: 21 pages,36 figures\n",
    "authors": [
      "Ting Li",
      "Bin Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08576"
  },
  {
    "id": "arXiv:2112.08578",
    "title": "CLICKER: A Computational LInguistics Classification Scheme for  Educational Resources",
    "abstract": "A classification scheme of a scientific subject gives an overview of its body\nof knowledge. It can also be used to facilitate access to research articles and\nother materials related to the subject. For example, the ACM Computing\nClassification System (CCS) is used in the ACM Digital Library search interface\nand also for indexing computer science papers. We observed that a comprehensive\nclassification system like CCS or Mathematics Subject Classification (MSC) does\nnot exist for Computational Linguistics (CL) and Natural Language Processing\n(NLP). We propose a classification scheme -- CLICKER for CL/NLP based on the\nanalysis of online lectures from 77 university courses on this subject. The\ncurrently proposed taxonomy includes 334 topics and focuses on educational\naspects of CL/NLP; it is based primarily, but not exclusively, on lecture notes\nfrom NLP courses. We discuss how such a taxonomy can help in various real-world\napplications, including tutoring platforms, resource retrieval, resource\nrecommendation, prerequisite chain learning, and survey generation.",
    "descriptor": "\nComments: 7 pages, 5 figures, 4 tables\n",
    "authors": [
      "Swapnil Hingmire",
      "Irene Li",
      "Rena Kawamura",
      "Benjamin Chen",
      "Alexander Fabbri",
      "Xiangru Tang",
      "Yixin Liu",
      "Thomas George",
      "Tammy Liao",
      "Wai Pan Wong",
      "Vanessa Yan",
      "Richard Zhou",
      "Girish K. Palshikar",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08578"
  },
  {
    "id": "arXiv:2112.08579",
    "title": "The Credibility Cryptocurrency Valuation: Statistical Learning Analysis  for Influencer Tweets",
    "abstract": "Cryptocurrency has attracted significant attention. Considering the number of\nindividuals investing in bitcoin, their motivations are comparatively less\nclear than traditional investment decisions. As of December 2020, the market\nhas continuously increased in cryptocurrency. Especially, the spike of joke\nDogecoin shows the weirdness of the modern meme economy with the support of\nElon Musk, whom himself appointed as \"Dogefather\". In this paper, we analysis\nthe impact of tweets by Elon musk and present some statistical analyze with\nevent study.",
    "descriptor": "",
    "authors": [
      "Haemin Lee",
      "Hyunhee Cho",
      "Soyi Jung",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.08579"
  },
  {
    "id": "arXiv:2112.08581",
    "title": "A First Mathematical Runtime Analysis of the Non-Dominated Sorting  Genetic Algorithm II (NSGA-II)",
    "abstract": "The non-dominated sorting genetic algorithm II (NSGA-II) is the most\nintensively used multi-objective evolutionary algorithm (MOEA) in real-world\napplications. However, in contrast to several simple MOEAs analyzed also via\nmathematical means, no such study exists for the NSGA-II so far. In this work,\nwe show that mathematical runtime analyses are feasible also for the NSGA-II.\nAs particular results, we prove that with a population size larger than the\nPareto front size by a constant factor, the NSGA-II with two classic mutation\noperators and three different ways to select the parents satisfies the same\nasymptotic runtime guarantees as the SEMO and GSEMO algorithms on the basic\nOneMinMax and LOTZ benchmark functions. However, if the population size is only\nequal to the size of the Pareto front, then the NSGA-II cannot efficiently\ncompute the full Pareto front (for an exponential number of iterations, the\npopulation will always miss a constant fraction of the Pareto front). Our\nexperiments confirm the above findings.",
    "descriptor": "\nComments: Preprint version (not the camera-ready version) of one paper accepted in AAAI 2022\n",
    "authors": [
      "Weijie Zheng",
      "Yufei Liu",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08581"
  },
  {
    "id": "arXiv:2112.08583",
    "title": "Does Pre-training Induce Systematic Inference? How Masked Language  Models Acquire Commonsense Knowledge",
    "abstract": "Transformer models pre-trained with a masked-language-modeling objective\n(e.g., BERT) encode commonsense knowledge as evidenced by behavioral probes;\nhowever, the extent to which this knowledge is acquired by systematic inference\nover the semantics of the pre-training corpora is an open question. To answer\nthis question, we selectively inject verbalized knowledge into the minibatches\nof a BERT model during pre-training and evaluate how well the model generalizes\nto supported inferences. We find generalization does not improve over the\ncourse of pre-training, suggesting that commonsense knowledge is acquired from\nsurface-level, co-occurrence patterns rather than induced, systematic\nreasoning.",
    "descriptor": "",
    "authors": [
      "Ian Porada",
      "Alessandro Sordoni",
      "Jackie Chi Kit Cheung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08583"
  },
  {
    "id": "arXiv:2112.08587",
    "title": "SGEITL: Scene Graph Enhanced Image-Text Learning for Visual Commonsense  Reasoning",
    "abstract": "Answering complex questions about images is an ambitious goal for machine\nintelligence, which requires a joint understanding of images, text, and\ncommonsense knowledge, as well as a strong reasoning ability. Recently,\nmultimodal Transformers have made great progress in the task of Visual\nCommonsense Reasoning (VCR), by jointly understanding visual objects and text\ntokens through layers of cross-modality attention. However, these approaches do\nnot utilize the rich structure of the scene and the interactions between\nobjects which are essential in answering complex commonsense questions. We\npropose a Scene Graph Enhanced Image-Text Learning (SGEITL) framework to\nincorporate visual scene graphs in commonsense reasoning. To exploit the scene\ngraph structure, at the model structure level, we propose a multihop graph\ntransformer for regularizing attention interaction among hops. As for\npre-training, a scene-graph-aware pre-training method is proposed to leverage\nstructure knowledge extracted in the visual scene graph. Moreover, we introduce\na method to train and generate domain-relevant visual scene graphs using\ntextual annotations in a weakly-supervised manner. Extensive experiments on VCR\nand other tasks show a significant performance boost compared with the\nstate-of-the-art methods and prove the efficacy of each proposed component.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Zhecan Wang",
      "Haoxuan You",
      "Liunian Harold Li",
      "Alireza Zareian",
      "Suji Park",
      "Yiqing Liang",
      "Kai-Wei Chang",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.08587"
  },
  {
    "id": "arXiv:2112.08588",
    "title": "Learning to acquire novel cognitive tasks with evolution, plasticity and  meta-meta-learning",
    "abstract": "In meta-learning, networks are trained with external algorithms to learn\ntasks that require acquiring, storing and exploiting unpredictable information\nfor each new instance of the task. However, animals are able to pick up such\ncognitive tasks automatically, as a result of their evolved neural architecture\nand synaptic plasticity mechanisms. Here we evolve neural networks, endowed\nwith plastic connections, over a sizable set of simple meta-learning tasks\nbased on a neuroscience modelling framework. The resulting evolved network can\nautomatically acquire a novel simple cognitive task, never seen during\ntraining, through the spontaneous operation of its evolved neural organization\nand plasticity structure. We suggest that attending to the multiplicity of\nloops involved in natural learning may provide useful insight into the\nemergence of intelligent behavior.",
    "descriptor": "",
    "authors": [
      "Thomas Miconi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08588"
  },
  {
    "id": "arXiv:2112.08589",
    "title": "Knowledge Graph Embedding in E-commerce Applications: Attentive  Reasoning, Explanations, and Transferable Rules",
    "abstract": "Knowledge Graphs (KGs), representing facts as triples, have been widely\nadopted in many applications. Reasoning tasks such as link prediction and rule\ninduction are important for the development of KGs. Knowledge Graph Embeddings\n(KGEs) embedding entities and relations of a KG into continuous vector spaces,\nhave been proposed for these reasoning tasks and proven to be efficient and\nrobust. But the plausibility and feasibility of applying and deploying KGEs in\nreal-work applications has not been well-explored. In this paper, we discuss\nand report our experiences of deploying KGEs in a real domain application:\ne-commerce. We first identity three important desiderata for e-commerce KG\nsystems: 1) attentive reasoning, reasoning over a few target relations of more\nconcerns instead of all; 2) explanation, providing explanations for a\nprediction to help both users and business operators understand why the\nprediction is made; 3) transferable rules, generating reusable rules to\naccelerate the deployment of a KG to new systems. While non existing KGE could\nmeet all these desiderata, we propose a novel one, an explainable knowledge\ngraph attention network that make prediction through modeling correlations\nbetween triples rather than purely relying on its head entity, relation and\ntail entity embeddings. It could automatically selects attentive triples for\nprediction and records the contribution of them at the same time, from which\nexplanations could be easily provided and transferable rules could be\nefficiently produced. We empirically show that our method is capable of meeting\nall three desiderata in our e-commerce application and outperform typical\nbaselines on datasets from real domain applications.",
    "descriptor": "\nComments: Accepted at IJCKG2021\n",
    "authors": [
      "Wen Zhang",
      "Shumin Deng",
      "Mingyang Chen",
      "Liang Wang",
      "Qiang Chen",
      "Feiyu Xiong",
      "Xiangwen Liu",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08589"
  },
  {
    "id": "arXiv:2112.08590",
    "title": "Federated 3GPP Mobile Edge Computing Systems: A Transparent Proxy for  Third Party Authentication with Application Mobility Support",
    "abstract": "Multi-Access or Mobile Edge Computing (MEC) is being deployed by 4G/5G\noperators to provide computational services at lower latencies. Federating MECs\nacross operators expands capability, capacity, and coverage but gives rise to\ntwo issues - third-party authentication and application mobility - for\ncontinuous service during roaming without re-authentication. In this work, we\npropose a Federated State transfer and 3rd-party Authentication (FS3A)\nmechanism that uses a transparent proxy to transfer the information of both\nauthentication and application state across operators to resolve these issues.\nThe FS3A proxy is kept transparent, with virtual counterparts, to avoid any\nchanges to the existing MEC and cellular architectures. FS3A provides users\nwith a token, when authenticated by an MEC, which can be reused across\noperators for faster authentication. Prefetching of subscription and state is\nalso proposed to further reduce the authentication and application mobility\nlatencies. We evaluated FS3A on an OpenAirInterface (OAI)-based testbed and the\nresults show that token reuse and subscription prefetching reduce the\nauthentication latency by 53-65%, compared to complete re-authentication, while\nstate prefetching reduces application mobility latency by 51-91%, compared to\nno prefetching. Overall, FS3A reduces the service interruption time by 33%,\ncompared to no token reuse and prefetching.",
    "descriptor": "\nComments: 14 pages. 8 figures. Submitted to IEEE Access\n",
    "authors": [
      "Asad Ali",
      "Samin Rahman Khan",
      "Sadman Sakib",
      "Md. Shohrab Hossain",
      "Ying-Dar Lin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.08590"
  },
  {
    "id": "arXiv:2112.08592",
    "title": "Idiomatic Expression Paraphrasing without Strong Supervision",
    "abstract": "Idiomatic expressions (IEs) play an essential role in natural language. In\nthis paper, we study the task of idiomatic sentence paraphrasing (ISP), which\naims to paraphrase a sentence with an IE by replacing the IE with its literal\nparaphrase. The lack of large-scale corpora with idiomatic-literal parallel\nsentences is a primary challenge for this task, for which we consider two\nseparate solutions. First, we propose an unsupervised approach to ISP, which\nleverages an IE's contextual information and definition and does not require a\nparallel sentence training set. Second, we propose a weakly supervised approach\nusing back-translation to jointly perform paraphrasing and generation of\nsentences with IEs to enlarge the small-scale parallel sentence training\ndataset. Other significant derivatives of the study include a model that\nreplaces a literal phrase in a sentence with an IE to generate an idiomatic\nexpression and a large scale parallel dataset with idiomatic/literal sentence\npairs. The effectiveness of the proposed solutions compared to competitive\nbaselines is seen in the relative gains of over 5.16 points in BLEU, over 8.75\npoints in METEOR, and over 19.57 points in SARI when the generated sentences\nare empirically validated on a parallel dataset using automatic and manual\nevaluations. We demonstrate the practical utility of ISP as a preprocessing\nstep in En-De machine translation.",
    "descriptor": "",
    "authors": [
      "Jianing Zhou",
      "Ziheng Zeng",
      "Hongyu Gong",
      "Suma Bhat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08592"
  },
  {
    "id": "arXiv:2112.08593",
    "title": "Goal-Directed Story Generation: Augmenting Generative Language Models  with Reinforcement Learning",
    "abstract": "The advent of large pre-trained generative language models has provided a\ncommon framework for AI story generation via sampling the model to create\nsequences that continue the story. However, sampling alone is insufficient for\nstory generation. In particular, it is hard to direct a language model to\ncreate stories to reach a specific goal event. We present two automated\ntechniques grounded in deep reinforcement learning and reward shaping to\ncontrol the plot of computer-generated stories. The first utilizes proximal\npolicy optimization to fine-tune an existing transformer-based language model\nto generate text continuations but also be goal-seeking. The second extracts a\nknowledge graph from the unfolding story, which is used by a policy network\nwith graph attention to select a candidate continuation generated by a language\nmodel. We report on automated metrics pertaining to how often stories achieve a\ngiven goal event as well as human participant rankings of coherence and overall\nstory quality compared to baselines and ablations.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Amal Alabdulkarim",
      "Winston Li",
      "Lara J. Martin",
      "Mark O. Riedl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08593"
  },
  {
    "id": "arXiv:2112.08594",
    "title": "Twitter-COMMs: Detecting Climate, COVID, and Military Multimodal  Misinformation",
    "abstract": "Detecting out-of-context media, such as \"miscaptioned\" images on Twitter,\noften requires detecting inconsistencies between the two modalities. This paper\ndescribes our approach to the Image-Text Inconsistency Detection challenge of\nthe DARPA Semantic Forensics (SemaFor) Program. First, we collect\nTwitter-COMMs, a large-scale multimodal dataset with 884k tweets relevant to\nthe topics of Climate Change, COVID-19, and Military Vehicles. We train our\napproach, based on the state-of-the-art CLIP model, leveraging automatically\ngenerated random and hard negatives. Our method is then tested on a hidden\nhuman-generated evaluation set. We achieve the best result on the program\nleaderboard, with 11% detection improvement in a high precision regime over a\nzero-shot CLIP baseline.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Giscard Biamby",
      "Grace Luo",
      "Trevor Darrell",
      "Anna Rohrbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08594"
  },
  {
    "id": "arXiv:2112.08595",
    "title": "Accuracy Enhancing Interface Treatment Algorithm: the Back and Forth  Error Compensation and Correction method",
    "abstract": "The accuracy of information transmission while solving domain decomposed\nproblems is crucial to smooth transition of a solution around the\ninterface/overlapping region. This paper describes a systematical study on an\naccuracy enhancing interface treatment algorithm based on the back and forth\nerror compensation and correction method (BFECC). By repetitively employing a\nlow order interpolation technique (normally local 2\\ts{nd} order) 3 times, this\nalgorithm achieves local 3\\ts{rd} order accuracy. Analytical derivations for 1D\n\\& 2D cases are made, and the \"super convergence\" phenomenon (4\\ts{th} order\naccuracy) is found for specific positioning of the donor and target grids. A\nset of numerical experiments based on various relative displacements, relative\nrotations, mesh ratios, and meshes with perturbation have been tested, and the\nresults match the derivations. Different interface treatments are compared with\n3D examples: corner flow and cavity flow. The component convergence rate\nanalysis shows that the BFECC method positively affects the accuracy of\nsolutions.",
    "descriptor": "\nComments: 27 pages, 16 figures\n",
    "authors": [
      "Wenbin Dong",
      "Yingjie Liu",
      "Hansong Tang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08595"
  },
  {
    "id": "arXiv:2112.08596",
    "title": "Guiding Neural Story Generation with Reader Models",
    "abstract": "Automated storytelling has long captured the attention of researchers for the\nubiquity of narratives in everyday life. However, it is challenging to maintain\ncoherence and stay on-topic toward a specific ending when generating narratives\nwith neural language models. In this paper, we introduce Story generation with\nReader Models (StoRM), a framework in which a reader model is used to reason\nabout the story should progress. A reader model infers what a human reader\nbelieves about the concepts, entities, and relations about the fictional story\nworld. We show how an explicit reader model represented as a knowledge graph\naffords story coherence and provides controllability in the form of achieving a\ngiven story world state goal. Experiments show that our model produces\nsignificantly more coherent and on-topic stories, outperforming baselines in\ndimensions including plot plausibility and staying on topic. Our system also\noutperforms outline-guided story generation baselines in composing given\nconcepts without ordering.",
    "descriptor": "",
    "authors": [
      "Xiangyu Peng",
      "Kaige Xie",
      "Amal Alabdulkarim",
      "Harshith Kayam",
      "Samihan Dani",
      "Mark O. Riedl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08596"
  },
  {
    "id": "arXiv:2112.08597",
    "title": "Reprogrammable Surfaces Through Star Graph Metamaterials",
    "abstract": "The ability to change a surface's profile allows biological systems to\neffectively manipulate and blend into their surroundings. Current surface\nmorphing techniques rely either on having a small number of fixed states or on\ndirectly driving the entire system. We discovered a subset of scale-independent\nauxetic metamaterials have a state trajectory with a star-graph structure. At\nthe central node, small nudges can move the material between trajectories,\nallowing us to locally shift Poisson's ratio, causing the material to take on\ndifferent shapes under loading. While the number of possible shapes grows\nexponentially with the size of the material, the probability of finding one at\nrandom is vanishingly small. By actively guiding the material through the node\npoints, we produce a reprogrammable surface that does not require inputs to\nmaintain shape and can display arbitrary 2D information and take on complex 3D\nshapes. Our work opens new opportunities in micro devices, tactile displays,\nmanufacturing, and robotic systems.",
    "descriptor": "",
    "authors": [
      "Sawyer Thomas",
      "Jeffrey Lipton"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08597"
  },
  {
    "id": "arXiv:2112.08598",
    "title": "FIgLib & SmokeyNet: Dataset and Deep Learning Model for Real-Time  Wildland Fire Smoke Detection",
    "abstract": "The size and frequency of wildland fires in the western United States have\ndramatically increased in recent years. On high fire-risk days, a small fire\nignition can rapidly grow and get out of control. Early detection of fire\nignitions from initial smoke can assist the response to such fires before they\nbecome difficult to manage. Past deep learning approaches for wildfire smoke\ndetection have suffered from small or unreliable datasets that make it\ndifficult to extrapolate performance to real-world scenarios. In this work, we\npresent the Fire Ignition Library (FIgLib), a publicly-available dataset of\nnearly 25,000 labeled wildfire smoke images as seen from fixed-view cameras\ndeployed in Southern California. We also introduce SmokeyNet, a novel deep\nlearning architecture using spatio-temporal information from camera imagery for\nreal-time wildfire smoke detection. When trained on the FIgLib dataset,\nSmokeyNet outperforms comparable baselines and rivals human performance. We\nhope that the availability of the FIgLib dataset and the SmokeyNet architecture\nwill inspire further research into deep learning methods for wildfire smoke\ndetection, leading to automated notification systems that reduce the time to\nwildfire response.",
    "descriptor": "",
    "authors": [
      "Anshuman Dewangan",
      "Yash Pande",
      "Hans-Werner Braun",
      "Frank Vernon",
      "Ismael Perez",
      "Ilkay Atlintas",
      "Gary Cottrell",
      "Mai H. Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08598"
  },
  {
    "id": "arXiv:2112.08604",
    "title": "Use Image Clustering to Facilitate Technology Assisted Review",
    "abstract": "During the past decade breakthroughs in GPU hardware and deep neural networks\ntechnologies have revolutionized the field of computer vision, making image\nanalytical potentials accessible to a range of real-world applications.\nTechnology Assisted Review (TAR) in electronic discovery though traditionally\nhas dominantly dealt with textual content, is witnessing a rising need to\nincorporate multimedia content in the scope. We have developed innovative image\nanalytics applications for TAR in the past years, such as image classification,\nimage clustering, and object detection, etc. In this paper, we discuss the use\nof image clustering applications to facilitate TAR based on our experiences in\nserving clients. We describe our general workflow on leveraging image\nclustering in tasks and use statistics from real projects to showcase the\neffectiveness of using image clustering in TAR. We also summarize lessons\nlearned and best practices on using image clustering in TAR.",
    "descriptor": "\nComments: 2021 IEEE International Conference on Big Data (Big Data)\n",
    "authors": [
      "Haozhen Zhao",
      "Fusheng Wei",
      "Hilary Quatinetz",
      "Han Qin",
      "Adam Dabrowski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.08604"
  },
  {
    "id": "arXiv:2112.08605",
    "title": "Frequency Spectrum Augmentation Consistency for Domain Adaptive Object  Detection",
    "abstract": "Domain adaptive object detection (DAOD) aims to improve the generalization\nability of detectors when the training and test data are from different\ndomains. Considering the significant domain gap, some typical methods, e.g.,\nCycleGAN-based methods, adopt the intermediate domain to bridge the source and\ntarget domains progressively. However, the CycleGAN-based intermediate domain\nlacks the pix- or instance-level supervision for object detection, which leads\nto semantic differences. To address this problem, in this paper, we introduce a\nFrequency Spectrum Augmentation Consistency (FSAC) framework with four\ndifferent low-frequency filter operations. In this way, we can obtain a series\nof augmented data as the intermediate domain. Concretely, we propose a\ntwo-stage optimization framework. In the first stage, we utilize all the\noriginal and augmented source data to train an object detector. In the second\nstage, augmented source and target data with pseudo labels are adopted to\nperform the self-training for prediction consistency. And a teacher model\noptimized using Mean Teacher is used to further revise the pseudo labels. In\nthe experiment, we evaluate our method on the single- and compound- target DAOD\nseparately, which demonstrate the effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Rui Liu",
      "Yahong Han",
      "Yaowei Wang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08605"
  },
  {
    "id": "arXiv:2112.08606",
    "title": "An Empirical Study on Transfer Learning for Privilege Review",
    "abstract": "Protecting privileged communications and data from inadvertent disclosure is\na paramount task in the US legal practice. Traditionally counsels rely on\nkeyword searching and manual review to identify privileged documents in cases.\nAs data volumes increase, this approach becomes less and less defensible in\ncosts. Machine learning methods have been used in identifying privilege\ndocuments. Given the generalizable nature of privilege in legal cases, we\nhypothesize that transfer learning can capitalize knowledge learned from\nexisting labeled data to identify privilege documents without requiring\nlabeling new training data. In this paper, we study both traditional machine\nlearning models and deep learning models based on BERT for privilege document\nclassification tasks in legal document review, and we examine the effectiveness\nof transfer learning in privilege model on three real world datasets with\nprivilege labels. Our results show that BERT model outperforms the industry\nstandard logistic regression algorithm and transfer learning models can achieve\ndecent performance on datasets in same or close domains.",
    "descriptor": "\nComments: 2021 IEEE International Conference on Big Data (Big Data)\n",
    "authors": [
      "Haozhen Zhao",
      "Shi Ye",
      "Jingchao Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.08606"
  },
  {
    "id": "arXiv:2112.08608",
    "title": "QuALITY: Question Answering with Long Input Texts, Yes!",
    "abstract": "To enable building and testing models on long-document comprehension, we\nintroduce QuALITY, a multiple-choice QA dataset with context passages in\nEnglish that have an average length of about 5,000 tokens, much longer than\ntypical current models can process. Unlike in prior work with passages, our\nquestions are written and validated by contributors who have read the entire\npassage, rather than relying on summaries or excerpts. In addition, only half\nof the questions are answerable by annotators working under tight time\nconstraints, indicating that skimming and simple search are not enough to\nconsistently perform well. Current models perform poorly on this task (55.4%)\nand significantly lag behind human performance (93.5%).",
    "descriptor": "",
    "authors": [
      "Richard Yuanzhe Pang",
      "Alicia Parrish",
      "Nitish Joshi",
      "Nikita Nangia",
      "Jason Phang",
      "Angelica Chen",
      "Vishakh Padmakumar",
      "Johnny Ma",
      "Jana Thompson",
      "He He",
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08608"
  },
  {
    "id": "arXiv:2112.08609",
    "title": "DuQM: A Chinese Dataset of Linguistically Perturbed Natural Questions  for Evaluating the Robustness of Question Matching Models",
    "abstract": "In this paper, we focus on studying robustness evaluation of Chinese question\nmatching. Most of the previous work on analyzing robustness issue focus on just\none or a few types of artificial adversarial examples. Instead, we argue that\nit is necessary to formulate a comprehensive evaluation about the linguistic\ncapabilities of models on natural texts. For this purpose, we create a Chinese\ndataset namely DuQM which contains natural questions with linguistic\nperturbations to evaluate the robustness of question matching models. DuQM\ncontains 3 categories and 13 subcategories with 32 linguistic perturbations.\nThe extensive experiments demonstrate that DuQM has a better ability to\ndistinguish different models. Importantly, the detailed breakdown of evaluation\nby linguistic phenomenon in DuQM helps us easily diagnose the strength and\nweakness of different models. Additionally, our experiment results show that\nthe effect of artificial adversarial examples does not work on the natural\ntexts.",
    "descriptor": "",
    "authors": [
      "Hongyu Zhu",
      "Yan Chen",
      "Jing Yan",
      "Jing Liu",
      "Yu Hong",
      "Ying Chen",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08609"
  },
  {
    "id": "arXiv:2112.08610",
    "title": "Electromagnetic Effective Degree of Freedom of a MIMO System in Free  Space",
    "abstract": "Effective degree of freedom (EDOF) of a multiple-input-multiple-output (MIMO)\nsystem represents its equivalent number of independent\nsingle-input-single-output (SISO) systems, which directly characterizes the\ncommunication performance. Traditional EDOF only considers single polarization,\nwhere the full polarized components degrade into two independent transverse\ncomponents under the far-field approximation. However, the traditional model is\nnot applicable to complex scenarios especially for the near-field region. Based\non an electromagnetic (EM) channel model built from the dyadic Green's\nfunction, we first calculate the EM EDOF to estimate the performance of an\narbitrary MIMO system with full polarizations in free space. Then, we clarify\nthe relations between the limit of EDOF and the optimal number of\nsources/receivers. Finally, potential benefits of near-field MIMO\ncommunications are demonstrated with the EM EDOF, in which the contribution of\nthe longitudinally polarized source is taken into account. This work\nestablishes a fundamental EM framework for MIMO wireless communications.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Shuai S. A. Yuan",
      "Zi He",
      "Xiaoming Chen",
      "Chongwen Huang",
      "Wei E. I. Sha"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.08610"
  },
  {
    "id": "arXiv:2112.08611",
    "title": "Clickbait in YouTube Prevention, Detection and Analysis of the Bait  using Ensemble Learning",
    "abstract": "Unscrupulous content creators on YouTube employ deceptive techniques such as\nspam and clickbait to reach a broad audience and trick users into clicking on\ntheir videos to increase their advertisement revenue. Clickbait detection on\nYouTube requires an in depth examination and analysis of the intricate\nrelationship between the video content and video descriptors title and\nthumbnail. However, the current solutions are mostly centred around the study\nof video descriptors and other metadata such as likes, tags, comments, etc and\nfail to utilize the video content, both video and audio. Therefore, we\nintroduce a novel model to detect clickbaits on YouTube that consider the\nrelationship between video content and title or thumbnail. The proposed model\nconsists of a stacking classifier framework composed of six base models (K\nNearest Neighbours, Support Vector Machine, XGBoost, Naive Bayes, Logistic\nRegression, and Multilayer Perceptron) and a meta classifier. The developed\nclickbait detection model achieved a high accuracy of 92.89% for the novel\nBollyBAIT dataset and 95.38% for Misleading Video Dataset. Additionally, the\nstated classifier does not use meta features or other statistics dependent on\nuser interaction with the video (the number of likes, followers, or comments)\nfor classification, and thus, can be used to detect potential clickbait videos\nbefore they are uploaded, thereby preventing the nuisance of clickbaits\naltogether and improving the users streaming experience.",
    "descriptor": "\nComments: 26 pages, 16 figures\n",
    "authors": [
      "Peya Mowar",
      "Mini Jain",
      "Ruchika Goel",
      "Dinesh Kumar Vishwakarma"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.08611"
  },
  {
    "id": "arXiv:2112.08614",
    "title": "KAT: A Knowledge Augmented Transformer for Vision-and-Language",
    "abstract": "The primary focus of recent work with largescale transformers has been on\noptimizing the amount of information packed into the model's parameters. In\nthis work, we ask a different question: Can multimodal transformers leverage\nexplicit knowledge in their reasoning? Existing, primarily unimodal, methods\nhave explored approaches under the paradigm of knowledge retrieval followed by\nanswer prediction, but leave open questions about the quality and relevance of\nthe retrieved knowledge used, and how the reasoning processes over implicit and\nexplicit knowledge should be integrated. To address these challenges, we\npropose a novel model - Knowledge Augmented Transformer (KAT) - which achieves\na strong state-of-the-art result (+6 points absolute) on the open-domain\nmultimodal task of OK-VQA. Our approach integrates implicit and explicit\nknowledge in an end to end encoder-decoder architecture, while still jointly\nreasoning over both knowledge sources during answer generation. An additional\nbenefit of explicit knowledge integration is seen in improved interpretability\nof model predictions in our analysis.",
    "descriptor": "",
    "authors": [
      "Liangke Gui",
      "Borui Wang",
      "Qiuyuan Huang",
      "Alex Hauptmann",
      "Yonatan Bisk",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08614"
  },
  {
    "id": "arXiv:2112.08615",
    "title": "Commonsense Knowledge-Augmented Pretrained Language Models for Causal  Reasoning Classification",
    "abstract": "Commonsense knowledge can be leveraged for identifying causal relations in\ntext. In this work, we verbalize triples in ATOMIC2020, a wide coverage\ncommonsense reasoning knowledge graph, to natural language text and continually\npretrain a BERT pretrained language model. We evaluate the resulting model on\nanswering commonsense reasoning questions. Our results show that a continually\npretrained language model augmented with commonsense reasoning knowledge\noutperforms our baseline on two commonsense causal reasoning benchmarks, COPA\nand BCOPA-CE, without additional improvement on the base model or using\nquality-enhanced data for fine-tuning.",
    "descriptor": "",
    "authors": [
      "Pedram Hosseini",
      "David A. Broniatowski",
      "Mona Diab"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08615"
  },
  {
    "id": "arXiv:2112.08616",
    "title": "Masked Measurement Prediction: Learning to Jointly Predict Quantities  and Units from Textual Context",
    "abstract": "Physical measurements constitute a large portion of numbers in academic\npapers, engineering reports, and web tables. Current benchmarks fall short of\nproperly evaluating numeracy of pretrained language models on measurements,\nhindering research on developing new methods and applying them to numerical\ntasks. To that end, we introduce a novel task, Masked Measurement Prediction\n(MMP), where a model learns to reconstruct a number together with its\nassociated unit given masked text. MMP is useful for both training new\nnumerically informed models as well as evaluating numeracy of existing systems.\nIn order to address this task, we introduce a new Generative Masked Measurement\n(GeMM) model that jointly learns to predict numbers along with their units. We\nperform fine-grained analyses comparing our model with various ablations and\nbaselines. We use linear probing of traditional pretrained transformer models\n(RoBERTa) to show that they significantly underperform jointly trained\nnumber-unit models, highlighting the difficulty of this new task and the\nbenefits of our proposed pretraining approach. We hope this framework\naccelerates the progress towards building more robust numerical reasoning\nsystems in the future.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Daniel Spokoyny",
      "Ivan Lee",
      "Zhao Jin",
      "Taylor Berg-Kirkpatrick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08616"
  },
  {
    "id": "arXiv:2112.08618",
    "title": "A Statistics and Deep Learning Hybrid Method for Multivariate Time  Series Forecasting and Mortality Modeling",
    "abstract": "Hybrid methods have been shown to outperform pure statistical and pure deep\nlearning methods at forecasting tasks and quantifying the associated\nuncertainty with those forecasts (prediction intervals). One example is\nExponential Smoothing Recurrent Neural Network (ES-RNN), a hybrid between a\nstatistical forecasting model and a recurrent neural network variant. ES-RNN\nachieves a 9.4\\% improvement in absolute error in the Makridakis-4 Forecasting\nCompetition. This improvement and similar outperformance from other hybrid\nmodels have primarily been demonstrated only on univariate datasets.\nDifficulties with applying hybrid forecast methods to multivariate data include\n($i$) the high computational cost involved in hyperparameter tuning for models\nthat are not parsimonious, ($ii$) challenges associated with auto-correlation\ninherent in the data, as well as ($iii$) complex dependency (cross-correlation)\nbetween the covariates that may be hard to capture. This paper presents\nMultivariate Exponential Smoothing Long Short Term Memory (MES-LSTM), a\ngeneralized multivariate extension to ES-RNN, that overcomes these challenges.\nMES-LSTM utilizes a vectorized implementation. We test MES-LSTM on several\naggregated coronavirus disease of 2019 (COVID-19) morbidity datasets and find\nour hybrid approach shows consistent, significant improvement over pure\nstatistical and deep learning methods at forecast accuracy and prediction\ninterval construction.",
    "descriptor": "",
    "authors": [
      "Thabang Mathonsi",
      "Terence L. van Zyl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08618"
  },
  {
    "id": "arXiv:2112.08619",
    "title": "Call for Customized Conversation: Customized Conversation Grounding  Persona and Knowledge",
    "abstract": "Humans usually have conversations by making use of prior knowledge about a\ntopic and background information of the people whom they are talking to.\nHowever, existing conversational agents and datasets do not consider such\ncomprehensive information, and thus they have a limitation in generating the\nutterances where the knowledge and persona are fused properly. To address this\nissue, we introduce a call For Customized conversation (FoCus) dataset where\nthe customized answers are built with the user's persona and Wikipedia\nknowledge. To evaluate the abilities to make informative and customized\nutterances of pre-trained language models, we utilize BART and GPT-2 as well as\ntransformer-based models. We assess their generation abilities with automatic\nscores and conduct human evaluations for qualitative results. We examine\nwhether the model reflects adequate persona and knowledge with our proposed two\nsub-tasks, persona grounding (PG) and knowledge grounding (KG). Moreover, we\nshow that the utterances of our data are constructed with the proper knowledge\nand persona through grounding quality assessment.",
    "descriptor": "\nComments: Accepted paper at the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22)\n",
    "authors": [
      "Yoonna Jang",
      "Jungwoo Lim",
      "Yuna Hur",
      "Dongsuk Oh",
      "Suhyune Son",
      "Yeonsoo Lee",
      "Donghoon Shin",
      "Seungryong Kim",
      "Heuiseok Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08619"
  },
  {
    "id": "arXiv:2112.08626",
    "title": "Analysis and Evaluation of Kinect-based Action Recognition Algorithms",
    "abstract": "Human action recognition still exists many challenging problems such as\ndifferent viewpoints, occlusion, lighting conditions, human body size and the\nspeed of action execution, although it has been widely used in different areas.\nTo tackle these challenges, the Kinect depth sensor has been developed to\nrecord real time depth sequences, which are insensitive to the color of human\nclothes and illumination conditions. Many methods on recognizing human action\nhave been reported in the literature such as HON4D, HOPC, RBD and HDG, which\nuse the 4D surface normals, pointclouds, skeleton-based model and depth\ngradients respectively to capture discriminative information from depth videos\nor skeleton data. In this research project, the performance of four\naforementioned algorithms will be analyzed and evaluated using five benchmark\ndatasets, which cover challenging issues such as noise, change of viewpoints,\nbackground clutters and occlusions. We also implemented and improved the HDG\nalgorithm, and applied it in cross-view action recognition using the UWA3D\nMultiview Activity dataset. Moreover, we used different combinations of\nindividual feature vectors in HDG for performance evaluation. The experimental\nresults show that our improvement of HDG outperforms other three\nstate-of-the-art algorithms for cross-view action recognition.",
    "descriptor": "\nComments: Master's thesis, 22 pages\n",
    "authors": [
      "Lei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08626"
  },
  {
    "id": "arXiv:2112.08627",
    "title": "On the Use of Quality Diversity Algorithms for The Traveling Thief  Problem",
    "abstract": "In real-world optimisation, it is common to face several sub-problems\ninteracting and forming the main problem. There is an inter-dependency between\nthe sub-problems, making it impossible to solve such a problem by focusing on\nonly one component. The traveling thief problem~(TTP) belongs to this category\nand is formed by the integration of the traveling salesperson problem~(TSP) and\nthe knapsack problem~(KP). In this paper, we investigate the inter-dependency\nof the TSP and the KP by means of quality diversity~(QD) approaches. QD\nalgorithms provide a powerful tool not only to obtain high-quality solutions\nbut also to illustrate the distribution of high-performing solutions in the\nbehavioural space. We introduce a MAP-Elite based evolutionary algorithm using\nwell-known TSP and KP search operators, taking the TSP and KP score as\nbehavioural descriptor. Afterwards, we conduct comprehensive experimental\nstudies that show the usefulness of using the QD approach applied to the TTP.\nFirst, we provide insights regarding high-quality TTP solutions in the TSP/KP\nbehavioural space. Afterwards, we show that better solutions for the TTP can be\nobtained by using our QD approach and show that it can improve the best-known\nsolution for a wide range of TTP instances used for benchmarking in the\nliterature.",
    "descriptor": "",
    "authors": [
      "Adel Nikfarjam",
      "Aneta Neumann",
      "Frank Neumann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.08627"
  },
  {
    "id": "arXiv:2112.08632",
    "title": "CDRec: Cayley-Dickson Recommender",
    "abstract": "In this paper, we propose a recommendation framework named Cayley-Dickson\nRecommender. We introduce Cayley-Dickson construction which uses a recursive\nprocess to define hypercomplex algebras and their mathematical operations. We\nalso design a graph convolution operator to learn representations in the\nhypercomplex space. To the best of our knowledge, it is the first time that\nCayley-Dickson construction and graph convolution techniques have been used in\nhypercomplex recommendation. Compared with the state-of-the-art recommendation\nmethods, our method achieves superior performance on real-world datasets.",
    "descriptor": "",
    "authors": [
      "Anchen Li",
      "Bo Yang",
      "Huan Huo",
      "Farookh Hussain"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.08632"
  },
  {
    "id": "arXiv:2112.08633",
    "title": "Learning To Retrieve Prompts for In-Context Learning",
    "abstract": "In-context learning is a recent paradigm in natural language understanding,\nwhere a large pre-trained language model (LM) observes a test instance and a\nfew training examples as its input, and directly decodes the output without any\nupdate to its parameters. However, performance has been shown to strongly\ndepend on the selected training examples (termed prompt). In this work, we\npropose an efficient method for retrieving prompts for in-context learning\nusing annotated data and a LM. Given an input-output pair, we estimate the\nprobability of the output given the input and a candidate training example as\nthe prompt, and label training examples as positive or negative based on this\nprobability. We then train an efficient dense retriever from this data, which\nis used to retrieve training examples as prompts at test time. We evaluate our\napproach on three sequence-to-sequence tasks where language utterances are\nmapped to meaning representations, and find that it substantially outperforms\nprior work and multiple baselines across the board.",
    "descriptor": "",
    "authors": [
      "Ohad Rubin",
      "Jonathan Herzig",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08633"
  },
  {
    "id": "arXiv:2112.08634",
    "title": "FRUIT: Faithfully Reflecting Updated Information in Text",
    "abstract": "Textual knowledge bases such as Wikipedia require considerable effort to keep\nup to date and consistent. While automated writing assistants could potentially\nease this burden, the problem of suggesting edits grounded in external\nknowledge has been under-explored. In this paper, we introduce the novel\ngeneration task of *faithfully reflecting updated information in text*(FRUIT)\nwhere the goal is to update an existing article given new evidence. We release\nthe FRUIT-WIKI dataset, a collection of over 170K distantly supervised data\nproduced from pairs of Wikipedia snapshots, along with our data generation\npipeline and a gold evaluation set of 914 instances whose edits are guaranteed\nto be supported by the evidence. We provide benchmark results for popular\ngeneration systems as well as EDIT5 -- a T5-based approach tailored to editing\nwe introduce that establishes the state of the art. Our analysis shows that\ndeveloping models that can update articles faithfully requires new capabilities\nfor neural generation models, and opens doors to many new applications.",
    "descriptor": "\nComments: v1.0\n",
    "authors": [
      "Robert L. Logan IV",
      "Alexandre Passos",
      "Sameer Singh",
      "Ming-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08634"
  },
  {
    "id": "arXiv:2112.08635",
    "title": "Road-aware Monocular Structure from Motion and Homography Estimation",
    "abstract": "Structure from motion (SFM) and ground plane homography estimation are\ncritical to autonomous driving and other robotics applications. Recently, much\nprogress has been made in using deep neural networks for SFM and homography\nestimation respectively. However, directly applying existing methods for ground\nplane homography estimation may fail because the road is often a small part of\nthe scene. Besides, the performances of deep SFM approaches are still inferior\nto traditional methods. In this paper, we propose a method that learns to solve\nboth problems in an end-to-end manner, improving performance on both. The\nproposed networks consist of a Depth-CNN, a Pose-CNN and a Ground-CNN. The\nDepth-CNN and Pose-CNN estimate dense depth map and ego-motion respectively,\nsolving SFM, while the Pose-CNN and Ground-CNN followed by a homography layer\nsolve the ground plane estimation problem. By enforcing coherency between SFM\nand homography estimation results, the whole network can be trained end to end\nusing photometric loss and homography loss without any groundtruth except the\nroad segmentation provided by an off-the-shelf segmenter. Comprehensive\nexperiments are conducted on KITTI benchmark to demonstrate promising results\ncompared with various state-of-the-art approaches.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Wei Sui",
      "Teng Chen",
      "Jiaxin Zhang",
      "Jiao Lu",
      "Qian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08635"
  },
  {
    "id": "arXiv:2112.08637",
    "title": "Analyzing the Limits of Self-Supervision in Handling Bias in Language",
    "abstract": "Prompting inputs with natural language task descriptions has emerged as a\npopular mechanism to elicit reasonably accurate outputs from large-scale\ngenerative language models with little to no in-context supervision. This also\nhelps gain insight into how well language models capture the semantics of a\nwide range of downstream tasks purely from self-supervised pre-training on\nmassive corpora of unlabeled text. Such models have naturally also been exposed\nto a lot of undesirable content like racist and sexist language and there is\nlimited work on awareness of models along these dimensions. In this paper, we\ndefine and comprehensively evaluate how well such language models capture the\nsemantics of four tasks for bias: diagnosis, identification, extraction and\nrephrasing. We define three broad classes of task descriptions for these tasks:\nstatement, question, and completion, with numerous lexical variants within each\nclass. We study the efficacy of prompting for each task using these classes and\nthe null task description across several decoding methods and few-shot\nexamples. Our analyses indicate that language models are capable of performing\nthese tasks to widely varying degrees across different bias dimensions, such as\ngender and political affiliation. We believe our work is an important step\ntowards unbiased language models by quantifying the limits of current\nself-supervision objectives at accomplishing such sociologically challenging\ntasks.",
    "descriptor": "\nComments: 16 pages, 1 figure\n",
    "authors": [
      "Lisa Bauer",
      "Karthik Gopalakrishnan",
      "Spandana Gella",
      "Yang Liu",
      "Mohit Bansal",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08637"
  },
  {
    "id": "arXiv:2112.08638",
    "title": "Evaluating Hybrid Graph Pattern Queries Using Runtime Index Graphs",
    "abstract": "Graph pattern matching is a fundamental operation for the analysis and\nexploration ofdata graphs. In thispaper, we presenta novel approachfor\nefficiently finding homomorphic matches for hybrid graph patterns, where each\npattern edge may be mapped either to an edge or to a path in the input data,\nthus allowing for higher expressiveness and flexibility in query formulation. A\nkey component of our approach is a lightweight index structure that leverages\ngraph simulation to compactly encode the query answer search space. The index\ncan be built on-the-fly during query execution and does not have to be\npersisted to disk. Using the index, we design a multi-way join algorithm to\nenumerate query solutions without generating any potentially exploding\nintermediate results. We demonstrate through extensive experiments that our\napproach can efficiently evaluate a wide range / broad spectrum of graph\npattern queries and greatly outperforms existing approaches and recent graph\nquery engines/systems.",
    "descriptor": "",
    "authors": [
      "Xiaoying Wu",
      "Dimitri Theodoratos"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.08638"
  },
  {
    "id": "arXiv:2112.08643",
    "title": "TransZero++: Cross Attribute-Guided Transformer for Zero-Shot Learning",
    "abstract": "Zero-shot learning (ZSL) tackles the novel class recognition problem by\ntransferring semantic knowledge from seen classes to unseen ones. Existing\nattention-based models have struggled to learn inferior region features in a\nsingle image by solely using unidirectional attention, which ignore the\ntransferability and discriminative attribute localization of visual features.\nIn this paper, we propose a cross attribute-guided Transformer network, termed\nTransZero++, to refine visual features and learn accurate attribute\nlocalization for semantic-augmented visual embedding representations in ZSL.\nTransZero++ consists of an attribute$\\rightarrow$visual Transformer sub-net\n(AVT) and a visual$\\rightarrow$attribute Transformer sub-net (VAT).\nSpecifically, AVT first takes a feature augmentation encoder to alleviate the\ncross-dataset problem, and improves the transferability of visual features by\nreducing the entangled relative geometry relationships among region features.\nThen, an attribute$\\rightarrow$visual decoder is employed to localize the image\nregions most relevant to each attribute in a given image for attribute-based\nvisual feature representations. Analogously, VAT uses the similar feature\naugmentation encoder to refine the visual features, which are further applied\nin visual$\\rightarrow$attribute decoder to learn visual-based attribute\nfeatures. By further introducing semantical collaborative losses, the two\nattribute-guided transformers teach each other to learn semantic-augmented\nvisual embeddings via semantical collaborative learning. Extensive experiments\nshow that TransZero++ achieves the new state-of-the-art results on three\nchallenging ZSL benchmarks. The codes are available at:\n\\url{https://github.com/shiming-chen/TransZero_pp}.",
    "descriptor": "\nComments: This is an extention of AAAI'22 paper (TransZero). Submitted to TPAMI. arXiv admin note: substantial text overlap with arXiv:2112.01683\n",
    "authors": [
      "Shiming Chen",
      "Ziming Hong",
      "Guo-Sen Xie",
      "Jian Zhao",
      "Xinge You",
      "Shuicheng Yan",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08643"
  },
  {
    "id": "arXiv:2112.08645",
    "title": "Learning Interpretable Models Through Multi-Objective Neural  Architecture Search",
    "abstract": "Monumental advances in deep learning have led to unprecedented achievements\nacross a multitude of domains. While the performance of deep neural networks is\nindubitable, the architectural design and interpretability of such models are\nnontrivial. Research has been introduced to automate the design of neural\nnetwork architectures through neural architecture search (NAS). Recent progress\nhas made these methods more pragmatic by exploiting distributed computation and\nnovel optimization algorithms. However, there is little work in optimizing\narchitectures for interpretability. To this end, we propose a multi-objective\ndistributed NAS framework that optimizes for both task performance and\nintrospection. We leverage the non-dominated sorting genetic algorithm\n(NSGA-II) and explainable AI (XAI) techniques to reward architectures that can\nbe better comprehended by humans. The framework is evaluated on several image\nclassification datasets. We demonstrate that jointly optimizing for\nintrospection ability and task error leads to more disentangled architectures\nthat perform within tolerable error.",
    "descriptor": "",
    "authors": [
      "Zachariah Carmichael",
      "Tim Moon",
      "Sam Ade Jacobs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.08645"
  },
  {
    "id": "arXiv:2112.08647",
    "title": "QAHOI: Query-Based Anchors for Human-Object Interaction Detection",
    "abstract": "Human-object interaction (HOI) detection as a downstream of object detection\ntasks requires localizing pairs of humans and objects and extracting the\nsemantic relationships between humans and objects from an image. Recently,\none-stage approaches have become a new trend for this task due to their high\nefficiency. However, these approaches focus on detecting possible interaction\npoints or filtering human-object pairs, ignoring the variability in the\nlocation and size of different objects at spatial scales. To address this\nproblem, we propose a transformer-based method, QAHOI (Query-Based Anchors for\nHuman-Object Interaction detection), which leverages a multi-scale architecture\nto extract features from different spatial scales and uses query-based anchors\nto predict all the elements of an HOI instance. We further investigate that a\npowerful backbone significantly increases accuracy for QAHOI, and QAHOI with a\ntransformer-based backbone outperforms recent state-of-the-art methods by large\nmargins on the HICO-DET benchmark. The source code is available at\n$\\href{https://github.com/cjw2021/QAHOI}{\\text{this https URL}}$.",
    "descriptor": "",
    "authors": [
      "Junwen Chen",
      "Keiji Yanai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08647"
  },
  {
    "id": "arXiv:2112.08652",
    "title": "Extreme Zero-Shot Learning for Extreme Text Classification",
    "abstract": "The eXtreme Multi-label text Classification (XMC) problem concerns finding\nmost relevant labels for an input text instance from a large label set.\nHowever, the XMC setup faces two challenges: (1) it is not generalizable to\npredict unseen labels in dynamic environments, and (2) it requires a large\namount of supervised (instance, label) pairs, which can be difficult to obtain\nfor emerging domains. Recently, the generalized zero-shot XMC (GZ-XMC) setup\nhas been studied and ZestXML is proposed accordingly to handle the unseen\nlabels, which still requires a large number of annotated (instance, label)\npairs. In this paper, we consider a more practical scenario called Extreme\nZero-Shot XMC (EZ-XMC), in which no supervision is needed and merely raw text\nof instances and labels are accessible. Few-Shot XMC (FS-XMC), an extension to\nEZ-XMC with limited supervision is also investigated. To learn the semantic\nembeddings of instances and labels with raw text, we propose to pre-train\nTransformer-based encoders with self-supervised contrastive losses.\nSpecifically, we develop a pre-training method MACLR, which thoroughly\nleverages the raw text with techniques including Multi-scale Adaptive\nClustering, Label Regularization, and self-training with pseudo positive pairs.\nExperimental results on four public EZ-XMC datasets demonstrate that MACLR\nachieves superior performance compared to all other leading baseline methods,\nin particular with approximately 5-10% improvement in precision and recall on\naverage. Moreover, we also show that our pre-trained encoder can be further\nimproved on FS-XMC when there are a limited number of ground-truth positive\npairs in training. By fine-tuning the encoder on such a few-shot subset, MACLR\nstill outperforms other extreme classifiers significantly.",
    "descriptor": "\nComments: Our code is available at this https URL\n",
    "authors": [
      "Yuanhao Xiong",
      "Wei-Cheng Chang",
      "Cho-Jui Hsieh",
      "Hsiang-Fu Yu",
      "Inderjit Dhillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08652"
  },
  {
    "id": "arXiv:2112.08653",
    "title": "Reconsidering the Past: Optimizing Hidden States in Language Models",
    "abstract": "We present Hidden-State Optimization (HSO), a gradient-based method for\nimproving the performance of transformer language models at inference time.\nSimilar to dynamic evaluation (Krause et al., 2018), HSO computes the gradient\nof the log-probability the language model assigns to an evaluation text, but\nuses it to update the cached hidden states rather than the model parameters. We\ntest HSO with pretrained Transformer-XL and GPT-2 language models, finding\nimprovement on the WikiText103 and PG-19 datasets in terms of perplexity,\nespecially when evaluating a model outside of its training distribution. We\nalso demonstrate downstream applicability by showing gains in the recently\ndeveloped prompt-based few-shot evaluation setting, again with no extra\nparameters or training data.",
    "descriptor": "\nComments: Findings of EMNLP version\n",
    "authors": [
      "Davis Yoshida",
      "Kevin Gimpel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08653"
  },
  {
    "id": "arXiv:2112.08654",
    "title": "Learning to Prompt for Continual Learning",
    "abstract": "The mainstream paradigm behind continual learning has been to adapt the model\nparameters to non-stationary data distributions, where catastrophic forgetting\nis the central challenge. Typical methods rely on a rehearsal buffer or known\ntask identity at test time to retrieve learned knowledge and address\nforgetting, while this work presents a new paradigm for continual learning that\naims to train a more succinct memory system without accessing task identity at\ntest time. Our method learns to dynamically prompt (L2P) a pre-trained model to\nlearn tasks sequentially under different task transitions. In our proposed\nframework, prompts are small learnable parameters, which are maintained in a\nmemory space. The objective is to optimize prompts to instruct the model\nprediction and explicitly manage task-invariant and task-specific knowledge\nwhile maintaining model plasticity. We conduct comprehensive experiments under\npopular image classification benchmarks with different challenging continual\nlearning settings, where L2P consistently outperforms prior state-of-the-art\nmethods. Surprisingly, L2P achieves competitive results against rehearsal-based\nmethods even without a rehearsal buffer and is directly applicable to\nchallenging task-agnostic continual learning. Source code is available at\nhttps://github.com/google-research/l2p.",
    "descriptor": "",
    "authors": [
      "Zifeng Wang",
      "Zizhao Zhang",
      "Chen-Yu Lee",
      "Han Zhang",
      "Ruoxi Sun",
      "Xiaoqi Ren",
      "Guolong Su",
      "Vincent Perot",
      "Jennifer Dy",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08654"
  },
  {
    "id": "arXiv:2112.08655",
    "title": "Feature Distillation Interaction Weighting Network for Lightweight Image  Super-Resolution",
    "abstract": "Convolutional neural networks based single-image super-resolution (SISR) has\nmade great progress in recent years. However, it is difficult to apply these\nmethods to real-world scenarios due to the computational and memory cost.\nMeanwhile, how to take full advantage of the intermediate features under the\nconstraints of limited parameters and calculations is also a huge challenge. To\nalleviate these issues, we propose a lightweight yet efficient Feature\nDistillation Interaction Weighted Network (FDIWN). Specifically, FDIWN utilizes\na series of specially designed Feature Shuffle Weighted Groups (FSWG) as the\nbackbone, and several novel mutual Wide-residual Distillation Interaction\nBlocks (WDIB) form an FSWG. In addition, Wide Identical Residual Weighting\n(WIRW) units and Wide Convolutional Residual Weighting (WCRW) units are\nintroduced into WDIB for better feature distillation. Moreover, a Wide-Residual\nDistillation Connection (WRDC) framework and a Self-Calibration Fusion (SCF)\nunit are proposed to interact features with different scales more flexibly and\nefficiently.Extensive experiments show that our FDIWN is superior to other\nmodels to strike a good balance between model performance and efficiency. The\ncode is available at https://github.com/IVIPLab/FDIWN.",
    "descriptor": "\nComments: 9 pages, 9 figures, 4 tables\n",
    "authors": [
      "Guangwei Gao",
      "Wenjie Li",
      "Juncheng Li",
      "Fei Wu",
      "Huimin Lu",
      "Yi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.08655"
  },
  {
    "id": "arXiv:2112.08656",
    "title": "DREAM: Uncovering Mental Models behind Language Models",
    "abstract": "To what extent do language models (LMs) build \"mental models\" of a scene when\nanswering situated questions (e.g., questions about a specific ethical\ndilemma)? While cognitive science has shown that mental models play a\nfundamental role in human problem-solving, it is unclear whether the high\nquestion-answering performance of existing LMs is backed by similar model\nbuilding - and if not, whether that can explain their well-known catastrophic\nfailures. We observed that Macaw, an existing T5-based LM, when probed provides\nsomewhat useful but inadequate mental models for situational questions\n(estimated accuracy=43%, usefulness=21%, consistency=42%). We propose DREAM, a\nmodel that takes a situational question as input to produce a mental model\nelaborating the situation, without any additional task specific training data\nfor mental models. It inherits its social commonsense through distant\nsupervision from existing NLP resources. Our analysis shows that DREAM can\nproduce significantly better mental models (estimated accuracy=67%,\nusefulness=37%, consistency=71%) compared to Macaw. Finally, mental models\ngenerated by DREAM can be used as additional context for situational QA tasks.\nThis additional context improves the answer accuracy of a Macaw zero-shot model\nby between +1% and +4% (absolute) on three different datasets.",
    "descriptor": "",
    "authors": [
      "Yuling Gu",
      "Bhavana Dalvi Mishra",
      "Peter Clark"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08656"
  },
  {
    "id": "arXiv:2112.08657",
    "title": "Taming Repetition in Dialogue Generation",
    "abstract": "The wave of pre-training language models has been continuously improving the\nquality of the machine-generated conversations, however, some of the generated\nresponses still suffer from excessive repetition, sometimes repeating words\nfrom utterance, sometimes repeating words within self-generated responses, or\nboth. Inappropriate repetition of words can significantly degrade the quality\nof the generated texts. Penalized sampling is one popular solution, reducing\nthe sampling probability of existing words during inference, however, it is\nhighly vulnerable to the inappropriate setting of the static weight. Setting it\ntoo high can yield strange and unrealistic sentences while setting it too low\nmakes the task of suppressing repetition trivial. To remedy the shortcomings of\nthe above methods, we design a context-aware classifier to explicitly decide\nwhen to allow repetition and when to employ penalized sampling. Such a\nclassifier can be easily integrated with existing decoding methods, reducing\nrepetitions where appropriate while preserving the diversity of the text.\nExperimental results demonstrate that our method can generate higher quality\nand more authentic dialogues.",
    "descriptor": "\nComments: accepted by AAAI-22 W16: Dialog System Technology Challenge (DSTC10)\n",
    "authors": [
      "Yadong Xi",
      "Jiashu Pu",
      "Xiaoxi Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08657"
  },
  {
    "id": "arXiv:2112.08658",
    "title": "Revisiting Fuzzy Signatures: Towards a More Risk-Free Cryptographic  Authentication System based on Biometrics",
    "abstract": "Biometric authentication is one of the promising alternatives to standard\npassword-based authentication offering better usability and security. In this\nwork, we revisit the biometric authentication based on \"fuzzy signatures\"\nintroduced by Takahashi et al. (ACNS'15, IJIS'19). These are special types of\ndigital signatures where the secret signing key can be a \"fuzzy\" data such as\nuser's biometrics. Compared to other cryptographically secure biometric\nauthentications as those relying on fuzzy extractors, the fuzzy signature-based\nscheme provides a more attractive security guarantee. However, despite their\npotential values, fuzzy signatures have not attracted much attention owing to\ntheir theory-oriented presentations in all prior works. For instance, the\ndiscussion on the practical feasibility of the assumptions (such as the entropy\nof user biometrics), which the security of fuzzy signatures hinges on, is\ncompletely missing.\nIn this work, we revisit fuzzy signatures and show that we can indeed\nefficiently and securely implement them in practice. At a high level, our\ncontribution is threefold: (i) we provide a much simpler, more efficient, and\ndirect construction of fuzzy signature compared to prior works; (ii) we\nestablish novel statistical techniques to experimentally evaluate the\nconditions on biometrics that are required to securely instantiate fuzzy\nsignatures; and (iii) we provide experimental results using a real-world\nfinger-vein dataset to show that finger-veins from a single hand are sufficient\nto construct efficient and secure fuzzy signatures.\nOur performance analysis shows that in a practical scenario with 112-bits of\nsecurity, the size of the signature is 1256 bytes, and the running time for\nsigning/verification is only a few milliseconds.",
    "descriptor": "",
    "authors": [
      "Shuichi Katsumata",
      "Takahiro Matsuda",
      "Wataru Nakamura",
      "Kazuma Ohara",
      "Kenta Takahashi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.08658"
  },
  {
    "id": "arXiv:2112.08662",
    "title": "Construction of Differentially Private Summaries over Fully Homomorphic  Encryption",
    "abstract": "Cloud computing has garnered attention as a platform of query processing\nsystems. However, data privacy leakage is a critical problem. Chowdhury et al.\nproposed Crypt(epsilon), which executes differential privacy (DP) over\nencrypted data on two non-colluding semi-honest servers. Further, the DP index\nproposed by these authors summarizes a dataset to prevent information leakage\nwhile improving the performance. However, two problems persist: 1) the original\ndata are decrypted to apply sorting via a garbled circuit, and 2) the added\nnoise becomes large because the sorted data are partitioned with equal width,\nregardless of the data distribution. To solve these problems, we propose a new\nmethod called DP-summary that summarizes a dataset into differentially private\ndata over a homomorphic encryption without decryption, thereby enhancing data\nsecurity. Furthermore, our scheme adopts Li et al.'s data-aware and\nworkload-aware (DAWA) algorithm for the encrypted data, thereby minimizing the\nnoise caused by DP and reducing the errors of query responses. An experimental\nevaluation using torus fully homomorphic encryption (TFHE), a bit-wise fully\nhomomorphic encryption library, confirms the applicability of the proposed\nmethod, which summarized eight 16-bit data in 12.5 h. We also confirmed that\nthere was no accuracy degradation even after adopting TFHE along with the DAWA\nalgorithm.",
    "descriptor": "\nComments: Accepted at the 32nd international Conference on Database and Expert Systems Applications (DEXA2021)\n",
    "authors": [
      "S. Ushiyama",
      "T. Takahashi",
      "M. Kudo",
      "H. Yamana"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.08662"
  },
  {
    "id": "arXiv:2112.08663",
    "title": "MAVE: A Product Dataset for Multi-source Attribute Value Extraction",
    "abstract": "Attribute value extraction refers to the task of identifying values of an\nattribute of interest from product information. Product attribute values are\nessential in many e-commerce scenarios, such as customer service robots,\nproduct ranking, retrieval and recommendations. While in the real world, the\nattribute values of a product are usually incomplete and vary over time, which\ngreatly hinders the practical applications. In this paper, we introduce MAVE, a\nnew dataset to better facilitate research on product attribute value\nextraction. MAVE is composed of a curated set of 2.2 million products from\nAmazon pages, with 3 million attribute-value annotations across 1257 unique\ncategories. MAVE has four main and unique advantages: First, MAVE is the\nlargest product attribute value extraction dataset by the number of\nattribute-value examples. Second, MAVE includes multi-source representations\nfrom the product, which captures the full product information with high\nattribute coverage. Third, MAVE represents a more diverse set of attributes and\nvalues relative to what previous datasets cover. Lastly, MAVE provides a very\nchallenging zero-shot test set, as we empirically illustrate in the\nexperiments. We further propose a novel approach that effectively extracts the\nattribute value from the multi-source product information. We conduct extensive\nexperiments with several baselines and show that MAVE is an effective dataset\nfor attribute value extraction task. It is also a very challenging task on\nzero-shot attribute extraction. Data is available at {\\it\n\\url{https://github.com/google-research-datasets/MAVE}}.",
    "descriptor": "\nComments: 10 pages, 7 figures. Accepted to WSDM 2022. Dataset available at this https URL\n",
    "authors": [
      "Li Yang",
      "Qifan Wang",
      "Zac Yu",
      "Anand Kulkarni",
      "Sumit Sanghai",
      "Bin Shu",
      "Jon Elsas",
      "Bhargav Kanagal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.08663"
  },
  {
    "id": "arXiv:2112.08665",
    "title": "Joint Power-control and Antenna Selection in User-Centric Cell-Free  Systems with Mixed Resolution ADC",
    "abstract": "In this paper, we propose a scheme for the joint optimization of the user\ntransmit power and the antenna selection at the access points (AP)s of a\nuser-centric cell-free massive multiple-input-multiple-output (UC CF-mMIMO)\nsystem. We derive an approximate expression for the achievable uplink rate of\nthe users in a UC CF-mMIMO system in the presence of a mixed analog-to-digital\nconverter (ADC) resolution profile at the APs. Using the derived approximation,\nwe propose to maximize the uplink sum rate of UC CF-mMIMO systems subject to\nenergy constraints at the APs. An alternating-optimization solution is proposed\nusing binary particle swarm optimization (BPSO) and successive convex\napproximation (SCA). We also study the impact of various system parameters on\nthe performance of the system.",
    "descriptor": "",
    "authors": [
      "Shashank Shekhar",
      "Athira Subhash",
      "Muralikrishnan Srinivasan",
      "Sheetal Kalyani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.08665"
  },
  {
    "id": "arXiv:2112.08670",
    "title": "Amortized Noisy Channel Neural Machine Translation",
    "abstract": "Noisy channel models have been especially effective in neural machine\ntranslation (NMT). However, recent approaches like \"beam search and rerank\"\n(BSR) incur significant computation overhead during inference, making\nreal-world application infeasible. We aim to build an amortized noisy channel\nNMT model such that greedily decoding from it would generate translations that\nmaximize the same reward as translations generated using BSR. We attempt three\napproaches: knowledge distillation, 1-step-deviation imitation learning, and Q\nlearning. The first approach obtains the noisy channel signal from a\npseudo-corpus, and the latter two approaches aim to optimize toward a\nnoisy-channel MT reward directly. All three approaches speed up inference by\n1-2 orders of magnitude. For all three approaches, the generated translations\nfail to achieve rewards comparable to BSR, but the translation quality\napproximated by BLEU is similar to the quality of BSR-produced translations.",
    "descriptor": "",
    "authors": [
      "Richard Yuanzhe Pang",
      "He He",
      "Kyunghyun Cho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08670"
  },
  {
    "id": "arXiv:2112.08673",
    "title": "Intelligent Bearing Fault Diagnosis Method Combining Mixed Input and  Hybrid CNN-MLP model",
    "abstract": "Rolling bearings are one of the most widely used bearings in industrial\nmachines. Deterioration in the condition of rolling bearings can result in the\ntotal failure of rotating machinery. AI-based methods are widely applied in the\ndiagnosis of rolling bearings. Hybrid NN-based methods have been shown to\nachieve the best diagnosis results. Typically, raw data is generated from\naccelerometers mounted on the machine housing. However, the diagnostic utility\nof each signal is highly dependent on the location of the corresponding\naccelerometer. This paper proposes a novel hybrid CNN-MLP model-based\ndiagnostic method which combines mixed input to perform rolling bearing\ndiagnostics. The method successfully detects and localizes bearing defects\nusing acceleration data from a shaft-mounted wireless acceleration sensor. The\nexperimental results show that the hybrid model is superior to the CNN and MLP\nmodels operating separately, and can deliver a high detection accuracy of 99,6%\nfor the bearing faults compared to 98% for CNN and 81% for MLP models.",
    "descriptor": "",
    "authors": [
      "V. Sinitsin",
      "O. Ibryaeva",
      "V. Sakovskaya",
      "V. Eremeeva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08673"
  },
  {
    "id": "arXiv:2112.08674",
    "title": "Reframing Human-AI Collaboration for Generating Free-Text Explanations",
    "abstract": "Large language models are increasingly capable of generating fluent-appearing\ntext with relatively little task-specific supervision. But can these models\naccurately explain classification decisions? We consider the task of generating\nfree-text explanations using a small number of human-written examples (i.e., in\na few-shot manner). We find that (1) authoring higher-quality examples for\nprompting results in higher quality generations; and (2) surprisingly, in a\nhead-to-head comparison, crowdworkers often prefer explanations generated by\nGPT-3 to crowdsourced human-written explanations contained within existing\ndatasets. Crowdworker ratings also show, however, that while models produce\nfactual, grammatical, and sufficient explanations, they have room to improve,\ne.g., along axes such as providing novel information and supporting the label.\nWe create a pipeline that combines GPT-3 with a supervised filter that\nincorporates humans-in-the-loop via binary acceptability judgments. Despite\nsignificant subjectivity intrinsic to judging acceptability, our approach is\nable to consistently filter GPT-3 generated explanations deemed acceptable by\nhumans.",
    "descriptor": "\nComments: 10 pages main; 13 pages appendix\n",
    "authors": [
      "Sarah Wiegreffe",
      "Jack Hessel",
      "Swabha Swayamdipta",
      "Mark Riedl",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08674"
  },
  {
    "id": "arXiv:2112.08676",
    "title": "Machine Learning-Accelerated Computational Solid Mechanics: Application  to Linear Elasticity",
    "abstract": "This work presents a novel physics-informed deep learning based\nsuper-resolution framework to reconstruct high-resolution deformation fields\nfrom low-resolution counterparts, obtained from coarse mesh simulations or\nexperiments. We leverage the governing equations and boundary conditions of the\nphysical system to train the model without using any high-resolution labeled\ndata. The proposed approach is applied to obtain the super-resolved deformation\nfields from the low-resolution stress and displacement fields obtained by\nrunning simulations on a coarse mesh for a body undergoing linear elastic\ndeformation. We demonstrate that the super-resolved fields match the accuracy\nof an advanced numerical solver running at 400 times the coarse mesh\nresolution, while simultaneously satisfying the governing laws. A brief\nevaluation study comparing the performance of two deep learning based\nsuper-resolution architectures is also presented.",
    "descriptor": "\nComments: Accepted in 1st Annual AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE). this https URL\n",
    "authors": [
      "Rajat Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2112.08676"
  },
  {
    "id": "arXiv:2112.08678",
    "title": "Asymptotically Optimal Golay-ZCZ Sequence Sets with Flexible Length",
    "abstract": "Zero correlation zone (ZCZ) sequences and Golay complementary sequences are\ntwo kinds of sequences with different preferable correlation properties.\nGolay-ZCZ sequences are special kinds of complementary sequences which also\npossess a large ZCZ and are good candidates for pilots in OFDM systems. Known\nGolay-ZCZ sequences reported in the literature have a limitation in the length\nwhich is the form of a power of 2. In this paper, we propose two constructions\nof Golay-ZCZ sequence sets with new parameters which generalize the\nconstructions of Gong et al. (IEEE Transaction on Communications 61(9), 2013)\nand Chen et al (IEEE Transaction on Communications 61(9), 2018). Notably, one\nof the constructions results in optimal binary Golay-ZCZ sequences, while the\nother results in asymptotically optimal polyphase Golay-ZCZ sequences as the\nnumber of sequences increases.",
    "descriptor": "\nComments: There are some cross between the paper with arXiv:2108.05657v2\n",
    "authors": [
      "Zhi Gu",
      "Zhengchun Zhou",
      "Avik Ranjan Adhikary",
      "Yanghe Feng",
      "Pingzhi Fan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.08678"
  },
  {
    "id": "arXiv:2112.08679",
    "title": "Graph Augmentation-Free Contrastive Learning for Recommendation",
    "abstract": "Contrastive learning (CL) recently has received considerable attention in the\nfield of recommendation, since it can greatly alleviate the data sparsity issue\nand improve recommendation performance in a self-supervised manner. A typical\nway to apply CL to recommendation is conducting edge/node dropout on the\nuser-item bipartite graph to augment the graph data and then maximizing the\ncorrespondence between representations of the same user/item augmentations\nunder a joint optimization setting. Despite the encouraging results brought by\nCL, however, what underlies the performance gains still remains unclear. In\nthis paper, we first experimentally demystify that the uniformity of the\nlearned user/item representation distributions on the unit hypersphere is\nclosely related to the recommendation performance. Based on the experimental\nfindings, we propose a graph augmentation-free CL method to simply adjust the\nuniformity by adding uniform noises to the original representations for data\naugmentations, and enhance recommendation from a geometric view. Specifically,\nthe constant graph perturbation during training is not required in our method\nand hence the positive and negative samples for CL can be generated on-the-fly.\nThe experimental results on three benchmark datasets demonstrate that the\nproposed method has distinct advantages over its graph augmentation-based\ncounterparts in terms of both the ability to improve recommendation performance\nand the running/convergence speed. The code is released at\nhttps://github.com/Coder-Yu/QRec.",
    "descriptor": "",
    "authors": [
      "Junliang Yu",
      "Hongzhi Yin",
      "Xin Xia",
      "Lizhen Cui",
      "Quoc Viet Hung Nguyen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.08679"
  },
  {
    "id": "arXiv:2112.08682",
    "title": "IsometricMT: Neural Machine Translation for Automatic Dubbing",
    "abstract": "Automatic dubbing (AD) is among the use cases where translations should fit a\ngiven length template in order to achieve synchronicity between source and\ntarget speech. For neural machine translation (MT), generating translations of\nlength close to the source length (e.g. within +-10% in character count), while\npreserving quality is a challenging task. Controlling NMT output length comes\nat a cost to translation quality which is usually mitigated with a two step\napproach of generation of n-best hypotheses and then re-ranking them based on\nlength and quality. This work, introduces a self-learning approach that allows\na transformer model to directly learn to generate outputs that closely match\nthe source length, in short isometric MT. In particular, our approach for\nisometric MT does not require to generate multiple hypotheses nor any auxiliary\nscoring function. We report results on four language pairs (English - French,\nItalian, German, Spanish) with a publicly available benchmark based on TED Talk\ndata. Both automatic and manual evaluations show that our self-learning\napproach to performs on par with more complex isometric MT approaches.",
    "descriptor": "\nComments: Submitted to IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2022\n",
    "authors": [
      "Surafel M. Lakew",
      "Yogesh Virkar",
      "Prashant Mathur",
      "Marcello Federico"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08682"
  },
  {
    "id": "arXiv:2112.08684",
    "title": "META: Mimicking Embedding via oThers' Aggregation for Generalizable  Person Re-identification",
    "abstract": "Domain generalizable (DG) person re-identification (ReID) aims to test across\nunseen domains without access to the target domain data at training time, which\nis a realistic but challenging problem. In contrast to methods assuming an\nidentical model for different domains, Mixture of Experts (MoE) exploits\nmultiple domain-specific networks for leveraging complementary information\nbetween domains, obtaining impressive results. However, prior MoE-based DG ReID\nmethods suffer from a large model size with the increase of the number of\nsource domains, and most of them overlook the exploitation of domain-invariant\ncharacteristics. To handle the two issues above, this paper presents a new\napproach called Mimicking Embedding via oThers' Aggregation (META) for DG ReID.\nTo avoid the large model size, experts in META do not add a branch network for\neach source domain but share all the parameters except for the batch\nnormalization layers. Besides multiple experts, META leverages Instance\nNormalization (IN) and introduces it into a global branch to pursue invariant\nfeatures across domains. Meanwhile, META considers the relevance of an unseen\ntarget sample and source domains via normalization statistics and develops an\naggregation network to adaptively integrate multiple experts for mimicking\nunseen target domain. Benefiting from a proposed consistency loss and an\nepisodic training algorithm, we can expect META to mimic embedding for a truly\nunseen target domain. Extensive experiments verify that META surpasses\nstate-of-the-art DG ReID methods by a large margin.",
    "descriptor": "",
    "authors": [
      "Boqiang Xu",
      "Jian Liang",
      "Lingxiao He",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08684"
  },
  {
    "id": "arXiv:2112.08686",
    "title": "Ruta: Dis-aggregated routing system over multi-cloud",
    "abstract": "Over the years, the SDN evolution create multiple overlay technologies which\nis inefficient and hard to deploy end-to-end traffic engineering services, Ruta\nis designed as an unified encapsulation with Segment Routing, Crypto and\nNAT-Traversal capabilities over UDP.\nRuta could be deployed as a cloud native SDN platform globally over\nmulti-cloud and integrated with each applications on transport layer, which\nprovide nearly zero loss and almost less than 200ms latency to access anywhere\nin the world over internet.",
    "descriptor": "",
    "authors": [
      "Kevin Fang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.08686"
  },
  {
    "id": "arXiv:2112.08688",
    "title": "Evidentiality-guided Generation for Knowledge-Intensive NLP Tasks",
    "abstract": "Retrieval-augmented generation models have shown state-of-the-art performance\nacross many knowledge-intensive NLP tasks such as open question answering and\nfact verification. These models are trained to generate the final output given\nthe retrieved passages, which can be irrelevant to the original query, leading\nto learning spurious cues or answer memorization. This work introduces a method\nto incorporate evidentiality of passages -- whether a passage contains correct\nevidence to support the output -- into training the generator. We introduce a\nmulti-task learning framework to jointly generate the final output and predict\nthe evidentiality of each passage, leveraging a new task-agnostic method to\nobtain {\\it silver} evidentiality labels for supervision. Our experiments on\nfive datasets across three knowledge-intensive tasks show that our new\nevidentiality-guided generator significantly outperforms its direct counterpart\nwith the same-size model and advances the state of the art on FaVIQ-Ambig. We\nattribute these improvements to both the auxiliary multi-task learning and\nsilver evidentiality mining techniques.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Akari Asai",
      "Matt Gardner",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08688"
  },
  {
    "id": "arXiv:2112.08691",
    "title": "Towards Robust Neural Image Compression: Adversarial Attack and Model  Finetuning",
    "abstract": "Deep neural network based image compression has been extensively studied.\nModel robustness is largely overlooked, though it is crucial to service\nenabling. We perform the adversarial attack by injecting a small amount of\nnoise perturbation to original source images, and then encode these adversarial\nexamples using prevailing learnt image compression models. Experiments report\nsevere distortion in the reconstruction of adversarial examples, revealing the\ngeneral vulnerability of existing methods, regardless of the settings used in\nunderlying compression model (e.g., network architecture, loss function,\nquality scale) and optimization strategy used for injecting perturbation (e.g.,\nnoise threshold, signal distance measurement). Later, we apply the iterative\nadversarial finetuning to refine pretrained models. In each iteration, random\nsource images and adversarial examples are mixed to update underlying model.\nResults show the effectiveness of the proposed finetuning strategy by\nsubstantially improving the compression model robustness. Overall, our\nmethodology is simple, effective, and generalizable, making it attractive for\ndeveloping robust learnt image compression solution. All materials have been\nmade publicly accessible at https://njuvision.github.io/RobustNIC for\nreproducible research.",
    "descriptor": "",
    "authors": [
      "Tong Chen",
      "Zhan Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.08691"
  },
  {
    "id": "arXiv:2112.08692",
    "title": "Lacuna Reconstruction: Self-supervised Pre-training for Low-Resource  Historical Document Transcription",
    "abstract": "We present a self-supervised pre-training approach for learning rich visual\nlanguage representations for both handwritten and printed historical document\ntranscription. After supervised fine-tuning of our pre-trained encoder\nrepresentations for low-resource document transcription on two languages, (1) a\nheterogeneous set of handwritten Islamicate manuscript images and (2) early\nmodern English printed documents, we show a meaningful improvement in\nrecognition accuracy over the same supervised model trained from scratch with\nas few as 30 line image transcriptions for training. Our masked language\nmodel-style pre-training strategy, where the model is trained to be able to\nidentify the true masked visual representation from distractors sampled from\nwithin the same line, encourages learning robust contextualized language\nrepresentations invariant to scribal writing style and printing noise present\nacross documents.",
    "descriptor": "",
    "authors": [
      "Nikolai Vogler",
      "Jonathan Parkes Allen",
      "Matthew Thomas Miller",
      "Taylor Berg-Kirkpatrick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08692"
  },
  {
    "id": "arXiv:2112.08693",
    "title": "Helmholtz equation and non-singular boundary elements applied to  multi-disciplinary physical problems",
    "abstract": "The famous scientist Hermann von Helmholtz was born 200 years ago. Many\ncomplex physical wave phenomena in engineering can effectively be described\nusing one or a set of equations named after him: the Helmholtz equation.\nAlthough this has been known for a long time from a theoretical point of view,\nthe actual numerical implementation has often been hindered by divergence free\nand/or curl free constraints. There is further a need for a numerical method\nwhich is accurate, reliable and takes into account radiation conditions at\ninfinity. The classical boundary element method (BEM) satisfies the last\ncondition, yet one has to deal with singularities in the implementation. Since\nthese singularities are mathematical in origin, they can actually be removed\nwithout losing accuracy by subtracting a carefully chosen theoretical solution\nwith the same singular behavior. We review here how a recently developed\nsingularity-free 3D boundary element framework with superior accuracy can be\nused to tackle such problems only using one or more Helmholtz equations with\nhigher order (quadratic) elements which can tackle complex shapes. Examples are\ngiven for acoustics (a Helmholtz resonator among others) and electromagnetic\nscattering. We briefly touch on the Helmholtz decomposition for dynamic elastic\nwaves as well.",
    "descriptor": "",
    "authors": [
      "Evert Klaseboer",
      "Qiang Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Physics (physics.class-ph)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2112.08693"
  },
  {
    "id": "arXiv:2112.08696",
    "title": "Few-Shot Semantic Parsing with Language Models Trained On Code",
    "abstract": "Large language models, prompted with in-context examples, can perform\nsemantic parsing with little training data. They do better when we formulate\nthe problem as paraphrasing into canonical utterances, which cast the\nunderlying meaning representations into a controlled natural language-like\nrepresentation. Intuitively, such models can more easily output canonical\nutterances as they are closer to the natural language used for pre-training.\nMore recently, models also pre-trained on code, like OpenAI Codex, have risen\nin prominence. Since accurately modeling code requires understanding of\nexecutable semantics. such models may prove more adept at semantic parsing. In\nthis paper, we test this hypothesis and find that Codex performs better at\nsemantic parsing than equivalent GPT-3 models. We find that unlike GPT-3, Codex\nperforms similarly when targeting meaning representations directly, perhaps as\nmeaning representations used in semantic parsing are structured similar to\ncode.",
    "descriptor": "",
    "authors": [
      "Richard Shin",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08696"
  },
  {
    "id": "arXiv:2112.08702",
    "title": "Learning to Share in Multi-Agent Reinforcement Learning",
    "abstract": "In this paper, we study the problem of networked multi-agent reinforcement\nlearning (MARL), where a number of agents are deployed as a partially connected\nnetwork and each interacts only with nearby agents. Networked MARL requires all\nagents make decision in a decentralized manner to optimize a global objective\nwith restricted communication between neighbors over the network. Inspired by\nthe fact that \\textit{sharing} plays a key role in human's learning of\ncooperation, we propose LToS, a hierarchically decentralized MARL framework\nthat enables agents to learn to dynamically share reward with neighbors so as\nto encourage agents to cooperate on the global objective. For each agent, the\nhigh-level policy learns how to share reward with neighbors to decompose the\nglobal objective, while the low-level policy learns to optimize local objective\ninduced by the high-level policies in the neighborhood. The two policies form a\nbi-level optimization and learn alternately. We empirically demonstrate that\nLToS outperforms existing methods in both social dilemma and networked MARL\nscenario.",
    "descriptor": "",
    "authors": [
      "Yuxuan Yi",
      "Ge Li",
      "Yaowei Wang",
      "Zongqing Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.08702"
  },
  {
    "id": "arXiv:2112.08703",
    "title": "ADEPT: Automatic Differentiable DEsign of Photonic Tensor Cores",
    "abstract": "Photonic tensor cores (PTCs) are essential building blocks for optical\nartificial intelligence (AI) accelerators based on programmable photonic\nintegrated circuits. PTCs can achieve ultra-fast and efficient tensor\noperations for neural network (NN) acceleration. Current PTC designs are either\nmanually constructed or based on matrix decomposition theory, which lacks the\nadaptability to meet various hardware constraints and device specifications. To\nour best knowledge, automatic PTC design methodology is still unexplored. It\nwill be promising to move beyond the manual design paradigm and \"nurture\"\nphotonic neurocomputing with AI and design automation. Therefore, in this work,\nfor the first time, we propose a fully differentiable framework, dubbed ADEPT,\nthat can efficiently search PTC designs adaptive to various circuit footprint\nconstraints and foundry PDKs. Extensive experiments show superior flexibility\nand effectiveness of the proposed ADEPT framework to explore a large PTC design\nspace. On various NN models and benchmarks, our searched PTC topology\noutperforms prior manually-designed structures with competitive matrix\nrepresentability, 2x-30x higher footprint compactness, and better noise\nrobustness, demonstrating a new paradigm in photonic neural chip design.",
    "descriptor": "",
    "authors": [
      "Jiaqi Gu",
      "Hanqing Zhu",
      "Chenghao Feng",
      "Zixuan Jiang",
      "Mingjie Liu",
      "Shuhan Zhang",
      "Ray T. Chen",
      "David Z. Pan"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2112.08703"
  },
  {
    "id": "arXiv:2112.08705",
    "title": "Bent Functions in the Partial Spread Class Generated by Linear Recurring  Sequences",
    "abstract": "We present a construction of partial spread bent functions using subspaces\ngenerated by linear recurring sequences (LRS). We first show that the kernels\nof the linear mappings defined by two LRS have a trivial intersection if and\nonly if their feedback polynomials are relatively prime. Then, we characterize\nthe appropriate parameters for a family of pairwise coprime polynomials to\ngenerate a partial spread required for the support of a bent function, showing\nthat such families exist if and only if the degrees of the underlying\npolynomials is either $1$ or $2$. We then count the resulting sets of\npolynomials and prove that for degree $1$, our LRS construction coincides with\nthe Desarguesian partial spread. Finally, we perform a computer search of all\n$\\mathcal{PS}^-$ and $\\mathcal{PS}^+$ bent functions of $n=8$ variables\ngenerated by our construction and compute their 2-ranks. The results show that\nmany of these functions defined by polynomials of degree $b=2$ are not\nEA-equivalent to any Maiorana-McFarland or Desarguesian partial spread\nfunction.",
    "descriptor": "\nComments: Completely revised version of \"Bent functions from Cellular Automata\" published in the Cryptology ePrint Archive. The construction here is described with linear recurring sequences instead of cellular automata, with new results. The original version in the ePrint archive is a standalone work discussing the connections between CA, Hadamard matrices, bent functions and orthogonal arrays\n",
    "authors": [
      "Maximilien Gadouleau",
      "Luca Mariot",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.08705"
  },
  {
    "id": "arXiv:2112.08706",
    "title": "Forecasting sales with Bayesian networks: a case study of a supermarket  product in the presence of promotions",
    "abstract": "Sales forecasting is the prerequisite for a lot of managerial decisions such\nas production planning, material resource planning and budgeting in the supply\nchain. Promotions are one of the most important business strategies that are\noften used to boost sales. While promotions are attractive for generating\ndemand, it is often difficult to forecast demand in their presence. In the past\nfew decades, several quantitative models have been developed to forecast sales\nincluding statistical and machine learning models. However, these methods may\nnot be adequate to account for all the internal and external factors that may\nimpact sales. As a result, qualitative models have been adopted along with\nquantitative methods as consulting experts has been proven to improve forecast\naccuracy by providing contextual information. Such models are being used\nextensively to account for factors that can lead to a rapid change in sales,\nsuch as during promotions. In this paper, we aim to use Bayesian Networks to\nforecast promotional sales where a combination of factors such as price, type\nof promotions, and product location impacts sales. We choose to develop a BN\nmodel because BN models essentially have the capability to combine various\nqualitative and quantitative factors with causal forms, making it an attractive\ntool for sales forecasting during promotions. This can be used to adjust a\ncompany's promotional strategy in the context of this case study. We gather\nsales data for a particular product from a retailer that sells products in\nAustralia. We develop a Bayesian Network for this product and validate our\nresults by empirical analysis. This paper confirms that BNs can be effectively\nused to forecast sales, especially during promotions. In the end, we provide\nsome research avenues for using BNs in forecasting sales.",
    "descriptor": "",
    "authors": [
      "Muhammad Hamza",
      "Mahdi Abolghasemi",
      "Abraham Oshni Alvandi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08706"
  },
  {
    "id": "arXiv:2112.08709",
    "title": "DOCmT5: Document-Level Pretraining of Multilingual Language Models",
    "abstract": "In this paper, we introduce DOCmT5, a multilingual sequence-to-sequence\nlanguage model pre-trained with large scale parallel documents. While previous\napproaches have focused on leveraging sentence-level parallel data, we try to\nbuild a general-purpose pre-trained model that can understand and generate long\ndocuments. We propose a simple and effective pre-training objective - Document\nReordering Machine Translation (DrMT), in which the input documents that are\nshuffled and masked need to be translated. DrMT brings consistent improvements\nover strong baselines on a variety of document-level generation tasks,\nincluding over 12 BLEU points for seen-language-pair document-level MT, over 7\nBLEU points for unseen-language-pair document-level MT and over 3 ROUGE-1\npoints for seen-language-pair cross-lingual summarization. We achieve\nstate-of-the-art (SOTA) on WMT20 De-En and IWSLT15 Zh-En document translation\ntasks. We also conduct extensive analysis on various factors for document\npre-training, including (1) the effects of pre-training data quality and (2)\nThe effects of combining mono-lingual and cross-lingual pre-training. We plan\nto make our model checkpoints publicly available.",
    "descriptor": "",
    "authors": [
      "Chia-Hsuan Lee",
      "Aditya Siddhant",
      "Viresh Ratnakar",
      "Melvin Johnson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08709"
  },
  {
    "id": "arXiv:2112.08713",
    "title": "CONFIT: Toward Faithful Dialogue Summarization with  Linguistically-Informed Contrastive Fine-tuning",
    "abstract": "Factual inconsistencies in generated summaries severely limit the practical\napplications of abstractive dialogue summarization. Although significant\nprogress has been achieved by using pre-trained models, substantial amounts of\nhallucinated content are found during the human evaluation. Pre-trained models\nare most commonly fine-tuned with cross-entropy loss for text summarization,\nwhich may not be an optimal strategy. In this work, we provide a typology of\nfactual errors with annotation data to highlight the types of errors and move\naway from a binary understanding of factuality. We further propose a training\nstrategy that improves the factual consistency and overall quality of summaries\nvia a novel contrastive fine-tuning, called ConFiT. Based on our\nlinguistically-informed typology of errors, we design different modular\nobjectives that each target a specific type. Specifically, we utilize hard\nnegative samples with errors to reduce the generation of factual inconsistency.\nIn order to capture the key information between speakers, we also design a\ndialogue-specific loss. Using human evaluation and automatic faithfulness\nmetrics, we show that our model significantly reduces all kinds of factual\nerrors on the dialogue summarization, SAMSum corpus. Moreover, our model could\nbe generalized to the meeting summarization, AMI corpus, and it produces\nsignificantly higher scores than most of the baselines on both datasets\nregarding word-overlap metrics.",
    "descriptor": "",
    "authors": [
      "Xiangru Tang",
      "Arjun Nair",
      "Borui Wang",
      "Bingyao Wang",
      "Jai Desai",
      "Aaron Wade",
      "Haoran Li",
      "Asli Celikyilmaz",
      "Yashar Mehdad",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08713"
  },
  {
    "id": "arXiv:2112.08717",
    "title": "GIMIRec: Global Interaction Information Aware Multi-Interest Framework  for Sequential Recommendation",
    "abstract": "Sequential recommendation based on multi-interest framework models the user's\nrecent interaction sequence into multiple different interest vectors, since a\nsingle low-dimensional vector cannot fully represent the diversity of user\ninterests. However, most existing models only intercept users' recent\ninteraction behaviors as training data, discarding a large amount of historical\ninteraction sequences. This may raise two issues. On the one hand, data\nreflecting multiple interests of users is missing; on the other hand, the\nco-occurrence between items in historical user-item interactions is not fully\nexplored. To tackle the two issues, this paper proposes a novel sequential\nrecommendation model called \"Global Interaction Aware Multi-Interest Framework\nfor Sequential Recommendation (GIMIRec)\". Specifically, a global context\nextraction module is firstly proposed without introducing any external\ninformation, which calculates a weighted co-occurrence matrix based on the\nconstrained co-occurrence number of each item pair and their time interval from\nthe historical interaction sequences of all users and then obtains the global\ncontext embedding of each item by using a simplified graph convolution.\nSecondly, the time interval of each item pair in the recent interaction\nsequence of each user is captured and combined with the global context item\nembedding to get the personalized item embedding. Finally, a self-attention\nbased multi-interest framework is applied to learn the diverse interests of\nusers for sequential recommendation. Extensive experiments on the three\nreal-world datasets of Amazon-Books, Taobao-Buy and Amazon-Hybrid show that the\nperformance of GIMIRec on the Recall, NDCG and Hit Rate indicators is\nsignificantly superior to that of the state-of-the-art methods. Moreover, the\nproposed global context extraction module can be easily transplanted to most\nsequential recommendation models.",
    "descriptor": "",
    "authors": [
      "Jie Zhang",
      "Ke-Jia Chen",
      "Jingqiang Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08717"
  },
  {
    "id": "arXiv:2112.08718",
    "title": "Domain Prompts: Towards memory and compute efficient domain adaptation  of ASR systems",
    "abstract": "Automatic Speech Recognition (ASR) systems have found their use in numerous\nindustrial applications in very diverse domains. Since domain-specific systems\nperform better than their generic counterparts on in-domain evaluation, the\nneed for memory and compute-efficient domain adaptation is obvious.\nParticularly, adapting parameter-heavy transformer-based language models used\nfor rescoring ASR hypothesis is challenging. In this work, we introduce\ndomain-prompts, a methodology that trains a small number of domain token\nembedding parameters to prime a transformer-based LM to a particular domain.\nWith just a handful of extra parameters per domain, we achieve 7-14% WER\nimprovement over the baseline of using an unadapted LM. Despite being\nparameter-efficient, these improvements are comparable to those of\nfully-fine-tuned models with hundreds of millions of parameters. With ablations\non prompt-sizes, dataset sizes, initializations and domains, we provide\nevidence for the benefits of using domain-prompts in ASR systems.",
    "descriptor": "\nComments: 4 pages ICASSP submission\n",
    "authors": [
      "Saket Dingliwal",
      "Ashish Shenoy",
      "Sravan Bodapati",
      "Ankur Gandhe",
      "Ravi Teja Gadde",
      "Katrin Kirchhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08718"
  },
  {
    "id": "arXiv:2112.08720",
    "title": "Improvement of Indoor Radio Coverage at 60 GHz in NLOS Configuration",
    "abstract": "In the current development of new technologies, the world of communications\nis experiencing significant growth thanks to the integration of wireless\ncommunications in millimeter band. In this context, the purpose of this paper\nis to assess the contribution that the use of a metallic reflector panel can\nintroduce to indoor radio coverage at 60 GHz in an NLOS (corridor)\nconfiguration. The results obtained by measurement show that the use of such a\npanel can lead to a significant path loss reduction up to 12 dB, which improves\nthe reception power.",
    "descriptor": "\nComments: 2021 IEEE Conference on Antenna Measurements & Applications (CAMA), Nov 2021, Antibes Juan-les-Pins, France\n",
    "authors": [
      "Mbissane Dieng",
      "El Hajj",
      "Gheorghe Zaharia",
      "Ghais El"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.08720"
  },
  {
    "id": "arXiv:2112.08723",
    "title": "Distilled Dual-Encoder Model for Vision-Language Understanding",
    "abstract": "We propose a cross-modal attention distillation framework to train a\ndual-encoder model for vision-language understanding tasks, such as visual\nreasoning and visual question answering. Dual-encoder models have a faster\ninference speed than fusion-encoder models and enable the pre-computation of\nimages and text during inference. However, the shallow interaction module used\nin dual-encoder models is insufficient to handle complex vision-language\nunderstanding tasks. In order to learn deep interactions of images and text, we\nintroduce cross-modal attention distillation, which uses the image-to-text and\ntext-to-image attention distributions of a fusion-encoder model to guide the\ntraining of our dual-encoder model. In addition, we show that applying the\ncross-modal attention distillation for both pre-training and fine-tuning stages\nachieves further improvements. Experimental results demonstrate that the\ndistilled dual-encoder model achieves competitive performance for visual\nreasoning, visual entailment and visual question answering tasks while enjoying\na much faster inference speed than fusion-encoder models. Our code and models\nwill be publicly available at https://github.com/kugwzk/Distilled-DualEncoder.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Zekun Wang",
      "Wenhui Wang",
      "Haichao Zhu",
      "Ming Liu",
      "Bing Qin",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08723"
  },
  {
    "id": "arXiv:2112.08726",
    "title": "NeuroLogic A*esque Decoding: Constrained Text Generation with Lookahead  Heuristics",
    "abstract": "The dominant paradigm for neural text generation is left-to-right decoding\nfrom autoregressive language models. Constrained or controllable generation\nunder complex lexical constraints, however, requires foresight to plan ahead\nfeasible future paths.\nDrawing inspiration from the A* search algorithm, we propose NeuroLogic\nA*esque, a decoding algorithm that incorporates heuristic estimates of future\ncost. We develop efficient lookahead heuristics that are efficient for\nlarge-scale language models, making our method a drop-in replacement for common\ntechniques such as beam search and top-k sampling. To enable constrained\ngeneration, we build on NeuroLogic decoding (Lu et al., 2021), combining its\nflexibility in incorporating logical constraints with A*esque estimates of\nfuture constraint satisfaction.\nOur approach outperforms competitive baselines on five generation tasks, and\nachieves new state-of-the-art performance on table-to-text generation,\nconstrained machine translation, and keyword-constrained generation. The\nimprovements are particularly notable on tasks that require complex constraint\nsatisfaction or in few-shot or zero-shot settings. NeuroLogic A*esque\nillustrates the power of decoding for improving and enabling new capabilities\nof large-scale language models.",
    "descriptor": "",
    "authors": [
      "Ximing Lu",
      "Sean Welleck",
      "Peter West",
      "Liwei Jiang",
      "Jungo Kasai",
      "Daniel Khashabi",
      "Ronan Le Bras",
      "Lianhui Qin",
      "Youngjae Yu",
      "Rowan Zellers",
      "Noah A. Smith",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08726"
  },
  {
    "id": "arXiv:2112.08733",
    "title": "Self-Supervised Dynamic Graph Representation Learning via Temporal  Subgraph Contrast",
    "abstract": "Self-supervised learning on graphs has recently drawn a lot of attention due\nto its independence from labels and its robustness in representation. Current\nstudies on this topic mainly use static information such as graph structures\nbut cannot well capture dynamic information such as timestamps of edges.\nRealistic graphs are often dynamic, which means the interaction between nodes\noccurs at a specific time. This paper proposes a self-supervised dynamic graph\nrepresentation learning framework (DySubC), which defines a temporal subgraph\ncontrastive learning task to simultaneously learn the structural and\nevolutional features of a dynamic graph. Specifically, a novel temporal\nsubgraph sampling strategy is firstly proposed, which takes each node of the\ndynamic graph as the central node and uses both neighborhood structures and\nedge timestamps to sample the corresponding temporal subgraph. The subgraph\nrepresentation function is then designed according to the influence of\nneighborhood nodes on the central node after encoding the nodes in each\nsubgraph. Finally, the structural and temporal contrastive loss are defined to\nmaximize the mutual information between node representation and temporal\nsubgraph representation. Experiments on five real-world datasets demonstrate\nthat (1) DySubC performs better than the related baselines including two graph\ncontrastive learning models and four dynamic graph representation learning\nmodels in the downstream link prediction task, and (2) the use of temporal\ninformation can not only sample more effective subgraphs, but also learn better\nrepresentation by temporal contrastive loss.",
    "descriptor": "",
    "authors": [
      "Linpu Jiang",
      "Ke-Jia Chen",
      "Jingqiang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08733"
  },
  {
    "id": "arXiv:2112.08735",
    "title": "Pay More Attention to History: A Context Modeling Strategy for  Conversational Text-to-SQL",
    "abstract": "Conversational text-to-SQL aims at converting multi-turn natural language\nqueries into their corresponding SQL representations. One of the most\nintractable problem of conversational text-to-SQL is modeling the semantics of\nmulti-turn queries and gathering proper information required for the current\nquery. This paper shows that explicit modeling the semantic changes by adding\neach turn and the summarization of the whole context can bring better\nperformance on converting conversational queries into SQLs. In particular, we\npropose two conversational modeling tasks in both turn grain and conversation\ngrain. These two tasks simply work as auxiliary training tasks to help with\nmulti-turn conversational semantic parsing. We conducted empirical studies and\nachieve new state-of-the-art results on large-scale open-domain conversational\ntext-to-SQL dataset. The results demonstrate that the proposed mechanism\nsignificantly improves the performance of multi-turn semantic parsing.",
    "descriptor": "",
    "authors": [
      "Yuntao Li",
      "Hanchu Zhang",
      "Yutian Li",
      "Sirui Wang",
      "Wei Wu",
      "Yan Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08735"
  },
  {
    "id": "arXiv:2112.08736",
    "title": "Learning to Minimize Cost-to-Serve for Multi-Node Multi-Product Order  Fulfilment in Electronic Commerce",
    "abstract": "We describe a novel decision-making problem developed in response to the\ndemands of retail electronic commerce (e-commerce). While working with\nlogistics and retail industry business collaborators, we found that the cost of\ndelivery of products from the most opportune node in the supply chain (a\nquantity called the cost-to-serve or CTS) is a key challenge. The large scale,\nhigh stochasticity, and large geographical spread of e-commerce supply chains\nmake this setting ideal for a carefully designed data-driven decision-making\nalgorithm. In this preliminary work, we focus on the specific subproblem of\ndelivering multiple products in arbitrary quantities from any warehouse to\nmultiple customers in each time period. We compare the relative performance and\ncomputational efficiency of several baselines, including heuristics and\nmixed-integer linear programming. We show that a reinforcement learning based\nalgorithm is competitive with these policies, with the potential of efficient\nscale-up in the real world.",
    "descriptor": "",
    "authors": [
      "Pranavi Pathakota",
      "Kunwar Zaid",
      "Anulekha Dhara",
      "Hardik Meisheri",
      "Shaun D Souza",
      "Dheeraj Shah",
      "Harshad Khadilkar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08736"
  },
  {
    "id": "arXiv:2112.08739",
    "title": "Forensic Analysis of Synthetically Generated Scientific Images",
    "abstract": "The widespread diffusion of synthetically generated content is a serious\nthreat that needs urgent countermeasures. The generation of synthetic content\nis not restricted to multimedia data like videos, photographs, or audio\nsequences, but covers a significantly vast area that can include biological\nimages as well, such as western-blot and microscopic images. In this paper, we\nfocus on the detection of synthetically generated western-blot images.\nWestern-blot images are largely explored in the biomedical literature and it\nhas been already shown how these images can be easily counterfeited with few\nhope to spot manipulations by visual inspection or by standard forensics\ndetectors. To overcome the absence of a publicly available dataset, we create a\nnew dataset comprising more than 14K original western-blot images and 18K\nsynthetic western-blot images, generated by three different state-of-the-art\ngeneration methods. Then, we investigate different strategies to detect\nsynthetic western blots, exploring binary classification methods as well as\none-class detectors. In both scenarios, we never exploit synthetic western-blot\nimages at training stage. The achieved results show that synthetically\ngenerated western-blot images can be spot with good accuracy, even though the\nexploited detectors are not optimized over synthetic versions of these\nscientific images.",
    "descriptor": "",
    "authors": [
      "Sara Mandelli",
      "Davide Cozzolino",
      "Joao P. Cardenuto",
      "Daniel Moreira",
      "Paolo Bestagini",
      "Walter Scheirer",
      "Anderson Rocha",
      "Luisa Verdoliva",
      "Stefano Tubaro",
      "Edward J. Delp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08739"
  },
  {
    "id": "arXiv:2112.08740",
    "title": "Feature Erasing and Diffusion Network for Occluded Person  Re-Identification",
    "abstract": "Occluded person re-identification (ReID) aims at matching occluded person\nimages to holistic ones across different camera views. Target Pedestrians (TP)\nare usually disturbed by Non-Pedestrian Occlusions (NPO) and NonTarget\nPedestrians (NTP). Previous methods mainly focus on increasing model's\nrobustness against NPO while ignoring feature contamination from NTP. In this\npaper, we propose a novel Feature Erasing and Diffusion Network (FED) to\nsimultaneously handle NPO and NTP. Specifically, NPO features are eliminated by\nour proposed Occlusion Erasing Module (OEM), aided by the NPO augmentation\nstrategy which simulates NPO on holistic pedestrian images and generates\nprecise occlusion masks. Subsequently, we Subsequently, we diffuse the\npedestrian representations with other memorized features to synthesize NTP\ncharacteristics in the feature space which is achieved by a novel Feature\nDiffusion Module (FDM) through a learnable cross attention mechanism. With the\nguidance of the occlusion scores from OEM, the feature diffusion process is\nmainly conducted on visible body parts, which guarantees the quality of the\nsynthesized NTP characteristics. By jointly optimizing OEM and FDM in our\nproposed FED network, we can greatly improve the model's perception ability\ntowards TP and alleviate the influence of NPO and NTP. Furthermore, the\nproposed FDM only works as an auxiliary module for training and will be\ndiscarded in the inference phase, thus introducing little inference\ncomputational overhead. Experiments on occluded and holistic person ReID\nbenchmarks demonstrate the superiority of FED over state-of-the-arts, where FED\nachieves 86.3% Rank-1 accuracy on Occluded-REID, surpassing others by at least\n4.7%.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Zhikang Wang",
      "Feng Zhu",
      "Shixiang Tang",
      "Rui Zhao",
      "Lihuo He",
      "Jiangning Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08740"
  },
  {
    "id": "arXiv:2112.08742",
    "title": "Reformulation of Matching Equation in Potential Energy Shaping",
    "abstract": "Stabilization of an underactuated mechanical system may be accomplished by\nenergy shaping. Interconnection and damping assignment passivity-based control\nis an approach based on total energy shaping by assigning desired kinetic and\npotential energy to the system. This method requires solving a partial\ndifferential equation (PDE) related to he potential energy shaping of the\nsystem. In this short paper, we focus on the reformulation of this PDE to be\nsolved easier. For this purpose, under a certain condition that depends on the\nphysical parameters and the controller gains, it is possible to merely solve\nthe homogeneous part of potential energy PDE. Furthermore, it is shown that the\ncondition may be reduced into a linear matrix inequality form. The results are\napplied to a number of benchmark systems.",
    "descriptor": "",
    "authors": [
      "M.Reza J. Harandi",
      "Hamid D. Taghirad"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.08742"
  },
  {
    "id": "arXiv:2112.08743",
    "title": "Radio-Assisted Human Detection",
    "abstract": "In this paper, we propose a radio-assisted human detection framework by\nincorporating radio information into the state-of-the-art detection methods,\nincluding anchor-based onestage detectors and two-stage detectors. We extract\nthe radio localization and identifer information from the radio signals to\nassist the human detection, due to which the problem of false positives and\nfalse negatives can be greatly alleviated. For both detectors, we use the\nconfidence score revision based on the radio localization to improve the\ndetection performance. For two-stage detection methods, we propose to utilize\nthe region proposals generated from radio localization rather than relying on\nregion proposal network (RPN). Moreover, with the radio identifier information,\na non-max suppression method with the radio localization constraint has also\nbeen proposed to further suppress the false detections and reduce miss\ndetections. Experiments on the simulative Microsoft COCO dataset and Caltech\npedestrian datasets show that the mean average precision (mAP) and the miss\nrate of the state-of-the-art detection methods can be improved with the aid of\nradio information. Finally, we conduct experiments in real-world scenarios to\ndemonstrate the feasibility of our proposed method in practice.",
    "descriptor": "",
    "authors": [
      "Chengrun Qiu",
      "Dongheng Zhang",
      "Yang Hu",
      "Houqiang Li",
      "Qibin Sun",
      "Yan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08743"
  },
  {
    "id": "arXiv:2112.08744",
    "title": "Distributed Nash Equilibrium Seeking for Noncooperative Games of  High-Order Nonlinear Multi-Agent Systems Over Weight-Unbalanced Digraphs",
    "abstract": "In this paper, we investigate the noncooperative games of multi-agent\nsystems. Different from existing noncooperative games, our formulation involves\nthe high-order nonlinear dynamics of players, and the communication topologies\namong players are weight-unbalanced digraphs. Due to the high-order nonlinear\ndynamics and the weight-unbalanced digraphs, existing Nash equilibrium seeking\nalgorithms cannot solve our problem. In order to seek the Nash equilibrium of\nthe noncooperative games, we propose two distributed algorithms based on state\nfeedback and output feedback, respectively. Moreover, we analyze the\nconvergence of the two algorithms with the help of variational analysis and\nLyapunov stability theory. By the two algorithms, the high-order nonlinear\nplayers exponentially converge to the Nash equilibrium. Finally, two simulation\nexamples illustrate the effectiveness of the algorithms.",
    "descriptor": "",
    "authors": [
      "Zhenhua Deng",
      "Jin Luo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.08744"
  },
  {
    "id": "arXiv:2112.08745",
    "title": "Knowledge-enhanced Session-based Recommendation with Temporal  Transformer",
    "abstract": "Recent research has achieved impressive progress in the session-based\nrecommendation. However, information such as item knowledge and click time\ninterval, which could be potentially utilized to improve the performance,\nremains largely unexploited. In this paper, we propose a framework called\nKnowledge-enhanced Session-based Recommendation with Temporal Transformer\n(KSTT) to incorporate such information when learning the item and session\nembeddings. Specifically, a knowledge graph, which models contexts among items\nwithin a session and their corresponding attributes, is proposed to obtain item\nembeddings through graph representation learning. We introduce time interval\nembedding to represent the time pattern between the item that needs to be\npredicted and historical click, and use it to replace the position embedding in\nthe original transformer (called temporal transformer). The item embeddings in\na session are passed through the temporal transformer network to get the\nsession embedding, based on which the final recommendation is made. Extensive\nexperiments demonstrate that our model outperforms state-of-the-art baselines\non four benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Rongzhi Zhang",
      "Yulong Gu",
      "Xiaoyu Shen",
      "Hui Su"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.08745"
  },
  {
    "id": "arXiv:2112.08746",
    "title": "Unsupervised Reinforcement Learning in Multiple Environments",
    "abstract": "Several recent works have been dedicated to unsupervised reinforcement\nlearning in a single environment, in which a policy is first pre-trained with\nunsupervised interactions, and then fine-tuned towards the optimal policy for\nseveral downstream supervised tasks defined over the same environment. Along\nthis line, we address the problem of unsupervised reinforcement learning in a\nclass of multiple environments, in which the policy is pre-trained with\ninteractions from the whole class, and then fine-tuned for several tasks in any\nenvironment of the class. Notably, the problem is inherently multi-objective as\nwe can trade off the pre-training objective between environments in many ways.\nIn this work, we foster an exploration strategy that is sensitive to the most\nadverse cases within the class. Hence, we cast the exploration problem as the\nmaximization of the mean of a critical percentile of the state visitation\nentropy induced by the exploration strategy over the class of environments.\nThen, we present a policy gradient algorithm, $\\alpha$MEPOL, to optimize the\nintroduced objective through mediated interactions with the class. Finally, we\nempirically demonstrate the ability of the algorithm in learning to explore\nchallenging classes of continuous environments and we show that reinforcement\nlearning greatly benefits from the pre-trained exploration strategy w.r.t.\nlearning from scratch.",
    "descriptor": "\nComments: In 36th AAAI Conference on Artificial Intelligence (AAAI 2022)\n",
    "authors": [
      "Mirco Mutti",
      "Mattia Mancassola",
      "Marcello Restelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08746"
  },
  {
    "id": "arXiv:2112.08754",
    "title": "CLIN-X: pre-trained language models and a study on cross-task transfer  for concept extraction in the clinical domain",
    "abstract": "The field of natural language processing (NLP) has recently seen a large\nchange towards using pre-trained language models for solving almost any task.\nDespite showing great improvements in benchmark datasets for various tasks,\nthese models often perform sub-optimal in non-standard domains like the\nclinical domain where a large gap between pre-training documents and target\ndocuments is observed. In this paper, we aim at closing this gap with\ndomain-specific training of the language model and we investigate its effect on\na diverse set of downstream tasks and settings. We introduce the pre-trained\nCLIN-X (Clinical XLM-R) language models and show how CLIN-X outperforms other\npre-trained transformer models by a large margin for ten clinical concept\nextraction tasks from two languages. In addition, we demonstrate how the\ntransformer model can be further improved with our proposed task- and\nlanguage-agnostic model architecture based on ensembles over random splits and\ncross-sentence context. Our studies in low-resource and transfer settings\nreveal stable model performance despite a lack of annotated data with\nimprovements of up to 47 F1points when only 250 labeled sentences are\navailable. Our results highlight the importance of specialized language models\nas CLIN-X for concept extraction in non-standard domains, but also show that\nour task-agnostic model architecture is robust across the tested tasks and\nlanguages so that domain- or task-specific adaptations are not required. The\nCLIN-Xlanguage models and source code for fine-tuning and transferring the\nmodel are publicly available at https://github.com/boschresearch/clin\\_x/ and\nthe huggingface model hub.",
    "descriptor": "",
    "authors": [
      "Lukas Lange",
      "Heike Adel",
      "Jannik Str\u00f6tgen",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08754"
  },
  {
    "id": "arXiv:2112.08759",
    "title": "KnAC: an approach for enhancing cluster analysis with background  knowledge and explanations",
    "abstract": "Pattern discovery in multidimensional data sets has been a subject of\nresearch since decades. There exists a wide spectrum of clustering algorithms\nthat can be used for that purpose. However, their practical applications share\nin common the post-clustering phase, which concerns expert-based interpretation\nand analysis of the obtained results. We argue that this can be a bottleneck of\nthe process, especially in the cases where domain knowledge exists prior to\nclustering. Such a situation requires not only a proper analysis of\nautomatically discovered clusters, but also a conformance checking with\nexisting knowledge. In this work, we present Knowledge Augmented Clustering\n(KnAC), which main goal is to confront expert-based labelling with automated\nclustering for the sake of updating and refining the former. Our solution does\nnot depend on any ready clustering algorithm, nor introduce one. Instead KnAC\ncan serve as an augmentation of an arbitrary clustering algorithm, making the\napproach robust and model-agnostic. We demonstrate the feasibility of our\nmethod on artificially, reproducible examples and on a real life use case\nscenario.",
    "descriptor": "\nComments: Submitted to Applied Intelligence\n",
    "authors": [
      "Szymon Bobek",
      "Micha\u0142 Kuk",
      "Jakub Brzegowski",
      "Edyta Brzychczy",
      "Grzegorz J. Nalepa"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08759"
  },
  {
    "id": "arXiv:2112.08760",
    "title": "Constrained multi-objective optimization of process design parameters in  settings with scarce data: an application to adhesive bonding",
    "abstract": "Adhesive joints are increasingly used in industry for a wide variety of\napplications because of their favorable characteristics such as high\nstrength-to-weight ratio, design flexibility, limited stress concentrations,\nplanar force transfer, good damage tolerance and fatigue resistance. Finding\nthe optimal process parameters for an adhesive bonding process is challenging:\nthe optimization is inherently multi-objective (aiming to maximize break\nstrength while minimizing cost) and constrained (the process should not result\nin any visual damage to the materials, and stress tests should not result in\nfailures that are adhesion-related). Real life physical experiments in the lab\nare expensive to perform; traditional evolutionary approaches (such as genetic\nalgorithms) are then ill-suited to solve the problem, due to the prohibitive\namount of experiments required for evaluation. In this research, we\nsuccessfully applied specific machine learning techniques (Gaussian Process\nRegression and Logistic Regression) to emulate the objective and constraint\nfunctions based on a limited amount of experimental data. The techniques are\nembedded in a Bayesian optimization algorithm, which succeeds in detecting\nPareto-optimal process settings in a highly efficient way (i.e., requiring a\nlimited number of extra experiments).",
    "descriptor": "",
    "authors": [
      "Alejandro Morales-Hern\u00e1ndez",
      "Sebastian Rojas Gonzalez",
      "Inneke Van Nieuwenhuyse",
      "Jeroen Jordens",
      "Maarten Witters",
      "Bart Van Doninck"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08760"
  },
  {
    "id": "arXiv:2112.08761",
    "title": "DISTREAL: Distributed Resource-Aware Learning in Heterogeneous Systems",
    "abstract": "We study the problem of distributed training of neural networks (NNs) on\ndevices with heterogeneous, limited, and time-varying availability of\ncomputational resources. We present an adaptive, resource-aware, on-device\nlearning mechanism, DISTREAL, which is able to fully and efficiently utilize\nthe available resources on devices in a distributed manner, increasing the\nconvergence speed. This is achieved with a dropout mechanism that dynamically\nadjusts the computational complexity of training an NN by randomly dropping\nfilters of convolutional layers of the model. Our main contribution is the\nintroduction of a design space exploration (DSE) technique, which finds\nPareto-optimal per-layer dropout vectors with respect to resource requirements\nand convergence speed of the training. Applying this technique, each device is\nable to dynamically select the dropout vector that fits its available resource\nwithout requiring any assistance from the server. We implement our solution in\na federated learning (FL) system, where the availability of computational\nresources varies both between devices and over time, and show through extensive\nevaluation that we are able to significantly increase the convergence speed\nover the state of the art without compromising on the final accuracy.",
    "descriptor": "\nComments: to be published in AAAI Conference on Artificial Intelligence (AAAI'22)\n",
    "authors": [
      "Martin Rapp",
      "Ramin Khalili",
      "Kilian Pfeiffer",
      "J\u00f6rg Henkel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08761"
  },
  {
    "id": "arXiv:2112.08764",
    "title": "Graph Convolutional Networks with Dual Message Passing for Subgraph  Isomorphism Counting and Matching",
    "abstract": "Graph neural networks (GNNs) and message passing neural networks (MPNNs) have\nbeen proven to be expressive for subgraph structures in many applications. Some\napplications in heterogeneous graphs require explicit edge modeling, such as\nsubgraph isomorphism counting and matching. However, existing message passing\nmechanisms are not designed well in theory. In this paper, we start from a\nparticular edge-to-vertex transform and exploit the isomorphism property in the\nedge-to-vertex dual graphs. We prove that searching isomorphisms on the\noriginal graph is equivalent to searching on its dual graph. Based on this\nobservation, we propose dual message passing neural networks (DMPNNs) to\nenhance the substructure representation learning in an asynchronous way for\nsubgraph isomorphism counting and matching as well as unsupervised node\nclassification. Extensive experiments demonstrate the robust performance of\nDMPNNs by combining both node and edge representation learning in synthetic and\nreal heterogeneous graphs. Code is available at\nhttps://github.com/HKUST-KnowComp/DualMessagePassing.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Xin Liu",
      "Yangqiu Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08764"
  },
  {
    "id": "arXiv:2112.08765",
    "title": "On Up-to Context Techniques in the $\u03c0$-calculus",
    "abstract": "We present a variant of the theory of compatible functions on relations, due\nto Sangiorgi and Pous. We show that the up-to context proof technique for\nbisimulation is compatible in this setting for two subsets of the pi-calculus:\nthe asynchronous pi-calculus and a pi-calculus with immediately available\nnames.",
    "descriptor": "",
    "authors": [
      "Enguerrand Prebet"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.08765"
  },
  {
    "id": "arXiv:2112.08766",
    "title": "CODER: An efficient framework for improving retrieval through  COntextualized Document Embedding Reranking",
    "abstract": "We present a framework for improving the performance of a wide class of\nretrieval models at minimal computational cost. It utilizes precomputed\ndocument representations extracted by a base dense retrieval method and\ninvolves training a model to jointly score a large set of retrieved candidate\ndocuments for each query, while potentially transforming on the fly the\nrepresentation of each document in the context of the other candidates as well\nas the query itself. When scoring a document representation based on its\nsimilarity to a query, the model is thus aware of the representation of its\n\"peer\" documents. We show that our approach leads to substantial improvement in\nretrieval performance over the base method and over scoring candidate documents\nin isolation from one another, as in a pair-wise training setting. Crucially,\nunlike term-interaction rerankers based on BERT-like encoders, it incurs a\nnegligible computational overhead on top of any first-stage method at run time,\nallowing it to be easily combined with any state-of-the-art dense retrieval\nmethod. Finally, concurrently considering a set of candidate documents for a\ngiven query enables additional valuable capabilities in retrieval, such as\nscore calibration and mitigating societal biases in ranking.",
    "descriptor": "",
    "authors": [
      "George Zerveas",
      "Navid Rekabsaz",
      "Daniel Cohen",
      "Carsten Eickhoff"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08766"
  },
  {
    "id": "arXiv:2112.08770",
    "title": "A Proposition-Level Clustering Approach for Multi-Document Summarization",
    "abstract": "Text clustering methods were traditionally incorporated into multi-document\nsummarization (MDS) as a means for coping with considerable information\nrepetition. Clusters were leveraged to indicate information saliency and to\navoid redundancy. These methods focused on clustering sentences, even though\nclosely related sentences also usually contain non-aligning information. In\nthis work, we revisit the clustering approach, grouping together propositions\nfor more precise information alignment. Specifically, our method detects\nsalient propositions, clusters them into paraphrastic clusters, and generates a\nrepresentative sentence for each cluster by fusing its propositions. Our\nsummarization method improves over the previous state-of-the-art MDS method in\nthe DUC 2004 and TAC 2011 datasets, both in automatic ROUGE scores and human\npreference.",
    "descriptor": "",
    "authors": [
      "Ori Ernst",
      "Avi Caciularu",
      "Ori Shapira",
      "Ramakanth Pasunuru",
      "Mohit Bansal",
      "Jacob Goldberger",
      "Ido Dagan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08770"
  },
  {
    "id": "arXiv:2112.08772",
    "title": "\u03b4-SAM: Sharpness-Aware Minimization with Dynamic Reweighting",
    "abstract": "Deep neural networks are often overparameterized and may not easily achieve\nmodel generalization. Adversarial training has shown effectiveness in improving\ngeneralization by regularizing the change of loss on top of adversarially\nchosen perturbations. The recently proposed sharpness-aware minimization (SAM)\nalgorithm adopts adversarial weight perturbation, encouraging the model to\nconverging to a flat minima. Unfortunately, due to increased computational\ncost, adversarial weight perturbation can only be efficiently approximated\nper-batch instead of per-instance, leading to degraded performance. In this\npaper, we propose that dynamically reweighted perturbation within each batch,\nwhere unguarded instances are up-weighted, can serve as a better approximation\nto per-instance perturbation. We propose sharpness-aware minimization with\ndynamic reweighting ({\\delta}-SAM), which realizes the idea with efficient\nguardedness estimation. Experiments on the GLUE benchmark demonstrate the\neffectiveness of {\\delta}-SAM.",
    "descriptor": "",
    "authors": [
      "Wenxuan Zhou",
      "Muhao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08772"
  },
  {
    "id": "arXiv:2112.08774",
    "title": "BoGraph: Structured Bayesian Optimization From Logs for Systems with  High-dimensional Parameter Space",
    "abstract": "Current auto-tuning frameworks struggle with tuning computer systems\nconfigurations due to their large parameter space, complex interdependencies,\nand high evaluation cost. Utilizing probabilistic models, Structured Bayesian\nOptimization (SBO) has recently overcome these difficulties. SBO decomposes the\nparameter space by utilizing contextual information provided by system experts\nleading to fast convergence. However, the complexity of building probabilistic\nmodels has hindered its wider adoption. We propose BoAnon, a SBO framework that\nlearns the system structure from its logs. BoAnon provides an API enabling\nexperts to encode knowledge of the system as performance models or components\ndependency. BoAnon takes in the learned structure and transforms it into a\nprobabilistic graph model. Then it applies the expert-provided knowledge to the\ngraph to further contextualize the system behavior. BoAnon probabilistic graph\nallows the optimizer to find efficient configurations faster than other\nmethods. We evaluate BoAnon via a hardware architecture search problem,\nachieving an improvement in energy-latency objectives ranging from $5-7$\nx-factors improvement over the default architecture. With its novel contextual\nstructure learning pipeline, BoAnon makes using SBO accessible for a wide range\nof other computer systems such as databases and stream processors.",
    "descriptor": "",
    "authors": [
      "Sami Alabed",
      "Eiko Yoneki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.08774"
  },
  {
    "id": "arXiv:2112.08775",
    "title": "DProST: 6-DoF Object Pose Estimation Using Space Carving and Dynamic  Projective Spatial Transformer",
    "abstract": "Predicting the pose of an object is a core computer vision task. Most deep\nlearning-based pose estimation methods require CAD data to use 3D intermediate\nrepresentations or project 2D appearance. However, these methods cannot be used\nwhen CAD data for objects of interest are unavailable. Besides, the existing\nmethods did not precisely reflect the perspective distortion to the learning\nprocess. In addition, information loss due to self-occlusion has not been\nstudied well. In this regard, we propose a new pose estimation system\nconsisting of a space carving module that reconstructs a reference 3D feature\nto replace the CAD data. Moreover, Our new transformation module, Dynamic\nProjective Spatial Transformer (DProST), transforms a reference 3D feature to\nreflect the pose while considering perspective distortion. Also, we overcome\nthe self-occlusion problem by a new Bidirectional Z-buffering (BiZ-buffer)\nmethod, which extracts both the front view and the self-occluded back view of\nthe object. Lastly, we suggest a Perspective Grid Distance Loss (PGDL),\nenabling stable learning of the pose estimator without CAD data. Experimental\nresults show that our method outperforms the state-of-the-art method on the\nLINEMOD dataset and comparable performance on LINEMOD-OCCLUSION dataset even\ncompared to the methods that require CAD data in network training.",
    "descriptor": "",
    "authors": [
      "Jaewoo Park",
      "Nam Ik Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08775"
  },
  {
    "id": "arXiv:2112.08776",
    "title": "Unsupervised Matching of Data and Text",
    "abstract": "Entity resolution is a widely studied problem with several proposals to match\nrecords across relations. Matching textual content is a widespread task in many\napplications, such as question answering and search. While recent methods\nachieve promising results for these two tasks, there is no clear solution for\nthe more general problem of matching textual content and structured data. We\nintroduce a framework that supports this new task in an unsupervised setting\nfor any pair of corpora, being relational tables or text documents. Our method\nbuilds a fine-grained graph over the content of the corpora and derives word\nembeddings to represent the objects to match in a low dimensional space. The\nlearned representation enables effective and efficient matching at different\ngranularity, from relational tuples to text sentences and paragraphs. Our\nflexible framework can exploit pre-trained resources, but it does not depends\non their existence and achieves better quality performance in matching content\nwhen the vocabulary is domain specific. We also introduce optimizations in the\ngraph creation process with an \"expand and compress\" approach that first\nidentifies new valid relationships across elements, to improve matching, and\nthen prunes nodes and edges, to reduce the graph size. Experiments on real use\ncases and public datasets show that our framework produces embeddings that\noutperform word embeddings and fine-tuned language models both in results'\nquality and in execution times.",
    "descriptor": "\nComments: Accepted at IEEE ICDE 2022 Code at this https URL\n",
    "authors": [
      "Naser Ahmadi",
      "Hansjorg Sand",
      "Paolo Papotti"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08776"
  },
  {
    "id": "arXiv:2112.08777",
    "title": "Utilizing Evidence Spans via Sequence-Level Contrastive Learning for  Long-Context Question Answering",
    "abstract": "Long-range transformer models have achieved encouraging results on\nlong-context question answering (QA) tasks. Such tasks often require reasoning\nover a long document, and they benefit from identifying a set of evidence spans\n(e.g., sentences) that provide supporting evidence for addressing the question.\nIn this work, we propose a novel method for equipping long-range transformers\nwith an additional sequence-level objective for better identification of\nsupporting evidence spans. We achieve this by proposing an additional\ncontrastive supervision signal in finetuning, where the model is encouraged to\nexplicitly discriminate supporting evidence sentences from negative ones by\nmaximizing the question-evidence similarity. The proposed additional loss\nexhibits consistent improvements on three different strong long-context\ntransformer models, across two challenging question answering benchmarks -\nHotpotQA and QAsper.",
    "descriptor": "",
    "authors": [
      "Avi Caciularu",
      "Ido Dagan",
      "Jacob Goldberger",
      "Arman Cohan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08777"
  },
  {
    "id": "arXiv:2112.08782",
    "title": "Improved YOLOv5 network for real-time multi-scale traffic sign detection",
    "abstract": "Traffic sign detection is a challenging task for the unmanned driving system,\nespecially for the detection of multi-scale targets and the real-time problem\nof detection. In the traffic sign detection process, the scale of the targets\nchanges greatly, which will have a certain impact on the detection accuracy.\nFeature pyramid is widely used to solve this problem but it might break the\nfeature consistency across different scales of traffic signs. Moreover, in\npractical application, it is difficult for common methods to improve the\ndetection accuracy of multi-scale traffic signs while ensuring real-time\ndetection. In this paper, we propose an improved feature pyramid model, named\nAF-FPN, which utilizes the adaptive attention module (AAM) and feature\nenhancement module (FEM) to reduce the information loss in the process of\nfeature map generation and enhance the representation ability of the feature\npyramid. We replaced the original feature pyramid network in YOLOv5 with\nAF-FPN, which improves the detection performance for multi-scale targets of the\nYOLOv5 network under the premise of ensuring real-time detection. Furthermore,\na new automatic learning data augmentation method is proposed to enrich the\ndataset and improve the robustness of the model to make it more suitable for\npractical scenarios. Extensive experimental results on the Tsinghua-Tencent\n100K (TT100K) dataset demonstrate the effectiveness and superiority of the\nproposed method when compared with several state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Junfan Wang",
      "Yi Chen",
      "Mingyu Gao",
      "Zhekang Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08782"
  },
  {
    "id": "arXiv:2112.08786",
    "title": "Efficient Hierarchical Domain Adaptation for Pretrained Language Models",
    "abstract": "Generative language models are trained on diverse, general domain corpora.\nHowever, this limits their applicability to narrower domains, and prior work\nhas shown that continued in-domain training can provide further gains. In this\npaper, we introduce a method to scale domain adaptation to many diverse domains\nusing a computationally efficient adapter approach. Our method is based on the\nobservation that textual domains are partially overlapping, and we represent\ndomains as a hierarchical tree structure where each node in the tree is\nassociated with a set of adapter weights. When combined with a frozen\npretrained language model, this approach enables parameter sharing among\nrelated domains, while avoiding negative interference between unrelated ones.\nIt is efficient and computational cost scales as O(log(D)) for D domains.\nExperimental results with GPT-2 and a large fraction of the 100 most\nrepresented websites in C4 show across-the-board improvements in-domain. We\nadditionally provide an inference time algorithm for a held-out domain and show\nthat averaging over multiple paths through the tree enables further gains in\ngeneralization, while adding only a marginal cost to inference.",
    "descriptor": "",
    "authors": [
      "Alexandra Chronopoulou",
      "Matthew E. Peters",
      "Jesse Dodge"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08786"
  },
  {
    "id": "arXiv:2112.08787",
    "title": "ATM: An Uncertainty-aware Active Self-training Framework for  Label-efficient Text Classification",
    "abstract": "Despite the great success of pre-trained language models (LMs) in many\nnatural language processing (NLP) tasks, they require excessive labeled data\nfor fine-tuning to achieve satisfactory performance. To enhance the label\nefficiency, researchers have resorted to active learning (AL), while the\npotential of unlabeled data is ignored by most of prior work. To unleash the\npower of unlabeled data for better label efficiency and model performance, we\ndevelop ATM, a new framework that leverage self-training to exploit unlabeled\ndata and is agnostic to the specific AL algorithm, serving as a plug-in module\nto improve existing AL methods. Specifically, the unlabeled data with high\nuncertainty is exposed to oracle for annotations while those with low\nuncertainty are leveraged for self-training. To alleviate the label noise\npropagation issue in self-training, we design a simple and effective\nmomentum-based memory bank to dynamically aggregate the model predictions from\nall rounds. By extensive experiments, we demonstrate that ATM outperforms the\nstrongest active learning and self-training baselines and improve the label\nefficiency by 51.9% on average.",
    "descriptor": "",
    "authors": [
      "Yue Yu",
      "Lingkai Kong",
      "Jieyu Zhang",
      "Rongzhi Zhang",
      "Chao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08787"
  },
  {
    "id": "arXiv:2112.08789",
    "title": "Harnessing Cross-lingual Features to Improve Cognate Detection for  Low-resource Languages",
    "abstract": "Cognates are variants of the same lexical form across different languages;\nfor example 'fonema' in Spanish and 'phoneme' in English are cognates, both of\nwhich mean 'a unit of sound'. The task of automatic detection of cognates among\nany two languages can help downstream NLP tasks such as Cross-lingual\nInformation Retrieval, Computational Phylogenetics, and Machine Translation. In\nthis paper, we demonstrate the use of cross-lingual word embeddings for\ndetecting cognates among fourteen Indian Languages. Our approach introduces the\nuse of context from a knowledge graph to generate improved feature\nrepresentations for cognate detection. We, then, evaluate the impact of our\ncognate detection mechanism on neural machine translation (NMT), as a\ndownstream task. We evaluate our methods to detect cognates on a challenging\ndataset of twelve Indian languages, namely, Sanskrit, Hindi, Assamese, Oriya,\nKannada, Gujarati, Tamil, Telugu, Punjabi, Bengali, Marathi, and Malayalam.\nAdditionally, we create evaluation datasets for two more Indian languages,\nKonkani and Nepali. We observe an improvement of up to 18% points, in terms of\nF-score, for cognate detection. Furthermore, we observe that cognates extracted\nusing our method help improve NMT quality by up to 2.76 BLEU. We also release\nour code, newly constructed datasets and cross-lingual models publicly.",
    "descriptor": "\nComments: Published at COLING 2020\n",
    "authors": [
      "Diptesh Kanojia",
      "Raj Dabre",
      "Shubham Dewangan",
      "Pushpak Bhattacharyya",
      "Gholamreza Haffari",
      "Malhar Kulkarni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08789"
  },
  {
    "id": "arXiv:2112.08796",
    "title": "Saliency Grafting: Innocuous Attribution-Guided Mixup with Calibrated  Label Mixing",
    "abstract": "The Mixup scheme suggests mixing a pair of samples to create an augmented\ntraining sample and has gained considerable attention recently for improving\nthe generalizability of neural networks. A straightforward and widely used\nextension of Mixup is to combine with regional dropout-like methods: removing\nrandom patches from a sample and replacing it with the features from another\nsample. Albeit their simplicity and effectiveness, these methods are prone to\ncreate harmful samples due to their randomness. To address this issue, 'maximum\nsaliency' strategies were recently proposed: they select only the most\ninformative features to prevent such a phenomenon. However, they now suffer\nfrom lack of sample diversification as they always deterministically select\nregions with maximum saliency, injecting bias into the augmented data. In this\npaper, we present, a novel, yet simple Mixup-variant that captures the best of\nboth worlds. Our idea is two-fold. By stochastically sampling the features and\n'grafting' them onto another sample, our method effectively generates diverse\nyet meaningful samples. Its second ingredient is to produce the label of the\ngrafted sample by mixing the labels in a saliency-calibrated fashion, which\nrectifies supervision misguidance introduced by the random sampling procedure.\nOur experiments under CIFAR, Tiny-ImageNet, and ImageNet datasets show that our\nscheme outperforms the current state-of-the-art augmentation strategies not\nonly in terms of classification accuracy, but is also superior in coping under\nstress conditions such as data corruption and object occlusion.",
    "descriptor": "\nComments: 12 pages; Accepted to AAAI2022\n",
    "authors": [
      "Joonhyung Park",
      "June Yong Yang",
      "Jinwoo Shin",
      "Sung Ju Hwang",
      "Eunho Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08796"
  },
  {
    "id": "arXiv:2112.08797",
    "title": "Minimizing Reachability Times on Temporal Graphs via Shifting Labels",
    "abstract": "We study how we can accelerate the spreading of information in temporal\ngraphs via delaying operations; a problem that captures real-world applications\nvarying from information flows to distribution schedules. In a temporal graph\nthere is a set of fixed vertices and the available connections between them\nchange over time in a predefined manner. We observe that, in some cases, the\ndelay of some connections can in fact decrease the time required to reach from\nsome vertex (source) to another vertex (target). We study how we can minimize\nthe maximum time a set of source vertices needs to reach every other vertex of\nthe graph when we are allowed to delay some of the connections of the graph.\nFor one source, we prove that the problem is W[2]-hard and NP-hard, when\nparameterized by the number of allowed delays. On the other hand, we derive a\npolynomial-time algorithm for one source and unbounded number of delays. This\nis the best we can hope for; we show that the problem becomes NP-hard when\nthere are two sources and the number of delays is not bounded. We complement\nour negative result by providing an FPT algorithm parameterized by the\ntreewidth of the graph plus the lifetime of the optimal solution. Finally, we\nprovide polynomial-time algorithms for several classes of graphs.",
    "descriptor": "",
    "authors": [
      "Argyrios Deligkas",
      "Eduard Eiben",
      "George Skretas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.08797"
  },
  {
    "id": "arXiv:2112.08798",
    "title": "Understanding Memorization from the Perspective of Optimization via  Efficient Influence Estimation",
    "abstract": "Over-parameterized deep neural networks are able to achieve excellent\ntraining accuracy while maintaining a small generalization error. It has also\nbeen found that they are able to fit arbitrary labels, and this behaviour is\nreferred to as the phenomenon of memorization. In this work, we study the\nphenomenon of memorization with turn-over dropout, an efficient method to\nestimate influence and memorization, for data with true labels (real data) and\ndata with random labels (random data). Our main findings are: (i) For both real\ndata and random data, the optimization of easy examples (e.g., real data) and\ndifficult examples (e.g., random data) are conducted by the network\nsimultaneously, with easy ones at a higher speed; (ii) For real data, a correct\ndifficult example in the training dataset is more informative than an easy one.\nBy showing the existence of memorization on random data and real data, we\nhighlight the consistency between them regarding optimization and we emphasize\nthe implication of memorization during optimization.",
    "descriptor": "",
    "authors": [
      "Futong Liu",
      "Tao Lin",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08798"
  },
  {
    "id": "arXiv:2112.08802",
    "title": "UniREx: A Unified Learning Framework for Language Model Rationale  Extraction",
    "abstract": "An extractive rationale explains a language model's (LM's) prediction on a\ngiven task instance by highlighting the text inputs that most influenced the\noutput. Ideally, rationale extraction should be faithful (reflects LM's\nbehavior), plausible (makes sense to humans), data-efficient, and fast, without\nsacrificing the LM's task performance. Prior rationale extraction works consist\nof specialized approaches for addressing various subsets of these desiderata --\nbut never all five. Narrowly focusing on certain desiderata typically comes at\nthe expense of ignored ones, so existing rationale extractors are often\nimpractical in real-world applications. To tackle this challenge, we propose\nUniREx, a unified and highly flexible learning framework for rationale\nextraction, which allows users to easily account for all five factors. UniREx\nenables end-to-end customization of the rationale extractor training process,\nsupporting arbitrary: (1) heuristic/learned rationale extractors, (2)\ncombinations of faithfulness and/or plausibility objectives, and (3) amounts of\ngold rationale supervision. Across three text classification datasets, our best\nUniREx configurations achieve a superior balance of the five desiderata, when\ncompared to strong baselines. Furthermore, UniREx-trained rationale extractors\ncan even generalize to unseen datasets and tasks.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Aaron Chan",
      "Maziar Sanjabi",
      "Lambert Mathias",
      "Liang Tan",
      "Shaoliang Nie",
      "Xiaochang Peng",
      "Xiang Ren",
      "Hamed Firooz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08802"
  },
  {
    "id": "arXiv:2112.08804",
    "title": "CrossSum: Beyond English-Centric Cross-Lingual Abstractive Text  Summarization for 1500+ Language Pairs",
    "abstract": "We present CrossSum, a large-scale dataset comprising 1.65 million\ncross-lingual article-summary samples in 1500+ language-pairs constituting 45\nlanguages. We use the multilingual XL-Sum dataset and align identical articles\nwritten in different languages via cross-lingual retrieval using a\nlanguage-agnostic representation model. We propose a multi-stage data sampling\nalgorithm and fine-tune mT5, a multilingual pretrained model, with explicit\ncross-lingual supervision with CrossSum and introduce a new metric for\nevaluating cross-lingual summarization. Results on established and our proposed\nmetrics indicate that models fine-tuned on CrossSum outperforms\nsummarization+translation baselines, even when the source and target language\npairs are linguistically distant. To the best of our knowledge, CrossSum is the\nlargest cross-lingual summarization dataset and also the first-ever that does\nnot rely on English as the pivot language. We are releasing the dataset,\nalignment and training scripts, and the models to spur future research on\ncross-lingual abstractive summarization. The resources can be found at\n\\url{https://github.com/csebuetnlp/CrossSum}.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Tahmid Hasan",
      "Abhik Bhattacharjee",
      "Wasi Uddin Ahmad",
      "Yuan-Fang Li",
      "Yong-Bin Kang",
      "Rifat Shahriyar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08804"
  },
  {
    "id": "arXiv:2112.08806",
    "title": "Dataset correlation inference attacks against machine learning models",
    "abstract": "Machine learning models are increasingly used by businesses and organizations\naround the world to automate tasks and decision-making. Trained on potentially\nsensitive datasets, machine learning models have been shown to leak information\nabout individuals in the dataset as well as global dataset information. We here\ntake research in dataset property inference attacks one step further by\nproposing a new attack against ML models: a dataset correlation inference\nattack, where an attacker's goal is to infer the correlation between input\nvariables of a model. We first show that an attacker can exploit the spherical\nparametrization of correlation matrices, to make an informed guess. This means\nthat using only the correlation between the input variables and the target\nvariable, an attacker can infer the correlation between two input variables\nmuch better than a random guess baseline. We propose a second attack which\nexploits the access to a machine learning model using shadow modeling to refine\nthe guess. Our attack uses Gaussian copula-based generative modeling to\ngenerate synthetic datasets with a wide variety of correlations in order to\ntrain a meta-model for the correlation inference task. We evaluate our attack\nagainst Logistic Regression and Multi-layer perceptron models and show it to\noutperform the model-less attack. Our results show that the accuracy of the\nsecond, machine learning-based attack decreases with the number of variables\nand converges towards the accuracy of the model-less attack. However,\ncorrelations between input variables which are highly correlated with the\ntarget variable are more vulnerable regardless of the number of variables. Our\nwork bridges the gap between what can be considered a global leakage about the\ntraining dataset and individual-level leakages. When coupled with marginal\nleakage attacks,it might also constitute a first step towards dataset\nreconstruction.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Ana-Maria Cre\u0163u",
      "Florent Gu\u00e9pin",
      "Yves-Alexandre de Montjoye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.08806"
  },
  {
    "id": "arXiv:2112.08808",
    "title": "Simple Questions Generate Named Entity Recognition Datasets",
    "abstract": "Named entity recognition (NER) is a task of extracting named entities of\nspecific types from text. Current NER models often rely on human-annotated\ndatasets requiring the vast engagement of professional knowledge on the target\ndomain and entities. This work introduces an ask-to-generate approach, which\nautomatically generates NER datasets by asking simple natural language\nquestions that reflect the needs for entity types (e.g., Which disease?) to an\nopen-domain question answering system. Without using any in-domain resources\n(i.e., training sentences, labels, or in-domain dictionaries), our models\nsolely trained on our generated datasets largely outperform previous weakly\nsupervised models on six NER benchmarks across four different domains.\nSurprisingly, on NCBI-disease, our model achieves 75.5 F1 score and even\noutperforms the previous best weakly supervised model by 4.1 F1 score, which\nutilizes a rich in-domain dictionary provided by domain experts. Formulating\nthe needs of NER with natural language also allows us to build NER models for\nfine-grained entity types such as Award, where our model even outperforms fully\nsupervised models. On three few-shot NER benchmarks, our model achieves new\nstate-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Hyunjae Kim",
      "Jaehyo Yoo",
      "Seunghyun Yoon",
      "Jinhyuk Lee",
      "Jaewoo Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08808"
  },
  {
    "id": "arXiv:2112.08810",
    "title": "Pure Noise to the Rescue of Insufficient Data: Improving Imbalanced  Classification by Training on Random Noise Images",
    "abstract": "Despite remarkable progress on visual recognition tasks, deep neural-nets\nstill struggle to generalize well when training data is scarce or highly\nimbalanced, rendering them extremely vulnerable to real-world examples. In this\npaper, we present a surprisingly simple yet highly effective method to mitigate\nthis limitation: using pure noise images as additional training data. Unlike\nthe common use of additive noise or adversarial noise for data augmentation, we\npropose an entirely different perspective by directly training on pure random\nnoise images. We present a new Distribution-Aware Routing Batch Normalization\nlayer (DAR-BN), which enables training on pure noise images in addition to\nnatural images within the same network. This encourages generalization and\nsuppresses overfitting. Our proposed method significantly improves imbalanced\nclassification performance, obtaining state-of-the-art results on a large\nvariety of long-tailed image classification datasets (CIFAR-10-LT,\nCIFAR-100-LT, ImageNet-LT, Places-LT, and CelebA-5). Furthermore, our method is\nextremely simple and easy to use as a general new augmentation tool (on top of\nexisting augmentations), and can be incorporated in any training scheme. It\ndoes not require any specialized data generation or training procedures, thus\nkeeping training fast and efficient",
    "descriptor": "",
    "authors": [
      "Shiran Zada",
      "Itay Benou",
      "Michal Irani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08810"
  },
  {
    "id": "arXiv:2112.08812",
    "title": "Ditch the Gold Standard: Re-evaluating Conversational Question Answering",
    "abstract": "Conversational question answering (CQA) systems aim to provide\nnatural-language answers to users in information-seeking conversations.\nExisting CQA benchmarks compare models with pre-collected human-human\nconversations, using ground-truth answers provided in conversational history.\nIt remains unclear whether we can rely on this static evaluation for model\ndevelopment and whether current systems can well generalize to real-world\nhuman-machine conversations. In this work, we conduct the first large-scale\nhuman evaluation of state-of-the-art CQA systems, where human evaluators\nconverse with models and judge the correctness of their answers. We find that\nthe distribution of human-machine conversations differs drastically from that\nof human-human conversations, and there is a disagreement between human and\ngold-history evaluation in terms of model ranking. We further investigate how\nto improve automatic evaluations, and propose a question rewriting mechanism\nbased on predicted history, which better correlates with human judgments.\nFinally, we discuss the impact of various modeling strategies and future\ndirections towards better conversational question answering systems.",
    "descriptor": "",
    "authors": [
      "Huihan Li",
      "Tianyu Gao",
      "Manan Goenka",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08812"
  },
  {
    "id": "arXiv:2112.08814",
    "title": "An Unsupervised Way to Understand Artifact Generating Internal Units in  Generative Neural Networks",
    "abstract": "Despite significant improvements on the image generation performance of\nGenerative Adversarial Networks (GANs), generations with low visual fidelity\nstill have been observed. As widely used metrics for GANs focus more on the\noverall performance of the model, evaluation on the quality of individual\ngenerations or detection of defective generations is challenging. While recent\nstudies try to detect featuremap units that cause artifacts and evaluate\nindividual samples, these approaches require additional resources such as\nexternal networks or a number of training data to approximate the real data\nmanifold. In this work, we propose the concept of local activation, and devise\na metric on the local activation to detect artifact generations without\nadditional supervision. We empirically verify that our approach can detect and\ncorrect artifact generations from GANs with various datasets. Finally, we\ndiscuss a geometrical analysis to partially reveal the relation between the\nproposed concept and low visual fidelity.",
    "descriptor": "\nComments: AAAI22 accepted paper\n",
    "authors": [
      "Haedong Jeong",
      "Jiyeon Han",
      "Jaesik Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08814"
  },
  {
    "id": "arXiv:2112.08816",
    "title": "Self-Distilled Hashing for Deep Image Retrieval",
    "abstract": "In hash-based image retrieval systems, the transformed input from the\noriginal usually generates different codes, deteriorating the retrieval\naccuracy. To mitigate this issue, data augmentation can be applied during\ntraining. However, even if the augmented samples of one content are similar in\nreal space, the quantization can scatter them far away in Hamming space. This\nresults in representation discrepancies that can impede training and degrade\nperformance. In this work, we propose a novel self-distilled hashing scheme to\nminimize the discrepancy while exploiting the potential of augmented data. By\ntransferring the hash knowledge of the weakly-transformed samples to the strong\nones, we make the hash code insensitive to various transformations. We also\nintroduce hash proxy-based similarity learning and binary cross entropy-based\nquantization loss to provide fine quality hash codes. Ultimately, we construct\na deep hashing framework that generates discriminative hash codes. Extensive\nexperiments on benchmarks verify that our self-distillation improves the\nexisting deep hashing approaches, and our framework achieves state-of-the-art\nretrieval results. The code will be released soon.",
    "descriptor": "",
    "authors": [
      "Young Kyun Jang",
      "Geonmo Gu",
      "Byungsoo Ko",
      "Nam Ik Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.08816"
  },
  {
    "id": "arXiv:2112.08817",
    "title": "Search for temporal cell segmentation robustness in phase-contrast  microscopy videos",
    "abstract": "Studying cell morphology changes in time is critical to understanding cell\nmigration mechanisms. In this work, we present a deep learning-based workflow\nto segment cancer cells embedded in 3D collagen matrices and imaged with\nphase-contrast microscopy. Our approach uses transfer learning and recurrent\nconvolutional long-short term memory units to exploit the temporal information\nfrom the past and provide a consistent segmentation result. Lastly, we propose\na geometrical-characterization approach to studying cancer cell morphology. Our\napproach provides stable results in time, and it is robust to the different\nweight initialization or training data sampling. We introduce a new annotated\ndataset for 2D cell segmentation and tracking, and an open-source\nimplementation to replicate the experiments or adapt them to new image\nprocessing problems.",
    "descriptor": "",
    "authors": [
      "Estibaliz G\u00f3mez-de-Mariscal",
      "Hasini Jayatilaka",
      "\u00d6zg\u00fcn \u00c7i\u00e7ek",
      "Thomas Brox",
      "Denis Wirtz",
      "Arrate Mu\u00f1oz-Barrutia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.08817"
  },
  {
    "id": "arXiv:2112.08826",
    "title": "A case study on parametric verification of failure detectors",
    "abstract": "Partial synchrony is a model of computation in many distributed algorithms\nand modern blockchains. These algorithms are typically parameterized in the\nnumber of participants, and their correctness requires the existence of bounds\non message delays and on the relative speed of processes after reaching Global\nStabilization Time. These characteristics make partially synchronous algorithms\nparameterized in the number of processes, and parametric in time bounds, which\nrender automated verification of partially synchronous algorithms challenging.\nIn this paper, we present a case study on formal verification of both safety\nand liveness of the Chandra and Toueg failure detector that is based on partial\nsynchrony. To this end, we first introduce and formalize the class of symmetric\npoint-to-point algorithms that contains the failure detector. Second, we show\nthat these symmetric point-to-point algorithms have a cutoff, and the cutoff\nresults hold in three models of computation: synchrony, asynchrony, and partial\nsynchrony. As a result, one can verify them by model checking small instances,\nbut the verification problem stays parametric in time. Next, we specify the\nfailure detector and the partial synchrony assumptions in three frameworks:\nTLA+, IVy, and counter automata. Importantly, we tune our modeling to use the\nstrength of each method: (1) We are using counters to encode message buffers\nwith counter automata, (2) we are using first-order relations to encode message\nbuffers in IVy, and (3) we are using both approaches in TLA+. By running the\ntools for TLA+ and counter automata, we demonstrate safety for fixed time\nbounds. By running IVy, we prove safety for arbitrary time bounds. Moreover, we\nshow how to verify liveness of the failure detector by reducing the\nverification problem to safety verification. Thus, both properties are verified\nby developing inductive invariants with IVy.",
    "descriptor": "",
    "authors": [
      "Thanh-Hai Tran",
      "Igor Konnov",
      "Josef Widder"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.08826"
  },
  {
    "id": "arXiv:2112.08827",
    "title": "Distributed event-triggered flocking control of Lagrangian systems",
    "abstract": "In this paper, an event-triggered control protocol is developed to\ninvestigate flocking control of Lagrangian systems, where event-triggering\nconditions are proposed to determine when the velocities of the agents are\ntransmitted to their neighbours. In particular, the proposed controller is\ndistributed, since it only depends on the available information of each agent\non their own reference frame. In addition, we derive sufficient conditions to\navoid Zeno behaviour. Numerical simulations are provided to show the\neffectiveness of the proposed control law.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Ernesto Aranda-Escol\u00e1stico",
      "Leonardo J. Colombo",
      "Mar\u00eda Guinaldo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.08827"
  },
  {
    "id": "arXiv:2112.08830",
    "title": "Graph-wise Common Latent Factor Extraction for Unsupervised Graph  Representation Learning",
    "abstract": "Unsupervised graph-level representation learning plays a crucial role in a\nvariety of tasks such as molecular property prediction and community analysis,\nespecially when data annotation is expensive. Currently, most of the\nbest-performing graph embedding methods are based on Infomax principle. The\nperformance of these methods highly depends on the selection of negative\nsamples and hurt the performance, if the samples were not carefully selected.\nInter-graph similarity-based methods also suffer if the selected set of graphs\nfor similarity matching is low in quality. To address this, we focus only on\nutilizing the current input graph for embedding learning. We are motivated by\nan observation from real-world graph generation processes where the graphs are\nformed based on one or more global factors which are common to all elements of\nthe graph (e.g., topic of a discussion thread, solubility level of a molecule).\nWe hypothesize extracting these common factors could be highly beneficial.\nHence, this work proposes a new principle for unsupervised graph representation\nlearning: Graph-wise Common latent Factor EXtraction (GCFX). We further propose\na deep model for GCFX, deepGCFX, based on the idea of reversing the\nabove-mentioned graph generation process which could explicitly extract common\nlatent factors from an input graph and achieve improved results on downstream\ntasks to the current state-of-the-art. Through extensive experiments and\nanalysis, we demonstrate that, while extracting common latent factors is\nbeneficial for graph-level tasks to alleviate distractions caused by local\nvariations of individual nodes or local neighbourhoods, it also benefits\nnode-level tasks by enabling long-range node dependencies, especially for\ndisassortative graphs.",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Thilini Cooray",
      "Ngai-Man Cheung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08830"
  },
  {
    "id": "arXiv:2112.08831",
    "title": "Bridging between Cognitive Processing Signals and Linguistic Features  via a Unified Attentional Network",
    "abstract": "Cognitive processing signals can be used to improve natural language\nprocessing (NLP) tasks. However, it is not clear how these signals correlate\nwith linguistic information. Bridging between human language processing and\nlinguistic features has been widely studied in neurolinguistics, usually via\nsingle-variable controlled experiments with highly-controlled stimuli. Such\nmethods not only compromises the authenticity of natural reading, but also are\ntime-consuming and expensive. In this paper, we propose a data-driven method to\ninvestigate the relationship between cognitive processing signals and\nlinguistic features. Specifically, we present a unified attentional framework\nthat is composed of embedding, attention, encoding and predicting layers to\nselectively map cognitive processing signals to linguistic features. We define\nthe mapping procedure as a bridging task and develop 12 bridging tasks for\nlexical, syntactic and semantic features. The proposed framework only requires\ncognitive processing signals recorded under natural reading as inputs, and can\nbe used to detect a wide range of linguistic features with a single cognitive\ndataset. Observations from experiment results resonate with previous\nneuroscience findings. In addition to this, our experiments also reveal a\nnumber of interesting findings, such as the correlation between contextual\neye-tracking features and tense of sentence.",
    "descriptor": "",
    "authors": [
      "Yuqi Ren",
      "Deyi Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08831"
  },
  {
    "id": "arXiv:2112.08835",
    "title": "Self-supervised Enhancement of Latent Discovery in GANs",
    "abstract": "Several methods for discovering interpretable directions in the latent space\nof pre-trained GANs have been proposed. Latent semantics discovered by\nunsupervised methods are relatively less disentangled than supervised methods\nsince they do not use pre-trained attribute classifiers. We propose Scale\nRanking Estimator (SRE), which is trained using self-supervision. SRE enhances\nthe disentanglement in directions obtained by existing unsupervised\ndisentanglement techniques. These directions are updated to preserve the\nordering of variation within each direction in latent space. Qualitative and\nquantitative evaluation of the discovered directions demonstrates that our\nproposed method significantly improves disentanglement in various datasets. We\nalso show that the learned SRE can be used to perform Attribute-based image\nretrieval task without further training.",
    "descriptor": "\nComments: Accepted to the 36th AAAI Conference on Artificial Intelligence (AAAI 2022)\n",
    "authors": [
      "Silpa Vadakkeeveetil Sreelatha",
      "Adarsh Kappiyath",
      "S Sumitra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08835"
  },
  {
    "id": "arXiv:2112.08836",
    "title": "Imbalanced Sample Generation and Evaluation for Power System Transient  Stability Using CTGAN",
    "abstract": "Although deep learning has achieved impressive advances in transient\nstability assessment of power systems, the insufficient and imbalanced samples\nstill trap the training effect of the data-driven methods. This paper proposes\na controllable sample generation framework based on Conditional Tabular\nGenerative Adversarial Network (CTGAN) to generate specified transient\nstability samples. To fit the complex feature distribution of the transient\nstability samples, the proposed framework firstly models the samples as tabular\ndata and uses Gaussian mixture models to normalize the tabular data. Then we\ntransform multiple conditions into a single conditional vector to enable\nmulti-conditional generation. Furthermore, this paper introduces three\nevaluation metrics to verify the quality of generated samples based on the\nproposed framework. Experimental results on the IEEE 39-bus system show that\nthe proposed framework effectively balances the transient stability samples and\nsignificantly improves the performance of transient stability assessment\nmodels.",
    "descriptor": "",
    "authors": [
      "Gengshi Han",
      "Shunyu Liu",
      "Kaixuan Chen",
      "Na Yu",
      "Zunlei Feng",
      "Mingli Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08836"
  },
  {
    "id": "arXiv:2112.08839",
    "title": "Topology Optimization with a Closed Cavity Exclusion Constraint for  Additive Manufacturing Based on the Fictitious Physical Model Approach",
    "abstract": "This paper proposes a topology optimization method that considers the\ngeometric constraint of no closed cavities to improve the effectiveness of\nadditive manufacturing based on the fictitious physical model approach. First,\nthe basic topology optimization concept and level set-based method are\nintroduced. Next, the fictitious physical model for a geometric constraint in\nthe topology optimization framework is discussed. Then, a model for the\ngeometric constraint of no closed cavities for additive manufacturing is\nproposed. Numerical examples are provided to validate the proposed model. In\naddition, topology optimization considering the geometric constraint is\nformulated, and topology optimization algorithms are constructed using the\nfinite element method. Finally, optimization examples are provided to validate\nthe proposed topology optimization method.",
    "descriptor": "\nComments: 29 pages, 14 figures\n",
    "authors": [
      "Takayuki Yamada",
      "Yuki Noguchi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.08839"
  },
  {
    "id": "arXiv:2112.08841",
    "title": "A CNN based method for Sub-pixel Urban Land Cover Classification using  Landsat-5 TM and Resourcesat-1 LISS-IV Imagery",
    "abstract": "Time series data of urban land cover is of great utility in analyzing urban\ngrowth patterns, changes in distribution of impervious surface and vegetation\nand resulting impacts on urban micro climate. While Landsat data is ideal for\nsuch analysis due to the long time series of free imagery, traditional\nper-pixel hard classification fails to yield full potential of the Landsat\ndata. This paper proposes a sub-pixel classification method that leverages the\ntemporal overlap of Landsat-5 TM and Resourcesat-1 LISS-IV sensors. We train a\nconvolutional neural network to predict fractional land cover maps from 30m\nLandsat-5 TM data. The reference land cover fractions are estimated from a\nhard-classified 5.8m LISS-IV image for Bengaluru from 2011. Further, we\ndemonstrate the generalizability and superior performance of the proposed model\nusing data for Mumbai from 2009 and comparing it to the results obtained using\na Random Forest classifier. For both Bengaluru (2011) and Mumbai (2009) data,\nMean Absolute Percentage Error of our CNN model is in the range of 7.2 to 11.3\nfor both built-up and vegetation fraction prediction at the 30m cell level.\nUnlike most recent studies where validation is conducted using data for a\nlimited spatial extent, our model has been trained and validated using data for\nthe complete spatial extent of two mega cities for two different time periods.\nHence it can reliably generate 30m built-up and vegetation fraction maps from\nLandsat-5 TM time series data to analyze long term urban growth patterns.",
    "descriptor": "\nComments: 29 pages, 14 figures (including appendix), 8 tables (including appendix)\n",
    "authors": [
      "Krishna Kumar Perikamana",
      "Krishnachandran Balakrishnan",
      "Pratyush Tripathy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08841"
  },
  {
    "id": "arXiv:2112.08842",
    "title": "Ubiq: A System to Build Flexible Social Virtual Reality Experiences",
    "abstract": "While they have long been a subject of academic study, social virtual reality\n(SVR) systems are now attracting increasingly large audiences on current\nconsumer virtual reality systems. The design space of SVR systems is very\nlarge, and relatively little is known about how these systems should be\nconstructed in order to be usable and efficient. In this paper we present Ubiq,\na toolkit that focuses on facilitating the construction of SVR systems. We\nargue for the design strategy of Ubiq and its scope. Ubiq is built on the Unity\nplatform. It provides core functionality of many SVR systems such as connection\nmanagement, voice, avatars, etc. However, its design remains easy to extend. We\ndemonstrate examples built on Ubiq and how it has been successfully used in\nclassroom teaching. Ubiq is open source (Apache License) and thus enables\nseveral use cases that commercial systems cannot.",
    "descriptor": "",
    "authors": [
      "Sebastian Friston",
      "Ben Congdon",
      "David Swapp",
      "Lisa Izzouzi",
      "Klara Brandst\u00e4tter",
      "Daniel Archer",
      "Otto Olkkonen",
      "Felix Thiel",
      "Anthony Steed"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.08842"
  },
  {
    "id": "arXiv:2112.08844",
    "title": "Adapting Document-Grounded Dialog Systems to Spoken Conversations using  Data Augmentation and a Noisy Channel Model",
    "abstract": "This paper summarizes our submission to Task 2 of the second track of the\n10th Dialog System Technology Challenge (DSTC10) \"Knowledge-grounded\nTask-oriented Dialogue Modeling on Spoken Conversations\". Similar to the\nprevious year's iteration, the task consists of three subtasks: detecting\nwhether a turn is knowledge seeking, selecting the relevant knowledge document\nand finally generating a grounded response. This year, the focus lies on\nadapting the system to noisy ASR transcripts. We explore different approaches\nto make the models more robust to this type of input and to adapt the generated\nresponses to the style of spoken conversations. For the latter, we get the best\nresults with a noisy channel model that additionally reduces the number of\nshort and generic responses. Our best system achieved the 1st rank in the\nautomatic and the 3rd rank in the human evaluation of the challenge.",
    "descriptor": "\nComments: Accepted to the DSTC10 workshop at AAAI 2022\n",
    "authors": [
      "David Thulke",
      "Nico Daheim",
      "Christian Dugast",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08844"
  },
  {
    "id": "arXiv:2112.08845",
    "title": "Multiple Instance Learning for Brain Tumor Detection from Magnetic  Resonance Spectroscopy Data",
    "abstract": "We apply deep learning (DL) on Magnetic resonance spectroscopy (MRS) data for\nthe task of brain tumor detection. Medical applications often suffer from data\nscarcity and corruption by noise. Both of these problems are prominent in our\ndata set. Furthermore, a varying number of spectra are available for the\ndifferent patients. We address these issues by considering the task as a\nmultiple instance learning (MIL) problem. Specifically, we aggregate multiple\nspectra from the same patient into a \"bag\" for classification and apply data\naugmentation techniques. To achieve the permutation invariance during the\nprocess of bagging, we proposed two approaches: (1) to apply min-, max-, and\naverage-pooling on the features of all samples in one bag and (2) to apply an\nattention mechanism. We tested these two approaches on multiple neural network\narchitectures. We demonstrate that classification performance is significantly\nimproved when training on multiple instances rather than single spectra. We\npropose a simple oversampling data augmentation method and show that it could\nfurther improve the performance. Finally, we demonstrate that our proposed\nmodel outperforms manual classification by neuroradiologists according to most\nperformance metrics.",
    "descriptor": "",
    "authors": [
      "Diyuan Lu",
      "Gerhard Kurz",
      "Nenad Polomac",
      "Iskra Gacheva",
      "Elke Hattingen",
      "Jochen Triesch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08845"
  },
  {
    "id": "arXiv:2112.08854",
    "title": "Multi-Camera LiDAR Inertial Extension to the Newer College Dataset",
    "abstract": "In this paper, we present a multi-camera LiDAR inertial dataset of 4.5km\nwalking distance as an expansion to the Newer College Dataset. The global\nshutter multi-camera device is hardware synchronized with the IMU and the\nLiDAR. This dataset also provides six Degrees of Freedom (DoF) ground truth\nposes, at the LiDAR frequency of 10hz. Three data collections are described and\nexample usage of multi-camera visual-inertial odometry is demonstrated. This\nexpansion dataset contains small and narrow passages, large scale open spaces\nas well as vegetated areas to test localization and mapping systems.\nFurthermore, some sequences present challenging situations such as abrupt\nlighting change, textureless surfaces, and aggressive motion. The dataset is\navailable at: https://ori-drs.github.io/newer-college-dataset",
    "descriptor": "",
    "authors": [
      "Lintong Zhang",
      "Marco Camurri",
      "Maurice Fallon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08854"
  },
  {
    "id": "arXiv:2112.08855",
    "title": "A Multi-band Solution for Interacting with Energy-Neutral Devices",
    "abstract": "RF Wireless Power Transfer (WPT) emerges as a technology for charging\nautonomous devices, enabling simultaneous power and information transfer.\nHowever, with increasing distance, single-input, single-channel rectenna\nsystems are not able to meet the power requirements of large scale IoT\napplications. In this paper, we tackle this problem on two levels. First, we\nminimize the energy consumption at the energy-constrained device on three\nlevels. Second, we evolve to a dual-band solution increasing RF WPT. One\nfrequency band is used to provide a base charge to many nodes in a shared\ntransmission. Beam steering, on the other hand, allows for more power hungry\noperations while introducing as minimal interference as possible. We showcase\nthis method for a hybrid RF-acoustic positioning system. Practical measurements\nconducted in a multi-antenna indoor testbed (Techtile) show the additional\npower gain and positioning rate.",
    "descriptor": "",
    "authors": [
      "Chesney Buyle",
      "Bert Cox",
      "Liesbet Van der Perre",
      "Lieven De Strycker"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.08855"
  },
  {
    "id": "arXiv:2112.08862",
    "title": "Addressing Adversarial Machine Learning Attacks in Smart Healthcare  Perspectives",
    "abstract": "Smart healthcare systems are gaining popularity with the rapid development of\nintelligent sensors, the Internet of Things (IoT) applications and services,\nand wireless communications. However, at the same time, several vulnerabilities\nand adversarial attacks make it challenging for a safe and secure smart\nhealthcare system from a security point of view. Machine learning has been used\nwidely to develop suitable models to predict and mitigate attacks. Still, the\nattacks could trick the machine learning models and misclassify outputs\ngenerated by the model. As a result, it leads to incorrect decisions, for\nexample, false disease detection and wrong treatment plans for patients. In\nthis paper, we address the type of adversarial attacks and their impact on\nsmart healthcare systems. We propose a model to examine how adversarial attacks\nimpact machine learning classifiers. To test the model, we use a medical image\ndataset. Our model can classify medical images with high accuracy. We then\nattacked the model with a Fast Gradient Sign Method attack (FGSM) to cause the\nmodel to predict the images and misclassify them inaccurately. Using transfer\nlearning, we train a VGG-19 model with the medical dataset and later implement\nthe FGSM to the Convolutional Neural Network (CNN) to examine the significant\nimpact it causes on the performance and accuracy of the machine learning model.\nOur results demonstrate that the adversarial attack misclassifies the images,\ncausing the model's accuracy rate to drop from 88% to 11%.",
    "descriptor": "",
    "authors": [
      "Arawinkumaar Selvakkumar",
      "Shantanu Pal",
      "Zahra Jadidi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.08862"
  },
  {
    "id": "arXiv:2112.08867",
    "title": "GRAM: Generative Radiance Manifolds for 3D-Aware Image Generation",
    "abstract": "3D-aware image generative modeling aims to generate 3D-consistent images with\nexplicitly controllable camera poses. Recent works have shown promising results\nby training neural radiance field (NeRF) generators on unstructured 2D images,\nbut still can not generate highly-realistic images with fine details. A\ncritical reason is that the high memory and computation cost of volumetric\nrepresentation learning greatly restricts the number of point samples for\nradiance integration during training. Deficient sampling not only limits the\nexpressive power of the generator to handle fine details but also impedes\neffective GAN training due to the noise caused by unstable Monte Carlo\nsampling. We propose a novel approach that regulates point sampling and\nradiance field learning on 2D manifolds, embodied as a set of learned implicit\nsurfaces in the 3D volume. For each viewing ray, we calculate ray-surface\nintersections and accumulate their radiance generated by the network. By\ntraining and rendering such radiance manifolds, our generator can produce high\nquality images with realistic fine details and strong visual 3D consistency.",
    "descriptor": "",
    "authors": [
      "Yu Deng",
      "Jiaolong Yang",
      "Jianfeng Xiang",
      "Xin Tong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08867"
  },
  {
    "id": "arXiv:2112.08874",
    "title": "Computing the Shapley Value of Facts in Query Answering",
    "abstract": "The Shapley value is a game-theoretic notion for wealth distribution that is\nnowadays extensively used to explain complex data-intensive computation, for\ninstance, in network analysis or machine learning. Recent theoretical works\nshow that query evaluation over relational databases fits well in this\nexplanation paradigm. Yet, these works fall short of providing practical\nsolutions to the computational challenge inherent to the Shapley computation.\nWe present in this paper two practically effective solutions for computing\nShapley values in query answering. We start by establishing a tight theoretical\nconnection to the extensively studied problem of query evaluation over\nprobabilistic databases, which allows us to obtain a polynomial-time algorithm\nfor the class of queries for which probability computation is tractable. We\nthen propose a first practical solution for computing Shapley values that\nadopts tools from probabilistic query evaluation. In particular, we capture the\ndependence of query answers on input database facts using Boolean expressions\n(data provenance), and then transform it, via Knowledge Compilation, into a\nparticular circuit form for which we devise an algorithm for computing the\nShapley values. Our second practical solution is a faster yet inexact approach\nthat transforms the provenance to a Conjunctive Normal Form and uses a\nheuristic to compute the Shapley values. Our experiments on TPC-H and IMDB\ndemonstrate the practical effectiveness of our solutions.",
    "descriptor": "",
    "authors": [
      "Daniel Deutch",
      "Nave Frost",
      "Benny Kimelfeld",
      "Mika\u00ebl Monet"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.08874"
  },
  {
    "id": "arXiv:2112.08878",
    "title": "Knowledge Distillation Leveraging Alternative Soft Targets from  Non-Parallel Qualified Speech Data",
    "abstract": "This paper describes a novel knowledge distillation framework that leverages\nacoustically qualified speech data included in an existing training data pool\nas privileged information. In our proposed framework, a student network is\ntrained with multiple soft targets for each utterance that consist of main soft\ntargets from original speakers' utterance and alternative targets from other\nspeakers' utterances spoken under better acoustic conditions as a secondary\nview. These qualified utterances from other speakers, used to generate better\nsoft targets, are collected from a qualified data pool by using strict\nconstraints in terms of word/phone/state durations. Our proposed method is a\nform of target-side data augmentation that creates multiple copies of data with\ncorresponding better soft targets obtained from a qualified data pool. We show\nin our experiments under acoustic model adaptation settings that the proposed\nmethod, exploiting better soft targets obtained from various speakers, can\nfurther improve recognition accuracy compared with conventional methods using\nonly soft targets from original speakers.",
    "descriptor": "",
    "authors": [
      "Tohru Nagano",
      "Takashi Fukuda",
      "Gakuto Kurata"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.08878"
  },
  {
    "id": "arXiv:2112.08879",
    "title": "Looking Outside the Box to Ground Language in 3D Scenes",
    "abstract": "Existing language grounding models often use object proposal bottlenecks: a\npre-trained detector proposes objects in the scene and the model learns to\nselect the answer from these box proposals, without attending to the original\nimage or 3D point cloud. Object detectors are typically trained on a fixed\nvocabulary of objects and attributes that is often too restrictive for\nopen-domain language grounding, where an utterance may refer to visual entities\nat various levels of abstraction, such as a chair, the leg of a chair, or the\ntip of the front leg of a chair. We propose a model for grounding language in\n3D scenes that bypasses box proposal bottlenecks with three main innovations:\ni) Iterative attention across the language stream, the point cloud feature\nstream and 3D box proposals. ii) Transformer decoders with non-parametric\nentity queries that decode 3D boxes for object and part referentials. iii)\nJoint supervision from 3D object annotations and language grounding\nannotations, by treating object detection as grounding of referential\nutterances comprised of a list of candidate category labels. These innovations\nresult in significant quantitative gains (up to +9% absolute improvement on the\nSR3D benchmark) over previous approaches on popular 3D language grounding\nbenchmarks. We ablate each of our innovations to show its contribution to the\nperformance of the model. When applied on language grounding on 2D images with\nminor changes, it performs on par with the state-of-the-art while converges in\nhalf of the GPU time. The code and checkpoints will be made available at\nhttps://github.com/nickgkan/beauty_detr",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Ayush Jain",
      "Nikolaos Gkanatsios",
      "Ishita Mediratta",
      "Katerina Fragkiadaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08879"
  },
  {
    "id": "arXiv:2112.08880",
    "title": "Uplink Transceiver Design and Optimization for Transmissive RMS  Multi-Antenna Systems",
    "abstract": "In this paper, a novel uplink communication for the transmissive\nreconfigurable metasurface (RMS) multi-antenna system with orthogonal frequency\ndivision multiple access (OFDMA) is investigated. Specifically, a transmissive\nRMS-based receiver equipped with a single receiving antenna is first proposed,\nand a far-near field channel model based on planar waves and spherical waves is\ngiven. Then, in order to maximize the system sum-rate of uplink communications,\nwe formulate a joint optimization problem over subcarrier allocation, power\nallocation and RMS transmissive coefficient design. Due to the coupling of\noptimization variables, the optimization problem is non-convex, so it is\nchallenging to solve it directly. In order to tackle this problem, the\nalternating optimization (AO) algorithm is used to decouple the optimization\nvariables and divide the problem into two sub-problems to solve. First, the\nproblem of joint subcarrier allocation and power allocation is solved via the\nLagrangian dual decomposition method. Then, the RMS transmissive coefficient\ndesign can be obtained by applying difference-of-convex (DC) programming,\nsuccessive convex approximation (SCA) and penalty function methods. Finally,\nthe two sub-problems are iterated alternately until convergence is achieved.\nNumerical simulation results verify that the proposed algorithm has good\nconvergence performance and can improve system sum-rate compared with other\nbenchmark algorithms.",
    "descriptor": "",
    "authors": [
      "Zhendong Li",
      "Wen Chen",
      "Jianmin Lu",
      "Kunlun Wang",
      "Jun Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.08880"
  },
  {
    "id": "arXiv:2112.08884",
    "title": "Skeleton Abstraction for Universal Temporal Properties",
    "abstract": "Uniform coloured Petri nets can be abstracted to their skeleton, the\nplace/transition net that simply turns the coloured tokens into black tokens. A\ncoloured net and its skeleton are related by a net morphism. For the\napplication of the skeleton as an abstraction method in the model checking\nprocess, we need to establish a simulation relation between the state spaces of\nthe two nets. Then, universal temporal properties (properties of the $ ACTL^* $\nlogic) are preserved. The abstraction relation induced by a net morphism is not\nnecessarily a simulation relation, due to a subtle issue related to deadlocks.\nWe discuss several situations where the abstraction relation induced by a net\nmorphism is as well a simulation relation, thus preserving $ACTL^*$ properties.\nWe further propose a partition refinement algorithm for folding a\nplace/transition net into a coloured net. This way, skeleton abstraction\nbecomes available for models given as place/transition nets. Experiments\ndemonstrate the capabilities of the proposed technology. Using skeleton\nabstraction, we are capable of solving problems that have not been solved\nbefore in the Model Checking Contest.",
    "descriptor": "",
    "authors": [
      "Sophie Wallner",
      "Karsten Wolf"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.08884"
  },
  {
    "id": "arXiv:2112.08885",
    "title": "A high-order residual-based viscosity finite element method for the  ideal MHD equations",
    "abstract": "We present a high order, robust, and stable shock-capturing technique for\nfinite element approximations of ideal MHD. The method uses continuous Lagrange\npolynomials in space and explicit Runge-Kutta schemes in time. The\nshock-capturing term is based on the residual of MHD which tracks the shock and\ndiscontinuity positions, and adds a sufficient amount of viscosity to stabilize\nthem. The method is tested up to third order polynomial spaces and an expected\nfourth-order convergence rate is obtained for smooth problems. Several\ndiscontinuous benchmarks such as Orszag-Tang, MHD rotor, Brio-Wu problems are\nsolved in one, two, and three spatial dimensions. Sharp shocks and\ndiscontinuity resolutions are obtained.",
    "descriptor": "",
    "authors": [
      "Tuan Anh Dao",
      "Murtazo Nazarov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08885"
  },
  {
    "id": "arXiv:2112.08888",
    "title": "Visual Parameter Selection for Spatial Blind Source Separation",
    "abstract": "Multivariate measurements at irregularly-spaced points and their analysis are\nintegral to many domains. For example, indicators of valuable minerals are\nmeasured for mine prospecting. Dimension reduction (DR) methods, like Principal\nComponent Analysis, are indispensable tools for multivariate data analysis.\nTheir applicability to spatial data is, however, limited. They do not account\nfor Tobler's first law of geography, which states that \"near things are more\nrelated than distant things.\" Spatial blind source separation (SBSS) is a data\nanalysis and DR method developed specifically for spatial multivariate point\ndata and hence accounts for such spatial dependence. SBSS requires analysts to\nset tuning parameters, which are themselves complex spatial objects: A\npartition of the spatial domain into regions and a point neighbourhood\nconfiguration. Their setting is dependent on each other, on domain knowledge of\nthe analyst and data-driven considerations. We present a visual analytics\nprototype that guides and supports analysts in this process. We evaluated it\nwith experts in visualization, SBSS, and geochemistry. Our evaluations show\nthat our interactive prototype allows to define complex and realistic parameter\nsettings efficiently, which was so far impractical. Settings identified by a\nnon-expert led to remarkable and surprising insights for a domain expert",
    "descriptor": "",
    "authors": [
      "Nikolaus Piccolotto",
      "Markus B\u00f6gl",
      "Christoph Muehlmann",
      "Klaus Nordhausen",
      "Peter Filzmoser",
      "Silvia Miksch"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.08888"
  },
  {
    "id": "arXiv:2112.08902",
    "title": "Toward Minimal Misalignment at Minimal Cost in One-Stage and Anchor-Free  Object Detection",
    "abstract": "Common object detection models consist of classification and regression\nbranches, due to different task drivers, these two branches have different\nsensibility to the features from the same scale level and the same spatial\nlocation. The point-based prediction method, which is based on the assumption\nthat the high classification confidence point has the high regression quality,\nleads to the misalignment problem. Our analysis shows, the problem is further\ncomposed of scale misalignment and spatial misalignment specifically. We aim to\nresolve the phenomenon at minimal cost: a minor adjustment of the head network\nand a new label assignment method replacing the rigid one. Our experiments show\nthat, compared to the baseline FCOS, a one-stage and anchor-free object\ndetection model, our model consistently get around 3 AP improvement with\ndifferent backbones, demonstrating both simplicity and efficiency of our\nmethod.",
    "descriptor": "",
    "authors": [
      "Shuaizheng Hao",
      "Hongzhe Liu",
      "Ningwei Wang",
      "Cheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08902"
  },
  {
    "id": "arXiv:2112.08903",
    "title": "Graph Structure Learning with Variational Information Bottleneck",
    "abstract": "Graph Neural Networks (GNNs) have shown promising results on a broad spectrum\nof applications. Most empirical studies of GNNs directly take the observed\ngraph as input, assuming the observed structure perfectly depicts the accurate\nand complete relations between nodes. However, graphs in the real world are\ninevitably noisy or incomplete, which could even exacerbate the quality of\ngraph representations. In this work, we propose a novel Variational Information\nBottleneck guided Graph Structure Learning framework, namely VIB-GSL, in the\nperspective of information theory. VIB-GSL advances the Information Bottleneck\n(IB) principle for graph structure learning, providing a more elegant and\nuniversal framework for mining underlying task-relevant relations. VIB-GSL\nlearns an informative and compressive graph structure to distill the actionable\ninformation for specific downstream tasks. VIB-GSL deduces a variational\napproximation for irregular graph data to form a tractable IB objective\nfunction, which facilitates training stability. Extensive experimental results\ndemonstrate that the superior effectiveness and robustness of VIB-GSL.",
    "descriptor": "\nComments: Accepted by AAAI 2022, Preprint version with Appendix\n",
    "authors": [
      "Qingyun Sun",
      "Jianxin Li",
      "Hao Peng",
      "Jia Wu",
      "Xingcheng Fu",
      "Cheng Ji",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08903"
  },
  {
    "id": "arXiv:2112.08906",
    "title": "On the Uncertain Single-View Depths in Endoscopies",
    "abstract": "Estimating depth from endoscopic images is a pre-requisite for a wide set of\nAI-assisted technologies, namely accurate localization, measurement of tumors,\nor identification of non-inspected areas. As the domain specificity of\ncolonoscopies -- a deformable low-texture environment with fluids, poor\nlighting conditions and abrupt sensor motions -- pose challenges to multi-view\napproaches, single-view depth learning stands out as a promising line of\nresearch. In this paper, we explore for the first time Bayesian deep networks\nfor single-view depth estimation in colonoscopies. Their uncertainty\nquantification offers great potential for such a critical application area. Our\nspecific contribution is two-fold: 1) an exhaustive analysis of Bayesian deep\nnetworks for depth estimation in three different datasets, highlighting\nchallenges and conclusions regarding synthetic-to-real domain changes and\nsupervised vs. self-supervised methods; and 2) a novel teacher-student approach\nto deep depth learning that takes into account the teacher uncertainty.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Javier Rodr\u00edguez-Puigvert",
      "David Recasens",
      "Javier Civera",
      "Rub\u00e9n Mart\u00ednez-Cant\u00edn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08906"
  },
  {
    "id": "arXiv:2112.08907",
    "title": "Inherently Explainable Reinforcement Learning in Natural Language",
    "abstract": "We focus on the task of creating a reinforcement learning agent that is\ninherently explainable -- with the ability to produce immediate local\nexplanations by thinking out loud while performing a task and analyzing entire\ntrajectories post-hoc to produce causal explanations. This Hierarchically\nExplainable Reinforcement Learning agent (HEX-RL), operates in Interactive\nFictions, text-based game environments in which an agent perceives and acts\nupon the world using textual natural language. These games are usually\nstructured as puzzles or quests with long-term dependencies in which an agent\nmust complete a sequence of actions to succeed -- providing ideal environments\nin which to test an agent's ability to explain its actions. Our agent is\ndesigned to treat explainability as a first-class citizen, using an extracted\nsymbolic knowledge graph-based state representation coupled with a Hierarchical\nGraph Attention mechanism that points to the facts in the internal graph\nrepresentation that most influenced the choice of actions. Experiments show\nthat this agent provides significantly improved explanations over strong\nbaselines, as rated by human participants generally unfamiliar with the\nenvironment, while also matching state-of-the-art task performance.",
    "descriptor": "",
    "authors": [
      "Xiangyu Peng",
      "Mark O. Riedl",
      "Prithviraj Ammanabrolu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08907"
  },
  {
    "id": "arXiv:2112.08908",
    "title": "Effective high order integrators for linear Klein-Gordon equations in  low to highly oscillatory regimes",
    "abstract": "We introduce an efficient class of high order schemes for the Klein--Gordon\nequation from low to high frequency regimes. The new schemes resolve the\noscillations triggered by the input term and allow for second order convergence\nin time uniformly in the high frequencies $\\omega_n$ and fourth order\nconvergence under the natural scaling $\\Delta t \\sim 1/\\sqrt[3]{\\vert\n\\omega_n\\vert}$. The construction is based on Magnus expansions tailored to the\nstructure of the input term. Numerically experiments underline our theoretical\nfindings and show the efficiency of the new schemes.",
    "descriptor": "",
    "authors": [
      "Karolina Kropielnicka",
      "Karolina Lademann",
      "Katharina Schratz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08908"
  },
  {
    "id": "arXiv:2112.08909",
    "title": "CodedPaddedFL and CodedSecAgg: Straggler Mitigation and Secure  Aggregation in Federated Learning",
    "abstract": "We present two novel coded federated learning (FL) schemes for linear\nregression that mitigate the effect of straggling devices. The first scheme,\nCodedPaddedFL, mitigates the effect of straggling devices while retaining the\nprivacy level of conventional FL. Particularly, it combines one-time padding\nfor user data privacy with gradient codes to yield resiliency against\nstraggling devices. To apply one-time padding to real data, our scheme exploits\na fixed-point arithmetic representation of the data. For a scenario with 25\ndevices, CodedPaddedFL achieves a speed-up factor of 6.6 and 9.2 for an\naccuracy of 95\\% and 85\\% on the MMIST and Fashion-MNIST datasets,\nrespectively, compared to conventional FL. Furthermore, it yields similar\nperformance in terms of latency compared to a recently proposed scheme by\nPrakash \\emph{et al.} without the shortcoming of additional leakage of private\ndata. The second scheme, CodedSecAgg, provides straggler resiliency and\nrobustness against model inversion attacks and is based on Shamir's secret\nsharing. CodedSecAgg outperforms state-of-the-art secure aggregation schemes\nsuch as LightSecAgg by a speed-up factor of 6.6--14.6, depending on the number\nof colluding devices, on the MNIST dataset for a scenario with 120 devices, at\nthe expense of a 30\\% increase in latency compared to CodedPaddedFL.",
    "descriptor": "\nComments: 12 pages, 7 figures, this work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Reent Schlegel",
      "Siddhartha Kumar",
      "Eirik Rosnes",
      "Alexandre Graell i Amat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.08909"
  },
  {
    "id": "arXiv:2112.08910",
    "title": "Gendered Language in Resumes and its Implications for Algorithmic Bias  in Hiring",
    "abstract": "Despite growing concerns around gender bias in NLP models used in algorithmic\nhiring, there is little empirical work studying the extent and nature of\ngendered language in resumes. Using a corpus of 709k resumes from IT firms, we\ntrain a series of models to classify the gender of the applicant, thereby\nmeasuring the extent of gendered information encoded in resumes. We also\ninvestigate whether it is possible to obfuscate gender from resumes by removing\ngender identifiers, hobbies, gender sub-space in embedding models, etc. We find\nthat there is a significant amount of gendered information in resumes even\nafter obfuscation. A simple Tf-Idf model can learn to classify gender with\nAUROC=0.75, and more sophisticated transformer-based models achieve AUROC=0.8.\nWe further find that gender predictive values have low correlation with gender\ndirection of embeddings -- meaning that, what is predictive of gender is much\nmore than what is \"gendered\" in the masculine/feminine sense. We discuss the\nalgorithmic bias and fairness implications of these findings in the hiring\ncontext.",
    "descriptor": "\nComments: None\n",
    "authors": [
      "Prasanna Parasurama",
      "Jo\u00e3o Sedoc"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.08910"
  },
  {
    "id": "arXiv:2112.08913",
    "title": "Contrastive Spatio-Temporal Pretext Learning for Self-supervised Video  Representation",
    "abstract": "Spatio-temporal representation learning is critical for video self-supervised\nrepresentation. Recent approaches mainly use contrastive learning and pretext\ntasks. However, these approaches learn representation by discriminating sampled\ninstances via feature similarity in the latent space while ignoring the\nintermediate state of the learned representations, which limits the overall\nperformance. In this work, taking into account the degree of similarity of\nsampled instances as the intermediate state, we propose a novel pretext task -\nspatio-temporal overlap rate (STOR) prediction. It stems from the observation\nthat humans are capable of discriminating the overlap rates of videos in space\nand time. This task encourages the model to discriminate the STOR of two\ngenerated samples to learn the representations. Moreover, we employ a joint\noptimization combining pretext tasks with contrastive learning to further\nenhance the spatio-temporal representation learning. We also study the mutual\ninfluence of each component in the proposed scheme. Extensive experiments\ndemonstrate that our proposed STOR task can favor both contrastive learning and\npretext tasks. The joint optimization scheme can significantly improve the\nspatio-temporal representation in video understanding. The code is available at\nhttps://github.com/Katou2/CSTP.",
    "descriptor": "\nComments: Accepted by AAAI 2022, Preprint version with Appendix\n",
    "authors": [
      "Yujia Zhang",
      "Lai-Man Po",
      "Xuyuan Xu",
      "Mengyang Liu",
      "Yexin Wang",
      "Weifeng Ou",
      "Yuzhi Zhao",
      "Wing-Yin Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08913"
  },
  {
    "id": "arXiv:2112.08914",
    "title": "Characterizing and addressing the issue of oversmoothing in neural  autoregressive sequence modeling",
    "abstract": "Neural autoregressive sequence models smear the probability among many\npossible sequences including degenerate ones, such as empty or repetitive\nsequences. In this work, we tackle one specific case where the model assigns a\nhigh probability to unreasonably short sequences. We define the oversmoothing\nrate to quantify this issue. After confirming the high degree of oversmoothing\nin neural machine translation, we propose to explicitly minimize the\noversmoothing rate during training. We conduct a set of experiments to study\nthe effect of the proposed regularization on both model distribution and\ndecoding performance. We use a neural machine translation task as the testbed\nand consider three different datasets of varying size. Our experiments reveal\nthree major findings. First, we can control the oversmoothing rate of the model\nby tuning the strength of the regularization. Second, by enhancing the\noversmoothing loss contribution, the probability and the rank of <eos> token\ndecrease heavily at positions where it is not supposed to be. Third, the\nproposed regularization impacts the outcome of beam search especially when a\nlarge beam is used. The degradation of translation quality (measured in BLEU)\nwith a large beam significantly lessens with lower oversmoothing rate, but the\ndegradation compared to smaller beam sizes remains to exist. From these\nobservations, we conclude that the high degree of oversmoothing is the main\nreason behind the degenerate case of overly probable short sequences in a\nneural autoregressive model.",
    "descriptor": "\nComments: Ilia Kulikov and Maksim Eremeev contributed equally\n",
    "authors": [
      "Ilia Kulikov",
      "Maksim Eremeev",
      "Kyunghyun Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08914"
  },
  {
    "id": "arXiv:2112.08916",
    "title": "GOSH: Task Scheduling Using Deep Surrogate Models in Fog Computing  Environments",
    "abstract": "Recently, intelligent scheduling approaches using surrogate models have been\nproposed to efficiently allocate volatile tasks in heterogeneous fog\nenvironments. Advances like deterministic surrogate models, deep neural\nnetworks (DNN) and gradient-based optimization allow low energy consumption and\nresponse times to be reached. However, deterministic surrogate models, which\nestimate objective values for optimization, do not consider the uncertainties\nin the distribution of the Quality of Service (QoS) objective function that can\nlead to high Service Level Agreement (SLA) violation rates. Moreover, the\nbrittle nature of DNN training and prevent such models from reaching minimal\nenergy or response times. To overcome these difficulties, we present a novel\nscheduler: GOSH i.e. Gradient Based Optimization using Second Order derivatives\nand Heteroscedastic Deep Surrogate Models. GOSH uses a second-order gradient\nbased optimization approach to obtain better QoS and reduce the number of\niterations to converge to a scheduling decision, subsequently lowering the\nscheduling time. Instead of a vanilla DNN, GOSH uses a Natural Parameter\nNetwork to approximate objective scores. Further, a Lower Confidence Bound\noptimization approach allows GOSH to find an optimal trade-off between greedy\nminimization of the mean latency and uncertainty reduction by employing\nerror-based exploration. Thus, GOSH and its co-simulation based extension\nGOSH*, can adapt quickly and reach better objective scores than baseline\nmethods. We show that GOSH* reaches better objective scores than GOSH, but it\nis suitable only for high resource availability settings, whereas GOSH is apt\nfor limited resource settings. Real system experiments for both GOSH and GOSH*\nshow significant improvements against the state-of-the-art in terms of energy\nconsumption, response time and SLA violations by up to 18, 27 and 82 percent,\nrespectively.",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Parallel and Distributed Systems (Special Issue on PDC for AI), 2022\n",
    "authors": [
      "Shreshth Tuli",
      "Giuliano Casale",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.08916"
  },
  {
    "id": "arXiv:2112.08918",
    "title": "Khmer Word Search: Challenges, Solutions, and Semantic-Aware Search",
    "abstract": "Search is one of the key functionalities in digital platforms and\napplications such as an electronic dictionary, a search engine, and an\ne-commerce platform. While the search function in some languages is trivial,\nKhmer word search is challenging given its complex writing system. Multiple\norders of characters and different spelling realizations of words impose a\nconstraint on Khmer word search functionality. Additionally, spelling mistakes\nare common since robust spellcheckers are not commonly available across the\ninput device platforms. These challenges hinder the use of Khmer language in\nsearch-embedded applications. Moreover, due to the absence of WordNet-like\nlexical databases for Khmer language, it is impossible to establish semantic\nrelation between words, enabling semantic search. In this paper, we propose a\nset of robust solutions to the above challenges associated with Khmer word\nsearch. The proposed solutions include character order normalization, grapheme\nand phoneme-based spellcheckers, and Khmer word semantic model. The semantic\nmodel is based on the word embedding model that is trained on a 30-million-word\ncorpus and is used to capture the semantic similarities between words.",
    "descriptor": "",
    "authors": [
      "Rina Buoy",
      "Nguonly Taing",
      "Sovisal Chenda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08918"
  },
  {
    "id": "arXiv:2112.08919",
    "title": "Deep Generative Models for Geometric Design Under Uncertainty",
    "abstract": "Deep generative models have demonstrated effectiveness in learning compact\nand expressive design representations that significantly improve geometric\ndesign optimization. However, these models do not consider the uncertainty\nintroduced by manufacturing or fabrication. Past work that quantifies such\nuncertainty often makes simplified assumptions on geometric variations, while\nthe \"real-world\" uncertainty and its impact on design performance are difficult\nto quantify due to the high dimensionality. To address this issue, we propose a\nGenerative Adversarial Network-based Design under Uncertainty Framework\n(GAN-DUF), which contains a deep generative model that simultaneously learns a\ncompact representation of nominal (ideal) designs and the conditional\ndistribution of fabricated designs given any nominal design. We demonstrated\nthe framework on two real-world engineering design examples and showed its\ncapability of finding the solution that possesses better performances after\nfabrication.",
    "descriptor": "\nComments: AAAI 2022 Workshop on AI for Design and Manufacturing (ADAM)\n",
    "authors": [
      "Chen",
      "Doksoo Lee",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08919"
  },
  {
    "id": "arXiv:2112.08921",
    "title": "Quaternion tensor singular value decomposition using a flexible  transform-based approach",
    "abstract": "A flexible transform-based tensor product named $\\star_{{\\rm{QT}}}$-product\nfor $L$th-order ($L\\geq 3$) quaternion tensors is proposed. Based on the\n$\\star_{{\\rm{QT}}}$-product, we define the corresponding singular value\ndecomposition named TQt-SVD and the rank named TQt-rank of the $L$th-order\n($L\\geq 3$) quaternion tensor. Furthermore, with orthogonal quaternion\ntransformations, the TQt-SVD can provide the best TQt-rank-$s$ approximation of\nany $L$th-order ($L\\geq 3$) quaternion tensor. In the experiments, we have\nverified the effectiveness of the proposed TQt-SVD in the application of the\nbest TQt-rank-$s$ approximation for color videos represented by third-order\nquaternion tensors.",
    "descriptor": "",
    "authors": [
      "Jifei Miao",
      "Kit Ian Kou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08921"
  },
  {
    "id": "arXiv:2112.08928",
    "title": "A Superconducting Nanowire-based Architecture for Neuromorphic Computing",
    "abstract": "Neuromorphic computing is poised to further the success of software-based\nneural networks by utilizing improved customized hardware. However, the\ntranslation of neuromorphic algorithms to hardware specifications is a problem\nthat has been seldom explored. Building superconducting neuromorphic systems\nrequires extensive expertise in both superconducting physics and theoretical\nneuroscience. In this work, we aim to bridge this gap by presenting a tool and\nmethodology to translate algorithmic parameters into circuit specifications. We\nfirst show the correspondence between theoretical neuroscience models and the\ndynamics of our circuit topologies. We then apply this tool to solve linear\nsystems by implementing a spiking neural network with our superconducting\nnanowire-based hardware.",
    "descriptor": "\nComments: 29 pages, 10 figures\n",
    "authors": [
      "Andres E. Lombo",
      "Jesus E. Lares",
      "Matteo Castellani",
      "Chi-Ning Chou",
      "Nancy Lynch",
      "Karl K. Berggren"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Superconductivity (cond-mat.supr-con)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.08928"
  },
  {
    "id": "arXiv:2112.08930",
    "title": "Intelli-Paint: Towards Developing Human-like Painting Agents",
    "abstract": "The generation of well-designed artwork is often quite time-consuming and\nassumes a high degree of proficiency on part of the human painter. In order to\nfacilitate the human painting process, substantial research efforts have been\nmade on teaching machines how to \"paint like a human\", and then using the\ntrained agent as a painting assistant tool for human users. However, current\nresearch in this direction is often reliant on a progressive grid-based\ndivision strategy wherein the agent divides the overall image into successively\nfiner grids, and then proceeds to paint each of them in parallel. This\ninevitably leads to artificial painting sequences which are not easily\nintelligible to human users. To address this, we propose a novel painting\napproach which learns to generate output canvases while exhibiting a more\nhuman-like painting style. The proposed painting pipeline Intelli-Paint\nconsists of 1) a progressive layering strategy which allows the agent to first\npaint a natural background scene representation before adding in each of the\nforeground objects in a progressive fashion. 2) We also introduce a novel\nsequential brushstroke guidance strategy which helps the painting agent to\nshift its attention between different image regions in a semantic-aware manner.\n3) Finally, we propose a brushstroke regularization strategy which allows for\n~60-80% reduction in the total number of required brushstrokes without any\nperceivable differences in the quality of the generated canvases. Through both\nquantitative and qualitative results, we show that the resulting agents not\nonly show enhanced efficiency in output canvas generation but also exhibit a\nmore natural-looking painting style which would better assist human users\nexpress their ideas through digital artwork.",
    "descriptor": "",
    "authors": [
      "Jaskirat Singh",
      "Cameron Smith",
      "Jose Echevarria",
      "Liang Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08930"
  },
  {
    "id": "arXiv:2112.08931",
    "title": "COVID-19 Electrocardiograms Classification using CNN Models",
    "abstract": "With the periodic rise and fall of COVID-19 and numerous countries being\naffected by its ramifications, there has been a tremendous amount of work that\nhas been done by scientists, researchers, and doctors all over the world.\nPrompt intervention is keenly needed to tackle the unconscionable dissemination\nof the disease. The implementation of Artificial Intelligence (AI) has made a\nsignificant contribution to the digital health district by applying the\nfundamentals of deep learning algorithms. In this study, a novel approach is\nproposed to automatically diagnose the COVID-19 by the utilization of\nElectrocardiogram (ECG) data with the integration of deep learning algorithms,\nspecifically the Convolutional Neural Network (CNN) models. Several CNN models\nhave been utilized in this proposed framework, including VGG16, VGG19,\nInceptionResnetv2, InceptionV3, Resnet50, and Densenet201. The VGG16 model has\noutperformed the rest of the models, with an accuracy of 85.92%. Our results\nshow a relatively low accuracy in the rest of the models compared to the VGG16\nmodel, which is due to the small size of the utilized dataset, in addition to\nthe exclusive utilization of the Grid search hyperparameters optimization\napproach for the VGG16 model only. Moreover, our results are preparatory, and\nthere is a possibility to enhance the accuracy of all models by further\nexpanding the dataset and adapting a suitable hyperparameters optimization\ntechnique.",
    "descriptor": "\nComments: 5 pages, 4 figures, accepted in the 14th International Conference on Developments in eSystems Engineering, 7-10 December, 2021\n",
    "authors": [
      "Ismail Shahin",
      "Ali Bou Nassif",
      "Mohamed Bader Alsabek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.08931"
  },
  {
    "id": "arXiv:2112.08932",
    "title": "Learning from Guided Play: A Scheduled Hierarchical Approach for  Improving Exploration in Adversarial Imitation Learning",
    "abstract": "Effective exploration continues to be a significant challenge that prevents\nthe deployment of reinforcement learning for many physical systems. This is\nparticularly true for systems with continuous and high-dimensional state and\naction spaces, such as robotic manipulators. The challenge is accentuated in\nthe sparse rewards setting, where the low-level state information required for\nthe design of dense rewards is unavailable. Adversarial imitation learning\n(AIL) can partially overcome this barrier by leveraging expert-generated\ndemonstrations of optimal behaviour and providing, essentially, a replacement\nfor dense reward information. Unfortunately, the availability of expert\ndemonstrations does not necessarily improve an agent's capability to explore\neffectively and, as we empirically show, can lead to inefficient or stagnated\nlearning. We present Learning from Guided Play (LfGP), a framework in which we\nleverage expert demonstrations of, in addition to a main task, multiple\nauxiliary tasks. Subsequently, a hierarchical model is used to learn each task\nreward and policy through a modified AIL procedure, in which exploration of all\ntasks is enforced via a scheduler composing different tasks together. This\naffords many benefits: learning efficiency is improved for main tasks with\nchallenging bottleneck transitions, expert data becomes reusable between tasks,\nand transfer learning through the reuse of learned auxiliary task models\nbecomes possible. Our experimental results in a challenging multitask robotic\nmanipulation domain indicate that our method compares favourably to supervised\nimitation learning and to a state-of-the-art AIL method. Code is available at\nhttps://github.com/utiasSTARS/lfgp.",
    "descriptor": "\nComments: Accepted at the Neurips 2021 Deep Reinforcement Learning Workshop, Sydney, Australia\n",
    "authors": [
      "Trevor Ablett",
      "Bryan Chan",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08932"
  },
  {
    "id": "arXiv:2112.08933",
    "title": "Responsive parallelized architecture for deploying deep learning models  in production environments",
    "abstract": "Recruiters can easily shortlist candidates for jobs via viewing their\ncurriculum vitae document. Unstructured document CV beholds candidates\nportfolio and named entities listing details. The main aim of this study is to\ndesign and propose a web oriented, highly responsive, computational pipeline\nthat systematically predicts CV entities using hierarchically refined label\nattention networks.",
    "descriptor": "\nComments: 20 Pages\n",
    "authors": [
      "Nikhil Verma",
      "Krishna Prasad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08933"
  },
  {
    "id": "arXiv:2112.08935",
    "title": "MVSS-Net: Multi-View Multi-Scale Supervised Networks for Image  Manipulation Detection",
    "abstract": "The key research question for image manipulation detection is how to learn\ngeneralizable features that are sensitive to manipulations in novel data,\nwhilst specific to prevent false alarms on authentic images. Current research\nemphasizes the sensitivity, with the specificity mostly ignored. In this paper\nwe address both aspects by multi-view feature learning and multi-scale\nsupervision. By exploiting noise distribution and boundary artifacts\nsurrounding tampered regions, the former aims to learn semantic-agnostic and\nthus more generalizable features. The latter allows us to learn from authentic\nimages which are nontrivial to be taken into account by the prior art that\nrelies on a semantic segmentation loss. Our thoughts are realized by a new\nnetwork which we term MVSS-Net and its enhanced version MVSS-Net++.\nComprehensive experiments on six public benchmark datasets justify the\nviability of the MVSS-Net series for both pixel-level and image-level\nmanipulation detection.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2104.06832\n",
    "authors": [
      "Chengbo Dong",
      "Xinru Chen",
      "Ruohan Hu",
      "Juan Cao",
      "Xirong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08935"
  },
  {
    "id": "arXiv:2112.08936",
    "title": "Autonomous Driving in Adverse Weather Conditions: A Survey",
    "abstract": "Automated Driving Systems (ADS) open up a new domain for the automotive\nindustry and offer new possibilities for future transportation with higher\nefficiency and comfortable experiences. However, autonomous driving under\nadverse weather conditions has been the problem that keeps autonomous vehicles\n(AVs) from going to level 4 or higher autonomy for a long time. This paper\nassesses the influences and challenges that weather brings to ADS sensors in an\nanalytic and statistical way, and surveys the solutions against inclement\nweather conditions. State-of-the-art techniques on perception enhancement with\nregard to each kind of weather are thoroughly reported. External auxiliary\nsolutions like V2X technology, weather conditions coverage in currently\navailable datasets, simulators, and experimental facilities with weather\nchambers are distinctly sorted out. By pointing out all kinds of major weather\nproblems the autonomous driving field is currently facing, and reviewing both\nhardware and computer science solutions in recent years, this survey\ncontributes a holistic overview on the obstacles and directions of ADS\ndevelopment in terms of adverse weather driving conditions.",
    "descriptor": "",
    "authors": [
      "Yuxiao Zhang",
      "Alexander Carballo",
      "Hanting Yang",
      "Kazuya Takeda"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08936"
  },
  {
    "id": "arXiv:2112.08940",
    "title": "Challenges and Solutions to Build a Data Pipeline to Identify Anomalies  in Enterprise System Performance",
    "abstract": "We discuss how VMware is solving the following challenges to harness data to\noperate our ML-based anomaly detection system to detect performance issues in\nour Software Defined Data Center (SDDC) enterprise deployments: (i) label\nscarcity and label bias due to heavy dependency on unscalable human annotators,\nand (ii) data drifts due to ever-changing workload patterns, software stack and\nunderlying hardware. Our anomaly detection system has been deployed in\nproduction for many years and has successfully detected numerous major\nperformance issues. We demonstrate that by addressing these data challenges, we\nnot only improve the accuracy of our performance anomaly detection model by\n30%, but also ensure that the model performance to never degrade over time.",
    "descriptor": "",
    "authors": [
      "Xiaobo Huang",
      "Amitabha Banerjee",
      "Chien-Chia Chen",
      "Chengzhi Huang",
      "Tzu Yi Chuang",
      "Abhishek Srivastava",
      "Razvan Cheveresan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08940"
  },
  {
    "id": "arXiv:2112.08943",
    "title": "Towards Homomorphic Inference Beyond the Edge",
    "abstract": "Beyond edge devices can function off the power grid and without batteries,\nenabling them to operate in difficult to access regions. However, energy costly\nlong-distance communication required for reporting results or offloading\ncomputation becomes a limitation. Here, we reduce this overhead by developing a\nbeyond edge device which can effectively act as a nearby server to offload\ncomputation. For security reasons, this device must operate on encrypted data,\nwhich incurs a high overhead. We use energy-efficient and intermittent-safe\nin-memory computation to enable this encrypted computation, allowing it to\nprovide a speedup for beyond edge applications within a power budget of a few\nmilliWatts.",
    "descriptor": "",
    "authors": [
      "Salonik Resch",
      "Zamshed I. Chowdhury",
      "Husrev Cilasun",
      "Masoud Zabihi",
      "Zhengyang Zhao",
      "Jian-Ping Wang",
      "Sachin Sapatnekar",
      "Ulya R. Karpuzcu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.08943"
  },
  {
    "id": "arXiv:2112.08947",
    "title": "Computational metrics and parameters of an injection-locked large area  semiconductor laser for neural network computing",
    "abstract": "Artificial neural networks have become a staple computing technique in many\nfields. Yet, they present fundamental differences with classical computing\nhardware in the way they process information. Photonic implementations of\nneural network architectures potentially offer fundamental advantages over\ntheir electronic counterparts in terms of speed, processing parallelism,\nscalability and energy efficiency. Scalable and high performance photonic\nneural networks (PNNs) have been demonstrated, yet they remain scarce. In this\nwork, we study the performance of such a scalable, fully parallel and\nautonomous PNN based on a large area vertical-cavity surface-emitting laser\n(LA-VCSEL). We show how the performance varies with different physical\nparameters, namely, injection wavelength, injection power, and bias current.\nFurthermore, we link these physical parameters to the general computational\nmeasures of consistency and dimensionality. We present a general method of\ngauging dimensionality in high dimensional nonlinear systems subject to noise,\nwhich could be applied to many systems in the context of neuromorphic\ncomputing. Our work will inform future implementations of spatially multiplexed\nVCSEL PNNs.",
    "descriptor": "",
    "authors": [
      "Anas Skalli",
      "Xavier Porte",
      "Nasibeh Haghighi",
      "Stephan Reitzenstein",
      "James A. Lott",
      "D. Brunner"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.08947"
  },
  {
    "id": "arXiv:2112.08949",
    "title": "Slot-VPS: Object-centric Representation Learning for Video Panoptic  Segmentation",
    "abstract": "Video Panoptic Segmentation (VPS) aims at assigning a class label to each\npixel, uniquely segmenting and identifying all object instances consistently\nacross all frames. Classic solutions usually decompose the VPS task into\nseveral sub-tasks and utilize multiple surrogates (e.g. boxes and masks,\ncentres and offsets) to represent objects. However, this divide-and-conquer\nstrategy requires complex post-processing in both spatial and temporal domains\nand is vulnerable to failures from surrogate tasks. In this paper, inspired by\nobject-centric learning which learns compact and robust object representations,\nwe present Slot-VPS, the first end-to-end framework for this task. We encode\nall panoptic entities in a video, including both foreground instances and\nbackground semantics, with a unified representation called panoptic slots. The\ncoherent spatio-temporal object's information is retrieved and encoded into the\npanoptic slots by the proposed Video Panoptic Retriever, enabling it to\nlocalize, segment, differentiate, and associate objects in a unified manner.\nFinally, the output panoptic slots can be directly converted into the class,\nmask, and object ID of panoptic objects in the video. We conduct extensive\nablation studies and demonstrate the effectiveness of our approach on two\nbenchmark datasets, Cityscapes-VPS (\\textit{val} and test sets) and VIPER\n(\\textit{val} set), achieving new state-of-the-art performance of 63.7, 63.3\nand 56.2 VPQ, respectively.",
    "descriptor": "",
    "authors": [
      "Yi Zhou",
      "Hui Zhang",
      "Hana Lee",
      "Shuyang Sun",
      "Pingjun Li",
      "Yangguang Zhu",
      "ByungIn Yoo",
      "Xiaojuan Qi",
      "Jae-Joon Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08949"
  },
  {
    "id": "arXiv:2112.08950",
    "title": "Stable Long-Term Recurrent Video Super-Resolution",
    "abstract": "Recurrent models have gained popularity in deep learning (DL) based video\nsuper-resolution (VSR), due to their increased computational efficiency,\ntemporal receptive field and temporal consistency compared to sliding-window\nbased models. However, when inferring on long video sequences presenting low\nmotion (i.e. in which some parts of the scene barely move), recurrent models\ndiverge through recurrent processing, generating high frequency artifacts. To\nthe best of our knowledge, no study about VSR pointed out this instability\nproblem, which can be critical for some real-world applications. Video\nsurveillance is a typical example where such artifacts would occur, as both the\ncamera and the scene stay static for a long time.\nIn this work, we expose instabilities of existing recurrent VSR networks on\nlong sequences with low motion. We demonstrate it on a new long sequence\ndataset Quasi-Static Video Set, that we have created. Finally, we introduce a\nnew framework of recurrent VSR networks that is both stable and competitive,\nbased on Lipschitz stability theory. We propose a new recurrent VSR network,\ncoined Middle Recurrent Video Super-Resolution (MRVSR), based on this\nframework. We empirically show its competitive performance on long sequences\nwith low motion.",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Benjamin Naoto Chiche",
      "Arnaud Woiselle",
      "Joana Frontera-Pons",
      "Jean-Luc Starck"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.08950"
  },
  {
    "id": "arXiv:2112.08952",
    "title": "Developing a Suitability Assessment Criteria for Software Developers:  Behavioral Assessment Using Psychometric Test",
    "abstract": "Developing a Suitability Assessment Criteria for Software Developers:\nBehavioral Assessment Using Psychometric Test",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Jayati Gulati",
      "Bharti Suri",
      "Luiz Fernando Capretz",
      "Bimlesh Wadhwa",
      "Anu Singh Lather"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.08952"
  },
  {
    "id": "arXiv:2112.08953",
    "title": "Deciding twin-width at most 4 is NP-complete",
    "abstract": "We show that determining if an $n$-vertex graph has twin-width at most 4 is\nNP-complete, and requires time $2^{\\Omega(n/\\log n)}$ unless the\nExponential-Time Hypothesis fails. Along the way, we give an elementary proof\nthat $n$-vertex graphs subdivided at least $2 \\log n$ times have twin-width at\nmost 4. We also show how to encode trigraphs $H$ (2-edge colored graphs\ninvolved in the definition of twin-width) into graphs $G$, in the sense that\nevery $d$-sequence (sequence of vertex contractions witnessing that the\ntwin-width is at most $d$) of $G$ inevitably creates $H$ as an induced\nsubtrigraph, whereas there exists a partial $d$-sequence that actually goes\nfrom $G$ to $H$. We believe that these facts and their proofs can be of\nindependent interest.",
    "descriptor": "\nComments: 30 pages, 17 figures\n",
    "authors": [
      "Pierre Berg\u00e9",
      "\u00c9douard Bonnet",
      "Hugues D\u00e9pr\u00e9s"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.08953"
  },
  {
    "id": "arXiv:2112.08954",
    "title": "Advancing Residual Learning towards Powerful Deep Spiking Neural  Networks",
    "abstract": "Despite the rapid progress of neuromorphic computing, inadequate capacity and\ninsufficient representation power of spiking neural networks (SNNs) severely\nrestrict their application scope in practice. Residual learning and shortcuts\nhave been evidenced as an important approach for training deep neural networks,\nbut rarely did previous work assess their applicability to the characteristics\nof spike-based communication and spatiotemporal dynamics. In this paper, we\nfirst identify that this negligence leads to impeded information flow and\naccompanying degradation problem in previous residual SNNs. Then we propose a\nnovel SNN-oriented residual block, MS-ResNet, which is able to significantly\nextend the depth of directly trained SNNs, e.g. up to 482 layers on CIFAR-10\nand 104 layers on ImageNet, without observing any slight degradation problem.\nWe validate the effectiveness of MS-ResNet on both frame-based and neuromorphic\ndatasets, and MS-ResNet104 achieves a superior result of 76.02% accuracy on\nImageNet, the first time in the domain of directly trained SNNs. Great energy\nefficiency is also observed that on average only one spike per neuron is needed\nto classify an input sample. We believe our powerful and scalable models will\nprovide a strong support for further exploration of SNNs.",
    "descriptor": "",
    "authors": [
      "Yifan Hu",
      "Yujie Wu",
      "Lei Deng",
      "Guoqi Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08954"
  },
  {
    "id": "arXiv:2112.08959",
    "title": "A molecular generative model with genetic algorithm and tree search for  cancer samples",
    "abstract": "Personalized medicine is expected to maximize the intended drug effects and\nminimize side effects by treating patients based on their genetic profiles.\nThus, it is important to generate drugs based on the genetic profiles of\ndiseases, especially in anticancer drug discovery. However, this is challenging\nbecause the vast chemical space and variations in cancer properties require a\nhuge time resource to search for proper molecules. Therefore, an efficient and\nfast search method considering genetic profiles is required for de novo\nmolecular design of anticancer drugs. Here, we propose a faster molecular\ngenerative model with genetic algorithm and tree search for cancer samples\n(FasterGTS). FasterGTS is constructed with a genetic algorithm and a Monte\nCarlo tree search with three deep neural networks: supervised learning,\nself-trained, and value networks, and it generates anticancer molecules based\non the genetic profiles of a cancer sample. When compared to other methods,\nFasterGTS generated cancer sample-specific molecules with general chemical\nproperties required for cancer drugs within the limited numbers of samplings.\nWe expect that FasterGTS contributes to the anticancer drug generation.",
    "descriptor": "",
    "authors": [
      "Sejin Park",
      "Hyunju Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08959"
  },
  {
    "id": "arXiv:2112.08967",
    "title": "End-to-End Multi-Task Deep Learning and Model Based Control Algorithm  for Autonomous Driving",
    "abstract": "End-to-end driving with a deep learning neural network (DNN) has become a\nrapidly growing paradigm of autonomous driving in industry and academia. Yet\nsafety measures and interpretability still pose challenges to this paradigm. We\npropose an end-to-end driving algorithm that integrates multi-task DNN, path\nprediction, and control models in a pipeline of data flow from sensory devices\nthrough these models to driving decisions. It provides quantitative measures to\nevaluate the holistic, dynamic, and real-time performance of end-to-end driving\nsystems, and thus allows to quantify their safety and interpretability. The DNN\nis a modified UNet, a well known encoder-decoder neural network of semantic\nsegmentation. It consists of one segmentation, one regression, and two\nclassification tasks for lane segmentation, path prediction, and vehicle\ncontrols. We present three variants of the modified UNet architecture having\ndifferent complexities, compare them on different tasks in four static measures\nfor both single and multi-task (MT) architectures, and then identify the best\none by two additional dynamic measures in real-time simulation. We also propose\na learning- and model-based longitudinal controller using model predictive\ncontrol method. With the Stanley lateral controller, our results show that\nMTUNet outperforms an earlier modified UNet in terms of curvature and lateral\noffset estimation on curvy roads at normal speed, which has been tested in a\nreal car driving on real roads.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Der-Hau Lee",
      "Jinn-Liang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08967"
  },
  {
    "id": "arXiv:2112.08970",
    "title": "Joint Analog and Digital Transceiver Design for Wideband Full Duplex  MIMO Systems",
    "abstract": "In this paper, we propose a wideband Full Duplex (FD) Multiple-Input\nMultiple-Output (MIMO) communication system comprising of an FD MIMO node\nsimultaneously communicating with two multi-antenna UpLink (UL) and DownLink\n(DL) nodes utilizing the same time and frequency resources. To suppress the\nstrong Self-Interference (SI) signal due to simultaneous transmission and\nreception in FD MIMO systems, we propose a joint design of Analog and Digital\n(A/D) cancellation as well as transmit and receive beamforming capitalizing on\nbaseband Orthogonal Frequency-Division Multiplexing (OFDM) signal modeling.\nConsidering practical transmitter impairments, we present a multi-tap wideband\nanalog canceller architecture whose number of taps does not scale with the\nnumber of transceiver antennas and multipath SI components. We also propose a\nnovel adaptive digital cancellation based on truncated singular value\ndecomposition that reduces the residual SI signal estimation parameters. To\nmaximize the FD sum rate, a joint optimization framework is presented for A/D\ncancellation and digital beamforming. Finally, our extensive waveform\nsimulation results demonstrate that the proposed wideband FD MIMO design\nexhibits higher SI cancellation capability with reduced complexity compared to\nexisting cancellation techniques, resulting in improved achievable rate\nperformance.",
    "descriptor": "\nComments: 32 pages, 10 figures, Under Review for Publication in the IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Md Atiqul Islam",
      "George C. Alexandropoulos",
      "Besma Smida"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.08970"
  },
  {
    "id": "arXiv:2112.08980",
    "title": "Performant, Multi-objective Scheduling of Highly Interleaved Task Graphs  on Heterogeneous System on Chip Devices",
    "abstract": "Performance-, power-, and energy-aware scheduling techniques play an\nessential role in optimally utilizing processing elements (PEs) of\nheterogeneous systems. List schedulers, a class of low-complexity static\nschedulers, have commonly been used in static execution scenarios. However,\nlist schedulers are not suitable for runtime decision making, particularly when\nmultiple concurrent applications are interleaved dynamically. For such cases,\nthe static task execution times and expectation of idle PEs assumed by list\nschedulers lead to inefficient system utilization and poor performance. To\naddress this problem, we present techniques for optimizing execution of list\nscheduling algorithms in dynamic runtime scenarios via a family of algorithms\ninspired by the well-known heterogeneous earliest finish time (HEFT) list\nscheduler. Through dynamically arriving, realistic workload scenarios that are\nsimulated in an open-source discrete event heterogeneous SoC simulator, we\nexhaustively evaluate each of the proposed algorithms across two SoCs modeled\nafter the Xilinx Zynq Ultrascale+ ZCU102 and O-Droid XU3 development boards.\nAltogether, depending on the chosen variant in this family of algorithms, we\nare able to achieve an up to 39% execution time improvement, up to 7.24x\nalgorithmic speedup, or up to 30% energy consumption improvement compared to\nthe baseline HEFT implementation.",
    "descriptor": "\nComments: 15 pages, 2 pages of appendix, 14 figures including appendix. Accepted for publication in IEEE Transactions on Parallel and Distributed Systems\n",
    "authors": [
      "Joshua Mack",
      "Samet E. Arda",
      "Umit Y. Ogras",
      "Ali Akoglu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.08980"
  },
  {
    "id": "arXiv:2112.08985",
    "title": "Effective Rate of RIS-aided Networks with Location and Phase Estimation  Uncertainty",
    "abstract": "Reconfigurable Intelligent Surfaces (RIS) are planar structures connected to\nelectronic circuitry, which can be employed to steer the electromagnetic\nsignals in a controlled manner. Through this, the signal quality and the\neffective data rate can be substantially improved. While the benefits of\nRIS-assisted wireless communications have been investigated for various\nscenarios, some aspects of the network design, such as coverage, optimal\nplacement of RIS, etc., often require complex optimization and numerical\nsimulations, since the achievable effective rate is difficult to predict. This\nproblem becomes even more difficult in the presence of phase estimation errors\nor location uncertainty, which can lead to substantial performance degradation\nif neglected. Considering randomly distributed receivers within a ring-shaped\nRIS-assisted wireless network, this paper mainly investigates the effective\nrate by taking into account the above-mentioned impairments. Furthermore, exact\nclosed-form expressions for the effective rate are derived in terms of Meijer's\n$G$-function, which (i) reveals that the location and phase estimation\nuncertainty should be well considered in the deployment of RIS in wireless\nnetworks; and (ii) facilitates future network design and performance\nprediction.",
    "descriptor": "\nComments: 5 pages, 6 figures, conference\n",
    "authors": [
      "Long Kong abd Steven Kisseleff",
      "Symeon Chatzinotas",
      "Bj\u00f6rn Ottersten",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.08985"
  },
  {
    "id": "arXiv:2112.08986",
    "title": "A Heterogeneous Graph Learning Model for Cyber-Attack Detection",
    "abstract": "A cyber-attack is a malicious attempt by experienced hackers to breach the\ntarget information system. Usually, the cyber-attacks are characterized as\nhybrid TTPs (Tactics, Techniques, and Procedures) and long-term adversarial\nbehaviors, making the traditional intrusion detection methods ineffective. Most\nexisting cyber-attack detection systems are implemented based on manually\ndesigned rules by referring to domain knowledge (e.g., threat models, threat\nintelligences). However, this process is lack of intelligence and\ngeneralization ability. Aiming at this limitation, this paper proposes an\nintelligent cyber-attack detection method based on provenance data. To\neffective and efficient detect cyber-attacks from a huge number of system\nevents in the provenance data, we firstly model the provenance data by a\nheterogeneous graph to capture the rich context information of each system\nentities (e.g., process, file, socket, etc.), and learns a semantic vector\nrepresentation for each system entity. Then, we perform online cyber-attack\ndetection by sampling a small and compact local graph from the heterogeneous\ngraph, and classifying the key system entities as malicious or benign. We\nconducted a series of experiments on two provenance datasets with real\ncyber-attacks. The experiment results show that the proposed method outperforms\nother learning based detection models, and has competitive performance against\nstate-of-the-art rule based cyber-attack detection systems.",
    "descriptor": "\nComments: 12pages,7figures,40 references\n",
    "authors": [
      "Mingqi Lv",
      "Chengyu Dong",
      "Tieming Chen",
      "Tiantian Zhu",
      "Qijie Song",
      "Yuan Fan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08986"
  },
  {
    "id": "arXiv:2112.08991",
    "title": "ADBCMM : Acronym Disambiguation by Building Counterfactuals and  Multilingual Mixing",
    "abstract": "Scientific documents often contain a large number of acronyms. Disambiguation\nof these acronyms will help researchers better understand the meaning of\nvocabulary in the documents. In the past, thanks to large amounts of data from\nEnglish literature, acronym task was mainly applied in English literature.\nHowever, for other low-resource languages, this task is difficult to obtain\ngood performance and receives less attention due to the lack of large amount of\nannotation data. To address the above issue, this paper proposes an new method\nfor acronym disambiguation, named as ADBCMM, which can significantly improve\nthe performance of low-resource languages by building counterfactuals and\nmultilingual mixing. Specifically, by balancing data bias in low-resource\nlangauge, ADBCMM will able to improve the test performance outside the data\nset. In SDU@AAAI-22 - Shared Task 2: Acronym Disambiguation, the proposed\nmethod won first place in French and Spanish. You can repeat our results here\nhttps://github.com/WENGSYX/ADBCMM.",
    "descriptor": "\nComments: SDU@AAAI-2022\n",
    "authors": [
      "Yixuan Weng",
      "Fei Xia",
      "Bin Li",
      "Xiusheng Huang",
      "Shizhu He",
      "Kang Liu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08991"
  },
  {
    "id": "arXiv:2112.08995",
    "title": "Connecting the Dots between Audio and Text without Parallel Data through  Visual Knowledge Transfer",
    "abstract": "Machines that can represent and describe environmental soundscapes have\npractical potential, e.g., for audio tagging and captioning systems. Prevailing\nlearning paradigms have been relying on parallel audio-text data, which is,\nhowever, scarcely available on the web. We propose VIP-ANT that induces\n\\textbf{A}udio-\\textbf{T}ext alignment without using any parallel audio-text\ndata. Our key idea is to share the image modality between bi-modal image-text\nrepresentations and bi-modal image-audio representations; the image modality\nfunctions as a pivot and connects audio and text in a tri-modal embedding space\nimplicitly.\nIn a difficult zero-shot setting with no paired audio-text data, our model\ndemonstrates state-of-the-art zero-shot performance on the ESC50 and US8K audio\nclassification tasks, and even surpasses the supervised state of the art for\nClotho caption retrieval (with audio queries) by 2.2\\% R@1. We further\ninvestigate cases of minimal audio-text supervision, finding that, e.g., just a\nfew hundred supervised audio-text pairs increase the zero-shot audio\nclassification accuracy by 8\\% on US8K. However, to match human parity on some\nzero-shot tasks, our empirical scaling experiments suggest that we would need\nabout $2^{21} \\approx 2M$ supervised audio-caption pairs. Our work opens up new\navenues for learning audio-text connections with little to no parallel\naudio-text data.",
    "descriptor": "\nComments: Our code is available at this https URL\n",
    "authors": [
      "Yanpeng Zhao",
      "Jack Hessel",
      "Youngjae Yu",
      "Ximing Lu",
      "Rowan Zellers",
      "Yejin Choi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.08995"
  },
  {
    "id": "arXiv:2112.08996",
    "title": "Activation Modulation and Recalibration Scheme for Weakly Supervised  Semantic Segmentation",
    "abstract": "Image-level weakly supervised semantic segmentation (WSSS) is a fundamental\nyet challenging computer vision task facilitating scene understanding and\nautomatic driving. Most existing methods resort to classification-based Class\nActivation Maps (CAMs) to play as the initial pseudo labels, which tend to\nfocus on the discriminative image regions and lack customized characteristics\nfor the segmentation task. To alleviate this issue, we propose a novel\nactivation modulation and recalibration (AMR) scheme, which leverages a\nspotlight branch and a compensation branch to obtain weighted CAMs that can\nprovide recalibration supervision and task-specific concepts. Specifically, an\nattention modulation module (AMM) is employed to rearrange the distribution of\nfeature importance from the channel-spatial sequential perspective, which helps\nto explicitly model channel-wise interdependencies and spatial encodings to\nadaptively modulate segmentation-oriented activation responses. Furthermore, we\nintroduce a cross pseudo supervision for dual branches, which can be regarded\nas a semantic similar regularization to mutually refine two branches. Extensive\nexperiments show that AMR establishes a new state-of-the-art performance on the\nPASCAL VOC 2012 dataset, surpassing not only current methods trained with the\nimage-level of supervision but also some methods relying on stronger\nsupervision, such as saliency label. Experiments also reveal that our scheme is\nplug-and-play and can be incorporated with other approaches to boost their\nperformance.",
    "descriptor": "\nComments: Accepted by AAAI2022\n",
    "authors": [
      "Jie Qin",
      "Jie Wu",
      "Xuefeng Xiao",
      "Lujun Li",
      "Xingang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08996"
  },
  {
    "id": "arXiv:2112.08998",
    "title": "Portfolio Optimization on Classical and Quantum Computers Using PortFawn",
    "abstract": "Portfolio diversification is one of the most effective ways to minimize\ninvestment risk. Individuals and fund managers aim to create a portfolio of\nassets that not only have high returns but are also uncorrelated. This goal can\nbe achieved by comparing the historical performance, fundamentals, predictions,\nnews sentiment, and many other parameters that can affect the portfolio's\nvalue. One of the most well-known approaches to manage/optimize portfolios is\nthe well-known mean-variance (Markowitz) portfolio. The algorithm's inputs are\nthe expected returns and risks (volatility), and its output is the optimized\nweights for each asset in the target portfolio. Simplified unrealistic\nassumptions and constraints were used in its original version preventing its\nuse in practical cases. One solution to improve its usability is by altering\nthe parameters and constraints to match investment goals and requirements. This\npaper introduces PortFawn, an open-source Python library to create and backtest\nmean-variance portfolios. PortFawn provides simple-to-use APIs to create and\nevaluate mean-variance optimization algorithms using classical computing\n(real-valued asset weights) as well as quantum annealing computing (binary\nasset weights). This tool has many parameters to customize the target\nportfolios according to the investment goals. The paper introduces the\nbackground and limitations of the mean-variance portfolio optimization\nalgorithm, its architecture, and a description of the functionalities of\nPortFawn. We also show how one can use this tool in practice using a simple\ninvestment scenario.",
    "descriptor": "",
    "authors": [
      "Moein Owhadi-Kareshk",
      "Pierre Boulanger"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2112.08998"
  },
  {
    "id": "arXiv:2112.09008",
    "title": "APTSHIELD: A Stable, Efficient and Real-time APT Detection System for  Linux Hosts",
    "abstract": "Advanced Persistent Threat (APT) attack usually refers to the form of\nlong-term, covert and sustained attack on specific targets, with an adversary\nusing advanced attack techniques to destroy the key facilities of an\norganization. APT attacks have caused serious security threats and massive\nfinancial loss worldwide. Academics and industry thereby have proposed a series\nof solutions to detect APT attacks, such as dynamic/static code analysis,\ntraffic detection, sandbox technology, endpoint detection and response (EDR),\netc. However, existing defenses are failed to accurately and effectively defend\nagainst the current APT attacks that exhibit strong persistent, stealthy,\ndiverse and dynamic characteristics due to the weak data source integrity,\nlarge data processing overhead and poor real-time performance in the process of\nreal-world scenarios.\nTo overcome these difficulties, in this paper we propose \\sn{}, a stable,\nefficient and real-time APT detection system for Linux hosts. In the aspect of\ndata collection, audit is selected to stably collect kernel data of the\noperating system so as to carry out a complete portrait of the attack based on\ncomprehensive analysis and comparison of existing logging tools; In the aspect\nof data processing, redundant semantics skipping and non-viable node pruning\nare adopted to reduce the amount of data, so as to reduce the overhead of the\ndetection system; In the aspect of attack detection, an APT attack detection\nframework based on ATT\\&CK model is designed to carry out real-time attack\nresponse and alarm through the transfer and aggregation of labels. Experimental\nresults on both laboratory and Darpa Engagement show that our system can\neffectively detect web vulnerability attacks, file-less attacks and remote\naccess trojan attacks, and has a low false positive rate, which adds far more\nvalue than the existing frontier work.",
    "descriptor": "",
    "authors": [
      "Tiantian Zhu",
      "Jinkai Yu",
      "Tieming Chen",
      "Jiayu Wang",
      "Jie Ying",
      "Ye Tian",
      "Mingqi Lv",
      "Yan Chen",
      "Yuan Fan",
      "Ting Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.09008"
  },
  {
    "id": "arXiv:2112.09011",
    "title": "Provenance-aware Discovery of Functional Dependencies on Integrated  Views",
    "abstract": "The automatic discovery of functional dependencies(FDs) has been widely\nstudied as one of the hardest problems in data profiling. Existing approaches\nhave focused on making the FD computation efficient while inspecting single\nrelations at a time. In this paper, for the first time we address the problem\nof inferring FDs for multiple relations as they occur in integrated views by\nsolely using the functional dependencies of the base relations of the view\nitself. To this purpose, we leverage logical inference and selective mining and\nshow that we can discover most of the exact FDs from the base relations and\navoid the full computation of the FDs for the integrated view itself, while at\nthe same time preserving the lineage of FDs of base relations. We propose\nalgorithms to speedup the inferred FD discovery process and mine FDs on-the-fly\nonly from necessary data partitions. We present InFine(INferred FunctIoNal\ndEpendency), an end-to-end solution to discover inferred FDs on integrated\nviews by leveraging provenance information of base relations. Our experiments\non a range of real-world and synthetic datasets demonstrate the benefits of our\nmethod over existing FD discovery methods that need to rerun the discovery\nprocess on the view from scratch and cannot exploit lineage information on the\nFDs. We show that InFine outperforms traditional methods necessitating the full\nintegrated view computation by one to two order of magnitude in terms of\nruntime. It is also the most memory efficient method while preserving FD\nprovenance information using mainly inference from base table with negligible\nexecution time.",
    "descriptor": "\nComments: 12 pages + biblio and appendices. arXiv admin note: text overlap with arXiv:2012.06237\n",
    "authors": [
      "Ugo Comignani",
      "Laure Berti-\u00c9quille",
      "No\u00ebl Novelli",
      "Angela Bonifati"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.09011"
  },
  {
    "id": "arXiv:2112.09012",
    "title": "Centralizing State-Values in Dueling Networks for Multi-Robot  Reinforcement Learning Mapless Navigation",
    "abstract": "We study the problem of multi-robot mapless navigation in the popular\nCentralized Training and Decentralized Execution (CTDE) paradigm. This problem\nis challenging when each robot considers its path without explicitly sharing\nobservations with other robots and can lead to non-stationary issues in Deep\nReinforcement Learning (DRL). The typical CTDE algorithm factorizes the joint\naction-value function into individual ones, to favor cooperation and achieve\ndecentralized execution. Such factorization involves constraints (e.g.,\nmonotonicity) that limit the emergence of novel behaviors in an individual as\neach agent is trained starting from a joint action-value. In contrast, we\npropose a novel architecture for CTDE that uses a centralized state-value\nnetwork to compute a joint state-value, which is used to inject global state\ninformation in the value-based updates of the agents. Consequently, each model\ncomputes its gradient update for the weights, considering the overall state of\nthe environment. Our idea follows the insights of Dueling Networks as a\nseparate estimation of the joint state-value has both the advantage of\nimproving sample efficiency, while providing each robot information whether the\nglobal state is (or is not) valuable. Experiments in a robotic navigation task\nwith 2 4, and 8 robots, confirm the superior performance of our approach over\nprior CTDE methods (e.g., VDN, QMIX).",
    "descriptor": "\nComments: 6 pages, 5 figures, 1 table. Accepted at IROS 2021\n",
    "authors": [
      "Enrico Marchesini",
      "Alessandro Farinelli"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.09012"
  },
  {
    "id": "arXiv:2112.09014",
    "title": "Anti-Tamper Radio: System-Level Tamper Detection for Computing Systems",
    "abstract": "A whole range of attacks becomes possible when adversaries gain physical\naccess to computing systems that process or contain sensitive data. Examples\ninclude side-channel analysis, bus probing, device cloning, or implanting\nhardware Trojans. Defending against these kinds of attacks is considered a\nchallenging endeavor, requiring anti-tamper solutions to monitor the physical\nenvironment of the system. Current solutions range from simple switches, which\ndetect if a case is opened, to meshes of conducting material that provide more\nfine-grained detection of integrity violations. However, these solutions suffer\nfrom an intricate trade-off between physical security on the one side and\nreliability, cost, and difficulty to manufacture on the other. In this work, we\ndemonstrate that radio wave propagation in an enclosed system of complex\ngeometry is sensitive against adversarial physical manipulation. We present an\nanti-tamper radio (ATR) solution as a method for tamper detection, which\ncombines high detection sensitivity and reliability with ease-of-use. ATR\nconstantly monitors the wireless signal propagation behavior within the\nboundaries of a metal case. Tamper attempts such as insertion of foreign\nobjects, will alter the observed radio signal response, subsequently raising an\nalarm. The ATR principle is applicable in many computing systems that require\nphysical security such as servers, ATMs, and smart meters. As a case study, we\nuse 19\" servers and thoroughly investigate capabilities and limits of the ATR.\nUsing a custom-built automated probing station, we simulate probing attacks by\ninserting needles with high precision into protected environments. Our\nexperimental results show that our ATR implementation can detect 16 mm\ninsertions of needles of diameter as low as 0.1 mm under ideal conditions. In\nthe more realistic environment of a running 19\" server, we demonstrate reliable\n[...]",
    "descriptor": "",
    "authors": [
      "Paul Staat",
      "Johannes Tobisch",
      "Christian Zenger",
      "Christof Paar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.09014"
  },
  {
    "id": "arXiv:2112.09019",
    "title": "Ephemeral Fabrication: Exploring a Ubiquitous Fabrication Scenario of  Low-Effort, In-Situ Creation of Short-Lived Physical Artifacts",
    "abstract": "Personal fabrication empowers users to create objects increasingly easier and\nfaster. This continuous decrease in effort evokes a speculative scenario of\nEphemeral Fabrication (EF), enabled and amplified by emerging paradigms of\nmobile, wearable, or even body-integrated fabrication. EF yields fast,\ntemporary, in-situ solutions for everyday problems (e.g., creating a protective\nskin, affixing a phone). Users solely create those, since the required effort\nis negligible. We present and critically reflect on the EF scenario, by\nexploring current trends in research and building a body-worn fabrication\ndevice. EF is a plausible extrapolation of current developments, entailing both\npositive (e.g., accessibility) and negative implications (e.g.,\nunsustainability). Using speculative design methodology to question the\ntrajectory of personal fabrication, we argue that to avert the aftermath of\nsuch futures, topics like sustainability can not remain an afterthought, but\nrather be situated in interactions themselves: through embedded constraints,\nconscious material choice, and constructive embedding of ephemerality.",
    "descriptor": "\nComments: 21.5 pages, 6 figures, 1 table, to appear in Proceedings of the Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction (TEI '22)\n",
    "authors": [
      "Evgeny Stemasov",
      "Alexander Botner",
      "Enrico Rukzio",
      "Jan Gugenheimer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.09019"
  },
  {
    "id": "arXiv:2112.09025",
    "title": "Deep Reinforcement Learning Policies Learn Shared Adversarial Features  Across MDPs",
    "abstract": "The use of deep neural networks as function approximators has led to striking\nprogress for reinforcement learning algorithms and applications. Yet the\nknowledge we have on decision boundary geometry and the loss landscape of\nneural policies is still quite limited. In this paper we propose a framework to\ninvestigate the decision boundary and loss landscape similarities across states\nand across MDPs. We conduct experiments in various games from Arcade Learning\nEnvironment, and discover that high sensitivity directions for neural policies\nare correlated across MDPs. We argue that these high sensitivity directions\nsupport the hypothesis that non-robust features are shared across training\nenvironments of reinforcement learning agents. We believe our results reveal\nfundamental properties of the environments used in deep reinforcement learning\ntraining, and represent a tangible step towards building robust and reliable\ndeep reinforcement learning agents.",
    "descriptor": "\nComments: Published in AAAI 2022\n",
    "authors": [
      "Ezgi Korkmaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.09025"
  },
  {
    "id": "arXiv:2112.09035",
    "title": "It was hard to find the words: Using an Autoethnographic Diary Study to  Understand the Difficulties of Smart Home Cyber Security Practices",
    "abstract": "This study considers how well an autoethnographic diary study helps as a\nmethod to explore why families might struggle in the application of strong and\ncohesive cyber security measures within the smart home. Combining two\nhuman-computer interaction (HCI) research methods - the relatively unstructured\nprocess of autoethnography and the more structured diary study - allowed the\nfirst author to reflect on the differences between researchers or experts, and\neveryday users. Having a physical set of structured diary prompts allowed for a\nperiod of 'thinking as writing', enabling reflection upon how having expert\nknowledge may or may not translate into useful knowledge when dealing with\neveryday life. This is particularly beneficial in the context of home cyber\nsecurity use, where first-person narratives have not made up part of the\nresearch corpus to date, despite a consistent recognition that users struggle\nto apply strong cyber security methods in personal contexts. The framing of the\nautoethnographic diary study contributes a very simple, but extremely powerful,\ntool for anyone with more knowledge than the average user of any technology,\nenabling the expert to reflect upon how they themselves have fared when using,\nunderstanding and discussing the technology in daily life.",
    "descriptor": "\nComments: 2022 ACM CHI Conference on Human Factors in Computing Systems\n",
    "authors": [
      "Sarah Turner",
      "Jason R.C. Nurse",
      "Shujun Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.09035"
  },
  {
    "id": "arXiv:2112.09037",
    "title": "A Static Analyzer for Detecting Tensor Shape Errors in Deep Neural  Network Training Code",
    "abstract": "We present an automatic static analyzer PyTea that detects tensor-shape\nerrors in PyTorch code. The tensor-shape error is critical in the deep neural\nnet code; much of the training cost and intermediate results are to be lost\nonce a tensor shape mismatch occurs in the midst of the training phase. Given\nthe input PyTorch source, PyTea statically traces every possible execution\npath, collects tensor shape constraints required by the tensor operation\nsequence of the path, and decides if the constraints are unsatisfiable (hence a\nshape error can occur). PyTea's scalability and precision hinges on the\ncharacteristics of real-world PyTorch applications: the number of execution\npaths after PyTea's conservative pruning rarely explodes and loops are simple\nenough to be circumscribed by our symbolic abstraction. We tested PyTea against\nthe projects in the official PyTorch repository and some tensor-error code\nquestioned in the StackOverflow. PyTea successfully detects tensor shape errors\nin these codes, each within a few seconds.",
    "descriptor": "",
    "authors": [
      "Ho Young Jhoo",
      "Sehoon Kim",
      "Woosung Song",
      "Kyuyeon Park",
      "DongKwon Lee",
      "Kwangkeun Yi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.09037"
  },
  {
    "id": "arXiv:2112.09039",
    "title": "Hypercontractive inequalities for the second norm of highly concentrated  functions, and Mrs. Gerber's-type inequalities for the second Renyi entropy",
    "abstract": "Let $T_{\\epsilon}$, $0 \\le \\epsilon \\le 1/2$, be the noise operator acting on\nfunctions on the boolean cube $\\{0,1\\}^n$. Let $f$ be a distribution on\n$\\{0,1\\}^n$ and let $q > 1$. We prove tight Mrs. Gerber-type results for the\nsecond Renyi entropy of $T_{\\epsilon} f$ which take into account the value of\nthe $q^{th}$ Renyi entropy of $f$. For a general function $f$ on $\\{0,1\\}^n$ we\nprove tight hypercontractive inequalities for the $\\ell_2$ norm of\n$T_{\\epsilon} f$ which take into account the ratio between $\\ell_q$ and\n$\\ell_1$ norms of $f$.",
    "descriptor": "",
    "authors": [
      "Niv Levhari",
      "Alex Samorodnitsky"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.09039"
  },
  {
    "id": "arXiv:2112.09040",
    "title": "Inexact Newton combined approximations in the topology optimization of  geometrically nonlinear elastic structures and compliant mechanisms",
    "abstract": "This work blends the inexact Newton method with iterative combined\napproximations (ICA) for solving topology optimization problems under the\nassumption of geometric nonlinearity. The density-based problem formulation is\nsolved using a sequential piecewise linear programming (SPLP) algorithm. Five\ndistinct strategies have been proposed to control the frequency of the\nfactorizations of the Jacobian matrices of the nonlinear equilibrium equations.\nAiming at speeding up the overall iterative scheme while keeping the accuracy\nof the approximate solutions, three of the strategies also use an ICA scheme\nfor the adjoint linear system associated with the sensitivity analysis. The\nrobustness of the proposed reanalysis strategies is corroborated by means of\nnumerical experiments with four benchmark problems -- two structures and two\ncompliant mechanisms. Besides assessing the performance of the strategies\nconsidering a fixed budget of iterations, the impact of a theoretically\nsupported stopping criterion for the SPLP algorithm was analyzed as well.",
    "descriptor": "",
    "authors": [
      "Thadeu A. Senne",
      "Francisco A. M. Gomes",
      "Sandra A. Santos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.09040"
  },
  {
    "id": "arXiv:2112.09043",
    "title": "Neural Style Transfer and Unpaired Image-to-Image Translation to deal  with the Domain Shift Problem on Spheroid Segmentation",
    "abstract": "Background and objectives. Domain shift is a generalisation problem of\nmachine learning models that occurs when the data distribution of the training\nset is different to the data distribution encountered by the model when it is\ndeployed. This is common in the context of biomedical image segmentation due to\nthe variance of experimental conditions, equipment, and capturing settings. In\nthis work, we address this challenge by studying both neural style transfer\nalgorithms and unpaired image-to-image translation methods in the context of\nthe segmentation of tumour spheroids.\nMethods. We have illustrated the domain shift problem in the context of\nspheroid segmentation with 4 deep learning segmentation models that achieved an\nIoU over 97% when tested with images following the training distribution, but\nwhose performance decreased up to an 84\\% when applied to images captured under\ndifferent conditions. In order to deal with this problem, we have explored 3\nstyle transfer algorithms (NST, deep image analogy, and STROTSS), and 6\nunpaired image-to-image translations algorithms (CycleGAN, DualGAN, ForkGAN,\nGANILLA, CUT, and FastCUT). These algorithms have been integrated into a\nhigh-level API that facilitates their application to other contexts where the\ndomain-shift problem occurs.\nResults. We have considerably improved the performance of the 4 segmentation\nmodels when applied to images captured under different conditions by using both\nstyle transfer and image-to-image translation algorithms. In particular, there\nare 2 style transfer algorithms (NST and deep image analogy) and 1 unpaired\nimage-to-image translations algorithm (CycleGAN) that improve the IoU of the\nmodels in a range from 0.24 to 76.07. Therefore, reaching a similar performance\nto the one obtained with the models are applied to images following the\ntraining distribution.",
    "descriptor": "",
    "authors": [
      "Manuel Garc\u00eda-Dom\u00ednguez",
      "C\u00e9sar Dom\u00ednguez",
      "J\u00f3nathan Heras",
      "Eloy Mata",
      "Vico Pascual"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.09043"
  },
  {
    "id": "arXiv:2112.09045",
    "title": "The MVTec 3D-AD Dataset for Unsupervised 3D Anomaly Detection and  Localization",
    "abstract": "We introduce the first comprehensive 3D dataset for the task of unsupervised\nanomaly detection and localization. It is inspired by real-world visual\ninspection scenarios in which a model has to detect various types of defects on\nmanufactured products, even if it is trained only on anomaly-free data. There\nare defects that manifest themselves as anomalies in the geometric structure of\nan object. These cause significant deviations in a 3D representation of the\ndata. We employed a high-resolution industrial 3D sensor to acquire depth scans\nof 10 different object categories. For all object categories, we present a\ntraining and validation set, each of which solely consists of scans of\nanomaly-free samples. The corresponding test sets contain samples showing\nvarious defects such as scratches, dents, holes, contaminations, or\ndeformations. Precise ground-truth annotations are provided for every anomalous\ntest sample. An initial benchmark of 3D anomaly detection methods on our\ndataset indicates a considerable room for improvement.",
    "descriptor": "\nComments: Accepted for presentation at VISAPP 2022\n",
    "authors": [
      "Paul Bergmann",
      "Xin Jin",
      "David Sattlegger",
      "Carsten Steger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09045"
  },
  {
    "id": "arXiv:2112.09046",
    "title": "Distributed neural network control with dependability guarantees: a  compositional port-Hamiltonian approach",
    "abstract": "Large-scale cyber-physical systems require that control policies are\ndistributed, that is, that they only rely on local real-time measurements and\ncommunication with neighboring agents. Optimal Distributed Control (ODC)\nproblems are, however, highly intractable even in seemingly simple cases.\nRecent work has thus proposed training Neural Network (NN) distributed\ncontrollers. A main challenge of NN controllers is that they are not dependable\nduring and after training, that is, the closed-loop system may be unstable, and\nthe training may fail due to vanishing and exploding gradients. In this paper,\nwe address these issues for networks of nonlinear port-Hamiltonian (pH)\nsystems, whose modeling power ranges from energy systems to non-holonomic\nvehicles and chemical reactions. Specifically, we embrace the compositional\nproperties of pH systems to characterize deep Hamiltonian control policies with\nbuilt-in closed-loop stability guarantees, irrespective of the interconnection\ntopology and the chosen NN parameters. Furthermore, our setup enables\nleveraging recent results on well-behaved neural ODEs to prevent the phenomenon\nof vanishing gradients by design. Numerical experiments corroborate the\ndependability of the proposed architecture, while matching the performance of\ngeneral neural network policies.",
    "descriptor": "",
    "authors": [
      "Luca Furieri",
      "Clara Luc\u00eda Galimberti",
      "Muhammad Zakwan",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09046"
  },
  {
    "id": "arXiv:2112.09052",
    "title": "Random Number Generator, Zero-Crossing, and Nonlinearity Attacks against  the Kirchhoff-Law-Johnson-Noise (KLJN) Secure Key Exchange Protocol",
    "abstract": "This dissertation demonstrates three new types of attacks against the KLJN\nscheme. The first attack type is based on compromised RNGs. The first RNG\nattacks are deterministic. First, Eve knows both noises. She can crack the bit\nvia Ohm's Law and one-bit powers within a fraction of the bit exchange period.\nSecond, Eve knows only Bob's noise, so she can learn Bob's resistance value via\nOhm's Law and Alice's resistance at the end of the bit exchange period. She can\nalso use a process of elimination. The second RNG attacks are statistical.\nFirst, Eve has partial knowledge of Alice's and Bob's noises. She can crack the\nbit by taking the highest cross-correlation between her noises and the measured\nnoise in the wire, and by taking the highest cross-correlation between her\nnoises and Alice's/Bob's noises. Second, Eve has partial knowledge of only\nAlice's noise. She can still crack the bit, but after the bit exchange period.\nThe second attack type is based on thermodynamics. Previously, the KLJN scheme\nrequired thermal equilibrium. However, Vadai, et al, in (Nature) Science\nReports shows a modified scheme, where there is a non-zero thermal noise, yet\nthe system resists all the known attacks. We utilize coincidence events between\nthe line current and voltage and show that there is non-zero information leak.\nAs soon as thermal equilibrium is restored, the system is perfectly secure\nagain. The final attack type is based on the nonlinearity of the noise\ngenerators. We explore the effect of distortion at the second and third orders.\nIt is demonstrated that 1% distortion results in a significant information\nleak. We also show that decreasing the effective temperature results in the\nKLJN scheme approaching perfect security.",
    "descriptor": "\nComments: PhD thesis. I paraphrased the abstract to fall within the character limit\n",
    "authors": [
      "Christiana Chamon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.09052"
  },
  {
    "id": "arXiv:2112.09054",
    "title": "Pushing the Limits of Rule Reasoning in Transformers through Natural  Language Satisfiability",
    "abstract": "Investigating the reasoning abilities of transformer models, and discovering\nnew challenging tasks for them, has been a topic of much interest. Recent\nstudies have found these models to be surprisingly strong at performing\ndeductive reasoning over formal logical theories expressed in natural language.\nA shortcoming of these studies, however, is that they do not take into account\nthat logical theories, when sampled uniformly at random, do not necessarily\nlead to hard instances. We propose a new methodology for creating challenging\nalgorithmic reasoning datasets that focus on natural language satisfiability\n(NLSat) problems. The key idea is to draw insights from empirical sampling of\nhard propositional SAT problems and from complexity-theoretic studies of\nlanguage. This methodology allows us to distinguish easy from hard instances,\nand to systematically increase the complexity of existing reasoning benchmarks\nsuch as RuleTaker. We find that current transformers, given sufficient training\ndata, are surprisingly robust at solving the resulting NLSat problems of\nsubstantially increased difficulty. They also exhibit some degree of\nscale-invariance - the ability to generalize to problems of larger size and\nscope. Our results, however, reveal important limitations too: a careful\nsampling of training data is crucial for building models that generalize to\nlarger problems, and transformer models' limited scale-invariance suggests they\nare far from learning robust deductive reasoning algorithms.",
    "descriptor": "\nComments: Accepted to AAAI-2022, AAAI preprint\n",
    "authors": [
      "Kyle Richardson",
      "Ashish Sabharwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.09054"
  },
  {
    "id": "arXiv:2112.09055",
    "title": "Hierarchical Clustering: $O(1)$-Approximation for Well-Clustered Graphs",
    "abstract": "Hierarchical clustering studies a recursive partition of a data set into\nclusters of successively smaller size, and is a fundamental problem in data\nanalysis. In this work we study the cost function for hierarchical clustering\nintroduced by Dasgupta, and present two polynomial-time approximation\nalgorithms: Our first result is an $O(1)$-approximation algorithm for graphs of\nhigh conductance. Our simple construction bypasses complicated recursive\nroutines of finding sparse cuts known in the literature. Our second and main\nresult is an $O(1)$-approximation algorithm for a wide family of graphs that\nexhibit a well-defined structure of clusters. This result generalises the\nprevious state-of-the-art, which holds only for graphs generated from\nstochastic models. The significance of our work is demonstrated by the\nempirical analysis on both synthetic and real-world data sets, on which our\npresented algorithm outperforms the previously proposed algorithm for graphs\nwith a well-defined cluster structure.",
    "descriptor": "\nComments: This work appeared at the 35th Conference on Neural Information Processing Systems (NeurIPS'21)\n",
    "authors": [
      "Bogdan-Adrian Manghiuc",
      "He Sun"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09055"
  },
  {
    "id": "arXiv:2112.09060",
    "title": "Towards Robust Real-time Audio-Visual Speech Enhancement",
    "abstract": "The human brain contextually exploits heterogeneous sensory information to\nefficiently perform cognitive tasks including vision and hearing. For example,\nduring the cocktail party situation, the human auditory cortex contextually\nintegrates audio-visual (AV) cues in order to better perceive speech. Recent\nstudies have shown that AV speech enhancement (SE) models can significantly\nimprove speech quality and intelligibility in very low signal to noise ratio\n(SNR) environments as compared to audio-only SE models. However, despite\nsignificant research in the area of AV SE, development of real-time processing\nmodels with low latency remains a formidable technical challenge. In this\npaper, we present a novel framework for low latency speaker-independent AV SE\nthat can generalise on a range of visual and acoustic noises. In particular, a\ngenerative adversarial networks (GAN) is proposed to address the practical\nissue of visual imperfections in AV SE. In addition, we propose a deep neural\nnetwork based real-time AV SE model that takes into account the cleaned visual\nspeech output from GAN to deliver more robust SE. The proposed framework is\nevaluated on synthetic and real noisy AV corpora using objective speech quality\nand intelligibility metrics and subjective listing tests. Comparative\nsimulation results show that our real time AV SE framework outperforms\nstate-of-the-art SE approaches, including recent DNN based SE models.",
    "descriptor": "",
    "authors": [
      "Mandar Gogate",
      "Kia Dashtipour",
      "Amir Hussain"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.09060"
  },
  {
    "id": "arXiv:2112.09061",
    "title": "Solving Inverse Problems with NerfGANs",
    "abstract": "We introduce a novel framework for solving inverse problems using NeRF-style\ngenerative models. We are interested in the problem of 3-D scene reconstruction\ngiven a single 2-D image and known camera parameters. We show that naively\noptimizing the latent space leads to artifacts and poor novel view rendering.\nWe attribute this problem to volume obstructions that are clear in the 3-D\ngeometry and become visible in the renderings of novel views. We propose a\nnovel radiance field regularization method to obtain better 3-D surfaces and\nimproved novel views given single view observations. Our method naturally\nextends to general inverse problems including inpainting where one observes\nonly partially a single view. We experimentally evaluate our method, achieving\nvisual improvements and performance boosts over the baselines in a wide range\nof tasks. Our method achieves $30-40\\%$ MSE reduction and $15-25\\%$ reduction\nin LPIPS loss compared to the previous state of the art.",
    "descriptor": "\nComments: 16 pages, 18 figures\n",
    "authors": [
      "Giannis Daras",
      "Wen-Sheng Chu",
      "Abhishek Kumar",
      "Dmitry Lagun",
      "Alexandros G. Dimakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09061"
  },
  {
    "id": "arXiv:2112.09062",
    "title": "Models in the Loop: Aiding Crowdworkers with Generative Annotation  Assistants",
    "abstract": "In Dynamic Adversarial Data Collection (DADC), human annotators are tasked\nwith finding examples that models struggle to predict correctly. Models trained\non DADC-collected training data have been shown to be more robust in\nadversarial and out-of-domain settings, and are considerably harder for humans\nto fool. However, DADC is more time-consuming than traditional data collection\nand thus more costly per example. In this work, we examine if we can maintain\nthe advantages of DADC, without suffering the additional cost. To that end, we\nintroduce Generative Annotation Assistants (GAAs), generator-in-the-loop models\nthat provide real-time suggestions that annotators can either approve, modify,\nor reject entirely. We collect training datasets in twenty experimental\nsettings and perform a detailed analysis of this approach for the task of\nextractive question answering (QA) for both standard and adversarial data\ncollection. We demonstrate that GAAs provide significant efficiency benefits in\nterms of annotation speed, while leading to improved model fooling rates. In\naddition, we show that GAA-assisted data leads to higher downstream model\nperformance on a variety of question answering tasks.",
    "descriptor": "",
    "authors": [
      "Max Bartolo",
      "Tristan Thrush",
      "Sebastian Riedel",
      "Pontus Stenetorp",
      "Robin Jia",
      "Douwe Kiela"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.09062"
  },
  {
    "id": "arXiv:2112.09069",
    "title": "Progressive Graph Convolution Network for EEG Emotion Recognition",
    "abstract": "Studies in the area of neuroscience have revealed the relationship between\nemotional patterns and brain functional regions, demonstrating that dynamic\nrelationships between different brain regions are an essential factor affecting\nemotion recognition determined through electroencephalography (EEG). Moreover,\nin EEG emotion recognition, we can observe that clearer boundaries exist\nbetween coarse-grained emotions than those between fine-grained emotions, based\non the same EEG data; this indicates the concurrence of large coarse- and small\nfine-grained emotion variations. Thus, the progressive classification process\nfrom coarse- to fine-grained categories may be helpful for EEG emotion\nrecognition. Consequently, in this study, we propose a progressive graph\nconvolution network (PGCN) for capturing this inherent characteristic in EEG\nemotional signals and progressively learning the discriminative EEG features.\nTo fit different EEG patterns, we constructed a dual-graph module to\ncharacterize the intrinsic relationship between different EEG channels,\ncontaining the dynamic functional connections and static spatial proximity\ninformation of brain regions from neuroscience research. Moreover, motivated by\nthe observation of the relationship between coarse- and fine-grained emotions,\nwe adopt a dual-head module that enables the PGCN to progressively learn more\ndiscriminative EEG features, from coarse-grained (easy) to fine-grained\ncategories (difficult), referring to the hierarchical characteristic of\nemotion. To verify the performance of our model, extensive experiments were\nconducted on two public datasets: SEED-IV and multi-modal physiological emotion\ndatabase (MPED).",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Yijin Zhou",
      "Fu Li",
      "Yang Li",
      "Youshuo Ji",
      "Guangming Shi",
      "Wenming Zheng",
      "Lijian Zhang",
      "Yuanfang Chen",
      "Rui Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.09069"
  },
  {
    "id": "arXiv:2112.09074",
    "title": "Influence of Pedestrian Collision Warning Systems on Driver Behavior: A  Driving Simulator Study",
    "abstract": "With the advent of connected and automated vehicle (CAV) technology, there is\nan increasing need to evaluate driver behavior while using such technology. In\nthis first of a kind study, a pedestrian collision warning (PCW) system using\nCAV technology, was introduced in a driving simulator environment, to evaluate\ndriver braking behavior, in the presence of a jaywalking pedestrian. A total of\n93 participants from diverse socio-economic backgrounds were recruited for this\nstudy, for which a virtual network of downtown Baltimore was created. An eye\ntracking device was also used to observe distractions and head movements. A Log\nlogistic accelerated failure time (AFT) distribution model was used for this\nanalysis, to calculate speed reduction times; time from the moment the\npedestrian becomes visible, to the point where a minimum speed was reached, to\nallow the pedestrian to pass. The presence of the PCW system significantly\nimpacted the speed reduction time and deceleration rate, as it increased the\nformer and reduced the latter, which proves the effectiveness of this system in\nproviding an effective driving maneuver, by drastically reducing speed. A jerk\nanalysis is conducted to analyze the suddenness of braking and acceleration.\nGaze analysis showed that the system was able to attract the attention of the\ndrivers, as the majority of the drivers noticed the displayed warning. The\nfamiliarity of the driver with the route and connected vehicles reduces the\nspeed reduction time; gender also can have a significant impact as males tend\nto have longer speed reduction time, i.e. more time to comfortably brake and\nallow the pedestrian to pass.",
    "descriptor": "\nComments: 8 figures and 4 tables\n",
    "authors": [
      "Snehanshu Banerjee",
      "Mansoureh Jeihani",
      "Nashid K Khadem",
      "Md. Muhib Kabir"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.09074"
  },
  {
    "id": "arXiv:2112.09075",
    "title": "A minimalistic stochastic dynamics model of cluttered obstacle traversal",
    "abstract": "Robots are still poor at traversing cluttered large obstacles required for\nimportant applications like search and rescue. By contrast, animals are\nexcellent at doing so, often using direct physical interaction with obstacles\nrather than avoiding them. Here, towards understanding the dynamics of\ncluttered obstacle traversal, we developed a minimalistic stochastic dynamics\nsimulation inspired by our recent study of insects traversing grass-like beams.\nThe 2-D model system consists of a forward self-propelled circular locomotor\ntranslating on a frictionless level plane with a lateral random force and\ninteracting with two adjacent horizontal beams that form a gate. We found that\ntraversal probability increases monotonically with propulsive force, but first\nincreases then decreases with random force magnitude. For asymmetric beams with\ndifferent stiffness, traversal is more likely towards the side of the less\nstiff beam. These observations are in accord with those expected from a\npotential energy landscape approach. Furthermore, we extended the single gate\nin a lattice configuration to form a large cluttered obstacle field. A Markov\nchain Monte Carlo method was applied to predict traversal in the large field,\nusing the input-output probability map obtained from single gate simulations.\nThis method achieved high accuracy in predicting the statistical distribution\nof the final location of the body within the obstacle field, while saving\ncomputation time by a factor of 10^5.",
    "descriptor": "",
    "authors": [
      "Bokun Zheng",
      "Qihan Xuan",
      "Chen Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.09075"
  },
  {
    "id": "arXiv:2112.09076",
    "title": "SanMove: Next Location Recommendation via Self-Attention Network",
    "abstract": "Currently, next location recommendation plays a vital role in location-based\nsocial network applications and services. Although many methods have been\nproposed to solve this problem, three important challenges have not been well\naddressed so far: (1) most existing methods are based on recurrent network,\nwhich is time-consuming to train long sequences due to not allowing for full\nparallelism; (2) personalized preferences generally are not considered\nreasonably; (3) existing methods rarely systematically studied how to\nefficiently utilize various auxiliary information (e.g., user ID and timestamp)\nin trajectory data and the spatio-temporal relations among non-consecutive\nlocations. To address the above challenges, we propose a novel method named\nSanMove, a self-attention network based model, to predict the next location via\ncapturing the long- and short-term mobility patterns of users. Specifically,\nSanMove introduces a long-term preference learning module, and it uses a\nself-attention module to capture the users long-term mobility pattern which can\nrepresent personalized location preferences of users. Meanwhile, SanMove uses a\nspatial-temporal guided non-invasive self-attention (STNOVA) to exploit\nauxiliary information to learn short-term preferences. We evaluate SanMove with\ntwo real-world datasets, and demonstrate SanMove is not only faster than the\nstate-of-the-art RNN-based predict model but also outperforms the baselines for\nnext location prediction.",
    "descriptor": "",
    "authors": [
      "Huifeng Li",
      "Bin Wang",
      "Sulei Zhu",
      "Yanyan Xu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09076"
  },
  {
    "id": "arXiv:2112.09078",
    "title": "SenSnake: A snake robot with contact force sensing for studying  locomotion in complex 3-D terrain",
    "abstract": "Despite advances in a diversity of environments, snake robots are still far\nbehind snakes in traversing complex 3-D terrain with large obstacles. This is\ndue to a lack of understanding of how to control 3-D body bending to push\nagainst terrain features to generate and control propulsion. Biological studies\nsuggested that generalist snakes use contact force sensing to adjust body\nbending in real time to do so. However, studying this sensory-modulated force\ncontrol in snakes is challenging, due to a lack of basic knowledge of how their\nforce sensing organs work. Here, we take a robophysics approach to make\nprogress, starting by developing a snake robot capable of 3-D body bending with\ncontact force sensing to enable systematic locomotion experiments and force\nmeasurements. Through two development and testing iterations, we created a\n12-segment robot with 36 piezo-resistive sheet sensors distributed on all\nsegments with compliant shells with a sampling frequency of 30 Hz. The robot\nmeasured contact forces while traversing a large obstacle using vertical\nbending with high repeatability, achieving the goal of providing a platform for\nsystematic experiments. Finally, we explored model-based calibration\nconsidering the viscoelastic behavior of the piezo-resistive sensor, which will\nfor useful for future studies.",
    "descriptor": "",
    "authors": [
      "Divya Ramesh",
      "Qiyuan Fu",
      "Chen Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.09078"
  },
  {
    "id": "arXiv:2112.09081",
    "title": "CrossLoc: Scalable Aerial Localization Assisted by Multimodal Synthetic  Data",
    "abstract": "We present a visual localization system that learns to estimate camera poses\nin the real world with the help of synthetic data. Despite significant progress\nin recent years, most learning-based approaches to visual localization target\nat a single domain and require a dense database of geo-tagged images to\nfunction well. To mitigate the data scarcity issue and improve the scalability\nof the neural localization models, we introduce TOPO-DataGen, a versatile\nsynthetic data generation tool that traverses smoothly between the real and\nvirtual world, hinged on the geographic camera viewpoint. New large-scale\nsim-to-real benchmark datasets are proposed to showcase and evaluate the\nutility of the said synthetic data. Our experiments reveal that synthetic data\ngenerically enhances the neural network performance on real data. Furthermore,\nwe introduce CrossLoc, a cross-modal visual representation learning approach to\npose estimation that makes full use of the scene coordinate ground truth via\nself-supervision. Without any extra data, CrossLoc significantly outperforms\nthe state-of-the-art methods and achieves substantially higher real-data sample\nefficiency. Our code is available at https://github.com/TOPO-EPFL/CrossLoc.",
    "descriptor": "\nComments: Preprint. Our code is available at this https URL\n",
    "authors": [
      "Qi Yan",
      "Jianhao Zheng",
      "Simon Reding",
      "Shanci Li",
      "Iordan Doytchinov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.09081"
  },
  {
    "id": "arXiv:2112.09093",
    "title": "Network Realization Functions for Optimal Distributed Control",
    "abstract": "In this paper we formalize a novel type of realizations for networks with\nlinear and time-invariant dynamics, which we have dubbed Network Realization\nFunctions. In doing so, we outline a novel type of \"structure\" in linear,\ndistributed control, which is amenable to convex formulations for controller\ndesign. This approach is well suited for large scale systems, since the\nsubsequent schemes completely avoid the exchange of internal states among\nsub-controllers, i.e., plant or controller states.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "\u015eerban Sab\u0103u",
      "Andrei Speril\u0103",
      "Cristian Oar\u0103",
      "Ali Jadbabaie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.09093"
  },
  {
    "id": "arXiv:2112.09097",
    "title": "Learning and Analyzing Generation Order for Undirected Sequence Models",
    "abstract": "Undirected neural sequence models have achieved performance competitive with\nthe state-of-the-art directed sequence models that generate monotonically from\nleft to right in machine translation tasks. In this work, we train a policy\nthat learns the generation order for a pre-trained, undirected translation\nmodel via reinforcement learning. We show that the translations decoded by our\nlearned orders achieve higher BLEU scores than the outputs decoded from left to\nright or decoded by the learned order from Mansimov et al. (2019) on the WMT'14\nGerman-English translation task. On examples with a maximum source and target\nlength of 30 from De-En, WMT'16 English-Romanian, and WMT'21 English-Chinese\ntranslation tasks, our learned order outperforms all heuristic generation\norders on four out of six tasks. We next carefully analyze the learned order\npatterns via qualitative and quantitative analysis. We show that our policy\ngenerally follows an outer-to-inner order, predicting the left-most and\nright-most positions first, and then moving toward the middle while skipping\nless important words at the beginning. Furthermore, the policy usually predicts\npositions for a single syntactic constituent structure in consecutive steps. We\nbelieve our findings could provide more insights on the mechanism of undirected\ngeneration models and encourage further research in this direction. Our code is\npublicly available at https://github.com/jiangycTarheel/undirected-generation",
    "descriptor": "\nComments: EMNLP 2021 Findings (12 pages)\n",
    "authors": [
      "Yichen Jiang",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09097"
  },
  {
    "id": "arXiv:2112.09099",
    "title": "Decentralized Mean Field Games",
    "abstract": "Multiagent reinforcement learning algorithms have not been widely adopted in\nlarge scale environments with many agents as they often scale poorly with the\nnumber of agents. Using mean field theory to aggregate agents has been proposed\nas a solution to this problem. However, almost all previous methods in this\narea make a strong assumption of a centralized system where all the agents in\nthe environment learn the same policy and are effectively indistinguishable\nfrom each other. In this paper, we relax this assumption about\nindistinguishable agents and propose a new mean field system known as\nDecentralized Mean Field Games, where each agent can be quite different from\nothers. All agents learn independent policies in a decentralized fashion, based\non their local observations. We define a theoretical solution concept for this\nsystem and provide a fixed point guarantee for a Q-learning based algorithm in\nthis system. A practical consequence of our approach is that we can address a\n`chicken-and-egg' problem in empirical mean field reinforcement learning\nalgorithms. Further, we provide Q-learning and actor-critic algorithms that use\nthe decentralized mean field learning approach and give stronger performances\ncompared to common baselines in this area. In our setting, agents do not need\nto be clones of each other and learn in a fully decentralized fashion. Hence,\nfor the first time, we show the application of mean field learning methods in\nfully competitive environments, large-scale continuous action space\nenvironments, and other environments with heterogeneous agents. Importantly, we\nalso apply the mean field method in a ride-sharing problem using a real-world\ndataset. We propose a decentralized solution to this problem, which is more\npractical than existing centralized training methods.",
    "descriptor": "\nComments: This work is to appear in AAAI-22\n",
    "authors": [
      "Sriram Ganapathi Subramanian",
      "Matthew E. Taylor",
      "Mark Crowley",
      "Pascal Poupart"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.09099"
  },
  {
    "id": "arXiv:2112.09104",
    "title": "Non-Gaussian Component Analysis via Lattice Basis Reduction",
    "abstract": "Non-Gaussian Component Analysis (NGCA) is the following distribution learning\nproblem: Given i.i.d. samples from a distribution on $\\mathbb{R}^d$ that is\nnon-gaussian in a hidden direction $v$ and an independent standard Gaussian in\nthe orthogonal directions, the goal is to approximate the hidden direction $v$.\nPrior work \\cite{DKS17-sq} provided formal evidence for the existence of an\ninformation-computation tradeoff for NGCA under appropriate moment-matching\nconditions on the univariate non-gaussian distribution $A$. The latter result\ndoes not apply when the distribution $A$ is discrete. A natural question is\nwhether information-computation tradeoffs persist in this setting. In this\npaper, we answer this question in the negative by obtaining a sample and\ncomputationally efficient algorithm for NGCA in the regime that $A$ is discrete\nor nearly discrete, in a well-defined technical sense. The key tool leveraged\nin our algorithm is the LLL method \\cite{LLL82} for lattice basis reduction.",
    "descriptor": "",
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.09104"
  },
  {
    "id": "arXiv:2112.09106",
    "title": "RegionCLIP: Region-based Language-Image Pretraining",
    "abstract": "Contrastive language-image pretraining (CLIP) using image-text pairs has\nachieved impressive results on image classification in both zero-shot and\ntransfer learning settings. However, we show that directly applying such models\nto recognize image regions for object detection leads to poor performance due\nto a domain shift: CLIP was trained to match an image as a whole to a text\ndescription, without capturing the fine-grained alignment between image regions\nand text spans. To mitigate this issue, we propose a new method called\nRegionCLIP that significantly extends CLIP to learn region-level visual\nrepresentations, thus enabling fine-grained alignment between image regions and\ntextual concepts. Our method leverages a CLIP model to match image regions with\ntemplate captions and then pretrains our model to align these region-text pairs\nin the feature space. When transferring our pretrained model to the\nopen-vocabulary object detection tasks, our method significantly outperforms\nthe state of the art by 3.8 AP50 and 2.2 AP for novel categories on COCO and\nLVIS datasets, respectively. Moreoever, the learned region representations\nsupport zero-shot inference for object detection, showing promising results on\nboth COCO and LVIS datasets. Our code is available at\nhttps://github.com/microsoft/RegionCLIP.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Yiwu Zhong",
      "Jianwei Yang",
      "Pengchuan Zhang",
      "Chunyuan Li",
      "Noel Codella",
      "Liunian Harold Li",
      "Luowei Zhou",
      "Xiyang Dai",
      "Lu Yuan",
      "Yin Li",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09106"
  },
  {
    "id": "arXiv:2112.09118",
    "title": "Towards Unsupervised Dense Information Retrieval with Contrastive  Learning",
    "abstract": "Information retrieval is an important component in natural language\nprocessing, for knowledge intensive tasks such as question answering and fact\nchecking. Recently, information retrieval has seen the emergence of dense\nretrievers, based on neural networks, as an alternative to classical sparse\nmethods based on term-frequency. These models have obtained state-of-the-art\nresults on datasets and tasks where large training sets are available. However,\nthey do not transfer well to new domains or applications with no training data,\nand are often outperformed by term-frequency methods such as BM25 which are not\nsupervised. Thus, a natural question is whether it is possible to train dense\nretrievers without supervision. In this work, we explore the limits of\ncontrastive learning as a way to train unsupervised dense retrievers, and show\nthat it leads to strong retrieval performance. More precisely, we show on the\nBEIR benchmark that our model outperforms BM25 on 11 out of 15 datasets.\nFurthermore, when a few thousands examples are available, we show that\nfine-tuning our model on these leads to strong improvements compared to BM25.\nFinally, when used as pre-training before fine-tuning on the MS-MARCO dataset,\nour technique obtains state-of-the-art results on the BEIR benchmark.",
    "descriptor": "",
    "authors": [
      "Gautier Izacard",
      "Mathilde Caron",
      "Lucas Hosseini",
      "Sebastian Riedel",
      "Piotr Bojanowski",
      "Armand Joulin",
      "Edouard Grave"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.09118"
  },
  {
    "id": "arXiv:2112.09120",
    "title": "Human Hands as Probes for Interactive Object Understanding",
    "abstract": "Interactive object understanding, or what we can do to objects and how is a\nlong-standing goal of computer vision. In this paper, we tackle this problem\nthrough observation of human hands in in-the-wild egocentric videos. We\ndemonstrate that observation of what human hands interact with and how can\nprovide both the relevant data and the necessary supervision. Attending to\nhands, readily localizes and stabilizes active objects for learning and reveals\nplaces where interactions with objects occur. Analyzing the hands shows what we\ncan do to objects and how. We apply these basic principles on the EPIC-KITCHENS\ndataset, and successfully learn state-sensitive features, and object\naffordances (regions of interaction and afforded grasps), purely by observing\nhands in egocentric videos.",
    "descriptor": "\nComments: Project website at this https URL\n",
    "authors": [
      "Mohit Goyal",
      "Sahil Modi",
      "Rishabh Goyal",
      "Saurabh Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.09120"
  },
  {
    "id": "arXiv:2112.09124",
    "title": "Sparse Euclidean Spanners with Tiny Diameter: A Tight Lower Bound",
    "abstract": "In STOC'95 [ADMSS95] Arya et al. showed that any set of $n$ points in\n$\\mathbb R^d$ admits a $(1+\\epsilon)$-spanner with hop-diameter at most 2\n(respectively, 3) and $O(n \\log n)$ edges (resp., $O(n \\log \\log n)$ edges).\nThey also gave a general upper bound tradeoff of hop-diameter at most $k$ and\n$O(n \\alpha_k(n))$ edges, for any $k \\ge 2$.\nThe function $\\alpha_k$ is the inverse of a certain Ackermann-style function\nat the $\\lfloor k/2 \\rfloor$th level of the primitive recursive hierarchy,\nwhere $\\alpha_0(n) = \\lceil n/2 \\rceil, \\alpha_1(n) = \\left\\lceil \\sqrt{n}\n\\right\\rceil, \\alpha_2(n) = \\lceil \\log{n} \\rceil, \\alpha_3(n) = \\lceil\n\\log\\log{n} \\rceil, \\alpha_4(n) = \\log^* n, \\alpha_5(n) = \\lfloor \\frac{1}{2}\n\\log^*n \\rfloor$, \\ldots. Roughly speaking, for $k \\ge 2$ the function\n$\\alpha_{k}$ is close to $\\lfloor \\frac{k-2}{2} \\rfloor$-iterated log-star\nfunction, i.e., $\\log$ with $\\lfloor \\frac{k-2}{2} \\rfloor$ stars.\nWhether or not this tradeoff is tight has remained open, even for the cases\n$k = 2$ and $k = 3$. Two lower bounds are known: The first applies only to\nspanners with stretch 1 and the second is sub-optimal and applies only to\nsufficiently large (constant) values of $k$. In this paper we prove a tight\nlower bound for any constant $k$: For any fixed $\\epsilon > 0$, any\n$(1+\\epsilon)$-spanner for the uniform line metric with hop-diameter at most\n$k$ must have at least $\\Omega(n \\alpha_k(n))$ edges.",
    "descriptor": "",
    "authors": [
      "Hung Le",
      "Lazar Milenkovic",
      "Shay Solomon"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.09124"
  },
  {
    "id": "arXiv:2112.09126",
    "title": "IS-COUNT: Large-scale Object Counting from Satellite Images with  Covariate-based Importance Sampling",
    "abstract": "Object detection in high-resolution satellite imagery is emerging as a\nscalable alternative to on-the-ground survey data collection in many\nenvironmental and socioeconomic monitoring applications. However, performing\nobject detection over large geographies can still be prohibitively expensive\ndue to the high cost of purchasing imagery and compute. Inspired by traditional\nsurvey data collection strategies, we propose an approach to estimate object\ncount statistics over large geographies through sampling. Given a cost budget,\nour method selects a small number of representative areas by sampling from a\nlearnable proposal distribution. Using importance sampling, we are able to\naccurately estimate object counts after processing only a small fraction of the\nimages compared to an exhaustive approach. We show empirically that the\nproposed framework achieves strong performance on estimating the number of\nbuildings in the United States and Africa, cars in Kenya, brick kilns in\nBangladesh, and swimming pools in the U.S., while requiring as few as 0.01% of\nsatellite images compared to an exhaustive approach.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Chenlin Meng",
      "Enci Liu",
      "Willie Neiswanger",
      "Jiaming Song",
      "Marshall Burke",
      "David Lobell",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09126"
  },
  {
    "id": "arXiv:2112.09127",
    "title": "ICON: Implicit Clothed humans Obtained from Normals",
    "abstract": "Current methods for learning realistic and animatable 3D clothed avatars need\neither posed 3D scans or 2D images with carefully controlled user poses. In\ncontrast, our goal is to learn the avatar from only 2D images of people in\nunconstrained poses. Given a set of images, our method estimates a detailed 3D\nsurface from each image and then combines these into an animatable avatar.\nImplicit functions are well suited to the first task, as they can capture\ndetails like hair or clothes. Current methods, however, are not robust to\nvaried human poses and often produce 3D surfaces with broken or disembodied\nlimbs, missing details, or non-human shapes. The problem is that these methods\nuse global feature encoders that are sensitive to global pose. To address this,\nwe propose ICON (\"Implicit Clothed humans Obtained from Normals\"), which uses\nlocal features, instead. ICON has two main modules, both of which exploit the\nSMPL(-X) body model. First, ICON infers detailed clothed-human normals\n(front/back) conditioned on the SMPL(-X) normals. Second, a visibility-aware\nimplicit surface regressor produces an iso-surface of a human occupancy field.\nImportantly, at inference time, a feedback loop alternates between refining the\nSMPL(-X) mesh using the inferred clothed normals and then refining the normals.\nGiven multiple reconstructed frames of a subject in varied poses, we use\nSCANimate to produce an animatable avatar from them. Evaluation on the AGORA\nand CAPE datasets shows that ICON outperforms the state of the art in\nreconstruction, even with heavily limited training data. Additionally, it is\nmuch more robust to out-of-distribution samples, e.g., in-the-wild poses/images\nand out-of-frame cropping. ICON takes a step towards robust 3D clothed human\nreconstruction from in-the-wild images. This enables creating avatars directly\nfrom video with personalized and natural pose-dependent cloth deformation.",
    "descriptor": "\nComments: 21 pages, 18 figures, 7 tables. Project page: this https URL\n",
    "authors": [
      "Yuliang Xiu",
      "Jinlong Yang",
      "Dimitrios Tzionas",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.09127"
  },
  {
    "id": "arXiv:2112.09129",
    "title": "Decoupling and Recoupling Spatiotemporal Representation for RGB-D-based  Motion Recognition",
    "abstract": "Decoupling spatiotemporal representation refers to decomposing the spatial\nand temporal features into dimension-independent factors. Although previous\nRGB-D-based motion recognition methods have achieved promising performance\nthrough the tightly coupled multi-modal spatiotemporal representation, they\nstill suffer from (i) optimization difficulty under small data setting due to\nthe tightly spatiotemporal-entangled modeling;(ii) information redundancy as it\nusually contains lots of marginal information that is weakly relevant to\nclassification; and (iii) low interaction between multi-modal spatiotemporal\ninformation caused by insufficient late fusion. To alleviate these drawbacks,\nwe propose to decouple and recouple spatiotemporal representation for\nRGB-D-based motion recognition. Specifically, we disentangle the task of\nlearning spatiotemporal representation into 3 sub-tasks: (1) Learning\nhigh-quality and dimension independent features through a decoupled spatial and\ntemporal modeling network. (2) Recoupling the decoupled representation to\nestablish stronger space-time dependency. (3) Introducing a Cross-modal\nAdaptive Posterior Fusion (CAPF) mechanism to capture cross-modal\nspatiotemporal information from RGB-D data. Seamless combination of these novel\ndesigns forms a robust spatialtemporal representation and achieves better\nperformance than state-of-the-art methods on four public motion datasets. Our\ncode is available at https://github.com/damo-cv/MotionRGBD.",
    "descriptor": "\nComments: open sourced; codes and models are available:this https URL; transformer-based method\n",
    "authors": [
      "Benjia Zhou",
      "Pichao Wang",
      "Jun Wan",
      "Yanyan Liang",
      "Fan Wang",
      "Du Zhang",
      "Zhen Lei",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09129"
  },
  {
    "id": "arXiv:2112.09130",
    "title": "Ensembling Off-the-shelf Models for GAN Training",
    "abstract": "The advent of large-scale training has produced a cornucopia of powerful\nvisual recognition models. However, generative models, such as GANs, have\ntraditionally been trained from scratch in an unsupervised manner. Can the\ncollective \"knowledge\" from a large bank of pretrained vision models be\nleveraged to improve GAN training? If so, with so many models to choose from,\nwhich one(s) should be selected, and in what manner are they most effective? We\nfind that pretrained computer vision models can significantly improve\nperformance when used in an ensemble of discriminators. Notably, the particular\nsubset of selected models greatly affects performance. We propose an effective\nselection mechanism, by probing the linear separability between real and fake\nsamples in pretrained model embeddings, choosing the most accurate model, and\nprogressively adding it to the discriminator ensemble. Interestingly, our\nmethod can improve GAN training in both limited data and large-scale settings.\nGiven only 10k training samples, our FID on LSUN Cat matches the StyleGAN2\ntrained on 1.6M images. On the full dataset, our method improves FID by 1.5x to\n2x on cat, church, and horse categories of LSUN.",
    "descriptor": "\nComments: GitHub: this https URL Project webpage: this https URL\n",
    "authors": [
      "Nupur Kumari",
      "Richard Zhang",
      "Eli Shechtman",
      "Jun-Yan Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09130"
  },
  {
    "id": "arXiv:2112.09131",
    "title": "HODOR: High-level Object Descriptors for Object Re-segmentation in Video  Learned from Static Images",
    "abstract": "Existing state-of-the-art methods for Video Object Segmentation (VOS) learn\nlow-level pixel-to-pixel correspondences between frames to propagate object\nmasks across video. This requires a large amount of densely annotated video\ndata, which is costly to annotate, and largely redundant since frames within a\nvideo are highly correlated. In light of this, we propose HODOR: a novel method\nthat tackles VOS by effectively leveraging annotated static images for\nunderstanding object appearance and scene context. We encode object instances\nand scene information from an image frame into robust high-level descriptors\nwhich can then be used to re-segment those objects in different frames. As a\nresult, HODOR achieves state-of-the-art performance on the DAVIS and\nYouTube-VOS benchmarks compared to existing methods trained without video\nannotations. Without any architectural modification, HODOR can also learn from\nvideo context around single annotated video frames by utilizing cyclic\nconsistency, whereas other methods rely on dense, temporally consistent\nannotations.",
    "descriptor": "",
    "authors": [
      "Ali Athar",
      "Jonathon Luiten",
      "Alexander Hermans",
      "Deva Ramanan",
      "Bastian Leibe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.09131"
  },
  {
    "id": "arXiv:2112.09133",
    "title": "Masked Feature Prediction for Self-Supervised Visual Pre-Training",
    "abstract": "We present Masked Feature Prediction (MaskFeat) for self-supervised\npre-training of video models. Our approach first randomly masks out a portion\nof the input sequence and then predicts the feature of the masked regions. We\nstudy five different types of features and find Histograms of Oriented\nGradients (HOG), a hand-crafted feature descriptor, works particularly well in\nterms of both performance and efficiency. We observe that the local contrast\nnormalization in HOG is essential for good results, which is in line with\nearlier work using HOG for visual recognition. Our approach can learn abundant\nvisual knowledge and drive large-scale Transformer-based models. Without using\nextra model weights or supervision, MaskFeat pre-trained on unlabeled videos\nachieves unprecedented results of 86.7% with MViT-L on Kinetics-400, 88.3% on\nKinetics-600, 80.4% on Kinetics-700, 38.8 mAP on AVA, and 75.0% on SSv2.\nMaskFeat further generalizes to image input, which can be interpreted as a\nvideo with a single frame and obtains competitive results on ImageNet.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Chen Wei",
      "Haoqi Fan",
      "Saining Xie",
      "Chao-Yuan Wu",
      "Alan Yuille",
      "Christoph Feichtenhofer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09133"
  },
  {
    "id": "arXiv:2112.08366",
    "title": "AGMI: Attention-Guided Multi-omics Integration for Drug Response  Prediction with Graph Neural Networks",
    "abstract": "Accurate drug response prediction (DRP) is a crucial yet challenging task in\nprecision medicine. This paper presents a novel Attention-Guided Multi-omics\nIntegration (AGMI) approach for DRP, which first constructs a Multi-edge Graph\n(MeG) for each cell line, and then aggregates multi-omics features to predict\ndrug response using a novel structure, called Graph edge-aware Network (GeNet).\nFor the first time, our AGMI approach explores gene constraint based\nmulti-omics integration for DRP with the whole-genome using GNNs. Empirical\nexperiments on the CCLE and GDSC datasets show that our AGMI largely\noutperforms state-of-the-art DRP methods by 8.3%--34.2% on four metrics. Our\ndata and code are available at https://github.com/yivan-WYYGDSG/AGMI.",
    "descriptor": "",
    "authors": [
      "Feng Ruiwei",
      "Xie Yufeng",
      "Lai Minshan",
      "Chen Danny",
      "Cao Ji",
      "Wu Jian"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08366"
  },
  {
    "id": "arXiv:2112.08391",
    "title": "Breeding realistic D-brane models",
    "abstract": "Intersecting branes provide a useful mechanism to construct particle physics\nmodels from string theory with a wide variety of desirable characteristics. The\nlandscape of such models can be enormous, and navigating towards regions which\nare most phenomenologically interesting is potentially challenging. Machine\nlearning techniques can be used to efficiently construct large numbers of\nconsistent and phenomenologically desirable models. In this work we phrase the\nproblem of finding consistent intersecting D-brane models in terms of genetic\nalgorithms, which mimic natural selection to evolve a population collectively\ntowards optimal solutions. For a four-dimensional ${\\cal N}=1$ supersymmetric\ntype IIA orientifold with intersecting D6-branes, we demonstrate that\n$\\mathcal{O}(10^6)$ unique, fully consistent models can be easily constructed,\nand, by a judicious choice of search environment and hyper-parameters,\n$\\mathcal{O}(30\\%)$ of the found models contain the desired Standard Model\ngauge group factor. Having a sizable sample allows us to draw some preliminary\nlandscape statistics of intersecting brane models both with and without the\nrestriction of having the Standard Model gauge factor.",
    "descriptor": "\nComments: 19 pages + appendices, 9 figures\n",
    "authors": [
      "Gregory J. Loges",
      "Gary Shiu"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.08391"
  },
  {
    "id": "arXiv:2112.08409",
    "title": "Quantum Model Learning Agent: characterisation of quantum systems  through machine learning",
    "abstract": "Accurate models of real quantum systems are important for investigating their\nbehaviour, yet are difficult to distill empirically. Here, we report an\nalgorithm -- the Quantum Model Learning Agent (QMLA) -- to reverse engineer\nHamiltonian descriptions of a target system. We test the performance of QMLA on\na number of simulated experiments, demonstrating several mechanisms for the\ndesign of candidate Hamiltonian models and simultaneously entertaining numerous\nhypotheses about the nature of the physical interactions governing the system\nunder study. QMLA is shown to identify the true model in the majority of\ninstances, when provided with limited a priori information, and control of the\nexperimental setup. Our protocol can explore Ising, Heisenberg and Hubbard\nfamilies of models in parallel, reliably identifying the family which best\ndescribes the system dynamics. We demonstrate QMLA operating on large model\nspaces by incorporating a genetic algorithm to formulate new hypothetical\nmodels. The selection of models whose features propagate to the next generation\nis based upon an objective function inspired by the Elo rating scheme,\ntypically used to rate competitors in games such as chess and football. In all\ninstances, our protocol finds models that exhibit $F_1$-score $\\geq 0.88$ when\ncompared with the true model, and it precisely identifies the true model in 72%\nof cases, whilst exploring a space of over $250,000$ potential models. By\ntesting which interactions actually occur in the target system, QMLA is a\nviable tool for both the exploration of fundamental physics and the\ncharacterisation and calibration of quantum devices.",
    "descriptor": "\nComments: 29 pages, 7 figures\n",
    "authors": [
      "Brian Flynn",
      "Antonio Andreas Gentile",
      "Nathan Wiebe",
      "Raffaele Santagati",
      "Anthony Laing"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08409"
  },
  {
    "id": "arXiv:2112.08411",
    "title": "Error Analysis of Surrogate Models Constructed through Operations on  Sub-models",
    "abstract": "Model-based methods are popular in derivative-free optimization (DFO). In\nmost of them, a single model function is built to approximate the objective\nfunction. This is generally based on the assumption that the objective function\nis one blackbox. However, some real-life and theoretical problems show that the\nobjective function may consist of several blackboxes. In those problems, the\ninformation provided by each blackbox may not be equal. In this situation, one\ncould build multiple sub-models that are then combined to become a final model.\nIn this paper, we analyze the relation between the accuracy of those sub-models\nand the model constructed through their operations. We develop a broad\nframework that can be used as a theoretical tool in model error analysis and\nfuture research in DFO algorithms design.",
    "descriptor": "",
    "authors": [
      "Yiwen Chen",
      "Gabriel Jarry-Bolduc",
      "Warren Hare"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08411"
  },
  {
    "id": "arXiv:2112.08417",
    "title": "Characterization of causal ancestral graphs for time series with latent  confounders",
    "abstract": "Generalizing directed maximal ancestral graphs, we introduce a class of\ngraphical models for representing time lag specific causal relationships and\nindependencies among finitely many regularly sampled and regularly subsampled\ntime steps of multivariate time series with unobserved variables. We completely\ncharacterize these graphs and show that they entail constraints beyond those\nthat have previously been considered in the literature. This allows for\nstronger causal inferences without having imposed additional assumptions. In\ngeneralization of directed partial ancestral graphs we further introduce a\ngraphical representation of Markov equivalence classes of the novel type of\ngraphs and show that these are more informative than what current\nstate-of-the-art causal discovery algorithms learn. We also analyze the\nadditional information gained by increasing the number of observed time steps.",
    "descriptor": "\nComments: 55 pages (including appendix), 16 figures\n",
    "authors": [
      "Andreas Gerhardus"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08417"
  },
  {
    "id": "arXiv:2112.08456",
    "title": "Edge Partitions of Complete Geometric Graphs (Part 2)",
    "abstract": "Recently, the second and third author showed that complete geometric graphs\non $2n$ vertices in general cannot be partitioned into $n$ plane spanning\ntrees. Building up on this work, in this paper, we initiate the study of\npartitioning into beyond planar subgraphs, namely into $k$-planar and\n$k$-quasi-planar subgraphs and obtain first bounds on the number of subgraphs\nrequired in this setting.",
    "descriptor": "",
    "authors": [
      "Oswin Aichholzer",
      "Johannes Obenaus",
      "Joachim Orthaber",
      "Rosna Paul",
      "Patrick Schnider",
      "Raphael Steiner",
      "Tim Taubner",
      "Birgit Vogtenhuber"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.08456"
  },
  {
    "id": "arXiv:2112.08503",
    "title": "On Generalizations of Pairwise Compatibility Graphs",
    "abstract": "A graph $G$ is a PCG if there exists an edge-weighted tree such that each\nleaf of the tree is a vertex of the graph, and there is an edge $\\{ x, y \\}$ in\n$G$ if and only if the weight of the path in the tree connecting $x$ and $y$\nlies within a given interval. PCGs have different applications in phylogenetics\nand have been lately generalized to multi-interval-PCGs. In this paper we\ndefine two new generalizations of the PCG class, namely k-OR-PCGs and\nk-AND-PCGs, that are the classes of graphs that can be expressed as union and\nintersection, respectively, of $k$ PCGs. The problems we consider can be also\ndescribed in terms of the \\emph{covering number} and the \\emph{intersection\ndimension} of a graph with respect to the PCG class. In this paper we\ninvestigate how the classes of PCG, multi-interval-PCG, OR-PCG and AND-PCG are\nrelated to each other and to other graph classes known in the literature. In\nparticular, we provide upper bounds on the minimum $k$ for which an arbitrary\ngraph $G$ belongs to k-interval-PCG, k-OR-PCG and k-AND-PCG classes.\nFurthermore, for particular graph classes we improve these general bounds.\nMoreover, we show that, for every integer $k$, there exists a bipartite graph\nthat is not in the k-interval-PCG class, proving that there is no finite $k$\nfor which the k-interval-PCG class contains all the graphs. Finally, we show\nthat there exist graphs that are not in 2-AND-PCG.",
    "descriptor": "",
    "authors": [
      "Tiziana Calamoneri",
      "Angelo Monti",
      "Blerina Sinaimeri"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.08503"
  },
  {
    "id": "arXiv:2112.08535",
    "title": "Fractional cyber-neural systems -- a brief survey",
    "abstract": "Neurotechnology has made great strides in the last 20 years. However, we\nstill have a long way to go to commercialize many of these technologies as we\nlack a unified framework to study cyber-neural systems (CNS) that bring the\nhardware, software, and the neural system together. Dynamical systems play a\nkey role in developing these technologies as they capture different aspects of\nthe brain and provide insight into their function. Converging evidence suggests\nthat fractional-order dynamical systems are advantageous in modeling neural\nsystems because of their compact representation and accuracy in capturing the\nlong-range memory exhibited in neural behavior. In this brief survey, we\nprovide an overview of fractional CNS that entails fractional-order systems in\nthe context of CNS. In particular, we introduce basic definitions required for\nthe analysis and synthesis of fractional CNS, encompassing system\nidentification, state estimation, and closed-loop control. Additionally, we\nprovide an illustration of some applications in the context of CNS and draw\nsome possible future research directions. Ultimately, advancements in these\nthree areas will be critical in developing the next generation of CNS, which\nwill, ultimately, improve people's quality of life.",
    "descriptor": "\nComments: 67 pages, 13 figures\n",
    "authors": [
      "Emily Reed",
      "Sarthak Chatterjee",
      "Guilherme Ramos",
      "Paul Bogdan",
      "S\u00e9rgio Pequito"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.08535"
  },
  {
    "id": "arXiv:2112.08628",
    "title": "Explainable Natural Language Processing with Matrix Product States",
    "abstract": "Despite empirical successes of recurrent neural networks (RNNs) in natural\nlanguage processing (NLP), theoretical understanding of RNNs is still limited\ndue to intrinsically complex computations in RNNs. We perform a systematic\nanalysis of RNNs' behaviors in a ubiquitous NLP task, the sentiment analysis of\nmovie reviews, via the mapping between a class of RNNs called recurrent\narithmetic circuits (RACs) and a matrix product state (MPS). Using the\nvon-Neumann entanglement entropy (EE) as a proxy for information propagation,\nwe show that single-layer RACs possess a maximum information propagation\ncapacity, reflected by the saturation of the EE. Enlarging the bond dimension\nof an MPS beyond the EE saturation threshold does not increase the prediction\naccuracies, so a minimal model that best estimates the data statistics can be\nconstructed. Although the saturated EE is smaller than the maximum EE\nachievable by the area law of an MPS, our model achieves ~99% training\naccuracies in realistic sentiment analysis data sets. Thus, low EE alone is not\na warrant against the adoption of single-layer RACs for NLP. Contrary to a\ncommon belief that long-range information propagation is the main source of\nRNNs' expressiveness, we show that single-layer RACs also harness high\nexpressiveness from meaningful word vector embeddings. Our work sheds light on\nthe phenomenology of learning in RACs and more generally on the explainability\naspects of RNNs for NLP, using tools from many-body quantum physics.",
    "descriptor": "\nComments: 25 pages, 7 figures\n",
    "authors": [
      "Jirawat Tangpanitanon",
      "Chanatip Mangkang",
      "Pradeep Bhadola",
      "Yuichiro Minato",
      "Dimitris Angelakis",
      "Thiparat Chotibut"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.08628"
  },
  {
    "id": "arXiv:2112.08644",
    "title": "A comparative study of paired versus unpaired deep learning methods for  physically enhancing digital rock image resolution",
    "abstract": "X-ray micro-computed tomography (micro-CT) has been widely leveraged to\ncharacterise pore-scale geometry in subsurface porous rock. Recent developments\nin super resolution (SR) methods using deep learning allow the digital\nenhancement of low resolution (LR) images over large spatial scales, creating\nSR images comparable to the high resolution (HR) ground truth. This circumvents\ntraditional resolution and field-of-view trade-offs. An outstanding issue is\nthe use of paired (registered) LR and HR data, which is often required in the\ntraining step of such methods but is difficult to obtain. In this work, we\nrigorously compare two different state-of-the-art SR deep learning techniques,\nusing both paired and unpaired data, with like-for-like ground truth data. The\nfirst approach requires paired images to train a convolutional neural network\n(CNN) while the second approach uses unpaired images to train a generative\nadversarial network (GAN). The two approaches are compared using a micro-CT\ncarbonate rock sample with complicated micro-porous textures. We implemented\nvarious image based and numerical verifications and experimental validation to\nquantitatively evaluate the physical accuracy and sensitivities of the two\nmethods. Our quantitative results show that unpaired GAN approach can\nreconstruct super-resolution images as precise as paired CNN method, with\ncomparable training times and dataset requirement. This unlocks new\napplications for micro-CT image enhancement using unpaired deep learning\nmethods; image registration is no longer needed during the data processing\nstage. Decoupled images from data storage platforms can be exploited more\nefficiently to train networks for SR digital rock applications. This opens up a\nnew pathway for various applications of multi-scale flow simulation in\nheterogeneous porous media.",
    "descriptor": "\nComments: 26 pages, 11 figures, 4 tables\n",
    "authors": [
      "Yufu Niu",
      "Samuel J. Jackson",
      "Naif Alqahtani",
      "Peyman Mostaghimi",
      "Ryan T. Armstrong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08644"
  },
  {
    "id": "arXiv:2112.08659",
    "title": "q-ary Propelinear Perfect Codes from the Regular Subgroups of the  GA(r,q) and Their Ranks",
    "abstract": "We propose a new method of constructing q-ary propelinear perfect codes. The\napproach utilizes permutations of the fixed length q-ary vectors that arise\nfrom the automorphisms of the regular subgroups of the affine group. For any\nprime q it is shown that the new class contains an infinite series of q-ary\npropelinear perfect codes of varying ranks of growing length.",
    "descriptor": "",
    "authors": [
      "Ivan Mogilnykh"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.08659"
  },
  {
    "id": "arXiv:2112.08767",
    "title": "Adaptation and Attention for Neural Video Coding",
    "abstract": "Neural image coding represents now the state-of-the-art image compression\napproach. However, a lot of work is still to be done in the video domain. In\nthis work, we propose an end-to-end learned video codec that introduces several\narchitectural novelties as well as training novelties, revolving around the\nconcepts of adaptation and attention. Our codec is organized as an intra-frame\ncodec paired with an inter-frame codec. As one architectural novelty, we\npropose to train the inter-frame codec model to adapt the motion estimation\nprocess based on the resolution of the input video. A second architectural\nnovelty is a new neural block that combines concepts from split-attention based\nneural networks and from DenseNets. Finally, we propose to overfit a set of\ndecoder-side multiplicative parameters at inference time. Through ablation\nstudies and comparisons to prior art, we show the benefits of our proposed\ntechniques in terms of coding gains. We compare our codec to VVC/H.266 and\nRLVC, which represent the state-of-the-art traditional and end-to-end learned\ncodecs, respectively, and to the top performing end-to-end learned approach in\n2021 CLIC competition, E2E_T_OL. Our codec clearly outperforms E2E_T_OL, and\ncompare favorably to VVC and RLVC in some settings.",
    "descriptor": "",
    "authors": [
      "Nannan Zou",
      "Honglei Zhang",
      "Francesco Cricri",
      "Ramin G. Youvalari",
      "Hamed R. Tavakoli",
      "Jani Lainema",
      "Emre Aksu",
      "Miska Hannuksela",
      "Esa Rahtu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08767"
  },
  {
    "id": "arXiv:2112.08778",
    "title": "Self-Supervised Learning for speech recognition with Intermediate layer  supervision",
    "abstract": "Recently, pioneer work finds that speech pre-trained models can solve\nfull-stack speech processing tasks, because the model utilizes bottom layers to\nlearn speaker-related information and top layers to encode content-related\ninformation. Since the network capacity is limited, we believe the speech\nrecognition performance could be further improved if the model is dedicated to\naudio content information learning. To this end, we propose Intermediate Layer\nSupervision for Self-Supervised Learning (ILS-SSL), which forces the model to\nconcentrate on content information as much as possible by adding an additional\nSSL loss on the intermediate layers. Experiments on LibriSpeech test-other set\nshow that our method outperforms HuBERT significantly, which achieves a\n23.5%/11.6% relative word error rate reduction in the w/o language model\nsetting for base/large models. Detailed analysis shows the bottom layers of our\nmodel have a better correlation with phonetic units, which is consistent with\nour intuition and explains the success of our method for ASR.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Chengyi Wang",
      "Yu Wu",
      "Sanyuan Chen",
      "Shujie Liu",
      "Jinyu Li",
      "Yao Qian",
      "Zhenglu Yang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08778"
  },
  {
    "id": "arXiv:2112.08781",
    "title": "Multi-Sidon spaces over finite fields",
    "abstract": "Sidon spaces have been introduced by Bachoc, Serra and Z\\'emor in 2017 in\nconnection with the linear analogue of Vosper's Theorem. In this paper, we\npropose a generalization of this notion to sets of subspaces, which we call\nmulti-Sidon space. We analyze their structures, provide examples and introduce\na notion of equivalnce among them. Making use of these results, we study a\nclass of linear sets in PG$(r-1,q^n)$ determined by $r$ points and we\ninvestigate multi-orbit cyclic subspace codes.",
    "descriptor": "",
    "authors": [
      "Ferdinando Zullo"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.08781"
  },
  {
    "id": "arXiv:2112.08791",
    "title": "Beamspace MIMO for Satellite Swarms",
    "abstract": "Systems of small distributed satellites in low Earth orbit (LEO) transmitting\ncooperatively to a multiple antenna ground station (GS) are investigated. These\nsatellite swarms have the benefit of much higher spatial separation in the\ntransmit antennas than traditional big satellites with antenna arrays,\npromising a massive increase in spectral efficiency. However, this would\nrequire instantaneous perfect channel state information (CSI) and strong\ncooperation between satellites. In practice, orbital velocities around 7.5 km/s\nlead to very short channel coherence times on the order of fractions of the\ninter-satellite propagation delay, invalidating these assumptions. In this\npaper, we propose a distributed linear precoding scheme and a GS equalizer\nrelying on local position information. In particular, each satellite only\nrequires information about its own position and that of the GS, while the GS\nhas complete positional information. Due to the deterministic nature of\nsatellite movement this information is easily obtained and no inter-satellite\ninformation exchange is required during transmission. Based on the underlying\ngeometrical channel approximation, the optimal inter-satellite distance is\nobtained analytically. Numerical evaluations show that the proposed scheme is,\non average, within 99.8% of the maximum achievable rate for instantaneous CSI\nand perfect cooperation",
    "descriptor": "\nComments: 6 pages, 5 figures, Accepted for presentation at IEEE Wireless Communications and Networking Conference 2022 (2022 IEEE WCNC)\n",
    "authors": [
      "Maik R\u00f6per",
      "Bho Matthiesen",
      "Dirk W\u00fcbben",
      "Petar Popovski",
      "Armin Dekorsy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.08791"
  },
  {
    "id": "arXiv:2112.08807",
    "title": "On $d$-panconnected tournaments with large semidegrees",
    "abstract": "We prove the following new results.\n(a) Let $T$ be a regular tournament of order $2n+1\\geq 11$ and $S$ a subset\nof $V(T)$. Suppose that $|S|\\leq \\frac{1}{2}(n-2)$ and $x$, $y$ are distinct\nvertices in $V(T)\\setminus S$. If the subtournament $T-S$ contains an\n$(x,y)$-path of length $r$, where $3\\leq r\\leq |V(T)\\setminus S|-2$, then $T-S$\nalso contains an $(x,y)$-path of length $r+1$.\n(b) Let $T$ be an $m$-irregular tournament of order $p$, i.e.,\n$|d^+(x)-d^-(x)|\\le m$ for every vertex $x$ of $T.$ If $m\\leq \\frac{1}{3}(p-5)$\n(respectively, $m\\leq \\frac{1}{5}(p-3)$), then for every pair of vertices $x$\nand $y$, $T$ has an $(x,y)$-path of any length $k$, $4\\leq k\\leq p-1$\n(respectively, $3\\leq k\\leq p-1$ or $T$ belongs to a family $\\cal G$ of\ntournaments, which is defined in the paper). In other words, (b) means that if\nthe semidegrees of every vertex of a tournament $T$ of order $p$ are between\n$\\frac{1}{3}(p+1)$ and $\\frac{2}{3}(p-2)$ (respectively, between\n$\\frac{1}{5}(2p-1)$ and $\\frac{1}{5}(3p-4)$), then the claims in (b) hold.\nOur results improve in a sense related results of Alspach (1967), Jacobsen\n(1972), Alspach et al. (1974), Thomassen (1978) and Darbinyan (1977, 1978,\n1979), and are sharp in a sense.",
    "descriptor": "",
    "authors": [
      "Samvel Kh. Darbinyan",
      "Gregory Z. Gutin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.08807"
  },
  {
    "id": "arXiv:2112.08837",
    "title": "Improving Unsupervised Stain-To-Stain Translation using Self-Supervision  and Meta-Learning",
    "abstract": "In digital pathology, many image analysis tasks are challenged by the need\nfor large and time-consuming manual data annotations to cope with various\nsources of variability in the image domain. Unsupervised domain adaptation\nbased on image-to-image translation is gaining importance in this field by\naddressing variabilities without the manual overhead. Here, we tackle the\nvariation of different histological stains by unsupervised stain-to-stain\ntranslation to enable a stain-independent applicability of a deep learning\nsegmentation model. We use CycleGANs for stain-to-stain translation in kidney\nhistopathology, and propose two novel approaches to improve translational\neffectivity. First, we integrate a prior segmentation network into the CycleGAN\nfor a self-supervised, application-oriented optimization of translation through\nsemantic guidance, and second, we incorporate extra channels to the translation\noutput to implicitly separate artificial meta-information otherwise encoded for\ntackling underdetermined reconstructions. The latter showed partially superior\nperformances to the unmodified CycleGAN, but the former performed best in all\nstains providing instance-level Dice scores ranging between 78% and 92% for\nmost kidney structures, such as glomeruli, tubules, and veins. However,\nCycleGANs showed only limited performance in the translation of other\nstructures, e.g. arteries. Our study also found somewhat lower performance for\nall structures in all stains when compared to segmentation in the original\nstain. Our study suggests that with current unsupervised technologies, it seems\nunlikely to produce generally applicable fake stains.",
    "descriptor": "",
    "authors": [
      "Nassim Bouteldja",
      "Barbara Mara Klinkhammer",
      "Tarek Schlaich",
      "Peter Boor",
      "Dorit Merhof"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.08837"
  },
  {
    "id": "arXiv:2112.08851",
    "title": "Classification Under Ambiguity: When Is Average-K Better Than Top-K?",
    "abstract": "When many labels are possible, choosing a single one can lead to low\nprecision. A common alternative, referred to as top-$K$ classification, is to\nchoose some number $K$ (commonly around 5) and to return the $K$ labels with\nthe highest scores. Unfortunately, for unambiguous cases, $K>1$ is too many\nand, for very ambiguous cases, $K \\leq 5$ (for example) can be too small. An\nalternative sensible strategy is to use an adaptive approach in which the\nnumber of labels returned varies as a function of the computed ambiguity, but\nmust average to some particular $K$ over all the samples. We denote this\nalternative average-$K$ classification. This paper formally characterizes the\nambiguity profile when average-$K$ classification can achieve a lower error\nrate than a fixed top-$K$ classification. Moreover, it provides natural\nestimation procedures for both the fixed-size and the adaptive classifier and\nproves their consistency. Finally, it reports experiments on real-world image\ndata sets revealing the benefit of average-$K$ classification over top-$K$ in\npractice. Overall, when the ambiguity is known precisely, average-$K$ is never\nworse than top-$K$, and, in our experiments, when it is estimated, this also\nholds.",
    "descriptor": "\nComments: 53 pages, 21 figures\n",
    "authors": [
      "Titouan Lorieul",
      "Alexis Joly",
      "Dennis Shasha"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08851"
  },
  {
    "id": "arXiv:2112.08859",
    "title": "Variational Quantum Algorithms for Semidefinite Programming",
    "abstract": "A semidefinite program (SDP) is a particular kind of convex optimization\nproblem with applications in operations research, combinatorial optimization,\nquantum information science, and beyond. In this work, we propose variational\nquantum algorithms for approximately solving SDPs. For one class of SDPs, we\nprovide a rigorous analysis of their convergence to approximate locally optimal\nsolutions, under the assumption that they are weakly constrained (i.e., $N\\gg\nM$, where $N$ is the dimension of the input matrices and $M$ is the number of\nconstraints). We also provide algorithms for a more general class of SDPs that\nrequires fewer assumptions. Finally, we numerically simulate our quantum\nalgorithms for applications such as MaxCut, and the results of these\nsimulations provide evidence that convergence still occurs in noisy settings.",
    "descriptor": "\nComments: 33 pages, 9 figures, preliminary version\n",
    "authors": [
      "Dhrumil Patel",
      "Patrick J. Coles",
      "Mark M. Wilde"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.08859"
  },
  {
    "id": "arXiv:2112.08866",
    "title": "BayesFlow can reliably detect Model Misspecification and Posterior  Errors in Amortized Bayesian Inference",
    "abstract": "Neural density estimators have proven remarkably powerful in performing\nefficient simulation-based Bayesian inference in various research domains. In\nparticular, the BayesFlow framework uses a two-step approach to enable\namortized parameter estimation in settings where the likelihood function is\nimplicitly defined by a simulation program. But how faithful is such inference\nwhen simulations are poor representations of reality? In this paper, we\nconceptualize the types of model misspecification arising in simulation-based\ninference and systematically investigate the performance of the BayesFlow\nframework under these misspecifications. We propose an augmented optimization\nobjective which imposes a probabilistic structure on the latent data space and\nutilize maximum mean discrepancy (MMD) to detect potentially catastrophic\nmisspecifications during inference undermining the validity of the obtained\nresults. We verify our detection criterion on a number of artificial and\nrealistic misspecifications, ranging from toy conjugate models to complex\nmodels of decision making and disease outbreak dynamics applied to real data.\nFurther, we show that posterior inference errors increase as a function of the\ndistance between the true data-generating distribution and the typical set of\nsimulations in the latent summary space. Thus, we demonstrate the dual utility\nof MMD as a method for detecting model misspecification and as a proxy for\nverifying the faithfulness of amortized Bayesian inference.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Marvin Schmitt",
      "Paul-Christian B\u00fcrkner",
      "Ullrich K\u00f6the",
      "Stefan T. Radev"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08866"
  },
  {
    "id": "arXiv:2112.08882",
    "title": "BitTorrent is Apt for Geophysical Data Collection and Distribution",
    "abstract": "This article covers a nouveau idea of how to collect and handle geophysical\ndata with a peer-to-peer network in near real-time. The text covers a brief\nintroduction to the cause, the technology, and the particular case of\ncollecting data from GNSS stations. We describe the proof-of-concept\nimplementation that has been tested. The test was conducted with an\nexperimental GNSS station and a data aggregation facility. In the test,\noriginal raw GNSS signal measurements were transferred to the data aggregation\ncenter and subsequently to the consumer. Our implementation utilized BitTorrent\nto communicate and transfer data. The solution could be used to establish the\nmajority of data aggregation centers activities to provide fast, reliable, and\ntransparent real-time data handling experience to the scientific community.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "K. I. Kholodkov",
      "I. M. Aleshin",
      "S. D. Ivanov"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.08882"
  },
  {
    "id": "arXiv:2112.08926",
    "title": "On the accuracy and performance of the lattice Boltzmann method with  64-bit, 32-bit and novel 16-bit number formats",
    "abstract": "Fluid dynamics simulations with the lattice Boltzmann method (LBM) are very\nmemory-intensive. Alongside reduction in memory footprint, significant\nperformance benefits can be achieved by using FP32 (single) precision compared\nto FP64 (double) precision, especially on GPUs. Here, we evaluate the\npossibility to use even FP16 and Posit16 (half) precision for storing fluid\npopulations, while still carrying arithmetic operations in FP32. For this, we\nfirst show that the commonly occurring number range in the LBM is a lot smaller\nthan the FP16 number range. Based on this observation, we develop novel 16-bit\nformats - based on a modified IEEE-754 and on a modified Posit standard - that\nare specifically tailored to the needs of the LBM. We then carry out an\nin-depth characterization of LBM accuracy for six different test systems with\nincreasing complexity: Poiseuille flow, Taylor-Green vortices, Karman vortex\nstreets, lid-driven cavity, a microcapsule in shear flow (utilizing the\nimmersed-boundary method) and finally the impact of a raindrop (based on a\nVolume-of-Fluid approach). We find that the difference in accuracy between FP64\nand FP32 is negligible in almost all cases, and that for a large number of\ncases even 16-bit is sufficient. Finally, we provide a detailed performance\nanalysis of all precision levels on a large number of hardware\nmicroarchitectures and show that significant speedup is achieved with mixed\nFP32/16-bit.",
    "descriptor": "\nComments: 30 pages, 20 figures, 4 tables, 2 code listings\n",
    "authors": [
      "Moritz Lehmann",
      "Mathias J. Krause",
      "Giorgio Amati",
      "Marcello Sega",
      "Jens Harting",
      "Stephan Gekle"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Biological Physics (physics.bio-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2112.08926"
  },
  {
    "id": "arXiv:2112.08929",
    "title": "Bootstrap Equilibrium and Probabilistic Speaker Representation Learning  for Self-supervised Speaker Verification",
    "abstract": "In this paper, we propose self-supervised speaker representation learning\nstrategies, which comprise of a bootstrap equilibrium speaker representation\nlearning in the front-end and an uncertainty-aware probabilistic speaker\nembedding training in the back-end. In the front-end stage, we learn the\nspeaker representations via the bootstrap training scheme with the uniformity\nregularization term. In the back-end stage, the probabilistic speaker\nembeddings are estimated by maximizing the mutual likelihood score between the\nspeech samples belonging to the same speaker, which provide not only speaker\nrepresentations but also data uncertainty. Experimental results show that the\nproposed bootstrap equilibrium training strategy can effectively help learn the\nspeaker representations and outperforms the conventional methods based on\ncontrastive learning. Also, we demonstrate that the integrated two-stage\nframework further improves the speaker verification performance on the\nVoxCeleb1 test set in terms of EER and MinDCF.",
    "descriptor": "\nComments: Accepted by IEEE Access\n",
    "authors": [
      "Sung Hwan Mun",
      "Min Hyun Han",
      "Dongjune Lee",
      "Jihwan Kim",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.08929"
  },
  {
    "id": "arXiv:2112.08958",
    "title": "Utility maximizing load balancing policies",
    "abstract": "Consider a service system where incoming tasks are instantaneously dispatched\nto one out of many heterogeneous server pools. Associated with each server pool\nis a concave utility function which depends on the class of the server pool and\nits current occupancy. We derive an upper bound for the mean normalized\naggregate utility in stationarity and introduce two load balancing policies\nthat achieve this upper bound in a large-scale regime. Furthermore, the\ntransient and stationary behavior of these asymptotically optimal load\nbalancing policies is characterized on the scale of the number of server pools,\nin the same large-scale regime.",
    "descriptor": "\nComments: 71 pages, 6 figures\n",
    "authors": [
      "Diego Goldsztajn",
      "Sem C. Borst",
      "Johan S.H. van Leeuwaarden"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.08958"
  },
  {
    "id": "arXiv:2112.08961",
    "title": "Objective hearing threshold identification from auditory brainstem  response measurements using supervised and self-supervised approaches",
    "abstract": "Hearing loss is a major health problem and psychological burden in humans.\nMouse models offer a possibility to elucidate genes involved in the underlying\ndevelopmental and pathophysiological mechanisms of hearing impairment. To this\nend, large-scale mouse phenotyping programs include auditory phenotyping of\nsingle-gene knockout mouse lines. Using the auditory brainstem response (ABR)\nprocedure, the German Mouse Clinic and similar facilities worldwide have\nproduced large, uniform data sets of averaged ABR raw data of mutant and\nwildtype mice. In the course of standard ABR analysis, hearing thresholds are\nassessed visually by trained staff from series of signal curves of increasing\nsound pressure level. This is time-consuming and prone to be biased by the\nreader as well as the graphical display quality and scale. In an attempt to\nreduce workload and improve quality and reproducibility, we developed and\ncompared two methods for automated hearing threshold identification from\naveraged ABR raw data: a supervised approach involving two combined neural\nnetworks trained on human-generated labels and a self-supervised approach,\nwhich exploits the signal power spectrum and combines random forest sound level\nestimation with a piece-wise curve fitting algorithm for threshold finding. We\nshow that both models work well, outperform human threshold detection, and are\nsuitable for fast, reliable, and unbiased hearing threshold detection and\nquality control. In a high-throughput mouse phenotyping environment, both\nmethods perform well as part of an automated end-to-end screening pipeline to\ndetect candidate genes for hearing involvement. Code for both models as well as\ndata used for this work are freely available.",
    "descriptor": "\nComments: 41 pages, 17 figures\n",
    "authors": [
      "Dominik Thalmeier",
      "Gregor Miller",
      "Elida Schneltzer",
      "Anja Hurt",
      "Martin Hrab\u011b de Angelis",
      "Lore Becker",
      "Christian L. M\u00fcller",
      "Holger Maier"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.08961"
  },
  {
    "id": "arXiv:2112.08968",
    "title": "Automated segmentation of 3-D body composition on computed tomography",
    "abstract": "Purpose: To develop and validate a computer tool for automatic and\nsimultaneous segmentation of body composition depicted on computed tomography\n(CT) scans for the following tissues: visceral adipose (VAT), subcutaneous\nadipose (SAT), intermuscular adipose (IMAT), skeletal muscle (SM), and bone.\nApproach: A cohort of 100 CT scans acquired from The Cancer Imaging Archive\n(TCIA) was used - 50 whole-body positron emission tomography (PET)-CTs, 25\nchest, and 25 abdominal. Five different body compositions were manually\nannotated (VAT, SAT, IMAT, SM, and bone). A training-while-annotating strategy\nwas used for efficiency. The UNet model was trained using the already annotated\ncases. Then, this model was used to enable semi-automatic annotation for the\nremaining cases. The 10-fold cross-validation method was used to develop and\nvalidate the performance of several convolutional neural networks (CNNs),\nincluding UNet, Recurrent Residual UNet (R2Unet), and UNet++. A 3-D patch\nsampling operation was used when training the CNN models. The separately\ntrained CNN models were tested to see if they could achieve a better\nperformance than segmenting them jointly. Paired-samples t-test was used to\ntest for statistical significance.\nResults: Among the three CNN models, UNet demonstrated the best overall\nperformance in jointly segmenting the five body compositions with a Dice\ncoefficient of 0.840+/-0.091, 0.908+/-0.067, 0.603+/-0.084, 0.889+/-0.027, and\n0.884+/-0.031, and a Jaccard index of 0.734+/-0.119, 0.837+/-0.096,\n0.437+/-0.082, 0.800+/-0.042, 0.793+/-0.049, respectively for VAT, SAT, IMAT,\nSM, and bone.\nConclusion: There were no significant differences among the CNN models in\nsegmenting body composition, but jointly segmenting body compositions achieved\na better performance than segmenting them separately.",
    "descriptor": "",
    "authors": [
      "Lucy Pu",
      "Syed F. Ashraf",
      "Naciye S Gezer",
      "Iclal Ocak",
      "Rajeev Dhupar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08968"
  },
  {
    "id": "arXiv:2112.08974",
    "title": "Quality monitoring of federated Covid-19 lesion segmentation",
    "abstract": "Federated Learning is the most promising way to train robust Deep Learning\nmodels for the segmentation of Covid-19-related findings in chest CTs. By\nlearning in a decentralized fashion, heterogeneous data can be leveraged from a\nvariety of sources and acquisition protocols whilst ensuring patient privacy.\nIt is, however, crucial to continuously monitor the performance of the model.\nYet when it comes to the segmentation of diffuse lung lesions, a quick visual\ninspection is not enough to assess the quality, and thorough monitoring of all\nnetwork outputs by expert radiologists is not feasible. In this work, we\npresent an array of lightweight metrics that can be calculated locally in each\nhospital and then aggregated for central monitoring of a federated system. Our\nlinear model detects over 70% of low-quality segmentations on an\nout-of-distribution dataset and thus reliably signals a decline in model\nperformance.",
    "descriptor": "",
    "authors": [
      "Camila Gonzalez",
      "Christian Harder",
      "Amin Ranem",
      "Ricarda Fischbach",
      "Isabel Kaltenborn",
      "Armin Dadras",
      "Andreas Bucher",
      "Anirban Mukhopadhyay"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08974"
  },
  {
    "id": "arXiv:2112.08984",
    "title": "Object-based synthesis of scraping and rolling sounds based on  non-linear physical constraints",
    "abstract": "Sustained contact interactions like scraping and rolling produce a wide\nvariety of sounds. Previous studies have explored ways to synthesize these\nsounds efficiently and intuitively but could not fully mimic the rich structure\nof real instances of these sounds. We present a novel source-filter model for\nrealistic synthesis of scraping and rolling sounds with physically and\nperceptually relevant controllable parameters constrained by principles of\nmechanics. Key features of our model include non-linearities to constrain the\ncontact force, naturalistic normal force variation for different motions, and a\nmethod for morphing impulse responses within a material to achieve\nlocation-dependence. Perceptual experiments show that the presented model is\nable to synthesize realistic scraping and rolling sounds while conveying\nphysical information similar to that in recorded sounds.",
    "descriptor": "",
    "authors": [
      "Vinayak Agarwal",
      "Maddie Cusimano",
      "James Traer",
      "Josh McDermott"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.08984"
  },
  {
    "id": "arXiv:2112.08988",
    "title": "Interference Suppression Using Deep Learning: Current Approaches and  Open Challenges",
    "abstract": "In light of the finite nature of the wireless spectrum and the increasing\ndemand for spectrum use arising from recent technological breakthroughs in\nwireless communication, the problem of interference continues to persist.\nDespite recent advancements in resolving interference issues, interference\nstill presents a difficult challenge to effective usage of the spectrum. This\nis partly due to the rise in the use of license-free and managed shared bands\nfor Wi-Fi, long term evolution (LTE) unlicensed (LTE-U), LTE licensed assisted\naccess (LAA), 5G NR, and other opportunistic spectrum access solutions. As a\nresult of this, the need for efficient spectrum usage schemes that are robust\nagainst interference has never been more important. In the past, most solutions\nto interference have addressed the problem by using avoidance techniques as\nwell as non-AI mitigation approaches (for example, adaptive filters). The key\ndownside to non-AI techniques is the need for domain expertise in the\nextraction or exploitation of signal features such as cyclostationarity,\nbandwidth and modulation of the interfering signals. More recently, researchers\nhave successfully explored AI/ML enabled physical (PHY) layer techniques,\nespecially deep learning which reduces or compensates for the interfering\nsignal instead of simply avoiding it. The underlying idea of ML based\napproaches is to learn the interference or the interference characteristics\nfrom the data, thereby sidelining the need for domain expertise in suppressing\nthe interference. In this paper, we review a wide range of techniques that have\nused deep learning to suppress interference. We provide comparison and\nguidelines for many different types of deep learning techniques in interference\nsuppression. In addition, we highlight challenges and potential future research\ndirections for the successful adoption of deep learning in interference\nsuppression.",
    "descriptor": "\nComments: 26 pages, 10 figures, journal article\n",
    "authors": [
      "Taiwo Oyedare",
      "Vijay K Shah",
      "Daniel J Jakubisin",
      "Jeff H Reed"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.08988"
  },
  {
    "id": "arXiv:2112.09015",
    "title": "Multivariate Realized Volatility Forecasting with Graph Neural Network",
    "abstract": "The existing publications demonstrate that the limit order book data is\nuseful in predicting short-term volatility in stock markets. Since stocks are\nnot independent, changes on one stock can also impact other related stocks. In\nthis paper, we are interested in forecasting short-term realized volatility in\na multivariate approach based on limit order book data and relational data. To\nachieve this goal, we introduce Graph Transformer Network for Volatility\nForecasting. The model allows to combine limit order book features and an\nunlimited number of temporal and cross-sectional relations from different\nsources. Through experiments based on about 500 stocks from S&P 500 index, we\nfind a better performance for our model than for other benchmarks.",
    "descriptor": "\nComments: 13 pages, 6 tables, 4 figures\n",
    "authors": [
      "Qinkai Chen",
      "Christian-Yann Robert"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2112.09015"
  },
  {
    "id": "arXiv:2112.09017",
    "title": "Large Scale Distributed Linear Algebra With Tensor Processing Units",
    "abstract": "We have repurposed Google Tensor Processing Units (TPUs),\napplication-specific chips developed for machine learning, into large-scale\ndense linear algebra supercomputers. The TPUs' fast inter-core interconnects\n(ICI)s, physically two-dimensional network topology, and high-bandwidth memory\n(HBM) permit distributed matrix multiplication algorithms to rapidly become\ncomputationally bound. In this regime, the matrix-multiply units (MXU)s\ndominate the runtime, yielding impressive scaling, performance, and raw size:\noperating in float32 precision, a full 2048-core pod of third generation TPUs\ncan multiply two matrices with linear size $N= 220= 1 048 576$ in about 2\nminutes. Via curated algorithms emphasizing large, single-core matrix\nmultiplications, other tasks in dense linear algebra can similarly scale. As\nexamples, we present (i) QR decomposition; (ii) resolution of linear systems;\nand (iii) the computation of matrix functions by polynomial iteration,\ndemonstrated by the matrix polar factorization.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Adam G.M. Lewis",
      "Jackson Beall",
      "Martin Ganahl",
      "Markus Hauru",
      "Shrestha Basu Mallick",
      "Guifre Vidal"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.09017"
  },
  {
    "id": "arXiv:2112.09020",
    "title": "Classification of diffraction patterns using a convolutional neural  network in single particle imaging experiments performed at X-ray  free-electron lasers",
    "abstract": "Single particle imaging (SPI) at X-ray free electron lasers (XFELs) is\nparticularly well suited to determine the 3D structure of particles in their\nnative environment. For a successful reconstruction, diffraction patterns\noriginating from a single hit must be isolated from a large number of acquired\npatterns. We propose to formulate this task as an image classification problem\nand solve it using convolutional neural network (CNN) architectures. Two CNN\nconfigurations are developed: one that maximises the F1-score and one that\nemphasises high recall. We also combine the CNNs with expectation maximization\n(EM) selection as well as size filtering. We observed that our CNN selections\nhave lower contrast in power spectral density functions relative to the EM\nselection, used in our previous work. However, the reconstruction of our\nCNN-based selections gives similar results. Introducing CNNs into SPI\nexperiments allows streamlining the reconstruction pipeline, enables\nresearchers to classify patterns on the fly, and, as a consequence, enables\nthem to tightly control the duration of their experiments. We think that\nbringing non-standard artificial intelligence (AI) based solutions in a\nwell-described SPI analysis workflow may be beneficial for the future\ndevelopment of the SPI experiments.",
    "descriptor": "\nComments: Main text: 28 pages, 7 figures, Supporting Information: 12 pages, 6 figures\n",
    "authors": [
      "Dameli Assalauova",
      "Alexandr Ignatenko",
      "Fabian Isensee",
      "Sergey Bobkov",
      "Darya Trofimova",
      "Ivan A. Vartanyants"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.09020"
  },
  {
    "id": "arXiv:2112.09036",
    "title": "The Dual PC Algorithm for Structure Learning",
    "abstract": "While learning the graphical structure of Bayesian networks from\nobservational data is key to describing and helping understand data generating\nprocesses in complex applications, the task poses considerable challenges due\nto its computational complexity. The directed acyclic graph (DAG) representing\na Bayesian network model is generally not identifiable from observational data,\nand a variety of methods exist to estimate its equivalence class instead. Under\ncertain assumptions, the popular PC algorithm can consistently recover the\ncorrect equivalence class by testing for conditional independence (CI),\nstarting from marginal independence relationships and progressively expanding\nthe conditioning set. Here, we propose the dual PC algorithm, a novel scheme to\ncarry out the CI tests within the PC algorithm by leveraging the inverse\nrelationship between covariance and precision matrices. Notably, the elements\nof the precision matrix coincide with partial correlations for Gaussian data.\nOur algorithm then exploits block matrix inversions on the covariance and\nprecision matrices to simultaneously perform tests on partial correlations of\ncomplementary (or dual) conditioning sets. The multiple CI tests of the dual PC\nalgorithm, therefore, proceed by first considering marginal and full-order CI\nrelationships and progressively moving to central-order ones. Simulation\nstudies indicate that the dual PC algorithm outperforms the classical PC\nalgorithm both in terms of run time and in recovering the underlying network\nstructure.",
    "descriptor": "",
    "authors": [
      "Enrico Giudice",
      "Jack Kuipers",
      "Giusi Moffa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09036"
  },
  {
    "id": "arXiv:2112.09047",
    "title": "Citation inequity and gendered citation practices in contemporary  physics",
    "abstract": "The historical and contemporary under-attribution of women's contributions to\nscientific scholarship is well-known and well-studied, with effects that are\nfelt today in myriad ways by women scientists. One measure of this\nunder-attribution is the so-called citation gap between men and women: the\nunder-citation of papers authored by women relative to expected rates coupled\nwith a corresponding over-citation of papers authored by men relative to\nexpected rates. We explore the citation gap in contemporary physics, analyzing\nover one million articles published over the last 25 years in 35 physics\njournals that span a wide range of subfields. Using a model that predicts\npapers' expected citation rates according to a set of characteristics separate\nfrom author gender, we find a global bias wherein papers authored by women are\nsignificantly under-cited, and papers authored by men are significantly\nover-cited. Moreover, we find that citation behavior varies along several\ndimensions, such that imbalances differ according to who is citing, where they\nare citing, and how they are citing. Specifically, citation imbalance in favor\nof man-authored papers is highest for papers authored by men, papers published\nin general physics journals, and papers likely to be less familiar to citing\nauthors. Our results suggest that, although deciding which papers to cite is an\nindividual choice, the cumulative effects of these choices needlessly harm a\nsubset of scholars. We discuss several strategies for the mitigation of these\neffects, including conscious behavioral changes at the individual, journal, and\ncommunity levels.",
    "descriptor": "",
    "authors": [
      "Erin G. Teich",
      "Jason Z. Kim",
      "Christopher W. Lynn",
      "Samantha C. Simon",
      "Andrei A. Klishin",
      "Karol P. Szymula",
      "Pragya Srivastava",
      "Lee C. Bassett",
      "Perry Zurn",
      "Jordan D. Dworkin",
      "Dani S. Bassett"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2112.09047"
  },
  {
    "id": "arXiv:2112.09051",
    "title": "Simultaneous Multivariate Forecast of Space Weather Indices using Deep  Neural Network Ensembles",
    "abstract": "Solar radio flux along with geomagnetic indices are important indicators of\nsolar activity and its effects. Extreme solar events such as flares and\ngeomagnetic storms can negatively affect the space environment including\nsatellites in low-Earth orbit. Therefore, forecasting these space weather\nindices is of great importance in space operations and science. In this study,\nwe propose a model based on long short-term memory neural networks to learn the\ndistribution of time series data with the capability to provide a simultaneous\nmultivariate 27-day forecast of the space weather indices using time series as\nwell as solar image data. We show a 30-40\\% improvement of the root mean-square\nerror while including solar image data with time series data compared to using\ntime series data alone. Simple baselines such as a persistence and running\naverage forecasts are also compared with the trained deep neural network\nmodels. We also quantify the uncertainty in our prediction using a model\nensemble.",
    "descriptor": "\nComments: Fourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021)\n",
    "authors": [
      "Bernard Benson",
      "Edward Brown",
      "Stefano Bonasera",
      "Giacomo Acciarini",
      "Jorge A. P\u00e9rez-Hern\u00e1ndez",
      "Eric Sutton",
      "Moriba K. Jah",
      "Christopher Bridges",
      "Meng Jin",
      "At\u0131l\u0131m G\u00fcne\u015f Baydin"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09051"
  },
  {
    "id": "arXiv:2112.09065",
    "title": "Macroscopic properties of buyer-seller networks in online marketplaces",
    "abstract": "Online marketplaces are the main engines of legal and illegal e-commerce, yet\nthe aggregate properties of buyer-seller networks behind them are poorly\nunderstood. We analyze two datasets containing 245M transactions (16B USD) that\ntook place on online marketplaces between 2010 and 2021. The data cover 28 dark\nweb marketplaces, i.e., unregulated markets whose main currency is Bitcoin, and\n144 product markets of one regulated e-commerce platform. We show how\ntransactions in online marketplaces exhibit strikingly similar patterns of\naggregate behavior despite significant differences in language, lifetimes\navailable products, regulation, oversight, and technology. We find remarkable\nregularities in the distributions of (i) transaction amounts, (ii) number of\ntransactions, (iii) inter-event times, (iv) time between first and last\ntransactions. We then show how buyer behavior is affected by the memory of past\ninteractions, and draw on these observations to propose a model of network\nformation able to reproduce the main stylized facts of the data. Our findings\nhave implications for understanding market power on online marketplaces as well\nas inter-marketplace competition.",
    "descriptor": "",
    "authors": [
      "Alberto Bracci",
      "J\u00f6rn Boehnke",
      "Abeer ElBahrawy",
      "Nicola Perra",
      "Alexander Teytelboym",
      "Andrea Baronchelli"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2112.09065"
  },
  {
    "id": "arXiv:2112.09066",
    "title": "An Interactive Approach for Identifying Structure Definitions",
    "abstract": "Our ability to grasp and understand complex phenomena is essentially based on\nrecognizing structures and relating these to each other. For example, any\nmeteorological description of a weather condition and explanation of its\nevolution recurs to meteorological structures, such as convection and\ncirculation structures, cloud fields and rain fronts. All of these are\nspatiotemporal structures, defined by time-dependent patterns in the underlying\nfields. Typically, such a structure is defined by a verbal description that\ncorresponds to the more or less uniform, often somewhat vague mental images of\nthe experts.\nHowever, a precise, formal definition of the structures or, more generally,\nconcepts is often desirable, e.g., to enable automated data analysis or the\ndevelopment of phenomenological models. Here, we present a systematic approach\nand an interactive tool to obtain formal definitions of spatiotemporal\nstructures. The tool enables experts to evaluate and compare different\nstructure definitions on the basis of data sets with time-dependent fields that\ncontain the respective structure. Since structure definitions are typically\nparameterized, an essential part is to identify parameter ranges that lead to\ndesired structures in all time steps. In addition, it is important to allow a\nquantitative assessment of the resulting structures simultaneously. We\ndemonstrate the use of the tool by applying it to two meteorological examples:\nfinding structure definitions for vortex cores and center lines of temporarily\nevolving tropical cyclones.\nIdeally, structure definitions should be objective and applicable to as many\ndata sets as possible. However, finding such definitions, e.g., for the common\natmospheric structures in meteorology, can only be a long-term goal. The\nproposed procedure, together with the presented tool, is just a first approach\nto facilitate this long and arduous way.",
    "descriptor": "\nComments: 29 pages, 12 figures\n",
    "authors": [
      "Natalia Mikula",
      "Tom D\u00f6rffel",
      "Daniel Baum",
      "Hans-Christian Hege"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.09066"
  },
  {
    "id": "arXiv:2112.09067",
    "title": "Open-Source Software Radio Platform for Research on Cellular Networked  UAVs -- It Works!",
    "abstract": "Cellular network-connected unmanned aerial vehicles (UAVs) experience\ndifferent radio propagation conditions than radio nodes on the ground.\nTherefore, it has become critical to investigate the performance of aerial\nradios, both theoretically and through field trials. In this paper, we consider\nlow-altitude aerial nodes that are served by an experimental cellular network.\nWe provide a detailed description of the hardware and software components\nneeded for establishing a broadband wireless testbed for UAV communications\nresearch using software radios. Results show that a testbed for innovation in\nUAV communications and networking is feasible with commercial off-the-shelf\nhardware, open-source software, and low-power signaling.",
    "descriptor": "\nComments: This article has been accepted for publication in the IEEE Communications Magazine\n",
    "authors": [
      "Aly Sabri Abdalla",
      "Andrew Yingst",
      "Keith Powell",
      "Antoni Gelonch-Bosch",
      "Vuk Marojevic"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Hardware Architecture (cs.AR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.09067"
  },
  {
    "id": "arXiv:2112.09068",
    "title": "Estimation of Physical Activity Level and Ambient Condition Thresholds  for Respiratory Health using Smartphone Sensors",
    "abstract": "While physical activity has been described as a primary prevention against\nchronic diseases, strenuous physical exertion under adverse ambient conditions\nhas also been reported as a major contributor to exacerbation of chronic\nrespiratory conditions. Maintaining a balance by monitoring the type and the\nlevel of physical activities of affected individuals, could help in reducing\nthe cost and burden of managing respiratory ailments. This paper explores the\npotentiality of motion sensors in Smartphones to estimate physical activity\nthresholds that could trigger symptoms of exercise induced respiratory\nconditions (EiRCs). The focus is on the extraction of measurements from the\nembedded motion sensors to determine the activity level and the type of\nactivity that is tolerable to individuals respiratory health. The calculations\nare based on the correlation between Signal Magnitude Area (SMA) and Energy\nExpenditure (EE). We also consider the effect of changes in the ambient\nconditions like temperature and humidity, as contributing factors to\nrespiratory distress during physical exercise. Real time data collected from\nhealthy individuals were used to demonstrate the potentiality of a mobile phone\nas tool to regulate the level of physical activities of individuals with EiRCs.\nWe describe a practical situation where the experimental outcomes can be\napplied to promote good respiratory health.",
    "descriptor": "",
    "authors": [
      "Chinazunwa Uwaoma"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09068"
  },
  {
    "id": "arXiv:2112.09071",
    "title": "A Deep Learning Based Multitask Network for Respiration Rate Estimation  -- A Practical Perspective",
    "abstract": "The exponential rise in wearable sensors has garnered significant interest in\nassessing the physiological parameters during day-to-day activities.\nRespiration rate is one of the vital parameters used in the performance\nassessment of lifestyle activities. However, obtrusive setup for measurement,\nmotion artifacts, and other noises complicate the process. This paper presents\na multitasking architecture based on Deep Learning (DL) for estimating\ninstantaneous and average respiration rate from ECG and accelerometer signals,\nsuch that it performs efficiently under daily living activities like cycling,\nwalking, etc. The multitasking network consists of a combination of\nEncoder-Decoder and Encoder-IncResNet, to fetch the average respiration rate\nand the respiration signal. The respiration signal can be leveraged to obtain\nthe breathing peaks and instantaneous breathing cycles. Mean absolute\nerror(MAE), Root mean square error (RMSE), inference time, and parameter count\nanalysis has been used to compare the network with the current state of art\nMachine Learning (ML) model and other DL models developed in previous studies.\nOther DL configurations based on a variety of inputs are also developed as a\npart of the work. The proposed model showed better overall accuracy and gave\nbetter results than individual modalities during different activities.",
    "descriptor": "\nComments: A DL based multitasking model to estimate respiratory rate is proposed. Paper is accepted in IEEE HI-POCT 2022\n",
    "authors": [
      "Kapil Singh Rathore",
      "Sricharan Vijayarangan",
      "Preejith SP",
      "Mohanasankar Sivaprakasam"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09071"
  },
  {
    "id": "arXiv:2112.09072",
    "title": "Sensor Sampling Trade-Offs for Air Quality Monitoring With Low-Cost  Sensors",
    "abstract": "The calibration of low-cost sensors using machine learning techniques is a\nmethodology widely used nowadays. Although many challenges remain to be solved\nin the deployment of low-cost sensors for air quality monitoring, low-cost\nsensors have been shown to be useful in conjunction with high-precision\ninstrumentation. Thus, most research is focused on the application of different\ncalibration techniques using machine learning. Nevertheless, the successful\napplication of these models depends on the quality of the data obtained by the\nsensors, and very little attention has been paid to the whole data gathering\nprocess, from sensor sampling and data pre-processing, to the calibration of\nthe sensor itself. In this article, we show the main sensor sampling\nparameters, with their corresponding impact on the quality of the resulting\nmachine learning-based sensor calibration and their impact on energy\nconsumption, thus showing the existing trade-offs. Finally, the results on an\nexperimental node show the impact of the data sampling strategy in the\ncalibration of tropospheric ozone, nitrogen dioxide and nitrogen monoxide\nlow-cost sensors. Specifically, we show how a sampling strategy that minimizes\nthe duty cycle of the sensing subsystem can reduce power consumption while\nmaintaining data quality.",
    "descriptor": "\nComments: Submitted to journal, 12 pages, 22 figures\n",
    "authors": [
      "Pau Ferrer-Cid",
      "Julio Garcia-Calvete",
      "Aina Main-Nadal",
      "Zhe Ye",
      "Jose M. Barcelo-Ordinas",
      "Jorge Garcia-Vidal"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.09072"
  },
  {
    "id": "arXiv:2112.09086",
    "title": "A new locally linear embedding scheme in light of Hessian eigenmap",
    "abstract": "We provide a new interpretation of Hessian locally linear embedding (HLLE),\nrevealing that it is essentially a variant way to implement the same idea of\nlocally linear embedding (LLE). Based on the new interpretation, a substantial\nsimplification can be made, in which the idea of \"Hessian\" is replaced by\nrather arbitrary weights. Moreover, we show by numerical examples that HLLE may\nproduce projection-like results when the dimension of the target space is\nlarger than that of the data manifold, and hence one further modification\nconcerning the manifold dimension is suggested. Combining all the observations,\nwe finally achieve a new LLE-type method, which is called tangential LLE\n(TLLE). It is simpler and more robust than HLLE.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Liren Lin",
      "Chih-Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.09086"
  },
  {
    "id": "arXiv:2112.09117",
    "title": "Machine Learning Kreuzer--Skarke Calabi--Yau Threefolds",
    "abstract": "Using a fully connected feedforward neural network we study topological\ninvariants of a class of Calabi--Yau manifolds constructed as hypersurfaces in\ntoric varieties associated with reflexive polytopes from the Kreuzer--Skarke\ndatabase. In particular, we find the existence of a simple expression for the\nEuler number that can be learned in terms of limited data extracted from the\npolytope and its dual.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Per Berglund",
      "Ben Campbell",
      "Vishnu Jejjala"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (cs.LG)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2112.09117"
  },
  {
    "id": "arXiv:1406.3399",
    "title": "Foundations of an Alternative Approach to Reification in RDF",
    "abstract": "Comments: This document has become **obsolete** and is replaced by the RDF-DEV community group report on RDF-star and SPARQL-star. For more details, see the comment added in the beginning of the document, and the report can be found at this https URL",
    "descriptor": "\nComments: This document has become **obsolete** and is replaced by the RDF-DEV community group report on RDF-star and SPARQL-star. For more details, see the comment added in the beginning of the document, and the report can be found at this https URL\n",
    "authors": [
      "Olaf Hartig",
      "Bryan Thompson"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/1406.3399"
  },
  {
    "id": "arXiv:1805.00918",
    "title": "Some Estimates of Virtual Element Methods for Fourth Order Problems",
    "abstract": "Some Estimates of Virtual Element Methods for Fourth Order Problems",
    "descriptor": "",
    "authors": [
      "Qingguang Guan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1805.00918"
  },
  {
    "id": "arXiv:1806.05971",
    "title": "An Enhanced Binary Particle-Swarm Optimization (E-BPSO) Algorithm for  Service Placement in Hybrid Cloud Platforms",
    "abstract": "An Enhanced Binary Particle-Swarm Optimization (E-BPSO) Algorithm for  Service Placement in Hybrid Cloud Platforms",
    "descriptor": "",
    "authors": [
      "Wissem Abbes",
      "Zied Kechaou",
      "Amir Hussain",
      "Abdulrahman M. Qahtani",
      "Omar Aimutiry",
      "Habib Dhahri",
      "Adel M. Alimi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1806.05971"
  },
  {
    "id": "arXiv:1812.08958",
    "title": "Expander Decomposition and Pruning: Faster, Stronger, and Simpler",
    "abstract": "Comments: Added more details and fixed typos in Appendix B about the cut-matching game",
    "descriptor": "\nComments: Added more details and fixed typos in Appendix B about the cut-matching game\n",
    "authors": [
      "Thatchaphol Saranurak",
      "Di Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1812.08958"
  },
  {
    "id": "arXiv:1904.11128",
    "title": "CBHE: Corner-based Building Height Estimation for Complex Street Scene  Images",
    "abstract": "CBHE: Corner-based Building Height Estimation for Complex Street Scene  Images",
    "descriptor": "",
    "authors": [
      "Yunxiang Zhao",
      "Jianzhong Qi",
      "Rui Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1904.11128"
  },
  {
    "id": "arXiv:1906.06659",
    "title": "A Generalized Minimax Q-learning Algorithm for Two-Player Zero-Sum  Stochastic Games",
    "abstract": "A Generalized Minimax Q-learning Algorithm for Two-Player Zero-Sum  Stochastic Games",
    "descriptor": "",
    "authors": [
      "Raghuram Bharadwaj Diddigi",
      "Chandramouli Kamanchi",
      "Shalabh Bhatnagar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.06659"
  },
  {
    "id": "arXiv:1906.07633",
    "title": "From Clustering to Cluster Explanations via Neural Networks",
    "abstract": "Comments: 15 pages + supplement",
    "descriptor": "\nComments: 15 pages + supplement\n",
    "authors": [
      "Jacob Kauffmann",
      "Malte Esders",
      "Lukas Ruff",
      "Gr\u00e9goire Montavon",
      "Wojciech Samek",
      "Klaus-Robert M\u00fcller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.07633"
  },
  {
    "id": "arXiv:1907.07585",
    "title": "Deep Metric Learning with Alternating Projections onto Feasible Sets",
    "abstract": "Comments: 10 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 10 pages, 3 figures, 2 tables\n",
    "authors": [
      "O\u011ful Can",
      "Yeti Ziya G\u00fcrb\u00fcz",
      "A. Ayd\u0131n Alatan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/1907.07585"
  },
  {
    "id": "arXiv:2001.02856",
    "title": "D-GCCA: Decomposition-based Generalized Canonical Correlation Analysis  for Multi-view High-dimensional Data",
    "abstract": "D-GCCA: Decomposition-based Generalized Canonical Correlation Analysis  for Multi-view High-dimensional Data",
    "descriptor": "",
    "authors": [
      "Hai Shu",
      "Zhe Qu",
      "Hongtu Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2001.02856"
  },
  {
    "id": "arXiv:2001.11797",
    "title": "A comparison of Vector Symbolic Architectures",
    "abstract": "Comments: 32 pages, 11 figures, preprint - accepted journal version",
    "descriptor": "\nComments: 32 pages, 11 figures, preprint - accepted journal version\n",
    "authors": [
      "Kenny Schlegel",
      "Peer Neubert",
      "Peter Protzel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2001.11797"
  },
  {
    "id": "arXiv:2003.09660",
    "title": "NeuCrowd: Neural Sampling Network for Representation Learning with  Crowdsourced Labels",
    "abstract": "Comments: Accepted in Knowledge and Information Systems",
    "descriptor": "\nComments: Accepted in Knowledge and Information Systems\n",
    "authors": [
      "Yang Hao",
      "Wenbiao Ding",
      "Zitao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.09660"
  },
  {
    "id": "arXiv:2004.14120",
    "title": "Learning Non-Monotonic Automatic Post-Editing of Translations from Human  Orderings",
    "abstract": "Comments: Accepted at EAMT 2020; dataset available here: this https URL",
    "descriptor": "\nComments: Accepted at EAMT 2020; dataset available here: this https URL\n",
    "authors": [
      "Ant\u00f3nio G\u00f3is",
      "Kyunghyun Cho",
      "Andr\u00e9 Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2004.14120"
  },
  {
    "id": "arXiv:2005.07564",
    "title": "Progressive Automatic Design of Search Space for One-Shot Neural  Architecture Search",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Xin Xia",
      "Xuefeng Xiao",
      "Xing Wang",
      "Min Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.07564"
  },
  {
    "id": "arXiv:2006.11165",
    "title": "Backdoor Attacks to Graph Neural Networks",
    "abstract": "Comments: In ACM SACMAT, 2022",
    "descriptor": "\nComments: In ACM SACMAT, 2022\n",
    "authors": [
      "Zaixi Zhang",
      "Jinyuan Jia",
      "Binghui Wang",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.11165"
  },
  {
    "id": "arXiv:2006.11695",
    "title": "Uncertainty-Aware (UNA) Bases for Deep Bayesian Regression Using  Multi-Headed Auxiliary Networks",
    "abstract": "Comments: Accepted at ICML 2020 Workshop on Uncertainty and Robustness in Deep Learning",
    "descriptor": "\nComments: Accepted at ICML 2020 Workshop on Uncertainty and Robustness in Deep Learning\n",
    "authors": [
      "Sujay Thakur",
      "Cooper Lorsung",
      "Yaniv Yacoby",
      "Finale Doshi-Velez",
      "Weiwei Pan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.11695"
  },
  {
    "id": "arXiv:2006.14058",
    "title": "Anycast Agility: Network Playbooks to Fight DDoS",
    "abstract": "Comments: 22 pages, 22 figures",
    "descriptor": "\nComments: 22 pages, 22 figures\n",
    "authors": [
      "A S M Rizvi",
      "Leandro Bertholdo",
      "Joao Ceron",
      "John Heidemann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2006.14058"
  },
  {
    "id": "arXiv:2006.15857",
    "title": "Constructing a Chain Event Graph from a Staged Tree",
    "abstract": "Constructing a Chain Event Graph from a Staged Tree",
    "descriptor": "",
    "authors": [
      "Aditi Shenvi",
      "Jim Q. Smith"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.15857"
  },
  {
    "id": "arXiv:2007.02466",
    "title": "Hybrid RF/VLC Systems: A Comprehensive Survey on Network Topologies,  Performance Analyses, Applications, and Future Directions",
    "abstract": "Comments: 27 pages survey paper",
    "descriptor": "\nComments: 27 pages survey paper\n",
    "authors": [
      "Hisham Abuella",
      "Mohammed Elamassie",
      "Murat Uysal",
      "Zhengyuan Xu",
      "Erchin Serpedin",
      "Khalid A. Qaraqe",
      "Sabit Ekin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2007.02466"
  },
  {
    "id": "arXiv:2007.03576",
    "title": "Algorithm 1019: A Task-based Multi-shift QR/QZ Algorithm with Aggressive  Early Deflation",
    "abstract": "Comments: 36 pages, 20 figures, 9 tables. Peer-reviewed version",
    "descriptor": "\nComments: 36 pages, 20 figures, 9 tables. Peer-reviewed version\n",
    "authors": [
      "Mirko Myllykoski"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2007.03576"
  },
  {
    "id": "arXiv:2007.04171",
    "title": "Domain Adaptation with Auxiliary Target Domain-Oriented Classifier",
    "abstract": "Comments: Fix typos after CVPR 2021. Code is available at this https URL",
    "descriptor": "\nComments: Fix typos after CVPR 2021. Code is available at this https URL\n",
    "authors": [
      "Jian Liang",
      "Dapeng Hu",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.04171"
  },
  {
    "id": "arXiv:2007.04410",
    "title": "A Bayesian decision support system for counteracting activities of  terrorist groups",
    "abstract": "A Bayesian decision support system for counteracting activities of  terrorist groups",
    "descriptor": "",
    "authors": [
      "Aditi Shenvi",
      "F. Oliver Bunnin",
      "Jim Q. Smith"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.04410"
  },
  {
    "id": "arXiv:2007.09948",
    "title": "Towards Joint Learning of Optimal MAC Signaling and Wireless Channel  Access",
    "abstract": "Comments: Submitted for journal publication",
    "descriptor": "\nComments: Submitted for journal publication\n",
    "authors": [
      "Alvaro Valcarce",
      "Jakob Hoydis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2007.09948"
  },
  {
    "id": "arXiv:2008.07644",
    "title": "Pictorial and apictorial polygonal jigsaw puzzles: The lazy caterer  model, properties, and solvers",
    "abstract": "Pictorial and apictorial polygonal jigsaw puzzles: The lazy caterer  model, properties, and solvers",
    "descriptor": "",
    "authors": [
      "Peleg Harel",
      "Ohad Ben-Shahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2008.07644"
  },
  {
    "id": "arXiv:2009.04930",
    "title": "Orientation Keypoints for 6D Human Pose Estimation",
    "abstract": "Comments: To appear in IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). Video: this https URL",
    "descriptor": "\nComments: To appear in IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). Video: this https URL\n",
    "authors": [
      "Martin Fisch",
      "Ronald Clark"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.04930"
  },
  {
    "id": "arXiv:2009.12326",
    "title": "Online Missing Value Imputation and Change Point Detection with the  Gaussian Copula",
    "abstract": "Comments: Accepted by AAAI 2022",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Yuxuan Zhao",
      "Eric Landgrebe",
      "Eliot Shekhtman",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.12326"
  },
  {
    "id": "arXiv:2010.01187",
    "title": "On the Nielsen-Schreier Theorem in Homotopy Type Theory",
    "abstract": "Comments: Minor formatting changes for journal",
    "descriptor": "\nComments: Minor formatting changes for journal\n",
    "authors": [
      "Andrew W Swan"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2010.01187"
  },
  {
    "id": "arXiv:2010.05949",
    "title": "Towards human-level performance on automatic pose estimation of infant  spontaneous movements",
    "abstract": "Comments: Published in Computerized Medical Imaging and Graphics (CMIG)",
    "descriptor": "\nComments: Published in Computerized Medical Imaging and Graphics (CMIG)\n",
    "authors": [
      "Daniel Groos",
      "Lars Adde",
      "Ragnhild St\u00f8en",
      "Heri Ramampiaro",
      "Espen A. F. Ihlen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.05949"
  },
  {
    "id": "arXiv:2010.05953",
    "title": "COMET-ATOMIC 2020: On Symbolic and Neural Commonsense Knowledge Graphs",
    "abstract": "COMET-ATOMIC 2020: On Symbolic and Neural Commonsense Knowledge Graphs",
    "descriptor": "",
    "authors": [
      "Jena D. Hwang",
      "Chandra Bhagavatula",
      "Ronan Le Bras",
      "Jeff Da",
      "Keisuke Sakaguchi",
      "Antoine Bosselut",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.05953"
  },
  {
    "id": "arXiv:2010.12723",
    "title": "Constrained Abstractive Summarization: Preserving Factual Consistency  with Constrained Generation",
    "abstract": "Constrained Abstractive Summarization: Preserving Factual Consistency  with Constrained Generation",
    "descriptor": "",
    "authors": [
      "Yuning Mao",
      "Xiang Ren",
      "Heng Ji",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.12723"
  },
  {
    "id": "arXiv:2011.09865",
    "title": "An experiment on the mechanisms of racial bias in ML-based credit  scoring in Brazil",
    "abstract": "An experiment on the mechanisms of racial bias in ML-based credit  scoring in Brazil",
    "descriptor": "",
    "authors": [
      "Ramon Vilarino",
      "Renato Vicente"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.09865"
  },
  {
    "id": "arXiv:2011.13752",
    "title": "Adaptive Non-linear Pattern Matching Automata",
    "abstract": "Adaptive Non-linear Pattern Matching Automata",
    "descriptor": "",
    "authors": [
      "Rick Erkens",
      "Maurice Laveaux"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2011.13752"
  },
  {
    "id": "arXiv:2012.05395",
    "title": "Infusing Finetuning with Semantic Dependencies",
    "abstract": "Comments: TACL 2021",
    "descriptor": "\nComments: TACL 2021\n",
    "authors": [
      "Zhaofeng Wu",
      "Hao Peng",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.05395"
  },
  {
    "id": "arXiv:2012.06244",
    "title": "The Implicit Bias for Adaptive Optimization Algorithms on Homogeneous  Neural Networks",
    "abstract": "Comments: ICML 2021 Long Talk",
    "descriptor": "\nComments: ICML 2021 Long Talk\n",
    "authors": [
      "Bohan Wang",
      "Qi Meng",
      "Wei Chen",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.06244"
  },
  {
    "id": "arXiv:2012.06922",
    "title": "Decimated Framelet System on Graphs and Fast G-Framelet Transforms",
    "abstract": "Comments: 69 pages, 10 figures, Published in JMLR",
    "descriptor": "\nComments: 69 pages, 10 figures, Published in JMLR\n",
    "authors": [
      "Xuebin Zheng",
      "Bingxin Zhou",
      "Yu Guang Wang",
      "Xiaosheng Zhuang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.06922"
  },
  {
    "id": "arXiv:2012.10142",
    "title": "Learning and balancing unknown loads in large-scale systems",
    "abstract": "Comments: 50 pages, 3 figures",
    "descriptor": "\nComments: 50 pages, 3 figures\n",
    "authors": [
      "Diego Goldsztajn",
      "Sem C. Borst",
      "Johan S.H. van Leeuwaarden"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Performance (cs.PF)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.10142"
  },
  {
    "id": "arXiv:2101.01801",
    "title": "Divergence/connection preservation scheme in the curvilinear domain with  a small geometric approximation error",
    "abstract": "Comments: 20 pages, 11 figures",
    "descriptor": "\nComments: 20 pages, 11 figures\n",
    "authors": [
      "Sehun Chun",
      "Taejin Oh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.01801"
  },
  {
    "id": "arXiv:2101.02180",
    "title": "Maximum a Posteriori Inference of Random Dot Product Graphs via Conic  Programming",
    "abstract": "Comments: submitted for publication in SIAM Journal on Optimization (SIOPT)",
    "descriptor": "\nComments: submitted for publication in SIAM Journal on Optimization (SIOPT)\n",
    "authors": [
      "David Wu",
      "David R. Palmer",
      "Daryl R. Deford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.02180"
  },
  {
    "id": "arXiv:2101.03164",
    "title": "E(3)-Equivariant Graph Neural Networks for Data-Efficient and Accurate  Interatomic Potentials",
    "abstract": "E(3)-Equivariant Graph Neural Networks for Data-Efficient and Accurate  Interatomic Potentials",
    "descriptor": "",
    "authors": [
      "Simon Batzner",
      "Albert Musaelian",
      "Lixin Sun",
      "Mario Geiger",
      "Jonathan P. Mailoa",
      "Mordechai Kornbluth",
      "Nicola Molinari",
      "Tess E. Smidt",
      "Boris Kozinsky"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.03164"
  },
  {
    "id": "arXiv:2101.03521",
    "title": "A Spatial-Temporal asymptotic preserving scheme for radiation  magnetohydrodynamics in the equilibrium and non-equilibrium diffusion limit",
    "abstract": "Comments: 29 pages, 40 figures",
    "descriptor": "\nComments: 29 pages, 40 figures\n",
    "authors": [
      "Shi Jin",
      "Min Tang",
      "Xiaojiang Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.03521"
  },
  {
    "id": "arXiv:2101.06919",
    "title": "Link Prediction and Unlink Prediction on Dynamic Networks",
    "abstract": "Link Prediction and Unlink Prediction on Dynamic Networks",
    "descriptor": "",
    "authors": [
      "Christina Muro",
      "Boyu Li",
      "Kun He"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2101.06919"
  },
  {
    "id": "arXiv:2101.10777",
    "title": "Dense Semantic Forecasting in Video by Joint Regression of Features and  Feature Motion",
    "abstract": "Comments: 13 pages, 10 figures",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Josip \u0160ari\u0107",
      "Sacha Vra\u017ei\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.10777"
  },
  {
    "id": "arXiv:2102.01223",
    "title": "Inducing Meaningful Units from Character Sequences with Slot Attention",
    "abstract": "Inducing Meaningful Units from Character Sequences with Slot Attention",
    "descriptor": "",
    "authors": [
      "Melika Behjati",
      "James Henderson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.01223"
  },
  {
    "id": "arXiv:2102.04966",
    "title": "Orbital Stabilization of Point-to-Point Maneuvers in Underactuated  Mechanical Systems",
    "abstract": "Comments: 21 pages, 8 figures, 1 table. Substantial changes made to sections 2, 3 and 5. Results unchanged",
    "descriptor": "\nComments: 21 pages, 8 figures, 1 table. Substantial changes made to sections 2, 3 and 5. Results unchanged\n",
    "authors": [
      "Christian Fredrik S\u00e6tre",
      "Anton Shiriaev"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.04966"
  },
  {
    "id": "arXiv:2102.05143",
    "title": "Classifier Calibration: with implications to threat scores in  cybersecurity",
    "abstract": "Classifier Calibration: with implications to threat scores in  cybersecurity",
    "descriptor": "",
    "authors": [
      "Waleed A. Yousef",
      "Issa Traore",
      "William Briguglio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.05143"
  },
  {
    "id": "arXiv:2102.11485",
    "title": "Generalized Equivariance and Preferential Labeling for GNN Node  Classification",
    "abstract": "Generalized Equivariance and Preferential Labeling for GNN Node  Classification",
    "descriptor": "",
    "authors": [
      "Zeyu Sun",
      "Wenjie Zhang",
      "Lili Mou",
      "Qihao Zhu",
      "Yingfei Xiong",
      "Lu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.11485"
  },
  {
    "id": "arXiv:2102.11724",
    "title": "Causal Mediation Analysis with Hidden Confounders",
    "abstract": "Comments: 10 pages, 4 figures",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Lu Cheng",
      "Ruocheng Guo",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.11724"
  },
  {
    "id": "arXiv:2102.12351",
    "title": "Approximability of all finite CSPs with linear sketches",
    "abstract": "Approximability of all finite CSPs with linear sketches",
    "descriptor": "",
    "authors": [
      "Chi-Ning Chou",
      "Alexander Golovnev",
      "Madhu Sudan",
      "Santhoshini Velusamy"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.12351"
  },
  {
    "id": "arXiv:2103.00794",
    "title": "Early-Bird GCNs: Graph-Network Co-Optimization Towards More Efficient  GCN Training and Inference via Drawing Early-Bird Lottery Tickets",
    "abstract": "Comments: Accepted by AAAI 2022",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Haoran You",
      "Zhihan Lu",
      "Zijian Zhou",
      "Yonggan Fu",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2103.00794"
  },
  {
    "id": "arXiv:2103.01007",
    "title": "Error Estimates for the Variational Training of Neural Networks with  Boundary Penalty",
    "abstract": "Comments: 16 pages, no figures",
    "descriptor": "\nComments: 16 pages, no figures\n",
    "authors": [
      "Johannes M\u00fcller",
      "Marius Zeinhofer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01007"
  },
  {
    "id": "arXiv:2103.04839",
    "title": "Efficient numerical approximation of a non-regular Fokker--Planck  equation associated with first-passage time distributions",
    "abstract": "Efficient numerical approximation of a non-regular Fokker--Planck  equation associated with first-passage time distributions",
    "descriptor": "",
    "authors": [
      "Udo Boehm",
      "Sonja Cox",
      "Gregor Gantner",
      "Rob Stevenson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.04839"
  },
  {
    "id": "arXiv:2103.07413",
    "title": "Understanding and mitigating noise in trained deep neural networks",
    "abstract": "Understanding and mitigating noise in trained deep neural networks",
    "descriptor": "",
    "authors": [
      "Nadezhda Semenova",
      "Laurent Larger",
      "Daniel Brunner"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2103.07413"
  },
  {
    "id": "arXiv:2103.08459",
    "title": "Specification Decomposition for Reactive Synthesis",
    "abstract": "Comments: This represents the journal version. For the full version with appendix of the NFM 2021 paper, see arXiv:2103.08459v2",
    "descriptor": "\nComments: This represents the journal version. For the full version with appendix of the NFM 2021 paper, see arXiv:2103.08459v2\n",
    "authors": [
      "Bernd Finkbeiner",
      "Gideon Geier",
      "Noemi Passing"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2103.08459"
  },
  {
    "id": "arXiv:2103.09450",
    "title": "Mechanical principles of dynamic terrestrial self-righting using wings",
    "abstract": "Mechanical principles of dynamic terrestrial self-righting using wings",
    "descriptor": "",
    "authors": [
      "Chen Li",
      "Chad C. Kessens",
      "Ronald S. Fearing",
      "Robert J. Full"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2103.09450"
  },
  {
    "id": "arXiv:2103.10918",
    "title": "Play the Shannon Game With Language Models: A Human-Free Approach to  Summary Evaluation",
    "abstract": "Comments: To appear at AAAI 2022",
    "descriptor": "\nComments: To appear at AAAI 2022\n",
    "authors": [
      "Nicholas Egan",
      "Oleg Vasilyev",
      "John Bohannon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10918"
  },
  {
    "id": "arXiv:2103.11399",
    "title": "Learning Calibrated-Guidance for Object Detection in Aerial Images",
    "abstract": "Learning Calibrated-Guidance for Object Detection in Aerial Images",
    "descriptor": "",
    "authors": [
      "Zongqi Wei",
      "Dong Liang",
      "Dong Zhang",
      "Liyan Zhang",
      "Qixiang Geng",
      "Mingqiang Wei",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11399"
  },
  {
    "id": "arXiv:2103.12701",
    "title": "A*+BFHS: A Hybrid Heuristic Search Algorithm",
    "abstract": "Comments: 8 pages, 5 figures, 1 table",
    "descriptor": "\nComments: 8 pages, 5 figures, 1 table\n",
    "authors": [
      "Zhaoxing Bu",
      "Richard E. Korf"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.12701"
  },
  {
    "id": "arXiv:2103.14347",
    "title": "Combating Adversaries with Anti-Adversaries",
    "abstract": "Comments: Accepted to AAAI Conference on Artificial Intelligence (AAAI'22)",
    "descriptor": "\nComments: Accepted to AAAI Conference on Artificial Intelligence (AAAI'22)\n",
    "authors": [
      "Motasem Alfarra",
      "Juan C. P\u00e9rez",
      "Ali Thabet",
      "Adel Bibi",
      "Philip H. S. Torr",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14347"
  },
  {
    "id": "arXiv:2103.14466",
    "title": "Prioritise the Best Variation",
    "abstract": "Prioritise the Best Variation",
    "descriptor": "",
    "authors": [
      "Wen Kokke",
      "Ornela Dardha"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2103.14466"
  },
  {
    "id": "arXiv:2103.16025",
    "title": "On the Predictability of Utilizing Rank Percentile to Evaluate  Scientific Impact",
    "abstract": "Comments: The dataset and the code to reproduce the results in this paper are available online at this https URL",
    "descriptor": "\nComments: The dataset and the code to reproduce the results in this paper are available online at this https URL\n",
    "authors": [
      "Sen Tian",
      "Panos Ipeirotis"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2103.16025"
  },
  {
    "id": "arXiv:2104.09844",
    "title": "Fluid-beam interaction: Capturing the effect of embedded slender bodies  on global fluid flow and vice versa",
    "abstract": "Fluid-beam interaction: Capturing the effect of embedded slender bodies  on global fluid flow and vice versa",
    "descriptor": "",
    "authors": [
      "Nora Hagmeyer",
      "Matthias Mayr",
      "Ivo Steinbrecher",
      "Alexander Popp"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2104.09844"
  },
  {
    "id": "arXiv:2104.11927",
    "title": "Anomaly Detection for Solder Joints Using $\u03b2$-VAE",
    "abstract": "Comments: Published in IEEE Transactions on Components, Packaging and Manufacturing Technology",
    "descriptor": "\nComments: Published in IEEE Transactions on Components, Packaging and Manufacturing Technology\n",
    "authors": [
      "Furkan Ulger",
      "Seniha Esen Yuksel",
      "Atila Yilmaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.11927"
  },
  {
    "id": "arXiv:2104.12910",
    "title": "A RoboStack Tutorial: Using the Robot Operating System Alongside the  Conda and Jupyter Data Science Ecosystems",
    "abstract": "Comments: IEEE Robotics & Automation Magazine",
    "descriptor": "\nComments: IEEE Robotics & Automation Magazine\n",
    "authors": [
      "Tobias Fischer",
      "Wolf Vollprecht",
      "Silvio Traversaro",
      "Sean Yen",
      "Carlos Herrero",
      "Michael Milford"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.12910"
  },
  {
    "id": "arXiv:2104.13905",
    "title": "CRC-Aided List Decoding of Convolutional Codes in the Short Blocklength  Regime",
    "abstract": "Comments: First revision submitted to IEEE Transactions on Information Theory",
    "descriptor": "\nComments: First revision submitted to IEEE Transactions on Information Theory\n",
    "authors": [
      "Hengjie Yang",
      "Ethan Liang",
      "Minghao Pan",
      "Richard Wesel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.13905"
  },
  {
    "id": "arXiv:2104.15021",
    "title": "Formalizing the Face Lattice of Polyhedra",
    "abstract": "Comments: 23 pages, 4 figures, minor revision",
    "descriptor": "\nComments: 23 pages, 4 figures, minor revision\n",
    "authors": [
      "Xavier Allamigeon",
      "Ricardo D. Katz",
      "Pierre-Yves Strub"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.15021"
  },
  {
    "id": "arXiv:2105.04599",
    "title": "Budget-limited distribution learning in multifidelity problems",
    "abstract": "Comments: 27 pages, added more some proofs",
    "descriptor": "\nComments: 27 pages, added more some proofs\n",
    "authors": [
      "Yiming Xu",
      "Akil Narayan"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.04599"
  },
  {
    "id": "arXiv:2105.05398",
    "title": "Sound, Precise, and Fast Abstract Interpretation with Tristate Numbers",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Harishankar Vishwanathan",
      "Matan Shachnai",
      "Srinivas Narayana",
      "Santosh Nagarakatte"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.05398"
  },
  {
    "id": "arXiv:2105.06738",
    "title": "Automated segmentation of microtomography imaging of Egyptian mummies",
    "abstract": "Automated segmentation of microtomography imaging of Egyptian mummies",
    "descriptor": "",
    "authors": [
      "Marc Tanti",
      "Camille Berruyer",
      "Paul Tafforeau",
      "Adrian Muscat",
      "Reuben Farrugia",
      "Kenneth Scerri",
      "Gianluca Valentino",
      "V. Armando Sol\u00e9",
      "Johann A. Briffa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.06738"
  },
  {
    "id": "arXiv:2105.08339",
    "title": "DRIVE: One-bit Distributed Mean Estimation",
    "abstract": "Comments: Appears in NeurIPS 2021",
    "descriptor": "\nComments: Appears in NeurIPS 2021\n",
    "authors": [
      "Shay Vargaftik",
      "Ran Ben Basat",
      "Amit Portnoy",
      "Gal Mendelson",
      "Yaniv Ben-Itzhak",
      "Michael Mitzenmacher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.08339"
  },
  {
    "id": "arXiv:2105.11777",
    "title": "Guaranteed a posteriori local error estimation for finite element  solutions of boundary value problems",
    "abstract": "Guaranteed a posteriori local error estimation for finite element  solutions of boundary value problems",
    "descriptor": "",
    "authors": [
      "Taiga Nakano",
      "Xuefeng Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.11777"
  },
  {
    "id": "arXiv:2105.11839",
    "title": "DiBS: Differentiable Bayesian Structure Learning",
    "abstract": "Comments: NeurIPS 2021; updated run time results",
    "descriptor": "\nComments: NeurIPS 2021; updated run time results\n",
    "authors": [
      "Lars Lorch",
      "Jonas Rothfuss",
      "Bernhard Sch\u00f6lkopf",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.11839"
  },
  {
    "id": "arXiv:2105.13336",
    "title": "TENSILE: A Tensor granularity dynamic GPU memory scheduling method  towards multiple dynamic workloads system",
    "abstract": "TENSILE: A Tensor granularity dynamic GPU memory scheduling method  towards multiple dynamic workloads system",
    "descriptor": "",
    "authors": [
      "Kaixin Zhang",
      "Hongzhi Wang",
      "Tongxin Li",
      "Han Hu",
      "Songling Zou",
      "Jiye Qiu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.13336"
  },
  {
    "id": "arXiv:2106.00592",
    "title": "Semi-Supervised Domain Generalization with Stochastic StyleMatch",
    "abstract": "Comments: Tech report. Code available at this https URL",
    "descriptor": "\nComments: Tech report. Code available at this https URL\n",
    "authors": [
      "Kaiyang Zhou",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00592"
  },
  {
    "id": "arXiv:2106.01263",
    "title": "Selecting the optimal dialogue response once for all from a panoramic  view",
    "abstract": "Selecting the optimal dialogue response once for all from a panoramic  view",
    "descriptor": "",
    "authors": [
      "Chiyu Song",
      "Hongliang He",
      "Haofei Yu",
      "Huachuan Qiu",
      "Zhenzhong Lan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01263"
  },
  {
    "id": "arXiv:2106.01808",
    "title": "MINIMALIST: Mutual INformatIon Maximization for Amortized Likelihood  Inference from Sampled Trajectories",
    "abstract": "MINIMALIST: Mutual INformatIon Maximization for Amortized Likelihood  Inference from Sampled Trajectories",
    "descriptor": "",
    "authors": [
      "Giulio Isacchini",
      "Natanael Spisak",
      "Armita Nourmohammad",
      "Thierry Mora",
      "Aleksandra M. Walczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01808"
  },
  {
    "id": "arXiv:2106.03035",
    "title": "Online Trading Models with Deep Reinforcement Learning in the Forex  Market Considering Transaction Costs",
    "abstract": "Comments: 7 pages, 2 figures, 6 tables",
    "descriptor": "\nComments: 7 pages, 2 figures, 6 tables\n",
    "authors": [
      "Koya Ishikawa",
      "Kazuhide Nakata"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03035"
  },
  {
    "id": "arXiv:2106.04224",
    "title": "Improved Online Correlated Selection",
    "abstract": "Comments: Compared to the first version, this version adds a discussion on two concurrent works on the same topic, gives a more accurate description of previous results, and improves the presentation based on the feedbacks by anonymous reviewers. The conference version appears in FOCS 2021",
    "descriptor": "\nComments: Compared to the first version, this version adds a discussion on two concurrent works on the same topic, gives a more accurate description of previous results, and improves the presentation based on the feedbacks by anonymous reviewers. The conference version appears in FOCS 2021\n",
    "authors": [
      "Ruiquan Gao",
      "Zhongtian He",
      "Zhiyi Huang",
      "Zipei Nie",
      "Bijun Yuan",
      "Yan Zhong"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.04224"
  },
  {
    "id": "arXiv:2106.04692",
    "title": "Provably Faster Algorithms for Bilevel Optimization",
    "abstract": "Comments: This paper is accepted in NeurIPS 2021",
    "descriptor": "\nComments: This paper is accepted in NeurIPS 2021\n",
    "authors": [
      "Junjie Yang",
      "Kaiyi Ji",
      "Yingbin Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.04692"
  },
  {
    "id": "arXiv:2106.04696",
    "title": "Curriculum Design for Teaching via Demonstrations: Theory and  Applications",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Gaurav Yengera",
      "Rati Devidze",
      "Parameswaran Kamalaruban",
      "Adish Singla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.04696"
  },
  {
    "id": "arXiv:2106.10689",
    "title": "NeuS: Learning Neural Implicit Surfaces by Volume Rendering for  Multi-view Reconstruction",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Peng Wang",
      "Lingjie Liu",
      "Yuan Liu",
      "Christian Theobalt",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.10689"
  },
  {
    "id": "arXiv:2106.13398",
    "title": "Code-Verification Techniques for the Method-of-Moments Implementation of  the Electric-Field Integral Equation",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2012.08681",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2012.08681\n",
    "authors": [
      "Brian A. Freno",
      "Neil R. Matula",
      "Justin I. Owen",
      "William A. Johnson"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13398"
  },
  {
    "id": "arXiv:2107.00379",
    "title": "On the Expected Complexity of Maxout Networks",
    "abstract": "Comments: Published at NeurIPS 2021, 47 pages, 18 figures",
    "descriptor": "\nComments: Published at NeurIPS 2021, 47 pages, 18 figures\n",
    "authors": [
      "Hanna Tseran",
      "Guido Mont\u00fafar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00379"
  },
  {
    "id": "arXiv:2107.01963",
    "title": "PANDADB: A Distributed Graph Database System to Query Unstructured Data  in Big Graph",
    "abstract": "Comments: 16pages",
    "descriptor": "\nComments: 16pages\n",
    "authors": [
      "Zihao Zhao",
      "Zhihong Shen",
      "Mingjie Tang",
      "Chuan Hu",
      "Yuanchun Zhou"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.01963"
  },
  {
    "id": "arXiv:2107.03331",
    "title": "KOALA: A Kalman Optimization Algorithm with Loss Adaptivity",
    "abstract": "Comments: Accepted to AAAI2022",
    "descriptor": "\nComments: Accepted to AAAI2022\n",
    "authors": [
      "Aram Davtyan",
      "Sepehr Sameni",
      "Llukman Cerkezi",
      "Givi Meishvilli",
      "Adam Bielski",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.03331"
  },
  {
    "id": "arXiv:2107.04642",
    "title": "Escaping the Impossibility of Fairness: From Formal to Substantive  Algorithmic Fairness",
    "abstract": "Escaping the Impossibility of Fairness: From Formal to Substantive  Algorithmic Fairness",
    "descriptor": "",
    "authors": [
      "Ben Green"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04642"
  },
  {
    "id": "arXiv:2107.04887",
    "title": "The prevalence and impact of university affiliation discrepancies  between four well-known bibliographic databases: Scopus, Web of Science,  Dimensions, and Microsoft Academic",
    "abstract": "Comments: 40 pages, 4 tables, 9 figures",
    "descriptor": "\nComments: 40 pages, 4 tables, 9 figures\n",
    "authors": [
      "Philip J. Purnell"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2107.04887"
  },
  {
    "id": "arXiv:2107.08013",
    "title": "Machine learning of Kondo physics using variational autoencoders and  symbolic regression",
    "abstract": "Comments: Update to match PRB publication + typo fixes + minor edits",
    "descriptor": "\nComments: Update to match PRB publication + typo fixes + minor edits\n",
    "authors": [
      "Cole Miles",
      "Matthew R. Carbone",
      "Erica J. Sturm",
      "Deyu Lu",
      "Andreas Weichselbaum",
      "Kipton Barros",
      "Robert M. Konik"
    ],
    "subjectives": [
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.08013"
  },
  {
    "id": "arXiv:2107.09070",
    "title": "Dim but not entirely dark: Extracting the Galactic Center Excess'  source-count distribution with neural nets",
    "abstract": "Comments: 36+9 pages, 15+7 figures, main results in Figs. 8 and 12. v2 matches published version in Phys. Rev. D",
    "descriptor": "\nComments: 36+9 pages, 15+7 figures, main results in Figs. 8 and 12. v2 matches published version in Phys. Rev. D\n",
    "authors": [
      "Florian List",
      "Nicholas L. Rodd",
      "Geraint F. Lewis"
    ],
    "subjectives": [
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.09070"
  },
  {
    "id": "arXiv:2107.10879",
    "title": "Discovering Sparse Interpretable Dynamics from Partial Observations",
    "abstract": "Comments: 10 pages, 6 figures (4 main text, 2 supplemental)",
    "descriptor": "\nComments: 10 pages, 6 figures (4 main text, 2 supplemental)\n",
    "authors": [
      "Peter Y. Lu",
      "Joan Ari\u00f1o",
      "Marin Solja\u010di\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2107.10879"
  },
  {
    "id": "arXiv:2107.12845",
    "title": "A Storytelling Robot managing Persuasive and Ethical Stances via ACT-R:  an Exploratory Study",
    "abstract": "Comments: 20 pages, 7 figures",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "Agnese Augello",
      "Giuseppe Citt\u00e0",
      "Manuel Gentile",
      "Antonio Lieto"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.12845"
  },
  {
    "id": "arXiv:2107.13377",
    "title": "Learning to solve complex tasks by growing knowledge culturally across  generations",
    "abstract": "Comments: Presented at the NeurIPS 2021 Cooperative AI Workshop (Dec 2021) and the 43rd Annual Meeting of the Cognitive Science Society (July 2021)",
    "descriptor": "\nComments: Presented at the NeurIPS 2021 Cooperative AI Workshop (Dec 2021) and the 43rd Annual Meeting of the Cognitive Science Society (July 2021)\n",
    "authors": [
      "Michael Henry Tessler",
      "Jason Madeano",
      "Pedro A. Tsividis",
      "Brin Harper",
      "Noah D. Goodman",
      "Joshua B. Tenenbaum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.13377"
  },
  {
    "id": "arXiv:2108.00946",
    "title": "StyleGAN-NADA: CLIP-Guided Domain Adaptation of Image Generators",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Rinon Gal",
      "Or Patashnik",
      "Haggai Maron",
      "Gal Chechik",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.00946"
  },
  {
    "id": "arXiv:2108.05525",
    "title": "Clustering with UMAP: Why and How Connectivity Matters",
    "abstract": "Comments: Published as a long paper at 2nd Graphs and more Complex structures for Learning and Reasoning Workshop in AAAI 2022",
    "descriptor": "\nComments: Published as a long paper at 2nd Graphs and more Complex structures for Learning and Reasoning Workshop in AAAI 2022\n",
    "authors": [
      "Ayush Dalmia",
      "Suzanna Sia"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.05525"
  },
  {
    "id": "arXiv:2108.07477",
    "title": "Efficient split-step schemes for fluid-structure interaction involving  incompressible generalised Newtonian flows",
    "abstract": "Comments: 41 pages, 19 figures, 4 tables, accepted manuscript",
    "descriptor": "\nComments: 41 pages, 19 figures, 4 tables, accepted manuscript\n",
    "authors": [
      "R. Schussnig",
      "D. R. Q. Pacheco",
      "T.-P. Fries"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Dynamical Systems (math.DS)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2108.07477"
  },
  {
    "id": "arXiv:2108.08481",
    "title": "Neural Operator: Learning Maps Between Function Spaces",
    "abstract": "Neural Operator: Learning Maps Between Function Spaces",
    "descriptor": "",
    "authors": [
      "Nikola Kovachki",
      "Zongyi Li",
      "Burigede Liu",
      "Kamyar Azizzadenesheli",
      "Kaushik Bhattacharya",
      "Andrew Stuart",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.08481"
  },
  {
    "id": "arXiv:2108.09293",
    "title": "Asleep at the Keyboard? Assessing the Security of GitHub Copilot's Code  Contributions",
    "abstract": "Comments: Accepted for publication in IEEE Symposium on Security and Privacy 2022",
    "descriptor": "\nComments: Accepted for publication in IEEE Symposium on Security and Privacy 2022\n",
    "authors": [
      "Hammond Pearce",
      "Baleegh Ahmad",
      "Benjamin Tan",
      "Brendan Dolan-Gavitt",
      "Ramesh Karri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.09293"
  },
  {
    "id": "arXiv:2108.11695",
    "title": "PAENet: A Progressive Attention-Enhanced Network for 3D to 2D Retinal  Vessel Segmentation",
    "abstract": "Comments: Accepted by BIBM 2021",
    "descriptor": "\nComments: Accepted by BIBM 2021\n",
    "authors": [
      "Zhuojie Wu",
      "Zijian Wang",
      "Wenxuan Zou",
      "Fan Ji",
      "Hao Dang",
      "Wanting Zhou",
      "Muyi Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11695"
  },
  {
    "id": "arXiv:2109.00397",
    "title": "Graph Automorphism Shuffles from Pile-Scramble Shuffles",
    "abstract": "Comments: 16 pages. We have corrected some typos and added Subsections 1.3, 3.6, Section 5, and proofs of correctness and security of protocols in Subsections 4.1. 4.2",
    "descriptor": "\nComments: 16 pages. We have corrected some typos and added Subsections 1.3, 3.6, Section 5, and proofs of correctness and security of protocols in Subsections 4.1. 4.2\n",
    "authors": [
      "Kengo Miyamoto",
      "Kazumasa Shinagawa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2109.00397"
  },
  {
    "id": "arXiv:2109.01348",
    "title": "Ground-Assisted Federated Learning in LEO Satellite Constellations",
    "abstract": "Comments: Submitted to IEEE Wireless Communications Letters",
    "descriptor": "\nComments: Submitted to IEEE Wireless Communications Letters\n",
    "authors": [
      "Nasrin Razmi",
      "Bho Matthiesen",
      "Armin Dekorsy",
      "Petar Popovski"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01348"
  },
  {
    "id": "arXiv:2109.02791",
    "title": "Safety-Critical Learning of Robot Control with Temporal Logic  Specifications",
    "abstract": "Comments: Under Review. arXiv admin note: text overlap with arXiv:2102.12855",
    "descriptor": "\nComments: Under Review. arXiv admin note: text overlap with arXiv:2102.12855\n",
    "authors": [
      "Mingyu Cai",
      "Cristian-Ioan Vasile"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02791"
  },
  {
    "id": "arXiv:2109.05278",
    "title": "Existence conditions for hidden feedback loops in online recommender  systems",
    "abstract": "Comments: 6 pages, 3 figures",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Anton S. Khritankov",
      "Anton A. Pilkevich"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05278"
  },
  {
    "id": "arXiv:2109.07532",
    "title": "Finding Efficient Domination for $(S_{1,2,5},S_{3,3,3}$-Free Chordal  Bipartite Graphs in Polynomial Time",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2101.01772, arXiv:2010.16076, arXiv:2008.04046",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2101.01772, arXiv:2010.16076, arXiv:2008.04046\n",
    "authors": [
      "Andreas Brandst\u00e4dt"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.07532"
  },
  {
    "id": "arXiv:2109.10569",
    "title": "The Curse Revisited: When are Distances Informative for the Ground Truth  in Noisy High-Dimensional Data?",
    "abstract": "The Curse Revisited: When are Distances Informative for the Ground Truth  in Noisy High-Dimensional Data?",
    "descriptor": "",
    "authors": [
      "Robin Vandaele",
      "Bo Kang",
      "Tijl De Bie",
      "Yvan Saeys"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.10569"
  },
  {
    "id": "arXiv:2109.12848",
    "title": "A General Gaussian Heatmap Label Assignment for Arbitrary-Oriented  Object Detection",
    "abstract": "Comments: 16 pages, 13 figures",
    "descriptor": "\nComments: 16 pages, 13 figures\n",
    "authors": [
      "Zhanchao Huang",
      "Wei Li",
      "Xiang-Gen Xia",
      "Ran Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12848"
  },
  {
    "id": "arXiv:2109.14419",
    "title": "On the Estimation Bias in Double Q-Learning",
    "abstract": "Comments: Thirty-Fifth Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: Thirty-Fifth Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Zhizhou Ren",
      "Guangxiang Zhu",
      "Hao Hu",
      "Beining Han",
      "Jianglun Chen",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.14419"
  },
  {
    "id": "arXiv:2109.14711",
    "title": "Explanation-Aware Experience Replay in Rule-Dense Environments",
    "abstract": "Comments: To appear in IEEE Robotics and Automation Letters (IEEE RA-L). Please cite the published version",
    "descriptor": "\nComments: To appear in IEEE Robotics and Automation Letters (IEEE RA-L). Please cite the published version\n",
    "authors": [
      "Francesco Sovrano",
      "Alex Raymond",
      "Amanda Prorok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.14711"
  },
  {
    "id": "arXiv:2110.00532",
    "title": "Fed-LAMB: Layerwise and Dimensionwise Locally Adaptive Optimization  Algorithm",
    "abstract": "Fed-LAMB: Layerwise and Dimensionwise Locally Adaptive Optimization  Algorithm",
    "descriptor": "",
    "authors": [
      "Belhal Karimi",
      "Xiaoyun Li",
      "Ping Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00532"
  },
  {
    "id": "arXiv:2110.00751",
    "title": "Partner-Aware Algorithms in Decentralized Cooperative Bandit Teams",
    "abstract": "Comments: 14 pages, 13 figures. To be presented at \"Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI) 2022\". Also presented at \"Artificial Intelligence for Human-Robot Interaction (AI-HRI) at AAAI Fall Symposium Series 2021\"",
    "descriptor": "\nComments: 14 pages, 13 figures. To be presented at \"Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI) 2022\". Also presented at \"Artificial Intelligence for Human-Robot Interaction (AI-HRI) at AAAI Fall Symposium Series 2021\"\n",
    "authors": [
      "Erdem B\u0131y\u0131k",
      "Anusha Lalitha",
      "Rajarshi Saha",
      "Andrea Goldsmith",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.00751"
  },
  {
    "id": "arXiv:2110.01330",
    "title": "InfiniteForm: A synthetic, minimal bias dataset for fitness applications",
    "abstract": "Comments: Presented at the NeurIPS Data Centric AI Workshop 2021",
    "descriptor": "\nComments: Presented at the NeurIPS Data Centric AI Workshop 2021\n",
    "authors": [
      "Andrew Weitz",
      "Lina Colucci",
      "Sidney Primas",
      "Brinnae Bent"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.01330"
  },
  {
    "id": "arXiv:2110.02750",
    "title": "Extensions of Karger's Algorithm: Why They Fail in Theory and How They  Are Useful in Practice",
    "abstract": "Comments: Oral at ICCV 2021; added acknowledgements",
    "descriptor": "\nComments: Oral at ICCV 2021; added acknowledgements\n",
    "authors": [
      "Erik Jenner",
      "Enrique Fita Sanmart\u00edn",
      "Fred A. Hamprecht"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02750"
  },
  {
    "id": "arXiv:2110.07700",
    "title": "Hindsight Network Credit Assignment: Efficient Credit Assignment in  Networks of Discrete Stochastic Units",
    "abstract": "Comments: To be presented at AAAI 2022",
    "descriptor": "\nComments: To be presented at AAAI 2022\n",
    "authors": [
      "Kenny Young"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.07700"
  },
  {
    "id": "arXiv:2110.12940",
    "title": "CoboGuider: Haptic Potential Fields for Safe Human-Robot Interaction",
    "abstract": "Comments: Accepted paper in SMC conference 2021, IEEE copyright",
    "descriptor": "\nComments: Accepted paper in SMC conference 2021, IEEE copyright\n",
    "authors": [
      "Viktor Rakhmatulin",
      "Miguel Altamirano Cabrera",
      "Fikre Hagos",
      "Oleg Sautenkov",
      "Jonathan Tirado",
      "Ighor Uzhinsky",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12940"
  },
  {
    "id": "arXiv:2110.13097",
    "title": "Rotation Equivariant Deforestation Segmentation and Driver  Classification",
    "abstract": "Comments: Tackling Climate Change with Machine Learning workshop at NeurIPS 2021",
    "descriptor": "\nComments: Tackling Climate Change with Machine Learning workshop at NeurIPS 2021\n",
    "authors": [
      "Joshua Mitton",
      "Roderick Murray-Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.13097"
  },
  {
    "id": "arXiv:2110.13721",
    "title": "Geometric Transformer for End-to-End Molecule Properties Prediction",
    "abstract": "Geometric Transformer for End-to-End Molecule Properties Prediction",
    "descriptor": "",
    "authors": [
      "Yoni Choukroun",
      "Lior Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13721"
  },
  {
    "id": "arXiv:2111.00444",
    "title": "Finite-Time Capacity: Making Exceed-Shannon Possible?",
    "abstract": "Finite-Time Capacity: Making Exceed-Shannon Possible?",
    "descriptor": "",
    "authors": [
      "Jieao Zhu",
      "Zijian Zhang",
      "Zhongzhichao Wan",
      "Linglong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00444"
  },
  {
    "id": "arXiv:2111.04771",
    "title": "Lipschitz regularization for fracture: the Lip-field approach",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "N. Chevaugeon",
      "N. Moes"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.04771"
  },
  {
    "id": "arXiv:2111.04808",
    "title": "Locally Testable Codes with constant rate, distance, and locality",
    "abstract": "Comments: This new version corrects and polishes a few minor points, but more importantly, adds references to other related very recent works which were done independently",
    "descriptor": "\nComments: This new version corrects and polishes a few minor points, but more importantly, adds references to other related very recent works which were done independently\n",
    "authors": [
      "Irit Dinur",
      "Shai Evra",
      "Ron Livne",
      "Alexander Lubotzky",
      "Shahar Mozes"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.04808"
  },
  {
    "id": "arXiv:2111.05530",
    "title": "Nearly Optimal Linear Convergence of Stochastic Primal-Dual Methods for  Linear Programming",
    "abstract": "Nearly Optimal Linear Convergence of Stochastic Primal-Dual Methods for  Linear Programming",
    "descriptor": "",
    "authors": [
      "Haihao Lu",
      "Jinwen Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05530"
  },
  {
    "id": "arXiv:2111.06162",
    "title": "Clicking Matters:Towards Interactive Human Parsing",
    "abstract": "Comments: Human parsing, interactive segmentation, semantic segmentation",
    "descriptor": "\nComments: Human parsing, interactive segmentation, semantic segmentation\n",
    "authors": [
      "Yutong Gao",
      "Liqian Liang",
      "Congyan Lang",
      "Songhe Feng",
      "Yidong Li",
      "Yunchao Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06162"
  },
  {
    "id": "arXiv:2111.07113",
    "title": "Novel Weight Update Scheme for Hardware Neural Network based on Synaptic  Devices Having Abrupt LTP or LTD Characteristics",
    "abstract": "Comments: 10 pages, 13 figures, 1 table",
    "descriptor": "\nComments: 10 pages, 13 figures, 1 table\n",
    "authors": [
      "Junmo Lee",
      "Joon Hwang",
      "Youngwoon Cho",
      "Sangbum Kim",
      "Jongho Lee"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2111.07113"
  },
  {
    "id": "arXiv:2111.07492",
    "title": "Finding Optimal Tangent Points for Reducing Distortions of Hard-label  Attacks",
    "abstract": "Comments: Accepted at NeurIPS 2021, including the appendix. In the previous versions (v1 and v2), the experimental results of Table 10 are incorrect and have been corrected in the current version",
    "descriptor": "\nComments: Accepted at NeurIPS 2021, including the appendix. In the previous versions (v1 and v2), the experimental results of Table 10 are incorrect and have been corrected in the current version\n",
    "authors": [
      "Chen Ma",
      "Xiangyu Guo",
      "Li Chen",
      "Jun-Hai Yong",
      "Yisen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.07492"
  },
  {
    "id": "arXiv:2111.08842",
    "title": "Privacy Guarantees of BLE Contact Tracing: A Case Study on COVIDWISE",
    "abstract": "Comments: \\{copyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: \\{copyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Salman Ahmed",
      "Ya Xiao",
      "Taejoong",
      "Chung",
      "Carol Fung",
      "Moti Yung",
      "Danfeng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.08842"
  },
  {
    "id": "arXiv:2111.09065",
    "title": "Sampling To Improve Predictions For Underrepresented Observations In  Imbalanced Data",
    "abstract": "Comments: Presented at Workshop on Data-Centric AI (NeurIPS 2021); v2/v3 fixed incorrect axis labels",
    "descriptor": "\nComments: Presented at Workshop on Data-Centric AI (NeurIPS 2021); v2/v3 fixed incorrect axis labels\n",
    "authors": [
      "Rune D. Kj\u00e6rsgaard",
      "Manja G. Gr\u00f8nberg",
      "Line K. H. Clemmensen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09065"
  },
  {
    "id": "arXiv:2111.09296",
    "title": "XLS-R: Self-supervised Cross-lingual Speech Representation Learning at  Scale",
    "abstract": "XLS-R: Self-supervised Cross-lingual Speech Representation Learning at  Scale",
    "descriptor": "",
    "authors": [
      "Arun Babu",
      "Changhan Wang",
      "Andros Tjandra",
      "Kushal Lakhotia",
      "Qiantong Xu",
      "Naman Goyal",
      "Kritika Singh",
      "Patrick von Platen",
      "Yatharth Saraf",
      "Juan Pino",
      "Alexei Baevski",
      "Alexis Conneau",
      "Michael Auli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.09296"
  },
  {
    "id": "arXiv:2111.09492",
    "title": "Reference-based Magnetic Resonance Image Reconstruction Using Texture  Transformer",
    "abstract": "Reference-based Magnetic Resonance Image Reconstruction Using Texture  Transformer",
    "descriptor": "",
    "authors": [
      "Pengfei Guo",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09492"
  },
  {
    "id": "arXiv:2111.09749",
    "title": "Detecting Cross-Language Plagiarism using Open Knowledge Graphs",
    "abstract": "Comments: 10 pages, EEKE21, Preprint",
    "descriptor": "\nComments: 10 pages, EEKE21, Preprint\n",
    "authors": [
      "Johannes Stegm\u00fcller",
      "Fabian Bauer-Marquart",
      "Norman Meuschke",
      "Terry Ruas",
      "Moritz Schubotz",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2111.09749"
  },
  {
    "id": "arXiv:2111.11397",
    "title": "Solar Potential Assessment using Multi-Class Buildings Segmentation from  Aerial Images",
    "abstract": "Solar Potential Assessment using Multi-Class Buildings Segmentation from  Aerial Images",
    "descriptor": "",
    "authors": [
      "Hasan Nasrallah",
      "Abed Ellatif Samhat",
      "Ghaleb Faour",
      "Yilei Shi",
      "Ali J. Ghandour"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11397"
  },
  {
    "id": "arXiv:2111.11637",
    "title": "On the Capacity of MISO Optical Intensity Channels With Per-Antenna  Intensity Constraints",
    "abstract": "On the Capacity of MISO Optical Intensity Channels With Per-Antenna  Intensity Constraints",
    "descriptor": "",
    "authors": [
      "Ru-Han Chen",
      "Longguang Li",
      "Jian Zhang",
      "Wenyi Zhang",
      "Jing Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.11637"
  },
  {
    "id": "arXiv:2111.12373",
    "title": "Solving cubic matrix equations arising in conservative dynamics",
    "abstract": "Comments: 13 pages, 1 figure",
    "descriptor": "\nComments: 13 pages, 1 figure\n",
    "authors": [
      "Michele Benzi",
      "Milo Viviani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12373"
  },
  {
    "id": "arXiv:2111.14709",
    "title": "Linguistic Knowledge in Data Augmentation for Natural Language  Processing: An Example on Chinese Question Matching",
    "abstract": "Comments: 13 pages; 5 tables; 3 figures",
    "descriptor": "\nComments: 13 pages; 5 tables; 3 figures\n",
    "authors": [
      "Zhengxiang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.14709"
  },
  {
    "id": "arXiv:2111.14733",
    "title": "Crime Prediction with Graph Neural Networks and Multivariate Normal  Distributions",
    "abstract": "Comments: Added references for coding libraries, and typos on equations and figure captions fixed",
    "descriptor": "\nComments: Added references for coding libraries, and typos on equations and figure captions fixed\n",
    "authors": [
      "Selim Furkan Tekin",
      "Suleyman Serdar Kozat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.14733"
  },
  {
    "id": "arXiv:2112.00971",
    "title": "Towards Personalization of User Preferences in Partially Observable  Smart Home Environments",
    "abstract": "Comments: The previous submission was the unedited version of the paper, which was uploaded by mistake",
    "descriptor": "\nComments: The previous submission was the unedited version of the paper, which was uploaded by mistake\n",
    "authors": [
      "Shashi Suman",
      "Francois Rivest",
      "Ali Etemad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00971"
  },
  {
    "id": "arXiv:2112.01488",
    "title": "ColBERTv2: Effective and Efficient Retrieval via Lightweight Late  Interaction",
    "abstract": "Comments: Preprint. Omar and Keshav contributed equally to this work",
    "descriptor": "\nComments: Preprint. Omar and Keshav contributed equally to this work\n",
    "authors": [
      "Keshav Santhanam",
      "Omar Khattab",
      "Jon Saad-Falcon",
      "Christopher Potts",
      "Matei Zaharia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01488"
  },
  {
    "id": "arXiv:2112.02365",
    "title": "TransBoost: A Boosting-Tree Kernel Transfer Learning Algorithm for  Improving Financial Inclusion",
    "abstract": "Comments: Accepted at AAAI-22",
    "descriptor": "\nComments: Accepted at AAAI-22\n",
    "authors": [
      "Yiheng Sun",
      "Tian Lu",
      "Cong Wang",
      "Yuan Li",
      "Huaiyu Fu",
      "Jingran Dong",
      "Yunjie Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.02365"
  },
  {
    "id": "arXiv:2112.03214",
    "title": "Piano Timbre Development Analysis using Machine Learning",
    "abstract": "Piano Timbre Development Analysis using Machine Learning",
    "descriptor": "",
    "authors": [
      "Niko Plath",
      "Rolf Bader"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.03214"
  },
  {
    "id": "arXiv:2112.03530",
    "title": "A Conditional Point Diffusion-Refinement Paradigm for 3D Point Cloud  Completion",
    "abstract": "Comments: Code will be released at this https URL",
    "descriptor": "\nComments: Code will be released at this https URL\n",
    "authors": [
      "Zhaoyang Lyu",
      "Zhifeng Kong",
      "Xudong Xu",
      "Liang Pan",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03530"
  },
  {
    "id": "arXiv:2112.03850",
    "title": "Policy Search for Model Predictive Control with Application to Agile  Drone Flight",
    "abstract": "Comments: The paper has been accepted for publication in the IEEE Transactions on Robotics (T-RO), 2021",
    "descriptor": "\nComments: The paper has been accepted for publication in the IEEE Transactions on Robotics (T-RO), 2021\n",
    "authors": [
      "Yunlong Song",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03850"
  },
  {
    "id": "arXiv:2112.04199",
    "title": "Scores of a specific field-normalized indicator calculated with  different approaches of field-categorization: Are the scores different or  similar?",
    "abstract": "Comments: 25 pages, 5 figures, and 2 tables",
    "descriptor": "\nComments: 25 pages, 5 figures, and 2 tables\n",
    "authors": [
      "Robin Haunschild",
      "Angela D. Daniels",
      "Lutz Bornmann"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2112.04199"
  },
  {
    "id": "arXiv:2112.05195",
    "title": "Context-aware Health Event Prediction via Transition Functions on  Dynamic Disease Graphs",
    "abstract": "Comments: This paper is accepted by AAAI 2022",
    "descriptor": "\nComments: This paper is accepted by AAAI 2022\n",
    "authors": [
      "Chang Lu",
      "Tian Han",
      "Yue Ning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05195"
  },
  {
    "id": "arXiv:2112.05686",
    "title": "Learning-based personal speech enhancement for teleconferencing by  exploiting spatial-spectral features",
    "abstract": "Comments: submitted to ICASSP 2022",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Yicheng Hsu",
      "Yonghan Lee",
      "Mingsian R. Bai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.05686"
  },
  {
    "id": "arXiv:2112.06358",
    "title": "Time-of-use Pricing for Energy Storage Investment",
    "abstract": "Time-of-use Pricing for Energy Storage Investment",
    "descriptor": "",
    "authors": [
      "Dongwei Zhao",
      "Hao Wang",
      "Jianwei Huang",
      "Xiaojun Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.06358"
  },
  {
    "id": "arXiv:2112.06431",
    "title": "GM Score: Incorporating inter-class and intra-class generator diversity,  discriminability of disentangled representation, and sample fidelity for  evaluating GANs",
    "abstract": "Comments: 21 pages, 9 figures. Version 2: Added author names and affiliation",
    "descriptor": "\nComments: 21 pages, 9 figures. Version 2: Added author names and affiliation\n",
    "authors": [
      "Harshvardhan GM",
      "Aanchal Sahu",
      "Mahendra Kumar Gourisaria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.06431"
  },
  {
    "id": "arXiv:2112.06471",
    "title": "Limit distributions for the discretization error of stochastic Volterra  equations",
    "abstract": "Limit distributions for the discretization error of stochastic Volterra  equations",
    "descriptor": "",
    "authors": [
      "Masaaki Fukasawa",
      "Takuto Ugai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.06471"
  },
  {
    "id": "arXiv:2112.06580",
    "title": "How to Find a Good Explanation for Clustering?",
    "abstract": "How to Find a Good Explanation for Clustering?",
    "descriptor": "",
    "authors": [
      "Sayan Bandyapadhyay",
      "Fedor V. Fomin",
      "Petr A. Golovach",
      "William Lochet",
      "Nidhi Purohit",
      "Kirill Simonov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06580"
  },
  {
    "id": "arXiv:2112.06660",
    "title": "Subspace Decomposition based DNN algorithm for elliptic type multi-scale  PDEs",
    "abstract": "Comments: 19pages,11 figures",
    "descriptor": "\nComments: 19pages,11 figures\n",
    "authors": [
      "Xi-An Li",
      "Zhi-Qin John Xu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06660"
  },
  {
    "id": "arXiv:2112.07065",
    "title": "Schmebulock's consensus",
    "abstract": "Schmebulock's consensus",
    "descriptor": "",
    "authors": [
      "Victor Grishchenko",
      "Mikhail Patrakeev",
      "S.Q.Locke III"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.07065"
  },
  {
    "id": "arXiv:2112.07163",
    "title": "Minimization of Stochastic First-order Oracle Complexity of Adaptive  Methods for Nonconvex Optimization",
    "abstract": "Minimization of Stochastic First-order Oracle Complexity of Adaptive  Methods for Nonconvex Optimization",
    "descriptor": "",
    "authors": [
      "Hideaki Iiduka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.07163"
  },
  {
    "id": "arXiv:2112.07232",
    "title": "Structure-Exploiting Newton-Type Method for Optimal Control of Switched  Systems",
    "abstract": "Comments: 15 pages, 6 figures, 2 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 15 pages, 6 figures, 2 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Sotaro Katayama",
      "Toshiyuki Ohtsuka"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.07232"
  },
  {
    "id": "arXiv:2112.07637",
    "title": "Exploring Neural Models for Query-Focused Summarization",
    "abstract": "Exploring Neural Models for Query-Focused Summarization",
    "descriptor": "",
    "authors": [
      "Jesse Vig",
      "Alexander R. Fabbri",
      "Wojciech Kry\u015bci\u0144ski",
      "Chien-Sheng Wu",
      "Wenhao Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07637"
  },
  {
    "id": "arXiv:2112.07859",
    "title": "Finite-Sample Analysis of Decentralized Q-Learning for Stochastic Games",
    "abstract": "Finite-Sample Analysis of Decentralized Q-Learning for Stochastic Games",
    "descriptor": "",
    "authors": [
      "Zuguang Gao",
      "Qianqian Ma",
      "Tamer Ba\u015far",
      "John R. Birge"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.07859"
  },
  {
    "id": "arXiv:2112.07867",
    "title": "Interscript: A dataset for interactive learning of scripts through error  feedback",
    "abstract": "Comments: AAAI'22-Workshop on Interactive Machine Learning",
    "descriptor": "\nComments: AAAI'22-Workshop on Interactive Machine Learning\n",
    "authors": [
      "Niket Tandon",
      "Aman Madaan",
      "Peter Clark",
      "Keisuke Sakaguchi",
      "Yiming Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07867"
  },
  {
    "id": "arXiv:2112.07891",
    "title": "Zero-shot Audio Source Separation through Query-based Learning from  Weakly-labeled Data",
    "abstract": "Comments: 9 pages, 3 figures, 5 tables, preprint version for Association for the Advancement of Artificial Intelligence Conference, AAAI 2022",
    "descriptor": "\nComments: 9 pages, 3 figures, 5 tables, preprint version for Association for the Advancement of Artificial Intelligence Conference, AAAI 2022\n",
    "authors": [
      "Ke Chen",
      "Xingjian Du",
      "Bilei Zhu",
      "Zejun Ma",
      "Taylor Berg-kirkpatrick",
      "Shlomo Dubnov"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.07891"
  },
  {
    "id": "arXiv:2112.07966",
    "title": "Modality-Aware Triplet Hard Mining for Zero-shot Sketch-Based Image  Retrieval",
    "abstract": "Comments: 13 pages, 7 figures",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Zongheng Huang",
      "YiFan Sun",
      "Chuchu Han",
      "Changxin Gao",
      "Nong Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07966"
  },
  {
    "id": "arXiv:2112.08075",
    "title": "Fast characterization of inducible regions of atrial fibrillation models  with multi-fidelity Gaussian process classification",
    "abstract": "Comments: 22 pages, 7 figures",
    "descriptor": "\nComments: 22 pages, 7 figures\n",
    "authors": [
      "Lia Gander",
      "Simone Pezzuto",
      "Ali Gharaviri",
      "Rolf Krause",
      "Paris Perdikaris",
      "Francisco Sahli Costabal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2112.08075"
  },
  {
    "id": "arXiv:2112.08186",
    "title": "Planning with Biological Neurons and Synapses",
    "abstract": "Planning with Biological Neurons and Synapses",
    "descriptor": "",
    "authors": [
      "Francesco d'Amore",
      "Daniel Mitropolsky",
      "Pierluigi Crescenzi",
      "Emanuele Natale",
      "Christos H. Papadimitriou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.08186"
  },
  {
    "id": "arXiv:2112.08232",
    "title": "RA V-Net: Deep learning network for automated liver segmentation",
    "abstract": "RA V-Net: Deep learning network for automated liver segmentation",
    "descriptor": "",
    "authors": [
      "Zhiqi Lee",
      "Sumin Qi",
      "Chongchong Fan",
      "Ziwei Xie"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08232"
  },
  {
    "id": "arXiv:2112.08300",
    "title": "Community Detection in Electrical Grids Using Quantum Annealing",
    "abstract": "Comments: 7 pages, 5 figures, conference",
    "descriptor": "\nComments: 7 pages, 5 figures, conference\n",
    "authors": [
      "Marina Fern\u00e1ndez-Campoamor",
      "Corey O'Meara",
      "Giorgio Cortiana",
      "Vedran Peric",
      "Juan Bernab\u00e9-Moreno"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.08300"
  }
]
[
  {
    "id": "arXiv:2112.00731",
    "title": "Is Projection Mapping Natural? Towards Physical World Augmentation  Consistent with Light Field Context",
    "abstract": "Projection mapping seamlessly merges real and virtual worlds. Although much\neffort was made to improve its image qualities so far, projection mapping is\nstill unnatural. We introduce the first steps towards natural projection\nmapping by making the projection results consistent with the light field\ncontext of our daily scene.",
    "descriptor": "",
    "authors": [
      "Daisuke Iwai"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.00731"
  },
  {
    "id": "arXiv:2112.00733",
    "title": "Efficient Symptom Inquiring and Diagnosis via Adaptive Alignment of  Reinforcement Learning and Classification",
    "abstract": "The medical automatic diagnosis system aims to imitate human doctors in the\nreal diagnostic process. This task is formulated as a sequential\ndecision-making problem with symptom inquiring and disease diagnosis. In recent\nyears, many researchers have used reinforcement learning methods to handle this\ntask. However, most recent works neglected to distinguish the symptom inquiring\nand disease diagnosing actions and mixed them into one action space. This\nresults in the unsatisfactory performance of reinforcement learning methods on\nthis task. Moreover, there is a lack of a public evaluation dataset that\ncontains various diseases and corresponding information. To address these\nissues, we first propose a novel method for medical automatic diagnosis with\nsymptom inquiring and disease diagnosing formulated as a reinforcement learning\ntask and a classification task, respectively. We also propose a robust and\nadaptive method to align the two tasks using distribution entropies as media.\nThen, we create a new dataset extracted from the MedlinePlus knowledge base.\nThe dataset contains more diseases and more complete symptom information. The\nsimulated patients for experiments are more realistic. Experimental evaluation\nresults show that our method outperforms three recent state-of-the-art methods\non different datasets by achieving higher medical diagnosis accuracies with few\ninquiring turns.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Hongyi Yuan",
      "Sheng Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00733"
  },
  {
    "id": "arXiv:2112.00734",
    "title": "Federated Learning with Adaptive Batchnorm for Personalized Healthcare",
    "abstract": "There is a growing interest in applying machine learning techniques for\nhealthcare. Recently, federated machine learning (FL) is gaining popularity\nsince it allows researchers to train powerful models without compromising data\nprivacy and security. However, the performance of existing FL approaches often\ndeteriorates when encountering non-iid situations where there exist\ndistribution gaps among clients, and few previous efforts focus on\npersonalization in healthcare. In this article, we propose AdaFed to tackle\ndomain shifts and obtain personalized models for local clients. AdaFed learns\nthe similarity between clients via the statistics of the batch normalization\nlayers while preserving the specificity of each client with different local\nbatch normalization. Comprehensive experiments on five healthcare benchmarks\ndemonstrate that AdaFed achieves better accuracy compared to state-of-the-art\nmethods (e.g., \\textbf{10}\\%+ accuracy improvement for PAMAP2) with faster\nconvergence speed.",
    "descriptor": "\nComments: Technical report. arXiv admin note: substantial text overlap with arXiv:2106.01009\n",
    "authors": [
      "Yiqiang Chen",
      "Wang Lu",
      "Jindong Wang",
      "Xin Qin",
      "Tao Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00734"
  },
  {
    "id": "arXiv:2112.00737",
    "title": "Hardware-friendly Deep Learning by Network Quantization and Binarization",
    "abstract": "Quantization is emerging as an efficient approach to promote\nhardware-friendly deep learning and run deep neural networks on\nresource-limited hardware. However, it still causes a significant decrease to\nthe network in accuracy. We summarize challenges of quantization into two\ncategories: Quantization for Diverse Architectures and Quantization on Complex\nScenes. Our studies focus mainly on applying quantization on various\narchitectures and scenes and pushing the limit of quantization to extremely\ncompress and accelerate networks. The comprehensive research on quantization\nwill achieve more powerful, more efficient, and more flexible hardware-friendly\ndeep learning, and make it better suited to more real-world applications.",
    "descriptor": "",
    "authors": [
      "Haotong Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00737"
  },
  {
    "id": "arXiv:2112.00739",
    "title": "Incomplete Multi-view Clustering via Cross-view Relation Transfer",
    "abstract": "In this paper, we consider the problem of multi-view clustering on incomplete\nviews. Compared with complete multi-view clustering, the view-missing problem\nincreases the difficulty of learning common representations from different\nviews. To address the challenge, we propose a novel incomplete multi-view\nclustering framework, which incorporates cross-view relation transfer and\nmulti-view fusion learning. Specifically, based on the consistency existing in\nmulti-view data, we devise a cross-view relation transfer-based completion\nmodule, which transfers known similar inter-instance relationships to the\nmissing view and recovers the missing data via graph networks based on the\ntransferred relationship graph. Then the view-specific encoders are designed to\nextract the recovered multi-view data, and an attention-based fusion layer is\nintroduced to obtain the common representation. Moreover, to reduce the impact\nof the error caused by the inconsistency between views and obtain a better\nclustering structure, a joint clustering layer is introduced to optimize\nrecovery and clustering simultaneously. Extensive experiments conducted on\nseveral real datasets demonstrate the effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Yiming Wang",
      "Dongxia Chang",
      "Zhiqiang Fu",
      "Yao Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00739"
  },
  {
    "id": "arXiv:2112.00740",
    "title": "Collaborative AI Needs Stronger Assurances Driven by Risks",
    "abstract": "Collaborative AI systems (CAISs) aim at working together with humans in a\nshared space to achieve a common goal. This critical setting yields hazardous\ncircumstances that could harm human beings. Thus, building such systems with\nstrong assurances of compliance with requirements, domain-specific standards\nand regulations is of greatest importance. Only few scale impact has been\nreported so far for such systems since much work remains to manage possible\nrisks. We identify emerging problems in this context and then we report our\nvision, as well as the progress of our multidisciplinary research team composed\nof software/systems, and mechatronics engineers to develop a risk-driven\nassurance process for CAISs.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Jubril Gbolahan Adigun",
      "Matteo Camilli",
      "Michael Felderer",
      "Andrea Giusti",
      "Dominik T Matt",
      "Anna Perini",
      "Barbara Russo",
      "Angelo Susi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.00740"
  },
  {
    "id": "arXiv:2112.00773",
    "title": "Reconsidering Tweets: Intervening During Tweet Creation Decreases  Offensive Content",
    "abstract": "The proliferation of harmful and offensive content is a problem that many\nonline platforms face today. One of the most common approaches for moderating\noffensive content online is via the identification and removal after it has\nbeen posted, increasingly assisted by machine learning algorithms. More\nrecently, platforms have begun employing moderation approaches which seek to\nintervene prior to offensive content being posted. In this paper, we conduct an\nonline randomized controlled experiment on Twitter to evaluate a new\nintervention that aims to encourage participants to reconsider their offensive\ncontent and, ultimately, seeks to reduce the amount of offensive content on the\nplatform. The intervention prompts users who are about to post harmful content\nwith an opportunity to pause and reconsider their Tweet. We find that users in\nour treatment prompted with this intervention posted 6% fewer offensive Tweets\nthan non-prompted users in our control. This decrease in the creation of\noffensive content can be attributed not just to the deletion and revision of\nprompted Tweets -- we also observed a decrease in both the number of offensive\nTweets that prompted users create in the future and the number of offensive\nreplies to prompted Tweets. We conclude that interventions allowing users to\nreconsider their comments can be an effective mechanism for reducing offensive\ncontent online.",
    "descriptor": "\nComments: Accepted at the International AAAI Conference on Web and Social Media (ICWSM 2022)\n",
    "authors": [
      "Matthew Katsaros",
      "Kathy Yang",
      "Lauren Fratamico"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.00773"
  },
  {
    "id": "arXiv:2112.00775",
    "title": "Routing with Self-Attention for Multimodal Capsule Networks",
    "abstract": "The task of multimodal learning has seen a growing interest recently as it\nallows for training neural architectures based on different modalities such as\nvision, text, and audio. One challenge in training such models is that they\nneed to jointly learn semantic concepts and their relationships across\ndifferent input representations. Capsule networks have been shown to perform\nwell in context of capturing the relation between low-level input features and\nhigher-level concepts. However, capsules have so far mainly been used only in\nsmall-scale fully supervised settings due to the resource demand of\nconventional routing algorithms. We present a new multimodal capsule network\nthat allows us to leverage the strength of capsules in the context of a\nmultimodal learning framework on large amounts of video data. To adapt the\ncapsules to large-scale input data, we propose a novel routing by\nself-attention mechanism that selects relevant capsules which are then used to\ngenerate a final joint multimodal feature representation. This allows not only\nfor robust training with noisy video data, but also to scale up the size of the\ncapsule network compared to traditional routing methods while still being\ncomputationally efficient. We evaluate the proposed architecture by pretraining\nit on a large-scale multimodal video dataset and applying it on four datasets\nin two challenging downstream tasks. Results show that the proposed multimodal\ncapsule network is not only able to improve results compared to other routing\ntechniques, but also achieves competitive performance on the task of multimodal\nlearning.",
    "descriptor": "",
    "authors": [
      "Kevin Duarte",
      "Brian Chen",
      "Nina Shvetsova",
      "Andrew Rouditchenko",
      "Samuel Thomas",
      "Alexander Liu",
      "David Harwath",
      "James Glass",
      "Hilde Kuehne",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00775"
  },
  {
    "id": "arXiv:2112.00779",
    "title": "Effects of Interfaces on Human-Robot Trust: Specifying and Visualizing  Physical Zones",
    "abstract": "In this paper we investigate the influence interfaces and feedback have on\nhuman-robot trust levels when operating in a shared physical space. The task we\nuse is specifying a \"no-go\" region for a robot in an indoor environment. We\nevaluate three styles of interface (physical, AR, and map-based) and four\nfeedback mechanisms (no feedback, robot drives around the space, an AR \"fence\",\nand the region marked on the map). Our evaluation looks at both usability and\ntrust. Specifically, if the participant trusts that the robot \"knows\" where the\nno-go region is and their confidence in the robot's ability to avoid that\nregion. We use both self-reported and indirect measures of trust and usability.\nOur key findings are: 1) interfaces and feedback do influence levels of trust;\n2) the participants largely preferred a mixed interface-feedback pair, where\nthe modality for the interface differed from the feedback.",
    "descriptor": "\nComments: 6 pages, 4 figures, 1 table\n",
    "authors": [
      "Marisa Hudspeth",
      "Sogol Balali",
      "Cindy Grimm",
      "Ross Sowell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00779"
  },
  {
    "id": "arXiv:2112.00787",
    "title": "Provable Guarantees for Understanding Out-of-distribution Detection",
    "abstract": "Out-of-distribution (OOD) detection is important for deploying machine\nlearning models in the real world, where test data from shifted distributions\ncan naturally arise. While a plethora of algorithmic approaches have recently\nemerged for OOD detection, a critical gap remains in theoretical understanding.\nIn this work, we develop an analytical framework that characterizes and unifies\nthe theoretical understanding for OOD detection. Our analytical framework\nmotivates a novel OOD detection method for neural networks, GEM, which\ndemonstrates both theoretical and empirical superiority. In particular, on\nCIFAR-100 as in-distribution data, our method outperforms a competitive\nbaseline by 16.57% (FPR95). Lastly, we formally provide provable guarantees and\ncomprehensive analysis of our method, underpinning how various properties of\ndata distribution affect the performance of OOD detection.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Peyman Morteza",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00787"
  },
  {
    "id": "arXiv:2112.00791",
    "title": "Controlling Conditional Language Models with Distributional Policy  Gradients",
    "abstract": "Machine learning is shifting towards general-purpose pretrained generative\nmodels, trained in a self-supervised manner on large amounts of data, which can\nthen be applied to solve a large number of tasks. However, due to their generic\ntraining methodology, these models often fail to meet some of the downstream\nrequirements (e.g. hallucination in abstractive summarization or wrong format\nin automatic code generation). This raises an important question on how to\nadapt pre-trained generative models to a new task without destroying its\ncapabilities. Recent work has suggested to solve this problem by representing\ntask-specific requirements through energy-based models (EBMs) and approximating\nthese EBMs using distributional policy gradients (DPG). Unfortunately, this\napproach is limited to unconditional distributions, represented by\nunconditional EBMs. In this paper, we extend this approach to conditional tasks\nby proposing Conditional DPG (CDPG). We evaluate CDPG on three different\ncontrol objectives across two tasks: summarization with T5 and code generation\nwith GPT-Neo. Our results show that fine-tuning using CDPG robustly moves these\npretrained models closer towards meeting control objectives and -- in contrast\nwith baseline approaches -- does not result in catastrophic forgetting.",
    "descriptor": "\nComments: CtrlGen: Controllable Generative Modeling in Language and Vision Workshop at NeurIPS 2021\n",
    "authors": [
      "Tomasz Korbak",
      "Hady Elsahar",
      "German Kruszewski",
      "Marc Dymetman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00791"
  },
  {
    "id": "arXiv:2112.00792",
    "title": "Ideals, Determinants, and Straightening: Proving and Using Lower Bounds  for Polynomial Ideals",
    "abstract": "We show that any nonzero polynomial in the ideal generated by the $r \\times\nr$ minors of an $n \\times n$ matrix $X$ can be used to efficiently approximate\nthe determinant. For any nonzero polynomial $f$ in this ideal, we construct a\nsmall depth-three $f$-oracle circuit that approximates the determinant of size\n$\\Theta(r^{1/3})$ in the sense of border complexity. For many classes of\nalgebraic circuits, this implies that every nonzero polynomial in the ideal\ngenerated by $r \\times r$ minors is at least as hard to approximately compute\nas the determinant of size $\\Theta(r^{1/3})$. We also prove an analogous result\nfor the Pfaffian of a $2n \\times 2n$ skew-symmetric matrix and the ideal\ngenerated by Pfaffians of $2r \\times 2r$ principal submatrices.\nThis answers a recent question of Grochow about complexity in polynomial\nideals in the setting of border complexity. We give several applications of our\nresult, two of which are highlighted below.\n$\\bullet$ We prove super-polynomial lower bounds for Ideal Proof System\nrefutations computed by low-depth circuits. This extends the recent\nbreakthrough low-depth circuit lower bounds of Limaye, Srinivasan, and Tavenas\nto the setting of proof complexity. For many natural circuit classes, we show\nthat the approximative proof complexity of our hard instance is governed by the\napproximative circuit complexity of the determinant.\n$\\bullet$ We construct new hitting set generators for polynomial-size\nlow-depth circuits. For any $\\varepsilon > 0$, we construct generators with\nseed length $O(n^\\varepsilon)$ that attain a near-optimal tradeoff between\ntheir seed length and degree, and are computable by low-depth circuits of\nnear-linear size (with respect to the size of their output). This matches the\nseed length of the generators recently obtained by Limaye, Srinivasan, and\nTavenas, but improves on the generator's degree and circuit complexity.",
    "descriptor": "\nComments: Abstract shortened to meet arXiv length requirement\n",
    "authors": [
      "Robert Andrews",
      "Michael A. Forbes"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.00792"
  },
  {
    "id": "arXiv:2112.00793",
    "title": "Using Deep Image Prior to Assist Variational Selective Segmentation Deep  Learning Algorithms",
    "abstract": "Variational segmentation algorithms require a prior imposed in the form of a\nregularisation term to enforce smoothness of the solution. Recently, it was\nshown in the Deep Image Prior work that the explicit regularisation in a model\ncan be removed and replaced by the implicit regularisation captured by the\narchitecture of a neural network. The Deep Image Prior approach is competitive,\nbut is only tailored to one specific image and does not allow us to predict\nfuture images. We propose to incorporate the ideas from Deep Image Prior into a\nmore traditional learning algorithm to allow us to use the implicit\nregularisation offered by the Deep Image Prior, but still be able to predict\nfuture images.",
    "descriptor": "\nComments: Presented at SIPAIM 2021\n",
    "authors": [
      "Liam Burrows",
      "Ke Chen",
      "Francesco Torella"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.00793"
  },
  {
    "id": "arXiv:2112.00797",
    "title": "A Feedback Integrated Web-Based Multi-Criteria Group Decision Support  Model for Contractor Selection using Fuzzy Analytic Hierarchy Process",
    "abstract": "In this paper, a feedback integrated multi-criteria group decision support\nmodel for contractor selection was proposed.",
    "descriptor": "\nComments: 20 pages, 2 figures\n",
    "authors": [
      "Abimbola Helen Afolayan",
      "Bolanle Adefowoke Ojokoh",
      "Adebayo Adetunmbi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00797"
  },
  {
    "id": "arXiv:2112.00798",
    "title": "How Smart Guessing Strategies Can Yield Massive Scalability Improvements  for Sparse Decision Tree Optimization",
    "abstract": "Sparse decision tree optimization has been one of the most fundamental\nproblems in AI since its inception and is a challenge at the core of\ninterpretable machine learning. Sparse decision tree optimization is\ncomputationally hard, and despite steady effort since the 1960's, breakthroughs\nhave only been made on the problem within the past few years, primarily on the\nproblem of finding optimal sparse decision trees. However, current\nstate-of-the-art algorithms often require impractical amounts of computation\ntime and memory to find optimal or near-optimal trees for some real-world\ndatasets, particularly those having several continuous-valued features. Given\nthat the search spaces of these decision tree optimization problems are\nmassive, can we practically hope to find a sparse decision tree that competes\nin accuracy with a black box machine learning model? We address this problem\nvia smart guessing strategies that can be applied to any optimal\nbranch-and-bound-based decision tree algorithm. We show that by using these\nguesses, we can reduce the run time by multiple orders of magnitude, while\nproviding bounds on how far the resulting trees can deviate from the black\nbox's accuracy and expressive power. Our approach enables guesses about how to\nbin continuous features, the size of the tree, and lower bounds on the error\nfor the optimal decision tree. Our experiments show that in many cases we can\nrapidly construct sparse decision trees that match the accuracy of black box\nmodels. To summarize: when you are having trouble optimizing, just guess.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Hayden McTavish",
      "Chudi Zhong",
      "Reto Achermann",
      "Ilias Karimalis",
      "Jacques Chen",
      "Cynthia Rudin",
      "Margo Seltzer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00798"
  },
  {
    "id": "arXiv:2112.00799",
    "title": "Finding, Scoring and Explaining Arguments in Bayesian Networks",
    "abstract": "We propose a new approach to explain Bayesian Networks. The approach revolves\naround a new definition of a probabilistic argument and the evidence it\nprovides. We define a notion of independent arguments, and propose an algorithm\nto extract a list of relevant, independent arguments given a Bayesian Network,\na target node and a set of observations. To demonstrate the relevance of the\narguments, we show how we can use the extracted arguments to approximate\nmessage passing. Finally, we show a simple scheme to explain the arguments in\nnatural language.",
    "descriptor": "",
    "authors": [
      "Jaime Sevilla"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.00799"
  },
  {
    "id": "arXiv:2112.00800",
    "title": "Iconary: A Pictionary-Based Game for Testing Multimodal Communication  with Drawings and Text",
    "abstract": "Communicating with humans is challenging for AIs because it requires a shared\nunderstanding of the world, complex semantics (e.g., metaphors or analogies),\nand at times multi-modal gestures (e.g., pointing with a finger, or an arrow in\na diagram). We investigate these challenges in the context of Iconary, a\ncollaborative game of drawing and guessing based on Pictionary, that poses a\nnovel challenge for the research community. In Iconary, a Guesser tries to\nidentify a phrase that a Drawer is drawing by composing icons, and the Drawer\niteratively revises the drawing to help the Guesser in response. This\nback-and-forth often uses canonical scenes, visual metaphor, or icon\ncompositions to express challenging words, making it an ideal test for mixing\nlanguage and visual/symbolic communication in AI. We propose models to play\nIconary and train them on over 55,000 games between human players. Our models\nare skillful players and are able to employ world knowledge in language models\nto play with words unseen during training. Elite human players outperform our\nmodels, particularly at the drawing task, leaving an important gap for future\nresearch to address. We release our dataset, code, and evaluation setup as a\nchallenge to the community at this http URL",
    "descriptor": "\nComments: In EMNLP 2021\n",
    "authors": [
      "Christopher Clark",
      "Jordi Salvador",
      "Dustin Schwenk",
      "Derrick Bonafilia",
      "Mark Yatskar",
      "Eric Kolve",
      "Alvaro Herrasti",
      "Jonghyun Choi",
      "Sachin Mehta",
      "Sam Skjonsberg",
      "Carissa Schoenick",
      "Aaron Sarnat",
      "Hannaneh Hajishirzi",
      "Aniruddha Kembhavi",
      "Oren Etzioni",
      "Ali Farhadi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00800"
  },
  {
    "id": "arXiv:2112.00803",
    "title": "A Review of Web Infodemic Analysis and Detection Trends across  Multi-modalities using Deep Neural Networks",
    "abstract": "Fake news and misinformation are a matter of concern for people around the\nglobe. Users of the internet and social media sites encounter content with\nfalse information much frequently. Fake news detection is one of the most\nanalyzed and prominent areas of research. These detection techniques apply\npopular machine learning and deep learning algorithms. Previous work in this\ndomain covers fake news detection vastly among text circulating online.\nPlatforms that have extensively been observed and analyzed include news\nwebsites and Twitter. Facebook, Reddit, WhatsApp, YouTube, and other social\napplications are gradually gaining attention in this emerging field.\nResearchers are analyzing online data based on multiple modalities composed of\ntext, image, video, speech, and other contributing factors. The combination of\nvarious modalities has resulted in efficient fake news detection. At present,\nthere is an abundance of surveys consolidating textual fake news detection\nalgorithms. This review primarily deals with multi-modal fake news detection\ntechniques that include images, videos, and their combinations with text. We\nprovide a comprehensive literature survey of eighty articles presenting\nstate-of-the-art detection techniques, thereby identifying research gaps and\nbuilding a pathway for researchers to further advance this domain.",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Chahat Raj",
      "Priyanka Meel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00803"
  },
  {
    "id": "arXiv:2112.00804",
    "title": "PreViTS: Contrastive Pretraining with Video Tracking Supervision",
    "abstract": "Videos are a rich source for self-supervised learning (SSL) of visual\nrepresentations due to the presence of natural temporal transformations of\nobjects. However, current methods typically randomly sample video clips for\nlearning, which results in a poor supervisory signal. In this work, we propose\nPreViTS, an SSL framework that utilizes an unsupervised tracking signal for\nselecting clips containing the same object, which helps better utilize temporal\ntransformations of objects. PreViTS further uses the tracking signal to\nspatially constrain the frame regions to learn from and trains the model to\nlocate meaningful objects by providing supervision on Grad-CAM attention maps.\nTo evaluate our approach, we train a momentum contrastive (MoCo) encoder on\nVGG-Sound and Kinetics-400 datasets with PreViTS. Training with PreViTS\noutperforms representations learnt by MoCo alone on both image recognition and\nvideo classification downstream tasks, obtaining state-of-the-art performance\non action classification. PreViTS helps learn feature representations that are\nmore robust to changes in background and context, as seen by experiments on\nimage and video datasets with background changes. Learning from large-scale\nuncurated videos with PreViTS could lead to more accurate and robust visual\nfeature representations.",
    "descriptor": "",
    "authors": [
      "Brian Chen",
      "Ramprasaath R. Selvaraju",
      "Shih-Fu Chang",
      "Juan Carlos Niebles",
      "Nikhil Naik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00804"
  },
  {
    "id": "arXiv:2112.00806",
    "title": "ReIGNN: State Register Identification Using Graph Neural Networks for  Circuit Reverse Engineering",
    "abstract": "Reverse engineering an integrated circuit netlist is a powerful tool to help\ndetect malicious logic and counteract design piracy. A critical challenge in\nthis domain is the correct classification of data-path and control-logic\nregisters in a design. We present ReIGNN, a novel learning-based register\nclassification methodology that combines graph neural networks (GNNs) with\nstructural analysis to classify the registers in a circuit with high accuracy\nand generalize well across different designs. GNNs are particularly effective\nin processing circuit netlists in terms of graphs and leveraging properties of\nthe nodes and their neighborhoods to learn to efficiently discriminate between\ndifferent types of nodes. Structural analysis can further rectify any registers\nmisclassified as state registers by the GNN by analyzing strongly connected\ncomponents in the netlist graph. Numerical results on a set of benchmarks show\nthat ReIGNN can achieve, on average, 96.5% balanced accuracy and 97.7%\nsensitivity across different designs.",
    "descriptor": "\nComments: This paper has been accepted to the 2021 International Conference On Computer-Aided Design (ICCAD 2021)\n",
    "authors": [
      "Subhajit Dutta Chowdhury",
      "Kaixin Yang",
      "Pierluigi Nuzzo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00806"
  },
  {
    "id": "arXiv:2112.00812",
    "title": "Evolving Open Complexity",
    "abstract": "Information theoretic analysis of large evolved programs produced by running\ngenetic programming for up to a million generations has shown even functions as\nsmooth and well behaved as floating point addition and multiplication loose\nentropy and consequently are robust and fail to propagate disruption to their\noutputs. This means, while dependent upon fitness tests, many genetic changes\ndeep within trees are silent. For evolution to proceed at reasonable rate it\nmust be possible to measure the impact of most code changes, yet in large trees\nmost crossover sites are distant from the root node. We suggest to evolve very\nlarge very complex programs, it will be necessary to adopt an open architecture\nwhere most mutation sites are within 10 to 100 levels of the organism's\nenvironment.",
    "descriptor": "\nComments: Accepted for publication by SIGEVOlution newsletter of the ACM Special Interest Group on Genetic and Evolutionary Computation, ISSN 1931-8499, evolution.sigevo.org (publication expected 2022). 4 pages, 1 figure this http URL\n",
    "authors": [
      "W. B. Langdon"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.00812"
  },
  {
    "id": "arXiv:2112.00818",
    "title": "Models of fairness in federated learning",
    "abstract": "In many real-world situations, data is distributed across multiple locations\nand can't be combined for training. Federated learning is a novel distributed\nlearning approach that allows multiple federating agents to jointly learn a\nmodel. While this approach might reduce the error each agent experiences, it\nalso raises questions of fairness: to what extent can the error experienced by\none agent be significantly lower than the error experienced by another agent?\nIn this work, we consider two notions of fairness that each may be appropriate\nin different circumstances: \"egalitarian fairness\" (which aims to bound how\ndissimilar error rates can be) and \"proportional fairness\" (which aims to\nreward players for contributing more data). For egalitarian fairness, we obtain\na tight multiplicative bound on how widely error rates can diverge between\nagents federating together. For proportional fairness, we show that\nsub-proportional error (relative to the number of data points contributed) is\nguaranteed for any individually rational federating coalition.",
    "descriptor": "\nComments: Preliminary version accepted for oral presentation at Neurips workshop on Learning in Presence of Strategic Behavior (2021)\n",
    "authors": [
      "Kate Donahue",
      "Jon Kleinberg"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00818"
  },
  {
    "id": "arXiv:2112.00819",
    "title": "CO-STAR: Conceptualisation of Stereotypes for Analysis and Reasoning",
    "abstract": "Warning: this paper contains material which may be offensive or upsetting.\nWhile much of recent work has focused on the detection of hate speech and\novertly offensive content, very little research has explored the more subtle\nbut equally harmful language in the form of implied stereotypes. This is a\nchallenging domain, made even more so by the fact that humans often struggle to\nunderstand and reason about stereotypes. We build on existing literature and\npresent CO-STAR (COnceptualisation of STereotypes for Analysis and Reasoning),\na novel framework which encodes the underlying concepts of implied stereotypes.\nWe also introduce the CO-STAR training data set, which contains just over 12K\nstructured annotations of implied stereotypes and stereotype\nconceptualisations, and achieve state-of-the-art results after training and\nmanual evaluation. The CO-STAR models are, however, limited in their ability to\nunderstand more complex and subtly worded stereotypes, and our research\nmotivates future work in developing models with more sophisticated methods for\nencoding common-sense knowledge.",
    "descriptor": "\nComments: 12 pages, 1 figure\n",
    "authors": [
      "Teyun Kwon",
      "Anandha Gopalan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00819"
  },
  {
    "id": "arXiv:2112.00821",
    "title": "FaSS-MVS -- Fast Multi-View Stereo with Surface-Aware Semi-Global  Matching from UAV-borne Monocular Imagery",
    "abstract": "With FaSS-MVS, we present an approach for fast multi-view stereo with\nsurface-aware Semi-Global Matching that allows for rapid depth and normal map\nestimation from monocular aerial video data captured by UAVs. The data\nestimated by FaSS-MVS, in turn, facilitates online 3D mapping, meaning that a\n3D map of the scene is immediately and incrementally generated while the image\ndata is acquired or being received. FaSS-MVS is comprised of a hierarchical\nprocessing scheme in which depth and normal data, as well as corresponding\nconfidence scores, are estimated in a coarse-to-fine manner, allowing to\nefficiently process large scene depths which are inherent to oblique imagery\ncaptured by low-flying UAVs. The actual depth estimation employs a plane-sweep\nalgorithm for dense multi-image matching to produce depth hypotheses from which\nthe actual depth map is extracted by means of a surface-aware semi-global\noptimization, reducing the fronto-parallel bias of SGM. Given the estimated\ndepth map, the pixel-wise surface normal information is then computed by\nreprojecting the depth map into a point cloud and calculating the normal\nvectors within a confined local neighborhood. In a thorough quantitative and\nablative study we show that the accuracies of the 3D information calculated by\nFaSS-MVS is close to that of state-of-the-art approaches for offline multi-view\nstereo, with the error not even being one magnitude higher than that of COLMAP.\nAt the same time, however, the average run-time of FaSS-MVS to estimate a\nsingle depth and normal map is less than 14 % of that of COLMAP, allowing to\nperform an online and incremental processing of Full-HD imagery at 1-2 Hz.",
    "descriptor": "",
    "authors": [
      "Boitumelo Ruf",
      "Martin Weinmann",
      "Stefan Hinz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00821"
  },
  {
    "id": "arXiv:2112.00825",
    "title": "Output-weighted and relative entropy loss functions for deep learning  precursors of extreme events",
    "abstract": "Many scientific and engineering problems require accurate models of dynamical\nsystems with rare and extreme events. Such problems present a challenging task\nfor data-driven modelling, with many naive machine learning methods failing to\npredict or accurately quantify such events. One cause for this difficulty is\nthat systems with extreme events, by definition, yield imbalanced datasets and\nthat standard loss functions easily ignore rare events. That is, metrics for\ngoodness of fit used to train models are not designed to ensure accuracy on\nrare events. This work seeks to improve the performance of regression models\nfor extreme events by considering loss functions designed to highlight\noutliers. We propose a novel loss function, the adjusted output weighted loss,\nand extend the applicability of relative entropy based loss functions to\nsystems with low dimensional output. The proposed functions are tested using\nseveral cases of dynamical systems exhibiting extreme events and shown to\nsignificantly improve accuracy in predictions of extreme events.",
    "descriptor": "",
    "authors": [
      "Samuel Rudy",
      "Themistoklis Sapsis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.00825"
  },
  {
    "id": "arXiv:2112.00826",
    "title": "Inducing Causal Structure for Interpretable Neural Networks",
    "abstract": "In many areas, we have well-founded insights about causal structure that\nwould be useful to bring into our trained models while still allowing them to\nlearn in a data-driven fashion. To achieve this, we present the new method of\ninterchange intervention training(IIT). In IIT, we (1)align variables in the\ncausal model with representations in the neural model and (2) train a neural\nmodel to match the counterfactual behavior of the causal model on a base input\nwhen aligned representations in both models are set to be the value they would\nbe for a second source input. IIT is fully differentiable, flexibly combines\nwith other objectives, and guarantees that the target causal model is acausal\nabstraction of the neural model when its loss is minimized. We evaluate IIT on\na structured vision task (MNIST-PVR) and a navigational instruction task\n(ReaSCAN). We compare IIT against multi-task training objectives and data\naugmentation. In all our experiments, IIT achieves the best results and\nproduces neural models that are more interpretable in the sense that they\nrealize the target causal model.",
    "descriptor": "",
    "authors": [
      "Atticus Geiger",
      "Zhengxuan Wu",
      "Hanson Lu",
      "Josh Rozner",
      "Elisa Kreiss",
      "Thomas Icard",
      "Noah D. Goodman",
      "Christopher Potts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00826"
  },
  {
    "id": "arXiv:2112.00827",
    "title": "Changepoint Analysis of Topic Proportions in Temporal Text Data",
    "abstract": "Changepoint analysis deals with unsupervised detection and/or estimation of\ntime-points in time-series data, when the distribution generating the data\nchanges. In this article, we consider \\emph{offline} changepoint detection in\nthe context of large scale textual data. We build a specialised temporal topic\nmodel with provisions for changepoints in the distribution of topic\nproportions. As full likelihood based inference in this model is\ncomputationally intractable, we develop a computationally tractable approximate\ninference procedure. More specifically, we use sample splitting to estimate\ntopic polytopes first and then apply a likelihood ratio statistic together with\na modified version of the wild binary segmentation algorithm of Fryzlewicz et\nal. (2014). Our methodology facilitates automated detection of structural\nchanges in large corpora without the need of manual processing by domain\nexperts. As changepoints under our model correspond to changes in topic\nstructure, the estimated changepoints are often highly interpretable as marking\nthe surge or decline in popularity of a fashionable topic. We apply our\nprocedure on two large datasets: (i) a corpus of English literature from the\nperiod 1800-1922 (Underwoodet al., 2015); (ii) abstracts from the High Energy\nPhysics arXiv repository (Clementet al., 2019). We obtain some historically\nwell-known changepoints and discover some new ones.",
    "descriptor": "\nComments: 32 pages, 9 figures\n",
    "authors": [
      "Avinandan Bose",
      "Soumendu Sundar Mukherjee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00827"
  },
  {
    "id": "arXiv:2112.00828",
    "title": "The Price of Differential Privacy under Continual Observation",
    "abstract": "We study the accuracy of differentially private mechanisms in the continual\nrelease model. A continual release mechanism receives a sensitive dataset as a\nstream of $T$ inputs and produces, after receiving each input, an accurate\noutput on the obtained inputs. In contrast, a batch algorithm receives the data\nas one batch and produces a single output.\nWe provide the first strong lower bounds on the error of continual release\nmechanisms. In particular, for two fundamental problems that are widely studied\nand used in the batch model, we show that the worst case error of every\ncontinual release algorithm is $\\tilde \\Omega(T^{1/3})$ times larger than that\nof the best batch algorithm. Previous work shows only a polylogarithimic (in\n$T$) gap between the worst case error achievable in these two models; further,\nfor many problems, including the summation of binary attributes, the\npolylogarithmic gap is tight (Dwork et al., 2010; Chan et al., 2010). Our\nresults show that closely related problems -- specifically, those that require\nselecting the largest of a set of sums -- are fundamentally harder in the\ncontinual release model than in the batch model.\nOur lower bounds assume only that privacy holds for streams fixed in advance\n(the \"nonadaptive\" setting). However, we provide matching upper bounds that\nhold in a model where privacy is required even for adaptively selected streams.\nThis model may be of independent interest.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Palak Jain",
      "Sofya Raskhodnikova",
      "Satchit Sivakumar",
      "Adam Smith"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.00828"
  },
  {
    "id": "arXiv:2112.00833",
    "title": "Processing Analytical Queries in the AWESOME Polystore [Information  Systems Architectures]",
    "abstract": "Modern big data applications usually involve heterogeneous data sources and\nanalytical functions, leading to increasing demand for polystore systems,\nespecially analytical polystore systems. This paper presents AWESOME system\nalong with a domain-specific language ADIL. ADIL is a powerful language which\nsupports 1) native heterogeneous data models such as Corpus, Graph, and\nRelation; 2) a rich set of analytical functions; and 3) clear and rigorous\nsemantics. AWESOME is an efficient tri-store middle-ware which 1) is built on\nthe top of three heterogeneous DBMSs (Postgres, Solr, and Neo4j) and is easy to\nbe extended to incorporate other systems; 2) supports the in-memory query\nengines and is equipped with analytical capability; 3) applies a cost model to\nefficiently execute workloads written in ADIL; 4) fully exploits machine\nresources to improve scalability. A set of experiments on real workloads\ndemonstrate the capability, efficiency, and scalability of AWESOME.",
    "descriptor": "",
    "authors": [
      "Xiuwen Zheng",
      "Subhasis Dasgupta",
      "Arun Kumar",
      "Amarnath Gupta"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.00833"
  },
  {
    "id": "arXiv:2112.00842",
    "title": "Robust Online Selection with Uncertain Offer Acceptance",
    "abstract": "Online advertising has motivated interest in online selection problems.\nDisplaying ads to the right users benefits both the platform (e.g., via\npay-per-click) and the advertisers (by increasing their reach). In practice,\nnot all users click on displayed ads, while the platform's algorithm may miss\nthe users most disposed to do so. This mismatch decreases the platform's\nrevenue and the advertiser's chances to reach the right customers. With this\nmotivation, we propose a secretary problem where a candidate may or may not\naccept an offer according to a known probability $p$. Because we do not know\nthe top candidate willing to accept an offer, the goal is to maximize a robust\nobjective defined as the minimum over integers $k$ of the probability of\nchoosing one of the top $k$ candidates, given that one of these candidates will\naccept an offer. Using Markov decision process theory, we derive a linear\nprogram for this max-min objective whose solution encodes an optimal policy.\nThe derivation may be of independent interest, as it is generalizable and can\nbe used to obtain linear programs for many online selection models. We further\nrelax this linear program into an infinite counterpart, which we use to provide\nbounds for the objective and closed-form policies. For $p \\geq p^* \\approx\n0.6$, an optimal policy is a simple threshold rule that observes the first\n$p^{1/(1-p)}$ fraction of candidates and subsequently makes offers to the best\ncandidate observed so far.",
    "descriptor": "",
    "authors": [
      "Sebastian Perez-Salazar",
      "Mohit Singh",
      "Alejandro Toriello"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.00842"
  },
  {
    "id": "arXiv:2112.00845",
    "title": "Differentially Private SGD with Sparse Gradients",
    "abstract": "To protect sensitive training data, differentially private stochastic\ngradient descent (DP-SGD) has been adopted in deep learning to provide\nrigorously defined privacy. However, DP-SGD requires the injection of an amount\nof noise that scales with the number of gradient dimensions, resulting in large\nperformance drops compared to non-private training. In this work, we propose\nrandom freeze which randomly freezes a progressively increasing subset of\nparameters and results in sparse gradient updates while maintaining or\nincreasing accuracy. We theoretically prove the convergence of random freeze\nand find that random freeze exhibits a signal loss and perturbation moderation\ntrade-off in DP-SGD. Applying random freeze across various DP-SGD frameworks,\nwe maintain accuracy within the same number of iterations while achieving up to\n70% representation sparsity, which demonstrates that the trade-off exists in a\nvariety of DP-SGD methods. We further note that random freeze significantly\nimproves accuracy, in particular for large networks. Additionally, axis-aligned\nsparsity induced by random freeze leads to various advantages for projected\nDP-SGD or federated learning in terms of computational cost, memory footprint\nand communication overhead.",
    "descriptor": "",
    "authors": [
      "Junyi Zhu",
      "Matthew Blaschko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.00845"
  },
  {
    "id": "arXiv:2112.00847",
    "title": "CLAWS: Contrastive Learning with hard Attention and Weak Supervision",
    "abstract": "Learning effective visual representations without human supervision is a\nlong-standing problem in computer vision. Recent advances in self-supervised\nlearning algorithms have utilized contrastive learning, with methods such as\nSimCLR, which applies a composition of augmentations to an image, and minimizes\na contrastive loss between the two augmented images. In this paper, we present\nCLAWS, an annotation-efficient learning framework, addressing the problem of\nmanually labeling large-scale agricultural datasets along with potential\napplications such as anomaly detection and plant growth analytics. CLAWS uses a\nnetwork backbone inspired by SimCLR and weak supervision to investigate the\neffect of contrastive learning within class clusters. In addition, we inject a\nhard attention mask to the cropped input image before maximizing agreement\nbetween the image pairs using a contrastive loss function. This mask forces the\nnetwork to focus on pertinent object features and ignore background features.\nWe compare results between a supervised SimCLR and CLAWS using an agricultural\ndataset with 227,060 samples consisting of 11 different crop classes. Our\nexperiments and extensive evaluations show that CLAWS achieves a competitive\nNMI score of 0.7325. Furthermore, CLAWS engenders the creation of low\ndimensional representations of very large datasets with minimal parameter\ntuning and forming well-defined clusters, which lends themselves to using\nefficient, transparent, and highly interpretable clustering methods such as\nGaussian Mixture Models.",
    "descriptor": "",
    "authors": [
      "Jansel Herrera-Gerena",
      "Ramakrishnan Sundareswaran",
      "John Just",
      "Matthew Darr",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00847"
  },
  {
    "id": "arXiv:2112.00848",
    "title": "First Steps of an Approach to the ARC Challenge based on Descriptive  Grid Models and the Minimum Description Length Principle",
    "abstract": "The Abstraction and Reasoning Corpus (ARC) was recently introduced by\nFran\\c{c}ois Chollet as a tool to measure broad intelligence in both humans and\nmachines. It is very challenging, and the best approach in a Kaggle competition\ncould only solve 20% of the tasks, relying on brute-force search for chains of\nhand-crafted transformations. In this paper, we present the first steps\nexploring an approach based on descriptive grid models and the Minimum\nDescription Length (MDL) principle. The grid models describe the contents of a\ngrid, and support both parsing grids and generating grids. The MDL principle is\nused to guide the search for good models, i.e. models that compress the grids\nthe most. We report on our progress over a year, improving on the general\napproach and the models. Out of the 400 training tasks, our performance\nincreased from 5 to 29 solved tasks, only using 30s computation time per task.\nOur approach not only predicts the output grids, but also outputs an\nintelligible model and explanations for how the model was incrementally built.",
    "descriptor": "\nComments: 26 pages, 6 figures, technical report of work in progress\n",
    "authors": [
      "S\u00e9bastien Ferr\u00e9"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00848"
  },
  {
    "id": "arXiv:2112.00849",
    "title": "Interpretable Deep Learning-Based Forensic Iris Segmentation and  Recognition",
    "abstract": "Iris recognition of living individuals is a mature biometric modality that\nhas been adopted globally from governmental ID programs, border crossing, voter\nregistration and de-duplication, to unlocking mobile phones. On the other hand,\nthe possibility of recognizing deceased subjects with their iris patterns has\nemerged recently. In this paper, we present an end-to-end deep learning-based\nmethod for postmortem iris segmentation and recognition with a special\nvisualization technique intended to support forensic human examiners in their\nefforts. The proposed postmortem iris segmentation approach outperforms the\nstate of the art and in addition to iris annulus, as in case of classical iris\nsegmentation methods - detects abnormal regions caused by eye decomposition\nprocesses, such as furrows or irregular specular highlights present on the\ndrying and wrinkling cornea. The method was trained and validated with data\nacquired from 171 cadavers, kept in mortuary conditions, and tested on\nsubject-disjoint data acquired from 259 deceased subjects. To our knowledge,\nthis is the largest corpus of data used in postmortem iris recognition research\nto date. The source code of the proposed method are offered with the paper. The\ntest data will be available through the National Archive of Criminal Justice\nData (NACJD) archives.",
    "descriptor": "",
    "authors": [
      "Andrey Kuehlkamp",
      "Aidan Boyd",
      "Adam Czajka",
      "Kevin Bowyer",
      "Patrick Flynn",
      "Dennis Chute",
      "Eric Benjamin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00849"
  },
  {
    "id": "arXiv:2112.00853",
    "title": "On the Scalability of Big Data Cyber Security Analytics Systems",
    "abstract": "Big Data Cyber Security Analytics (BDCA) systems use big data technologies\n(e.g., Apache Spark) to collect, store, and analyze a large volume of security\nevent data for detecting cyber-attacks. The volume of digital data in general\nand security event data in specific is increasing exponentially. The velocity\nwith which the security event data is generated and fed into a BDCA system is\nunpredictable. Therefore, a BDCA system should be highly scalable to deal with\nthe unpredictable increase/decrease in the velocity of security event data.\nHowever, there has been little effort to investigate the scalability of BDCA\nsystems to identify and exploit the sources of scalability improvement. In this\npaper, we first investigate the scalability of a Spark-based BDCA system with\ndefault Spark settings. we then identify Spark configuration parameters (e.g.,\nexecution memory) that can significantly impact the scalability of a BDCA\nsystem. Based on the identified parameters, we finally propose a\nparameter-driven adaptation approach, SCALER, for optimizing a system's\nscalability. We have conducted a set of experiments by implementing a\nSpark-based BDCA system on a large-scale OpenStack cluster. We ran our\nexperiments with four security datasets. We have found that (i) a BDCA system\nwith default Spark configuration parameters deviates from ideal scalability by\n59.5% (ii) 9 out of 11 studied Spark configuration parameters significantly\nimpact scalability (iii) SCALER improves the BDCA system's scalability by 20.8%\ncompared to the scalability with default Spark parameter setting. The findings\nof our study highlight the importance of exploring the parameter space of the\nunderlying big data framework (e.g., Apache Spark) for scalable cyber security\nanalytics.",
    "descriptor": "",
    "authors": [
      "Faheem Ullah",
      "Muhammad Ali Babar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.00853"
  },
  {
    "id": "arXiv:2112.00854",
    "title": "GANORCON: Are Generative Models Useful for Few-shot Segmentation?",
    "abstract": "Advances in generative modeling based on GANs has motivated the community to\nfind their use beyond image generation and editing tasks. In particular,\nseveral recent works have shown that GAN representations can be re-purposed for\ndiscriminative tasks such as part segmentation, especially when training data\nis limited. But how do these improvements stack-up against recent advances in\nself-supervised learning? Motivated by this we present an alternative approach\nbased on contrastive learning and compare their performance on standard\nfew-shot part segmentation benchmarks. Our experiments reveal that not only do\nthe GAN-based approach offer no significant performance advantage, their\nmulti-step training is complex, nearly an order-of-magnitude slower, and can\nintroduce additional bias. These experiments suggest that the inductive biases\nof generative models, such as their ability to disentangle shape and texture,\nare well captured by standard feed-forward networks trained using contrastive\nlearning. These experiments suggest that the inductive biases present in\ncurrent generative models, such as their ability to disentangle shape and\ntexture, are well captured by standard feed-forward networks trained using\ncontrastive learning.",
    "descriptor": "",
    "authors": [
      "Oindrila Saha",
      "Zezhou Cheng",
      "Subhransu Maji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00854"
  },
  {
    "id": "arXiv:2112.00856",
    "title": "Decomposing Representations for Deterministic Uncertainty Estimation",
    "abstract": "Uncertainty estimation is a key component in any deployed machine learning\nsystem. One way to evaluate uncertainty estimation is using\n\"out-of-distribution\" (OoD) detection, that is, distinguishing between the\ntraining data distribution and an unseen different data distribution using\nuncertainty. In this work, we show that current feature density based\nuncertainty estimators cannot perform well consistently across different OoD\ndetection settings. To solve this, we propose to decompose the learned\nrepresentations and integrate the uncertainties estimated on them separately.\nThrough experiments, we demonstrate that we can greatly improve the performance\nand the interpretability of the uncertainty estimation.",
    "descriptor": "",
    "authors": [
      "Haiwen Huang",
      "Joost van Amersfoort",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00856"
  },
  {
    "id": "arXiv:2112.00857",
    "title": "Phasor Modelling Approaches and Simulation Guidelines of Voltage-Source  Converters in Grid-Integration Studies",
    "abstract": "This paper reviews Voltage-Source Converters (VSCs) EMT and Phasor models\ncurrently used to simulate converter-interfaced generation (CIG) and renewable\nenergy resources integration to power systems. Several modelling guidelines and\nsuitability analyses were provided based on a comprehensive comparative study\namong the models. Various studies were performed in a small system and a large\nsystem, modelled in Simulink. We address a gap related to the suitability of\nCIGs phasor models in studies where the boundary between electromagnetic and\nelectromechanical transients overlap. An insightful analysis of the adequate\nsimulation time step for each model and study is also provided, along with\nseveral simulation guidelines.",
    "descriptor": "",
    "authors": [
      "Vin\u00edcius Albernaz Lacerda",
      "Eduardo Prieto Araujo",
      "Marc Cheah-Ma\u00f1e",
      "Oriol Gomis-Bellmunt"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00857"
  },
  {
    "id": "arXiv:2112.00858",
    "title": "Common Bugs in Scratch Programs",
    "abstract": "Bugs in Scratch programs can spoil the fun and inhibit learning success. Many\ncommon bugs are the result of recurring patterns of bad code. In this paper we\npresent a collection of common code patterns that typically hint at bugs in\nScratch programs, and the LitterBox tool which can automatically detect them.\nWe empirically evaluate how frequently these patterns occur, and how severe\ntheir consequences usually are. While fixing bugs inevitably is part of\nlearning, the possibility to identify the bugs automatically provides the\npotential to support learners",
    "descriptor": "\nComments: Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education (pp. 89-95)\n",
    "authors": [
      "Christoph Fr\u00e4drich",
      "Florian Oberm\u00fcller",
      "Nina K\u00f6rber",
      "Ute Heuer",
      "Gordon Fraser"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.00858"
  },
  {
    "id": "arXiv:2112.00859",
    "title": "Are Investors Biased Against Women? Analyzing How Gender Affects Startup  Funding in Europe",
    "abstract": "One of the main challenges of startups is to raise capital from investors.\nFor startup founders, it is therefore crucial to know whether investors have a\nbias against women as startup founders and in which way startups face\ndisadvantages due to gender bias. Existing works on gender studies have mainly\nanalyzed the US market. In this paper, we aim to give a more comprehensive\npicture of gender bias in early-stage startup funding. We examine European\nstartups listed on Crunchbase using Semantic Web technologies and analyze how\nthe share of female founders in a founding team affects the funding amount. We\nfind that the relative amount of female founders has a negative impact on the\nfunding raised. Furthermore, we observe that founder characteristics have an\neffect on the funding raised based on the founders' gender. Moreover, we find\nthat gender bias in early-stage funding is less prevalent for serial founders\nwith entrepreneurial experience as female founders benefit three times more\nthan male founders from already having founded a startup. Overall, our study\nsuggests that gender bias exists and is worth to be considered in the context\nof startup funding.",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Michael F\u00e4rber",
      "Alexander Klein"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.00859"
  },
  {
    "id": "arXiv:2112.00860",
    "title": "Robust Resource-Aware Self-triggered Model Predictive Control",
    "abstract": "The wide adoption of wireless devices in the Internet of Things requires\ncontrollers that are able to operate with limited resources, such as battery\nlife. Operating these devices robustly in an uncertain environment, while\nmanaging available resources, increases the difficultly of controller design.\nThis paper proposes a robust self-triggered model predictive control approach\nto optimize a control objective while managing resource consumption. In\nparticular, a novel zero-order-hold aperiodic discrete-time feedback control\nlaw is developed to ensure robust constraint satisfaction for continuous-time\nlinear systems.",
    "descriptor": "\nComments: Accepted to L-CSS and ACC 2022\n",
    "authors": [
      "Yingzhao Lian",
      "Yuning Jiang",
      "Naomi Stricker",
      "Lothar Thiele",
      "Colin N. Jones"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00860"
  },
  {
    "id": "arXiv:2112.00861",
    "title": "A General Language Assistant as a Laboratory for Alignment",
    "abstract": "Given the broad capabilities of large language models, it should be possible\nto work towards a general-purpose, text-based assistant that is aligned with\nhuman values, meaning that it is helpful, honest, and harmless. As an initial\nforay in this direction we study simple baseline techniques and evaluations,\nsuch as prompting. We find that the benefits from modest interventions increase\nwith model size, generalize to a variety of alignment evaluations, and do not\ncompromise the performance of large models. Next we investigate scaling trends\nfor several training objectives relevant to alignment, comparing imitation\nlearning, binary discrimination, and ranked preference modeling. We find that\nranked preference modeling performs much better than imitation learning, and\noften scales more favorably with model size. In contrast, binary discrimination\ntypically performs and scales very similarly to imitation learning. Finally we\nstudy a `preference model pre-training' stage of training, with the goal of\nimproving sample efficiency when finetuning on human preferences.",
    "descriptor": "\nComments: 26+19 pages\n",
    "authors": [
      "Amanda Askell",
      "Yuntao Bai",
      "Anna Chen",
      "Dawn Drain",
      "Deep Ganguli",
      "Tom Henighan",
      "Andy Jones",
      "Nicholas Joseph",
      "Ben Mann",
      "Nova DasSarma",
      "Nelson Elhage",
      "Zac Hatfield-Dodds",
      "Danny Hernandez",
      "Jackson Kernion",
      "Kamal Ndousse",
      "Catherine Olsson",
      "Dario Amodei",
      "Tom Brown",
      "Jack Clark",
      "Sam McCandlish",
      "Chris Olah",
      "Jared Kaplan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00861"
  },
  {
    "id": "arXiv:2112.00862",
    "title": "Modelling and Simulation of Power Systems with Grid-Connected Converters  in OpenModelica",
    "abstract": "This paper analyses the capabilities of the OpenModelica environment to\nperform electromagnetic transient (EMT) type simulations of power transmission\nsystems with grid-connected converters. A power transmission system has been\nmodelled and simulated in OpenModelica and Simulink to compare both tools in\nterms of accuracy, robustness, flexibility and computational performance. Power\nsystem transient studies such as faults and switching of capacitor banks have\nbeen performed. The results confirmed an excellent overall agreement between\nboth software and demonstrated a remarkable potential for using OpenModelica\nfor EMT-type modelling and simulation of future power electronic dominated\ngrids.",
    "descriptor": "",
    "authors": [
      "Lluc Figueras Llerins",
      "Vin\u00edcius Albernaz Lacerda",
      "Adrien Guironnet",
      "Quentin Cossart",
      "Eduardo Prieto-Araujo",
      "Oriol Gomis-Bellmunt"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00862"
  },
  {
    "id": "arXiv:2112.00864",
    "title": "A fast method for evaluating Volume potentials in the Galerkin boundary  element method",
    "abstract": "Three algorithm are proposed to evaluate volume potentials that arise in\nboundary element methods for elliptic PDEs. The approach is to apply a modified\nfast multipole method for a boundary concentrated volume mesh. If $h$ is the\nmeshwidth of the boundary, then the volume is discretized using nearly\n$O(h^{-2})$ degrees of freedom, and the algorithm computes potentials in nearly\n$O(h^{-2})$ complexity. Here nearly means that logarithmic terms of $h$ may\nappear. Thus the complexity of volume potentials calculations is of the same\nasymptotic order as boundary potentials. For sources and potentials with\nsufficient regularity the parameters of the algorithm can be designed such that\nthe error of the approximated potential converges at any specified rate\n$O(h^p)$. The accuracy and effectiveness of the proposed algorithms are\ndemonstrated for potentials of the Poisson equation in three dimensions.",
    "descriptor": "\nComments: 20 pages, 3 figures\n",
    "authors": [
      "Sasan Mohyaddin",
      "Johannes Tausch"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.00864"
  },
  {
    "id": "arXiv:2112.00867",
    "title": "Modelling Approaches of Power Systems Considering Grid-Connected  Converters and Renewable Generation Dynamics",
    "abstract": "This paper presents a comparative analysis of several modelling approaches of\nkey elements used in simulations of power systems with renewable energy\nsources. Different models of synchronous generators, transmission lines,\nconverters, wind generators and photovoltaic (PV) power plants are compared to\nassess the most suitable models for grid-connection studies. It also analyses\nhow the dynamics of PV power plants and the mechanical dynamics of wind\ngenerators affect the electrical variables on the grid side. The models were\ncompared in terms of precision and computational time through simulations of\nload connection, short-circuits, disconnection of generators and lines in a\nbenchmark system modelled in Simulink.",
    "descriptor": "",
    "authors": [
      "Vin\u00edcius Albernaz Lacerda",
      "Jaume Girona-Badia",
      "Stephan Kusche",
      "Florian P\u00f6schke",
      "Eduardo Prieto-Araujo",
      "Horst Schulte",
      "Oriol Gomis-Bellmunt"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00867"
  },
  {
    "id": "arXiv:2112.00869",
    "title": "Definition of scenarios for modern power systems with a high renewable  energy share",
    "abstract": "Recent environmental policies have led many academic, industrial and\ngovernmental stakeholders to design and plan scenarios with very high share of\nrenewable energy sources (RES). New system elements such as High-voltage Direct\nCurrent (HVDC) transmission, Microgrids, Virtual Power Plants (VPP) and Dynamic\nVirtual Power Plants (DVPP) are being increasingly studied with respect to\ntheir contribution to integrate future RES plants in the main grid. Several\nfuture scenarios are being analysed for each system and region, to ensure that\nthe future energy systems, composed mostly of RES, can remain stable, match the\ndemand during the seasonal variations across the year and are economically\nfeasible. In this article, different types of energy scenarios are considered\nto obtain a range of options in terms of size, renewable generation\ntechnologies, and electrical network configuration. The scenarios were studied\nin the context of the POSYTYF project and were quantified through an\noptimization-based algorithm, using specific locations in Europe, and real data\nrelated to the availability of different RES, as well as the demand. It has\nbeen shown that photovoltaic (PV) and wind generation can provide the renewable\nbackbone but they lack the flexibility needed to achieve a very high share in\nthe energy mix. Other technologies, such as solar thermal and pumped hydro,\nbecome important to cover the last range of integration, as they provide a high\nflexibility, which is crucial for high share.",
    "descriptor": "",
    "authors": [
      "Carlos Collados-Rodr\u00edguez",
      "Eduard Antol\u00ed-Gil",
      "Enric S\u00e1nchez-S\u00e1nchez",
      "Jaume Girona-Badia",
      "Vin\u00edcius Albernaz Lacerda",
      "Marc Cheah-Ma\u00f1e",
      "Eduardo Prieto-Araujo",
      "Oriol Gomis-Bellmunt"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00869"
  },
  {
    "id": "arXiv:2112.00874",
    "title": "Neural Stochastic Dual Dynamic Programming",
    "abstract": "Stochastic dual dynamic programming (SDDP) is a state-of-the-art method for\nsolving multi-stage stochastic optimization, widely used for modeling\nreal-world process optimization tasks. Unfortunately, SDDP has a worst-case\ncomplexity that scales exponentially in the number of decision variables, which\nseverely limits applicability to only low dimensional problems. To overcome\nthis limitation, we extend SDDP by introducing a trainable neural model that\nlearns to map problem instances to a piece-wise linear value function within\nintrinsic low-dimension space, which is architected specifically to interact\nwith a base SDDP solver, so that can accelerate optimization performance on new\ninstances. The proposed Neural Stochastic Dual Dynamic Programming ($\\nu$-SDDP)\ncontinually self-improves by solving successive problems. An empirical\ninvestigation demonstrates that $\\nu$-SDDP can significantly reduce problem\nsolving cost without sacrificing solution quality over competitors such as SDDP\nand reinforcement learning algorithms, across a range of synthetic and\nreal-world process optimization problems.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Hanjun Dai",
      "Yuan Xue",
      "Zia Syed",
      "Dale Schuurmans",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00874"
  },
  {
    "id": "arXiv:2112.00875",
    "title": "Secure and Safety Mobile Network System for Visually Impaired People",
    "abstract": "The proposed system aims to be a techno-friend of visually impaired people to\nassist them in orientation and mobility both indoor and outdoor. Moving through\nan unknown environment becomes a real challenge for most of them, although they\nrely on their other senses. An age old mechanism used for assistance for the\nblind people is a white cane commonly known as walking cane a simple and purely\nmechanical device to detect the ground, uneven surfaces, holes and steps using\nsimple Tactile-force feedback.",
    "descriptor": "\nComments: 4 pages, 3 figures, Accepted at 2012 IEEE ICECE, Bangalore\n",
    "authors": [
      "Shyama Kumari Arunachalam",
      "Roopa V",
      "Meena H B",
      "Vijayalakshmi",
      "T Malavika"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.00875"
  },
  {
    "id": "arXiv:2112.00879",
    "title": "Generating Diverse 3D Reconstructions from a Single Occluded Face Image",
    "abstract": "Occlusions are a common occurrence in unconstrained face images. Single image\n3D reconstruction from such face images often suffers from corruption due to\nthe presence of occlusions. Furthermore, while a plurality of 3D\nreconstructions is plausible in the occluded regions, existing approaches are\nlimited to generating only a single solution. To address both of these\nchallenges, we present Diverse3DFace, which is specifically designed to\nsimultaneously generate a diverse and realistic set of 3D reconstructions from\na single occluded face image. It consists of three components: a global+local\nshape fitting process, a graph neural network-based mesh VAE, and a\nDeterminantal Point Process based diversity promoting iterative optimization\nprocedure. Quantitative and qualitative comparisons of 3D reconstruction on\noccluded faces show that Diverse3DFace can estimate 3D shapes that are\nconsistent with the visible regions in the target image while exhibiting high,\nyet realistic, levels of diversity on the occluded regions. On face images\noccluded by masks, glasses, and other random objects, Diverse3DFace generates a\ndistribution of 3D shapes having ~50% higher diversity on the occluded regions\ncompared to the baselines. Moreover, our closest sample to the ground truth has\n~40% lower MSE than the singular reconstructions by existing approaches.",
    "descriptor": "\nComments: Submitted to CVPR 2022\n",
    "authors": [
      "Rahul Dey",
      "Vishnu Naresh Boddeti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00879"
  },
  {
    "id": "arXiv:2112.00881",
    "title": "Learning Invariant Representations with Missing Data",
    "abstract": "Spurious correlations allow flexible models to predict well during training\nbut poorly on related test populations. Recent work has shown that models that\nsatisfy particular independencies involving correlation-inducing\n\\textit{nuisance} variables have guarantees on their test performance.\nEnforcing such independencies requires nuisances to be observed during\ntraining. However, nuisances, such as demographics or image background labels,\nare often missing. Enforcing independence on just the observed data does not\nimply independence on the entire population. Here we derive \\acrshort{mmd}\nestimators used for invariance objectives under missing nuisances. On\nsimulations and clinical data, optimizing through these estimates achieves test\nperformance similar to using estimators that make use of the full data.",
    "descriptor": "\nComments: NeurIPS 2021 DistShift Workshop\n",
    "authors": [
      "Mark Goldstein",
      "J\u00f6rn-Henrik Jacobsen",
      "Olina Chau",
      "Adriel Saporta",
      "Aahlad Puli",
      "Rajesh Ranganath",
      "Andrew C. Miller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00881"
  },
  {
    "id": "arXiv:2112.00884",
    "title": "Rate-Splitting Meets Cell-Free MIMOCommunications",
    "abstract": "Multiuser multiple-input multiple-output wireless communications systems have\nthe potential to satisfy the performance requirements of fifth-generation and\nfuture wireless networks. In this context, cell-free (CF) systems, where the\nantennas are distributed over the area of interest, have attracted attention\nbecause of their potential to enhance the overall efficiency and throughput\nperformance when compared to traditional networks based on cells. However, the\nperformance of CF systems is degraded by imperfect channel state information\n(CSI). To mitigate the detrimental effects of imperfect CSI, we employ rate\nsplitting (RS) - a multiple-access scheme. The RS schemes divides the messages\nof the users into two separate common and private portions so that interference\nis managed robustly. Unlike prior works, where the impact of RS in CF systems\nremains unexamined, we propose a CF architecture that employs RS with linear\nprecoders to address deteriorated CSI. We derive closed-form expressions to\ncompute the sum-rate performance of the proposed RS-CF architecture. Our\nnumerical experiments show that our RS-CF system outperforms existing systems\nin terms of sum-rate, obtaining up to $10$.",
    "descriptor": "\nComments: 4 figures, 7 pages\n",
    "authors": [
      "Andr\u00e9 Flores",
      "Rodrigo C. de Lamare",
      "Kumar Vijay Mishra"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.00884"
  },
  {
    "id": "arXiv:2112.00885",
    "title": "Safe Exploration for Constrained Reinforcement Learning with Provable  Guarantees",
    "abstract": "We consider the problem of learning an episodic safe control policy that\nminimizes an objective function, while satisfying necessary safety constraints\n-- both during learning and deployment. We formulate this safety constrained\nreinforcement learning (RL) problem using the framework of a finite-horizon\nConstrained Markov Decision Process (CMDP) with an unknown transition\nprobability function. Here, we model the safety requirements as constraints on\nthe expected cumulative costs that must be satisfied during all episodes of\nlearning. We propose a model-based safe RL algorithm that we call the\nOptimistic-Pessimistic Safe Reinforcement Learning (OPSRL) algorithm, and show\nthat it achieves an $\\tilde{\\mathcal{O}}(S^{2}\\sqrt{A H^{7}K}/ (\\bar{C} -\n\\bar{C}_{b}))$ cumulative regret without violating the safety constraints\nduring learning, where $S$ is the number of states, $A$ is the number of\nactions, $H$ is the horizon length, $K$ is the number of learning episodes, and\n$(\\bar{C} - \\bar{C}_{b})$ is the safety gap, i.e., the difference between the\nconstraint value and the cost of a known safe baseline policy. The scaling as\n$\\tilde{\\mathcal{O}}(\\sqrt{K})$ is the same as the traditional approach where\nconstraints may be violated during learning, which means that our algorithm\nsuffers no additional regret in spite of providing a safety guarantee. Our key\nidea is to use an optimistic exploration approach with pessimistic constraint\nenforcement for learning the policy. This approach simultaneously incentivizes\nthe exploration of unknown states while imposing a penalty for visiting states\nthat are likely to cause violation of safety constraints. We validate our\nalgorithm by evaluating its performance on benchmark problems against\nconventional approaches.",
    "descriptor": "",
    "authors": [
      "Archana Bura",
      "Aria HasanzadeZonuzy",
      "Dileep Kalathil",
      "Srinivas Shakkottai",
      "Jean-Francois Chamberland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00885"
  },
  {
    "id": "arXiv:2112.00888",
    "title": "The (1+1)-ES Reliably Overcomes Saddle Points",
    "abstract": "It is known that step size adaptive evolution strategies (ES) do not converge\n(prematurely) to regular points of continuously differentiable objective\nfunctions. Among critical points, convergence to minima is desired, and\nconvergence to maxima is easy to exclude. However, surprisingly little is known\non whether ES can get stuck at a saddle point. In this work we establish that\neven the simple (1+1)-ES reliably overcomes most saddle points under quite mild\nregularity conditions. Our analysis is based on drift with tail bounds. It is\nnon-standard in that we do not even aim to estimate hitting times based on\ndrift. Rather, in our case it suffices to show that the relevant time is finite\nwith full probability.",
    "descriptor": "",
    "authors": [
      "Tobias Glasmachers"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.00888"
  },
  {
    "id": "arXiv:2112.00890",
    "title": "Counterfactual Explanations via Latent Space Projection and  Interpolation",
    "abstract": "Counterfactual explanations represent the minimal change to a data sample\nthat alters its predicted classification, typically from an unfavorable initial\nclass to a desired target class. Counterfactuals help answer questions such as\n\"what needs to change for this application to get accepted for a loan?\". A\nnumber of recently proposed approaches to counterfactual generation give\nvarying definitions of \"plausible\" counterfactuals and methods to generate\nthem. However, many of these methods are computationally intensive and provide\nunconvincing explanations. Here we introduce SharpShooter, a method for binary\nclassification that starts by creating a projected version of the input that\nclassifies as the target class. Counterfactual candidates are then generated in\nlatent space on the interpolation line between the input and its projection. We\nthen demonstrate that our framework translates core characteristics of a sample\nto its counterfactual through the use of learned representations. Furthermore,\nwe show that SharpShooter is competitive across common quality metrics on\ntabular and image datasets while being orders of magnitude faster than two\ncomparable methods and excels at measures of realism, making it well-suited for\nhigh velocity machine learning applications which require timely explanations.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Brian Barr",
      "Matthew R. Harrington",
      "Samuel Sharpe",
      "C. Bayan Bruss"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00890"
  },
  {
    "id": "arXiv:2112.00891",
    "title": "Event Neural Networks",
    "abstract": "Video data is often repetitive; for example, the content of adjacent frames\nis usually strongly correlated. Such repetition occurs at multiple levels of\ncomplexity, from low-level pixel values to textures and high-level semantics.\nWe propose Event Neural Networks (EvNets), a novel class of networks that\nleverage this repetition to achieve considerable computation savings for video\ninference tasks. A defining characteristic of EvNets is that each neuron has\nstate variables that provide it with long-term memory, which allows low-cost\ninference even in the presence of significant camera motion. We show that it is\npossible to transform virtually any conventional neural into an EvNet. We\ndemonstrate the effectiveness of our method on several state-of-the-art neural\nnetworks for both high- and low-level visual processing, including pose\nrecognition, object detection, optical flow, and image enhancement. We observe\nup to an order-of-magnitude reduction in computational costs (2-20x) as\ncompared to conventional networks, with minimal reductions in model accuracy.",
    "descriptor": "\nComments: Main paper: 8 pages, 7 figures; supplementary material: 6 pages, 5 figures\n",
    "authors": [
      "Matthew Dutson",
      "Mohit Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00891"
  },
  {
    "id": "arXiv:2112.00894",
    "title": "Context-Dependent Semantic Parsing for Temporal Relation Extraction",
    "abstract": "Extracting temporal relations among events from unstructured text has\nextensive applications, such as temporal reasoning and question answering.\nWhile it is difficult, recent development of Neural-symbolic methods has shown\npromising results on solving similar tasks. Current temporal relation\nextraction methods usually suffer from limited expressivity and inconsistent\nrelation inference. For example, in TimeML annotations, the concept of\nintersection is absent. Additionally, current methods do not guarantee the\nconsistency among the predicted annotations. In this work, we propose SMARTER,\na neural semantic parser, to extract temporal information in text effectively.\nSMARTER parses natural language to an executable logical form representation,\nbased on a custom typed lambda calculus. In the training phase, dynamic\nprogramming on denotations (DPD) technique is used to provide weak supervision\non logical forms. In the inference phase, SMARTER generates a temporal relation\ngraph by executing the logical form. As a result, our neural semantic parser\nproduces logical forms capturing the temporal information of text precisely.\nThe accurate logical form representations of an event given the context ensure\nthe correctness of the extracted relations.",
    "descriptor": "",
    "authors": [
      "Bo-Ying Su",
      "Shang-Ling Hsu",
      "Kuan-Yin Lai",
      "Jane Yung-jen Hsu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00894"
  },
  {
    "id": "arXiv:2112.00900",
    "title": "Empirical Game-Theoretic Analysis in Mean Field Games",
    "abstract": "In this study, we demonstrate how empirical game-theoretical analysis (EGTA)\ncan be applied to mean field games (MFGs). Since the utility function of a MFG\nis not generally linear in the distribution of the population, it is\nimpractical to define an explicit payoff matrix for empirical game analysis as\nusual. Instead, we utilize query-based approaches without keeping an explicit\npayoff matrix. We propose an iterative EGTA framework to learn Nash equilibrium\n(NE) for MFGs and study the convergence of our algorithm from two aspects: the\nexistence of NE in the empirical MFG and the convergence of iterative EGTA to\nNE of the full MFG. We test the performance of iterative EGTA in various games\nand show its superior performance against Fictitious Play under some common\nassumptions in EGTA. Finally, we discuss the limitations of applying iterative\nEGTA to MFGs as well as potential future research directions.",
    "descriptor": "\nComments: 9 papes, 3 figures\n",
    "authors": [
      "Yongzhao Wang",
      "Michael P. Wellman"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.00900"
  },
  {
    "id": "arXiv:2112.00901",
    "title": "Hindsight Task Relabelling: Experience Replay for Sparse Reward Meta-RL",
    "abstract": "Meta-reinforcement learning (meta-RL) has proven to be a successful framework\nfor leveraging experience from prior tasks to rapidly learn new related tasks,\nhowever, current meta-RL approaches struggle to learn in sparse reward\nenvironments. Although existing meta-RL algorithms can learn strategies for\nadapting to new sparse reward tasks, the actual adaptation strategies are\nlearned using hand-shaped reward functions, or require simple environments\nwhere random exploration is sufficient to encounter sparse reward. In this\npaper, we present a formulation of hindsight relabeling for meta-RL, which\nrelabels experience during meta-training to enable learning to learn entirely\nusing sparse reward. We demonstrate the effectiveness of our approach on a\nsuite of challenging sparse reward goal-reaching environments that previously\nrequired dense reward during meta-training to solve. Our approach solves these\nenvironments using the true sparse reward function, with performance comparable\nto training with a proxy dense reward function.",
    "descriptor": "",
    "authors": [
      "Charles Packer",
      "Pieter Abbeel",
      "Joseph E. Gonzalez"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00901"
  },
  {
    "id": "arXiv:2112.00903",
    "title": "Modeling human intention inference in continuous 3D domains by inverse  planning and body kinematics",
    "abstract": "How to build AI that understands human intentions, and uses this knowledge to\ncollaborate with people? We describe a computational framework for evaluating\nmodels of goal inference in the domain of 3D motor actions, which receives as\ninput the 3D coordinates of an agent's body, and of possible targets, to\nproduce a continuously updated inference of the intended target. We evaluate\nour framework in three behavioural experiments using a novel Target Reaching\nTask, in which human observers infer intentions of actors reaching for targets\namong distracts. We describe Generative Body Kinematics model, which predicts\nhuman intention inference in this domain using Bayesian inverse planning and\ninverse body kinematics. We compare our model to three heuristics, which\nformalize the principle of least effort using simple assumptions about the\nactor's constraints, without the use of inverse planning. Despite being more\ncomputationally costly, the Generative Body Kinematics model outperforms the\nheuristics in certain scenarios, such as environments with obstacles, and at\nthe beginning of reaching actions while the actor is relatively far from the\nintended target. The heuristics make increasingly accurate predictions during\nlater stages of reaching actions, such as, when the intended target is close,\nand can be inferred by extrapolating the wrist trajectory. Our results identify\ncontexts in which inverse body kinematics is useful for intention inference. We\nshow that human observers indeed rely on inverse body kinematics in such\nscenarios, suggesting that modeling body kinematic can improve performance of\ninference algorithms.",
    "descriptor": "",
    "authors": [
      "Yingdong Qian",
      "Marta Kryven",
      "Tao Gao",
      "Hanbyul Joo",
      "Josh Tenenbaum"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00903"
  },
  {
    "id": "arXiv:2112.00905",
    "title": "CELLS: Cost-Effective Evolution in Latent Space for Goal-Directed  Molecular Generation",
    "abstract": "Efficiently discovering molecules that meet various property requirements can\nsignificantly benefit the drug discovery industry. Since it is infeasible to\nsearch over the entire chemical space, recent works adopt generative models for\ngoal-directed molecular generation. They tend to utilize the iterative\nprocesses, optimizing the parameters of the molecular generative models at each\niteration to produce promising molecules for further validation. Assessments\nare exploited to evaluate the generated molecules at each iteration, providing\ndirection for model optimization. However, most previous works require a\nmassive number of expensive and time-consuming assessments, e.g., wet\nexperiments and molecular dynamic simulations, leading to the lack of\npracticability. To reduce the assessments in the iterative process, we propose\na cost-effective evolution strategy in latent space, which optimizes the\nmolecular latent representation vectors instead. We adopt a pre-trained\nmolecular generative model to map the latent and observation spaces, taking\nadvantage of the large-scale unlabeled molecules to learn chemical knowledge.\nTo further reduce the number of expensive assessments, we introduce a\npre-screener as the proxy to the assessments. We conduct extensive experiments\non multiple optimization tasks comparing the proposed framework to several\nadvanced techniques, showing that the proposed framework achieves better\nperformance with fewer assessments.",
    "descriptor": "",
    "authors": [
      "Zhiyuan Chen",
      "Xiaomin Fang",
      "Fan Wang",
      "Xiaotian Fan",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.00905"
  },
  {
    "id": "arXiv:2112.00910",
    "title": "IMRecoNet: Learn to Detect in Index Modulation Aided MIMO Systems with  Complex Valued Neural Networks",
    "abstract": "Index modulation (IM) reduces the power consumption and hardware cost of the\nmultiple-input multiple-output (MIMO) system by activating part of the antennas\nfor data transmission. However, IM significantly increases the complexity of\nthe receiver and needs accurate channel estimation to guarantee its\nperformance. To tackle these challenges, in this paper, we design a deep\nlearning (DL) based detector for the IM aided MIMO (IM-MIMO) systems. We first\nformulate the detection process as a sparse reconstruction problem by utilizing\nthe inherent attributes of IM. Then, based on greedy strategy, we design a DL\nbased detector, called IMRecoNet, to realize this sparse reconstruction\nprocess. Different from the general neural networks, we introduce complex value\noperations to adapt the complex signals in communication systems. To the best\nof our knowledge, this is the first attempt that introduce complex valued\nneural network to the design of detector for the IM-MIMO systems. Finally, to\nverify the adaptability and robustness of the proposed detector, simulations\nare carried out with consideration of inaccurate channel state information\n(CSI) and correlated MIMO channels. The simulation results demonstrate that the\nproposed detector outperforms existing algorithms in terms of antenna\nrecognition accuracy and bit error rate under various scenarios.",
    "descriptor": "",
    "authors": [
      "Chenwu Zhang",
      "Hancheng Lu",
      "Jinxue Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.00910"
  },
  {
    "id": "arXiv:2112.00911",
    "title": "ProtGNN: Towards Self-Explaining Graph Neural Networks",
    "abstract": "Despite the recent progress in Graph Neural Networks (GNNs), it remains\nchallenging to explain the predictions made by GNNs. Existing explanation\nmethods mainly focus on post-hoc explanations where another explanatory model\nis employed to provide explanations for a trained GNN. The fact that post-hoc\nmethods fail to reveal the original reasoning process of GNNs raises the need\nof building GNNs with built-in interpretability. In this work, we propose\nPrototype Graph Neural Network (ProtGNN), which combines prototype learning\nwith GNNs and provides a new perspective on the explanations of GNNs. In\nProtGNN, the explanations are naturally derived from the case-based reasoning\nprocess and are actually used during classification. The prediction of ProtGNN\nis obtained by comparing the inputs to a few learned prototypes in the latent\nspace. Furthermore, for better interpretability and higher efficiency, a novel\nconditional subgraph sampling module is incorporated to indicate which part of\nthe input graph is most similar to each prototype in ProtGNN+. Finally, we\nevaluate our method on a wide range of datasets and perform concrete case\nstudies. Extensive results show that ProtGNN and ProtGNN+ can provide inherent\ninterpretability while achieving accuracy on par with the non-interpretable\ncounterparts.",
    "descriptor": "\nComments: Accepted by AAAI'22\n",
    "authors": [
      "Zaixi Zhang",
      "Qi Liu",
      "Hao Wang",
      "Chengqiang Lu",
      "Cheekong Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00911"
  },
  {
    "id": "arXiv:2112.00914",
    "title": "HyperSPNs: Compact and Expressive Probabilistic Circuits",
    "abstract": "Probabilistic circuits (PCs) are a family of generative models which allows\nfor the computation of exact likelihoods and marginals of its probability\ndistributions. PCs are both expressive and tractable, and serve as popular\nchoices for discrete density estimation tasks. However, large PCs are\nsusceptible to overfitting, and only a few regularization strategies (e.g.,\ndropout, weight-decay) have been explored. We propose HyperSPNs: a new paradigm\nof generating the mixture weights of large PCs using a small-scale neural\nnetwork. Our framework can be viewed as a soft weight-sharing strategy, which\ncombines the greater expressiveness of large models with the better\ngeneralization and memory-footprint properties of small models. We show the\nmerits of our regularization strategy on two state-of-the-art PC families\nintroduced in recent literature -- RAT-SPNs and EiNETs -- and demonstrate\ngeneralization improvements in both models on a suite of density estimation\nbenchmarks in both discrete and continuous domains.",
    "descriptor": "\nComments: In Advances in Neural Information Processing Systems 34 (NeurIPS), 2021\n",
    "authors": [
      "Andy Shih",
      "Dorsa Sadigh",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00914"
  },
  {
    "id": "arXiv:2112.00925",
    "title": "Context-Aware Online Client Selection for Hierarchical Federated  Learning",
    "abstract": "Federated Learning (FL) has been considered as an appealing framework to\ntackle data privacy issues of mobile devices compared to conventional Machine\nLearning (ML). Using Edge Servers (ESs) as intermediaries to perform model\naggregation in proximity can reduce the transmission overhead, and it enables\ngreat potentials in low-latency FL, where the hierarchical architecture of FL\n(HFL) has been attracted more attention. Designing a proper client selection\npolicy can significantly improve training performance, and it has been\nextensively used in FL studies. However, to the best of our knowledge, there\nare no studies focusing on HFL. In addition, client selection for HFL faces\nmore challenges than conventional FL, e.g., the time-varying connection of\nclient-ES pairs and the limited budget of the Network Operator (NO). In this\npaper, we investigate a client selection problem for HFL, where the NO learns\nthe number of successful participating clients to improve the training\nperformance (i.e., select as many clients in each round) as well as under the\nlimited budget on each ES. An online policy, called Context-aware Online Client\nSelection (COCS), is developed based on Contextual Combinatorial Multi-Armed\nBandit (CC-MAB). COCS observes the side-information (context) of local\ncomputing and transmission of client-ES pairs and makes client selection\ndecisions to maximize NO's utility given a limited budget. Theoretically, COCS\nachieves a sublinear regret compared to an Oracle policy on both strongly\nconvex and non-convex HFL. Simulation results also support the efficiency of\nthe proposed COCS policy on real-world datasets.",
    "descriptor": "",
    "authors": [
      "Zhe Qu",
      "Rui Duan",
      "Lixing Chen",
      "Jie Xu",
      "Zhuo Lu",
      "Yao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.00925"
  },
  {
    "id": "arXiv:2112.00926",
    "title": "Long-Term Recurrent Convolutional Network-based Inertia Estimation using  Ambient Measurements",
    "abstract": "Conventional synchronous machines are gradually replaced by converter-based\nrenewable resources. As a result, synchronous inertia, an important\ntime-varying quantity, has substantially more impact on modern power systems\nstability. The increasing integration of renewable energy resources imports\ndifferent dynamics into traditional power systems; therefore, the estimation of\nsystem inertia using mathematical model becomes more difficult. In this paper,\nwe propose a novel learning-assisted inertia estimation model based on\nlong-term recurrent convolutional network (LRCN) that uses system wide\nfrequency and phase voltage measurements. The proposed approach uses a\nnon-intrusive probing signal to perturb the system and collects ambient\nmeasurements with phasor measurement units (PMU) to train the proposed LRCN\nmodel. Case studies are conducted on the IEEE 24-bus system. Under a\nsignal-to-noise ratio (SNR) of 60dB condition, the proposed LRCN based inertia\nestimation model achieves an accuracy of 97.56% with a mean squared error (MSE)\nof 0.0552. Furthermore, with a low SNR of 45dB, the proposed learning-assisted\ninertia estimation model is still able to achieve a high accuracy of 93.07%.",
    "descriptor": "",
    "authors": [
      "Mingjian Tuo",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00926"
  },
  {
    "id": "arXiv:2112.00931",
    "title": "Antenna Selection in Polarization Reconfigurable MIMO (PR-MIMO)  Communication Systems",
    "abstract": "Adaptation of a wireless system to the polarization state of the propagation\nchannel can improve reliability and throughput. This paper in particular\nconsiders polarization reconfigurable multiple input multiple output (PR-MIMO)\nsystems, where both transmitter and receiver can change the (linear)\npolarization orientation at each element of their antenna arrays. We first\nintroduce joint polarization pre-post coding to maximize bounds on the capacity\nand the maximum eigenvalue of the channel matrix. For this we first derive\napproximate closed form equations of optimal polarization vectors at one link\nend, and then use iterative joint polarization pre-post coding to pursue joint\noptimal polarization vectors at both link ends. Next we investigate the\ncombination of PR-MIMO with hybrid antenna selection / maximum ratio\ntransmission (PR-HS/MRT), which can achieve a remarkable improvement of channel\ncapacity and symbol error rate (SER). Further, two novel schemes of element\nwise and global polarization reconfiguration are presented for PR-HS/MRT.\nComprehensive simulation results indicate that the proposed schemes provide 3\nto 5 dB SNR gain in PR-MIMO spatial multiplexing and approximately 3 dB SNR\ngain in PRHS/ MRT, with concomitant improvements of channel capacity and SER.",
    "descriptor": "",
    "authors": [
      "Paul S. Oh",
      "Sean S. Kwon",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.00931"
  },
  {
    "id": "arXiv:2112.00932",
    "title": "Multi-fidelity methods for uncertainty propagation in kinetic equations",
    "abstract": "The construction of efficient methods for uncertainty quantification in\nkinetic equations represents a challenge due to the high dimensionality of the\nmodels: often the computational costs involved become prohibitive. On the other\nhand, precisely because of the curse of dimensionality, the construction of\nsimplified models capable of providing approximate solutions at a\ncomputationally reduced cost has always represented one of the main research\nstrands in the field of kinetic equations. Approximations based on suitable\nclosures of the moment equations or on simplified collisional models have been\nstudied by many authors. In the context of uncertainty quantification, it is\ntherefore natural to take advantage of such models in a multi-fidelity setting\nwhere the original kinetic equation represents the high-fidelity model, and the\nsimplified models define the low-fidelity surrogate models. The scope of this\narticle is to survey some recent results about multi-fidelity methods for\nkinetic equations that are able to accelerate the solution of the uncertainty\nquantification process by combining high-fidelity and low-fidelity model\nevaluations with particular attention to the case of compressible and\nincompressible hydrodynamic limits. We will focus essentially on two classes of\nstrategies: multi-fidelity control variates methods and bi-fidelity stochastic\ncollocation methods. The various approaches considered are analyzed in light of\nthe different surrogate models used and the different numerical techniques\nadopted. Given the relevance of the specific choice of the surrogate model, an\napplication-oriented approach has been chosen in the presentation.",
    "descriptor": "",
    "authors": [
      "Giacomo Dimarco",
      "Liu Liu",
      "Lorenzo Pareschi",
      "Xueyu Zhu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.00932"
  },
  {
    "id": "arXiv:2112.00933",
    "title": "PartImageNet: A Large, High-Quality Dataset of Parts",
    "abstract": "A part-based object understanding facilitates efficient compositional\nlearning and knowledge transfer, robustness to occlusion, and has the potential\nto increase the performance on general recognition and localization tasks.\nHowever, research on part-based models is hindered due to the lack of datasets\nwith part annotations, which is caused by the extreme difficulty and high cost\nof annotating object parts in images. In this paper, we propose PartImageNet, a\nlarge, high-quality dataset with part segmentation annotations. It consists of\n158 classes from ImageNet with approximately 24000 images. PartImageNet is\nunique because it offers part-level annotations on a general set of classes\nwith non-rigid, articulated objects, while having an order of magnitude larger\nsize compared to existing datasets. It can be utilized in multiple vision tasks\nincluding but not limited to: Part Discovery, Semantic Segmentation, Few-shot\nLearning. Comprehensive experiments are conducted to set up a set of baselines\non PartImageNet and we find that existing works on part discovery can not\nalways produce satisfactory results during complex variations. The exploit of\nparts on downstream tasks also remains insufficient. We believe that our\nPartImageNet will greatly facilitate the research on part-based models and\ntheir applications. The dataset and scripts will soon be released at\nhttps://github.com/TACJu/PartImageNet.",
    "descriptor": "",
    "authors": [
      "Ju He",
      "Shuo Yang",
      "Shaokang Yang",
      "Adam Kortylewski",
      "Xiaoding Yuan",
      "Jie-Neng Chen",
      "Shuai Liu",
      "Cheng Yang",
      "Alan Yuille"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00933"
  },
  {
    "id": "arXiv:2112.00940",
    "title": "Reward-Free Attacks in Multi-Agent Reinforcement Learning",
    "abstract": "We investigate how effective an attacker can be when it only learns from its\nvictim's actions, without access to the victim's reward. In this work, we are\nmotivated by the scenario where the attacker wants to behave strategically when\nthe victim's motivations are unknown. We argue that one heuristic approach an\nattacker can use is to maximize the entropy of the victim's policy. The policy\nis generally not obfuscated, which implies it may be extracted simply by\npassively observing the victim. We provide such a strategy in the form of a\nreward-free exploration algorithm that maximizes the attacker's entropy during\nthe exploration phase, and then maximizes the victim's empirical entropy during\nthe planning phase. In our experiments, the victim agents are subverted through\npolicy entropy maximization, implying an attacker might not need access to the\nvictim's reward to succeed. Hence, reward-free attacks, which are based only on\nobserving behavior, show the feasibility of an attacker to act strategically\nwithout knowledge of the victim's motives even if the victim's reward\ninformation is protected.",
    "descriptor": "\nComments: Presented at the NeurIPS 2021 Workshop on Learning in Presence of Strategic Behavior\n",
    "authors": [
      "Ted Fujimoto",
      "Timothy Doster",
      "Adam Attarian",
      "Jill Brandenberger",
      "Nathan Hodas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.00940"
  },
  {
    "id": "arXiv:2112.00941",
    "title": "Generalized Closed-form Formulae for Feature-based Subpixel Alignment in  Patch-based Matching",
    "abstract": "Cost-based image patch matching is at the core of various techniques in\ncomputer vision, photogrammetry and remote sensing. When the subpixel disparity\nbetween the reference patch in the source and target images is required, either\nthe cost function or the target image have to be interpolated. While cost-based\ninterpolation is the easiest to implement, multiple works have shown that image\nbased interpolation can increase the accuracy of the subpixel matching, but\nusually at the cost of expensive search procedures. This, however, is\nproblematic, especially for very computation intensive applications such as\nstereo matching or optical flow computation. In this paper, we show that closed\nform formulae for subpixel disparity computation for the case of one\ndimensional matching, e.g., in the case of rectified stereo images where the\nsearch space is of one dimension, exists when using the standard NCC, SSD and\nSAD cost functions. We then demonstrate how to generalize the proposed formulae\nto the case of high dimensional search spaces, which is required for\nunrectified stereo matching and optical flow extraction. We also compare our\nresults with traditional cost volume interpolation formulae as well as with\nstate-of-the-art cost-based refinement methods, and show that the proposed\nformulae bring a small improvement over the state-of-the-art cost-based methods\nin the case of one dimensional search spaces, and a significant improvement\nwhen the search space is two dimensional.",
    "descriptor": "\nComments: 13 pages, 12 figures\n",
    "authors": [
      "Laurent Valentin Jospin",
      "Farid Boussaid",
      "Hamid Laga",
      "Mohammed Bennamoun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00941"
  },
  {
    "id": "arXiv:2112.00942",
    "title": "On Salience-Sensitive Sign Classification in Autonomous Vehicle Path  Planning: Experimental Explorations with a Novel Dataset",
    "abstract": "Safe path planning in autonomous driving is a complex task due to the\ninterplay of static scene elements and uncertain surrounding agents. While all\nstatic scene elements are a source of information, there is asymmetric\nimportance to the information available to the ego vehicle. We present a\ndataset with a novel feature, sign salience, defined to indicate whether a sign\nis distinctly informative to the goals of the ego vehicle with regards to\ntraffic regulations. Using convolutional networks on cropped signs, in tandem\nwith experimental augmentation by road type, image coordinates, and planned\nmaneuver, we predict the sign salience property with 76% accuracy, finding the\nbest improvement using information on vehicle maneuver with sign images.",
    "descriptor": "",
    "authors": [
      "Ross Greer",
      "Jason Isa",
      "Nachiket Deo",
      "Akshay Rangesh",
      "Mohan M. Trivedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00942"
  },
  {
    "id": "arXiv:2112.00944",
    "title": "Tiny-NewsRec: Efficient and Effective PLM-based News Recommendation",
    "abstract": "Personalized news recommendation has been widely adopted to improve user\nexperience. Recently, pre-trained language models (PLMs) have demonstrated the\ngreat capability of natural language understanding and the potential of\nimproving news modeling for news recommendation. However, existing PLMs are\nusually pre-trained on general corpus such as BookCorpus and Wikipedia, which\nhave some gaps with the news domain. Directly finetuning PLMs with the news\nrecommendation task may be sub-optimal for news understanding. Besides, PLMs\nusually contain a large volume of parameters and have high computational\noverhead, which imposes a great burden on the low-latency online services. In\nthis paper, we propose Tiny-NewsRec, which can improve both the effectiveness\nand the efficiency of PLM-based news recommendation. In order to reduce the\ndomain gap between general corpora and the news data, we propose a\nself-supervised domain-specific post-training method to adapt the generally\npre-trained language models to the news domain with the task of news title and\nnews body matching. To improve the efficiency of PLM-based news recommendation\nwhile maintaining the performance, we propose a two-stage knowledge\ndistillation method. In the first stage, we use the domain-specific teacher PLM\nto guide the student model for news semantic modeling. In the second stage, we\nuse a multi-teacher knowledge distillation framework to transfer the\ncomprehensive knowledge from a set of teacher models finetuned for news\nrecommendation to the student. Experiments on two real-world datasets show that\nour methods can achieve better performance in news recommendation with smaller\nmodels.",
    "descriptor": "\nComments: 11 pages, 10 figures\n",
    "authors": [
      "Yang Yu",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Jingwei Yi",
      "Tao Qi",
      "Qi Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.00944"
  },
  {
    "id": "arXiv:2112.00945",
    "title": "DPVI: A Dynamic-Weight Particle-Based Variational Inference Framework",
    "abstract": "The recently developed Particle-based Variational Inference (ParVI) methods\ndrive the empirical distribution of a set of \\emph{fixed-weight} particles\ntowards a given target distribution $\\pi$ by iteratively updating particles'\npositions. However, the fixed weight restriction greatly confines the empirical\ndistribution's approximation ability, especially when the particle number is\nlimited. In this paper, we propose to dynamically adjust particles' weights\naccording to a Fisher-Rao reaction flow. We develop a general Dynamic-weight\nParticle-based Variational Inference (DPVI) framework according to a novel\ncontinuous composite flow, which evolves the positions and weights of particles\nsimultaneously. We show that the mean-field limit of our composite flow is\nactually a Wasserstein-Fisher-Rao gradient flow of certain dissimilarity\nfunctional $\\mathcal{F}$, which leads to a faster decrease of $\\mathcal{F}$\nthan the Wasserstein gradient flow underlying existing fixed-weight ParVIs. By\nusing different finite-particle approximations in our general framework, we\nderive several efficient DPVI algorithms. The empirical results demonstrate the\nsuperiority of our derived DPVI algorithms over their fixed-weight\ncounterparts.",
    "descriptor": "",
    "authors": [
      "Chao Zhang",
      "Zhijian Li",
      "Hui Qian",
      "Xin Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00945"
  },
  {
    "id": "arXiv:2112.00948",
    "title": "Visual-Semantic Transformer for Scene Text Recognition",
    "abstract": "Modeling semantic information is helpful for scene text recognition. In this\nwork, we propose to model semantic and visual information jointly with a\nVisual-Semantic Transformer (VST). The VST first explicitly extracts primary\nsemantic information from visual feature maps with a transformer module and a\nprimary visual-semantic alignment module. The semantic information is then\njoined with the visual feature maps (viewed as a sequence) to form a pseudo\nmulti-domain sequence combining visual and semantic information, which is\nsubsequently fed into an transformer-based interaction module to enable\nlearning of interactions between visual and semantic features. In this way, the\nvisual features can be enhanced by the semantic information and vice versus.\nThe enhanced version of visual features are further decoded by a secondary\nvisual-semantic alignment module which shares weights with the primary one.\nFinally, the decoded visual features and the enhanced semantic features are\njointly processed by the third transformer module obtaining the final text\nprediction. Experiments on seven public benchmarks including regular/ irregular\ntext recognition datasets verifies the effectiveness our proposed model,\nreaching state of the art on four of the seven benchmarks.",
    "descriptor": "",
    "authors": [
      "Xin Tang",
      "Yongquan Lai",
      "Ying Liu",
      "Yuanyuan Fu",
      "Rui Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00948"
  },
  {
    "id": "arXiv:2112.00950",
    "title": "Quantile Filtered Imitation Learning",
    "abstract": "We introduce quantile filtered imitation learning (QFIL), a novel policy\nimprovement operator designed for offline reinforcement learning. QFIL performs\npolicy improvement by running imitation learning on a filtered version of the\noffline dataset. The filtering process removes $ s,a $ pairs whose estimated Q\nvalues fall below a given quantile of the pushforward distribution over values\ninduced by sampling actions from the behavior policy. The definitions of both\nthe pushforward Q distribution and resulting value function quantile are key\ncontributions of our method. We prove that QFIL gives us a safe policy\nimprovement step with function approximation and that the choice of quantile\nprovides a natural hyperparameter to trade off bias and variance of the\nimprovement step. Empirically, we perform a synthetic experiment illustrating\nhow QFIL effectively makes a bias-variance tradeoff and we see that QFIL\nperforms well on the D4RL benchmark.",
    "descriptor": "\nComments: Offline Reinforcement Learning Workshop at Neural Information Processing Systems, 2021\n",
    "authors": [
      "David Brandfonbrener",
      "William F. Whitney",
      "Rajesh Ranganath",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00950"
  },
  {
    "id": "arXiv:2112.00952",
    "title": "A Discrete-event-based Simulator for Deep Learning at Edge",
    "abstract": "Novel smart environments, such as smart home, smart city, and intelligent\ntransportation, are driving increasing interest in deploying deep neural\nnetworks (DNN) at edge devices. Unfortunately, deploying DNN on\nresource-constrained edge devices poses a huge challenge. If a simulator can\ninteract with deep learning frameworks, it can facilitate researches on deep\nlearning at edge. The existing simulation frameworks, such as Matlab, NS-3,\netc., haven't been extended to support simulations of edge learning. To support\nlarge-scale training simulations on edge nodes, we propose a\ndiscrete-event-based edge learning simulator. It includes a deep learning\nmodule and a network simulation module. Specifically, it enable simulations as\nan environment for deep learning. Our framework is generic and can be used in\nvarious deep learning problems before the deep learning model is deployed. In\nthis paper, we give the design and implementation details of the\ndiscrete-event-based learning simulator and present an illustrative use case of\nthe proposed simulator.",
    "descriptor": "\nComments: 6 pages,conference\n",
    "authors": [
      "Xiaoyan Liu",
      "Zhiwei Xu",
      "Yana Qin",
      "Jie Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.00952"
  },
  {
    "id": "arXiv:2112.00953",
    "title": "Maximum Consensus by Weighted Influences of Monotone Boolean Functions",
    "abstract": "Robust model fitting is a fundamental problem in computer vision: used to\npre-process raw data in the presence of outliers. Maximisation of Consensus\n(MaxCon) is one of the most popular robust criteria and widely used. Recently\n(Tennakoon et al. CVPR2021), a connection has been made between MaxCon and\nestimation of influences of a Monotone Boolean function. Equipping the Boolean\ncube with different measures and adopting different sampling strategies (two\nsides of the same coin) can have differing effects: which leads to the current\nstudy. This paper studies the concept of weighted influences for solving\nMaxCon. In particular, we study endowing the Boolean cube with the Bernoulli\nmeasure and performing biased (as opposed to uniform) sampling. Theoretically,\nwe prove the weighted influences, under this measure, of points belonging to\nlarger structures are smaller than those of points belonging to smaller\nstructures in general. We also consider another \"natural\" family of\nsampling/weighting strategies, sampling with uniform measure concentrated on a\nparticular (Hamming) level of the cube.\nBased on weighted sampling, we modify the algorithm of Tennakoon et al., and\ntest on both synthetic and real datasets. This paper is not promoting a new\napproach per se, but rather studying the issue of weighted sampling.\nAccordingly, we are not claiming to have produced a superior algorithm: rather\nwe show some modest gains of Bernoulli sampling, and we illuminate some of the\ninteractions between structure in data and weighted sampling.",
    "descriptor": "",
    "authors": [
      "Erchuan Zhang",
      "David Suter",
      "Ruwan Tennakoon",
      "Tat-Jun Chin",
      "Alireza Bab-Hadiashar",
      "Giang Truong",
      "Syed Zulqarnain Gilani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00953"
  },
  {
    "id": "arXiv:2112.00954",
    "title": "Temporally Resolution Decrement: Utilizing the Shape Consistency for  Higher Computational Efficiency",
    "abstract": "Image resolution that has close relations with accuracy and computational\ncost plays a pivotal role in network training. In this paper, we observe that\nthe reduced image retains relatively complete shape semantics but loses\nextensive texture information. Inspired by the consistency of the shape\nsemantics as well as the fragility of the texture information, we propose a\nnovel training strategy named Temporally Resolution Decrement. Wherein, we\nrandomly reduce the training images to a smaller resolution in the time domain.\nDuring the alternate training with the reduced images and the original images,\nthe unstable texture information in the images results in a weaker correlation\nbetween the texture-related patterns and the correct label, naturally enforcing\nthe model to rely more on shape properties that are robust and conform to the\nhuman decision rule. Surprisingly, our approach greatly improves the\ncomputational efficiency of convolutional neural networks. On ImageNet\nclassification, using only 33% calculation quantity (randomly reducing the\ntraining image to 112$\\times$112 within 90% epochs) can still improve ResNet-50\nfrom 76.32% to 77.71%, and using 63% calculation quantity (randomly reducing\nthe training image to 112 x 112 within 50% epochs) can improve ResNet-50 to\n78.18%.",
    "descriptor": "",
    "authors": [
      "Tianshu Xie",
      "Xuan Cheng",
      "Minghui Liu",
      "Jiali Deng",
      "Xiaomin Wang",
      "Ming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00954"
  },
  {
    "id": "arXiv:2112.00955",
    "title": "Source Free Unsupervised Graph Domain Adaptation",
    "abstract": "Graph Neural Networks (GNNs) have achieved great success on a variety of\ntasks with graph-structural data, among which node classification is an\nessential one. Unsupervised Graph Domain Adaptation (UGDA) shows its practical\nvalue of reducing the labeling cost for node classification. It leverages\nknowledge from a labeled graph (i.e., source domain) to tackle the same task on\nanother unlabeled graph (i.e., target domain). Most existing UGDA methods\nheavily rely on the labeled graph in the source domain. They utilize labels\nfrom the source domain as the supervision signal and are jointly trained on\nboth the source graph and the target graph. However, in some real-world\nscenarios, the source graph is inaccessible because of either unavailability or\nprivacy issues. Therefore, we propose a novel scenario named Source Free\nUnsupervised Graph Domain Adaptation (SFUGDA). In this scenario, the only\ninformation we can leverage from the source domain is the well-trained source\nmodel, without any exposure to the source graph and its labels. As a result,\nexisting UGDA methods are not feasible anymore. To address the non-trivial\nadaptation challenges in this practical scenario, we propose a model-agnostic\nalgorithm for domain adaptation to fully exploit the discriminative ability of\nthe source model while preserving the consistency of structural proximity on\nthe target graph. We prove the effectiveness of the proposed algorithm both\ntheoretically and empirically. The experimental results on four cross-domain\ntasks show consistent improvements of the Macro-F1 score up to 0.17.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Haitao Mao",
      "Lun Du",
      "Yujia Zheng",
      "Qiang Fu",
      "Zelin Li",
      "Xu Chen",
      "Han Shi",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00955"
  },
  {
    "id": "arXiv:2112.00956",
    "title": "Personalized Federated Learning of Driver Prediction Models for  Autonomous Driving",
    "abstract": "Autonomous vehicles (AVs) must interact with a diverse set of human drivers\nin heterogeneous geographic areas. Ideally, fleets of AVs should share\ntrajectory data to continually re-train and improve trajectory forecasting\nmodels from collective experience using cloud-based distributed learning. At\nthe same time, these robots should ideally avoid uploading raw driver\ninteraction data in order to protect proprietary policies (when sharing\ninsights with other companies) or protect driver privacy from insurance\ncompanies. Federated learning (FL) is a popular mechanism to learn models in\ncloud servers from diverse users without divulging private local data. However,\nFL is often not robust -- it learns sub-optimal models when user data comes\nfrom highly heterogeneous distributions, which is a key hallmark of human-robot\ninteractions. In this paper, we present a novel variant of personalized FL to\nspecialize robust robot learning models to diverse user distributions. Our\nalgorithm outperforms standard FL benchmarks by up to 2x in real user studies\nthat we conducted where human-operated vehicles must gracefully merge lanes\nwith simulated AVs in the standard CARLA and CARLO AV simulators.",
    "descriptor": "",
    "authors": [
      "Manabu Nakanoya",
      "Junha Im",
      "Hang Qiu",
      "Sachin Katti",
      "Marco Pavone",
      "Sandeep Chinchali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00956"
  },
  {
    "id": "arXiv:2112.00958",
    "title": "Hierarchical Neural Implicit Pose Network for Animation and Motion  Retargeting",
    "abstract": "We present HIPNet, a neural implicit pose network trained on multiple\nsubjects across many poses. HIPNet can disentangle subject-specific details\nfrom pose-specific details, effectively enabling us to retarget motion from one\nsubject to another or to animate between keyframes through latent space\ninterpolation. To this end, we employ a hierarchical skeleton-based\nrepresentation to learn a signed distance function on a canonical unposed\nspace. This joint-based decomposition enables us to represent subtle details\nthat are local to the space around the body joint. Unlike previous neural\nimplicit method that requires ground-truth SDF for training, our model we only\nneed a posed skeleton and the point cloud for training, and we have no\ndependency on a traditional parametric model or traditional skinning\napproaches. We achieve state-of-the-art results on various single-subject and\nmulti-subject benchmarks.",
    "descriptor": "",
    "authors": [
      "Sourav Biswas",
      "Kangxue Yin",
      "Maria Shugrina",
      "Sanja Fidler",
      "Sameh Khamis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00958"
  },
  {
    "id": "arXiv:2112.00962",
    "title": "Large-Scale Data Mining of Rapid Residue Detection Assay Data From HTML  and PDF Documents: Improving Data Access and Visualization for Veterinarians",
    "abstract": "Extra-label drug use in food animal medicine is authorized by the US Animal\nMedicinal Drug Use Clarification Act (AMDUCA), and estimated withdrawal\nintervals are based on published scientific pharmacokinetic data. Occasionally\nthere is a paucity of scientific data on which to base a withdrawal interval or\na large number of animals being treated, driving the need to test for drug\nresidues. Rapid assay commercial farm-side tests are essential for monitoring\ndrug residues in animal products to protect human health. Active ingredients,\nsensitivity, matrices, and species that have been evaluated for commercial\nrapid assay tests are typically reported on manufacturers' websites or in PDF\ndocuments that are available to consumers but may require a special access\nrequest. Additionally, this information is not always correlated with\nFDA-approved tolerances. Furthermore, parameter changes for these tests can be\nvery challenging to regularly identify, especially those listed on websites or\nin documents that are not publicly available. Therefore, artificial\nintelligence plays a critical role in efficiently extracting the data and\nensure current information. Extracting tables from PDF and HTML documents has\nbeen investigated both by academia and commercial tool builders. Research in\ntext mining of such documents has become a widespread yet challenging arena in\nimplementing natural language programming. However, techniques of extracting\ntables are still in their infancy and being investigated and improved by\nresearchers. In this study, we developed and evaluated a data-mining method for\nautomatically extracting rapid assay data from electronic documents. Our\nautomatic electronic data extraction method includes a software package module,\na developed pattern recognition tool, and a data mining engine. Assay details\nwere provided by several commercial entities that produce these rapid drug\nresidue assay",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Majid Jaberi-Douraki",
      "Soudabeh Taghian Dinani",
      "Nuwan Indika Millagaha Gedara",
      "Xuan Xu",
      "Emily Richards",
      "Fiona Maunsell",
      "Nader Zad",
      "Lisa Ann Tell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00962"
  },
  {
    "id": "arXiv:2112.00963",
    "title": "Multi-Domain Transformer-Based Counterfactual Augmentation for Earnings  Call Analysis",
    "abstract": "Earnings call (EC), as a periodic teleconference of a publicly-traded\ncompany, has been extensively studied as an essential market indicator because\nof its high analytical value in corporate fundamentals. The recent emergence of\ndeep learning techniques has shown great promise in creating automated\npipelines to benefit the EC-supported financial applications. However, these\nmethods presume all included contents to be informative without refining\nvaluable semantics from long-text transcript and suffer from EC scarcity issue.\nMeanwhile, these black-box methods possess inherent difficulties in providing\nhuman-understandable explanations. To this end, in this paper, we propose a\nMulti-Domain Transformer-Based Counterfactual Augmentation, named MTCA, to\naddress the above problems. Specifically, we first propose a transformer-based\nEC encoder to attentively quantify the task-inspired significance of critical\nEC content for market inference. Then, a multi-domain counterfactual learning\nframework is developed to evaluate the gradient-based variations after we\nperturb limited EC informative texts with plentiful cross-domain documents,\nenabling MTCA to perform unsupervised data augmentation. As a bonus, we\ndiscover a way to use non-training data as instance-based explanations for\nwhich we show the result with case studies. Extensive experiments on the\nreal-world financial datasets demonstrate the effectiveness of interpretable\nMTCA for improving the volatility evaluation ability of the state-of-the-art by\n14.2\\% in accuracy.",
    "descriptor": "",
    "authors": [
      "Zixuan Yuan",
      "Yada Zhu",
      "Wei Zhang",
      "Ziming Huang",
      "Guangnan Ye",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.00963"
  },
  {
    "id": "arXiv:2112.00964",
    "title": "A Survey on Scenario-Based Testing for Automated Driving Systems in  High-Fidelity Simulation",
    "abstract": "Automated Driving Systems (ADSs) have seen rapid progress in recent years. To\nensure the safety and reliability of these systems, extensive testings are\nbeing conducted before their future mass deployment. Testing the system on the\nroad is the closest to real-world and desirable approach, but it is incredibly\ncostly. Also, it is infeasible to cover rare corner cases using such real-world\ntesting. Thus, a popular alternative is to evaluate an ADS's performance in\nsome well-designed challenging scenarios, a.k.a. scenario-based testing.\nHigh-fidelity simulators have been widely used in this setting to maximize\nflexibility and convenience in testing what-if scenarios. Although many works\nhave been proposed offering diverse frameworks/methods for testing specific\nsystems, the comparisons and connections among these works are still missing.\nTo bridge this gap, in this work, we provide a generic formulation of\nscenario-based testing in high-fidelity simulation and conduct a literature\nreview on the existing works. We further compare them and present the open\nchallenges as well as potential future research directions.",
    "descriptor": "",
    "authors": [
      "Ziyuan Zhong",
      "Yun Tang",
      "Yuan Zhou",
      "Vania de Oliveira Neves",
      "Yang Liu",
      "Baishakhi Ray"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00964"
  },
  {
    "id": "arXiv:2112.00965",
    "title": "Vision Pair Learning: An Efficient Training Framework for Image  Classification",
    "abstract": "Transformer is a potentially powerful architecture for vision tasks. Although\nequipped with more parameters and attention mechanism, its performance is not\nas dominant as CNN currently. CNN is usually computationally cheaper and still\nthe leading competitor in various vision tasks. One research direction is to\nadopt the successful ideas of CNN and improve transformer, but it often relies\non elaborated and heuristic network design. Observing that transformer and CNN\nare complementary in representation learning and convergence speed, we propose\nan efficient training framework called Vision Pair Learning (VPL) for image\nclassification task. VPL builds up a network composed of a transformer branch,\na CNN branch and pair learning module. With multi-stage training strategy, VPL\nenables the branches to learn from their partners during the appropriate stage\nof the training process, and makes them both achieve better performance with\nless time cost. Without external data, VPL promotes the top-1 accuracy of\nViT-Base and ResNet-50 on the ImageNet-1k validation set to 83.47% and 79.61%\nrespectively. Experiments on other datasets of various domains prove the\nefficacy of VPL and suggest that transformer performs better when paired with\nthe differently structured CNN in VPL. we also analyze the importance of\ncomponents through ablation study.",
    "descriptor": "",
    "authors": [
      "Bei Tong",
      "Xiaoyuan Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00965"
  },
  {
    "id": "arXiv:2112.00967",
    "title": "Relational Graph Learning for Grounded Video Description Generation",
    "abstract": "Grounded video description (GVD) encourages captioning models to attend to\nappropriate video regions (e.g., objects) dynamically and generate a\ndescription. Such a setting can help explain the decisions of captioning models\nand prevents the model from hallucinating object words in its description.\nHowever, such design mainly focuses on object word generation and thus may\nignore fine-grained information and suffer from missing visual concepts.\nMoreover, relational words (e.g., \"jump left or right\") are usual\nspatio-temporal inference results, i.e., these words cannot be grounded on\ncertain spatial regions. To tackle the above limitations, we design a novel\nrelational graph learning framework for GVD, in which a language-refined scene\ngraph representation is designed to explore fine-grained visual concepts.\nFurthermore, the refined graph can be regarded as relational inductive\nknowledge to assist captioning models in selecting the relevant information it\nneeds to generate correct words. We validate the effectiveness of our model\nthrough automatic metrics and human evaluation, and the results indicate that\nour approach can generate more fine-grained and accurate description, and it\nsolves the problem of object hallucination to some extent.",
    "descriptor": "\nComments: 10 pages, 5 figures, ACM MM 2020\n",
    "authors": [
      "Wenqiao Zhang",
      "Xin Eric Wang",
      "Siliang Tang",
      "Haizhou Shi",
      "Haocheng Shi",
      "Jun Xiao",
      "Yueting Zhuang",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00967"
  },
  {
    "id": "arXiv:2112.00969",
    "title": "Object-Centric Unsupervised Image Captioning",
    "abstract": "Training an image captioning model in an unsupervised manner without\nutilizing annotated image-caption pairs is an important step towards tapping\ninto a wider corpus of text and images. In the supervised setting,\nimage-caption pairs are \"well-matched\", where all objects mentioned in the\nsentence appear in the corresponding image. These pairings are, however, not\navailable in the unsupervised setting. To overcome this, a main school of\nresearch that has been shown to be effective in overcoming this is to construct\npairs from the images and texts in the training set according to their overlap\nof objects. Unlike in the supervised setting, these constructed pairings are\nhowever not guaranteed to have fully overlapping set of objects. Our work in\nthis paper overcomes this by harvesting objects corresponding to a given\nsentence from the training set, even if they don't belong to the same image.\nWhen used as input to a transformer, such mixture of objects enable larger if\nnot full object coverage, and when supervised by the corresponding sentence,\nproduced results that outperform current state of the art unsupervised methods\nby a significant margin. Building upon this finding, we further show that (1)\nadditional information on relationship between objects and attributes of\nobjects also helps in boosting performance; and (2) our method also extends\nwell to non-English image captioning, which usually suffers from a scarcer\nlevel of annotations. Our findings are supported by strong empirical results.",
    "descriptor": "",
    "authors": [
      "Zihang Meng",
      "David Yang",
      "Xuefei Cao",
      "Ashish Shah",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00969"
  },
  {
    "id": "arXiv:2112.00970",
    "title": "Narrative Cartography with Knowledge Graphs",
    "abstract": "Narrative cartography is a discipline which studies the interwoven nature of\nstories and maps. However, conventional geovisualization techniques of\nnarratives often encounter several prominent challenges, including the data\nacquisition & integration challenge and the semantic challenge. To tackle these\nchallenges, in this paper, we propose the idea of narrative cartography with\nknowledge graphs (KGs). Firstly, to tackle the data acquisition & integration\nchallenge, we develop a set of KG-based GeoEnrichment toolboxes to allow users\nto search and retrieve relevant data from integrated cross-domain knowledge\ngraphs for narrative mapping from within a GISystem. With the help of this\ntool, the retrieved data from KGs are directly materialized in a GIS format\nwhich is ready for spatial analysis and mapping. Two use cases - Magellan's\nexpedition and World War II - are presented to show the effectiveness of this\napproach. In the meantime, several limitations are identified from this\napproach, such as data incompleteness, semantic incompatibility, and the\nsemantic challenge in geovisualization. For the later two limitations, we\npropose a modular ontology for narrative cartography, which formalizes both the\nmap content (Map Content Module) and the geovisualization process (Cartography\nModule). We demonstrate that, by representing both the map content and the\ngeovisualization process in KGs (an ontology), we can realize both data\nreusability and map reproducibility for narrative cartography.",
    "descriptor": "\nComments: 33 pages, 5 figures, Accepted to Journal of Geovisualization and Spatial Analysis\n",
    "authors": [
      "Gengchen Mai",
      "Weiming Huang",
      "Ling Cai",
      "Rui Zhu",
      "Ni Lao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.00970"
  },
  {
    "id": "arXiv:2112.00971",
    "title": "Personal Comfort Estimation in Partial Observable Environment using  Reinforcement Learning",
    "abstract": "The technology used in smart homes have improved to learn the user\npreferences from feedbacks in order to provide convenience to the user in the\nhome environment. Most smart homes learn a uniform model to represent the\nthermal preference of user which generally fails when the pool of occupants\nincludes people having different age, gender, and location. Having different\nthermal sensation for each user poses a challenge for the smart homes to learn\na personalized preference for each occupant without forgetting the policy of\nothers. A smart home with single optimal policy may fail to provide comfort\nwhen a new user with different preference is integrated in the home. In this\npaper, we propose POSHS, a Bayesian Reinforcement learning algorithm that can\napproximate the current occupant state in a partial observable environment\nusing its thermal preference and then decide if its a new occupant or belongs\nto the pool of previously observed users. We then compare POSHS algorithm with\nan LSTM based algorithm to learn and estimate the current state of the occupant\nwhile also taking optimal actions to reduce the timesteps required to set the\npreferences. We perform these experiments with upto 5 simulated human models\neach based on hierarchical reinforcement learning. The results show that POSHS\ncan approximate the current user state just from its temperature and humidity\npreference and also reduce the number of time-steps required to set optimal\ntemperature and humidity by the human model in the presence of the smart home.",
    "descriptor": "",
    "authors": [
      "Shashi Suman",
      "Ali Etemad",
      "Francois Rivest"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00971"
  },
  {
    "id": "arXiv:2112.00973",
    "title": "Adversarial Robustness of Deep Reinforcement Learning based Dynamic  Recommender Systems",
    "abstract": "Adversarial attacks, e.g., adversarial perturbations of the input and\nadversarial samples, pose significant challenges to machine learning and deep\nlearning techniques, including interactive recommendation systems. The latent\nembedding space of those techniques makes adversarial attacks difficult to\ndetect at an early stage. Recent advance in causality shows that counterfactual\ncan also be considered one of ways to generate the adversarial samples drawn\nfrom different distribution as the training samples. We propose to explore\nadversarial examples and attack agnostic detection on reinforcement\nlearning-based interactive recommendation systems. We first craft different\ntypes of adversarial examples by adding perturbations to the input and\nintervening on the casual factors. Then, we augment recommendation systems by\ndetecting potential attacks with a deep learning-based classifier based on the\ncrafted data. Finally, we study the attack strength and frequency of\nadversarial examples and evaluate our model on standard datasets with multiple\ncrafting methods. Our extensive experiments show that most adversarial attacks\nare effective, and both attack strength and attack frequency impact the attack\nperformance. The strategically-timed attack achieves comparative attack\nperformance with only 1/3 to 1/2 attack frequency. Besides, our black-box\ndetector trained with one crafting method has the generalization ability over\nseveral other crafting methods.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2006.07934\n",
    "authors": [
      "Siyu Wang",
      "Yuanjiang Cao",
      "Xiaocong Chen",
      "Lina Yao",
      "Xianzhi Wang",
      "Quan Z. Sheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.00973"
  },
  {
    "id": "arXiv:2112.00974",
    "title": "Consensus Graph Representation Learning for Better Grounded Image  Captioning",
    "abstract": "The contemporary visual captioning models frequently hallucinate objects that\nare not actually in a scene, due to the visual misclassification or\nover-reliance on priors that resulting in the semantic inconsistency between\nthe visual information and the target lexical words. The most common way is to\nencourage the captioning model to dynamically link generated object words or\nphrases to appropriate regions of the image, i.e., the grounded image\ncaptioning (GIC). However, GIC utilizes an auxiliary task (grounding objects)\nthat has not solved the key issue of object hallucination, i.e., the semantic\ninconsistency. In this paper, we take a novel perspective on the issue above -\nexploiting the semantic coherency between the visual and language modalities.\nSpecifically, we propose the Consensus Rraph Representation Learning framework\n(CGRL) for GIC that incorporates a consensus representation into the grounded\ncaptioning pipeline. The consensus is learned by aligning the visual graph\n(e.g., scene graph) to the language graph that consider both the nodes and\nedges in a graph. With the aligned consensus, the captioning model can capture\nboth the correct linguistic characteristics and visual relevance, and then\ngrounding appropriate image regions further. We validate the effectiveness of\nour model, with a significant decline in object hallucination (-9% CHAIRi) on\nthe Flickr30k Entities dataset. Besides, our CGRL also evaluated by several\nautomatic metrics and human evaluation, the results indicate that the proposed\napproach can simultaneously improve the performance of image captioning (+2.9\nCider) and grounding (+2.3 F1LOC).",
    "descriptor": "\nComments: 9 pages, 5 figures, AAAI 2021\n",
    "authors": [
      "Wenqiao Zhang",
      "Haochen Shi",
      "Siliang Tang",
      "Jun Xiao",
      "Qiang Yu",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00974"
  },
  {
    "id": "arXiv:2112.00976",
    "title": "Gaussian Mixture Variational Autoencoder with Contrastive Learning for  Multi-Label Classification",
    "abstract": "Multi-label classification (MLC) is a prediction task where each sample can\nhave more than one label. We propose a novel contrastive learning boosted\nmulti-label prediction model based on a Gaussian mixture variational\nautoencoder (C-GMVAE), which learns a multimodal prior space and employs a\ncontrastive loss. Many existing methods introduce extra complex neural modules\nto capture the label correlations, in addition to the prediction modules. We\nfound that by using contrastive learning in the supervised setting, we can\nexploit label information effectively, and learn meaningful feature and label\nembeddings capturing both the label correlations and predictive power, without\nextra neural modules. Our method also adopts the idea of learning and aligning\nlatent spaces for both features and labels. C-GMVAE imposes a Gaussian mixture\nstructure on the latent space, to alleviate posterior collapse and\nover-regularization issues, in contrast to previous works based on a unimodal\nprior. C-GMVAE outperforms existing methods on multiple public datasets and can\noften match other models' full performance with only 50% of the training data.\nFurthermore, we show that the learnt embeddings provide insights into the\ninterpretation of label-label interactions.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications\n",
    "authors": [
      "Junwen Bai",
      "Shufeng Kong",
      "Carla P. Gomes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00976"
  },
  {
    "id": "arXiv:2112.00979",
    "title": "Recommending with Recommendations",
    "abstract": "Recommendation systems are a key modern application of machine learning, but\nthey have the downside that they often draw upon sensitive user information in\nmaking their predictions. We show how to address this deficiency by basing a\nservice's recommendation engine upon recommendations from other existing\nservices, which contain no sensitive information by nature. Specifically, we\nintroduce a contextual multi-armed bandit recommendation framework where the\nagent has access to recommendations for other services. In our setting, the\nuser's (potentially sensitive) information belongs to a high-dimensional latent\nspace, and the ideal recommendations for the source and target tasks (which are\nnon-sensitive) are given by unknown linear transformations of the user\ninformation. So long as the tasks rely on similar segments of the user\ninformation, we can decompose the target recommendation problem into systematic\ncomponents that can be derived from the source recommendations, and\nidiosyncratic components that are user-specific and cannot be derived from the\nsource, but have significantly lower dimensionality. We propose an\nexplore-then-refine approach to learning and utilizing this decomposition; then\nusing ideas from perturbation theory and statistical concentration of measure,\nwe prove our algorithm achieves regret comparable to a strong skyline that has\nfull knowledge of the source and target transformations. We also consider a\ngeneralization of our algorithm to a model with many simultaneous targets and\nno source. Our methods obtain superior empirical results on synthetic\nbenchmarks.",
    "descriptor": "\nComments: 22 pages, 2 figures\n",
    "authors": [
      "Naveen Durvasula",
      "Franklyn Wang",
      "Scott Duke Kominers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00979"
  },
  {
    "id": "arXiv:2112.00980",
    "title": "Trap of Feature Diversity in the Learning of MLPs",
    "abstract": "In this paper, we discover a two-phase phenomenon in the learning of\nmulti-layer perceptrons (MLPs). I.e., in the first phase, the training loss\ndoes not decrease significantly, but the similarity of features between\ndifferent samples keeps increasing, which hurts the feature diversity. We\nexplain such a two-phase phenomenon in terms of the learning dynamics of the\nMLP. Furthermore, we propose two normalization operations to eliminate the\ntwo-phase phenomenon, which avoids the decrease of the feature diversity and\nspeeds up the training process.",
    "descriptor": "",
    "authors": [
      "Dongrui Liu",
      "Shaobo Wang",
      "Jie Ren",
      "Kangrui Wang",
      "Sheng Yin",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00980"
  },
  {
    "id": "arXiv:2112.00985",
    "title": "Evaluation of mathematical questioning strategies using data collected  through weak supervision",
    "abstract": "A large body of research demonstrates how teachers' questioning strategies\ncan improve student learning outcomes. However, developing new scenarios is\nchallenging because of the lack of training data for a specific scenario and\nthe costs associated with labeling. This paper presents a high-fidelity,\nAI-based classroom simulator to help teachers rehearse research-based\nmathematical questioning skills. Using a human-in-the-loop approach, we\ncollected a high-quality training dataset for a mathematical questioning\nscenario. Using recent advances in uncertainty quantification, we evaluated our\nconversational agent for usability and analyzed the practicality of\nincorporating a human-in-the-loop approach for data collection and system\nevaluation for a mathematical questioning scenario.",
    "descriptor": "\nComments: Accepted to appear at the NeurIPS 2021 Workshop on Math AI for Education (MATHAI4ED)\n",
    "authors": [
      "Debajyoti Datta",
      "Maria Phillips",
      "James P Bywater",
      "Jennifer Chiu",
      "Ginger S. Watson",
      "Laura E. Barnes",
      "Donald E Brown"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00985"
  },
  {
    "id": "arXiv:2112.00987",
    "title": "On Large Batch Training and Sharp Minima: A Fokker-Planck Perspective",
    "abstract": "We study the statistical properties of the dynamic trajectory of stochastic\ngradient descent (SGD). We approximate the mini-batch SGD and the momentum SGD\nas stochastic differential equations (SDEs). We exploit the continuous\nformulation of SDE and the theory of Fokker-Planck equations to develop new\nresults on the escaping phenomenon and the relationship with large batch and\nsharp minima. In particular, we find that the stochastic process solution tends\nto converge to flatter minima regardless of the batch size in the asymptotic\nregime. However, the convergence rate is rigorously proven to depend on the\nbatch size. These results are validated empirically with various datasets and\nmodels.",
    "descriptor": "",
    "authors": [
      "Xiaowu Dai",
      "Yuhua Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.00987"
  },
  {
    "id": "arXiv:2112.00988",
    "title": "Deep Transfer Learning: A Novel Collaborative Learning Model for  Cyberattack Detection Systems in IoT Networks",
    "abstract": "Federated Learning (FL) has recently become an effective approach for\ncyberattack detection systems, especially in Internet-of-Things (IoT) networks.\nBy distributing the learning process across IoT gateways, FL can improve\nlearning efficiency, reduce communication overheads and enhance privacy for\ncyberattack detection systems. Challenges in implementation of FL in such\nsystems include unavailability of labeled data and dissimilarity of data\nfeatures in different IoT networks. In this paper, we propose a novel\ncollaborative learning framework that leverages Transfer Learning (TL) to\novercome these challenges. Particularly, we develop a novel collaborative\nlearning approach that enables a target network with unlabeled data to\neffectively and quickly learn knowledge from a source network that possesses\nabundant labeled data. It is important that the state-of-the-art studies\nrequire the participated datasets of networks to have the same features, thus\nlimiting the efficiency, flexibility as well as scalability of intrusion\ndetection systems. However, our proposed framework can address these problems\nby exchanging the learning knowledge among various deep learning models, even\nwhen their datasets have different features. Extensive experiments on recent\nreal-world cybersecurity datasets show that the proposed framework can improve\nmore than 40% as compared to the state-of-the-art deep learning based\napproaches.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Tran Viet Khoa",
      "Dinh Thai Hoang",
      "Nguyen Linh Trung",
      "Cong T. Nguyen",
      "Tran Thi Thuy Quynh",
      "Diep N. Nguyen",
      "Nguyen Viet Ha",
      "Eryk Dutkiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00988"
  },
  {
    "id": "arXiv:2112.00989",
    "title": "Embedding Decomposition for Artifacts Removal in EEG Signals",
    "abstract": "Electroencephalogram (EEG) recordings are often contaminated with artifacts.\nVarious methods have been developed to eliminate or weaken the influence of\nartifacts. However, most of them rely on prior experience for analysis. Here,\nwe propose an deep learning framework to separate neural signal and artifacts\nin the embedding space and reconstruct the denoised signal, which is called\nDeepSeparator. DeepSeparator employs an encoder to extract and amplify the\nfeatures in the raw EEG, a module called decomposer to extract the trend,\ndetect and suppress artifact and a decoder to reconstruct the denoised signal.\nBesides, DeepSeparator can extract the artifact, which largely increases the\nmodel interpretability. The proposed method is tested with a semi-synthetic EEG\ndataset and a real task-related EEG dataset, suggesting that DeepSeparator\noutperforms the conventional models in both EOG and EMG artifact removal.\nDeepSeparator can be extended to multi-channel EEG and data of any length. It\nmay motivate future developments and application of deep learning-based EEG\ndenoising. The code for DeepSeparator is available at\nhttps://github.com/ncclabsustech/DeepSeparator.",
    "descriptor": "",
    "authors": [
      "Junjie Yu",
      "Chenyi Li",
      "Kexin Lou",
      "Chen Wei",
      "Quanying Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.00989"
  },
  {
    "id": "arXiv:2112.00995",
    "title": "SwinTrack: A Simple and Strong Baseline for Transformer Tracking",
    "abstract": "Transformer has recently demonstrated clear potential in improving visual\ntracking algorithms. Nevertheless, existing transformer-based trackers mostly\nuse Transformer to fuse and enhance the features generated by convolutional\nneural networks (CNNs). By contrast, in this paper, we propose a fully\nattentional-based Transformer tracking algorithm, Swin-Transformer Tracker\n(SwinTrack). SwinTrack uses Transformer for both feature extraction and feature\nfusion, allowing full interactions between the target object and the search\nregion for tracking. To further improve performance, we investigate\ncomprehensively different strategies for feature fusion, position encoding, and\ntraining loss. All these efforts make SwinTrack a simple yet solid baseline. In\nour thorough experiments, SwinTrack sets a new record with 0.717 SUC on LaSOT,\nsurpassing STARK by 4.6\\% while still running at 45 FPS. Besides, it achieves\nstate-of-the-art performances with 0.483 SUC, 0.832 SUC and 0.694 AO on other\nchallenging LaSOT$_{ext}$, TrackingNet, and GOT-10k. Our implementation and\ntrained models are available at https://github.com/LitingLin/SwinTrack.",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Liting Lin",
      "Heng Fan",
      "Yong Xu",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00995"
  },
  {
    "id": "arXiv:2112.00999",
    "title": "Contrastive Cross-domain Recommendation in Matching",
    "abstract": "Cross-domain recommendation (CDR) aims to provide better recommendation\nresults in the target domain with the help of the source domain, which is\nwidely used and explored in real-world systems. However, CDR in the matching\n(i.e., candidate generation) module struggles with the data sparsity and\npopularity bias issues in both representation learning and knowledge transfer.\nIn this work, we propose a novel Contrastive Cross-Domain Recommendation (CCDR)\nframework for CDR in matching. Specifically, we build a huge diversified\npreference network to capture multiple information reflecting user diverse\ninterests, and design an intra-domain contrastive learning (intra-CL) and three\ninter-domain contrastive learning (inter-CL) tasks for better representation\nlearning and knowledge transfer. The intra-CL enables more effective and\nbalanced training inside the target domain via a graph augmentation, while the\ninter-CL builds different types of cross-domain interactions from user,\ntaxonomy, and neighbor aspects. In experiments, CCDR achieves significant\nimprovements on both offline and online evaluations in a real-world system.\nCurrently, we have deployed CCDR on a well-known recommendation system,\naffecting millions of users. The source code will be released in the future.",
    "descriptor": "\nComments: 10 pages, under review\n",
    "authors": [
      "Ruobing Xie",
      "Qi Liu",
      "Liangdong Wang",
      "Shukai Liu",
      "Bo Zhang",
      "Leyu Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.00999"
  },
  {
    "id": "arXiv:2112.01001",
    "title": "SEAL: Self-supervised Embodied Active Learning using Exploration and 3D  Consistency",
    "abstract": "In this paper, we explore how we can build upon the data and models of\nInternet images and use them to adapt to robot vision without requiring any\nextra labels. We present a framework called Self-supervised Embodied Active\nLearning (SEAL). It utilizes perception models trained on internet images to\nlearn an active exploration policy. The observations gathered by this\nexploration policy are labelled using 3D consistency and used to improve the\nperception model. We build and utilize 3D semantic maps to learn both action\nand perception in a completely self-supervised manner. The semantic map is used\nto compute an intrinsic motivation reward for training the exploration policy\nand for labelling the agent observations using spatio-temporal 3D consistency\nand label propagation. We demonstrate that the SEAL framework can be used to\nclose the action-perception loop: it improves object detection and instance\nsegmentation performance of a pretrained perception model by just moving around\nin training environments and the improved perception model can be used to\nimprove Object Goal Navigation.",
    "descriptor": "\nComments: Published at NeurIPS 2021. See project webpage at this https URL\n",
    "authors": [
      "Devendra Singh Chaplot",
      "Murtaza Dalal",
      "Saurabh Gupta",
      "Jitendra Malik",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.01001"
  },
  {
    "id": "arXiv:2112.01003",
    "title": "Worst-case Optimal Binary Join Algorithms under General $\\ell_p$  Constraints",
    "abstract": "Worst-case optimal join algorithms have so far been studied in two broad\ncontexts -- $(1)$ when we are given input relation sizes [Atserias et al., FOCS\n2008, Ngo et al., PODS 2012, Velduizhen et. al, ICDT 2014] $(2)$ when in\naddition to size, we are given a degree bound on the relation [Abo Khamis et\nal., PODS 2017]. To the best of our knowledge, this problem has not been\nstudied beyond these two statistics even for the case when input relations have\narity (at most) two.\nIn this paper, we present a worst-case optimal join algorithm when are given\n$\\ell_{p}$-norm size bounds on input relations of arity at most two for $p \\in\n(1, 2]$. ($p=1$ corresponds to relation size bounds and $p=\\infty$ corresponds\nto the degree bounds.) The worst-case optimality holds any fixed $p \\in (2,\n\\infty)$ as well (as long as the join query graph has large enough girth). Our\nalgorithm is {\\em simple}, does not depend on $p$ (or) the $\\ell_{p}$-norm\nbounds and avoids the (large) poly-log factor associated with the best known\nalgorithm PANDA [Abo Khamis et al., PODS 2017] for the size and degree bounds\nsetting of the problem. In this process, we (partially) resolve two open\nquestion from [Ngo, 2018 Gems of PODS]. We believe our algorithm has the {\\em\npotential} to pave the way for practical worst-case optimal join algorithms\nbeyond the case of size bounds.",
    "descriptor": "",
    "authors": [
      "Sai Vikneshwar Mani Jayaraman",
      "Corey Ropell",
      "Atri Rudra"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.01003"
  },
  {
    "id": "arXiv:2112.01006",
    "title": "Distributed Control for a Robotic Swarm to Pass through a Curve Virtual  Tube",
    "abstract": "Robotic swarm systems are now becoming increasingly attractive for many\nchallenging applications. The main task for any robot is to reach the\ndestination while keeping a safe separation from other robots and obstacles. In\nmany scenarios, robots need to move within a narrow corridor, through a window\nor a doorframe. In order to guide all robots to move in a cluttered\nenvironment, a curve virtual tube with no obstacle inside is carefully designed\nin this paper. There is no obstacle inside the tube, namely the area inside the\ntube can be seen as a safety zone. Then, a distributed swarm controller is\nproposed with three elaborate control terms: a line approaching term, a robot\navoidance term and a tube keeping term. Formal analysis and proofs are made to\nshow that the curve virtual tube passing problem can be solved in a finite\ntime. For the convenience in practical use, a modified controller with an\napproximate control performance is put forward. Finally, the effectiveness of\nthe proposed method is validated by numerical simulations and real experiments.\nTo show the advantages of the proposed method, the comparison between our\nmethod and the control barrier function method is also presented in terms of\ncalculation speed.",
    "descriptor": "\nComments: 18 pages, 21 figures\n",
    "authors": [
      "Quan Quan",
      "Yan Gao",
      "Chenggang Bai"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.01006"
  },
  {
    "id": "arXiv:2112.01008",
    "title": "Editing a classifier by rewriting its prediction rules",
    "abstract": "We present a methodology for modifying the behavior of a classifier by\ndirectly rewriting its prediction rules. Our approach requires virtually no\nadditional data collection and can be applied to a variety of settings,\nincluding adapting a model to new environments, and modifying it to ignore\nspurious features. Our code is available at\nhttps://github.com/MadryLab/EditingClassifiers .",
    "descriptor": "",
    "authors": [
      "Shibani Santurkar",
      "Dimitris Tsipras",
      "Mahalaxmi Elango",
      "David Bau",
      "Antonio Torralba",
      "Aleksander Madry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01008"
  },
  {
    "id": "arXiv:2112.01010",
    "title": "Differentiable Spatial Planning using Transformers",
    "abstract": "We consider the problem of spatial path planning. In contrast to the\nclassical solutions which optimize a new plan from scratch and assume access to\nthe full map with ground truth obstacle locations, we learn a planner from the\ndata in a differentiable manner that allows us to leverage statistical\nregularities from past data. We propose Spatial Planning Transformers (SPT),\nwhich given an obstacle map learns to generate actions by planning over\nlong-range spatial dependencies, unlike prior data-driven planners that\npropagate information locally via convolutional structure in an iterative\nmanner. In the setting where the ground truth map is not known to the agent, we\nleverage pre-trained SPTs in an end-to-end framework that has the structure of\nmapper and planner built into it which allows seamless generalization to\nout-of-distribution maps and goals. SPTs outperform prior state-of-the-art\ndifferentiable planners across all the setups for both manipulation and\nnavigation tasks, leading to an absolute improvement of 7-19%.",
    "descriptor": "\nComments: Published at ICML 2021. See project webpage at this https URL\n",
    "authors": [
      "Devendra Singh Chaplot",
      "Deepak Pathak",
      "Jitendra Malik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.01010"
  },
  {
    "id": "arXiv:2112.01011",
    "title": "Local Similarity Pattern and Cost Self-Reassembling for Deep Stereo  Matching Networks",
    "abstract": "Although convolution neural network based stereo matching architectures have\nmade impressive achievements, there are still some limitations: 1)\nConvolutional Feature (CF) tends to capture appearance information, which is\ninadequate for accurate matching. 2) Due to the static filters, current\nconvolution based disparity refinement modules often produce over-smooth\nresults. In this paper, we present two schemes to address these issues, where\nsome traditional wisdoms are integrated. Firstly, we introduce a pairwise\nfeature for deep stereo matching networks, named LSP (Local Similarity\nPattern). Through explicitly revealing the neighbor relationships, LSP contains\nrich structural information, which can be leveraged to aid CF for more\ndiscriminative feature description. Secondly, we design a dynamic\nself-reassembling refinement strategy and apply it to the cost distribution and\nthe disparity map respectively. The former could be equipped with the unimodal\ndistribution constraint to alleviate the over-smoothing problem, and the latter\nis more practical. The effectiveness of the proposed methods is demonstrated\nvia incorporating them into two well-known basic architectures, GwcNet and\nGANet-deep. Experimental results on the SceneFlow and KITTI benchmarks show\nthat our modules significantly improve the performance of the model.",
    "descriptor": "\nComments: Accepted by AAAI-2022\n",
    "authors": [
      "Biyang Liu",
      "Huimin Yu",
      "Yangqi Long"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01011"
  },
  {
    "id": "arXiv:2112.01012",
    "title": "Improving Controllability of Educational Question Generation by Keyword  Provision",
    "abstract": "Question Generation (QG) receives increasing research attention in NLP\ncommunity. One motivation for QG is that QG significantly facilitates the\npreparation of educational reading practice and assessments. While the\nsignificant advancement of QG techniques was reported, current QG results are\nnot ideal for educational reading practice assessment in terms of\n\\textit{controllability} and \\textit{question difficulty}. This paper reports\nour results toward the two issues. First, we report a state-of-the-art\nexam-like QG model by advancing the current best model from 11.96 to 20.19 (in\nterms of BLEU 4 score). Second, we propose to investigate a variant of QG\nsetting by allowing users to provide keywords for guiding QG direction. We also\npresent a simple but effective model toward the QG controllability task.\nExperiments are also performed and the results demonstrate the feasibility and\npotentials of improving QG diversity and controllability by the proposed\nkeyword provision QG model.",
    "descriptor": "\nComments: AAAI2020 Workshop on AI for Education\n",
    "authors": [
      "Ying-Hong Chan",
      "Ho-Lam Chung",
      "Yao-Chung Fan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01012"
  },
  {
    "id": "arXiv:2112.01014",
    "title": "Constructive approach to the monotone rearrangement of functions",
    "abstract": "We detail a simple procedure (easily convertible to an algorithm) for\nconstructing from quasi-uniform samples of $f$ a sequence of linear spline\nfunctions converging to the monotone rearrangement of $f$, in the case where\n$f$ is an almost everywhere continuous function defined on a bounded set\n$\\Omega$ with negligible boundary. Under additional assumptions on $f$ and\n$\\Omega$, we prove that the convergence of the sequence is uniform. We also\nshow that the same procedure applies to arbitrary measurable functions too, but\nwith the substantial difference that in this case the procedure has only a\ntheoretical interest and cannot be converted to an algorithm.",
    "descriptor": "\nComments: In Press\n",
    "authors": [
      "Giovanni Barbarino",
      "Davide Bianchi",
      "Carlo Garoni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.01014"
  },
  {
    "id": "arXiv:2112.01016",
    "title": "On Two XAI Cultures: A Case Study of Non-technical Explanations in  Deployed AI System",
    "abstract": "Explainable AI (XAI) research has been booming, but the question \"$\\textbf{To\nwhom}$ are we making AI explainable?\" is yet to gain sufficient attention. Not\nmuch of XAI is comprehensible to non-AI experts, who nonetheless, are the\nprimary audience and major stakeholders of deployed AI systems in practice. The\ngap is glaring: what is considered \"explained\" to AI-experts versus non-experts\nare very different in practical scenarios. Hence, this gap produced two\ndistinct cultures of expectations, goals, and forms of XAI in real-life AI\ndeployments.\nWe advocate that it is critical to develop XAI methods for non-technical\naudiences. We then present a real-life case study, where AI experts provided\nnon-technical explanations of AI decisions to non-technical stakeholders, and\ncompleted a successful deployment in a highly regulated industry. We then\nsynthesize lessons learned from the case, and share a list of suggestions for\nAI experts to consider when explaining AI decisions to non-technical\nstakeholders.",
    "descriptor": "\nComments: Accepted to the Human-centered AI (HCAI) workshop at NeurIPS 2021\n",
    "authors": [
      "Helen Jiang",
      "Erwen Senge"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01016"
  },
  {
    "id": "arXiv:2112.01019",
    "title": "Unconstrained Face Sketch Synthesis via Perception-Adaptive Network and  A New Benchmark",
    "abstract": "Face sketch generation has attracted much attention in the field of visual\ncomputing. However, existing methods either are limited to constrained\nconditions or heavily rely on various preprocessing steps to deal with\nin-the-wild cases. In this paper, we argue that accurately perceiving facial\nregion and facial components is crucial for unconstrained sketch synthesis. To\nthis end, we propose a novel Perception-Adaptive Network (PANet), which can\ngenerate high-quality face sketches under unconstrained conditions in an\nend-to-end scheme. Specifically, our PANet is composed of i) a Fully\nConvolutional Encoder for hierarchical feature extraction, ii) a Face-Adaptive\nPerceiving Decoder for extracting potential facial region and handling face\nvariations, and iii) a Component-Adaptive Perceiving Module for facial\ncomponent aware feature representation learning. To facilitate further\nresearches of unconstrained face sketch synthesis, we introduce a new benchmark\ntermed WildSketch, which contains 800 pairs of face photo-sketch with large\nvariations in pose, expression, ethnic origin, background, and illumination.\nExtensive experiments demonstrate that the proposed method is capable of\nachieving state-of-the-art performance under both constrained and unconstrained\nconditions. Our source codes and the WildSketch benchmark are resealed on the\nproject page this http URL",
    "descriptor": "\nComments: We proposed the first medium-scale benchmark for unconstrained face sketch synthesis\n",
    "authors": [
      "Lin Nie",
      "Lingbo Liu",
      "Zhengtao Wu",
      "Wenxiong Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01019"
  },
  {
    "id": "arXiv:2112.01020",
    "title": "Learning Optimal Predictive Checklists",
    "abstract": "Checklists are simple decision aids that are often used to promote safety and\nreliability in clinical applications. In this paper, we present a method to\nlearn checklists for clinical decision support. We represent predictive\nchecklists as discrete linear classifiers with binary features and unit\nweights. We then learn globally optimal predictive checklists from data by\nsolving an integer programming problem. Our method allows users to customize\nchecklists to obey complex constraints, including constraints to enforce group\nfairness and to binarize real-valued features at training time. In addition, it\npairs models with an optimality gap that can inform model development and\ndetermine the feasibility of learning sufficiently accurate checklists on a\ngiven dataset. We pair our method with specialized techniques that speed up its\nability to train a predictive checklist that performs well and has a small\noptimality gap. We benchmark the performance of our method on seven clinical\nclassification problems, and demonstrate its practical benefits by training a\nshort-form checklist for PTSD screening. Our results show that our method can\nfit simple predictive checklists that perform well and that can easily be\ncustomized to obey a rich class of custom constraints.",
    "descriptor": "\nComments: Published in NeurIPS 2021\n",
    "authors": [
      "Haoran Zhang",
      "Quaid Morris",
      "Berk Ustun",
      "Marzyeh Ghassemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01020"
  },
  {
    "id": "arXiv:2112.01021",
    "title": "Fighting Fire with Fire: Contrastive Debiasing without Bias-free Data  via Generative Bias-transformation",
    "abstract": "Despite their remarkable ability to generalize with over-capacity networks,\ndeep neural networks often learn to abuse spurious biases in the data instead\nof using the actual task-related information. Since such shortcuts are only\neffective within the collected dataset, the resulting biased model\nunderperforms on real-world inputs, or cause unintended social repercussions\nsuch as gender discrimination. To counteract the influence of bias, existing\nmethods either exploit auxiliary information which is rarely obtainable in\npractice, or sift for bias-free samples in the training data, hoping for the\nsufficient existence of clean samples. However, such presumptions about the\ndata are not always guaranteed. In this paper, we propose Contrastive Debiasing\nvia Generative Bias-transformation~(CDvG) which is capable of operating in more\ngeneral environments where existing methods break down due to unmet\npresumptions such as insufficient bias-free samples. Motivated by our\nobservation that not only discriminative models, as previously known, but also\ngenerative models tend to focus on the bias when possible, CDvG uses a\ntranslation model to transform the bias in the sample to another mode of bias\nwhile preserving task-relevant information. Through contrastive learning, we\nset transformed biased views against another, learning bias-invariant\nrepresentations. Experimental results on synthetic and real-world datasets\ndemonstrate that our framework outperforms the current state-of-the-arts, and\neffectively prevents the models from being biased even when bias-free samples\nare extremely scarce.",
    "descriptor": "",
    "authors": [
      "Yeonsung Jung",
      "Hajin Shim",
      "June Yong Yang",
      "Eunho Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01021"
  },
  {
    "id": "arXiv:2112.01030",
    "title": "TransMEF: A Transformer-Based Multi-Exposure Image Fusion Framework  using Self-Supervised Multi-Task Learning",
    "abstract": "In this paper, we propose TransMEF, a transformer-based multi-exposure image\nfusion framework that uses self-supervised multi-task learning. The framework\nis based on an encoder-decoder network, which can be trained on large natural\nimage datasets and does not require ground truth fusion images. We design three\nself-supervised reconstruction tasks according to the characteristics of\nmulti-exposure images and conduct these tasks simultaneously using multi-task\nlearning; through this process, the network can learn the characteristics of\nmulti-exposure images and extract more generalized features. In addition, to\ncompensate for the defect in establishing long-range dependencies in CNN-based\narchitectures, we design an encoder that combines a CNN module with a\ntransformer module. This combination enables the network to focus on both local\nand global information. We evaluated our method and compared it to 11\ncompetitive traditional and deep learning-based methods on the latest released\nmulti-exposure image fusion benchmark dataset, and our method achieved the best\nperformance in both subjective and objective evaluations.",
    "descriptor": "\nComments: accepted by the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI2022)\n",
    "authors": [
      "Linhao Qu",
      "Shaolei Liu",
      "Manning Wang",
      "Zhijian Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01030"
  },
  {
    "id": "arXiv:2112.01033",
    "title": "TBN-ViT: Temporal Bilateral Network with Vision Transformer for Video  Scene Parsing",
    "abstract": "Video scene parsing in the wild with diverse scenarios is a challenging and\ngreat significance task, especially with the rapid development of automatic\ndriving technique. The dataset Video Scene Parsing in the Wild(VSPW) contains\nwell-trimmed long-temporal, dense annotation and high resolution clips. Based\non VSPW, we design a Temporal Bilateral Network with Vision Transformer. We\nfirst design a spatial path with convolutions to generate low level features\nwhich can preserve the spatial information. Meanwhile, a context path with\nvision transformer is employed to obtain sufficient context information.\nFurthermore, a temporal context module is designed to harness the inter-frames\ncontextual information. Finally, the proposed method can achieve the mean\nintersection over union(mIoU) of 49.85\\% for the VSPW2021 Challenge test\ndataset.",
    "descriptor": "\nComments: The sixth place solution for ICCV2021 VSPW Challenge\n",
    "authors": [
      "Bo Yan",
      "Leilei Cao",
      "Hongbin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01033"
  },
  {
    "id": "arXiv:2112.01034",
    "title": "Leveraging Human Selective Attention for Medical Image Analysis with  Limited Training Data",
    "abstract": "The human gaze is a cost-efficient physiological data that reveals human\nunderlying attentional patterns. The selective attention mechanism helps the\ncognition system focus on task-relevant visual clues by ignoring the presence\nof distractors. Thanks to this ability, human beings can efficiently learn from\na very limited number of training samples. Inspired by this mechanism, we aim\nto leverage gaze for medical image analysis tasks with small training data. Our\nproposed framework includes a backbone encoder and a Selective Attention\nNetwork (SAN) that simulates the underlying attention. The SAN implicitly\nencodes information such as suspicious regions that is relevant to the medical\ndiagnose tasks by estimating the actual human gaze. Then we design a novel\nAuxiliary Attention Block (AAB) to allow information from SAN to be utilized by\nthe backbone encoder to focus on selective areas. Specifically, this block uses\na modified version of a multi-head attention layer to simulate the human visual\nsearch procedure. Note that the SAN and AAB can be plugged into different\nbackbones, and the framework can be used for multiple medical image analysis\ntasks when equipped with task-specific heads. Our method is demonstrated to\nachieve superior performance on both 3D tumor segmentation and 2D chest X-ray\nclassification tasks. We also show that the estimated gaze probability map of\nthe SAN is consistent with an actual gaze fixation map obtained by\nboard-certified doctors.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Yifei Huang",
      "Xiaoxiao Li",
      "Lijin Yang",
      "Lin Gu",
      "Yingying Zhu",
      "Hirofumi Seo",
      "Qiuming Meng",
      "Tatsuya Harada",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.01034"
  },
  {
    "id": "arXiv:2112.01035",
    "title": "Graph4Rec: A Universal Toolkit with Graph Neural Networks for  Recommender Systems",
    "abstract": "In recent years, owing to the outstanding performance in graph representation\nlearning, graph neural network (GNN) techniques have gained considerable\ninterests in many real-world scenarios, such as recommender systems and social\nnetworks. In recommender systems, the main challenge is to learn the effective\nuser/item representations from their interactions. However, many recent\npublications using GNNs for recommender systems cannot be directly compared,\ndue to their difference on datasets and evaluation metrics. Furthermore, many\nof them only provide a demo to conduct experiments on small datasets, which is\nfar away to be applied in real-world recommender systems. To address this\nproblem, we introduce Graph4Rec, a universal toolkit that unifies the paradigm\nto train GNN models into the following parts: graphs input, random walk\ngeneration, ego graphs generation, pairs generation and GNNs selection. From\nthis training pipeline, one can easily establish his own GNN model with a few\nconfigurations. Besides, we develop a large-scale graph engine and a parameter\nserver to support distributed GNN training. We conduct a systematic and\ncomprehensive experiment to compare the performance of different GNN models on\nseveral scenarios in different scale. Extensive experiments are demonstrated to\nidentify the key components of GNNs. We also try to figure out how the sparse\nand dense parameters affect the performance of GNNs. Finally, we investigate\nmethods including negative sampling, ego graph construction order, and warm\nstart strategy to find a more effective and efficient GNNs practice on\nrecommender systems. Our toolkit is based on PGL\nhttps://github.com/PaddlePaddle/PGL and the code is opened source in\nhttps://github.com/PaddlePaddle/PGL/tree/main/apps/Graph4Rec.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Weibin Li",
      "Mingkai He",
      "Zhengjie Huang",
      "Xianming Wang",
      "Shikun Feng",
      "Weiyue Su",
      "Yu Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01035"
  },
  {
    "id": "arXiv:2112.01036",
    "title": "GANSeg: Learning to Segment by Unsupervised Hierarchical Image  Generation",
    "abstract": "Segmenting an image into its parts is a frequent preprocess for high-level\nvision tasks such as image editing. However, annotating masks for supervised\ntraining is expensive. Weakly-supervised and unsupervised methods exist, but\nthey depend on the comparison of pairs of images, such as from multi-views,\nframes of videos, and image transformations of single images, which limits\ntheir applicability. To address this, we propose a GAN-based approach that\ngenerates images conditioned on latent masks, thereby alleviating full or weak\nannotations required in previous approaches. We show that such mask-conditioned\nimage generation can be learned faithfully when conditioning the masks in a\nhierarchical manner on latent keypoints that define the position of parts\nexplicitly. Without requiring supervision of masks or points, this strategy\nincreases robustness to viewpoint and object positions changes. It also lets us\ngenerate image-mask pairs for training a segmentation network, which\noutperforms the state-of-the-art unsupervised segmentation methods on\nestablished benchmarks.",
    "descriptor": "",
    "authors": [
      "Xingzhe He",
      "Bastian Wandt",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01036"
  },
  {
    "id": "arXiv:2112.01037",
    "title": "Inferring Prototypes for Multi-Label Few-Shot Image Classification with  Word Vector Guided Attention",
    "abstract": "Multi-label few-shot image classification (ML-FSIC) is the task of assigning\ndescriptive labels to previously unseen images, based on a small number of\ntraining examples. A key feature of the multi-label setting is that images\noften have multiple labels, which typically refer to different regions of the\nimage. When estimating prototypes, in a metric-based setting, it is thus\nimportant to determine which regions are relevant for which labels, but the\nlimited amount of training data makes this highly challenging. As a solution,\nin this paper we propose to use word embeddings as a form of prior knowledge\nabout the meaning of the labels. In particular, visual prototypes are obtained\nby aggregating the local feature maps of the support images, using an attention\nmechanism that relies on the label embeddings. As an important advantage, our\nmodel can infer prototypes for unseen labels without the need for fine-tuning\nany model parameters, which demonstrates its strong generalization abilities.\nExperiments on COCO and PASCAL VOC furthermore show that our model\nsubstantially improves the current state-of-the-art.",
    "descriptor": "\nComments: Accepted by AAAI2022\n",
    "authors": [
      "Kun Yan",
      "Chenbin Zhang",
      "Jun Hou",
      "Ping Wang",
      "Zied Bouraoui",
      "Shoaib Jameel",
      "Steven Schockaert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01037"
  },
  {
    "id": "arXiv:2112.01038",
    "title": "Stacked Temporal Attention: Improving First-person Action Recognition by  Emphasizing Discriminative Clips",
    "abstract": "First-person action recognition is a challenging task in video understanding.\nBecause of strong ego-motion and a limited field of view, many backgrounds or\nnoisy frames in a first-person video can distract an action recognition model\nduring its learning process. To encode more discriminative features, the model\nneeds to have the ability to focus on the most relevant part of the video for\naction recognition. Previous works explored to address this problem by applying\ntemporal attention but failed to consider the global context of the full video,\nwhich is critical for determining the relatively significant parts. In this\nwork, we propose a simple yet effective Stacked Temporal Attention Module\n(STAM) to compute temporal attention based on the global knowledge across clips\nfor emphasizing the most discriminative features. We achieve this by stacking\nmultiple self-attention layers. Instead of naive stacking, which is\nexperimentally proven to be ineffective, we carefully design the input to each\nself-attention layer so that both the local and global context of the video is\nconsidered during generating the temporal attention weights. Experiments\ndemonstrate that our proposed STAM can be built on top of most existing\nbackbones and boost the performance in various datasets.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Lijin Yang",
      "Yifei Huang",
      "Yusuke Sugano",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01038"
  },
  {
    "id": "arXiv:2112.01039",
    "title": "A Communication-efficient Federated learning assisted by Central data:  Implementation of vertical training into Horizontal Federated learning",
    "abstract": "Federated learning (FL) has emerged to jointly train a model with distributed\ndata sets in IoT while avoiding the need for central data collection. Due to\nlimited observation range, such data sets can only reflect local information,\nwhich limits the quality of trained models. In practical network, the global\ninformation and local observations always coexist, which requires joint\nconsideration for learning to make reasonable policy. However, in horizontal FL\namong distributed clients, the central agency only acts as a model aggregator\nwithout utilizing its global features to further improve the model. This could\nlargely degrade the performance in some missions such as flow prediction, where\nthe global information could obviously enhance the accuracy. Meanwhile, such\nglobal feature may not be directly transmitted to agents for data security.\nThen how to utilize the global observation residing in the central agency while\nprotecting its safety rises up as an important problem in FL. In this paper, we\ndeveloped the vertical-horizontal federated learning (VHFL) process, where the\nglobal feature is shared with the agents in a procedure similar to vertical FL\nwithout extra communication rounds. Considering the delay and packet loss, we\nanalyzed its convergence in the network system and validated its performance by\nexperiments. The proposed VHFL could enhance the accuracy compared with the\nhorizontal FL while protecting the security of global data.",
    "descriptor": "",
    "authors": [
      "Shuo Wan",
      "Jiaxun Lu",
      "Pingyi Fan",
      "Yunfeng Shao",
      "Chenghui Peng",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.01039"
  },
  {
    "id": "arXiv:2112.01040",
    "title": "EngineKGI: Closed-Loop Knowledge Graph Inference",
    "abstract": "Knowledge Graph (KG) inference is the vital technique to address the natural\nincompleteness of KGs. The existing KG inference approaches can be classified\ninto rule learning-based and KG embedding-based models. However, these\napproaches cannot well balance accuracy, generalization, interpretability and\nefficiency, simultaneously. Besides, these models always rely on pure triples\nand neglect additional information. Therefore, both KG embedding (KGE) and rule\nlearning KG inference approaches face challenges due to the sparse entities and\nthe limited semantics. We propose a novel and effective closed-loop KG\ninference framework EngineKGI operating similarly as an engine based on these\nobservations. EngineKGI combines KGE and rule learning to complement each other\nin a closed-loop pattern while taking advantage of semantics in paths and\nconcepts. KGE module exploits paths to enhance the semantic association between\nentities and introduces rules for interpretability. A novel rule pruning\nmechanism is proposed in the rule learning module by leveraging paths as\ninitial candidate rules and employing KG embeddings together with concepts for\nextracting more high-quality rules. Experimental results on four real-world\ndatasets show that our model outperforms other baselines on link prediction\ntasks, demonstrating the effectiveness and superiority of our model on KG\ninference in a joint logic and data-driven fashion with a closed-loop\nmechanism.",
    "descriptor": "\nComments: 9 pages, 6 figures, 3 tables\n",
    "authors": [
      "Guanglin Niu",
      "Bo Li",
      "Yongfei Zhang",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01040"
  },
  {
    "id": "arXiv:2112.01041",
    "title": "N-ImageNet: Towards Robust, Fine-Grained Object Recognition with Event  Cameras",
    "abstract": "We introduce N-ImageNet, a large-scale dataset targeted for robust,\nfine-grained object recognition with event cameras. The dataset is collected\nusing programmable hardware in which an event camera consistently moves around\na monitor displaying images from ImageNet. N-ImageNet serves as a challenging\nbenchmark for event-based object recognition, due to its large number of\nclasses and samples. We empirically show that pretraining on N-ImageNet\nimproves the performance of event-based classifiers and helps them learn with\nfew labeled data. In addition, we present several variants of N-ImageNet to\ntest the robustness of event-based classifiers under diverse camera\ntrajectories and severe lighting conditions, and propose a novel event\nrepresentation to alleviate the performance degradation. To the best of our\nknowledge, we are the first to quantitatively investigate the consequences\ncaused by various environmental conditions on event-based object recognition\nalgorithms. N-ImageNet and its variants are expected to guide practical\nimplementations for deploying event-based object recognition algorithms in the\nreal world.",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Junho Kim",
      "Jaehyeok Bae",
      "Gangin Park",
      "Young Min Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01041"
  },
  {
    "id": "arXiv:2112.01042",
    "title": "Gomory-Hu Trees in Quadratic Time",
    "abstract": "Gomory-Hu tree [Gomory and Hu, 1961] is a succinct representation of pairwise\nminimum cuts in an undirected graph. When the input graph has general edge\nweights, classic algorithms need at least cubic running time to compute a\nGomory-Hu tree. Very recently, the authors of [AKL+, arXiv v1, 2021] have\nimproved the running time to $\\tilde{O}(n^{2.875})$ which breaks the cubic\nbarrier for the first time. In this paper, we refine their approach and improve\nthe running time to $\\tilde{O}(n^2)$. This quadratic upper bound is also\nobtained independently in an updated version by the same group of authors\n[AKL+, arXiv v2, 2021].",
    "descriptor": "",
    "authors": [
      "Tianyi Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.01042"
  },
  {
    "id": "arXiv:2112.01044",
    "title": "ShuttleNet: Position-aware Fusion of Rally Progress and Player Styles  for Stroke Forecasting in Badminton",
    "abstract": "The increasing demand for analyzing the insights in sports has stimulated a\nline of productive studies from a variety of perspectives, e.g., health state\nmonitoring, outcome prediction. In this paper, we focus on objectively judging\nwhat and where to return strokes, which is still unexplored in turn-based\nsports. By formulating stroke forecasting as a sequence prediction task,\nexisting works can tackle the problem but fail to model information based on\nthe characteristics of badminton. To address these limitations, we propose a\nnovel Position-aware Fusion of Rally Progress and Player Styles framework\n(ShuttleNet) that incorporates rally progress and information of the players by\ntwo modified encoder-decoder extractors. Moreover, we design a fusion network\nto integrate rally contexts and contexts of the players by conditioning on\ninformation dependency and different positions. Extensive experiments on the\nbadminton dataset demonstrate that ShuttleNet significantly outperforms the\nstate-of-the-art methods and also empirically validates the feasibility of each\ncomponent in ShuttleNet. On top of that, we provide an analysis scenario for\nthe stroke forecasting problem.",
    "descriptor": "\nComments: Accepted by AAAI 2022, code is available at this https URL\n",
    "authors": [
      "Wei-Yao Wang",
      "Hong-Han Shuai",
      "Kai-Shiang Chang",
      "Wen-Chih Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01044"
  },
  {
    "id": "arXiv:2112.01047",
    "title": "DKPLM: Decomposable Knowledge-enhanced Pre-trained Language Model for  Natural Language Understanding",
    "abstract": "Knowledge-Enhanced Pre-trained Language Models (KEPLMs) are pre-trained\nmodels with relation triples injecting from knowledge graphs to improve\nlanguage understanding abilities. To guarantee effective knowledge injection,\nprevious studies integrate models with knowledge encoders for representing\nknowledge retrieved from knowledge graphs. The operations for knowledge\nretrieval and encoding bring significant computational burdens, restricting the\nusage of such models in real-world applications that require high inference\nspeed. In this paper, we propose a novel KEPLM named DKPLM that Decomposes\nKnowledge injection process of the Pre-trained Language Models in pre-training,\nfine-tuning and inference stages, which facilitates the applications of KEPLMs\nin real-world scenarios. Specifically, we first detect knowledge-aware\nlong-tail entities as the target for knowledge injection, enhancing the KEPLMs'\nsemantic understanding abilities and avoiding injecting redundant information.\nThe embeddings of long-tail entities are replaced by \"pseudo token\nrepresentations\" formed by relevant knowledge triples. We further design the\nrelational knowledge decoding task for pre-training to force the models to\ntruly understand the injected knowledge by relation triple reconstruction.\nExperiments show that our model outperforms other KEPLMs significantly over\nzero-shot knowledge probing tasks and multiple knowledge-aware language\nunderstanding tasks. We further show that DKPLM has a higher inference speed\nthan other competing models due to the decomposing mechanism.",
    "descriptor": "\nComments: Accepted by AAAI22\n",
    "authors": [
      "Taolin Zhang",
      "Chengyu Wang",
      "Nan Hu",
      "Minghui Qiu",
      "Chengguang Tang",
      "Xiaofeng He",
      "Jun Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01047"
  },
  {
    "id": "arXiv:2112.01048",
    "title": "From Consensus to Disagreement: Multi-Teacher Distillation for  Semi-Supervised Relation Extraction",
    "abstract": "Lack of labeled data is a main obstacle in relation extraction.\nSemi-supervised relation extraction (SSRE) has been proven to be a promising\nway for this problem through annotating unlabeled samples as additional\ntraining data. Almost all prior researches along this line adopt multiple\nmodels to make the annotations more reliable by taking the intersection set of\npredicted results from these models. However, the difference set, which\ncontains rich information about unlabeled data, has been long neglected by\nprior studies.\nIn this paper, we propose to learn not only from the consensus but also the\ndisagreement among different models in SSRE. To this end, we develop a simple\nand general multi-teacher distillation (MTD) framework, which can be easily\nintegrated into any existing SSRE methods. Specifically, we first let the\nteachers correspond to the multiple models and select the samples in the\nintersection set of the last iteration in SSRE methods to augment labeled data\nas usual. We then transfer the class distributions for samples in the\ndifference set as soft labels to guide the student. We finally perform\nprediction using the trained student model. Experimental results on two public\ndatasets demonstrate that our framework significantly promotes the performance\nof the base SSRE methods with pretty low computational cost.",
    "descriptor": "",
    "authors": [
      "Wanli Li",
      "Tieyun Qian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01048"
  },
  {
    "id": "arXiv:2112.01049",
    "title": "Bayesian Optimization over Permutation Spaces",
    "abstract": "Optimizing expensive to evaluate black-box functions over an input space\nconsisting of all permutations of d objects is an important problem with many\nreal-world applications. For example, placement of functional blocks in\nhardware design to optimize performance via simulations. The overall goal is to\nminimize the number of function evaluations to find high-performing\npermutations. The key challenge in solving this problem using the Bayesian\noptimization (BO) framework is to trade-off the complexity of statistical model\nand tractability of acquisition function optimization. In this paper, we\npropose and evaluate two algorithms for BO over Permutation Spaces (BOPS).\nFirst, BOPS-T employs Gaussian process (GP) surrogate model with Kendall\nkernels and a Tractable acquisition function optimization approach based on\nThompson sampling to select the sequence of permutations for evaluation.\nSecond, BOPS-H employs GP surrogate model with Mallow kernels and a Heuristic\nsearch approach to optimize expected improvement acquisition function. We\ntheoretically analyze the performance of BOPS-T to show that their regret grows\nsub-linearly. Our experiments on multiple synthetic and real-world benchmarks\nshow that both BOPS-T and BOPS-H perform better than the state-of-the-art BO\nalgorithm for combinatorial spaces. To drive future research on this important\nproblem, we make new resources and real-world benchmarks available to the\ncommunity.",
    "descriptor": "\nComments: Accepted at AAAI 2022\n",
    "authors": [
      "Aryan Deshwal",
      "Syrine Belakaria",
      "Janardhan Rao Doppa",
      "Dae Hyun Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01049"
  },
  {
    "id": "arXiv:2112.01050",
    "title": "CloudWalker: 3D Point Cloud Learning by Random Walks for Shape Analysis",
    "abstract": "Point clouds are gaining prominence as a method for representing 3D shapes,\nbut its irregular structure poses a challenge for deep learning methods. In\nthis paper we propose CloudWalker, a novel method for learning 3D shapes using\nrandom walks. Previous works attempt to adapt Convolutional Neural Networks\n(CNNS) or impose a grid or mesh structure to 3D point clouds. This work\npresents a different approach to represent and learn the shape from a given\npoint set. The key idea is to impose structure on the point set by multiple\nrandom walks through the cloud for exploring different regions of the 3D\nobject. Then we learn a per-point and per-walk representation and aggregate\nmultiple walk predictions at inference. Our approach achieves state-of-the-art\nresults for two 3D shape analysis tasks: classification and retrieval.\nFurthermore, we propose a shape complexity indicator function that uses\ncross-walk and inter-walk variance measures to subdivide the shape space.",
    "descriptor": "",
    "authors": [
      "Adi Mesika",
      "Yizhak Ben-Shabat",
      "Ayellet Tal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01050"
  },
  {
    "id": "arXiv:2112.01054",
    "title": "Emotions are Subtle: Learning Sentiment Based Text Representations Using  Contrastive Learning",
    "abstract": "Contrastive learning techniques have been widely used in the field of\ncomputer vision as a means of augmenting datasets. In this paper, we extend the\nuse of these contrastive learning embeddings to sentiment analysis tasks and\ndemonstrate that fine-tuning on these embeddings provides an improvement over\nfine-tuning on BERT-based embeddings to achieve higher benchmarks on the task\nof sentiment analysis when evaluated on the DynaSent dataset. We also explore\nhow our fine-tuned models perform on cross-domain benchmark datasets.\nAdditionally, we explore upsampling techniques to achieve a more balanced class\ndistribution to make further improvements on our benchmark tasks.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Ipsita Mohanty",
      "Ankit Goyal",
      "Alex Dotterweich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01054"
  },
  {
    "id": "arXiv:2112.01058",
    "title": "A Foreground-Background queueing model with speed or capacity modulation",
    "abstract": "The models studied in the steady state involve two queues which are served\neither by a single server whose speed depends on the number of jobs present, or\nby several parallel servers whose number may be controlled dynamically. Job\nservice times have a two-phase Coxian distribution and the second phase is\ngiven lower priority than the first. The trade-offs between holding costs and\nenergy consumption costs are examined by means of a suitable cost functions.\nTwo different two-dimensional Markov process are solved exactly. The solutions\nare used in several numerical experiments. Some counter-intuitive results are\nobserved.",
    "descriptor": "",
    "authors": [
      "Andrea Marin",
      "Isi Mitrani"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.01058"
  },
  {
    "id": "arXiv:2112.01059",
    "title": "Stronger Baseline for Person Re-Identification",
    "abstract": "Person re-identification (re-ID) aims to identify the same person of interest\nacross non-overlapping capturing cameras, which plays an important role in\nvisual surveillance applications and computer vision research areas. Fitting a\nrobust appearance-based representation extractor with limited collected\ntraining data is crucial for person re-ID due to the high expanse of annotating\nthe identity of unlabeled data. In this work, we propose a Stronger Baseline\nfor person re-ID, an enhancement version of the current prevailing method,\nnamely, Strong Baseline, with tiny modifications but a faster convergence rate\nand higher recognition performance. With the aid of Stronger Baseline, we\nobtained the third place (i.e., 0.94 in mAP) in 2021 VIPriors Re-identification\nChallenge without the auxiliary of ImageNet-based pre-trained parameter\ninitialization and any extra supplemental dataset.",
    "descriptor": "\nComments: The third-place solution for ICCV2021 VIPriors Re-identification Challenge\n",
    "authors": [
      "Fengliang Qi",
      "Bo Yan",
      "Leilei Cao",
      "Hongbin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01059"
  },
  {
    "id": "arXiv:2112.01061",
    "title": "Data-Driven Interaction Analysis of Line Failure Cascading in Power Grid  Networks",
    "abstract": "We use machine learning tools to model the line interaction of failure\ncascading in power grid networks. We first collect data sets of simulated\ntrajectories of possible consecutive line failure following an initial random\nfailure and considering actual constraints in a model power network until the\nsystem settles at a steady state. We use weighted $l_1$-regularized logistic\nregression-based models to find static and dynamic models that capture pairwise\nand latent higher-order lines' failure interactions using pairwise statistical\ndata. The static model captures the failures' interactions near the steady\nstates of the network, and the dynamic model captures the failure unfolding in\na time series of consecutive network states. We test models over independent\ntrajectories of failure unfolding in the network to evaluate their failure\npredictive power. We observe asymmetric, strongly positive, and negative\ninteractions between different lines' states in the network. We use the static\ninteraction model to estimate the distribution of cascade size and identify\ngroups of lines that tend to fail together, and compare against the data. The\ndynamic interaction model successfully predicts the network state for\nlong-lasting failure propagation trajectories after an initial failure.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Abdorasoul Ghasemi",
      "Holger Kantz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2112.01061"
  },
  {
    "id": "arXiv:2112.01062",
    "title": "Syntax Customized Video Captioning by Imitating Exemplar Sentences",
    "abstract": "Enhancing the diversity of sentences to describe video contents is an\nimportant problem arising in recent video captioning research. In this paper,\nwe explore this problem from a novel perspective of customizing video captions\nby imitating exemplar sentence syntaxes. Specifically, given a video and any\nsyntax-valid exemplar sentence, we introduce a new task of Syntax Customized\nVideo Captioning (SCVC) aiming to generate one caption which not only\nsemantically describes the video contents but also syntactically imitates the\ngiven exemplar sentence. To tackle the SCVC task, we propose a novel video\ncaptioning model, where a hierarchical sentence syntax encoder is firstly\ndesigned to extract the syntactic structure of the exemplar sentence, then a\nsyntax conditioned caption decoder is devised to generate the syntactically\nstructured caption expressing video semantics. As there is no available syntax\ncustomized groundtruth video captions, we tackle such a challenge by proposing\na new training strategy, which leverages the traditional pairwise video\ncaptioning data and our collected exemplar sentences to accomplish the model\nlearning. Extensive experiments, in terms of semantic, syntactic, fluency, and\ndiversity evaluations, clearly demonstrate our model capability to generate\nsyntax-varied and semantics-coherent video captions that well imitate different\nexemplar sentences with enriched diversities.",
    "descriptor": "",
    "authors": [
      "Yitian Yuan",
      "Lin Ma",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01062"
  },
  {
    "id": "arXiv:2112.01063",
    "title": "Fast automatic deforestation detectors and their extensions for other  spatial objects",
    "abstract": "This paper is devoted to the problem of detection of forest and non-forest\nareas on Earth images. We propose two statistical methods to tackle this\nproblem: one based on multiple hypothesis testing with parametric distribution\nfamilies, another one -- on non-parametric tests. The parametric approach is\nnovel in the literature and relevant to a larger class of problems -- detection\nof natural objects, as well as anomaly detection. We develop mathematical\nbackground for each of the two methods, build self-sufficient detection\nalgorithms using them and discuss numerical aspects of their implementation. We\nalso compare our algorithms with those from standard machine learning using\nsatellite data.",
    "descriptor": "",
    "authors": [
      "Jesper Muren",
      "Vilhelm Niklasson",
      "Dmitry Otryakhin",
      "Maxim Romashin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.01063"
  },
  {
    "id": "arXiv:2112.01064",
    "title": "AutoGEL: An Automated Graph Neural Network with Explicit Link  Information",
    "abstract": "Recently, Graph Neural Networks (GNNs) have gained popularity in a variety of\nreal-world scenarios. Despite the great success, the architecture design of\nGNNs heavily relies on manual labor. Thus, automated graph neural network\n(AutoGNN) has attracted interest and attention from the research community,\nwhich makes significant performance improvements in recent years. However,\nexisting AutoGNN works mainly adopt an implicit way to model and leverage the\nlink information in the graphs, which is not well regularized to the link\nprediction task on graphs, and limits the performance of AutoGNN for other\ngraph tasks. In this paper, we present a novel AutoGNN work that explicitly\nmodels the link information, abbreviated to AutoGEL. In such a way, AutoGEL can\nhandle the link prediction task and improve the performance of AutoGNNs on the\nnode classification and graph classification task. Specifically, AutoGEL\nproposes a novel search space containing various design dimensions at both\nintra-layer and inter-layer designs and adopts a more robust differentiable\nsearch algorithm to further improve efficiency and effectiveness. Experimental\nresults on benchmark data sets demonstrate the superiority of AutoGEL on\nseveral tasks.",
    "descriptor": "",
    "authors": [
      "Zhili Wang",
      "Shimin Di",
      "Lei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01064"
  },
  {
    "id": "arXiv:2112.01068",
    "title": "The Packet Number Space Debate in Multipath QUIC",
    "abstract": "With a standardization process that attracted many interest, QUIC can been\nseen as the next general-purpose transport protocol. Still, it does not provide\ntrue multipath support yet, missing some use cases that MPTCP can address. To\nfill that gap, the IETF recently adopted a multipath proposal merging all the\nproposed designs. While it focuses on its core components, there still remains\none major design issue in the proposal: the number of packet number spaces that\nshould be used. This paper provides experimental results with two different\nMultipath QUIC implementations based on NS3 simulations to understand the\nimpact of using one packet number space per path or a single packet number\nspace for the whole connection. Our results suggest that using one packet\nnumber space per path makes the Multipath QUIC connection more resilient to the\nreceiver's acknowledgment strategy.",
    "descriptor": "\nComments: 7 pages, submitted to ACM CCR\n",
    "authors": [
      "Quentin De Coninck"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.01068"
  },
  {
    "id": "arXiv:2112.01071",
    "title": "DenseCLIP: Extract Free Dense Labels from CLIP",
    "abstract": "Contrastive Language-Image Pre-training (CLIP) has made a remarkable\nbreakthrough in open-vocabulary zero-shot image recognition. Many recent\nstudies leverage the pre-trained CLIP models for image-level classification and\nmanipulation. In this paper, we further explore the potentials of CLIP for\npixel-level dense prediction, specifically in semantic segmentation. Our\nmethod, DenseCLIP, in the absence of annotations and fine-tuning, yields\nreasonable segmentation results on open concepts across various datasets. By\nadding pseudo labeling and self-training, DenseCLIP+ surpasses SOTA\ntransductive zero-shot semantic segmentation methods by large margins, e.g.,\nmIoUs of unseen classes on PASCAL VOC/PASCAL Context/COCO Stuff are improved\nfrom 35.6/20.7/30.3 to 86.1/66.7/54.7. We also test the robustness of DenseCLIP\nunder input corruption and evaluate its capability in discriminating\nfine-grained objects and novel concepts. Our finding suggests that DenseCLIP\ncan serve as a new reliable source of supervision for dense prediction tasks to\nachieve annotation-free segmentation.",
    "descriptor": "\nComments: Tech report, 12 pages, 6 figures\n",
    "authors": [
      "Chong Zhou",
      "Chen Change Loy",
      "Bo Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01071"
  },
  {
    "id": "arXiv:2112.01072",
    "title": "The Second Place Solution for ICCV2021 VIPriors Instance Segmentation  Challenge",
    "abstract": "The Visual Inductive Priors(VIPriors) for Data-Efficient Computer Vision\nchallenges ask competitors to train models from scratch in a data-deficient\nsetting. In this paper, we introduce the technical details of our submission to\nthe ICCV2021 VIPriors instance segmentation challenge. Firstly, we designed an\neffective data augmentation method to improve the problem of data-deficient.\nSecondly, we conducted some experiments to select a proper model and made some\nimprovements for this task. Thirdly, we proposed an effective training strategy\nwhich can improve the performance. Experimental results demonstrate that our\napproach can achieve a competitive result on the test set. According to the\ncompetition rules, we do not use any external image or video data and\npre-trained weights. The implementation details above are described in section\n2 and section 3. Finally, our approach can achieve 40.2\\%AP@0.50:0.95 on the\ntest set of ICCV2021 VIPriors instance segmentation challenge.",
    "descriptor": "",
    "authors": [
      "Bo Yan",
      "Fengliang Qi",
      "Leilei Cao",
      "Hongbin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01072"
  },
  {
    "id": "arXiv:2112.01073",
    "title": "Controllable Video Captioning with an Exemplar Sentence",
    "abstract": "In this paper, we investigate a novel and challenging task, namely\ncontrollable video captioning with an exemplar sentence. Formally, given a\nvideo and a syntactically valid exemplar sentence, the task aims to generate\none caption which not only describes the semantic contents of the video, but\nalso follows the syntactic form of the given exemplar sentence. In order to\ntackle such an exemplar-based video captioning task, we propose a novel Syntax\nModulated Caption Generator (SMCG) incorporated in an\nencoder-decoder-reconstructor architecture. The proposed SMCG takes video\nsemantic representation as an input, and conditionally modulates the gates and\ncells of long short-term memory network with respect to the encoded syntactic\ninformation of the given exemplar sentence. Therefore, SMCG is able to control\nthe states for word prediction and achieve the syntax customized caption\ngeneration. We conduct experiments by collecting auxiliary exemplar sentences\nfor two public video captioning datasets. Extensive experimental results\ndemonstrate the effectiveness of our approach on generating syntax controllable\nand semantic preserved video captions. By providing different exemplar\nsentences, our approach is capable of producing different captions with various\nsyntactic structures, thus indicating a promising way to strengthen the\ndiversity of video captioning.",
    "descriptor": "",
    "authors": [
      "Yitian Yuan",
      "Lin Ma",
      "Jingwen Wang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01073"
  },
  {
    "id": "arXiv:2112.01075",
    "title": "Memory-efficient array redistribution through portable collective  communication",
    "abstract": "Modern large-scale deep learning workloads highlight the need for parallel\nexecution across many devices in order to fit model data into hardware\naccelerator memories. In these settings, array redistribution may be required\nduring a computation, but can also become a bottleneck if not done efficiently.\nIn this paper we address the problem of redistributing multi-dimensional array\ndata in SPMD computations, the most prevalent form of parallelism in deep\nlearning. We present a type-directed approach to synthesizing array\nredistributions as sequences of MPI-style collective operations. We prove\nformally that our synthesized redistributions are memory-efficient and perform\nno excessive data transfers. Array redistribution for SPMD computations using\ncollective operations has also been implemented in the context of the XLA SPMD\npartitioner, a production-grade tool for partitioning programs across\naccelerator systems. We evaluate our approach against the XLA implementation\nand find that our approach delivers a geometric mean speedup of $1.22\\times$,\nwith maximum speedups as a high as $5.7\\times$, while offering provable memory\nguarantees, making our system particularly appealing for large-scale models.",
    "descriptor": "",
    "authors": [
      "Norman A. Rink",
      "Adam Paszke",
      "Dimitrios Vytiniotis",
      "Georg Stefan Schmid"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.01075"
  },
  {
    "id": "arXiv:2112.01077",
    "title": "Blind Super-resolution of Point Sources via Projected Gradient Descent",
    "abstract": "Blind super-resolution can be cast as a low rank matrix recovery problem by\nexploiting the inherent simplicity of the signal and the low dimensional\nstructure of point spread functions. In this paper, we develop a simple yet\nefficient non-convex projected gradient descent method for this problem based\non the low rank structure of the vectorized Hankel matrix associated with the\ntarget matrix. Theoretical analysis indicates that the proposed method exactly\nconverges to the target matrix with a linear convergence rate under the similar\nconditions as convex approaches. Numerical results show that our approach is\ncompetitive with existing convex approaches in terms of recovery ability and\nefficiency.",
    "descriptor": "\nComments: Part of this work is submitted to the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Singapore, May 2022. arXiv admin note: text overlap with arXiv:2110.02478\n",
    "authors": [
      "Sihan Mao",
      "Jinchi Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.01077"
  },
  {
    "id": "arXiv:2112.01078",
    "title": "Multi-Agent Intention Sharing via Leader-Follower Forest",
    "abstract": "Intention sharing is crucial for efficient cooperation under partially\nobservable environments in multi-agent reinforcement learning (MARL). However,\nmessage deceiving, i.e., a mismatch between the propagated intentions and the\nfinal decisions, may happen when agents change strategies simultaneously\naccording to received intentions. Message deceiving leads to potential\nmiscoordination and difficulty for policy learning. This paper proposes the\nleader-follower forest (LFF) to learn the hierarchical relationship between\nagents based on interdependencies, achieving one-sided intention sharing in\nmulti-agent communication. By limiting the flowings of intentions through\ndirected edges, intention sharing via LFF (IS-LFF) can eliminate message\ndeceiving effectively and achieve better coordination. In addition, a twostage\nlearning algorithm is proposed to train the forest and the agent network. We\nevaluate IS-LFF on multiple partially observable MARL benchmarks, and the\nexperimental results show that our method outperforms state-of-the-art\ncommunication algorithms.",
    "descriptor": "",
    "authors": [
      "Zeyang Liu",
      "Lipeng Wan",
      "Xue sui",
      "Kewu Sun",
      "Xuguang Lan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.01078"
  },
  {
    "id": "arXiv:2112.01079",
    "title": "Who will dropout from university? Academic risk prediction based on  interpretable machine learning",
    "abstract": "In the institutional research mode, in order to explore which characteristics\nare the best indicators for predicting academic risk from the student behavior\ndata sets that have high-dimensional, unbalanced classified small sample, it\ntransforms the academic risk prediction of college students into a binary\nclassification task. It predicts academic risk based on the LightGBM model and\nthe interpretable machine learning method of Shapley value. The simulation\nresults show that from the global perspective of the prediction model,\ncharacteristics such as the quality of academic partners, the seating position\nin classroom, the dormitory study atmosphere, the English scores of the college\nentrance examination, the quantity of academic partners, the addiction level of\nvideo games, the mobility of academic partners, and the degree of truancy are\nthe best 8 predictors for academic risk. It is contrary to intuition that\ncharacteristics such as living in campus or not, work-study, lipstick\naddiction, student leader or not, lover amount, and smoking have little\ncorrelation with university academic risk in this experiment. From the local\nperspective of the sample, the factors affecting academic risk vary from person\nto person. It can perform personalized interpretable analysis through Shapley\nvalues, which cannot be done by traditional mathematical statistical prediction\nmodels. The academic contributions of this research are mainly in two aspects:\nFirst, the learning interaction networks is proposed for the first time, so\nthat social behavior can be used to compensate for the one-sided individual\nbehavior and improve the performance of academic risk prediction. Second, the\nintroduction of Shapley value calculation makes machine learning that lacks a\nclear reasoning process visualized, and provides intuitive decision support for\neducation managers.",
    "descriptor": "\nComments: 15 pages,7 figures\n",
    "authors": [
      "Shudong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.01079"
  },
  {
    "id": "arXiv:2112.01082",
    "title": "Grafana plugin for visualising vote based consensus mechanisms, and  network P2P overlay networks",
    "abstract": "In this paper, we present a plugin for visualising vote based consensus\nmechanisms primarily aimed to help engineers understand and debug blockchain\nand distributed ledger protocols. Both tools are built as Grafana plugins and\nmake no assumptions on the data storage implementation. The plugins can be\nconfigured via Grafana plugin configuration interface to fit the specifics of\nthe protocol implementation.",
    "descriptor": "",
    "authors": [
      "Daniil Baldouski",
      "Aleksandar To\u0161i\u0107"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.01082"
  },
  {
    "id": "arXiv:2112.01085",
    "title": "TCTN: A 3D-Temporal Convolutional Transformer Network for Spatiotemporal  Predictive Learning",
    "abstract": "Spatiotemporal predictive learning is to generate future frames given a\nsequence of historical frames. Conventional algorithms are mostly based on\nrecurrent neural networks (RNNs). However, RNN suffers from heavy computational\nburden such as time and long back-propagation process due to the seriality of\nrecurrent structure. Recently, Transformer-based methods have also been\ninvestigated in the form of encoder-decoder or plain encoder, but the\nencoder-decoder form requires too deep networks and the plain encoder is lack\nof short-term dependencies. To tackle these problems, we propose an algorithm\nnamed 3D-temporal convolutional transformer (TCTN), where a transformer-based\nencoder with temporal convolutional layers is employed to capture short-term\nand long-term dependencies. Our proposed algorithm can be easy to implement and\ntrained much faster compared with RNN-based methods thanks to the parallel\nmechanism of Transformer. To validate our algorithm, we conduct experiments on\nthe MovingMNIST and KTH dataset, and show that TCTN outperforms\nstate-of-the-art (SOTA) methods in both performance and training speed.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Ziao Yang",
      "Xiangrui Yang",
      "Qifeng Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.01085"
  },
  {
    "id": "arXiv:2112.01087",
    "title": "NeuroHammer: Inducing Bit-Flips in Memristive Crossbar Memories",
    "abstract": "Emerging non-volatile memory (NVM) technologies offer unique advantages in\nenergy efficiency, latency, and features such as computing-in-memory.\nConsequently, emerging NVM technologies are considered an ideal substrate for\ncomputation and storage in future-generation neuromorphic platforms. These\ntechnologies need to be evaluated for fundamental reliability and security\nissues. In this paper, we present \\emph{NeuroHammer}, a security threat in\nReRAM crossbars caused by thermal crosstalk between memory cells. We\ndemonstrate that bit-flips can be deliberately induced in ReRAM devices in a\ncrossbar by systematically writing adjacent memory cells. A simulation flow is\ndeveloped to evaluate NeuroHammer and the impact of physical parameters on the\neffectiveness of the attack. Finally, we discuss the security implications in\nthe context of possible attack scenarios.",
    "descriptor": "",
    "authors": [
      "Felix Staudigl",
      "Hazem Al Indari",
      "Daniel Sch\u00f6n",
      "Dominik Sisejkovic",
      "Farhad Merchant",
      "Jan Moritz Joseph",
      "Vikas Rana",
      "Stephan Menzel",
      "Rainer Leupers"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.01087"
  },
  {
    "id": "arXiv:2112.01088",
    "title": "Constrained Machine Learning: The Bagel Framework",
    "abstract": "Machine learning models are widely used for real-world applications, such as\ndocument analysis and vision. Constrained machine learning problems are\nproblems where learned models have to both be accurate and respect constraints.\nFor continuous convex constraints, many works have been proposed, but learning\nunder combinatorial constraints is still a hard problem. The goal of this paper\nis to broaden the modeling capacity of constrained machine learning problems by\nincorporating existing work from combinatorial optimization. We propose first a\ngeneral framework called BaGeL (Branch, Generate and Learn) which applies\nBranch and Bound to constrained learning problems where a learning problem is\ngenerated and trained at each node until only valid models are obtained.\nBecause machine learning has specific requirements, we also propose an extended\ntable constraint to split the space of hypotheses. We validate the approach on\ntwo examples: a linear regression under configuration constraints and a\nnon-negative matrix factorization with prior knowledge for latent semantics\nanalysis.",
    "descriptor": "",
    "authors": [
      "Guillaume Perez",
      "Sebastian Ament",
      "Carla Gomes",
      "Arnaud Lallouet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.01088"
  },
  {
    "id": "arXiv:2112.01090",
    "title": "The Mirage of Universality in Cellular Automata",
    "abstract": "This note is a survey of examples and results about cellular automata with\nthe purpose of recalling that there is no 'universal' way of being\ncomputationally universal. In particular, we show how some cellular automata\ncan embed efficient but bounded computation, while others can embed unbounded\ncomputations but not efficiently. We also study two variants of Boolean circuit\nembedding, transient versus repeatable simulations, and underline their\ndifferences. Finally we show how strong forms of universality can be hidden\ninside some seemingly simple cellular automata according to some classical\ndynamical parameters.",
    "descriptor": "",
    "authors": [
      "Guillaume Theyssier"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.01090"
  },
  {
    "id": "arXiv:2112.01097",
    "title": "CoviChain: A Blockchain Based COVID-19 Vaccination Passport",
    "abstract": "Vaccination passports are being issued by governments around the world in\norder to open up their travel and hospitality sectors. Civil liberty\ncampaigners on the other hand argue that such mandatory instruments encroach\nupon our fundamental right to anonymity, freedom of movement, and are a\nbackdoor to issuing \"identity documents\" to citizens by their governments. We\npresent a privacy-preserving framework that uses two-factor authentication to\ncreate a unique identifier that can be used to locate a person's vaccination\nrecord on a blockchain, but does not store any personal information about them.\nOur main contribution is the employment of a locality sensitive hashing\nalgorithm over an iris extraction technique, that can be used to authenticate\nusers and anonymously locate vaccination records on the blockchain, without\nleaking any personally identifiable information to the blockchain. Our proposed\nsystem allows for the safe reopening of society, while maintaining the privacy\nof citizens.",
    "descriptor": "",
    "authors": [
      "Philip Bradish",
      "Sarang Chaudhari",
      "Michael Clear",
      "Hitesh Tewari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.01097"
  },
  {
    "id": "arXiv:2112.01098",
    "title": "Attention based Occlusion Removal for Hybrid Telepresence Systems",
    "abstract": "Traditionally, video conferencing is a widely adopted solution for\ntelecommunication, but a lack of immersiveness comes inherently due to the 2D\nnature of facial representation. The integration of Virtual Reality (VR) in a\ncommunication/telepresence system through Head Mounted Displays (HMDs) promises\nto provide users a much better immersive experience. However, HMDs cause\nhindrance by blocking the facial appearance and expressions of the user. To\novercome these issues, we propose a novel attention-enabled encoder-decoder\narchitecture for HMD de-occlusion. We also propose to train our person-specific\nmodel using short videos (1-2 minutes) of the user, captured in varying\nappearances, and demonstrated generalization to unseen poses and appearances of\nthe user. We report superior qualitative and quantitative results over\nstate-of-the-art methods. We also present applications of this approach to\nhybrid video teleconferencing using existing animation and 3D face\nreconstruction pipelines.",
    "descriptor": "",
    "authors": [
      "Surabhi Gupta",
      "Ashwath Shetty",
      "Avinash Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01098"
  },
  {
    "id": "arXiv:2112.01103",
    "title": "A tool to support the investigation and visualization of cyber and/or  physical incidents",
    "abstract": "Investigating efficiently the data collected from a system's activity can\nhelp to detect malicious attempts and better understand the context behind past\nincident occurrences. Nowadays, several solutions can be used to monitor system\nactivities to detect probable abnormalities and malfunctions. However, most of\nthese systems overwhelm their users with vast amounts of information, making it\nharder for them to perceive incident occurrences and their context. Our\napproach combines a dynamic and intuitive user interface with Machine Learning\nforecasts to provide an intelligent investigation tool that facilitates the\nsecurity operator's work. Our system can also act as an enhanced and fully\nautomated decision support mechanism that provides suggestions about possible\nincident occurrences.",
    "descriptor": "",
    "authors": [
      "In\u00eas Macedo",
      "Sinan Wanous",
      "Nuno Oliveira",
      "Orlando Sousa",
      "Isabel Pra\u00e7a"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.01103"
  },
  {
    "id": "arXiv:2112.01104",
    "title": "A Constant-Factor Approximation Algorithm for Point Guarding an Art  Gallery",
    "abstract": "Given a simple polygon $\\cal P$, in the Art Gallery problem the goal is to\nfind the minimum number of guards needed to cover the entire $\\cal P$, where a\nguard is a point and can see another point $q$ when $\\overline{pq}$ does not\ncross the edges of $\\cal P$.\nThis paper studies a variant of the Art Gallery problem in which guards are\nrestricted to lie on a dense grid inside $\\cal P$. In the general problem,\nguards can be anywhere inside or on the boundary of $\\cal P$. The general\nproblem is called the \\emph{point} guarding problem. It was proved that the\npoint guarding problem is APX-complete, meaning that we cannot do better than a\nconstant-factor approximation algorithm unless $P = NP$.\nA huge amount of research is committed to the studies of combinatorial and\nalgorithmic aspects of this problem, and as of this time, we could not find a\nconstant factor approximation for simple polygons. The last best-known\napproximation factor for point guarding a simple polygon was $\\mathcal{O}(\\log\n(|OPT|))$ introduced by E. Bonnet and T. Miltzow in 2020, where $|OPT|$ is the\nsize of the optimal solution. Here, we propose an algorithm with a constant\napproximation factor for the point guarding problem where the location of\nguards is restricted to a grid. The running time of the proposed algorithm\ndepends on the number of cells of the grid. The approximation factor is\nconstant regardless of the grid we use, the running time could be\nsuper-polynomial if the grid size becomes exponential.",
    "descriptor": "",
    "authors": [
      "Arash Vaezi",
      "Mohammad Ghodsi"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.01104"
  },
  {
    "id": "arXiv:2112.01107",
    "title": "Control of over-redundant cooperative manipulation via sampled  communication",
    "abstract": "In this work we consider the problem of mobile robots that need to\nmanipulate/transport an object via cables or robotic arms. We consider the\nscenario where the number of manipulating robots is redundant, i.e. a desired\nobject configuration can be obtained by different configurations of the robots.\nThe objective of this work is to show that communication can be used to\nimplement cooperative local feedback controllers in the robots to improve\ndisturbance rejection and reduce structural stress in the object. In particular\nwe consider the realistic scenario where measurements are sampled and\ntransmitted over wireless, and the sampling period is comparable with the\nsystem dynamics time constants. We first propose a kinematic model which is\nconsistent with the overall systems dynamics under high-gain control and then\nwe provide sufficient conditions for the exponential stability and monotonic\ndecrease of the configuration error under different norms. Finally, we test the\nproposed controllers on the full dynamical systems showing the benefit of local\ncommunication.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Enrica Rossi",
      "Marco Tognon",
      "Ruggero Carli",
      "Antonio Franchi",
      "Luca Schenato"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.01107"
  },
  {
    "id": "arXiv:2112.01108",
    "title": "A short note on the counting complexity of conjunctive queries",
    "abstract": "This note closes a minor gap in the literature on the counting complexity of\nconjunctive queries by showing that queries that are not free-connex do not\nhave a linear time counting algorithm under standard complexity assumptions.\nMore generally, it is shown that the so-called quantified star size is a lower\nbound for the exponent in the runtime of any counting algorithm for conjunctive\nqueries.",
    "descriptor": "",
    "authors": [
      "Stefan Mengel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.01108"
  },
  {
    "id": "arXiv:2112.01110",
    "title": "Contrastive Adaptive Propagation Graph Neural Networks for Efficient  Graph Learning",
    "abstract": "Graph Neural Networks (GNNs) have achieved great success in processing graph\ndata by extracting and propagating structure-aware features. Existing GNN\nresearch designs various propagation schemes to guide the aggregation of\nneighbor information. Recently the field has advanced from local propagation\nschemes that focus on local neighbors towards extended propagation schemes that\ncan directly deal with extended neighbors consisting of both local and\nhigh-order neighbors. Despite the impressive performance, existing approaches\nare still insufficient to build an efficient and learnable extended propagation\nscheme that can adaptively adjust the influence of local and high-order\nneighbors. This paper proposes an efficient yet effective end-to-end framework,\nnamely Contrastive Adaptive Propagation Graph Neural Networks (CAPGNN), to\naddress these issues by combining Personalized PageRank and attention\ntechniques. CAPGNN models the learnable extended propagation scheme with a\npolynomial of a sparse local affinity matrix, where the polynomial relies on\nPersonalized PageRank to provide superior initial coefficients. In order to\nadaptively adjust the influence of both local and high-order neighbors, a\ncoefficient-attention model is introduced to learn to adjust the coefficients\nof the polynomial. In addition, we leverage self-supervised learning techniques\nand design a negative-free entropy-aware contrastive loss to explicitly take\nadvantage of unlabeled data for training. We implement CAPGNN as two different\nversions named CAPGCN and CAPGAT, which use static and dynamic sparse local\naffinity matrices, respectively. Experiments on graph benchmark datasets\nsuggest that CAPGNN can consistently outperform or match state-of-the-art\nbaselines. The source code is publicly available at\nhttps://github.com/hujunxianligong/CAPGNN.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Jun Hu",
      "Shengsheng Qian",
      "Quan Fang",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.01110"
  },
  {
    "id": "arXiv:2112.01121",
    "title": "\"Just Drive\": Colour Bias Mitigation for Semantic Segmentation in the  Context of Urban Driving",
    "abstract": "Biases can filter into AI technology without our knowledge. Oftentimes,\nseminal deep learning networks champion increased accuracy above all else. In\nthis paper, we attempt to alleviate biases encountered by semantic segmentation\nmodels in urban driving scenes, via an iteratively trained unlearning\nalgorithm. Convolutional neural networks have been shown to rely on colour and\ntexture rather than geometry. This raises issues when safety-critical\napplications, such as self-driving cars, encounter images with covariate shift\nat test time - induced by variations such as lighting changes or seasonality.\nConceptual proof of bias unlearning has been shown on simple datasets such as\nMNIST. However, the strategy has never been applied to the safety-critical\ndomain of pixel-wise semantic segmentation of highly variable training data -\nsuch as urban scenes. Trained models for both the baseline and bias unlearning\nscheme have been tested for performance on colour-manipulated validation sets\nshowing a disparity of up to 85.50% in mIoU from the original RGB images -\nconfirming segmentation networks strongly depend on the colour information in\nthe training data to make their classification. The bias unlearning scheme\nshows improvements of handling this covariate shift of up to 61% in the best\nobserved case - and performs consistently better at classifying the \"human\" and\n\"vehicle\" classes compared to the baseline model.",
    "descriptor": "\nComments: 2021 IEEE International Conference on Big Data (IEEE BigData 2021)\n",
    "authors": [
      "Jack Stelling",
      "Amir Atapour-Abarghouei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01121"
  },
  {
    "id": "arXiv:2112.01122",
    "title": "CEV Framework: A Central Bank Digital Currency Evaluation and  Verification Framework with Focus of Consensus Algorithms and Operating  Models",
    "abstract": "We propose a general framework (CEV Framework) for recommending and verifying\ntechnical solutions in central bank digital currency(CBDC) system, in which we\nbuild two sub-frameworks: an evaluation sub-framework that analyzes current\nproblems about CBDC and provides solutions in terms of consensus algorithms and\noperating models, and a verification sub-framework that proves the feasibility\nof recommended solutions. Our framework provides a workflow and can be used as\na reference to design CBDC systems based on related national economic and\nregulatory conditions. The working procedure to generate customized solutions\nis to split consensus algorithms into different components and analyze their\nimpact on CBDC systems. Furthermore, we also propose two operating models to\ncover operational aspects. Then we build a verification sub-framework to verify\npotential solutions through empirical experiments and formal logic proof. To\nthe best of our knowledge, we are the first to propose a framework to recommend\nand verify CBDC related technical solutions.",
    "descriptor": "",
    "authors": [
      "Si Yuan Jin",
      "Yong Xia"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2112.01122"
  },
  {
    "id": "arXiv:2112.01126",
    "title": "Situation-Aware Environment Perception Using a Multi-Layer Attention Map",
    "abstract": "Within the field of automated driving, a clear trend in environment\nperception tends towards more sensors, higher redundancy, and overall increase\nin computational power. This is mainly driven by the paradigm to perceive the\nentire environment as best as possible at all times. However, due to the\nongoing rise in functional complexity, compromises have to be considered to\nensure real-time capabilities of the perception system.\nIn this work, we introduce a concept for situation-aware environment\nperception to control the resource allocation towards processing relevant areas\nwithin the data as well as towards employing only a subset of functional\nmodules for environment perception, if sufficient for the current driving task.\nSpecifically, we propose to evaluate the context of an automated vehicle to\nderive a multi-layer attention map (MLAM) that defines relevant areas. Using\nthis MLAM, the optimum of active functional modules is dynamically configured\nand intra-module processing of only relevant data is enforced.\nWe outline the feasibility of application of our concept using real-world\ndata in a straight-forward implementation for our system at hand. While\nretaining overall functionality, we achieve a reduction of accumulated\nprocessing time of 59%.",
    "descriptor": "\nComments: Submitted to review and possible publication. Copyright will be transferred without notice\n",
    "authors": [
      "Matti Henning",
      "Johannes M\u00fcller",
      "Fabian Gies",
      "Michael Buchholz",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.01126"
  },
  {
    "id": "arXiv:2112.01131",
    "title": "FNR: A Similarity and Transformer-Based Approachto Detect Multi-Modal  FakeNews in Social Media",
    "abstract": "The availability and interactive nature of social media have made them the\nprimary source of news around the globe. The popularity of social media tempts\ncriminals to pursue their immoral intentions by producing and disseminating\nfake news using seductive text and misleading images. Therefore, verifying\nsocial media news and spotting fakes is crucial. This work aims to analyze\nmulti-modal features from texts and images in social media for detecting fake\nnews. We propose a Fake News Revealer (FNR) method that utilizes transform\nlearning to extract contextual and semantic features and contrastive loss to\ndetermine the similarity between image and text. We applied FNR on two real\nsocial media datasets. The results show the proposed method achieves higher\naccuracies in detecting fake news compared to the previous works.",
    "descriptor": "\nComments: 10 pages, 11 figures, 4 tables and 20 references\n",
    "authors": [
      "Faeze Ghorbanpour",
      "Maryam Ramezani",
      "Mohammad A. Fazli",
      "Hamid R. Rabiee"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.01131"
  },
  {
    "id": "arXiv:2112.01132",
    "title": "A Practical Dynamic Programming Approach to Datalog Provenance  Computation",
    "abstract": "We establish a translation between a formalism for dynamic programming over\nhypergraphs and the computation of semiring-based provenance for Datalog\nprograms. The benefit of this translation is a new method for computing\nprovenance for a specific class of semirings. Theoretical and practical\noptimizations lead to an efficient implementation using \\textsc{Souffl\\'e}, a\nstate-of-the-art Datalog interpreter. Experimental results on real-world data\nsuggest this approach to be efficient in practical contexts, even competing\nwith our previous dedicated solutions for computing provenance in annotated\ngraph databases. The cost overhead compared to plain Datalog evaluation is\nfairly moderate in many cases of interest.",
    "descriptor": "",
    "authors": [
      "Yann Ramusat",
      "Silviu Maniu",
      "Pierre Senellart"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.01132"
  },
  {
    "id": "arXiv:2112.01135",
    "title": "Open-set 3D Object Detection",
    "abstract": "3D object detection has been wildly studied in recent years, especially for\nrobot perception systems. However, existing 3D object detection is under a\nclosed-set condition, meaning that the network can only output boxes of trained\nclasses. Unfortunately, this closed-set condition is not robust enough for\npractical use, as it will identify unknown objects as known by mistake.\nTherefore, in this paper, we propose an open-set 3D object detector, which aims\nto (1) identify known objects, like the closed-set detection, and (2) identify\nunknown objects and give their accurate bounding boxes. Specifically, we divide\nthe open-set 3D object detection problem into two steps: (1) finding out the\nregions containing the unknown objects with high probability and (2) enclosing\nthe points of these regions with proper bounding boxes. The first step is\nsolved by the finding that unknown objects are often classified as known\nobjects with low confidence, and we show that the Euclidean distance sum based\non metric learning is a better confidence score than the naive softmax\nprobability to differentiate unknown objects from known objects. On this basis,\nunsupervised clustering is used to refine the bounding boxes of unknown\nobjects. The proposed method combining metric learning and unsupervised\nclustering is called the MLUC network. Our experiments show that our MLUC\nnetwork achieves state-of-the-art performance and can identify both known and\nunknown objects as expected.",
    "descriptor": "\nComments: Received by 3DV 2021\n",
    "authors": [
      "Jun Cen",
      "Peng Yun",
      "Junhao Cai",
      "Michael Yu Wang",
      "Ming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01135"
  },
  {
    "id": "arXiv:2112.01141",
    "title": "Risk-Aware Algorithms for Combinatorial Semi-Bandits",
    "abstract": "In this paper, we study the stochastic combinatorial multi-armed bandit\nproblem under semi-bandit feedback. While much work has been done on algorithms\nthat optimize the expected reward for linear as well as some general reward\nfunctions, we study a variant of the problem, where the objective is to be\nrisk-aware. More specifically, we consider the problem of maximizing the\nConditional Value-at-Risk (CVaR), a risk measure that takes into account only\nthe worst-case rewards. We propose new algorithms that maximize the CVaR of the\nrewards obtained from the super arms of the combinatorial bandit for the two\ncases of Gaussian and bounded arm rewards. We further analyze these algorithms\nand provide regret bounds. We believe that our results provide the first\ntheoretical insights into combinatorial semi-bandit problems in the risk-aware\ncase.",
    "descriptor": "",
    "authors": [
      "Shaarad Ayyagari",
      "Ambedkar Dukkipati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01141"
  },
  {
    "id": "arXiv:2112.01146",
    "title": "Conversational Agents in Therapeutic Interventions for  Neurodevelopmental Disorders: A Survey",
    "abstract": "Neurodevelopmental Disorders (NDD) are a group of conditions with onset in\nthe developmental period characterized by deficits in the cognitive and social\nareas. Conversational agents have been increasingly explored to support\ntherapeutic interventions for people with NDD. This survey provides a\nstructured view of the crucial design features of these systems, the types of\ntherapeutic goals they address, and the empirical methods adopted for their\nevaluation. From this analysis, we elaborate a set of recommendations and\nhighlight the gaps left unsolved in the state of the art, upon which we ground\na research agenda on conversational agents for NDD.",
    "descriptor": "",
    "authors": [
      "Fabio Catania",
      "Micol Spitale",
      "Franca Garzotto"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.01146"
  },
  {
    "id": "arXiv:2112.01147",
    "title": "CO2Sum:Contrastive Learning for Factual-Consistent Abstractive  Summarization",
    "abstract": "Generating factual-consistent summaries is a challenging task for abstractive\nsummarization. Previous works mainly encode factual information or perform\npost-correct/rank after decoding. In this paper, we provide a\nfactual-consistent solution from the perspective of contrastive learning, which\nis a natural extension of previous works. We propose CO2Sum (Contrastive for\nConsistency), a contrastive learning scheme that can be easily applied on\nsequence-to-sequence models for factual-consistent abstractive summarization,\nproving that the model can be fact-aware without modifying the architecture.\nCO2Sum applies contrastive learning on the encoder, which can help the model be\naware of the factual information contained in the input article, or performs\ncontrastive learning on the decoder, which makes the model to generate\nfactual-correct output summary. What's more, these two schemes are orthogonal\nand can be combined to further improve faithfulness. Comprehensive experiments\non public benchmarks demonstrate that CO2Sum improves the faithfulness on large\npre-trained language models and reaches competitive results compared to other\nstrong factual-consistent summarization baselines.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Wei Liu",
      "Huanqin Wu",
      "Wenjing Mu",
      "Zhen Li",
      "Tao Chen",
      "Dan Nie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01147"
  },
  {
    "id": "arXiv:2112.01148",
    "title": "FIBA: Frequency-Injection based Backdoor Attack in Medical Image  Analysis",
    "abstract": "In recent years, the security of AI systems has drawn increasing research\nattention, especially in the medical imaging realm. To develop a secure medical\nimage analysis (MIA) system, it is a must to study possible backdoor attacks\n(BAs), which can embed hidden malicious behaviors into the system. However,\ndesigning a unified BA method that can be applied to various MIA systems is\nchallenging due to the diversity of imaging modalities (e.g., X-Ray, CT, and\nMRI) and analysis tasks (e.g., classification, detection, and segmentation).\nMost existing BA methods are designed to attack natural image classification\nmodels, which apply spatial triggers to training images and inevitably corrupt\nthe semantics of poisoned pixels, leading to the failures of attacking dense\nprediction models. To address this issue, we propose a novel\nFrequency-Injection based Backdoor Attack method (FIBA) that is capable of\ndelivering attacks in various MIA tasks. Specifically, FIBA leverages a trigger\nfunction in the frequency domain that can inject the low-frequency information\nof a trigger image into the poisoned image by linearly combining the spectral\namplitude of both images. Since it preserves the semantics of the poisoned\nimage pixels, FIBA can perform attacks on both classification and dense\nprediction models. Experiments on three benchmarks in MIA (i.e., ISIC-2019 for\nskin lesion classification, KiTS-19 for kidney tumor segmentation, and EAD-2019\nfor endoscopic artifact detection), validate the effectiveness of FIBA and its\nsuperiority over state-of-the-art methods in attacking MIA models as well as\nbypassing backdoor defense. The code will be available at\nhttps://github.com/HazardFY/FIBA.",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Yu Feng",
      "Benteng Ma",
      "Jing Zhang",
      "Shanshan Zhao",
      "Yong Xia",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01148"
  },
  {
    "id": "arXiv:2112.01154",
    "title": "Autonomous Vehicular Networks: Perspective and Open Issues",
    "abstract": "The vehicular ad hoc networks (VANETs) have been researched for over twenty\nyears. Although being a fundamental communication approach for vehicles, the\nconventional VANETs are challenged by the newly emerged autonomous vehicles\n(AVs) which introduce new features and challenges on communications. In the\nmeantime, with the recent advances of artificial intelligence and 5G cellular\nnetworks, how should the fundamental framework of VANET evolve to utilize the\nnew technologies? In this article, we reconsider the problem of\nvehicle-to-vehicle communications when the network is composed of AVs. We\ndiscuss the features and specific demands of AVs and how the conventional\nVANETs should adapt to fit them.",
    "descriptor": "",
    "authors": [
      "Tom H. Luan",
      "Yao Zhang",
      "Lin Cai",
      "Yilong Hui",
      "Changle Li",
      "Nan Cheng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.01154"
  },
  {
    "id": "arXiv:2112.01155",
    "title": "Batch Normalization Tells You Which Filter is Important",
    "abstract": "The goal of filter pruning is to search for unimportant filters to remove in\norder to make convolutional neural networks (CNNs) efficient without\nsacrificing the performance in the process. The challenge lies in finding\ninformation that can help determine how important or relevant each filter is\nwith respect to the final output of neural networks. In this work, we share our\nobservation that the batch normalization (BN) parameters of pre-trained CNNs\ncan be used to estimate the feature distribution of activation outputs, without\nprocessing of training data. Upon observation, we propose a simple yet\neffective filter pruning method by evaluating the importance of each filter\nbased on the BN parameters of pre-trained CNNs. The experimental results on\nCIFAR-10 and ImageNet demonstrate that the proposed method can achieve\noutstanding performance with and without fine-tuning in terms of the trade-off\nbetween the accuracy drop and the reduction in computational complexity and\nnumber of parameters of pruned networks.",
    "descriptor": "",
    "authors": [
      "Junghun Oh",
      "Heewon Kim",
      "Sungyong Baik",
      "Cheeun Hong",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01155"
  },
  {
    "id": "arXiv:2112.01156",
    "title": "A Unified Framework for Adversarial Attack and Defense in Constrained  Feature Space",
    "abstract": "The generation of feasible adversarial examples is necessary for properly\nassessing models that work on constrained feature space. However, it remains a\nchallenging task to enforce constraints into attacks that were designed for\ncomputer vision. We propose a unified framework to generate feasible\nadversarial examples that satisfy given domain constraints. Our framework\nsupports the use cases reported in the literature and can handle both linear\nand non-linear constraints. We instantiate our framework into two algorithms: a\ngradient-based attack that introduces constraints in the loss function to\nmaximize, and a multi-objective search algorithm that aims for\nmisclassification, perturbation minimization, and constraint satisfaction. We\nshow that our approach is effective on two datasets from different domains,\nwith a success rate of up to 100%, where state-of-the-art attacks fail to\ngenerate a single feasible example. In addition to adversarial retraining, we\npropose to introduce engineered non-convex constraints to improve model\nadversarial robustness. We demonstrate that this new defense is as effective as\nadversarial retraining. Our framework forms the starting point for research on\nconstrained adversarial attacks and provides relevant baselines and datasets\nthat future research can exploit.",
    "descriptor": "",
    "authors": [
      "Thibault Simonetto",
      "Salijona Dyrmishi",
      "Salah Ghamizi",
      "Maxime Cordy",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01156"
  },
  {
    "id": "arXiv:2112.01159",
    "title": "Perception and Attitude of Reddit Users Towards Use of Face-Masks in  Controlling COVID-19",
    "abstract": "In the wake of the COVID-19 pandemic, World Health Organization (WHO)\nrecommended the use of face-masks to combat the disease. A fraction of the\npopulation has been vocal about their disapproval, especially on social media.\nMotivated by the need to understand their opinions, an international online\nsurvey in English was shared to the community /r/SampleSize in Reddit. The\nresults obtained were summarized; binomial and multinomial confidence intervals\nwere constructed for variables of interest; Pearson's Chi-squared test was used\nto test whether relationship exists between two variables of interest. A\nsecond, smaller survey was conducted to cross-validate the results. The study\ndemonstrates that despite the digital polarization of public opinion, opinions\nfrom both sides of the spectrum are not ubiquitous.",
    "descriptor": "",
    "authors": [
      "G.N. Singh",
      "D. Bhattacharyya",
      "A. Bandyopadhyay"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.01159"
  },
  {
    "id": "arXiv:2112.01160",
    "title": "Learning Robust Recommender from Noisy Implicit Feedback",
    "abstract": "The ubiquity of implicit feedback makes it indispensable for building\nrecommender systems. However, it does not actually reflect the actual\nsatisfaction of users. For example, in E-commerce, a large portion of clicks do\nnot translate to purchases, and many purchases end up with negative reviews. As\nsuch, it is of importance to account for the inevitable noises in implicit\nfeedback. However, little work on recommendation has taken the noisy nature of\nimplicit feedback into consideration. In this work, we explore the central\ntheme of denoising implicit feedback for recommender learning, including\ntraining and inference. By observing the process of normal recommender\ntraining, we find that noisy feedback typically has large loss values in the\nearly stages. Inspired by this observation, we propose a new training strategy\nnamed Adaptive Denoising Training (ADT), which adaptively prunes the noisy\ninteractions by two paradigms (i.e., Truncated Loss and Reweighted Loss).\nFurthermore, we consider extra feedback (e.g., rating) as auxiliary signal and\npropose three strategies to incorporate extra feedback into ADT: finetuning,\nwarm-up training, and colliding inference. We instantiate the two paradigms on\nthe widely used binary cross-entropy loss and test them on three representative\nrecommender models. Extensive experiments on three benchmarks demonstrate that\nADT significantly improves the quality of recommendation over normal training\nwithout using extra feedback. Besides, the proposed three strategies for using\nextra feedback largely enhance the denoising ability of ADT.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2006.04153\n",
    "authors": [
      "Wenjie Wang",
      "Fuli Feng",
      "Xiangnan He",
      "Liqiang Nie",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01160"
  },
  {
    "id": "arXiv:2112.01161",
    "title": "Video Frame Interpolation without Temporal Priors",
    "abstract": "Video frame interpolation, which aims to synthesize non-exist intermediate\nframes in a video sequence, is an important research topic in computer vision.\nExisting video frame interpolation methods have achieved remarkable results\nunder specific assumptions, such as instant or known exposure time. However, in\ncomplicated real-world situations, the temporal priors of videos, i.e. frames\nper second (FPS) and frame exposure time, may vary from different camera\nsensors. When test videos are taken under different exposure settings from\ntraining ones, the interpolated frames will suffer significant misalignment\nproblems. In this work, we solve the video frame interpolation problem in a\ngeneral situation, where input frames can be acquired under uncertain exposure\n(and interval) time. Unlike previous methods that can only be applied to a\nspecific temporal prior, we derive a general curvilinear motion trajectory\nformula from four consecutive sharp frames or two consecutive blurry frames\nwithout temporal priors. Moreover, utilizing constraints within adjacent motion\ntrajectories, we devise a novel optical flow refinement strategy for better\ninterpolation results. Finally, experiments demonstrate that one well-trained\nmodel is enough for synthesizing high-quality slow-motion videos under\ncomplicated real-world situations. Codes are available on\nhttps://github.com/yjzhang96/UTI-VFI.",
    "descriptor": "\nComments: Accepted by Neural Information Processing Systems (NeurIPS) 2020\n",
    "authors": [
      "Youjian Zhang",
      "Chaoyue Wang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01161"
  },
  {
    "id": "arXiv:2112.01163",
    "title": "Robust Robotic Control from Pixels using Contrastive Recurrent  State-Space Models",
    "abstract": "Modeling the world can benefit robot learning by providing a rich training\nsignal for shaping an agent's latent state space. However, learning world\nmodels in unconstrained environments over high-dimensional observation spaces\nsuch as images is challenging. One source of difficulty is the presence of\nirrelevant but hard-to-model background distractions, and unimportant visual\ndetails of task-relevant entities. We address this issue by learning a\nrecurrent latent dynamics model which contrastively predicts the next\nobservation. This simple model leads to surprisingly robust robotic control\neven with simultaneous camera, background, and color distractions. We\noutperform alternatives such as bisimulation methods which impose\nstate-similarity measures derived from divergence in future reward or future\noptimal actions. We obtain state-of-the-art results on the Distracting Control\nSuite, a challenging benchmark for pixel-based robotic control.",
    "descriptor": "\nComments: NeurIPS Deep Reinforcement Learning Workshop 2021. Code can be found at this https URL\n",
    "authors": [
      "Nitish Srivastava",
      "Walter Talbott",
      "Martin Bertran Lopez",
      "Shuangfei Zhai",
      "Josh Susskind"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.01163"
  },
  {
    "id": "arXiv:2112.01165",
    "title": "Subgraph Contrastive Link Representation Learning",
    "abstract": "Graph representation learning (GRL) has emerged as a powerful technique for\nsolving graph analytics tasks. It can effectively convert discrete graph data\ninto a low-dimensional space where the graph structural information and graph\nproperties are maximumly preserved. While there is rich literature on node and\nwhole-graph representation learning, GRL for link is relatively less studied\nand less understood. One common practice in previous works is to generate link\nrepresentations by directly aggregating the representations of their incident\nnodes, which is not capable of capturing effective link features. Moreover,\ncommon GRL methods usually rely on full-graph training, suffering from poor\nscalability and high resource consumption on large-scale graphs. In this paper,\nwe design Subgraph Contrastive Link Representation Learning (SCLRL) -- a\nself-supervised link embedding framework, which utilizes the strong correlation\nbetween central links and their neighborhood subgraphs to characterize links.\nWe extract the \"link-centric induced subgraphs\" as input, with a subgraph-level\ncontrastive discrimination as pretext task, to learn the intrinsic and\nstructural link features via subgraph mini-batch training. Extensive\nexperiments conducted on five datasets demonstrate that SCLRL has significant\nperformance advantages in link representation learning on benchmark datasets\nand prominent efficiency advantages in terms of training speed and memory\nconsumption on large-scale graphs, when compared with existing link\nrepresentation learning methods.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Jiajun Zhou",
      "Qi Xuan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.01165"
  },
  {
    "id": "arXiv:2112.01167",
    "title": "Multi-scale simulation of COVID-19 epidemics",
    "abstract": "Over a year after the start of the COVID-19 epidemics, we are still facing\nthe virus and it is hard to correctly predict its future spread over weeks to\ncome, as well as the impacts of potential political interventions. Current\nepidemic models mainly fall in two approaches: compartmental models, divide the\npopulation in epidemiological classes and rely on the mathematical resolution\nof differential equations to give a macroscopic view of the epidemical\ndynamics, allowing to evaluate its spread a posteriori; agent-based models are\ncomputer models that give a microscopic view of the situation, since each human\nis modelled as one autonomous agent, allowing to study the epidemical dynamics\nin relation to (heterogeneous) individual behaviours. In this work, we compared\nboth methodologies and combined them to try and take advantage of the benefits\nof each, and to overcome their limits. In particular, agent-based simulation\ncan be used to refine the values of the parameters of a compartmental model, or\nto predict how these values evolve depending on sanitary policies applied. In\nthis report we discuss the conditions of such a combination of approaches, and\nfuture improvements.",
    "descriptor": "\nComments: M2 internship report for ENSIMAG degree\n",
    "authors": [
      "Benoit Doussin",
      "Carole Adam",
      "Didier Georges"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2112.01167"
  },
  {
    "id": "arXiv:2112.01168",
    "title": "MemPool-3D: Boosting Performance and Efficiency of Shared-L1 Memory  Many-Core Clusters with 3D Integration",
    "abstract": "Three-dimensional integrated circuits promise power, performance, and\nfootprint gains compared to their 2D counterparts, thanks to drastic reductions\nin the interconnects' length through their smaller form factor. We can leverage\nthe potential of 3D integration by enhancing MemPool, an open-source many-core\ndesign with 256 cores and a shared pool of L1 scratchpad memory connected with\na low-latency interconnect. MemPool's baseline 2D design is severely limited by\nrouting congestion and wire propagation delay, making the design ideal for 3D\nintegration. In architectural terms, we increase MemPool's scratchpad memory\ncapacity beyond the sweet spot for 2D designs, improving performance in a\ncommon digital signal processing kernel. We propose a 3D MemPool design that\nleverages a smart partitioning of the memory resources across two layers to\nbalance the size and utilization of the stacked dies. In this paper, we explore\nthe architectural and the technology parameter spaces by analyzing the power,\nperformance, area, and energy efficiency of MemPool instances in 2D and 3D with\n1 MiB, 2 MiB, 4 MiB, and 8 MiB of scratchpad memory in a commercial 28 nm\ntechnology node. We observe a performance gain of 9.1% when running a matrix\nmultiplication on the MemPool-3D design with 4 MiB of scratchpad memory\ncompared to the MemPool 2D counterpart. In terms of energy efficiency, we can\nimplement the MemPool-3D instance with 4 MiB of L1 memory on an energy budget\n15% smaller than its 2D counterpart, and even 3.7% smaller than the MemPool-2D\ninstance with one-fourth of the L1 scratchpad memory capacity.",
    "descriptor": "\nComments: Accepted for publication in DATE 2022 -- Design, Automation and Test in Europe Conference\n",
    "authors": [
      "Matheus Cavalcante",
      "Anthony Agnesina",
      "Samuel Riedel",
      "Moritz Brunion",
      "Alberto Garcia-Ortiz",
      "Dragomir Milojevic",
      "Francky Catthoor",
      "Sung Kyu Lim",
      "Luca Benini"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.01168"
  },
  {
    "id": "arXiv:2112.01174",
    "title": "Multi-task Self-distillation for Graph-based Semi-Supervised Learning",
    "abstract": "Graph convolutional networks have made great progress in graph-based\nsemi-supervised learning. Existing methods mainly assume that nodes connected\nby graph edges are prone to have similar attributes and labels, so that the\nfeatures smoothed by local graph structures can reveal the class similarities.\nHowever, there often exist mismatches between graph structures and labels in\nmany real-world scenarios, where the structures may propagate misleading\nfeatures or labels that eventually affect the model performance. In this paper,\nwe propose a multi-task self-distillation framework that injects\nself-supervised learning and self-distillation into graph convolutional\nnetworks to separately address the mismatch problem from the structure side and\nthe label side. First, we formulate a self-supervision pipeline based on\npre-text tasks to capture different levels of similarities in graphs. The\nfeature extraction process is encouraged to capture more complex proximity by\njointly optimizing the pre-text task and the target task. Consequently, the\nlocal feature aggregations are improved from the structure side. Second,\nself-distillation uses soft labels of the model itself as additional\nsupervision, which has similar effects as label smoothing. The knowledge from\nthe classification pipeline and the self-supervision pipeline is collectively\ndistilled to improve the generalization ability of the model from the label\nside. Experiment results show that the proposed method obtains remarkable\nperformance gains under several classic graph convolutional architectures.",
    "descriptor": "",
    "authors": [
      "Yating Ren",
      "Junzhong Ji",
      "Lingfeng Niu",
      "Minglong Lei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01174"
  },
  {
    "id": "arXiv:2112.01176",
    "title": "Overcoming the Domain Gap in Neural Action Representations",
    "abstract": "Relating animal behaviors to brain activity is a fundamental goal in\nneuroscience, with practical applications in building robust brain-machine\ninterfaces. However, the domain gap between individuals is a major issue that\nprevents the training of general models that work on unlabeled subjects.\nSince 3D pose data can now be reliably extracted from multi-view video\nsequences without manual intervention, we propose to use it to guide the\nencoding of neural action representations together with a set of neural and\nbehavioral augmentations exploiting the properties of microscopy imaging. To\nreduce the domain gap, during training, we swap neural and behavioral data\nacross animals that seem to be performing similar actions.\nTo demonstrate this, we test our methods on three very different multimodal\ndatasets; one that features flies and their neural activity, one that contains\nhuman neural Electrocorticography (ECoG) data, and lastly the RGB video data of\nhuman activities from different viewpoints.",
    "descriptor": "",
    "authors": [
      "Semih G\u00fcnel",
      "Florian Aymanns",
      "Sina Honari",
      "Pavan Ramdya",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01176"
  },
  {
    "id": "arXiv:2112.01177",
    "title": "MTFNet: Mutual-Transformer Fusion Network for RGB-D Salient Object  Detection",
    "abstract": "Salient object detection (SOD) on RGB-D images is an active problem in\ncomputer vision. The main challenges for RGB-D SOD problem are how to 1)\nextract the accurate features for RGB and Depth image data with clutter\nbackground or poor image quality and 2) explore the complementary information\nbetween RGB and Depth image data. To address these challenges, we propose a\nnovel Mutual-Transformer Fusion Network (MTFNet) for RGB-D SOD. MTFNet contains\ntwo main modules, $i.e.$, Focal Feature Extractor (FFE) and Mutual-Transformer\nFusion (MTF). FFE aims to extract the more accurate CNN features for RGB and\nDepth images by introducing a novel pixel-level focal regularization to guide\nCNN feature extractor. MTF is designed to deeply exploit the multi-modal\ninteraction between RGB and Depth images on both coarse and fine scales. The\nmain benefit of MTF is that it conducts the learning of intra-modality and\ninter-modality simultaneously and thus can achieve communication across\ndifferent modalities more directly and sufficiently. Comprehensive experimental\nresults on six public benchmarks demonstrate the superiority of our proposed\nMTFNet.",
    "descriptor": "",
    "authors": [
      "Xixi Wang",
      "Bo Jiang",
      "Xiao Wang",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01177"
  },
  {
    "id": "arXiv:2112.01181",
    "title": "LDA2Net: Digging under the surface of COVID-19 topics in scientific  literature",
    "abstract": "During the COVID-19 pandemic, the scientific literature related to SARS-COV-2\nhas been growing dramatically, both in terms of the number of publications and\nof its impact on people's life. This literature encompasses a varied set of\nsensible topics, ranging from vaccination, to protective equipment efficacy, to\nlockdown policy evaluation. Up to now, hundreds of thousands of papers have\nbeen uploaded on online repositories and published in scientific journals. As a\nresult, the development of digital methods that allow an in-depth exploration\nof this growing literature has become a relevant issue, both to identify the\ntopical trends of COVID-related research and to zoom-in its sub-themes. This\nwork proposes a novel methodology, called LDA2Net, which combines topic\nmodelling and network analysis to investigate topics under their surface.\nSpecifically, LDA2Net exploits the frequencies of pairs of consecutive words to\nreconstruct the network structure of topics discussed in the Cord-19 corpus.\nThe results suggest that the effectiveness of topic models can be magnified by\nenriching them with word network representations, and by using the latter to\ndisplay, analyse, and explore COVID-related topics at different levels of\ngranularity.",
    "descriptor": "",
    "authors": [
      "Giorgia Minello",
      "Carlo R. M. A. Santagiustina",
      "Massimo Warglien"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.01181"
  },
  {
    "id": "arXiv:2112.01182",
    "title": "Age of Information in Prioritized Random Access",
    "abstract": "Age of information (AoI) is a performance metric that captures the freshness\nof status updates. While AoI has been studied thoroughly for point-to-point\nlinks, the impact of modern random-access protocols on this metric is still\nunclear. In this paper, we extend the recent results by Munari to prioritized\nrandom access where devices are divided into different classes according to\ndifferent AoI requirements. We consider the irregular repetition slotted ALOHA\nprotocol and analyze the AoI evolution by means of a Markovian analysis\nfollowing similar lines as in Munari (2021). We aim to design the protocol to\nsatisfy the AoI requirements for each class while minimizing the power\nconsumption. To this end, we optimize the update probability and the degree\ndistributions of each class, such that the probability that their AoI exceeds a\ngiven threshold lies below a given target and the average number of transmitted\npackets is minimized.",
    "descriptor": "\nComments: 6 pages, 3 figures, presented in Asilomar 2021\n",
    "authors": [
      "Khac-Hoang Ngo",
      "Giuseppe Durisi",
      "Alexandre Graell i Amat"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.01182"
  },
  {
    "id": "arXiv:2112.01183",
    "title": "Shallow geothermal energy potential for heating and cooling of buildings  with regeneration under climate change scenarios",
    "abstract": "Shallow ground-source heat pumps (GSHPs) are a promising technology for\ncontributing to the decarbonisation of the energy sector. In heating-dominated\nclimates, the combined use of GSHPs for both heating and cooling increases\ntheir technical potential, defined as the maximum energy that can be exchanged\nwith the ground, as the re-injection of excess heat from space cooling leads to\na seasonal regeneration of the ground. This paper proposes a new approach to\nquantify the technical potential of GSHPs, accounting for effects of seasonal\nregeneration, and to estimate the useful energy to supply building energy\ndemands at regional scale. The useful energy is obtained for direct heat\nexchange and for district heating and cooling (DHC) under several scenarios for\nclimate change and market penetration levels of cooling systems. The case study\nin western Switzerland suggests that seasonal regeneration allows for annual\nmaximum heat extraction densities above 300 kWh/m$^2$ at heat injection\ndensities above 330 kWh/m$^2$. Results also show that GSHPs may cover up to 55%\nof heating demand while covering 57% of service-sector cooling demand for\nindividual GSHPs in 2050, which increases to around 85% with DHC. The\nregional-scale results may serve to inform decision making on strategic areas\nfor installing GSHPs.",
    "descriptor": "\nComments: Walch and Li contributed equally. Revision submitted to Energy\n",
    "authors": [
      "Alina Walch",
      "Xiang Li",
      "Jonathan Chambers",
      "Nahid Mohajeri",
      "Selin Yilmaz",
      "Martin Patel",
      "Jean-Louis Scartezzini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.01183"
  },
  {
    "id": "arXiv:2112.01184",
    "title": "AST-Transformer: Encoding Abstract Syntax Trees Efficiently for Code  Summarization",
    "abstract": "Code summarization aims to generate brief natural language descriptions for\nsource code. As source code is highly structured and follows strict programming\nlanguage grammars, its Abstract Syntax Tree (AST) is often leveraged to inform\nthe encoder about the structural information. However, ASTs are usually much\nlonger than the source code. Current approaches ignore the size limit and\nsimply feed the whole linearized AST into the encoder. To address this problem,\nwe propose AST-Transformer to efficiently encode tree-structured ASTs.\nExperiments show that AST-Transformer outperforms the state-of-arts by a\nsubstantial margin while being able to reduce $90\\sim95\\%$ of the computational\ncomplexity in the encoding process.",
    "descriptor": "",
    "authors": [
      "Ze Tang",
      "Chuanyi Li",
      "Jidong Ge",
      "Xiaoyu Shen",
      "Zheling Zhu",
      "Bin Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.01184"
  },
  {
    "id": "arXiv:2112.01187",
    "title": "Computing Class Hierarchies from Classifiers",
    "abstract": "A class or taxonomic hierarchy is often manually constructed, and part of our\nknowledge about the world. In this paper, we propose a novel algorithm for\nautomatically acquiring a class hierarchy from a classifier which is often a\nlarge neural network these days. The information that we need from a classifier\nis its confusion matrix which contains, for each pair of base classes, the\nnumber of errors the classifier makes by mistaking one for another. Our\nalgorithm produces surprisingly good hierarchies for some well-known deep\nneural network models trained on the CIFAR-10 dataset, a neural network model\nfor predicting the native language of a non-native English speaker, a neural\nnetwork model for detecting the language of a written text, and a classifier\nfor identifying music genre. In the literature, such class hierarchies have\nbeen used to provide interpretability to the neural networks. We also discuss\nsome other potential uses of the acquired hierarchies.",
    "descriptor": "",
    "authors": [
      "Kai Kang",
      "Fangzhen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01187"
  },
  {
    "id": "arXiv:2112.01188",
    "title": "Cost Functions over Feasible Power Transfer Regions of Virtual Power  Plants",
    "abstract": "A virtual power plant (VPP) facilitates the integration of distributed energy\nresources (DERs) for the transmission-level operation. A challenge in operating\na VPP is to characterize the cost function over its feasible power transfer\nregion under DERs' uncertainties. To address this challenge, a characterization\nmethod is presented in this paper for the intraday operation of a VPP based on\nthe concepts of nonanticipativity and robustness to DERs' uncertainties. The\ncharacterization stems from designing a second-order cone programming (SOCP)\nproblem, based on which a feasible power transfer region across all time\nperiods is constructed by exploring boundary points at each time period and\nestablishing time coupling constraints. Furthermore, a cost function over the\nfeasible power transfer region is formulated as a convex piecewise surface\nwhose breakpoints are obtained by solving SOCP problems, together with a\nconstant compensation cost from a linear programming problem. Finally, to\nalleviate the heavy computational burden brought by numerous DERs, an\napproximation method is presented by identifying the critical DERs whose\nuncertainties have dominant impacts. The effectiveness of the presented methods\nis verified by the numerical experiments in a 3-bus system and the IEEE 136-bus\nsystem.",
    "descriptor": "",
    "authors": [
      "Wei Lin",
      "Changhong Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.01188"
  },
  {
    "id": "arXiv:2112.01189",
    "title": "Simplifying heterogeneous migration between x86 and ARM machines",
    "abstract": "Heterogeneous computing is the strategy of deploying multiple types of\nprocessing elements within a single workflow, and allowing each to perform the\ntasks to which is best suited. To fully harness the power of heterogeneity, we\nwant to be able to dynamically schedule portions of the code and migrate\nprocesses at runtime between the architectures. Also, migration includes\ntransforming the execution state of the process, which induces a significant\noverhead that offsets the benefits of migrating in the first place. The goal of\nmy PhD is to work on techniques that allow applications to run on heterogeneous\ncores under a shared programming model, and to tackle the generic problem of\ncreating a uniform address space between processes running on these highly\ndiverse systems. This would greatly simplify the migration process. We will\nstart by examining a common stack layout between x86 and ARM binaries, focusing\non these two widely spread architectures, and later we will try to generalize\nto other more diverse execution environments. On top of that, the performance\nand energy efficiency of the above effort compared to current approaches will\nbe benchmarked.",
    "descriptor": "\nComments: 3 pages, 1 figure, submitted and accepted at EuroSys Doctoral Workshop 2021 (no proceedings)\n",
    "authors": [
      "Nikolaos Mavrogeorgis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.01189"
  },
  {
    "id": "arXiv:2112.01194",
    "title": "Video-Text Pre-training with Learned Regions",
    "abstract": "Video-Text pre-training aims at learning transferable representations from\nlarge-scale video-text pairs via aligning the semantics between visual and\ntextual information. State-of-the-art approaches extract visual features from\nraw pixels in an end-to-end fashion. However, these methods operate at\nframe-level directly and thus overlook the spatio-temporal structure of objects\nin video, which yet has a strong synergy with nouns in textual descriptions. In\nthis work, we propose a simple yet effective module for video-text\nrepresentation learning, namely RegionLearner, which can take into account the\nstructure of objects during pre-training on large-scale video-text pairs. Given\na video, our module (1) first quantizes visual features into semantic clusters,\nthen (2) generates learnable masks and uses them to aggregate the features\nbelonging to the same semantic region, and finally (3) models the interactions\nbetween different aggregated regions. In contrast to using off-the-shelf object\ndetectors, our proposed module does not require explicit supervision and is\nmuch more computationally efficient. We pre-train the proposed approach on the\npublic WebVid2M and CC3M datasets. Extensive evaluations on four downstream\nvideo-text retrieval benchmarks clearly demonstrate the effectiveness of our\nRegionLearner. The code will be available at\nhttps://github.com/ruiyan1995/Region_Learner.",
    "descriptor": "",
    "authors": [
      "Rui Yan",
      "Mike Zheng Shou",
      "Yixiao Ge",
      "Alex Jinpeng Wang",
      "Xudong Lin",
      "Guanyu Cai",
      "Jinhui Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.01194"
  },
  {
    "id": "arXiv:2112.01195",
    "title": "Maximum Entropy Model-based Reinforcement Learning",
    "abstract": "Recent advances in reinforcement learning have demonstrated its ability to\nsolve hard agent-environment interaction tasks on a super-human level. However,\nthe application of reinforcement learning methods to practical and real-world\ntasks is currently limited due to most RL state-of-art algorithms' sample\ninefficiency, i.e., the need for a vast number of training episodes. For\nexample, OpenAI Five algorithm that has beaten human players in Dota 2 has\ntrained for thousands of years of game time. Several approaches exist that\ntackle the issue of sample inefficiency, that either offers a more efficient\nusage of already gathered experience or aim to gain a more relevant and diverse\nexperience via a better exploration of an environment. However, to our\nknowledge, no such approach exists for model-based algorithms, that showed\ntheir high sample efficiency in solving hard control tasks with\nhigh-dimensional state space. This work connects exploration techniques and\nmodel-based reinforcement learning. We have designed a novel exploration method\nthat takes into account features of the model-based approach. We also\ndemonstrate through experiments that our method significantly improves the\nperformance of the model-based algorithm Dreamer.",
    "descriptor": "\nComments: NeurIPS'2021 Deep Reinforcement Learning Workshop\n",
    "authors": [
      "Oleg Svidchenko",
      "Aleksei Shpilman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01195"
  },
  {
    "id": "arXiv:2112.01197",
    "title": "Sample Prior Guided Robust Model Learning to Suppress Noisy Labels",
    "abstract": "Imperfect labels are ubiquitous in real-world datasets and seriously harm the\nmodel performance. Several recent effective methods for handling noisy labels\nhave two key steps: 1) dividing samples into cleanly labeled and wrongly\nlabeled sets by training loss, 2) using semi-supervised methods to generate\npseudo-labels for samples in the wrongly labeled set. However, current methods\nalways hurt the informative hard samples due to the similar loss distribution\nbetween the hard samples and the noisy ones. In this paper, we proposed PGDF\n(Prior Guided Denoising Framework), a novel framework to learn a deep model to\nsuppress noise by generating the samples' prior knowledge, which is integrated\ninto both dividing samples step and semi-supervised step. Our framework can\nsave more informative hard clean samples into the cleanly labeled set. Besides,\nour framework also promotes the quality of pseudo-labels during the\nsemi-supervised step by suppressing the noise in the current pseudo-labels\ngenerating scheme. To further enhance the hard samples, we reweight the samples\nin the cleanly labeled set during training. We evaluated our method using\nsynthetic datasets based on CIFAR-10 and CIFAR-100, as well as on the\nreal-world datasets WebVision and Clothing1M. The results demonstrate\nsubstantial improvements over state-of-the-art methods.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Wenkai Chen",
      "Chuang Zhu",
      "Yi Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01197"
  },
  {
    "id": "arXiv:2112.01198",
    "title": "The Effect of COVID-19 on the Transit System in Two Regions: Japan and  USA",
    "abstract": "The communication revolution that happened in the last ten years has\nincreased the use of technology in the transportation world. Intelligent\nTransportation Systems wish to predict how many buses are needed in a transit\nsystem. With the pandemic effect that the world has faced since early 2020, it\nis essential to study the impact of the pandemic on the transit system. This\npaper proposes the leverage of Internet of Things (IoT) devices to predict the\nnumber of bus ridership before and during the pandemic. We compare the\ncollected data from Kobe city, Hyogo, Japan, with data gathered from a college\ncity in Virginia, USA. Our goal is to show the effect of the pandemic on\nridership through the year 2020 in two different countries. The ultimate goal\nis to help transit system managers predict how many buses are needed if another\npandemic hits.",
    "descriptor": "\nComments: 6 pages, 8 figures, conference\n",
    "authors": [
      "Ismail Arai",
      "Samy El-Tawab",
      "Ahmad Salman",
      "Ahmed Elnoshokaty"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01198"
  },
  {
    "id": "arXiv:2112.01204",
    "title": "Formal verification of a controller implementation in fixed-point  arithmetic",
    "abstract": "For the implementations of controllers on digital processors, certain\nlimitations, e.g. in the instruction set and register length, need to be taken\ninto account, especially for safety-critical applications. This work aims to\nprovide a computer-certified inductive definition for the control functions\nthat are implemented on such processors accompanied with the fixed-point data\ntype in a proof assistant. Using these inductive definitions we formally ensure\ncorrect realization of the controllers on a digital processor. Our results\nguarantee overflow-free computations of the implemented control algorithm. The\nmethod presented in this paper currently supports functions that are defined as\npolynomials within an arbitrary fixed-point structure. We demonstrate the\nverification process in the case study on an example with different scenarios\nof fixed-point type implementations.",
    "descriptor": "",
    "authors": [
      "Lars Flessing",
      "Grigory Devadze",
      "Stefan Streif"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.01204"
  },
  {
    "id": "arXiv:2112.01206",
    "title": "Local Citation Recommendation with Hierarchical-Attention Text Encoder  and SciBERT-based Reranking",
    "abstract": "The goal of local citation recommendation is to recommend a missing reference\nfrom the local citation context and optionally also from the global context. To\nbalance the tradeoff between speed and accuracy of citation recommendation in\nthe context of a large-scale paper database, a viable approach is to first\nprefetch a limited number of relevant documents using efficient ranking methods\nand then to perform a fine-grained reranking using more sophisticated models.\nIn that vein, BM25 has been found to be a tough-to-beat approach to\nprefetching, which is why recent work has focused mainly on the reranking step.\nEven so, we explore prefetching with nearest neighbor search among text\nembeddings constructed by a hierarchical attention network. When coupled with a\nSciBERT reranker fine-tuned on local citation recommendation tasks, our\nhierarchical Attention encoder (HAtten) achieves high prefetch recall for a\ngiven number of candidates to be reranked. Consequently, our reranker needs to\nrerank fewer prefetch candidates, yet still achieves state-of-the-art\nperformance on various local citation recommendation datasets such as ACL-200,\nFullTextPeerRead, RefSeer, and arXiv.",
    "descriptor": "\nComments: Accepted by ECIR 2022: this https URL\n",
    "authors": [
      "Nianlong Gu",
      "Yingqiang Gao",
      "Richard H.R. Hahnloser"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01206"
  },
  {
    "id": "arXiv:2112.01210",
    "title": "Resonating Minds -- Emergent Collaboration Through Hierarchical Active  Inference",
    "abstract": "Working together on complex collaborative tasks requires agents to coordinate\ntheir actions. Doing this explicitly or completely prior to the actual\ninteraction is not always possible nor sufficient. Agents also need to\ncontinuously understand the current actions of others and quickly adapt their\nown behavior appropriately. Here we investigate how efficient, automatic\ncoordination processes at the level of mental states (intentions, goals), which\nwe call belief resonance, can lead to collaborative situated problem-solving.\nWe present a model of hierarchical active inference for collaborative agents\n(HAICA). It combines efficient Bayesian Theory of Mind processes with a\nperception-action system based on predictive processing and active inference.\nBelief resonance is realized by letting the inferred mental states of one agent\ninfluence another agent's predictive beliefs about its own goals and\nintentions. This way, the inferred mental states influence the agent's own task\nbehavior without explicit collaborative reasoning. We implement and evaluate\nthis model in the Overcooked domain, in which two agents with varying degrees\nof belief resonance team up to fulfill meal orders. Our results demonstrate\nthat agents based on HAICA achieve a team performance comparable to recent\nstate of the art approaches, while incurring much lower computational costs. We\nalso show that belief resonance is especially beneficial in settings were the\nagents have asymmetric knowledge about the environment. The results indicate\nthat belief resonance and active inference allow for quick and efficient agent\ncoordination, and thus can serve as a building block for collaborative\ncognitive agents.",
    "descriptor": "\nComments: This version of the article has been accepted for publication, after peer review but is not the Version of Record and does not reflect post-acceptance improvements, or any corrections. The Version of Record is available online at: this http URL, Cogn Comput (2021)\n",
    "authors": [
      "Jan P\u00f6ppel",
      "Sebastian Kahl",
      "Stefan Kopp"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01210"
  },
  {
    "id": "arXiv:2112.01215",
    "title": "Adaptive Group Collaborative Artificial Bee Colony Algorithm",
    "abstract": "As an effective algorithm for solving complex optimization problems,\nartificial bee colony (ABC) algorithm has shown to be competitive, but the same\nas other population-based algorithms, it is poor at balancing the abilities of\nglobal searching in the whole solution space (named as exploration) and quick\nsearching in local solution space which is defined as exploitation. For\nimproving the performance of ABC, an adaptive group collaborative ABC (AgABC)\nalgorithm is introduced where the population in different phases is divided to\nspecific groups and different search strategies with different abilities are\nassigned to the members in groups, and the member or strategy which obtains the\nbest solution will be employed for further searching. Experimental results on\nbenchmark functions show that the proposed algorithm with dynamic mechanism is\nsuperior to other algorithms in searching accuracy and stability. Furthermore,\nnumerical experiments show that the proposed method can generate the optimal\nsolution for the complex scheduling problem.",
    "descriptor": "",
    "authors": [
      "Haiquan Wang",
      "Hans-DietrichHaasis",
      "Panpan Du",
      "Xiaobin Xu",
      "Menghao Su",
      "Shengjun Wen",
      "Wenxuan Yue",
      "Shanshan Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.01215"
  },
  {
    "id": "arXiv:2112.01218",
    "title": "GraphCode2Vec: Generic Code Embedding via Lexical and Program Dependence  Analyses",
    "abstract": "Code embedding is a keystone in the application of machine learning on\nseveral Software Engineering (SE) tasks, e.g., method name prediction and code\nclone detection. To be effective, the embedding needs to capture program\nsemantics in a way that is effective and generic, in a sense being able to\neffectively support a plethora of SE tasks. To this end, we propose an approach\n(called GraphCode2Vec) thatcaptures program semantics through lexical and\nprogram dependence features via an effective combination of code analysis and\nGraph Neural Networks. GraphCode2Vec is generic, i.e., it allows pre-training,\nand it is effectively applicable to several SE downstream tasks. We evaluate\nthe effectiveness of GraphCode2Vec on three (3) tasks (method name prediction,\nsolution classification and code clone detection), and compare it with four (4)\nsimilarly generic code embedding baselines (Code2Seq, Code2Vec, CodeBERT,\nGraphCodeBERT) and seven (7) task-specific, learning-based methods. In\nparticular, GraphCode2Vec is more effective than both generic and task-specific\nlearning-based baselines for all three tasks, with the exception of one task\nwhere it is slightly less effective than GraphCodeBERT. We also demonstrate\nthrough a purposely designed probing and ablation study that GraphCode2Vec\neffectively learns lexical and program dependence features and that\npre-training improves its effectiveness.",
    "descriptor": "",
    "authors": [
      "Wei Ma",
      "Mengjie Zhao",
      "Ezekiel Soremekun",
      "Qiang Hu",
      "Jie Zhang",
      "Mike Papadakis",
      "Maxime Cordy",
      "Xiaofei Xie",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.01218"
  },
  {
    "id": "arXiv:2112.01220",
    "title": "A Quantum Annealing Approach to Reduce Covid-19 Spread on College  Campuses",
    "abstract": "Disruptions of university campuses caused by COVID-19 have motivated\nstrategies to prevent the spread of infectious diseases while maintaining some\nlevel of in person learning. In response, the proposed approach recursively\napplied a quantum annealing algorithm for Max-Cut optimization on D-Wave\nSystems, which grouped students into cohorts such that the number of possible\ninfection events via shared classrooms was minimized. To test this approach,\navailable coursework data was used to generate highly clustered course\nenrollment networks representing students and the classes they share. The\nalgorithm was then recursively called on these networks to group students, and\na disease model was applied to forecast disease spread. Simulation results\nshowed that under some assumptions on disease statistics and methods of spread,\nthe quantum grouping method reduced both the total and peak percentage of\ninfected students when compared against random groupings of students. Scaling\nto larger networks, it is possible that this quantum annealer-assisted grouping\napproach may provide practical advantage over classical approaches. This paper,\nhowever, is strictly a proof-of-concept demonstration of the approach and is\nnot intended to argue for a quantum speedup.",
    "descriptor": "\nComments: 6 pages, 4 figures, 2 tables, 1 algorithm\n",
    "authors": [
      "James Sud",
      "Victor Li"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.01220"
  },
  {
    "id": "arXiv:2112.01224",
    "title": "Using word embedding for environmental violation analysis: Evidence from  Pennsylvania unconventional oil and gas compliance reports",
    "abstract": "With the booming of the unconventional oil and gas industry, its inevitable\ndamage to the environment and human health has attracted public attention. We\napplied text mining on a total 6057 the type of Environmental Health and Safety\ncompliance reports from 2008 to 2018 lunched by the Department of Environmental\nProtection in Pennsylvania, USA, to discover the intern mechanism of\nenvironmental violations.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Dan Bi",
      "Ju-e Guo",
      "Erlong Zhao",
      "Shaolong Sun",
      "Shouyang Wang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01224"
  },
  {
    "id": "arXiv:2112.01225",
    "title": "Invisible Data Curation Practices: A Case Study from Facility Management",
    "abstract": "Facility management, which concerns the administration, operations, and\nmainte-nance of buildings, is a sector undergoing significant changes while\nbecoming digitalized and data driven. In facility management sector, companies\nseek to ex-tract value from data about their buildings. As a consequence,\ncraftsmen, such as janitors, are becoming involved in data curation. Data\ncuration refers to activities related to cleaning, assembling, setting up, and\nstewarding data to make them fit existing templates. Craftsmen in facility\nmanagement, despite holding a pivotal role for successful data curation in the\ndomain, are understudied and disregarded. To remedy this, our holistic case\nstudy investigates how janitors' data curation practices shape the data being\nproduced in three facility management organiza-tions. Our findings illustrate\nthe unfortunate that janitors are treated more like a sensor than a human data\ncurator. This treatment makes them less engaged in data curation, and hence do\nnot engage in a much necessary correction of essential fa-cility data. We apply\nthe conceptual lens of invisible work - work that blends into the background\nand is taken for granted - to explain why this happens and how data comes to\nbe. The findings also confirm the usefulness of a previously pro-posed\nanalytical framework by using it to interpret data curation practices within\nfacility management. The paper contributes to practitioners by proposing\ntraining and education in data curation.",
    "descriptor": "\nComments: 14 pages, Preprint accepted to Norwegian ICT conference for research and education 2021, p-ISSN: 1892-0713\n",
    "authors": [
      "Tor Sporsem",
      "Morten Hatling",
      "Marius Mikalsen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01225"
  },
  {
    "id": "arXiv:2112.01226",
    "title": "Role of Artificial Intelligence, Clinicians & Policymakers in Clinical  Decision Making: A Systems Viewpoint",
    "abstract": "What is a system? Is one of those questions that is yet not clear to most\nindividuals in this world. A system is an assemblage of interacting,\ninterrelated and interdependent components forming a complex and integrated\nwhole with an unambiguous and common goal. This paper emphasizes on the fact\nthat all components of a complex system are inter-related and interdependent in\nsome way and the behavior of that system depends on these independences. A\nhealth care system as portrayed in this article is widespread and complex. This\nencompasses not only hospitals but also governing bodies like the FDA,\ntechnologies such as AI, biomedical devices, Cloud computing and many more. The\ninteractions between all these components govern the behavior and existence of\nthe overall healthcare system. In this paper, we focus on the interaction of\nartificial intelligence, care providers and policymakers and analyze using\nsystems thinking approach, their impact on clinical decision making",
    "descriptor": "",
    "authors": [
      "Avishek Choudhury",
      "Onur Asan",
      "Mo Mansouri"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01226"
  },
  {
    "id": "arXiv:2112.01228",
    "title": "AI-Fuzzy Markup Language with Computational Intelligence for High-School  Student Learning",
    "abstract": "Computational Intelligence (CI), which includes fuzzy logic (FL), neural\nnetwork (NN), and evolutionary computation (EC), is an imperative branch of\nartificial intelligence (AI). As a core technology of AI, it plays a vital role\nin developing intelligent systems, such as games and game engines, neural-based\nsystems including a variety of deep network models, evolutionary-based\noptimization methods, and advanced cognitive techniques. The 2021 IEEE CIS\nSummer School on CI for High-School Student Learning was held physically at the\nJanFuSun Resort Hotel, Taiwan, and virtually on Zoom, on August 10-12, 2021.\nThe main contents of the Summer School were lectures focused on the basics of\nFL, NN, and EC and the workshop on AIoT (Artificial Intelligence of Things).\nInvited speakers gave nine courses covering topics like CI real-world\napplications, fundamentals of FL, and the introduction to NN and EC. The 2021\nSummer School was supported by the 2021 IEEE CIS High School Outreach\nSubcommittee. We also invited students and teachers of high and elementary\nschools from Taiwan, Japan, and Indonesia. They attended the school and\nparticipated in AIoT workshop, gaining experience in applications of AIoT-FML\nlearning tools. According to the short report and feedback from the involved\nstudents and teachers, we find out that most participants have quickly\nunderstood the principles of CI, FL, NN, and EC. In addition, one of the\nteachers sent the following remark to the organizers: \"This is a great event to\nintroduce students to computational intelligence at a young age, stimulate them\nto be involved in rapidly evolving fields, and foster participation in future\nresearch adventures.\"",
    "descriptor": "\nComments: 4 pages, 7 figures, and 1 table\n",
    "authors": [
      "Chang-Shing Lee",
      "Mei-Hui Wang",
      "Yusuke Nojima",
      "Marek Reformat",
      "Leo Guo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01228"
  },
  {
    "id": "arXiv:2112.01229",
    "title": "An AI-based Solution for Enhancing Delivery of Digital Learning for  Future Teachers",
    "abstract": "There has been a recent and rapid shift to digital learning hastened by the\npandemic but also influenced by ubiquitous availability of digital tools and\nplatforms now, making digital learning ever more accessible. An integral and\none of the most difficult part of scaling digital learning and teaching is to\nbe able to assess learner's knowledge and competency. An educator can record a\nlecture or create digital content that can be delivered to thousands of\nlearners but assessing learners is extremely time consuming. In the paper, we\npropose an Artificial Intelligence (AI)-based solution namely VidVersityQG for\ngenerating questions automatically from pre-recorded video lectures. The\nsolution can automatically generate different types of assessment questions\n(including short answer, multiple choice, true/false and fill in the blank\nquestions) based on contextual and semantic information inferred from the\nvideos. The proposed solution takes a human-centred approach, wherein teachers\nare provided the ability to modify/edit any AI generated questions. This\napproach encourages trust and engagement of teachers in the use and\nimplementation of AI in education. The AI-based solution was evaluated for its\naccuracy in generating questions by 7 experienced teaching professionals and\n117 education videos from multiple domains provided to us by our industry\npartner VidVersity. VidVersityQG solution showed promising results in\ngenerating high-quality questions automatically from video thereby\nsignificantly reducing the time and effort for educators in manual question\ngeneration.",
    "descriptor": "",
    "authors": [
      "Yong-Bin Kang",
      "Abdur Rahim Mohammad Forkan",
      "Prem Prakash Jayaraman",
      "Natalie Wieland",
      "Elizabeth Kolliasl",
      "Hung Du",
      "Steven Thomson",
      "Yuan-Fang Li"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01229"
  },
  {
    "id": "arXiv:2112.01230",
    "title": "Early Prediction of Mortality in Critical Care Setting in Sepsis  Patients Using Structured Features and Unstructured Clinical Notes",
    "abstract": "Sepsis is an important cause of mortality, especially in intensive care unit\n(ICU) patients. Developing novel methods to identify early mortality is\ncritical for improving survival outcomes in sepsis patients. Using the\nMIMIC-III database, we integrated demographic data, physiological measurements\nand clinical notes. We built and applied several machine learning models to\npredict the risk of hospital mortality and 30-day mortality in sepsis patients.\nFrom the clinical notes, we generated clinically meaningful word\nrepresentations and embeddings. Supervised learning classifiers and a deep\nlearning architecture were used to construct prediction models. The\nconfigurations that utilized both structured and unstructured clinical features\nyielded competitive F-measure of 0.512. Our results showed that the approaches\nintegrating both structured and unstructured clinical features can be\neffectively applied to assist clinicians in identifying the risk of mortality\nin sepsis patients upon admission to the ICU.",
    "descriptor": "",
    "authors": [
      "Jiyoung Shin",
      "Yikuan Li",
      "Yuan Luo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01230"
  },
  {
    "id": "arXiv:2112.01231",
    "title": "Internationalizing AI: Evolution and Impact of Distance Factors",
    "abstract": "International collaboration has become imperative in the field of AI.\nHowever, few studies exist concerning how distance factors have affected the\ninternational collaboration in AI research. In this study, we investigate this\nproblem by using 1,294,644 AI related collaborative papers harvested from the\nMicrosoft Academic Graph (MAG) dataset. A framework including 13 indicators to\nquantify the distance factors between countries from 5 perspectives (i.e.,\ngeographic distance, economic distance, cultural distance, academic distance,\nand industrial distance) is proposed. The relationships were conducted by the\nmethods of descriptive analysis and regression analysis. The results show that\ninternational collaboration in the field of AI today is not prevalent (only\n15.7%). All the separations in international collaborations have increased over\nyears, except for the cultural distance in masculinity/felinity dimension and\nthe industrial distance. The geographic distance, economic distance and\nacademic distances have shown significantly negative relationships with the\ndegree of international collaborations in the field of AI. The industrial\ndistance has a significant positive relationship with the degree of\ninternational collaboration in the field of AI. Also, the results demonstrate\nthat the participation of the United States and China have promoted the\ninternational collaboration in the field of AI. This study provides a\ncomprehensive understanding of internationalizing AI research in geographic,\neconomic, cultural, academic, and industrial aspects.",
    "descriptor": "",
    "authors": [
      "Xuli Tang",
      "Xin Li",
      "Feicheng Ma"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01231"
  },
  {
    "id": "arXiv:2112.01236",
    "title": "Local Justice and the Algorithmic Allocation of Societal Resources",
    "abstract": "AI is increasingly used to aid decision-making about the allocation of scarce\nsocietal resources, for example housing for homeless people, organs for\ntransplantation, and food donations. Recently, there have been several\nproposals for how to design objectives for these systems that attempt to\nachieve some combination of fairness, efficiency, incentive compatibility, and\nsatisfactory aggregation of stakeholder preferences. This paper lays out\npossible roles and opportunities for AI in this domain, arguing for a closer\nengagement with the political philosophy literature on local justice, which\nprovides a framework for thinking about how societies have over time framed\nobjectives for such allocation problems. It also discusses how we may be able\nto integrate into this framework the opportunities and risks opened up by the\nubiquity of data and the availability of algorithms that can use them to make\naccurate predictions about the future.",
    "descriptor": "\nComments: To appear in AAAI 2022 (Senior Member Track, Blue Sky paper)\n",
    "authors": [
      "Sanmay Das"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01236"
  },
  {
    "id": "arXiv:2112.01237",
    "title": "Designing a Framework for Digital KYC Processes Built on  Blockchain-Based Self-Sovereign Identity",
    "abstract": "Know your customer (KYC) processes place a great burden on banks, because\nthey are costly, inefficient, and inconvenient for customers. While blockchain\ntechnology is often mentioned as a potential solution, it is not clear how to\nuse the technology's advantages without violating data protection regulations\nand customer privacy. We demonstrate how blockchain-based self-sovereign\nidentity (SSI) can solve the challenges of KYC. We follow a rigorous design\nscience research approach to create a framework that utilizes SSI in the KYC\nprocess, deriving nascent design principles that theorize on blockchain's role\nfor SSI.",
    "descriptor": "",
    "authors": [
      "Vincent Schlatt",
      "Johannes Sedlmeir",
      "Simon Feulner",
      "Nils Urbach"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2112.01237"
  },
  {
    "id": "arXiv:2112.01238",
    "title": "Ethereum Emissions: A Bottom-up Estimate",
    "abstract": "The Ethereum ecosystem is maintained by a distributed global network of\ncomputers that currently require massive amounts of computational power.\nPrevious work on estimating the energy use and emissions of the Ethereum\nnetwork has relied on top-down economic analysis and rough estimates of\nhardware efficiency and emissions factors. In this work we provide a bottom-up\nanalysis that works from hashrate to an energy usage estimate, and from mining\nlocations to an emissions factor estimate, and combines these for an overall\nemissions estimate.",
    "descriptor": "\nComments: Code at this https URL\n",
    "authors": [
      "Kyle McDonald"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.01238"
  },
  {
    "id": "arXiv:2112.01239",
    "title": "Improving Teacher-Student Interactions in Online Educational Forums  using a Markov Chain based Stackelberg Game Model",
    "abstract": "With the rapid proliferation of the Internet, the area of education has\nundergone a massive transformation in terms of how students and instructors\ninteract in a classroom. Online learning now takes more than one form,\nincluding the use of technology to enhance a face-to-face class, a hybrid class\nthat combines both face-to-face meetings and online work, and fully online\ncourses. Further, online classrooms are usually composed of an online education\nforum (OEF) where students and instructor discuss open-ended questions for\ngaining better understanding of the subject. However, empirical studies have\nrepeatedly shown that the dropout rates in these online courses are very high\npartly due to the lack of motivation among the enrolled students. We undertake\nan empirical comparison of student behavior in OEFs associated with a\ngraduate-level course during two terms. We identify key parameters dictating\nthe dynamics of OEFs like effective incentive design, student heterogeneity,\nand super-posters phenomenon. Motivated by empirical observations, we propose\nan analytical model based on continuous time Markov chains (CTMCs) to capture\ninstructor-student interactions in an OEF. Using concepts from lumpability of\nCTMCs, we compute steady state and transient probabilities along with expected\nnet-rewards for the instructor and the students. We formulate a mixed-integer\nlinear program which views an OEF as a single-leader-multiple-followers\nStackelberg game. Through simulations, we observe that students exhibit varied\ndegree of non-monotonicity in their participation (with increasing instructor\ninvolvement). We also study the effect of instructor bias and budget on the\nstudent participation levels. Our model exhibits the empirically observed\nsuper-poster phenomenon under certain parameter configurations and recommends\nan optimal plan to the instructor for maximizing student participation in OEFs.",
    "descriptor": "\nComments: 44 pages, 9 figures\n",
    "authors": [
      "Rohith Dwarakanath Vallam",
      "Priyanka Bhatt",
      "Debmalya Mandal",
      "Y Narahari"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.01239"
  },
  {
    "id": "arXiv:2112.01240",
    "title": "A Neuroscience Approach regarding Student Engagement in the Classes of  Microcontrollers during the COVID19 Pandemic",
    "abstract": "The process of teaching has been greatly changed by the COVID-19 pandemic. It\nis possible that studying will not resemble anymore the process known by the\nprevious generations of students. As the current generations learn by doing and\nuse their intuition, new platforms need to be involved in the teaching process.\nThe current paper proposes a new method to keep the students engaged while\nlearning by involving neuroscience during the classes of Microcontrollers.\nArduino and Raspberry Pi boards are studied at the course of Microcontrollers\nusing online simulation environments. The Emotiv Insight headset is used by the\nprofessor during the theoretical and practical hours of the Microcontrollers\ncourse. The analysis performed on the brainwaves generated by the headset\nprovides numerical values for the mood, focus, stress, relaxation, engagement,\nexcitement and interest levels of the professor. The approaches used during\nteaching were inquiry-based learning, game-based learning and personalized\nlearning. In this way, professors can determine how to improve the connection\nwith their students based on the use of technology and virtual simulation\nplatforms. The results of the test show that the game-based learning was be\nbest approach because students had to become problem solves and start to use\nthe software skills which they will need as future software engineers. The\nemphasis is put on mastering the mindset by having to choose their actions and\nto experiment along the way. According to their achievement, students receive\nexperience points in a gamified environment. Professors need to adjust to a new\nera of teaching and refine their practices and learning philosophy. They need\nto be able to use virtual platforms with ease, as well as to engage with their\nstudents in order to determine and satisfy their needs.",
    "descriptor": "\nComments: 14th International Conference of Education, Research and Innovation (ICERI2021)\n",
    "authors": [
      "Iuliana Marin"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01240"
  },
  {
    "id": "arXiv:2112.01241",
    "title": "Course Difficulty Estimation Based on Mapping of Bloom's Taxonomy and  ABET Criteria",
    "abstract": "Current Educational system uses grades or marks to assess the performance of\nthe student. The marks or grades a students scores depends on different\nparameters, the main parameter being the difficulty level of a course.\nComputation of this difficulty level may serve as a support for both the\nstudents and teachers to fix the level of training needed for successful\ncompletion of course. In this paper, we proposed a methodology that estimates\nthe difficulty level of a course by mapping the Bloom's Taxonomy action words\nalong with Accreditation Board for Engineering and Technology (ABET) criteria\nand learning outcomes. The estimated difficulty level is validated based on the\nhistory of grades secured by the students.",
    "descriptor": "",
    "authors": [
      "Premalatha M",
      "Suganya G",
      "Viswanathan V",
      "G Jignesh Chowdary"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01241"
  },
  {
    "id": "arXiv:2112.01242",
    "title": "An AI-based Learning Companion Promoting Lifelong Learning Opportunities  for All",
    "abstract": "Artifical Intelligence (AI) in Education has great potential for building\nmore personalised curricula, as well as democratising education worldwide and\ncreating a Renaissance of new ways of teaching and learning. We believe this is\na crucial moment for setting the foundations of AI in education in the\nbeginning of this Fourth Industrial Revolution. This report aims to synthesize\nhow AI might change (and is already changing) how we learn, as well as what\ntechnological features are crucial for these AI systems in education, with the\nend goal of starting this pressing dialogue of how the future of AI in\neducation should unfold, engaging policy makers, engineers, researchers and\nobviously, teachers and learners. This report also presents the advances within\nthe X5GON project, a European H2020 project aimed at building and deploying a\ncross-modal, cross-lingual, cross-cultural, cross-domain and cross-site\npersonalised learning platform for Open Educational Resources (OER).",
    "descriptor": "\nComments: Published as an Opinion Report from the International Research Centre on Artificial Intelligence under the auspices of UNESCO\n",
    "authors": [
      "Maria Perez-Ortiz",
      "Erik Novak",
      "Sahan Bulathwela",
      "John Shawe-Taylor"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01242"
  },
  {
    "id": "arXiv:2112.01243",
    "title": "Towards Continuous Compounding Effects and Agile Practices in  Educational Experimentation",
    "abstract": "Randomised control trials are currently the definitive gold standard approach\nfor formal educational experiments. Although conclusions from these experiments\nare highly credible, their relatively slow experimentation rate, high expense\nand rigid framework can be seen to limit scope on: 1. $\\textit{metrics}$:\nautomation of the consistent rigorous computation of hundreds of metrics for\nevery experiment; 2. $\\textit{concurrency}$: fast automated releases of\nhundreds of concurrent experiments daily; and 3. $\\textit{safeguards}$: safety\nnet tests and ramping up/rolling back treatments quickly to minimise negative\nimpact. This paper defines a framework for categorising different experimental\nprocesses, and places a particular emphasis on technology readiness.\nOn the basis of our analysis, our thesis is that the next generation of\neducation technology successes will be heralded by recognising the context of\nexperiments and collectively embracing the full set of processes that are at\nhand: from rapid ideation and prototyping produced in small scale experiments\non the one hand, to influencing recommendations of best teaching practices with\nlarge-scale and technology-enabled online A/B testing on the other. A key\nbenefit of the latter is that the running costs tend towards zero (leading to\n`free experimentation'). This offers low-risk opportunities to explore and\ndrive value though well-planned lasting campaigns that iterate quickly at a\nlarge scale. Importantly, because these experimental platforms are so\nadaptable, the cumulative effect of the experimental campaign delivers\ncompounding value exponentially over time even if each individual experiment\ndelivers a small effect.",
    "descriptor": "",
    "authors": [
      "Luis M. Vaquero",
      "Niall Twomey",
      "Miguel Patricio Dias",
      "Massimo Camplani",
      "Robert Hardman"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01243"
  },
  {
    "id": "arXiv:2112.01244",
    "title": "A Crowdsourced Contact Tracing Model to Detect COVID-19 Patients using  Smartphones",
    "abstract": "Millions of people have died all across the world because of the COVID-19\noutbreak. Researchers worldwide are working together and facing many challenges\nto bring out the proper vaccines to prevent this infectious virus. Therefore,\nin this study, a system has been designed which will be adequate to stop the\noutbreak of COVID-19 by spreading awareness of the COVID-19 infected patient\nsituated area. The model has been formulated for Location base COVID-19 patient\nidentification using mobile crowdsourcing. In this system, the government will\nupdate the information about inflected COVID-19 patients. It will notify other\nusers in the vulnerable area to stay at 6 feet or 1.8-meter distance to remain\nsafe. We utilized the Haversine formula and circle formula to generate the\nunsafe area. Ten thousand valid information has been collected to support the\nresults of this research. The algorithm is tested for 10 test cases every time,\nand the datasets are increased by 1000. The run time of that algorithm is\ngrowing linearly. Thus, we can say that the proposed algorithm can run in\npolynomial time. The algorithm's correctness is also being tested where it is\nfound that the proposed algorithm is correct and efficient. We also implement\nthe system, and the application is evaluated by taking feedback from users.\nThus, people can use our system to keep themselves in a safe area and decrease\nCOVID patients' rate.",
    "descriptor": "",
    "authors": [
      "Linta Islam",
      "Mafizur Rahman",
      "Nabila Ahmad",
      "Tasnia Sharmin",
      "Jannatul Ferdous Sorna"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01244"
  },
  {
    "id": "arXiv:2112.01247",
    "title": "Predicting Student's Performance Through Data Mining",
    "abstract": "Predicting the performance of students early and as accurately as possible is\none of the biggest challenges of educational institutions. Analyzing the\nperformance of students early can help in finding the strengths and weakness of\nstudents and help the perform better in examinations. Using machine learning\nthe student's performance can be predicted with the help of students' data\ncollected from Learning Management Systems (LMS). The data collected from LMSs\ncan provide insights about student's behavior that will result in good or bad\nperformance in examinations which then can be studied and used in helping\nstudents performing poorly in examinations to perform better.",
    "descriptor": "\nComments: 15 pages, 11 figures\n",
    "authors": [
      "Aaditya Bhusal"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01247"
  },
  {
    "id": "arXiv:2112.01250",
    "title": "The Benefits of Edge Computing in Healthcare, Smart Cities, and IoT",
    "abstract": "Recent advancements in technology now allow for the generation of massive\nquantities of data. There is a growing need to transmit this data faster and\nmore securely such that it cannot be accessed by malicious individuals. Edge\ncomputing has emerged in previous research as a method capable of improving\ndata transmission times and security before the data ends up in the cloud. Edge\ncomputing has an impressive transmission speed based on fifth generation (5G)\ncommunication which transmits data with low latency and high bandwidth. While\nedge computing is sufficient to extract important features from the raw data to\nprevent large amounts of data requiring excessive bandwidth to be transmitted,\ncloud computing is used for the computational processes required for developing\nalgorithms and modeling the data. Edge computing also improves the quality of\nthe user experience by saving time and integrating quality of life (QoL)\nfeatures. QoL features are important for the healthcare sector by helping to\nprovide real-time feedback of data produced by healthcare devices back to\npatients for a faster recovery. Edge computing has better energy efficiency,\ncan reduce the electricity cost, and in turn help people reduce their living\nexpenses. This paper will take a detailed look into edge computing applications\naround Internet of Things (IoT) devices, smart city infrastructure, and\nbenefits to healthcare.",
    "descriptor": "",
    "authors": [
      "Rushit Dave",
      "Naeem Seliya",
      "Nyle Siddiqui"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01250"
  },
  {
    "id": "arXiv:2112.01251",
    "title": "Health Detection on Cattle Compressed Images in Precision Livestock  Farming",
    "abstract": "The constant population growth brings the needing to make up for food also\ngrows at the same rate. The livestock provides one-third of humans protein base\nas meat and milk. To improve cattles health and welfare the pastoral farming\nemploys Precision Livestock farming (PLF). This technique implementation brings\na challenge to minimize energy consumption due to farmers not having enough\nenergy or devices to transmit large volumes of information at the size are\nreceived from their farms monitors. Therefore, in this project, we will design\nan algorithm to compress and decompress images reducing energy consumption with\nthe less information lost. Initially, the related problems have been read and\nanalyzed to learn about the techniques used in the past and to be updated with\nthe current works. We implemented Seam Carving and LZW algorithms. The\ncompression of all images, around 1000 takes a time of 5 hours 10 min. We got a\ncompression rate of 1.82:1 with 13.75s average time for each file and a\ndecompression rate of 1.64:1 and 7.5 s average time for each file. The memory\nconsumption we obtained was between 146MB and 504 MB and time consumption was\nbetween 30,5s for 90MB to 12192s for 24410 MB, it was all files.",
    "descriptor": "\nComments: 8 pages, 10 images, 2 figures\n",
    "authors": [
      "Miguel Angel Calvache",
      "Valeria Cardona",
      "Sebastian Tapias",
      "Simon Marin",
      "Mauricio Toro"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01251"
  },
  {
    "id": "arXiv:2112.01252",
    "title": "Australia's Approach to AI Governance in Security and Defence",
    "abstract": "Australia is a leading AI nation with strong allies and partnerships.\nAustralia has prioritised robotics, AI, and autonomous systems to develop\nsovereign capability for the military. Australia commits to Article 36 reviews\nof all new means and methods of warfare to ensure weapons and weapons systems\nare operated within acceptable systems of control. Additionally, Australia has\nundergone significant reviews of the risks of AI to human rights and within\nintelligence organisations and has committed to producing ethics guidelines and\nframeworks in Security and Defence. Australia is committed to OECD's\nvalues-based principles for the responsible stewardship of trustworthy AI as\nwell as adopting a set of National AI ethics principles. While Australia has\nnot adopted an AI governance framework specifically for Defence; Defence\nScience has published 'A Method for Ethical AI in Defence' (MEAID) technical\nreport which includes a framework and pragmatic tools for managing ethical and\nlegal risks for military applications of AI.",
    "descriptor": "\nComments: 38 pages, 7 boxes, 2 figures, 2 annexes, submitted for Eds M. Raska, Z. Stanley-Lockman, & R. Bitzinger. AI Governance for National Security and Defence: Assessing Military AI Strategic Perspectives. Routledge\n",
    "authors": [
      "Susannah Kate Devitt",
      "Damian Copeland"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01252"
  },
  {
    "id": "arXiv:2112.01253",
    "title": "Youla-REN: Learning Nonlinear Feedback Policies with Robust Stability  Guarantees",
    "abstract": "This paper presents a parameterization of nonlinear controllers for uncertain\nsystems building on a recently developed neural network architecture, called\nthe recurrent equilibrium network (REN), and a nonlinear version of the Youla\nparameterization. The proposed framework has \"built-in\" guarantees of\nstability, i.e., all policies in the search space result in a contracting\n(globally exponentially stable) closed-loop system. Thus, it requires very mild\nassumptions on the choice of cost function and the stability property can be\ngeneralized to unseen data. Another useful feature of this approach is that\npolicies are parameterized directly without any constraints, which simplifies\nlearning by a broad range of policy-learning methods based on unconstrained\noptimization (e.g. stochastic gradient descent). We illustrate the proposed\napproach with a variety of simulation examples.",
    "descriptor": "\nComments: submitted to ACC2022\n",
    "authors": [
      "Ruigang Wang",
      "Ian R. Manchester"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.01253"
  },
  {
    "id": "arXiv:2112.01254",
    "title": "Hierarchical Learning to Solve Partial Differential Equations Using  Physics-Informed Neural Networks",
    "abstract": "The Neural network-based approach to solving partial differential equations\nhas attracted considerable attention due to its simplicity and flexibility to\nrepresent the solution of the partial differential equation. In training a\nneural network, the network tends to learn global features corresponding to\nlow-frequency components while high-frequency components are approximated at a\nmuch slower rate (F-principle). For a class of equations in which the solution\ncontains a wide range of scales, the network training process can suffer from\nslow convergence and low accuracy due to its inability to capture the\nhigh-frequency components. In this work, we propose a hierarchical approach to\nimprove the convergence rate and accuracy of the neural network solution to\npartial differential equations. The proposed method comprises multi-training\nlevels in which a newly introduced neural network is guided to learn the\nresidual of the previous level approximation. By the nature of neural networks'\ntraining process, the high-level correction is inclined to capture the\nhigh-frequency components. We validate the efficiency and robustness of the\nproposed hierarchical approach through a suite of linear and nonlinear partial\ndifferential equations.",
    "descriptor": "\nComments: 22 pages, 12 figures\n",
    "authors": [
      "Jihun Han",
      "Yoonsang Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01254"
  },
  {
    "id": "arXiv:2112.01257",
    "title": "Simulation Method Of Cabin Oil Leakage Into Water In Case Of Accidental  Oil Spill",
    "abstract": "Ship oil spill accident has become one of the main causes of Marine\nenvironmental pollution and ecological damage. It is of great significance to\nstudy the process of oil spill into water by using simulation prediction method\nfor oil spill clean-up and emergency rescue work. A great deal of in-depth\nresearch on oil spill simulation and prediction is done. The development\nprocess of the research on the behavior process of oil spill into water is\nanalyzed and the problems are put forward. The advantages and disadvantages of\nsimplified simulation model, keyhole jet model and computational fluid dynamics\nmodel are analyzed and compared. On this basis, the problems existing in the\nresearch and the emphases of future research are pointed out, and a new idea of\nbuilding complex hull model, superposition of complex sea conditions and\ncoupling of simulation calculation methods is proposed.",
    "descriptor": "\nComments: in Chinese language\n",
    "authors": [
      "Qianqian Gu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.01257"
  },
  {
    "id": "arXiv:2112.01258",
    "title": "A framework for fitting quadratic-bilinear systems with applications to  models of electrical circuits",
    "abstract": "In this contribution, we propose a data-driven procedure to fit\nquadratic-bilinear surrogate models from data. Although the dynamics\ncharacterizing the original model are strongly nonlinear, we rely on lifting\ntechniques to embed the original model into a quadratic-bilinear format. Here,\ndata represent generalized transfer function values. This method is an\nextension of methods that do bilinear, or quadratic inference, separately. It\nis based on first fitting a linear model with the classical Loewner framework,\nand then on inferring the best supplementing nonlinear operators, in a\nleast-squares sense. The application scope of this method is given by\nelectrical circuits with nonlinear components (such as diodes). We propose\nvarious test cases to illustrate the performance of the method.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Dimitrios S. Karachalios",
      "Ion Victor Gosea",
      "Athanasios C. Antoulas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.01258"
  },
  {
    "id": "arXiv:2112.01259",
    "title": "Borrowing from Similar Code: A Deep Learning NLP-Based Approach for Log  Statement Automation",
    "abstract": "Software developers embed logging statements inside the source code as an\nimperative duty in modern software development as log files are necessary for\ntracking down runtime system issues and troubleshooting system management\ntasks. However, the current logging process is mostly manual, and thus, proper\nplacement and content of logging statements remain as challenges. To overcome\nthese challenges, methods that aim to automate log placement and predict its\ncontent, i.e., 'where and what to log', are of high interest. Thus, we focus on\npredicting the location (i.e., where) and description (i.e., what) for log\nstatements by utilizing source code clones and natural language processing\n(NLP), as these approaches provide additional context and advantage for log\nprediction. Specifically, we guide our research with three research questions\n(RQs): (RQ1) how similar code snippets, i.e., code clones, can be leveraged for\nlog statements prediction? (RQ2) how the approach can be extended to automate\nlog statements' descriptions? and (RQ3) how effective the proposed methods are\nfor log location and description prediction? To pursue our RQs, we perform an\nexperimental study on seven open-source Java projects. We introduce an updated\nand improved log-aware code-clone detection method to predict the location of\nlogging statements (RQ1). Then, we incorporate natural language processing\n(NLP) and deep learning methods to automate the log statements' description\nprediction (RQ2). Our analysis shows that our hybrid NLP and code-clone\ndetection approach (NLP CC'd) outperforms conventional clone detectors in\nfinding log statement locations on average by 15.60% and achieves 40.86% higher\nperformance on BLEU and ROUGE scores for predicting the description of logging\nstatements when compared to prior research (RQ3).",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Sina Gholamian",
      "Paul A. S. Ward"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01259"
  },
  {
    "id": "arXiv:2112.01261",
    "title": "ViF-SD2E: A Robust Weakly-Supervised Method for Neural Decoding",
    "abstract": "Neural decoding plays a vital role in the interaction between the brain and\noutside world. In this paper, we directly decode the movement track of the\nfinger based on the neural signals of a macaque. The supervised regression\nmethods may over-fit to actual labels contained with noise and require high\nlabeling cost, while unsupervised approaches often have unsatisfactory\naccuracy. Besides, the spatial and temporal information are often ignored or\nnot well exploited in these works. This motivates us to propose a robust\nweakly-supervised method termed ViF-SD2E for neural decoding. In particular,\nViF-SD2E consists of a space-division (SD) module and a\nexploration-exploitation (2E) strategy, to effectively exploit both the spatial\ninformation of the outside world and temporal information of neural activity,\nwhere the SD2E output is compared with the weak 0/1 vision-feedback (ViF) label\nfor training. Extensive experiments demonstrate the effectiveness of our\nmethod, which can be sometimes comparable to the supervised counterparts.",
    "descriptor": "\nComments: 12 pages, 8 figures, 4 tables\n",
    "authors": [
      "Jingyi Feng",
      "Yong Luo",
      "Shuang Song"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01261"
  },
  {
    "id": "arXiv:2112.01270",
    "title": "Multi-Object Grasping -- Estimating the Number of Objects in a Robotic  Grasp",
    "abstract": "A human hand can grasp a desired number of objects at once from a pile based\nsolely on tactile sensing. To do so, a robot needs to grasp within a pile,\nsense the number of objects in the grasp before lifting, and predict the number\nof objects that will remain in the grasp after lifting. It is a challenging\nproblem because when making the prediction, the robotic hand is still in the\npile and the objects in the grasp are not observable to vision systems.\nMoreover, some objects that are grasped by the hand before lifting from the\npile may fall out of the grasp when the hand is lifted. This occurs because\nthey were supported by other objects in the pile instead of the fingers of the\nhand. Therefore, a robotic hand should sense the number of objects in a grasp\nusing its tactile sensors before lifting. This paper presents novel\nmulti-object grasping analyzing methods for solving this problem. They include\na grasp volume calculation, tactile force analysis, and a data-driven deep\nlearning approach. The methods have been implemented on a Barrett hand and then\nevaluated in simulations and a real setup with a robotic system. The evaluation\nresults conclude that once the Barrett hand grasps multiple objects in the\npile, the data-driven model can predict, before lifting, the number of objects\nthat will remain in the hand after lifting. The root-mean-square errors for our\napproach are 0.74 for balls and 0.58 for cubes in simulations, and 1.06 for\nballs, and 1.45 for cubes in the real system.",
    "descriptor": "\nComments: This paper has been accepted to IROS 2021\n",
    "authors": [
      "Tianze Chen",
      "Adheesh Shenoy",
      "Anzhelika Kolinko",
      "Syed Shah",
      "Yu Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01270"
  },
  {
    "id": "arXiv:2112.01273",
    "title": "RawArray: A Simple, Fast, and Extensible Archival Format for Numeric  Data",
    "abstract": "Raw data sizes are growing and proliferating in scientific research, driven\nby the success of data-hungry computational methods, such as machine learning.\nThe preponderance of proprietary and shoehorned data formats make computations\nslower and make it harder to reproduce research and to port methods to new\nplatforms. Here we present the RawArray format: a simple, fast, and extensible\nformat for archival storage of multidimensional numeric arrays on disk.\nThe RawArray file format is a simple concatenation of a header array and a\ndata array. The header comprises seven or more 64-bit unsigned integers. The\narray data can be anything. Arbitrary user metadata can be appended to an\nRawArray file if desired, for example to store measurement details, color\npalettes, or geolocation data.\nWe present benchmarks showing a factor of 2--3$\\times$ speedup over HDF5 for\na range of array sizes and a speedup of up to 20$\\times$ in reading the common\ndeep learning datasets MNIST and CIFAR10.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "David S. Smith"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01273"
  },
  {
    "id": "arXiv:2112.01274",
    "title": "The Impact of Data Distribution on Fairness and Robustness in Federated  Learning",
    "abstract": "Federated Learning (FL) is a distributed machine learning protocol that\nallows a set of agents to collaboratively train a model without sharing their\ndatasets. This makes FL particularly suitable for settings where data privacy\nis desired. However, it has been observed that the performance of FL is closely\nrelated to the similarity of the local data distributions of agents.\nParticularly, as the data distributions of agents differ, the accuracy of the\ntrained models drop. In this work, we look at how variations in local data\ndistributions affect the fairness and the robustness properties of the trained\nmodels in addition to the accuracy. Our experimental results indicate that, the\ntrained models exhibit higher bias, and become more susceptible to attacks as\nlocal data distributions differ. Importantly, the degradation in the fairness,\nand robustness can be much more severe than the accuracy. Therefore, we reveal\nthat small variations that have little impact on the accuracy could still be\nimportant if the trained model is to be deployed in a fairness/security\ncritical context.",
    "descriptor": "\nComments: Published at The Third IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications. arXiv admin note: text overlap with arXiv:2010.07427, arXiv:2007.03767\n",
    "authors": [
      "Mustafa Safa Ozdayi",
      "Murat Kantarcioglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01274"
  },
  {
    "id": "arXiv:2112.01275",
    "title": "Advancing Artificial Intelligence and Machine Learning in the U.S.  Government Through Improved Public Competitions",
    "abstract": "In the last two years, the U.S. government has emphasized the importance of\naccelerating artificial intelligence (AI) and machine learning (ML) within the\ngovernment and across the nation. In particular, the National Artificial\nIntelligence Initiative Act of 2020, which became law on January 1, 2021,\nprovides for a coordinated program across the entire federal government to\naccelerate AI research and application. The U.S. government can benefit from\npublic artificial intelligence and machine learning challenges through the\ndevelopment of novel algorithms and participation in experiential training.\nAlthough the public, private, and non-profit sectors have a history of\nleveraging crowdsourcing initiatives to generate novel solutions to difficult\nproblems and engage stakeholders, interest in public competitions has waned in\nrecent years as a result of at least three major factors: (1) a lack of\nhigh-quality, high-impact data; (2) a narrow engagement focus on specialized\ngroups; and (3) insufficient operationalization of challenge results. Herein we\nidentify common issues and recommend approaches to increase the effectiveness\nof challenges. To address these barriers, enabling the use of public\ncompetitions for accelerating AI and ML practice, the U.S. government must\nleverage methods that protect sensitive data while enabling modelling, enable\neasier participation, empower deployment of validated models, and incentivize\nengagement from broad sections of the population.",
    "descriptor": "\nComments: Presented at AAAI FSS-21: Artificial Intelligence in Government and Public Sector, Washington, DC, USA\n",
    "authors": [
      "Ezekiel J. Maier"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01275"
  },
  {
    "id": "arXiv:2112.01276",
    "title": "(SARS-CoV-2) COVID 19: Genomic surveillance and evaluation of the impact  on the population speaker of indigenous language in Mexico",
    "abstract": "The importance of the working document is that it allows the analysis of\ninformation and cases associated with (SARS-CoV-2) COVID-19, based on the daily\ninformation generated by the Government of Mexico through the Secretariat of\nHealth, responsible for the Epidemiological Surveillance System for Viral\nRespiratory Diseases (SVEERV). The information in the SVEERV is disseminated as\nopen data, and the level of information is displayed at the municipal, state\nand national levels. On the other hand, the monitoring of the genomic\nsurveillance of (SARS-CoV-2) COVID-19, through the identification of variants\nand mutations, is registered in the database of the Information System of the\nGlobal Initiative on Sharing All Influenza Data (GISAID) based in Germany.\nThese two sources of information SVEERV and GISAID provide the information for\nthe analysis of the impact of (SARS-CoV-2) COVID-19 on the population in\nMexico. The first data source identifies information, at the national level, on\npatients according to age, sex, comorbidities and COVID-19 presence\n(SARS-CoV-2), among other characteristics. The data analysis is carried out by\nmeans of the design of an algorithm applying data mining techniques and\nmethodology, to estimate the case fatality rate, positivity index and identify\na typology according to the severity of the infection identified in patients\nwho present a positive result. for (SARS-CoV-2) COVID-19. From the second data\nsource, information is obtained worldwide on the new variants and mutations of\nCOVID-19 (SARS-CoV-2), providing valuable information for timely genomic\nsurveillance. This study analyzes the impact of (SARS-CoV-2) COVID-19 on the\nindigenous language-speaking population, it allows us to provide information,\nquickly and in a timely manner, to support the design of public policy on\nhealth.",
    "descriptor": "\nComments: 37 pages, 11 tables, 5 graphs\n",
    "authors": [
      "Medel-Ram\u00edrez Carlos",
      "Medel-L\u00f3pez Hilario",
      "Lara-M\u00e9rida Jennifer"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01276"
  },
  {
    "id": "arXiv:2112.01278",
    "title": "Where the Earth is flat and 9/11 is an inside job: A comparative  algorithm audit of conspiratorial information in web search results",
    "abstract": "Web search engines are important online information intermediaries that are\nfrequently used and highly trusted by the public despite multiple evidence of\ntheir outputs being subjected to inaccuracies and biases. One form of such\ninaccuracy, which so far received little scholarly attention, is the presence\nof conspiratorial information, namely pages promoting conspiracy theories. We\naddress this gap by conducting a comparative algorithm audit to examine the\ndistribution of conspiratorial information in search results across five search\nengines: Google, Bing, DuckDuckGo, Yahoo and Yandex. Using a virtual\nagent-based infrastructure, we systematically collect search outputs for six\nconspiracy theory-related queries (flat earth, new world order, qanon, 9/11,\nilluminati, george soros) across three locations (two in the US and one in the\nUK) and two observation periods (March and May 2021). We find that all search\nengines except Google consistently displayed conspiracy-promoting results and\nreturned links to conspiracy-dedicated websites in their top results, although\nthe share of such content varied across queries. Most conspiracy-promoting\nresults came from social media and conspiracy-dedicated websites while\nconspiracy-debunking information was shared by scientific websites and, to a\nlesser extent, legacy media. The fact that these observations are consistent\nacross different locations and time periods highlight the possibility of some\nsearch engines systematically prioritizing conspiracy-promoting content and,\nthus, amplifying their distribution in the online environments.",
    "descriptor": "",
    "authors": [
      "Aleksandra Urman",
      "Mykola Makhortykh",
      "Roberto Ulloa",
      "Juhi Kulshrestha"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01278"
  },
  {
    "id": "arXiv:2112.01280",
    "title": "Learning Graphon Mean Field Games and Approximate Nash Equilibria",
    "abstract": "Recent advances at the intersection of dense large graph limits and mean\nfield games have begun to enable the scalable analysis of a broad class of\ndynamical sequential games with large numbers of agents. So far, results have\nbeen largely limited to graphon mean field systems with continuous-time\ndiffusive or jump dynamics, typically without control and with little focus on\ncomputational methods. We propose a novel discrete-time formulation for graphon\nmean field games as the limit of non-linear dense graph Markov games with weak\ninteraction. On the theoretical side, we give extensive and rigorous existence\nand approximation properties of the graphon mean field solution in sufficiently\nlarge systems. On the practical side, we provide general learning schemes for\ngraphon mean field equilibria by either introducing agent equivalence classes\nor reformulating the graphon mean field system as a classical mean field\nsystem. By repeatedly finding a regularized optimal control solution and its\ngenerated mean field, we successfully obtain plausible approximate Nash\nequilibria in otherwise infeasible large dense graph games with many agents.\nEmpirically, we are able to demonstrate on a number of examples that the\nfinite-agent behavior comes increasingly close to the mean field behavior for\nour computed equilibria as the graph or system size grows, verifying our\ntheory. More generally, we successfully apply policy gradient reinforcement\nlearning in conjunction with sequential Monte Carlo methods.",
    "descriptor": "",
    "authors": [
      "Kai Cui",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.01280"
  },
  {
    "id": "arXiv:2112.01281",
    "title": "Expose Uncertainty, Instill Distrust, Avoid Explanations: Towards  Ethical Guidelines for AI",
    "abstract": "In this position paper, I argue that the best way to help and protect humans\nusing AI technology is to make them aware of the intrinsic limitations and\nproblems of AI algorithms. To accomplish this, I suggest three ethical\nguidelines to be used in the presentation of results, mandating AI systems to\nexpose uncertainty, to instill distrust, and, contrary to traditional views, to\navoid explanations. The paper does a preliminary discussion of the guidelines\nand provides some arguments for their adoption, aiming to start a debate in the\ncommunity about AI ethics in practice.",
    "descriptor": "\nComments: Presented in the NeurIPS 2021 workshop on Human-Centered AI. December 13th 2021\n",
    "authors": [
      "Claudio S. Pinhanez"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01281"
  },
  {
    "id": "arXiv:2112.01282",
    "title": "Achieving a Data-driven Risk Assessment Methodology for Ethical AI",
    "abstract": "The AI landscape demands a broad set of legal, ethical, and societal\nconsiderations to be accounted for in order to develop ethical AI (eAI)\nsolutions which sustain human values and rights. Currently, a variety of\nguidelines and a handful of niche tools exist to account for and tackle\nindividual challenges. However, it is also well established that many\norganizations face practical challenges in navigating these considerations from\na risk management perspective. Therefore, new methodologies are needed to\nprovide a well-vetted and real-world applicable structure and path through the\nchecks and balances needed for ethically assessing and guiding the development\nof AI. In this paper we show that a multidisciplinary research approach,\nspanning cross-sectional viewpoints, is the foundation of a pragmatic\ndefinition of ethical and societal risks faced by organizations using AI.\nEqually important is the findings of cross-structural governance for\nimplementing eAI successfully. Based on evidence acquired from our\nmultidisciplinary research investigation, we propose a novel data-driven risk\nassessment methodology, entitled DRESS-eAI. In addition, through the evaluation\nof our methodological implementation, we demonstrate its state-of-the-art\nrelevance as a tool for sustaining human values in the data-driven AI era.",
    "descriptor": "\nComments: 29 pages, 5 figures\n",
    "authors": [
      "Anna Fell\u00e4nder",
      "Jonathan Rebane",
      "Stefan Larsson",
      "Mattias Wiggberg",
      "Fredrik Heintz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01282"
  },
  {
    "id": "arXiv:2112.01283",
    "title": "Detecting Extratropical Cyclones of the Northern Hemisphere with Single  Shot Detector",
    "abstract": "In this paper, we propose a deep learning-based model to detect extratropical\ncyclones (ETCs) of northern hemisphere, while developing a novel workflow of\nprocessing images and generating labels for ETCs. We first label the cyclone\ncenter by adapting an approach from Bonfanti et.al. [1] and set up criteria of\nlabeling ETCs of three categories: developing, mature, and declining stages. We\nthen propose a framework of labeling and preprocessing the images in our\ndataset. Once the images and labels are ready to serve as inputs, we create our\nobject detection model named Single Shot Detector (SSD) to fit the format of\nour dataset. We train and evaluate our model with our labeled dataset on two\nsettings (binary and multiclass classifications), while keeping a record of the\nresults. Finally, we achieved relatively high performance with detecting ETCs\nof mature stage (mean Average Precision is 86.64%), and an acceptable result\nfor detecting ETCs of all three categories (mean Average Precision 79.34%). We\nconclude that the single-shot detector model can succeed in detecting ETCs of\ndifferent stages, and it has demonstrated great potential in the future\napplications of ETC detection in other relevant settings.",
    "descriptor": "",
    "authors": [
      "Minjing Shi",
      "Pengfei He",
      "Yuli Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.01283"
  },
  {
    "id": "arXiv:2112.01285",
    "title": "Adaptive non-intrusive reconstruction of solutions to high-dimensional  parametric PDEs",
    "abstract": "Numerical methods for random parametric PDEs can greatly benefit from\nadaptive refinement schemes, in particular when functional approximations are\ncomputed as in stochastic Galerkin and stochastic collocations methods. This\nwork is concerned with a non-intrusive generalization of the adaptive Galerkin\nFEM with residual based error estimation. It combines the non-intrusive\ncharacter of a randomized least-squares method with the a posteriori error\nanalysis of stochastic Galerkin methods. The proposed approach uses the\nVariational Monte Carlo method to obtain a quasi-optimal low-rank approximation\nof the Galerkin projection in a highly efficient hierarchical tensor format. We\nderive an adaptive refinement algorithm which is steered by a reliable error\nestimator. Opposite to stochastic Galerkin methods, the approach is easily\napplicable to a wide range of problems, enabling a fully automated adjustment\nof all discretization parameters. Benchmark examples with affine and\n(unbounded) lognormal coefficient fields illustrate the performance of the\nnon-intrusive adaptive algorithm, showing best-in-class performance.",
    "descriptor": "",
    "authors": [
      "Martin Eigel",
      "Nando Farchmin",
      "Sebastian Heidenreich",
      "Philipp Trunschke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Functional Analysis (math.FA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.01285"
  },
  {
    "id": "arXiv:2112.01292",
    "title": "Optimal regularizations for data generation with probabilistic graphical  models",
    "abstract": "Understanding the role of regularization is a central question in Statistical\nInference. Empirically, well-chosen regularization schemes often dramatically\nimprove the quality of the inferred models by avoiding overfitting of the\ntraining data. We consider here the particular case of L 2 and L 1\nregularizations in the Maximum A Posteriori (MAP) inference of generative\npairwise graphical models. Based on analytical calculations on Gaussian\nmultivariate distributions and numerical experiments on Gaussian and Potts\nmodels we study the likelihoods of the training, test, and 'generated data'\n(with the inferred models) sets as functions of the regularization strengths.\nWe show in particular that, at its maximum, the test likelihood and the\n'generated' likelihood, which quantifies the quality of the generated samples,\nhave remarkably close values. The optimal value for the regularization strength\nis found to be approximately equal to the inverse sum of the squared couplings\nincoming on sites on the underlying network of interactions. Our results seem\nlargely independent of the structure of the true underlying interactions that\ngenerated the data, of the regularization scheme considered, and are valid when\nsmall fluctuations of the posterior distribution around the MAP estimator are\ntaken into account. Connections with empirical works on protein models learned\nfrom homologous sequences are discussed.",
    "descriptor": "",
    "authors": [
      "Arnaud Fanthomme",
      "F Rizzato",
      "S Cocco",
      "R Monasson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.01292"
  },
  {
    "id": "arXiv:2112.01293",
    "title": "The empirical study of e-learning post-acceptance after the spread of  COVID-19: A multi-analytical approach based hybrid SEM-ANN",
    "abstract": "There are several reasons why the fear of vaccination has caused population\nrejection. Questions have been raised by students regarding the effectiveness\nof vaccines, which in turn has led to vaccination hesitancy. Students\nperceptions are influenced by vaccination hesitancy, which affects the\nacceptance of e-learning platforms. Hence, this research aimed to examine the\npost-acceptance of e-learning platforms on the basis of a conceptual model that\nemploys different variables. Distinct contribution is made by every variable to\nthe post-acceptance of e-learning platforms. A hybrid model was used in the\ncurrent study in which technology acceptance model (TAM) determinants were\nemployed along with other external factors such as fear of vaccination,\nperceived routine use, perceived enjoyment, perceived critical mass, and\nself-efficiency which are directly linked to post-acceptance of e-learning\nplatforms. The focus of earlier studies on this topic has been on the\nsignificance of e-learning acceptance in various environments and countries.\nHowever, in this study, the newly-spread use of e-learning platforms in the\ngulf area was examined using a hybrid conceptual model. The empirical studies\ncarried out in the past mainly used structural equation modelling (SEM)\nanalysis; however, this study used an evolving hybrid analysis approach, in\nwhich SEM and the artificial neural network (ANN) that are based on deep\nlearning were employed. The importance-performance map analysis (IPMA) was also\nused in this study to determine the significance and performance of each\nfactor. The proposed model is backed by the findings of data analysis.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Ashraf Elnagar",
      "Imad Afyouni",
      "Ismail Shahin",
      "Ali Bou Nassif",
      "Said A. Salloum"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.01293"
  },
  {
    "id": "arXiv:2112.01298",
    "title": "Meaningful human control over AI systems: beyond talking the talk",
    "abstract": "The concept of meaningful human control has been proposed to address\nresponsibility gaps and mitigate them by establishing conditions that enable a\nproper attribution of responsibility for humans (e.g., users, designers and\ndevelopers, manufacturers, legislators). However, the relevant discussions\naround meaningful human control have so far not resulted in clear requirements\nfor researchers, designers, and engineers. As a result, there is no consensus\non how to assess whether a designed AI system is under meaningful human\ncontrol, making the practical development of AI-based systems that remain under\nmeaningful human control challenging. In this paper, we address the gap between\nphilosophical theory and engineering practice by identifying four actionable\nproperties which AI-based systems must have to be under meaningful human\ncontrol. First, a system in which humans and AI algorithms interact should have\nan explicitly defined domain of morally loaded situations within which the\nsystem ought to operate. Second, humans and AI agents within the system should\nhave appropriate and mutually compatible representations. Third, responsibility\nattributed to a human should be commensurate with that human's ability and\nauthority to control the system. Fourth, there should be explicit links between\nthe actions of the AI agents and actions of humans who are aware of their moral\nresponsibility. We argue these four properties are necessary for AI systems\nunder meaningful human control, and provide possible directions to incorporate\nthem into practice. We illustrate these properties with two use cases,\nautomated vehicle and AI-based hiring. We believe these four properties will\nsupport practically-minded professionals to take concrete steps toward\ndesigning and engineering for AI systems that facilitate meaningful human\ncontrol and responsibility.",
    "descriptor": "",
    "authors": [
      "Luciano Cavalcante Siebert",
      "Maria Luce Lupetti",
      "Evgeni Aizenberg",
      "Niek Beckers",
      "Arkady Zgonnikov",
      "Herman Veluwenkamp",
      "David Abbink",
      "Elisa Giaccardi",
      "Geert-Jan Houben",
      "Catholijn M. Jonker",
      "Jeroen van den Hoven",
      "Deborah Forster",
      "Reginald L. Lagendijk"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01298"
  },
  {
    "id": "arXiv:2112.01299",
    "title": "Gradient Inversion Attack: Leaking Private Labels in Two-Party Split  Learning",
    "abstract": "Split learning is a popular technique used to perform vertical federated\nlearning, where the goal is to jointly train a model on the private input and\nlabel data held by two parties. To preserve privacy of the input and label\ndata, this technique uses a split model and only requires the exchange of\nintermediate representations (IR) of the inputs and gradients of the IR between\nthe two parties during the learning process. In this paper, we propose Gradient\nInversion Attack (GIA), a label leakage attack that allows an adversarial input\nowner to learn the label owner's private labels by exploiting the gradient\ninformation obtained during split learning. GIA frames the label leakage attack\nas a supervised learning problem by developing a novel loss function using\ncertain key properties of the dataset and models. Our attack can uncover the\nprivate label data on several multi-class image classification problems and a\nbinary conversion prediction task with near-perfect accuracy (97.01% - 99.96%),\ndemonstrating that split learning provides negligible privacy benefits to the\nlabel owner. Furthermore, we evaluate the use of gradient noise to defend\nagainst GIA. While this technique is effective for simpler datasets, it\nsignificantly degrades utility for datasets with higher input dimensionality.\nOur findings underscore the need for better privacy-preserving training\ntechniques for vertically split data.",
    "descriptor": "",
    "authors": [
      "Sanjay Kariyappa",
      "Moinuddin K Qureshi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01299"
  },
  {
    "id": "arXiv:2112.01301",
    "title": "Machine Learning for Air Transport Planning and Management",
    "abstract": "In this work we compare the performance of several machine learning\nalgorithms applied to the problem of modelling air transport demand.\nForecasting in the air transport industry is an essential part of planning and\nmanaging because of the economic and financial aspects of the industry. The\ntraditional approach used in airline operations as specified by the\nInternational Civil Aviation Organization is the use of a multiple linear\nregression (MLR) model, utilizing cost variables and economic factors. Here,\nthe performance of models utilizing an artificial neural network (ANN), an\nadaptive neuro-fuzzy inference system (ANFIS), a genetic algorithm, a support\nvector machine, and a regression tree are compared to MLR. The ANN and ANFIS\nhad the best performance in terms of the lowest mean squared error.",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Graham Wild",
      "Glenn Baxter",
      "Pannarat Srisaeng",
      "Steven Richardson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.01301"
  },
  {
    "id": "arXiv:2112.01304",
    "title": "The voice of few, the opinions of many: evidence of social biases in  Twitter COVID-19 fake news sharing",
    "abstract": "Online platforms play a relevant role in creation and diffusion of false or\nmisleading news. Concerningly, the COVID-19 pandemic is shaping a communication\nnetwork - barely considered in the literature - which reflects the emergence of\ncollective attention towards a topic that rapidly gained universal interest.\nHere, we characterize the dynamics of this network on Twitter, analyzing how\nunreliable content distributes among its users. We find that a minority of\naccounts is responsible for the majority of the misinformation circulating\nonline, and identify two categories of users: a few active ones, playing the\nrole of \"creators\", and a majority playing the role of \"consumers\". The\nrelative proportion of these groups ($\\approx$14% creators - 86% consumers)\nappears stable over time: Consumers are mostly exposed to the opinions of a\nvocal minority of creators, that could be mistakenly understood as of\nrepresentative of the majority of users. The corresponding pressure from a\nperceived majority is identified as a potential driver of the ongoing COVID-19\ninfodemic.",
    "descriptor": "",
    "authors": [
      "Piergiorgio Castioni",
      "Giulia Andrighetto",
      "Riccardo Gallotti",
      "Eugenia Polizzi",
      "Manlio De Domenico"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.01304"
  },
  {
    "id": "arXiv:2112.01305",
    "title": "Security Monitoring System Using FaceNet For Wireless Sensor Network",
    "abstract": "Wireless Sensor networks are used to monitor remote areas. Wireless sensor\nnetwork can be applied to monitor a facility by considering each camera as\nsensor nodes. Cameras are used as nodes in a wireless sensor network with a\ncentral server or a gateway node for all the monitoring and analysis of the\ninformation retrieved from the nodes. Identification and authentication of\nusers in any organization is quite difficult due to high movement. Face\nrecognition can be used detect faces and identify them continuously in a video\nfeed which can be deployed to continuously monitor an area. Feeding from camera\nto base station uses Multi-task Cascaded Convolutional Neural Networks (MCTNN)\nand FaceNet algorithms for face recognition. Further information about the\nperson is sent to all the end-user nodes present in the wireless network. This\napproach has been implemented and evaluated on a prototype wired camera network\ncalled FaceNet. A method for tracking people in 2D world coordinates and\nacquiring canonical frontal face images that fits the sensor network paradigm.\nThe approach evaluates and demonstrates the tasking algorithm in action on data\nacquired from the FaceNet camera network. In this paper, face recognition\nalgorithm FaceNet is used to implement security monitoring network",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Preetha S",
      "Sheela S V"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01305"
  },
  {
    "id": "arXiv:2112.01310",
    "title": "An Intelligent Vice Cluster Head Election Protocol in WSN",
    "abstract": "Wireless sensor networks (WSNs) has a practical ability to link a set of\nsensors to build a wireless network that can be accessed remotely; this\ntechnology has become increasingly popular in recent years. Wi-Fi-enabled\nsensor networks (WSNs) are used to gather information from the environment in\nwhich the network operates. Many obstacles prevent wireless sensor networks\nfrom being used in a wide range of fields. This includes maintaining network\nstability and extending network life. In a wireless network, sensors are the\nmost essential component. Sensors are powered by a battery that has a finite\namount of power. The battery is prone to power loss, and the sensor is\ntherefore rendered inoperative as a result. In addition, the growing number of\nsensor nodes off-site affects the network's stability. The transmission and\nreception of information between the sensors and the base consumes the most\nenergy in the sensor. An Intelligent Vice Cluster Head Selection Protocol is\nproposed in this study (IVC LEACH). In order to achieve the best performance\nwith the least amount of energy consumption, the proposed hierarchical protocol\nrelies on a fuzzy logic algorithm using four parameters to calculate the value\nof each node in the network and divides them into three hierarchical levels\nbased on their value. This improves network efficiency and reliability while\nextending network life by 50 percent more than the original Low Energy Adaptive\nClustering Hierarchy protocol",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Ghassan Samara",
      "Mohammad A. Hassan",
      "Yahya Zayed"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.01310"
  },
  {
    "id": "arXiv:2112.01314",
    "title": "NeSF: Neural Shading Field for Image Harmonization",
    "abstract": "Image harmonization aims at adjusting the appearance of the foreground to\nmake it more compatible with the background. Due to a lack of understanding of\nthe background illumination direction, existing works are incapable of\ngenerating a realistic foreground shading. In this paper, we decompose the\nimage harmonization into two sub-problems: 1) illumination estimation of\nbackground images and 2) rendering of foreground objects. Before solving these\ntwo sub-problems, we first learn a direction-aware illumination descriptor via\na neural rendering framework, of which the key is a Shading Module that\ndecomposes the shading field into multiple shading components given depth\ninformation. Then we design a Background Illumination Estimation Module to\nextract the direction-aware illumination descriptor from the background.\nFinally, the illumination descriptor is used in conjunction with the neural\nrendering framework to generate the harmonized foreground image containing a\nnovel harmonized shading. Moreover, we construct a photo-realistic synthetic\nimage harmonization dataset that contains numerous shading variations by\nimage-based lighting. Extensive experiments on this dataset demonstrate the\neffectiveness of the proposed method. Our dataset and code will be made\npublicly available.",
    "descriptor": "",
    "authors": [
      "Zhongyun Hu",
      "Ntumba Elie Nsampi",
      "Xue Wang",
      "Qing Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01314"
  },
  {
    "id": "arXiv:2112.01315",
    "title": "A Generator Framework For Evolving Variant-Rich Software",
    "abstract": "Evolving software is challenging, even more when it exists in many different\nvariants. Such software evolves not only in time, but also in space--another\ndimension of complexity. While evolution in space is supported by a variety of\nproduct-line and variability management tools, many of which originating from\nresearch, their level of evaluation varies significantly, which threatens their\nrelevance for practitioners and future research. Many tools have only been\nevaluated on ad hoc datasets, minimal examples or available preprocessor-based\nproduct lines, missing the early clone & own phases and the re-engineering into\nconfigurable platforms--large parts of the actual evolution lifecycle of\nvariant-rich systems. Our long-term goal is to provide benchmarks to increase\nthe maturity of evaluating such tools. However, providing manually curated\nbenchmarks that cover the whole evolution lifecycle and that are detailed\nenough to serve as ground truths, is challenging. We present the framework\nvpbench to generates source-code histories of variant-rich systems. Vpbench\ncomprises several modular generators relying on evolution operators that\nsystematically and automatically evolve real codebases and document the\nevolution in detail. We provide simple and more advanced generators--e.g.,\nrelying on code transplantation techniques to obtain whole features from\nexternal, real-world projects. We define requirements and demonstrate how\nvpbench addresses them for the generated version histories, focusing on support\nfor evolution in time and space, the generation of detailed meta-data about the\nevolution, also considering compileability and extensibility.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Christoph Derks",
      "Daniel Str\u00fcber",
      "Thorsten Berger"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.01315"
  },
  {
    "id": "arXiv:2112.01316",
    "title": "Putting 3D Spatially Sparse Networks on a Diet",
    "abstract": "3D neural networks have become prevalent for many 3D vision tasks including\nobject detection, segmentation, registration, and various perception tasks for\n3D inputs. However, due to the sparsity and irregularity of 3D data, custom 3D\noperators or network designs have been the primary focus of 3D research, while\nthe size of networks or efficacy of parameters has been overlooked. In this\nwork, we perform the first comprehensive study on the weight sparsity of\nspatially sparse 3D convolutional networks and propose a compact weight-sparse\nand spatially sparse 3D convnet (WS^3-ConvNet) for semantic segmentation and\ninstance segmentation. We employ various network pruning strategies to find\ncompact networks and show our WS^3-ConvNet achieves minimal loss in performance\n(2.15% drop) with orders-of-magnitude smaller number of parameters (1/100\ncompression rate). Finally, we systematically analyze the compression patterns\nof WS^3-ConvNet and show interesting emerging sparsity patterns common in our\ncompressed networks to further speed up inference.",
    "descriptor": "",
    "authors": [
      "Junha Lee",
      "Christopher Choy",
      "Jaesik Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01316"
  },
  {
    "id": "arXiv:2112.01317",
    "title": "Monolith to Microservices: Representing Application Software through  Heterogeneous GNN",
    "abstract": "Monolith software applications encapsulate all functional capabilities into a\nsingle deployable unit. While there is an intention to maintain clean\nseparation of functionalities even within the monolith, they tend to get\ncompromised with the growing demand for new functionalities, changing team\nmembers, tough timelines, non-availability of skill sets, etc. As such\napplications age, they become hard to understand and maintain. Therefore,\nmicroservice architectures are increasingly used as they advocate building an\napplication through multiple smaller sized, loosely coupled functional\nservices, wherein each service owns a single functional responsibility. This\napproach has made microservices architecture as the natural choice for cloud\nbased applications. But the challenges in the automated separation of\nfunctional modules for the already written monolith code slows down their\nmigration task.\nGraphs are a natural choice to represent software applications. Various\nsoftware artifacts like programs, tables and files become nodes in the graph\nand the different relationships they share, such as function calls,\ninheritance, resource(tables, files) access types (Create, Read, Update,\nDelete) can be represented as links in the graph. We therefore deduce this\ntraditional application decomposition problem to a heterogeneous graph based\nclustering task. Our solution is the first of its kind to leverage\nheterogeneous graph neural network to learn representations of such diverse\nsoftware entities and their relationships for the clustering task. We study the\neffectiveness by comparing with works from both software engineering and\nexisting graph representation based techniques. We experiment with applications\nwritten in an object oriented language like Java and a procedural language like\nCOBOL and show that our work is applicable across different programming\nparadigms.",
    "descriptor": "",
    "authors": [
      "Alex Mathai",
      "Sambaran Bandyopadhyay",
      "Utkarsh Desai",
      "Srikanth Tamilselvam"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01317"
  },
  {
    "id": "arXiv:2112.01319",
    "title": "TinyML Platforms Benchmarking",
    "abstract": "Recent advances in state-of-the-art ultra-low power embedded devices for\nmachine learning (ML) have permitted a new class of products whose key features\nenable ML capabilities on microcontrollers with less than 1 mW power\nconsumption (TinyML). TinyML provides a unique solution by aggregating and\nanalyzing data at the edge on low-power embedded devices. However, we have only\nrecently been able to run ML on microcontrollers, and the field is still in its\ninfancy, which means that hardware, software, and research are changing\nextremely rapidly. Consequently, many TinyML frameworks have been developed for\ndifferent platforms to facilitate the deployment of ML models and standardize\nthe process. Therefore, in this paper, we focus on bench-marking two popular\nframeworks: Tensorflow Lite Micro (TFLM) on the Arduino Nano BLE and CUBE AI on\nthe STM32-NucleoF401RE to provide a standardized framework selection criterion\nfor specific applications.",
    "descriptor": "",
    "authors": [
      "Anas Osman",
      "Usman Abid",
      "Luca Gemma",
      "Matteo Perotto",
      "Davide Brunelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.01319"
  },
  {
    "id": "arXiv:2112.01321",
    "title": "Lists of Top Artists to Watch computed algorithmically",
    "abstract": "Lists of top artists to watch are periodically published by various art world\nmedia publications. These lists are selected editorially and reflect the\nsubjective opinions of their creators.\nWe show an application of ranking by momentum method to algorithmically\nproduce lists of artists to watch derived from our platform Articker. We use\nour algorithms every month to produce a new list of momentum leaders on\nwww.articker.org.\nThe lists of momentum leaders computed this way has the following properties:\na.It is small (because of the small frontier property). b.It is unbiased --\nwith no bias towards famous artists nor emerging, and yet unknown, artists c It\nis fair -- artists who are not included in the list must be Pareto dominated by\nat least one member of the momentum leaders list (Pareto frontier) d.It is\nobjective -- it is computed automatically, not editorially selected.",
    "descriptor": "\nComments: 12 pages, 13 figures\n",
    "authors": [
      "Tomasz Imielinski"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.01321"
  },
  {
    "id": "arXiv:2112.01326",
    "title": "A More Scalable Mixed-Integer Encoding for Metric Temporal Logic",
    "abstract": "The state-of-the-art in optimal control from timed temporal logic\nspecifications, including Metric Temporal Logic (MTL) and Signal Temporal Logic\n(STL), is based on Mixed-Integer Convex Programming (MICP). The standard MICP\napproach is sound and complete, but struggles to scale to long and complex\nspecifications. Drawing on recent advances in trajectory optimization for\npiecewise-affine systems, we propose a new MICP encoding for finite transition\nsystems that significantly improves scalability to long and complex MTL\nspecifications. Rather than seeking to reduce the number of variables in the\nMICP, we focus instead on designing an encoding with a tight convex relaxation.\nThis leads to a larger optimization problem, but significantly improves\nbranch-and-bound solver performance. In simulation experiments involving a\nmobile robot in a grid-world, the proposed encoding can reduce computation\ntimes by several orders of magnitude.",
    "descriptor": "\nComments: L-CSS extended version\n",
    "authors": [
      "Vince Kurtz",
      "Hai Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.01326"
  },
  {
    "id": "arXiv:2112.01328",
    "title": "Homotopy Based Reinforcement Learning with Maximum Entropy for  Autonomous Air Combat",
    "abstract": "The Intelligent decision of the unmanned combat aerial vehicle (UCAV) has\nlong been a challenging problem. The conventional search method can hardly\nsatisfy the real-time demand during high dynamics air combat scenarios. The\nreinforcement learning (RL) method can significantly shorten the decision time\nvia using neural networks. However, the sparse reward problem limits its\nconvergence speed and the artificial prior experience reward can easily deviate\nits optimal convergent direction of the original task, which raises great\ndifficulties for the RL air combat application. In this paper, we propose a\nhomotopy-based soft actor-critic method (HSAC) which focuses on addressing\nthese problems via following the homotopy path between the original task with\nsparse reward and the auxiliary task with artificial prior experience reward.\nThe convergence and the feasibility of this method are also proved in this\npaper. To confirm our method feasibly, we construct a detailed 3D air combat\nsimulation environment for the RL-based methods training firstly, and we\nimplement our method in both the attack horizontal flight UCAV task and the\nself-play confrontation task. Experimental results show that our method\nperforms better than the methods only utilizing the sparse reward or the\nartificial prior experience reward. The agent trained by our method can reach\nmore than 98.3% win rate in the attack horizontal flight UCAV task and average\n67.4% win rate when confronted with the agents trained by the other two\nmethods.",
    "descriptor": "",
    "authors": [
      "Yiwen Zhu",
      "Zhou Fang",
      "Yuan Zheng",
      "Wenya Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01328"
  },
  {
    "id": "arXiv:2112.01330",
    "title": "CSAW-M: An Ordinal Classification Dataset for Benchmarking Mammographic  Masking of Cancer",
    "abstract": "Interval and large invasive breast cancers, which are associated with worse\nprognosis than other cancers, are usually detected at a late stage due to false\nnegative assessments of screening mammograms. The missed screening-time\ndetection is commonly caused by the tumor being obscured by its surrounding\nbreast tissues, a phenomenon called masking. To study and benchmark\nmammographic masking of cancer, in this work we introduce CSAW-M, the largest\npublic mammographic dataset, collected from over 10,000 individuals and\nannotated with potential masking. In contrast to the previous approaches which\nmeasure breast image density as a proxy, our dataset directly provides\nannotations of masking potential assessments from five specialists. We also\ntrained deep learning models on CSAW-M to estimate the masking level and showed\nthat the estimated masking is significantly more predictive of screening\nparticipants diagnosed with interval and large invasive cancers -- without\nbeing explicitly trained for these tasks -- than its breast density\ncounterparts.",
    "descriptor": "\nComments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks\n",
    "authors": [
      "Moein Sorkhei",
      "Yue Liu",
      "Hossein Azizpour",
      "Edward Azavedo",
      "Karin Dembrower",
      "Dimitra Ntoula",
      "Athanasios Zouzos",
      "Fredrik Strand",
      "Kevin Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01330"
  },
  {
    "id": "arXiv:2112.01332",
    "title": "Towards generating citation sentences for multiple references with  intent control",
    "abstract": "Machine-generated citation sentences can aid automated scientific literature\nreview and assist article writing. Current methods in generating citation text\nwere limited to single citation generation using the citing document and a\ncited document as input. However, in real-world situations, writers often\nsummarize several studies in one sentence or discuss relevant information\nacross the entire paragraph. In addition, multiple citation intents have been\npreviously identified, implying that writers may need control over the intents\nof generated sentences to cover different scenarios. Therefore, this work\nfocuses on generating multiple citations and releasing a newly collected\ndataset named CiteMI to drive the future research. We first build a novel\ngeneration model with the Fusion-in-Decoder approach to cope with multiple long\ninputs. Second, we incorporate the predicted citation intents into training for\nintent control. The experiments demonstrate that the proposed approaches\nprovide much more comprehensive features for generating citation sentences.",
    "descriptor": "",
    "authors": [
      "Jia-Yan Wu",
      "Alexander Te-Wei Shieh",
      "Shih-Ju Hsu",
      "Yun-Nung Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01332"
  },
  {
    "id": "arXiv:2112.01334",
    "title": "Stationary Diffusion State Neural Estimation for Multiview Clustering",
    "abstract": "Although many graph-based clustering methods attempt to model the stationary\ndiffusion state in their objectives, their performance limits to using a\npredefined graph. We argue that the estimation of the stationary diffusion\nstate can be achieved by gradient descent over neural networks. We specifically\ndesign the Stationary Diffusion State Neural Estimation (SDSNE) to exploit\nmultiview structural graph information for co-supervised learning. We explore\nhow to design a graph neural network specially for unsupervised multiview\nlearning and integrate multiple graphs into a unified consensus graph by a\nshared self-attentional module. The view-shared self-attentional module\nutilizes the graph structure to learn a view-consistent global graph.\nMeanwhile, instead of using auto-encoder in most unsupervised learning graph\nneural networks, SDSNE uses a co-supervised strategy with structure information\nto supervise the model learning. The co-supervised strategy as the loss\nfunction guides SDSNE in achieving the stationary state. With the help of the\nloss and the self-attentional module, we learn to obtain a graph in which nodes\nin each connected component fully connect by the same weight. Experiments on\nseveral multiview datasets demonstrate effectiveness of SDSNE in terms of six\nclustering evaluation metrics.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Chenghua Liu",
      "Zhuolin Liao",
      "Yixuan Ma",
      "Kun Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01334"
  },
  {
    "id": "arXiv:2112.01335",
    "title": "Semantic-Sparse Colorization Network for Deep Exemplar-based  Colorization",
    "abstract": "Exemplar-based colorization approaches rely on reference image to provide\nplausible colors for target gray-scale image. The key and difficulty of\nexemplar-based colorization is to establish an accurate correspondence between\nthese two images. Previous approaches have attempted to construct such a\ncorrespondence but are faced with two obstacles. First, using luminance\nchannels for the calculation of correspondence is inaccurate. Second, the dense\ncorrespondence they built introduces wrong matching results and increases the\ncomputation burden. To address these two problems, we propose Semantic-Sparse\nColorization Network (SSCN) to transfer both the global image style and\ndetailed semantic-related colors to the gray-scale image in a coarse-to-fine\nmanner. Our network can perfectly balance the global and local colors while\nalleviating the ambiguous matching problem. Experiments show that our method\noutperforms existing methods in both quantitative and qualitative evaluation\nand achieves state-of-the-art performance.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Yunpeng Bai",
      "Chao Dong",
      "Zenghao Chai",
      "Andong Wang",
      "Zhengzhuo Xu",
      "Chun Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01335"
  },
  {
    "id": "arXiv:2112.01336",
    "title": "Simultaneously Transmitting and Reflecting Reconfigurable Intelligent  Surface Assisted NOMA Networks",
    "abstract": "Simultaneously transmitting/refracting and reflecting reconfigurable\nintelligent surface (STAR-RIS) has been introduced to achieve full coverage\narea. This paper investigate the performance of STAR-RIS assisted\nnon-orthogonal multiple access (NOMA) networks over Rician fading channels,\nwhere the incidence signals sent by base station are reflected and transmitted\nto the nearby user and distant user, respectively. To evaluate the performance\nof STAR-RIS-NOMA networks, we derive new exact and asymptotic expressions of\noutage probability and ergodic rate for a pair of users, in which the imperfect\nsuccessive interference cancellation (ipSIC) and perfect SIC (pSIC) schemes are\ntaken into consideration. Based on the approximated results, the diversity\norders of $zero$ and $ {\\frac{{\\mu _n^2K}}{{2{\\Omega _n}}} + 1} $ are achieved\nfor the nearby user with ipSIC/pSIC, while the diversity order of distant user\nis equal to ${\\frac{{\\mu _m^2 K}}{{2{\\Omega _m}}}}$. The high signal-to-noise\nradio (SNR) slopes of ergodic rates for nearby user with pSIC and distant user\nare equal to $one$ and $zero$, respectively. In addition, the system throughput\nof STAR-RIS-NOMA is discussed in delay-limited and delay-tolerant modes.\nSimulation results are provided to verify the accuracy of the theoretical\nanalyses and demonstrate that: 1) The outage probability of STAR-RIS-NOMA\noutperforms that of STAR-RIS assisted orthogonal multiple access (OMA) and\nconventional cooperative communication systems; 2) With the increasing of\nconfigurable elements $K$ and Rician factor $\\kappa $, the STAR-RIS-NOMA\nnetworks are capable of attaining the enhanced performance; and 3) The ergodic\nrates of STAR-RIS-NOMA are superior to that of STAR-RIS-OMA.",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Xinwei Yue",
      "Jin Xie",
      "Yuanwei Liu",
      "Zhihao Han",
      "Rongke Liu",
      "Zhiguo Ding"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.01336"
  },
  {
    "id": "arXiv:2112.01340",
    "title": "Generalized Framework for Group Testing: Queries, Feedbacks and  Adversaries",
    "abstract": "In the Group Testing problem, the objective is to learn a subset K of some\nmuch larger domain N, using the shortest-possible sequence of queries Q. A\nfeedback to a query provides some information about the intersection between\nthe query and subset K. Several specific feedbacks have been studied in the\nliterature, often proving different formulas for the estimate of the query\ncomplexity of the problem, defined as the shortest length of queries' sequence\nsolving Group Testing problem with specific feedback. In this paper we study\nwhat are the properties of the feedback that influence the query complexity of\nGroup Testing and what is their measurable impact. We propose a generic\nframework that covers a vast majority of relevant settings considered in the\nliterature, which depends on two fundamental parameters of the feedback: input\ncapacity $\\alpha$ and output expressiveness $\\beta$. They upper bound the\nlogarithm of the size of the feedback function domain and image, respectively.\nTo justify the value of the framework, we prove upper bounds on query\ncomplexity of non adaptive, deterministic Group Testing under some \"efficient\"\nfeedbacks, for minimum, maximum and general expressiveness, and complement them\nwith a lower bound on all feedbacks with given parameters $\\alpha,\\beta$. Our\nupper bounds also hold if the feedback function could get an input twisted by a\nmalicious adversary, in case the intersection of a query and the hidden set is\nbigger than the feedback capacity $\\alpha$. We also show that slight change in\nthe feedback function may result in substantial worsening of the query\ncomplexity. Additionally, we analyze explicitly constructed randomized\ncounterparts of the deterministic results. Our results provide some insights to\nwhat are the most useful bits of information an output-restricted feedback\ncould provide, and open a number of challenging research directions.",
    "descriptor": "",
    "authors": [
      "Marek Klonowski",
      "Dariusz R. Kowalski",
      "Dominik Pajak"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.01340"
  },
  {
    "id": "arXiv:2112.01342",
    "title": "How not to Lie with a Benchmark: Rearranging NLP Leaderboards",
    "abstract": "Comparison with a human is an essential requirement for a benchmark for it to\nbe a reliable measurement of model capabilities. Nevertheless, the methods for\nmodel comparison could have a fundamental flaw - the arithmetic mean of\nseparate metrics is used for all tasks of different complexity, different size\nof test and training sets.\nIn this paper, we examine popular NLP benchmarks' overall scoring methods and\nrearrange the models by geometric and harmonic mean (appropriate for averaging\nrates) according to their reported results. We analyze several popular\nbenchmarks including GLUE, SuperGLUE, XGLUE, and XTREME. The analysis shows\nthat e.g. human level on SuperGLUE is still not reached, and there is still\nroom for improvement for the current models.",
    "descriptor": "\nComments: Accepted to ICBINB Workshop, NeurIPS 2021\n",
    "authors": [
      "Shavrina Tatiana",
      "Malykh Valentin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01342"
  },
  {
    "id": "arXiv:2112.01346",
    "title": "A Priori Error Bounds for Parabolic Interface Problems with Measure Data",
    "abstract": "This article studies a priori error analysis for linear parabolic interface\nproblems with measure data in time in a bounded convex polygonal domain in\n$\\mathbb{R}^2$. We have used the standard continuous fitted finite element\ndiscretization for the space. Due to the low regularity of the data of the\nproblem, the solution possesses very low regularity in the entire domain. A\npriori error bound in the $L^2(L^2(\\Omega))$-norm for the spatially discrete\nfinite element approximations are derived under minimal regularity with the\nhelp of the $L^2$ projection operators and the duality argument. The interfaces\nare assumed to be smooth for our purpose.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Jhuma Sen Gupta"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.01346"
  },
  {
    "id": "arXiv:2112.01348",
    "title": "3rd Place Solution for NeurIPS 2021 Shifts Challenge: Vehicle Motion  Prediction",
    "abstract": "Shifts Challenge: Robustness and Uncertainty under Real-World Distributional\nShift is a competition held by NeurIPS 2021. The objective of this competition\nis to search for methods to solve the motion prediction problem in\ncross-domain. In the real world dataset, It exists variance between input data\ndistribution and ground-true data distribution, which is called the domain\nshift problem. In this report, we propose a new architecture inspired by state\nof the art papers. The main contribution is the backbone architecture with\nself-attention mechanism and predominant loss function. Subsequently, we won\n3rd place as shown on the leaderboard.",
    "descriptor": "",
    "authors": [
      "Ching-Yu Tseng",
      "Po-Shao Lin",
      "Yu-Jia Liou",
      "Kuan-Chih Huang",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01348"
  },
  {
    "id": "arXiv:2112.01349",
    "title": "MegBA: A High-Performance and Distributed Library for Large-Scale Bundle  Adjustment",
    "abstract": "Large-scale Bundle Adjustment (BA) is the key for many 3D vision applications\n(e.g., Structure-from-Motion and SLAM). Though important, large-scale BA is\nstill poorly supported by existing BA libraries (e.g., Ceres and g2o). These\nlibraries under-utilise accelerators (i.e., GPUs), and they lack algorithms to\ndistribute BA computation constrained by the memory on a single device.\nIn this paper, we propose MegBA, a high-performance and distributed library\nfor large-scale BA. MegBA has a novel end-to-end vectorised BA algorithm that\ncan fully exploit the massive parallel cores on GPUs, thus speeding up the\nentire BA computation. It also has a novel distributed BA algorithm that can\nautomatically partition BA problems, and solve BA sub-problems using\ndistributed GPUs. The GPUs synchronise intermediate solving state using\nnetwork-efficient collective communication, and the synchronisation is designed\nto minimise communication cost. MegBA has a memory-efficient GPU runtime and\nexposes g2o-compatible APIs. Experiments show that MegBA can out-perform\nstate-of-the-art BA libraries (i.e., Ceres and DeepLM) by up to 33x and 3.3x\nrespectively, in public large-scale BA benchmarks. The code of MegBA is\navailable at: \\url{https://github.com/MegviiRobot/MegBA}.",
    "descriptor": "\nComments: 15 pages, code: this https URL\n",
    "authors": [
      "Jie Ren",
      "Wenteng Liang",
      "Ran Yan",
      "Luo Mai",
      "Shiwen Liu",
      "Xiao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01349"
  },
  {
    "id": "arXiv:2112.01351",
    "title": "Equivalent Circuit Programming for Power Flow Analysis and Optimization",
    "abstract": "The utility of domain-specific knowledge for modeling, simulation, and\noptimization has been demonstrated for various research problem domains,\nincluding power systems. The concept of Equivalent Circuit Programming was\npreviously developed and facilitated for robust, efficient, and scalable\nsolution of network simulation and optimization problems. This paper extends\nthe theoretical foundation of Equivalent Circuit Programming to enable the\nfusion of optimization theory and algorithms with the numerical methods that\nutilize the domain-specific knowledge of power flow models. The generality,\nscalability, and numerical robustness of the resulting framework are\ndemonstrated on realistic AC power flow (ACPF) models of up to 70k buses with\nproper enforcement of industry-required operational and security constraints.",
    "descriptor": "\nComments: Under review: submitted for consideration for IEEE Transactions on Power Systems\n",
    "authors": [
      "Marko Jereminov",
      "Larry Pileggi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.01351"
  },
  {
    "id": "arXiv:2112.01358",
    "title": "Mixing Deep Learning and Multiple Criteria Optimization: An Application  to Distributed Learning with Multiple Datasets",
    "abstract": "The training phase is the most important stage during the machine learning\nprocess. In the case of labeled data and supervised learning, machine training\nconsists in minimizing the loss function subject to different constraints. In\nan abstract setting, it can be formulated as a multiple criteria optimization\nmodel in which each criterion measures the distance between the output\nassociated with a specific input and its label. Therefore, the fitting term is\na vector function and its minimization is intended in the Pareto sense. We\nprovide stability results of the efficient solutions with respect to\nperturbations of input and output data. We then extend the same approach to the\ncase of learning with multiple datasets. The multiple dataset environment is\nrelevant when reducing the bias due to the choice of a specific training set.\nWe propose a scalarization approach to implement this model and numerical\nexperiments in digit classification using MNIST data.",
    "descriptor": "",
    "authors": [
      "Davide La Torre",
      "Danilo Liuzzi",
      "Marco Repetto",
      "Matteo Rocca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01358"
  },
  {
    "id": "arXiv:2112.01360",
    "title": "Probabilistic Approach for Road-Users Detection",
    "abstract": "Object detection in autonomous driving applications implies that the\ndetection and tracking of semantic objects are commonly native to urban driving\nenvironments, as pedestrians and vehicles. One of the major challenges in\nstate-of-the-art deep-learning based object detection is false positive which\noccurrences with overconfident scores. This is highly undesirable in autonomous\ndriving and other critical robotic-perception domains because of safety\nconcerns. This paper proposes an approach to alleviate the problem of\noverconfident predictions by introducing a novel probabilistic layer to deep\nobject detection networks in testing. The suggested approach avoids the\ntraditional Sigmoid or Softmax prediction layer which often produces\noverconfident predictions. It is demonstrated that the proposed technique\nreduces overconfidence in the false positives without degrading the performance\non the true positives. The approach is validated on the 2D-KITTI objection\ndetection through the YOLOV4 and SECOND (Lidar-based detector). The proposed\napproach enables enabling interpretable probabilistic predictions without the\nrequirement of re-training the network and therefore is very practical.",
    "descriptor": "\nComments: This work has been submitted to IEEE T-ITS for review and possible publication\n",
    "authors": [
      "G. Melotti",
      "W. Lu",
      "D. Zhao",
      "A. Asvadi",
      "N. Gon\u00e7alves",
      "C. Premebida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01360"
  },
  {
    "id": "arXiv:2112.01361",
    "title": "Phasic Policy Gradient Based Resource Allocation for Industrial Internet  of Things",
    "abstract": "Time Slotted Channel Hopping (TSCH) behavioural mode has been introduced in\nIEEE 802.15.4e standard to address the ultra-high reliability and ultra-low\npower communication requirements of Industrial Internet of Things (IIoT)\nnetworks. Scheduling the packet transmissions in IIoT networks is a difficult\ntask owing to the limited resources and dynamic topology. In this paper, we\npropose a phasic policy gradient (PPG) based TSCH schedule learning algorithm.\nThe proposed PPG based scheduling algorithm overcomes the drawbacks of totally\ndistributed and totally centralized deep reinforcement learning-based\nscheduling algorithms by employing the actor-critic policy gradient method that\nlearns the scheduling algorithm in two phases, namely policy phase and\nauxiliary phase.",
    "descriptor": "",
    "authors": [
      "Lokesh Bommisetty",
      "TG Venkatesh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.01361"
  },
  {
    "id": "arXiv:2112.01365",
    "title": "Tesselating a Pascal-like tetrahedron for the subdivision of high order  tetrahedral finite elements",
    "abstract": "Three-dimensional $N^{th}$ order nodal Lagrangian tetrahedral finite elements\n($P_N$ elements) can be generated using Pascal's tetrahedron $\\mathcal{H}$\nwhere each node in 3D element space corresponds to an entry in $\\mathcal{H}$.\nFor the purposes of visualization and post-processing, it is desirable to\n\"subdivide\" these high-order tetrahedral elements into sub-tetrahedra which\ncover the whole space without intersections and without introducing new\nexterior edges or vertices. That is, the exterior triangulation of the element\nshould be congruent with the \"natural\" triangulation of the $2D$ Pascal's\ntriangle. This work attempts to describe that process of subdivision for\narbitrary $N$.",
    "descriptor": "",
    "authors": [
      "Mark W. Lohry"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.01365"
  },
  {
    "id": "arXiv:2112.01366",
    "title": "MuA-Ori: Multimodal Actuated Origami",
    "abstract": "Recently, inflatable elements integrated in robotics systems have enabled\ncomplex motions as a result of simple inputs. However, these fluidic actuators\ntypically exhibit unimodal deformation upon inflation. Here, we present a new\ndesign concept for modular, fluidic actuators that can switch between\ndeformation modes as a response to an input threshold. Our system comprises\nbistable origami modules in which snapping breaks rotational symmetry, giving\naccess to a bending deformation. By tuning geometry, the modules can be\ndesigned to snap at different pressure thresholds, rotate clockwise or\ncounterclockwise when actuated, and bend in different planes. Due to their\nability to assume multiple deformation modes as response to a single pressure\ninput we call our system MuA-Ori, or Multimodal Actuated Origami. MuA-Ori\nprovides an ideal platform to design actuators that can switch between\ndifferent configurations, reach multiple, pre-defined targets in space, and\nmove along complex trajectories.",
    "descriptor": "",
    "authors": [
      "Antonio Elia Forte",
      "David Melancon",
      "Leon M. Kamp",
      "Benjamin Gorissen",
      "Katia Bertoldi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.01366"
  },
  {
    "id": "arXiv:2112.01367",
    "title": "Digital Twin-Assisted Controlling of AGVs in Flexible Manufacturing  Environments",
    "abstract": "Digital Twins are increasingly being introduced for smart manufacturing\nsystems to improve the efficiency of the main disciplines of such systems.\nFormal techniques, such as graphs, are a common way of describing Digital Twin\nmodels, allowing broad types of tools to provide Digital Twin based services\nsuch as fault detection in production lines. Obtaining correct and complete\nformal Digital Twins of physical systems can be a complicated and time\nconsuming process, particularly for manufacturing systems with plenty of\nphysical objects and the associated manufacturing processes. Automatic\ngeneration of Digital Twins is an emerging research field and can reduce time\nand costs. In this paper, we focus on the generation of Digital Twins for\nflexible manufacturing systems with Automated Guided Vehicles (AGVs) on the\nfactory floor. In particular, we propose an architectural framework and the\nassociated design choices and software development tools that facilitate\nautomatic generation of Digital Twins for AGVs. Specifically, the scope of the\ngenerated digital twins is controlling AGVs in the factory floor. To this end,\nwe focus on different control levels of AGVs and utilize graph theory to\ngenerate the graph-based Digital Twin of the factory floor.",
    "descriptor": "",
    "authors": [
      "Mohammad Azangoo",
      "Amir Taherkordi",
      "Jan Olaf Blech",
      "Valeriy Vyatkin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.01367"
  },
  {
    "id": "arXiv:2112.01368",
    "title": "ScaleVLAD: Improving Multimodal Sentiment Analysis via Multi-Scale  Fusion of Locally Descriptors",
    "abstract": "Fusion technique is a key research topic in multimodal sentiment analysis.\nThe recent attention-based fusion demonstrates advances over simple\noperation-based fusion. However, these fusion works adopt single-scale, i.e.,\ntoken-level or utterance-level, unimodal representation. Such single-scale\nfusion is suboptimal because that different modality should be aligned with\ndifferent granularities. This paper proposes a fusion model named ScaleVLAD to\ngather multi-Scale representation from text, video, and audio with shared\nVectors of Locally Aggregated Descriptors to improve unaligned multimodal\nsentiment analysis. These shared vectors can be regarded as shared topics to\nalign different modalities. In addition, we propose a self-supervised shifted\nclustering loss to keep the fused feature differentiation among samples. The\nbackbones are three Transformer encoders corresponding to three modalities, and\nthe aggregated features generated from the fusion module are feed to a\nTransformer plus a full connection to finish task predictions. Experiments on\nthree popular sentiment analysis benchmarks, IEMOCAP, MOSI, and MOSEI,\ndemonstrate significant gains over baselines.",
    "descriptor": "",
    "authors": [
      "Huaishao Luo",
      "Lei Ji",
      "Yanyong Huang",
      "Bin Wang",
      "Shenggong Ji",
      "Tianrui Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01368"
  },
  {
    "id": "arXiv:2112.01375",
    "title": "Flood Analytics Information System (FAIS) Version 4.00 Manual",
    "abstract": "This project was the first attempt to use big data analytics approaches and\nmachine learning along with Natural Language Processing (NLP) of tweets for\nflood risk assessment and decision making. Multiple Python packages were\ndeveloped and integrated within the Flood Analytics Information System (FAIS).\nFAIS workflow includes the use of IoTs-APIs and various machine learning\napproaches for transmitting, processing, and loading big data through which the\napplication gathers information from various data servers and replicates it to\na data warehouse (IBM database service). Users are allowed to directly stream\nand download flood related images/videos from the US Geological Survey (USGS)\nand Department of Transportation (DOT) and save the data on a local storage.\nThe outcome of the river measurement, imagery, and tabular data is displayed on\na web based remote dashboard and the information can be plotted in real-time.\nFAIS proved to be a robust and user-friendly tool for flood data analysis at\nregional scale that could help stakeholders for rapid assessment of flood\nsituation and damages. FAIS also provides flood frequency analysis (FFA) to\nestimate flood quantiles including the associated uncertainties that combine\nthe elements of observational analysis, stochastic probability distribution and\ndesign return periods. FAIS is publicly available and deployed on the\nClemson-IBM cloud service.",
    "descriptor": "",
    "authors": [
      "Vidya Samadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.01375"
  },
  {
    "id": "arXiv:2112.01379",
    "title": "Sentinel node approach to monitoring online COVID-19 misinformation",
    "abstract": "Understanding how different online communities engage with COVID-19\nmisinformation is critical for public health response, as misinformation\nconfined to a small, isolated community of users poses a different public\nhealth risk than misinformation being consumed by a large population spanning\nmany diverse communities. Here we take a longitudinal approach that leverages\ntools from network science to study COVID-19 misinformation on Twitter. Our\napproach provides a means to examine the breadth of misinformation engagement\nusing modest data needs and computational resources. We identify influential\naccounts from different Twitter communities discussing COVID-19, and follow\nthese `sentinel nodes' longitudinally from July 2020 to January 2021. We\ncharacterize sentinel nodes in terms of a linked-media preference score, and\nuse a standardized similarity score to examine alignment of tweets within and\nbetween communities. We find that media preference is strongly correlated with\nthe amount of misinformation propagated by sentinel nodes. Engagement with\nsensationalist misinformation topics is largely confined to a cluster of\nsentinel nodes that includes influential conspiracy theorist accounts, while\nmisinformation relating to COVID-19 severity generated widespread engagement\nacross multiple communities. Our findings indicate that misinformation\ndownplaying COVID-19 severity is of particular concern for public health\nresponse.",
    "descriptor": "",
    "authors": [
      "Matthew T. Osborne",
      "Samuel S. Malloy",
      "Erik C. Nisbet",
      "Robert M. Bond",
      "Joseph H. Tien"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.01379"
  },
  {
    "id": "arXiv:2112.01383",
    "title": "A New Approach to Detect Important Members that Create the Communities  in Bipartite Networks",
    "abstract": "The world around us consists of objects that have different relationships\nwith each other. The result of these communications is various networks, part\nof which are bipartite networks. While many studies have investigated essential\nnetwork members, less attention has been paid to the bipartite graphs. On the\nother hand, one of the most critical aspects of network analysis is the\ndetection and extraction of communities that arise in the structure of\nnetworks. For these reasons, we have introduced a measure called H.H to\nidentify influential nodes in community formation in the one-mode projection of\na bipartite graph. The three main parameters that influence this measure are\nthe size of the formed community, the effect of each node in the formation of\nthat community, and the number of communities in which the node had an impact.\nThe results of this paper show the differences of this measure with other\ncentralities (eigenvector centrality, closeness centrality, betweenness\ncentrality, and degree centrality) and how this measure takes into account\naspects that other centralities do not. Through H.H score, we can find\nessential nodes that have been effective in forming a community, and by\nremoving these nodes, communities can be eliminated. Any of the existing\ncentralities has not addressed this issue, and this measure has sufficient\nindependence to represent the important nodes in the formation of the\ncommunities. Experimental validation of the proposed measure is carried out on\ntwo real-world datasets: Southern Women Network and Person-Crime Network. The\nresults of the implementation of the H.H score on the Person-Crime dataset show\nthat by eliminating the nodes with the highest H.H score (top-10%), 29% of the\ncommunities have changed; this is while the centralities change the average of\n18% of the communities and this shows the importance of the H.H score.",
    "descriptor": "",
    "authors": [
      "Ali Hojjat",
      "Ghazaleh Haddad"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.01383"
  },
  {
    "id": "arXiv:2112.01388",
    "title": "Residual Pathway Priors for Soft Equivariance Constraints",
    "abstract": "There is often a trade-off between building deep learning systems that are\nexpressive enough to capture the nuances of the reality, and having the right\ninductive biases for efficient learning. We introduce Residual Pathway Priors\n(RPPs) as a method for converting hard architectural constraints into soft\npriors, guiding models towards structured solutions, while retaining the\nability to capture additional complexity. Using RPPs, we construct neural\nnetwork priors with inductive biases for equivariances, but without limiting\nflexibility. We show that RPPs are resilient to approximate or misspecified\nsymmetries, and are as effective as fully constrained models even when\nsymmetries are exact. We showcase the broad applicability of RPPs with\ndynamical systems, tabular data, and reinforcement learning. In Mujoco\nlocomotion tasks, where contact forces and directional rewards violate strict\nequivariance assumptions, the RPP outperforms baseline model-free RL agents,\nand also improves the learned transition models for model-based RL.",
    "descriptor": "\nComments: NeurIPS 2021. Code available at this https URL\n",
    "authors": [
      "Marc Finzi",
      "Gregory Benton",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.01388"
  },
  {
    "id": "arXiv:2112.01390",
    "title": "InsCLR: Improving Instance Retrieval with Self-Supervision",
    "abstract": "This work aims at improving instance retrieval with self-supervision. We find\nthat fine-tuning using the recently developed self-supervised (SSL) learning\nmethods, such as SimCLR and MoCo, fails to improve the performance of instance\nretrieval. In this work, we identify that the learnt representations for\ninstance retrieval should be invariant to large variations in viewpoint and\nbackground etc., whereas self-augmented positives applied by the current SSL\nmethods can not provide strong enough signals for learning robust\ninstance-level representations. To overcome this problem, we propose InsCLR, a\nnew SSL method that builds on the \\textit{instance-level} contrast, to learn\nthe intra-class invariance by dynamically mining meaningful pseudo positive\nsamples from both mini-batches and a memory bank during training. Extensive\nexperiments demonstrate that InsCLR achieves similar or even better performance\nthan the state-of-the-art SSL methods on instance retrieval. Code is available\nat https://github.com/zeludeng/insclr.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Zelu Deng",
      "Yujie Zhong",
      "Sheng Guo",
      "Weilin Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01390"
  },
  {
    "id": "arXiv:2112.01394",
    "title": "Dynamic Sparse Tensor Algebra Compilation",
    "abstract": "This paper shows how to generate efficient tensor algebra code that compute\non dynamic sparse tensors, which have sparsity structures that evolve over\ntime. We propose a language for precisely specifying recursive, pointer-based\ndata structures, and we show how this language can express a wide range of\ndynamic data structures that support efficient modification, such as linked\nlists, binary search trees, and B-trees. We then describe how, given high-level\nspecifications of such data structures, a compiler can generate code to\nefficiently iterate over and compute with dynamic sparse tensors that are\nstored in the aforementioned data structures. Furthermore, we define an\nabstract interface that captures how nonzeros can be inserted into dynamic data\nstructures, and we show how this abstraction guides a compiler to emit\nefficient code that store the results of sparse tensor algebra computations in\ndynamic data structures.\nWe evaluate our technique and find that it generates efficient dynamic sparse\ntensor algebra kernels. Code that our technique emits to compute the main\nkernel of the PageRank algorithm is 1.05$\\times$ as fast as Aspen, a\nstate-of-the-art dynamic graph processing framework. Furthermore, our technique\noutperforms PAM, a parallel ordered (key-value) maps library, by 7.40$\\times$\nwhen used to implement element-wise addition of a dynamic sparse matrix to a\nstatic sparse matrix.",
    "descriptor": "\nComments: 15 pages, 16 figures\n",
    "authors": [
      "Stephen Chou",
      "Saman Amarasinghe"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.01394"
  },
  {
    "id": "arXiv:2112.01397",
    "title": "Efficient Calling Conventions for Irregular Architectures",
    "abstract": "We empirically evaluated thousands of different C calling conventions for\nirregular microcontroller architectures, and found potential for improvement\nover the calling conventions previously used in the Small Device C Compiler\n(SDCC). The improvements in code size and speed are substantial enough that\nSDCC made changes to its default calling convention, breaking ABI\ncompatibility.",
    "descriptor": "",
    "authors": [
      "Philipp K. Krause"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.01397"
  },
  {
    "id": "arXiv:2112.01398",
    "title": "TISE: A Toolbox for Text-to-Image Synthesis Evaluation",
    "abstract": "In this paper, we conduct a study on state-of-the-art methods for single- and\nmulti-object text-to-image synthesis and propose a common framework for\nevaluating these methods. We first identify several common issues in the\ncurrent evaluation of text-to-image models, which are: (i) a commonly used\nmetric for image quality assessment, e.g., Inception Score (IS), is often\neither miscalibrated for the single-object case or misused for the multi-object\ncase; (ii) the overfitting phenomenon appears in the existing R-precision (RP)\nand SOA metrics, which are used to assess text relevance and object accuracy\naspects, respectively; (iii) many vital factors in the evaluation of the\nmulti-object case are primarily dismissed, e.g., object fidelity, positional\nalignment, counting alignment; (iv) the ranking of the methods based on current\nmetrics is highly inconsistent with real images. Then, to overcome these\nlimitations, we propose a combined set of existing and new metrics to\nsystematically evaluate the methods. For existing metrics, we develop an\nimproved version of IS named IS* by using temperature scaling to calibrate the\nconfidence of the classifier used by IS; we also propose a solution to mitigate\nthe overfitting issues of RP and SOA. Regarding a set of new metrics\ncompensating for the lacking of vital evaluating factors in the multi-object\ncase, we develop CA for counting alignment, PA for positional alignment,\nobject-centric IS (O-IS), object-centric FID (O-FID) for object fidelity. Our\nbenchmark, therefore, results in a highly consistent ranking among existing\nmethods, being well-aligned to human evaluation. We also create a strong\nbaseline model (AttnGAN++) for the benchmark by a simple modification from the\nwell-known AttnGAN. We will release this toolbox for unified evaluation,\nso-called TISE, to standardize the evaluation of the text-to-image synthesis\nmodels.",
    "descriptor": "\nComments: 21 pages, 13 figures, project page is located at this https URL\n",
    "authors": [
      "Tan M. Dinh",
      "Rang Nguyen",
      "Binh-Son Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01398"
  },
  {
    "id": "arXiv:2112.01401",
    "title": "Newton methods based convolution neural networks using parallel  processing",
    "abstract": "Training of convolutional neural networks is a high dimensional and a\nnon-convex optimization problem. At present, it is inefficient in situations\nwhere parametric learning rates can not be confidently set. Some past works\nhave introduced Newton methods for training deep neural networks. Newton\nmethods for convolutional neural networks involve complicated operations.\nFinding the Hessian matrix in second-order methods becomes very complex as we\nmainly use the finite differences method with the image data. Newton methods\nfor convolutional neural networks deals with this by using the sub-sampled\nHessian Newton methods. In this paper, we have used the complete data instead\nof the sub-sampled methods that only handle partial data at a time. Further, we\nhave used parallel processing instead of serial processing in mini-batch\ncomputations. The results obtained using parallel processing in this study,\noutperform the time taken by the previous approach.",
    "descriptor": "",
    "authors": [
      "Ujjwal Thakur",
      "Anuj Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01401"
  },
  {
    "id": "arXiv:2112.01402",
    "title": "Iterative Frame-Level Representation Learning And Classification For  Semi-Supervised Temporal Action Segmentation",
    "abstract": "Temporal action segmentation classifies the action of each frame in (long)\nvideo sequences. Due to the high cost of frame-wise labeling, we propose the\nfirst semi-supervised method for temporal action segmentation. Our method\nhinges on unsupervised representation learning, which, for temporal action\nsegmentation, poses unique challenges. Actions in untrimmed videos vary in\nlength and have unknown labels and start/end times. Ordering of actions across\nvideos may also vary. We propose a novel way to learn frame-wise\nrepresentations from temporal convolutional networks (TCNs) by clustering input\nfeatures with added time-proximity condition and multi-resolution similarity.\nBy merging representation learning with conventional supervised learning, we\ndevelop an \"Iterative-Contrast-Classify (ICC)\" semi-supervised learning scheme.\nWith more labelled data, ICC progressively improves in performance; ICC\nsemi-supervised learning, with 40% labelled videos, performs similar to\nfully-supervised counterparts. Our ICC improves MoF by {+1.8, +5.6, +2.5}% on\nBreakfast, 50Salads and GTEA respectively for 100% labelled videos.",
    "descriptor": "\nComments: AAAI-2022\n",
    "authors": [
      "Dipika Singhania",
      "Rahul Rahaman",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01402"
  },
  {
    "id": "arXiv:2112.01404",
    "title": "LOGEN: Few-shot Logical Knowledge-Conditioned Text Generation with  Self-training",
    "abstract": "Natural language generation from structured data mainly focuses on\nsurface-level descriptions, suffering from uncontrollable content selection and\nlow fidelity. Previous works leverage logical forms to facilitate logical\nknowledge-conditioned text generation. Though achieving remarkable progress,\nthey are data-hungry, which makes the adoption for real-world applications\nchallenging with limited data. To this end, this paper proposes a unified\nframework for logical knowledge-conditioned text generation in the few-shot\nsetting. With only a few seeds logical forms (e.g., 20/100 shot), our approach\nleverages self-training and samples pseudo logical forms based on content and\nstructure consistency. Experimental results demonstrate that our approach can\nobtain better few-shot performance than baselines.",
    "descriptor": "",
    "authors": [
      "Ningyu Zhang",
      "Hongbin Ye",
      "Jiacheng Yang",
      "Shumin Deng",
      "Chuanqi Tan",
      "Mosha Chen",
      "Songfang Huang",
      "Fei Huang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01404"
  },
  {
    "id": "arXiv:2112.01405",
    "title": "FedRAD: Federated Robust Adaptive Distillation",
    "abstract": "The robustness of federated learning (FL) is vital for the distributed\ntraining of an accurate global model that is shared among large number of\nclients. The collaborative learning framework by typically aggregating model\nupdates is vulnerable to model poisoning attacks from adversarial clients.\nSince the shared information between the global server and participants are\nonly limited to model parameters, it is challenging to detect bad model\nupdates. Moreover, real-world datasets are usually heterogeneous and not\nindependent and identically distributed (Non-IID) among participants, which\nmakes the design of such robust FL pipeline more difficult. In this work, we\npropose a novel robust aggregation method, Federated Robust Adaptive\nDistillation (FedRAD), to detect adversaries and robustly aggregate local\nmodels based on properties of the median statistic, and then performing an\nadapted version of ensemble Knowledge Distillation. We run extensive\nexperiments to evaluate the proposed method against recently published works.\nThe results show that FedRAD outperforms all other aggregators in the presence\nof adversaries, as well as in heterogeneous data distributions.",
    "descriptor": "\nComments: Accepted for 1st NeurIPS Workshop on New Frontiers in Federated Learning (NFFL 2021), Virtual Meeting\n",
    "authors": [
      "Stef\u00e1n P\u00e1ll Sturluson",
      "Samuel Trew",
      "Luis Mu\u00f1oz-Gonz\u00e1lez",
      "Matei Grama",
      "Jonathan Passerat-Palmbach",
      "Daniel Rueckert",
      "Amir Alansary"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.01405"
  },
  {
    "id": "arXiv:2112.01406",
    "title": "Active Learning for Domain Adaptation: An Energy-based Approach",
    "abstract": "Unsupervised domain adaptation has recently emerged as an effective paradigm\nfor generalizing deep neural networks to new target domains. However, there is\nstill enormous potential to be tapped to reach the fully supervised\nperformance. In this paper, we present a novel active learning strategy to\nassist knowledge transfer in the target domain, dubbed active domain\nadaptation. We start from an observation that energy-based models exhibit free\nenergy biases when training (source) and test (target) data come from different\ndistributions. Inspired by this inherent mechanism, we empirically reveal that\na simple yet efficient energy-based sampling strategy sheds light on selecting\nthe most valuable target samples than existing approaches requiring particular\narchitectures or computation of the distances. Our algorithm, Energy-based\nActive Domain Adaptation (EADA), queries groups of targe data that incorporate\nboth domain characteristic and instance uncertainty into every selection round.\nMeanwhile, by aligning the free energy of target data compact around the source\ndomain via a regularization term, domain gap can be implicitly diminished.\nThrough extensive experiments, we show that EADA surpasses state-of-the-art\nmethods on well-known challenging benchmarks with substantial improvements,\nmaking it a useful option in the open world. Code is available at\nhttps://github.com/BIT-DA/EADA.",
    "descriptor": "\nComments: Accepted by AAAI 2022. Code is available at this https URL\n",
    "authors": [
      "Binhui Xie",
      "Longhui Yuan",
      "Shuang Li",
      "Chi Harold Liu",
      "Xinjing Cheng",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01406"
  },
  {
    "id": "arXiv:2112.01413",
    "title": "Channel Estimation for STAR-RIS-aided Wireless Communication",
    "abstract": "In this letter, we study efficient uplink channel estimation design for a\nsimultaneously transmitting and reflecting reconfigurable intelligent surface\n(STAR-RIS) assisted two-user communication systems. We first consider the time\nswitching (TS) protocol for STAR-RIS and propose an efficient scheme to\nseparately estimate the channels of the two users with optimized training\n(transmission/reflection) pattern. Next, we consider the energy splitting (ES)\nprotocol for STAR-RIS under the practical coupled phase-shift model and devise\na customized scheme to simultaneously estimate the channels of both users.\nAlthough the problem of minimizing the resultant channel estimation error for\nthe ES protocol is difficult to solve, we propose an efficient algorithm to\nobtain a high-quality solution by jointly designing the pilot sequences,\npower-splitting ratio, and training patterns. Numerical results show the\neffectiveness of the proposed channel estimation designs and reveal that the\nSTAR-RIS under the TS protocol achieves a smaller channel estimation error than\nthe ES case.",
    "descriptor": "",
    "authors": [
      "Chenyu Wu",
      "Changsheng You",
      "Yuanwei Liu",
      "Xuemai Gu",
      "Yunlong Cai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.01413"
  },
  {
    "id": "arXiv:2112.01421",
    "title": "Deep residential representations: Using unsupervised learning to unlock  elevation data for geo-demographic prediction",
    "abstract": "LiDAR (short for \"Light Detection And Ranging\" or \"Laser Imaging, Detection,\nAnd Ranging\") technology can be used to provide detailed three-dimensional\nelevation maps of urban and rural landscapes. To date, airborne LiDAR imaging\nhas been predominantly confined to the environmental and archaeological\ndomains. However, the geographically granular and open-source nature of this\ndata also lends itself to an array of societal, organizational and business\napplications where geo-demographic type data is utilised. Arguably, the\ncomplexity involved in processing this multi-dimensional data has thus far\nrestricted its broader adoption. In this paper, we propose a series of\nconvenient task-agnostic tile elevation embeddings to address this challenge,\nusing recent advances from unsupervised Deep Learning. We test the potential of\nour embeddings by predicting seven English indices of deprivation (2019) for\nsmall geographies in the Greater London area. These indices cover a range of\nsocio-economic outcomes and serve as a proxy for a wide variety of downstream\ntasks to which the embeddings can be applied. We consider the suitability of\nthis data not just on its own but also as an auxiliary source of data in\ncombination with demographic features, thus providing a realistic use case for\nthe embeddings. Having trialled various model/embedding configurations, we find\nthat our best performing embeddings lead to Root-Mean-Squared-Error (RMSE)\nimprovements of up to 21% over using standard demographic features alone. We\nalso demonstrate how our embedding pipeline, using Deep Learning combined with\nK-means clustering, produces coherent tile segments which allow the latent\nembedding features to be interpreted.",
    "descriptor": "\nComments: 22 pages, 9 figures. V1 - Submitted\n",
    "authors": [
      "Matthew Stevenson",
      "Christophe Mues",
      "Cristi\u00e1n Bravo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01421"
  },
  {
    "id": "arXiv:2112.01422",
    "title": "3D-Aware Semantic-Guided Generative Model for Human Synthesis",
    "abstract": "Generative Neural Radiance Field (GNeRF) models, which extract implicit 3D\nrepresentations from 2D images, have recently been shown to produce realistic\nimages representing rigid objects, such as human faces or cars. However, they\nusually struggle to generate high-quality images representing non-rigid\nobjects, such as the human body, which is of a great interest for many computer\ngraphics applications. This paper proposes a 3D-aware Semantic-Guided\nGenerative Model (3D-SGAN) for human image synthesis, which integrates a GNeRF\nand a texture generator. The former learns an implicit 3D representation of the\nhuman body and outputs a set of 2D semantic segmentation masks. The latter\ntransforms these semantic masks into a real image, adding a realistic texture\nto the human appearance. Without requiring additional 3D information, our model\ncan learn 3D human representations with a photo-realistic controllable\ngeneration. Our experiments on the DeepFashion dataset show that 3D-SGAN\nsignificantly outperforms the most recent baselines.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Jichao Zhang",
      "Enver Sangineto",
      "Hao Tang",
      "Aliaksandr Siarohin",
      "Zhun Zhong",
      "Nicu Sebe",
      "Wei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01422"
  },
  {
    "id": "arXiv:2112.01423",
    "title": "Training Efficiency and Robustness in Deep Learning",
    "abstract": "Deep Learning has revolutionized machine learning and artificial\nintelligence, achieving superhuman performance in several standard benchmarks.\nIt is well-known that deep learning models are inefficient to train; they learn\nby processing millions of training data multiple times and require powerful\ncomputational resources to process large batches of data in parallel at the\nsame time rather than sequentially. Deep learning models also have unexpected\nfailure modes; they can be fooled into misbehaviour, producing unexpectedly\nincorrect predictions.\nIn this thesis, we study approaches to improve the training efficiency and\nrobustness of deep learning models. In the context of learning visual-semantic\nembeddings, we find that prioritizing learning on more informative training\ndata increases convergence speed and improves generalization performance on\ntest data. We formalize a simple trick called hard negative mining as a\nmodification to the learning objective function with no computational overhead.\nNext, we seek improvements to optimization speed in general-purpose\noptimization methods in deep learning. We show that a redundancy-aware\nmodification to the sampling of training data improves the training speed and\ndevelops an efficient method for detecting the diversity of training signal,\nnamely, gradient clustering. Finally, we study adversarial robustness in deep\nlearning and approaches to achieve maximal adversarial robustness without\ntraining with additional data. For linear models, we prove guaranteed maximal\nrobustness achieved only by appropriate choice of the optimizer,\nregularization, or architecture.",
    "descriptor": "\nComments: A thesis submitted in conformity with the requirements for the degree of Doctor of Philosophy\n",
    "authors": [
      "Fartash Faghri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01423"
  },
  {
    "id": "arXiv:2112.01426",
    "title": "SCNet: A Generalized Attention-based Model for Crack Fault Segmentation",
    "abstract": "Anomaly detection and localization is an important vision problem, having\nmultiple applications. Effective and generic semantic segmentation of anomalous\nregions on various different surfaces, where most anomalous regions inherently\ndo not have any obvious pattern, is still under active research. Periodic\nhealth monitoring and fault (anomaly) detection in vast infrastructures, which\nis an important safety-related task, is one such application area of\nvision-based anomaly segmentation. However, the task is quite challenging due\nto large variations in surface faults, texture-less construction\nmaterial/background, lighting conditions etc. Cracks are critical and frequent\nsurface faults that manifest as extreme zigzag-shaped thin, elongated regions.\nThey are among the hardest faults to detect, even with deep learning. In this\nwork, we address an open aspect of automatic crack segmentation problem, that\nof generalizing and improving the performance of segmentation across a variety\nof scenarios, by modeling the problem differently. We carefully study and\nabstract the sub-problems involved and solve them in a broader context, making\nour solution generic. On a variety of datasets related to surveillance of\ndifferent infrastructures, under varying conditions, our model consistently\noutperforms the state-of-the-art algorithms by a significant margin, without\nany bells-and-whistles. This performance advantage easily carried over in two\ndeployments of our model, tested against industry-provided datasets. Even\nfurther, we could establish our model's performance for two manufacturing\nquality inspection scenarios as well, where the defect types are not just crack\nequivalents, but much more and different. Hence we hope that our model is\nindeed a truly generic defect segmentation model.",
    "descriptor": "\nComments: Accepted at ICVGIP 2021\n",
    "authors": [
      "Hrishikesh Sharma",
      "Prakhar Pradhan",
      "Balamuralidhar P"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01426"
  },
  {
    "id": "arXiv:2112.01433",
    "title": "Loss Landscape Dependent Self-Adjusting Learning Rates in Decentralized  Stochastic Gradient Descent",
    "abstract": "Distributed Deep Learning (DDL) is essential for large-scale Deep Learning\n(DL) training. Synchronous Stochastic Gradient Descent (SSGD) 1 is the de facto\nDDL optimization method. Using a sufficiently large batch size is critical to\nachieving DDL runtime speedup. In a large batch setting, the learning rate must\nbe increased to compensate for the reduced number of parameter updates.\nHowever, a large learning rate may harm convergence in SSGD and training could\neasily diverge. Recently, Decentralized Parallel SGD (DPSGD) has been proposed\nto improve distributed training speed. In this paper, we find that DPSGD not\nonly has a system-wise run-time benefit but also a significant convergence\nbenefit over SSGD in the large batch setting. Based on a detailed analysis of\nthe DPSGD learning dynamics, we find that DPSGD introduces additional\nlandscape-dependent noise that automatically adjusts the effective learning\nrate to improve convergence. In addition, we theoretically show that this noise\nsmoothes the loss landscape, hence allowing a larger learning rate. We conduct\nextensive studies over 18 state-of-the-art DL models/tasks and demonstrate that\nDPSGD often converges in cases where SSGD diverges for large learning rates in\nthe large batch setting. Our findings are consistent across two different\napplication domains: Computer Vision (CIFAR10 and ImageNet-1K) and Automatic\nSpeech Recognition (SWB300 and SWB2000), and two different types of neural\nnetwork models: Convolutional Neural Networks and Long Short-Term Memory\nRecurrent Neural Networks.",
    "descriptor": "",
    "authors": [
      "Wei Zhang",
      "Mingrui Liu",
      "Yu Feng",
      "Xiaodong Cui",
      "Brian Kingsbury",
      "Yuhai Tu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01433"
  },
  {
    "id": "arXiv:2112.01438",
    "title": "Level set learning with pseudo-reversible neural networks for nonlinear  dimension reduction in function approximation",
    "abstract": "Due to the curse of dimensionality and the limitation on training data,\napproximating high-dimensional functions is a very challenging task even for\npowerful deep neural networks. Inspired by the Nonlinear Level set Learning\n(NLL) method that uses the reversible residual network (RevNet), in this paper\nwe propose a new method of Dimension Reduction via Learning Level Sets (DRiLLS)\nfor function approximation. Our method contains two major components: one is\nthe pseudo-reversible neural network (PRNN) module that effectively transforms\nhigh-dimensional input variables to low-dimensional active variables, and the\nother is the synthesized regression module for approximating function values\nbased on the transformed data in the low-dimensional space. The PRNN not only\nrelaxes the invertibility constraint of the nonlinear transformation present in\nthe NLL method due to the use of RevNet, but also adaptively weights the\ninfluence of each sample and controls the sensitivity of the function to the\nlearned active variables. The synthesized regression uses Euclidean distance in\nthe input space to select neighboring samples, whose projections on the space\nof active variables are used to perform local least-squares polynomial fitting.\nThis helps to resolve numerical oscillation issues present in traditional local\nand global regressions. Extensive experimental results demonstrate that our\nDRiLLS method outperforms both the NLL and Active Subspace methods, especially\nwhen the target function possesses critical points in the interior of its input\ndomain.",
    "descriptor": "",
    "authors": [
      "Yuankai Teng",
      "Zhu Wang",
      "Lili Ju",
      "Anthony Gruber",
      "Guannan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.01438"
  },
  {
    "id": "arXiv:2112.01439",
    "title": "Game-Theoretic Model Based Resource Allocation During Floods",
    "abstract": "For multiple emergencies caused by natural disasters, it is crucial to\nallocate resources equitably to each emergency location, especially when the\navailability of resources is limited in quantity. This paper has developed a\nmulti-event crisis management system using a non-cooperative, complete\ninformation, strategic form game model. In the proposed system, each emergency\nevent is assumed to occur in different locations simultaneously. These\nlocations are represented as the players in the game, competing with the other\nplayers for an optimal allocation of scarce resources available at different\nresource stations. The players incur a non-monetary cost for obtaining resource\nunits. The objective of the proposed game is to derive optimal strategies for\nan effective and fair allocation of resources to the respective players.",
    "descriptor": "\nComments: Presented in 4th World Congress on Disaster Management, IIT Bombay, Mumbai, India, 29 Jan-01 Feb 2019 (11 pages)\n",
    "authors": [
      "Rudrashis Majumder",
      "Rakesh R Warier",
      "Debasish Ghose"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.01439"
  },
  {
    "id": "arXiv:2112.01441",
    "title": "A Review of SHACL: From Data Validation to Schema Reasoning for RDF  Graphs",
    "abstract": "We present an introduction and a review of the Shapes Constraint Language\n(SHACL), the W3C recommendation language for validating RDF data. A SHACL\ndocument describes a set of constraints on RDF nodes, and a graph is valid with\nrespect to the document if its nodes satisfy these constraints. We revisit the\nbasic concepts of the language, its constructs and components and their\ninteraction. We review the different formal frameworks used to study this\nlanguage and the different semantics proposed. We examine a number of related\nproblems, from containment and satisfiability to the interaction of SHACL with\ninference rules, and exhibit how different modellings of the language are\nuseful for different problems. We also cover practical aspects of SHACL,\ndiscussing its implementations and state of adoption, to present a holistic\nreview useful to practitioners and theoreticians alike.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2108.13063\n",
    "authors": [
      "Paolo Pareti",
      "George Konstantinidis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.01441"
  },
  {
    "id": "arXiv:2112.01442",
    "title": "Learning Large-scale Network Embedding from Representative Subgraph",
    "abstract": "We study the problem of large-scale network embedding, which aims to learn\nlow-dimensional latent representations for network mining applications. Recent\nresearch in the field of network embedding has led to significant progress such\nas DeepWalk, LINE, NetMF, NetSMF. However, the huge size of many real-world\nnetworks makes it computationally expensive to learn network embedding from the\nentire network. In this work, we present a novel network embedding method\ncalled \"NES\", which learns network embedding from a small representative\nsubgraph. NES leverages theories from graph sampling to efficiently construct\nrepresentative subgraph with smaller size which can be used to make inferences\nabout the full network, enabling significantly improved efficiency in embedding\nlearning. Then, NES computes the network embedding from this representative\nsubgraph, efficiently. Compared with well-known methods, extensive experiments\non networks of various scales and types demonstrate that NES achieves\ncomparable performance and significant efficiency superiority.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Junsheng Kong",
      "Weizhao Li",
      "Ben Liao",
      "Jiezhong Qiu",
      "Chang-Yu",
      "Hsieh",
      "Yi Cai",
      "Jinhui Zhu",
      "Shengyu Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01442"
  },
  {
    "id": "arXiv:2112.01451",
    "title": "Architecting and Visualizing Deep Reinforcement Learning Models",
    "abstract": "To meet the growing interest in Deep Reinforcement Learning (DRL), we sought\nto construct a DRL-driven Atari Pong agent and accompanying visualization tool.\nExisting approaches do not support the flexibility required to create an\ninteractive exhibit with easily-configurable physics and a human-controlled\nplayer. Therefore, we constructed a new Pong game environment, discovered and\naddressed a number of unique data deficiencies that arise when applying DRL to\na new environment, architected and tuned a policy gradient based DRL model,\ndeveloped a real-time network visualization, and combined these elements into\nan interactive display to help build intuition and awareness of the mechanics\nof DRL inference.",
    "descriptor": "\nComments: Presented at MICS 2020\n",
    "authors": [
      "Alexander Neuwirth",
      "Derek Riley"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01451"
  },
  {
    "id": "arXiv:2112.01452",
    "title": "Indexed Minimum Empirical Divergence for Unimodal Bandits",
    "abstract": "We consider a multi-armed bandit problem specified by a set of\none-dimensional family exponential distributions endowed with a unimodal\nstructure. We introduce IMED-UB, a algorithm that optimally exploits the\nunimodal-structure, by adapting to this setting the Indexed Minimum Empirical\nDivergence (IMED) algorithm introduced by Honda and Takemura [2015]. Owing to\nour proof technique, we are able to provide a concise finite-time analysis of\nIMED-UB algorithm. Numerical experiments show that IMED-UB competes with the\nstate-of-the-art algorithms.",
    "descriptor": "\nComments: NeurIPS 2021 - International Conference on Neural Information Processing Systems, Dec 2021, Virtual-only Conference, United States. arXiv admin note: substantial text overlap with arXiv:2006.16569, arXiv:2007.03224\n",
    "authors": [
      "Hassan Saber",
      "Pierre M\u00e9nard",
      "Odalric-Ambrym Maillard"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.01452"
  },
  {
    "id": "arXiv:2112.01453",
    "title": "Target Propagation via Regularized Inversion",
    "abstract": "Target Propagation (TP) algorithms compute targets instead of gradients along\nneural networks and propagate them backward in a way that is similar yet\ndifferent than gradient back-propagation (BP). The idea was first presented as\na perturbative alternative to back-propagation that may achieve greater\naccuracy in gradient evaluation when training multi-layer neural networks\n(LeCun et al., 1989). However, TP has remained more of a template algorithm\nwith many variations than a well-identified algorithm. Revisiting insights of\nLeCun et al., (1989) and more recently of Lee et al. (2015), we present a\nsimple version of target propagation based on regularized inversion of network\nlayers, easily implementable in a differentiable programming framework. We\ncompare its computational complexity to the one of BP and delineate the regimes\nin which TP can be attractive compared to BP. We show how our TP can be used to\ntrain recurrent neural networks with long sequences on various sequence\nmodeling problems. The experimental results underscore the importance of\nregularization in TP in practice.",
    "descriptor": "",
    "authors": [
      "Vincent Roulet",
      "Zaid Harchaoui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01453"
  },
  {
    "id": "arXiv:2112.01454",
    "title": "Altering Facial Expression Based on Textual Emotion",
    "abstract": "Faces and their expressions are one of the potent subjects for digital\nimages. Detecting emotions from images is an ancient task in the field of\ncomputer vision; however, performing its reverse -- synthesizing facial\nexpressions from images -- is quite new. Such operations of regenerating images\nwith different facial expressions, or altering an existing expression in an\nimage require the Generative Adversarial Network (GAN). In this paper, we aim\nto change the facial expression in an image using GAN, where the input image\nwith an initial expression (i.e., happy) is altered to a different expression\n(i.e., disgusted) for the same person. We used StarGAN techniques on a modified\nversion of the MUG dataset to accomplish this objective. Moreover, we extended\nour work further by remodeling facial expressions in an image indicated by the\nemotion from a given text. As a result, we applied a Long Short-Term Memory\n(LSTM) method to extract emotion from the text and forwarded it to our\nexpression-altering module. As a demonstration of our working pipeline, we also\ncreate an application prototype of a blog that regenerates the profile picture\nwith different expressions based on the user's textual emotion.",
    "descriptor": "\nComments: Accepted in VISAPP2022\n",
    "authors": [
      "Mohammad Imrul Jubair",
      "Md. Masud Rana",
      "Md. Amir Hamza",
      "Mohsena Ashraf",
      "Fahim Ahsan Khan",
      "Ahnaf Tahseen Prince"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.01454"
  },
  {
    "id": "arXiv:2112.01455",
    "title": "Zero-Shot Text-Guided Object Generation with Dream Fields",
    "abstract": "We combine neural rendering with multi-modal image and text representations\nto synthesize diverse 3D objects solely from natural language descriptions. Our\nmethod, Dream Fields, can generate the geometry and color of a wide range of\nobjects without 3D supervision. Due to the scarcity of diverse, captioned 3D\ndata, prior methods only generate objects from a handful of categories, such as\nShapeNet. Instead, we guide generation with image-text models pre-trained on\nlarge datasets of captioned images from the web. Our method optimizes a Neural\nRadiance Field from many camera views so that rendered images score highly with\na target caption according to a pre-trained CLIP model. To improve fidelity and\nvisual quality, we introduce simple geometric priors, including\nsparsity-inducing transmittance regularization, scene bounds, and new MLP\narchitectures. In experiments, Dream Fields produce realistic, multi-view\nconsistent object geometry and color from a variety of natural language\ncaptions.",
    "descriptor": "\nComments: 12 pages. Website: this https URL\n",
    "authors": [
      "Ajay Jain",
      "Ben Mildenhall",
      "Jonathan T. Barron",
      "Pieter Abbeel",
      "Ben Poole"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01455"
  },
  {
    "id": "arXiv:2112.01465",
    "title": "Unifying Diffusion Models on Networks and Their Influence Maximisation",
    "abstract": "Information diffusion in social networks is a central theme in computational\nsocial sciences, with important theoretical and practical implications, such as\nthe influence maximisation problem for viral marketing. Two widely adopted\ndiffusion models are the independent cascade model where nodes adopt their\nbehaviour from each neighbour independently, and the linear threshold model\nwhere collective effort from the whole neighbourhood is needed to influence a\nnode. However, both models suffer from certain drawbacks, including a binary\nstate space, where nodes are either active or not, and the absence of feedback,\nas nodes can not be influenced after having been activated. To address these\nissues, we consider a model with continuous variables that has the additional\nadvantage of unifying the two classic models, as the extended independent\ncascade model and the extended linear threshold model are recovered by setting\nappropriate parameters. For the associated influence maximisation problem, the\nobjective function is no longer submodular, a feature that most approximation\nalgorithms are based on but is arguably strict in practice. Hence, we develop a\nframework, where we formulate the influence maximisation problem as a mixed\ninteger nonlinear programming and adopt derivative-free methods. Furthermore,\nwe propose a customised direct search method specifically for the proposed\ndiffusion model, with local convergence. We also show that the problem can be\nexactly solved in the case of linear dynamics by selecting nodes according to\ntheir Katz centrality. We demonstrate the rich behaviour of the newly proposed\ndiffusion model and the close-to-optimal performance of the customised direct\nsearch numerically on both synthetic and real networks.",
    "descriptor": "\nComments: 41 pages, 25 figures\n",
    "authors": [
      "Yu Tian",
      "Renaud Lambiotte"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.01465"
  },
  {
    "id": "arXiv:2112.01472",
    "title": "Unity is Strength: A Formalization of Cross-Domain Maximal Extractable  Value",
    "abstract": "The multi-chain future is upon us. Modular architectures are coming to\nmaturity across the ecosystem to scale bandwidth and throughput of\ncryptocurrency. One example of such is the Ethereum modular architecture, with\nits beacon chain, its execution chain, its Layer 2s, and soon its shards. These\ncan all be thought as separate blockchains, heavily inter-connected with one\nanother, and together forming an ecosystem. In this work, we call each of these\ninterconnected blockchains \"domains\", and study the manifestation of Maximal\nExtractable Value (MEV, a generalization of \"Miner Extractable Value\") across\nthem. In other words, we investigate whether there exists extractable value\nthat depends on the ordering of transactions in two or more domains jointly. We\nfirst recall the definitions of Extractable and Maximal Extractable Value,\nbefore introducing a definition of Cross-Domain Maximal Extractable Value. We\nfind that Cross-Domain MEV can be used to measure the incentive for transaction\nsequencers in different domains to collude with one another, and study the\nscenarios in which there exists such an incentive. We end the work with a list\nof negative externalities that might arise from cross-domain MEV extraction and\nlay out several open questions. We note that the formalism in this work is a\nwork in progress, and we hope that it can serve as the basis for formal\nanalysis tools in the style of those presented in Clockwork Finance, as well as\nfor discussion on how to mitigate the upcoming negative externalities of\nsubstantial cross-domain MEV.",
    "descriptor": "",
    "authors": [
      "Alexandre Obadia",
      "Alejo Salles",
      "Lakshman Sankar",
      "Tarun Chitra",
      "Vaibhav Chellani",
      "Philip Daian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.01472"
  },
  {
    "id": "arXiv:2112.01473",
    "title": "Neural Point Light Fields",
    "abstract": "We introduce Neural Point Light Fields that represent scenes implicitly with\na light field living on a sparse point cloud. Combining differentiable volume\nrendering with learned implicit density representations has made it possible to\nsynthesize photo-realistic images for novel views of small scenes. As neural\nvolumetric rendering methods require dense sampling of the underlying\nfunctional scene representation, at hundreds of samples along a ray cast\nthrough the volume, they are fundamentally limited to small scenes with the\nsame objects projected to hundreds of training views. Promoting sparse point\nclouds to neural implicit light fields allows us to represent large scenes\neffectively with only a single implicit sampling operation per ray. These point\nlight fields are as a function of the ray direction, and local point feature\nneighborhood, allowing us to interpolate the light field conditioned training\nimages without dense object coverage and parallax. We assess the proposed\nmethod for novel view synthesis on large driving scenarios, where we synthesize\nrealistic unseen views that existing implicit approaches fail to represent. We\nvalidate that Neural Point Light Fields make it possible to predict videos\nalong unseen trajectories previously only feasible to generate by explicitly\nmodeling the scene.",
    "descriptor": "",
    "authors": [
      "Julian Ost",
      "Issam Laradji",
      "Alejandro Newell",
      "Yuval Bahat",
      "Felix Heide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.01473"
  },
  {
    "id": "arXiv:2112.01474",
    "title": "Approximation by tree tensor networks in high dimensions: Sobolev and  compositional functions",
    "abstract": "This paper is concerned with convergence estimates for fully discrete tree\ntensor network approximations of high-dimensional functions from several model\nclasses. For functions having standard or mixed Sobolev regularity, new\nestimates generalizing and refining known results are obtained, based on\nnotions of linear widths of multivariate functions. In the main results of this\npaper, such techniques are applied to classes of functions with compositional\nstructure, which are known to be particularly suitable for approximation by\ndeep neural networks. As shown here, such functions can also be approximated by\ntree tensor networks without a curse of dimensionality -- however, subject to\ncertain conditions, in particular on the depth of the underlying tree. In\naddition, a constructive encoding of compositional functions in tree tensor\nnetworks is given.",
    "descriptor": "\nComments: Dedicated to Ronald DeVore on the occasion of his 80th birthday\n",
    "authors": [
      "Markus Bachmayr",
      "Anthony Nouy",
      "Reinhold Schneider"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.01474"
  },
  {
    "id": "arXiv:2112.01475",
    "title": "A Hybrid Science-Guided Machine Learning Approach for Modeling and  Optimizing Chemical Processes",
    "abstract": "This study presents a broad perspective of hybrid process modeling and\noptimization combining the scientific knowledge and data analytics in\nbioprocessing and chemical engineering with a science-guided machine learning\n(SGML) approach. We divide the approach into two major categories. The first\nrefers to the case where a data-based ML model compliments and makes the\nfirst-principle science-based model more accurate in prediction, and the second\ncorresponds to the case where scientific knowledge helps make the ML model more\nscientifically consistent. We present a detailed review of scientific and\nengineering literature relating to the hybrid SGML approach, and propose a\nsystematic classification of hybrid SGML models. For applying ML to improve\nscience-based models, we present expositions of the sub-categories of direct\nserial and parallel hybrid modeling and their combinations, inverse modeling,\nreduced-order modeling, quantifying uncertainty in the process and even\ndiscovering governing equations of the process model. For applying scientific\nprinciples to improve ML models, we discuss the sub-categories of\nscience-guided design, learning and refinement. For each sub-category, we\nidentify its requirements, advantages and limitations, together with their\npublished and potential areas of applications in bioprocessing and chemical\nengineering.",
    "descriptor": "\nComments: 29 pages 12 figures, 1 table\n",
    "authors": [
      "Niket Sharma",
      "Y. A. Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01475"
  },
  {
    "id": "arXiv:2112.01476",
    "title": "KPDrop: An Approach to Improving Absent Keyphrase Generation",
    "abstract": "Keyphrase generation is the task of generating phrases (keyphrases) that\nsummarize the main topics of a given document. The generated keyphrases can be\neither present or absent from the text of the given document. While the\nextraction of present keyphrases has received much attention in the past, only\nrecently a stronger focus has been placed on the generation of absent\nkeyphrases. However, generating absent keyphrases is very challenging; even the\nbest methods show only a modest degree of success. In this paper, we propose an\napproach, called keyphrase dropout (or KPDrop), to improve absent keyphrase\ngeneration. We randomly drop present keyphrases from the document and turn them\ninto artificial absent keyphrases during training. We test our approach\nextensively and show that it consistently improves the absent performance of\nstrong baselines in keyphrase generation.",
    "descriptor": "\nComments: 4 pages, 1 Figure\n",
    "authors": [
      "Seoyeon Park",
      "Jishnu Ray Chowdhury",
      "Tuhin Kundu",
      "Cornelia Caragea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01476"
  },
  {
    "id": "arXiv:2112.01477",
    "title": "Why Calibration Error is Wrong Given Model Uncertainty: Using Posterior  Predictive Checks with Deep Learning",
    "abstract": "Within the last few years, there has been a move towards using statistical\nmodels in conjunction with neural networks with the end goal of being able to\nbetter answer the question, \"what do our models know?\". From this trend,\nclassical metrics such as Prediction Interval Coverage Probability (PICP) and\nnew metrics such as calibration error have entered the general repertoire of\nmodel evaluation in order to gain better insight into how the uncertainty of\nour model compares to reality. One important component of uncertainty modeling\nis model uncertainty (epistemic uncertainty), a measurement of what the model\ndoes and does not know. However, current evaluation techniques tends to\nconflate model uncertainty with aleatoric uncertainty (irreducible error),\nleading to incorrect conclusions. In this paper, using posterior predictive\nchecks, we show how calibration error and its variants are almost always\nincorrect to use given model uncertainty, and further show how this mistake can\nlead to trust in bad models and mistrust in good models. Though posterior\npredictive checks has often been used for in-sample evaluation of Bayesian\nmodels, we show it still has an important place in the modern deep learning\nworld.",
    "descriptor": "",
    "authors": [
      "Achintya Gopal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.01477"
  },
  {
    "id": "arXiv:2112.01479",
    "title": "Learning Spatial-Temporal Graphs for Active Speaker Detection",
    "abstract": "We address the problem of active speaker detection through a new framework,\ncalled SPELL, that learns long-range multimodal graphs to encode the\ninter-modal relationship between audio and visual data. We cast active speaker\ndetection as a node classification task that is aware of longer-term\ndependencies. We first construct a graph from a video so that each node\ncorresponds to one person. Nodes representing the same identity share edges\nbetween them within a defined temporal window. Nodes within the same video\nframe are also connected to encode inter-person interactions. Through extensive\nexperiments on the Ava-ActiveSpeaker dataset, we demonstrate that learning\ngraph-based representation, owing to its explicit spatial and temporal\nstructure, significantly improves the overall performance. SPELL outperforms\nseveral relevant baselines and performs at par with state of the art models\nwhile requiring an order of magnitude lower computation cost.",
    "descriptor": "",
    "authors": [
      "Sourya Roy",
      "Kyle Min",
      "Subarna Tripathi",
      "Tanaya Guha",
      "Somdeb Majumdar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01479"
  },
  {
    "id": "arXiv:2112.01484",
    "title": "Safe Reinforcement Learning for Grid Voltage Control",
    "abstract": "Under voltage load shedding has been considered as a standard approach to\nrecover the voltage stability of the electric power grid under emergency\nconditions, yet this scheme usually trips a massive amount of load\ninefficiently. Reinforcement learning (RL) has been adopted as a promising\napproach to circumvent the issues; however, RL approach usually cannot\nguarantee the safety of the systems under control. In this paper, we discuss a\ncouple of novel safe RL approaches, namely constrained optimization approach\nand Barrier function-based approach, that can safely recover voltage under\nemergency events. This method is general and can be applied to other\nsafety-critical control problems. Numerical simulations on the 39-bus IEEE\nbenchmark are performed to demonstrate the effectiveness of the proposed safe\nRL emergency control.",
    "descriptor": "\nComments: Workshop on Safe and Robust Control of Uncertain Systems at the 35th Conference on Neural Information Processing Systems (NeurIPS) 2021. arXiv admin note: substantial text overlap with arXiv:2103.14186, arXiv:2011.09664, arXiv:2006.12667\n",
    "authors": [
      "Thanh Long Vu",
      "Sayak Mukherjee",
      "Renke Huang",
      "Qiuhua Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.01484"
  },
  {
    "id": "arXiv:2112.01488",
    "title": "ColBERTv2: Effective and Efficient Retrieval via Lightweight Late  Interaction",
    "abstract": "Neural information retrieval (IR) has greatly advanced search and other\nknowledge-intensive language tasks. While many neural IR methods encode queries\nand documents into single-vector representations, late interaction models\nproduce multi-vector representations at the granularity of each token and\ndecompose relevance modeling into scalable token-level computations. This\ndecomposition has been shown to make late interaction more effective, but it\ninflates the space footprint of these models by an order of magnitude. In this\nwork, we introduce ColBERTv2, a retriever that couples an aggressive residual\ncompression mechanism with a denoised supervision strategy to simultaneously\nimprove the quality and space footprint of late interaction. We evaluate\nColBERTv2 across a wide range of benchmarks, establishing state-of-the-art\nquality within and outside the training domain while reducing the space\nfootprint of late interaction models by 5--8$\\times$.",
    "descriptor": "\nComments: Preprint. Omar and Keshav contributed equally to this work\n",
    "authors": [
      "Keshav Santhanam",
      "Omar Khattab",
      "Jon Saad-Falcon",
      "Christopher Potts",
      "Matei Zaharia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01488"
  },
  {
    "id": "arXiv:2112.01502",
    "title": "Dimensions of Motion: Learning to Predict a Subspace of Optical Flow  from a Single Image",
    "abstract": "We introduce the problem of predicting, from a single video frame, a\nlow-dimensional subspace of optical flow which includes the actual\ninstantaneous optical flow. We show how several natural scene assumptions allow\nus to identify an appropriate flow subspace via a set of basis flow fields\nparameterized by disparity and a representation of object instances. The flow\nsubspace, together with a novel loss function, can be used for the tasks of\npredicting monocular depth or predicting depth plus an object instance\nembedding. This provides a new approach to learning these tasks in an\nunsupervised fashion using monocular input video without requiring camera\nintrinsics or poses.",
    "descriptor": "\nComments: Project page at this https URL\n",
    "authors": [
      "Richard Strong Bowen",
      "Richard Tucker",
      "Ramin Zabih",
      "Noah Snavely"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01502"
  },
  {
    "id": "arXiv:2112.01503",
    "title": "Machine Learning-Based Classification Algorithms for the Prediction of  Coronary Heart Diseases",
    "abstract": "Coronary heart disease, which is a form of cardiovascular disease (CVD), is\nthe leading cause of death worldwide. The odds of survival are good if it is\nfound or diagnosed early. The current report discusses a comparative approach\nto the classification of coronary heart disease datasets using machine learning\n(ML) algorithms. The current study created and tested several\nmachine-learning-based classification models. The dataset was subjected to\nSmote to handle unbalanced classes and feature selection technique in order to\nassess the impact on two distinct performance metrics. The results show that\nlogistic regression produced the highest performance score on the original\ndataset compared to the other algorithms employed. In conclusion, this study\nsuggests that LR on a well-processed and standardized dataset can predict\ncoronary heart disease with greater accuracy than the other algorithms.",
    "descriptor": "",
    "authors": [
      "Kelvin Kwakye",
      "Emmanuel Dadzie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01503"
  },
  {
    "id": "arXiv:2112.01504",
    "title": "Neural Weight Step Video Compression",
    "abstract": "A variety of compression methods based on encoding images as weights of a\nneural network have been recently proposed. Yet, the potential of similar\napproaches for video compression remains unexplored. In this work, we suggest a\nset of experiments for testing the feasibility of compressing video using two\narchitectural paradigms, coordinate-based MLP (CbMLP) and convolutional\nnetwork. Furthermore, we propose a novel technique of neural weight stepping,\nwhere subsequent frames of a video are encoded as low-entropy parameter\nupdates. To assess the feasibility of the considered approaches, we will test\nthe video compression performance on several high-resolution video datasets and\ncompare against existing conventional and neural compression techniques.",
    "descriptor": "\nComments: Accepted to the pre-registration workshop at NeurIPS 2021\n",
    "authors": [
      "Mikolaj Czerkawski",
      "Javier Cardona",
      "Robert Atkinson",
      "Craig Michie",
      "Ivan Andonovic",
      "Carmine Clemente",
      "Christos Tachtatzis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.01504"
  },
  {
    "id": "arXiv:2112.01506",
    "title": "Sample Complexity of Robust Reinforcement Learning with a Generative  Model",
    "abstract": "The Robust Markov Decision Process (RMDP) framework focuses on designing\ncontrol policies that are robust against the parameter uncertainties due to the\nmismatches between the simulator model and real-world settings. An RMDP problem\nis typically formulated as a max-min problem, where the objective is to find\nthe policy that maximizes the value function for the worst possible model that\nlies in an uncertainty set around a nominal model. The standard robust dynamic\nprogramming approach requires the knowledge of the nominal model for computing\nthe optimal robust policy. In this work, we propose a model-based reinforcement\nlearning (RL) algorithm for learning an $\\epsilon$-optimal robust policy when\nthe nominal model is unknown. We consider three different forms of uncertainty\nsets, characterized by the total variation distance, chi-square divergence, and\nKL divergence. For each of these uncertainty sets, we give a precise\ncharacterization of the sample complexity of our proposed algorithm. In\naddition to the sample complexity results, we also present a formal analytical\nargument on the benefit of using robust policies. Finally, we demonstrate the\nperformance of our algorithm on two benchmark problems.",
    "descriptor": "\nComments: 22 pages, 8 figures, under review\n",
    "authors": [
      "Kishan Panaganti",
      "Dileep Kalathil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.01506"
  },
  {
    "id": "arXiv:2112.01511",
    "title": "The Surprising Effectiveness of Representation Learning for Visual  Imitation",
    "abstract": "While visual imitation learning offers one of the most effective ways of\nlearning from visual demonstrations, generalizing from them requires either\nhundreds of diverse demonstrations, task specific priors, or large,\nhard-to-train parametric models. One reason such complexities arise is because\nstandard visual imitation frameworks try to solve two coupled problems at once:\nlearning a succinct but good representation from the diverse visual data, while\nsimultaneously learning to associate the demonstrated actions with such\nrepresentations. Such joint learning causes an interdependence between these\ntwo problems, which often results in needing large amounts of demonstrations\nfor learning. To address this challenge, we instead propose to decouple\nrepresentation learning from behavior learning for visual imitation. First, we\nlearn a visual representation encoder from offline data using standard\nsupervised and self-supervised learning methods. Once the representations are\ntrained, we use non-parametric Locally Weighted Regression to predict the\nactions. We experimentally show that this simple decoupling improves the\nperformance of visual imitation models on both offline demonstration datasets\nand real-robot door opening compared to prior work in visual imitation. All of\nour generated data, code, and robot videos are publicly available at\nhttps://jyopari.github.io/VINN/.",
    "descriptor": "\nComments: The first two authors contributed equally\n",
    "authors": [
      "Jyothish Pari",
      "Nur Muhammad",
      "Shafiullah",
      "Sridhar Pandian Arunachalam",
      "Lerrel Pinto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01511"
  },
  {
    "id": "arXiv:2112.01513",
    "title": "OW-DETR: Open-world Detection Transformer",
    "abstract": "Open-world object detection (OWOD) is a challenging computer vision problem,\nwhere the task is to detect a known set of object categories while\nsimultaneously identifying unknown objects. Additionally, the model must\nincrementally learn new classes that become known in the next training\nepisodes. Distinct from standard object detection, the OWOD setting poses\nsignificant challenges for generating quality candidate proposals on\npotentially unknown objects, separating the unknown objects from the background\nand detecting diverse unknown objects. Here, we introduce a novel end-to-end\ntransformer-based framework, OW-DETR, for open-world object detection. The\nproposed OW-DETR comprises three dedicated components namely, attention-driven\npseudo-labeling, novelty classification and objectness scoring to explicitly\naddress the aforementioned OWOD challenges. Our OW-DETR explicitly encodes\nmulti-scale contextual information, possesses less inductive bias, enables\nknowledge transfer from known classes to the unknown class and can better\ndiscriminate between unknown objects and background. Comprehensive experiments\nare performed on two benchmarks: MS-COCO and PASCAL VOC. The extensive\nablations reveal the merits of our proposed contributions. Further, our model\noutperforms the recently introduced OWOD approach, ORE, with absolute gains\nranging from 1.8% to 3.3% in terms of unknown recall on the MS-COCO benchmark.\nIn the case of incremental object detection, OW-DETR outperforms the\nstate-of-the-art for all settings on the PASCAL VOC benchmark. Our codes and\nmodels will be publicly released.",
    "descriptor": "",
    "authors": [
      "Akshita Gupta",
      "Sanath Narayan",
      "K J Joseph",
      "Salman Khan",
      "Fahad Shahbaz Khan",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01513"
  },
  {
    "id": "arXiv:2112.01514",
    "title": "Self-supervised Video Transformer",
    "abstract": "In this paper, we propose self-supervised training for video transformers\nusing unlabelled video data. From a given video, we create local and global\nspatiotemporal views with varying spatial sizes and frame rates. Our\nself-supervised objective seeks to match the features of these different views\nrepresenting the same video, to be invariant to spatiotemporal variations in\nactions. To the best of our knowledge, the proposed approach is the first to\nalleviate the dependency on negative samples or dedicated memory banks in\nSelf-supervised Video Transformer (SVT). Further, owing to the flexibility of\nTransformer models, SVT supports slow-fast video processing within a single\narchitecture using dynamically adjusted positional encodings and supports\nlong-term relationship modeling along spatiotemporal dimensions. Our approach\nperforms well on four action recognition benchmarks (Kinetics-400, UCF-101,\nHMDB-51, and SSv2) and converges faster with small batch sizes. Code:\nhttps://git.io/J1juJ",
    "descriptor": "",
    "authors": [
      "Kanchana Ranasinghe",
      "Muzammal Naseer",
      "Salman Khan",
      "Fahad Shahbaz Khan",
      "Michael Ryoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01514"
  },
  {
    "id": "arXiv:2112.01515",
    "title": "TransFGU: A Top-down Approach to Fine-Grained Unsupervised Semantic  Segmentation",
    "abstract": "Unsupervised semantic segmentation aims to obtain high-level semantic\nrepresentation on low-level visual features without manual annotations. Most\nexisting methods are bottom-up approaches that try to group pixels into regions\nbased on their visual cues or certain predefined rules. As a result, it is\ndifficult for these bottom-up approaches to generate fine-grained semantic\nsegmentation when coming to complicated scenes with multiple objects and some\nobjects sharing similar visual appearance. In contrast, we propose the first\ntop-down unsupervised semantic segmentation framework for fine-grained\nsegmentation in extremely complicated scenarios. Specifically, we first obtain\nrich high-level structured semantic concept information from large-scale vision\ndata in a self-supervised learning manner, and use such information as a prior\nto discover potential semantic categories presented in target datasets.\nSecondly, the discovered high-level semantic categories are mapped to low-level\npixel features by calculating the class activate map (CAM) with respect to\ncertain discovered semantic representation. Lastly, the obtained CAMs serve as\npseudo labels to train the segmentation module and produce final semantic\nsegmentation. Experimental results on multiple semantic segmentation benchmarks\nshow that our top-down unsupervised segmentation is robust to both\nobject-centric and scene-centric datasets under different semantic granularity\nlevels, and outperforms all the current state-of-the-art bottom-up methods. Our\ncode is available at \\url{https://github.com/damo-cv/TransFGU}.",
    "descriptor": "\nComments: open sourced; codes and models available\n",
    "authors": [
      "Zhaoyuan Yin",
      "Pichao Wang",
      "Fan Wang",
      "Xianzhe Xu",
      "Hanling Zhang",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01515"
  },
  {
    "id": "arXiv:2112.01516",
    "title": "Ownership and Creativity in Generative Models",
    "abstract": "Machine learning generated content such as image artworks, textual poems and\nmusic become prominent in recent years. These tools attract much attention from\nthe media, artists, researchers, and investors. Because these tools are\ndata-driven, they are inherently different than the traditional creative tools\nwhich arises the question - who may own the content that is generated by these\ntools? In this paper we aim to address this question, we start by providing a\nbackground to this problem, raising several candidates that may own the content\nand arguments for each one of them. Then we propose a possible algorithmic\nsolution in the vision-based model's regime. Finally, we discuss the broader\nimplications of this problem.",
    "descriptor": "",
    "authors": [
      "Omri Avrahami",
      "Bar Tamir"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01516"
  },
  {
    "id": "arXiv:2112.01517",
    "title": "Efficient Neural Radiance Fields with Learned Depth-Guided Sampling",
    "abstract": "This paper aims to reduce the rendering time of generalizable radiance\nfields. Some recent works equip neural radiance fields with image encoders and\nare able to generalize across scenes, which avoids the per-scene optimization.\nHowever, their rendering process is generally very slow. A major factor is that\nthey sample lots of points in empty space when inferring radiance fields. In\nthis paper, we present a hybrid scene representation which combines the best of\nimplicit radiance fields and explicit depth maps for efficient rendering.\nSpecifically, we first build the cascade cost volume to efficiently predict the\ncoarse geometry of the scene. The coarse geometry allows us to sample few\npoints near the scene surface and significantly improves the rendering speed.\nThis process is fully differentiable, enabling us to jointly learn the depth\nprediction and radiance field networks from only RGB images. Experiments show\nthat the proposed approach exhibits state-of-the-art performance on the DTU,\nReal Forward-facing and NeRF Synthetic datasets, while being at least 50 times\nfaster than previous generalizable radiance field methods. We also demonstrate\nthe capability of our method to synthesize free-viewpoint videos of dynamic\nhuman performers in real-time. The code will be available at\nhttps://zju3dv.github.io/enerf/.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Haotong Lin",
      "Sida Peng",
      "Zhen Xu",
      "Hujun Bao",
      "Xiaowei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01517"
  },
  {
    "id": "arXiv:2112.01518",
    "title": "DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting",
    "abstract": "Recent progress has shown that large-scale pre-training using contrastive\nimage-text pairs can be a promising alternative for high-quality visual\nrepresentation learning from natural language supervision. Benefiting from a\nbroader source of supervision, this new paradigm exhibits impressive\ntransferability to downstream classification tasks and datasets. However, the\nproblem of transferring the knowledge learned from image-text pairs to more\ncomplex dense prediction tasks has barely been visited. In this work, we\npresent a new framework for dense prediction by implicitly and explicitly\nleveraging the pre-trained knowledge from CLIP. Specifically, we convert the\noriginal image-text matching problem in CLIP to a pixel-text matching problem\nand use the pixel-text score maps to guide the learning of dense prediction\nmodels. By further using the contextual information from the image to prompt\nthe language model, we are able to facilitate our model to better exploit the\npre-trained knowledge. Our method is model-agnostic, which can be applied to\narbitrary dense prediction systems and various pre-trained visual backbones\nincluding both CLIP models and ImageNet pre-trained models. Extensive\nexperiments demonstrate the superior performance of our methods on semantic\nsegmentation, object detection, and instance segmentation tasks. Code is\navailable at https://github.com/raoyongming/DenseCLIP",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yongming Rao",
      "Wenliang Zhao",
      "Guangyi Chen",
      "Yansong Tang",
      "Zheng Zhu",
      "Guan Huang",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01518"
  },
  {
    "id": "arXiv:2112.01520",
    "title": "Recognizing Scenes from Novel Viewpoints",
    "abstract": "Humans can perceive scenes in 3D from a handful of 2D views. For AI agents,\nthe ability to recognize a scene from any viewpoint given only a few images\nenables them to efficiently interact with the scene and its objects. In this\nwork, we attempt to endow machines with this ability. We propose a model which\ntakes as input a few RGB images of a new scene and recognizes the scene from\nnovel viewpoints by segmenting it into semantic categories. All this without\naccess to the RGB images from those views. We pair 2D scene recognition with an\nimplicit 3D representation and learn from multi-view 2D annotations of hundreds\nof scenes without any 3D supervision beyond camera poses. We experiment on\nchallenging datasets and demonstrate our model's ability to jointly capture\nsemantics and geometry of novel scenes with diverse layouts, object types and\nshapes.",
    "descriptor": "",
    "authors": [
      "Shengyi Qian",
      "Alexander Kirillov",
      "Nikhila Ravi",
      "Devendra Singh Chaplot",
      "Justin Johnson",
      "David F. Fouhey",
      "Georgia Gkioxari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01520"
  },
  {
    "id": "arXiv:2112.01521",
    "title": "Object-aware Monocular Depth Prediction with Instance Convolutions",
    "abstract": "With the advent of deep learning, estimating depth from a single RGB image\nhas recently received a lot of attention, being capable of empowering many\ndifferent applications ranging from path planning for robotics to computational\ncinematography. Nevertheless, while the depth maps are in their entirety fairly\nreliable, the estimates around object discontinuities are still far from\nsatisfactory. This can be contributed to the fact that the convolutional\noperator naturally aggregates features across object discontinuities, resulting\nin smooth transitions rather than clear boundaries. Therefore, in order to\ncircumvent this issue, we propose a novel convolutional operator which is\nexplicitly tailored to avoid feature aggregation of different object parts. In\nparticular, our method is based on estimating per-part depth values by means of\nsuperpixels. The proposed convolutional operator, which we dub \"Instance\nConvolution\", then only considers each object part individually on the basis of\nthe estimated superpixels. Our evaluation with respect to the NYUv2 as well as\nthe iBims dataset clearly demonstrates the superiority of Instance Convolutions\nover the classical convolution at estimating depth around occlusion boundaries,\nwhile producing comparable results elsewhere. Code will be made publicly\navailable upon acceptance.",
    "descriptor": "",
    "authors": [
      "Enis Simsar",
      "Evin P\u0131nar \u00d6rnek",
      "Fabian Manhardt",
      "Helisa Dhamo",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01521"
  },
  {
    "id": "arXiv:2112.01522",
    "title": "Uni-Perceiver: Pre-training Unified Architecture for Generic Perception  for Zero-shot and Few-shot Tasks",
    "abstract": "Biological intelligence systems of animals perceive the world by integrating\ninformation in different modalities and processing simultaneously for various\ntasks. In contrast, current machine learning research follows a task-specific\nparadigm, leading to inefficient collaboration between tasks and high marginal\ncosts of developing perception models for new tasks. In this paper, we present\na generic perception architecture named Uni-Perceiver, which processes a\nvariety of modalities and tasks with unified modeling and shared parameters.\nSpecifically, Uni-Perceiver encodes different task inputs and targets from\narbitrary modalities into a unified representation space with a\nmodality-agnostic Transformer encoder and lightweight modality-specific\ntokenizers. Different perception tasks are modeled as the same formulation,\nthat is, finding the maximum likelihood target for each input through the\nsimilarity of their representations. The model is pre-trained on several\nuni-modal and multi-modal tasks, and evaluated on a variety of downstream\ntasks, including novel tasks that did not appear in the pre-training stage.\nResults show that our pre-trained model without any tuning can achieve\nreasonable performance even on novel tasks. The performance can be improved to\na level close to state-of-the-art methods by conducting prompt tuning on 1% of\ndownstream task data. Full-data fine-tuning further delivers results on par\nwith or better than state-of-the-art results. Code shall be released.",
    "descriptor": "",
    "authors": [
      "Xizhou Zhu",
      "Jinguo Zhu",
      "Hao Li",
      "Xiaoshi Wu",
      "Xiaogang Wang",
      "Hongsheng Li",
      "Xiaohua Wang",
      "Jifeng Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01522"
  },
  {
    "id": "arXiv:2112.01523",
    "title": "Learning Neural Light Fields with Ray-Space Embedding Networks",
    "abstract": "Neural radiance fields (NeRFs) produce state-of-the-art view synthesis\nresults. However, they are slow to render, requiring hundreds of network\nevaluations per pixel to approximate a volume rendering integral. Baking NeRFs\ninto explicit data structures enables efficient rendering, but results in a\nlarge increase in memory footprint and, in many cases, a quality reduction. In\nthis paper, we propose a novel neural light field representation that, in\ncontrast, is compact and directly predicts integrated radiance along rays. Our\nmethod supports rendering with a single network evaluation per pixel for small\nbaseline light field datasets and can also be applied to larger baselines with\nonly a few evaluations per pixel. At the core of our approach is a ray-space\nembedding network that maps the 4D ray-space manifold into an intermediate,\ninterpolable latent space. Our method achieves state-of-the-art quality on\ndense forward-facing datasets such as the Stanford Light Field dataset. In\naddition, for forward-facing scenes with sparser inputs we achieve results that\nare competitive with NeRF-based approaches in terms of quality while providing\na better speed/quality/memory trade-off with far fewer network evaluations.",
    "descriptor": "\nComments: Project webpage: this https URL\n",
    "authors": [
      "Benjamin Attal",
      "Jia-Bin Huang",
      "Michael Zollhoefer",
      "Johannes Kopf",
      "Changil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01523"
  },
  {
    "id": "arXiv:2112.01524",
    "title": "GLAMR: Global Occlusion-Aware Human Mesh Recovery with Dynamic Cameras",
    "abstract": "We present an approach for 3D global human mesh recovery from monocular\nvideos recorded with dynamic cameras. Our approach is robust to severe and\nlong-term occlusions and tracks human bodies even when they go outside the\ncamera's field of view. To achieve this, we first propose a deep generative\nmotion infiller, which autoregressively infills the body motions of occluded\nhumans based on visible motions. Additionally, in contrast to prior work, our\napproach reconstructs human meshes in consistent global coordinates even with\ndynamic cameras. Since the joint reconstruction of human motions and camera\nposes is underconstrained, we propose a global trajectory predictor that\ngenerates global human trajectories based on local body movements. Using the\npredicted trajectories as anchors, we present a global optimization framework\nthat refines the predicted trajectories and optimizes the camera poses to match\nthe video evidence such as 2D keypoints. Experiments on challenging indoor and\nin-the-wild datasets with dynamic cameras demonstrate that the proposed\napproach outperforms prior methods significantly in terms of motion infilling\nand global mesh recovery.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Ye Yuan",
      "Umar Iqbal",
      "Pavlo Molchanov",
      "Kris Kitani",
      "Jan Kautz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.01524"
  },
  {
    "id": "arXiv:2112.01525",
    "title": "Co-domain Symmetry for Complex-Valued Deep Learning",
    "abstract": "We study complex-valued scaling as a type of symmetry natural and unique to\ncomplex-valued measurements and representations. Deep Complex Networks (DCN)\nextends real-valued algebra to the complex domain without addressing\ncomplex-valued scaling. SurReal takes a restrictive manifold view of complex\nnumbers, adopting a distance metric to achieve complex-scaling invariance while\nlosing rich complex-valued information. We analyze complex-valued scaling as a\nco-domain transformation and design novel equivariant and invariant neural\nnetwork layer functions for this special transformation. We also propose novel\ncomplex-valued representations of RGB images, where complex-valued scaling\nindicates hue shift or correlated changes across color channels. Benchmarked on\nMSTAR, CIFAR10, CIFAR100, and SVHN, our co-domain symmetric (CDS) classifiers\ndeliver higher accuracy, better generalization, robustness to co-domain\ntransformations, and lower model bias and variance than DCN and SurReal with\nfar fewer parameters.",
    "descriptor": "",
    "authors": [
      "Utkarsh Singhal",
      "Yifei Xing",
      "Stella X. Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01525"
  },
  {
    "id": "arXiv:2112.01526",
    "title": "Improved Multiscale Vision Transformers for Classification and Detection",
    "abstract": "In this paper, we study Multiscale Vision Transformers (MViT) as a unified\narchitecture for image and video classification, as well as object detection.\nWe present an improved version of MViT that incorporates decomposed relative\npositional embeddings and residual pooling connections. We instantiate this\narchitecture in five sizes and evaluate it for ImageNet classification, COCO\ndetection and Kinetics video recognition where it outperforms prior work. We\nfurther compare MViTs' pooling attention to window attention mechanisms where\nit outperforms the latter in accuracy/compute. Without bells-and-whistles, MViT\nhas state-of-the-art performance in 3 domains: 88.8% accuracy on ImageNet\nclassification, 56.1 box AP on COCO object detection as well as 86.1% on\nKinetics-400 video classification. Code and models will be made publicly\navailable.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Yanghao Li",
      "Chao-Yuan Wu",
      "Haoqi Fan",
      "Karttikeya Mangalam",
      "Bo Xiong",
      "Jitendra Malik",
      "Christoph Feichtenhofer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01526"
  },
  {
    "id": "arXiv:2112.01527",
    "title": "Masked-attention Mask Transformer for Universal Image Segmentation",
    "abstract": "Image segmentation is about grouping pixels with different semantics, e.g.,\ncategory or instance membership, where each choice of semantics defines a task.\nWhile only the semantics of each task differ, current research focuses on\ndesigning specialized architectures for each task. We present Masked-attention\nMask Transformer (Mask2Former), a new architecture capable of addressing any\nimage segmentation task (panoptic, instance or semantic). Its key components\ninclude masked attention, which extracts localized features by constraining\ncross-attention within predicted mask regions. In addition to reducing the\nresearch effort by at least three times, it outperforms the best specialized\narchitectures by a significant margin on four popular datasets. Most notably,\nMask2Former sets a new state-of-the-art for panoptic segmentation (57.8 PQ on\nCOCO), instance segmentation (50.1 AP on COCO) and semantic segmentation (57.7\nmIoU on ADE20K).",
    "descriptor": "\nComments: Project page/code/models: this https URL\n",
    "authors": [
      "Bowen Cheng",
      "Ishan Misra",
      "Alexander G. Schwing",
      "Alexander Kirillov",
      "Rohit Girdhar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01527"
  },
  {
    "id": "arXiv:2112.01528",
    "title": "A Fast Knowledge Distillation Framework for Visual Recognition",
    "abstract": "While Knowledge Distillation (KD) has been recognized as a useful tool in\nmany visual tasks, such as supervised classification and self-supervised\nrepresentation learning, the main drawback of a vanilla KD framework is its\nmechanism, which consumes the majority of the computational overhead on\nforwarding through the giant teacher networks, making the entire learning\nprocedure inefficient and costly. ReLabel, a recently proposed solution,\nsuggests creating a label map for the entire image. During training, it\nreceives the cropped region-level label by RoI aligning on a pre-generated\nentire label map, allowing for efficient supervision generation without having\nto pass through the teachers many times. However, as the KD teachers are from\nconventional multi-crop training, there are various mismatches between the\nglobal label-map and region-level label in this technique, resulting in\nperformance deterioration. In this study, we present a Fast Knowledge\nDistillation (FKD) framework that replicates the distillation training phase\nand generates soft labels using the multi-crop KD approach, while training\nfaster than ReLabel since no post-processes such as RoI align and softmax\noperations are used. When conducting multi-crop in the same image for data\nloading, our FKD is even more efficient than the traditional image\nclassification framework. On ImageNet-1K, we obtain 79.8% with ResNet-50,\noutperforming ReLabel by ~1.0% while being faster. On the self-supervised\nlearning task, we also show that FKD has an efficiency advantage. Our project\npage: this http URL, source code and models\nare available at: https://github.com/szq0214/FKD.",
    "descriptor": "\nComments: Our project page: this http URL, code and models are available at: this https URL\n",
    "authors": [
      "Zhiqiang Shen",
      "Eric Xing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01528"
  },
  {
    "id": "arXiv:2112.01529",
    "title": "BEVT: BERT Pretraining of Video Transformers",
    "abstract": "This paper studies the BERT pretraining of video transformers. It is a\nstraightforward but worth-studying extension given the recent success from BERT\npretraining of image transformers. We introduce BEVT which decouples video\nrepresentation learning into spatial representation learning and temporal\ndynamics learning. In particular, BEVT first performs masked image modeling on\nimage data, and then conducts masked image modeling jointly with masked video\nmodeling on video data. This design is motivated by two observations: 1)\ntransformers learned on image datasets provide decent spatial priors that can\nease the learning of video transformers, which are often times\ncomputationally-intensive if trained from scratch; 2) discriminative clues,\ni.e., spatial and temporal information, needed to make correct predictions vary\namong different videos due to large intra-class and inter-class variations. We\nconduct extensive experiments on three challenging video benchmarks where BEVT\nachieves very promising results. On Kinetics 400, for which recognition mostly\nrelies on discriminative spatial representations, BEVT achieves comparable\nresults to strong supervised baselines. On Something-Something-V2 and Diving\n48, which contain videos relying on temporal dynamics, BEVT outperforms by\nclear margins all alternative baselines and achieves state-of-the-art\nperformance with a 70.6% and 86.7% Top-1 accuracy respectively.",
    "descriptor": "",
    "authors": [
      "Rui Wang",
      "Dongdong Chen",
      "Zuxuan Wu",
      "Yinpeng Chen",
      "Xiyang Dai",
      "Mengchen Liu",
      "Yu-Gang Jiang",
      "Luowei Zhou",
      "Lu Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01529"
  },
  {
    "id": "arXiv:2112.01530",
    "title": "StyleMesh: Style Transfer for Indoor 3D Scene Reconstructions",
    "abstract": "We apply style transfer on mesh reconstructions of indoor scenes. This\nenables VR applications like experiencing 3D environments painted in the style\nof a favorite artist. Style transfer typically operates on 2D images, making\nstylization of a mesh challenging. When optimized over a variety of poses,\nstylization patterns become stretched out and inconsistent in size. On the\nother hand, model-based 3D style transfer methods exist that allow stylization\nfrom a sparse set of images, but they require a network at inference time. To\nthis end, we optimize an explicit texture for the reconstructed mesh of a scene\nand stylize it jointly from all available input images. Our depth- and\nangle-aware optimization leverages surface normal and depth data of the\nunderlying mesh to create a uniform and consistent stylization for the whole\nscene. Our experiments show that our method creates sharp and detailed results\nfor the complete scene without view-dependent artifacts. Through extensive\nablation studies, we show that the proposed 3D awareness enables style transfer\nto be applied to the 3D domain of a mesh. Our method can be used to render a\nstylized mesh in real-time with traditional rendering pipelines.",
    "descriptor": "\nComments: Video: this https URL\n",
    "authors": [
      "Lukas H\u00f6llein",
      "Justin Johnson",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01530"
  },
  {
    "id": "arXiv:2112.01531",
    "title": "The MAIEI Learning Community Report",
    "abstract": "This is a labor of the Learning Community cohort that was convened by MAIEI\nin Winter 2021 to work through and discuss important research issues in the\nfield of AI ethics from a multidisciplinary lens. The community came together\nsupported by facilitators from the MAIEI staff to vigorously debate and explore\nthe nuances of issues like bias, privacy, disinformation, accountability, and\nmore especially examining them from the perspective of industry, civil society,\nacademia, and government.\nThe outcome of these discussions is reflected in the report that you are\nreading now - an exploration of a variety of issues with deep-dive, critical\ncommentary on what has been done, what worked and what didn't, and what remains\nto be done so that we can meaningfully move forward in addressing the societal\nchallenges posed by the deployment of AI systems.\nThe chapters titled \"Design and Techno-isolationism\", \"Facebook and the\nDigital Divide: Perspectives from Myanmar, Mexico, and India\", \"Future of\nWork\", and \"Media & Communications & Ethical Foresight\" will hopefully provide\nwith you novel lenses to explore this domain beyond the usual tropes that are\ncovered in the domain of AI ethics.",
    "descriptor": "\nComments: Authors listed in alphabetical order\n",
    "authors": [
      "Brittany Wills",
      "Christina Isaicu",
      "Heather von Stackelberg",
      "Lujain Ibrahim",
      "Matthew Hutson",
      "Mitchel Fleming",
      "Nanditha Narayanamoorthy",
      "Samuel Curtis",
      "Shreyasha Paudel",
      "Sofia Trejo",
      "Tiziana Zevallos",
      "Victoria Mart\u00edn del Campo",
      "Wilson Lee"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01531"
  },
  {
    "id": "arXiv:2008.09743",
    "title": "A Efficient Multimodal Framework for Large Scale Emotion Recognition by  Fusing Music and Electrodermal Activity Signals",
    "abstract": "Considerable attention has been paid for physiological signal-based emotion\nrecognition in field of affective computing. For the reliability and user\nfriendly acquisition, Electrodermal Activity (EDA) has great advantage in\npractical applications. However, the EDA-based emotion recognition with\nhundreds of subjects still lacks effective solution. In this paper, our work\nmakes an attempt to fuse the subject individual EDA features and the external\nevoked music features. And we propose an end-to-end multimodal framework, the\n1-dimensional residual temporal and channel attention network (RTCAN-1D). For\nEDA features, the novel convex optimization-based EDA (CvxEDA) method is\napplied to decompose EDA signals into pahsic and tonic signals for mining the\ndynamic and steady features. The channel-temporal attention mechanism for\nEDA-based emotion recognition is firstly involved to improve the temporal- and\nchannel-wise representation. For music features, we process the music signal\nwith the open source toolkit openSMILE to obtain external feature vectors. The\nindividual emotion features from EDA signals and external emotion benchmarks\nfrom music are fused in the classifing layers. We have conducted systematic\ncomparisons on three multimodal datasets (PMEmo, DEAP, AMIGOS) for 2-classes\nvalance/arousal emotion recognition. Our proposed RTCAN-1D outperforms the\nexisting state-of-the-art models, which also validate that our work provides an\nreliable and efficient solution for large scale emotion recognition. Our code\nhas been released at https://github.com/guanghaoyin/RTCAN-1D.",
    "descriptor": "\nComments: ACM Transactions on Multimedia Computing, Communications, and Applications (Acceptance 07-Oct-2021)\n",
    "authors": [
      "Guanghao Yin",
      "Shouqian Sun",
      "Dian Yu",
      "Dejian Li",
      "Kejun Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.09743"
  },
  {
    "id": "arXiv:2106.15353",
    "title": "Patient-independent Schizophrenia Relapse Prediction Using Mobile Sensor  based Daily Behavioral Rhythm Changes",
    "abstract": "A schizophrenia relapse has severe consequences for a patient's health, work,\nand sometimes even life safety. If an oncoming relapse can be predicted on\ntime, for example by detecting early behavioral changes in patients, then\ninterventions could be provided to prevent the relapse. In this work, we\ninvestigated a machine learning based schizophrenia relapse prediction model\nusing mobile sensing data to characterize behavioral features. A\npatient-independent model providing sequential predictions, closely\nrepresenting the clinical deployment scenario for relapse prediction, was\nevaluated. The model uses the mobile sensing data from the recent four weeks to\npredict an oncoming relapse in the next week. We used the behavioral rhythm\nfeatures extracted from daily templates of mobile sensing data, self-reported\nsymptoms collected via EMA (Ecological Momentary Assessment), and demographics\nto compare different classifiers for the relapse prediction. Naive Bayes based\nmodel gave the best results with an F2 score of 0.083 when evaluated in a\ndataset consisting of 63 schizophrenia patients, each monitored for up to a\nyear. The obtained F2 score, though low, is better than the baseline\nperformance of random classification (F2 score of 0.02 $\\pm$ 0.024). Thus,\nmobile sensing has predictive value for detecting an oncoming relapse and needs\nfurther investigation to improve the current performance. Towards that end,\nfurther feature engineering and model personalization based on the behavioral\nidiosyncrasies of a patient could be helpful.",
    "descriptor": "\nComments: EAI MobiHealth 2020\n",
    "authors": [
      "Bishal Lamichhane",
      "Dror Ben-Zeev",
      "Andrew Campbell",
      "Tanzeem Choudhury",
      "Marta Hauser",
      "John Kane",
      "Mikio Obuchi",
      "Emily Scherer",
      "Megan Walsh",
      "Rui Wang",
      "Weichen Wang",
      "Akane Sano"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15353"
  },
  {
    "id": "arXiv:2112.00729",
    "title": "Total-Body Low-Dose CT Image Denoising using Prior Knowledge Transfer  Technique with Contrastive Regularization Mechanism",
    "abstract": "Reducing the radiation exposure for patients in Total-body CT scans has\nattracted extensive attention in the medical imaging community. Given the fact\nthat low radiation dose may result in increased noise and artifacts, which\ngreatly affected the clinical diagnosis. To obtain high-quality Total-body\nLow-dose CT (LDCT) images, previous deep-learning-based research work has\nintroduced various network architectures. However, most of these methods only\nadopt Normal-dose CT (NDCT) images as ground truths to guide the training of\nthe denoising network. Such simple restriction leads the model to less\neffectiveness and makes the reconstructed images suffer from over-smoothing\neffects. In this paper, we propose a novel intra-task knowledge transfer method\nthat leverages the distilled knowledge from NDCT images to assist the training\nprocess on LDCT images. The derived architecture is referred to as the\nTeacher-Student Consistency Network (TSC-Net), which consists of the teacher\nnetwork and the student network with identical architecture. Through the\nsupervision between intermediate features, the student network is encouraged to\nimitate the teacher network and gain abundant texture details. Moreover, to\nfurther exploit the information contained in CT scans, a contrastive\nregularization mechanism (CRM) built upon contrastive learning is\nintroduced.CRM performs to pull the restored CT images closer to the NDCT\nsamples and push far away from the LDCT samples in the latent space. In\naddition, based on the attention and deformable convolution mechanism, we\ndesign a Dynamic Enhancement Module (DEM) to improve the network transformation\ncapability.",
    "descriptor": "",
    "authors": [
      "Minghan Fu",
      "Yanhua Duan",
      "Zhaoping Cheng",
      "Wenjian Qin",
      "Ying Wang",
      "Dong Liang",
      "Zhanli Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.00729"
  },
  {
    "id": "arXiv:2112.00730",
    "title": "Highly accelerated MR parametric mapping by undersampling the k-space  and reducing the contrast number simultaneously with deep learning",
    "abstract": "Purpose: To propose a novel deep learning-based method called RG-Net\n(reconstruction and generation network) for highly accelerated MR parametric\nmapping by undersampling k-space and reducing the acquired contrast number\nsimultaneously.\nMethods: The proposed framework consists of a reconstruction module and a\ngenerative module. The reconstruction module reconstructs MR images from the\nacquired few undersampled k-space data with the help of a data prior. The\ngenerative module then synthesizes the remaining multi-contrast images from the\nreconstructed images, where the exponential model is implicitly incorporated\ninto the image generation through the supervision of fully sampled labels. The\nRG-Net was evaluated on the T1\\r{ho} mapping data of knee and brain at\ndifferent acceleration rates. Regional T1\\r{ho} analysis for cartilage and the\nbrain was performed to access the performance of RG-Net.\nResults: RG-Net yields a high-quality T1\\r{ho} map at a high acceleration\nrate of 17. Compared with the competing methods that only undersample k-space,\nour framework achieves better performance in T1\\r{ho} value analysis. Our\nmethod also improves quality of T1\\r{ho} maps on patient with glioma.\nConclusion: The proposed RG-Net that adopted a new strategy by undersampling\nk-space and reducing the contrast number simultaneously for fast MR parametric\nmapping, can achieve a high acceleration rate while maintaining good\nreconstruction quality. The generative module of our framework can also be used\nas an insert module in other fast MR parametric mapping methods.\nKeywords: Deep learning, convolutional neural network, fast MR parametric\nmapping",
    "descriptor": "\nComments: 27 pages,11 figures. Submitted to Magnetic Resonance in Medicine\n",
    "authors": [
      "Yanjie Zhu",
      "Haoxiang Li",
      "Yuanyuan Liu",
      "Muzi Guo",
      "Guanxun Cheng",
      "Gang Yang",
      "Haifeng Wang",
      "Dong Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00730"
  },
  {
    "id": "arXiv:2112.00735",
    "title": "Reference-guided Pseudo-Label Generation for Medical Semantic  Segmentation",
    "abstract": "Producing densely annotated data is a difficult and tedious task for medical\nimaging applications. To address this problem, we propose a novel approach to\ngenerate supervision for semi-supervised semantic segmentation. We argue that\nvisually similar regions between labeled and unlabeled images likely contain\nthe same semantics and therefore should share their label. Following this\nthought, we use a small number of labeled images as reference material and\nmatch pixels in an unlabeled image to the semantics of the best fitting pixel\nin a reference set. This way, we avoid pitfalls such as confirmation bias,\ncommon in purely prediction-based pseudo-labeling. Since our method does not\nrequire any architectural changes or accompanying networks, one can easily\ninsert it into existing frameworks. We achieve the same performance as a\nstandard fully supervised model on X-ray anatomy segmentation, albeit 95% fewer\nlabeled images. Aside from an in-depth analysis of different aspects of our\nproposed method, we further demonstrate the effectiveness of our\nreference-guided learning paradigm by comparing our approach against existing\nmethods for retinal fluid segmentation with competitive performance as we\nimprove upon recent work by up to 15% mean IoU.",
    "descriptor": "\nComments: 36th AAAI Conference on Artificial Intelligence 2022\n",
    "authors": [
      "Constantin Seibold",
      "Simon Rei\u00df",
      "Jens Kleesiek",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00735"
  },
  {
    "id": "arXiv:2112.00738",
    "title": "Aiding Medical Diagnosis Through the Application of Graph Neural  Networks to Functional MRI Scans",
    "abstract": "Graph Neural Networks (GNNs) have been shown to be a powerful tool for\ngenerating predictions from biological data. Their application to neuroimaging\ndata such as functional magnetic resonance imaging (fMRI) scans has been\nlimited. However, applying GNNs to fMRI scans may substantially improve\npredictive accuracy and could be used to inform clinical diagnosis in the\nfuture. In this paper, we present a novel approach to representing\nresting-state fMRI data as a graph containing nodes and edges without omitting\nany of the voxels and thus reducing information loss. We compare multiple GNN\narchitectures and show that they can successfully predict the disease and sex\nof a person. We hope to provide a basis for future work to exploit the power of\nGNNs when applied to brain imaging data.",
    "descriptor": "\nComments: 5 pages, 1 figure, 1 table\n",
    "authors": [
      "Katharina Z\u00fchlsdorff",
      "Clayton M. Rabideau"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00738"
  },
  {
    "id": "arXiv:2112.00760",
    "title": "Biology and medicine in the landscape of quantum advantages",
    "abstract": "Quantum computing holds significant potential for applications in biology and\nmedicine, spanning from the simulation of biomolecules to machine learning\napproaches for subtyping cancers on the basis of clinical features. This\npotential is encapsulated by the concept of a quantum advantage, which is\ntypically contingent on a reduction in the consumption of a computational\nresource, such as time, space, or data. Here, we distill the concept of a\nquantum advantage into a simple framework that we hope will aid researchers in\nbiology and medicine pursuing the development of quantum applications. We then\napply this framework to a wide variety of computational problems relevant to\nthese domains in an effort to i) assess the potential of quantum advantages in\nspecific application areas and ii) identify gaps that may be addressed with\nnovel quantum approaches. Bearing in mind the rapid pace of change in the\nfields of quantum computing and classical algorithms, we aim to provide an\nextensive survey of applications in biology and medicine that may lead to\npractical quantum advantages.",
    "descriptor": "\nComments: 40 pages, 2 figures, 3 tables, 1 box\n",
    "authors": [
      "Benjamin A. Cordier",
      "Nicolas P. D. Sawaya",
      "Gian G. Guerreschi",
      "Shannon K. McWeeney"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.00760"
  },
  {
    "id": "arXiv:2112.00778",
    "title": "Quantum advantage in learning from experiments",
    "abstract": "Quantum technology has the potential to revolutionize how we acquire and\nprocess experimental data to learn about the physical world. An experimental\nsetup that transduces data from a physical system to a stable quantum memory,\nand processes that data using a quantum computer, could have significant\nadvantages over conventional experiments in which the physical system is\nmeasured and the outcomes are processed using a classical computer. We prove\nthat, in various tasks, quantum machines can learn from exponentially fewer\nexperiments than those required in conventional experiments. The exponential\nadvantage holds in predicting properties of physical systems, performing\nquantum principal component analysis on noisy states, and learning approximate\nmodels of physical dynamics. In some tasks, the quantum processing needed to\nachieve the exponential advantage can be modest; for example, one can\nsimultaneously learn about many noncommuting observables by processing only two\ncopies of the system. Conducting experiments with up to 40 superconducting\nqubits and 1300 quantum gates, we demonstrate that a substantial quantum\nadvantage can be realized using today's relatively noisy quantum processors.\nOur results highlight how quantum technology can enable powerful new strategies\nto learn about nature.",
    "descriptor": "\nComments: 6 pages, 17 figures + 46 page appendix; open-source code available at this https URL\n",
    "authors": [
      "Hsin-Yuan Huang",
      "Michael Broughton",
      "Jordan Cotler",
      "Sitan Chen",
      "Jerry Li",
      "Masoud Mohseni",
      "Hartmut Neven",
      "Ryan Babbush",
      "Richard Kueng",
      "John Preskill",
      "Jarrod R. McClean"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00778"
  },
  {
    "id": "arXiv:2112.00794",
    "title": "DFTS2: Simulating Deep Feature Transmission Over Packet Loss Channels",
    "abstract": "In edge-cloud collaborative intelligence (CI), an unreliable transmission\nchannel exists in the information path of the AI model performing the\ninference. It is important to be able to simulate the performance of the CI\nsystem across an imperfect channel in order to understand system behavior and\ndevelop appropriate error control strategies. In this paper we present a\nsimulation framework called DFTS2, which enables researchers to define the\ncomponents of the CI system in TensorFlow~2, select a packet-based channel\nmodel with various parameters, and simulate system behavior under various\nchannel conditions and error/loss control strategies. Using DFTS2, we also\npresent the most comprehensive study to date of the packet loss concealment\nmethods for collaborative image classification models.",
    "descriptor": "\nComments: 6 pages, 4 figures, IEEE Conference on Visual Communications and Image Processing (VCIP) 2021\n",
    "authors": [
      "Ashiv Dhondea",
      "Robert A. Cohen",
      "Ivan V. Baji\u0107"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00794"
  },
  {
    "id": "arXiv:2112.00811",
    "title": "Revisiting dequantization and quantum advantage in learning tasks",
    "abstract": "It has been shown that the apparent advantage of some quantum machine\nlearning algorithms may be efficiently replicated using classical algorithms\nwith suitable data access -- a process known as dequantization. Existing works\non dequantization compare quantum algorithms which take copies of an n-qubit\nquantum state $|x\\rangle = \\sum_{i} x_i |i\\rangle$ as input to classical\nalgorithms which have sample and query (SQ) access to the vector $x$. In this\nnote, we prove that classical algorithms with SQ access can accomplish some\nlearning tasks exponentially faster than quantum algorithms with quantum state\ninputs. Because classical algorithms are a subset of quantum algorithms, this\ndemonstrates that SQ access can sometimes be significantly more powerful than\nquantum state inputs. Our findings suggest that the absence of exponential\nquantum advantage in some learning tasks may be due to SQ access being too\npowerful relative to quantum state inputs. If we compare quantum algorithms\nwith quantum state inputs to classical algorithms with access to measurement\ndata on quantum states, the landscape of quantum advantage can be dramatically\ndifferent.",
    "descriptor": "\nComments: 6 pages, 1 figure\n",
    "authors": [
      "Jordan Cotler",
      "Hsin-Yuan Huang",
      "Jarrod R. McClean"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00811"
  },
  {
    "id": "arXiv:2112.00838",
    "title": "Convergence of batch Greenkhorn for Regularized Multimarginal Optimal  Transport",
    "abstract": "In this work we propose a batch version of the Greenkhorn algorithm for\nmultimarginal regularized optimal transport problems. Our framework is general\nenough to cover, as particular cases, some existing algorithms like Sinkhorn\nand Greenkhorn algorithm for the bi-marginal setting, and (greedy)\nMultiSinkhorn for multimarginal optimal transport. We provide a complete\nconverge analysis, which is based on the properties of the iterative Bregman\nprojections (IBP) method with greedy control. Global linear rate of convergence\nand explicit bound on the iteration complexity are obtained. When specialized\nto above mentioned algorithms, our results give new insights and/or improve\nexisting ones.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Vladimir Kostic",
      "Saverio Salzo",
      "Massimilano Pontil"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.00838"
  },
  {
    "id": "arXiv:2112.00851",
    "title": "The Physics of Machine Learning: An Intuitive Introduction for the  Physical Scientist",
    "abstract": "This article is intended for physical scientists who wish to gain deeper\ninsights into machine learning algorithms which we present via the domain they\nknow best, physics. We begin with a review of two energy-based machine learning\nalgorithms, Hopfield networks and Boltzmann machines, and their connection to\nthe Ising model. This serves as a foundation to understand the phenomenon of\nlearning more generally. Equipped with this intuition we then delve into\nadditional, more \"practical,\" machine learning architectures including\nfeedforward neural networks, convolutional neural networks, and autoencoders.\nWe also provide code that explicitly demonstrates training a neural network\nwith gradient descent.",
    "descriptor": "\nComments: 22 pages, 14 figures. Accompanying Jupyter notebook available at this https URL\n",
    "authors": [
      "Stephon Alexander",
      "Sarah Bawabe",
      "Batia Friedman-Shaw",
      "Michael W. Toomey"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00851"
  },
  {
    "id": "arXiv:2112.00882",
    "title": "Robust and Adaptive Temporal-Difference Learning Using An Ensemble of  Gaussian Processes",
    "abstract": "Value function approximation is a crucial module for policy evaluation in\nreinforcement learning when the state space is large or continuous. The present\npaper takes a generative perspective on policy evaluation via\ntemporal-difference (TD) learning, where a Gaussian process (GP) prior is\npresumed on the sought value function, and instantaneous rewards are\nprobabilistically generated based on value function evaluations at two\nconsecutive states. Capitalizing on a random feature-based approximant of the\nGP prior, an online scalable (OS) approach, termed {OS-GPTD}, is developed to\nestimate the value function for a given policy by observing a sequence of\nstate-reward pairs. To benchmark the performance of OS-GPTD even in an\nadversarial setting, where the modeling assumptions are violated, complementary\nworst-case analyses are performed by upper-bounding the cumulative Bellman\nerror as well as the long-term reward prediction error, relative to their\ncounterparts from a fixed value function estimator with the entire state-reward\ntrajectory in hindsight. Moreover, to alleviate the limited expressiveness\nassociated with a single fixed kernel, a weighted ensemble (E) of GP priors is\nemployed to yield an alternative scheme, termed OS-EGPTD, that can jointly\ninfer the value function, and select interactively the EGP kernel on-the-fly.\nFinally, performances of the novel OS-(E)GPTD schemes are evaluated on two\nbenchmark problems.",
    "descriptor": "",
    "authors": [
      "Qin Lu",
      "Georgios B. Giannakis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00882"
  },
  {
    "id": "arXiv:2112.00913",
    "title": "CDLNet: Noise-Adaptive Convolutional Dictionary Learning Network for  Blind Denoising and Demosaicing",
    "abstract": "Deep learning based methods hold state-of-the-art results in low-level image\nprocessing tasks, but remain difficult to interpret due to their black-box\nconstruction. Unrolled optimization networks present an interpretable\nalternative to constructing deep neural networks by deriving their architecture\nfrom classical iterative optimization methods without use of tricks from the\nstandard deep learning tool-box. So far, such methods have demonstrated\nperformance close to that of state-of-the-art models while using their\ninterpretable construction to achieve a comparably low learned parameter count.\nIn this work, we propose an unrolled convolutional dictionary learning network\n(CDLNet) and demonstrate its competitive denoising and joint denoising and\ndemosaicing (JDD) performance both in low and high parameter count regimes.\nSpecifically, we show that the proposed model outperforms state-of-the-art\nfully convolutional denoising and JDD models when scaled to a similar parameter\ncount. In addition, we leverage the model's interpretable construction to\npropose a noise-adaptive parameterization of thresholds in the network that\nenables state-of-the-art blind denoising performance, and near perfect\ngeneralization on noise-levels unseen during training. Furthermore, we show\nthat such performance extends to the JDD task and unsupervised learning.",
    "descriptor": "",
    "authors": [
      "Nikola Janju\u0161evi\u0107",
      "Amirhossein Kalilian-Gourtani",
      "Yao Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00913"
  },
  {
    "id": "arXiv:2112.01023",
    "title": "A higher order Minkowski loss for improved prediction ability of  acoustic model in ASR",
    "abstract": "Conventional automatic speech recognition (ASR) system uses second-order\nminkowski loss during inference time which is suboptimal as it incorporates\nonly first order statistics in posterior estimation [2]. In this paper we have\nproposed higher order minkowski loss (4th Order and 6th Order) during inference\ntime, without any changes during training time. The main contribution of the\npaper is to show that higher order loss uses higher order statistics in\nposterior estimation, which improves the prediction ability of acoustic model\nin ASR system. We have shown mathematically that posterior probability obtained\ndue to higher order loss is function of second order posterior and thus the\nmethod can be incorporated in standard ASR system in an easy manner. It is to\nbe noted that all changes are proposed during test(inference) time, we do not\nmake any change in any training pipeline. Multiple baseline systems namely,\nTDNN1, TDNN2, DNN and LSTM are developed to verify the improvement incurred due\nto higher order minkowski loss. All experiments are conducted on LibriSpeech\ndataset and performance metrics are word error rate (WER) on \"dev-clean\",\n\"test-clean\", \"dev-other\" and \"test-other\" datasets.",
    "descriptor": "",
    "authors": [
      "Vishwanath Pratap Singh",
      "Shakti P. Rath",
      "Abhishek Pandey"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.01023"
  },
  {
    "id": "arXiv:2112.01025",
    "title": "A Mixture of Expert Based Deep Neural Network for Improved ASR",
    "abstract": "This paper presents a novel deep learning architecture for acoustic model in\nthe context of Automatic Speech Recognition (ASR), termed as MixNet. Besides\nthe conventional layers, such as fully connected layers in DNN-HMM and memory\ncells in LSTM-HMM, the model uses two additional layers based on Mixture of\nExperts (MoE). The first MoE layer operating at the input is based on\npre-defined broad phonetic classes and the second layer operating at the\npenultimate layer is based on automatically learned acoustic classes. In\nnatural speech, overlap in distribution across different acoustic classes is\ninevitable, which leads to inter-class mis-classification. The ASR accuracy is\nexpected to improve if the conventional architecture of acoustic model is\nmodified to make them more suitable to account for such overlaps. MixNet is\ndeveloped keeping this in mind. Analysis conducted by means of scatter diagram\nverifies that MoE indeed improves the separation between classes that\ntranslates to better ASR accuracy. Experiments are conducted on a large\nvocabulary ASR task which show that the proposed architecture provides 13.6%\nand 10.0% relative reduction in word error rates compared to the conventional\nmodels, namely, DNN and LSTM respectively, trained using sMBR criteria. In\ncomparison to an existing method developed for phone-classification (by Eigen\net al), our proposed method yields a significant improvement.",
    "descriptor": "",
    "authors": [
      "Vishwanath Pratap Singh",
      "Shakti P. Rath",
      "Abhishek Pandey"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.01025"
  },
  {
    "id": "arXiv:2112.01067",
    "title": "Optimal Control of the Kirchhoff Equation",
    "abstract": "We consider an optimal control problem for the steady-state Kirchhoff\nequation, a prototype for nonlocal partial differential equations, different\nfrom fractional powers of closed operators. Existence and uniqueness of\nsolutions of the state equation, existence of global optimal solutions,\ndifferentiability of the control-to-state map and first-order necessary\noptimality conditions are established. The aforementioned results require the\ncontrols to be functions in $H^1$ and subject to pointwise upper and lower\nbounds. In order to obtain the Newton differentiability of the optimality\nconditions, we employ a Moreau-Yosida-type penalty approach to treat the\ncontrol constraints and study its convergence. The first-order optimality\nconditions of the regularized problems are shown to be Newton diffentiable, and\na generalized Newton method is detailed. A discretization of the optimal\ncontrol problem by piecewise linear finite elements is proposed and numerical\nresults are presented.",
    "descriptor": "",
    "authors": [
      "Masoumeh Hashemi",
      "Roland Herzog",
      "Thomas M. Surowiec"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.01067"
  },
  {
    "id": "arXiv:2112.01069",
    "title": "Tactical cooperation of defectors in a multi-stage public goods game",
    "abstract": "The basic social dilemma is frequently captured by a public goods game where\nparticipants decide simultaneously whether to support a common pool or not and\nafter the enhanced contributions are distributed uniformly among all\ncompetitors. What if the result of common efforts is {\\it not} distributed\nimmediately, but it is reinvested and added to the pool for a next round? This\nextension may not only result in an enhanced benefit for group members but also\nopens new strategies for involved players because they may act in distinct\nrounds differently. In this work we focus on the simplest case when two rounds\nare considered, but the applied multiplication factors dedicated to a certain\nround can be different. We show that in structured populations the winning\nstrategy may depend sensitively on the ratio of these factors and the last\nround has a special importance to reach a fully cooperative state. We also\nobserve that it may pay for defectors to support the first round and after\nenjoy the extra benefit of accumulated contributions. Full cooperator strategy\nis only viable if the second round ensures a premium benefit of investments.",
    "descriptor": "\nComments: 9 pages, 6 figures, accepted for publication in Chaos Solitons and Fractals\n",
    "authors": [
      "Attila Szolnoki",
      "Xiaojie Chen"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computer Science and Game Theory (cs.GT)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2112.01069"
  },
  {
    "id": "arXiv:2112.01095",
    "title": "On the Dominant of the Multicut Polytope",
    "abstract": "Given a graph $G=(V,E)$ and a set $S \\subseteq \\binom{V}{2}$ of terminal\npairs, the minimum multicut problem asks for a minimum edge set $\\delta\n\\subseteq E$ such that there is no $s$-$t$-path in $G -\\delta$ for any\n$\\{s,t\\}\\in S$. For $|S|=1$ this is the well known $s$-$t$-cut problem, but in\ngeneral the minimum multicut problem is NP-complete, even if the input graph is\na tree. The multicut polytope $\\text{MultC}^\\square (G,S)$ is the convex hull\nof all multicuts in $G$; the multicut dominant is given by\n$\\text{MultC}(G,S)=\\text{MultC}^\\square (G,S)+\\mathbb{R}^E$. The latter is the\nrelevant object for the minimization problem. While polyhedra associated to\nseveral cut problems have been studied intensively there is only little\nknowledge for multicut.\nWe investigate properties of the multicut dominant and in particular derive\nresults on liftings of facet-defining inequalities. This yields a\nclassification of all facet-defining path- and edge inequalities. Moreover, we\ninvestigate the effect of graph operations such as node splitting, edge\nsubdivisions, and edge contractions on the multicut-dominant and its\nfacet-defining inequalities. In addition, we introduce facet-defining\ninequalities supported on stars, trees, and cycles and show that the former two\ncan be separated in polynomial time when the input graph is a tree.",
    "descriptor": "\nComments: 28 pages, 5 figures\n",
    "authors": [
      "Markus Chimani",
      "Martina Juhnke-Kubitzke",
      "Alexander Nover"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.01095"
  },
  {
    "id": "arXiv:2112.01118",
    "title": "Near-Optimal Lower Bounds For Convex Optimization For All Orders of  Smoothness",
    "abstract": "We study the complexity of optimizing highly smooth convex functions. For a\npositive integer $p$, we want to find an $\\epsilon$-approximate minimum of a\nconvex function $f$, given oracle access to the function and its first $p$\nderivatives, assuming that the $p$th derivative of $f$ is Lipschitz.\nRecently, three independent research groups (Jiang et al., PLMR 2019;\nGasnikov et al., PLMR 2019; Bubeck et al., PLMR 2019) developed a new algorithm\nthat solves this problem with $\\tilde{O}(1/\\epsilon^{\\frac{2}{3p+1}})$ oracle\ncalls for constant $p$. This is known to be optimal (up to log factors) for\ndeterministic algorithms, but known lower bounds for randomized algorithms do\nnot match this bound. We prove a new lower bound that matches this bound (up to\nlog factors), and holds not only for randomized algorithms, but also for\nquantum algorithms.",
    "descriptor": "\nComments: To be presented as a spotlight talk at NeurIPS 2021\n",
    "authors": [
      "Ankit Garg",
      "Robin Kothari",
      "Praneeth Netrapalli",
      "Suhail Sherif"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01118"
  },
  {
    "id": "arXiv:2112.01137",
    "title": "Deep Learning-Based Carotid Artery Vessel Wall Segmentation in  Black-Blood MRI Using Anatomical Priors",
    "abstract": "Carotid artery vessel wall thickness measurement is an essential step in the\nmonitoring of patients with atherosclerosis. This requires accurate\nsegmentation of the vessel wall, i.e., the region between an artery's lumen and\nouter wall, in black-blood magnetic resonance (MR) images. Commonly used\nconvolutional neural networks (CNNs) for semantic segmentation are suboptimal\nfor this task as their use does not guarantee a contiguous ring-shaped\nsegmentation. Instead, in this work, we cast vessel wall segmentation as a\nmulti-task regression problem in a polar coordinate system. For each carotid\nartery in each axial image slice, we aim to simultaneously find two\nnon-intersecting nested contours that together delineate the vessel wall. CNNs\napplied to this problem enable an inductive bias that guarantees ring-shaped\nvessel walls. Moreover, we identify a problem-specific training data\naugmentation technique that substantially affects segmentation performance. We\napply our method to segmentation of the internal and external carotid artery\nwall, and achieve top-ranking quantitative results in a public challenge, i.e.,\na median Dice similarity coefficient of 0.813 for the vessel wall and median\nHausdorff distances of 0.552 mm and 0.776 mm for lumen and outer wall,\nrespectively. Moreover, we show how the method improves over a conventional\nsemantic segmentation approach. These results show that it is feasible to\nautomatically obtain anatomically plausible segmentations of the carotid vessel\nwall with high accuracy.",
    "descriptor": "\nComments: SPIE Medical Imaging 2022\n",
    "authors": [
      "Dieuwertje Alblas",
      "Christoph Brune",
      "Jelmer M. Wolterink"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01137"
  },
  {
    "id": "arXiv:2112.01140",
    "title": "On the computational complexity of the Steiner $k$-eccentricity",
    "abstract": "The Steiner $k$-eccentricity of a vertex $v$ of a graph $G$ is the maximum\nSteiner distance over all $k$-subsets of $V (G)$ which contain $v$. A linear\ntime algorithm for calculating the Steiner $k$-eccentricity of a vertex on\nblock graphs is presented. For general graphs, an $O(n^{\\nu(G)+1}(n(G) + m(G) +\nk))$ algorithm is designed, where $\\nu(G)$ is the cyclomatic number of $G$. A\nlinear algorithm for computing the Steiner $3$-eccentricities of all vertices\nof a tree is also presented which improves the quadratic algorithm from\n[Discrete Appl.\\ Math.\\ 304 (2021) 181--195].",
    "descriptor": "",
    "authors": [
      "Xingfu Li",
      "Guihai Yu",
      "Aleksandar Ili\u0107",
      "Sandi Klav\u017ear"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.01140"
  },
  {
    "id": "arXiv:2112.01166",
    "title": "Forex Trading Volatility Prediction using NeuralNetwork Models",
    "abstract": "In this paper, we investigate the problem of predicting the future volatility\nof Forex currency pairs using the deep learning techniques. We show\nstep-by-step how to construct the deep-learning network by the guidance of the\nempirical patterns of the intra-day volatility. The numerical results show that\nthe multiscale Long Short-Term Memory (LSTM) model with the input of\nmulti-currency pairs consistently achieves the state-of-the-art accuracy\ncompared with both the conventional baselines, i.e. autoregressive and GARCH\nmodel, and the other deep learning models.",
    "descriptor": "",
    "authors": [
      "Shujian Liao",
      "Jian Chen",
      "Hao Ni"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01166"
  },
  {
    "id": "arXiv:2112.01221",
    "title": "Analyzing High-Resolution Clouds and Convection using Multi-Channel VAEs",
    "abstract": "Understanding the details of small-scale convection and storm formation is\ncrucial to accurately represent the larger-scale planetary dynamics. Presently,\natmospheric scientists run high-resolution, storm-resolving simulations to\ncapture these kilometer-scale weather details. However, because they contain\nabundant information, these simulations can be overwhelming to analyze using\nconventional approaches. This paper takes a data-driven approach and jointly\nembeds spatial arrays of vertical wind velocities, temperatures, and water\nvapor information as three \"channels\" of a VAE architecture. Our \"multi-channel\nVAE\" results in more interpretable and robust latent structures than earlier\nwork analyzing vertical velocities in isolation. Analyzing and clustering the\nVAE's latent space identifies weather patterns and their geographical\nmanifestations in a fully unsupervised fashion. Our approach shows that VAEs\ncan play essential roles in analyzing high-dimensional simulation data and\nextracting critical weather and climate characteristics.",
    "descriptor": "\nComments: 4 Pages, 3 Figures. Accepted to NeurIPS 2021 (Machine Learning and Physical Sciences)\n",
    "authors": [
      "Harshini Mangipudi",
      "Griffin Mooers",
      "Mike Pritchard",
      "Tom Beucler",
      "Stephan Mandt"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01221"
  },
  {
    "id": "arXiv:2112.01288",
    "title": "How to quantify fields or textures? A guide to the scattering transform",
    "abstract": "Extracting information from stochastic fields or textures is a ubiquitous\ntask in science, from exploratory data analysis to classification and parameter\nestimation. From physics to biology, it tends to be done either through a power\nspectrum analysis, which is often too limited, or the use of convolutional\nneural networks (CNNs), which require large training sets and lack\ninterpretability. In this paper, we advocate for the use of the scattering\ntransform (Mallat 2012), a powerful statistic which borrows mathematical ideas\nfrom CNNs but does not require any training, and is interpretable. We show that\nit provides a relatively compact set of summary statistics with visual\ninterpretation and which carries most of the relevant information in a wide\nrange of scientific applications. We present a non-technical introduction to\nthis estimator and we argue that it can benefit data analysis, comparison to\nmodels and parameter inference in many fields of science. Interestingly,\nunderstanding the core operations of the scattering transform allows one to\ndecipher many key aspects of the inner workings of CNNs.",
    "descriptor": "\nComments: 18 pages, 16 figures\n",
    "authors": [
      "Sihao Cheng",
      "Brice M\u00e9nard"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2112.01288"
  },
  {
    "id": "arXiv:2112.01320",
    "title": "Multi-task fusion for improving mammography screening data  classification",
    "abstract": "Machine learning and deep learning methods have become essential for\ncomputer-assisted prediction in medicine, with a growing number of applications\nalso in the field of mammography. Typically these algorithms are trained for a\nspecific task, e.g., the classification of lesions or the prediction of a\nmammogram's pathology status. To obtain a comprehensive view of a patient,\nmodels which were all trained for the same task(s) are subsequently ensembled\nor combined. In this work, we propose a pipeline approach, where we first train\na set of individual, task-specific models and subsequently investigate the\nfusion thereof, which is in contrast to the standard model ensembling strategy.\nWe fuse model predictions and high-level features from deep learning models\nwith hybrid patient models to build stronger predictors on patient level. To\nthis end, we propose a multi-branch deep learning model which efficiently fuses\nfeatures across different tasks and mammograms to obtain a comprehensive\npatient-level prediction. We train and evaluate our full pipeline on public\nmammography data, i.e., DDSM and its curated version CBIS-DDSM, and report an\nAUC score of 0.962 for predicting the presence of any lesion and 0.791 for\npredicting the presence of malignant lesions on patient level. Overall, our\nfusion approaches improve AUC scores significantly by up to 0.04 compared to\nstandard model ensembling. Moreover, by providing not only global patient-level\npredictions but also task-specific model results that are related to\nradiological features, our pipeline aims to closely support the reading\nworkflow of radiologists.",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Maria Wimmer",
      "Gert Sluiter",
      "David Major",
      "Dimitrios Lenis",
      "Astrid Berg",
      "Theresa Neubauer",
      "Katja B\u00fchler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01320"
  },
  {
    "id": "arXiv:2112.01327",
    "title": "A modified limited memory Nesterov's accelerated quasi-Newton",
    "abstract": "The Nesterov's accelerated quasi-Newton (L)NAQ method has shown to accelerate\nthe conventional (L)BFGS quasi-Newton method using the Nesterov's accelerated\ngradient in several neural network (NN) applications. However, the calculation\nof two gradients per iteration increases the computational cost. The Momentum\naccelerated Quasi-Newton (MoQ) method showed that the Nesterov's accelerated\ngradient can be approximated as a linear combination of past gradients. This\nabstract extends the MoQ approximation to limited memory NAQ and evaluates the\nperformance on a function approximation problem.",
    "descriptor": "\nComments: Abstract presented at the NOLTA Society Conference, IEICE, Japan\n",
    "authors": [
      "S. Indrapriyadarsini",
      "Shahrzad Mahboubi",
      "Hiroshi Ninomiya",
      "Takeshi Kamio",
      "Hideki Asai"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01327"
  },
  {
    "id": "arXiv:2112.01363",
    "title": "Breaking the Convergence Barrier: Optimization via Fixed-Time Convergent  Flows",
    "abstract": "Accelerated gradient methods are the cornerstones of large-scale, data-driven\noptimization problems that arise naturally in machine learning and other fields\nconcerning data analysis. We introduce a gradient-based optimization framework\nfor achieving acceleration, based on the recently introduced notion of\nfixed-time stability of dynamical systems. The method presents itself as a\ngeneralization of simple gradient-based methods suitably scaled to achieve\nconvergence to the optimizer in a fixed-time, independent of the\ninitialization. We achieve this by first leveraging a continuous-time framework\nfor designing fixed-time stable dynamical systems, and later providing a\nconsistent discretization strategy, such that the equivalent discrete-time\nalgorithm tracks the optimizer in a practically fixed number of iterations. We\nalso provide a theoretical analysis of the convergence behavior of the proposed\ngradient flows, and their robustness to additive disturbances for a range of\nfunctions obeying strong convexity, strict convexity, and possibly nonconvexity\nbut satisfying the Polyak-{\\L}ojasiewicz inequality. We also show that the\nregret bound on the convergence rate is constant by virtue of the fixed-time\nconvergence. The hyperparameters have intuitive interpretations and can be\ntuned to fit the requirements on the desired convergence rates. We validate the\naccelerated convergence properties of the proposed schemes on a range of\nnumerical examples against the state-of-the-art optimization algorithms. Our\nwork provides insights on developing novel optimization algorithms via\ndiscretization of continuous-time flows.",
    "descriptor": "\nComments: Accepted at AAAI Conference on Artificial Intelligence, 2022, to appear\n",
    "authors": [
      "Param Budhraja",
      "Mayank Baranwal",
      "Kunal Garg",
      "Ashish Hota"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.01363"
  },
  {
    "id": "arXiv:2112.01369",
    "title": "The Classic Cross-Correlation and the Real-Valued Jaccard and  Coincidence Indices",
    "abstract": "In this work we describe and compare the classic inner product and Pearson\ncorrelation coefficient as well as the recently introduced real-valued Jaccard\nand coincidence indices. Special attention is given to diverse schemes for\ntaking into account the signs of the operands, as well as on the study of the\ngeometry of the scalar field surface related to the generalized multiset binary\noperations underling the considered similarity indices. The possibility to\nsplit the classic inner product, cross-correlation, and Pearson correlation\ncoefficient is also described.",
    "descriptor": "\nComments: 9 pages, 8 figure. A preprint\n",
    "authors": [
      "Luciano da F. Costa"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.01369"
  },
  {
    "id": "arXiv:2112.01372",
    "title": "Hierarchical clustering: visualization, feature importance and model  selection",
    "abstract": "We propose methods for the analysis of hierarchical clustering that fully use\nthe multi-resolution structure provided by a dendrogram. Specifically, we\npropose a loss for choosing between clustering methods, a feature importance\nscore and a graphical tool for visualizing the segmentation of features in a\ndendrogram. Current approaches to these tasks lead to loss of information since\nthey require the user to generate a single partition of the instances by\ncutting the dendrogram at a specified level. Our proposed methods, instead, use\nthe full structure of the dendrogram. The key insight behind the proposed\nmethods is to view a dendrogram as a phylogeny. This analogy permits the\nassignment of a feature value to each internal node of a tree through ancestral\nstate reconstruction. Real and simulated datasets provide evidence that our\nproposed framework has desirable outcomes. We provide an R package that\nimplements our methods.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Luben M. C. Cabezas",
      "Rafael Izbicki",
      "Rafael B. Stern"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01372"
  },
  {
    "id": "arXiv:2112.01374",
    "title": "On the optimization of hyperparameters in Gaussian process regression",
    "abstract": "When the data are sparse, optimization of hyperparameters of the kernel in\nGaussian process regression by the commonly used maximum likelihood estimation\n(MLE) criterion often leads to overfitting. We show that choosing\nhyperparameters based on a criterion of the completeness of the basis in the\ncorresponding linear regression problem is superior to MLE. We show that this\nis facilitated by the use of High-dimensional model representation whereby a\nlow-order HDMR representation can provide reliable reference functions and\nlarge synthetic test data sets needed for basis parameter optimization even\nwith few data.",
    "descriptor": "\nComments: 14 pages, 2 figures, 2 tables\n",
    "authors": [
      "Sergei Manzhos",
      "Manabu Ihara"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.01374"
  },
  {
    "id": "arXiv:2112.01377",
    "title": "Structural Sieves",
    "abstract": "This paper explores the use of deep neural networks for semiparametric\nestimation of economic models of maximizing behavior in production or discrete\nchoice. We argue that certain deep networks are particularly well suited as a\nnonparametric sieve to approximate regression functions that result from\nnonlinear latent variable models of continuous or discrete optimization.\nMulti-stage models of this type will typically generate rich interaction\neffects between regressors (\"inputs\") in the regression function so that there\nmay be no plausible separability restrictions on the \"reduced-form\" mapping\nform inputs to outputs to alleviate the curse of dimensionality. Rather,\neconomic shape, sparsity, or separability restrictions either at a global level\nor intermediate stages are usually stated in terms of the latent variable\nmodel. We show that restrictions of this kind are imposed in a more\nstraightforward manner if a sufficiently flexible version of the latent\nvariable model is in fact used to approximate the unknown regression function.",
    "descriptor": "",
    "authors": [
      "Konrad Menzel"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.01377"
  },
  {
    "id": "arXiv:2112.01386",
    "title": "Relativistic zero-knowledge protocol for NP over the internet  unconditionally secure against quantum adversaries",
    "abstract": "Relativistic cryptography is a proposal for achieving unconditional security\nthat exploits the fact that no information carrier can travel faster than the\nspeed of light. It is based on space-time constraints but doesn't require\nquantum hardware. Nevertheless, it was unclear whether this proposal is\nrealistic or not. Recently, Alikhani et al. [ABC+21] performed an\nimplementation of a relativistic zero-knowledge for NP. Their implemented\nscheme shows the feasibility of relativistic cryptography but it is only secure\nagainst classical adversaries. In this work, we present a new relativistic\nprotocol for NP which is secure against quantum adversaries and which is\nefficient enough so that it can be implemented on everyday laptops and internet\nconnections. We use Stern's zero-knowledge scheme for the Syndrome Decoding\nproblem, which was used before in post-quantum cryptography. The main technical\ncontribution is a generalization of the consecutive measurement framework of\n[CL17] to prove the security of our scheme against quantum adversaries, and we\nperform an implementation that demonstrates the feasibility and efficiency of\nour proposed scheme.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Chailloux",
      "Yann Barsamian"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.01386"
  },
  {
    "id": "arXiv:2112.01387",
    "title": "Generalizing Off-Policy Learning under Sample Selection Bias",
    "abstract": "Learning personalized decision policies that generalize to the target\npopulation is of great relevance. Since training data is often not\nrepresentative of the target population, standard policy learning methods may\nyield policies that do not generalize target population. To address this\nchallenge, we propose a novel framework for learning policies that generalize\nto the target population. For this, we characterize the difference between the\ntraining data and the target population as a sample selection bias using a\nselection variable. Over an uncertainty set around this selection variable, we\noptimize the minimax value of a policy to achieve the best worst-case policy\nvalue on the target population. In order to solve the minimax problem, we\nderive an efficient algorithm based on a convex-concave procedure and prove\nconvergence for parametrized spaces of policies such as logistic policies. We\nprove that, if the uncertainty set is well-specified, our policies generalize\nto the target population as they can not do worse than on the training data.\nUsing simulated data and a clinical trial, we demonstrate that, compared to\nstandard policy learning methods, our framework improves the generalizability\nof policies substantially.",
    "descriptor": "",
    "authors": [
      "Tobias Hatt",
      "Daniel Tschernutter",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01387"
  },
  {
    "id": "arXiv:2112.01496",
    "title": "Analysis of an adaptive lead weighted ResNet for multiclass  classification of 12-lead ECGs",
    "abstract": "Background: Twelve lead ECGs are a core diagnostic tool for cardiovascular\ndiseases. Here, we describe and analyse an ensemble deep neural network\narchitecture to classify 24 cardiac abnormalities from 12-lead ECGs.\nMethod: We proposed a squeeze and excite ResNet to automatically learn deep\nfeatures from 12-lead ECGs, in order to identify 24 cardiac conditions. The\ndeep features were augmented with age and gender features in the final fully\nconnected layers. Output thresholds for each class were set using a constrained\ngrid search. To determine why the model made incorrect predictions, two expert\nclinicians independently interpreted a random set of 100 misclassified ECGs\nconcerning Left Axis Deviation.\nResults: Using the bespoke weighted accuracy metric, we achieved a 5-fold\ncross validation score of 0.684, and sensitivity and specificity of 0.758 and\n0.969, respectively. We scored 0.520 on the full test data, and ranked 2nd out\nof 41 in the official challenge rankings. On a random set of misclassified\nECGs, agreement between two clinicians and training labels was poor (clinician\n1: kappa = -0.057, clinician 2: kappa = -0.159). In contrast, agreement between\nthe clinicians was very high (kappa = 0.92).\nDiscussion: The proposed prediction model performed well on the validation\nand hidden test data in comparison to models trained on the same data. We also\ndiscovered considerable inconsistency in training labels, which is likely to\nhinder development of more accurate models.",
    "descriptor": "\nComments: 13 pages, 4 Figure, 4 Tables. To be submitted to Physiological Measurement (special issue for Physionet Challenge)\n",
    "authors": [
      "Zhibin Zhao",
      "Darcy Murphy",
      "Hugh Gifford",
      "Stefan Williams",
      "Annie Darlington",
      "Samuel D. Relton",
      "Hui Fang",
      "David C. Wong"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01496"
  },
  {
    "id": "arXiv:1606.09549",
    "title": "Fully-Convolutional Siamese Networks for Object Tracking",
    "abstract": "Comments: The first two authors contributed equally, and are listed in alphabetical order. Code available at this http URL",
    "descriptor": "\nComments: The first two authors contributed equally, and are listed in alphabetical order. Code available at this http URL\n",
    "authors": [
      "Luca Bertinetto",
      "Jack Valmadre",
      "Jo\u00e3o F. Henriques",
      "Andrea Vedaldi",
      "Philip H. S. Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1606.09549"
  },
  {
    "id": "arXiv:1607.01205",
    "title": "Learning the semantic structure of objects from Web supervision",
    "abstract": "Learning the semantic structure of objects from Web supervision",
    "descriptor": "",
    "authors": [
      "David Novotny",
      "Diane Larlus",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1607.01205"
  },
  {
    "id": "arXiv:1703.00443",
    "title": "OptNet: Differentiable Optimization as a Layer in Neural Networks",
    "abstract": "Comments: ICML 2017",
    "descriptor": "\nComments: ICML 2017\n",
    "authors": [
      "Brandon Amos",
      "J. Zico Kolter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1703.00443"
  },
  {
    "id": "arXiv:1705.03951",
    "title": "Learning 3D Object Categories by Looking Around Them",
    "abstract": "Comments: Proceedings of the International Conference on Computer Vision, 2017",
    "descriptor": "\nComments: Proceedings of the International Conference on Computer Vision, 2017\n",
    "authors": [
      "David Novotny",
      "Diane Larlus",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1705.03951"
  },
  {
    "id": "arXiv:1706.05060",
    "title": "Undecidability of first-order modal and intuitionistic logics with two  variables and one monadic predicate letter",
    "abstract": "Comments: Corrected version of the paper published in Studia Logica, 107(2), 695-717 (2019). doi:10.1007/s11225-018-9815-7.},doi:10.1007/s11225-018-9815-7",
    "descriptor": "\nComments: Corrected version of the paper published in Studia Logica, 107(2), 695-717 (2019). doi:10.1007/s11225-018-9815-7.},doi:10.1007/s11225-018-9815-7\n",
    "authors": [
      "Mikhail Rybakov",
      "Dmitry Shkatov"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/1706.05060"
  },
  {
    "id": "arXiv:1804.00596",
    "title": "TacticToe: Learning to Prove with Tactics",
    "abstract": "TacticToe: Learning to Prove with Tactics",
    "descriptor": "",
    "authors": [
      "Thibault Gauthier",
      "Cezary Kaliszyk",
      "Josef Urban",
      "Ramana Kumar",
      "Michael Norrish"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1804.00596"
  },
  {
    "id": "arXiv:1811.06016",
    "title": "To bee or not to bee: Investigating machine learning approaches for  beehive sound recognition",
    "abstract": "Comments: Presented at Detection and Classification of Acoustic Scenes and Events (DCASE) workshop 2018",
    "descriptor": "\nComments: Presented at Detection and Classification of Acoustic Scenes and Events (DCASE) workshop 2018\n",
    "authors": [
      "In\u00eas Nolasco",
      "Emmanouil Benetos"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/1811.06016"
  },
  {
    "id": "arXiv:1901.10002",
    "title": "A Framework for Understanding Sources of Harm throughout the Machine  Learning Life Cycle",
    "abstract": "A Framework for Understanding Sources of Harm throughout the Machine  Learning Life Cycle",
    "descriptor": "",
    "authors": [
      "Harini Suresh",
      "John V. Guttag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1901.10002"
  },
  {
    "id": "arXiv:1902.00468",
    "title": "Multilevel Monte Carlo Variational Inference",
    "abstract": "Comments: 44pages, 10 figures; Journal of Machine Learning Research (JMLR)",
    "descriptor": "\nComments: 44pages, 10 figures; Journal of Machine Learning Research (JMLR)\n",
    "authors": [
      "Masahiro Fujisawa",
      "Issei Sato"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1902.00468"
  },
  {
    "id": "arXiv:1905.10395",
    "title": "Leader Stochastic Gradient Descent for Distributed Training of Deep  Learning Models: Extension",
    "abstract": "Comments: Extension of LSGD published in NeurIPS 2019. 24 pages",
    "descriptor": "\nComments: Extension of LSGD published in NeurIPS 2019. 24 pages\n",
    "authors": [
      "Yunfei Teng",
      "Wenbo Gao",
      "Francois Chalus",
      "Anna Choromanska",
      "Donald Goldfarb",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.10395"
  },
  {
    "id": "arXiv:1906.01756",
    "title": "Group Chat Ecology in Enterprise Instant Messaging: How Employees  Collaborate Through Multi-User Chat Channels on Slack",
    "abstract": "Comments: Accepted at ACM CSCW'22",
    "descriptor": "\nComments: Accepted at ACM CSCW'22\n",
    "authors": [
      "Dakuo Wang",
      "Haoyu Wang",
      "Mo Yu",
      "Zahra Ashktorab",
      "Ming Tan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1906.01756"
  },
  {
    "id": "arXiv:1906.08386",
    "title": "Inherent Tradeoffs in Learning Fair Representations",
    "abstract": "Comments: A new constructive algorithm for the optimal fair classifier; Extension of the previous lower bounds to a general setting",
    "descriptor": "\nComments: A new constructive algorithm for the optimal fair classifier; Extension of the previous lower bounds to a general setting\n",
    "authors": [
      "Han Zhao",
      "Geoffrey J. Gordon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.08386"
  },
  {
    "id": "arXiv:1909.02788",
    "title": "Lightweight Mediated Semi-Quantum Key Distribution Protocol with a  Dishonest Third Party based on Bell States",
    "abstract": "Lightweight Mediated Semi-Quantum Key Distribution Protocol with a  Dishonest Third Party based on Bell States",
    "descriptor": "",
    "authors": [
      "Chia-Wei Tsai",
      "Chun-Wei Yang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1909.02788"
  },
  {
    "id": "arXiv:1910.08293",
    "title": "ALOHA: Artificial Learning of Human Attributes for Dialogue Agents",
    "abstract": "Comments: AAAI 2020. Code available at this https URL Talk at this https URL&ab_channel=StevenFeng",
    "descriptor": "\nComments: AAAI 2020. Code available at this https URL Talk at this https URL&ab_channel=StevenFeng\n",
    "authors": [
      "Aaron W. Li",
      "Veronica Jiang",
      "Steven Y. Feng",
      "Julia Sprague",
      "Wei Zhou",
      "Jesse Hoey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1910.08293"
  },
  {
    "id": "arXiv:2001.07588",
    "title": "Vietoris-Rips Persistent Homology, Injective Metric Spaces, and The  Filling Radius",
    "abstract": "Comments: We added the following materials: (1) Stronger version of Hausmann's theorem for n-spheres and its proof (2) Simplicial proof of interval types of open VR filtration (3) Introduced a localized version of spread and gave examples (4) An example of one parameter family of deformations of the 2-sphere with constant filling radius",
    "descriptor": "\nComments: We added the following materials: (1) Stronger version of Hausmann's theorem for n-spheres and its proof (2) Simplicial proof of interval types of open VR filtration (3) Introduced a localized version of spread and gave examples (4) An example of one parameter family of deformations of the 2-sphere with constant filling radius\n",
    "authors": [
      "Sunhyuk Lim",
      "Facundo Memoli",
      "Osman Berat Okutan"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2001.07588"
  },
  {
    "id": "arXiv:2001.07641",
    "title": "Deceptive AI Explanations: Creation and Detection",
    "abstract": "Deceptive AI Explanations: Creation and Detection",
    "descriptor": "",
    "authors": [
      "Johannes Schneider",
      "Christian Meske",
      "Michalis Vlachos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.07641"
  },
  {
    "id": "arXiv:2002.00612",
    "title": "Adaptive strategy in differential evolution via explicit exploitation  and exploration controls",
    "abstract": "Adaptive strategy in differential evolution via explicit exploitation  and exploration controls",
    "descriptor": "",
    "authors": [
      "Sheng Xin Zhang",
      "Wing Shing Chan",
      "Kit Sang Tang",
      "Shao Yong Zheng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2002.00612"
  },
  {
    "id": "arXiv:2003.04883",
    "title": "Maximum Likelihood Speed Estimation of Moving Objects in Video Signals",
    "abstract": "Maximum Likelihood Speed Estimation of Moving Objects in Video Signals",
    "descriptor": "",
    "authors": [
      "Veronica Mattioli",
      "Davide Alinovi",
      "Riccardo Raheli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2003.04883"
  },
  {
    "id": "arXiv:2003.13777",
    "title": "Subgraph densities in a surface",
    "abstract": "Comments: v4: referee's comments implemented. v3: proof of the main theorem fully rewritten, fixes a serious error in the previous version found by Kevin Hendrey",
    "descriptor": "\nComments: v4: referee's comments implemented. v3: proof of the main theorem fully rewritten, fixes a serious error in the previous version found by Kevin Hendrey\n",
    "authors": [
      "Tony Huynh",
      "Gwena\u00ebl Joret",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2003.13777"
  },
  {
    "id": "arXiv:2004.13472",
    "title": "Linear Dependent Type Theory for Quantum Programming Languages",
    "abstract": "Linear Dependent Type Theory for Quantum Programming Languages",
    "descriptor": "",
    "authors": [
      "Peng Fu",
      "Kohei Kishida",
      "Peter Selinger"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2004.13472"
  },
  {
    "id": "arXiv:2005.00777",
    "title": "Deep Feature Mining via Attention-based BiLSTM-GCN for Human Motor  Imagery Recognition",
    "abstract": "Deep Feature Mining via Attention-based BiLSTM-GCN for Human Motor  Imagery Recognition",
    "descriptor": "",
    "authors": [
      "Yimin Hou",
      "Shuyue Jia",
      "Xiangmin Lun",
      "Shu Zhang",
      "Tao Chen",
      "Fang Wang",
      "Jinglei Lv"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.00777"
  },
  {
    "id": "arXiv:2005.08334",
    "title": "Marginal likelihood computation for model selection and hypothesis  testing: an extensive review",
    "abstract": "Comments: Keywords: Marginal likelihood, Bayesian evidence, numerical integration, model selection, hypothesis testing, quadrature rules, double-intractable posteriors, partition functions",
    "descriptor": "\nComments: Keywords: Marginal likelihood, Bayesian evidence, numerical integration, model selection, hypothesis testing, quadrature rules, double-intractable posteriors, partition functions\n",
    "authors": [
      "Fernando Llorente",
      "Luca Martino",
      "David Delgado",
      "Javier Lopez-Santiago"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.08334"
  },
  {
    "id": "arXiv:2005.12106",
    "title": "An intent-based approach for creating assistive robots' control systems",
    "abstract": "Comments: 6 pages, 8figures, The work was initially submitted to the 25th International Conference on Methods and Models in Automation and Robotics (MMAR) that was cancelled due to COVID-2019",
    "descriptor": "\nComments: 6 pages, 8figures, The work was initially submitted to the 25th International Conference on Methods and Models in Automation and Robotics (MMAR) that was cancelled due to COVID-2019\n",
    "authors": [
      "Tomasz Winiarski",
      "Wojciech Dudek",
      "Maciej Stefa\u0144czyk",
      "\u0141ukasz Zieli\u0144ski",
      "Daniel Gie\u0142dowski",
      "Dawid Seredy\u0144ski"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2005.12106"
  },
  {
    "id": "arXiv:2006.03196",
    "title": "Towards Better Driver Safety: Empowering Personal Navigation  Technologies with Road Safety Awareness",
    "abstract": "Comments: Submitted to Autonomous Intelligent System Journal",
    "descriptor": "\nComments: Submitted to Autonomous Intelligent System Journal\n",
    "authors": [
      "Runsheng Xu",
      "Shibo Zhang",
      "Yue Zhao",
      "Peixi Xiong",
      "Allen Yilun Lin",
      "Brent Hecht",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2006.03196"
  },
  {
    "id": "arXiv:2006.05371",
    "title": "Bayesian Probabilistic Numerical Integration with Tree-Based Models",
    "abstract": "Bayesian Probabilistic Numerical Integration with Tree-Based Models",
    "descriptor": "",
    "authors": [
      "Harrison Zhu",
      "Xing Liu",
      "Ruya Kang",
      "Zhichao Shen",
      "Seth Flaxman",
      "Fran\u00e7ois-Xavier Briol"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05371"
  },
  {
    "id": "arXiv:2006.08924",
    "title": "GCNs-Net: A Graph Convolutional Neural Network Approach for Decoding  Time-resolved EEG Motor Imagery Signals",
    "abstract": "GCNs-Net: A Graph Convolutional Neural Network Approach for Decoding  Time-resolved EEG Motor Imagery Signals",
    "descriptor": "",
    "authors": [
      "Yimin Hou",
      "Shuyue Jia",
      "Xiangmin Lun",
      "Shu Zhang",
      "Tao Chen",
      "Fang Wang",
      "Jinglei Lv"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2006.08924"
  },
  {
    "id": "arXiv:2007.03800",
    "title": "Efficient and Parallel Separable Dictionary Learning",
    "abstract": "Efficient and Parallel Separable Dictionary Learning",
    "descriptor": "",
    "authors": [
      "Cristian Rusu",
      "Paul Irofti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.03800"
  },
  {
    "id": "arXiv:2007.14247",
    "title": "Downlink channel access performance of NR-U: Impact of numerology and  mini-slots on coexistence with Wi-Fi in the 5 GHz band",
    "abstract": "Comments: 20 double-column single-spaced pages, 10 figures, 3 tables, 39 references, journal submission",
    "descriptor": "\nComments: 20 double-column single-spaced pages, 10 figures, 3 tables, 39 references, journal submission\n",
    "authors": [
      "Katarzyna Kosek-Szott",
      "Alice Lo Valvo",
      "Szymon Szott",
      "Pierluigi Gallo",
      "Ilenia Tinnirello"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2007.14247"
  },
  {
    "id": "arXiv:2007.14384",
    "title": "Noise-Induced Barren Plateaus in Variational Quantum Algorithms",
    "abstract": "Comments: 12+15 pages, 6+1 figures. Updated to published version",
    "descriptor": "\nComments: 12+15 pages, 6+1 figures. Updated to published version\n",
    "authors": [
      "Samson Wang",
      "Enrico Fontana",
      "M. Cerezo",
      "Kunal Sharma",
      "Akira Sone",
      "Lukasz Cincio",
      "Patrick J. Coles"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.14384"
  },
  {
    "id": "arXiv:2008.09052",
    "title": "On transversality of bent hyperplane arrangements and the topological  expressiveness of ReLU neural networks",
    "abstract": "Comments: 29 pages, 1 figure; exposition and notation streamlined from version 1; to appear in SIAM Journal on Applied Algebra and Geometry",
    "descriptor": "\nComments: 29 pages, 1 figure; exposition and notation streamlined from version 1; to appear in SIAM Journal on Applied Algebra and Geometry\n",
    "authors": [
      "J. Elisenda Grigsby",
      "Kathryn Lindsey"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2008.09052"
  },
  {
    "id": "arXiv:2008.09743",
    "title": "A Efficient Multimodal Framework for Large Scale Emotion Recognition by  Fusing Music and Electrodermal Activity Signals",
    "abstract": "Comments: ACM Transactions on Multimedia Computing, Communications, and Applications (Acceptance 07-Oct-2021)",
    "descriptor": "\nComments: ACM Transactions on Multimedia Computing, Communications, and Applications (Acceptance 07-Oct-2021)\n",
    "authors": [
      "Guanghao Yin",
      "Shouqian Sun",
      "Dian Yu",
      "Dejian Li",
      "Kejun Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.09743"
  },
  {
    "id": "arXiv:2009.02452",
    "title": "A Lower Bound on Determinantal Complexity",
    "abstract": "Comments: v2: corrected a few typos and added references",
    "descriptor": "\nComments: v2: corrected a few typos and added references\n",
    "authors": [
      "Mrinal Kumar",
      "Ben Lee Volk"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2009.02452"
  },
  {
    "id": "arXiv:2009.08906",
    "title": "Learning Unseen Emotions from Gestures via Semantically-Conditioned  Zero-Shot Perception with Adversarial Autoencoders",
    "abstract": "Learning Unseen Emotions from Gestures via Semantically-Conditioned  Zero-Shot Perception with Adversarial Autoencoders",
    "descriptor": "",
    "authors": [
      "Abhishek Banerjee",
      "Uttaran Bhattacharya",
      "Aniket Bera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.08906"
  },
  {
    "id": "arXiv:2009.12619",
    "title": "Enabling and Emerging Sensing Technologies for Crowd Management in  Public Transportation Systems: A Review",
    "abstract": "Comments: 15 pages, 2 figures, 2 tables, submitted to IEEE Sensors Journal",
    "descriptor": "\nComments: 15 pages, 2 figures, 2 tables, submitted to IEEE Sensors Journal\n",
    "authors": [
      "Donatella Darsena",
      "Giacinto Gelli",
      "Ivan Iudice",
      "Francesco Verde"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2009.12619"
  },
  {
    "id": "arXiv:2009.13772",
    "title": "Trust-Region Method with Deep Reinforcement Learning in Analog Design  Space Exploration",
    "abstract": "Comments: 6 pages, 3 figures, 5 tables",
    "descriptor": "\nComments: 6 pages, 3 figures, 5 tables\n",
    "authors": [
      "Kai-En Yang",
      "Chia-Yu Tsai",
      "Hung-Hao Shen",
      "Chen-Feng Chiang",
      "Feng-Ming Tsai",
      "Chung-An Wang",
      "Yiju Ting",
      "Chia-Shun Yeh",
      "Chin-Tang Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.13772"
  },
  {
    "id": "arXiv:2009.14539",
    "title": "Case-based Abductive Natural Language Inference",
    "abstract": "Case-based Abductive Natural Language Inference",
    "descriptor": "",
    "authors": [
      "Marco Valentino",
      "Mokanarangan Thayaparan",
      "Andr\u00e9 Freitas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.14539"
  },
  {
    "id": "arXiv:2010.03415",
    "title": "Knowledge-Based Learning of Nonlinear Dynamics and Chaos",
    "abstract": "Comments: 8 pages, 12 figures in main text, 6 figures and 8 tables in supplement",
    "descriptor": "\nComments: 8 pages, 12 figures in main text, 6 figures and 8 tables in supplement\n",
    "authors": [
      "Tom Z. Jiahao",
      "M. Ani Hsieh",
      "Eric Forgoston"
    ],
    "subjectives": [
      "Chaotic Dynamics (nlin.CD)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.03415"
  },
  {
    "id": "arXiv:2010.05125",
    "title": "Learning Task-aware Robust Deep Learning Systems",
    "abstract": "Comments: 9 Pages",
    "descriptor": "\nComments: 9 Pages\n",
    "authors": [
      "Keji Han",
      "Yun Li",
      "Xianzhong Long",
      "Yao Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.05125"
  },
  {
    "id": "arXiv:2010.08155",
    "title": "Interface Design and Task Difficulty Impact ML-Assisted Visual Data  Foraging",
    "abstract": "Interface Design and Task Difficulty Impact ML-Assisted Visual Data  Foraging",
    "descriptor": "",
    "authors": [
      "Shayan Monadjemi",
      "Sunwoo Ha",
      "Quan Nguyen",
      "Henry Chai",
      "Roman Garnett",
      "Alvitta Ottley"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2010.08155"
  },
  {
    "id": "arXiv:2010.09231",
    "title": "CT-CPP: Coverage Path Planning for 3D Terrain Reconstruction Using  Dynamic Coverage Trees",
    "abstract": "CT-CPP: Coverage Path Planning for 3D Terrain Reconstruction Using  Dynamic Coverage Trees",
    "descriptor": "",
    "authors": [
      "Zongyuan Shen",
      "Junnan Song",
      "Khushboo Mittal",
      "Shalabh Gupta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.09231"
  },
  {
    "id": "arXiv:2010.12784",
    "title": "Deep Clustering of Text Representations for Supervision-free Probing of  Syntax",
    "abstract": "Deep Clustering of Text Representations for Supervision-free Probing of  Syntax",
    "descriptor": "",
    "authors": [
      "Vikram Gupta",
      "Haoyue Shi",
      "Kevin Gimpel",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.12784"
  },
  {
    "id": "arXiv:2011.03107",
    "title": "Visibility Extension via Reflection",
    "abstract": "Comments: 32 pages, 10 figures",
    "descriptor": "\nComments: 32 pages, 10 figures\n",
    "authors": [
      "Arash Vaezi",
      "Bodhayan Roy",
      "Mohammad Ghodsi"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2011.03107"
  },
  {
    "id": "arXiv:2011.03293",
    "title": "On the Stability Properties and the Optimization Landscape of Training  Problems with Squared Loss for Neural Networks and General Nonlinear Conic  Approximation Schemes",
    "abstract": "Comments: Final version, Journal of Machine Learning Research, 22(263):1-77, 2021, this https URL",
    "descriptor": "\nComments: Final version, Journal of Machine Learning Research, 22(263):1-77, 2021, this https URL\n",
    "authors": [
      "Constantin Christof"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.03293"
  },
  {
    "id": "arXiv:2011.07442",
    "title": "Speech Enhancement Guided by Contextual Articulatory Information",
    "abstract": "Comments: Will be submitted to TASLP",
    "descriptor": "\nComments: Will be submitted to TASLP\n",
    "authors": [
      "Yen-Ju Lu",
      "Chia-Yu Chang",
      "Cheng Yu",
      "Jeih-weih Hung",
      "Shinji Watanabe",
      "Yu Tsao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2011.07442"
  },
  {
    "id": "arXiv:2011.14821",
    "title": "Discovering Causal Structure with Reproducing-Kernel Hilbert Space  $\u03b5$-Machines",
    "abstract": "Comments: 23 pages, 11 figures, 64 citations; this https URL",
    "descriptor": "\nComments: 23 pages, 11 figures, 64 citations; this https URL\n",
    "authors": [
      "Nicolas Brodu",
      "James P. Crutchfield"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.14821"
  },
  {
    "id": "arXiv:2012.01708",
    "title": "Feature-Based Software Design Pattern Detection",
    "abstract": "Comments: Accepted in Journal of Systems and Software (JSS)",
    "descriptor": "\nComments: Accepted in Journal of Systems and Software (JSS)\n",
    "authors": [
      "Najam Nazar",
      "Aldeida Aleti",
      "Yaokun Zheng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2012.01708"
  },
  {
    "id": "arXiv:2012.01920",
    "title": "Quantum learning algorithms imply circuit lower bounds",
    "abstract": "Quantum learning algorithms imply circuit lower bounds",
    "descriptor": "",
    "authors": [
      "Srinivasan Arunachalam",
      "Alex B. Grilo",
      "Tom Gur",
      "Igor C. Oliveira",
      "Aarthi Sundaram"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.01920"
  },
  {
    "id": "arXiv:2012.02282",
    "title": "Creativity of Deep Learning: Conceptualization and Assessment",
    "abstract": "Creativity of Deep Learning: Conceptualization and Assessment",
    "descriptor": "",
    "authors": [
      "Johannes Schneider",
      "Marcus Basalla"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.02282"
  },
  {
    "id": "arXiv:2012.03765",
    "title": "Certified Robustness of Nearest Neighbors against Data Poisoning and  Backdoor Attacks",
    "abstract": "Comments: To appear in AAAI Conference on Artificial Intelligence, 2022",
    "descriptor": "\nComments: To appear in AAAI Conference on Artificial Intelligence, 2022\n",
    "authors": [
      "Jinyuan Jia",
      "Yupei Liu",
      "Xiaoyu Cao",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.03765"
  },
  {
    "id": "arXiv:2012.10715",
    "title": "Multi-Label Noise Robust Collaborative Learning Model for Remote Sensing  Image Classification",
    "abstract": "Comments: Our code is publicly available online: this http URL",
    "descriptor": "\nComments: Our code is publicly available online: this http URL\n",
    "authors": [
      "Ahmet Kerem Aksoy",
      "Mahdyar Ravanbakhsh",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.10715"
  },
  {
    "id": "arXiv:2012.10959",
    "title": "Physical Implementability of Linear Maps and Its Application in Error  Mitigation",
    "abstract": "Comments: 25 pages, v2 accepted by Quantum",
    "descriptor": "\nComments: 25 pages, v2 accepted by Quantum\n",
    "authors": [
      "Jiaqing Jiang",
      "Kun Wang",
      "Xin Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "High Energy Physics - Theory (hep-th)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.10959"
  },
  {
    "id": "arXiv:2012.12687",
    "title": "Wasserstein Dropout",
    "abstract": "Wasserstein Dropout",
    "descriptor": "",
    "authors": [
      "Joachim Sicking",
      "Maram Akila",
      "Maximilian Pintz",
      "Tim Wirtz",
      "Asja Fischer",
      "Stefan Wrobel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.12687"
  },
  {
    "id": "arXiv:2012.14704",
    "title": "Advances in deep learning methods for pavement surface crack detection  and identification with visible light visual images",
    "abstract": "Comments: 15 pages, 14 figures, 11 tables",
    "descriptor": "\nComments: 15 pages, 14 figures, 11 tables\n",
    "authors": [
      "Kailiang Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2012.14704"
  },
  {
    "id": "arXiv:2101.01000",
    "title": "Conditional Local Convolution for Spatio-temporal Meteorological  Forecasting",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Haitao Lin",
      "Zhangyang Gao",
      "Yongjie Xu",
      "Lirong Wu",
      "Ling Li",
      "Stan. Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.01000"
  },
  {
    "id": "arXiv:2101.04378",
    "title": "Rethinking Interactive Image Segmentation: Feature Space Annotation",
    "abstract": "Rethinking Interactive Image Segmentation: Feature Space Annotation",
    "descriptor": "",
    "authors": [
      "Jord{\u00e3}o Bragantini",
      "Alexandre Falc{\u00e3}o",
      "Laurent Najman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.04378"
  },
  {
    "id": "arXiv:2101.09163",
    "title": "The Next Decade of Telecommunications Artificial Intelligence",
    "abstract": "Comments: 19 pages, in Chinese, 24 figures",
    "descriptor": "\nComments: 19 pages, in Chinese, 24 figures\n",
    "authors": [
      "Ye Ouyang",
      "Lilei Wang",
      "Aidong Yang",
      "Maulik Shah",
      "David Belanger",
      "Tongqing Gao",
      "Leping Wei",
      "Yaqin Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.09163"
  },
  {
    "id": "arXiv:2101.09583",
    "title": "Communication-Efficient Variance-Reduced Decentralized Stochastic  Optimization over Time-Varying Directed Graphs",
    "abstract": "Communication-Efficient Variance-Reduced Decentralized Stochastic  Optimization over Time-Varying Directed Graphs",
    "descriptor": "",
    "authors": [
      "Yiyue Chen",
      "Abolfazl Hashemi",
      "Haris Vikalo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.09583"
  },
  {
    "id": "arXiv:2102.03064",
    "title": "\"I Don't Think So\": Summarizing Policy Disagreements for Agent  Comparison",
    "abstract": "\"I Don't Think So\": Summarizing Policy Disagreements for Agent  Comparison",
    "descriptor": "",
    "authors": [
      "Yotam Amitai",
      "Ofra Amir"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.03064"
  },
  {
    "id": "arXiv:2102.04906",
    "title": "Dynamic Neural Networks: A Survey",
    "abstract": "Dynamic Neural Networks: A Survey",
    "descriptor": "",
    "authors": [
      "Yizeng Han",
      "Gao Huang",
      "Shiji Song",
      "Le Yang",
      "Honghui Wang",
      "Yulin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.04906"
  },
  {
    "id": "arXiv:2102.11434",
    "title": "Smart Navigation for In-pipe Robots with Multi-phase Motion Control and  Particle Filter",
    "abstract": "Smart Navigation for In-pipe Robots with Multi-phase Motion Control and  Particle Filter",
    "descriptor": "",
    "authors": [
      "Saber Kazeminasab",
      "Vahid Janfaza",
      "Moein Razavi",
      "M. Katherine Banks"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.11434"
  },
  {
    "id": "arXiv:2103.00111",
    "title": "Graph Self-Supervised Learning: A Survey",
    "abstract": "Comments: 25 pages, 9 figures, 9 tables",
    "descriptor": "\nComments: 25 pages, 9 figures, 9 tables\n",
    "authors": [
      "Yixin Liu",
      "Ming Jin",
      "Shirui Pan",
      "Chuan Zhou",
      "Feng Xia",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00111"
  },
  {
    "id": "arXiv:2103.01049",
    "title": "Diversifying Sample Generation for Accurate Data-Free Quantization",
    "abstract": "Diversifying Sample Generation for Accurate Data-Free Quantization",
    "descriptor": "",
    "authors": [
      "Xiangguo Zhang",
      "Haotong Qin",
      "Yifu Ding",
      "Ruihao Gong",
      "Qinghua Yan",
      "Renshuai Tao",
      "Yuhang Li",
      "Fengwei Yu",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.01049"
  },
  {
    "id": "arXiv:2103.03239",
    "title": "Moshpit SGD: Communication-Efficient Decentralized Training on  Heterogeneous Unreliable Devices",
    "abstract": "Comments: Accepted to Conference on Neural Information Processing Systems (NeurIPS) 2021. 50 pages, 6 figures. Code: this https URL",
    "descriptor": "\nComments: Accepted to Conference on Neural Information Processing Systems (NeurIPS) 2021. 50 pages, 6 figures. Code: this https URL\n",
    "authors": [
      "Max Ryabinin",
      "Eduard Gorbunov",
      "Vsevolod Plokhotnyuk",
      "Gennady Pekhimenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.03239"
  },
  {
    "id": "arXiv:2103.03240",
    "title": "Learning ABCs: Approximate Bijective Correspondence for isolating  factors of variation",
    "abstract": "Learning ABCs: Approximate Bijective Correspondence for isolating  factors of variation",
    "descriptor": "",
    "authors": [
      "Kieran A. Murphy",
      "Varun Jampani",
      "Srikumar Ramalingam",
      "Ameesh Makadia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03240"
  },
  {
    "id": "arXiv:2103.05896",
    "title": "Streaming Linear System Identification with Reverse Experience Replay",
    "abstract": "Streaming Linear System Identification with Reverse Experience Replay",
    "descriptor": "",
    "authors": [
      "Prateek Jain",
      "Suhas S Kowshik",
      "Dheeraj Nagaraj",
      "Praneeth Netrapalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.05896"
  },
  {
    "id": "arXiv:2103.06076",
    "title": "Designing Disaggregated Evaluations of AI Systems: Choices,  Considerations, and Tradeoffs",
    "abstract": "Designing Disaggregated Evaluations of AI Systems: Choices,  Considerations, and Tradeoffs",
    "descriptor": "",
    "authors": [
      "Solon Barocas",
      "Anhong Guo",
      "Ece Kamar",
      "Jacquelyn Krones",
      "Meredith Ringel Morris",
      "Jennifer Wortman Vaughan",
      "Duncan Wadsworth",
      "Hanna Wallach"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06076"
  },
  {
    "id": "arXiv:2103.07976",
    "title": "TransFG: A Transformer Architecture for Fine-grained Recognition",
    "abstract": "TransFG: A Transformer Architecture for Fine-grained Recognition",
    "descriptor": "",
    "authors": [
      "Ju He",
      "Jie-Neng Chen",
      "Shuai Liu",
      "Adam Kortylewski",
      "Cheng Yang",
      "Yutong Bai",
      "Changhu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.07976"
  },
  {
    "id": "arXiv:2103.14789",
    "title": "EM-WaveHoltz: A flexible frequency-domain method built from time-domain  solvers",
    "abstract": "EM-WaveHoltz: A flexible frequency-domain method built from time-domain  solvers",
    "descriptor": "",
    "authors": [
      "Zhichao Peng",
      "Daniel Appel\u00f6"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.14789"
  },
  {
    "id": "arXiv:2103.15812",
    "title": "LatentKeypointGAN: Controlling GANs via Latent Keypoints",
    "abstract": "LatentKeypointGAN: Controlling GANs via Latent Keypoints",
    "descriptor": "",
    "authors": [
      "Xingzhe He",
      "Bastian Wandt",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15812"
  },
  {
    "id": "arXiv:2104.01539",
    "title": "DINE: Domain Adaptation from Single and Multiple Black-box Predictors",
    "abstract": "DINE: Domain Adaptation from Single and Multiple Black-box Predictors",
    "descriptor": "",
    "authors": [
      "Jian Liang",
      "Dapeng Hu",
      "Jiashi Feng",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.01539"
  },
  {
    "id": "arXiv:2104.03414",
    "title": "PrivateSNN: Privacy-Preserving Spiking Neural Networks",
    "abstract": "Comments: Accepted to AAAI2022",
    "descriptor": "\nComments: Accepted to AAAI2022\n",
    "authors": [
      "Youngeun Kim",
      "Yeshwanth Venkatesha",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.03414"
  },
  {
    "id": "arXiv:2104.05857",
    "title": "From partners to populations: A hierarchical Bayesian account of  coordination and convention",
    "abstract": "Comments: In press at Psychological Review",
    "descriptor": "\nComments: In press at Psychological Review\n",
    "authors": [
      "Robert D. Hawkins",
      "Michael Franke",
      "Michael C. Frank",
      "Adele E. Goldberg",
      "Kenny Smith",
      "Thomas L. Griffiths",
      "Noah D. Goodman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.05857"
  },
  {
    "id": "arXiv:2104.06219",
    "title": "UAV-ReID: A Benchmark on Unmanned Aerial Vehicle Re-identification in  Video Imagery",
    "abstract": "UAV-ReID: A Benchmark on Unmanned Aerial Vehicle Re-identification in  Video Imagery",
    "descriptor": "",
    "authors": [
      "Daniel Organisciak",
      "Matthew Poyser",
      "Aishah Alsehaim",
      "Shanfeng Hu",
      "Brian K. S. Isaac-Medina",
      "Toby P. Breckon",
      "Hubert P. H. Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.06219"
  },
  {
    "id": "arXiv:2104.06669",
    "title": "NAREOR: The Narrative Reordering Problem",
    "abstract": "Comments: Accepted to AAAI 2022",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Varun Gangal",
      "Steven Y. Feng",
      "Malihe Alikhani",
      "Teruko Mitamura",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.06669"
  },
  {
    "id": "arXiv:2104.09872",
    "title": "Robust Sensor Fusion Algorithms Against Voice Command Attacks in  Autonomous Vehicles",
    "abstract": "Comments: 8 pages, 2 tables, 9 figures",
    "descriptor": "\nComments: 8 pages, 2 tables, 9 figures\n",
    "authors": [
      "Jiwei Guan",
      "Xi Zheng",
      "Chen Wang",
      "Yipeng Zhou",
      "Alireza Jolfa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.09872"
  },
  {
    "id": "arXiv:2104.13018",
    "title": "Attention and Prediction Guided Motion Detection for Low-Contrast Small  Moving Targets",
    "abstract": "Comments: 14 pages, 25 figures",
    "descriptor": "\nComments: 14 pages, 25 figures\n",
    "authors": [
      "Hongxin Wang",
      "Jiannan Zhao",
      "Huatian Wang",
      "Cheng Hu",
      "Jigen Peng",
      "Shigang Yue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.13018"
  },
  {
    "id": "arXiv:2104.14368",
    "title": "Fast computation of matrix function-based centrality measures for  layer-coupled multiplex networks",
    "abstract": "Fast computation of matrix function-based centrality measures for  layer-coupled multiplex networks",
    "descriptor": "",
    "authors": [
      "Kai Bergermann",
      "Martin Stoll"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.14368"
  },
  {
    "id": "arXiv:2104.15119",
    "title": "Deep Multi-View Stereo gone wild",
    "abstract": "Comments: Accepted to 3DV2021",
    "descriptor": "\nComments: Accepted to 3DV2021\n",
    "authors": [
      "Fran\u00e7ois Darmon",
      "B\u00e9n\u00e9dicte Bascle",
      "Jean-Cl\u00e9ment Devaux",
      "Pascal Monasse",
      "Mathieu Aubry"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.15119"
  },
  {
    "id": "arXiv:2105.00243",
    "title": "FedProto: Federated Prototype Learning over Heterogeneous Devices",
    "abstract": "FedProto: Federated Prototype Learning over Heterogeneous Devices",
    "descriptor": "",
    "authors": [
      "Yue Tan",
      "Guodong Long",
      "Lu Liu",
      "Tianyi Zhou",
      "Qinghua Lu",
      "Jing Jiang",
      "Chengqi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.00243"
  },
  {
    "id": "arXiv:2105.03075",
    "title": "A Survey of Data Augmentation Approaches for NLP",
    "abstract": "Comments: Accepted to ACL 2021 Findings. GitHub repo with paper list at this https URL ; Talk at this https URL&ab_channel=StevenFeng ; Podcast at this https URL&ab_channel=GradientFlow and this https URL",
    "descriptor": "\nComments: Accepted to ACL 2021 Findings. GitHub repo with paper list at this https URL ; Talk at this https URL&ab_channel=StevenFeng ; Podcast at this https URL&ab_channel=GradientFlow and this https URL\n",
    "authors": [
      "Steven Y. Feng",
      "Varun Gangal",
      "Jason Wei",
      "Sarath Chandar",
      "Soroush Vosoughi",
      "Teruko Mitamura",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03075"
  },
  {
    "id": "arXiv:2105.04738",
    "title": "Lightweight Distributed Gaussian Process Regression for Online Machine  Learning",
    "abstract": "Lightweight Distributed Gaussian Process Regression for Online Machine  Learning",
    "descriptor": "",
    "authors": [
      "Zhenyuan Yuan",
      "Minghui Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.04738"
  },
  {
    "id": "arXiv:2105.05557",
    "title": "Mining Legacy Issues in Open Pit Mining Sites: Innovation & Support of  Renaturalization and Land Utilization",
    "abstract": "Mining Legacy Issues in Open Pit Mining Sites: Innovation & Support of  Renaturalization and Land Utilization",
    "descriptor": "",
    "authors": [
      "Christopher Schr\u00f6der",
      "Kim B\u00fcrgl",
      "Yves Annanias",
      "Andreas Niekler",
      "Lydia M\u00fcller",
      "Daniel Wiegreffe",
      "Christian Bender",
      "Christoph Mengs",
      "Gerik Scheuermann",
      "Gerhard Heyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.05557"
  },
  {
    "id": "arXiv:2105.11363",
    "title": "Learning Security Classifiers with Verified Global Robustness Properties",
    "abstract": "Comments: ACM Conference on Computer and Communications Security (CCS) 2021 Best Paper Award Runner-Up",
    "descriptor": "\nComments: ACM Conference on Computer and Communications Security (CCS) 2021 Best Paper Award Runner-Up\n",
    "authors": [
      "Yizheng Chen",
      "Shiqi Wang",
      "Yue Qin",
      "Xiaojing Liao",
      "Suman Jana",
      "David Wagner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11363"
  },
  {
    "id": "arXiv:2105.11558",
    "title": "Near-optimal Offline and Streaming Algorithms for Learning Non-Linear  Dynamical Systems",
    "abstract": "Near-optimal Offline and Streaming Algorithms for Learning Non-Linear  Dynamical Systems",
    "descriptor": "",
    "authors": [
      "Prateek Jain",
      "Suhas S Kowshik",
      "Dheeraj Nagaraj",
      "Praneeth Netrapalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.11558"
  },
  {
    "id": "arXiv:2105.11689",
    "title": "Self-Supervised Graph Representation Learning via Topology  Transformations",
    "abstract": "Comments: Accepted to IEEE Transactions on Knowledge and Data Engineering (TKDE)",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Knowledge and Data Engineering (TKDE)\n",
    "authors": [
      "Xiang Gao",
      "Wei Hu",
      "Guo-Jun Qi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.11689"
  },
  {
    "id": "arXiv:2105.11879",
    "title": "Flexible Table Recognition and Semantic Interpretation System",
    "abstract": "Comments: Accepted for publication in Proceedings of the 17th International Conference on Computer Vision Theory and Applications (VISAPP 2022)",
    "descriptor": "\nComments: Accepted for publication in Proceedings of the 17th International Conference on Computer Vision Theory and Applications (VISAPP 2022)\n",
    "authors": [
      "Marcin Namysl",
      "Alexander M. Esser",
      "Sven Behnke",
      "Joachim K\u00f6hler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11879"
  },
  {
    "id": "arXiv:2105.12931",
    "title": "YOLO5Face: Why Reinventing a Face Detector",
    "abstract": "YOLO5Face: Why Reinventing a Face Detector",
    "descriptor": "",
    "authors": [
      "Delong Qi",
      "Weijun Tan",
      "Qi Yao",
      "Jingfeng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.12931"
  },
  {
    "id": "arXiv:2105.13570",
    "title": "Predicting the hosts of prokaryotic viruses using GCN-based  semi-supervised learning",
    "abstract": "Comments: 16 pages, 14 figures",
    "descriptor": "\nComments: 16 pages, 14 figures\n",
    "authors": [
      "Jiayu Shang",
      "Yanni Sun"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13570"
  },
  {
    "id": "arXiv:2105.14216",
    "title": "Efficient Cross-Device Federated Learning Algorithms for Minimax  Problems",
    "abstract": "Efficient Cross-Device Federated Learning Algorithms for Minimax  Problems",
    "descriptor": "",
    "authors": [
      "Jiahao Xie",
      "Chao Zhang",
      "Zebang Shen",
      "Weijie Liu",
      "Hui Qian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.14216"
  },
  {
    "id": "arXiv:2106.03443",
    "title": "Causal Influence Detection for Improving Efficiency in Reinforcement  Learning",
    "abstract": "Comments: NeurIPS 2021 camera-ready version. Code available at this http URL",
    "descriptor": "\nComments: NeurIPS 2021 camera-ready version. Code available at this http URL\n",
    "authors": [
      "Maximilian Seitzer",
      "Bernhard Sch\u00f6lkopf",
      "Georg Martius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03443"
  },
  {
    "id": "arXiv:2106.03455",
    "title": "Knowledge-aware Deep Framework for Collaborative Skin Lesion  Segmentation and Melanoma Recognition",
    "abstract": "Comments: Pattern Recognition",
    "descriptor": "\nComments: Pattern Recognition\n",
    "authors": [
      "Xiaohong Wang",
      "Xudong Jiang",
      "Henghui Ding",
      "Yuqian Zhao",
      "Jun Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03455"
  },
  {
    "id": "arXiv:2106.05931",
    "title": "Score-based Generative Modeling in Latent Space",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Arash Vahdat",
      "Karsten Kreis",
      "Jan Kautz"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05931"
  },
  {
    "id": "arXiv:2106.07824",
    "title": "Communicating Natural Programs to Humans and Machines",
    "abstract": "Comments: equal contributions: (author 3,4,5), (author 6,7)",
    "descriptor": "\nComments: equal contributions: (author 3,4,5), (author 6,7)\n",
    "authors": [
      "Samuel Acquaviva",
      "Yewen Pu",
      "Marta Kryven",
      "Theodoros Sechopoulos",
      "Catherine Wong",
      "Gabrielle E Ecanow",
      "Maxwell Nye",
      "Michael Henry Tessler",
      "Joshua B. Tenenbaum"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07824"
  },
  {
    "id": "arXiv:2106.08365",
    "title": "Test Sample Accuracy Scales with Training Sample Density in Neural  Networks",
    "abstract": "Comments: Updated version (Dec 2021)",
    "descriptor": "\nComments: Updated version (Dec 2021)\n",
    "authors": [
      "Xu Ji",
      "Razvan Pascanu",
      "Devon Hjelm",
      "Balaji Lakshminarayanan",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08365"
  },
  {
    "id": "arXiv:2106.08630",
    "title": "HELP: Hardware-Adaptive Efficient Latency Prediction for NAS via  Meta-Learning",
    "abstract": "Comments: NeurIPS 2021 (Spotlight)",
    "descriptor": "\nComments: NeurIPS 2021 (Spotlight)\n",
    "authors": [
      "Hayeon Lee",
      "Sewoong Lee",
      "Song Chong",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08630"
  },
  {
    "id": "arXiv:2106.09719",
    "title": "Machining Cycle Time Prediction: Data-driven Modelling of Machine Tool  Feedrate Behavior with Neural Networks",
    "abstract": "Machining Cycle Time Prediction: Data-driven Modelling of Machine Tool  Feedrate Behavior with Neural Networks",
    "descriptor": "",
    "authors": [
      "Chao Sun",
      "Javier Dominguez-Caballero",
      "Rob Ward",
      "Sabino Ayvar-Soberanis",
      "David Curtis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09719"
  },
  {
    "id": "arXiv:2106.10900",
    "title": "Self-Supervised Tracking via Target-Aware Data Synthesis",
    "abstract": "Comments: 11 pages, 7 figures",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Xin Li",
      "Wenjie Pei",
      "Zikun Zhou",
      "Zhenyu He",
      "Huchuan Lu",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10900"
  },
  {
    "id": "arXiv:2106.11945",
    "title": "Smaller extended formulations for spanning tree polytopes in  minor-closed classes and beyond",
    "abstract": "Comments: v2: Minor changes following the referees' comments",
    "descriptor": "\nComments: v2: Minor changes following the referees' comments\n",
    "authors": [
      "Manuel Aprile",
      "Samuel Fiorini",
      "Tony Huynh",
      "Gwena\u00ebl Joret",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.11945"
  },
  {
    "id": "arXiv:2106.12062",
    "title": "A Practical & Unified Notation for Information-Theoretic Quantities in  ML",
    "abstract": "A Practical & Unified Notation for Information-Theoretic Quantities in  ML",
    "descriptor": "",
    "authors": [
      "Andreas Kirsch",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.12062"
  },
  {
    "id": "arXiv:2106.12142",
    "title": "IQ-Learn: Inverse soft-Q Learning for Imitation",
    "abstract": "Comments: Spotlight in NeurIPS 2021. Website: this https URL",
    "descriptor": "\nComments: Spotlight in NeurIPS 2021. Website: this https URL\n",
    "authors": [
      "Divyansh Garg",
      "Shuvam Chakraborty",
      "Chris Cundy",
      "Jiaming Song",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.12142"
  },
  {
    "id": "arXiv:2106.13002",
    "title": "Loosely-Stabilizing Phase Clocks and the Adaptive Majority Problem",
    "abstract": "Loosely-Stabilizing Phase Clocks and the Adaptive Majority Problem",
    "descriptor": "",
    "authors": [
      "Petra Berenbrink",
      "Felix Biermeier",
      "Christopher Hahn",
      "Dominik Kaaser"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.13002"
  },
  {
    "id": "arXiv:2106.13436",
    "title": "A hybrid model-based and learning-based approach for classification  using limited number of training samples",
    "abstract": "Comments: An extended version of the paper accepted in the open journal of signal processing. This version includes the following extra materials compared to the accepted paper: 1. Appendix D: Proof of Lemma 5, 2. Appendix E: Proof of Lemma 6, 3. Appendix F: A heuristic approach for channel parameter estimation for CDMA system",
    "descriptor": "\nComments: An extended version of the paper accepted in the open journal of signal processing. This version includes the following extra materials compared to the accepted paper: 1. Appendix D: Proof of Lemma 5, 2. Appendix E: Proof of Lemma 6, 3. Appendix F: A heuristic approach for channel parameter estimation for CDMA system\n",
    "authors": [
      "Alireza Nooraiepour",
      "Waheed U. Bajwa",
      "Narayan B. Mandayam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.13436"
  },
  {
    "id": "arXiv:2106.14790",
    "title": "PhysiNet: A Combination of Physics-based Model and Neural Network Model  for Digital Twins",
    "abstract": "PhysiNet: A Combination of Physics-based Model and Neural Network Model  for Digital Twins",
    "descriptor": "",
    "authors": [
      "Chao Sun",
      "Victor Guang Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.14790"
  },
  {
    "id": "arXiv:2106.16009",
    "title": "MissFormer: (In-)attention-based handling of missing observations for  trajectory filtering and prediction",
    "abstract": "Comments: Accepted at the International Symposium on Visual Computing (ISVC) 2021",
    "descriptor": "\nComments: Accepted at the International Symposium on Visual Computing (ISVC) 2021\n",
    "authors": [
      "Stefan Becker",
      "Ronny Hug",
      "Wolfgang H\u00fcbner",
      "Michael Arens",
      "Brendan T. Morris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16009"
  },
  {
    "id": "arXiv:2107.01912",
    "title": "Berserker: ASN.1-based Fuzzing of Radio Resource Control Protocol for 4G  and 5G",
    "abstract": "Comments: 19 pages, 9 figures, 17 tables",
    "descriptor": "\nComments: 19 pages, 9 figures, 17 tables\n",
    "authors": [
      "Srinath Potnuru",
      "Prajwol Kumar Nakarmi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.01912"
  },
  {
    "id": "arXiv:2107.05399",
    "title": "Transfer Learning from Synthetic to Real LiDAR Point Cloud for Semantic  Segmentation",
    "abstract": "Comments: Accepted by AAAI 2022",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Aoran Xiao",
      "Jiaxing Huang",
      "Dayan Guan",
      "Fangneng Zhan",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05399"
  },
  {
    "id": "arXiv:2107.06696",
    "title": "Social nucleation: Group formation as a phase transition",
    "abstract": "Social nucleation: Group formation as a phase transition",
    "descriptor": "",
    "authors": [
      "Frank Schweitzer",
      "Georges Andres"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Other Condensed Matter (cond-mat.other)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.06696"
  },
  {
    "id": "arXiv:2107.07579",
    "title": "A Channel Coding Benchmark for Meta-Learning",
    "abstract": "A Channel Coding Benchmark for Meta-Learning",
    "descriptor": "",
    "authors": [
      "Rui Li",
      "Ondrej Bohdal",
      "Rajesh Mishra",
      "Hyeji Kim",
      "Da Li",
      "Nicholas Lane",
      "Timothy Hospedales"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07579"
  },
  {
    "id": "arXiv:2107.08467",
    "title": "GoTube: Scalable Stochastic Verification of Continuous-Depth Models",
    "abstract": "Comments: Accepted to the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22)",
    "descriptor": "\nComments: Accepted to the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22)\n",
    "authors": [
      "Sophie Gruenbacher",
      "Mathias Lechner",
      "Ramin Hasani",
      "Daniela Rus",
      "Thomas A. Henzinger",
      "Scott Smolka",
      "Radu Grosu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.08467"
  },
  {
    "id": "arXiv:2107.09133",
    "title": "Limiting Dynamics of SGD: Modified Loss, Phase Space Oscillations, and  Anomalous Diffusion",
    "abstract": "Comments: 31 pages, 8 figures",
    "descriptor": "\nComments: 31 pages, 8 figures\n",
    "authors": [
      "Daniel Kunin",
      "Javier Sagastuy-Brena",
      "Lauren Gillespie",
      "Eshed Margalit",
      "Hidenori Tanaka",
      "Surya Ganguli",
      "Daniel L. K. Yamins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.09133"
  },
  {
    "id": "arXiv:2107.10323",
    "title": "The Optimality of Upgrade Pricing",
    "abstract": "Comments: 22 pages, 4 figures",
    "descriptor": "\nComments: 22 pages, 4 figures\n",
    "authors": [
      "Dirk Bergemann",
      "Alessandro Bonatti",
      "Andreas Haupt",
      "Alex Smolin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2107.10323"
  },
  {
    "id": "arXiv:2107.11733",
    "title": "Revisiting Analog Over-the-Air Machine Learning: The Blessing and Curse  of Interference",
    "abstract": "Revisiting Analog Over-the-Air Machine Learning: The Blessing and Curse  of Interference",
    "descriptor": "",
    "authors": [
      "Howard H. Yang",
      "Zihan Chen",
      "Tony Q. S. Quek",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.11733"
  },
  {
    "id": "arXiv:2107.13492",
    "title": "BROUTE: a benchmark suite for the implementation of standard vehicle  routing algorithms",
    "abstract": "BROUTE: a benchmark suite for the implementation of standard vehicle  routing algorithms",
    "descriptor": "",
    "authors": [
      "Fabien Tricoire"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.13492"
  },
  {
    "id": "arXiv:2108.00712",
    "title": "Local Diversity and Ultra-Reliable Antenna Arrays",
    "abstract": "Comments: 7 pages, 5 figures, 2 tables, presented at Asilomar 2021; v1: initial submission, v2: fixed typos, restructured sections, updated notation",
    "descriptor": "\nComments: 7 pages, 5 figures, 2 tables, presented at Asilomar 2021; v1: initial submission, v2: fixed typos, restructured sections, updated notation\n",
    "authors": [
      "Jens Abraham",
      "Torbj\u00f6rn Ekman"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.00712"
  },
  {
    "id": "arXiv:2108.01615",
    "title": "Accelerating the Adoption of Disruptive Technologies: The Impact of  COVID-19 on Intentions to Use Autonomous Vehicles",
    "abstract": "Comments: Accepted at Transportation Research Board 2022 for presentation (2nd revision)",
    "descriptor": "\nComments: Accepted at Transportation Research Board 2022 for presentation (2nd revision)\n",
    "authors": [
      "Maher Said",
      "Emma R. Zajdela",
      "Amanda Stathopoulos"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2108.01615"
  },
  {
    "id": "arXiv:2108.05877",
    "title": "DexMV: Imitation Learning for Dexterous Manipulation from Human Videos",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Yuzhe Qin",
      "Yueh-Hua Wu",
      "Shaowei Liu",
      "Hanwen Jiang",
      "Ruihan Yang",
      "Yang Fu",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.05877"
  },
  {
    "id": "arXiv:2108.06643",
    "title": "SAPPHIRE: Approaches for Enhanced Concept-to-Text Generation",
    "abstract": "Comments: INLG 2021 [Best Long Paper]. Code available at this https URL",
    "descriptor": "\nComments: INLG 2021 [Best Long Paper]. Code available at this https URL\n",
    "authors": [
      "Steven Y. Feng",
      "Jessica Huynh",
      "Chaitanya Narisetty",
      "Eduard Hovy",
      "Varun Gangal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.06643"
  },
  {
    "id": "arXiv:2108.09117",
    "title": "OpenStreetMap-based Autonomous Navigation With LiDAR Naive-Valley-Path  Obstacle Avoidance",
    "abstract": "Comments: This paper was submitted to Elsevier's Measurement journal and is currently under review",
    "descriptor": "\nComments: This paper was submitted to Elsevier's Measurement journal and is currently under review\n",
    "authors": [
      "Miguel Angel Munoz-Banon",
      "Edison Velasco-Sanchez",
      "Francisco A. Candelas",
      "Fernando Torres"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.09117"
  },
  {
    "id": "arXiv:2108.12094",
    "title": "A Numerical Verification Framework for Differential Privacy in  Estimation",
    "abstract": "Comments: The paper is accepted by IEEE Control System Letter (L-CSS)",
    "descriptor": "\nComments: The paper is accepted by IEEE Control System Letter (L-CSS)\n",
    "authors": [
      "Yunhai Han",
      "Sonia Mart\u00ednez"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.12094"
  },
  {
    "id": "arXiv:2109.01652",
    "title": "Finetuned Language Models Are Zero-Shot Learners",
    "abstract": "Comments: Version 4. Find list of changes in Appendix F (page 36)",
    "descriptor": "\nComments: Version 4. Find list of changes in Appendix F (page 36)\n",
    "authors": [
      "Jason Wei",
      "Maarten Bosma",
      "Vincent Y. Zhao",
      "Kelvin Guu",
      "Adams Wei Yu",
      "Brian Lester",
      "Nan Du",
      "Andrew M. Dai",
      "Quoc V. Le"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.01652"
  },
  {
    "id": "arXiv:2109.03892",
    "title": "Retrieve, Caption, Generate: Visual Grounding for Enhancing Commonsense  in Text Generation Models",
    "abstract": "Comments: Accepted to AAAI 2022",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Steven Y. Feng",
      "Kevin Lu",
      "Zhuofu Tao",
      "Malihe Alikhani",
      "Teruko Mitamura",
      "Eduard Hovy",
      "Varun Gangal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03892"
  },
  {
    "id": "arXiv:2109.06152",
    "title": "Enumerating independent sets in Abelian Cayley graphs",
    "abstract": "Comments: 21 pages, fixed minor typos and citations",
    "descriptor": "\nComments: 21 pages, fixed minor typos and citations\n",
    "authors": [
      "Aditya Potukuchi",
      "Liana Yepremyan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.06152"
  },
  {
    "id": "arXiv:2109.06403",
    "title": "Symbolic determinant identity testing and non-commutative ranks of  matrix Lie algebras",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "G\u00e1bor Ivanyos",
      "Tushant Mittal",
      "Youming Qiao"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2109.06403"
  },
  {
    "id": "arXiv:2109.07025",
    "title": "Globally-Attractive Logarithmic Geometric Control of a Quadrotor for  Aggressive Trajectory Tracking",
    "abstract": "Globally-Attractive Logarithmic Geometric Control of a Quadrotor for  Aggressive Trajectory Tracking",
    "descriptor": "",
    "authors": [
      "Jacob Johnson",
      "Randal Beard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07025"
  },
  {
    "id": "arXiv:2109.08811",
    "title": "Homogeneous and Heterogeneous Relational Graph for Visible-infrared  Person Re-identification",
    "abstract": "Homogeneous and Heterogeneous Relational Graph for Visible-infrared  Person Re-identification",
    "descriptor": "",
    "authors": [
      "Yujian Feng",
      "Feng Chen",
      "Jian Yu",
      "Yimu Ji",
      "Fei Wu",
      "Shangdong Liu",
      "Xiao-Yuan Jing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.08811"
  },
  {
    "id": "arXiv:2109.11265",
    "title": "End-to-End Dense Video Grounding via Parallel Regression",
    "abstract": "Comments: Technical report",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Fengyuan Shi",
      "Limin Wang",
      "Weilin Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.11265"
  },
  {
    "id": "arXiv:2109.13346",
    "title": "Quantum Computational Phase Transition in Combinatorial Problems",
    "abstract": "Comments: 12 pages, 10 figures",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Bingzhi Zhang",
      "Akira Sone",
      "Quntao Zhuang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.13346"
  },
  {
    "id": "arXiv:2109.14979",
    "title": "Moving Object Detection for Event-based vision using Graph Spectral  Clustering",
    "abstract": "Comments: Ten pages, five figures, Published in 2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW), Montreal, BC, Canada",
    "descriptor": "\nComments: Ten pages, five figures, Published in 2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW), Montreal, BC, Canada\n",
    "authors": [
      "Anindya Mondal",
      "Shashant R",
      "Jhony H. Giraldo",
      "Thierry Bouwmans",
      "Ananda S. Chowdhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.14979"
  },
  {
    "id": "arXiv:2109.15130",
    "title": "Motion-aware Contrastive Video Representation Learning via  Foreground-background Merging",
    "abstract": "Comments: Technical report",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Shuangrui Ding",
      "Maomao Li",
      "Tianyu Yang",
      "Rui Qian",
      "Haohang Xu",
      "Qingyi Chen",
      "Jue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.15130"
  },
  {
    "id": "arXiv:2110.00605",
    "title": "Direct LiDAR Odometry: Fast Localization with Dense Point Clouds",
    "abstract": "Direct LiDAR Odometry: Fast Localization with Dense Point Clouds",
    "descriptor": "",
    "authors": [
      "Kenny Chen",
      "Brett T. Lopez",
      "Ali-akbar Agha-mohammadi",
      "Ankur Mehta"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.00605"
  },
  {
    "id": "arXiv:2110.00629",
    "title": "Factored couplings in multi-marginal optimal transport via difference of  convex programming",
    "abstract": "Comments: Revision of notation and proofs",
    "descriptor": "\nComments: Revision of notation and proofs\n",
    "authors": [
      "Quang Huy Tran",
      "Hicham Janati",
      "Ievgen Redko",
      "R\u00e9mi Flamary",
      "Nicolas Courty"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.00629"
  },
  {
    "id": "arXiv:2110.00653",
    "title": "Sparse Deep Learning: A New Framework Immune to Local Traps and  Miscalibration",
    "abstract": "Comments: Neurips 2021",
    "descriptor": "\nComments: Neurips 2021\n",
    "authors": [
      "Yan Sun",
      "Wenjun Xiong",
      "Faming Liang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00653"
  },
  {
    "id": "arXiv:2110.01165",
    "title": "DESTRESS: Computation-Optimal and Communication-Efficient Decentralized  Nonconvex Finite-Sum Optimization",
    "abstract": "DESTRESS: Computation-Optimal and Communication-Efficient Decentralized  Nonconvex Finite-Sum Optimization",
    "descriptor": "",
    "authors": [
      "Boyue Li",
      "Zhize Li",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.01165"
  },
  {
    "id": "arXiv:2110.02491",
    "title": "Data-Centric AI Requires Rethinking Data Notion",
    "abstract": "Data-Centric AI Requires Rethinking Data Notion",
    "descriptor": "",
    "authors": [
      "Mustafa Hajij",
      "Ghada Zamzmi",
      "Karthikeyan Natesan Ramamurthy",
      "Aldo Guzman Saenz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Category Theory (math.CT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02491"
  },
  {
    "id": "arXiv:2110.02782",
    "title": "How BPE Affects Memorization in Transformers",
    "abstract": "How BPE Affects Memorization in Transformers",
    "descriptor": "",
    "authors": [
      "Eugene Kharitonov",
      "Marco Baroni",
      "Dieuwke Hupkes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02782"
  },
  {
    "id": "arXiv:2110.03975",
    "title": "Tensor train completion: local recovery guarantees via Riemannian  optimization",
    "abstract": "Comments: 1 figure added",
    "descriptor": "\nComments: 1 figure added\n",
    "authors": [
      "Stanislav Budzinskiy",
      "Nikolai Zamarashkin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03975"
  },
  {
    "id": "arXiv:2110.05454",
    "title": "Momentum Centering and Asynchronous Update for Adaptive Gradient Methods",
    "abstract": "Momentum Centering and Asynchronous Update for Adaptive Gradient Methods",
    "descriptor": "",
    "authors": [
      "Juntang Zhuang",
      "Yifan Ding",
      "Tommy Tang",
      "Nicha Dvornek",
      "Sekhar Tatikonda",
      "James S. Duncan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.05454"
  },
  {
    "id": "arXiv:2110.06850",
    "title": "Boosting the Certified Robustness of L-infinity Distance Nets",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Bohang Zhang",
      "Du Jiang",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06850"
  },
  {
    "id": "arXiv:2110.07554",
    "title": "Looper: An end-to-end ML platform for product decisions",
    "abstract": "Comments: 10 pages + references, 5 figures",
    "descriptor": "\nComments: 10 pages + references, 5 figures\n",
    "authors": [
      "Igor L. Markov",
      "Hanson Wang",
      "Nitya Kasturi",
      "Shaun Singh",
      "Sze Wai Yuen",
      "Mia Garrard",
      "Sarah Tran",
      "Yin Huang",
      "Zehui Wang",
      "Igor Glotov",
      "Tanvi Gupta",
      "Boshuang Huang",
      "Peng Chen",
      "Xiaowen Xie",
      "Michael Belkin",
      "Sal Uryasev",
      "Sam Howie",
      "Eytan Bakshy",
      "Norm Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.07554"
  },
  {
    "id": "arXiv:2110.09304",
    "title": "Prediction of Occurrence of Extreme Events using Machine Learning",
    "abstract": "Comments: To appear in The European Physical Journal Plus",
    "descriptor": "\nComments: To appear in The European Physical Journal Plus\n",
    "authors": [
      "J. Meiyazhagan",
      "S. Sudharsan",
      "A. Venkatasen",
      "M. Senthilvelan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2110.09304"
  },
  {
    "id": "arXiv:2110.09868",
    "title": "Designing A Clinically Applicable Deep Recurrent Model to Identify  Neuropsychiatric Symptoms in People Living with Dementia Using In-Home  Monitoring Data",
    "abstract": "Comments: 13 pages, accepted to Research2Clinics WS @ NeurIPS 2021",
    "descriptor": "\nComments: 13 pages, accepted to Research2Clinics WS @ NeurIPS 2021\n",
    "authors": [
      "Francesca Palermo",
      "Honglin Li",
      "Alexander Capstick",
      "Nan Fletcher-Lloyd",
      "Yuchen Zhao",
      "Samaneh Kouchaki",
      "Ramin Nilforooshan",
      "David Sharp",
      "Payam Barnaghi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09868"
  },
  {
    "id": "arXiv:2110.10596",
    "title": "Look at What I'm Doing: Self-Supervised Spatial Grounding of Narrations  in Instructional Videos",
    "abstract": "Comments: Accepted at NeurIPS 2021 (Spotlight)",
    "descriptor": "\nComments: Accepted at NeurIPS 2021 (Spotlight)\n",
    "authors": [
      "Reuben Tan",
      "Bryan A. Plummer",
      "Kate Saenko",
      "Hailin Jin",
      "Bryan Russell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10596"
  },
  {
    "id": "arXiv:2110.10666",
    "title": "Efficient Consensus-Free Weight Reassignment for Atomic Storage  (Extended Version)",
    "abstract": "Efficient Consensus-Free Weight Reassignment for Atomic Storage  (Extended Version)",
    "descriptor": "",
    "authors": [
      "Hasan Heydari",
      "Guthemberg Silvestre",
      "Luciana Arantes"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.10666"
  },
  {
    "id": "arXiv:2110.11760",
    "title": "Distributed Simulation and Visualization of The ALICE Detector Magnetic  Field",
    "abstract": "Distributed Simulation and Visualization of The ALICE Detector Magnetic  Field",
    "descriptor": "",
    "authors": [
      "Piotr Nowakowski",
      "Przemys\u0142aw Rokita",
      "\u0141ukasz Graczykowski"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.11760"
  },
  {
    "id": "arXiv:2110.13179",
    "title": "Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures",
    "abstract": "Comments: Probabilistic Hierarchical Forecasting, Neural Networks, Poisson Mixtures, Preprint submitted to IJF",
    "descriptor": "\nComments: Probabilistic Hierarchical Forecasting, Neural Networks, Poisson Mixtures, Preprint submitted to IJF\n",
    "authors": [
      "Kin G. Olivares",
      "O. Nganba Meetei",
      "Ruijun Ma",
      "Rohan Reddy",
      "Mengfei Cao",
      "Lee Dicker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13179"
  },
  {
    "id": "arXiv:2110.15101",
    "title": "Identification over Compound Multiple-Input Multiple-Output Broadcast  Channels",
    "abstract": "Comments: refined for journal submission; simplified and specified constraint in Theorem 3; fixed epsilon in Section V (minor correction); updated References; improved notation and formatting",
    "descriptor": "\nComments: refined for journal submission; simplified and specified constraint in Theorem 3; fixed epsilon in Section V (minor correction); updated References; improved notation and formatting\n",
    "authors": [
      "Johannes Rosenberger",
      "Uzi Pereg",
      "Christian Deppe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.15101"
  },
  {
    "id": "arXiv:2111.00193",
    "title": "M2MRF: Many-to-Many Reassembly of Features for Tiny Lesion Segmentation  in Fundus Images",
    "abstract": "M2MRF: Many-to-Many Reassembly of Features for Tiny Lesion Segmentation  in Fundus Images",
    "descriptor": "",
    "authors": [
      "Qing Liu",
      "Haotian Liu",
      "Wei Ke",
      "Yixiong Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00193"
  },
  {
    "id": "arXiv:2111.00207",
    "title": "PatchFormer: An Efficient Point Transformer with Patch Attention",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Zhang Cheng",
      "Haocheng Wan",
      "Xinyi Shen",
      "Zizhao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00207"
  },
  {
    "id": "arXiv:2111.00429",
    "title": "Enhancing Top-N Item Recommendations by Peer Collaboration",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Yang Sun",
      "Fajie Yuan",
      "Min Yang",
      "Alexandros Karatzoglou",
      "Shen Li",
      "Xiaoyan Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.00429"
  },
  {
    "id": "arXiv:2111.03308",
    "title": "Confidential Machine Learning Computation in Untrusted Environments: A  Systems Security Perspective",
    "abstract": "Comments: It is agreed among the authors the research need more polishing. We are withdrawing this paper for now. Sorry for the inconvenience",
    "descriptor": "\nComments: It is agreed among the authors the research need more polishing. We are withdrawing this paper for now. Sorry for the inconvenience\n",
    "authors": [
      "Kha Dinh Duy",
      "Taehyun Noh",
      "Siwon Huh",
      "Hojoon Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03308"
  },
  {
    "id": "arXiv:2111.05553",
    "title": "Matrix anti-concentration inequalities with applications",
    "abstract": "Comments: 42 pages, 1 figure, more references for better introduction, pseudocode for simplified block Krylov space algorithm added",
    "descriptor": "\nComments: 42 pages, 1 figure, more references for better introduction, pseudocode for simplified block Krylov space algorithm added\n",
    "authors": [
      "Zipei Nie"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.05553"
  },
  {
    "id": "arXiv:2111.05820",
    "title": "Multi-Task Neural Processes",
    "abstract": "Multi-Task Neural Processes",
    "descriptor": "",
    "authors": [
      "Jiayi Shen",
      "Xiantong Zhen",
      "Marcel Worring",
      "Ling Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05820"
  },
  {
    "id": "arXiv:2111.06377",
    "title": "Masked Autoencoders Are Scalable Vision Learners",
    "abstract": "Comments: Tech report. arXiv v2: add more transfer learning results",
    "descriptor": "\nComments: Tech report. arXiv v2: add more transfer learning results\n",
    "authors": [
      "Kaiming He",
      "Xinlei Chen",
      "Saining Xie",
      "Yanghao Li",
      "Piotr Doll\u00e1r",
      "Ross Girshick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06377"
  },
  {
    "id": "arXiv:2111.07647",
    "title": "Enumerating Minimal Separators in Ranked Order",
    "abstract": "Comments: Error in Lemma 13",
    "descriptor": "\nComments: Error in Lemma 13\n",
    "authors": [
      "Batya Kenig"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.07647"
  },
  {
    "id": "arXiv:2111.08163",
    "title": "An Underexplored Dilemma between Confidence and Calibration in Quantized  Neural Networks",
    "abstract": "Comments: Accepted at I (Still) Can't Believe It's Not Better Workshop at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at I (Still) Can't Believe It's Not Better Workshop at NeurIPS 2021\n",
    "authors": [
      "Guoxuan Xia",
      "Sangwon Ha",
      "Tiago Azevedo",
      "Partha Maji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08163"
  },
  {
    "id": "arXiv:2111.08462",
    "title": "Towards Lightweight Controllable Audio Synthesis with Conditional  Implicit Neural Representations",
    "abstract": "Comments: Accepted to \"Deep Generative Models and Downstream Applications\" (Oral) and \"Machine Learning for Creativity and Design\" (Poster) workshops at NeurIPS 2021",
    "descriptor": "\nComments: Accepted to \"Deep Generative Models and Downstream Applications\" (Oral) and \"Machine Learning for Creativity and Design\" (Poster) workshops at NeurIPS 2021\n",
    "authors": [
      "Jan Zuiderveld",
      "Marco Federici",
      "Erik J. Bekkers"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08462"
  },
  {
    "id": "arXiv:2111.08856",
    "title": "Fairness Testing of Deep Image Classification with Adequacy Metrics",
    "abstract": "Fairness Testing of Deep Image Classification with Adequacy Metrics",
    "descriptor": "",
    "authors": [
      "Peixin Zhang",
      "Jingyi Wang",
      "Jun Sun",
      "Xinyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08856"
  },
  {
    "id": "arXiv:2111.09341",
    "title": "Strong L2 convergence of time Euler schemes for stochastic 3D  Brinkman-Forchheimer-Navier-Stokes equations",
    "abstract": "Strong L2 convergence of time Euler schemes for stochastic 3D  Brinkman-Forchheimer-Navier-Stokes equations",
    "descriptor": "",
    "authors": [
      "Hakima Bessaih",
      "Annie Millet"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.09341"
  },
  {
    "id": "arXiv:2111.11629",
    "title": "Uncertainty-Aware Deep Co-training for Semi-supervised Medical Image  Segmentation",
    "abstract": "Uncertainty-Aware Deep Co-training for Semi-supervised Medical Image  Segmentation",
    "descriptor": "",
    "authors": [
      "Xu Zheng",
      "Chong Fu",
      "Haoyu Xie",
      "Jialei Chen",
      "Xingwei Wang",
      "Chiu-Wing Sham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11629"
  },
  {
    "id": "arXiv:2111.11730",
    "title": "A Lightweight Encryption Scheme for IoT Devices in the Fog",
    "abstract": "A Lightweight Encryption Scheme for IoT Devices in the Fog",
    "descriptor": "",
    "authors": [
      "Hitesh Tewari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.11730"
  },
  {
    "id": "arXiv:2111.12063",
    "title": "Quantum Advantage for All",
    "abstract": "Quantum Advantage for All",
    "descriptor": "",
    "authors": [
      "Christoph M. Kirsch",
      "Stefanie Muroya Lei"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.12063"
  },
  {
    "id": "arXiv:2111.13003",
    "title": "The intrinsic Toeplitz structure and its applications in algebraic  Riccati equations",
    "abstract": "Comments: 28 pages, 1 figure",
    "descriptor": "\nComments: 28 pages, 1 figure\n",
    "authors": [
      "Zhen-Chen Guo",
      "Xin Liang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.13003"
  },
  {
    "id": "arXiv:2111.13143",
    "title": "Casimir preserving stochastic Lie-Poisson integrators",
    "abstract": "Comments: 18 pages, 5 figures, second version, all comments are welcome!",
    "descriptor": "\nComments: 18 pages, 5 figures, second version, all comments are welcome!\n",
    "authors": [
      "Erwin Luesink",
      "Sagy Ephrati",
      "Paolo Cifani",
      "Bernard Geurts"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.13143"
  },
  {
    "id": "arXiv:2111.13301",
    "title": "Simple Contrastive Representation Adversarial Learning for NLP Tasks",
    "abstract": "Simple Contrastive Representation Adversarial Learning for NLP Tasks",
    "descriptor": "",
    "authors": [
      "Deshui Miao",
      "Jiaqi Zhang",
      "Wenbo Xie",
      "Jian Song",
      "Xin Li",
      "Lijuan Jia",
      "Ning Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.13301"
  },
  {
    "id": "arXiv:2111.13445",
    "title": "How Well Do Sparse Imagenet Models Transfer?",
    "abstract": "Comments: 19 pages, 8 figures",
    "descriptor": "\nComments: 19 pages, 8 figures\n",
    "authors": [
      "Eugenia Iofinova",
      "Alexandra Peste",
      "Mark Kurtz",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13445"
  },
  {
    "id": "arXiv:2111.13684",
    "title": "Spatio-Temporal Joint Graph Convolutional Networks for Traffic  Forecasting",
    "abstract": "Spatio-Temporal Joint Graph Convolutional Networks for Traffic  Forecasting",
    "descriptor": "",
    "authors": [
      "Chuanpan Zheng",
      "Xiaoliang Fan",
      "Shirui Pan",
      "Zonghan Wu",
      "Cheng Wang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.13684"
  },
  {
    "id": "arXiv:2111.14042",
    "title": "On Thermodynamic Interpretation of Copula Entropy",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Jian Ma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2111.14042"
  },
  {
    "id": "arXiv:2111.14110",
    "title": "Enhancing Identification of Structure Function of Academic Articles  Using Contextual Information",
    "abstract": "Enhancing Identification of Structure Function of Academic Articles  Using Contextual Information",
    "descriptor": "",
    "authors": [
      "Bowen Ma",
      "Chengzhi Zhang",
      "Yuzhuo Wang",
      "Sanhong Deng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.14110"
  },
  {
    "id": "arXiv:2111.14341",
    "title": "ROBIN : A Benchmark for Robustness to Individual Nuisances in Real-World  Out-of-Distribution Shifts",
    "abstract": "Comments: Project webpage: this https URL",
    "descriptor": "\nComments: Project webpage: this https URL\n",
    "authors": [
      "Bingchen Zhao",
      "Shaozuo Yu",
      "Wufei Ma",
      "Mingxin Yu",
      "Shenxiao Mei",
      "Angtian Wang",
      "Ju He",
      "Alan Yuille",
      "Adam Kortylewski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.14341"
  },
  {
    "id": "arXiv:2111.14427",
    "title": "Self-Training of Halfspaces with Generalization Guarantees under Massart  Mislabeling Noise Model",
    "abstract": "Self-Training of Halfspaces with Generalization Guarantees under Massart  Mislabeling Noise Model",
    "descriptor": "",
    "authors": [
      "Lies Hadjadj",
      "Massih-Reza Amini",
      "Sana Louhichi",
      "Alexis Deschamps"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.14427"
  },
  {
    "id": "arXiv:2111.14831",
    "title": "MIST-net: Multi-domain Integrative Swin Transformer network for  Sparse-View CT Reconstruction",
    "abstract": "Comments: 24 pages, 10 figures, 57 references",
    "descriptor": "\nComments: 24 pages, 10 figures, 57 references\n",
    "authors": [
      "Jiayi Pan",
      "Weiwen Wu",
      "Zhifan Gao",
      "Heye Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.14831"
  },
  {
    "id": "arXiv:2111.15112",
    "title": "AugLiChem: Data Augmentation Library of Chemical Structures for Machine  Learning",
    "abstract": "Comments: Preprint under review 4 figures, 3 tables",
    "descriptor": "\nComments: Preprint under review 4 figures, 3 tables\n",
    "authors": [
      "Rishikesh Magar",
      "Yuyang Wang",
      "Cooper Lorsung",
      "Chen Liang",
      "Hariharan Ramasubramanian",
      "Peiyuan Li",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.15112"
  },
  {
    "id": "arXiv:2111.15182",
    "title": "Easy Semantification of Bioassays",
    "abstract": "Comments: 12 pages, 5 figures, Accepted for Publication in AIxIA 2021 (this https URL)",
    "descriptor": "\nComments: 12 pages, 5 figures, Accepted for Publication in AIxIA 2021 (this https URL)\n",
    "authors": [
      "Marco Anteghini",
      "Jennifer D'Souza",
      "Vitor A.P. Martins dos Santos",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15182"
  },
  {
    "id": "arXiv:2111.15207",
    "title": "NeeDrop: Self-supervised Shape Representation from Sparse Point Clouds  using Needle Dropping",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Alexandre Boulch",
      "Pierre-Alain Langlois",
      "Gilles Puy",
      "Renaud Marlet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15207"
  },
  {
    "id": "arXiv:2111.15380",
    "title": "Transient Stability of Low-Inertia Power Systems with Inverter-Based  Generation",
    "abstract": "Transient Stability of Low-Inertia Power Systems with Inverter-Based  Generation",
    "descriptor": "",
    "authors": [
      "Changjun He",
      "Xiuqiang He",
      "Hua Geng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.15380"
  },
  {
    "id": "arXiv:2111.15409",
    "title": "Fully Automatic Deep Learning Framework for Pancreatic Ductal  Adenocarcinoma Detection on Computed Tomography",
    "abstract": "Fully Automatic Deep Learning Framework for Pancreatic Ductal  Adenocarcinoma Detection on Computed Tomography",
    "descriptor": "",
    "authors": [
      "Nat\u00e1lia Alves",
      "Megan Schuurmans",
      "Geke Litjens",
      "Joeran S. Bosma",
      "John Hermans",
      "Henkjan Huisman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.15409"
  },
  {
    "id": "arXiv:2111.15506",
    "title": "Towards a comprehensive visualization of structure in data",
    "abstract": "Comments: 32 pages, 11 figures",
    "descriptor": "\nComments: 32 pages, 11 figures\n",
    "authors": [
      "Joan Garriga",
      "Frederic Bartumeus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.15506"
  },
  {
    "id": "arXiv:2111.15588",
    "title": "SimpleTron: Eliminating Softmax from Attention Computation",
    "abstract": "SimpleTron: Eliminating Softmax from Attention Computation",
    "descriptor": "",
    "authors": [
      "Uladzislau Yorsh",
      "Pavel Kord\u00edk",
      "Alexander Kovalenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15588"
  },
  {
    "id": "arXiv:2112.00093",
    "title": "\"Vironment\": An Art of Wearable Social Distancing",
    "abstract": "Comments: 6 pages, LaTex; fixed missing authors",
    "descriptor": "\nComments: 6 pages, LaTex; fixed missing authors\n",
    "authors": [
      "Steve Mann",
      "Cayden Pierce",
      "Christopher Tong",
      "Christina Mann"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.00093"
  },
  {
    "id": "arXiv:2112.00209",
    "title": "Environmental Sound Extraction Using Onomatopoeia",
    "abstract": "Comments: Submitted to ICASSP2022",
    "descriptor": "\nComments: Submitted to ICASSP2022\n",
    "authors": [
      "Yuki Okamoto",
      "Shota Horiguchi",
      "Masaaki Yamamoto",
      "Keisuke Imoto",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.00209"
  },
  {
    "id": "arXiv:2112.00229",
    "title": "Frequency Fitness Assignment: Optimization without a Bias for Good  Solutions can be Efficient",
    "abstract": "Frequency Fitness Assignment: Optimization without a Bias for Good  Solutions can be Efficient",
    "descriptor": "",
    "authors": [
      "Thomas Weise",
      "Zhize Wu",
      "Xinlu Li",
      "Yan Chen",
      "J\u00f6rg L\u00e4ssig"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.00229"
  },
  {
    "id": "arXiv:2112.00289",
    "title": "Point Cloud Segmentation Using Sparse Temporal Local Attention",
    "abstract": "Comments: 8 pages, 3 figures Published at the Australasian Conference on Robotics and Automation (ACRA) 2021",
    "descriptor": "\nComments: 8 pages, 3 figures Published at the Australasian Conference on Robotics and Automation (ACRA) 2021\n",
    "authors": [
      "Joshua Knights",
      "Peyman Moghadam",
      "Clinton Fookes",
      "Sridha Sridharan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00289"
  },
  {
    "id": "arXiv:2112.00503",
    "title": "Zero-Shot Cross-Lingual Machine Reading Comprehension via Inter-Sentence  Dependency Graph",
    "abstract": "Comments: Accepted to AAAI 2022",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Liyan Xu",
      "Xuchao Zhang",
      "Bo Zong",
      "Yanchi Liu",
      "Wei Cheng",
      "Jingchao Ni",
      "Haifeng Chen",
      "Liang Zhao",
      "Jinho D. Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00503"
  },
  {
    "id": "arXiv:2112.00573",
    "title": "Uniqueness for the q-state antiferromagnetic Potts model on the regular  tree",
    "abstract": "Comments: We find errors in Section 2",
    "descriptor": "\nComments: We find errors in Section 2\n",
    "authors": [
      "Chenlin Gu",
      "Wei Wu",
      "Kuan Yang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Mathematical Physics (math-ph)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.00573"
  },
  {
    "id": "arXiv:2112.00597",
    "title": "Wish you were here: Hindsight Goal Selection for long-horizon dexterous  manipulation",
    "abstract": "Wish you were here: Hindsight Goal Selection for long-horizon dexterous  manipulation",
    "descriptor": "",
    "authors": [
      "Todor Davchev",
      "Oleg Sushkov",
      "Jean-Baptiste Regli",
      "Stefan Schaal",
      "Yusuf Aytar",
      "Markus Wulfmeier",
      "Jon Scholz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00597"
  },
  {
    "id": "arXiv:2112.00656",
    "title": "Object-aware Video-language Pre-training for Retrieval",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Alex Jinpeng Wang",
      "Yixiao Ge",
      "Guanyu Cai",
      "Rui Yan",
      "Xudong Lin",
      "Ying Shan",
      "Xiaohu Qie",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00656"
  }
]
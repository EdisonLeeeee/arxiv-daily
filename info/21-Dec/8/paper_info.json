[
  {
    "id": "arXiv:2112.03262",
    "title": "Multi-scale Graph Convolutional Networks with Self-Attention",
    "abstract": "Graph convolutional networks (GCNs) have achieved remarkable learning ability\nfor dealing with various graph structural data recently. In general, deep GCNs\ndo not work well since graph convolution in conventional GCNs is a special form\nof Laplacian smoothing, which makes the representation of different nodes\nindistinguishable. In the literature, multi-scale information was employed in\nGCNs to enhance the expressive power of GCNs. However, over-smoothing\nphenomenon as a crucial issue of GCNs remains to be solved and investigated. In\nthis paper, we propose two novel multi-scale GCN frameworks by incorporating\nself-attention mechanism and multi-scale information into the design of GCNs.\nOur methods greatly improve the computational efficiency and prediction\naccuracy of the GCNs model. Extensive experiments on both node classification\nand graph classification demonstrate the effectiveness over several\nstate-of-the-art GCNs. Notably, the proposed two architectures can efficiently\nmitigate the over-smoothing problem of GCNs, and the layer of our model can\neven be increased to $64$.",
    "descriptor": "",
    "authors": [
      "Zhilong Xiong",
      "Jia Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03262"
  },
  {
    "id": "arXiv:2112.03265",
    "title": "A Deep-Learning Intelligent System Incorporating Data Augmentation for  Short-Term Voltage Stability Assessment of Power Systems",
    "abstract": "Facing the difficulty of expensive and trivial data collection and\nannotation, how to make a deep learning-based short-term voltage stability\nassessment (STVSA) model work well on a small training dataset is a challenging\nand urgent problem. Although a big enough dataset can be directly generated by\ncontingency simulation, this data generation process is usually cumbersome and\ninefficient; while data augmentation provides a low-cost and efficient way to\nartificially inflate the representative and diversified training datasets with\nlabel preserving transformations. In this respect, this paper proposes a novel\ndeep-learning intelligent system incorporating data augmentation for STVSA of\npower systems. First, due to the unavailability of reliable quantitative\ncriteria to judge the stability status for a specific power system,\nsemi-supervised cluster learning is leveraged to obtain labeled samples in an\noriginal small dataset. Second, to make deep learning applicable to the small\ndataset, conditional least squares generative adversarial networks\n(LSGAN)-based data augmentation is introduced to expand the original dataset\nvia artificially creating additional valid samples. Third, to extract temporal\ndependencies from the post-disturbance dynamic trajectories of a system, a\nbi-directional gated recurrent unit with attention mechanism based assessment\nmodel is established, which bi-directionally learns the significant time\ndependencies and automatically allocates attention weights. The test results\ndemonstrate the presented approach manages to achieve better accuracy and a\nfaster response time with original small datasets. Besides classification\naccuracy, this work employs statistical measures to comprehensively examine the\nperformance of the proposal.",
    "descriptor": "\nComments: Accepted by Applied Energy\n",
    "authors": [
      "Yang Li",
      "Meng Zhang",
      "Chen Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03265"
  },
  {
    "id": "arXiv:2112.03267",
    "title": "Communication and Energy Efficient Slimmable Federated Learning via  Superposition Coding and Successive Decoding",
    "abstract": "Mobile devices are indispensable sources of big data. Federated learning (FL)\nhas a great potential in exploiting these private data by exchanging locally\ntrained models instead of their raw data. However, mobile devices are often\nenergy limited and wirelessly connected, and FL cannot cope flexibly with their\nheterogeneous and time-varying energy capacity and communication throughput,\nlimiting the adoption. Motivated by these issues, we propose a novel energy and\ncommunication efficient FL framework, coined SlimFL. To resolve the\nheterogeneous energy capacity problem, each device in SlimFL runs a\nwidth-adjustable slimmable neural network (SNN). To address the heterogeneous\ncommunication throughput problem, each full-width (1.0x) SNN model and its\nhalf-width ($0.5$x) model are superposition-coded before transmission, and\nsuccessively decoded after reception as the 0.5x or $1.0$x model depending on\nthe channel quality. Simulation results show that SlimFL can simultaneously\ntrain both $0.5$x and $1.0$x models with reasonable accuracy and convergence\nspeed, compared to its vanilla FL counterpart separately training the two\nmodels using $2$x more communication resources. Surprisingly, SlimFL achieves\neven higher accuracy with lower energy footprints than vanilla FL for poor\nchannels and non-IID data distributions, under which vanilla FL converges\nslowly.",
    "descriptor": "\nComments: 11 pages, 10 Figures, presented at the International Workshop on Federated Learning for User Privacy and Data Confidentiality in Conjunction with ICML 2021 (FL-ICML'21). arXiv admin note: substantial text overlap with arXiv:2112.02543\n",
    "authors": [
      "Hankyul Baek",
      "Won Joon Yun",
      "Soyi Jung",
      "Jihong Park",
      "Mingyue Ji",
      "Joongheon Kim",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03267"
  },
  {
    "id": "arXiv:2112.03268",
    "title": "Synthetic ECG Signal Generation Using Generative Neural Networks",
    "abstract": "Electrocardiogram (ECG) datasets tend to be highly imbalanced due to the\nscarcity of abnormal cases. Additionally, the use of real patients' ECG is\nhighly regulated due to privacy issues. Therefore, there is always a need for\nmore ECG data, especially for the training of automatic diagnosis machine\nlearning models, which perform better when trained on a balanced dataset. We\nstudied the synthetic ECG generation capability of 5 different models from the\ngenerative adversarial network (GAN) family and compared their performances,\nthe focus being only on Normal cardiac cycles. Dynamic Time Warping (DTW),\nFr\\'echet, and Euclidean distance functions were employed to quantitatively\nmeasure performance. Five different methods for evaluating generated beats were\nproposed and applied. We also proposed 3 new concepts (threshold, accepted beat\nand productivity rate) and employed them along with the aforementioned methods\nas a systematic way for comparison between models. The results show that all\nthe tested models can to an extent successfully mass-generate acceptable\nheartbeats with high similarity in morphological features, and potentially all\nof them can be used to augment imbalanced datasets. However, visual inspections\nof generated beats favor BiLSTM-DC GAN and WGAN, as they produce statistically\nmore acceptable beats. Also, with regards to productivity rate, the Classic GAN\nis superior with a 72% productivity rate.",
    "descriptor": "",
    "authors": [
      "Edmond Adib",
      "Fatemeh Afghah",
      "John J. Prevost"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03268"
  },
  {
    "id": "arXiv:2112.03269",
    "title": "DIY Graphics Tab: A Cost-Effective Alternative to Graphics Tablet for  Educators",
    "abstract": "Everyday, more and more people are turning to online learning, which has\naltered our traditional classroom method. Recording lectures has always been a\nnormal task for online educators, and it has lately become even more important\nduring the epidemic because actual lessons are still being postponed in several\ncountries. When recording lectures, a graphics tablet is a great substitute for\na whiteboard because of its portability and ability to interface with\ncomputers. This graphic tablet, however, is too expensive for the majority of\ninstructors. In this paper, we propose a computer vision-based alternative to\nthe graphics tablet for instructors and educators, which functions largely in\nthe same way as a graphic tablet but just requires a pen, paper, and a laptop's\nwebcam. We call it \"Do-It-Yourself Graphics Tab\" or \"DIY Graphics Tab\". Our\nsystem receives a sequence of images of a person's writing on paper acquired by\na camera as input and outputs the screen containing the contents of the writing\nfrom the paper. The task is not straightforward since there are many obstacles\nsuch as occlusion due to the person's hand, random movement of the paper, poor\nlighting condition, perspective distortion due to the angle of view, etc. A\npipeline is used to route the input recording through our system, which\nconducts instance segmentation and preprocessing before generating the\nappropriate output. We also conducted user experience evaluations from the\nteachers and students, and their responses are examined in this paper.",
    "descriptor": "\nComments: Accepted in AAAI2022 workshop\n",
    "authors": [
      "Mohammad Imrul Jubair",
      "Arafat Ibne Yousuf",
      "Tashfiq Ahmed",
      "Hasanath Jamy",
      "Foisal Reza",
      "Mohsena Ashraf"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03269"
  },
  {
    "id": "arXiv:2112.03270",
    "title": "Toward a Taxonomy of Trust for Probabilistic Machine Learning",
    "abstract": "Probabilistic machine learning increasingly informs critical decisions in\nmedicine, economics, politics, and beyond. We need evidence to support that the\nresulting decisions are well-founded. To aid development of trust in these\ndecisions, we develop a taxonomy delineating where trust in an analysis can\nbreak down: (1) in the translation of real-world goals to goals on a particular\nset of available training data, (2) in the translation of abstract goals on the\ntraining data to a concrete mathematical problem, (3) in the use of an\nalgorithm to solve the stated mathematical problem, and (4) in the use of a\nparticular code implementation of the chosen algorithm. We detail how trust can\nfail at each step and illustrate our taxonomy with two case studies: an\nanalysis of the efficacy of microcredit and The Economist's predictions of the\n2020 US presidential election. Finally, we describe a wide variety of methods\nthat can be used to increase trust at each step of our taxonomy. The use of our\ntaxonomy highlights steps where existing research work on trust tends to\nconcentrate and also steps where establishing trust is particularly\nchallenging.",
    "descriptor": "\nComments: 18 pages, 2 figures\n",
    "authors": [
      "Tamara Broderick",
      "Andrew Gelman",
      "Rachael Meager",
      "Anna L. Smith",
      "Tian Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.03270"
  },
  {
    "id": "arXiv:2112.03271",
    "title": "Adapting BERT for Continual Learning of a Sequence of Aspect Sentiment  Classification Tasks",
    "abstract": "This paper studies continual learning (CL) of a sequence of aspect sentiment\nclassification (ASC) tasks. Although some CL techniques have been proposed for\ndocument sentiment classification, we are not aware of any CL work on ASC. A CL\nsystem that incrementally learns a sequence of ASC tasks should address the\nfollowing two issues: (1) transfer knowledge learned from previous tasks to the\nnew task to help it learn a better model, and (2) maintain the performance of\nthe models for previous tasks so that they are not forgotten. This paper\nproposes a novel capsule network based model called B-CL to address these\nissues. B-CL markedly improves the ASC performance on both the new task and the\nold tasks via forward and backward knowledge transfer. The effectiveness of\nB-CL is demonstrated through extensive experiments.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.02714, arXiv:2112.02706\n",
    "authors": [
      "Zixuan Ke",
      "Hu Xu",
      "Bing Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03271"
  },
  {
    "id": "arXiv:2112.03273",
    "title": "Dynamic Graph Learning-Neural Network for Multivariate Time Series  Modeling",
    "abstract": "Multivariate time series forecasting is a challenging task because the data\ninvolves a mixture of long- and short-term patterns, with dynamic\nspatio-temporal dependencies among variables. Existing graph neural networks\n(GNN) typically model multivariate relationships with a pre-defined spatial\ngraph or learned fixed adjacency graph. It limits the application of GNN and\nfails to handle the above challenges. In this paper, we propose a novel\nframework, namely static- and dynamic-graph learning-neural network (SDGL). The\nmodel acquires static and dynamic graph matrices from data to model long- and\nshort-term patterns respectively. Static matric is developed to capture the\nfixed long-term association pattern via node embeddings, and we leverage graph\nregularity for controlling the quality of the learned static graph. To capture\ndynamic dependencies among variables, we propose dynamic graphs learning method\nto generate time-varying matrices based on changing node features and static\nnode embeddings. And in the method, we integrate the learned static graph\ninformation as inductive bias to construct dynamic graphs and local\nspatio-temporal patterns better. Extensive experiments are conducted on two\ntraffic datasets with extra structural information and four time series\ndatasets, which show that our approach achieves state-of-the-art performance on\nalmost all datasets. If the paper is accepted, I will open the source code on\ngithub.",
    "descriptor": "",
    "authors": [
      "Zhuoling Li",
      "Gaowei Zhang",
      "Lingyu Xu",
      "Jie Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03273"
  },
  {
    "id": "arXiv:2112.03275",
    "title": "Smart Metering System Capable of Anomaly Detection by Bi-directional  LSTM Autoencoder",
    "abstract": "Anomaly detection is concerned with a wide range of applications such as\nfault detection, system monitoring, and event detection. Identifying anomalies\nfrom metering data obtained from smart metering system is a critical task to\nenhance reliability, stability, and efficiency of the power system. This paper\npresents an anomaly detection process to find outliers observed in the smart\nmetering system. In the proposed approach, bi-directional long short-term\nmemory (BiLSTM) based autoencoder is used and finds the anomalous data point.\nIt calculates the reconstruction error through autoencoder with the\nnon-anomalous data, and the outliers to be classified as anomalies are\nseparated from the non-anomalous data by predefined threshold. Anomaly\ndetection method based on the BiLSTM autoencoder is tested with the metering\ndata corresponding to 4 types of energy sources electricity/water/heating/hot\nwater collected from 985 households.",
    "descriptor": "\nComments: 6 pages, 6 figures, accepted by \"IEEE 40th International Conference on Consumer Electronics\"\n",
    "authors": [
      "Sangkeum Lee",
      "Hojun Jin",
      "Sarvar Hussain Nengroo",
      "Yoonmee Doh",
      "Chungho Lee",
      "Taewook Heo",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03275"
  },
  {
    "id": "arXiv:2112.03288",
    "title": "Dense Depth Priors for Neural Radiance Fields from Sparse Input Views",
    "abstract": "Neural radiance fields (NeRF) encode a scene into a neural representation\nthat enables photo-realistic rendering of novel views. However, a successful\nreconstruction from RGB images requires a large number of input views taken\nunder static conditions - typically up to a few hundred images for room-size\nscenes. Our method aims to synthesize novel views of whole rooms from an order\nof magnitude fewer images. To this end, we leverage dense depth priors in order\nto constrain the NeRF optimization. First, we take advantage of the sparse\ndepth data that is freely available from the structure from motion (SfM)\npreprocessing step used to estimate camera poses. Second, we use depth\ncompletion to convert these sparse points into dense depth maps and uncertainty\nestimates, which are used to guide NeRF optimization. Our method enables\ndata-efficient novel view synthesis on challenging indoor scenes, using as few\nas 18 images for an entire scene.",
    "descriptor": "\nComments: Video: this https URL\n",
    "authors": [
      "Barbara Roessle",
      "Jonathan T. Barron",
      "Ben Mildenhall",
      "Pratul P. Srinivasan",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03288"
  },
  {
    "id": "arXiv:2112.03315",
    "title": "Adversarial Machine Learning In Network Intrusion Detection Domain: A  Systematic Review",
    "abstract": "Due to their massive success in various domains, deep learning techniques are\nincreasingly used to design network intrusion detection solutions that detect\nand mitigate unknown and known attacks with high accuracy detection rates and\nminimal feature engineering. However, it has been found that deep learning\nmodels are vulnerable to data instances that can mislead the model to make\nincorrect classification decisions so-called (adversarial examples). Such\nvulnerability allows attackers to target NIDSs by adding small crafty\nperturbations to the malicious traffic to evade detection and disrupt the\nsystem's critical functionalities. The problem of deep adversarial learning has\nbeen extensively studied in the computer vision domain; however, it is still an\narea of open research in network security applications. Therefore, this survey\nexplores the researches that employ different aspects of adversarial machine\nlearning in the area of network intrusion detection in order to provide\ndirections for potential solutions. First, the surveyed studies are categorized\nbased on their contribution to generating adversarial examples, evaluating the\nrobustness of ML-based NIDs towards adversarial examples, and defending these\nmodels against such attacks. Second, we highlight the characteristics\nidentified in the surveyed research. Furthermore, we discuss the applicability\nof the existing generic adversarial attacks for the NIDS domain, the\nfeasibility of launching the proposed attacks in real-world scenarios, and the\nlimitations of the existing mitigation solutions.",
    "descriptor": "",
    "authors": [
      "Huda Ali Alatwi",
      "Charles Morisset"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.03315"
  },
  {
    "id": "arXiv:2112.03321",
    "title": "Noether Networks: Meta-Learning Useful Conserved Quantities",
    "abstract": "Progress in machine learning (ML) stems from a combination of data\navailability, computational resources, and an appropriate encoding of inductive\nbiases. Useful biases often exploit symmetries in the prediction problem, such\nas convolutional networks relying on translation equivariance. Automatically\ndiscovering these useful symmetries holds the potential to greatly improve the\nperformance of ML systems, but still remains a challenge. In this work, we\nfocus on sequential prediction problems and take inspiration from Noether's\ntheorem to reduce the problem of finding inductive biases to meta-learning\nuseful conserved quantities. We propose Noether Networks: a new type of\narchitecture where a meta-learned conservation loss is optimized inside the\nprediction function. We show, theoretically and experimentally, that Noether\nNetworks improve prediction quality, providing a general framework for\ndiscovering inductive biases in sequential problems.",
    "descriptor": "\nComments: Accepted to NeurIPS '21. The first two authors contributed equally\n",
    "authors": [
      "Ferran Alet",
      "Dylan Doblar",
      "Allan Zhou",
      "Joshua Tenenbaum",
      "Kenji Kawaguchi",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03321"
  },
  {
    "id": "arXiv:2112.03324",
    "title": "Neuro-Symbolic Inductive Logic Programming with Logical Neural Networks",
    "abstract": "Recent work on neuro-symbolic inductive logic programming has led to\npromising approaches that can learn explanatory rules from noisy, real-world\ndata. While some proposals approximate logical operators with differentiable\noperators from fuzzy or real-valued logic that are parameter-free thus\ndiminishing their capacity to fit the data, other approaches are only loosely\nbased on logic making it difficult to interpret the learned \"rules\". In this\npaper, we propose learning rules with the recently proposed logical neural\nnetworks (LNN). Compared to others, LNNs offer strong connection to classical\nBoolean logic thus allowing for precise interpretation of learned rules while\nharboring parameters that can be trained with gradient-based optimization to\neffectively fit the data. We extend LNNs to induce rules in first-order logic.\nOur experiments on standard benchmarking tasks confirm that LNN rules are\nhighly interpretable and can achieve comparable or higher accuracy due to their\nflexible parameterization.",
    "descriptor": "",
    "authors": [
      "Prithviraj Sen",
      "Breno W. S. R. de Carvalho",
      "Ryan Riegel",
      "Alexander Gray"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2112.03324"
  },
  {
    "id": "arXiv:2112.03325",
    "title": "Self-Supervised Camera Self-Calibration from Video",
    "abstract": "Camera calibration is integral to robotics and computer vision algorithms\nthat seek to infer geometric properties of the scene from visual input streams.\nIn practice, calibration is a laborious procedure requiring specialized data\ncollection and careful tuning. This process must be repeated whenever the\nparameters of the camera change, which can be a frequent occurrence for mobile\nrobots and autonomous vehicles. In contrast, self-supervised depth and\nego-motion estimation approaches can bypass explicit calibration by inferring\nper-frame projection models that optimize a view synthesis objective. In this\npaper, we extend this approach to explicitly calibrate a wide range of cameras\nfrom raw videos in the wild. We propose a learning algorithm to regress\nper-sequence calibration parameters using an efficient family of general camera\nmodels. Our procedure achieves self-calibration results with sub-pixel\nreprojection error, outperforming other learning-based methods. We validate our\napproach on a wide variety of camera geometries, including perspective,\nfisheye, and catadioptric. Finally, we show that our approach leads to\nimprovements in the downstream task of depth estimation, achieving\nstate-of-the-art results on the EuRoC dataset with greater computational\nefficiency than contemporary methods.",
    "descriptor": "",
    "authors": [
      "Jiading Fang",
      "Igor Vasiljevic",
      "Vitor Guizilini",
      "Rares Ambrus",
      "Greg Shakhnarovich",
      "Adrien Gaidon",
      "Matthew R.Walter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.03325"
  },
  {
    "id": "arXiv:2112.03328",
    "title": "Learning Connectivity with Graph Convolutional Networks for  Skeleton-based Action Recognition",
    "abstract": "Learning graph convolutional networks (GCNs) is an emerging field which aims\nat generalizing convolutional operations to arbitrary non-regular domains. In\nparticular, GCNs operating on spatial domains show superior performances\ncompared to spectral ones, however their success is highly dependent on how the\ntopology of input graphs is defined. In this paper, we introduce a novel\nframework for graph convolutional networks that learns the topological\nproperties of graphs. The design principle of our method is based on the\noptimization of a constrained objective function which learns not only the\nusual convolutional parameters in GCNs but also a transformation basis that\nconveys the most relevant topological relationships in these graphs.\nExperiments conducted on the challenging task of skeleton-based action\nrecognition shows the superiority of the proposed method compared to\nhandcrafted graph design as well as the related work.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2104.04255, arXiv:2104.05482\n",
    "authors": [
      "Hichem Sahbi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03328"
  },
  {
    "id": "arXiv:2112.03329",
    "title": "Inconsistent Planning: When in doubt, toss a coin!",
    "abstract": "One of the most widespread human behavioral biases is the present bias -- the\ntendency to overestimate current costs by a bias factor. Kleinberg and Oren\n(2014) introduced an elegant graph-theoretical model of inconsistent planning\ncapturing the behavior of a present-biased agent accomplishing a set of\nactions. The essential measure of the system introduced by Kleinberg and Oren\nis the cost of irrationality -- the ratio of the total cost of the actions\nperformed by the present-biased agent to the optimal cost. This measure is\nvital for a task designer to estimate the aftermaths of human behavior related\nto time-inconsistent planning, including procrastination and abandonment.\nAs we prove in this paper, the cost of irrationality is highly susceptible to\nthe agent's choices when faced with a few possible actions of equal estimated\ncosts. To address this issue, we propose a modification of Kleinberg-Oren's\nmodel of inconsistent planning. In our model, when an agent selects from\nseveral options of minimum prescribed cost, he uses a randomized procedure. We\nexplore the algorithmic complexity of computing and estimating the cost of\nirrationality in the new model.",
    "descriptor": "",
    "authors": [
      "Yuriy Dementiev",
      "Fedor V. Fomin",
      "Artur Ignatiev"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.03329"
  },
  {
    "id": "arXiv:2112.03334",
    "title": "A Family of Density-Scaled Filtered Complexes",
    "abstract": "We develop novel methods for using persistent homology to infer the homology\nof an unknown Riemannian manifold $(M, g)$ from a point cloud sampled from an\narbitrary smooth probability density function. Standard distance-based filtered\ncomplexes, such as the \\v{C}ech complex, often have trouble distinguishing\nnoise from features that are simply small. We address this problem by defining\na family of \"density-scaled filtered complexes\" that includes a density-scaled\n\\v{C}ech complex and a density-scaled Vietoris--Rips complex. We show that the\ndensity-scaled \\v{C}ech complex is homotopy-equivalent to $M$ for filtration\nvalues in an interval whose starting point converges to $0$ in probability as\nthe number of points $N \\to \\infty$ and whose ending point approaches infinity\nas $N \\to \\infty$. By contrast, the standard \\v{C}ech complex may only be\nhomotopy-equivalent to $M$ for a very small range of filtration values. The\ndensity-scaled filtered complexes also have the property that they are\ninvariant under conformal transformations, such as scaling. We implement a\nfiltered complex $\\widehat{DVR}$ that approximates the density-scaled\nVietoris--Rips complex, and we empirically test the performance of our\nimplementation. As examples, we use $\\widehat{DVR}$ to identify clusters that\nhave different densities, and we apply $\\widehat{DVR}$ to a time-delay\nembedding of the Lorenz dynamical system. Our implementation is stable (under\nconditions that are almost surely satisfied) and designed to handle outliers in\nthe point cloud that do not lie on $M$.",
    "descriptor": "\nComments: 40 pages, 14 figures\n",
    "authors": [
      "Abigail Hickok"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2112.03334"
  },
  {
    "id": "arXiv:2112.03337",
    "title": "Dense and well-connected subgraph detection in dual networks",
    "abstract": "Dense subgraph discovery is a fundamental problem in graph mining with a wide\nrange of applications \\cite{gionis2015dense}. Despite a large number of\napplications ranging from computational neuroscience to social network\nanalysis, that take as input a {\\em dual} graph, namely a pair of graphs on the\nsame set of nodes, dense subgraph discovery methods focus on a single graph\ninput with few notable exceptions\n\\cite{semertzidis2019finding,charikar2018finding,reinthal2016finding,jethava2015finding}.\nIn this work, we focus the following problem: given a pair of graphs $G,H$ on\nthe same set of nodes $V$, how do we find a subset of nodes $S \\subseteq V$\nthat induces a well-connected subgraph in $G$ and a dense subgraph in $H$?\nOur formulation generalizes previous research on dual graphs\n\\cite{Wu+15,WuZLFJZ16,Cui2018}, by enabling the {\\em control} of the\nconnectivity constraint on $G$. We propose a novel mathematical formulation\nbased on $k$-edge connectivity, and prove that it is solvable exactly in\npolynomial time. We compare our method to state-of-the-art competitors; we find\nempirically that ranging the connectivity constraint enables the practitioner\nto obtain insightful information that is otherwise inaccessible. Finally, we\nshow that our proposed mining tool can be used to better understand how users\ninteract on Twitter, and connectivity aspects of human brain networks with and\nwithout Autism Spectrum Disorder (ASD).",
    "descriptor": "",
    "authors": [
      "Tianyi Chen",
      "Francesco Bonchi",
      "David Garcia-Soriano",
      "Atsushi Miyauchi",
      "Charalampos E. Tsourakakis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.03337"
  },
  {
    "id": "arXiv:2112.03339",
    "title": "Neural Energy Casimir Control",
    "abstract": "The energy Casimir method is an effective controller design approach to\nstabilize port-Hamiltonian systems at a desired equilibrium. However, its\napplication relies on finding suitable Casimir and Lyapunov functions, which\nare generally intractable. In this paper, we propose a neural network-based\nframework to learn these functions. We show how to achieve equilibrium\nassignment by adding suitable regularization terms in the optimization cost. We\nalso propose a parameterization of Casimir functions for reducing the training\ncomplexity. Moreover, the distance between the equilibrium point of the learned\nLyapunov function and the desired equilibrium point is analyzed, which\nindicates that for small suboptimality gaps, the error decreases linearly with\nrespect to the training loss. Our methods are backed up by simulations on a\npendulum system.",
    "descriptor": "",
    "authors": [
      "Liang Xu",
      "Muhammad Zakwan",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03339"
  },
  {
    "id": "arXiv:2112.03340",
    "title": "Label Hallucination for Few-Shot Classification",
    "abstract": "Few-shot classification requires adapting knowledge learned from a large\nannotated base dataset to recognize novel unseen classes, each represented by\nfew labeled examples. In such a scenario, pretraining a network with high\ncapacity on the large dataset and then finetuning it on the few examples causes\nsevere overfitting. At the same time, training a simple linear classifier on\ntop of \"frozen\" features learned from the large labeled dataset fails to adapt\nthe model to the properties of the novel classes, effectively inducing\nunderfitting. In this paper we propose an alternative approach to both of these\ntwo popular strategies. First, our method pseudo-labels the entire large\ndataset using the linear classifier trained on the novel classes. This\neffectively \"hallucinates\" the novel classes in the large dataset, despite the\nnovel categories not being present in the base database (novel and base classes\nare disjoint). Then, it finetunes the entire model with a distillation loss on\nthe pseudo-labeled base examples, in addition to the standard cross-entropy\nloss on the novel dataset. This step effectively trains the network to\nrecognize contextual and appearance cues that are useful for the novel-category\nrecognition but using the entire large-scale base dataset and thus overcoming\nthe inherent data-scarcity problem of few-shot learning. Despite the simplicity\nof the approach, we show that that our method outperforms the state-of-the-art\non four well-established few-shot classification benchmarks.",
    "descriptor": "\nComments: Accepted by AAAI 2022. Code is available: this https URL\n",
    "authors": [
      "Yiren Jian",
      "Lorenzo Torresani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03340"
  },
  {
    "id": "arXiv:2112.03345",
    "title": "Learning-based synthesis of robust linear time-invariant controllers",
    "abstract": "Recent advances in learning for control allow to synthesize controllers from\nlearned system dynamics and maintain robust stability guarantees. However, no\napproach is well-suited for training linear time-invariant (LTI) controllers\nusing arbitrary learned models of the dynamics. This article introduces a\nmethod to do so. It uses a robust control framework to derive robust stability\ncriteria. It also uses simulated policy rollouts to obtain gradients on the\ncontroller parameters, which serve to improve the closed-loop performance. By\nformulating the stability criteria as penalties with computable gradients, they\ncan be used to guide the controller parameters toward robust stability during\ngradient descent. The approach is flexible as it does not restrict the type of\nlearned model for the simulated rollouts. The robust control framework ensures\nthat the controller is already robustly stabilizing when first implemented on\nthe actual system and no data is yet collected. It also ensures that the system\nstays stable in the event of a shift in dynamics, given the system behavior\nremains within assumed uncertainty bounds. We demonstrate the approach by\nsynthesizing a controller for simulated autonomous lane change maneuvers. This\nwork thus presents a flexible approach to learning robustly stabilizing LTI\ncontrollers that take advantage of modern machine learning techniques.",
    "descriptor": "",
    "authors": [
      "Marc-Antoine Beaudoin",
      "Benoit Boulet"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03345"
  },
  {
    "id": "arXiv:2112.03346",
    "title": "Multidimensional Assignment Problem for multipartite entity resolution",
    "abstract": "Multipartite entity resolution aims at integrating records from multiple\ndatasets into one entity. We derive a mathematical formulation for a general\nclass of record linkage problems in multipartite entity resolution across many\ndatasets as a combinatorial optimization problem known as the multidimensional\nassignment problem. As a motivation for our approach, we illustrate the\nadvantage of multipartite entity resolution over sequential bipartite matching.\nBecause the optimization problem is NP-hard, we apply two heuristic procedures,\na Greedy algorithm and very large scale neighborhood search, to solve the\nassignment problem and find the most likely matching of records from multiple\ndatasets into a single entity. We evaluate and compare the performance of these\nalgorithms and their modifications on synthetically generated data. We perform\ncomputational experiments to compare performance of recent heuristic, the very\nlarge-scale neighborhood search, with a Greedy algorithm, another heuristic for\nthe MAP, as well as with two versions of genetic algorithm, a general\nmetaheuristic. Importantly, we perform experiments to compare two alternative\nmethods of re-starting the search for the former heuristic, specifically a\nrandom-sampling multi-start and a deterministic design-based multi-start. We\nfind evidence that design-based multi-start can be more efficient as the size\nof databases grow large. In addition, we show that very large scale search,\nespecially its multi-start version, outperforms simple Greedy heuristic.\nHybridization of Greedy search with very large scale neighborhood search\nimproves the performance. Using multi-start with as few as three additional\nruns of very large scale search offers some improvement in the performance of\nthe very large scale search procedure. Last, we propose an approach to\nevaluating complexity of the very large-scale neighborhood search.",
    "descriptor": "",
    "authors": [
      "Alla Kammerdiner",
      "Alexander Semenov",
      "Eduardo Pasiliao"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03346"
  },
  {
    "id": "arXiv:2112.03347",
    "title": "Structured learning of safety guarantees for the control of uncertain  dynamical systems",
    "abstract": "Approaches to keeping a dynamical system within state constraints typically\nrely on a model-based safety condition to limit the control signals. In the\nface of significant modeling uncertainty, the system can suffer from important\nperformance penalties due to the safety condition becoming overly conservative.\nMachine learning can be employed to reduce the uncertainty around the system\ndynamics, and allow for higher performance. In this article, we propose the\nsafe uncertainty learning principle, and argue that the learning must be\nproperly structured to preserve safety guarantees. For instance, robust safety\nconditions are necessary, and they must be initialized with conservative\nuncertainty bounds prior to learning. Also, the uncertainty bounds should only\nbe tightened if the collected data sufficiently capture the future system\nbehavior. To support the principle, two example problems are solved with\ncontrol barrier functions: a lane-change controller for an autonomous vehicle,\nand an adaptive cruise controller. This work offers a way to evaluate if\nmachine learning preserves safety guarantees during the control of uncertain\ndynamical systems. It also highlights challenging aspects of learning for\ncontrol.",
    "descriptor": "",
    "authors": [
      "Marc-Antoine Beaudoin",
      "Benoit Boulet"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03347"
  },
  {
    "id": "arXiv:2112.03350",
    "title": "Test-Time Detection of Backdoor Triggers for Poisoned Deep Neural  Networks",
    "abstract": "Backdoor (Trojan) attacks are emerging threats against deep neural networks\n(DNN). A DNN being attacked will predict to an attacker-desired target class\nwhenever a test sample from any source class is embedded with a backdoor\npattern; while correctly classifying clean (attack-free) test samples. Existing\nbackdoor defenses have shown success in detecting whether a DNN is attacked and\nin reverse-engineering the backdoor pattern in a \"post-training\" regime: the\ndefender has access to the DNN to be inspected and a small, clean dataset\ncollected independently, but has no access to the (possibly poisoned) training\nset of the DNN. However, these defenses neither catch culprits in the act of\ntriggering the backdoor mapping, nor mitigate the backdoor attack at test-time.\nIn this paper, we propose an \"in-flight\" defense against backdoor attacks on\nimage classification that 1) detects use of a backdoor trigger at test-time;\nand 2) infers the class of origin (source class) for a detected trigger\nexample. The effectiveness of our defense is demonstrated experimentally\nagainst different strong backdoor attacks.",
    "descriptor": "",
    "authors": [
      "Xi Li",
      "Zhen Xiang",
      "David J. Miller",
      "George Kesidis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03350"
  },
  {
    "id": "arXiv:2112.03351",
    "title": "Audio Deepfake Perceptions in College Going Populations",
    "abstract": "Deepfake is content or material that is generated or manipulated using AI\nmethods, to pass off as real. There are four different deepfake types: audio,\nvideo, image and text. In this research we focus on audio deepfakes and how\npeople perceive it. There are several audio deepfake generation frameworks, but\nwe chose MelGAN which is a non-autoregressive and fast audio deepfake\ngenerating framework, requiring fewer parameters. This study tries to assess\naudio deepfake perceptions among college students from different majors. This\nstudy also answers the question of how their background and major can affect\ntheir perception towards AI generated deepfakes. We also analyzed the results\nbased on different aspects of: grade level, complexity of the grammar used in\nthe audio clips, length of the audio clips, those who knew the term deepfakes\nand those who did not, as well as the political angle. It is interesting that\nthe results show when an audio clip has a political connotation, it can affect\nwhat people think about whether it is real or fake, even if the content is\nfairly similar. This study also explores the question of how background and\nmajor can affect perception towards deepfakes.",
    "descriptor": "\nComments: Summary of study findings\n",
    "authors": [
      "Gabrielle Watson",
      "Zahra Khanjani",
      "Vandana P. Janeja"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.03351"
  },
  {
    "id": "arXiv:2112.03354",
    "title": "Labeling Out-of-View Objects in Immersive Analytics to Support Situated  Visual Searching",
    "abstract": "Augmented Reality (AR) embeds digital information into objects of the\nphysical world. Data can be shown in-situ, thereby enabling real-time visual\ncomparisons and object search in real-life user tasks, such as comparing\nproducts and looking up scores in a sports game. While there have been studies\non designing AR interfaces for situated information retrieval, there has only\nbeen limited research on AR object labeling for visual search tasks in the\nspatial environment. In this paper, we identify and categorize different design\naspects in AR label design and report on a formal user study on labels for\nout-of-view objects to support visual search tasks in AR. We design three\nvisualization techniques for out-of-view object labeling in AR, which\nrespectively encode the relative physical position (height-encoded), the\nrotational direction (angle-encoded), and the label values (value-encoded) of\nthe objects. We further implement two traditional in-view object labeling\ntechniques, where labels are placed either next to the respective objects\n(situated) or at the edge of the AR FoV (boundary). We evaluate these five\ndifferent label conditions in three visual search tasks for static objects. Our\nstudy shows that out-of-view object labels are beneficial when searching for\nobjects outside the FoV, spatial orientation, and when comparing multiple\nspatially sparse objects. Angle-encoded labels with directional cues of the\nsurrounding objects have the overall best performance with the highest user\nsatisfaction. We discuss the implications of our findings for future immersive\nAR interface design.",
    "descriptor": "\nComments: To be published in IEEE Transactions on Visualization and Computer Graphics\n",
    "authors": [
      "Tica Lin",
      "Yalong Yang",
      "Johanna Beyer",
      "Hanspeter Pfister"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.03354"
  },
  {
    "id": "arXiv:2112.03358",
    "title": "Associative Memories Using Complex-Valued Hopfield Networks Based on  Spin-Torque Oscillator Arrays",
    "abstract": "Simulations of complex-valued Hopfield networks based on spin-torque\noscillators can recover phase-encoded images. Sequences of memristor-augmented\ninverters provide tunable delay elements that implement complex weights by\nphase shifting the oscillatory output of the oscillators. Pseudo-inverse\ntraining suffices to store at least 12 images in a set of 192 oscillators,\nrepresenting 16$\\times$12 pixel images. The energy required to recover an image\ndepends on the desired error level. For the oscillators and circuitry\nconsidered here, 5 % root mean square deviations from the ideal image require\napproximately 5 $\\mu$s and consume roughly 130 nJ. Simulations show that the\nnetwork functions well when the resonant frequency of the oscillators can be\ntuned to have a fractional spread less than $10^{-3}$, depending on the\nstrength of the feedback.",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Nitin Prasad",
      "Prashansa Mukim",
      "Advait Madhavan",
      "Mark D. Stiles"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.03358"
  },
  {
    "id": "arXiv:2112.03359",
    "title": "Alice in Passphraseland: Assessing the Memorability of Familiar  Vocabularies for System-Assigned Passphrases",
    "abstract": "Text-based secrets are still the most commonly used authentication mechanism\nin information systems. IT managers must strike a balance between security and\nmemorability while developing password policies. Initially introduced as more\nsecure authentication keys that people could recall, passphrases are passwords\nconsisting of multiple words. However, when left to the choice of users, they\ntend to choose predictable natural language patterns in passphrases, resulting\nin vulnerability to guessing attacks. System-assigned authentication keys can\nbe guaranteed to be secure, but this comes at a cost to memorability. In this\nstudy we investigate the memorability of system-assigned passphrases from a\nfamiliar vocabulary to the user. The passphrases are generated with the\nGenerative Pre-trained Transformer 2 (GPT-2) model trained on the familiar\nvocabulary and are readable, pronounceable, sentence like passphrases\nresembling natural English sentences. Through an online user study with 500\nparticipants on Amazon Mechanical Turk, we test our hypothesis - following a\nspaced repetition schedule, passphrases as natural English sentences, based on\nfamiliar vocabulary are easier to recall than passphrases composed of random\ncommon words. As a proof-of-concept, we tested the idea with Amazon Mechanical\nTurk participants by assigning them GPT-2 generated passphrases based on\nstories they were familiar with. Contrary to expectations, following a spaced\nrepetition schedule, passphrases as natural English sentences, based on\nfamiliar vocabulary performed similarly to system-assigned passphrases based on\nrandom common words.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Noopa Jagadeesh",
      "Miguel Vargas Martin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.03359"
  },
  {
    "id": "arXiv:2112.03360",
    "title": "Cadence: A Practical Time-series Partitioning Algorithm for Unlabeled  IoT Sensor Streams",
    "abstract": "Timeseries partitioning is an essential step in most machine-learning driven,\nsensor-based IoT applications. This paper introduces a sample-efficient,\nrobust, time-series segmentation model and algorithm. We show that by learning\na representation specifically with the segmentation objective based on maximum\nmean discrepancy (MMD), our algorithm can robustly detect time-series events\nacross different applications. Our loss function allows us to infer whether\nconsecutive sequences of samples are drawn from the same distribution (null\nhypothesis) and determines the change-point between pairs that reject the null\nhypothesis (i.e., come from different distributions). We demonstrate its\napplicability in a real-world IoT deployment for ambient-sensing based activity\nrecognition. Moreover, while many works on change-point detection exist in the\nliterature, our model is significantly simpler and matches or outperforms\nstate-of-the-art methods. We can fully train our model in 9-93 seconds on\naverage with little variation in hyperparameters for data across different\napplications.",
    "descriptor": "\nComments: 27 pages, 13 figures\n",
    "authors": [
      "Tahiya Chowdhury",
      "Murtadha Aldeer",
      "Shantanu Laghate",
      "Jorge Ortiz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03360"
  },
  {
    "id": "arXiv:2112.03364",
    "title": "Scalable Geometric Deep Learning on Molecular Graphs",
    "abstract": "Deep learning in molecular and materials sciences is limited by the lack of\nintegration between applied science, artificial intelligence, and\nhigh-performance computing. Bottlenecks with respect to the amount of training\ndata, the size and complexity of model architectures, and the scale of the\ncompute infrastructure are all key factors limiting the scaling of deep\nlearning for molecules and materials. Here, we present $\\textit{LitMatter}$, a\nlightweight framework for scaling molecular deep learning methods. We train\nfour graph neural network architectures on over 400 GPUs and investigate the\nscaling behavior of these methods. Depending on the model architecture,\ntraining time speedups up to $60\\times$ are seen. Empirical neural scaling\nrelations quantify the model-dependent scaling and enable optimal compute\nresource allocation and the identification of scalable molecular geometric deep\nlearning model implementations.",
    "descriptor": "\nComments: 7 pages, 3 figures, NeurIPS 2021 AI for Science workshop\n",
    "authors": [
      "Nathan C. Frey",
      "Siddharth Samsi",
      "Joseph McDonald",
      "Lin Li",
      "Connor W. Coley",
      "Vijay Gadepally"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.03364"
  },
  {
    "id": "arXiv:2112.03371",
    "title": "Graphical Models with Attention for Context-Specific Independence and an  Application to Perceptual Grouping",
    "abstract": "Discrete undirected graphical models, also known as Markov Random Fields\n(MRFs), can flexibly encode probabilistic interactions of multiple variables,\nand have enjoyed successful applications to a wide range of problems. However,\na well-known yet little studied limitation of discrete MRFs is that they cannot\ncapture context-specific independence (CSI). Existing methods require carefully\ndeveloped theories and purpose-built inference methods, which limit their\napplications to only small-scale problems. In this paper, we propose the Markov\nAttention Model (MAM), a family of discrete MRFs that incorporates an attention\nmechanism. The attention mechanism allows variables to dynamically attend to\nsome other variables while ignoring the rest, and enables capturing of CSIs in\nMRFs. A MAM is formulated as an MRF, allowing it to benefit from the rich set\nof existing MRF inference methods and scale to large models and datasets. To\ndemonstrate MAM's capabilities to capture CSIs at scale, we apply MAMs to\ncapture an important type of CSI that is present in a symbolic approach to\nrecurrent computations in perceptual grouping. Experiments on two recently\nproposed synthetic perceptual grouping tasks and on realistic images\ndemonstrate the advantages of MAMs in sample-efficiency, interpretability and\ngeneralizability when compared with strong recurrent neural network baselines,\nand validate MAM's capabilities to efficiently capture CSIs at scale.",
    "descriptor": "",
    "authors": [
      "Guangyao Zhou",
      "Wolfgang Lehrach",
      "Antoine Dedieu",
      "Miguel L\u00e1zaro-Gredilla",
      "Dileep George"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03371"
  },
  {
    "id": "arXiv:2112.03376",
    "title": "Convergence Guarantees for Deep Epsilon Greedy Policy Learning",
    "abstract": "Policy learning is a quickly growing area. As robotics and computers control\nday-to-day life, their error rate needs to be minimized and controlled. There\nare many policy learning methods and provable error rates that accompany them.\nWe show an error or regret bound and convergence of the Deep Epsilon Greedy\nmethod which chooses actions with a neural network's prediction. In experiments\nwith the real-world dataset MNIST, we construct a nonlinear reinforcement\nlearning problem. We witness how with either high or low noise, some methods do\nand some do not converge which agrees with our proof of convergence.",
    "descriptor": "",
    "authors": [
      "Michael Rawson",
      "Radu Balan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.03376"
  },
  {
    "id": "arXiv:2112.03377",
    "title": "RafterNet: Probabilistic predictions in multi-response regression",
    "abstract": "A fully nonparametric approach for making probabilistic predictions in\nmulti-response regression problems is introduced. Random forests are used as\nmarginal models for each response variable and, as novel contribution of the\npresent work, the dependence between the multiple response variables is modeled\nby a generative neural network. This combined modeling approach of random\nforests, corresponding empirical marginal residual distributions and a\ngenerative neural network is referred to as RafterNet. Multiple datasets serve\nas examples to demonstrate the flexibility of the approach and its impact for\nmaking probabilistic forecasts.",
    "descriptor": "",
    "authors": [
      "Marius Hofert",
      "Avinash Prasad",
      "Mu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.03377"
  },
  {
    "id": "arXiv:2112.03378",
    "title": "Differentiable Generalised Predictive Coding",
    "abstract": "This paper deals with differentiable dynamical models congruent with neural\nprocess theories in neuroscience that cast brain function as hierarchical\nfiltering aiming at the refinement of an internal generative model explaining\nobservations. Our work extends existing implementations of predictive coding\nwith exact gradients and allows integration with deep neural networks for\nnon-linear latent state parameterization. In contrast to Gradient Descent in\ncombination with error backpropagation, such gradient based predictive coding\noptimises neural networks locally in each layer by optimising\nprecision-weighted prediction errors that propagate from data towards latent\nstates. Predictions flow backwards, from latent states towards lower layers.\nThe model suggested here, GPC, uses exact gradients to learn hierarchical and\ndynamical predictions of lower latent states. Hierarchical predictions encode\nthe perceived content and its structure. Dynamical predictions address changes\nin the encoded content. As a result, hierarchical and dynamical predictions\naddress different aspects of the same latent states. Since changes in latent\nstates are influenced by the content they represent and vice versa, both\npathways interact and allow to encode representations of content-dynamics\ndependencies across spatio-temporal scales and even backwards in time. We apply\nGPC to various perception tasks on sequential data with adaptive sampling\nrates. We discuss possibilities to relax the assumption of linearly\nhierarchical model layout in favour of arbitrary graph structure. Finally, we\nsketch out ideas for efficient perception and planning in nested\nspatio-temporal hierarchies and discuss the connection to Markov Blankets in\nthe brain.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Ofner",
      "Sebastian Stober"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.03378"
  },
  {
    "id": "arXiv:2112.03379",
    "title": "Efficient Continuous Manifold Learning for Time Series Modeling",
    "abstract": "Modeling non-Euclidean data is drawing attention along with the unprecedented\nsuccesses of deep neural networks in diverse fields. In particular, symmetric\npositive definite (SPD) matrix is being actively studied in computer vision,\nsignal processing, and medical image analysis, thanks to its ability to learn\nappropriate statistical representations. However, due to its strong\nconstraints, it remains challenging for optimization problems or inefficient\ncomputation costs, especially, within a deep learning framework. In this paper,\nwe propose to exploit a diffeomorphism mapping between Riemannian manifolds and\na Cholesky space, by which it becomes feasible not only to efficiently solve\noptimization problems but also to reduce computation costs greatly. Further, in\norder for dynamics modeling in time series data, we devise a continuous\nmanifold learning method by integrating a manifold ordinary differential\nequation and a gated recurrent neural network in a systematic manner. It is\nnoteworthy that because of the nice parameterization of matrices in a Cholesky\nspace, it is straightforward to train our proposed network with Riemannian\ngeometric metrics equipped. We demonstrate through experiments that the\nproposed model can be efficiently and reliably trained as well as outperform\nexisting manifold methods and state-of-the-art methods in two classification\ntasks: action recognition and sleep staging classification.",
    "descriptor": "",
    "authors": [
      "Seungwoo Jeong",
      "Wonjun Ko",
      "Ahmad Wisnu Mulyadi",
      "Heung-Il Suk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03379"
  },
  {
    "id": "arXiv:2112.03383",
    "title": "Graph Neural Networks Accelerated Molecular Dynamics",
    "abstract": "Molecular Dynamics (MD) simulation is a powerful tool for understanding the\ndynamics and structure of matter. Since the resolution of MD is atomic-scale,\nachieving long time-scale simulations with femtosecond integration is very\nexpensive. In each MD step, numerous redundant computations are performed which\ncan be learnt and avoided. These redundant computations can be surrogated and\nmodeled by a deep learning model like a Graph Neural Network (GNN). In this\nwork, we developed a GNN Accelerated Molecular Dynamics (GAMD) model that\nachieves fast and accurate force predictions and generates trajectories\nconsistent with the classical MD simulations. Our results show that GAMD can\naccurately predict the dynamics of two typical molecular systems, Lennard-Jones\n(LJ) particles and Water (LJ+Electrostatics). GAMD's learning and inference are\nagnostic to the scale, where it can scale to much larger systems at test time.\nWe also performed a comprehensive benchmark test comparing our implementation\nof GAMD to production-level MD softwares, where we showed GAMD is competitive\nwith them on the large-scale simulation.",
    "descriptor": "\nComments: preprint; under review\n",
    "authors": [
      "Zijie Li",
      "Kazem Meidani",
      "Prakarsh Yadav",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.03383"
  },
  {
    "id": "arXiv:2112.03386",
    "title": "Guided Imitation of Task and Motion Planning",
    "abstract": "While modern policy optimization methods can do complex manipulation from\nsensory data, they struggle on problems with extended time horizons and\nmultiple sub-goals. On the other hand, task and motion planning (TAMP) methods\nscale to long horizons but they are computationally expensive and need to\nprecisely track world state. We propose a method that draws on the strength of\nboth methods: we train a policy to imitate a TAMP solver's output. This\nproduces a feed-forward policy that can accomplish multi-step tasks from\nsensory data. First, we build an asynchronous distributed TAMP solver that can\nproduce supervision data fast enough for imitation learning. Then, we propose a\nhierarchical policy architecture that lets us use partially trained control\npolicies to speed up the TAMP solver. In robotic manipulation tasks with 7-DoF\njoint control, the partially trained policies reduce the time needed for\nplanning by a factor of up to 2.6. Among these tasks, we can learn a policy\nthat solves the RoboSuite 4-object pick-place task 88% of the time from object\npose observations and a policy that solves the RoboDesk 9-goal benchmark 79% of\nthe time from RGB images (averaged across the 9 disparate tasks).",
    "descriptor": "\nComments: 16 pages, 6 figures, 2 tables, submitted to Conference on Robot Learning 2021, to be published in Proceedings of Machine Learning Research\n",
    "authors": [
      "Michael James McDonald",
      "Dylan Hadfield-Menell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03386"
  },
  {
    "id": "arXiv:2112.03391",
    "title": "A hybrid projection algorithm for stochastic differential equations on  manifolds",
    "abstract": "Stochastic differential equations projected onto manifolds occur widely in\nphysics, chemistry, biology, engineering, nanotechnology and optimization\ntheory. In some problems one can use an intrinsic coordinate system on the\nmanifold, but this is often computationally impractical. Numerical projections\nare preferable in many cases. We derive an algorithm to solve these, using\nadiabatic elimination and a constraining potential. We also review earlier\nproposed algorithms. Our hybrid midpoint projection algorithm uses a midpoint\nprojection on a tangent manifold, combined with a normal projection to satisfy\nthe constraints. We show from numerical examples on spheroidal and\nhyperboloidal surfaces that this has greatly reduced errors compared to earlier\nmethods using either a hybrid Euler with tangential and normal projections or\npurely tangential derivative methods. Our technique can handle multiple\nconstraints. This allows, for example, the treatment of manifolds that embody\nseveral conserved quantities. The resulting algorithm is accurate, relatively\nsimple to implement and efficient.",
    "descriptor": "",
    "authors": [
      "Ria Rushin Joseph",
      "Jesse van Rhijn",
      "Peter D. Drummond"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.03391"
  },
  {
    "id": "arXiv:2112.03395",
    "title": "Manas: Mining Software Repositories to Assist AutoML",
    "abstract": "Today deep learning is widely used for building software. A software\nengineering problem with deep learning is that finding an appropriate\nconvolutional neural network (CNN) model for the task can be a challenge for\ndevelopers. Recent work on AutoML, more precisely neural architecture search\n(NAS), embodied by tools like Auto-Keras aims to solve this problem by\nessentially viewing it as a search problem where the starting point is a\ndefault CNN model, and mutation of this CNN model allows exploration of the\nspace of CNN models to find a CNN model that will work best for the problem.\nThese works have had significant success in producing high-accuracy CNN models.\nThere are two problems, however. First, NAS can be very costly, often taking\nseveral hours to complete. Second, CNN models produced by NAS can be very\ncomplex that makes it harder to understand them and costlier to train them. We\npropose a novel approach for NAS, where instead of starting from a default CNN\nmodel, the initial model is selected from a repository of models extracted from\nGitHub. The intuition being that developers solving a similar problem may have\ndeveloped a better starting point compared to the default model. We also\nanalyze common layer patterns of CNN models in the wild to understand changes\nthat the developers make to improve their models. Our approach uses commonly\noccurring changes as mutation operators in NAS. We have extended Auto-Keras to\nimplement our approach. Our evaluation using 8 top voted problems from Kaggle\nfor tasks including image classification and image regression shows that given\nthe same search time, without loss of accuracy, Manas produces models with\n42.9% to 99.6% fewer number of parameters than Auto-Keras' models. Benchmarked\non GPU, Manas' models train 30.3% to 641.6% faster than Auto-Keras' models.",
    "descriptor": "",
    "authors": [
      "Giang Nguyen",
      "Johir Islam",
      "Rangeet Pan",
      "Hridesh Rajan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03395"
  },
  {
    "id": "arXiv:2112.03396",
    "title": "A Sensitivity Analysis of the MSMARCO Passage Collection",
    "abstract": "The recent MSMARCO passage retrieval collection has allowed researchers to\ndevelop highly tuned retrieval systems. One aspect of this data set that makes\nit distinctive compared to traditional corpora is that most of the topics only\nhave a single answer passage marked relevant. Here we carry out a \"what if\"\nsensitivity study, asking whether a set of systems would still have the same\nrelative performance if more passages per topic were deemed to be \"relevant\",\nexploring several mechanisms for identifying sets of passages to be so\ncategorized. Our results show that, in general, while run scores can vary\nmarkedly if additional plausible passages are presumed to be relevant, the\nderived system ordering is relatively insensitive to additional relevance,\nproviding support for the methodology that was used at the time the MSMARCO\npassage collection was created.",
    "descriptor": "",
    "authors": [
      "Joel Mackenzie",
      "Matthias Petri",
      "Alistair Moffat"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.03396"
  },
  {
    "id": "arXiv:2112.03398",
    "title": "Top-Down Deep Clustering with Multi-generator GANs",
    "abstract": "Deep clustering (DC) leverages the representation power of deep architectures\nto learn embedding spaces that are optimal for cluster analysis. This approach\nfilters out low-level information irrelevant for clustering and has proven\nremarkably successful for high dimensional data spaces. Some DC methods employ\nGenerative Adversarial Networks (GANs), motivated by the powerful latent\nrepresentations these models are able to learn implicitly. In this work, we\npropose HC-MGAN, a new technique based on GANs with multiple generators\n(MGANs), which have not been explored for clustering. Our method is inspired by\nthe observation that each generator of a MGAN tends to generate data that\ncorrelates with a sub-region of the real data distribution. We use this\nclustered generation to train a classifier for inferring from which generator a\ngiven image came from, thus providing a semantically meaningful clustering for\nthe real distribution. Additionally, we design our method so that it is\nperformed in a top-down hierarchical clustering tree, thus proposing the first\nhierarchical DC method, to the best of our knowledge. We conduct several\nexperiments to evaluate the proposed method against recent DC methods,\nobtaining competitive results. Last, we perform an exploratory analysis of the\nhierarchical clustering tree that highlights how accurately it organizes the\ndata in a hierarchy of semantically coherent patterns.",
    "descriptor": "\nComments: Accepted to AAAI 2021\n",
    "authors": [
      "Daniel de Mello",
      "Renato Assun\u00e7\u00e3o",
      "Fabricio Murai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03398"
  },
  {
    "id": "arXiv:2112.03402",
    "title": "Nested Hyperbolic Spaces for Dimensionality Reduction and Hyperbolic NN  Design",
    "abstract": "Hyperbolic neural networks have been popular in the recent past due to their\nability to represent hierarchical data sets effectively and efficiently. The\nchallenge in developing these networks lies in the nonlinearity of the\nembedding space namely, the Hyperbolic space. Hyperbolic space is a homogeneous\nRiemannian manifold of the Lorentz group. Most existing methods (with some\nexceptions) use local linearization to define a variety of operations\nparalleling those used in traditional deep neural networks in Euclidean spaces.\nIn this paper, we present a novel fully hyperbolic neural network which uses\nthe concept of projections (embeddings) followed by an intrinsic aggregation\nand a nonlinearity all within the hyperbolic space. The novelty here lies in\nthe projection which is designed to project data on to a lower-dimensional\nembedded hyperbolic space and hence leads to a nested hyperbolic space\nrepresentation independently useful for dimensionality reduction. The main\ntheoretical contribution is that the proposed embedding is proved to be\nisometric and equivariant under the Lorentz transformations. This projection is\ncomputationally efficient since it can be expressed by simple linear\noperations, and, due to the aforementioned equivariance property, it allows for\nweight sharing. The nested hyperbolic space representation is the core\ncomponent of our network and therefore, we first compare this ensuing nested\nhyperbolic space representation with other dimensionality reduction methods\nsuch as tangent PCA, principal geodesic analysis (PGA) and HoroPCA. Based on\nthis equivariant embedding, we develop a novel fully hyperbolic graph\nconvolutional neural network architecture to learn the parameters of the\nprojection. Finally, we present experiments demonstrating comparative\nperformance of our network on several publicly available data sets.",
    "descriptor": "\nComments: 19 pages, 6 figures\n",
    "authors": [
      "Xiran Fan",
      "Chun-Hao Yang",
      "Baba C. Vemuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03402"
  },
  {
    "id": "arXiv:2112.03404",
    "title": "Feature Importance-aware Graph Attention Network and Dueling Double Deep  Q-Network Combined Approach for Critical Node Detection Problems",
    "abstract": "Detecting critical nodes in sparse networks is important in a variety of\napplication domains. A Critical Node Problem (CNP) aims to find a set of\ncritical nodes from a network whose deletion maximally degrades the pairwise\nconnectivity of the residual network. Due to its general NP-hard nature,\nstate-of-the-art CNP solutions are based on heuristic approaches. Domain\nknowledge and trial-and-error are usually required when designing such\napproaches, thus consuming considerable effort and time. This work proposes a\nfeature importance-aware graph attention network for node representation and\ncombines it with dueling double deep Q-network to create an end-to-end\nalgorithm to solve CNP for the first time. It does not need any\nproblem-specific knowledge or labeled datasets as required by most of existing\nmethods. Once the model is trained, it can be generalized to cope with various\ntypes of CNPs (with different sizes and topological structures) without\nre-training. Extensive experiments on 28 real-world networks show that the\nproposed method is highly comparable to state-of-the-art methods. It does not\nrequire any problem-specific knowledge and, hence, can be applicable to many\napplications including those impossible ones by using the existing approaches.\nIt can be combined with some local search methods to further improve its\nsolution quality. Extensive comparison results are given to show its\neffectiveness in solving CNP.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Xuwei Tan",
      "Yangming Zhou",
      "Zhang-Hua Fu",
      "Mengchu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03404"
  },
  {
    "id": "arXiv:2112.03405",
    "title": "A Novel Deep Parallel Time-series Relation Network for Fault Diagnosis",
    "abstract": "Considering the models that apply the contextual information of time-series\ndata could improve the fault diagnosis performance, some neural network\nstructures such as RNN, LSTM, and GRU were proposed to model the industrial\nprocess effectively. However, these models are restricted by their serial\ncomputation and hence cannot achieve high diagnostic efficiency. Also the\nparallel CNN is difficult to implement fault diagnosis in an efficient way\nbecause it requires larger convolution kernels or deep structure to achieve\nlong-term feature extraction capabilities. Besides, BERT model applies absolute\nposition embedding to introduce contextual information to the model, which\nwould bring noise to the raw data and therefore cannot be applied to fault\ndiagnosis directly. In order to address the above problems, a fault diagnosis\nmodel named deep parallel time-series relation network(\\textit{DPTRN}) has been\nproposed in this paper. There are mainly three advantages for DPTRN: (1) Our\nproposed time relationship unit is based on full multilayer\nperceptron(\\textit{MLP}) structure, therefore, DPTRN performs fault diagnosis\nin a parallel way and improves computing efficiency significantly. (2) By\nimproving the absolute position embedding, our novel decoupling position\nembedding unit could be applied on the fault diagnosis directly and learn\ncontextual information. (3) Our proposed DPTRN has obvious advantage in feature\ninterpretability. Our model outperforms other methods on both TE and KDD-CUP99\ndatasets which confirms the effectiveness, efficiency and interpretability of\nthe proposed DPTRN model.",
    "descriptor": "",
    "authors": [
      "Chun Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03405"
  },
  {
    "id": "arXiv:2112.03406",
    "title": "Equal Bits: Enforcing Equally Distributed Binary Network Weights",
    "abstract": "Binary networks are extremely efficient as they use only two symbols to\ndefine the network: $\\{+1,-1\\}$. One can make the prior distribution of these\nsymbols a design choice. The recent IR-Net of Qin et al. argues that imposing a\nBernoulli distribution with equal priors (equal bit ratios) over the binary\nweights leads to maximum entropy and thus minimizes information loss. However,\nprior work cannot precisely control the binary weight distribution during\ntraining, and therefore cannot guarantee maximum entropy. Here, we show that\nquantizing using optimal transport can guarantee any bit ratio, including equal\nratios. We investigate experimentally that equal bit ratios are indeed\npreferable and show that our method leads to optimization benefits. We show\nthat our quantization method is effective when compared to state-of-the-art\nbinarization methods, even when using binary weight pruning.",
    "descriptor": "",
    "authors": [
      "Yunqiang Li",
      "Silvia L. Pintea",
      "Jan C. van Gemert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03406"
  },
  {
    "id": "arXiv:2112.03407",
    "title": "Causal Analysis and Classification of Traffic Crash Injury Severity  Using Machine Learning Algorithms",
    "abstract": "Causal analysis and classification of injury severity applying non-parametric\nmethods for traffic crashes has received limited attention. This study presents\na methodological framework for causal inference, using Granger causality\nanalysis, and injury severity classification of traffic crashes, occurring on\ninterstates, with different machine learning techniques including decision\ntrees (DT), random forest (RF), extreme gradient boosting (XGBoost), and deep\nneural network (DNN). The data used in this study were obtained for traffic\ncrashes on all interstates across the state of Texas from a period of six years\nbetween 2014 and 2019. The output of the proposed severity classification\napproach includes three classes for fatal and severe injury (KA) crashes,\nnon-severe and possible injury (BC) crashes, and property damage only (PDO)\ncrashes. While Granger Causality helped identify the most influential factors\naffecting crash severity, the learning-based models predicted the severity\nclasses with varying performance. The results of Granger causality analysis\nidentified the speed limit, surface and weather conditions, traffic volume,\npresence of workzones, workers in workzones, and high occupancy vehicle (HOV)\nlanes, among others, as the most important factors affecting crash severity.\nThe prediction performance of the classifiers yielded varying results across\nthe different classes. Specifically, while decision tree and random forest\nclassifiers provided the greatest performance for PDO and BC severities,\nrespectively, for the KA class, the rarest class in the data, deep neural net\nclassifier performed superior than all other algorithms, most likely due to its\ncapability of approximating nonlinear models. This study contributes to the\nlimited body of knowledge pertaining to causal analysis and classification\nprediction of traffic crash injury severity using non-parametric approaches.",
    "descriptor": "",
    "authors": [
      "Meghna Chakraborty",
      "Timothy Gates",
      "Subhrajit Sinha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.03407"
  },
  {
    "id": "arXiv:2112.03411",
    "title": "Extrapolation Frameworks in Cognitive Psychology Suitable for Study of  Image Classification Models",
    "abstract": "We study the functional task of deep learning image classification models and\nshow that image classification requires extrapolation capabilities. This\nsuggests that new theories have to be developed for the understanding of deep\nlearning as the current theory assumes models are solely interpolating, leaving\nmany questions about them unanswered. We investigate the pixel space and also\nthe feature spaces extracted from images by trained models (in their hidden\nlayers, including the 64-dimensional feature space in the last hidden layer of\npre-trained residual neural networks), and also the feature space extracted by\nwavelets/shearlets. In all these domains, testing samples considerably fall\noutside the convex hull of training sets, and image classification requires\nextrapolation. In contrast to the deep learning literature, in cognitive\nscience, psychology, and neuroscience, extrapolation and learning are often\nstudied in tandem. Moreover, many aspects of human visual cognition and\nbehavior are reported to involve extrapolation. We propose a novel\nextrapolation framework for the mathematical study of deep learning models. In\nour framework, we use the term extrapolation in this specific way of\nextrapolating outside the convex hull of training set (in the pixel space or\nfeature space) but within the specific scope defined by the training data, the\nsame way extrapolation is defined in many studies in cognitive science. We\nexplain that our extrapolation framework can provide novel answers to open\nresearch problems about deep learning including their over-parameterization,\ntheir training regime, out-of-distribution detection, etc. We also see that the\nextent of extrapolation is negligible in learning tasks where deep learning is\nreported to have no advantage over simple models.",
    "descriptor": "\nComments: 1st Workshop on Human and Machine Decisions (WHMD 2021) at NeurIPS 2021\n",
    "authors": [
      "Roozbeh Yousefzadeh",
      "Jessica A. Mollick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03411"
  },
  {
    "id": "arXiv:2112.03414",
    "title": "JUSTICE: A Benchmark Dataset for Supreme Court's Judgment Prediction",
    "abstract": "Artificial intelligence is being utilized in many domains as of late, and the\nlegal system is no exception. However, as it stands now, the number of\nwell-annotated datasets pertaining to legal documents from the Supreme Court of\nthe United States (SCOTUS) is very limited for public use. Even though the\nSupreme Court rulings are public domain knowledge, trying to do meaningful work\nwith them becomes a much greater task due to the need to manually gather and\nprocess that data from scratch each time. Hence, our goal is to create a\nhigh-quality dataset of SCOTUS court cases so that they may be readily used in\nnatural language processing (NLP) research and other data-driven applications.\nAdditionally, recent advances in NLP provide us with the tools to build\npredictive models that can be used to reveal patterns that influence court\ndecisions. By using advanced NLP algorithms to analyze previous court cases,\nthe trained models are able to predict and classify a court's judgment given\nthe case's facts from the plaintiff and the defendant in textual format; in\nother words, the model is emulating a human jury by generating a final verdict.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Mohammad Alali",
      "Shaayan Syed",
      "Mohammed Alsayed",
      "Smit Patel",
      "Hemanth Bodala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03414"
  },
  {
    "id": "arXiv:2112.03415",
    "title": "Producing augmentation-invariant embeddings from real-life imagery",
    "abstract": "This article presents an efficient way to produce feature-rich,\nhigh-dimensionality embedding spaces from real-life images. The features\nproduced are designed to be independent from augmentations used in real-life\ncases which appear on social media. Our approach uses convolutional neural\nnetworks (CNN) to produce an embedding space. An ArcFace head was used to train\nthe model by employing automatically produced augmentations. Additionally, we\npresent a way to make an ensemble out of different embeddings containing the\nsame semantic information, a way to normalize the resulting embedding using an\nexternal dataset, and a novel way to perform quick training of these models\nwith a high number of classes in the ArcFace head. Using this approach we\nachieved the 2nd place in the 2021 Facebook AI Image Similarity Challenge:\nDescriptor Track.",
    "descriptor": "",
    "authors": [
      "Sergio Manuel Papadakis",
      "Sanjay Addicam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03415"
  },
  {
    "id": "arXiv:2112.03420",
    "title": "ORCLSim: A System Architecture for Studying Bicyclist and Pedestrian  Physiological Behavior Through Immersive Virtual Environments",
    "abstract": "Injuries and fatalities for vulnerable road users, especially bicyclists and\npedestrians, are on the rise. To better inform design for vulnerable road\nusers, we need to conduct more studies to evaluate how bicyclist and pedestrian\nbehavior and physiological states change in different roadway designs and\ncontextual settings. Previous research highlights the advantages of Immersive\nVirtual Environment (IVE) in conducting bicyclist and pedestrian studies. These\nenvironments do not put participants at risk of getting injured, are low-cost\ncompared to on-road or naturalistic studies and allow researchers to fully\ncontrol variables of interest. In this paper, we propose a framework ORCLSim,\nto support human sensing techniques within IVE to evaluate bicyclist and\npedestrian physiological and behavioral changes in different contextual\nsettings. To showcase this framework, we present two case studies where we\ncollect and analyze pilot data from five participants' physiological and\nbehavioral responses in an IVE setting, representing real-world roadway\nsegments and traffic conditions. Results from these case studies indicate that\nphysiological data is sensitive to road environment changes and real-time\nevents, especially changes in heart rate and gaze behavior. Additionally, our\npreliminary data indicates participants may respond differently to various\nroadway settings (e.g., intersections with or without traffic signal). By\nanalyzing these changes, we can identify how participants' stress levels and\ncognitive load is impacted by the simulated surrounding environment. The\nORCLSim system architecture can be further utilized for future studies in\nusers' behavioral and physiological responses in different virtual reality\nsettings.",
    "descriptor": "\nComments: 36 pages, 7 figures\n",
    "authors": [
      "Xiang Guo",
      "Austin Angulo",
      "Erin Robartes",
      "T. Donna Chen",
      "Arsalan Heydarian"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.03420"
  },
  {
    "id": "arXiv:2112.03421",
    "title": "Virtual Replay Cache",
    "abstract": "Return caching is a recent strategy that enables efficient minibatch training\nwith multistep estimators (e.g. the {\\lambda}-return) for deep reinforcement\nlearning. By precomputing return estimates in sequential batches and then\nstoring the results in an auxiliary data structure for later sampling, the\naverage computation spent per estimate can be greatly reduced. Still, the\nefficiency of return caching could be improved, particularly with regard to its\nlarge memory usage and repetitive data copies. We propose a new data structure,\nthe Virtual Replay Cache (VRC), to address these shortcomings. When learning to\nplay Atari 2600 games, the VRC nearly eliminates DQN({\\lambda})'s cache memory\nfootprint and slightly reduces the total training time on our hardware.",
    "descriptor": "\nComments: 4 pages, 1 figure, 3 tables\n",
    "authors": [
      "Brett Daley",
      "Christopher Amato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03421"
  },
  {
    "id": "arXiv:2112.03423",
    "title": "Hybrid SNN-ANN: Energy-Efficient Classification and Object Detection for  Event-Based Vision",
    "abstract": "Event-based vision sensors encode local pixel-wise brightness changes in\nstreams of events rather than image frames and yield sparse, energy-efficient\nencodings of scenes, in addition to low latency, high dynamic range, and lack\nof motion blur. Recent progress in object recognition from event-based sensors\nhas come from conversions of deep neural networks, trained with\nbackpropagation. However, using these approaches for event streams requires a\ntransformation to a synchronous paradigm, which not only loses computational\nefficiency, but also misses opportunities to extract spatio-temporal features.\nIn this article we propose a hybrid architecture for end-to-end training of\ndeep neural networks for event-based pattern recognition and object detection,\ncombining a spiking neural network (SNN) backbone for efficient event-based\nfeature extraction, and a subsequent analog neural network (ANN) head to solve\nsynchronous classification and detection tasks. This is achieved by combining\nstandard backpropagation with surrogate gradient training to propagate\ngradients through the SNN. Hybrid SNN-ANNs can be trained without conversion,\nand result in highly accurate networks that are substantially more\ncomputationally efficient than their ANN counterparts. We demonstrate results\non event-based classification and object detection datasets, in which only the\narchitecture of the ANN heads need to be adapted to the tasks, and no\nconversion of the event-based input is necessary. Since ANNs and SNNs require\ndifferent hardware paradigms to maximize their efficiency, we envision that SNN\nbackbone and ANN head can be executed on different processing units, and thus\nanalyze the necessary bandwidth to communicate between the two parts. Hybrid\nnetworks are promising architectures to further advance machine learning\napproaches for event-based vision, without having to compromise on efficiency.",
    "descriptor": "\nComments: Accepted at DAGM German Conference on Pattern Recognition (GCPR 2021)\n",
    "authors": [
      "Alexander Kugele",
      "Thomas Pfeil",
      "Michael Pfeiffer",
      "Elisabetta Chicca"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.03423"
  },
  {
    "id": "arXiv:2112.03424",
    "title": "Learning to Solve Hard Minimal Problems",
    "abstract": "We present an approach to solving hard geometric optimization problems in the\nRANSAC framework. The hard minimal problems arise from relaxing the original\ngeometric optimization problem into a minimal problem with many spurious\nsolutions. Our approach avoids computing large numbers of spurious solutions.\nWe design a learning strategy for selecting a starting problem-solution pair\nthat can be numerically continued to the problem and the solution of interest.\nWe demonstrate our approach by developing a RANSAC solver for the problem of\ncomputing the relative pose of three calibrated cameras, via a minimal\nrelaxation using four points in each view. On average, we can solve a single\nproblem in under 70 $\\mu s.$ We also benchmark and study our engineering\nchoices on the very familiar problem of computing the relative pose of two\ncalibrated cameras, via the minimal case of five points in two views.",
    "descriptor": "\nComments: 24 pages total: 14 pages main paper and 10 pages supplementary\n",
    "authors": [
      "Petr Hruby",
      "Timothy Duff",
      "Anton Leykin",
      "Tomas Pajdla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03424"
  },
  {
    "id": "arXiv:2112.03426",
    "title": "A Survey of Verification, Validation and Testing Solutions for Smart  Contracts",
    "abstract": "Smart contracts are programs stored on a blockchain that run when\npredetermined conditions are met. However, designing and implementing a smart\ncontract is not trivial since upon deployment on a blockchain, it is no longer\npossible to modify it (neither for improving nor for bug fixing). It is only\npossible by deploying a new version of the smart contract which is costly\n(deployment cost for the new contract and destruction cost for the old\ncontract). To this end, there are many solutions for testing the smart\ncontracts before their deployment. Since realizing bug-free smart contracts\nincrease the reliability, as well as reduce the cost, testing is an essential\nactivity. In this paper, we group the existing solutions that attempt to tackle\nsmart contract testing into following categories: public test networks,\nsecurity analysis tools, blockchain emulators and blockchain simulators. Then,\nwe analyze these solutions, categorize them and show what their pros and cons\nare.",
    "descriptor": "\nComments: 8 pages, 3 tables, The Third IEEE International Conference on Blockchain Computing and Applications (BCCA 2021)\n",
    "authors": [
      "Cha\u00efmaa Benabbou",
      "\u00d6nder G\u00fcrcan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.03426"
  },
  {
    "id": "arXiv:2112.03431",
    "title": "Finite Element numerical schemes for a chemo-attraction and consumption  model",
    "abstract": "This work is devoted to design and study efficient and accurate numerical\nschemes to approximate a chemo-attraction model with consumption effects, which\nis a nonlinear parabolic system for two variables; the cell density and the\nconcentration of the chemical signal that the cell feel attracted to. We\npresent several finite element schemes to approximate the system, detailing the\nmain properties of each of them, such as conservation of cells,\nenergy-stability and approximated positivity. Moreover, we carry out several\nnumerical simulations to study the efficiency of each of the schemes and to\ncompare them with others classical schemes.",
    "descriptor": "",
    "authors": [
      "F. Guill\u00e9n-Gonz\u00e1lez",
      "G. Tierra"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.03431"
  },
  {
    "id": "arXiv:2112.03432",
    "title": "First-Order Regret in Reinforcement Learning with Linear Function  Approximation: A Robust Estimation Approach",
    "abstract": "Obtaining first-order regret bounds -- regret bounds scaling not as the\nworst-case but with some measure of the performance of the optimal policy on a\ngiven instance -- is a core question in sequential decision-making. While such\nbounds exist in many settings, they have proven elusive in reinforcement\nlearning with large state spaces. In this work we address this gap, and show\nthat it is possible to obtain regret scaling as $\\mathcal{O}(\\sqrt{V_1^\\star\nK})$ in reinforcement learning with large state spaces, namely the linear MDP\nsetting. Here $V_1^\\star$ is the value of the optimal policy and $K$ is the\nnumber of episodes. We demonstrate that existing techniques based on least\nsquares estimation are insufficient to obtain this result, and instead develop\na novel robust self-normalized concentration bound based on the robust Catoni\nmean estimator, which may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Andrew Wagenmaker",
      "Yifang Chen",
      "Max Simchowitz",
      "Simon S. Du",
      "Kevin Jamieson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03432"
  },
  {
    "id": "arXiv:2112.03435",
    "title": "Campaign Knowledge Network: Building Knowledge for Campaign Efficiency",
    "abstract": "In the landscape of exascale computing collaborative research campaigns are\nconducted as co-design activities of loosely coordinated experiments. But the\nhigher level context and the knowledge of individual experimental activity is\nlost over time. We undertook a knowledge capture and representation aid called\nCampaign Knowledge Network(CKN), a co-design design and analysis tool. We\ndemonstrate that CKN can satisfy the Hoarde abstraction and can distill\ncampaign context from runtime information thereby creating a knowledge resource\nupon which analysis tools can run to provide more efficient experimentation",
    "descriptor": "",
    "authors": [
      "Sachith Withana",
      "Kshitij Mehta",
      "Matthew Wolf",
      "Beth Plale"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.03435"
  },
  {
    "id": "arXiv:2112.03440",
    "title": "A Unified Framework for Multi-distribution Density Ratio Estimation",
    "abstract": "Binary density ratio estimation (DRE), the problem of estimating the ratio\n$p_1/p_2$ given their empirical samples, provides the foundation for many\nstate-of-the-art machine learning algorithms such as contrastive representation\nlearning and covariate shift adaptation. In this work, we consider a\ngeneralized setting where given samples from multiple distributions $p_1,\n\\ldots, p_k$ (for $k > 2$), we aim to efficiently estimate the density ratios\nbetween all pairs of distributions. Such a generalization leads to important\nnew applications such as estimating statistical discrepancy among multiple\nrandom variables like multi-distribution $f$-divergence, and bias correction\nvia multiple importance sampling. We then develop a general framework from the\nperspective of Bregman divergence minimization, where each strictly convex\nmultivariate function induces a proper loss for multi-distribution DRE.\nMoreover, we rederive the theoretical connection between multi-distribution\ndensity ratio estimation and class probability estimation, justifying the use\nof any strictly proper scoring rule composite with a link function for\nmulti-distribution DRE. We show that our framework leads to methods that\nstrictly generalize their counterparts in binary DRE, as well as new methods\nthat show comparable or superior performance on various downstream tasks.",
    "descriptor": "",
    "authors": [
      "Lantao Yu",
      "Yujia Jin",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03440"
  },
  {
    "id": "arXiv:2112.03442",
    "title": "Approximating Nash Equilibrium in Random Graphical Games",
    "abstract": "Computing Nash equilibrium in multi-agent games is a longstanding challenge\nat the interface of game theory and computer science. It is well known that a\ngeneral normal form game in N players and k strategies requires exponential\nspace simply to write down. This Curse of Multi-Agents prompts the study of\nsuccinct games which can be written down efficiently. A canonical example of a\nsuccinct game is the graphical game which models players as nodes in a graph\ninteracting with only their neighbors in direct analogy with markov random\nfields. Graphical games have found applications in wireless, financial, and\nsocial networks. However, computing the nash equilbrium of graphical games has\nproven challenging. Even for polymatrix games, a model where payoffs to an\nagent can be written as the sum of payoffs of interactions with the agent's\nneighbors, it has been shown that computing an epsilon approximate nash\nequilibrium is PPAD hard for epsilon smaller than a constant. The focus of this\nwork is to circumvent this computational hardness by considering average case\ngraph models i.e random graphs. We provide a quasipolynomial time approximation\nscheme (QPTAS) for computing an epsilon approximate nash equilibrium of\npolymatrix games on random graphs with edge density greater than poly(k,\n1/epsilon, ln(N))$ with high probability. Furthermore, with the same runtime we\ncan compute an epsilon-approximate Nash equilibrium that epsilon-approximates\nthe maximum social welfare of any nash equilibrium of the game. Our primary\ntechnical innovation is an \"accelerated rounding\" of a novel hierarchical\nconvex program for the nash equilibrium problem. Our accelerated rounding also\nyields faster algorithms for Max-2CSP on the same family of random graphs,\nwhich may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Morris Yau"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.03442"
  },
  {
    "id": "arXiv:2112.03444",
    "title": "GPU-Based Homotopy Continuation for Minimal Problems in Computer Vision",
    "abstract": "Systems of polynomial equations arise frequently in computer vision,\nespecially in multiview geometry problems. Traditional methods for solving\nthese systems typically aim to eliminate variables to reach a univariate\npolynomial, e.g., a tenth-order polynomial for 5-point pose estimation, using\nclever manipulations, or more generally using Grobner basis, resultants, and\nelimination templates, leading to successful algorithms for multiview geometry\nand other problems. However, these methods do not work when the problem is\ncomplex and when they do, they face efficiency and stability issues. Homotopy\nContinuation (HC) can solve more complex problems without the stability issues,\nand with guarantees of a global solution, but they are known to be slow. In\nthis paper we show that HC can be parallelized on a GPU, showing significant\nspeedups up to 26 times on polynomial benchmarks. We also show that GPU-HC can\nbe generically applied to a range of computer vision problems, including 4-view\ntriangulation and trifocal pose estimation with unknown focal length, which\ncannot be solved with elimination template but they can be efficiently solved\nwith HC. GPU-HC opens the door to easy formulation and solution of a range of\ncomputer vision problems.",
    "descriptor": "",
    "authors": [
      "Chiang-Heng Chien",
      "Hongyi Fan",
      "Ahmad Abdelfattah",
      "Elias Tsigaridas",
      "Stanimire Tomov",
      "Benjamin Kimia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03444"
  },
  {
    "id": "arXiv:2112.03449",
    "title": "Locally Differentially Private Sparse Vector Aggregation",
    "abstract": "Vector mean estimation is a central primitive in federated analytics. In\nvector mean estimation, each user $i \\in [n]$ holds a real-valued vector\n$v_i\\in [-1, 1]^d$, and a server wants to Not only so, we would like to protect\neach individual user's privacy. In this paper, we consider the $k$-sparse\nversion of the vector mean estimation problem, that is, suppose that each\nuser's vector has at most $k$ non-zero coordinates in its $d$-dimensional\nvector, and moreover, $k \\ll d$. In practice, since the universe size $d$ can\nbe very large (e.g., the space of all possible URLs), we would like the\nper-user communication to be succinct, i.e., independent of or\n(poly-)logarithmic in the universe size.\nIn this paper, we are the first to show matching upper- and lower-bounds for\nthe $k$-sparse vector mean estimation problem under local differential privacy.\nSpecifically, we construct new mechanisms that achieve asymptotically optimal\nerror as well as succinct communication, either under user-level-LDP or\nevent-level-LDP. We implement our algorithms and evaluate them on synthetic as\nwell as real-world datasets. Our experiments show that we can often achieve one\nor two orders of magnitude reduction in error in comparison with prior works\nunder typical choices of parameters, while incurring insignificant\ncommunication cost.",
    "descriptor": "",
    "authors": [
      "Mingxun Zhou",
      "Tianhao Wang",
      "Hubert Chan",
      "Giulia Fanti",
      "Elaine Shi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.03449"
  },
  {
    "id": "arXiv:2112.03450",
    "title": "Do explanations increase the effectiveness of AI-crowd generated fake  news warnings?",
    "abstract": "Social media platforms are increasingly deploying complex interventions to\nhelp users detect false news. Labeling false news using techniques that combine\ncrowd-sourcing with artificial intelligence (AI) offers a promising way to\ninform users about potentially low-quality information without censoring\ncontent, but also can be hard for users to understand. In this study, we\nexamine how users respond in their sharing intentions to information they are\nprovided about a hypothetical human-AI hybrid system. We ask i) if these\nwarnings increase discernment in social media sharing intentions and ii) if\nexplaining how the labeling system works can boost the effectiveness of the\nwarnings. To do so, we conduct a study ($N=1473$ Americans) in which\nparticipants indicated their likelihood of sharing content. Participants were\nrandomly assigned to a control, a treatment where false content was labeled, or\na treatment where the warning labels came with an explanation of how they were\ngenerated. We find clear evidence that both treatments increase sharing\ndiscernment, and directional evidence that explanations increase the warnings'\neffectiveness. Interestingly, we do not find that the explanations increase\nself-reported trust in the warning labels, although we do find some evidence\nthat participants found the warnings with the explanations to be more\ninformative. Together, these results have important implications for designing\nand deploying transparent misinformation warning labels, and AI-mediated\nsystems more broadly.",
    "descriptor": "\nComments: Forthcoming in ICWSM 2022\n",
    "authors": [
      "Ziv Epstein",
      "Nicol\u00f2 Foppiani",
      "Sophie Hilgard",
      "Sanjana Sharma",
      "Elena Glassman",
      "David Rand"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.03450"
  },
  {
    "id": "arXiv:2112.03451",
    "title": "Deep Level Set for Box-supervised Instance Segmentation in Aerial Images",
    "abstract": "Box-supervised instance segmentation has recently attracted lots of research\nefforts while little attention is received in aerial image domain. In contrast\nto the general object collections, aerial objects have large intra-class\nvariances and inter-class similarity with complex background. Moreover, there\nare many tiny objects in the high-resolution satellite images. This makes the\nrecent pairwise affinity modeling method inevitably to involve the noisy\nsupervision with the inferior results. To tackle these problems, we propose a\nnovel aerial instance segmentation approach, which drives the network to learn\na series of level set functions for the aerial objects with only box\nannotations in an end-to-end fashion. Instead of learning the pairwise\naffinity, the level set method with the carefully designed energy functions\ntreats the object segmentation as curve evolution, which is able to accurately\nrecover the object's boundaries and prevent the interference from the\nindistinguishable background and similar objects. The experimental results\ndemonstrate that the proposed approach outperforms the state-of-the-art\nbox-supervised instance segmentation methods. The source code is available at\nhttps://github.com/LiWentomng/boxlevelset.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Wentong Li",
      "Yijie Chen",
      "Wenyu Liu",
      "Jianke Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03451"
  },
  {
    "id": "arXiv:2112.03452",
    "title": "Location Leakage in Federated Signal Maps",
    "abstract": "We consider the problem of predicting cellular network performance (signal\nmaps) from measurements collected by several mobile devices. We formulate the\nproblem within the online federated learning framework: (i) federated learning\n(FL) enables users to collaboratively train a model, while keeping their\ntraining data on their devices; (ii) measurements are collected as users move\naround over time and are used for local training in an online fashion. We\nconsider an honest-but-curious server, who observes the updates from target\nusers participating in FL and infers their location using a deep leakage from\ngradients (DLG) type of attack, originally developed to reconstruct training\ndata of DNN image classifiers. We make the key observation that a DLG attack,\napplied to our setting, infers the average location of a batch of local data,\nand can thus be used to reconstruct the target users' trajectory at a coarse\ngranularity. We show that a moderate level of privacy protection is already\noffered by the averaging of gradients, which is inherent to Federated\nAveraging. Furthermore, we propose an algorithm that devices can apply locally\nto curate the batches used for local updates, so as to effectively protect\ntheir location privacy without hurting utility. Finally, we show that the\neffect of multiple users participating in FL depends on the similarity of their\ntrajectories. To the best of our knowledge, this is the first study of DLG\nattacks in the setting of FL from crowdsourced spatio-temporal data.",
    "descriptor": "",
    "authors": [
      "Evita Bakopoulou",
      "Jiang Zhang",
      "Justin Ley",
      "Konstantinos Psounis",
      "Athina Markopoulou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.03452"
  },
  {
    "id": "arXiv:2112.03458",
    "title": "Glue: Adaptively Merging Single Table Cardinality to Estimate Join Query  Size",
    "abstract": "Cardinality estimation (CardEst), a central component of the query optimizer,\nplays a significant role in generating high-quality query plans in DBMS. The\nCardEst problem has been extensively studied in the last several decades, using\nboth traditional and ML-enhanced methods. Whereas, the hardest problem in\nCardEst, i.e., how to estimate the join query size on multiple tables, has not\nbeen extensively solved. Current methods either reply on independence\nassumptions or apply techniques with heavy burden, whose performance is still\nfar from satisfactory. Even worse, existing CardEst methods are often designed\nto optimize one goal, i.e., inference speed or estimation accuracy, which can\nnot adapt to different occasions.\nIn this paper, we propose a very general framework, called Glue, to tackle\nwith these challenges. Its key idea is to elegantly decouple the correlations\nacross different tables and losslessly merge single table CardEst results to\nestimate the join query size. Glue supports obtaining the single table-wise\nCardEst results using any existing CardEst method and can process any complex\njoin schema. Therefore, it easily adapts to different scenarios having\ndifferent performance requirements, i.e., OLTP with fast estimation time or\nOLAP with high estimation accuracy. Meanwhile, we show that Glue can be\nseamlessly integrated into the plan search process and is able to support\ncounting distinct number of values. All these properties exhibit the potential\nadvances of deploying Glue in real-world DBMS.",
    "descriptor": "",
    "authors": [
      "Rong Zhu",
      "Tianjing Zeng",
      "Andreas Pfadler",
      "Wei Chen",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03458"
  },
  {
    "id": "arXiv:2112.03459",
    "title": "A Novel Convergence Analysis for Algorithms of the Adam Family",
    "abstract": "Since its invention in 2014, the Adam optimizer has received tremendous\nattention. On one hand, it has been widely used in deep learning and many\nvariants have been proposed, while on the other hand their theoretical\nconvergence property remains to be a mystery. It is far from satisfactory in\nthe sense that some studies require strong assumptions about the updates, which\nare not necessarily applicable in practice, while other studies still follow\nthe original problematic convergence analysis of Adam, which was shown to be\nnot sufficient to ensure convergence. Although rigorous convergence analysis\nexists for Adam, they impose specific requirements on the update of the\nadaptive step size, which are not generic enough to cover many other variants\nof Adam. To address theses issues, in this extended abstract, we present a\nsimple and generic proof of convergence for a family of Adam-style methods\n(including Adam, AMSGrad, Adabound, etc.). Our analysis only requires an\nincreasing or large \"momentum\" parameter for the first-order moment, which is\nindeed the case used in practice, and a boundness condition on the adaptive\nfactor of the step size, which applies to all variants of Adam under mild\nconditions of stochastic gradients. We also establish a variance diminishing\nresult for the used stochastic gradient estimators. Indeed, our analysis of\nAdam is so simple and generic that it can be leveraged to establish the\nconvergence for solving a broader family of non-convex optimization problems,\nincluding min-max, compositional, and bilevel optimization problems. For the\nfull (earlier) version of this extended abstract, please refer to\narXiv:2104.14840.",
    "descriptor": "\nComments: In NeurIPS OPT Workshop 2021. arXiv admin note: substantial text overlap with arXiv:2104.14840\n",
    "authors": [
      "Zhishuai Guo",
      "Yi Xu",
      "Wotao Yin",
      "Rong Jin",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.03459"
  },
  {
    "id": "arXiv:2112.03461",
    "title": "GraphPAS: Parallel Architecture Search for Graph Neural Networks",
    "abstract": "Graph neural architecture search has received a lot of attention as Graph\nNeural Networks (GNNs) has been successfully applied on the non-Euclidean data\nrecently. However, exploring all possible GNNs architectures in the huge search\nspace is too time-consuming or impossible for big graph data. In this paper, we\npropose a parallel graph architecture search (GraphPAS) framework for graph\nneural networks. In GraphPAS, we explore the search space in parallel by\ndesigning a sharing-based evolution learning, which can improve the search\nefficiency without losing the accuracy. Additionally, architecture information\nentropy is adopted dynamically for mutation selection probability, which can\nreduce space exploration. The experimental result shows that GraphPAS\noutperforms state-of-art models with efficiency and accuracy simultaneously.",
    "descriptor": "\nComments: 5 papes,3 figures,Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
    "authors": [
      "Jiamin Chen",
      "Jianliang Gao",
      "Yibo Chen",
      "Oloulade Babatounde Moctard",
      "Tengfei Lyu",
      "Zhao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03461"
  },
  {
    "id": "arXiv:2112.03462",
    "title": "SpaceSaving$^\\pm$: An Optimal Algorithm for Frequency Estimation and  Frequent items in the Bounded Deletion Model",
    "abstract": "In this paper, we propose the first deterministic algorithms to solve the\nfrequency estimation and frequent item problems in the bounded deletion model.\nWe establish the space lower bound for solving the deterministic frequent items\nproblem in the bounded deletion model, and propose the Lazy SpaceSaving$^\\pm$\nand SpaceSaving$^\\pm$ algorithms with optimal space bound. We then develop an\nefficient implementation of the SpaceSaving$^\\pm$ algorithm that minimizes the\nlatency of update operations using novel data structures. The experimental\nevaluations testify that SpaceSaving$^\\pm$ has accurate frequency estimations\nand achieves very high recall and precision across different data distributions\nwhile using minimal space. Our analysis and experiments clearly demonstrate\nthat SpaceSaving$^\\pm$ provides more accurate estimations using the same space\nas the state of the art protocols for applications with 93% of items deleted.\nMoreover, motivated by prior work, we propose Dyadic SpaceSaving$^\\pm$, the\nfirst deterministic quantile approximation sketch in the bounded deletion\nmodel.",
    "descriptor": "",
    "authors": [
      "Fuheng Zhao",
      "Divyakant Agrawal",
      "Amr El Abbadi",
      "Ahmed Metwally"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.03462"
  },
  {
    "id": "arXiv:2112.03465",
    "title": "Federated Deep Reinforcement Learning for the Distributed Control of  NextG Wireless Networks",
    "abstract": "Next Generation (NextG) networks are expected to support demanding tactile\ninternet applications such as augmented reality and connected autonomous\nvehicles. Whereas recent innovations bring the promise of larger link capacity,\ntheir sensitivity to the environment and erratic performance defy traditional\nmodel-based control rationales. Zero-touch data-driven approaches can improve\nthe ability of the network to adapt to the current operating conditions. Tools\nsuch as reinforcement learning (RL) algorithms can build optimal control policy\nsolely based on a history of observations. Specifically, deep RL (DRL), which\nuses a deep neural network (DNN) as a predictor, has been shown to achieve good\nperformance even in complex environments and with high dimensional inputs.\nHowever, the training of DRL models require a large amount of data, which may\nlimit its adaptability to ever-evolving statistics of the underlying\nenvironment. Moreover, wireless networks are inherently distributed systems,\nwhere centralized DRL approaches would require excessive data exchange, while\nfully distributed approaches may result in slower convergence rates and\nperformance degradation. In this paper, to address these challenges, we propose\na federated learning (FL) approach to DRL, which we refer to federated DRL\n(F-DRL), where base stations (BS) collaboratively train the embedded DNN by\nonly sharing models' weights rather than training data. We evaluate two\ndistinct versions of F-DRL, value and policy based, and show the superior\nperformance they achieve compared to distributed and centralized DRL.",
    "descriptor": "\nComments: 6pages\n",
    "authors": [
      "Peyman Tehrani",
      "Francesco Restuccia",
      "Marco Levorato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03465"
  },
  {
    "id": "arXiv:2112.03467",
    "title": "Spectral Complexity-scaled Generalization Bound of Complex-valued Neural  Networks",
    "abstract": "Complex-valued neural networks (CVNNs) have been widely applied to various\nfields, especially signal processing and image recognition. However, few works\nfocus on the generalization of CVNNs, albeit it is vital to ensure the\nperformance of CVNNs on unseen data. This paper is the first work that proves a\ngeneralization bound for the complex-valued neural network. The bound scales\nwith the spectral complexity, the dominant factor of which is the spectral norm\nproduct of weight matrices. Further, our work provides a generalization bound\nfor CVNNs when training data is sequential, which is also affected by the\nspectral complexity. Theoretically, these bounds are derived via Maurey\nSparsification Lemma and Dudley Entropy Integral. Empirically, we conduct\nexperiments by training complex-valued convolutional neural networks on\ndifferent datasets: MNIST, FashionMNIST, CIFAR-10, CIFAR-100, Tiny ImageNet,\nand IMDB. Spearman's rank-order correlation coefficients and the corresponding\np values on these datasets give strong proof that the spectral complexity of\nthe network, measured by the weight matrices spectral norm product, has a\nstatistically significant correlation with the generalization ability.",
    "descriptor": "",
    "authors": [
      "Haowen Chen",
      "Fengxiang He",
      "Shiye Lei",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03467"
  },
  {
    "id": "arXiv:2112.03470",
    "title": "Structural Health Monitoring of a Foot Bridge in Virtual Reality  Environment",
    "abstract": "Ageing civil infrastructure systems require imminent attention before any\nfailure mechanism becomes critical. Structural Health Monitoring (SHM) is\nemployed to track inputs and/or responses of structural systems for decision\nsupport. Inspections and structural health monitoring require field visits, and\nsubsequently expert assessment of critical elements at site, which may be both\ntime-consuming and costly. Also, fieldwork including visits and inspections may\npose danger, require personal protective equipment and structure closures\nduring the fieldwork. To address some of these issues, a Virtual Reality (VR)\ncollaborative application is developed to bring the structure and SHM data from\nthe field to the office such that many experts from different places can\nsimultaneously virtually visit the bridge structure for final assessment. In\nthis work, we present an SHM system in a VR environment that includes the\ntechnical and visual information necessary for the engineers to make decisions\nfor a footbridge on the campus of the University of Central Florida. In this VR\napplication, for the visualization stage, UAV (Unmanned Air Vehicle)\nphotogrammetry and LiDAR (Light Detection and Ranging) methods are used to\ncapture the bridge. For the technical assessment stage, Finite Element Analysis\n(FEA) and Operational Modal Analysis (OMA) from vibration data as part of SHM\nare analyzed. To better visualize the dynamic response of the structure, the\noperational behaviour from the FEA is reflected on the LiDAR point cloud model\nfor immersive. The multi-user feature allowing teams to collaborate\nsimultaneously is essential for decision-making activities. In conclusion, the\nproposed VR environment offers the potential to provide beneficial features\nwith further automated and real-time improvements along with the SHM and FEA\nmodels.",
    "descriptor": "",
    "authors": [
      "Furkan Luleci",
      "Liangding Li",
      "Jiapeng Chi",
      "Dirk Reiners",
      "Carolina Cruz-Neira",
      "F. Necati Catbas"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.03470"
  },
  {
    "id": "arXiv:2112.03471",
    "title": "Voxelized 3D Feature Aggregation for Multiview Detection",
    "abstract": "Multi-view detection incorporates multiple camera views to alleviate\nocclusion in crowded scenes, where the state-of-the-art approaches adopt\nhomography transformations to project multi-view features to the ground plane.\nHowever, we find that these 2D transformations do not take into account the\nobject's height, and with this neglection features along the vertical direction\nof same object are likely not projected onto the same ground plane point,\nleading to impure ground-plane features. To solve this problem, we propose VFA,\nvoxelized 3D feature aggregation, for feature transformation and aggregation in\nmulti-view detection. Specifically, we voxelize the 3D space, project the\nvoxels onto each camera view, and associate 2D features with these projected\nvoxels. This allows us to identify and then aggregate 2D features along the\nsame vertical line, alleviating projection distortions to a large extent.\nAdditionally, because different kinds of objects (human vs. cattle) have\ndifferent shapes on the ground plane, we introduce the oriented Gaussian\nencoding to match such shapes, leading to increased accuracy and efficiency. We\nperform experiments on multiview 2D detection and multiview 3D detection\nproblems. Results on four datasets (including a newly introduced MultiviewC\ndataset) show that our system is very competitive compared with the\nstate-of-the-art approaches. %Our code and data will be open-sourced.Code and\nMultiviewC are released at https://github.com/Robert-Mar/VFA.",
    "descriptor": "",
    "authors": [
      "Jiahao Ma",
      "Jinguang Tong",
      "Shan Wang",
      "Wei Zhao",
      "Liang Zheng",
      "Chuong Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03471"
  },
  {
    "id": "arXiv:2112.03473",
    "title": "Improving Neural Cross-Lingual Summarization via Employing Optimal  Transport Distance for Knowledge Distillation",
    "abstract": "Current state-of-the-art cross-lingual summarization models employ multi-task\nlearning paradigm, which works on a shared vocabulary module and relies on the\nself-attention mechanism to attend among tokens in two languages. However,\ncorrelation learned by self-attention is often loose and implicit, inefficient\nin capturing crucial cross-lingual representations between languages. The\nmatter worsens when performing on languages with separate morphological or\nstructural features, making the cross-lingual alignment more challenging,\nresulting in the performance drop. To overcome this problem, we propose a novel\nKnowledge-Distillation-based framework for Cross-Lingual Summarization, seeking\nto explicitly construct cross-lingual correlation by distilling the knowledge\nof the monolingual summarization teacher into the cross-lingual summarization\nstudent. Since the representations of the teacher and the student lie on two\ndifferent vector spaces, we further propose a Knowledge Distillation loss using\nSinkhorn Divergence, an Optimal-Transport distance, to estimate the discrepancy\nbetween those teacher and student representations. Due to the intuitively\ngeometric nature of Sinkhorn Divergence, the student model can productively\nlearn to align its produced cross-lingual hidden states with monolingual hidden\nstates, hence leading to a strong correlation between distant languages.\nExperiments on cross-lingual summarization datasets in pairs of distant\nlanguages demonstrate that our method outperforms state-of-the-art models under\nboth high and low-resourced settings.",
    "descriptor": "\nComments: Accepted by 36th AAAI Conference on Artificial Intelligence (AAAI 2022)\n",
    "authors": [
      "Thong Nguyen",
      "Luu Anh Tuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03473"
  },
  {
    "id": "arXiv:2112.03476",
    "title": "Defending against Model Stealing via Verifying Embedded External  Features",
    "abstract": "Obtaining a well-trained model involves expensive data collection and\ntraining procedures, therefore the model is a valuable intellectual property.\nRecent studies revealed that adversaries can `steal' deployed models even when\nthey have no training samples and can not get access to the model parameters or\nstructures. Currently, there were some defense methods to alleviate this\nthreat, mostly by increasing the cost of model stealing. In this paper, we\nexplore the defense from another angle by verifying whether a suspicious model\ncontains the knowledge of defender-specified \\emph{external features}.\nSpecifically, we embed the external features by tempering a few training\nsamples with style transfer. We then train a meta-classifier to determine\nwhether a model is stolen from the victim. This approach is inspired by the\nunderstanding that the stolen models should contain the knowledge of features\nlearned by the victim model. We examine our method on both CIFAR-10 and\nImageNet datasets. Experimental results demonstrate that our method is\neffective in detecting different types of model stealing simultaneously, even\nif the stolen model is obtained via a multi-stage stealing process. The codes\nfor reproducing main results are available at Github\n(https://github.com/zlh-thu/StealingVerification).",
    "descriptor": "\nComments: This work is accepted by the AAAI 2022. The first two authors contributed equally to this work. 11 pages\n",
    "authors": [
      "Yiming Li",
      "Linghui Zhu",
      "Xiaojun Jia",
      "Yong Jiang",
      "Shu-Tao Xia",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03476"
  },
  {
    "id": "arXiv:2112.03477",
    "title": "BDFA: A Blind Data Adversarial Bit-flip Attack on Deep Neural Networks",
    "abstract": "Adversarial bit-flip attack (BFA) on Neural Network weights can result in\ncatastrophic accuracy degradation by flipping a very small number of bits. A\nmajor drawback of prior bit flip attack techniques is their reliance on test\ndata. This is frequently not possible for applications that contain sensitive\nor proprietary data. In this paper, we propose Blind Data Adversarial Bit-flip\nAttack (BDFA), a novel technique to enable BFA without any access to the\ntraining or testing data. This is achieved by optimizing for a synthetic\ndataset, which is engineered to match the statistics of batch normalization\nacross different layers of the network and the targeted label. Experimental\nresults show that BDFA could decrease the accuracy of ResNet50 significantly\nfrom 75.96\\% to 13.94\\% with only 4 bits flips.",
    "descriptor": "",
    "authors": [
      "Behnam Ghavami",
      "Mani Sadati",
      "Mohammad Shahidzadeh",
      "Zhenman Fang",
      "Lesley Shannon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03477"
  },
  {
    "id": "arXiv:2112.03478",
    "title": "Generative Adversarial Networks for Labeled Data Creation for Structural  Damage Detection",
    "abstract": "There has been a drastic progression in the field of Data Science in the last\nfew decades and other disciplines have been continuously benefitting from it.\nStructural Health Monitoring (SHM) is one of those fields that use Artificial\nIntelligence (AI) such as Machine Learning (ML) and Deep Learning (DL)\nalgorithms for condition assessment of civil structures based on the collected\ndata. The ML and DL methods require plenty of data for training procedures;\nhowever, in SHM, data collection from civil structures is very exhaustive;\nparticularly getting useful data (damage associated data) can be very\nchallenging. This paper uses 1-D Wasserstein Deep Convolutional Generative\nAdversarial Networks using Gradient Penalty (1-D WDCGAN-GP) for synthetic\nlabeled vibration data generation. Then, implements structural damage detection\non different levels of synthetically enhanced vibration datasets by using 1-D\nDeep Convolutional Neural Network (1-D DCNN). The damage detection results show\nthat the 1-D WDCGAN-GP can be successfully utilized to tackle data scarcity in\nvibration-based damage diagnostics of civil structures. Keywords: Structural\nHealth Monitoring (SHM), Structural Damage Diagnostics, Structural Damage\nDetection, 1-D Deep Convolutional Neural Networks (1-D DCNN), 1-D Generative\nAdversarial Networks (1-D GAN), Deep Convolutional Generative Adversarial\nNetworks (DCGAN), Wasserstein Generative Adversarial Networks with Gradient\nPenalty (WGAN-GP)",
    "descriptor": "",
    "authors": [
      "Furkan Luleci",
      "F. Necati Catbas",
      "Onur Avci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03478"
  },
  {
    "id": "arXiv:2112.03482",
    "title": "Combining Learning from Human Feedback and Knowledge Engineering to  Solve Hierarchical Tasks in Minecraft",
    "abstract": "Real-world tasks of interest are generally poorly defined by human-readable\ndescriptions and have no pre-defined reward signals unless it is defined by a\nhuman designer. Conversely, data-driven algorithms are often designed to solve\na specific, narrowly defined, task with performance metrics that drives the\nagent's learning. In this work, we present the solution that won first place\nand was awarded the most human-like agent in the 2021 NeurIPS Competition\nMineRL BASALT Challenge: Learning from Human Feedback in Minecraft, which\nchallenged participants to use human data to solve four tasks defined only by a\nnatural language description and no reward function. Our approach uses the\navailable human demonstration data to train an imitation learning policy for\nnavigation and additional human feedback to train an image classifier. These\nmodules, together with an estimated odometry map, are then combined into a\nstate-machine designed based on human knowledge of the tasks that breaks them\ndown in a natural hierarchy and controls which macro behavior the learning\nagent should follow at any instant. We compare this hybrid intelligence\napproach to both end-to-end machine learning and pure engineered solutions,\nwhich are then judged by human evaluators. Codebase is available at\nhttps://github.com/viniciusguigo/kairos_minerl_basalt.",
    "descriptor": "\nComments: Submitted to the AAAI 2022 Spring Symposium on Machine Learning and Knowledge Engineering for Hybrid Intelligence (AAAI-MAKE 2022)\n",
    "authors": [
      "Vinicius G. Goecks",
      "Nicholas Waytowich",
      "David Watkins",
      "Bharat Prakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.03482"
  },
  {
    "id": "arXiv:2112.03484",
    "title": "Computational complexity of problems for deterministic presentations of  sofic shifts",
    "abstract": "Sofic shifts are symbolic dynamical systems defined by the set of bi-infinite\nsequences on an edge-labeled directed graph, called a presentation. We study\nthe computational complexity of an array of natural decision problems about\npresentations of sofic shifts, such as whether a given graph presents a shift\nof finite type, or an irreducible shift; whether one graph presents a subshift\nof another; and whether a given presentation is minimal, or has a synchronizing\nword. Leveraging connections to automata theory, we first observe that these\nproblems are all decidable in polynomial time when the given presentation is\nirreducible (strongly connected), via algorithms both known and novel to this\nwork. For the general (reducible) case, however, we show they are all\nPSPACE-complete. All but one of these problems (subshift) remain\npolynomial-time solvable when restricting to synchronizing deterministic\npresentations. We also study the size of synchronizing words and synchronizing\ndeterministic presentations.",
    "descriptor": "",
    "authors": [
      "Justin Cai",
      "Rafael Frongillo"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.03484"
  },
  {
    "id": "arXiv:2112.03485",
    "title": "VizExtract: Automatic Relation Extraction from Data Visualizations",
    "abstract": "Visual graphics, such as plots, charts, and figures, are widely used to\ncommunicate statistical conclusions. Extracting information directly from such\nvisualizations is a key sub-problem for effective search through scientific\ncorpora, fact-checking, and data extraction. This paper presents a framework\nfor automatically extracting compared variables from statistical charts. Due to\nthe diversity and variation of charting styles, libraries, and tools, we\nleverage a computer vision based framework to automatically identify and\nlocalize visualization facets in line graphs, scatter plots, or bar graphs and\ncan include multiple series per graph. The framework is trained on a large\nsynthetically generated corpus of matplotlib charts and we evaluate the trained\nmodel on other chart datasets. In controlled experiments, our framework is able\nto classify, with 87.5% accuracy, the correlation between variables for graphs\nwith 1-3 series per graph, varying colors, and solid line styles. When deployed\non real-world graphs scraped from the internet, it achieves 72.8% accuracy\n(81.2% accuracy when excluding \"hard\" graphs). When deployed on the FigureQA\ndataset, it achieves 84.7% accuracy.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Dale Decatur",
      "Sanjay Krishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03485"
  },
  {
    "id": "arXiv:2112.03487",
    "title": "Enhanced Exploration in Neural Feature Selection for Deep Click-Through  Rate Prediction Models via Ensemble of Gating Layers",
    "abstract": "Feature selection has been an essential step in developing industry-scale\ndeep Click-Through Rate (CTR) prediction systems. The goal of neural feature\nselection (NFS) is to choose a relatively small subset of features with the\nbest explanatory power as a means to remove redundant features and reduce\ncomputational cost. Inspired by gradient-based neural architecture search (NAS)\nand network pruning methods, people have tackled the NFS problem with Gating\napproach that inserts a set of differentiable binary gates to drop less\ninformative features. The binary gates are optimized along with the network\nparameters in an efficient end-to-end manner. In this paper, we analyze the\ngradient-based solution from an exploration-exploitation perspective and use\nempirical results to show that Gating approach might suffer from insufficient\nexploration. To improve the exploration capacity of gradient-based solutions,\nwe propose a simple but effective ensemble learning approach, named Ensemble\nGating. We choose two public datasets, namely Avazu and Criteo, to evaluate\nthis approach. Our experiments show that, without adding any computational\noverhead or introducing any hyper-parameter (except the size of the ensemble),\nour method is able to consistently improve Gating approach and find a better\nsubset of features on the two datasets with three different underlying deep CTR\nprediction models.",
    "descriptor": "",
    "authors": [
      "Lin Guan",
      "Xia Xiao",
      "Ming Chen",
      "Youlong Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03487"
  },
  {
    "id": "arXiv:2112.03492",
    "title": "Decision-based Black-box Attack Against Vision Transformers via  Patch-wise Adversarial Removal",
    "abstract": "Vision transformers (ViTs) have demonstrated impressive performance and\nstronger adversarial robustness compared to Deep Convolutional Neural Networks\n(CNNs). On the one hand, ViTs' focus on global interaction between individual\npatches reduces the local noise sensitivity of images. On the other hand, the\nexisting decision-based attacks for CNNs ignore the difference in noise\nsensitivity between different regions of the image, which affects the\nefficiency of noise compression. Therefore, validating the black-box\nadversarial robustness of ViTs when the target model can only be queried still\nremains a challenging problem. In this paper, we propose a new decision-based\nblack-box attack against ViTs termed Patch-wise Adversarial Removal (PAR). PAR\ndivides images into patches through a coarse-to-fine search process and\ncompresses the noise on each patch separately. PAR records the noise magnitude\nand noise sensitivity of each patch and selects the patch with the highest\nquery value for noise compression. In addition, PAR can be used as a noise\ninitialization method for other decision-based attacks to improve the noise\ncompression efficiency on both ViTs and CNNs without introducing additional\ncalculations. Extensive experiments on ImageNet-21k, ILSVRC-2012, and\nTiny-Imagenet datasets demonstrate that PAR achieves a much lower magnitude of\nperturbation on average with the same number of queries.",
    "descriptor": "",
    "authors": [
      "Yucheng Shi",
      "Yahong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.03492"
  },
  {
    "id": "arXiv:2112.03494",
    "title": "Learning Instance and Task-Aware Dynamic Kernels for Few Shot Learning",
    "abstract": "Learning and generalizing to novel concepts with few samples (Few-Shot\nLearning) is still an essential challenge to real-world applications. A\nprinciple way of achieving few-shot learning is to realize a model that can\nrapidly adapt to the context of a given task. Dynamic networks have been shown\ncapable of learning content-adaptive parameters efficiently, making them\nsuitable for few-shot learning. In this paper, we propose to learn the dynamic\nkernels of a convolution network as a function of the task at hand, enabling\nfaster generalization. To this end, we obtain our dynamic kernels based on the\nentire task and each sample and develop a mechanism further conditioning on\neach individual channel and position independently. This results in dynamic\nkernels that simultaneously attend to the global information whilst also\nconsidering minuscule details available. We empirically show that our model\nimproves performance on few-shot classification and detection tasks, achieving\na tangible improvement over several baseline models. This includes\nstate-of-the-art results on 4 few-shot classification benchmarks:\nmini-ImageNet, tiered-ImageNet, CUB and FC100 and competitive results on a\nfew-shot detection dataset: MS COCO-PASCAL-VOC.",
    "descriptor": "",
    "authors": [
      "Rongkai Ma",
      "Pengfei Fang",
      "Gil Avraham",
      "Yan Zuo",
      "Tom Drummond",
      "Mehrtash Harandi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03494"
  },
  {
    "id": "arXiv:2112.03497",
    "title": "Dataset Geography: Mapping Language Data to Language Users",
    "abstract": "As language technologies become more ubiquitous, there are increasing efforts\ntowards expanding the language diversity and coverage of natural language\nprocessing (NLP) systems. Arguably, the most important factor influencing the\nquality of modern NLP systems is data availability. In this work, we study the\ngeographical representativeness of NLP datasets, aiming to quantify if and by\nhow much do NLP datasets match the expected needs of the language speakers. In\ndoing so, we use entity recognition and linking systems, also making important\nobservations about their cross-lingual consistency and giving suggestions for\nmore robust evaluation. Last, we explore some geographical and economic factors\nthat may explain the observed dataset distributions. Code and data are\navailable here: https://github.com/ffaisal93/dataset_geography. Additional\nvisualizations are available here: https://nlp.cs.gmu.edu/project/datasetmaps/.",
    "descriptor": "",
    "authors": [
      "Fahim Faisal",
      "Yinkai Wang",
      "Antonios Anastasopoulos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03497"
  },
  {
    "id": "arXiv:2112.03498",
    "title": "Hypergraph Ego-networks and Their Temporal Evolution",
    "abstract": "Interactions involving multiple objects simultaneously are ubiquitous across\nmany domains. The systems these interactions inhabit can be modelled using\nhypergraphs, a generalization of traditional graphs in which each edge can\nconnect any number of nodes. Analyzing the global and static properties of\nthese hypergraphs has led to a plethora of novel findings regarding how these\nmodelled systems are structured. However, less is known about the localized\nstructure of these systems and how they evolve over time. In this paper, we\npropose the study of hypergraph ego-networks, a structure that can be used to\nmodel higher-order interactions involving a single node. We also propose the\ntemporal reconstruction of hypergraph ego-networks as a benchmark problem for\nmodels that aim to predict the local temporal structure of hypergraphs. By\ncombining a deep learning binary classifier with a hill-climbing algorithm, we\nwill present a model for reconstructing hypergraph ego-networks by\nincorporating structural patterns found across multiple domains.",
    "descriptor": "\nComments: Appearing in IEEE ICDM 2021\n",
    "authors": [
      "Cazamere Comrie",
      "Jon Kleinberg"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.03498"
  },
  {
    "id": "arXiv:2112.03499",
    "title": "A Piece-wise Polynomial Filtering Approach for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) exploit signals from node features and the input\ngraph topology to improve node classification task performance. However, these\nmodels tend to perform poorly on heterophilic graphs, where connected nodes\nhave different labels. Recently proposed GNNs work across graphs having varying\nlevels of homophily. Among these, models relying on polynomial graph filters\nhave shown promise. We observe that solutions to these polynomial graph filter\nmodels are also solutions to an overdetermined system of equations. It suggests\nthat in some instances, the model needs to learn a reasonably high order\npolynomial. On investigation, we find the proposed models ineffective at\nlearning such polynomials due to their designs. To mitigate this issue, we\nperform an eigendecomposition of the graph and propose to learn multiple\nadaptive polynomial filters acting on different subsets of the spectrum. We\ntheoretically and empirically show that our proposed model learns a better\nfilter, thereby improving classification accuracy. We study various aspects of\nour proposed model including, dependency on the number of eigencomponents\nutilized, latent polynomial filters learned, and performance of the individual\npolynomials on the node classification task. We further show that our model is\nscalable by evaluating over large graphs. Our model achieves performance gains\nof up to 5% over the state-of-the-art models and outperforms existing\npolynomial filter-based approaches in general.",
    "descriptor": "\nComments: 28 pages, 9 figures, Under Review\n",
    "authors": [
      "Vijay Lingam",
      "Chanakya Ekbote",
      "Manan Sharma",
      "Rahul Ragesh",
      "Arun Iyer",
      "Sundararajan Sellamanickam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03499"
  },
  {
    "id": "arXiv:2112.03500",
    "title": "Understanding Distributed Tutorship in Online Language Tutoring",
    "abstract": "With the rise of the gig economy, online language tutoring platforms are\nbecoming increasingly popular. They provide temporary and flexible jobs for\nnative speakers as tutors and allow language learners to have one-on-one\nspeaking practices on demand. However, the lack of stable relationships hinders\ntutors and learners from building long-term trust. \"Distributed tutorship\" --\ntemporally discontinuous learning experience with different tutors -- has been\nunderexplored yet has many implications for modern learning platforms. In this\npaper, we analyzed tutorship sequences of 15,959 learners and found that around\n40\\% of learners change to new tutors every session; 44\\% learners change to\nnew tutors while reverting to previous tutors sometimes; only 16\\% learners\nchange to new tutors and then fix on one tutor. We also found suggestive\nevidence that higher distributedness -- higher diversity and lower continuity\nin tutorship -- is correlated to slower improvements in speaking performance\nscores with a similar number of sessions. We further surveyed 519 and\ninterviewed 40 learners and found that more learners preferred fixed tutorship\nwhile some do not have it due to various reasons. Finally, we conducted\nsemi-structured interviews with three tutors and one product manager to discuss\nthe implications for improving the continuity in learning under distributed\ntutorship.",
    "descriptor": "\nComments: 16 pages, LAK22 (Learning Analytics & Knowledge)\n",
    "authors": [
      "Meng Xia",
      "Yankun Zhao",
      "Mehmet Hamza Erol",
      "Jihyeong Hong",
      "Juho Kim"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.03500"
  },
  {
    "id": "arXiv:2112.03502",
    "title": "A Generic Approach for Enhancing GANs by Regularized Latent Optimization",
    "abstract": "With the rapidly growing model complexity and data volume, training deep\ngenerative models (DGMs) for better performance has becoming an increasingly\nmore important challenge. Previous research on this problem has mainly focused\non improving DGMs by either introducing new objective functions or designing\nmore expressive model architectures. However, such approaches often introduce\nsignificantly more computational and/or designing overhead. To resolve such\nissues, we introduce in this paper a generic framework called {\\em\ngenerative-model inference} that is capable of enhancing pre-trained GANs\neffectively and seamlessly in a variety of application scenarios. Our basic\nidea is to efficiently infer the optimal latent distribution for the given\nrequirements using Wasserstein gradient flow techniques, instead of re-training\nor fine-tuning pre-trained model parameters. Extensive experimental results on\napplications like image generation, image translation, text-to-image\ngeneration, image inpainting, and text-guided image editing suggest the\neffectiveness and superiority of our proposed framework.",
    "descriptor": "",
    "authors": [
      "Yufan Zhou",
      "Chunyuan Li",
      "Changyou Chen",
      "Jinhui Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03502"
  },
  {
    "id": "arXiv:2112.03506",
    "title": "How do scientific papers with different levels of journals spread  online? Exploring the temporal dynamics in the diffusion processes",
    "abstract": "Social media has become an important channel for publicizing academic\nresearch, which provides an opportunity for each scientific paper to become a\nhit. Employing a dataset of about 10 million tweets of 584,264 scientific\npapers from 2012 to 2018, this study investigates the differential diffusion of\nelite and non-elite journal papers (divided by Average journal impact factor\npercentile). We find that non-elite journal papers are diffused deeper and\nfarther than elite journal papers, showing a diffusion trend with multiple\nrounds, sparse, short-duration and small-scale bursts. In contrast, the bursts\nof elite journals are characterized by a small number of persistent, dense and\nlarge-scale bursts. We also discover that elite journal papers are more\ninclined to broadcast diffusion while non-elite journal papers prefer viral\ndiffusion. Elite journal papers are generally disseminated to many loosely\nconnected communities, while non-elite journal papers are diffused to several\ndensely connected communities.",
    "descriptor": "",
    "authors": [
      "Renmeng Cao",
      "Xiaoke Xu",
      "Yunxue Cui",
      "Zhizhao Fang",
      "Xianwen Wang"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2112.03506"
  },
  {
    "id": "arXiv:2112.03510",
    "title": "Model-free Nearly Optimal Control of Constrained-Input Nonlinear Systems  Based on Synchronous Reinforcement Learning",
    "abstract": "In this paper a novel model-free algorithm is proposed. This algorithm can\nlearn the nearly optimal control law of constrained-input systems from online\ndata without requiring any a priori knowledge of system dynamics. Based on the\nconcept of generalized policy iteration method, there are two neural networks\n(NNs), namely actor and critic NN to approximate the optimal value function and\noptimal policy. The stability of closed-loop systems and the convergence of\nweights are also guaranteed by Lyapunov analysis.",
    "descriptor": "",
    "authors": [
      "Han Zhao",
      "Lei Guo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03510"
  },
  {
    "id": "arXiv:2112.03511",
    "title": "Control Parameters Considered Harmful: Detecting Range Specification  Bugs in Drone Configuration Modules via Learning-Guided Search",
    "abstract": "In order to support a variety of missions and deal with different flight\nenvironments, drone control programs typically provide configurable control\nparameters. However, such a flexibility introduces vulnerabilities. One such\nvulnerability, referred to as range specification bugs, has been recently\nidentified. The vulnerability originates from the fact that even though each\nindividual parameter receives a value in the recommended value range, certain\ncombinations of parameter values may affect the drone physical stability. In\nthis paper we develop a novel learning-guided search system to find such\ncombinations, that we refer to as incorrect configurations. Our system applies\nmetaheuristic search algorithms mutating configurations to detect the\nconfiguration parameters that have values driving the drone to unstable\nphysical states. To guide the mutations, our system leverages a machine\nlearning predictor as the fitness evaluator. Finally, by utilizing\nmulti-objective optimization, our system returns the feasible ranges based on\nthe mutation search results. Because in our system the mutations are guided by\na predictor, evaluating the parameter configurations does not require\nrealistic/simulation executions. Therefore, our system supports a comprehensive\nand yet efficient detection of incorrect configurations. We have carried out an\nexperimental evaluation of our system. The evaluation results show that the\nsystem successfully reports potentially incorrect configurations, of which over\n85% lead to actual unstable physical states.",
    "descriptor": "\nComments: Accepted to ICSE2022 Technical Track\n",
    "authors": [
      "Ruidong Han",
      "Chao Yang",
      "Siqi Ma",
      "JiangFeng Ma",
      "Cong Sun",
      "Juanru Li",
      "Elisa Bertino"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03511"
  },
  {
    "id": "arXiv:2112.03515",
    "title": "$N$-Timescale Stochastic Approximation: Stability and Convergence",
    "abstract": "This paper presents the first sufficient conditions that guarantee the\nstability and almost sure convergence of $N$-timescale stochastic approximation\n(SA) iterates. It extends the existing results on One-timescale and\nTwo-timescale SA iterates with a martingale noise to $N$ timescale recursions\nusing the ordinary differential equation (ODE) based method. As an application\nof our results, we study SA algorithms with an added heavy ball momentum term\nin the context of Gradient Temporal Difference (GTD) algorithms. We show that,\nwhen the momentum parameters are chosen in a certain way, the schemes are\nstable and convergent to the same solution using our proposed results.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2111.11004\n",
    "authors": [
      "Rohan Deb",
      "Shalabh Bhatnagar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03515"
  },
  {
    "id": "arXiv:2112.03517",
    "title": "CG-NeRF: Conditional Generative Neural Radiance Fields",
    "abstract": "While recent NeRF-based generative models achieve the generation of diverse\n3D-aware images, these approaches have limitations when generating images that\ncontain user-specified characteristics. In this paper, we propose a novel\nmodel, referred to as the conditional generative neural radiance fields\n(CG-NeRF), which can generate multi-view images reflecting extra input\nconditions such as images or texts. While preserving the common characteristics\nof a given input condition, the proposed model generates diverse images in fine\ndetail. We propose: 1) a novel unified architecture which disentangles the\nshape and appearance from a condition given in various forms and 2) the\npose-consistent diversity loss for generating multimodal outputs while\nmaintaining consistency of the view. Experimental results show that the\nproposed method maintains consistent image quality on various condition types\nand achieves superior fidelity and diversity compared to existing NeRF-based\ngenerative models.",
    "descriptor": "",
    "authors": [
      "Kyungmin Jo",
      "Gyumin Shim",
      "Sanghun Jung",
      "Soyoung Yang",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.03517"
  },
  {
    "id": "arXiv:2112.03518",
    "title": "Genetic Algorithm for Constrained Molecular Inverse Design",
    "abstract": "A genetic algorithm is suitable for exploring large search spaces as it finds\nan approximate solution. Because of this advantage, genetic algorithm is\neffective in exploring vast and unknown space such as molecular search space.\nThough the algorithm is suitable for searching vast chemical space, it is\ndifficult to optimize pharmacological properties while maintaining molecular\nsubstructure. To solve this issue, we introduce a genetic algorithm featuring a\nconstrained molecular inverse design. The proposed algorithm successfully\nproduces valid molecules for crossover and mutation. Furthermore, it optimizes\nspecific properties while adhering to structural constraints using a two-phase\noptimization. Experiments prove that our algorithm effectively finds molecules\nthat satisfy specific properties while maintaining structural constraints.",
    "descriptor": "",
    "authors": [
      "Yurim Lee",
      "Gydam Choi",
      "Minsug Yoon",
      "Cheongwon Kim"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03518"
  },
  {
    "id": "arXiv:2112.03521",
    "title": "UNITER-Based Situated Coreference Resolution with Rich Multimodal Input",
    "abstract": "We present our work on the multimodal coreference resolution task of the\nSituated and Interactive Multimodal Conversation 2.0 (SIMMC 2.0) dataset as a\npart of the tenth Dialog System Technology Challenge (DSTC10). We propose a\nUNITER-based model utilizing rich multimodal context such as textual dialog\nhistory, object knowledge base and visual dialog scenes to determine whether\neach object in the current scene is mentioned in the current dialog turn.\nResults show that the proposed approach outperforms the official DSTC10\nbaseline substantially, with the object F1 score boosted from 36.6% to 77.3% on\nthe development set, demonstrating the effectiveness of the proposed object\nrepresentations from rich multimodal input. Our model ranks second in the\nofficial evaluation on the object coreference resolution task with an F1 score\nof 73.3% after model ensembling.",
    "descriptor": "",
    "authors": [
      "Yichen Huang",
      "Yuchen Wang",
      "Yik-Cheung Tam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03521"
  },
  {
    "id": "arXiv:2112.03523",
    "title": "Distributed Containment Reference Signal for Nonholonomic Planar  Vehicles",
    "abstract": "Cooperative of multiple nonholonomic vehicles can be converted into tracking\nproblems of a single-vehicle. The reference trajectory design within\ndistributed features for each vehicle in the group is addressed in this note.\nThe motivation is that nonholonomic vehicles cannot achieve asymptotical\nstabilization of non-feasible reference signals, and modifications about the\nvirtual reference trajectory design are needed. Reduced-order design and\ntime-varying technique, and some simple geometry tricks are applied to derive\nthe dynamic reference trajectory.",
    "descriptor": "",
    "authors": [
      "Lixia Yan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03523"
  },
  {
    "id": "arXiv:2112.03526",
    "title": "Socially acceptable route planning and trajectory behavior analysis of  personal mobility device for mobility management with improved sensing",
    "abstract": "In urban cities, with increasing acceptability of shared spaces used by\npedestrians and personal mobility devices (PMDs), there is need for pragmatic\nsocially ac-ceptable path planning and navigation management policies. Hence,\nwe propose a socially acceptable global route planner and assess the legibility\nof the resulting global route. Our approach proposed for choosing global route\navoids streets penetrating shared spaces and main routes with high probability\nof dense usage. The experimental study shows that socially acceptable routes\ncan be effectively found with an average of 10 % increment of route length with\noptimal hyperpa-rameters. This helps PMDs to reach the goal while taking a\nsocially acceptable and safe route with minimal interaction of different PMDs\nand pedestrians. When PMDs interact with pedestrians and other types of PMDs in\nshared spaces, mi-cro-mobility simulations are of prime usage for acceptable\nand safe navigation policy. Social force models being state of the art for\npedestrian simulation are cal-ibrated for capturing random movements of\npedestrian behavior. Social force model with calibration can imitate the\nrequired behavior of PMDs in a pedestrian mix navigation scheme. Based on\ncalibrated models, simulations on shared space links and gate structures are\nperformed to assist policies related to deciding wait-ing and stopping time.\nAlso, based on simulated PMDs interaction with pedestri-ans, location data with\nfiner resolution can be obtained if the resolution of GPS sensor is 0.2 m or\nless. This will help in formalizing better modelling and hence better\nmicro-mobility policies.",
    "descriptor": "\nComments: 12 pages, 6 figures, Accepted by \"The 9th International Conference on Robot Intelligence Technology and Applications, RiTA 2021\"\n",
    "authors": [
      "Sumit Mishra",
      "Praveen Kumar Rajendran",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.03526"
  },
  {
    "id": "arXiv:2112.03529",
    "title": "Ground-Truth, Whose Truth? -- Examining the Challenges with Annotating  Toxic Text Datasets",
    "abstract": "The use of machine learning (ML)-based language models (LMs) to monitor\ncontent online is on the rise. For toxic text identification, task-specific\nfine-tuning of these models are performed using datasets labeled by annotators\nwho provide ground-truth labels in an effort to distinguish between offensive\nand normal content. These projects have led to the development, improvement,\nand expansion of large datasets over time, and have contributed immensely to\nresearch on natural language. Despite the achievements, existing evidence\nsuggests that ML models built on these datasets do not always result in\ndesirable outcomes. Therefore, using a design science research (DSR) approach,\nthis study examines selected toxic text datasets with the goal of shedding\nlight on some of the inherent issues and contributing to discussions on\nnavigating these challenges for existing and future projects. To achieve the\ngoal of the study, we re-annotate samples from three toxic text datasets and\nfind that a multi-label approach to annotating toxic text samples can help to\nimprove dataset quality. While this approach may not improve the traditional\nmetric of inter-annotator agreement, it may better capture dependence on\ncontext and diversity in annotators. We discuss the implications of these\nresults for both theory and practice.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Kofi Arhin",
      "Ioana Baldini",
      "Dennis Wei",
      "Karthikeyan Natesan Ramamurthy",
      "Moninder Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03529"
  },
  {
    "id": "arXiv:2112.03530",
    "title": "A Conditional Point Diffusion-Refinement Paradigm for 3D Point Cloud  Completion",
    "abstract": "3D point cloud is an important 3D representation for capturing real world 3D\nobjects. However, real-scanned 3D point clouds are often incomplete, and it is\nimportant to recover complete point clouds for downstream applications. Most\nexisting point cloud completion methods use Chamfer Distance (CD) loss for\ntraining. The CD loss estimates correspondences between two point clouds by\nsearching nearest neighbors, which does not capture the overall point density\ndistribution on the generated shape, and therefore likely leads to non-uniform\npoint cloud generation. To tackle this problem, we propose a novel Point\nDiffusion-Refinement (PDR) paradigm for point cloud completion. PDR consists of\na Conditional Generation Network (CGNet) and a ReFinement Network (RFNet). The\nCGNet uses a conditional generative model called the denoising diffusion\nprobabilistic model (DDPM) to generate a coarse completion conditioned on the\npartial observation. DDPM establishes a one-to-one pointwise mapping between\nthe generated point cloud and the uniform ground truth, and then optimizes the\nmean squared error loss to realize uniform generation. The RFNet refines the\ncoarse output of the CGNet and further improves quality of the completed point\ncloud. Furthermore, we develop a novel dual-path architecture for both\nnetworks. The architecture can (1) effectively and efficiently extract\nmulti-level features from partially observed point clouds to guide completion,\nand (2) accurately manipulate spatial locations of 3D points to obtain smooth\nsurfaces and sharp details. Extensive experimental results on various benchmark\ndatasets show that our PDR paradigm outperforms previous state-of-the-art\nmethods for point cloud completion. Remarkably, with the help of the RFNet, we\ncan accelerate the iterative generation process of the DDPM by up to 50 times\nwithout much performance drop.",
    "descriptor": "",
    "authors": [
      "Zhaoyang Lyu",
      "Zhifeng Kong",
      "Xudong Xu",
      "Liang Pan",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03530"
  },
  {
    "id": "arXiv:2112.03534",
    "title": "Deep Surrogate Assisted MAP-Elites for Automated Hearthstone  Deckbuilding",
    "abstract": "We study the problem of efficiently generating high-quality and diverse\ncontent in games. Previous work on automated deckbuilding in Hearthstone shows\nthat the quality diversity algorithm MAP-Elites can generate a collection of\nhigh-performing decks with diverse strategic gameplay. However, MAP-Elites\nrequires a large number of expensive evaluations to discover the diverse\ncollection of decks. We propose assisting MAP-Elites with a deep surrogate\nmodel trained online to predict game outcomes with respect to candidate decks.\nMAP-Elites discovers a diverse dataset to improve the surrogate model accuracy,\nwhile the surrogate model helps guide MAP-Elites towards promising new content.\nIn a Hearthstone deckbuilding case study, we show that our approach improves\nthe sample efficiency of MAP-Elites and outperforms a model trained offline\nwith random decks, as well as a linear surrogate model baseline, setting a new\nstate-of-the-art for quality diversity approaches in the application domain of\nautomated Hearthstone deckbuilding.",
    "descriptor": "\nComments: in preparation\n",
    "authors": [
      "Yulun Zhang",
      "Matthew C. Fontaine",
      "Amy K. Hoover",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.03534"
  },
  {
    "id": "arXiv:2112.03541",
    "title": "Predicting the Travel Distance of Patients to Access Healthcare using  Deep Neural Networks",
    "abstract": "Objective: Improving geographical access remains a key issue in determining\nthe sufficiency of regional medical resources during health policy design.\nHowever, patient choices can be the result of the complex interactivity of\nvarious factors. The aim of this study is to propose a deep neural network\napproach to model the complex decision of patient choice in travel distance to\naccess care, which is an important indicator for policymaking in allocating\nresources. Method: We used the 4-year nationwide insurance data of Taiwan and\naccumulated the possible features discussed in earlier literature. This study\nproposes the use of a convolutional neural network (CNN)-based framework to\nmake predictions. The model performance was tested against other machine\nlearning methods. The proposed framework was further interpreted using\nIntegrated Gradients (IG) to analyze the feature weights. Results: We\nsuccessfully demonstrated the effectiveness of using a CNN-based framework to\npredict the travel distance of patients, achieving an accuracy of 0.968, AUC of\n0.969, sensitivity of 0.960, and specificity of 0.989. The CNN-based framework\noutperformed all other methods. In this research, the IG weights are\npotentially explainable; however, the relationship does not correspond to known\nindicators in public health, similar to common consensus. Conclusions: Our\nresults demonstrate the feasibility of the deep learning-based travel distance\nprediction model. It has the potential to guide policymaking in resource\nallocation.",
    "descriptor": "\nComments: accepted by IEEE Journal of Translational Engineering in Health and Medicine\n",
    "authors": [
      "Li-Chin Chen",
      "Ji-Tian Sheu",
      "Yuh-Jue Chuang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03541"
  },
  {
    "id": "arXiv:2112.03543",
    "title": "Phase Transition of the 3-Majority Dynamics with Uniform Communication  Noise",
    "abstract": "Communication noise is a common feature in several real-world scenarios where\nsystems of agents need to communicate in order to pursue some collective task.\nIn particular, many biologically inspired systems that try to achieve\nagreements on some opinion must implement resilient dynamics that are not\nstrongly affected by noisy communications. In this work, we study the popular\n3-Majority dynamics, an opinion dynamics which has been proved to be an\nefficient protocol for the majority consensus problem, in which we introduce a\nsimple feature of uniform communication noise, following (d'Amore et al. 2020).\nWe prove that in the fully connected communication network of n agents and in\nthe binary opinion case, the process induced by the 3-Majority dynamics\nexhibits a phase transition. For a noise probability $p < 1/3$, the dynamics\nreaches in logarithmic time an almost-consensus metastable phase which lasts\nfor a polynomial number of rounds with high probability. Furthermore, departing\nfrom previous analyses, we further characterize this phase by showing that\nthere exists an attractive equilibrium value $s_{\\text{eq}} \\in [n]$ for the\nbias of the system, i.e. the difference between the majority community size and\nthe minority one. Moreover, the agreement opinion turns out to be the initial\nmajority one if the bias towards it is of magnitude $\\Omega(\\sqrt{n\\log n})$ in\nthe initial configuration. If, instead, $p > 1/3$, no form of consensus is\npossible, and any information regarding the initial majority opinion is lost in\nlogarithmic time with high probability. Despite more communications per-round\nare allowed, the 3-Majority dynamics surprisingly turns out to be less\nresilient to noise than the Undecided-State dynamics (d'Amore et al. 2020),\nwhose noise threshold value is $p = 1/2$.",
    "descriptor": "",
    "authors": [
      "Francesco d'Amore",
      "Isabella Ziccardi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.03543"
  },
  {
    "id": "arXiv:2112.03546",
    "title": "Predicting peer-to-peer and collective social contagion from individual  behaviour",
    "abstract": "Understanding the heterogeneous role of individuals for large-scale\ninformation spreading is essential to manage online behaviour as well as its\npotential offline consequences. To this end, most existing studies from diverse\nresearch domains focus on the disproportionate role played by highly-connected\n\"hub\" individuals. However, we demonstrate here that information spreading in\nonline social media is best understood and predicted by simultaneously\nuncovering two individual-level behavioural traits: influence and\nsusceptibility. Specifically, we derive a nonlinear network-based algorithm to\nquantify individuals' influence and susceptibility from multiple spreading\nevent data. By applying the algorithm to large-scale data from Twitter and\nWeibo, we demonstrate that both individuals' influence and susceptibility are\nkey determinants of peer-to-peer information propagation: neglecting one of the\ntwo properties leads to sub-optimal propagation predictions. Besides, we show\nthat both properties are needed to accurately identify superspreaders of\ninformation, which challenges common assumptions in studies on influential\nindividuals in social networks.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Fang Zhou",
      "Linyuan L\u00fc",
      "Jianguo Liu",
      "Manuel Sebastian Mariani"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.03546"
  },
  {
    "id": "arXiv:2112.03547",
    "title": "Self-Organized Polynomial-Time Coordination Graphs",
    "abstract": "Coordination graph is a promising approach to model agent collaboration in\nmulti-agent reinforcement learning. It factorizes a large multi-agent system\ninto a suite of overlapping groups that represent the underlying coordination\ndependencies. One critical challenge in this paradigm is the complexity of\ncomputing maximum-value actions for a graph-based value factorization. It\nrefers to the decentralized constraint optimization problem (DCOP), which and\nwhose constant-ratio approximation are NP-hard problems. To bypass this\nfundamental hardness, this paper proposes a novel method, named Self-Organized\nPolynomial-time Coordination Graphs (SOP-CG), which uses structured graph\nclasses to guarantee the optimality of the induced DCOPs with sufficient\nfunction expressiveness. We extend the graph topology to be state-dependent,\nformulate the graph selection as an imaginary agent, and finally derive an\nend-to-end learning paradigm from the unified Bellman optimality equation. In\nexperiments, we show that our approach learns interpretable graph topologies,\ninduces effective coordination, and improves performance across a variety of\ncooperative multi-agent tasks.",
    "descriptor": "",
    "authors": [
      "Qianlan Yang",
      "Weijun Dong",
      "Zhizhou Ren",
      "Jianhao Wang",
      "Tonghan Wang",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.03547"
  },
  {
    "id": "arXiv:2112.03549",
    "title": "GaTector: A Unified Framework for Gaze Object Prediction",
    "abstract": "Gaze object prediction (GOP) is a newly proposed task that aims to discover\nthe objects being stared at by humans. It is of great application significance\nbut still lacks a unified solution framework. An intuitive solution is to\nincorporate an object detection branch into an existing gaze prediction method.\nHowever, previous gaze prediction methods usually use two different networks to\nextract features from scene image and head image, which would lead to heavy\nnetwork architecture and prevent each branch from joint optimization. In this\npaper, we build a novel framework named GaTector to tackle the gaze object\nprediction problem in a unified way. Particularly, a specific-general-specific\n(SGS) feature extractor is firstly proposed to utilize a shared backbone to\nextract general features for both scene and head images. To better consider the\nspecificity of inputs and tasks, SGS introduces two input-specific blocks\nbefore the shared backbone and three task-specific blocks after the shared\nbackbone. Specifically, a novel defocus layer is designed to generate\nobject-specific features for object detection task without losing information\nor requiring extra computations. Moreover, the energy aggregation loss is\nintroduced to guide the gaze heatmap to concentrate on the stared box. In the\nend, we propose a novel mDAP metric that can reveal the difference between\nboxes even when they share no overlapping area. Extensive experiments on the\nGOO dataset verify the superiority of our method in all three tracks, i.e.\nobject detection, gaze estimation, and gaze object prediction.",
    "descriptor": "\nComments: Techinical report\n",
    "authors": [
      "Binglu Wang",
      "Tao Hu",
      "Baoshan Li",
      "Xiaojuan Chen",
      "Zhijie Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03549"
  },
  {
    "id": "arXiv:2112.03551",
    "title": "Optimal Scheduling of Energy Storage for Power System with Capability of  Sensing Short-term Future PV Power Production",
    "abstract": "Constant rise in energy consumption that comes with the population growth and\nintroduction of new technologies has posed critical issues such as efficient\nenergy management on the consumer side. That has elevated the importance of the\nuse of renewable energy sources, particularly photovoltaic (PV) system and wind\nturbine. This work models and discusses design options based on the hybrid\npower system of grid and battery storage. The effects of installed capacity on\nrenewable penetration (RP) and cost of electricity (COE) are investigated for\neach modality. For successful operation of hybrid power system and electricity\ntrading in power market, accurate predictions of PV power production and load\ndemand are taken into account. A machine learning (ML) model is introduced for\nscheduling, and predicting variations of the PV power production and load\ndemand. Fitness of the ML model shows, when employing a linear regression\nmodel, the mean squared error (MSE) of 0.000012, root mean square error (RMSE)\nof 0.003560 and R2 of 0.999379. Using predicted PV power production and load\ndemand, reduction of electricity cost is 37.5 % when PV and utility grid are\nutilized, and is 43.06% when PV, utility grid, and storage system are utilized.",
    "descriptor": "\nComments: 5 pages, 9 figures, Accepted by \"2021 11th International Conference on Power and Energy Systems (ICPES 2021)\"\n",
    "authors": [
      "Sarvar Hussain Nengroo",
      "Sangkeum Lee",
      "Hojun Jin",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03551"
  },
  {
    "id": "arXiv:2112.03552",
    "title": "Bootstrapping ViTs: Towards Liberating Vision Transformers from  Pre-training",
    "abstract": "Recently, vision Transformers (ViTs) are developing rapidly and starting to\nchallenge the domination of convolutional neural networks (CNNs) in the realm\nof computer vision (CV). With the general-purpose Transformer architecture for\nreplacing the hard-coded inductive biases of convolution, ViTs have surpassed\nCNNs, especially in data-sufficient circumstances. However, ViTs are prone to\nover-fit on small datasets and thus rely on large-scale pre-training, which\nexpends enormous time. In this paper, we strive to liberate ViTs from\npre-training by introducing CNNs' inductive biases back to ViTs while\npreserving their network architectures for higher upper bound and setting up\nmore suitable optimization objectives. To begin with, an agent CNN is designed\nbased on the given ViT with inductive biases. Then a bootstrapping training\nalgorithm is proposed to jointly optimize the agent and ViT with weight\nsharing, during which the ViT learns inductive biases from the intermediate\nfeatures of the agent. Extensive experiments on CIFAR-10/100 and ImageNet-1k\nwith limited training data have shown encouraging results that the inductive\nbiases help ViTs converge significantly faster and outperform conventional CNNs\nwith even fewer parameters.",
    "descriptor": "\nComments: 10 Pages, Reviewing under CVPR 2022\n",
    "authors": [
      "Haofei Zhang",
      "Jiarui Duan",
      "Mengqi Xue",
      "Jie Song",
      "Li Sun",
      "Mingli Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03552"
  },
  {
    "id": "arXiv:2112.03553",
    "title": "ADD: Frequency Attention and Multi-View based Knowledge Distillation to  Detect Low-Quality Compressed Deepfake Images",
    "abstract": "Despite significant advancements of deep learning-based forgery detectors for\ndistinguishing manipulated deepfake images, most detection approaches suffer\nfrom moderate to significant performance degradation with low-quality\ncompressed deepfake images. Because of the limited information in low-quality\nimages, detecting low-quality deepfake remains an important challenge. In this\nwork, we apply frequency domain learning and optimal transport theory in\nknowledge distillation (KD) to specifically improve the detection of\nlow-quality compressed deepfake images. We explore transfer learning capability\nin KD to enable a student network to learn discriminative features from\nlow-quality images effectively. In particular, we propose the Attention-based\nDeepfake detection Distiller (ADD), which consists of two novel distillations:\n1) frequency attention distillation that effectively retrieves the removed\nhigh-frequency components in the student network, and 2) multi-view attention\ndistillation that creates multiple attention vectors by slicing the teacher's\nand student's tensors under different views to transfer the teacher tensor's\ndistribution to the student more efficiently. Our extensive experimental\nresults demonstrate that our approach outperforms state-of-the-art baselines in\ndetecting low-quality compressed deepfake images.",
    "descriptor": "",
    "authors": [
      "Binh M. Le",
      "Simon S. Woo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03553"
  },
  {
    "id": "arXiv:2112.03554",
    "title": "Combining optimal control and learning for autonomous aerial navigation  in novel indoor environments",
    "abstract": "This report proposes a combined optimal control and perception framework for\nMicro Aerial Vehicle (MAV) autonomous navigation in novel indoor enclosed\nenvironments, relying exclusively on on-board sensor data. We use privileged\ninformation from a simulator to generate optimal waypoints in 3D space for our\nperception system learns to imitate. The trained learning based perception\nmodule in turn is able to generate similar obstacle avoiding waypoints from\nsensor data (RGB + IMU) alone. We demonstrate the efficacy of the framework\nacross novel scenes in the iGibson simulation environment.",
    "descriptor": "",
    "authors": [
      "Kevin Lin",
      "Brian Huo",
      "Megan Hu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.03554"
  },
  {
    "id": "arXiv:2112.03555",
    "title": "Federated Causal Discovery",
    "abstract": "Causal discovery aims to learn a causal graph from observational data. To\ndate, most causal discovery methods require data to be stored in a central\nserver. However, data owners gradually refuse to share their personalized data\nto avoid privacy leakage, making this task more troublesome by cutting off the\nfirst step. A puzzle arises: $\\textit{how do we infer causal relations from\ndecentralized data?}$ In this paper, with the additive noise model assumption\nof data, we take the first step in developing a gradient-based learning\nframework named DAG-Shared Federated Causal Discovery (DS-FCD), which can learn\nthe causal graph without directly touching local data and naturally handle the\ndata heterogeneity. DS-FCD benefits from a two-level structure of each local\nmodel. The first level learns the causal graph and communicates with the server\nto get model information from other clients, while the second level\napproximates causal mechanisms and personally updates from its own data to\naccommodate the data heterogeneity. Moreover, DS-FCD formulates the overall\nlearning task as a continuous optimization problem by taking advantage of an\nequality acyclicity constraint, which can be naturally solved by gradient\ndescent methods. Extensive experiments on both synthetic and real-world\ndatasets verify the efficacy of the proposed method.",
    "descriptor": "",
    "authors": [
      "Erdun Gao",
      "Junjia Chen",
      "Li Shen",
      "Tongliang Liu",
      "Mingming Gong",
      "Howard Bondell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03555"
  },
  {
    "id": "arXiv:2112.03557",
    "title": "Multi-speaker Emotional Text-to-speech Synthesizer",
    "abstract": "We present a methodology to train our multi-speaker emotional text-to-speech\nsynthesizer that can express speech for 10 speakers' 7 different emotions. All\nsilences from audio samples are removed prior to learning. This results in fast\nlearning by our model. Curriculum learning is applied to train our model\nefficiently. Our model is first trained with a large single-speaker neutral\ndataset, and then trained with neutral speech from all speakers. Finally, our\nmodel is trained using datasets of emotional speech from all speakers. In each\nstage, training samples of each speaker-emotion pair have equal probability to\nappear in mini-batches. Through this procedure, our model can synthesize speech\nfor all targeted speakers and emotions. Our synthesized audio sets are\navailable on our web page.",
    "descriptor": "\nComments: 2 pages; Published in the Proceedings of Interspeech 2021; Presented in Show and Tell; For the published paper, see this https URL\n",
    "authors": [
      "Sungjae Cho",
      "Soo-Young Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.03557"
  },
  {
    "id": "arXiv:2112.03558",
    "title": "Graph Neural Controlled Differential Equations for Traffic Forecasting",
    "abstract": "Traffic forecasting is one of the most popular spatio-temporal tasks in the\nfield of machine learning. A prevalent approach in the field is to combine\ngraph convolutional networks and recurrent neural networks for the\nspatio-temporal processing. There has been fierce competition and many novel\nmethods have been proposed. In this paper, we present the method of\nspatio-temporal graph neural controlled differential equation (STG-NCDE).\nNeural controlled differential equations (NCDEs) are a breakthrough concept for\nprocessing sequential data. We extend the concept and design two NCDEs: one for\nthe temporal processing and the other for the spatial processing. After that,\nwe combine them into a single framework. We conduct experiments with 6\nbenchmark datasets and 20 baselines. STG-NCDE shows the best accuracy in all\ncases, outperforming all those 20 baselines by non-trivial margins.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Jeongwhan Choi",
      "Hwangyong Choi",
      "Jeehyun Hwang",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03558"
  },
  {
    "id": "arXiv:2112.03562",
    "title": "CMA-CLIP: Cross-Modality Attention CLIP for Image-Text Classification",
    "abstract": "Modern Web systems such as social media and e-commerce contain rich contents\nexpressed in images and text. Leveraging information from multi-modalities can\nimprove the performance of machine learning tasks such as classification and\nrecommendation. In this paper, we propose the Cross-Modality Attention\nContrastive Language-Image Pre-training (CMA-CLIP), a new framework which\nunifies two types of cross-modality attentions, sequence-wise attention and\nmodality-wise attention, to effectively fuse information from image and text\npairs. The sequence-wise attention enables the framework to capture the\nfine-grained relationship between image patches and text tokens, while the\nmodality-wise attention weighs each modality by its relevance to the downstream\ntasks. In addition, by adding task specific modality-wise attentions and\nmultilayer perceptrons, our proposed framework is capable of performing\nmulti-task classification with multi-modalities.\nWe conduct experiments on a Major Retail Website Product Attribute (MRWPA)\ndataset and two public datasets, Food101 and Fashion-Gen. The results show that\nCMA-CLIP outperforms the pre-trained and fine-tuned CLIP by an average of 11.9%\nin recall at the same level of precision on the MRWPA dataset for multi-task\nclassification. It also surpasses the state-of-the-art method on Fashion-Gen\nDataset by 5.5% in accuracy and achieves competitive performance on Food101\nDataset. Through detailed ablation studies, we further demonstrate the\neffectiveness of both cross-modality attention modules and our method's\nrobustness against noise in image and text inputs, which is a common challenge\nin practice.",
    "descriptor": "",
    "authors": [
      "Huidong Liu",
      "Shaoyuan Xu",
      "Jinmiao Fu",
      "Yang Liu",
      "Ning Xie",
      "Chien-chih Wang",
      "Bryan Wang",
      "Yi Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03562"
  },
  {
    "id": "arXiv:2112.03565",
    "title": "Spiking Control Systems",
    "abstract": "Spikes and rhythms organize control and communication in the animal world, in\ncontrast to the bits and clocks of digital technology. As continuous-time\nsignals that can be counted, spikes have a mixed nature. This paper reviews\nongoing efforts to develop a control theory of spiking systems. The central\nthesis is that the mixed nature of spiking results from a mixed feedback\nprinciple, and that a control theory of mixed feedback can be grounded in the\noperator theoretic concept of maximal monotonicity. As a nonlinear\ngeneralization of passivity, maximal monotonicity acknowledges at once the\nphysics of electrical circuits, the algorithmic tractability of convex\noptimization, and the feedback control theory of incremental passivity. We\ndiscuss the relevance of a theory of spiking control systems in the emerging\nage of event-based technology.",
    "descriptor": "",
    "authors": [
      "Rodolphe Sepulchre"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03565"
  },
  {
    "id": "arXiv:2112.03566",
    "title": "More layers! End-to-end regression and uncertainty on tabular data with  deep learning",
    "abstract": "This paper attempts to analyze the effectiveness of deep learning for tabular\ndata processing. It is believed that decision trees and their ensembles is the\nleading method in this domain, and deep neural networks must be content with\ncomputer vision and so on. But the deep neural network is a framework for\nbuilding gradient-based hierarchical representations, and this key feature\nshould be able to provide the best processing of generic structured (tabular)\ndata, not just image matrices and audio spectrograms. This problem is\nconsidered through the prism of the Weather Prediction track in the Yandex\nShifts challenge (in other words, the Yandex Shifts Weather task). This task is\na variant of the classical tabular data regression problem. It is also\nconnected with another important problem: generalization and uncertainty in\nmachine learning. This paper proposes an end-to-end algorithm for solving the\nproblem of regression with uncertainty on tabular data, which is based on the\ncombination of four ideas: 1) deep ensemble of self-normalizing neural\nnetworks, 2) regression as parameter estimation of the Gaussian target error\ndistribution, 3) hierarchical multitask learning, and 4) simple data\npreprocessing. Three modifications of the proposed algorithm form the top-3\nleaderboard of the Yandex Shifts Weather challenge respectively. This paper\nconsiders that this success has occurred due to the fundamental properties of\nthe deep learning algorithm, and tries to prove this.",
    "descriptor": "\nComments: 12 pages, 5 figures, the described solution is submitted to the Shifts Challenge (see this https URL), the code is available on this https URL\n",
    "authors": [
      "Ivan Bondarenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03566"
  },
  {
    "id": "arXiv:2112.03568",
    "title": "Unsupervised Learning of Compositional Scene Representations from  Multiple Unspecified Viewpoints",
    "abstract": "Visual scenes are extremely rich in diversity, not only because there are\ninfinite combinations of objects and background, but also because the\nobservations of the same scene may vary greatly with the change of viewpoints.\nWhen observing a visual scene that contains multiple objects from multiple\nviewpoints, humans are able to perceive the scene in a compositional way from\neach viewpoint, while achieving the so-called \"object constancy\" across\ndifferent viewpoints, even though the exact viewpoints are untold. This ability\nis essential for humans to identify the same object while moving and to learn\nfrom vision efficiently. It is intriguing to design models that have the\nsimilar ability. In this paper, we consider a novel problem of learning\ncompositional scene representations from multiple unspecified viewpoints\nwithout using any supervision, and propose a deep generative model which\nseparates latent representations into a viewpoint-independent part and a\nviewpoint-dependent part to solve this problem. To infer latent\nrepresentations, the information contained in different viewpoints is\niteratively integrated by neural networks. Experiments on several specifically\ndesigned synthetic datasets have shown that the proposed method is able to\neffectively learn from multiple unspecified viewpoints.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Jinyang Yuan",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03568"
  },
  {
    "id": "arXiv:2112.03570",
    "title": "Membership Inference Attacks From First Principles",
    "abstract": "A membership inference attack allows an adversary to query a trained machine\nlearning model to predict whether or not a particular example was contained in\nthe model's training dataset. These attacks are currently evaluated using\naverage-case \"accuracy\" metrics that fail to characterize whether the attack\ncan confidently identify any members of the training set. We argue that attacks\nshould instead be evaluated by computing their true-positive rate at low (e.g.,\n<0.1%) false-positive rates, and find most prior attacks perform poorly when\nevaluated in this way. To address this we develop a Likelihood Ratio Attack\n(LiRA) that carefully combines multiple ideas from the literature. Our attack\nis 10x more powerful at low false-positive rates, and also strictly dominates\nprior attacks on existing metrics.",
    "descriptor": "",
    "authors": [
      "Nicholas Carlini",
      "Steve Chien",
      "Milad Nasr",
      "Shuang Song",
      "Andreas Terzis",
      "Florian Tramer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03570"
  },
  {
    "id": "arXiv:2112.03571",
    "title": "Neural Networks for Infectious Diseases Detection: Prospects and  Challenges",
    "abstract": "Artificial neural network (ANN) ability to learn, correct errors, and\ntransform a large amount of raw data into useful medical decisions for\ntreatment and care have increased its popularity for enhanced patient safety\nand quality of care. Therefore, this paper reviews the critical role of ANNs in\nproviding valuable insights for patients' healthcare decisions and efficient\ndisease diagnosis. We thoroughly review different types of ANNs presented in\nthe existing literature that advanced ANNs adaptation for complex applications.\nMoreover, we also investigate ANN's advances for various disease diagnoses and\ntreatments such as viral, skin, cancer, and COVID-19. Furthermore, we propose a\nnovel deep Convolutional Neural Network (CNN) model called ConXNet for\nimproving the detection accuracy of COVID-19 disease. ConXNet is trained and\ntested using different datasets, and it achieves more than 97% detection\naccuracy and precision, which is significantly better than existing models.\nFinally, we highlight future research directions and challenges such as\ncomplexity of the algorithms, insufficient available data, privacy and\nsecurity, and integration of biosensing with ANNs. These research directions\nrequire considerable attention for improving the scope of ANNs for medical\ndiagnostic and treatment applications.",
    "descriptor": "\nComments: Submitted to IEEE/ACM Transactions on Computational Biology and Bioinformatics\n",
    "authors": [
      "Muhammad Azeem",
      "Shumaila Javaid",
      "Hamza Fahim",
      "Nasir Saeed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.03571"
  },
  {
    "id": "arXiv:2112.03572",
    "title": "Question Answering Survey: Directions, Challenges, Datasets, Evaluation  Matrices",
    "abstract": "The usage and amount of information available on the internet increase over\nthe past decade. This digitization leads to the need for automated answering\nsystem to extract fruitful information from redundant and transitional\nknowledge sources. Such systems are designed to cater the most prominent answer\nfrom this giant knowledge source to the user query using natural language\nunderstanding (NLU) and thus eminently depends on the Question-answering(QA)\nfield.\nQuestion answering involves but not limited to the steps like mapping of user\nquestion to pertinent query, retrieval of relevant information, finding the\nbest suitable answer from the retrieved information etc. The current\nimprovement of deep learning models evince compelling performance improvement\nin all these tasks.\nIn this review work, the research directions of QA field are analyzed based\non the type of question, answer type, source of evidence-answer, and modeling\napproach. This detailing followed by open challenges of the field like\nautomatic question generation, similarity detection and, low resource\navailability for a language. In the end, a survey of available datasets and\nevaluation measures is presented.",
    "descriptor": "",
    "authors": [
      "Hariom A. Pandya",
      "Brijesh S. Bhatt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03572"
  },
  {
    "id": "arXiv:2112.03575",
    "title": "MESA: Offline Meta-RL for Safe Adaptation and Fault Tolerance",
    "abstract": "Safe exploration is critical for using reinforcement learning (RL) in\nrisk-sensitive environments. Recent work learns risk measures which measure the\nprobability of violating constraints, which can then be used to enable safety.\nHowever, learning such risk measures requires significant interaction with the\nenvironment, resulting in excessive constraint violations during learning.\nFurthermore, these measures are not easily transferable to new environments. We\ncast safe exploration as an offline meta-RL problem, where the objective is to\nleverage examples of safe and unsafe behavior across a range of environments to\nquickly adapt learned risk measures to a new environment with previously unseen\ndynamics. We then propose MEta-learning for Safe Adaptation (MESA), an approach\nfor meta-learning a risk measure for safe RL. Simulation experiments across 5\ncontinuous control domains suggest that MESA can leverage offline data from a\nrange of different environments to reduce constraint violations in unseen\nenvironments by up to a factor of 2 while maintaining task performance. See\nhttps://tinyurl.com/safe-meta-rl for code and supplementary material.",
    "descriptor": "",
    "authors": [
      "Michael Luo",
      "Ashwin Balakrishna",
      "Brijen Thananjeyan",
      "Suraj Nair",
      "Julian Ibarz",
      "Jie Tan",
      "Chelsea Finn",
      "Ion Stoica",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.03575"
  },
  {
    "id": "arXiv:2112.03577",
    "title": "Pragmatic Implementation of Reinforcement Algorithms For Path Finding On  Raspberry Pi",
    "abstract": "In this paper, pragmatic implementation of an indoor autonomous delivery\nsystem that exploits Reinforcement Learning algorithms for path planning and\ncollision avoidance is audited. The proposed system is a cost-efficient\napproach that is implemented to facilitate a Raspberry Pi controlled\nfour-wheel-drive non-holonomic robot map a grid. This approach computes and\nnavigates the shortest path from a source key point to a destination key point\nto carry out the desired delivery. Q learning and Deep-Q learning are used to\nfind the optimal path while avoiding collision with static obstacles. This work\ndefines an approach to deploy these two algorithms on a robot. A novel\nalgorithm to decode an array of directions into accurate movements in a certain\naction space is also proposed. The procedure followed to dispatch this system\nwith the said requirements is described, ergo presenting our proof of concept\nfor indoor autonomous delivery vehicles.",
    "descriptor": "\nComments: 5 pages, 7 figures\n",
    "authors": [
      "Serena Raju",
      "Sherin Shibu",
      "Riya Mol Raji",
      "Joel Thomas"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03577"
  },
  {
    "id": "arXiv:2112.03580",
    "title": "Disability and Library Services: Global Research Trend",
    "abstract": "The research on differently abled persons, and their use of library is\ngetting global attention in recent years. The field has shown a modest,\ncontinuous but wide-scale growth. This research paper aimed at capturing the\ndynamics of the field using various bibliometrics and text mining tools. The\nbibliographic data of journal articles published in the field were collected\nfrom the Web of Science (WoS) database. The records were collected form the\nyear 1991 to 2021 and analysed to observed the trends of literature growth,\ncore journals, institutes from where most of the literature is being published,\nprominent keywords and so on. The results show that there is a significant\ngrowth of publications since the year 2000. The trends shows that the research\nin these areas is mostly emerging from developed countries. The developing\ncountries should also pay more attention to do research in this area because\ndifferently abled peoples need in developed countries may vary with respect to\ndeveloped countries.",
    "descriptor": "",
    "authors": [
      "Swapan Kumar Patra"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.03580"
  },
  {
    "id": "arXiv:2112.03582",
    "title": "On a 2-relative entropy",
    "abstract": "We construct a 2-categorical extension of the relative entropy functor of\nBaez and Fritz, and show that our construction is functorial with respect to\nvertical morphisms. Moreover, we show such a `2-relative entropy' satisfies\nnatural 2-categorial analogues of convex linearity, vanishing under optimal\nhypotheses, and lower semicontinuity. While relative entropy is a relative\nmeasure of information between probability distributions, we view our\nconstruction as a relative measure of information between channels.",
    "descriptor": "\nComments: No figures (only diagrams)\n",
    "authors": [
      "James Fullwood"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2112.03582"
  },
  {
    "id": "arXiv:2112.03587",
    "title": "TCGL: Temporal Contrastive Graph for Self-supervised Video  Representation Learning",
    "abstract": "Video self-supervised learning is a challenging task, which requires\nsignificant expressive power from the model to leverage rich spatial-temporal\nknowledge and generate effective supervisory signals from large amounts of\nunlabeled videos. However, existing methods fail to increase the temporal\ndiversity of unlabeled videos and ignore elaborately modeling multi-scale\ntemporal dependencies in an explicit way. To overcome these limitations, we\ntake advantage of the multi-scale temporal dependencies within videos and\nproposes a novel video self-supervised learning framework named Temporal\nContrastive Graph Learning (TCGL), which jointly models the inter-snippet and\nintra-snippet temporal dependencies for temporal representation learning with a\nhybrid graph contrastive learning strategy. Specifically, a Spatial-Temporal\nKnowledge Discovering (STKD) module is first introduced to extract\nmotion-enhanced spatial-temporal representations from videos based on the\nfrequency domain analysis of discrete cosine transform. To explicitly model\nmulti-scale temporal dependencies of unlabeled videos, our TCGL integrates the\nprior knowledge about the frame and snippet orders into graph structures, i.e.,\nthe intra-/inter- snippet Temporal Contrastive Graphs (TCG). Then, specific\ncontrastive learning modules are designed to maximize the agreement between\nnodes in different graph views. To generate supervisory signals for unlabeled\nvideos, we introduce an Adaptive Snippet Order Prediction (ASOP) module which\nleverages the relational knowledge among video snippets to learn the global\ncontext representation and recalibrate the channel-wise features adaptively.\nExperimental results demonstrate the superiority of our TCGL over the\nstate-of-the-art methods on large-scale action recognition and video retrieval\nbenchmarks.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: substantial text overlap with arXiv:2101.00820\n",
    "authors": [
      "Yang Liu",
      "Keze Wang",
      "Lingbo Liu",
      "Haoyuan Lan",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03587"
  },
  {
    "id": "arXiv:2112.03588",
    "title": "A deep language model to predict metabolic network equilibria",
    "abstract": "We show that deep learning models, and especially architectures like the\nTransformer, originally intended for natural language, can be trained on\nrandomly generated datasets to predict to very high accuracy both the\nqualitative and quantitative features of metabolic networks. Using standard\nmathematical techniques, we create large sets (40 million elements) of random\nnetworks that can be used to train our models. These trained models can predict\nnetwork equilibrium on random graphs in more than 99% of cases. They can also\ngeneralize to graphs with different structure than those encountered at\ntraining. Finally, they can predict almost perfectly the equilibria of a small\nset of known biological networks. Our approach is both very economical in\nexperimental data and uses only small and shallow deep-learning model, far from\nthe large architectures commonly used in machine translation. Such results pave\nthe way for larger use of deep learning models for problems related to\nbiological networks in key areas such as quantitative systems pharmacology,\nsystems biology, and synthetic biology.",
    "descriptor": "",
    "authors": [
      "Fran\u00e7ois Charton",
      "Amaury Hayat",
      "Sean T. McQuade",
      "Nathaniel J. Merrill",
      "Benedetto Piccoli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03588"
  },
  {
    "id": "arXiv:2112.03590",
    "title": "Contrastive Learning from Extremely Augmented Skeleton Sequences for  Self-supervised Action Recognition",
    "abstract": "In recent years, self-supervised representation learning for skeleton-based\naction recognition has been developed with the advance of contrastive learning\nmethods. The existing contrastive learning methods use normal augmentations to\nconstruct similar positive samples, which limits the ability to explore novel\nmovement patterns. In this paper, to make better use of the movement patterns\nintroduced by extreme augmentations, a Contrastive Learning framework utilizing\nAbundant Information Mining for self-supervised action Representation (AimCLR)\nis proposed. First, the extreme augmentations and the Energy-based\nAttention-guided Drop Module (EADM) are proposed to obtain diverse positive\nsamples, which bring novel movement patterns to improve the universality of the\nlearned representations. Second, since directly using extreme augmentations may\nnot be able to boost the performance due to the drastic changes in original\nidentity, the Dual Distributional Divergence Minimization Loss (D$^3$M Loss) is\nproposed to minimize the distribution divergence in a more gentle way. Third,\nthe Nearest Neighbors Mining (NNM) is proposed to further expand positive\nsamples to make the abundant information mining process more reasonable.\nExhaustive experiments on NTU RGB+D 60, PKU-MMD, NTU RGB+D 120 datasets have\nverified that our AimCLR can significantly perform favorably against\nstate-of-the-art methods under a variety of evaluation protocols with observed\nhigher quality action representations. Our code is available at\nhttps://github.com/Levigty/AimCLR.",
    "descriptor": "\nComments: Accepted by AAAI2022\n",
    "authors": [
      "Tianyu Guo",
      "Hong Liu",
      "Zhan Chen",
      "Mengyuan Liu",
      "Tao Wang",
      "Runwei Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03590"
  },
  {
    "id": "arXiv:2112.03592",
    "title": "Parallel Discrete Convolutions on Adaptive Particle Representations of  Images",
    "abstract": "We present data structures and algorithms for native implementations of\ndiscrete convolution operators over Adaptive Particle Representations (APR) of\nimages on parallel computer architectures. The APR is a content-adaptive image\nrepresentation that locally adapts the sampling resolution to the image signal.\nIt has been developed as an alternative to pixel representations for large,\nsparse images as they typically occur in fluorescence microscopy. It has been\nshown to reduce the memory and runtime costs of storing, visualizing, and\nprocessing such images. This, however, requires that image processing natively\noperates on APRs, without intermediately reverting to pixels. Designing\nefficient and scalable APR-native image processing primitives, however, is\ncomplicated by the APR's irregular memory structure. Here, we provide the\nalgorithmic building blocks required to efficiently and natively process APR\nimages using a wide range of algorithms that can be formulated in terms of\ndiscrete convolutions. We show that APR convolution naturally leads to\nscale-adaptive algorithms that efficiently parallelize on multi-core CPU and\nGPU architectures. We quantify the speedups in comparison to pixel-based\nalgorithms and convolutions on evenly sampled data. We achieve pixel-equivalent\nthroughputs of up to 1 TB/s on a single Nvidia GeForce RTX 2080 gaming GPU,\nrequiring up to two orders of magnitude less memory than a pixel-based\nimplementation.",
    "descriptor": "\nComments: 18 pages, 13 figures\n",
    "authors": [
      "Joel Jonsson",
      "Bevan L. Cheeseman",
      "Suryanarayana Maddu",
      "Krzysztof Gonciarz",
      "Ivo F. Sbalzarini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Performance (cs.PF)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.03592"
  },
  {
    "id": "arXiv:2112.03595",
    "title": "State-of-the-art predictive and prescriptive analytics for IEEE CIS 3rd  Technical Challenge",
    "abstract": "In this paper, we describe our proposed methodology to approach the\npredict+optimise challenge introduced in the IEEE CIS 3rd Technical Challenge.\nThe predictive model employs an ensemble of LightGBM models and the\nprescriptive analysis employs mathematical optimisation to efficiently\nprescribe solutions that minimise the average cost over multiple scenarios. Our\nsolutions ranked 1st in the optimisation and 2nd in the prediction challenge of\nthe competition.",
    "descriptor": "",
    "authors": [
      "Mahdi Abolghasemi",
      "Rasul Esmaeilbeigi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03595"
  },
  {
    "id": "arXiv:2112.03596",
    "title": "E$^2$(GO)MOTION: Motion Augmented Event Stream for Egocentric Action  Recognition",
    "abstract": "Event cameras are novel bio-inspired sensors, which asynchronously capture\npixel-level intensity changes in the form of \"events\". Due to their sensing\nmechanism, event cameras have little to no motion blur, a very high temporal\nresolution and require significantly less power and memory than traditional\nframe-based cameras. These characteristics make them a perfect fit to several\nreal-world applications such as egocentric action recognition on wearable\ndevices, where fast camera motion and limited power challenge traditional\nvision sensors. However, the ever-growing field of event-based vision has, to\ndate, overlooked the potential of event cameras in such applications. In this\npaper, we show that event data is a very valuable modality for egocentric\naction recognition. To do so, we introduce N-EPIC-Kitchens, the first\nevent-based camera extension of the large-scale EPIC-Kitchens dataset. In this\ncontext, we propose two strategies: (i) directly processing event-camera data\nwith traditional video-processing architectures (E$^2$(GO)) and (ii) using\nevent-data to distill optical flow information (E$^2$(GO)MO). On our proposed\nbenchmark, we show that event data provides a comparable performance to RGB and\noptical flow, yet without any additional flow computation at deploy time, and\nan improved performance of up to 4% with respect to RGB only information.",
    "descriptor": "",
    "authors": [
      "Chiara Plizzari",
      "Mirco Planamente",
      "Gabriele Goletto",
      "Marco Cannici",
      "Emanuele Gusso",
      "Matteo Matteucci",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03596"
  },
  {
    "id": "arXiv:2112.03603",
    "title": "Handwritten Mathematical Expression Recognition via Attention  Aggregation based Bi-directional Mutual Learning",
    "abstract": "Handwritten mathematical expression recognition aims to automatically\ngenerate LaTeX sequences from given images. Currently, attention-based\nencoder-decoder models are widely used in this task. They typically generate\ntarget sequences in a left-to-right (L2R) manner, leaving the right-to-left\n(R2L) contexts unexploited. In this paper, we propose an Attention aggregation\nbased Bi-directional Mutual learning Network (ABM) which consists of one shared\nencoder and two parallel inverse decoders (L2R and R2L). The two decoders are\nenhanced via mutual distillation, which involves one-to-one knowledge transfer\nat each training step, making full use of the complementary information from\ntwo inverse directions. Moreover, in order to deal with mathematical symbols in\ndiverse scales, an Attention Aggregation Module (AAM) is proposed to\neffectively integrate multi-scale coverage attentions. Notably, in the\ninference phase, given that the model already learns knowledge from two inverse\ndirections, we only use the L2R branch for inference, keeping the original\nparameter size and inference speed. Extensive experiments demonstrate that our\nproposed approach achieves the recognition accuracy of 56.85 % on CROHME 2014,\n52.92 % on CROHME 2016, and 53.96 % on CROHME 2019 without data augmentation\nand model ensembling, substantially outperforming the state-of-the-art methods.\nThe source code is available in the supplementary materials.",
    "descriptor": "\nComments: 9 pages,5 figures, to be published in AAAI 2022\n",
    "authors": [
      "Xiaohang Bian",
      "Bo Qin",
      "Xiaozhe Xin",
      "Jianwu Li",
      "Xuefeng Su",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03603"
  },
  {
    "id": "arXiv:2112.03604",
    "title": "PRM path smoothening by circular arc fillet method for mobile robot  navigation",
    "abstract": "Motion planning and navigation, especially for mobile robots operating in\ncomplex navigational environments, has been a central problem since robotics\nstarted. A heuristic way to address it is the construction of a graph-based\nrepresentation (a path) capturing the connectivity of the configuration space.\nProbabilistic Roadmap is a commonly used method by the robotics community to\nbuild a path for navigational mobile robot path planning. In this study, path\nsmoothening by arc fillets is proposed for mobile robot path planning after\nobtaining the path from PRM in the presence of the obstacle. The proposed\nmethod runs in two steps; the first one is generating the shortest path between\nthe initial state to one of the goal states in the obstacle presence\nenvironment, wherein the PRM is used to construct a straight-lined path by\nconnecting the intermediate nodes. The second step is smoothening every corner\ncaused by node presence. Smoothening the corners with arc fillets ensures\nsmooth turns for the mobile robots. The suggested method has been simulated and\ntested with different PRM features. Experiment results show that the\nconstructed path is not just providing smooth turning; it is also shorter and\nquicker to finish for a robot while avoiding obstacles.",
    "descriptor": "\nComments: 22 pages, 18 figures, 6 tables\n",
    "authors": [
      "Meral K\u0131l\u0131\u00e7arslan Ouach",
      "Tolga Eren",
      "Evrencan \u00d6zcan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.03604"
  },
  {
    "id": "arXiv:2112.03605",
    "title": "Some Basic Techniques allowing Petri Net Synthesis: Complexity and  Algorithmic Issues",
    "abstract": "In Petri net synthesis we ask whether a given transition system $A$ can be\nimplemented by a Petri net $N$. Depending on the level of accuracy, there are\nthree ways how $N$ can implement $A$: an embedding, the least accurate\nimplementation, preserves only the diversity of states of $A$; a language\nsimulation already preserves exactly the language of $A$; a realization, the\nmost accurate implementation, realizes the behavior of $A$ exactly. However,\nwhatever the sought implementation, a corresponding net does not always exist.\nIn this case, it was suggested to modify the input behavior -- of course as\nlittle as possible. Since transition systems consist of states, events and\nedges, these components appear as a natural choice for modifications. In this\npaper we show that the task of converting an unimplementable transition system\ninto an implementable one by removing as few states or events or edges as\npossible is NP-complete -- regardless of what type of implementation we are\naiming for; we also show that the corresponding parameterized problems are\n$W[2]$-hard, where the number of removed components is considered as the\nparameter; finally, we show there is no $c$-approximation algorithm for neither\nof these problems, for every constant $c\\geq 1$.",
    "descriptor": "",
    "authors": [
      "Raymond Devillers",
      "Ronny Tredup"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2112.03605"
  },
  {
    "id": "arXiv:2112.03608",
    "title": "Synthesis of Pure and Impure Petri nets With Restricted  Place-environments: Complexity Issues",
    "abstract": "Petri net synthesis consists in deciding for a given transition system $A$\nwhether there exists a Petri net $N$ whose reachability graph is isomorphic to\n$A$. Several works examined the synthesis of Petri net subclasses that\nrestrict, for every place $p$ of the net, the cardinality of its preset or of\nits postset or both in advance by small natural numbers $\\varrho$ and $\\kappa$,\nrespectively, such as for example (weighted) marked graphs, (weighted)\nT-systems and choice-free nets. In this paper, we study the synthesis aiming at\nPetri nets which have such restricted place environments, from the viewpoint of\nclassical and parameterized complexity: We first show that, for any fixed\nnatural numbers $\\varrho$ and $\\kappa$, deciding whether for a given transition\nsystem $A$ there is a Petri net $N$ such that (1) its reachability graph is\nisomorphic to $A$ and (2) for every place $p$ of $N$ the preset of $p$ has at\nmost $\\varrho$ and the postset of $p$ has at most $\\kappa$ elements is doable\nin polynomial time. Secondly, we introduce a modified version of the problem,\nnamely Environment Restricted Synthesis (ERS, for short), where $\\varrho$ and\n$\\kappa$ are part of the input, and show that ERS is NP-complete, regardless\nwhether the sought net is impure or pure. In case of the impure nets, our\nmethods also imply that ERS parameterized by $\\varrho+\\kappa$ is $W[2]$-hard.",
    "descriptor": "",
    "authors": [
      "Raymond Devillers",
      "Ronny Tredup"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2112.03608"
  },
  {
    "id": "arXiv:2112.03609",
    "title": "Predict and Optimize: Through the Lens of Learning to Rank",
    "abstract": "In the last years predict-and-optimize approaches (Elmachtoub and Grigas\n2021; Wilder, Dilkina, and Tambe 2019) have received increasing attention.\nThese problems have the settings where the predictions of predictive machine\nlearning (ML) models are fed to downstream optimization problems for decision\nmaking. Predict-and-optimize approaches propose to train the ML models, often\nneural network models, by directly optimizing the quality of decisions made by\nthe optimization solvers. However, one major bottleneck of predict-and-optimize\napproaches is solving the optimization problem for each training instance at\nevery epoch. To address this challenge, Mulamba et al. (2021) propose noise\ncontrastive estimation by caching feasible solutions. In this work, we show the\nnoise contrastive estimation can be considered a case of learning to rank the\nsolution cache. We also develop pairwise and listwise ranking loss functions,\nwhich can be differentiated in closed form without the need of solving the\noptimization problem. By training with respect to these surrogate loss\nfunction, we empirically show that we are able to minimize the regret of the\npredictions.",
    "descriptor": "\nComments: Working paper\n",
    "authors": [
      "Jayanta Mandi",
      "V\u00edctor Bucarey",
      "Maxime Mulamba",
      "Tias Guns"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03609"
  },
  {
    "id": "arXiv:2112.03611",
    "title": "Hybrid Controlled User Association and Resource Management for  Energy-Efficient Green RANs with Limited Fronthaul",
    "abstract": "To alleviate green house effect, high network energy efficiency (EE) has\nincreasingly become an important research target in wireless green\ncommunications. Therefore, the investigation for resource management to\nmitigate the co-tier interference in the small cell network (SCN) is provided.\nMoreover, with the merits of cloud radio access network (C-RAN), small cell\nbase stations (SBSs) can be decomposed of a central small cell (CSC) and remote\nsmall cells (RSCs). To achieve the coordination, the split medium access\ncontrol (MAC) based functional splitting is adopted with scheduler deployed at\nCSCs and retransmission functions left at RSCs. However, limited fronthaul has\na compelling impact at RSCs due to requirements of user quality-of-service\n(QoS). Accordingly, a traffic control-based user association and resource\nallocation (TURA) scheme is proposed for a centralized resource management. To\ndeal with the infeasibility to control all RSCs by CSC, we propose a hybrid\ncontrolled user and resource management (HARM) scheme. A CSC performs TURA for\nRSCs to mitigate intra-group interference within localized C-RANs, whereas the\nCSCs among separate C-RANs conduct cooperative resource competition (CRC) game\nfor alleviating inter-group interference. Based on regret-based learning\nalgorithm, the proposed schemes are analytically proved to reach the correlated\nequilibrium (CE). Simulation results have validated the effect of traffic\ncontrol in TURA scheme and the convergence of CRC. Moreover, the comparison of\nthe proposed TURA, HARM, and CRC schemes with the benchmark is revealed. It is\nobserved that the TURA scheme outperforms the other schemes under ideal\nfronthaul control, whilst the proposed HARM scheme can sustain EE performance\nconsidering feasible implementation.",
    "descriptor": "",
    "authors": [
      "Li-Hsiang Shen",
      "Chia-Lin Tsai",
      "Chia-Yu Wang",
      "Kai-Ten Feng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03611"
  },
  {
    "id": "arXiv:2112.03612",
    "title": "DCAN: Improving Temporal Action Detection via Dual Context Aggregation",
    "abstract": "Temporal action detection aims to locate the boundaries of action in the\nvideo. The current method based on boundary matching enumerates and calculates\nall possible boundary matchings to generate proposals. However, these methods\nneglect the long-range context aggregation in boundary prediction. At the same\ntime, due to the similar semantics of adjacent matchings, local semantic\naggregation of densely-generated matchings cannot improve semantic richness and\ndiscrimination. In this paper, we propose the end-to-end proposal generation\nmethod named Dual Context Aggregation Network (DCAN) to aggregate context on\ntwo levels, namely, boundary level and proposal level, for generating\nhigh-quality action proposals, thereby improving the performance of temporal\naction detection. Specifically, we design the Multi-Path Temporal Context\nAggregation (MTCA) to achieve smooth context aggregation on boundary level and\nprecise evaluation of boundaries. For matching evaluation, Coarse-to-fine\nMatching (CFM) is designed to aggregate context on the proposal level and\nrefine the matching map from coarse to fine. We conduct extensive experiments\non ActivityNet v1.3 and THUMOS-14. DCAN obtains an average mAP of 35.39% on\nActivityNet v1.3 and reaches mAP 54.14% at IoU@0.5 on THUMOS-14, which\ndemonstrates DCAN can generate high-quality proposals and achieve\nstate-of-the-art performance. We release the code at\nhttps://github.com/cg1177/DCAN.",
    "descriptor": "\nComments: AAAI 2022 camera ready version\n",
    "authors": [
      "Guo Chen",
      "Yin-Dong Zheng",
      "Limin Wang",
      "Tong Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03612"
  },
  {
    "id": "arXiv:2112.03615",
    "title": "Saliency Diversified Deep Ensemble for Robustness to Adversaries",
    "abstract": "Deep learning models have shown incredible performance on numerous image\nrecognition, classification, and reconstruction tasks. Although very appealing\nand valuable due to their predictive capabilities, one common threat remains\nchallenging to resolve. A specifically trained attacker can introduce malicious\ninput perturbations to fool the network, thus causing potentially harmful\nmispredictions. Moreover, these attacks can succeed when the adversary has full\naccess to the target model (white-box) and even when such access is limited\n(black-box setting). The ensemble of models can protect against such attacks\nbut might be brittle under shared vulnerabilities in its members (attack\ntransferability). To that end, this work proposes a novel diversity-promoting\nlearning approach for the deep ensembles. The idea is to promote saliency map\ndiversity (SMD) on ensemble members to prevent the attacker from targeting all\nensemble members at once by introducing an additional term in our learning\nobjective. During training, this helps us minimize the alignment between model\nsaliencies to reduce shared member vulnerabilities and, thus, increase ensemble\nrobustness to adversaries. We empirically show a reduced transferability\nbetween ensemble members and improved performance compared to the\nstate-of-the-art ensemble defense against medium and high strength white-box\nattacks. In addition, we demonstrate that our approach combined with existing\nmethods outperforms state-of-the-art ensemble algorithms for defense under\nwhite-box and black-box attacks.",
    "descriptor": "\nComments: Accepted to AAAI Workshop on Adversarial Machine Learning and Beyond 2022\n",
    "authors": [
      "Alex Bogun",
      "Dimche Kostadinov",
      "Damian Borth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03615"
  },
  {
    "id": "arXiv:2112.03616",
    "title": "Improved uniform error bounds on time-splitting methods for the  long-time dynamics of the Dirac equation with small potentials",
    "abstract": "We establish improved uniform error bounds on time-splitting methods for the\nlong-time dynamics of the Dirac equation with small electromagnetic potentials\ncharacterized by a dimensionless parameter $\\varepsilon\\in (0, 1]$ representing\nthe amplitude of the potentials. We begin with a semi-discritization of the\nDirac equation in time by a time-splitting method, and then followed by a\nfull-discretization in space by the Fourier pseudospectral method. Employing\nthe unitary flow property of the second-order time-splitting method for the\nDirac equation, we prove uniform error bounds at $C(t)\\tau^2$ and\n$C(t)(h^m+\\tau^2)$ for the semi-discretization and full-discretization,\nrespectively, for any time $t\\in[0,T_\\varepsilon]$ with $T_\\varepsilon =\nT/\\varepsilon$ for $T > 0$, which are uniformly for $\\varepsilon \\in (0, 1]$,\nwhere $\\tau$ is the time step, $h$ is the mesh size, $m\\geq 2$ depends on the\nregularity of the solution, and $C(t) = C_0 + C_1\\varepsilon t\\le C_0+C_1T$\ngrows at most linearly with respect to $t$ with $C_0\\ge0$ and $C_1>0$ two\nconstants independent of $t$, $h$, $\\tau$ and $\\varepsilon$. Then by adopting\nthe regularity compensation oscillation (RCO) technique which controls the high\nfrequency modes by the regularity of the solution and low frequency modes by\nphase cancellation and energy method, we establish improved uniform error\nbounds at $O(\\varepsilon\\tau^2)$ and $O(h^m +\\varepsilon\\tau^2)$ for the\nsemi-discretization and full-discretization, respectively, up to the long-time\n$T_\\varepsilon$. Numerical results are reported to confirm our error bounds and\nto demonstrate that they are sharp. Comparisons on the accuracy of different\ntime discretizations for the Dirac equation are also provided.",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Weizhu Bao",
      "Yue Feng",
      "Jia Yin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.03616"
  },
  {
    "id": "arXiv:2112.03619",
    "title": "IntelliTC: Automating Type Changes in IntelliJ IDEA",
    "abstract": "Developers often change the types of program elements. Such a refactoring\nfrequently involves updating not only the type of the element itself, but also\nthe API of all type-dependent references in the code, thus it is tedious and\ntime-consuming. Despite type changes being more frequent than renamings, just a\nfew current IDE tools provide partially-automated support only for a small set\nof hard-coded types. Researchers have recently proposed a data-driven approach\nto inferring API rewrite rules for type change patterns in Java using code\ncommits history. In this paper, we build upon these recent advances and\nintroduce IntelliTC - a tool to perform Java type change refactoring. We\nimplemented it as a plugin for IntelliJ IDEA, a popular Java IDE developed by\nJetBrains. We present 3 different ways of providing support for such a\nrefactoring from the standpoint of the user experience: Classic mode, Suggested\nRefactoring, and Inspection mode. To evaluate these modalities of using\nIntelliTC, we surveyed 15 experienced software developers. They positively\nrated the usefulness of the tool.\nThe source code and distribution of the plugin are available on GitHub:\nhttps://github.com/JetBrains-Research/data-driven-type-migration. A\ndemonstration video is on YouTube: https://youtu.be/pdcfvADA1PY.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Oleg Smirnov",
      "Ameya Ketkar",
      "Timofey Bryksin",
      "Nikolaos Tsantalis",
      "Danny Dig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.03619"
  },
  {
    "id": "arXiv:2112.03621",
    "title": "Permutation Equivariant Generative Adversarial Networks for Graphs",
    "abstract": "One of the most discussed issues in graph generative modeling is the ordering\nof the representation. One solution consists of using equivariant generative\nfunctions, which ensure the ordering invariance. After having discussed some\nproperties of such functions, we propose 3G-GAN, a 3-stages model relying on\nGANs and equivariant functions. The model is still under development. However,\nwe present some encouraging exploratory experiments and discuss the issues\nstill to be addressed.",
    "descriptor": "\nComments: ELLIS Machine Learning for Molecule Discovery Workshop. 5 pages + ref. + appendix\n",
    "authors": [
      "Yoann Boget",
      "Magda Gregorova",
      "Alexandros Kalousis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03621"
  },
  {
    "id": "arXiv:2112.03624",
    "title": "Time-Equivariant Contrastive Video Representation Learning",
    "abstract": "We introduce a novel self-supervised contrastive learning method to learn\nrepresentations from unlabelled videos. Existing approaches ignore the\nspecifics of input distortions, e.g., by learning invariance to temporal\ntransformations. Instead, we argue that video representation should preserve\nvideo dynamics and reflect temporal manipulations of the input. Therefore, we\nexploit novel constraints to build representations that are equivariant to\ntemporal transformations and better capture video dynamics. In our method,\nrelative temporal transformations between augmented clips of a video are\nencoded in a vector and contrasted with other transformation vectors. To\nsupport temporal equivariance learning, we additionally propose the\nself-supervised classification of two clips of a video into 1. overlapping 2.\nordered, or 3. unordered. Our experiments show that time-equivariant\nrepresentations achieve state-of-the-art results in video retrieval and action\nrecognition benchmarks on UCF101, HMDB51, and Diving48.",
    "descriptor": "\nComments: ICCV 2021 (oral)\n",
    "authors": [
      "Simon Jenni",
      "Hailin Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03624"
  },
  {
    "id": "arXiv:2112.03625",
    "title": "Parsing with Pretrained Language Models, Multiple Datasets, and Dataset  Embeddings",
    "abstract": "With an increase of dataset availability, the potential for learning from a\nvariety of data sources has increased. One particular method to improve\nlearning from multiple data sources is to embed the data source during\ntraining. This allows the model to learn generalizable features as well as\ndistinguishing features between datasets. However, these dataset embeddings\nhave mostly been used before contextualized transformer-based embeddings were\nintroduced in the field of Natural Language Processing. In this work, we\ncompare two methods to embed datasets in a transformer-based multilingual\ndependency parser, and perform an extensive evaluation. We show that: 1)\nembedding the dataset is still beneficial with these models 2) performance\nincreases are highest when embedding the dataset at the encoder level 3)\nunsurprisingly, we confirm that performance increases are highest for small\ndatasets and datasets with a low baseline score. 4) we show that training on\nthe combination of all datasets performs similarly to designing smaller\nclusters based on language-relatedness.",
    "descriptor": "\nComments: Accepted to TLT at SyntaxFest 2021\n",
    "authors": [
      "Rob van der Goot",
      "Miryam de Lhoneux"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03625"
  },
  {
    "id": "arXiv:2112.03631",
    "title": "SSAT: A Symmetric Semantic-Aware Transformer Network for Makeup Transfer  and Removal",
    "abstract": "Makeup transfer is not only to extract the makeup style of the reference\nimage, but also to render the makeup style to the semantic corresponding\nposition of the target image. However, most existing methods focus on the\nformer and ignore the latter, resulting in a failure to achieve desired\nresults. To solve the above problems, we propose a unified Symmetric\nSemantic-Aware Transformer (SSAT) network, which incorporates semantic\ncorrespondence learning to realize makeup transfer and removal simultaneously.\nIn SSAT, a novel Symmetric Semantic Corresponding Feature Transfer (SSCFT)\nmodule and a weakly supervised semantic loss are proposed to model and\nfacilitate the establishment of accurate semantic correspondence. In the\ngeneration process, the extracted makeup features are spatially distorted by\nSSCFT to achieve semantic alignment with the target image, then the distorted\nmakeup features are combined with unmodified makeup irrelevant features to\nproduce the final result. Experiments show that our method obtains more\nvisually accurate makeup transfer results, and user study in comparison with\nother state-of-the-art makeup transfer methods reflects the superiority of our\nmethod. Besides, we verify the robustness of the proposed method in the\ndifference of expression and pose, object occlusion scenes, and extend it to\nvideo makeup transfer. Code will be available at\nhttps://gitee.com/sunzhaoyang0304/ssat-msp.",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Zhaoyang Sun",
      "Yaxiong Chen",
      "Shengwu Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03631"
  },
  {
    "id": "arXiv:2112.03632",
    "title": "Generation of Non-Deterministic Synthetic Face Datasets Guided by  Identity Priors",
    "abstract": "Enabling highly secure applications (such as border crossing) with face\nrecognition requires extensive biometric performance tests through large scale\ndata. However, using real face images raises concerns about privacy as the laws\ndo not allow the images to be used for other purposes than originally intended.\nUsing representative and subsets of face data can also lead to unwanted\ndemographic biases and cause an imbalance in datasets. One possible solution to\novercome these issues is to replace real face images with synthetically\ngenerated samples. While generating synthetic images has benefited from recent\nadvancements in computer vision, generating multiple samples of the same\nsynthetic identity resembling real-world variations is still unaddressed, i.e.,\nmated samples. This work proposes a non-deterministic method for generating\nmated face images by exploiting the well-structured latent space of StyleGAN.\nMated samples are generated by manipulating latent vectors, and more precisely,\nwe exploit Principal Component Analysis (PCA) to define semantically meaningful\ndirections in the latent space and control the similarity between the original\nand the mated samples using a pre-trained face recognition system. We create a\nnew dataset of synthetic face images (SymFace) consisting of 77,034 samples\nincluding 25,919 synthetic IDs. Through our analysis using well-established\nface image quality metrics, we demonstrate the differences in the biometric\nquality of synthetic samples mimicking characteristics of real biometric data.\nThe analysis and results thereof indicate the use of synthetic samples created\nusing the proposed approach as a viable alternative to replacing real biometric\ndata.",
    "descriptor": "",
    "authors": [
      "Marcel Grimmer",
      "Haoyu Zhang",
      "Raghavendra Ramachandra",
      "Kiran Raja",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03632"
  },
  {
    "id": "arXiv:2112.03634",
    "title": "Change Summarization of Diachronic Scholarly Paper Collections by  Semantic Evolution Analysis",
    "abstract": "The amount of scholarly data has been increasing dramatically over the last\nyears. For newcomers to a particular science domain (e.g., IR, physics, NLP) it\nis often difficult to spot larger trends and to position the latest research in\nthe context of prior scientific achievements and breakthroughs. Similarly,\nresearchers in the history of science are interested in tools that allow them\nto analyze and visualize changes in particular scientific domains. Temporal\nsummarization and related methods should be then useful for making sense of\nlarge volumes of scientific discourse data aggregated over time. We demonstrate\na novel approach to analyze the collections of research papers published over\nlonger time periods to provide a high-level overview of important semantic\nchanges that occurred over the progress of time. Our approach is based on\ncomparing word semantic representations over time and aims to support users in\na better understanding of large domain-focused archives of scholarly\npublications. As an example dataset we use the ACL Anthology Reference Corpus\nthat spans from 1979 to 2015 and contains 22,878 scholarly articles.",
    "descriptor": "\nComments: 4 pages, JCDL-2021\n",
    "authors": [
      "Naman Paharia",
      "Muhammad Syafiq Mohd Pozi",
      "Adam Jatowt"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03634"
  },
  {
    "id": "arXiv:2112.03636",
    "title": "Godot Reinforcement Learning Agents",
    "abstract": "We present Godot Reinforcement Learning (RL) Agents, an open-source interface\nfor developing environments and agents in the Godot Game Engine. The Godot RL\nAgents interface allows the design, creation and learning of agent behaviors in\nchallenging 2D and 3D environments with various on-policy and off-policy Deep\nRL algorithms. We provide a standard Gym interface, with wrappers for learning\nin the Ray RLlib and Stable Baselines RL frameworks. This allows users access\nto over 20 state of the art on-policy, off-policy and multi-agent RL\nalgorithms. The framework is a versatile tool that allows researchers and game\ndesigners the ability to create environments with discrete, continuous and\nmixed action spaces. The interface is relatively performant, with 12k\ninteractions per second on a high end laptop computer, when parallized on 4 CPU\ncores. An overview video is available here: https://youtu.be/g1MlZSFqIj4",
    "descriptor": "",
    "authors": [
      "Edward Beeching",
      "Jilles Debangoye",
      "Olivier Simonin",
      "Christian Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03636"
  },
  {
    "id": "arXiv:2112.03638",
    "title": "Scaling Structured Inference with Randomization",
    "abstract": "The scale of the state space of discrete graphical models is crucial for\nmodel capacity in the era of deep learning. Existing dynamic programming (DP)\nbased inference typically works with a small number of states (usually less\nthan hundreds). In this work, we propose a family of randomized dynamic\nprogramming (RDP) algorithms for scaling structured models to tens of thousands\nof latent states. Our method is widely applicable to classical DP-based\ninference (partition, marginal, reparameterization, entropy, .etc) and\ndifferent graph structures (chains, trees, and more general hypergraphs). It is\nalso compatible with automatic differentiation so can be integrated with neural\nnetworks seamlessly and learned with gradient-based optimizers. Our core\ntechnique is randomization, which is to restrict and reweight DP on a small\nselected subset of nodes, leading to computation reduction by orders of\nmagnitudes. We further achieve low bias and variance with Rao-Blackwellization\nand importance sampling. Experiments on different inferences over different\ngraphs demonstrate the accuracy and efficiency of our methods. Furthermore,\nwhen using RDP to train a scaled structured VAE, it outperforms baselines in\nterms of test likelihood and successfully prevents posterior collapse.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Yao Fu",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Data Structures and Algorithms (cs.DS)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03638"
  },
  {
    "id": "arXiv:2112.03641",
    "title": "Gram-SLD: Automatic Self-labeling and Detection for Instance Objects",
    "abstract": "Instance object detection plays an important role in intelligent monitoring,\nvisual navigation, human-computer interaction, intelligent services and other\nfields. Inspired by the great success of Deep Convolutional Neural Network\n(DCNN), DCNN-based instance object detection has become a promising research\ntopic. To address the problem that DCNN always requires a large-scale annotated\ndataset to supervise its training while manual annotation is exhausting and\ntime-consuming, we propose a new framework based on co-training called Gram\nSelf-Labeling and Detection (Gram-SLD). The proposed Gram-SLD can automatically\nannotate a large amount of data with very limited manually labeled key data and\nachieve competitive performance. In our framework, gram loss is defined and\nused to construct two fully redundant and independent views and a key sample\nselection strategy along with an automatic annotating strategy that\ncomprehensively consider precision and recall are proposed to generate high\nquality pseudo-labels. Experiments on the public GMU Kitchen Dataset , Active\nVision Dataset and the self-made BHID-ITEM Datasetdemonstrate that, with only\n5% labeled training data, our Gram-SLD achieves competitive performance in\nobject detection (less than 2% mAP loss), compared with the fully supervised\nmethods. In practical applications with complex and changing environments, the\nproposed method can satisfy the real-time and accuracy requirements on instance\nobject detection.",
    "descriptor": "\nComments: 37 pages with 7 figures\n",
    "authors": [
      "Rui Wang",
      "Chengtun Wu",
      "Jiawen Xin",
      "Liang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03641"
  },
  {
    "id": "arXiv:2112.03644",
    "title": "CCasGNN: Collaborative Cascade Prediction Based on Graph Neural Networks",
    "abstract": "Cascade prediction aims at modeling information diffusion in the network.\nMost previous methods concentrate on mining either structural or sequential\nfeatures from the network and the propagation path. Recent efforts devoted to\ncombining network structure and sequence features by graph neural networks and\nrecurrent neural networks. Nevertheless, the limitation of spectral or spatial\nmethods restricts the improvement of prediction performance. Moreover,\nrecurrent neural networks are time-consuming and computation-expensive, which\ncauses the inefficiency of prediction. Here, we propose a novel method CCasGNN\nconsidering the individual profile, structural features, and sequence\ninformation. The method benefits from using a collaborative framework of GAT\nand GCN and stacking positional encoding into the layers of graph neural\nnetworks, which is different from all existing ones and demonstrates good\nperformance. The experiments conducted on two real-world datasets confirm that\nour method significantly improves the prediction accuracy compared to\nstate-of-the-art approaches. What's more, the ablation study investigates the\ncontribution of each component in our method.",
    "descriptor": "",
    "authors": [
      "Yansong Wang",
      "Xiaomeng Wang",
      "Tao Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.03644"
  },
  {
    "id": "arXiv:2112.03645",
    "title": "Soft Robots Modeling: a Literature Unwinding",
    "abstract": "The robotics community has seen an exponential growth in the level of\ncomplexity of the theoretical tools presented for the modeling of soft robotics\ndevices. Different solutions have been presented to overcome the difficulties\nrelated to the modeling of soft robots, often leveraging on other scientific\ndisciplines, such as continuum mechanics and computer graphics. These\ntheoretical foundations are often taken for granted and this lead to an\nintricate literature that, consequently, has never been the subject of a\ncomplete review. Withing this scenario, the objective of the presented paper is\ntwofold. The common theoretical roots that relate the different families of\nmodeling techniques are highlighted, employing a unifying language that ease\nthe analysis of their main connections and differences. Thus, the listing of\nthe approaches naturally follows and a complete, untangled, review of the main\nworks on the field is finally provided.",
    "descriptor": "",
    "authors": [
      "Costanza Armanini",
      "Conor Messer",
      "Anup Teejo Mathew",
      "Fr\u00e9d\u00e9ric Boyer",
      "Christian Duriez",
      "Federico Renda"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.03645"
  },
  {
    "id": "arXiv:2112.03649",
    "title": "Regularity Learning via Explicit Distribution Modeling for Skeletal  Video Anomaly Detection",
    "abstract": "Anomaly detection in surveillance videos is challenging and important for\nensuring public security. Different from pixel-based anomaly detection methods,\npose-based methods utilize highly-structured skeleton data, which decreases the\ncomputational burden and also avoids the negative impact of background noise.\nHowever, unlike pixel-based methods, which could directly exploit explicit\nmotion features such as optical flow, pose-based methods suffer from the lack\nof alternative dynamic representation. In this paper, a novel Motion Embedder\n(ME) is proposed to provide a pose motion representation from the probability\nperspective. Furthermore, a novel task-specific Spatial-Temporal Transformer\n(STT) is deployed for self-supervised pose sequence reconstruction. These two\nmodules are then integrated into a unified framework for pose regularity\nlearning, which is referred to as Motion Prior Regularity Learner (MoPRL).\nMoPRL achieves the state-of-the-art performance by an average improvement of\n4.7% AUC on several challenging datasets. Extensive experiments validate the\nversatility of each proposed module.",
    "descriptor": "",
    "authors": [
      "Shoubin Yu",
      "Zhongyin Zhao",
      "Haoshu Fang",
      "Andong Deng",
      "Haisheng Su",
      "Dongliang Wang",
      "Weihao Gan",
      "Cewu Lu",
      "Wei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03649"
  },
  {
    "id": "arXiv:2112.03650",
    "title": "Activation to Saliency: Forming High-Quality Labels for Unsupervised  Salient Object Detection",
    "abstract": "Unsupervised Salient Object Detection (USOD) is of paramount significance for\nboth industrial applications and downstream tasks. Existing deep-learning (DL)\nbased USOD methods utilize some low-quality saliency predictions extracted by\nseveral traditional SOD methods as saliency cues, which mainly capture some\nconspicuous regions in images. Furthermore, they refine these saliency cues\nwith the assistant of semantic information, which is obtained from some models\ntrained by supervised learning in other related vision tasks. In this work, we\npropose a two-stage Activation-to-Saliency (A2S) framework that effectively\ngenerates high-quality saliency cues and uses these cues to train a robust\nsaliency detector. More importantly, no human annotations are involved in our\nframework during the whole training process. In the first stage, we transform a\npretrained network (MoCo v2) to aggregate multi-level features to a single\nactivation map, where an Adaptive Decision Boundary (ADB) is proposed to assist\nthe training of the transformed network. To facilitate the generation of\nhigh-quality pseudo labels, we propose a loss function to enlarges the feature\ndistances between pixels and their means. In the second stage, an Online Label\nRectifying (OLR) strategy updates the pseudo labels during the training process\nto reduce the negative impact of distractors. In addition, we construct a\nlightweight saliency detector using two Residual Attention Modules (RAMs),\nwhich refine the high-level features using the complementary information in\nlow-level features, such as edges and colors. Extensive experiments on several\nSOD benchmarks prove that our framework reports significant performance\ncompared with existing USOD methods. Moreover, training our framework on 3000\nimages consumes about 1 hour, which is over 30x faster than previous\nstate-of-the-art methods.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Huajun Zhou",
      "Peijia Chen",
      "Lingxiao Yang",
      "Jianhuang Lai",
      "Xiaohua Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03650"
  },
  {
    "id": "arXiv:2112.03653",
    "title": "A Specification for Typed Template Haskell",
    "abstract": "Multi-stage programming is a proven technique that provides predictable\nperformance characteristics by controlling code generation. We propose a core\nsemantics for Typed Template Haskell, an extension of Haskell that supports\nmulti staged programming that interacts well with polymorphism and qualified\ntypes. Our semantics relates a declarative source language with qualified types\nto a core language based on the the polymorphic lambda calculus augmented with\nmulti-stage constructs.",
    "descriptor": "",
    "authors": [
      "Matthew Pickering",
      "Andres L\u00f6h",
      "Nicolas Wu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.03653"
  },
  {
    "id": "arXiv:2112.03654",
    "title": "Secure learning-based MPC via garbled circuit",
    "abstract": "Encrypted control seeks confidential controller evaluation in cloud-based or\nnetworked systems. Many existing approaches build on homomorphic encryption\n(HE) that allow simple mathematical operations to be carried out on encrypted\ndata. Unfortunately, HE is computationally demanding and many control laws (in\nparticular non-polynomial ones) cannot be efficiently implemented with this\ntechnology.\nWe show in this paper that secure two-party computation using garbled\ncircuits provides a powerful alternative to HE for encrypted control. More\nprecisely, we present a novel scheme that allows to efficiently implement\n(non-polynomial) max-out neural networks with one hidden layer in a secure\nfashion. These networks are of special interest for control since they allow,\nin principle, to exactly describe piecewise affine control laws resulting from,\ne.g., linear model predictive control (MPC). However, exact fits require\nhigh-dimensional preactivations of the neurons. Fortunately, we illustrate that\neven low-dimensional learning-based approximations are sufficiently accurate\nfor linear MPC. In addition, these approximations can be securely evaluated\nusing garbled circuit in less than 100~ms for our numerical example. Hence, our\napproach opens new opportunities for applying encrypted control.",
    "descriptor": "",
    "authors": [
      "K. Tjell",
      "N. Schl\u00fcter",
      "P. Binfet",
      "M. Schulze Darup"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03654"
  },
  {
    "id": "arXiv:2112.03656",
    "title": "Tighter bounds for reconstruction from $\u03b5$-samples",
    "abstract": "We show that reconstructing a curve in $\\mathbb{R}^d$ for $d\\geq 2$ from a\n$0.66$-sample is always possible using an algorithm similar to the classical\nNN-Crust algorithm. Previously, this was only known to be possible for\n$0.47$-samples in $\\mathbb{R}^2$ and $\\frac{1}{3}$-samples in $\\mathbb{R}^d$\nfor $d\\geq 3$. In addition, we show that there is not always a unique way to\nreconstruct a curve from a $0.72$-sample; this was previously only known for\n$1$-samples. We also extend this non-uniqueness result to hypersurfaces in all\nhigher dimensions.",
    "descriptor": "\nComments: 22 pages, 14 figures\n",
    "authors": [
      "H\u00e5vard Bakke Bjerkevik"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.03656"
  },
  {
    "id": "arXiv:2112.03659",
    "title": "BlockGC: A Joint Learning Framework for Account Identity Inference on  Blockchain with Graph Contrast",
    "abstract": "Blockchain technology has the characteristics of decentralization,\ntraceability and tamper proof, which creates a reliable decentralized\ntransaction mode, further accelerating the development of the blockchain\nplatforms. However, with the popularization of various financial applications,\nsecurity problems caused by blockchain digital assets, such as money\nlaundering, illegal fundraising and phishing fraud, are constantly on the rise.\nTherefore, financial security has become an important issue in the blockchain\necosystem, and identifying the types of accounts in blockchain (e.g. miners,\nphishing accounts, Ponzi contracts, etc.) is of great significance in risk\nassessment and market supervision. In this paper, we construct an account\ninteraction graph using raw blockchain data in a graph perspective, and\nproposes a joint learning framework for account identity inference on\nblockchain with graph contrast. We first capture transaction feature and\ncorrelation feature from interaction graph, and then perform sampling and data\naugmentation to generate multiple views for account subgraphs, finally jointly\ntrain the subgraph contrast and account classification task. Extensive\nexperiments on Ethereum datasets show that our method achieves significant\nadvantages in account identity inference task in terms of classification\nperformance, scalability and generalization.",
    "descriptor": "",
    "authors": [
      "Jiajun Zhou",
      "Chenkai Hu",
      "Shenbo Gong",
      "Jiaying Xu",
      "Jie Shen",
      "Qi Xuan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.03659"
  },
  {
    "id": "arXiv:2112.03662",
    "title": "Lightning: Striking the Secure Isolation on GPU Clouds with Transient  Hardware Faults",
    "abstract": "GPU clouds have become a popular computing platform because of the cost of\nowning and maintaining high-performance computing clusters. Many cloud\narchitectures have also been proposed to ensure a secure execution environment\nfor guest applications by enforcing strong security policies to isolate the\nuntrusted hypervisor from the guest virtual machines (VMs). In this paper, we\nstudy the impact of GPU chip's hardware faults on the security of cloud\n\"trusted\" execution environment using Deep Neural Network (DNN) as the\nunderlying application. We show that transient hardware faults of GPUs can be\ngenerated by exploiting the Dynamic Voltage and Frequency Scaling (DVFS)\ntechnology, and these faults may cause computation errors, but they have\nlimited impact on the inference accuracy of DNN due to the robustness and\nfault-tolerant nature of well-developed DNN models. To take full advantage of\nthese transient hardware faults, we propose the Lightning attack to locate the\nfault injection targets of DNNs and to control the fault injection precision in\nterms of timing and position. We conduct experiments on three commodity GPUs to\nattack four widely-used DNNs. Experimental results show that the proposed\nattack can reduce the inference accuracy of the models by as high as 78.3\\% and\n64.5\\% on average. More importantly, 67.9\\% of the targeted attacks have\nsuccessfully misled the models to give our desired incorrect inference result.\nThis demonstrates that the secure isolation on GPU clouds is vulnerable against\ntransient hardware faults and the computation results may not be trusted.",
    "descriptor": "",
    "authors": [
      "Rihui Sun",
      "Pefei Qiu",
      "Yongqiang Lyu",
      "Donsheng Wang",
      "Jiang Dong",
      "Gang Qu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.03662"
  },
  {
    "id": "arXiv:2112.03665",
    "title": "Data-Driven Controllability Analysis and Stabilization for Linear  Descriptor Systems",
    "abstract": "For a parameter-unknown linear discrete-time descriptor system, three\nimplementable experiments are devised and corresponding data are collected in\nthis paper. Then data-based conditions are given to identify the system's type\nand controllability. Since many data-driven control methods assume that the\ninvestigated system is a controllable normal system, this work will verify the\nassumption and guarantee that those methods will not be misused. Furthermore,\nif it is a descriptor system, inspired by the equivalent stabilizability\nbetween a nominal descriptor system and its slow subsystem, a data-based\ndecomposing method is proposed to transfer the nominal system into its\nslow-fast subsystems' form. Then a state feedback controller for the slow\nsubsystem is presented based on persistently exciting input and state\nsequences. In this way, the stability of the nominal descriptor system is also\nguaranteed. Compared with other related research, we do not require any\nconservative assumptions or prior knowledge about the system.",
    "descriptor": "",
    "authors": [
      "Jiabao He",
      "Feng Xu",
      "Xueqian Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03665"
  },
  {
    "id": "arXiv:2112.03667",
    "title": "Cross-domain User Preference Learning for Cold-start Recommendation",
    "abstract": "Cross-domain cold-start recommendation is an increasingly emerging issue for\nrecommender systems. Existing works mainly focus on solving either cross-domain\nuser recommendation or cold-start content recommendation. However, when a new\ndomain evolves at its early stage, it has potential users similar to the source\ndomain but with much fewer interactions. It is critical to learn a user's\npreference from the source domain and transfer it into the target domain,\nespecially on the newly arriving contents with limited user feedback. To bridge\nthis gap, we propose a self-trained Cross-dOmain User Preference LEarning\n(COUPLE) framework, targeting cold-start recommendation with various semantic\ntags, such as attributes of items or genres of videos. More specifically, we\nconsider three levels of preferences, including user history, user content and\nuser group to provide reliable recommendation. With user history represented by\na domain-aware sequential model, a frequency encoder is applied to the\nunderlying tags for user content preference learning. Then, a hierarchical\nmemory tree with orthogonal node representation is proposed to further\ngeneralize user group preference across domains. The whole framework updates in\na contrastive way with a First-In-First-Out (FIFO) queue to obtain more\ndistinctive representations. Extensive experiments on two datasets demonstrate\nthe efficiency of COUPLE in both user and content cold-start situations. By\ndeploying an online A/B test for a week, we show that the Click-Through-Rate\n(CTR) of COUPLE is superior to other baselines used on Taobao APP. Now the\nmethod is serving online for the cross-domain cold micro-video recommendation.",
    "descriptor": "",
    "authors": [
      "Huiling Zhou",
      "Jie Liu",
      "Zhikang Li",
      "Jin Yu",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03667"
  },
  {
    "id": "arXiv:2112.03669",
    "title": "On Information Processing Limitations In Humans and Machines",
    "abstract": "Information theory is concerned with the study of transmission, processing,\nextraction, and utilization of information. In its most abstract form,\ninformation is conceived as a means of resolving uncertainty. Shannon and\nWeaver (1949) were among the first to develop a conceptual framework for\ninformation theory. One of the key assumptions of the model is that uncertainty\nincreases linearly with the amount of complexity (in bit units) of information\ntransmitted or generated. A whole body of data from the cognitive neurosciences\nhas shown since that the time of human response or action increases in a\nsimilar fashion as a function of information complexity. This paper will\ndiscuss some of the implications of what is known about the limitations of\nhuman information processing for the development of reliable Artificial\nIntelligence. It is concluded that novel conceptual frameworks are needed to\ninspire future studies on this complex problem space.",
    "descriptor": "\nComments: 1st International Electronic Conference on Information IECI2021, online, December 2021\n",
    "authors": [
      "Birgitta Dresp-Langley"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.03669"
  },
  {
    "id": "arXiv:2112.03670",
    "title": "Hybrid Self-Attention NEAT: A novel evolutionary approach to improve the  NEAT algorithm",
    "abstract": "This article presents a \"Hybrid Self-Attention NEAT\" method to improve the\noriginal NeuroEvolution of Augmenting Topologies (NEAT) algorithm in\nhigh-dimensional inputs. Although the NEAT algorithm has shown a significant\nresult in different challenging tasks, as input representations are high\ndimensional, it cannot create a well-tuned network. Our study addresses this\nlimitation by using self-attention as an indirect encoding method to select the\nmost important parts of the input. In addition, we improve its overall\nperformance with the help of a hybrid method to evolve the final network\nweights. The main conclusion is that Hybrid Self- Attention NEAT can eliminate\nthe restriction of the original NEAT. The results indicate that in comparison\nwith evolutionary algorithms, our model can get comparable scores in Atari\ngames with raw pixels input with a much lower number of parameters.",
    "descriptor": "",
    "authors": [
      "Saman Khamesian",
      "Hamed Malek"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03670"
  },
  {
    "id": "arXiv:2112.03675",
    "title": "The VLSAT-3 Benchmark Suite",
    "abstract": "This report presents VLSAT-3 (an acronym for \"Very Large Boolean\nSATisfiability problems\"),the third part of a benchmark suite to be used in\nscientific experimentsand software competitions addressing SAT and SMT\n(Satisfiability Modulo Theories) solving issues.VLSAT-3 contains 1200\n(600~satisfiable and 600~unsatisfiable) quantifier-free first-order logic\nformulasof increasing complexity, proposed in SMT-LIB format under a permissive\nCreative Commons license.More than 90% of these benchmarks have been used\nduring the 16th International Satisfiability Modulo TheoriesCompetition\n(SMT-COMP~2021).",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2011.11049, arXiv:2110.06336\n",
    "authors": [
      "Pierre Bouvier"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2112.03675"
  },
  {
    "id": "arXiv:2112.03676",
    "title": "Domain Generalization via Progressive Layer-wise and Channel-wise  Dropout",
    "abstract": "By training a model on multiple observed source domains, domain\ngeneralization aims to generalize well to arbitrary unseen target domains\nwithout further training. Existing works mainly focus on learning\ndomain-invariant features to improve the generalization ability. However, since\ntarget domain is not available during training, previous methods inevitably\nsuffer from overfitting in source domains. To tackle this issue, we develop an\neffective dropout-based framework to enlarge the region of the model's\nattention, which can effectively mitigate the overfitting problem.\nParticularly, different from the typical dropout scheme, which normally\nconducts the dropout on the fixed layer, first, we randomly select one layer,\nand then we randomly select its channels to conduct dropout. Besides, we\nleverage the progressive scheme to add the ratio of the dropout during\ntraining, which can gradually boost the difficulty of training model to enhance\nthe robustness of the model. Moreover, to further alleviate the impact of the\noverfitting issue, we leverage the augmentation schemes on image-level and\nfeature-level to yield a strong baseline model. We conduct extensive\nexperiments on multiple benchmark datasets, which show our method can\noutperform the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Jintao Guo",
      "Lei Qi",
      "Yinghuan Shi",
      "Yang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03676"
  },
  {
    "id": "arXiv:2112.03677",
    "title": "On Baker-Gill-Solovay Oracle Turing Machines and Relativization Barrier",
    "abstract": "This work analysis the so-called \"Relativization Barrier\" with respect to\nBaker-Gill-Solovay oracle Turing machine. We show that the diagonalization\ntechnique is a valid mathematical proof method, but it has some prerequisites\nwhen referring to \"Relativization barrier\".",
    "descriptor": "\nComments: To overcome the so-called \"Relativization barrier\". 6 pages, feedbacks are welcome\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.03677"
  },
  {
    "id": "arXiv:2112.03678",
    "title": "Does Proprietary Software Still Offer Protection of Intellectual  Property in the Age of Machine Learning? -- A Case Study using Dual Energy CT  Data",
    "abstract": "In the domain of medical image processing, medical device manufacturers\nprotect their intellectual property in many cases by shipping only compiled\nsoftware, i.e. binary code which can be executed but is difficult to be\nunderstood by a potential attacker. In this paper, we investigate how well this\nprocedure is able to protect image processing algorithms. In particular, we\ninvestigate whether the computation of mono-energetic images and iodine maps\nfrom dual energy CT data can be reverse-engineered by machine learning methods.\nOur results indicate that both can be approximated using only one single slice\nimage as training data at a very high accuracy with structural similarity\ngreater than 0.98 in all investigated cases.",
    "descriptor": "\nComments: 6 pages, 2 figures, 1 table, accepted on BVM 2022\n",
    "authors": [
      "Andreas Maier",
      "Seung Hee Yang",
      "Farhad Maleki",
      "Nikesh Muthukrishnan",
      "Reza Forghani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.03678"
  },
  {
    "id": "arXiv:2112.03683",
    "title": "In-Network Processing for Low-Latency Industrial Anomaly Detection in  Softwarized Networks",
    "abstract": "Modern manufacturers are currently undertaking the integration of novel\ndigital technologies - such as 5G-based wireless networks, the Internet of\nThings (IoT), and cloud computing - to elevate their production process to a\nbrand new level, the level of smart factories. In the setting of a modern smart\nfactory, time-critical applications are increasingly important to facilitate\nefficient and safe production. However, these applications suffer from delays\nin data transmission and processing due to the high density of wireless sensors\nand the large volumes of data that they generate. As the advent of\nnext-generation networks has made network nodes intelligent and capable of\nhandling multiple network functions, the increased computational power of the\nnodes makes it possible to offload some of the computational overhead. In this\npaper, we show for the first time our IA-Net-Lite industrial anomaly detection\nsystem with the novel capability of in-network data processing. IA-Net-Lite\nutilizes intelligent network devices to combine data transmission and\nprocessing, as well as to progressively filter redundant data in order to\noptimize service latency. By testing in a practical network emulator, we showed\nthat the proposed approach can reduce the service latency by up to 40%.\nMoreover, the benefits of our approach could potentially be exploited in other\nlarge-volume and artificial intelligence applications.",
    "descriptor": "",
    "authors": [
      "Huanzhuo Wu",
      "Jia He",
      "M\u00e1t\u00e9 T\u00f6m\u00f6sk\u00f6zi",
      "Zuo Xiang",
      "Frank H.P. Fitzek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.03683"
  },
  {
    "id": "arXiv:2112.03685",
    "title": "A low-cost wave-solar powered Unmanned Surface Vehicle",
    "abstract": "This paper presents a prototype of a low-cost Unmanned Surface Vehicle (USV)\nthat is operated by wave and solar energy which can be used to minimize the\ncost of ocean data collection. The current prototype is a compact USV, with a\nlength of 1.2m that can be deployed and recovered by two persons. The design\nincludes an electrically operated winch that can be used to retract and lower\nthe underwater unit. Several elements of the design make use of additive\nmanufacturing and inexpensive materials. The vehicle can be controlled using\nradio frequency (RF) and a satellite communication, through a custom developed\nweb application. Both the surface and underwater units were optimized with\nregard to drag, lift, weight, and price by using recommendation of previous\nresearch work and advanced materials. The USV could be used in water condition\nmonitoring by measuring several parameters, such as dissolved oxygen, salinity,\ntemperature, and pH.",
    "descriptor": "",
    "authors": [
      "Moustafa Elkolali",
      "Ahmed Al-Tawil",
      "Lennard Much",
      "Ryan Schrader",
      "Olivier Masset",
      "Marina Sayols",
      "Andrew Jenkins",
      "Sara Alonso",
      "Alfredo Carella",
      "Alex Alcocer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.03685"
  },
  {
    "id": "arXiv:2112.03690",
    "title": "Low-rank Tensor Decomposition for Compression of Convolutional Neural  Networks Using Funnel Regularization",
    "abstract": "Tensor decomposition is one of the fundamental technique for model\ncompression of deep convolution neural networks owing to its ability to reveal\nthe latent relations among complex structures. However, most existing methods\ncompress the networks layer by layer, which cannot provide a satisfactory\nsolution to achieve global optimization. In this paper, we proposed a model\nreduction method to compress the pre-trained networks using low-rank tensor\ndecomposition of the convolution layers. Our method is based on the\noptimization techniques to select the proper ranks of decomposed network\nlayers. A new regularization method, called funnel function, is proposed to\nsuppress the unimportant factors during the compression, so the proper ranks\ncan be revealed much easier. The experimental results show that our algorithm\ncan reduce more model parameters than other tensor compression methods. For\nResNet18 with ImageNet2012, our reduced model can reach more than twi times\nspeed up in terms of GMAC with merely 0.7% Top-1 accuracy drop, which\noutperforms most existing methods in both metrics.",
    "descriptor": "",
    "authors": [
      "Bo-Shiuan Chu",
      "Che-Rung Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.03690"
  },
  {
    "id": "arXiv:2112.03692",
    "title": "Blockchain Synchronous Trust Consensus Model",
    "abstract": "This work introduces a novel approach for the governance of a blockchain\ncontaining social constructs and technical viability for widescale applications\nfor the next generation of distributed ledgers. Functional requirements for\nthis new blockchain distributed ledger (BDL) were garnered from an analysis of\nthe needs for large-scale applications. Applied research was employed as part\nof this endeavor to test the practicality and scalability of the solution\noutline. Novel features in this application draw together controls and\nenforcement for cybersecurity, digital content management, licensing, and\nconfiguration management. The Synchronous Trust Consensus Model applied\nresearch project named Project Philos was sponsored by the BlockChain\nDevelopment Community (BCDC) with support from the University of Colorado.\nResearch has followed both theorized conceptual and theory-to-practice models\nto prove the scientific soundness and the viability of incentive for community\nengagement. Results show that this new model proves the feasibility of an\nindefinitely expandable blockchain distributed ledger capability, while also\nproviding a new participant incentive that is highly effective in engaging a\ncommunity of practitioners.",
    "descriptor": "\nComments: Publication TBD\n",
    "authors": [
      "Christopher Gorog",
      "Terrance E. Boult"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.03692"
  },
  {
    "id": "arXiv:2112.03695",
    "title": "Safe Distillation Box",
    "abstract": "Knowledge distillation (KD) has recently emerged as a powerful strategy to\ntransfer knowledge from a pre-trained teacher model to a lightweight student,\nand has demonstrated its unprecedented success over a wide spectrum of\napplications. In spite of the encouraging results, the KD process per se poses\na potential threat to network ownership protection, since the knowledge\ncontained in network can be effortlessly distilled and hence exposed to a\nmalicious user. In this paper, we propose a novel framework, termed as Safe\nDistillation Box (SDB), that allows us to wrap a pre-trained model in a virtual\nbox for intellectual property protection. Specifically, SDB preserves the\ninference capability of the wrapped model to all users, but precludes KD from\nunauthorized users. For authorized users, on the other hand, SDB carries out a\nknowledge augmentation scheme to strengthen the KD performances and the results\nof the student model. In other words, all users may employ a model in SDB for\ninference, but only authorized users get access to KD from the model. The\nproposed SDB imposes no constraints over the model architecture, and may\nreadily serve as a plug-and-play solution to protect the ownership of a\npre-trained network. Experiments across various datasets and architectures\ndemonstrate that, with SDB, the performance of an unauthorized KD drops\nsignificantly while that of an authorized gets enhanced, demonstrating the\neffectiveness of SDB.",
    "descriptor": "\nComments: Accepted by AAAI2022\n",
    "authors": [
      "Jingwen Ye",
      "Yining Mao",
      "Jie Song",
      "Xinchao Wang",
      "Cheng Jin",
      "Mingli Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03695"
  },
  {
    "id": "arXiv:2112.03703",
    "title": "Construction de variables \u00e0 l'aide de classifieurs comme aide \u00e0 la  r\u00e9gression",
    "abstract": "This paper proposes a method for the automatic creation of variables (in the\ncase of regression) that complement the information contained in the initial\ninput vector. The method works as a pre-processing step in which the continuous\nvalues of the variable to be regressed are discretized into a set of intervals\nwhich are then used to define value thresholds. Then classifiers are trained to\npredict whether the value to be regressed is less than or equal to each of\nthese thresholds. The different outputs of the classifiers are then\nconcatenated in the form of an additional vector of variables that enriches the\ninitial vector of the regression problem. The implemented system can thus be\nconsidered as a generic pre-processing tool. We tested the proposed enrichment\nmethod with 5 types of regressors and evaluated it in 33 regression datasets.\nOur experimental results confirm the interest of the approach.",
    "descriptor": "\nComments: in French\n",
    "authors": [
      "Colin Troisemaine",
      "Vincent Lemaire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03703"
  },
  {
    "id": "arXiv:2112.03704",
    "title": "Two-stage Deep Stacked Autoencoder with Shallow Learning for Network  Intrusion Detection System",
    "abstract": "Sparse events, such as malign attacks in real-time network traffic, have\ncaused big organisations an immense hike in revenue loss. This is due to the\nexcessive growth of the network and its exposure to a plethora of people. The\nstandard methods used to detect intrusions are not promising and have\nsignificant failure to identify new malware. Moreover, the challenges in\nhandling high volume data with sparsity, high false positives, fewer detection\nrates in minor class, training time and feature engineering of the\ndimensionality of data has promoted deep learning to take over the task with\nless time and great results. The existing system needs improvement in solving\nreal-time network traffic issues along with feature engineering. Our proposed\nwork overcomes these challenges by giving promising results using deep-stacked\nautoencoders in two stages. The two-stage deep learning combines with shallow\nlearning using the random forest for classification in the second stage. This\nmade the model get well with the latest Canadian Institute for Cybersecurity -\nIntrusion Detection System 2017 (CICIDS-2017) dataset. Zero false positives\nwith admirable detection accuracy were achieved.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Nasreen Fathima",
      "Akshara Pramod",
      "Yash Srivastava",
      "Anusha Maria Thomas",
      "Syed Ibrahim S P",
      "Chandran K R"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03704"
  },
  {
    "id": "arXiv:2112.03705",
    "title": "Correlation Based Feature Subset Selection for Multivariate Time-Series  Data",
    "abstract": "Correlations in streams of multivariate time series data means that\ntypically, only a small subset of the features are required for a given data\nmining task. In this paper, we propose a technique which we call Merit Score\nfor Time-Series data (MSTS) that does feature subset selection based on the\ncorrelation patterns of single feature classifier outputs. We assign a Merit\nScore to the feature subsets which is used as the basis for selecting 'good'\nfeature subsets. The proposed technique is evaluated on datasets from the UEA\nmultivariate time series archive and is compared against a Wrapper approach for\nfeature subset selection. MSTS is shown to be effective for feature subset\nselection and is in particular effective as a data reduction technique. MSTS is\nshown here to be computationally more efficient than the Wrapper strategy in\nselecting a suitable feature subset, being more than 100 times faster for some\nlarger datasets while also maintaining a good classification accuracy.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Bahavathy Kathirgamanathan",
      "Padraig Cunningham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03705"
  },
  {
    "id": "arXiv:2112.03710",
    "title": "CapsProm: A Capsule Network For Promoter Prediction",
    "abstract": "Locating the promoter region in DNA sequences is of paramount importance in\nthe field of bioinformatics. This is a problem widely studied in the\nliterature, however, not yet fully resolved. Some researchers have presented\nremarkable results using convolution networks, that allowed the automatic\nextraction of features from a DNA chain. However, a universal architecture that\ncould generalize to several organisms has not yet been achieved, and thus,\nrequiring researchers to seek new architectures and hyperparameters for each\nnew organism evaluated. In this work, we propose a versatile architecture,\nbased on capsule network, that can accurately identify promoter sequences in\nraw DNA data from seven different organisms, eukaryotic, and prokaryotic. Our\nmodel, the CapsProm, could assist in the transfer of learning between organisms\nand expand its applicability. Furthermore the CapsProm showed competitive\nresults, overcoming the baseline method in five out of seven of the tested\ndatasets (F1-score). The models and source code are made available at\nhttps://github.com/lauromoraes/CapsNet-promoter.",
    "descriptor": "",
    "authors": [
      "Lauro Moraes",
      "Pedro Silva",
      "Eduardo Luz",
      "Gladston Moreira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03710"
  },
  {
    "id": "arXiv:2112.03715",
    "title": "Enhancing the SVD Compression",
    "abstract": "Orthonormality is the foundation of matrix decomposition. For example,\nSingular Value Decomposition (SVD) implements the compression by factoring a\nmatrix with orthonormal parts and is pervasively utilized in various fields.\nOrthonormality, however, inherently includes constraints that would induce\nredundant degrees of freedom, preventing SVD from deeper compression and even\nmaking it frustrated as the data fidelity is strictly required. In this paper,\nwe theoretically prove that these redundancies resulted by orthonormality can\nbe completely eliminated in a lossless manner. An enhanced version of SVD,\nnamely E-SVD, is accordingly established to losslessly and quickly release\nconstraints and recover the orthonormal parts in SVD by avoiding multiple\nmatrix multiplications. According to the theory, advantages of E-SVD over SVD\nbecome increasingly evident with the rising requirement of data fidelity. In\nparticular, E-SVD will reduce 25% storage units as SVD reaches its limitation\nand fails to compress data. Empirical evidences from typical scenarios of\nremote sensing and Internet of things further justify our theory and\nconsistently demonstrate the superiority of E-SVD in compression. The presented\ntheory sheds insightful lights on the constraint solution in orthonormal\nmatrices and E-SVD, guaranteed by which will profoundly enhance the SVD-based\ncompression in the context of explosive growth in both data acquisition and\nfidelity levels.",
    "descriptor": "\nComments: The code can be accessed through this https URL\n",
    "authors": [
      "Huiwen Wang",
      "Yanwen Zhang",
      "Jichang Zhao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.03715"
  },
  {
    "id": "arXiv:2112.03719",
    "title": "GKS: Graph-based Knowledge Selector for Task-oriented Dialog System",
    "abstract": "In previous research, knowledge selection tasks mostly rely on language\nmodel-based methods or knowledge ranking. However, approaches simply rely on\nthe language model take all knowledge as sequential input that knowledge does\nnot contain sequential information in most circumstances. On the other hand,\nthe knowledge ranking method leverage dialog history and each given knowledge\nbut not between pieces of knowledge. In the 10th Dialog System Technology\nChallenges (DSTC 10), we participated the second track of Knowledge-grounded\nTask-oriented Dialogue Modeling on Spoken Conversations. To deal with the\nproblems mentioned above, we modified training methods based on SOTA models for\nthe first and third sub-tasks and proposed Graph-Knowledge Selector (GKS),\nutilizing a graph-attention base model incorporated with language model for\nknowledge selection sub-task two. GKS makes knowledge selection decisions in\nthe dialog by simultaneously considering each knowledge embedding generated\nfrom the language model, without sequential features. GKS also leverages\nconsiderable knowledge in the decision-making, takes relations across knowledge\nas a part of the selection process. GKS outperforms several SOTA models\nproposed in the data-set on knowledge selection from the 9th Dialog System\nTechnology Challenges (DSTC9).",
    "descriptor": "\nComments: Accepted to The Tenth Dialog System Technology Challenge workshop at Association for the Advancement of Artificial Intelligence (AAAI) 2022\n",
    "authors": [
      "Jen-Chieh Yang",
      "Jia-Yan Wu",
      "Sung-Ping Chang",
      "Ya-Chieh Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03719"
  },
  {
    "id": "arXiv:2112.03723",
    "title": "Shrub Ensembles for Online Classification",
    "abstract": "Online learning algorithms have become a ubiquitous tool in the machine\nlearning toolbox and are frequently used in small, resource-constraint\nenvironments. Among the most successful online learning methods are Decision\nTree (DT) ensembles. DT ensembles provide excellent performance while adapting\nto changes in the data, but they are not resource efficient. Incremental tree\nlearners keep adding new nodes to the tree but never remove old ones increasing\nthe memory consumption over time. Gradient-based tree learning, on the other\nhand, requires the computation of gradients over the entire tree which is\ncostly for even moderately sized trees. In this paper, we propose a novel\nmemory-efficient online classification ensemble called shrub ensembles for\nresource-constraint systems. Our algorithm trains small to medium-sized\ndecision trees on small windows and uses stochastic proximal gradient descent\nto learn the ensemble weights of these `shrubs'. We provide a theoretical\nanalysis of our algorithm and include an extensive discussion on the behavior\nof our approach in the online setting. In a series of 2~959 experiments on 12\ndifferent datasets, we compare our method against 8 state-of-the-art methods.\nOur Shrub Ensembles retain an excellent performance even when only little\nmemory is available. We show that SE offers a better accuracy-memory trade-off\nin 7 of 12 cases, while having a statistically significant better performance\nthan most other methods. Our implementation is available under\nhttps://github.com/sbuschjaeger/se-online .",
    "descriptor": "\nComments: 9 pages main content, 13 pages appendix, accepted at AAAI-2022\n",
    "authors": [
      "Sebastian Buschj\u00e4ger",
      "Sibylle Hess",
      "Katharina Morik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.03723"
  },
  {
    "id": "arXiv:2112.03727",
    "title": "RFGAN: RF-Based Human Synthesis",
    "abstract": "This paper demonstrates human synthesis based on the Radio Frequency (RF)\nsignals, which leverages the fact that RF signals can record human movements\nwith the signal reflections off the human body. Different from existing RF\nsensing works that can only perceive humans roughly, this paper aims to\ngenerate fine-grained optical human images by introducing a novel cross-modal\nRFGAN model. Specifically, we first build a radio system equipped with\nhorizontal and vertical antenna arrays to transceive RF signals. Since the\nreflected RF signals are processed as obscure signal projection heatmaps on the\nhorizontal and vertical planes, we design a RF-Extractor with RNN in RFGAN for\nRF heatmap encoding and combining to obtain the human activity information.\nThen we inject the information extracted by the RF-Extractor and RNN as the\ncondition into GAN using the proposed RF-based adaptive normalizations.\nFinally, we train the whole model in an end-to-end manner. To evaluate our\nproposed model, we create two cross-modal datasets (RF-Walk & RF-Activity) that\ncontain thousands of optical human activity frames and corresponding RF\nsignals. Experimental results show that the RFGAN can generate target human\nactivity frames using RF signals. To the best of our knowledge, this is the\nfirst work to generate optical images based on RF signals.",
    "descriptor": "",
    "authors": [
      "Cong Yu",
      "Zhi Wu",
      "Dongheng Zhang",
      "Zhi Lu",
      "Yang Hu",
      "Yan Chen"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03727"
  },
  {
    "id": "arXiv:2112.03728",
    "title": "Flexible Networks for Learning Physical Dynamics of Deformable Objects",
    "abstract": "Learning the physical dynamics of deformable objects with particle-based\nrepresentation has been the objective of many computational models in machine\nlearning. While several state-of-the-art models have achieved this objective in\nsimulated environments, most existing models impose a precondition, such that\nthe input is a sequence of ordered point sets - i.e., the order of the points\nin each point set must be the same across the entire input sequence. This\nrestrains the model to generalize to real-world data, which is considered to be\na sequence of unordered point sets. In this paper, we propose a model named\ntime-wise PointNet (TP-Net) that solves this problem by directly consuming a\nsequence of unordered point sets to infer the future state of a deformable\nobject with particle-based representation. Our model consists of a shared\nfeature extractor that extracts global features from each input point set in\nparallel and a prediction network that aggregates and reasons on these features\nfor future prediction. The key concept of our approach is that we use global\nfeatures rather than local features to achieve invariance to input permutations\nand ensure the stability and scalability of our model. Experiments demonstrate\nthat our model achieves state-of-the-art performance in both synthetic dataset\nand in real-world dataset, with real-time prediction speed. We provide\nquantitative and qualitative analysis on why our approach is more effective and\nefficient than existing approaches.",
    "descriptor": "",
    "authors": [
      "Jinhyung Park",
      "DoHae Lee",
      "In-Kwon Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03728"
  },
  {
    "id": "arXiv:2112.03731",
    "title": "SalFBNet: Learning Pseudo-Saliency Distribution via Feedback  Convolutional Networks",
    "abstract": "Feed-forward only convolutional neural networks (CNNs) may ignore intrinsic\nrelationships and potential benefits of feedback connections in vision tasks\nsuch as saliency detection, despite their significant representation\ncapabilities. In this work, we propose a feedback-recursive convolutional\nframework (SalFBNet) for saliency detection. The proposed feedback model can\nlearn abundant contextual representations by bridging a recursive pathway from\nhigher-level feature blocks to low-level layer. Moreover, we create a\nlarge-scale Pseudo-Saliency dataset to alleviate the problem of data deficiency\nin saliency detection. We first use the proposed feedback model to learn\nsaliency distribution from pseudo-ground-truth. Afterwards, we fine-tune the\nfeedback model on existing eye-fixation datasets. Furthermore, we present a\nnovel Selective Fixation and Non-Fixation Error (sFNE) loss to make proposed\nfeedback model better learn distinguishable eye-fixation-based features.\nExtensive experimental results show that our SalFBNet with fewer parameters\nachieves competitive results on the public saliency detection benchmarks, which\ndemonstrate the effectiveness of proposed feedback model and Pseudo-Saliency\ndata. Source codes and Pseudo-Saliency dataset can be found at\nhttps://github.com/gqding/SalFBNet",
    "descriptor": "",
    "authors": [
      "Guanqun Ding",
      "Nevrez Imamouglu",
      "Ali Caglayan",
      "Masahiro Murakawa",
      "Ryosuke Nakamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03731"
  },
  {
    "id": "arXiv:2112.03732",
    "title": "A coarse space acceleration of deep-DDM",
    "abstract": "The use of deep learning methods for solving PDEs is a field in full\nexpansion. In particular, Physical Informed Neural Networks, that implement a\nsampling of the physical domain and use a loss function that penalizes the\nviolation of the partial differential equation, have shown their great\npotential. Yet, to address large scale problems encountered in real\napplications and compete with existing numerical methods for PDEs, it is\nimportant to design parallel algorithms with good scalability properties. In\nthe vein of traditional domain decomposition methods (DDM), we consider the\nrecently proposed deep-ddm approach. We present an extension of this method\nthat relies on the use of a coarse space correction, similarly to what is done\nin traditional DDM solvers. Our investigations shows that the coarse correction\nis able to alleviate the deterioration of the convergence of the solver when\nthe number of subdomains is increased thanks to an instantaneous information\nexchange between subdomains at each iteration. Experimental results demonstrate\nthat our approach induces a remarkable acceleration of the original deep-ddm\nmethod, at a reduced additional computational cost.",
    "descriptor": "",
    "authors": [
      "Valentin Mercier",
      "Serge Gratton",
      "Pierre Boudier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03732"
  },
  {
    "id": "arXiv:2112.03734",
    "title": "Towards Modeling and Resolving Singular Parameter Spaces using  Stratifolds",
    "abstract": "When analyzing parametric statistical models, a useful approach consists in\nmodeling geometrically the parameter space. However, even for very simple and\ncommonly used hierarchical models like statistical mixtures or stochastic deep\nneural networks, the smoothness assumption of manifolds is violated at singular\npoints which exhibit non-smooth neighborhoods in the parameter space. These\nsingular models have been analyzed in the context of learning dynamics, where\nsingularities can act as attractors on the learning trajectory and, therefore,\nnegatively influence the convergence speed of models. We propose a general\napproach to circumvent the problem arising from singularities by using\nstratifolds, a concept from algebraic topology, to formally model singular\nparameter spaces. We use the property that specific stratifolds are equipped\nwith a resolution method to construct a smooth manifold approximation of the\nsingular space. We empirically show that using (natural) gradient descent on\nthe smooth manifold approximation instead of the singular space allows us to\navoid the attractor behavior and therefore improve the convergence speed in\nlearning.",
    "descriptor": "\nComments: A preliminary version of this work was presented at NeurIPS 2021 as a Spotlight in the 13th Annual Workshop on Optimization for Machine Learning (OPT2021)\n",
    "authors": [
      "Pascal Mattia Esser",
      "Frank Nielsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03734"
  },
  {
    "id": "arXiv:2112.03735",
    "title": "Adaptive Mimic: Deep Reinforcement Learning of Parameterized Bipedal  Walking from Infeasible References",
    "abstract": "Not until recently, robust robot locomotion has been achieved by deep\nreinforcement learning (DRL). However, for efficient learning of parametrized\nbipedal walking, developed references are usually required, limiting the\nperformance to that of the references. In this paper, we propose to design an\nadaptive reward function for imitation learning from the references. The agent\nis encouraged to mimic the references when its performance is low, while to\npursue high performance when it reaches the limit of references. We further\ndemonstrate that developed references can be replaced by low-quality references\nthat are generated without laborious tuning and infeasible to deploy by\nthemselves, as long as they can provide a priori knowledge to expedite the\nlearning process.",
    "descriptor": "\nComments: 12pages, 8 figures\n",
    "authors": [
      "Chong Zhang",
      "Qi Wu",
      "Liqian Ma",
      "Hongyuan Su"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.03735"
  },
  {
    "id": "arXiv:2112.03736",
    "title": "Gaussian map predictions for 3D surface feature localisation and  counting",
    "abstract": "In this paper, we propose to employ a Gaussian map representation to estimate\nprecise location and count of 3D surface features, addressing the limitations\nof state-of-the-art methods based on density estimation which struggle in\npresence of local disturbances. Gaussian maps indicate probable object location\nand can be generated directly from keypoint annotations avoiding laborious and\ncostly per-pixel annotations. We apply this method to the 3D spheroidal class\nof objects which can be projected into 2D shape representation enabling\nefficient processing by a neural network GNet, an improved UNet architecture,\nwhich generates the likely locations of surface features and their precise\ncount. We demonstrate a practical use of this technique for counting strawberry\nachenes which is used as a fruit quality measure in phenotyping applications.\nThe results of training the proposed system on several hundreds of 3D scans of\nstrawberries from a publicly available dataset demonstrate the accuracy and\nprecision of the system which outperforms the state-of-the-art density-based\nmethods for this application.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Justin Le Lou\u00ebdec",
      "Grzegorz Cielniak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03736"
  },
  {
    "id": "arXiv:2112.03737",
    "title": "UCD-CS at TREC 2021 Incident Streams Track",
    "abstract": "In recent years, the task of mining important information from social media\nposts during crises has become a focus of research for the purposes of\nassisting emergency response (ES). The TREC Incident Streams (IS) track is a\nresearch challenge organised for this purpose. The track asks participating\nsystems to both classify a stream of crisis-related tweets into humanitarian\naid related information types and estimate their importance regarding\ncriticality. The former refers to a multi-label information type classification\ntask and the latter refers to a priority estimation task. In this paper, we\nreport on the participation of the University College Dublin School of Computer\nScience (UCD-CS) in TREC-IS 2021. We explored a variety of approaches,\nincluding simple machine learning algorithms, multi-task learning techniques,\ntext augmentation, and ensemble approaches. The official evaluation results\nindicate that our runs achieve the highest scores in many metrics. To aid\nreproducibility, our code is publicly available at\nhttps://github.com/wangcongcong123/crisis-mtl.",
    "descriptor": "",
    "authors": [
      "Congcong Wang",
      "David Lillis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03737"
  },
  {
    "id": "arXiv:2112.03738",
    "title": "A more efficient algorithm to compute the Rand Index for change-point  problems",
    "abstract": "In this paper we provide a more efficient algorithm to compute the Rand Index\nwhen the data cluster comes from change-point detection problems. Given $N$\ndata points and two clusters of size $r$ and $s$, the algorithm runs on\n$O(r+s)$ time complexity and $O(1)$ memory complexity. The traditional\nalgorithm, in contrast, runs on $O(rs+N)$ time complexity and $O(rs)$ memory\ncomplexity.",
    "descriptor": "",
    "authors": [
      "Lucas de Oliveira Prates"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.03738"
  },
  {
    "id": "arXiv:2112.03740",
    "title": "Dilated convolution with learnable spacings",
    "abstract": "Dilated convolution is basically a convolution with a wider kernel created by\nregularly inserting spaces between the kernel elements. In this article, we\npresent a new version of the dilated convolution in which the spacings are made\nlearnable via backpropagation through an interpolation technique. We call this\nmethod \"Dilated Convolution with Learnable Spacings\" (DCLS) and we generalize\nits approach to the n-dimensional convolution case. However, our main focus\nhere will be the 2D case for which we developed two implementations: a naive\none that constructs the dilated kernel, suitable for small dilation rates, and\na more time/memory efficient one that uses a modified version of the \"im2col\"\nalgorithm. We then illustrate how this technique improves the accuracy of\nexisting architectures on semantic segmentation task on Pascal Voc 2012 dataset\nvia a simple drop-in replacement of the classical dilated convolutional layers\nby DCLS ones. Furthermore, we show that DCLS allows to reduce the number of\nlearnable parameters of the depthwise convolutions used in the recent ConvMixer\narchitecture by a factor 3 with no or very low reduction in accuracy and that\nby replacing large dense kernels with sparse DCLS ones. The code of the method\nis based on Pytorch and available at:\nhttps://github.com/K-H-Ismail/Dilated-Convolution-with-Learnable-Spacings-PyTorch.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Ismail Khalfaoui Hassani",
      "Thomas Pellegrini",
      "Timoth\u00e9e Masquelier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.03740"
  },
  {
    "id": "arXiv:2112.03749",
    "title": "Interpolating between BSDEs and PINNs -- deep learning for elliptic and  parabolic boundary value problems",
    "abstract": "Solving high-dimensional partial differential equations is a recurrent\nchallenge in economics, science and engineering. In recent years, a great\nnumber of computational approaches have been developed, most of them relying on\na combination of Monte Carlo sampling and deep learning based approximation.\nFor elliptic and parabolic problems, existing methods can broadly be classified\ninto those resting on reformulations in terms of $\\textit{backward stochastic\ndifferential equations}$ (BSDEs) and those aiming to minimize a regression-type\n$L^2$-error ($\\textit{physics-informed neural networks}$, PINNs). In this\npaper, we review the literature and suggest a methodology based on the novel\n$\\textit{diffusion loss}$ that interpolates between BSDEs and PINNs. Our\ncontribution opens the door towards a unified understanding of numerical\napproaches for high-dimensional PDEs, as well as for implementations that\ncombine the strengths of BSDEs and PINNs. We also provide generalizations to\neigenvalue problems and perform extensive numerical studies, including\ncalculations of the ground state for nonlinear Schr\\\"odinger operators and\ncommittor functions relevant in molecular dynamics.",
    "descriptor": "",
    "authors": [
      "Nikolas N\u00fcsken",
      "Lorenz Richter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03749"
  },
  {
    "id": "arXiv:2112.03750",
    "title": "Wild ToFu: Improving Range and Quality of Indirect Time-of-Flight Depth  with RGB Fusion in Challenging Environments",
    "abstract": "Indirect Time-of-Flight (I-ToF) imaging is a widespread way of depth\nestimation for mobile devices due to its small size and affordable price.\nPrevious works have mainly focused on quality improvement for I-ToF imaging\nespecially curing the effect of Multi Path Interference (MPI). These\ninvestigations are typically done in specifically constrained scenarios at\nclose distance, indoors and under little ambient light. Surprisingly little\nwork has investigated I-ToF quality improvement in real-life scenarios where\nstrong ambient light and far distances pose difficulties due to an extreme\namount of induced shot noise and signal sparsity, caused by the attenuation\nwith limited sensor power and light scattering. In this work, we propose a new\nlearning based end-to-end depth prediction network which takes noisy raw I-ToF\nsignals as well as an RGB image and fuses their latent representation based on\na multi step approach involving both implicit and explicit alignment to predict\na high quality long range depth map aligned to the RGB viewpoint. We test our\napproach on challenging real-world scenes and show more than 40% RMSE\nimprovement on the final depth map compared to the baseline approach.",
    "descriptor": "",
    "authors": [
      "HyunJun Jung",
      "Nikolas Brasch",
      "Ales Leonardis",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03750"
  },
  {
    "id": "arXiv:2112.03753",
    "title": "Tell me why! -- Explanations support learning of relational and causal  structure",
    "abstract": "Explanations play a considerable role in human learning, especially in areas\nthatremain major challenges for AI -- forming abstractions, and learning about\nthe re-lational and causal structure of the world. Here, we explore whether\nreinforcement learning agents might likewise benefit from explanations. We\noutline a family of relational tasks that involve selecting an object that is\nthe odd one out in a set (i.e., unique along one of many possible feature\ndimensions). Odd-one-out tasks require agents to reason over multi-dimensional\nrelationships among a set of objects. We show that agents do not learn these\ntasks well from reward alone, but achieve >90% performance when they are also\ntrained to generate language explaining object properties or why a choice is\ncorrect or incorrect. In further experiments, we show how predicting\nexplanations enables agents to generalize appropriately from ambiguous,\ncausally-confounded training, and even to meta-learn to perform experimental\ninterventions to identify causal structure. We show that explanations help\novercome the tendency of agents to fixate on simple features, and explore which\naspects of explanations make them most beneficial. Our results suggest that\nlearning from explanations is a powerful principle that could offer a promising\npath towards training more robust and general machine learning systems.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Andrew K. Lampinen",
      "Nicholas A. Roy",
      "Ishita Dasgupta",
      "Stephanie C. Y. Chan",
      "Allison C. Tam",
      "James L. McClelland",
      "Chen Yan",
      "Adam Santoro",
      "Neil C. Rabinowitz",
      "Jane X. Wang",
      "Felix Hill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03753"
  },
  {
    "id": "arXiv:2112.03754",
    "title": "A Continuous-time Stochastic Gradient Descent Method for Continuous Data",
    "abstract": "Optimization problems with continuous data appear in, e.g., robust machine\nlearning, functional data analysis, and variational inference. Here, the target\nfunction is given as an integral over a family of (continuously) indexed target\nfunctions - integrated with respect to a probability measure. Such problems can\noften be solved by stochastic optimization methods: performing optimization\nsteps with respect to the indexed target function with randomly switched\nindices. In this work, we study a continuous-time variant of the stochastic\ngradient descent algorithm for optimization problems with continuous data. This\nso-called stochastic gradient process consists in a gradient flow minimizing an\nindexed target function that is coupled with a continuous-time index process\ndetermining the index. Index processes are, e.g., reflected diffusions, pure\njump processes, or other L\\'evy processes on compact spaces. Thus, we study\nmultiple sampling patterns for the continuous data space and allow for data\nsimulated or streamed at runtime of the algorithm. We analyze the approximation\nproperties of the stochastic gradient process and study its longtime behavior\nand ergodicity under constant and decreasing learning rates. We end with\nillustrating the applicability of the stochastic gradient process in a\npolynomial regression problem with noisy functional data, as well as in a\nphysics-informed neural network.",
    "descriptor": "",
    "authors": [
      "Kexin Jin",
      "Jonas Latz",
      "Chenguang Liu",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.03754"
  },
  {
    "id": "arXiv:2112.03756",
    "title": "Bridging the Model-Reality Gap with Lipschitz Network Adaptation",
    "abstract": "As robots venture into the real world, they are subject to unmodeled dynamics\nand disturbances. Traditional model-based control approaches have been proven\nsuccessful in relatively static and known operating environments. However, when\nan accurate model of the robot is not available, model-based design can lead to\nsuboptimal and even unsafe behaviour. In this work, we propose a method that\nbridges the model-reality gap and enables the application of model-based\napproaches even if dynamic uncertainties are present. In particular, we present\na learning-based model reference adaptation approach that makes a robot system,\nwith possibly uncertain dynamics, behave as a predefined reference model. In\nturn, the reference model can be used for model-based controller design. In\ncontrast to typical model reference adaptation control approaches, we leverage\nthe representative power of neural networks to capture highly nonlinear\ndynamics uncertainties and guarantee stability by encoding a certifying\nLipschitz condition in the architectural design of a special type of neural\nnetwork called the Lipschitz network. Our approach applies to a general class\nof nonlinear control-affine systems even when our prior knowledge about the\ntrue robot system is limited. We demonstrate our approach in flying inverted\npendulum experiments, where an off-the-shelf quadrotor is challenged to balance\nan inverted pendulum while hovering or tracking circular trajectories.",
    "descriptor": "",
    "authors": [
      "Siqi Zhou",
      "Karime Pereida",
      "Wenda Zhao",
      "Angela P. Schoellig"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03756"
  },
  {
    "id": "arXiv:2112.03759",
    "title": "Learning a Robust Multiagent Driving Policy for Traffic Congestion  Reduction",
    "abstract": "The advent of automated and autonomous vehicles (AVs) creates opportunities\nto achieve system-level goals using multiple AVs, such as traffic congestion\nreduction. Past research has shown that multiagent congestion-reducing driving\npolicies can be learned in a variety of simulated scenarios. While initial\nproofs of concept were in small, closed traffic networks with a centralized\ncontroller, recently successful results have been demonstrated in more\nrealistic settings with distributed control policies operating in open road\nnetworks where vehicles enter and leave. However, these driving policies were\nmostly tested under the same conditions they were trained on, and have not been\nthoroughly tested for robustness to different traffic conditions, which is a\ncritical requirement in real-world scenarios. This paper presents a learned\nmultiagent driving policy that is robust to a variety of open-network traffic\nconditions, including vehicle flows, the fraction of AVs in traffic, AV\nplacement, and different merging road geometries. A thorough empirical analysis\ninvestigates the sensitivity of such a policy to the amount of AVs in both a\nsimple merge network and a more complex road with two merging ramps. It shows\nthat the learned policy achieves significant improvement over simulated\nhuman-driven policies even with AV penetration as low as 2%. The same policy is\nalso shown to be capable of reducing traffic congestion in more complex roads\nwith two merging ramps.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Yulin Zhang",
      "William Macke",
      "Jiaxun Cui",
      "Daniel Urieli",
      "Peter Stone"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.03759"
  },
  {
    "id": "arXiv:2112.03763",
    "title": "Creating Multimodal Interactive Agents with Imitation and  Self-Supervised Learning",
    "abstract": "A common vision from science fiction is that robots will one day inhabit our\nphysical spaces, sense the world as we do, assist our physical labours, and\ncommunicate with us through natural language. Here we study how to design\nartificial agents that can interact naturally with humans using the\nsimplification of a virtual environment. We show that imitation learning of\nhuman-human interactions in a simulated world, in conjunction with\nself-supervised learning, is sufficient to produce a multimodal interactive\nagent, which we call MIA, that successfully interacts with non-adversarial\nhumans 75% of the time. We further identify architectural and algorithmic\ntechniques that improve performance, such as hierarchical action selection.\nAltogether, our results demonstrate that imitation of multi-modal, real-time\nhuman behaviour may provide a straightforward and surprisingly effective means\nof imbuing agents with a rich behavioural prior from which agents might then be\nfine-tuned for specific purposes, thus laying a foundation for training capable\nagents for interactive robots or digital assistants. A video of MIA's behaviour\nmay be found at https://youtu.be/ZFgRhviF7mY",
    "descriptor": "",
    "authors": [
      "DeepMind Interactive Agents Team",
      "Josh Abramson",
      "Arun Ahuja",
      "Arthur Brussee",
      "Federico Carnevale",
      "Mary Cassin",
      "Felix Fischer",
      "Petko Georgiev",
      "Alex Goldin",
      "Tim Harley",
      "Felix Hill",
      "Peter C Humphreys",
      "Alden Hung",
      "Jessica Landon",
      "Timothy Lillicrap",
      "Hamza Merzic",
      "Alistair Muldal",
      "Adam Santoro",
      "Guy Scully",
      "Tamara von Glehn",
      "Greg Wayne",
      "Nathaniel Wong",
      "Chen Yan",
      "Rui Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03763"
  },
  {
    "id": "arXiv:2112.03765",
    "title": "In-flight Novelty Detection with Convolutional Neural Networks",
    "abstract": "Gas turbine engines are complex machines that typically generate a vast\namount of data, and require careful monitoring to allow for cost-effective\npreventative maintenance. In aerospace applications, returning all measured\ndata to ground is prohibitively expensive, often causing useful, high value,\ndata to be discarded. The ability to detect, prioritise, and return useful data\nin real-time is therefore vital. This paper proposes that system output\nmeasurements, described by a convolutional neural network model of normality,\nare prioritised in real-time for the attention of preventative maintenance\ndecision makers.\nDue to the complexity of gas turbine engine time-varying behaviours, deriving\naccurate physical models is difficult, and often leads to models with low\nprediction accuracy and incompatibility with real-time execution. Data-driven\nmodelling is a desirable alternative producing high accuracy, asset specific\nmodels without the need for derivation from first principles.\nWe present a data-driven system for online detection and prioritisation of\nanomalous data. Biased data assessment deriving from novel operating conditions\nis avoided by uncertainty management integrated into the deep neural predictive\nmodel. Testing is performed on real and synthetic data, showing sensitivity to\nboth real and synthetic faults. The system is capable of running in real-time\non low-power embedded hardware and is currently in deployment on the\nRolls-Royce Pearl 15 engine flight trials.",
    "descriptor": "",
    "authors": [
      "Adam Hartwell",
      "Felipe Montana",
      "Will Jacobs",
      "Visakan Kadirkamanathan",
      "Andrew R Mills",
      "Tom Clark"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03765"
  },
  {
    "id": "arXiv:2112.03772",
    "title": "Explicit approximations for nonlinear switching diffusion systems in  finite and infinite horizons",
    "abstract": "Focusing on hybrid diffusion dynamics involving continuous dynamics as well\nas discrete events, this article investigates the explicit approximations for\nnonlinear switching diffusion systems modulated by a Markov chain. Different\nkinds of easily implementable explicit schemes have been proposed to\napproximate the dynamical behaviors of switching diffusion systems with local\nLipschitz continuous drift and diffusion coefficients in both finite and\ninfinite intervals. Without additional restriction conditions except those\nwhich guarantee the exact solutions posses their dynamical properties, the\nnumerical solutions converge strongly to the exact solutions in finite horizon,\nmoreover, realize the approximation of long-time dynamical properties including\nthe moment boundedness, stability and ergodicity. Some simulations and examples\nare provided to support the theoretical results and demonstrate the validity of\nthe approach.",
    "descriptor": "\nComments: 50 pages, 8 figures\n",
    "authors": [
      "Hongfu Yang",
      "Xiaoyue Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.03772"
  },
  {
    "id": "arXiv:2112.03773",
    "title": "On the Effectiveness of Mode Exploration in Bayesian Model Averaging for  Neural Networks",
    "abstract": "Multiple techniques for producing calibrated predictive probabilities using\ndeep neural networks in supervised learning settings have emerged that leverage\napproaches to ensemble diverse solutions discovered during cyclic training or\ntraining from multiple random starting points (deep ensembles). However, only a\nlimited amount of work has investigated the utility of exploring the local\nregion around each diverse solution (posterior mode). Using three well-known\ndeep architectures on the CIFAR-10 dataset, we evaluate several simple methods\nfor exploring local regions of the weight space with respect to Brier score,\naccuracy, and expected calibration error. We consider both Bayesian inference\ntechniques (variational inference and Hamiltonian Monte Carlo applied to the\nsoftmax output layer) as well as utilizing the stochastic gradient descent\ntrajectory near optima. While adding separate modes to the ensemble uniformly\nimproves performance, we show that the simple mode exploration methods\nconsidered here produce little to no improvement over ensembles without mode\nexploration.",
    "descriptor": "\nComments: Presented at the ICML 2021 Workshop on Uncertainty and Robustness in Deep Learning\n",
    "authors": [
      "John T. Holodnak",
      "Allan B. Wollaber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03773"
  },
  {
    "id": "arXiv:2112.03777",
    "title": "Variance-Aware Weight Initialization for Point Convolutional Neural  Networks",
    "abstract": "Appropriate weight initialization has been of key importance to successfully\ntrain neural networks. Recently, batch normalization has diminished the role of\nweight initialization by simply normalizing each layer based on batch\nstatistics. Unfortunately, batch normalization has several drawbacks when\napplied to small batch sizes, as they are required to cope with memory\nlimitations when learning on point clouds. While well-founded weight\ninitialization strategies can render batch normalization unnecessary and thus\navoid these drawbacks, no such approaches have been proposed for point\nconvolutional networks. To fill this gap, we propose a framework to unify the\nmultitude of continuous convolutions. This enables our main contribution,\nvariance-aware weight initialization. We show that this initialization can\navoid batch normalization while achieving similar and, in some cases, better\nperformance.",
    "descriptor": "",
    "authors": [
      "Pedro Hermosilla",
      "Michael Schelling",
      "Tobias Ritschel",
      "Timo Ropinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03777"
  },
  {
    "id": "arXiv:2112.03784",
    "title": "Qualitative Analysis for Human Centered AI",
    "abstract": "Human-centered artificial intelligence (AI) posits that machine learning and\nAI should be developed and applied in a socially aware way. In this article, we\nargue that qualitative analysis (QA) can be a valuable tool in this process,\nsupplementing, informing, and extending the possibilities of AI models. We show\nthis by describing how QA can be integrated in the current prediction paradigm\nof AI, assisting scientists in the process of selecting data, variables, and\nmodel architectures. Furthermore, we argue that QA can be a part of novel\nparadigms towards Human Centered AI. QA can support scientists and\npractitioners in practical problem solving and situated model development. It\ncan also promote participatory design approaches, reveal understudied and\nemerging issues in AI systems, and assist policy making.",
    "descriptor": "",
    "authors": [
      "Orestis Papakyriakopoulos",
      "Elizabeth Anne Watkins",
      "Amy Winecoff",
      "Klaudia Ja\u017awi\u0144ska",
      "Tithi Chattopadhyay"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.03784"
  },
  {
    "id": "arXiv:2112.03791",
    "title": "Online Sorting and Translational Packing of Convex Polygons",
    "abstract": "We investigate various online packing problems in which convex polygons\narrive one by one and have to be placed irrevocably into a container before the\nnext piece is revealed; the pieces must not be rotated, but only translated.\nThe aim is to minimize the used space depending on the specific problem at\nhand, e.g., the strip length in strip packing, the number of bins in bin\npacking, etc.\nWe draw interesting connections to the following online sorting problem\n\\OnlineSorting{}$[\\gamma,n]$: We receive a stream of real numbers\n$s_1,\\ldots,s_n$, $s_i\\in[0,1]$, one by one. Each real must be placed in an\narray~$A$ with $\\gamma n$ initially empty cells without knowing the subsequent\nreals. The goal is to minimize the sum of differences of consecutive reals in\n$A$. The offline optimum is to place the reals in sorted order so the cost is\nat most $1$. We show that for any $\\Delta$-competitive online algorithm of\n\\OnlineSorting{}$[\\gamma,n]$, it holds that $\\gamma \\Delta \\in\\Omega(\\log\nn/\\log \\log n)$.\nWe use this lower bound to prove the non-existence of competitive algorithms\nfor various online translational packing problems of convex polygons, among\nthem strip packing, bin packing and perimeter packing. This also implies that\nthere exists no online algorithm that can pack all streams of pieces of\ndiameter and total area at most $\\delta$ into the unit square. These results\nare in contrast to the case when the pieces are restricted to rectangles, for\nwhich competitive algorithms are known. Likewise, the offline versions of\npacking convex polygons have constant factor approximation algorithms.\nOn the positive side, we present an algorithm with competitive ratio\n$O(n^{0.59})$ for online translational strip packing of convex polygons. In the\ncase of \\OnlineSorting{}$[C,n]$ for any constant $C>1$, we present an\n$O(2^{O(\\sqrt{\\log n\\log\\log n})})$-competitive algorithm.",
    "descriptor": "",
    "authors": [
      "Anders Aamand",
      "Mikkel Abrahamsen",
      "Lorenzo Beretta",
      "Linda Kleist"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.03791"
  },
  {
    "id": "arXiv:2112.03796",
    "title": "New Lower Bounds on the Capacity of Optical Fiber Channels via Optimized  Shaping and Detection",
    "abstract": "Constellation shaping is a practical and effective technique to improve the\nperformance and the rate adaptivity of optical communication systems. In\nprinciple, it could also be used to mitigate the impact of nonlinear effects,\npossibly increasing the information rate beyond the current limit dictated by\nfiber nonlinearity. However, this appealing idea is frustrated by the\ndifficulty of designing an effective shaping strategy that takes into account\nthe nonlinearity and long memory of the fiber channel, as well as the possible\ninterplay with other nonlinearity mitigation strategies. As a result, only\nlittle progress has been made so far, while the optimal shaping distribution\nand the ultimate channel capacity remain unknown. In this work, we describe a\nnovel technique to optimize the shaping distribution in a very general setting\nand high-dimensional space. For a simplified block-memoryless nonlinear optical\nchannel, the capacity lower bound obtained by the proposed technique can be\nexpressed analytically, establishing the conditions for an unbounded growth of\ncapacity with power. In a more realistic scenario, the technique can be\nimplemented by a rejection sampling algorithm driven by a suitable cost\nfunction, and the corresponding achievable information rate estimated\nnumerically. The combination of the proposed technique with an improved\n(non-Gaussian) decoding metric yields a new capacity lower bound for the\ndual-polarization WDM channel.",
    "descriptor": "\nComments: Submitted to IEEE Journal of Lightwave Technology on November 30th, 2021\n",
    "authors": [
      "Marco Secondini",
      "Stella Civelli",
      "Enrico Forestieri",
      "Lareb Zar Khan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.03796"
  },
  {
    "id": "arXiv:2112.03798",
    "title": "PTR-PPO: Proximal Policy Optimization with Prioritized Trajectory Replay",
    "abstract": "On-policy deep reinforcement learning algorithms have low data utilization\nand require significant experience for policy improvement. This paper proposes\na proximal policy optimization algorithm with prioritized trajectory replay\n(PTR-PPO) that combines on-policy and off-policy methods to improve sampling\nefficiency by prioritizing the replay of trajectories generated by old\npolicies. We first design three trajectory priorities based on the\ncharacteristics of trajectories: the first two being max and mean trajectory\npriorities based on one-step empirical generalized advantage estimation (GAE)\nvalues and the last being reward trajectory priorities based on normalized\nundiscounted cumulative reward. Then, we incorporate the prioritized trajectory\nreplay into the PPO algorithm, propose a truncated importance weight method to\novercome the high variance caused by large importance weights under multistep\nexperience, and design a policy improvement loss function for PPO under\noff-policy conditions. We evaluate the performance of PTR-PPO in a set of Atari\ndiscrete control tasks, achieving state-of-the-art performance. In addition, by\nanalyzing the heatmap of priority changes at various locations in the priority\nmemory during training, we find that memory size and rollout length can have a\nsignificant impact on the distribution of trajectory priorities and, hence, on\nthe performance of the algorithm.",
    "descriptor": "\nComments: 16 pages,10figures, We plan to submit a paper to the conference of IJCAI-2022\n",
    "authors": [
      "Xingxing Liang",
      "Yang Ma",
      "Yanghe Feng",
      "Zhong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03798"
  },
  {
    "id": "arXiv:2112.03799",
    "title": "A pragmatic account of the weak evidence effect",
    "abstract": "Language is not only used to inform. We often seek to persuade by arguing in\nfavor of a particular view. Persuasion raises a number of challenges for\nclassical accounts of belief updating, as information cannot be taken at face\nvalue. How should listeners account for a speaker's \"hidden agenda\" when\nincorporating new information? Here, we extend recent probabilistic models of\nrecursive social reasoning to allow for persuasive goals and show that our\nmodel provides a new pragmatic explanation for why weakly favorable arguments\nmay backfire, a phenomenon known as the weak evidence effect. Critically, our\nmodel predicts a relationship between belief updating and speaker expectations:\nweak evidence should only backfire when speakers are expected to act under\npersuasive goals, implying the absence of stronger evidence. We introduce a\nsimple experimental paradigm called the Stick Contest to measure the extent to\nwhich the weak evidence effect depends on speaker expectations, and show that a\npragmatic listener model accounts for the empirical data better than\nalternative models. Our findings suggest potential avenues for rational models\nof social reasoning to further illuminate decision-making phenomena.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Samuel A. Barnett",
      "Robert D. Hawkins",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03799"
  },
  {
    "id": "arXiv:2112.03803",
    "title": "Suppressing Static Visual Cues via Normalizing Flows for Self-Supervised  Video Representation Learning",
    "abstract": "Despite the great progress in video understanding made by deep convolutional\nneural networks, feature representation learned by existing methods may be\nbiased to static visual cues. To address this issue, we propose a novel method\nto suppress static visual cues (SSVC) based on probabilistic analysis for\nself-supervised video representation learning. In our method, video frames are\nfirst encoded to obtain latent variables under standard normal distribution via\nnormalizing flows. By modelling static factors in a video as a random variable,\nthe conditional distribution of each latent variable becomes shifted and scaled\nnormal. Then, the less-varying latent variables along time are selected as\nstatic cues and suppressed to generate motion-preserved videos. Finally,\npositive pairs are constructed by motion-preserved videos for contrastive\nlearning to alleviate the problem of representation bias to static cues. The\nless-biased video representation can be better generalized to various\ndownstream tasks. Extensive experiments on publicly available benchmarks\ndemonstrate that the proposed method outperforms the state of the art when only\nsingle RGB modality is used for pre-training.",
    "descriptor": "\nComments: AAAI2022\n",
    "authors": [
      "Manlin Zhang",
      "Jinpeng Wang",
      "Andy J. Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03803"
  },
  {
    "id": "arXiv:2112.03804",
    "title": "Fast Payoff Matrix Sparsification Techniques for Structured  Extensive-Form Games",
    "abstract": "The practical scalability of many optimization algorithms for large\nextensive-form games is often limited by the games' huge payoff matrices. To\nameliorate the issue, Zhang and Sandholm (2020) recently proposed a\nsparsification technique that factorizes the payoff matrix $\\mathbf{A}$ into a\nsparser object $\\mathbf{A} = \\hat{\\mathbf{A}} + \\mathbf{U}\\mathbf{V}^\\top$,\nwhere the total combined number of nonzeros of $\\hat{\\mathbf{A}}$,\n$\\mathbf{U}$, and $\\mathbf{V}$ is significantly smaller. Such a factorization\ncan be used in place of the original payoff matrix in many optimization\nalgorithm, such as interior-point and second-order methods, thus increasing the\nsize of games that can be handled. Their technique significantly sparsifies\npoker (end)games, standard benchmarks used in computational game theory, AI,\nand more broadly. We show that the existence of extremely sparse factorizations\nin poker games can be tied to their particular \\emph{Kronecker-product}\nstructure. We clarify how such structure arises and introduce the connection\nbetween that structure and sparsification. By leveraging such structure, we\ngive two ways of computing strong sparsifications of poker games (as well as\nany other game with a similar structure) that are i) orders of magnitude faster\nto compute, ii) more numerically stable, and iii) produce a dramatically\nsmaller number of nonzeros than the prior technique. Our techniques enable --\nfor the first time -- effective computation of high-precision Nash equilibria\nand strategies subject to constraints on the amount of allowed randomization.\nFurthermore, they significantly speed up parallel first-order game-solving\nalgorithms; we show state-of-the-art speed on a GPU.",
    "descriptor": "\nComments: To appear at AAAI'22\n",
    "authors": [
      "Gabriele Farina",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.03804"
  },
  {
    "id": "arXiv:2112.03805",
    "title": "Learning nonlinear feedforward: a Gaussian Process Approach Applied to a  Printer with Friction",
    "abstract": "Feedforward control is essential to achieving good tracking performance in\npositioning systems. The aim of this paper is to develop an identification\nstrategy for inverse models of systems with nonlinear dynamics of unknown\nstructure using input-output data, which directly delivers feedforward signals\nfor a-priori unknown tasks. To this end, inverse systems are regarded as\nnoncausal nonlinear finite impulse response (NFIR) systems and modeled as a\nGaussian Process with a stationary kernel function that imposes properties such\nas smoothness and periodicity. The approach is validated experimentally on a\nconsumer printer with friction and shown to lead to improved tracking\nperformance with respect to linear feedforward.",
    "descriptor": "\nComments: 7 pages, 9 figures, submitted to American Control Conference 2022\n",
    "authors": [
      "Max van Meer",
      "Maurice Poot",
      "Jim Portegies",
      "Tom Oomen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03805"
  },
  {
    "id": "arXiv:2112.03806",
    "title": "OOD-GNN: Out-of-Distribution Generalized Graph Neural Network",
    "abstract": "Graph neural networks (GNNs) have achieved impressive performance when\ntesting and training graph data come from identical distribution. However,\nexisting GNNs lack out-of-distribution generalization abilities so that their\nperformance substantially degrades when there exist distribution shifts between\ntesting and training graph data. To solve this problem, in this work, we\npropose an out-of-distribution generalized graph neural network (OOD-GNN) for\nachieving satisfactory performance on unseen testing graphs that have different\ndistributions with training graphs. Our proposed OOD-GNN employs a novel\nnonlinear graph representation decorrelation method utilizing random Fourier\nfeatures, which encourages the model to eliminate the statistical dependence\nbetween relevant and irrelevant graph representations through iteratively\noptimizing the sample graph weights and graph encoder. We further design a\nglobal weight estimator to learn weights for training graphs such that\nvariables in graph representations are forced to be independent. The learned\nweights help the graph encoder to get rid of spurious correlations and, in\nturn, concentrate more on the true connection between learned discriminative\ngraph representations and their ground-truth labels. We conduct extensive\nexperiments to validate the out-of-distribution generalization abilities on two\nsynthetic and 12 real-world datasets with distribution shifts. The results\ndemonstrate that our proposed OOD-GNN significantly outperforms\nstate-of-the-art baselines.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Haoyang Li",
      "Xin Wang",
      "Ziwei Zhang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03806"
  },
  {
    "id": "arXiv:2112.03807",
    "title": "raceBERT -- A Transformer-based Model for Predicting Race from Names",
    "abstract": "This paper presents raceBERT -- a transformer-based model for predicting race\nfrom character sequences in names, and an accompanying python package. Using a\ntransformer-based model trained on a U.S. Florida voter registration dataset,\nthe model predicts the likelihood of a name belonging to 5 U.S. census race\ncategories (White, Black, Hispanic, Asian & Pacific Islander, American Indian &\nAlaskan Native). I build on Sood and Laohaprapanon (2018) by replacing their\nLSTM model with transformer-based models (pre-trained BERT model, and a roBERTa\nmodel trained from scratch), and compare the results. To the best of my\nknowledge, raceBERT achieves state-of-the-art results in race prediction using\nnames, with an average f1-score of 0.86 -- a 4.\\1% improvement over the\nprevious state-of-the-art, and improvements between 15-17\\% for non-white\nnames.",
    "descriptor": "\nComments: See this http URL\n",
    "authors": [
      "Prasanna Parasurama"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03807"
  },
  {
    "id": "arXiv:2112.03808",
    "title": "Automated Story Generation as Question-Answering",
    "abstract": "Neural language model-based approaches to automated story generation suffer\nfrom two important limitations. First, language model-based story generators\ngenerally do not work toward a given goal or ending. Second, they often lose\ncoherence as the story gets longer. We propose a novel approach to automated\nstory generation that treats the problem as one of generative\nquestion-answering. Our proposed story generation system starts with sentences\nencapsulating the final event of the story. The system then iteratively (1)\nanalyzes the text describing the most recent event, (2) generates a question\nabout \"why\" a character is doing the thing they are doing in the event, and\nthen (3) attempts to generate another, preceding event that answers this\nquestion.",
    "descriptor": "",
    "authors": [
      "Louis Castricato",
      "Spencer Frazier",
      "Jonathan Balloch",
      "Nitya Tarakad",
      "Mark Riedl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03808"
  },
  {
    "id": "arXiv:2112.03809",
    "title": "The Partially Observable Asynchronous Multi-Agent Cooperation Challenge",
    "abstract": "Multi-agent reinforcement learning (MARL) has received increasing attention\nfor its applications in various domains. Researchers have paid much attention\non its partially observable and cooperative settings for meeting real-world\nrequirements. For testing performance of different algorithms, standardized\nenvironments are designed such as the StarCraft Multi-Agent Challenge, which is\none of the most successful MARL benchmarks. To our best knowledge, most of\ncurrent environments are synchronous, where agents execute actions in the same\npace. However, heterogeneous agents usually have their own action spaces and\nthere is no guarantee for actions from different agents to have the same\nexecuted cycle, which leads to asynchronous multi-agent cooperation. Inspired\nfrom the Wargame, a confrontation game between two armies abstracted from real\nworld environment, we propose the first Partially Observable Asynchronous\nmulti-agent Cooperation challenge (POAC) for the MARL community. Specifically,\nPOAC supports two teams of heterogeneous agents to fight with each other, where\nan agent selects actions based on its own observations and cooperates\nasynchronously with its allies. Moreover, POAC is a light weight, flexible and\neasy to use environment, which can be configured by users to meet different\nexperimental requirements such as self-play model, human-AI model and so on.\nAlong with our benchmark, we offer six game scenarios of varying difficulties\nwith the built-in rule-based AI as opponents. Finally, since most MARL\nalgorithms are designed for synchronous agents, we revise several\nrepresentatives to meet the asynchronous setting, and the relatively poor\nexperimental results validate the challenge of POAC. Source code is released in\n\\url{this http URL}.",
    "descriptor": "",
    "authors": [
      "Meng Yao",
      "Qiyue Yin",
      "Jun Yang",
      "Tongtong Yu",
      "Shengqi Shen",
      "Junge Zhang",
      "Bin Liang",
      "Kaiqi Huang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.03809"
  },
  {
    "id": "arXiv:2112.03810",
    "title": "Polarimetric Pose Prediction",
    "abstract": "Light has many properties that can be passively measured by vision sensors.\nColour-band separated wavelength and intensity are arguably the most commonly\nused ones for monocular 6D object pose estimation. This paper explores how\ncomplementary polarisation information, i.e. the orientation of light wave\noscillations, can influence the accuracy of pose predictions. A hybrid model\nthat leverages physical priors jointly with a data-driven learning strategy is\ndesigned and carefully tested on objects with different amount of photometric\ncomplexity. Our design not only significantly improves the pose accuracy in\nrelation to photometric state-of-the-art approaches, but also enables object\npose estimation for highly reflective and transparent objects.",
    "descriptor": "",
    "authors": [
      "Daoyi Gao",
      "Yitong Li",
      "Patrick Ruhkamp",
      "Iuliia Skobleva",
      "Magdalena Wysock",
      "HyunJun Jung",
      "Pengyuan Wang",
      "Arturo Guridi",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03810"
  },
  {
    "id": "arXiv:2112.03811",
    "title": "Disentangled Counterfactual Recurrent Networks for Treatment Effect  Inference over Time",
    "abstract": "Choosing the best treatment-plan for each individual patient requires\naccurate forecasts of their outcome trajectories as a function of the\ntreatment, over time. While large observational data sets constitute rich\nsources of information to learn from, they also contain biases as treatments\nare rarely assigned randomly in practice. To provide accurate and unbiased\nforecasts, we introduce the Disentangled Counterfactual Recurrent Network\n(DCRN), a novel sequence-to-sequence architecture that estimates treatment\noutcomes over time by learning representations of patient histories that are\ndisentangled into three separate latent factors: a treatment factor,\ninfluencing only treatment selection; an outcome factor, influencing only the\noutcome; and a confounding factor, influencing both. With an architecture that\nis completely inspired by the causal structure of treatment influence over\ntime, we advance forecast accuracy and disease understanding, as our\narchitecture allows for practitioners to infer which patient features influence\nwhich part in a patient's trajectory, contrasting other approaches in this\ndomain. We demonstrate that DCRN outperforms current state-of-the-art methods\nin forecasting treatment responses, on both real and simulated data.",
    "descriptor": "",
    "authors": [
      "Jeroen Berrevoets",
      "Alicia Curth",
      "Ioana Bica",
      "Eoin McKinney",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03811"
  },
  {
    "id": "arXiv:2112.03814",
    "title": "A Contrastive Distillation Approach for Incremental Semantic  Segmentation in Aerial Images",
    "abstract": "Incremental learning represents a crucial task in aerial image processing,\nespecially given the limited availability of large-scale annotated datasets. A\nmajor issue concerning current deep neural architectures is known as\ncatastrophic forgetting, namely the inability to faithfully maintain past\nknowledge once a new set of data is provided for retraining. Over the years,\nseveral techniques have been proposed to mitigate this problem for image\nclassification and object detection. However, only recently the focus has\nshifted towards more complex downstream tasks such as instance or semantic\nsegmentation. Starting from incremental-class learning for semantic\nsegmentation tasks, our goal is to adapt this strategy to the aerial domain,\nexploiting a peculiar feature that differentiates it from natural images,\nnamely the orientation. In addition to the standard knowledge distillation\napproach, we propose a contrastive regularization, where any given input is\ncompared with its augmented version (i.e. flipping and rotations) in order to\nminimize the difference between the segmentation features produced by both\ninputs. We show the effectiveness of our solution on the Potsdam dataset,\noutperforming the incremental baseline in every test. Code available at:\nhttps://github.com/edornd/contrastive-distillation.",
    "descriptor": "\nComments: 12 pages, ICIAP 2021\n",
    "authors": [
      "Edoardo Arnaudo",
      "Fabio Cermelli",
      "Antonio Tavera",
      "Claudio Rossi",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.03814"
  },
  {
    "id": "arXiv:2112.03816",
    "title": "A Deep Learning Driven Algorithmic Pipeline for Autonomous Navigation in  Row-Based Crops",
    "abstract": "Expensive sensors and inefficient algorithmic pipelines significantly affect\nthe overall cost of autonomous machines. However, affordable robotic solutions\nare essential to practical usage, and their financial impact constitutes a\nfundamental requirement to employ service robotics in most fields of\napplication. Among all, researchers in the precision agriculture domain strive\nto devise robust and cost-effective autonomous platforms in order to provide\ngenuinely large-scale competitive solutions. In this article, we present a\ncomplete algorithmic pipeline for row-based crops autonomous navigation,\nspecifically designed to cope with low-range sensors and seasonal variations.\nFirstly, we build on a robust data-driven methodology to generate a viable path\nfor the autonomous machine, covering the full extension of the crop with only\nthe occupancy grid map information of the field. Moreover, our solution\nleverages on latest advancement of deep learning optimization techniques and\nsynthetic generation of data to provide an affordable solution that efficiently\ntackles the well-known Global Navigation Satellite System unreliability and\ndegradation due to vegetation growing inside rows. Extensive experimentation\nand simulations against computer-generated environments and real-world crops\ndemonstrated the robustness and intrinsic generalizability of our methodology\nthat opens the possibility of highly affordable and fully autonomous machines.",
    "descriptor": "\nComments: Submitted to IEEE/ASME Transactions on Mechatronics (TMECH)\n",
    "authors": [
      "Simone Cerrato",
      "Vittorio Mazzia",
      "Francesco Salvetti",
      "Marcello Chiaberge"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03816"
  },
  {
    "id": "arXiv:2112.03826",
    "title": "Hybrid Visual SLAM for Underwater Vehicle Manipulator Systems",
    "abstract": "This paper presents a novel visual scene mapping method for underwater\nvehicle manipulator systems (UVMSs), with specific emphasis on robust mapping\nin natural seafloor environments. Prior methods for underwater scene mapping\ntypically process the data offline, while existing underwater SLAM methods that\nrun in real-time are generally focused on localization and not mapping. Our\nmethod uses GPU accelerated SIFT features in a graph optimization framework to\nbuild a feature map. The map scale is constrained by features from a vehicle\nmounted stereo camera, and we exploit the dynamic positioning capability of the\nmanipulator system by fusing features from a wrist mounted fisheye camera into\nthe map to extend it beyond the limited viewpoint of the vehicle mounted\ncameras. Our hybrid SLAM method is evaluated on challenging image sequences\ncollected with a UVMS in natural deep seafloor environments of the Costa Rican\ncontinental shelf margin, and we also evaluate the stereo only mode on a\nshallow reef survey dataset. Results on these datasets demonstrate the high\naccuracy of our system and suitability for operating in diverse and natural\nseafloor environments.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Gideon Billings",
      "Richard Camilli",
      "Matthew Johnson-Roberson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.03826"
  },
  {
    "id": "arXiv:2112.03835",
    "title": "Attention-Based Model and Deep Reinforcement Learning for Distribution  of Event Processing Tasks",
    "abstract": "Event processing is the cornerstone of the dynamic and responsive Internet of\nThings (IoT). Recent approaches in this area are based on representational\nstate transfer (REST) principles, which allow event processing tasks to be\nplaced at any device that follows the same principles. However, the tasks\nshould be properly distributed among edge devices to ensure fair resources\nutilization and guarantee seamless execution. This article investigates the use\nof deep learning to fairly distribute the tasks. An attention-based neural\nnetwork model is proposed to generate efficient load balancing solutions under\ndifferent scenarios. The proposed model is based on the Transformer and Pointer\nNetwork architectures, and is trained by an advantage actor-critic\nreinforcement learning algorithm. The model is designed to scale to the number\nof event processing tasks and the number of edge devices, with no need for\nhyperparameters re-tuning or even retraining. Extensive experimental results\nshow that the proposed model outperforms conventional heuristics in many key\nperformance indicators. The generic design and the obtained results show that\nthe proposed model can potentially be applied to several other load balancing\nproblem variations, which makes the proposal an attractive option to be used in\nreal-world scenarios due to its scalability and efficiency.",
    "descriptor": "\nComments: 19 pages, 6 figures\n",
    "authors": [
      "A. Mazayev",
      "F. Al-Tam",
      "N. Correia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.03835"
  },
  {
    "id": "arXiv:2112.03837",
    "title": "Augment & Valuate : A Data Enhancement Pipeline for Data-Centric AI",
    "abstract": "Data scarcity and noise are important issues in industrial applications of\nmachine learning. However, it is often challenging to devise a scalable and\ngeneralized approach to address the fundamental distributional and semantic\nproperties of dataset with black box models. For this reason, data-centric\napproaches are crucial for the automation of machine learning operation\npipeline. In order to serve as the basis for this automation, we suggest a\ndomain-agnostic pipeline for refining the quality of data in image\nclassification problems. This pipeline contains data valuation, cleansing, and\naugmentation. With an appropriate combination of these methods, we could\nachieve 84.711% test accuracy (ranked #6, Honorable Mention in the Most\nInnovative) in the Data-Centric AI competition only with the provided dataset.",
    "descriptor": "\nComments: Data Centric AI Workshop at NeurIPS 2021\n",
    "authors": [
      "Youngjune Lee",
      "Oh Joon Kwon",
      "Haeju Lee",
      "Joonyoung Kim",
      "Kangwook Lee",
      "Kee-Eung Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03837"
  },
  {
    "id": "arXiv:2112.03839",
    "title": "Stupid, Evil, or Both? Understanding the Smittestopp conflict",
    "abstract": "Like many governments, the Norwegian government provided a contact tracing\napplication to help in combating the COVID-19 pandemic at its outset. However,\nthe application was widely criticized for enabling an unacceptable intrusion\ninto its subjects' lives, leading to its discontinuation only four months into\nthe pandemic. In this essay, we will take a closer look at what went wrong,\nattempt to gain a deeper understanding of the passionate nature of the\nconflict, and how both sides came to view the other as being either stupid, or\nevil, or both.",
    "descriptor": "\nComments: Accepted for publication at the 14th Norwegian Information Security Conference (NISK 2021). 9 pages, 3 figures\n",
    "authors": [
      "Hans Heum"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.03839"
  },
  {
    "id": "arXiv:2112.03842",
    "title": "A Survey on Intrinsic Images: Delving Deep Into Lambert and Beyond",
    "abstract": "Intrinsic imaging or intrinsic image decomposition has traditionally been\ndescribed as the problem of decomposing an image into two layers: a\nreflectance, the albedo invariant color of the material; and a shading,\nproduced by the interaction between light and geometry. Deep learning\ntechniques have been broadly applied in recent years to increase the accuracy\nof those separations. In this survey, we overview those results in context of\nwell-known intrinsic image data sets and relevant metrics used in the\nliterature, discussing their suitability to predict a desirable intrinsic image\ndecomposition. Although the Lambertian assumption is still a foundational basis\nfor many methods, we show that there is increasing awareness on the potential\nof more sophisticated physically-principled components of the image formation\nprocess, that is, optically accurate material models and geometry, and more\ncomplete inverse light transport estimations. We classify these methods in\nterms of the type of decomposition, considering the priors and models used, as\nwell as the learning architecture and methodology driving the decomposition\nprocess. We also provide insights about future directions for research, given\nthe recent advances in neural, inverse and differentiable rendering techniques.",
    "descriptor": "\nComments: Accepted at International Journal of Computer Vision (to appear in 2022) this http URL\n",
    "authors": [
      "Elena Garces",
      "Carlos Rodriguez-Pardo",
      "Dan Casas",
      "Jorge Lopez-Moreno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03842"
  },
  {
    "id": "arXiv:2112.03849",
    "title": "Natural Answer Generation: From Factoid Answer to Full-length Answer  using Grammar Correction",
    "abstract": "Question Answering systems these days typically use template-based language\ngeneration. Though adequate for a domain-specific task, these systems are too\nrestrictive and predefined for domain-independent systems. This paper proposes\na system that outputs a full-length answer given a question and the extracted\nfactoid answer (short spans such as named entities) as the input. Our system\nuses constituency and dependency parse trees of questions. A transformer-based\nGrammar Error Correction model GECToR (2020), is used as a post-processing step\nfor better fluency. We compare our system with (i) Modified Pointer Generator\n(SOTA) and (ii) Fine-tuned DialoGPT for factoid questions. We also test our\napproach on existential (yes-no) questions with better results. Our model\ngenerates accurate and fluent answers than the state-of-the-art (SOTA)\napproaches. The evaluation is done on NewsQA and SqUAD datasets with an\nincrement of 0.4 and 0.9 percentage points in ROUGE-1 score respectively. Also\nthe inference time is reduced by 85\\% as compared to the SOTA. The improved\ndatasets used for our evaluation will be released as part of the research\ncontribution.",
    "descriptor": "",
    "authors": [
      "Manas Jain",
      "Sriparna Saha",
      "Pushpak Bhattacharyya",
      "Gladvin Chinnadurai",
      "Manish Kumar Vatsa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03849"
  },
  {
    "id": "arXiv:2112.03850",
    "title": "Policy Search for Model Predictive Control with Application to Agile  Drone Flight",
    "abstract": "Policy Search and Model Predictive Control~(MPC) are two different paradigms\nfor robot control: policy search has the strength of automatically learning\ncomplex policies using experienced data, while MPC can offer optimal control\nperformance using models and trajectory optimization. An open research question\nis how to leverage and combine the advantages of both approaches. In this work,\nwe provide an answer by using policy search for automatically choosing\nhigh-level decision variables for MPC, which leads to a novel\npolicy-search-for-model-predictive-control framework. Specifically, we\nformulate the MPC as a parameterized controller, where the hard-to-optimize\ndecision variables are represented as high-level policies. Such a formulation\nallows optimizing policies in a self-supervised fashion. We validate this\nframework by focusing on a challenging problem in agile drone flight: flying a\nquadrotor through fast-moving gates. Experiments show that our controller\nachieves robust and real-time control performance in both simulation and the\nreal world. The proposed framework offers a new perspective for merging\nlearning and control.",
    "descriptor": "\nComments: This paper is currently under review TRO\n",
    "authors": [
      "Yunlong Song",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03850"
  },
  {
    "id": "arXiv:2112.03851",
    "title": "Stochastic Optimized Schwarz Methods for the Gravity Equations on  Graphics Processing Unit",
    "abstract": "Low order, sequential or non-massively parallel finite elements are generaly\nused for three-dimensional gravity modelling. In this paper, in order to obtain\nbetter gravity anomaly solutions in heterogeneous media, we solve the\ngravimetry problem using massively parallel high order finite elements on\nhybrid multi-CPU/GPU clusters. Parallel algorithms well suited for such hybrid\narchitectures have to be designed. A new stochastic-based optimization\nprocedure for the optimized Schwarz method is here presented, implemented and\ntuned to graphical cards processors units. Numerical experiments performed on a\nreallistic test case, demonstrates the robustness and efficiency of the\nproposed method and of its implementation on massive multi-CPU/GPU\narchitectures.",
    "descriptor": "",
    "authors": [
      "Abal-Kassim Cheik Ahamed",
      "Frederic Magoules"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.03851"
  },
  {
    "id": "arXiv:2112.03857",
    "title": "Grounded Language-Image Pre-training",
    "abstract": "This paper presents a grounded language-image pre-training (GLIP) model for\nlearning object-level, language-aware, and semantic-rich visual\nrepresentations. GLIP unifies object detection and phrase grounding for\npre-training. The unification brings two benefits: 1) it allows GLIP to learn\nfrom both detection and grounding data to improve both tasks and bootstrap a\ngood grounding model; 2) GLIP can leverage massive image-text pairs by\ngenerating grounding boxes in a self-training fashion, making the learned\nrepresentation semantic-rich. In our experiments, we pre-train GLIP on 27M\ngrounding data, including 3M human-annotated and 24M web-crawled image-text\npairs. The learned representations demonstrate strong zero-shot and few-shot\ntransferability to various object-level recognition tasks. 1) When directly\nevaluated on COCO and LVIS (without seeing any images in COCO during\npre-training), GLIP achieves 49.8 AP and 26.9 AP, respectively, surpassing many\nsupervised baselines. 2) After fine-tuned on COCO, GLIP achieves 60.8 AP on val\nand 61.5 AP on test-dev, surpassing prior SoTA. 3) When transferred to 13\ndownstream object detection tasks, a 1-shot GLIP rivals with a fully-supervised\nDynamic Head. Code will be released at https://github.com/microsoft/GLIP.",
    "descriptor": "\nComments: Code will be released at this https URL\n",
    "authors": [
      "Liunian Harold Li",
      "Pengchuan Zhang",
      "Haotian Zhang",
      "Jianwei Yang",
      "Chunyuan Li",
      "Yiwu Zhong",
      "Lijuan Wang",
      "Lu Yuan",
      "Lei Zhang",
      "Jenq-Neng Hwang",
      "Kai-Wei Chang",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.03857"
  },
  {
    "id": "arXiv:2112.03858",
    "title": "Reducing Target Group Bias in Hate Speech Detectors",
    "abstract": "The ubiquity of offensive and hateful content on online fora necessitates the\nneed for automatic solutions that detect such content competently across target\ngroups. In this paper we show that text classification models trained on large\npublicly available datasets despite having a high overall performance, may\nsignificantly under-perform on several protected groups. On the\n\\citet{vidgen2020learning} dataset, we find the accuracy to be 37\\% lower on an\nunder annotated Black Women target group and 12\\% lower on Immigrants, where\nhate speech involves a distinct style. To address this, we propose to perform\ntoken-level hate sense disambiguation, and utilize tokens' hate sense\nrepresentations for detection, modeling more general signals. On two publicly\navailable datasets, we observe that the variance in model accuracy across\ntarget groups drops by at least 30\\%, improving the average target group\nperformance by 4\\% and worst case performance by 13\\%.",
    "descriptor": "",
    "authors": [
      "Darsh J Shah",
      "Sinong Wang",
      "Han Fang",
      "Hao Ma",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03858"
  },
  {
    "id": "arXiv:2112.03860",
    "title": "Traversing within the Gaussian Typical Set: Differentiable  Gaussianization Layers for Inverse Problems Augmented by Normalizing Flows",
    "abstract": "Generative networks such as normalizing flows can serve as a learning-based\nprior to augment inverse problems to achieve high-quality results. However, the\nlatent space vector may not remain a typical sample from the desired\nhigh-dimensional standard Gaussian distribution when traversing the latent\nspace during an inversion. As a result, it can be challenging to attain a\nhigh-fidelity solution, particularly in the presence of noise and inaccurate\nphysics-based models. To address this issue, we propose to re-parameterize and\nGaussianize the latent vector using novel differentiable data-dependent layers\nwherein custom operators are defined by solving optimization problems. These\nproposed layers enforce an inversion to find a feasible solution within a\nGaussian typical set of the latent space. We tested and validated our technique\non an image deblurring task and eikonal tomography -- a PDE-constrained inverse\nproblem and achieved high-fidelity results.",
    "descriptor": "\nComments: 16 pages, 12 figures\n",
    "authors": [
      "Dongzhuo Li",
      "Huseyin Denli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03860"
  },
  {
    "id": "arXiv:2112.03865",
    "title": "Universalizing Weak Supervision",
    "abstract": "Weak supervision (WS) frameworks are a popular way to bypass hand-labeling\nlarge datasets for training data-hungry models. These approaches synthesize\nmultiple noisy but cheaply-acquired estimates of labels into a set of\nhigh-quality pseudolabels for downstream training. However, the synthesis\ntechnique is specific to a particular kind of label, such as binary labels or\nsequences, and each new label type requires manually designing a new synthesis\nalgorithm. Instead, we propose a universal technique that enables weak\nsupervision over any label type while still offering desirable properties,\nincluding practical flexibility, computational efficiency, and theoretical\nguarantees. We apply this technique to important problems previously not\ntackled by WS frameworks including learning to rank, regression, and learning\nin hyperbolic manifolds. Theoretically, our synthesis approach produces a\nconsistent estimator for learning a challenging but important generalization of\nthe exponential family model. Experimentally, we validate our framework and\nshow improvement over baselines in diverse settings including real-world\nlearning-to-rank and regression problems along with learning on hyperbolic\nmanifolds.",
    "descriptor": "",
    "authors": [
      "Changho Shin",
      "Winfred Li",
      "Harit Vishwakarma",
      "Nicholas Roberts",
      "Frederic Sala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03865"
  },
  {
    "id": "arXiv:2112.03867",
    "title": "Towards a Shared Rubric for Dataset Annotation",
    "abstract": "When arranging for third-party data annotation, it can be hard to compare how\nwell the competing providers apply best practices to create high-quality\ndatasets. This leads to a \"race to the bottom,\" where competition based solely\non price makes it hard for vendors to charge for high-quality annotation. We\npropose a voluntary rubric which can be used (a) as a scorecard to compare\nvendors' offerings, (b) to communicate our expectations of the vendors more\nclearly and consistently than today, (c) to justify the expense of choosing\nsomeone other than the lowest bidder, and (d) to encourage annotation providers\nto improve their practices.",
    "descriptor": "\nComments: 4 pages. To be presented at the Data-Centric AI Workshop at NeurIPS 2021\n",
    "authors": [
      "Andrew Marc Greene"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03867"
  },
  {
    "id": "arXiv:2112.03877",
    "title": "Is Complexity Important for Philosophy of Mind?",
    "abstract": "Computational complexity has often been ignored in philosophy of mind, in\nphilosophical artificial intelligence studies. The purpose of this paper is\nthreefold. First and foremost, to show the importance of complexity rather than\ncomputability in philosophical and AI problems. Second, to rephrase the notion\nof computability in terms of solvability, i.e. treating computability as\nnon-sufficient for establishing intelligence. The Church-Turing thesis is\ntherefore revisited and rephrased in order to capture the ontological\nbackground of spatial and temporal complexity. Third, to emphasize ontological\ndifferences between different time complexities, which seem to provide a solid\nbase towards better understanding of artificial intelligence in general.",
    "descriptor": "",
    "authors": [
      "Kristina \u0160ekrst",
      "Sandro Skansi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03877"
  },
  {
    "id": "arXiv:2112.03879",
    "title": "Datensouver\u00e4nit\u00e4t f\u00fcr Verbraucher:innen: Technische Ans\u00e4tze  durch KI-basierte Transparenz und Auskunft im Kontext der DSGVO",
    "abstract": "A sufficient level of data sovereignty is extremely difficult for consumers\nin practice. The EU General Data Protection Regulation guarantees comprehensive\ndata subject rights, which must be implemented by responsible controllers\nthrough technical and organizational measures. Traditional approaches, such as\nthe provision of lengthy data protection declarations or the downloading of raw\npersonal data without further assistance, do not meet the requirements of\ninformational self-determination. The new technical approaches outlined below,\nin particular AI-based transparency and access modalities, demonstrate the\npracticability of effective and versatile mechanisms. For this purpose, the\nrelevant transparency information is extracted in a semi-automated way,\nrepresented in a machine-readable format, and then played out via diverse\nchannels such as virtual assistants or the enrichment of search results.\n---\nHinreichende Datensouver\\\"anit\\\"at gestaltet sich f\\\"ur Verbraucher:innen in\nder Praxis als \\\"au{\\ss}erst schwierig. Die Europ\\\"aische\nDatenschutzgrundverordnung garantiert umfassende Betroffenenrechte, die von\nverantwortlichen Stellen durch technisch-organisatorische Ma{\\ss}nahmen\numzusetzen sind. Traditionelle Vorgehensweisen wie die Bereitstellung\nl\\\"anglicher Datenschutzerkl\\\"arungen oder der ohne weitere Hilfestellungen\nangebotene Download von personenbezogenen Rohdaten werden dem Anspruch der\ninformationellen Selbstbestimmung nicht gerecht. Die im Folgenden aufgezeigten\nneuen technischen Ans\\\"atze insbesondere KI-basierter Transparenz- und\nAuskunftsmodalit\\\"aten zeigen die Praktikabilit\\\"at wirksamer und vielseitiger\nMechanismen. Hierzu werden die relevanten Transparenzangaben teilautomatisiert\nextrahiert, maschinenlesbar repr\\\"asentiert und anschlie{\\ss}end \\\"uber diverse\nKan\\\"ale wie virtuelle Assistenten oder die Anreicherung von Suchergebnissen\nausgespielt.",
    "descriptor": "\nComments: In German, appears in \"Schriften der Verbraucherinformatik 2021\". Original publication: this https URL\n",
    "authors": [
      "Elias Gr\u00fcnewald",
      "Frank Pallas"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.03879"
  },
  {
    "id": "arXiv:2112.03882",
    "title": "From Assistants to Friends: Investigating Emotional Intelligence of IPAs  in Hindi and English",
    "abstract": "Intelligent Personal Assistants (IPAs) like Amazon Alexa, Apple Siri, and\nGoogle Assistant are increasingly becoming a part of our everyday. As IPAs\nbecome ubiquitous and their applications expand, users turn to them for not\njust routine tasks, but also intelligent conversations. In this study, we\nmeasure the emotional intelligence (EI) displayed by IPAs in the English and\nHindi languages; to our knowledge, this is a pioneering effort in probing the\nemotional intelligence of IPAs in Indian languages. We pose utterances that\nconvey the Sadness or Humor emotion and evaluate IPA responses. We build on\nprevious research to propose a quantitative and qualitative evaluation scheme\nencompassing new criteria from social science perspectives (display of empathy,\nwit, understanding) and IPA-specific features (voice modulation, search\nredirects).\nWe find EI displayed by Google Assistant in Hindi is comparable to EI\ndisplayed in English, with the assistant employing both voice modulation and\nemojis in text. However, we do find that IPAs are unable to understand and\nrespond intelligently to all queries, sometimes even offering\ncounter-productive and problematic responses. Our experiment offers evidence\nand directions to augment the potential for EI in IPAs.",
    "descriptor": "\nComments: 6 pages, 2 figures, 2 tables, Verbal Presentation at IndiaHCI 2021\n",
    "authors": [
      "Mallika Subramanian",
      "Shradha Sehgal",
      "Nimmi Rangaswamy"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.03882"
  },
  {
    "id": "arXiv:2112.03896",
    "title": "Gradient and Projection Free Distributed Online Min-Max Resource  Optimization",
    "abstract": "We consider distributed online min-max resource allocation with a set of\nparallel agents and a parameter server. Our goal is to minimize the pointwise\nmaximum over a set of time-varying convex and decreasing cost functions,\nwithout a priori information about these functions. We propose a novel online\nalgorithm, termed Distributed Online resource Re-Allocation (DORA), where\nnon-stragglers learn to relinquish resource and share resource with stragglers.\nA notable feature of DORA is that it does not require gradient calculation or\nprojection operation, unlike most existing online optimization strategies. This\nallows it to substantially reduce the computation overhead in large-scale and\ndistributed networks. We show that the dynamic regret of the proposed algorithm\nis upper bounded by $O\\left(T^{\\frac{3}{4}}(1+P_T)^{\\frac{1}{4}}\\right)$, where\n$T$ is the total number of rounds and $P_T$ is the path-length of the\ninstantaneous minimizers. We further consider an application to the bandwidth\nallocation problem in distributed online machine learning. Our numerical study\ndemonstrates the efficacy of the proposed solution and its performance\nadvantage over gradient- and/or projection-based resource allocation algorithms\nin reducing wall-clock time.",
    "descriptor": "",
    "authors": [
      "Jingrong Wang",
      "Ben Liang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.03896"
  },
  {
    "id": "arXiv:2112.03898",
    "title": "Lattice-Based Methods Surpass Sum-of-Squares in Clustering",
    "abstract": "Clustering is a fundamental primitive in unsupervised learning which gives\nrise to a rich class of computationally-challenging inference tasks. In this\nwork, we focus on the canonical task of clustering $d$-dimensional Gaussian\nmixtures with unknown (and possibly degenerate) covariance. Recent works (Ghosh\net al.\\ '20; Mao, Wein '21; Davis, Diaz, Wang '21) have established lower\nbounds against the class of low-degree polynomial methods and the\nsum-of-squares (SoS) hierarchy for recovering certain hidden structures planted\nin Gaussian clustering instances. Prior work on many similar inference tasks\nportends that such lower bounds strongly suggest the presence of an inherent\nstatistical-to-computational gap for clustering, that is, a parameter regime\nwhere the clustering task is \\textit{statistically} possible but no\n\\textit{polynomial-time} algorithm succeeds.\nOne special case of the clustering task we consider is equivalent to the\nproblem of finding a planted hypercube vector in an otherwise random subspace.\nWe show that, perhaps surprisingly, this particular clustering model\n\\textit{does not exhibit} a statistical-to-computational gap, even though the\naforementioned low-degree and SoS lower bounds continue to apply in this case.\nTo achieve this, we give a polynomial-time algorithm based on the\nLenstra--Lenstra--Lovasz lattice basis reduction method which achieves the\nstatistically-optimal sample complexity of $d+1$ samples. This result extends\nthe class of problems whose conjectured statistical-to-computational gaps can\nbe \"closed\" by \"brittle\" polynomial-time algorithms, highlighting the crucial\nbut subtle role of noise in the onset of statistical-to-computational gaps.",
    "descriptor": "",
    "authors": [
      "Ilias Zadik",
      "Min Jae Song",
      "Alexander S. Wein",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03898"
  },
  {
    "id": "arXiv:2112.03899",
    "title": "Information is Power: Intrinsic Control via Information Capture",
    "abstract": "Humans and animals explore their environment and acquire useful skills even\nin the absence of clear goals, exhibiting intrinsic motivation. The study of\nintrinsic motivation in artificial agents is concerned with the following\nquestion: what is a good general-purpose objective for an agent? We study this\nquestion in dynamic partially-observed environments, and argue that a compact\nand general learning objective is to minimize the entropy of the agent's state\nvisitation estimated using a latent state-space model. This objective induces\nan agent to both gather information about its environment, corresponding to\nreducing uncertainty, and to gain control over its environment, corresponding\nto reducing the unpredictability of future world states. We instantiate this\napproach as a deep reinforcement learning agent equipped with a deep\nvariational Bayes filter. We find that our agent learns to discover, represent,\nand exercise control of dynamic objects in a variety of partially-observed\nenvironments sensed with visual observations without extrinsic reward.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Nicholas Rhinehart",
      "Jenny Wang",
      "Glen Berseth",
      "John D. Co-Reyes",
      "Danijar Hafner",
      "Chelsea Finn",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03899"
  },
  {
    "id": "arXiv:2112.03902",
    "title": "MS-TCT: Multi-Scale Temporal ConvTransformer for Action Detection",
    "abstract": "Action detection is an essential and challenging task, especially for densely\nlabelled datasets of untrimmed videos. The temporal relation is complex in\nthose datasets, including challenges like composite action, and co-occurring\naction. For detecting actions in those complex videos, efficiently capturing\nboth short-term and long-term temporal information in the video is critical. To\nthis end, we propose a novel ConvTransformer network for action detection. This\nnetwork comprises three main components: (1) Temporal Encoder module\nextensively explores global and local temporal relations at multiple temporal\nresolutions. (2) Temporal Scale Mixer module effectively fuses the multi-scale\nfeatures to have a unified feature representation. (3) Classification module is\nused to learn the instance center-relative position and predict the frame-level\nclassification scores. The extensive experiments on multiple datasets,\nincluding Charades, TSU and MultiTHUMOS, confirm the effectiveness of our\nproposed method. Our network outperforms the state-of-the-art methods on all\nthree datasets.",
    "descriptor": "",
    "authors": [
      "Rui Dai",
      "Srijan Das",
      "Kumara Kahatapitiya",
      "Michael S. Ryoo",
      "Francois Bremond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03902"
  },
  {
    "id": "arXiv:2112.03903",
    "title": "Improved a priori error estimates for a discontinuous Galerkin pressure  correction scheme for the Navier-Stokes equations",
    "abstract": "The pressure correction scheme is combined with interior penalty\ndiscontinuous Galerkin method to solve the time-dependent Navier-Stokes\nequations. Optimal error estimates are derived for the velocity in the L$^2$\nnorm in time and in space. Error bounds for the discrete time derivative of the\nvelocity and for the pressure are also established.",
    "descriptor": "",
    "authors": [
      "Rami Masri",
      "Chen Liu",
      "Beatrice Riviere"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.03903"
  },
  {
    "id": "arXiv:2112.03905",
    "title": "ViewCLR: Learning Self-supervised Video Representation for Unseen  Viewpoints",
    "abstract": "Learning self-supervised video representation predominantly focuses on\ndiscriminating instances generated from simple data augmentation schemes.\nHowever, the learned representation often fails to generalize over unseen\ncamera viewpoints. To this end, we propose ViewCLR, that learns self-supervised\nvideo representation invariant to camera viewpoint changes. We introduce a\nview-generator that can be considered as a learnable augmentation for any\nself-supervised pre-text tasks, to generate latent viewpoint representation of\na video. ViewCLR maximizes the similarities between the latent viewpoint\nrepresentation with its representation from the original viewpoint, enabling\nthe learned video encoder to generalize over unseen camera viewpoints.\nExperiments on cross-view benchmark datasets including NTU RGB+D dataset show\nthat ViewCLR stands as a state-of-the-art viewpoint invariant self-supervised\nmethod.",
    "descriptor": "\nComments: 13 pages, Codes and models will updated soon\n",
    "authors": [
      "Srijan Das",
      "Michael S. Ryoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03905"
  },
  {
    "id": "arXiv:2112.03906",
    "title": "STC-mix: Space, Time, Channel mixing for Self-supervised Video  Representation",
    "abstract": "Contrastive representation learning of videos highly relies on the\navailability of millions of unlabelled videos. This is practical for videos\navailable on web but acquiring such large scale of videos for real-world\napplications is very expensive and laborious. Therefore, in this paper we focus\non designing video augmentation for self-supervised learning, we first analyze\nthe best strategy to mix videos to create a new augmented video sample. Then,\nthe question remains, can we make use of the other modalities in videos for\ndata mixing? To this end, we propose Cross-Modal Manifold Cutmix (CMMC) that\ninserts a video tesseract into another video tesseract in the feature space\nacross two different modalities. We find that our video mixing strategy\nSTC-mix, i.e. preliminary mixing of videos followed by CMMC across different\nmodalities in a video, improves the quality of learned video representations.\nWe conduct thorough experiments for two downstream tasks: action recognition\nand video retrieval on two small scale video datasets UCF101, and HMDB51. We\nalso demonstrate the effectiveness of our STC-mix on NTU dataset where domain\nknowledge is limited. We show that the performance of our STC-mix on both the\ndownstream tasks is on par with the other self-supervised approaches while\nrequiring less training data.",
    "descriptor": "\nComments: 12 pages, codes and model links will be updated soon\n",
    "authors": [
      "Srijan Das",
      "Michael S. Ryoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03906"
  },
  {
    "id": "arXiv:2112.03907",
    "title": "Ref-NeRF: Structured View-Dependent Appearance for Neural Radiance  Fields",
    "abstract": "Neural Radiance Fields (NeRF) is a popular view synthesis technique that\nrepresents a scene as a continuous volumetric function, parameterized by\nmultilayer perceptrons that provide the volume density and view-dependent\nemitted radiance at each location. While NeRF-based techniques excel at\nrepresenting fine geometric structures with smoothly varying view-dependent\nappearance, they often fail to accurately capture and reproduce the appearance\nof glossy surfaces. We address this limitation by introducing Ref-NeRF, which\nreplaces NeRF's parameterization of view-dependent outgoing radiance with a\nrepresentation of reflected radiance and structures this function using a\ncollection of spatially-varying scene properties. We show that together with a\nregularizer on normal vectors, our model significantly improves the realism and\naccuracy of specular reflections. Furthermore, we show that our model's\ninternal representation of outgoing radiance is interpretable and useful for\nscene editing.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Dor Verbin",
      "Peter Hedman",
      "Ben Mildenhall",
      "Todd Zickler",
      "Jonathan T. Barron",
      "Pratul P. Srinivasan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.03907"
  },
  {
    "id": "arXiv:2112.03908",
    "title": "Causal Imitative Model for Autonomous Driving",
    "abstract": "Imitation learning is a powerful approach for learning autonomous driving\npolicy by leveraging data from expert driver demonstrations. However, driving\npolicies trained via imitation learning that neglect the causal structure of\nexpert demonstrations yield two undesirable behaviors: inertia and collision.\nIn this paper, we propose Causal Imitative Model (CIM) to address inertia and\ncollision problems. CIM explicitly discovers the causal model and utilizes it\nto train the policy. Specifically, CIM disentangles the input to a set of\nlatent variables, selects the causal variables, and determines the next\nposition by leveraging the selected variables. Our experiments show that our\nmethod outperforms previous work in terms of inertia and collision rates.\nMoreover, thanks to exploiting the causal structure, CIM shrinks the input\ndimension to only two, hence, can adapt to new environments in a few-shot\nsetting. Code is available at https://github.com/vita-epfl/CIM.",
    "descriptor": "",
    "authors": [
      "Mohammad Reza Samsami",
      "Mohammadhossein Bahari",
      "Saber Salehkaleybar",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03908"
  },
  {
    "id": "arXiv:2112.03909",
    "title": "Vehicle trajectory prediction works, but not everywhere",
    "abstract": "Vehicle trajectory prediction is nowadays a fundamental pillar of\nself-driving cars. Both the industry and research communities have acknowledged\nthe need for such a pillar by running public benchmarks. While state-of-the-art\nmethods are impressive, i.e., they have no off-road prediction, their\ngeneralization to cities outside of the benchmark is unknown. In this work, we\nshow that those methods do not generalize to new scenes. We present a novel\nmethod that automatically generates realistic scenes that cause\nstate-of-the-art models go off-road. We frame the problem through the lens of\nadversarial scene generation. We promote a simple yet effective generative\nmodel based on atomic scene generation functions along with physical\nconstraints. Our experiments show that more than $60\\%$ of the existing scenes\nfrom the current benchmarks can be modified in a way to make prediction methods\nfail (predicting off-road). We further show that (i) the generated scenes are\nrealistic since they do exist in the real world, and (ii) can be used to make\nexisting models robust by 30-40%. Code is available at\nhttps://s-attack.github.io/.",
    "descriptor": "",
    "authors": [
      "Mohammadhossein Bahari",
      "Saeed Saadatnejad",
      "Ahmad Rahimi",
      "Mohammad Shaverdikondori",
      "Mohammad Shahidzadeh",
      "Seyed-Mohsen Moosavi-Dezfooli",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03909"
  },
  {
    "id": "arXiv:2112.03261",
    "title": "Modeling Demand Flexibility of RES-based Virtual Power Plants",
    "abstract": "In this paper, an approach to evaluate the benefits of demand flexibility for\nVirtual Power Plants (VPPs) is presented. The flexible demands chosen in this\nstudy are part of a renewable energy source-based VPP that participates in\nDay-Ahead Market (DAM) and Intra-Day Market (IDM) and has dispatchable and\nnon-dispatchable assets. A demand model with bi-level flexibility is proposed:\nthe first level is associated with DAM, whereas the second level is related to\nIDM sessions. Simulations are carried out considering a 12-node network to\nascertain the eventual impacts of modeling demand flexibility on VPP operation.\nThe market structure considered in the case study resembles the different\ntrading floors in the Spanish electricity market. Results obtained show that\nthe proposed demand flexibility scheme increases the overall profit of the VPP,\nas well as the revenues of the demand owners without disrupting consumers'\ncomfort.",
    "descriptor": "\nComments: 5 pages, 5 figures, conference. arXiv admin note: substantial text overlap with arXiv:2112.02200\n",
    "authors": [
      "Oluwaseun Oladimeji",
      "Alvaro Ortega",
      "Lukas Sigrist",
      "Pedro Sanchez-Martin",
      "Enrique Lobato",
      "Luis Rouco"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03261"
  },
  {
    "id": "arXiv:2112.03266",
    "title": "Contrastive Cycle Adversarial Autoencoders for Single-cell Multi-omics  Alignment and Integration",
    "abstract": "Muilti-modality data are ubiquitous in biology, especially that we have\nentered the multi-omics era, when we can measure the same biological object\n(cell) from different aspects (omics) to provide a more comprehensive insight\ninto the cellular system. When dealing with such multi-omics data, the first\nstep is to determine the correspondence among different modalities. In other\nwords, we should match data from different spaces corresponding to the same\nobject. This problem is particularly challenging in the single-cell multi-omics\nscenario because such data are very sparse with extremely high dimensions.\nSecondly, matched single-cell multi-omics data are rare and hard to collect.\nFurthermore, due to the limitations of the experimental environment, the data\nare usually highly noisy. To promote the single-cell multi-omics research, we\novercome the above challenges, proposing a novel framework to align and\nintegrate single-cell RNA-seq data and single-cell ATAC-seq data. Our approach\ncan efficiently map the above data with high sparsity and noise from different\nspaces to a low-dimensional manifold in a unified space, making the downstream\nalignment and integration straightforward. Compared with the other\nstate-of-the-art methods, our method performs better in both simulated and real\nsingle-cell data. The proposed method is helpful for the single-cell\nmulti-omics research. The improvement for integration on the simulated data is\nsignificant.",
    "descriptor": "",
    "authors": [
      "Xuesong Wang",
      "Zhihang Hu",
      "Tingyang Yu",
      "Ruijie Wang",
      "Yumeng Wei",
      "Juan Shu",
      "Jianzhu Ma",
      "Yu Li"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03266"
  },
  {
    "id": "arXiv:2112.03276",
    "title": "Organ localisation using supervised and semi supervised approaches  combining reinforcement learning with imitation learning",
    "abstract": "Computer aided diagnostics often requires analysis of a region of interest\n(ROI) within a radiology scan, and the ROI may be an organ or a suborgan.\nAlthough deep learning algorithms have the ability to outperform other methods,\nthey rely on the availability of a large amount of annotated data. Motivated by\nthe need to address this limitation, an approach to localisation and detection\nof multiple organs based on supervised and semi-supervised learning is\npresented here. It draws upon previous work by the authors on localising the\nthoracic and lumbar spine region in CT images. The method generates six\nbounding boxes of organs of interest, which are then fused to a single bounding\nbox. The results of experiments on localisation of the Spleen, Left and Right\nKidneys in CT Images using supervised and semi supervised learning (SSL)\ndemonstrate the ability to address data limitations with a much smaller data\nset and fewer annotations, compared to other state-of-the-art methods. The SSL\nperformance was evaluated using three different mixes of labelled and\nunlabelled data (i.e.30:70,35:65,40:60) for each of lumbar spine, spleen left\nand right kidneys respectively. The results indicate that SSL provides a\nworkable alternative especially in medical imaging where it is difficult to\nobtain annotated data.",
    "descriptor": "\nComments: 16 pages, 12 figures\n",
    "authors": [
      "Sankaran Iyer",
      "Alan Blair",
      "Laughlin Dawes",
      "Daniel Moses",
      "Christopher White",
      "Arcot Sowmya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03276"
  },
  {
    "id": "arXiv:2112.03277",
    "title": "Quality control for more reliable integration of deep learning-based  image segmentation into medical workflows",
    "abstract": "Machine learning algorithms underpin modern diagnostic-aiding software, which\nhas proved valuable in clinical practice, particularly in radiology. However,\ninaccuracies, mainly due to the limited availability of clinical samples for\ntraining these algorithms, hamper their wider applicability, acceptance, and\nrecognition amongst clinicians. We present an analysis of state-of-the-art\nautomatic quality control (QC) approaches that can be implemented within these\nalgorithms to estimate the certainty of their outputs. We validated the most\npromising approaches on a brain image segmentation task identifying white\nmatter hyperintensities (WMH) in magnetic resonance imaging data. WMH are a\ncorrelate of small vessel disease common in mid-to-late adulthood and are\nparticularly challenging to segment due to their varied size, and\ndistributional patterns. Our results show that the aggregation of uncertainty\nand Dice prediction were most effective in failure detection for this task.\nBoth methods independently improved mean Dice from 0.82 to 0.84. Our work\nreveals how QC methods can help to detect failed segmentation cases and\ntherefore make automatic segmentation more reliable and suitable for clinical\npractice.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Elena Williams",
      "Sebastian Niehaus",
      "Janis Reinelt",
      "Alberto Merola",
      "Paul Glad Mihai",
      "Ingo Roeder",
      "Nico Scherf",
      "Maria del C. Vald\u00e9s Hern\u00e1ndez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03277"
  },
  {
    "id": "arXiv:2112.03298",
    "title": "Automation Of Transiting Exoplanet Detection, Identification and  Habitability Assessment Using Machine Learning Approaches",
    "abstract": "We are at a unique timeline in the history of human evolution where we may be\nable to discover earth-like planets around stars outside our solar system where\nconditions can support life or even find evidence of life on those planets.\nWith the launch of several satellites in recent years by NASA, ESA, and other\nmajor space agencies, an ample amount of datasets are at our disposal which can\nbe utilized to train machine learning models that can automate the arduous\ntasks of exoplanet detection, its identification, and habitability\ndetermination. Automating these tasks can save a considerable amount of time\nand minimize human errors due to manual intervention. To achieve this aim, we\nfirst analyze the light intensity curves from stars captured by the Kepler\ntelescope to detect the potential curves that exhibit the characteristics of an\nexistence of a possible planetary system. For this detection, along with\ntraining conventional models, we propose a stacked GBDT model that can be\ntrained on multiple representations of the light signals simultaneously.\nSubsequently, we address the automation of exoplanet identification and\nhabitability determination by leveraging several state-of-art machine learning\nand ensemble approaches. The identification of exoplanets aims to distinguish\nfalse positive instances from the actual instances of exoplanets whereas the\nhabitability assessment groups the exoplanet instances into different clusters\nbased on their habitable characteristics. Additionally, we propose a new metric\ncalled Adequate Thermal Adequacy (ATA) score to establish a potential linear\nrelationship between habitable and non-habitable instances. Experimental\nresults suggest that the proposed stacked GBDT model outperformed the\nconventional models in detecting transiting exoplanets. Furthermore, the\nincorporation of ATA scores in habitability classification enhanced the\nperformance of models.",
    "descriptor": "\nComments: 19 pages, 21 figures\n",
    "authors": [
      "Pawel Pratyush",
      "Akshata Gangrade"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03298"
  },
  {
    "id": "arXiv:2112.03348",
    "title": "Grain segmentation in atomistic simulations using orientation-based  iterative self-organizing data analysis",
    "abstract": "Atomistic simulations have now established themselves as an indispensable\ntool in understanding deformation mechanisms of materials at the atomic scale.\nLarge scale simulations are regularly used to study the behavior of\npolycrystalline materials at the nanoscale. In this work, we propose a method\nfor grain segmentation of an atomistic configuration using an unsupervised\nmachine learning algorithm that clusters atoms into individual grains based on\ntheir orientation. The proposed method, called the Orisodata algorithm, is\nbased on the iterative self-organizing data analysis technique and is modified\nto work in the orientation space. The working of the algorithm is demonstrated\non a 122 grain nanocrystalline thin film sample in both undeformed and deformed\nstates. The Orisodata algorithm is also compared with two other grain\nsegmentation algorithms available in the open-source visualization tool Ovito.\nThe results show that the Orisodata algorithm is able to correctly identify\ndeformation twins as well as regions separated by low angle grain boundaries.\nThe model parameters have intuitive physical meaning and relate to similar\nthresholds used in experiments, which not only helps obtain optimal values but\nalso facilitates easy interpretation and validation of results.",
    "descriptor": "\nComments: 40 pages, 8 figures, 9 supplementary figures\n",
    "authors": [
      "M. Vimal",
      "S. Sandfeld",
      "A. Prakash"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03348"
  },
  {
    "id": "arXiv:2112.03380",
    "title": "Dynamic imaging using Motion-Compensated SmooThness Regularization on  Manifolds (MoCo-SToRM)",
    "abstract": "We introduce an unsupervised motion-compensated reconstruction scheme for\nhigh-resolution free-breathing pulmonary MRI. We model the image frames in the\ntime series as the deformed version of the 3D template image volume. We assume\nthe deformation maps to be points on a smooth manifold in high-dimensional\nspace. Specifically, we model the deformation map at each time instant as the\noutput of a CNN-based generator that has the same weight for all time-frames,\ndriven by a low-dimensional latent vector. The time series of latent vectors\naccount for the dynamics in the dataset, including respiratory motion and bulk\nmotion. The template image volume, the parameters of the generator, and the\nlatent vectors are learned directly from the k-t space data in an unsupervised\nfashion. Our experimental results show improved reconstructions compared to\nstate-of-the-art methods, especially in the context of bulk motion during the\nscans.",
    "descriptor": "",
    "authors": [
      "Qing Zou",
      "Luis A. Torres",
      "Sean B. Fain",
      "Nara S. Higano",
      "Alister J. Bates",
      "Mathews Jacob"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03380"
  },
  {
    "id": "arXiv:2112.03393",
    "title": "A Proof of the Simplex Mean Width Conjecture",
    "abstract": "The mean width of a convex body is the average distance between parallel\nsupporting hyperplanes when the normal direction is chosen uniformly over the\nsphere. The Simplex Mean Width Conjecture (SMWC) is a longstanding open problem\nthat says the regular simplex has maximum mean width of all simplices contained\nin the unit ball and is unique up to isometry. We give a self contained proof\nof the SMWC in $d$ dimensions. The main idea is that when discussing mean\nwidth, $d+1$ vertices $v_i\\in\\mathbb{S}^{d-1}$ naturally divide\n$\\mathbb{S}^{d-1}$ into $d+1$ Voronoi cells and conversely any partition of\n$\\mathbb{S}^{d-1}$ points to selecting the centroids of regions as vertices. We\nwill show that these two conditions are enough to ensure that a simplex with\nmaximum mean width is a regular simplex.",
    "descriptor": "\nComments: 7 pages, 1 figure\n",
    "authors": [
      "Aaron Goldsmith"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.03393"
  },
  {
    "id": "arXiv:2112.03419",
    "title": "Using Image Transformations to Learn Network Structure",
    "abstract": "Many learning tasks require observing a sequence of images and making a\ndecision. In a transportation problem of designing and planning for shipping\nboxes between nodes, we show how to treat the network of nodes and the flows\nbetween them as images. These images have useful structural information that\ncan be statistically summarized. Using image compression techniques, we reduce\nan image down to a set of numbers that contain interpretable geographic\ninformation that we call geographic signatures. Using geographic signatures, we\nlearn network structure that can be utilized to recommend future network\nconnectivity. We develop a Bayesian reinforcement algorithm that takes\nadvantage of statistically summarized network information as priors and\nuser-decisions to reinforce an agent's probabilistic decision.",
    "descriptor": "\nComments: 11 pages, 6 figures, 5 tables, In Submission with International Journal of Data Science and Analytics, Special Issue: Domain Driven Data Mining\n",
    "authors": [
      "Brayan Ortiz",
      "Amitabh Sinha"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.03419"
  },
  {
    "id": "arXiv:2112.03454",
    "title": "Robust Speech Representation Learning via Flow-based Embedding  Regularization",
    "abstract": "Over the recent years, various deep learning-based methods were proposed for\nextracting a fixed-dimensional embedding vector from speech signals. Although\nthe deep learning-based embedding extraction methods have shown good\nperformance in numerous tasks including speaker verification, language\nidentification and anti-spoofing, their performance is limited when it comes to\nmismatched conditions due to the variability within them unrelated to the main\ntask. In order to alleviate this problem, we propose a novel training strategy\nthat regularizes the embedding network to have minimum information about the\nnuisance attributes. To achieve this, our proposed method directly incorporates\nthe information bottleneck scheme into the training process, where the mutual\ninformation is estimated using the main task classifier and an auxiliary\nnormalizing flow network. The proposed method was evaluated on different speech\nprocessing tasks and showed improvement over the standard training strategy in\nall experimentation.",
    "descriptor": "",
    "authors": [
      "Woo Hyun Kang",
      "Jahangir Alam",
      "Abderrahim Fathan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.03454"
  },
  {
    "id": "arXiv:2112.03455",
    "title": "Hybrid guiding: A multi-resolution refinement approach for semantic  segmentation of gigapixel histopathological images",
    "abstract": "Histopathological cancer diagnostics has become more complex, and the\nincreasing number of biopsies is a challenge for most pathology laboratories.\nThus, development of automatic methods for evaluation of histopathological\ncancer sections would be of value. In this study, we used 624 whole slide\nimages (WSIs) of breast cancer from a Norwegian cohort. We propose a cascaded\nconvolutional neural network design, called H2G-Net, for semantic segmentation\nof gigapixel histopathological images. The design involves a detection stage\nusing a patch-wise method, and a refinement stage using a convolutional\nautoencoder. To validate the design, we conducted an ablation study to assess\nthe impact of selected components in the pipeline on tumour segmentation.\nGuiding segmentation, using hierarchical sampling and deep heatmap refinement,\nproved to be beneficial when segmenting the histopathological images. We found\na significant improvement when using a refinement network for postprocessing\nthe generated tumour segmentation heatmaps. The overall best design achieved a\nDice score of 0.933 on an independent test set of 90 WSIs. The design\noutperformed single-resolution approaches, such as cluster-guided, patch-wise\nhigh-resolution classification using MobileNetV2 (0.872) and a low-resolution\nU-Net (0.874). In addition, segmentation on a representative x400 WSI took ~58\nseconds, using only the CPU. The findings demonstrate the potential of\nutilizing a refinement network to improve patch-wise predictions. The solution\nis efficient and does not require overlapping patch inference or ensembling.\nFurthermore, we showed that deep neural networks can be trained using a random\nsampling scheme that balances on multiple different labels simultaneously,\nwithout the need of storing patches on disk. Future work should involve more\nefficient patch generation and sampling, as well as improved clustering.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Andr\u00e9 Pedersen",
      "Erik Smistad",
      "Tor V. Rise",
      "Vibeke G. Dale",
      "Henrik S. Pettersen",
      "Tor-Arne S. Nordmo",
      "David Bouget",
      "Ingerid Reinertsen",
      "Marit Valla"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03455"
  },
  {
    "id": "arXiv:2112.03456",
    "title": "RSBNet: One-Shot Neural Architecture Search for A Backbone Network in  Remote Sensing Image Recognition",
    "abstract": "Recently, a massive number of deep learning based approaches have been\nsuccessfully applied to various remote sensing image (RSI) recognition tasks.\nHowever, most existing advances of deep learning methods in the RSI field\nheavily rely on the features extracted by the manually designed backbone\nnetwork, which severely hinders the potential of deep learning models due the\ncomplexity of RSI and the limitation of prior knowledge. In this paper, we\nresearch a new design paradigm for the backbone architecture in RSI recognition\ntasks, including scene classification, land-cover classification and object\ndetection. A novel one-shot architecture search framework based on\nweight-sharing strategy and evolutionary algorithm is proposed, called RSBNet,\nwhich consists of three stages: Firstly, a supernet constructed in a layer-wise\nsearch space is pretrained on a self-assembled large-scale RSI dataset based on\nan ensemble single-path training strategy. Next, the pre-trained supernet is\nequipped with different recognition heads through the switchable recognition\nmodule and respectively fine-tuned on the target dataset to obtain\ntask-specific supernet. Finally, we search the optimal backbone architecture\nfor different recognition tasks based on the evolutionary algorithm without any\nnetwork training. Extensive experiments have been conducted on five benchmark\ndatasets for different recognition tasks, the results show the effectiveness of\nthe proposed search paradigm and demonstrate that the searched backbone is able\nto flexibly adapt different RSI recognition tasks and achieve impressive\nperformance.",
    "descriptor": "",
    "authors": [
      "Cheng Peng",
      "Yangyang Li",
      "Ronghua Shang",
      "Licheng Jiao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03456"
  },
  {
    "id": "arXiv:2112.03469",
    "title": "Emulating Spatio-Temporal Realizations of Three-Dimensional Isotropic  Turbulence via Deep Sequence Learning Models",
    "abstract": "We use a data-driven approach to model a three-dimensional turbulent flow\nusing cutting-edge Deep Learning techniques. The deep learning framework\nincorporates physical constraints on the flow, such as preserving\nincompressibility and global statistical invariants of velocity gradient\ntensor. The accuracy of the model is assessed using statistical and\nphysics-based metrics. The data set comes from Direct Numerical Simulation of\nan incompressible, statistically stationary, isotropic turbulent flow in a\ncubic box. Since the size of the dataset is memory intensive, we first generate\na low-dimensional representation of the velocity data, and then pass it to a\nsequence prediction network that learns the spatial and temporal correlations\nof the underlying data. The dimensionality reduction is performed via\nextraction using Vector-Quantized Autoencoder (VQ-AE), which learns the\ndiscrete latent variables. For the sequence forecasting, the idea of\nTransformer architecture from natural language processing is used, and its\nperformance compared against more standard Recurrent Networks (such as\nConvolutional LSTM). These architectures are designed and trained to perform a\nsequence to sequence multi-class classification task in which they take an\ninput sequence with a fixed length (k) and predict a sequence with a fixed\nlength (p), representing the future time instants of the flow. Our results for\nthe short-term predictions show that the accuracy of results for both models\ndeteriorates across predicted snapshots due to autoregressive nature of the\npredictions. Based on our diagnostics tests, the trained Conv-Transformer model\noutperforms the Conv-LSTM one and can accurately, both quantitatively and\nqualitatively, retain the large scales and capture well the inertial scales of\nflow but fails at recovering the small and intermittent fluid motions.",
    "descriptor": "\nComments: AI2ASE: AAAI Workshop on AI to Accelerate Science and Engineering, 2022\n",
    "authors": [
      "Mohammadreza Momenifar",
      "Enmao Diao",
      "Vahid Tarokh",
      "Andrew D. Bragg"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03469"
  },
  {
    "id": "arXiv:2112.03491",
    "title": "Explicitly antisymmetrized neural network layers for variational Monte  Carlo simulation",
    "abstract": "The combination of neural networks and quantum Monte Carlo methods has arisen\nas a path forward for highly accurate electronic structure calculations.\nPrevious proposals have combined equivariant neural network layers with an\nantisymmetric layer to satisfy the antisymmetry requirements of the electronic\nwavefunction. However, to date it is unclear if one can represent antisymmetric\nfunctions of physical interest, and it is difficult to measure the\nexpressiveness of the antisymmetric layer. This work attempts to address this\nproblem by introducing explicitly antisymmetrized universal neural network\nlayers as a diagnostic tool. We first introduce a generic antisymmetric (GA)\nlayer, which we use to replace the entire antisymmetric layer of the highly\naccurate ansatz known as the FermiNet. We demonstrate that the resulting\nFermiNet-GA architecture can yield effectively the exact ground state energy\nfor small systems. We then consider a factorized antisymmetric (FA) layer which\nmore directly generalizes the FermiNet by replacing products of determinants\nwith products of antisymmetrized neural networks. Interestingly, the resulting\nFermiNet-FA architecture does not outperform the FermiNet. This suggests that\nthe sum of products of antisymmetries is a key limiting aspect of the FermiNet\narchitecture. To explore this further, we investigate a slight modification of\nthe FermiNet called the full determinant mode, which replaces each product of\ndeterminants with a single combined determinant. The full single-determinant\nFermiNet closes a large part of the gap between the standard single-determinant\nFermiNet and FermiNet-GA. Surprisingly, on the nitrogen molecule at a\ndissociating bond length of 4.0 Bohr, the full single-determinant FermiNet can\nsignificantly outperform the standard 64-determinant FermiNet, yielding an\nenergy within 0.4 kcal/mol of the best available computational benchmark.",
    "descriptor": "\nComments: 33 pages, 14 figures\n",
    "authors": [
      "Jeffmin Lin",
      "Gil Goldshlager",
      "Lin Lin"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.03491"
  },
  {
    "id": "arXiv:2112.03504",
    "title": "Improving Dynamic Regret in Distributed Online Mirror Descent Using  Primal and Dual Information",
    "abstract": "We consider the problem of distributed online optimization, with a group of\nlearners connected via a dynamic communication graph. The goal of the learners\nis to track the global minimizer of a sum of time-varying loss functions in a\ndistributed manner. We propose a novel algorithm, termed Distributed Online\nMirror Descent with Multiple Averaging Decision and Gradient Consensus\n(DOMD-MADGC), which is based on mirror descent but incorporates multiple\nconsensus averaging iterations over local gradients as well as local decisions.\nThe key idea is to allow the local learners to collect a sufficient amount of\nglobal information, which enables them to more accurately approximation the\ntime-varying global loss, so that they can closely track the dynamic global\nminimizer over time. We show that the dynamic regret of DOMD-MADGC is upper\nbounded by the path length, which is defined as the cumulative distance between\nsuccessive minimizers. The resulting bound improves upon the bounds of existing\ndistributed online algorithms and removes the explicit dependence on $T$.",
    "descriptor": "",
    "authors": [
      "Nima Eshraghi",
      "Ben Liang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.03504"
  },
  {
    "id": "arXiv:2112.03508",
    "title": "Training Deep Models to be Explained with Fewer Examples",
    "abstract": "Although deep models achieve high predictive performance, it is difficult for\nhumans to understand the predictions they made. Explainability is important for\nreal-world applications to justify their reliability. Many example-based\nexplanation methods have been proposed, such as representer point selection,\nwhere an explanation model defined by a set of training examples is used for\nexplaining a prediction model. For improving the interpretability, reducing the\nnumber of examples in the explanation model is important. However, the\nexplanations with fewer examples can be unfaithful since it is difficult to\napproximate prediction models well by such example-based explanation models.\nThe unfaithful explanations mean that the predictions by the explainable model\nare different from those by the prediction model. We propose a method for\ntraining deep models such that their predictions are faithfully explained by\nexplanation models with a small number of examples. We train the prediction and\nexplanation models simultaneously with a sparse regularizer for reducing the\nnumber of examples. The proposed method can be incorporated into any neural\nnetwork-based prediction models. Experiments using several datasets demonstrate\nthat the proposed method improves faithfulness while keeping the predictive\nperformance.",
    "descriptor": "",
    "authors": [
      "Tomoharu Iwata",
      "Yuya Yoshikawa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03508"
  },
  {
    "id": "arXiv:2112.03512",
    "title": "Constrained Resource Allocation Problems in Communications: An  Information-assisted Approach",
    "abstract": "We consider a class of resource allocation problems given a set of\nunconditional constraints whose objective function satisfies Bellman's\noptimality principle. Such problems are ubiquitous in wireless communication,\nsignal processing, and networking. These constrained combinatorial optimization\nproblems are, in general, NP-Hard. This paper proposes two algorithms to solve\nthis class of problems using a dynamic programming framework assisted by an\ninformation-theoretic measure. We demonstrate that the proposed algorithms\nensure optimal solutions under carefully chosen conditions and use\nsignificantly reduced computational resources. We substantiate our claims by\nsolving the power-constrained bit allocation problem in 5G massive\nMultiple-Input Multiple-Output receivers using the proposed approach.",
    "descriptor": "\nComments: Accepted for publication in IEEE Military Communications Conference 2021\n",
    "authors": [
      "I. Zakir Ahmed",
      "Hamid Sadjadpour",
      "Shahram Yousefi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.03512"
  },
  {
    "id": "arXiv:2112.03528",
    "title": "Physics guided deep learning generative models for crystal materials  discovery",
    "abstract": "Deep learning based generative models such as deepfake have been able to\ngenerate amazing images and videos. However, these models may need significant\ntransformation when applied to generate crystal materials structures in which\nthe building blocks, the physical atoms are very different from the pixels.\nNaively transferred generative models tend to generate a large portion of\nphysically infeasible crystal structures that are not stable or synthesizable.\nHerein we show that by exploiting and adding physically oriented data\naugmentation, loss function terms, and post processing, our deep adversarial\nnetwork (GAN) based generative models can now generate crystal structures with\nhigher physical feasibility and expand our previous models which can only\ncreate cubic structures.",
    "descriptor": "",
    "authors": [
      "Yong Zhao",
      "Edirisuriya MD Siriwardane",
      "Jianjun Hu"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03528"
  },
  {
    "id": "arXiv:2112.03533",
    "title": "A Time-domain Generalized Wiener Filter for Multi-channel Speech  Separation",
    "abstract": "Frequency-domain neural beamformers are the mainstream methods for recent\nmulti-channel speech separation models. Despite their well-defined behaviors\nand the effectiveness, such frequency-domain beamformers still have the\nlimitations of a bounded oracle performance and the difficulties of designing\nproper networks for the complex-valued operations. In this paper, we propose a\ntime-domain generalized Wiener filter (TD-GWF), an extension to the\nconventional frequency-domain beamformers that has higher oracle performance\nand only involves real-valued operations. We also provide discussions on how\nTD-GWF can be connected to conventional frequency-domain beamformers.\nExperiment results show that a significant performance improvement can be\nachieved by replacing frequency-domain beamformers by the TD-GWF in the\nrecently proposed sequential neural beamforming pipelines.",
    "descriptor": "",
    "authors": [
      "Yi Luo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.03533"
  },
  {
    "id": "arXiv:2112.03536",
    "title": "Learning Pixel-Adaptive Weights for Portrait Photo Retouching",
    "abstract": "Portrait photo retouching is a photo retouching task that emphasizes\nhuman-region priority and group-level consistency. The lookup table-based\nmethod achieves promising retouching performance by learning image-adaptive\nweights to combine 3-dimensional lookup tables (3D LUTs) and conducting\npixel-to-pixel color transformation. However, this paradigm ignores the local\ncontext cues and applies the same transformation to portrait pixels and\nbackground pixels when they exhibit the same raw RGB values. In contrast, an\nexpert usually conducts different operations to adjust the color temperatures\nand tones of portrait regions and background regions. This inspires us to model\nlocal context cues to improve the retouching quality explicitly. Firstly, we\nconsider an image patch and predict pixel-adaptive lookup table weights to\nprecisely retouch the center pixel. Secondly, as neighboring pixels exhibit\ndifferent affinities to the center pixel, we estimate a local attention mask to\nmodulate the influence of neighboring pixels. Thirdly, the quality of the local\nattention mask can be further improved by applying supervision, which is based\non the affinity map calculated by the groundtruth portrait mask. As for\ngroup-level consistency, we propose to directly constrain the variance of mean\ncolor components in the Lab space. Extensive experiments on PPR10K dataset\nverify the effectiveness of our method, e.g. on high-resolution photos, the\nPSNR metric receives over 0.5 gains while the group-level consistency metric\nobtains at least 2.1 decreases.",
    "descriptor": "\nComments: Techinical report\n",
    "authors": [
      "Binglu Wang",
      "Chengzhe Lu",
      "Dawei Yan",
      "Yongqiang Zhao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03536"
  },
  {
    "id": "arXiv:2112.03548",
    "title": "Private Robust Estimation by Stabilizing Convex Relaxations",
    "abstract": "We give the first polynomial time and sample $(\\epsilon,\n\\delta)$-differentially private (DP) algorithm to estimate the mean, covariance\nand higher moments in the presence of a constant fraction of adversarial\noutliers. Our algorithm succeeds for families of distributions that satisfy two\nwell-studied properties in prior works on robust estimation: certifiable\nsubgaussianity of directional moments and certifiable hypercontractivity of\ndegree 2 polynomials. Our recovery guarantees hold in the \"right\naffine-invariant norms\": Mahalanobis distance for mean, multiplicative spectral\nand relative Frobenius distance guarantees for covariance and injective norms\nfor higher moments. Prior works obtained private robust algorithms for mean\nestimation of subgaussian distributions with bounded covariance. For covariance\nestimation, ours is the first efficient algorithm (even in the absence of\noutliers) that succeeds without any condition-number assumptions.\nOur algorithms arise from a new framework that provides a general blueprint\nfor modifying convex relaxations for robust estimation to satisfy strong\nworst-case stability guarantees in the appropriate parameter norms whenever the\nalgorithms produce witnesses of correctness in their run. We verify such\nguarantees for a modification of standard sum-of-squares (SoS) semidefinite\nprogramming relaxations for robust estimation. Our privacy guarantees are\nobtained by combining stability guarantees with a new \"estimate dependent\"\nnoise injection mechanism in which noise scales with the eigenvalues of the\nestimated covariance. We believe this framework will be useful more generally\nin obtaining DP counterparts of robust estimators.\nIndependently of our work, Ashtiani and Liaw [AL21] also obtained a\npolynomial time and sample private robust estimation algorithm for Gaussian\ndistributions.",
    "descriptor": "",
    "authors": [
      "Pravesh K. Kothari",
      "Pasin Manurangsi",
      "Ameya Velingker"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03548"
  },
  {
    "id": "arXiv:2112.03622",
    "title": "Evaluating Generic Auto-ML Tools for Computational Pathology",
    "abstract": "Image analysis tasks in computational pathology are commonly solved using\nconvolutional neural networks (CNNs). The selection of a suitable CNN\narchitecture and hyperparameters is usually done through exploratory iterative\noptimization, which is computationally expensive and requires substantial\nmanual work. The goal of this article is to evaluate how generic tools for\nneural network architecture search and hyperparameter optimization perform for\ncommon use cases in computational pathology. For this purpose, we evaluated one\non-premises and one cloud-based tool for three different classification tasks\nfor histological images: tissue classification, mutation prediction, and\ngrading.\nWe found that the default CNN architectures and parameterizations of the\nevaluated AutoML tools already yielded classification performance on par with\nthe original publications. Hyperparameter optimization for these tasks did not\nsubstantially improve performance, despite the additional computational effort.\nHowever, performance varied substantially between classifiers obtained from\nindividual AutoML runs due to non-deterministic effects.\nGeneric CNN architectures and AutoML tools could thus be a viable alternative\nto manually optimizing CNN architectures and parametrizations. This would allow\ndevelopers of software solutions for computational pathology to focus efforts\non harder-to-automate tasks such as data curation.",
    "descriptor": "",
    "authors": [
      "Lars Ole Schwen",
      "Daniela Schacherer",
      "Christian Gei\u00dfler",
      "Andr\u00e9 Homeyer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03622"
  },
  {
    "id": "arXiv:2112.03626",
    "title": "Bless and curse of smoothness and phase transitions in nonparametric  regressions: a nonasymptotic perspective",
    "abstract": "When the regression function belongs to the standard smooth classes\nconsisting of univariate functions with derivatives up to the $(\\gamma+1)$th\norder bounded by a common constant everywhere or a.e., it is well known that\nthe minimax optimal rate of convergence in mean squared error (MSE) is\n$\\left(\\frac{\\sigma^{2}}{n}\\right)^{\\frac{2\\gamma+2}{2\\gamma+3}}$ when $\\gamma$\nis finite and the sample size $n\\rightarrow\\infty$. From a nonasymptotic\nviewpoint that considers finite $n$, this paper shows that: for the standard\nH\\\"older and Sobolev classes, the minimax optimal rate is\n$\\frac{\\sigma^{2}\\left(\\gamma\\vee1\\right)}{n}$ when\n$\\frac{n}{\\sigma^{2}}\\precsim\\left(\\gamma\\vee1\\right)^{2\\gamma+3}$ and\n$\\left(\\frac{\\sigma^{2}}{n}\\right)^{\\frac{2\\gamma+2}{2\\gamma+3}}$ when\n$\\frac{n}{\\sigma^{2}}\\succsim\\left(\\gamma\\vee1\\right)^{2\\gamma+3}$. To\nestablish these results, we derive upper and lower bounds on the covering and\npacking numbers for the generalized H\\\"older class where the $k$th\n($k=0,...,\\gamma$) derivative is bounded from above by a parameter $R_{k}$ and\nthe $\\gamma$th derivative is $R_{\\gamma+1}-$Lipschitz (and also for the\ngeneralized ellipsoid class of smooth functions). Our bounds sharpen the\nclassical metric entropy results for the standard classes, and give the general\ndependence on $\\gamma$ and $R_{k}$. By deriving the minimax optimal MSE rates\nunder $R_{k}=1$, $R_{k}\\leq\\left(k-1\\right)!$ and $R_{k}=k!$ (with the latter\ntwo cases motivated in our introduction) with the help of our new entropy\nbounds, we show a couple of interesting results that cannot be shown with the\nexisting entropy bounds in the literature. For the H\\\"older class of\n$d-$variate functions, our result suggests that the classical asymptotic rate\n$\\left(\\frac{\\sigma^{2}}{n}\\right)^{\\frac{2\\gamma+2}{2\\gamma+2+d}}$ could be an\nunderestimate of the MSE in finite samples.",
    "descriptor": "\nComments: 3 Tables\n",
    "authors": [
      "Ying Zhu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03626"
  },
  {
    "id": "arXiv:2112.03633",
    "title": "Applications of the Frenet Frame to Electric Circuits",
    "abstract": "The paper discusses the relationships between electrical quantities, such as\nvoltages, currents, and frequency, and geometrical ones, namely curvature and\ntorsion. The proposed approach is based on the Frenet frame utilized in\ndifferential geometry and provides a general framework for the definition of\nthe time derivative of electrical quantities in stationary as well as transient\nconditions. As a byproduct, the proposed approach unifies and generalizes the\ntime- and phasor-domain frameworks. Other noteworthy results are a new\ninterpretation of the link between frequency and the time derivatives of\nvoltage and current; and a definition of the rate of change of frequency that\nincludes the novel concept of \"torsional frequency.\" Several numerical examples\nbased on balanced, unbalanced, harmonically-distorted and transient voltages\nillustrate the findings of the paper.",
    "descriptor": "",
    "authors": [
      "Federico Milano",
      "Georgios Tzounas",
      "Ioannis Dassios",
      "Taulant Kerci"
    ],
    "subjectives": [
      "Differential Geometry (math.DG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03633"
  },
  {
    "id": "arXiv:2112.03643",
    "title": "QKSA: Quantum Knowledge Seeking Agent -- resource-optimized  reinforcement learning using quantum process tomography",
    "abstract": "In this research, we extend the universal reinforcement learning (URL) agent\nmodels of artificial general intelligence to quantum environments. The utility\nfunction of a classical exploratory stochastic Knowledge Seeking Agent, KL-KSA,\nis generalized to distance measures from quantum information theory on density\nmatrices. Quantum process tomography (QPT) algorithms form the tractable subset\nof programs for modeling environmental dynamics. The optimal QPT policy is\nselected based on a mutable cost function based on algorithmic complexity as\nwell as computational resource complexity. Instead of Turing machines, we\nestimate the cost metrics on a high-level language to allow realistic\nexperimentation. The entire agent design is encapsulated in a self-replicating\nquine which mutates the cost function based on the predictive value of the\noptimal policy choosing scheme. Thus, multiple agents with pareto-optimal QPT\npolicies evolve using genetic programming, mimicking the development of\nphysical theories each with different resource trade-offs. This formal\nframework is termed Quantum Knowledge Seeking Agent (QKSA).\nDespite its importance, few quantum reinforcement learning models exist in\ncontrast to the current thrust in quantum machine learning. QKSA is the first\nproposal for a framework that resembles the classical URL models. Similar to\nhow AIXI-tl is a resource-bounded active version of Solomonoff universal\ninduction, QKSA is a resource-bounded participatory observer framework to the\nrecently proposed algorithmic information-based reconstruction of quantum\nmechanics. QKSA can be applied for simulating and studying aspects of quantum\ninformation theory. Specifically, we demonstrate that it can be used to\naccelerate quantum variational algorithms which include tomographic\nreconstruction as its integral subroutine.",
    "descriptor": "\nComments: superseding initial QKSA framework as presented in arXiv:2107.01429\n",
    "authors": [
      "Aritra Sarkar",
      "Zaid Al-Ars",
      "Harshitta Gandhi",
      "Koen Bertels"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.03643"
  },
  {
    "id": "arXiv:2112.03657",
    "title": "Understanding Square Loss in Training Overparametrized Neural Network  Classifiers",
    "abstract": "Deep learning has achieved many breakthroughs in modern classification tasks.\nNumerous architectures have been proposed for different data structures but\nwhen it comes to the loss function, the cross-entropy loss is the predominant\nchoice. Recently, several alternative losses have seen revived interests for\ndeep classifiers. In particular, empirical evidence seems to promote square\nloss but a theoretical justification is still lacking. In this work, we\ncontribute to the theoretical understanding of square loss in classification by\nsystematically investigating how it performs for overparametrized neural\nnetworks in the neural tangent kernel (NTK) regime. Interesting properties\nregarding the generalization error, robustness, and calibration error are\nrevealed. We consider two cases, according to whether classes are separable or\nnot. In the general non-separable case, fast convergence rate is established\nfor both misclassification rate and calibration error. When classes are\nseparable, the misclassification rate improves to be exponentially fast.\nFurther, the resulting margin is proven to be lower bounded away from zero,\nproviding theoretical guarantees for robustness. We expect our findings to hold\nbeyond the NTK regime and translate to practical settings. To this end, we\nconduct extensive empirical studies on practical neural networks, demonstrating\nthe effectiveness of square loss in both synthetic low-dimensional data and\nreal image data. Comparing to cross-entropy, square loss has comparable\ngeneralization error but noticeable advantages in robustness and model\ncalibration.",
    "descriptor": "",
    "authors": [
      "Tianyang Hu",
      "Jun Wang",
      "Wenjia Wang",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03657"
  },
  {
    "id": "arXiv:2112.03660",
    "title": "A generalization gap estimation for overparameterized models via  Langevin functional variance",
    "abstract": "This paper discusses estimating the generalization gap, a difference between\na generalization gap and an empirical error, for overparameterized models\n(e.g., neural networks). We first show that a functional variance, a key\nconcept in defining a widely-applicable information criterion, characterizes\nthe generalization gap even in overparameterized settings, where a conventional\ntheory cannot be applied. We next propose a computationally efficient\napproximation of the function variance, a Langevin approximation of the\nfunctional variance~(Langevin FV). This method leverages the 1st-order but not\nthe 2nd-order gradient of the squared loss function; so, it can be computed\nefficiently and implemented consistently with gradient-based optimization\nalgorithms. We demonstrate the Langevin FV numerically in estimating\ngeneralization gaps of overparameterized linear regression and non-linear\nneural network models.",
    "descriptor": "\nComments: 21 pages, no figure\n",
    "authors": [
      "Akifumi Okuno",
      "Keisuke Yano"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.03660"
  },
  {
    "id": "arXiv:2112.03694",
    "title": "Hard Sample Aware Noise Robust Learning for Histopathology Image  Classification",
    "abstract": "Deep learning-based histopathology image classification is a key technique to\nhelp physicians in improving the accuracy and promptness of cancer diagnosis.\nHowever, the noisy labels are often inevitable in the complex manual annotation\nprocess, and thus mislead the training of the classification model. In this\nwork, we introduce a novel hard sample aware noise robust learning method for\nhistopathology image classification. To distinguish the informative hard\nsamples from the harmful noisy ones, we build an easy/hard/noisy (EHN)\ndetection model by using the sample training history. Then we integrate the EHN\ninto a self-training architecture to lower the noise rate through gradually\nlabel correction. With the obtained almost clean dataset, we further propose a\nnoise suppressing and hard enhancing (NSHE) scheme to train the noise robust\nmodel. Compared with the previous works, our method can save more clean samples\nand can be directly applied to the real-world noisy dataset scenario without\nusing a clean subset. Experimental results demonstrate that the proposed scheme\noutperforms the current state-of-the-art methods in both the synthetic and\nreal-world noisy datasets. The source code and data are available at\nhttps://github.com/bupt-ai-cz/HSA-NRL/.",
    "descriptor": "\nComments: 14 pages, 20figures, IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Chuang Zhu",
      "Wenkai Chen",
      "Ting Peng",
      "Ying Wang",
      "Mulan Jin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.03694"
  },
  {
    "id": "arXiv:2112.03696",
    "title": "Noise Distribution Adaptive Self-Supervised Image Denoising using  Tweedie Distribution and Score Matching",
    "abstract": "Tweedie distributions are a special case of exponential dispersion models,\nwhich are often used in classical statistics as distributions for generalized\nlinear models. Here, we reveal that Tweedie distributions also play key roles\nin modern deep learning era, leading to a distribution independent\nself-supervised image denoising formula without clean reference images.\nSpecifically, by combining with the recent Noise2Score self-supervised image\ndenoising approach and the saddle point approximation of Tweedie distribution,\nwe can provide a general closed-form denoising formula that can be used for\nlarge classes of noise distributions without ever knowing the underlying noise\ndistribution. Similar to the original Noise2Score, the new approach is composed\nof two successive steps: score matching using perturbed noisy images, followed\nby a closed form image denoising formula via distribution-independent Tweedie's\nformula. This also suggests a systematic algorithm to estimate the noise model\nand noise parameters for a given noisy image data set. Through extensive\nexperiments, we demonstrate that the proposed method can accurately estimate\nnoise models and parameters, and provide the state-of-the-art self-supervised\nimage denoising performance in the benchmark dataset and real-world dataset.",
    "descriptor": "",
    "authors": [
      "Kwanyoung Kim",
      "Taesung Kwon",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03696"
  },
  {
    "id": "arXiv:2112.03698",
    "title": "Modeling and Predicting Blood Flow Characteristics through Double  Stenosed Artery from CFD simulation using Deep Learning Models",
    "abstract": "Establishing patient-specific finite element analysis (FEA) models for\ncomputational fluid dynamics (CFD) of double stenosed artery models involves\ntime and effort, restricting physicians' ability to respond quickly in\ntime-critical medical applications. Such issues might be addressed by training\ndeep learning (DL) models to learn and predict blood flow characteristics using\na dataset generated by CFD simulations of simplified double stenosed artery\nmodels with different configurations. When blood flow patterns are compared\nthrough an actual double stenosed artery model, derived from IVUS imaging, it\nis revealed that the sinusoidal approximation of stenosed neck geometry, which\nhas been widely used in previous research works, fails to effectively represent\nthe effects of a real constriction. As a result, a novel geometric\nrepresentation of the constricted neck is proposed which, in terms of a\ngeneralized simplified model, outperforms the former assumption. The sequential\nchange in artery lumen diameter and flow parameters along the length of the\nvessel presented opportunities for the use of LSTM and GRU DL models. However,\nwith the small dataset of short lengths of doubly constricted blood arteries,\nthe basic neural network model outperforms the specialized RNNs for most flow\nproperties. LSTM, on the other hand, performs better for predicting flow\nproperties with large fluctuations, such as varying blood pressure over the\nlength of the vessels. Despite having good overall accuracies in training and\ntesting across all the properties for the vessels in the dataset, the GRU model\nunderperforms for an individual vessel flow prediction in all cases. The\nresults also point to the need of individually optimized hyperparameters for\neach property in any model rather than aiming to achieve overall good\nperformance across all outputs with a single set of hyperparameters.",
    "descriptor": "",
    "authors": [
      "Ishat Raihan Jamil",
      "Mayeesha Humaira"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03698"
  },
  {
    "id": "arXiv:2112.03701",
    "title": "Efficient joint noise removal and multi exposure fusion",
    "abstract": "Multi-exposure fusion (MEF) is a technique for combining different images of\nthe same scene acquired with different exposure settings into a single image.\nAll the proposed MEF algorithms combine the set of images, somehow choosing\nfrom each one the part with better exposure.\nWe propose a novel multi-exposure image fusion chain taking into account\nnoise removal. The novel method takes advantage of DCT processing and the\nmulti-image nature of the MEF problem. We propose a joint fusion and denoising\nstrategy taking advantage of spatio-temporal patch selection and collaborative\n3D thresholding. The overall strategy permits to denoise and fuse the set of\nimages without the need of recovering each denoised exposure image, leading to\na very efficient procedure.",
    "descriptor": "",
    "authors": [
      "A. Buades",
      "J.L Lisani",
      "O. Martorell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03701"
  },
  {
    "id": "arXiv:2112.03712",
    "title": "Image Compressed Sensing Using Non-local Neural Network",
    "abstract": "Deep network-based image Compressed Sensing (CS) has attracted much attention\nin recent years. However, the existing deep network-based CS schemes either\nreconstruct the target image in a block-by-block manner that leads to serious\nblock artifacts or train the deep network as a black box that brings about\nlimited insights of image prior knowledge. In this paper, a novel image CS\nframework using non-local neural network (NL-CSNet) is proposed, which utilizes\nthe non-local self-similarity priors with deep network to improve the\nreconstruction quality. In the proposed NL-CSNet, two non-local subnetworks are\nconstructed for utilizing the non-local self-similarity priors in the\nmeasurement domain and the multi-scale feature domain respectively.\nSpecifically, in the subnetwork of measurement domain, the long-distance\ndependencies between the measurements of different image blocks are established\nfor better initial reconstruction. Analogically, in the subnetwork of\nmulti-scale feature domain, the affinities between the dense feature\nrepresentations are explored in the multi-scale space for deep reconstruction.\nFurthermore, a novel loss function is developed to enhance the coupling between\nthe non-local representations, which also enables an end-to-end training of\nNL-CSNet. Extensive experiments manifest that NL-CSNet outperforms existing\nstate-of-the-art CS methods, while maintaining fast computational speed.",
    "descriptor": "\nComments: 14 pages, 11 figures, 7 tables\n",
    "authors": [
      "Wenxue Cui",
      "Shaohui Liu",
      "Feng Jiang",
      "Debin Zhao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03712"
  },
  {
    "id": "arXiv:2112.03744",
    "title": "Spatial Search on Johnson Graphs by Discrete-Time Quantum Walk",
    "abstract": "The spatial search problem aims to find a marked vertex of a finite graph\nusing a dynamic with two constraints: (1) The walker has no compass and (2) the\nwalker can check whether a vertex is marked only after reaching it. This\nproblem is a generalization of unsorted database search and has many\napplications to algorithms. Classical algorithms that solve the spatial search\nproblem are based on random walks and the computational complexity is\ndetermined by the hitting time. On the other hand, quantum algorithms are based\non quantum walks and the computational complexity is determined not only by the\nnumber of steps to reach a marked vertex, but also by the success probability,\nsince we need to perform a measurement at the end of the algorithm to determine\nthe walker's position. In this work, we address the spatial search problem on\nJohnson graphs using the coined quantum walk model. Since Johnson graphs are\nvertex- and distance-transitive, we have found an invariant subspace of the\nHilbert space, which aids in the calculation of the computational complexity.\nWe have shown that, for every fixed diameter, the asymptotic success\nprobability is $1/2$ after taking $\\pi\\sqrt N/(2\\sqrt 2)$ steps, where $N$ is\nthe number of vertices of the Johnson graph.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Hajime Tanaka",
      "Mohamed Sabri",
      "Renato Portugal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.03744"
  },
  {
    "id": "arXiv:2112.03752",
    "title": "Danna-Sep: Unite to separate them all",
    "abstract": "Deep learning-based music source separation has gained a lot of interest in\nthe last decades. Most of the existing methods operate with either spectrograms\nor waveforms. Spectrogram based models learn suitable masks for separating\nmagnitude spectrogram into different sources, and waveform-based models\ndirectly generate waveforms of individual sources. The two types of models have\ncomplementary strengths; the former is superior given harmonic sources such as\nvocals, while the latter demonstrates better results for percussion and bass\ninstruments. In this work, we improved upon the state-of-the-art (SoTA) models\nand successfully combined the best of both worlds. The backbones of the\nproposed framework, dubbed Danna-Sep, are two spectrogram-based models\nincluding a modified X-UMX and U-Net, and an enhanced Demucs as the\nwaveform-based model. Given an input of mixture, we linearly combined\nrespective outputs from the three models to obtain the final result. We showed\nin the experiments that, despite its simplicity, Danna-Sep surpassed the SoTA\nmodels by a large margin in terms of Source-to-Distortion Ratio.",
    "descriptor": "\nComments: 3 pages, 1 figure, accepted at MDX workshop, ISMIR 2021\n",
    "authors": [
      "Chin-Yun Yu",
      "Kin-Wai Cheuk"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.03752"
  },
  {
    "id": "arXiv:2112.03761",
    "title": "Outpatient Diversion using Real-Time Length-of-Stay Predictions",
    "abstract": "In this work, we show how real-time length-of-stay (LOS) predictions can be\nused to divert outpatients from their assigned facility to other facilities\nwith lesser congestion. We illustrate the implementation of this diversion\nmechanism for two primary health centers (PHCs), wherein we divert patients\nfrom their assigned PHC to the other PHC based on their predicted LOSs in both\nfacilities. We develop a discrete-event simulation model of patient flow\noperations at these two PHCs in an Indian district and observe significantly\nlonger LOSs at one of the PHCs due to disparities in the patient loads across\nboth PHCs. We first determine the expected LOS of the patient at the point in\ntime at which they are expected to arrive at a PHC using system state\ninformation recorded at the current time at the PHC in question. The real-time\nLOS predictions are generated by estimating patient wait times on a real-time\nbasis at the queueing subsystems within the PHC. We then divert the patient to\nthe appropriate PHC on the basis of the predicted LOS estimates at both PHCs,\nand show through simulation that the proposed framework leads to more equitable\nutilization of resources involved in provision of outpatient care.",
    "descriptor": "",
    "authors": [
      "Najiya Fatma",
      "Varun Ramamohan"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03761"
  },
  {
    "id": "arXiv:2112.03815",
    "title": "Accurate parameter estimation using scan-specific unsupervised deep  learning for relaxometry and MR fingerprinting",
    "abstract": "We propose an unsupervised convolutional neural network (CNN) for relaxation\nparameter estimation. This network incorporates signal relaxation and Bloch\nsimulations while taking advantage of residual learning and spatial relations\nacross neighboring voxels. Quantification accuracy and robustness to noise is\nshown to be significantly improved compared to standard parameter estimation\nmethods in numerical simulations and in vivo data for multi-echo T2 and T2*\nmapping. The combination of the proposed network with subspace modeling and MR\nfingerprinting (MRF) from highly undersampled data permits high quality T1 and\nT2 mapping.",
    "descriptor": "\nComments: 7 pages, 5 figures, submitted to International Society for Magnetic Resonance in Medicine 2022\n",
    "authors": [
      "Mengze Gao",
      "Huihui Ye",
      "Tae Hyung Kim",
      "Zijing Zhang",
      "Seohee So",
      "Berkin Bilgic"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.03815"
  },
  {
    "id": "arXiv:2112.03868",
    "title": "EmTract: Investor Emotions and Market Behavior",
    "abstract": "We develop a tool that extracts emotions from social media text data. Our\nmethodology has three main advantages. First, it is tailored for financial\ncontext; second, it incorporates key aspects of social media data, such as\nnon-standard phrases, emojis and emoticons; and third, it operates by\nsequentially learning a latent representation that includes features such as\nword order, word usage, and local context. This tool, along with a user guide\nis available at: https://github.com/dvamossy/EmTract. Using EmTract, we explore\nthe relationship between investor emotions expressed on social media and asset\nprices. We document a number of interesting insights. First, we confirm some of\nthe findings of controlled laboratory experiments relating investor emotions to\nasset price movements. Second, we show that investor emotions are predictive of\ndaily price movements. These impacts are larger when volatility or short\ninterest are higher, and when institutional ownership or liquidity are lower.\nThird, increased investor enthusiasm prior to the IPO contributes to the large\nfirst-day return and long-run underperformance of IPO stocks. To corroborate\nour results, we provide a number of robustness checks, including using an\nalternative emotion model. Our findings reinforce the intuition that emotions\nand market dynamics are closely related, and highlight the importance of\nconsidering investor emotions when assessing a stock's short-term value.",
    "descriptor": "",
    "authors": [
      "Domonkos Vamossy",
      "Rolf Skog"
    ],
    "subjectives": [
      "Pricing of Securities (q-fin.PR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03868"
  },
  {
    "id": "arXiv:2112.03871",
    "title": "Training end-to-end speech-to-text models on mobile phones",
    "abstract": "Training the state-of-the-art speech-to-text (STT) models in mobile devices\nis challenging due to its limited resources relative to a server environment.\nIn addition, these models are trained on generic datasets that are not\nexhaustive in capturing user-specific characteristics. Recently, on-device\npersonalization techniques have been making strides in mitigating the problem.\nAlthough many current works have already explored the effectiveness of\non-device personalization, the majority of their findings are limited to\nsimulation settings or a specific smartphone. In this paper, we develop and\nprovide a detailed explanation of our framework to train end-to-end models in\nmobile phones. To make it simple, we considered a model based on connectionist\ntemporal classification (CTC) loss. We evaluated the framework on various\nmobile phones from different brands and reported the results. We provide enough\nevidence that fine-tuning the models and choosing the right hyperparameter\nvalues is a trade-off between the lowest WER achievable, training time\non-device, and memory consumption. Hence, this is vital for a successful\ndeployment of on-device training onto a resource-limited environment like\nmobile phones. We use training sets from speakers with different accents and\nrecord a 7.6% decrease in average word error rate (WER). We also report the\nassociated computational cost measurements with respect to time, memory usage,\nand cpu utilization in mobile phones in real-time.",
    "descriptor": "",
    "authors": [
      "Zitha S",
      "Raghavendra Rao Suresh",
      "Pooja Rao",
      "T. V. Prabhakar"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.03871"
  },
  {
    "id": "arXiv:2112.03874",
    "title": "Efficient Calibration of Multi-Agent Market Simulators from Time Series  with Bayesian Optimization",
    "abstract": "Multi-agent market simulation is commonly used to create an environment for\ndownstream machine learning or reinforcement learning tasks, such as training\nor testing trading strategies before deploying them to real-time trading. In\nelectronic trading markets only the price or volume time series, that result\nfrom interaction of multiple market participants, are typically directly\nobservable. Therefore, multi-agent market environments need to be calibrated so\nthat the time series that result from interaction of simulated agents resemble\nhistorical -- which amounts to solving a highly complex large-scale\noptimization problem. In this paper, we propose a simple and efficient\nframework for calibrating multi-agent market simulator parameters from\nhistorical time series observations. First, we consider a novel concept of\neligibility set to bypass the potential non-identifiability issue. Second, we\ngeneralize the two-sample Kolmogorov-Smirnov (K-S) test with Bonferroni\ncorrection to test the similarity between two high-dimensional time series\ndistributions, which gives a simple yet effective distance metric between the\ntime series sample sets. Third, we suggest using Bayesian optimization (BO) and\ntrust-region BO (TuRBO) to minimize the aforementioned distance metric.\nFinally, we demonstrate the efficiency of our framework using numerical\nexperiments.",
    "descriptor": "",
    "authors": [
      "Yuanlu Bai",
      "Henry Lam",
      "Svitlana Vyetrenko",
      "Tucker Balch"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.03874"
  },
  {
    "id": "arXiv:2112.03881",
    "title": "Nashian game theory is incompatible with quantum contextuality",
    "abstract": "In this work, we design a novel game-theoretical framework capable of\ncapturing the defining aspects of quantum theory. We introduce an original\nmodel and an algorithmic procedure that enables to express measurement\nscenarios encountered in quantum mechanics as multiplayer games and to\ntranslate physical notions of causality, correlation, and contextuality to\nparticular aspects of game theory. Furthermore, inspired by the established\ncorrespondence, we investigate the causal consistency of games in extensive\nform with imperfect information from the quantum perspective and we conclude\nthat counterfactual dependencies should be distinguished from causation and\ncorrelation as a separate phenomenon of its own. Most significantly, we deduce\nthat Nashian free choice game theory is non-contextual and hence is in\ncontradiction with the Kochen-Specker theorem. Hence, we propose that quantum\nphysics should be analysed with toolkits from non-Nashian game theory applied\nto our suggested model.",
    "descriptor": "\nComments: Technical report, 15 pages, 9 figures\n",
    "authors": [
      "Michal Baczyk",
      "Ghislain Fourny"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.03881"
  },
  {
    "id": "arXiv:2112.03888",
    "title": "Image Enhancement via Bilateral Learning",
    "abstract": "Nowadays, due to advanced digital imaging technologies and internet\naccessibility to the public, the number of generated digital images has\nincreased dramatically. Thus, the need for automatic image enhancement\ntechniques is quite apparent. In recent years, deep learning has been used\neffectively. Here, after introducing some recently developed works on image\nenhancement, an image enhancement system based on convolutional neural networks\nis presented. Our goal is to make an effective use of two available approaches,\nconvolutional neural network and bilateral grid. In our approach, we increase\nthe training data and the model dimensions and propose a variable rate during\nthe training process. The enhancement results produced by our proposed method,\nwhile incorporating 5 different experts, show both quantitative and qualitative\nimprovements as compared to other available methods.",
    "descriptor": "",
    "authors": [
      "Saeedeh Rezaee",
      "Nezam Mahdavi-Amiri"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03888"
  },
  {
    "id": "arXiv:2112.03904",
    "title": "Hypergraph Co-Optimal Transport: Metric and Categorical Properties",
    "abstract": "Hypergraphs capture multi-way relationships in data, and they have\nconsequently seen a number of applications in higher-order network analysis,\ncomputer vision, geometry processing, and machine learning. In this paper, we\ndevelop the theoretical foundations in studying the space of hypergraphs using\ningredients from optimal transport. By enriching a hypergraph with probability\nmeasures on its nodes and hyperedges, as well as relational information\ncapturing local and global structure, we obtain a general and robust framework\nfor studying the collection of all hypergraphs. First, we introduce a\nhypergraph distance based on the co-optimal transport framework of Redko et al.\nand study its theoretical properties. Second, we formalize common methods for\ntransforming a hypergraph into a graph as maps from the space of hypergraphs to\nthe space of graphs and study their functorial properties and Lipschitz bounds.\nFinally, we demonstrate the versatility of our Hypergraph Co-Optimal Transport\n(HyperCOT) framework through various examples.",
    "descriptor": "",
    "authors": [
      "Samir Chowdhury",
      "Tom Needham",
      "Ethan Semrad",
      "Bei Wang",
      "Youjia Zhou"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.03904"
  },
  {
    "id": "arXiv:1704.01014",
    "title": "An Ontological Architecture for Orbital Debris Data",
    "abstract": "An Ontological Architecture for Orbital Debris Data",
    "descriptor": "",
    "authors": [
      "Robert J. Rovetto"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/1704.01014"
  },
  {
    "id": "arXiv:1812.10309",
    "title": "Efficiently list-edge coloring multigraphs asymptotically optimally",
    "abstract": "Efficiently list-edge coloring multigraphs asymptotically optimally",
    "descriptor": "",
    "authors": [
      "Fotis Iliopoulos",
      "Alistair Sinclair"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1812.10309"
  },
  {
    "id": "arXiv:1904.09193",
    "title": "Cantor-Bernstein implies Excluded Middle",
    "abstract": "Comments: 6pp / update: corrected an error in the intro wrt applicability of Thm 1, added a couple of acks and a ref",
    "descriptor": "\nComments: 6pp / update: corrected an error in the intro wrt applicability of Thm 1, added a couple of acks and a ref\n",
    "authors": [
      "Pierre Pradic",
      "Chad E. Brown"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1904.09193"
  },
  {
    "id": "arXiv:1906.07801",
    "title": "Safe Testing",
    "abstract": "Comments: Submitted",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Peter Gr\u00fcnwald",
      "Rianne de Heide",
      "Wouter Koolen"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/1906.07801"
  },
  {
    "id": "arXiv:1910.05065",
    "title": "A Theory of Relation Learning and Cross-domain Generalization",
    "abstract": "Comments: Includes supplemental material",
    "descriptor": "\nComments: Includes supplemental material\n",
    "authors": [
      "Leonidas A. A. Doumas",
      "Guillermo Puebla",
      "Andrea E. Martin",
      "John E. Hummel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1910.05065"
  },
  {
    "id": "arXiv:1910.13620",
    "title": "Algorithmic Randomness in Continuous-Time Markov Chains",
    "abstract": "Algorithmic Randomness in Continuous-Time Markov Chains",
    "descriptor": "",
    "authors": [
      "Xiang Huang",
      "Jack H. Lutz",
      "Andrei N. Migunov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Logic in Computer Science (cs.LO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1910.13620"
  },
  {
    "id": "arXiv:2003.00400",
    "title": "Learn Task First or Learn Human Partner First: A Hierarchical Task  Decomposition Method for Human-Robot Cooperation",
    "abstract": "Comments: Accepted by SMC2021",
    "descriptor": "\nComments: Accepted by SMC2021\n",
    "authors": [
      "Lingfeng Tao",
      "Michael Bowman",
      "Jiucai Zhang",
      "Xiaoli Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2003.00400"
  },
  {
    "id": "arXiv:2003.08907",
    "title": "Overinterpretation reveals image classification model pathologies",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Brandon Carter",
      "Siddhartha Jain",
      "Jonas Mueller",
      "David Gifford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.08907"
  },
  {
    "id": "arXiv:2003.12523",
    "title": "On the utilization of Macroscopic Information for String Stability of a  Vehicular Platoon",
    "abstract": "On the utilization of Macroscopic Information for String Stability of a  Vehicular Platoon",
    "descriptor": "",
    "authors": [
      "Marco Mirabilio",
      "Alessio Iovine",
      "Elena De Santis",
      "Maria Domenica Di Benedetto",
      "Giordano Pola"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2003.12523"
  },
  {
    "id": "arXiv:2004.09281",
    "title": "Tractable Approximate Gaussian Inference for Bayesian Neural Networks",
    "abstract": "Tractable Approximate Gaussian Inference for Bayesian Neural Networks",
    "descriptor": "",
    "authors": [
      "James-A. Goulet",
      "Luong Ha Nguyen",
      "Saeid Amiri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.09281"
  },
  {
    "id": "arXiv:2005.14707",
    "title": "Towards Context-Agnostic Learning Using Synthetic Data",
    "abstract": "Comments: Appearing at NeurIPS 2021. Code is available at this https URL",
    "descriptor": "\nComments: Appearing at NeurIPS 2021. Code is available at this https URL\n",
    "authors": [
      "Charles Jin",
      "Martin Rinard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.14707"
  },
  {
    "id": "arXiv:2006.00452",
    "title": "Crossed-Time Delay Neural Network for Speaker Recognition",
    "abstract": "Comments: MMM 2021 Paper, add GitHub address",
    "descriptor": "\nComments: MMM 2021 Paper, add GitHub address\n",
    "authors": [
      "Liang Chen",
      "Yanchun Liang",
      "Xiaohu Shi",
      "You Zhou",
      "Chunguo Wu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2006.00452"
  },
  {
    "id": "arXiv:2006.06422",
    "title": "String Stability of a Vehicular Platoon with the use of Macroscopic  Information",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2003.12523",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2003.12523\n",
    "authors": [
      "Marco Mirabilio",
      "Alessio Iovine",
      "Elena De Santis",
      "Maria Domenica Di Benedetto",
      "Giordano Pola"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.06422"
  },
  {
    "id": "arXiv:2006.06966",
    "title": "RISCuer: A Reliable Multi-UAV Search and Rescue Testbed",
    "abstract": "Comments: Book chapter: 41 pages, 27 figures (Minor revision: Corrected references)",
    "descriptor": "\nComments: Book chapter: 41 pages, 27 figures (Minor revision: Corrected references)\n",
    "authors": [
      "Mohamed Abdelkader",
      "Usman A. Fiaz",
      "Noureddine Toumi",
      "Mohamed A. Mabrok",
      "Jeff S. Shamma"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2006.06966"
  },
  {
    "id": "arXiv:2006.08485",
    "title": "A Faithful Binary Circuit Model with Adversarial Noise",
    "abstract": "Comments: 9 pages, 9 figures, extended version of a paper which was accepted at DATE'18",
    "descriptor": "\nComments: 9 pages, 9 figures, extended version of a paper which was accepted at DATE'18\n",
    "authors": [
      "Matthias F\u00fcgger",
      "J\u00fcrgen Maier",
      "Robert Najvirt",
      "Thomas Nowak",
      "Ulrich Schmid"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2006.08485"
  },
  {
    "id": "arXiv:2007.01795",
    "title": "Multi-Winner Voting with Approval Preferences",
    "abstract": "Comments: This is a draft of the upcoming book \"Multi-Winner Voting with Approval Preferences\"",
    "descriptor": "\nComments: This is a draft of the upcoming book \"Multi-Winner Voting with Approval Preferences\"\n",
    "authors": [
      "Martin Lackner",
      "Piotr Skowron"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2007.01795"
  },
  {
    "id": "arXiv:2007.04178",
    "title": "Evaluation for Weakly Supervised Object Localization: Protocol, Metrics,  and Datasets",
    "abstract": "Comments: TPAMI submission. First two authors contributed equally. This is a journal extension of our CVPR 2020 paper arXiv:2001.07437. Code: this https URL",
    "descriptor": "\nComments: TPAMI submission. First two authors contributed equally. This is a journal extension of our CVPR 2020 paper arXiv:2001.07437. Code: this https URL\n",
    "authors": [
      "Junsuk Choe",
      "Seong Joon Oh",
      "Sanghyuk Chun",
      "Seungho Lee",
      "Zeynep Akata",
      "Hyunjung Shim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.04178"
  },
  {
    "id": "arXiv:2007.14596",
    "title": "The Contact and Mobility Networks of Mexico City",
    "abstract": "The Contact and Mobility Networks of Mexico City",
    "descriptor": "",
    "authors": [
      "Guillermo de Anda-J\u00e1uregui",
      "Plinio Guzm\u00e1n",
      "Oscar Fontanelli",
      "Amilcar Meneses",
      "Alfredo Hern\u00e1ndez",
      "Janeth de Anda-Gil",
      "Marisol Flores Garrido",
      "Maribel Hern\u00e1ndez-Rosales"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2007.14596"
  },
  {
    "id": "arXiv:2008.07912",
    "title": "Inductive logic programming at 30: a new introduction",
    "abstract": "Comments: Paper under review",
    "descriptor": "\nComments: Paper under review\n",
    "authors": [
      "Andrew Cropper",
      "Sebastijan Duman\u010di\u0107"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.07912"
  },
  {
    "id": "arXiv:2008.12595",
    "title": "Dynamical Variational Autoencoders: A Comprehensive Review",
    "abstract": "Comments: This document corresponds to the submitted version of the paper. The revised and final version can be found in the web page of the publisher: this https URL",
    "descriptor": "\nComments: This document corresponds to the submitted version of the paper. The revised and final version can be found in the web page of the publisher: this https URL\n",
    "authors": [
      "Laurent Girin",
      "Simon Leglaive",
      "Xiaoyu Bie",
      "Julien Diard",
      "Thomas Hueber",
      "Xavier Alameda-Pineda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.12595"
  },
  {
    "id": "arXiv:2008.13336",
    "title": "Shape Defense Against Adversarial Attacks",
    "abstract": "Shape Defense Against Adversarial Attacks",
    "descriptor": "",
    "authors": [
      "Ali Borji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.13336"
  },
  {
    "id": "arXiv:2009.04796",
    "title": "XCM: An Explainable Convolutional Neural Network for Multivariate Time  Series Classification",
    "abstract": "Comments: Accepted for publication in Mathematics. Another machine learning method for multivariate time series classification providing faithful explanations is presented in arXiv:2005.03645",
    "descriptor": "\nComments: Accepted for publication in Mathematics. Another machine learning method for multivariate time series classification providing faithful explanations is presented in arXiv:2005.03645\n",
    "authors": [
      "Kevin Fauvel",
      "Tao Lin",
      "V\u00e9ronique Masson",
      "\u00c9lisa Fromont",
      "Alexandre Termier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.04796"
  },
  {
    "id": "arXiv:2009.08427",
    "title": "Discovering Dynamic Salient Regions for Spatio-Temporal Graph Neural  Networks",
    "abstract": "Comments: Accepted at Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: Accepted at Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Iulia Duta",
      "Andrei Nicolicioiu",
      "Marius Leordeanu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.08427"
  },
  {
    "id": "arXiv:2010.08222",
    "title": "Towards Tight Communication Lower Bounds for Distributed Optimisation",
    "abstract": "Towards Tight Communication Lower Bounds for Distributed Optimisation",
    "descriptor": "",
    "authors": [
      "Dan Alistarh",
      "Janne H. Korhonen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2010.08222"
  },
  {
    "id": "arXiv:2010.08261",
    "title": "Relating Functional and Imperative Session Types",
    "abstract": "Comments: 39 pages, insubmission",
    "descriptor": "\nComments: 39 pages, insubmission\n",
    "authors": [
      "Hannes Saffrich",
      "Peter Thiemann"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2010.08261"
  },
  {
    "id": "arXiv:2010.09505",
    "title": "Gray codes for Fibonacci q-decreasing words",
    "abstract": "Comments: 19 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 19 pages, 5 figures, 3 tables\n",
    "authors": [
      "Jean-Luc Baril",
      "Sergey Kirgizov",
      "Vincent Vajnovszki"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2010.09505"
  },
  {
    "id": "arXiv:2010.11914",
    "title": "Gaussoids are two-antecedental approximations of Gaussian conditional  independence structures",
    "abstract": "Comments: 24 pages; v3: added Preliminaries section; corrected miscalculations in examples and added source code link",
    "descriptor": "\nComments: 24 pages; v3: added Preliminaries section; corrected miscalculations in examples and added source code link\n",
    "authors": [
      "Tobias Boege"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.11914"
  },
  {
    "id": "arXiv:2011.01805",
    "title": "HeLayers: A Tile Tensors Framework for Large Neural Networks on  Encrypted Data",
    "abstract": "Comments: 17 pages, 7 figures",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Ehud Aharoni",
      "Allon Adir",
      "Moran Baruch",
      "Nir Drucker",
      "Gilad Ezov",
      "Ariel Farkash",
      "Lev Greenberg",
      "Ramy Masalha",
      "Guy Moshkowich",
      "Dov Murik",
      "Hayim Shaul",
      "Omri Soceanu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.01805"
  },
  {
    "id": "arXiv:2011.05625",
    "title": "CAN: Feature Co-Action for Click-Through Rate Prediction",
    "abstract": "Comments: WSDM 2022",
    "descriptor": "\nComments: WSDM 2022\n",
    "authors": [
      "Weijie Bian",
      "Kailun Wu",
      "Lejian Ren",
      "Qi Pi",
      "Yujing Zhang",
      "Can Xiao",
      "Xiang-Rong Sheng",
      "Yong-Nan Zhu",
      "Zhangming Chan",
      "Na Mou",
      "Xinchen Luo",
      "Shiming Xiang",
      "Guorui Zhou",
      "Xiaoqiang Zhu",
      "Hongbo Deng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.05625"
  },
  {
    "id": "arXiv:2011.09218",
    "title": "Modelling imperfect knowledge via location semantics for realistic  privacy risks estimation in trajectory data",
    "abstract": "Modelling imperfect knowledge via location semantics for realistic  privacy risks estimation in trajectory data",
    "descriptor": "",
    "authors": [
      "Stefano Bennati",
      "Aleksandra Kovacevic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.09218"
  },
  {
    "id": "arXiv:2011.12193",
    "title": "xFraud: Explainable Fraud Transaction Detection",
    "abstract": "Comments: This is the extended version of a full paper to appear in PVLDB 15 (3) (VLDB 2022)",
    "descriptor": "\nComments: This is the extended version of a full paper to appear in PVLDB 15 (3) (VLDB 2022)\n",
    "authors": [
      "Susie Xi Rao",
      "Shuai Zhang",
      "Zhichao Han",
      "Zitao Zhang",
      "Wei Min",
      "Zhiyao Chen",
      "Yinan Shan",
      "Yang Zhao",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2011.12193"
  },
  {
    "id": "arXiv:2011.12639",
    "title": "Computation of Feedback Control Laws Based on Switched Tracking of  Demonstrations",
    "abstract": "Comments: 36 pages",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Ji\u0159\u00ed Fejlek",
      "Stefan Ratschan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.12639"
  },
  {
    "id": "arXiv:2012.09090",
    "title": "You Are What You Tweet: Profiling Users by Past Tweets to Improve Hate  Speech Detection",
    "abstract": "You Are What You Tweet: Profiling Users by Past Tweets to Improve Hate  Speech Detection",
    "descriptor": "",
    "authors": [
      "Prateek Chaudhry",
      "Matthew Lease"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.09090"
  },
  {
    "id": "arXiv:2012.10773",
    "title": "Forming Human-Robot Cooperation for Tasks with General Goal using  Evolutionary Value Learning",
    "abstract": "Comments: Accepted by RAL",
    "descriptor": "\nComments: Accepted by RAL\n",
    "authors": [
      "Lingfeng Tao",
      "Michael Bowman",
      "Jiucai Zhang",
      "Xiaoli Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.10773"
  },
  {
    "id": "arXiv:2101.06482",
    "title": "A Renormalization Group Approach to Connect Discrete- and  Continuous-Time Descriptions of Gaussian Processes",
    "abstract": "Comments: 13 pages, 3 figures, 1 table",
    "descriptor": "\nComments: 13 pages, 3 figures, 1 table\n",
    "authors": [
      "Federica Ferretti",
      "Victor Chard\u00e8s",
      "Thierry Mora",
      "Aleksandra M Walczak",
      "Irene Giardina"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.06482"
  },
  {
    "id": "arXiv:2101.07415",
    "title": "ES-ENAS: Blackbox Optimization over Hybrid Spaces via Combinatorial and  Continuous Evolution",
    "abstract": "Comments: 22 pages. See this https URL for associated code",
    "descriptor": "\nComments: 22 pages. See this https URL for associated code\n",
    "authors": [
      "Xingyou Song",
      "Krzysztof Choromanski",
      "Jack Parker-Holder",
      "Yunhao Tang",
      "Qiuyi Zhang",
      "Daiyi Peng",
      "Deepali Jain",
      "Wenbo Gao",
      "Aldo Pacchiano",
      "Tamas Sarlos",
      "Yuxiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.07415"
  },
  {
    "id": "arXiv:2101.10238",
    "title": "Mismatched decoding reliability function at zero rate",
    "abstract": "Mismatched decoding reliability function at zero rate",
    "descriptor": "",
    "authors": [
      "Marco Bondaschi",
      "Albert Guill\u00e9n i F\u00e0bregas",
      "Marco Dalai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.10238"
  },
  {
    "id": "arXiv:2101.11805",
    "title": "Chronological age estimation of lateral cephalometric radiographs with  deep learning",
    "abstract": "Chronological age estimation of lateral cephalometric radiographs with  deep learning",
    "descriptor": "",
    "authors": [
      "Ningtao Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.11805"
  },
  {
    "id": "arXiv:2102.01635",
    "title": "An offline-online strategy for multiscale problems with random defects",
    "abstract": "An offline-online strategy for multiscale problems with random defects",
    "descriptor": "",
    "authors": [
      "Axel M\u00e5lqvist",
      "Barbara Verf\u00fcrth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.01635"
  },
  {
    "id": "arXiv:2102.02597",
    "title": "A Faster Algorithm for Finding Closest Pairs in Hamming Metric",
    "abstract": "Comments: 22, 6 figures code: this https URL",
    "descriptor": "\nComments: 22, 6 figures code: this https URL\n",
    "authors": [
      "Andre Esser",
      "Robert K\u00fcbler",
      "Floyd Zweydinger"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.02597"
  },
  {
    "id": "arXiv:2102.04159",
    "title": "Deep Residual Learning in Spiking Neural Networks",
    "abstract": "Comments: Accepted by Advances in Neural Information Processing Systems (NeurIPS) 2021",
    "descriptor": "\nComments: Accepted by Advances in Neural Information Processing Systems (NeurIPS) 2021\n",
    "authors": [
      "Wei Fang",
      "Zhaofei Yu",
      "Yanqi Chen",
      "Tiejun Huang",
      "Timoth\u00e9e Masquelier",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2102.04159"
  },
  {
    "id": "arXiv:2102.11166",
    "title": "On the Axiomatisability of Parallel Composition",
    "abstract": "On the Axiomatisability of Parallel Composition",
    "descriptor": "",
    "authors": [
      "Luca Aceto",
      "Valentina Castiglioni",
      "Anna Ingolfsdottir",
      "Bas Luttik",
      "Mathias R. Pedersen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.11166"
  },
  {
    "id": "arXiv:2102.11859",
    "title": "STEP: Segmenting and Tracking Every Pixel",
    "abstract": "Comments: Accepted to NeurIPS 2021 Track on Datasets and Benchmarks. Code: this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 Track on Datasets and Benchmarks. Code: this https URL\n",
    "authors": [
      "Mark Weber",
      "Jun Xie",
      "Maxwell Collins",
      "Yukun Zhu",
      "Paul Voigtlaender",
      "Hartwig Adam",
      "Bradley Green",
      "Andreas Geiger",
      "Bastian Leibe",
      "Daniel Cremers",
      "Aljo\u0161a O\u0161ep",
      "Laura Leal-Taix\u00e9",
      "Liang-Chieh Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.11859"
  },
  {
    "id": "arXiv:2102.12060",
    "title": "Teach Me to Explain: A Review of Datasets for Explainable Natural  Language Processing",
    "abstract": "Comments: v3: NeurIPS 2021 accepted paper camera-ready version. The content of v3 is almost the same as of v1-2 but is more condensed. v4: Fixed a typo in the title and added acknowledgements. 10 pages main, 6 pages appendix",
    "descriptor": "\nComments: v3: NeurIPS 2021 accepted paper camera-ready version. The content of v3 is almost the same as of v1-2 but is more condensed. v4: Fixed a typo in the title and added acknowledgements. 10 pages main, 6 pages appendix\n",
    "authors": [
      "Sarah Wiegreffe",
      "Ana Marasovi\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12060"
  },
  {
    "id": "arXiv:2102.12562",
    "title": "Approximating the Derivative of Manifold-valued Functions",
    "abstract": "Comments: 25 pages, 5 figures",
    "descriptor": "\nComments: 25 pages, 5 figures\n",
    "authors": [
      "Ralf Hielscher",
      "Laura Lippert"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2102.12562"
  },
  {
    "id": "arXiv:2102.13276",
    "title": "Spectral Top-Down Recovery of Latent Tree Models",
    "abstract": "Spectral Top-Down Recovery of Latent Tree Models",
    "descriptor": "",
    "authors": [
      "Yariv Aizenbud",
      "Ariel Jaffe",
      "Meng Wang",
      "Amber Hu",
      "Noah Amsel",
      "Boaz Nadler",
      "Joseph T. Chang",
      "Yuval Kluger"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2102.13276"
  },
  {
    "id": "arXiv:2103.00139",
    "title": "Scalable Causal Domain Adaptation",
    "abstract": "Scalable Causal Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Mohammad Ali Javidian",
      "Om Pandey",
      "Pooyan Jamshidi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.00139"
  },
  {
    "id": "arXiv:2103.06169",
    "title": "On the primitivity of the AES-128 key-schedule",
    "abstract": "On the primitivity of the AES-128 key-schedule",
    "descriptor": "",
    "authors": [
      "Riccardo Aragona",
      "Roberto Civino",
      "Francesca Dalla Volta"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.06169"
  },
  {
    "id": "arXiv:2103.08245",
    "title": "Emergence of Self-Reproducing Metabolisms as Recursive Algorithms in an  Artificial Chemistry",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2003.07916",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2003.07916\n",
    "authors": [
      "Germ\u00e1n Kruszewski",
      "Tomas Mikolov"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2103.08245"
  },
  {
    "id": "arXiv:2103.10132",
    "title": "An efficient algorithm to compute the exponential of skew-Hermitian  matrices for the time integration of the Schr\u00f6dinger equation",
    "abstract": "An efficient algorithm to compute the exponential of skew-Hermitian  matrices for the time integration of the Schr\u00f6dinger equation",
    "descriptor": "",
    "authors": [
      "Philipp Bader",
      "Sergio Blanes",
      "Fernando Casas",
      "Muaz Seydao\u011flu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.10132"
  },
  {
    "id": "arXiv:2103.11784",
    "title": "Towards Ultra-Resolution Neural Style Transfer via Thumbnail Instance  Normalization",
    "abstract": "Comments: 10 pages, 13 figures",
    "descriptor": "\nComments: 10 pages, 13 figures\n",
    "authors": [
      "Zhe Chen",
      "Wenhai Wang",
      "Enze Xie",
      "Tong Lu",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.11784"
  },
  {
    "id": "arXiv:2103.13973",
    "title": "Learning Temporal Quantum Tomography",
    "abstract": "Comments: Main: 6 pages, 4 figures; Supplementary: 29 pages -&gt; Revised version; Close to the accepted version. The results of tomography task for the quantum switch have been added to the Supplementary Material",
    "descriptor": "\nComments: Main: 6 pages, 4 figures; Supplementary: 29 pages -&gt; Revised version; Close to the accepted version. The results of tomography task for the quantum switch have been added to the Supplementary Material\n",
    "authors": [
      "Quoc Hoan Tran",
      "Kohei Nakajima"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2103.13973"
  },
  {
    "id": "arXiv:2103.16355",
    "title": "Nonlinear Weighted Directed Acyclic Graph and A Priori Estimates for  Neural Networks",
    "abstract": "Nonlinear Weighted Directed Acyclic Graph and A Priori Estimates for  Neural Networks",
    "descriptor": "",
    "authors": [
      "Yuqing Li",
      "Tao Luo",
      "Chao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.16355"
  },
  {
    "id": "arXiv:2104.00269",
    "title": "The Compact Support Neural Network",
    "abstract": "Comments: 13 pages, 6 figures",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Adrian Barbu",
      "Hongyu Mou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.00269"
  },
  {
    "id": "arXiv:2104.00352",
    "title": "Decentralized and Model-Free Federated Learning: Consensus-Based  Distillation in Function Space",
    "abstract": "Comments: submitted to IEEE TSIPN",
    "descriptor": "\nComments: submitted to IEEE TSIPN\n",
    "authors": [
      "Akihito Taya",
      "Takayuki Nishio",
      "Masahiro Morikura",
      "Koji Yamamoto"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.00352"
  },
  {
    "id": "arXiv:2104.01546",
    "title": "Graph Sampling Based Deep Metric Learning for Generalizable Person  Re-Identification",
    "abstract": "Graph Sampling Based Deep Metric Learning for Generalizable Person  Re-Identification",
    "descriptor": "",
    "authors": [
      "Shengcai Liao",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.01546"
  },
  {
    "id": "arXiv:2104.01714",
    "title": "Urysohn Forest for Aleatoric Uncertainty Quantification",
    "abstract": "Urysohn Forest for Aleatoric Uncertainty Quantification",
    "descriptor": "",
    "authors": [
      "Michael Poluektov",
      "Andrew Polar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.01714"
  },
  {
    "id": "arXiv:2104.03642",
    "title": "CLIMAT: Clinically-Inspired Multi-Agent Transformers for Knee  Osteoarthritis Trajectory Forecasting",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Huy Hoang Nguyen",
      "Simo Saarakkala",
      "Matthew B. Blaschko",
      "Aleksei Tiulpin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03642"
  },
  {
    "id": "arXiv:2104.09455",
    "title": "Arithmetic-Intensity-Guided Fault Tolerance for Neural Network Inference  on GPUs",
    "abstract": "Comments: Appeared in The International Conference for High Performance Computing, Networking, Storage and Analysis (SC '21), November 14--19, 2021, St. Louis, MO, USA",
    "descriptor": "\nComments: Appeared in The International Conference for High Performance Computing, Networking, Storage and Analysis (SC '21), November 14--19, 2021, St. Louis, MO, USA\n",
    "authors": [
      "Jack Kosaian",
      "K. V. Rashmi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09455"
  },
  {
    "id": "arXiv:2104.11178",
    "title": "VATT: Transformers for Multimodal Self-Supervised Learning from Raw  Video, Audio and Text",
    "abstract": "Comments: Published in the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: Published in the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Hassan Akbari",
      "Liangzhe Yuan",
      "Rui Qian",
      "Wei-Hong Chuang",
      "Shih-Fu Chang",
      "Yin Cui",
      "Boqing Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.11178"
  },
  {
    "id": "arXiv:2104.14528",
    "title": "GasHis-Transformer: A Multi-scale Visual Transformer Approach for  Gastric Histopathology Image Classification",
    "abstract": "GasHis-Transformer: A Multi-scale Visual Transformer Approach for  Gastric Histopathology Image Classification",
    "descriptor": "",
    "authors": [
      "Haoyuan Chen",
      "Chen Li",
      "Xiaoyan Li",
      "Ge Wang",
      "Weiming Hu",
      "Yixin Li",
      "Wanli Liu",
      "Changhao Sun",
      "Yudong Yao",
      "Yueyang Teng",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.14528"
  },
  {
    "id": "arXiv:2104.14759",
    "title": "Non-Deterministic Functions as Non-Deterministic Processes (Extended  Version)",
    "abstract": "Comments: Extended version of an FSCD 2021 paper. 49 pages plus appendices with full proofs",
    "descriptor": "\nComments: Extended version of an FSCD 2021 paper. 49 pages plus appendices with full proofs\n",
    "authors": [
      "Joseph W. N. Paulus",
      "Daniele Nantes-Sobrinho",
      "Jorge A. P\u00e9rez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.14759"
  },
  {
    "id": "arXiv:2105.00149",
    "title": "SVT-Net: Super Light-Weight Sparse Voxel Transformer for Large Scale  Place Recognition",
    "abstract": "Comments: accepted to AAAI 2022",
    "descriptor": "\nComments: accepted to AAAI 2022\n",
    "authors": [
      "Zhaoxin Fan",
      "Zhenbo Song",
      "Hongyan Liu",
      "Zhiwu Lu",
      "Jun He",
      "Xiaoyong Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.00149"
  },
  {
    "id": "arXiv:2105.00949",
    "title": "CMA-Net: A Cascaded Mutual Attention Network for Light Field Salient  Object Detection",
    "abstract": "Comments: 6 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: 6 pages, 4 figures, 2 tables\n",
    "authors": [
      "Yi Zhang",
      "Lu Zhang",
      "Wassim Hamidouche",
      "Olivier Deforges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.00949"
  },
  {
    "id": "arXiv:2105.03389",
    "title": "GADTs, Functoriality, Parametricity: Pick Two",
    "abstract": "GADTs, Functoriality, Parametricity: Pick Two",
    "descriptor": "",
    "authors": [
      "Patricia Johann",
      "Enrico Ghiorzi",
      "Daniel Jeffries"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.03389"
  },
  {
    "id": "arXiv:2105.04040",
    "title": "Truly shift-equivariant convolutional neural networks with adaptive  polyphase upsampling",
    "abstract": "Truly shift-equivariant convolutional neural networks with adaptive  polyphase upsampling",
    "descriptor": "",
    "authors": [
      "Anadi Chaman",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.04040"
  },
  {
    "id": "arXiv:2105.06903",
    "title": "Posterior Regularization on Bayesian Hierarchical Mixture Clustering",
    "abstract": "Posterior Regularization on Bayesian Hierarchical Mixture Clustering",
    "descriptor": "",
    "authors": [
      "Weipeng Huang",
      "Tin Lok James Ng",
      "Nishma Laitonjam",
      "Neil J. Hurley"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.06903"
  },
  {
    "id": "arXiv:2105.07562",
    "title": "Power-grid stability predictions using transferable machine learning",
    "abstract": "Comments: 10 pages, 6 figures, 4 tables",
    "descriptor": "\nComments: 10 pages, 6 figures, 4 tables\n",
    "authors": [
      "Seong-Gyu Yang",
      "Beom Jun Kim",
      "Seung-Woo Son",
      "Heetae Kim"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.07562"
  },
  {
    "id": "arXiv:2105.08155",
    "title": "(Deep) Induction Rules for GADTs",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Patricia Johann",
      "Enrico Ghiorzi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.08155"
  },
  {
    "id": "arXiv:2105.14432",
    "title": "TransMatcher: Deep Image Matching Through Transformers for Generalizable  Person Re-identification",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Shengcai Liao",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14432"
  },
  {
    "id": "arXiv:2106.00198",
    "title": "Gradient play in stochastic games: stationary points, convergence, and  sample complexity",
    "abstract": "Gradient play in stochastic games: stationary points, convergence, and  sample complexity",
    "descriptor": "",
    "authors": [
      "Runyu Zhang",
      "Zhaolin Ren",
      "Na Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.00198"
  },
  {
    "id": "arXiv:2106.00886",
    "title": "Partial Wasserstein Covering",
    "abstract": "Partial Wasserstein Covering",
    "descriptor": "",
    "authors": [
      "Keisuke Kawano",
      "Satoshi Koide",
      "Keisuke Otaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00886"
  },
  {
    "id": "arXiv:2106.01357",
    "title": "Diffusion Schr\u00f6dinger Bridge with Applications to Score-Based  Generative Modeling",
    "abstract": "Comments: 58 pages, 18 figures (correction of Proposition 5)",
    "descriptor": "\nComments: 58 pages, 18 figures (correction of Proposition 5)\n",
    "authors": [
      "Valentin De Bortoli",
      "James Thornton",
      "Jeremy Heng",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.01357"
  },
  {
    "id": "arXiv:2106.01686",
    "title": "AliCG: Fine-grained and Evolvable Conceptual Graph Construction for  Semantic Search at Alibaba",
    "abstract": "Comments: Accepted by KDD 2021 (Applied Data Science Track)",
    "descriptor": "\nComments: Accepted by KDD 2021 (Applied Data Science Track)\n",
    "authors": [
      "Ningyu Zhang",
      "Qianghuai Jia",
      "Shumin Deng",
      "Xiang Chen",
      "Hongbin Ye",
      "Hui Chen",
      "Huaixiao Tou",
      "Gang Huang",
      "Zhao Wang",
      "Nengwei Hua",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01686"
  },
  {
    "id": "arXiv:2106.01693",
    "title": "Bridging the Multiscale Hybrid-Mixed and Multiscale Hybrid High-Order  methods",
    "abstract": "Bridging the Multiscale Hybrid-Mixed and Multiscale Hybrid High-Order  methods",
    "descriptor": "",
    "authors": [
      "T. Chaumont-Frelet",
      "A. Ern",
      "S. Lemaire",
      "F. Valentin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01693"
  },
  {
    "id": "arXiv:2106.03348",
    "title": "ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias",
    "abstract": "Comments: Accepted by NeurIPS 2021, 23 pages, including downstream task results (detection, semantic segmentation, human pose, and video object segmentation)",
    "descriptor": "\nComments: Accepted by NeurIPS 2021, 23 pages, including downstream task results (detection, semantic segmentation, human pose, and video object segmentation)\n",
    "authors": [
      "Yufei Xu",
      "Qiming Zhang",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03348"
  },
  {
    "id": "arXiv:2106.03553",
    "title": "Playing with words: Do people exploit loaded language to affect others'  decisions for their own benefit?",
    "abstract": "Comments: in press at Judgment and Decision Making",
    "descriptor": "\nComments: in press at Judgment and Decision Making\n",
    "authors": [
      "Valerio Capraro",
      "Andrea Vanzo",
      "Antonio Cabrales"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2106.03553"
  },
  {
    "id": "arXiv:2106.03907",
    "title": "Deep Proxy Causal Learning and its Application to Confounded Bandit  Policy Evaluation",
    "abstract": "Deep Proxy Causal Learning and its Application to Confounded Bandit  Policy Evaluation",
    "descriptor": "",
    "authors": [
      "Liyuan Xu",
      "Heishiro Kanagawa",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03907"
  },
  {
    "id": "arXiv:2106.04015",
    "title": "Uncertainty Baselines: Benchmarks for Uncertainty & Robustness in Deep  Learning",
    "abstract": "Uncertainty Baselines: Benchmarks for Uncertainty & Robustness in Deep  Learning",
    "descriptor": "",
    "authors": [
      "Zachary Nado",
      "Neil Band",
      "Mark Collier",
      "Josip Djolonga",
      "Michael W. Dusenberry",
      "Sebastian Farquhar",
      "Qixuan Feng",
      "Angelos Filos",
      "Marton Havasi",
      "Rodolphe Jenatton",
      "Ghassen Jerfel",
      "Jeremiah Liu",
      "Zelda Mariet",
      "Jeremy Nixon",
      "Shreyas Padhy",
      "Jie Ren",
      "Tim G. J. Rudner",
      "Yeming Wen",
      "Florian Wenzel",
      "Kevin Murphy",
      "D. Sculley",
      "Balaji Lakshminarayanan",
      "Jasper Snoek",
      "Yarin Gal",
      "Dustin Tran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04015"
  },
  {
    "id": "arXiv:2106.04677",
    "title": "Differential Entropy of the Conditional Expectation under Gaussian Noise",
    "abstract": "Comments: Partially presented at the 2021 IEEE Information Theory Workshop, Japan",
    "descriptor": "\nComments: Partially presented at the 2021 IEEE Information Theory Workshop, Japan\n",
    "authors": [
      "Arda Atalik",
      "Alper K\u00f6se",
      "Michael Gastpar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.04677"
  },
  {
    "id": "arXiv:2106.09524",
    "title": "Implicit Bias of SGD for Diagonal Linear Networks: a Provable Benefit of  Stochasticity",
    "abstract": "Implicit Bias of SGD for Diagonal Linear Networks: a Provable Benefit of  Stochasticity",
    "descriptor": "",
    "authors": [
      "Scott Pesme",
      "Loucas Pillaud-Vivien",
      "Nicolas Flammarion"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09524"
  },
  {
    "id": "arXiv:2106.11297",
    "title": "TokenLearner: What Can 8 Learned Tokens Do for Images and Videos?",
    "abstract": "Comments: This is an extended version of the paper to appear at NeurIPS 2021. Code released",
    "descriptor": "\nComments: This is an extended version of the paper to appear at NeurIPS 2021. Code released\n",
    "authors": [
      "Michael S. Ryoo",
      "AJ Piergiovanni",
      "Anurag Arnab",
      "Mostafa Dehghani",
      "Anelia Angelova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11297"
  },
  {
    "id": "arXiv:2106.12233",
    "title": "Testing of Autonomous Driving Systems: where are we and where should we  go?",
    "abstract": "Testing of Autonomous Driving Systems: where are we and where should we  go?",
    "descriptor": "",
    "authors": [
      "Guannan Lou",
      "Yao Deng",
      "Xi Zheng",
      "Tianyi Zhang",
      "Mengshi Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.12233"
  },
  {
    "id": "arXiv:2106.15577",
    "title": "As easy as APC: overcoming missing data and class imbalance in time  series with self-supervised learning",
    "abstract": "Comments: Accepted to the NeurIPS 2021 Workshop on Self-Supervised Learning: Theory and Practice",
    "descriptor": "\nComments: Accepted to the NeurIPS 2021 Workshop on Self-Supervised Learning: Theory and Practice\n",
    "authors": [
      "Fiorella Wever",
      "T. Anderson Keller",
      "Victor Garcia",
      "Laura Symul"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.15577"
  },
  {
    "id": "arXiv:2107.00783",
    "title": "Reinforcement Learning for Feedback-Enabled Cyber Resilience",
    "abstract": "Reinforcement Learning for Feedback-Enabled Cyber Resilience",
    "descriptor": "",
    "authors": [
      "Yunhan Huang",
      "Linan Huang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00783"
  },
  {
    "id": "arXiv:2107.01163",
    "title": "Unveiling the structure of wide flat minima in neural networks",
    "abstract": "Comments: 15 pages, 8 figures",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Carlo Baldassi",
      "Clarissa Lauditi",
      "Enrico M. Malatesta",
      "Gabriele Perugini",
      "Riccardo Zecchina"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.01163"
  },
  {
    "id": "arXiv:2107.02192",
    "title": "Long-Short Transformer: Efficient Transformers for Language and Vision",
    "abstract": "Comments: Published at NeurIPS 2021",
    "descriptor": "\nComments: Published at NeurIPS 2021\n",
    "authors": [
      "Chen Zhu",
      "Wei Ping",
      "Chaowei Xiao",
      "Mohammad Shoeybi",
      "Tom Goldstein",
      "Anima Anandkumar",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.02192"
  },
  {
    "id": "arXiv:2107.02712",
    "title": "Network-Coded Cooperative LoRa Network with D2D Communication",
    "abstract": "Comments: 11 pages, 7 figures, published on the IEEE Internet of Things Journal",
    "descriptor": "\nComments: 11 pages, 7 figures, published on the IEEE Internet of Things Journal\n",
    "authors": [
      "L. H. O. Alves",
      "J. L. Rebelatto",
      "R. D. Souza",
      "G. Brante"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.02712"
  },
  {
    "id": "arXiv:2107.03157",
    "title": "Semilinear Transformations in Coding Theory: A New Technique in  Code-Based Cryptography",
    "abstract": "Semilinear Transformations in Coding Theory: A New Technique in  Code-Based Cryptography",
    "descriptor": "",
    "authors": [
      "Wenshuo Guo",
      "Fang-Wei Fu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.03157"
  },
  {
    "id": "arXiv:2107.03453",
    "title": "$S^3$: Sign-Sparse-Shift Reparametrization for Effective Training of  Low-bit Shift Networks",
    "abstract": "$S^3$: Sign-Sparse-Shift Reparametrization for Effective Training of  Low-bit Shift Networks",
    "descriptor": "",
    "authors": [
      "Xinlin Li",
      "Bang Liu",
      "Yaoliang Yu",
      "Wulong Liu",
      "Chunjing Xu",
      "Vahid Partovi Nia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.03453"
  },
  {
    "id": "arXiv:2107.07016",
    "title": "Forgetting in Answer Set Programming -- A Survey",
    "abstract": "Comments: Under consideration in Theory and Practice of Logic Programming (TPLP)",
    "descriptor": "\nComments: Under consideration in Theory and Practice of Logic Programming (TPLP)\n",
    "authors": [
      "Ricardo Gon\u00e7alves",
      "Matthias Knorr",
      "Jo\u00e3o Leite"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.07016"
  },
  {
    "id": "arXiv:2107.07985",
    "title": "Unpaired cross-modality educed distillation (CMEDL) for medical image  segmentation",
    "abstract": "Comments: This manuscript is has been accepted by IEEE Transactions on Medical Imaging",
    "descriptor": "\nComments: This manuscript is has been accepted by IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Jue Jiang",
      "Andreas Rimner",
      "Joseph O. Deasy",
      "Harini Veeraraghavan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07985"
  },
  {
    "id": "arXiv:2107.13147",
    "title": "Mechanical Cloak via Data-Driven Aperiodic Metamaterial Design",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Liwei Wang",
      "Jagannadh Boddapati",
      "Ke Liu",
      "Ping Zhu",
      "Chiara Daraio",
      "Wei Chen"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2107.13147"
  },
  {
    "id": "arXiv:2107.13545",
    "title": "Fully Autonomous Real-World Reinforcement Learning with Applications to  Mobile Manipulation",
    "abstract": "Comments: 16 pages, Published at CoRL 2021",
    "descriptor": "\nComments: 16 pages, Published at CoRL 2021\n",
    "authors": [
      "Charles Sun",
      "J\u0119drzej Orbik",
      "Coline Devin",
      "Brian Yang",
      "Abhishek Gupta",
      "Glen Berseth",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.13545"
  },
  {
    "id": "arXiv:2108.00106",
    "title": "Soft Calibration Objectives for Neural Networks",
    "abstract": "Comments: 17 pages total, 10 page main paper, 5 page appendix, 10 figures total, 8 figures in main paper, 2 figures in appendix",
    "descriptor": "\nComments: 17 pages total, 10 page main paper, 5 page appendix, 10 figures total, 8 figures in main paper, 2 figures in appendix\n",
    "authors": [
      "Archit Karandikar",
      "Nicholas Cain",
      "Dustin Tran",
      "Balaji Lakshminarayanan",
      "Jonathon Shlens",
      "Michael C. Mozer",
      "Becca Roelofs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.00106"
  },
  {
    "id": "arXiv:2108.00259",
    "title": "How much pre-training is enough to discover a good subnetwork?",
    "abstract": "Comments: 33 pages, 5 figures",
    "descriptor": "\nComments: 33 pages, 5 figures\n",
    "authors": [
      "Cameron R. Wolfe",
      "Qihan Wang",
      "Junhyung Lyle Kim",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.00259"
  },
  {
    "id": "arXiv:2108.06266",
    "title": "Safe Learning in Robotics: From Learning-Based Control to Safe  Reinforcement Learning",
    "abstract": "Comments: 36 pages, 8 figures",
    "descriptor": "\nComments: 36 pages, 8 figures\n",
    "authors": [
      "Lukas Brunke",
      "Melissa Greeff",
      "Adam W. Hall",
      "Zhaocong Yuan",
      "Siqi Zhou",
      "Jacopo Panerati",
      "Angela P. Schoellig"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.06266"
  },
  {
    "id": "arXiv:2108.06699",
    "title": "Efficient Anytime CLF Reactive Planning System for a Bipedal Robot on  Undulating Terrain",
    "abstract": "Efficient Anytime CLF Reactive Planning System for a Bipedal Robot on  Undulating Terrain",
    "descriptor": "",
    "authors": [
      "Jiunn-Kai Huang",
      "Jessy W. Grizzle"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.06699"
  },
  {
    "id": "arXiv:2108.07435",
    "title": "Modeling Protein Using Large-scale Pretrain Language Model",
    "abstract": "Comments: Accepted paper in Pretrain@KDD 2021 (The International Workshop on Pretraining: Algorithms, Architectures, and Applications)",
    "descriptor": "\nComments: Accepted paper in Pretrain@KDD 2021 (The International Workshop on Pretraining: Algorithms, Architectures, and Applications)\n",
    "authors": [
      "Yijia Xiao",
      "Jiezhong Qiu",
      "Ziang Li",
      "Chang-Yu Hsieh",
      "Jie Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2108.07435"
  },
  {
    "id": "arXiv:2108.08532",
    "title": "An Information Theory-inspired Strategy for Automatic Network Pruning",
    "abstract": "An Information Theory-inspired Strategy for Automatic Network Pruning",
    "descriptor": "",
    "authors": [
      "Xiawu Zheng",
      "Yuexiao Ma",
      "Teng Xi",
      "Gang Zhang",
      "Errui Ding",
      "Yuchao Li",
      "Jie Chen",
      "Yonghong Tian",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.08532"
  },
  {
    "id": "arXiv:2108.12056",
    "title": "Continual learning under domain transfer with sparse synaptic bursting",
    "abstract": "Continual learning under domain transfer with sparse synaptic bursting",
    "descriptor": "",
    "authors": [
      "Shawn L. Beaulieu",
      "Jeff Clune",
      "Nick Cheney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.12056"
  },
  {
    "id": "arXiv:2108.13468",
    "title": "A Boundary-Layer Preconditioner for Singularly Perturbed Convection  Diffusion",
    "abstract": "Comments: 23 pages, 4 figures",
    "descriptor": "\nComments: 23 pages, 4 figures\n",
    "authors": [
      "Scott P. MacLachlan",
      "Niall Madden",
      "Th\u00e1i Anh Nhan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.13468"
  },
  {
    "id": "arXiv:2109.01192",
    "title": "Log severity levels matter: A multivocal mapping",
    "abstract": "Comments: 12 pages, 4 figures, 6 tables",
    "descriptor": "\nComments: 12 pages, 4 figures, 6 tables\n",
    "authors": [
      "Eduardo Mendes",
      "Fabio Petrillo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.01192"
  },
  {
    "id": "arXiv:2109.03861",
    "title": "Recurrent Neural Network Controllers Synthesis with Stability Guarantees  for Partially Observed Systems",
    "abstract": "Recurrent Neural Network Controllers Synthesis with Stability Guarantees  for Partially Observed Systems",
    "descriptor": "",
    "authors": [
      "Fangda Gu",
      "He Yin",
      "Laurent El Ghaoui",
      "Murat Arcak",
      "Peter Seiler",
      "Ming Jin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.03861"
  },
  {
    "id": "arXiv:2109.04364",
    "title": "Detection of Epileptic Seizures on EEG Signals Using ANFIS Classifier,  Autoencoders and Fuzzy Entropies",
    "abstract": "Detection of Epileptic Seizures on EEG Signals Using ANFIS Classifier,  Autoencoders and Fuzzy Entropies",
    "descriptor": "",
    "authors": [
      "Afshin Shoeibi",
      "Navid Ghassemi",
      "Marjane Khodatars",
      "Parisa Moridian",
      "Roohallah Alizadehsani",
      "Assef Zare",
      "Abbas Khosravi",
      "Abdulhamit Subasi",
      "U. Rajendra Acharya",
      "J. Manuel Gorriz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04364"
  },
  {
    "id": "arXiv:2109.06561",
    "title": "Beyond Distributed Subgraph Detection: Induced Subgraphs, Multicolored  Problems and Graph Parameters",
    "abstract": "Beyond Distributed Subgraph Detection: Induced Subgraphs, Multicolored  Problems and Graph Parameters",
    "descriptor": "",
    "authors": [
      "Janne H. Korhonen",
      "Amir Nikabadi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.06561"
  },
  {
    "id": "arXiv:2109.07263",
    "title": "End-to-End Learning of Flowchart Grounded Task-Oriented Dialogs",
    "abstract": "Comments: This is a Post-EMNLP Version that contains results on the new hidden test set. D.Raghu and S.Agarwal contributed equally to this work",
    "descriptor": "\nComments: This is a Post-EMNLP Version that contains results on the new hidden test set. D.Raghu and S.Agarwal contributed equally to this work\n",
    "authors": [
      "Dinesh Raghu",
      "Shantanu Agarwal",
      "Sachindra Joshi",
      "Mausam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07263"
  },
  {
    "id": "arXiv:2109.07818",
    "title": "Learning logic programs through divide, constrain, and conquer",
    "abstract": "Comments: Accepted for AAAI2022",
    "descriptor": "\nComments: Accepted for AAAI2022\n",
    "authors": [
      "Andrew Cropper"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07818"
  },
  {
    "id": "arXiv:2109.09477",
    "title": "Beyond Semantic to Instance Segmentation: Weakly-Supervised Instance  Segmentation via Semantic Knowledge Transfer and Self-Refinement",
    "abstract": "Comments: 15 pages, 14 figures",
    "descriptor": "\nComments: 15 pages, 14 figures\n",
    "authors": [
      "Beomyoung Kim",
      "Youngjoon Yoo",
      "Chaeeun Rhee",
      "Junmo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.09477"
  },
  {
    "id": "arXiv:2109.10065",
    "title": "Comparison of Neural Network based Soft Computing Techniques for  Electromagnetic Modeling of a Microstrip Patch Antenna",
    "abstract": "Comments: Part of SoCTA (Soft Computing: Theories and Applications) 2021",
    "descriptor": "\nComments: Part of SoCTA (Soft Computing: Theories and Applications) 2021\n",
    "authors": [
      "Yuvraj Singh Malhi",
      "Navneet Gupta"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.10065"
  },
  {
    "id": "arXiv:2109.10252",
    "title": "Audiomer: A Convolutional Transformer For Keyword Spotting",
    "abstract": "Comments: Accepted at AAAI 2022 Dialog System Technology Challenge Workshop",
    "descriptor": "\nComments: Accepted at AAAI 2022 Dialog System Technology Challenge Workshop\n",
    "authors": [
      "Surya Kant Sahu",
      "Sai Mitheran",
      "Juhi Kamdar",
      "Meet Gandhi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.10252"
  },
  {
    "id": "arXiv:2109.10498",
    "title": "Less is More: Learning from Synthetic Data with Fine-grained Attributes  for Person Re-Identification",
    "abstract": "Comments: 21 pages with supplementary material",
    "descriptor": "\nComments: 21 pages with supplementary material\n",
    "authors": [
      "Suncheng Xiang",
      "Guanjie You",
      "Mengyuan Guan",
      "Hao Chen",
      "Binjie Yan",
      "Ting Liu",
      "Yuzhuo Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.10498"
  },
  {
    "id": "arXiv:2109.11577",
    "title": "Text Ranking and Classification using Data Compression",
    "abstract": "Text Ranking and Classification using Data Compression",
    "descriptor": "",
    "authors": [
      "Nitya Kasturi",
      "Igor L. Markov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.11577"
  },
  {
    "id": "arXiv:2109.11711",
    "title": "Stable Volumes for Persistent Homology",
    "abstract": "Stable Volumes for Persistent Homology",
    "descriptor": "",
    "authors": [
      "Ippei Obayashi"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2109.11711"
  },
  {
    "id": "arXiv:2109.12135",
    "title": "Attentive Contractive Flow: Improved Contractive Flows with  Lipschitz-constrained Self-Attention",
    "abstract": "Attentive Contractive Flow: Improved Contractive Flows with  Lipschitz-constrained Self-Attention",
    "descriptor": "",
    "authors": [
      "Avideep Mukherjee",
      "Badri Narayan Patro",
      "Sahil Sidheekh",
      "Maneesh Singh",
      "Vinay P. Namboodiri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12135"
  },
  {
    "id": "arXiv:2109.13283",
    "title": "CS Education for the Socially-Just Worlds We Need: The Case for  Justice-Centered Approaches to CS in Higher Education",
    "abstract": "Comments: Position paper in the Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 1 (SIGCSE 2022); 7 pages",
    "descriptor": "\nComments: Position paper in the Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 1 (SIGCSE 2022); 7 pages\n",
    "authors": [
      "Kevin Lin"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.13283"
  },
  {
    "id": "arXiv:2109.13871",
    "title": "Expectation-based Minimalist Grammars",
    "abstract": "Comments: This is an extended version of a paper published in CLiC-it 2021 - Italian Conference on Computational Linguistics 2021 - Proceedings of the Eighth Italian Conference on Computational Linguistics Milan, Italy, January 26-28, 2022. Edited by Elisabetta Fersini, Marco Passarotti, Viviana Patti. CEUR-WS.org, ISSN 1613-0073",
    "descriptor": "\nComments: This is an extended version of a paper published in CLiC-it 2021 - Italian Conference on Computational Linguistics 2021 - Proceedings of the Eighth Italian Conference on Computational Linguistics Milan, Italy, January 26-28, 2022. Edited by Elisabetta Fersini, Marco Passarotti, Viviana Patti. CEUR-WS.org, ISSN 1613-0073\n",
    "authors": [
      "Cristiano Chesi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.13871"
  },
  {
    "id": "arXiv:2109.14798",
    "title": "Introducing the DOME Activation Functions",
    "abstract": "Comments: 16 pages, 9 figures",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Mohamed E. Hussein",
      "Wael AbdAlmageed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.14798"
  },
  {
    "id": "arXiv:2110.00577",
    "title": "Reconstruction for Powerful Graph Representations",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Leonardo Cotta",
      "Christopher Morris",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.00577"
  },
  {
    "id": "arXiv:2110.01175",
    "title": "An Unconditionally Stable Conformal LOD-FDTD Method For Curved PEC  Objects and Its Application to EMC Problems",
    "abstract": "An Unconditionally Stable Conformal LOD-FDTD Method For Curved PEC  Objects and Its Application to EMC Problems",
    "descriptor": "",
    "authors": [
      "Hanhong Liu",
      "Xiaoying Zhao",
      "Xiang-Hua Wang",
      "Shunchuan Yang",
      "Zhizhang",
      "Chen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.01175"
  },
  {
    "id": "arXiv:2110.02852",
    "title": "Pretrained Transformers for Offensive Language Identification in  Tanglish",
    "abstract": "Comments: Accepted at FIRE 2021",
    "descriptor": "\nComments: Accepted at FIRE 2021\n",
    "authors": [
      "Sean Benhur",
      "Kanchana Sivanraju"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02852"
  },
  {
    "id": "arXiv:2110.05597",
    "title": "Learning to Coordinate in Multi-Agent Systems: A Coordinated  Actor-Critic Algorithm and Finite-Time Guarantees",
    "abstract": "Learning to Coordinate in Multi-Agent Systems: A Coordinated  Actor-Critic Algorithm and Finite-Time Guarantees",
    "descriptor": "",
    "authors": [
      "Siliang Zeng",
      "Tianyi Chen",
      "Alfredo Garcia",
      "Mingyi Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.05597"
  },
  {
    "id": "arXiv:2110.07039",
    "title": "Presenting a Larger Up-to-date Movie Dataset and Investigating the  Effects of Pre-released Attributes on Gross Revenue",
    "abstract": "Presenting a Larger Up-to-date Movie Dataset and Investigating the  Effects of Pre-released Attributes on Gross Revenue",
    "descriptor": "",
    "authors": [
      "Arnab Sen Sharma",
      "Tirtha Roy",
      "Sadique Ahmmod Rifat",
      "Maruf Ahmed Mridul"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.07039"
  },
  {
    "id": "arXiv:2110.10233",
    "title": "Forecasting Market Prices using DL with Data Augmentation and  Meta-learning: ARIMA still wins!",
    "abstract": "Comments: Camera Ready Version for ICBINB Workshop @ NeurIPS 2021",
    "descriptor": "\nComments: Camera Ready Version for ICBINB Workshop @ NeurIPS 2021\n",
    "authors": [
      "Vedant Shah",
      "Gautam Shroff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10233"
  },
  {
    "id": "arXiv:2110.10456",
    "title": "Noisy Annotation Refinement for Object Detection",
    "abstract": "Noisy Annotation Refinement for Object Detection",
    "descriptor": "",
    "authors": [
      "Jiafeng Mao",
      "Qing Yu",
      "Yoko Yamakata",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10456"
  },
  {
    "id": "arXiv:2110.11027",
    "title": "FedGEMS: Federated Learning of Larger Server Models via Selective  Knowledge Fusion",
    "abstract": "Comments: Under review as a conference paper at ICLR 2022",
    "descriptor": "\nComments: Under review as a conference paper at ICLR 2022\n",
    "authors": [
      "Sijie Cheng",
      "Jingwen Wu",
      "Yanghua Xiao",
      "Yang Liu",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11027"
  },
  {
    "id": "arXiv:2110.12544",
    "title": "Online estimation and control with optimal pathlength regret",
    "abstract": "Online estimation and control with optimal pathlength regret",
    "descriptor": "",
    "authors": [
      "Gautam Goel",
      "Babak Hassibi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.12544"
  },
  {
    "id": "arXiv:2110.13771",
    "title": "AugMax: Adversarial Composition of Random Augmentations for Robust  Training",
    "abstract": "Comments: NeurIPS, 2021",
    "descriptor": "\nComments: NeurIPS, 2021\n",
    "authors": [
      "Haotao Wang",
      "Chaowei Xiao",
      "Jean Kossaifi",
      "Zhiding Yu",
      "Anima Anandkumar",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13771"
  },
  {
    "id": "arXiv:2110.14947",
    "title": "Probabilistic Autoencoder using Fisher Information",
    "abstract": "Comments: 25 pages, 11 figures",
    "descriptor": "\nComments: 25 pages, 11 figures\n",
    "authors": [
      "Johannes Zacherl",
      "Philipp Frank",
      "Torsten A. En\u00dflin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14947"
  },
  {
    "id": "arXiv:2110.15718",
    "title": "Deep convolutional forest: a dynamic deep ensemble approach for spam  detection in text",
    "abstract": "Deep convolutional forest: a dynamic deep ensemble approach for spam  detection in text",
    "descriptor": "",
    "authors": [
      "Mai A. Shaaban",
      "Yasser F. Hassan",
      "Shawkat K. Guirguis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15718"
  },
  {
    "id": "arXiv:2110.15960",
    "title": "Support Recovery with Stochastic Gates: Theory and Application for  Linear Models",
    "abstract": "Comments: 12 pages, 3 figures, Updated plots and proof techniques in this revision. This version is submitted to IEEE signal processing letters",
    "descriptor": "\nComments: 12 pages, 3 figures, Updated plots and proof techniques in this revision. This version is submitted to IEEE signal processing letters\n",
    "authors": [
      "Soham Jana",
      "Henry Li",
      "Yutaro Yamada",
      "Ofir Lindenbaum"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15960"
  },
  {
    "id": "arXiv:2111.01218",
    "title": "Information and Communication Security Mechanisms For  Microservices-based Systems",
    "abstract": "Comments: 19 pages, 4 Figures, 5 tables",
    "descriptor": "\nComments: 19 pages, 4 Figures, 5 tables\n",
    "authors": [
      "Lenin Leines-Vite",
      "Juan Carlos P\u00e9rez-Arriaga",
      "Xavier Lim\u00f3n"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.01218"
  },
  {
    "id": "arXiv:2111.04809",
    "title": "Absence of zeros implies strong spatial mixing",
    "abstract": "Comments: 23 pages; minor error corrected in Lemma 3 and Lemma 4 and some typos corrected.. The main results are unaffected",
    "descriptor": "\nComments: 23 pages; minor error corrected in Lemma 3 and Lemma 4 and some typos corrected.. The main results are unaffected\n",
    "authors": [
      "Guus Regts"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.04809"
  },
  {
    "id": "arXiv:2111.04841",
    "title": "First equilibrium reconstruction for ITER with the code NICE",
    "abstract": "Comments: ICFRD2020",
    "descriptor": "\nComments: ICFRD2020\n",
    "authors": [
      "Blaise Faugeras",
      "Jacques Blum",
      "Cedric Boulbe"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.04841"
  },
  {
    "id": "arXiv:2111.08067",
    "title": "ModelLight: Model-Based Meta-Reinforcement Learning for Traffic Signal  Control",
    "abstract": "ModelLight: Model-Based Meta-Reinforcement Learning for Traffic Signal  Control",
    "descriptor": "",
    "authors": [
      "Xingshuai Huang",
      "Di Wu",
      "Michael Jenkin",
      "Benoit Boulet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08067"
  },
  {
    "id": "arXiv:2111.08082",
    "title": "Learning Graph Neural Networks for Multivariate Time Series Anomaly  Detection",
    "abstract": "Learning Graph Neural Networks for Multivariate Time Series Anomaly  Detection",
    "descriptor": "",
    "authors": [
      "Saswati Ray",
      "Sana Lakdawala",
      "Mononito Goswami",
      "Chufan Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08082"
  },
  {
    "id": "arXiv:2111.08095",
    "title": "TimeVAE: A Variational Auto-Encoder for Multivariate Time Series  Generation",
    "abstract": "TimeVAE: A Variational Auto-Encoder for Multivariate Time Series  Generation",
    "descriptor": "",
    "authors": [
      "Abhyuday Desai",
      "Cynthia Freeman",
      "Zuhui Wang",
      "Ian Beaver"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08095"
  },
  {
    "id": "arXiv:2111.08202",
    "title": "Learn Locally, Correct Globally: A Distributed Algorithm for Training  Graph Neural Networks",
    "abstract": "Learn Locally, Correct Globally: A Distributed Algorithm for Training  Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Morteza Ramezani",
      "Weilin Cong",
      "Mehrdad Mahdavi",
      "Mahmut T. Kandemir",
      "Anand Sivasubramaniam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08202"
  },
  {
    "id": "arXiv:2111.11154",
    "title": "Efficient formulation of a two-noded curved beam element under finite  rotations",
    "abstract": "Efficient formulation of a two-noded curved beam element under finite  rotations",
    "descriptor": "",
    "authors": [
      "Martin Hor\u00e1k",
      "Emma La Malfa Ribolla",
      "Milan Jir\u00e1sek"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.11154"
  },
  {
    "id": "arXiv:2111.11492",
    "title": "Analysis of pedestrian stress level using GSR sensor in virtual  immersive reality",
    "abstract": "Comments: Accepted for publication in Collective Dynamics. Proceedings of the 10th Pedestrian and Evacuation Dynamics, 2021",
    "descriptor": "\nComments: Accepted for publication in Collective Dynamics. Proceedings of the 10th Pedestrian and Evacuation Dynamics, 2021\n",
    "authors": [
      "Mahwish Mudassar",
      "Arash Kalatian",
      "Bilal Farooq"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.11492"
  },
  {
    "id": "arXiv:2111.11755",
    "title": "Guided-TTS:Text-to-Speech with Untranscribed Speech",
    "abstract": "Guided-TTS:Text-to-Speech with Untranscribed Speech",
    "descriptor": "",
    "authors": [
      "Heeseung Kim",
      "Sungwon Kim",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.11755"
  },
  {
    "id": "arXiv:2111.12860",
    "title": "Critical Review of Exoskeleton Technology: State of the art and  development of physical and cognitive human-robot interface",
    "abstract": "Critical Review of Exoskeleton Technology: State of the art and  development of physical and cognitive human-robot interface",
    "descriptor": "",
    "authors": [
      "Farhad Nazari",
      "Navid Mohajer",
      "Darius Nahavandi",
      "Abbas Khosravi",
      "Saeid Nahavandi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.12860"
  },
  {
    "id": "arXiv:2111.13365",
    "title": "Machines and Influence",
    "abstract": "Machines and Influence",
    "descriptor": "",
    "authors": [
      "Shashank Yadav"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.13365"
  },
  {
    "id": "arXiv:2111.14422",
    "title": "Agent-Centric Relation Graph for Object Visual Navigation",
    "abstract": "Agent-Centric Relation Graph for Object Visual Navigation",
    "descriptor": "",
    "authors": [
      "Xiaobo Hu",
      "Zhihao Wu",
      "Kai Lv",
      "Shuo Wang",
      "Youfang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14422"
  },
  {
    "id": "arXiv:2111.14482",
    "title": "High Quality Segmentation for Ultra High-resolution Images",
    "abstract": "High Quality Segmentation for Ultra High-resolution Images",
    "descriptor": "",
    "authors": [
      "Tiancheng Shen",
      "Yuechen Zhang",
      "Lu Qi",
      "Jason Kuen",
      "Xingyu Xie",
      "Jianlong Wu",
      "Zhe Lin",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14482"
  },
  {
    "id": "arXiv:2111.14592",
    "title": "GALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with  Semi-Supervised Learning and Explicit Policy Injection",
    "abstract": "Comments: 7 pages, 5 figures. Accepted by AAAI 2022",
    "descriptor": "\nComments: 7 pages, 5 figures. Accepted by AAAI 2022\n",
    "authors": [
      "Wanwei He",
      "Yinpei Dai",
      "Yinhe Zheng",
      "Yuchuan Wu",
      "Zheng Cao",
      "Dermot Liu",
      "Peng Jiang",
      "Min Yang",
      "Fei Huang",
      "Luo Si",
      "Jian Sun",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.14592"
  },
  {
    "id": "arXiv:2111.14833",
    "title": "Adversarial Attacks in Cooperative AI",
    "abstract": "Adversarial Attacks in Cooperative AI",
    "descriptor": "",
    "authors": [
      "Ted Fujimoto",
      "Arthur Paul Pedersen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.14833"
  },
  {
    "id": "arXiv:2111.15491",
    "title": "PolyWorld: Polygonal Building Extraction with Graph Neural Networks in  Satellite Images",
    "abstract": "PolyWorld: Polygonal Building Extraction with Graph Neural Networks in  Satellite Images",
    "descriptor": "",
    "authors": [
      "Stefano Zorzi",
      "Shabab Bazrafkan",
      "Stefan Habenschuss",
      "Friedrich Fraundorfer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15491"
  },
  {
    "id": "arXiv:2112.00061",
    "title": "Open-Domain, Content-based, Multi-modal Fact-checking of Out-of-Context  Images via Online Resources",
    "abstract": "Open-Domain, Content-based, Multi-modal Fact-checking of Out-of-Context  Images via Online Resources",
    "descriptor": "",
    "authors": [
      "Sahar Abdelnabi",
      "Rakibul Hasan",
      "Mario Fritz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00061"
  },
  {
    "id": "arXiv:2112.00953",
    "title": "Maximum Consensus by Weighted Influences of Monotone Boolean Functions",
    "abstract": "Maximum Consensus by Weighted Influences of Monotone Boolean Functions",
    "descriptor": "",
    "authors": [
      "Erchuan Zhang",
      "David Suter",
      "Ruwan Tennakoon",
      "Tat-Jun Chin",
      "Alireza Bab-Hadiashar",
      "Giang Truong",
      "Syed Zulqarnain Gilani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00953"
  },
  {
    "id": "arXiv:2112.01037",
    "title": "Inferring Prototypes for Multi-Label Few-Shot Image Classification with  Word Vector Guided Attention",
    "abstract": "Comments: Accepted by AAAI2022",
    "descriptor": "\nComments: Accepted by AAAI2022\n",
    "authors": [
      "Kun Yan",
      "Chenbin Zhang",
      "Jun Hou",
      "Ping Wang",
      "Zied Bouraoui",
      "Shoaib Jameel",
      "Steven Schockaert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01037"
  },
  {
    "id": "arXiv:2112.01097",
    "title": "CoviChain: A Blockchain Based COVID-19 Vaccination Passport",
    "abstract": "CoviChain: A Blockchain Based COVID-19 Vaccination Passport",
    "descriptor": "",
    "authors": [
      "Philip Bradish",
      "Sarang Chaudhari",
      "Michael Clear",
      "Hitesh Tewari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.01097"
  },
  {
    "id": "arXiv:2112.01361",
    "title": "Phasic Policy Gradient Based Resource Allocation for Industrial Internet  of Things",
    "abstract": "Phasic Policy Gradient Based Resource Allocation for Industrial Internet  of Things",
    "descriptor": "",
    "authors": [
      "Lokesh Bommisetty",
      "TG Venkatesh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.01361"
  },
  {
    "id": "arXiv:2112.01585",
    "title": "Differentially Private Exploration in Reinforcement Learning with Linear  Representation",
    "abstract": "Differentially Private Exploration in Reinforcement Learning with Linear  Representation",
    "descriptor": "",
    "authors": [
      "Paul Luyo",
      "Evrard Garcelon",
      "Alessandro Lazaric",
      "Matteo Pirotta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01585"
  },
  {
    "id": "arXiv:2112.01897",
    "title": "GECCO: Constraint-driven Abstraction of Low-level Event Logs",
    "abstract": "Comments: 14 pages, 8 figures, accepted for IEEE ICDE 2022",
    "descriptor": "\nComments: 14 pages, 8 figures, accepted for IEEE ICDE 2022\n",
    "authors": [
      "Adrian Rebmann",
      "Matthias Weidlich",
      "Han van der Aa"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.01897"
  },
  {
    "id": "arXiv:2112.01953",
    "title": "Improving the Robustness of Reinforcement Learning Policies with  $\\mathcal{L}_{1}$ Adaptive Control",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2106.02249",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.02249\n",
    "authors": [
      "Y. Cheng",
      "P. Zhao",
      "F. Wang",
      "D. J. Block",
      "N. Hovakimyan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.01953"
  },
  {
    "id": "arXiv:2112.02214",
    "title": "Joint Audio-Text Model for Expressive Speech-Driven 3D Facial Animation",
    "abstract": "Joint Audio-Text Model for Expressive Speech-Driven 3D Facial Animation",
    "descriptor": "",
    "authors": [
      "Yingruo Fan",
      "Zhaojiang Lin",
      "Jun Saito",
      "Wenping Wang",
      "Taku Komura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.02214"
  },
  {
    "id": "arXiv:2112.02236",
    "title": "SemanticStyleGAN: Learning Compositional Generative Priors for  Controllable Image Synthesis and Editing",
    "abstract": "Comments: project page at this https URL",
    "descriptor": "\nComments: project page at this https URL\n",
    "authors": [
      "Yichun Shi",
      "Xiao Yang",
      "Yangyue Wan",
      "Xiaohui Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.02236"
  },
  {
    "id": "arXiv:2112.02366",
    "title": "Characterizing Retweet Bots: The Case of Black Market Accounts",
    "abstract": "Characterizing Retweet Bots: The Case of Black Market Accounts",
    "descriptor": "",
    "authors": [
      "Tu\u011frulcan Elmas",
      "Rebekah Overdorf",
      "Karl Aberer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.02366"
  },
  {
    "id": "arXiv:2112.02378",
    "title": "Quasiplanar graphs, string graphs, and the Erdos-Gallai problem",
    "abstract": "Quasiplanar graphs, string graphs, and the Erdos-Gallai problem",
    "descriptor": "",
    "authors": [
      "Jacob Fox",
      "Janos Pach",
      "Andrew Suk"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.02378"
  },
  {
    "id": "arXiv:2112.02472",
    "title": "Augmentation-Free Self-Supervised Learning on Graphs",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Namkyeong Lee",
      "Junseok Lee",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.02472"
  },
  {
    "id": "arXiv:2112.02516",
    "title": "Energy-Efficient Deflection-based On-chip Networks: Topology, Routing,  Flow Control",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1602.06005",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1602.06005\n",
    "authors": [
      "Rachata Ausavarungnirun",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.02516"
  },
  {
    "id": "arXiv:2112.02557",
    "title": "Interpretable Privacy Preservation of Text Representations Using Vector  Steganography",
    "abstract": "Comments: Accepted at AAAI 2022 Doctoral Consortium",
    "descriptor": "\nComments: Accepted at AAAI 2022 Doctoral Consortium\n",
    "authors": [
      "Geetanjali Bihani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.02557"
  },
  {
    "id": "arXiv:2112.02581",
    "title": "Long-Tail Session-based Recommendation from Calibration",
    "abstract": "Long-Tail Session-based Recommendation from Calibration",
    "descriptor": "",
    "authors": [
      "Jiayi Chen",
      "Wen Wu",
      "Wei Zheng",
      "Liang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.02581"
  },
  {
    "id": "arXiv:2112.02646",
    "title": "Diverse, Global and Amortised Counterfactual Explanations for  Uncertainty Estimates",
    "abstract": "Comments: Accepted as a conference paper to AAAI 2022",
    "descriptor": "\nComments: Accepted as a conference paper to AAAI 2022\n",
    "authors": [
      "Dan Ley",
      "Umang Bhatt",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.02646"
  },
  {
    "id": "arXiv:2112.02681",
    "title": "Fine spectral estimates with applications to the optimally fast solution  of large FDE linear systems",
    "abstract": "Fine spectral estimates with applications to the optimally fast solution  of large FDE linear systems",
    "descriptor": "",
    "authors": [
      "M. Bogoya",
      "S.M. Grudsky",
      "S. Serra-Capizzano",
      "C. Tablino-Possio"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.02681"
  },
  {
    "id": "arXiv:2112.02857",
    "title": "PTTR: Relational 3D Point Cloud Object Tracking with Transformer",
    "abstract": "PTTR: Relational 3D Point Cloud Object Tracking with Transformer",
    "descriptor": "",
    "authors": [
      "Changqing Zhou",
      "Zhipeng Luo",
      "Yueru Luo",
      "Tianrui Liu",
      "Liang Pan",
      "Zhongang Cai",
      "Haiyu Zhao",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.02857"
  },
  {
    "id": "arXiv:2112.02936",
    "title": "Pairwise Learning for Neural Link Prediction",
    "abstract": "Pairwise Learning for Neural Link Prediction",
    "descriptor": "",
    "authors": [
      "Zhitao Wang",
      "Yong Zhou",
      "Litao Hong",
      "Yuanhang Zou",
      "Hanjing Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.02936"
  },
  {
    "id": "arXiv:2112.02954",
    "title": "Reinforcement Learning for Navigation of Mobile Robot with LiDAR",
    "abstract": "Comments: 7 pages, 7 figures, Accepted by \"5th International Conference on Electronics, Communication and Aerospace Technology (ICECA 2021)\"",
    "descriptor": "\nComments: 7 pages, 7 figures, Accepted by \"5th International Conference on Electronics, Communication and Aerospace Technology (ICECA 2021)\"\n",
    "authors": [
      "Inhwan Kim",
      "Sarvar Hussain Nengroo",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.02954"
  },
  {
    "id": "arXiv:2112.03093",
    "title": "Semantic Coded Transmission: Architecture, Methodology, and Challenges",
    "abstract": "Semantic Coded Transmission: Architecture, Methodology, and Challenges",
    "descriptor": "",
    "authors": [
      "Jincheng Dai",
      "Ping Zhang",
      "Kai Niu",
      "Sixian Wang",
      "Zhongwei Si",
      "Xiaoqi Qin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.03093"
  }
]
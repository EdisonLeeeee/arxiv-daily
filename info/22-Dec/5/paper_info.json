[
  {
    "id": "arXiv:2212.00797",
    "title": "The upper-crossing/solution (US) algorithm for root-finding with  strongly stable convergence",
    "abstract": "In this paper, we propose a new and broadly applicable root-finding method,\ncalled as the upper-crossing/solution (US) algorithm, which belongs to the\ncategory of non-bracketing (or open domain) methods. The US algorithm is a\ngeneral principle for iteratively seeking the unique root $\\theta^{*}$ of a\nnon-linear equation $g(\\theta)=0$ and its each iteration consists of two steps:\nan upper-crossing step (U-step) and a solution step (S-step), where the U-step\nfinds an upper-crossing function or a $U$-function $U(\\theta|\\theta^{(t)})$\n[whose form depends on $\\theta^{(t)}$ being the $t$-th iteration of\n$\\theta^{*}$] based on a new notion of so-called changing direction inequality,\nand the S-step solves the simple $U$-equation $U(\\theta|\\theta^{(t)}) =0$ to\nobtain its explicit solution $\\theta^{(t+1)}$. The US algorithm holds two major\nadvantages: (i) It strongly stably converges to the root $\\theta^{*}$; and (ii)\nit does not depend on any initial values, in contrast to Newton's method. The\nkey step for applying the US algorithm is to construct one simple $U$-function\n$U(\\theta|\\theta^{(t)})$ such that an explicit solution to the $U$-equation\n$U(\\theta|\\theta^{(t)}) =0$ is available. Based on the first-, second- and\nthird-derivative of $g(\\theta)$, three methods are given for constructing such\n$U$-functions. We show various applications of the US algorithm in such as\ncalculating quantile in continuous distributions, calculating exact $p$-values\nfor skew null distributions, and finding maximum likelihood estimates of\nparameters in a class of continuous/discrete distributions. The analysis of the\nconvergence rate of the US algorithm and some numerical experiments are also\nprovided. Especially, because of the property of strongly stable convergence,\nthe US algorithm could be one of the powerful tools for solving an equation\nwith multiple roots.",
    "descriptor": "\nComments: 40 pages, 4 figures\n",
    "authors": [
      "Xunjian LI",
      "Guo-Liang Tian"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.00797"
  },
  {
    "id": "arXiv:2212.00798",
    "title": "Pre-training strategy for solving evolution equations based on  physics-informed neural networks",
    "abstract": "The physics informed neural network (PINN) is a promising method for solving\ntime-evolution partial differential equations (PDEs). However, the standard\nPINN method may fail to solve the PDEs with strongly nonlinear characteristics\nor those with high-frequency solutions. The physics informed neural network\n(PINN) is a promising method for solving time-evolution partial differential\nequations (PDEs). However, the standard PINN method may fail to solve the PDEs\nwith strongly nonlinear characteristics or those with high-frequency solutions.\nThe PT-PINN method transforms the difficult problem on the entire time domain\nto relatively simple problems defined on small subdomains. The neural network\ntrained on small subdomains provides the neural network initialization and\nextra supervised learning data for the problems on larger subdomains or on the\nentire time-domain. By numerical experiments, we demonstrate that the PT-PINN\nsucceeds in solving the evolution PDEs with strong non-linearity and/or high\nfrequency solutions, including the strongly nonlinear heat equation, the\nAllen-Cahn equation, the convection equation with high-frequency solutions and\nso on, and that the convergence and accuracy of the PT-PINN is superior to the\nstandard PINN method. The PT-PINN method is a competitive method for solving\nthe time-evolution PDEs.",
    "descriptor": "",
    "authors": [
      "Jiawei Guo",
      "Yanzhong Yao",
      "Han Wang",
      "Tongxiang Gu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.00798"
  },
  {
    "id": "arXiv:2212.00799",
    "title": "Efficient parallel optimization for approximating CAD curves featuring  super-convergence",
    "abstract": "We present an efficient, parallel, constrained optimization technique for\napproximating CAD curves with super-convergent rates.\nThe optimization function is a disparity measure in terms of a piece-wise\npolynomial approximation and a curve re-parametrization.\nThe constrained problem solves the disparity functional fixing the mesh\nelement interfaces.\nWe have numerical evidence that the constrained disparity preserves the\noriginal super-convergence: ${2p}$ order for planar curves and $\\lfloor\\frac\n32(p-1)\\rfloor + 2$ for 3D curves, $p$ being the mesh polynomial degree.\nOur optimization scheme consists of a globalized Newton method with a\nnonmonotone line search, and a log barrier function preventing element\ninversion in the curve re-parameterization. Moreover, we introduce a\n\\emph{Julia} interface to the EGADS geometry kernel and a parallel optimization\nalgorithm. We test the potential of our curve mesh generation tool on a\ncomputer cluster using several aircraft CAD models. We conclude that the solver\nis well-suited for parallel computing, producing super-convergent\napproximations to CAD curves.",
    "descriptor": "",
    "authors": [
      "Julia Docampo S\u00e1nchez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.00799"
  },
  {
    "id": "arXiv:2212.00800",
    "title": "The purpose of qualia: What if human thinking is not (only) information  processing?",
    "abstract": "Despite recent breakthroughs in the field of artificial intelligence (AI) -\nor more specifically machine learning (ML) algorithms for object recognition\nand natural language processing - it seems to be the majority view that current\nAI approaches are still no real match for natural intelligence (NI). More\nimportantly, philosophers have collected a long catalogue of features which\nimply that NI works differently from current AI not only in a gradual sense,\nbut in a more substantial way: NI is closely related to consciousness,\nintentionality and experiential features like qualia (the subjective contents\nof mental states) and allows for understanding (e.g., taking insight into\ncausal relationships instead of 'blindly' relying on correlations), as well as\naesthetical and ethical judgement beyond what we can put into (explicit or\ndata-induced implicit) rules to program machines with. Additionally,\nPsychologists find NI to range from unconscious psychological processes to\nfocused information processing, and from embodied and implicit cognition to\n'true' agency and creativity. NI thus seems to transcend any neurobiological\nfunctionalism by operating on 'bits of meaning' instead of information in the\nsense of data, quite unlike both the 'good old fashioned', symbolic AI of the\npast, as well as the current wave of deep neural network based, 'sub-symbolic'\nAI, which both share the idea of thinking as (only) information processing. In\nthe following I propose an alternative view of NI as information processing\nplus 'bundle pushing', discuss an example which illustrates how bundle pushing\ncan cut information processing short, and suggest first ideas for scientific\nexperiments in neuro-biology and information theory as further investigations.",
    "descriptor": "",
    "authors": [
      "Martin Korth"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00800"
  },
  {
    "id": "arXiv:2212.00801",
    "title": "Monolithic parallel overlapping Schwarz methods in fully-coupled  nonlinear chemo-mechanics problems",
    "abstract": "We consider the swelling of hydrogels as an example of a chemo-mechanical\nproblem with strong coupling between the mechanical balance relations and the\nmass diffusion. The problem is cast into a minimization formulation using a\ntime-explicit approach for the dependency of the dissipation potential on the\ndeformation and the swelling volume fraction to obtain symmetric matrices,\nwhich are typically better suited for iterative solvers. The MPI-parallel\nimplementation uses the software libraries deal.II, p4est and FROSch (Fast of\nRobust Overlapping Schwarz). FROSch is part of the Trilinos library and is used\nin fully algebraic mode, i.e., the preconditioner is constructed from the\nmonolithic system matrix without making explicit use of the problem structure.\nStrong and weak parallel scalability is studied using up to 512 cores,\nconsidering the standard GDSW (Generalized Dryja-Smith-Widlund) coarse space\nand the newer coarse space with reduced dimension. The FROSch solver is\napplicable to the coupled problems within in the range of processor cores\nconsidered here, although numerical scalablity cannot be expected (and is not\nobserved) for the fully algebraic mode. In our strong scalability study, the\naverage number of Krylov iterations per Newton iteration is higher by a factor\nof up to six compared to a linear elasticity problem. However, making mild use\nof the problem structure in the preconditioner, this number can be reduced to a\nfactor of two and, importantly, also numerical scalability can then be achieved\nexperimentally. Nevertheless, the fully algebraic mode is still preferable\nsince a faster time to solution is achieved.",
    "descriptor": "",
    "authors": [
      "Bjoern Kiefer",
      "Stefan Pr\u00fcger",
      "Oliver Rheinbach",
      "Friederike R\u00f6ver"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.00801"
  },
  {
    "id": "arXiv:2212.00802",
    "title": "An Introduction to Kernel and Operator Learning Methods for  Homogenization by Self-consistent Clustering Analysis",
    "abstract": "Recent advances in operator learning theory have improved our knowledge about\nlearning maps between infinite dimensional spaces. However, for large-scale\nengineering problems such as concurrent multiscale simulation for mechanical\nproperties, the training cost for the current operator learning methods is very\nhigh. The article presents a thorough analysis on the mathematical\nunderpinnings of the operator learning paradigm and proposes a kernel learning\nmethod that maps between function spaces. We first provide a survey of modern\nkernel and operator learning theory, as well as discuss recent results and open\nproblems. From there, the article presents an algorithm to how we can\nanalytically approximate the piecewise constant functions on R for operator\nlearning. This implies the potential feasibility of success of neural operators\non clustered functions. Finally, a k-means clustered domain on the basis of a\nmechanistic response is considered and the Lippmann-Schwinger equation for\nmicro-mechanical homogenization is solved. The article briefly discusses the\nmathematics of previous kernel learning methods and some preliminary results\nwith those methods. The proposed kernel operator learning method uses graph\nkernel networks to come up with a mechanistic reduced order method for\nmultiscale homogenization.",
    "descriptor": "",
    "authors": [
      "Owen Huang",
      "Sourav Saha",
      "Jiachen Guo",
      "Wing Kam Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00802"
  },
  {
    "id": "arXiv:2212.00822",
    "title": "Navigating an Ocean of Video Data: Deep Learning for Humpback Whale  Classification in YouTube Videos",
    "abstract": "Image analysis technologies empowered by artificial intelligence (AI) have\nproved images and videos to be an opportune source of data to learn about\nhumpback whale (Megaptera novaeangliae) population sizes and dynamics. With the\nadvent of social media, platforms such as YouTube present an abundance of video\ndata across spatiotemporal contexts documenting humpback whale encounters from\nusers worldwide. In our work, we focus on automating the classification of\nYouTube videos as relevant or irrelevant based on whether they document a true\nhumpback whale encounter or not via deep learning. We use a CNN-RNN\narchitecture pretrained on the ImageNet dataset for classification of YouTube\nvideos as relevant or irrelevant. We achieve an average 85.7% accuracy, and\n84.7% (irrelevant)/ 86.6% (relevant) F1 scores using five-fold cross validation\nfor evaluation on the dataset. We show that deep learning can be used as a\ntime-efficient step to make social media a viable source of image and video\ndata for biodiversity assessments.",
    "descriptor": "",
    "authors": [
      "Michelle Ramirez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2212.00822"
  },
  {
    "id": "arXiv:2212.00823",
    "title": "Exponentially Convergent Multiscale Finite Element Method",
    "abstract": "We provide a concise review of the exponentially convergent multiscale finite\nelement method (ExpMsFEM) for efficient model reduction of PDEs in\nheterogeneous media without scale separation and in high-frequency wave\npropagation. ExpMsFEM is built on the non-overlapped domain decomposition in\nthe classical MsFEM while enriching the approximation space systematically to\nachieve a nearly exponential convergence rate regarding the number of basis\nfunctions. Unlike most generalizations of MsFEM in the literature, ExpMsFEM\ndoes not rely on any partition of unity functions.\nIn general, it is necessary to use function representations dependent on the\nright-hand side to break the algebraic Kolmogorov $n$-width barrier to achieve\nexponential convergence. Indeed, there are online and offline parts in the\nfunction representation provided by ExpMsFEM. The online part depends on the\nright-hand side locally and can be computed in parallel efficiently. The\noffline part contains basis functions that are used in the Galerkin method to\nassemble the stiffness matrix; they are all independent of the right-hand side,\nso the stiffness matrix can be used repeatedly in multi-query scenarios.",
    "descriptor": "",
    "authors": [
      "Yifan Chen",
      "Thomas Y. Hou",
      "Yixuan Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.00823"
  },
  {
    "id": "arXiv:2212.00824",
    "title": "On-device Training: A First Overview on Existing Systems",
    "abstract": "The recent breakthroughs in machine learning (ML) and deep learning (DL) have\nenabled many new capabilities across plenty of application domains. While most\nexisting machine learning models require large memory and computing power,\nefforts have been made to deploy some models on resource-constrained devices as\nwell. There are several systems that perform inference on the device, while\ndirect training on the device still remains a challenge. On-device training,\nhowever, is attracting more and more interest because: (1) it enables training\nmodels on local data without needing to share data over the cloud, thus\nenabling privacy preserving computation by design; (2) models can be refined on\ndevices to provide personalized services and cope with model drift in order to\nadapt to the changes of the real-world environment; and (3) it enables the\ndeployment of models in remote, hardly accessible locations or places without\nstable internet connectivity. We summarize and analyze the-state-of-art systems\nresearch to provide the first survey of on-device training from a systems\nperspective.",
    "descriptor": "",
    "authors": [
      "Shuai Zhu",
      "Thiemo Voigt",
      "JeongGil Ko",
      "Fatemeh Rahimian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00824"
  },
  {
    "id": "arXiv:2212.00827",
    "title": "Architectural Implications of Embedding Dimension during GCN on CPU and  GPU",
    "abstract": "Graph Neural Networks (GNNs) are a class of neural networks designed to\nextract information from the graphical structure of data. Graph Convolutional\nNetworks (GCNs) are a widely used type of GNN for transductive graph learning\nproblems which apply convolution to learn information from graphs. GCN is a\nchallenging algorithm from an architecture perspective due to inherent\nsparsity, low data reuse, and massive memory capacity requirements. Traditional\nneural algorithms exploit the high compute capacity of GPUs to achieve high\nperformance for both inference and training. The architectural decision to use\na GPU for GCN inference is a question explored in this work. GCN on both CPU\nand GPU was characterized in order to better understand the implications of\ngraph size, embedding dimension, and sampling on performance.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Matthew Adiletta",
      "David Brooks",
      "Gu-Yeon Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2212.00827"
  },
  {
    "id": "arXiv:2212.00833",
    "title": "Generalizing Math Word Problem Solvers via Solution Diversification",
    "abstract": "Current math word problem (MWP) solvers are usually Seq2Seq models trained by\nthe (one-problem; one-solution) pairs, each of which is made of a problem\ndescription and a solution showing reasoning flow to get the correct answer.\nHowever, one MWP problem naturally has multiple solution equations. The\ntraining of an MWP solver with (one-problem; one-solution) pairs excludes other\ncorrect solutions, and thus limits the generalizability of the MWP solver. One\nfeasible solution to this limitation is to augment multiple solutions to a\ngiven problem. However, it is difficult to collect diverse and accurate augment\nsolutions through human efforts. In this paper, we design a new training\nframework for an MWP solver by introducing a solution buffer and a solution\ndiscriminator. The buffer includes solutions generated by an MWP solver to\nencourage the training data diversity. The discriminator controls the quality\nof buffered solutions to participate in training. Our framework is flexibly\napplicable to a wide setting of fully, semi-weakly and weakly supervised\ntraining for all Seq2Seq MWP solvers. We conduct extensive experiments on a\nbenchmark dataset Math23k and a new dataset named Weak12k, and show that our\nframework improves the performance of various MWP solvers under different\nsettings by generating correct and diverse solutions.",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Zhenwen Liang",
      "Jipeng Zhang",
      "Lei Wang",
      "Yan Wang",
      "Jie Shao",
      "Xiangliang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00833"
  },
  {
    "id": "arXiv:2212.00836",
    "title": "UniT3D: A Unified Transformer for 3D Dense Captioning and Visual  Grounding",
    "abstract": "Performing 3D dense captioning and visual grounding requires a common and\nshared understanding of the underlying multimodal relationships. However,\ndespite some previous attempts on connecting these two related tasks with\nhighly task-specific neural modules, it remains understudied how to explicitly\ndepict their shared nature to learn them simultaneously. In this work, we\npropose UniT3D, a simple yet effective fully unified transformer-based\narchitecture for jointly solving 3D visual grounding and dense captioning.\nUniT3D enables learning a strong multimodal representation across the two tasks\nthrough a supervised joint pre-training scheme with bidirectional and\nseq-to-seq objectives. With a generic architecture design, UniT3D allows\nexpanding the pre-training scope to more various training sources such as the\nsynthesized data from 2D prior knowledge to benefit 3D vision-language tasks.\nExtensive experiments and analysis demonstrate that UniT3D obtains significant\ngains for 3D dense captioning and visual grounding.",
    "descriptor": "",
    "authors": [
      "Dave Zhenyu Chen",
      "Ronghang Hu",
      "Xinlei Chen",
      "Matthias Nie\u00dfner",
      "Angel X. Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00836"
  },
  {
    "id": "arXiv:2212.00837",
    "title": "Analogical Math Word Problems Solving with Enhanced Problem-Solution  Association",
    "abstract": "Math word problem (MWP) solving is an important task in question answering\nwhich requires human-like reasoning ability. Analogical reasoning has long been\nused in mathematical education, as it enables students to apply common\nrelational structures of mathematical situations to solve new problems. In this\npaper, we propose to build a novel MWP solver by leveraging analogical MWPs,\nwhich advance the solver's generalization ability across different kinds of\nMWPs. The key idea, named analogy identification, is to associate the\nanalogical MWP pairs in a latent space, i.e., encoding an MWP close to another\nanalogical MWP, while moving away from the non-analogical ones. Moreover, a\nsolution discriminator is integrated into the MWP solver to enhance the\nassociation between the representations of MWPs and their true solutions. The\nevaluation results verify that our proposed analogical learning strategy\npromotes the performance of MWP-BERT on Math23k over the state-of-the-art model\nGenerate2Rank, with 5 times fewer parameters in the encoder. We also find that\nour model has a stronger generalization ability in solving difficult MWPs due\nto the analogical learning from easy MWPs.",
    "descriptor": "\nComments: Accepted by EMNLP 2022 main conference\n",
    "authors": [
      "Zhenwen Liang",
      "Jipeng Zhang",
      "Xiangliang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00837"
  },
  {
    "id": "arXiv:2212.00842",
    "title": "3D-LDM: Neural Implicit 3D Shape Generation with Latent Diffusion Models",
    "abstract": "Diffusion models have shown great promise for image generation, beating GANs\nin terms of generation diversity, with comparable image quality. However, their\napplication to 3D shapes has been limited to point or voxel representations\nthat can in practice not accurately represent a 3D surface. We propose a\ndiffusion model for neural implicit representations of 3D shapes that operates\nin the latent space of an auto-decoder. This allows us to generate diverse and\nhigh quality 3D surfaces. We additionally show that we can condition our model\non images or text to enable image-to-3D generation and text-to-3D generation\nusing CLIP embeddings. Furthermore, adding noise to the latent codes of\nexisting shapes allows us to explore shape variations.",
    "descriptor": "",
    "authors": [
      "Gimin Nam",
      "Mariem Khlifi",
      "Andrew Rodriguez",
      "Alberto Tono",
      "Linqi Zhou",
      "Paul Guerrero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00842"
  },
  {
    "id": "arXiv:2212.00843",
    "title": "Focus! Relevant and Sufficient Context Selection for News Image  Captioning",
    "abstract": "News Image Captioning requires describing an image by leveraging additional\ncontext from a news article. Previous works only coarsely leverage the article\nto extract the necessary context, which makes it challenging for models to\nidentify relevant events and named entities. In our paper, we first demonstrate\nthat by combining more fine-grained context that captures the key named\nentities (obtained via an oracle) and the global context that summarizes the\nnews, we can dramatically improve the model's ability to generate accurate news\ncaptions. This begs the question, how to automatically extract such key\nentities from an image? We propose to use the pre-trained vision and language\nretrieval model CLIP to localize the visually grounded entities in the news\narticle and then capture the non-visual entities via an open relation\nextraction model. Our experiments demonstrate that by simply selecting a better\ncontext from the article, we can significantly improve the performance of\nexisting models and achieve new state-of-the-art performance on multiple\nbenchmarks.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Mingyang Zhou",
      "Grace Luo",
      "Anna Rohrbach",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.00843"
  },
  {
    "id": "arXiv:2212.00844",
    "title": "A Comparison of New Swarm Task Allocation Algorithms in Unknown  Environments with Varying Task Density",
    "abstract": "Task allocation is an important problem for robot swarms to solve, allowing\nagents to use reduce task completion time by performing tasks in a distributed\nfashion. Existing task allocation algorithms often assume prior knowledge of\ntask location and demand or fail to consider the effects of the geometric\ndistribution of tasks on the completion time and communication cost of the\nalgorithms. In this paper, we examine an environment where agents must explore\nand discover tasks with positive demand and successfully assign themselves to\ncomplete all such tasks. We propose two new task allocation algorithms for\ninitially unknown environments -- one based on N-site selection and the other\non virtual pheromones. We analyze each algorithm separately and also evaluate\nthe effectiveness of the two algorithms in dense vs. sparse task distributions.\nCompared to the Levy walk, which has been theorized to be optimal for foraging,\nour virtual pheromone inspired algorithm is much faster in sparse to medium\ntask densities but is communication and agent intensive. Our site selection\ninspired algorithm also outperforms Levy walk in sparse task densities and is a\nless resource-intensive option than our virtual pheromone algorithm for this\ncase. Because the performance of both algorithms relative to random walk is\ndependent on task density, our results shed light on how task density is\nimportant in choosing a task allocation algorithm in initially unknown\nenvironments.",
    "descriptor": "\nComments: 10 pages, 9 figures\n",
    "authors": [
      "Grace Cai",
      "Noble Harasha",
      "Nancy Lynch"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.00844"
  },
  {
    "id": "arXiv:2212.00847",
    "title": "Weakly Supervised Annotations for Multi-modal Greeting Cards Dataset",
    "abstract": "In recent years, there is a growing number of pre-trained models trained on a\nlarge corpus of data and yielding good performance on various tasks such as\nclassifying multimodal datasets. These models have shown good performance on\nnatural images but are not fully explored for scarce abstract concepts in\nimages. In this work, we introduce an image/text-based dataset called Greeting\nCards. Dataset (GCD) that has abstract visual concepts. In our work, we propose\nto aggregate features from pretrained images and text embeddings to learn\nabstract visual concepts from GCD. This allows us to learn the text-modified\nimage features, which combine complementary and redundant information from the\nmulti-modal data streams into a single, meaningful feature. Secondly, the\ncaptions for the GCD dataset are computed with the pretrained CLIP-based image\ncaptioning model. Finally, we also demonstrate that the proposed the dataset is\nalso useful for generating greeting card images using pre-trained text-to-image\ngeneration model.",
    "descriptor": "\nComments: Accepted for poster presentation at Pretrain@WACV 2023\n",
    "authors": [
      "Sidra Hanif",
      "Longin Jan Latecki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00847"
  },
  {
    "id": "arXiv:2212.00849",
    "title": "\"All of the White People Went First\": How Video Conferencing  Consolidates Control and Exacerbates Workplace Bias",
    "abstract": "Workplace bias creates negative psychological outcomes for employees,\npermeating the larger organization. Workplace meetings are frequent, making\nthem a key context where bias may occur. Video conferencing (VC) is an\nincreasingly common medium for workplace meetings; we therefore investigated\nhow VC tools contribute to increasing or reducing bias in meetings. Through a\nsemi-structured interview study with 22 professionals, we found that VC\nfeatures push meeting leaders to exercise control over various meeting\nparameters, giving leaders an outsized role in affecting bias. We demonstrate\nthis with respect to four core VC features -- user tiles, raise hand,\ntext-based chat, and meeting recording -- and recommend employing at least one\nof two mechanisms for mitigating bias in VC meetings -- 1) transferring control\nfrom meeting leaders to technical systems or other attendees and 2) helping\nmeeting leaders better exercise the control they do wield.",
    "descriptor": "\nComments: To appear at the 26th ACM Conference On Computer-Supported Cooperative Work And Social Computing (CSCW 2023)\n",
    "authors": [
      "Mo Houtti",
      "Moyan Zhou",
      "Loren Terveen",
      "Stevie Chancellor"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.00849"
  },
  {
    "id": "arXiv:2212.00850",
    "title": "When Neural Networks Fail to Generalize? A Model Sensitivity Perspective",
    "abstract": "Domain generalization (DG) aims to train a model to perform well in unseen\ndomains under different distributions. This paper considers a more realistic\nyet more challenging scenario,namely Single Domain Generalization (Single-DG),\nwhere only a single source domain is available for training. To tackle this\nchallenge, we first try to understand when neural networks fail to generalize?\nWe empirically ascertain a property of a model that correlates strongly with\nits generalization that we coin as \"model sensitivity\". Based on our analysis,\nwe propose a novel strategy of Spectral Adversarial Data Augmentation (SADA) to\ngenerate augmented images targeted at the highly sensitive frequencies. Models\ntrained with these hard-to-learn samples can effectively suppress the\nsensitivity in the frequency space, which leads to improved generalization\nperformance. Extensive experiments on multiple public datasets demonstrate the\nsuperiority of our approach, which surpasses the state-of-the-art single-DG\nmethods.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Jiajin Zhang",
      "Hanqing Chao",
      "Amit Dhurandhar",
      "Pin-Yu Chen",
      "Ali Tajer",
      "Yangyang Xu",
      "Pingkun Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00850"
  },
  {
    "id": "arXiv:2212.00851",
    "title": "SOLD: Sinhala Offensive Language Dataset",
    "abstract": "The widespread of offensive content online, such as hate speech and\ncyber-bullying, is a global phenomenon. This has sparked interest in the\nartificial intelligence (AI) and natural language processing (NLP) communities,\nmotivating the development of various systems trained to detect potentially\nharmful content automatically. These systems require annotated datasets to\ntrain the machine learning (ML) models. However, with a few notable exceptions,\nmost datasets on this topic have dealt with English and a few other\nhigh-resource languages. As a result, the research in offensive language\nidentification has been limited to these languages. This paper addresses this\ngap by tackling offensive language identification in Sinhala, a low-resource\nIndo-Aryan language spoken by over 17 million people in Sri Lanka. We introduce\nthe Sinhala Offensive Language Dataset (SOLD) and present multiple experiments\non this dataset. SOLD is a manually annotated dataset containing 10,000 posts\nfrom Twitter annotated as offensive and not offensive at both sentence-level\nand token-level, improving the explainability of the ML models. SOLD is the\nfirst large publicly available offensive language dataset compiled for Sinhala.\nWe also introduce SemiSOLD, a larger dataset containing more than 145,000\nSinhala tweets, annotated following a semi-supervised approach.",
    "descriptor": "\nComments: This is a preprint of an article submitted to Applied Intelligence, Springer\n",
    "authors": [
      "Tharindu Ranasinghe",
      "Isuri Anuradha",
      "Damith Premasiri",
      "Kanishka Silva",
      "Hansi Hettiarachchi",
      "Lasitha Uyangodage",
      "Marcos Zampieri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.00851"
  },
  {
    "id": "arXiv:2212.00852",
    "title": "Symphony in the Latent Space: Provably Integrating High-dimensional  Techniques with Non-linear Machine Learning Models",
    "abstract": "This paper revisits building machine learning algorithms that involve\ninteractions between entities, such as those between financial assets in an\nactively managed portfolio, or interactions between users in a social network.\nOur goal is to forecast the future evolution of ensembles of multivariate time\nseries in such applications (e.g., the future return of a financial asset or\nthe future popularity of a Twitter account). Designing ML algorithms for such\nsystems requires addressing the challenges of high-dimensional interactions and\nnon-linearity. Existing approaches usually adopt an ad-hoc approach to\nintegrating high-dimensional techniques into non-linear models and recent\nstudies have shown these approaches have questionable efficacy in time-evolving\ninteracting systems.\nTo this end, we propose a novel framework, which we dub as the additive\ninfluence model. Under our modeling assumption, we show that it is possible to\ndecouple the learning of high-dimensional interactions from the learning of\nnon-linear feature interactions. To learn the high-dimensional interactions, we\nleverage kernel-based techniques, with provable guarantees, to embed the\nentities in a low-dimensional latent space. To learn the non-linear\nfeature-response interactions, we generalize prominent machine learning\ntechniques, including designing a new statistically sound non-parametric method\nand an ensemble learning algorithm optimized for vector regressions. Extensive\nexperiments on two common applications demonstrate that our new algorithms\ndeliver significantly stronger forecasting power compared to standard and\nrecently proposed methods.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Qiong Wu",
      "Jian Li",
      "Zhenming Liu",
      "Yanhua Li",
      "Mihai Cucuringu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00852"
  },
  {
    "id": "arXiv:2212.00855",
    "title": "Reward Function Optimization of a Deep Reinforcement Learning Collision  Avoidance System",
    "abstract": "The proliferation of unmanned aircraft systems (UAS) has caused airspace\nregulation authorities to examine the interoperability of these aircraft with\ncollision avoidance systems initially designed for large transport category\naircraft. Limitations in the currently mandated TCAS led the Federal Aviation\nAdministration to commission the development of a new solution, the Airborne\nCollision Avoidance System X (ACAS X), designed to enable a collision avoidance\ncapability for multiple aircraft platforms, including UAS. While prior research\nexplored using deep reinforcement learning algorithms (DRL) for collision\navoidance, DRL did not perform as well as existing solutions. This work\nexplores the benefits of using a DRL collision avoidance system whose\nparameters are tuned using a surrogate optimizer. We show the use of a\nsurrogate optimizer leads to DRL approach that can increase safety and\noperational viability and support future capability development for UAS\ncollision avoidance.",
    "descriptor": "",
    "authors": [
      "Cooper Cone",
      "Michael Owen",
      "Luis Alvarez",
      "Marc Brittain"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.00855"
  },
  {
    "id": "arXiv:2212.00857",
    "title": "a survey on GPT-3",
    "abstract": "This paper provides an introductory survey to GPT-3. We cover some of the\nhistorical development behind this technology, some of the key features of\nGPT-3, and discuss the machine learning model and the datasets used. We survey\nboth academic and commercial efforts applying GPT-3 in diverse domains such as\ndeveloping conversational AI chatbots, software development, creative work,\ndomain knowledge, and business productivity. We discuss some of the challenges\nthat GPT-3 faces such as the problems of training complexity, bias, and\nhallucination/incorrect answers. We also discuss the future research\nopportunities in this area.",
    "descriptor": "",
    "authors": [
      "Mingyu Zong",
      "Bhaskar Krishnamachari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00857"
  },
  {
    "id": "arXiv:2212.00862",
    "title": "An introduction to optimization under uncertainty -- A short survey",
    "abstract": "Optimization equips engineers and scientists in a variety of fields with the\nability to transcribe their problems into a generic formulation and receive\noptimal solutions with relative ease. Industries ranging from aerospace to\nrobotics continue to benefit from advancements in optimization theory and the\nassociated algorithmic developments. Nowadays, optimization is used in real\ntime on autonomous systems acting in safety critical situations, such as\nself-driving vehicles. It has become increasingly more important to produce\nrobust solutions by incorporating uncertainty into optimization programs. This\npaper provides a short survey about the state of the art in optimization under\nuncertainty. The paper begins with a brief overview of the main classes of\noptimization without uncertainty. The rest of the paper focuses on the\ndifferent methods for handling both aleatoric and epistemic uncertainty. Many\nof the applications discussed in this paper are within the domain of control.\nThe goal of this survey paper is to briefly touch upon the state of the art in\na variety of different methods and refer the reader to other literature for\nmore in-depth treatments of the topics discussed here.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Keivan Shariatmadar",
      "Kaizheng Wang",
      "Calvin R. Hubbard",
      "Hans Hallez",
      "David Moens"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.00862"
  },
  {
    "id": "arXiv:2212.00863",
    "title": "Modeling Mobile Health Users as Reinforcement Learning Agents",
    "abstract": "Mobile health (mHealth) technologies empower patients to adopt/maintain\nhealthy behaviors in their daily lives, by providing interventions (e.g. push\nnotifications) tailored to the user's needs. In these settings, without\nintervention, human decision making may be impaired (e.g. valuing near term\npleasure over own long term goals). In this work, we formalize this\nrelationship with a framework in which the user optimizes a (potentially\nimpaired) Markov Decision Process (MDP) and the mHealth agent intervenes on the\nuser's MDP parameters. We show that different types of impairments imply\ndifferent types of optimal intervention. We also provide analytical and\nempirical explorations of these differences.",
    "descriptor": "",
    "authors": [
      "Eura Shin",
      "Siddharth Swaroop",
      "Weiwei Pan",
      "Susan Murphy",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00863"
  },
  {
    "id": "arXiv:2212.00866",
    "title": "Learning Robust State Observers using Neural ODEs (longer version)",
    "abstract": "Relying on recent research results on Neural ODEs, this paper presents a\nmethodology for the design of state observers for nonlinear systems based on\nNeural ODEs, learning Luenberger-like observers and their nonlinear extension\n(Kazantzis-Kravaris-Luenberger (KKL) observers) for systems with\npartially-known nonlinear dynamics and fully unknown nonlinear dynamics,\nrespectively. In particular, for tuneable KKL observers, the relationship\nbetween the design of the observer and its trade-off between convergence speed\nand robustness is analysed and used as a basis for improving the robustness of\nthe learning-based observer in training. We illustrate the advantages of this\napproach in numerical simulations.",
    "descriptor": "\nComments: 19 pages, 12 figures\n",
    "authors": [
      "Keyan Miao",
      "Konstantinos Gatsis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00866"
  },
  {
    "id": "arXiv:2212.00869",
    "title": "Flexible social inference facilitates targeted social learning when  rewards are not observable",
    "abstract": "Relying on others can be as risky as it can be rewarding. Advice seekers must\ndisentangle good advice from bad, and balance the potential benefits of shared\nwisdom against the risks of being misled. Groups are most effective at sharing\ninformation and solving problems together when everyone is sensitive to ``who\nknows what.'' Acquiring such knowledge in the first place, however, is not\ntrivial -- especially in contexts where background information is limited. What\nunderlying cognitive abilities are needed for social learning to be useful in\ninformation-limited environments? Here, we propose that the capacity for\nflexible social inference plays a key role in human group behavior, allowing\nlatent properties such as success or skill to be inferred from others' outward\nbehavior even when there is no direct access to others' private rewards and\n\"success\" manifests differently from context to context. We begin by\nformalizing our proposal in a cognitive model and comparing this model's\npredictions against those of simpler heuristics in a series of computational\nsimulations. We then evaluated these predictions in three large-scale\nbehavioral experiments using a multi-agent search paradigm with hidden rewards.\nIn Experiment 1, we found that average performance improves as a function of\ngroup size at a rate predicted by our model but not by three simpler\nalternatives. In Experiment 2, we placed human participants in controlled\nscenarios with artificial agents to more systematically evaluate the conditions\nunder which people choose to rely on social information. Finally, in Experiment\n3, we generalized these findings to a more complex and noisy environment,\nsuggesting regimes where inferences may break down. Taken together, we find\nthat even the most rudimentary social cognition abilities may facilitate the\ncharacteristic flexibility of human collective behavior.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Robert D. Hawkins",
      "Andrew M. Berdahl",
      "Alex \"Sandy\" Pentland",
      "Joshua B. Tenenbaum",
      "Noah D. Goodman",
      "P. M. Krafft"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.00869"
  },
  {
    "id": "arXiv:2212.00873",
    "title": "CONVOLVE: Smart and seamless design of smart edge processors",
    "abstract": "With the rise of DL, our world braces for AI in every edge device, creating\nan urgent need for edge-AI SoCs. This SoC hardware needs to support high\nthroughput, reliable and secure AI processing at ULP, with a very short time to\nmarket. With its strong legacy in edge solutions and open processing platforms,\nthe EU is well positioned to become leader in this SoC market. However, this\nrequires AI edge processing to become at least 100 times more energy-efficient,\nwhile offering sufficient flexibility and scalability to deal with AI as a\nfast-moving target. Since the design space of these complex SoCs is huge,\nadvanced tooling is needed to make their design tractable. The CONVOLVE project\naddresses these roadblocks. It takes a holistic approach with innovations at\nall levels of design hierarchy. Starting with an overview of SOTA DL processing\nsupport and our project methodology, this paper presents 8 important design\nchoices largely impacting energy-efficiency and flexibility of DL hardware.\nFinding good solutions is key in making smart-edge computing reality.",
    "descriptor": "",
    "authors": [
      "M. Gomony",
      "F. Putter",
      "A. Gebregiorgis",
      "G. Paulin",
      "L. Mei",
      "V. Jain",
      "S. Hamdioui",
      "V. Sanchez",
      "T. Grosser",
      "M. Geilen",
      "M. Verhelst",
      "F. Zenke",
      "F. Gurkaynak",
      "B. Bruin",
      "S. Stuijk",
      "S. Davidson",
      "S. De",
      "M. Ghogho",
      "A. Jimborean",
      "S. Eissa",
      "L. Benini",
      "D. Soudris",
      "R. Bishnoi",
      "S. Ainsworth",
      "F. Corradi",
      "O. Karrakchou",
      "T. G\u00fcneysu",
      "H. Corporaal"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2212.00873"
  },
  {
    "id": "arXiv:2212.00877",
    "title": "Dual Arm Impact-Aware Grasping through Time-Invariant Reference  Spreading Control",
    "abstract": "With the goal of increasing the speed and efficiency in robotic dual-arm\nmanipulation, a novel control approach is presented that utilizes intentional\nsimultaneous impacts to rapidly grasp objects. This approach uses the\ntime-invariant reference spreading framework, in which partly-overlapping ante-\nand post-impact reference vector fields are used. These vector fields are\ncoupled via the impact dynamics in proximity of the expected impact area,\nminimizing the otherwise large velocity errors after the impact and the\ncorresponding large control efforts. A purely spatial task is introduced to\nstrongly encourage the synchronization of impact times of the two arms. An\ninterim-impact control phase provides robustness in the execution against the\ninevitable lack of exact impact simultaneity and the corresponding unreliable\nvelocity error. In this interim phase, a position feedback signal is derived\nfrom the ante-impact velocity reference, which is used to enforce sustained\ncontact in all contact points without using velocity error feedback. With an\neye towards real-life implementation, the approach is formulated using a QP\ncontrol framework, and is validated using numerical simulations on a realistic\nrobot model with flexible joints and low-level torque control.",
    "descriptor": "\nComments: 8 pages, 4 figures, submitted for publication to IFAC World Congress 2023\n",
    "authors": [
      "Jari J. van Steen",
      "Abdullah Co\u015fgun",
      "Nathan van de Wouw",
      "Alessandro Saccon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.00877"
  },
  {
    "id": "arXiv:2212.00881",
    "title": "Investigating Deep Learning Model Calibration for Classification  Problems in Mechanics",
    "abstract": "Recently, there has been a growing interest in applying machine learning\nmethods to problems in engineering mechanics. In particular, there has been\nsignificant interest in applying deep learning techniques to predicting the\nmechanical behavior of heterogeneous materials and structures. Researchers have\nshown that deep learning methods are able to effectively predict mechanical\nbehavior with low error for systems ranging from engineered composites, to\ngeometrically complex metamaterials, to heterogeneous biological tissue.\nHowever, there has been comparatively little attention paid to deep learning\nmodel calibration, i.e., the match between predicted probabilities of outcomes\nand the true probabilities of outcomes. In this work, we perform a\ncomprehensive investigation into ML model calibration across seven open access\nengineering mechanics datasets that cover three distinct types of mechanical\nproblems. Specifically, we evaluate both model and model calibration error for\nmultiple machine learning methods, and investigate the influence of ensemble\naveraging and post hoc model calibration via temperature scaling. Overall, we\nfind that ensemble averaging of deep neural networks is both an effective and\nconsistent tool for improving model calibration, while temperature scaling has\ncomparatively limited benefits. Looking forward, we anticipate that this\ninvestigation will lay the foundation for future work in developing mechanics\nspecific approaches to deep learning model calibration.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Saeed Mohammadzadeh",
      "Peerasait Prachaseree",
      "Emma Lejeune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2212.00881"
  },
  {
    "id": "arXiv:2212.00882",
    "title": "Extended isogeometric analysis of multi-material and multi-physics  problems using hierarchical B-splines",
    "abstract": "This paper presents an immersed, isogeometric finite element framework to\npredict the response of multi-material, multi-physics problems with complex\ngeometries using locally refined discretizations. To circumvent the need to\ngenerate conformal meshes, this work uses an eXtended Finite Element Method\n(XFEM) to discretize the governing equations on non-conforming, embedding\nmeshes. A flexible approach to create truncated hierarchical B-splines\ndiscretizations is presented. This approach enables the refinement of each\nstate variable field individually to meet field-specific accuracy requirements.\nTo obtain an immersed geometry representation that is consistent across all\nhierarchically refined B-spline discretizations, the geometry is immersed into\na single mesh, the XFEM background mesh, which is constructed from the union of\nall hierarchical B-spline meshes. An extraction operator is introduced to\nrepresent the truncated hierarchical B-spline bases in terms of Lagrange shape\nfunctions on the XFEM background mesh without loss of accuracy. The truncated\nhierarchical B-spline bases are enriched using a generalized Heaviside\nenrichment strategy to accommodate small geometric features and multi-material\nproblems. The governing equations are augmented by a formulation of the\nface-oriented ghost stabilization enhanced for locally refined B-spline bases.\nWe present examples for two- and three-dimensional linear elastic and\nthermo-elastic problems. The numerical results validate the accuracy of our\nframework. The results also demonstrate the applicability of the proposed\nframework to large, geometrically complex problems.",
    "descriptor": "",
    "authors": [
      "Mathias Schmidt",
      "Lise Noel",
      "Keenan Doble",
      "John A. Evans",
      "Kurt Maute"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.00882"
  },
  {
    "id": "arXiv:2212.00884",
    "title": "Pareto Regret Analyses in Multi-objective Multi-armed Bandit",
    "abstract": "We study Pareto optimality in multi-objective multi-armed bandit by providing\na formulation of adversarial multi-objective multi-armed bandit and properly\ndefining its Pareto regrets that can be generalized to stochastic settings as\nwell. The regrets do not rely on any scalarization functions and reflect Pareto\noptimality compared to scalarized regrets. We also present new algorithms\nassuming both with and without prior information of the multi-objective\nmulti-armed bandit setting. The algorithms are shown optimal in adversarial\nsettings and nearly optimal in stochastic settings simultaneously by our\nestablished upper bounds and lower bounds on Pareto regrets. Moreover, the\nlower bound analyses show that the new regrets are consistent with the existing\nPareto regret for stochastic settings and extend an adversarial attack\nmechanism from bandit to the multi-objective one.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Mengfan Xu",
      "Diego Klabjan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.00884"
  },
  {
    "id": "arXiv:2212.00886",
    "title": "Diffusion Generative Models in Infinite Dimensions",
    "abstract": "Diffusion generative models have recently been applied to domains where the\navailable data can be seen as a discretization of an underlying function, such\nas audio signals or time series. However, these models operate directly on the\ndiscretized data, and there are no semantics in the modeling process that\nrelate the observed data to the underlying functional forms. We generalize\ndiffusion models to operate directly in function space by developing the\nfoundational theory for such models in terms of Gaussian measures on Hilbert\nspaces. A significant benefit of our function space point of view is that it\nallows us to explicitly specify the space of functions we are working in,\nleading us to develop methods for diffusion generative modeling in Sobolev\nspaces. Our approach allows us to perform both unconditional and conditional\ngeneration of function-valued data. We demonstrate our methods on several\nsynthetic and real-world benchmarks.",
    "descriptor": "\nComments: 25 pages, 6 figures\n",
    "authors": [
      "Gavin Kerrigan",
      "Justin Ley",
      "Padhraic Smyth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.00886"
  },
  {
    "id": "arXiv:2212.00888",
    "title": "Decisions that Explain Themselves: A User-Centric Deep Reinforcement  Learning Explanation System",
    "abstract": "With deep reinforcement learning (RL) systems like autonomous driving being\nwildly deployed but remaining largely opaque, developers frequently use\nexplainable RL (XRL) tools to better understand and work with deep RL agents.\nHowever, previous XRL works employ a techno-centric research approach, ignoring\nhow RL developers perceive the generated explanations. Through a pilot study,\nwe identify major goals for RL practitioners to use XRL methods and four\npitfalls that widen the gap between existing XRL methods and these goals. The\npitfalls include inaccessible reasoning processes, inconsistent or\nunintelligible explanations, and explanations that cannot be generalized. To\nfill the discovered gap, we propose a counterfactual-inference-based\nexplanation method that discovers the details of the reasoning process of RL\nagents and generates natural language explanations. Surrounding this method, we\nbuild an interactive XRL system where users can actively explore explanations\nand influential information. In a user study with 14 participants, we validated\nthat developers identified 20.9% more abnormal behaviors and limitations of RL\nagents with our system compared to the baseline method, and using our system\nhelped end users improve their performance in actionability tests by 25.1% in\nan auto-driving task and by 16.9% in a StarCraft II micromanagement task.",
    "descriptor": "",
    "authors": [
      "Xiaoran Wu",
      "Zihan Yan",
      "Chongjie Zhang",
      "Shuangtong Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.00888"
  },
  {
    "id": "arXiv:2212.00891",
    "title": "Space Complexity of Stack Automata Models",
    "abstract": "This paper examines several measures of space complexity of variants of stack\nautomata: non-erasing stack automata and checking stack automata. These\nmeasures capture the minimum stack size required to accept every word in the\nlanguage of the automaton (weak measure), the maximum stack size used in any\naccepting computation on any accepted word (accept measure),and the maximum\nstack size used in any computation (strong measure). We give a detailed\ncharacterization of the accept and strong space complexity measures for\nchecking stack automata. Exactly one of three cases can occur: the complexity\nis either bounded by a constant, behaves like a linear function, or it can not\nbe bounded by any function of the length of the input word (and it is decidable\nwhich case occurs). However, this result does not hold for non-erasing stack\nautomata; we provide an example where the space complexity grows proportionally\nto the square root of the length of the input. Furthermore, we study the\ncomplexity bounds of machines which accept a given language, and decidability\nof space complexity properties.",
    "descriptor": "\nComments: 23 pages, 1 figure, 2 tables\n",
    "authors": [
      "Oscar H. Ibarra",
      "Jozef Jir\u00e1sek",
      "Ian McQuillan",
      "Luca Prigioniero"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2212.00891"
  },
  {
    "id": "arXiv:2212.00892",
    "title": "Progressive Feature Upgrade in Semi-supervised Learning on Tabular  Domain",
    "abstract": "Recent semi-supervised and self-supervised methods have shown great success\nin the image and text domain by utilizing augmentation techniques. Despite such\nsuccess, it is not easy to transfer this success to tabular domains. It is not\neasy to adapt domain-specific transformations from image and language to\ntabular data due to mixing of different data types (continuous data and\ncategorical data) in the tabular domain. There are a few semi-supervised works\non the tabular domain that have focused on proposing new augmentation\ntechniques for tabular data. These approaches may have shown some improvement\non datasets with low-cardinality in categorical data. However, the fundamental\nchallenges have not been tackled. The proposed methods either do not apply to\ndatasets with high-cardinality or do not use an efficient encoding of\ncategorical data. We propose using conditional probability representation and\nan efficient progressively feature upgrading framework to effectively learn\nrepresentations for tabular data in semi-supervised applications. The extensive\nexperiments show superior performance of the proposed framework and the\npotential application in semi-supervised settings.",
    "descriptor": "",
    "authors": [
      "Morteza Mohammady Gharasuie",
      "Fenjiao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00892"
  },
  {
    "id": "arXiv:2212.00893",
    "title": "Compositional Learning of Dynamical System Models Using Port-Hamiltonian  Neural Networks",
    "abstract": "Many dynamical systems -- from robots interacting with their surroundings to\nlarge-scale multiphysics systems -- involve a number of interacting subsystems.\nToward the objective of learning composite models of such systems from data, we\npresent i) a framework for compositional neural networks, ii) algorithms to\ntrain these models, iii) a method to compose the learned models, iv)\ntheoretical results that bound the error of the resulting composite models, and\nv) a method to learn the composition itself, when it is not known a prior. The\nend result is a modular approach to learning: neural network submodels are\ntrained on trajectory data generated by relatively simple subsystems, and the\ndynamics of more complex composite systems are then predicted without requiring\nadditional data generated by the composite systems themselves. We achieve this\ncompositionality by representing the system of interest, as well as each of its\nsubsystems, as a port-Hamiltonian neural network (PHNN) -- a class of neural\nordinary differential equations that uses the port-Hamiltonian systems\nformulation as inductive bias. We compose collections of PHNNs by using the\nsystem's physics-informed interconnection structure, which may be known a\npriori, or may itself be learned from data. We demonstrate the novel\ncapabilities of the proposed framework through numerical examples involving\ninteracting spring-mass-damper systems. Models of these systems, which include\nnonlinear energy dissipation and control inputs, are learned independently.\nAccurate compositions are learned using an amount of training data that is\nnegligible in comparison with that required to train a new model from scratch.\nFinally, we observe that the composite PHNNs enjoy properties of\nport-Hamiltonian systems, such as cyclo-passivity -- a property that is useful\nfor control purposes.",
    "descriptor": "",
    "authors": [
      "Cyrus Neary",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.00893"
  },
  {
    "id": "arXiv:2212.00897",
    "title": "Generalizations of Checking Stack Automata: Characterizations and  Hierarchies",
    "abstract": "We examine different generalizations of checking stack automata by allowing\nmultiple input heads and multiple stacks, and characterize their computing\npower in terms of two-way multi-head finite automata and space-bounded Turing\nmachines. For various models, we obtain hierarchies in terms of their computing\npower. Our characterizations and hierarchies expand or tighten some previously\nknown results. We also discuss some decidability questions and the space/time\ncomplexity of the models.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Oscar H. Ibarra",
      "Ian McQuillan"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2212.00897"
  },
  {
    "id": "arXiv:2212.00898",
    "title": "Hierarchical Model Selection for Graph Neural Netoworks",
    "abstract": "Node classification on graph data is a major problem, and various graph\nneural networks (GNNs) have been proposed. Variants of GNNs such as H2GCN and\nCPF outperform graph convolutional networks (GCNs) by improving on the\nweaknesses of the traditional GNN. However, there are some graph data which\nthese GNN variants fail to perform well than other GNNs in the node\nclassification task. This is because H2GCN has a feature thinning on graph data\nwith high average degree, and CPF gives rise to a problem about\nlabel-propagation suitability. Accordingly, we propose a hierarchical model\nselection framework (HMSF) that selects an appropriate GNN model by analyzing\nthe indicators of each graph data. In the experiment, we show that the model\nselected by our HMSF achieves high performance on node classification for\nvarious types of graph data.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Yuga Oishi",
      "Ken Kaneiwa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00898"
  },
  {
    "id": "arXiv:2212.00903",
    "title": "DeclutterCam: A Photographic Assistant System with Clutter Detection and  Removal",
    "abstract": "Photographs convey the stories of photographers to the audience. However,\nthis story-telling aspect of photography is easily distracted by visual\nclutter. Informed by a pilot study, we identified the kinds of clutter that\namateurs frequently include in their photos. We were thus inspired to develop\nDeclutterCam, a photographic assistant system that incorporates novel user\ninteractions and AI algorithms for photographic decluttering. Clutter elements\nare detected by an aesthetic quality evaluation algorithm and are highlighted\nso that users can interactively identify distracting elements. A GAN-based\niterative clutter removal tool enables users to test their photographic ideas\nin real-time. User studies with 32 photography beginners demonstrate that our\nsystem provides flexible interfaces, accurate algorithms, and immediate\nfeedback that allow users to avoid clutter and explore more photographic ideas.\nEvaluations by photography experts show that users can take higher-quality\nphotos that better convey the intended story using our system.",
    "descriptor": "",
    "authors": [
      "Xiaoran Wu",
      "Zihan Yan",
      "Xiang Anthony Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.00903"
  },
  {
    "id": "arXiv:2212.00904",
    "title": "Human-instructed Deep Hierarchical Generative Learning for Automated  Urban Planning",
    "abstract": "The essential task of urban planning is to generate the optimal land-use\nconfiguration of a target area. However, traditional urban planning is\ntime-consuming and labor-intensive. Deep generative learning gives us hope that\nwe can automate this planning process and come up with the ideal urban plans.\nWhile remarkable achievements have been obtained, they have exhibited\nlimitations in lacking awareness of: 1) the hierarchical dependencies between\nfunctional zones and spatial grids; 2) the peer dependencies among functional\nzones; and 3) human regulations to ensure the usability of generated\nconfigurations. To address these limitations, we develop a novel\nhuman-instructed deep hierarchical generative model. We rethink the urban\nplanning generative task from a unique functionality perspective, where we\nsummarize planning requirements into different functionality projections for\nbetter urban plan generation. To this end, we develop a three-stage generation\nprocess from a target area to zones to grids. The first stage is to label the\ngrids of a target area with latent functionalities to discover functional\nzones. The second stage is to perceive the planning requirements to form urban\nfunctionality projections. We propose a novel module: functionalizer to project\nthe embedding of human instructions and geospatial contexts to the zone-level\nplan to obtain such projections. Each projection includes the information of\nland-use portfolios and the structural dependencies across spatial grids in\nterms of a specific urban function. The third stage is to leverage\nmulti-attentions to model the zone-zone peer dependencies of the functionality\nprojections to generate grid-level land-use configurations. Finally, we present\nextensive experiments to demonstrate the effectiveness of our framework.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Dongjie Wang",
      "Lingfei Wu",
      "Denghui Zhang",
      "Jingbo Zhou",
      "Leilei Sun",
      "Yanjie Fu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.00904"
  },
  {
    "id": "arXiv:2212.00906",
    "title": "Karolos: An Open-Source Reinforcement Learning Framework for Robot-Task  Environments",
    "abstract": "In reinforcement learning (RL) research, simulations enable benchmarks\nbetween algorithms, as well as prototyping and hyper-parameter tuning of\nagents. In order to promote RL both in research and real-world applications,\nframeworks are required which are on the one hand efficient in terms of running\nexperiments as fast as possible. On the other hand, they must be flexible\nenough to allow the integration of newly developed optimization techniques,\ne.g. new RL algorithms, which are continuously put forward by an active\nresearch community. In this paper, we introduce Karolos, a RL framework\ndeveloped for robotic applications, with a particular focus on transfer\nscenarios with varying robot-task combinations reflected in a modular\nenvironment architecture. In addition, we provide implementations of\nstate-of-the-art RL algorithms along with common learning-facilitating\nenhancements, as well as an architecture to parallelize environments across\nmultiple processes to significantly speed up experiments. The code is open\nsource and published on GitHub with the aim of promoting research of RL\napplications in robotics.",
    "descriptor": "",
    "authors": [
      "Christian Bitter",
      "Timo Thun",
      "Tobias Meisen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00906"
  },
  {
    "id": "arXiv:2212.00908",
    "title": "Test Flakiness' Causes, Detection, Impact and Responses: A Multivocal  Review",
    "abstract": "Flaky tests (tests with non-deterministic outcomes) pose a major challenge\nfor software testing. They are known to cause significant issues such as\nreducing the effectiveness and efficiency of testing and delaying software\nreleases. In recent years, there has been an increased interest in flaky tests,\nwith research focusing on different aspects of flakiness, such as identifying\ncauses, detection methods and mitigation strategies. Test flakiness has also\nbecome a key discussion point for practitioners (in blog posts, technical\nmagazines, etc.) as the impact of flaky tests is felt across the industry. This\npaper presents a multivocal review that investigates how flaky tests, as a\ntopic, have been addressed in both research and practice. We cover a total of\n651 articles (560 academic articles and 91 grey literature articles/posts), and\nstructure the body of relevant research and knowledge using four different\ndimensions: causes, detection, impact and responses. For each of those\ndimensions we provide a categorisation, and classify existing research,\ndiscussions, methods and tools. With this, we provide a comprehensive and\ncurrent snapshot of existing thinking on test flakiness, covering both academic\nviews and industrial practices, and identify limitations and opportunities for\nfuture research.",
    "descriptor": "\nComments: Under review at Journal of Systems and Software\n",
    "authors": [
      "Shawn Rasheed",
      "Amjed Tahir",
      "Jens Dietrich",
      "Negar Hashemi",
      "Lu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.00908"
  },
  {
    "id": "arXiv:2212.00911",
    "title": "Navigating causal deep learning",
    "abstract": "Causal deep learning (CDL) is a new and important research area in the larger\nfield of machine learning. With CDL, researchers aim to structure and encode\ncausal knowledge in the extremely flexible representation space of deep\nlearning models. Doing so will lead to more informed, robust, and general\npredictions and inference -- which is important! However, CDL is still in its\ninfancy. For example, it is not clear how we ought to compare different methods\nas they are so different in their output, the way they encode causal knowledge,\nor even how they represent this knowledge. This is a living paper that\ncategorises methods in causal deep learning beyond Pearl's ladder of causation.\nWe refine the rungs in Pearl's ladder, while also adding a separate dimension\nthat categorises the parametric assumptions of both input and representation,\narriving at the map of causal deep learning. Our map covers machine learning\ndisciplines such as supervised learning, reinforcement learning, generative\nmodelling and beyond. Our paradigm is a tool which helps researchers to: find\nbenchmarks, compare methods, and most importantly: identify research gaps. With\nthis work we aim to structure the avalanche of papers being published on causal\ndeep learning. While papers on the topic are being published daily, our map\nremains fixed. We open-source our map for others to use as they see fit:\nperhaps to offer guidance in a related works section, or to better highlight\nthe contribution of their paper.",
    "descriptor": "",
    "authors": [
      "Jeroen Berrevoets",
      "Krzysztof Kacprzyk",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00911"
  },
  {
    "id": "arXiv:2212.00912",
    "title": "Private Multiparty Perception for Navigation",
    "abstract": "We introduce a framework for navigating through cluttered environments by\nconnecting multiple cameras together while simultaneously preserving privacy.\nOcclusions and obstacles in large environments are often challenging situations\nfor navigation agents because the environment is not fully observable from a\nsingle camera view. Given multiple camera views of an environment, our approach\nlearns to produce a multiview scene representation that can only be used for\nnavigation, provably preventing one party from inferring anything beyond the\noutput task. On a new navigation dataset that we will publicly release,\nexperiments show that private multiparty representations allow navigation\nthrough complex scenes and around obstacles while jointly preserving privacy.\nOur approach scales to an arbitrary number of camera viewpoints. We believe\ndeveloping visual representations that preserve privacy is increasingly\nimportant for many applications such as navigation.",
    "descriptor": "",
    "authors": [
      "Hui Lu",
      "Mia Chiquier",
      "Carl Vondrick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00912"
  },
  {
    "id": "arXiv:2212.00914",
    "title": "QFF: Quantized Fourier Features for Neural Field Representations",
    "abstract": "Multilayer perceptrons (MLPs) learn high frequencies slowly. Recent\napproaches encode features in spatial bins to improve speed of learning\ndetails, but at the cost of larger model size and loss of continuity. Instead,\nwe propose to encode features in bins of Fourier features that are commonly\nused for positional encoding. We call these Quantized Fourier Features (QFF).\nAs a naturally multiresolution and periodic representation, our experiments\nshow that using QFF can result in smaller model size, faster training, and\nbetter quality outputs for several applications, including Neural Image\nRepresentations (NIR), Neural Radiance Field (NeRF) and Signed Distance\nFunction (SDF) modeling. QFF are easy to code, fast to compute, and serve as a\nsimple drop-in addition to many neural field representations.",
    "descriptor": "",
    "authors": [
      "Jae Yong Lee",
      "Yuqun Wu",
      "Chuhang Zou",
      "Shenlong Wang",
      "Derek Hoiem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00914"
  },
  {
    "id": "arXiv:2212.00916",
    "title": "Learning Temporal Logic Properties: an Overview of Two Recent Methods",
    "abstract": "Learning linear temporal logic (LTL) formulas from examples labeled as\npositive or negative has found applications in inferring descriptions of system\nbehavior. We summarize two methods to learn LTL formulas from examples in two\ndifferent problem settings. The first method assumes noise in the labeling of\nthe examples. For that, they define the problem of inferring an LTL formula\nthat must be consistent with most but not all of the examples. The second\nmethod considers the other problem of inferring meaningful LTL formulas in the\ncase where only positive examples are given. Hence, the first method addresses\nthe robustness to noise, and the second method addresses the balance between\nconciseness and specificity (i.e., language minimality) of the inferred\nformula. The summarized methods propose different algorithms to solve the\naforementioned problems, as well as to infer other descriptions of temporal\nproperties, such as signal temporal logic or deterministic finite automata.",
    "descriptor": "\nComments: Appears in Proceedings of AAAI FSS-22 Symposium \"Lessons Learned for Autonomous Assessment of Machine Abilities (LLAAMA)\"\n",
    "authors": [
      "Jean-Rapha\u00ebl Gaglione",
      "Rajarshi Roy",
      "Nasim Baharisangari",
      "Daniel Neider",
      "Zhe Xu",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00916"
  },
  {
    "id": "arXiv:2212.00920",
    "title": "Geometry-Aware Network for Domain Adaptive Semantic Segmentation",
    "abstract": "Measuring and alleviating the discrepancies between the synthetic (source)\nand real scene (target) data is the core issue for domain adaptive semantic\nsegmentation. Though recent works have introduced depth information in the\nsource domain to reinforce the geometric and semantic knowledge transfer, they\ncannot extract the intrinsic 3D information of objects, including positions and\nshapes, merely based on 2D estimated depth. In this work, we propose a novel\nGeometry-Aware Network for Domain Adaptation (GANDA), leveraging more compact\n3D geometric point cloud representations to shrink the domain gaps. In\nparticular, we first utilize the auxiliary depth supervision from the source\ndomain to obtain the depth prediction in the target domain to accomplish\nstructure-texture disentanglement. Beyond depth estimation, we explicitly\nexploit 3D topology on the point clouds generated from RGB-D images for further\ncoordinate-color disentanglement and pseudo-labels refinement in the target\ndomain. Moreover, to improve the 2D classifier in the target domain, we perform\ndomain-invariant geometric adaptation from source to target and unify the 2D\nsemantic and 3D geometric segmentation results in two domains. Note that our\nGANDA is plug-and-play in any existing UDA framework. Qualitative and\nquantitative results demonstrate that our model outperforms state-of-the-arts\non GTA5->Cityscapes and SYNTHIA->Cityscapes.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Yinghong Liao",
      "Wending Zhou",
      "Xu Yan",
      "Shuguang Cui",
      "Yizhou Yu",
      "Zhen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00920"
  },
  {
    "id": "arXiv:2212.00921",
    "title": "AGRO: Adversarial Discovery of Error-prone groups for Robust  Optimization",
    "abstract": "Models trained via empirical risk minimization (ERM) are known to rely on\nspurious correlations between labels and task-independent input features,\nresulting in poor generalization to distributional shifts. Group\ndistributionally robust optimization (G-DRO) can alleviate this problem by\nminimizing the worst-case loss over a set of pre-defined groups over training\ndata. G-DRO successfully improves performance of the worst-group, where the\ncorrelation does not hold. However, G-DRO assumes that the spurious\ncorrelations and associated worst groups are known in advance, making it\nchallenging to apply it to new tasks with potentially multiple unknown spurious\ncorrelations. We propose AGRO -- Adversarial Group discovery for\nDistributionally Robust Optimization -- an end-to-end approach that jointly\nidentifies error-prone groups and improves accuracy on them. AGRO equips G-DRO\nwith an adversarial slicing model to find a group assignment for training\nexamples which maximizes worst-case loss over the discovered groups. On the\nWILDS benchmark, AGRO results in 8% higher model performance on average on\nknown worst-groups, compared to prior group discovery approaches used with\nG-DRO. AGRO also improves out-of-distribution performance on SST2, QQP, and\nMS-COCO -- datasets where potential spurious correlations are as yet\nuncharacterized. Human evaluation of ARGO groups shows that they contain\nwell-defined, yet previously unstudied spurious correlations that lead to model\nerrors.",
    "descriptor": "",
    "authors": [
      "Bhargavi Paranjape",
      "Pradeep Dasigi",
      "Vivek Srikumar",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.00921"
  },
  {
    "id": "arXiv:2212.00922",
    "title": "Navigating to Objects in the Real World",
    "abstract": "Semantic navigation is necessary to deploy mobile robots in uncontrolled\nenvironments like our homes, schools, and hospitals. Many learning-based\napproaches have been proposed in response to the lack of semantic understanding\nof the classical pipeline for spatial navigation, which builds a geometric map\nusing depth sensors and plans to reach point goals. Broadly, end-to-end\nlearning approaches reactively map sensor inputs to actions with deep neural\nnetworks, while modular learning approaches enrich the classical pipeline with\nlearning-based semantic sensing and exploration. But learned visual navigation\npolicies have predominantly been evaluated in simulation. How well do different\nclasses of methods work on a robot? We present a large-scale empirical study of\nsemantic visual navigation methods comparing representative methods from\nclassical, modular, and end-to-end learning approaches across six homes with no\nprior experience, maps, or instrumentation. We find that modular learning works\nwell in the real world, attaining a 90% success rate. In contrast, end-to-end\nlearning does not, dropping from 77% simulation to 23% real-world success rate\ndue to a large image domain gap between simulation and reality. For\npractitioners, we show that modular learning is a reliable approach to navigate\nto objects: modularity and abstraction in policy design enable Sim-to-Real\ntransfer. For researchers, we identify two key issues that prevent today's\nsimulators from being reliable evaluation benchmarks - (A) a large Sim-to-Real\ngap in images and (B) a disconnect between simulation and real-world error\nmodes - and propose concrete steps forward.",
    "descriptor": "\nComments: 39 pages, 19 figures and tables, submitted to Science Robotics\n",
    "authors": [
      "Theophile Gervet",
      "Soumith Chintala",
      "Dhruv Batra",
      "Jitendra Malik",
      "Devendra Singh Chaplot"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00922"
  },
  {
    "id": "arXiv:2212.00923",
    "title": "A Tractable Probability Distribution with Applications in  Three-Dimensional Statistics",
    "abstract": "A new family of continuous probability distributions is highlighted in this\npaper that has found applications in norm distributions of three-dimensional\nrandom spaces. The distribution is defined over the semi-infinite interval\n$[0,\\infty)$, indicates remarkably tractable characteristics, and provides\ninteresting applications.",
    "descriptor": "",
    "authors": [
      "Seyed Mohammad Azimi-Abarghouyi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2212.00923"
  },
  {
    "id": "arXiv:2212.00926",
    "title": "Fair Generative Models via Transfer Learning",
    "abstract": "This work addresses fair generative models. Dataset biases have been a major\ncause of unfairness in deep generative models. Previous work had proposed to\naugment large, biased datasets with small, unbiased reference datasets. Under\nthis setup, a weakly-supervised approach has been proposed, which achieves\nstate-of-the-art quality and fairness in generated samples. In our work, based\non this setup, we propose a simple yet effective approach. Specifically, first,\nwe propose fairTL, a transfer learning approach to learn fair generative\nmodels. Under fairTL, we pre-train the generative model with the available\nlarge, biased datasets and subsequently adapt the model using the small,\nunbiased reference dataset. We find that our fairTL can learn expressive sample\ngeneration during pre-training, thanks to the large (biased) dataset. This\nknowledge is then transferred to the target model during adaptation, which also\nlearns to capture the underlying fair distribution of the small reference\ndataset. Second, we propose fairTL++, where we introduce two additional\ninnovations to improve upon fairTL: (i) multiple feedback and (ii)\nLinear-Probing followed by Fine-Tuning (LP-FT). Taking one step further, we\nconsider an alternative, challenging setup when only a pre-trained (potentially\nbiased) model is available but the dataset that was used to pre-train the model\nis inaccessible. We demonstrate that our proposed fairTL and fairTL++ remain\nvery effective under this setup. We note that previous work requires access to\nthe large, biased datasets and is incapable of handling this more challenging\nsetup. Extensive experiments show that fairTL and fairTL++ achieve\nstate-of-the-art in both quality and fairness of generated samples. The code\nand additional resources can be found at bearwithchris.github.io/fairTL/.",
    "descriptor": "\nComments: Accepted in AAAI-2023\n",
    "authors": [
      "Christopher TH Teo",
      "Milad Abdollahzadeh",
      "Ngai-Man Cheung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.00926"
  },
  {
    "id": "arXiv:2212.00928",
    "title": "Single-shot ToF sensing with sub-mm precision using conventional CMOS  sensors",
    "abstract": "We present a novel single-shot interferometric ToF camera targeted for\nprecise 3D measurements of dynamic objects. The camera concept is based on\nSynthetic Wavelength Interferometry, a technique that allows retrieval of depth\nmaps of objects with optically rough surfaces at submillimeter depth precision.\nIn contrast to conventional ToF cameras, our device uses only off-the-shelf\nCCD/CMOS detectors and works at their native chip resolution (as of today,\ntheoretically up to 20 Mp and beyond). Moreover, we can obtain a full 3D model\nof the object in single-shot, meaning that no temporal sequence of exposures or\ntemporal illumination modulation (such as amplitude or frequency modulation) is\nnecessary, which makes our camera robust against object motion.\nIn this paper, we introduce the novel camera concept and show first\nmeasurements that demonstrate the capabilities of our system. We present 3D\nmeasurements of small (cm-sized) objects with > 2 Mp point cloud resolution\n(the resolution of our used detector) and up to sub-mm depth precision. We also\nreport a \"single-shot 3D video\" acquisition and a first single-shot\n\"Non-Line-of-Sight\" measurement. Our technique has great potential for\nhigh-precision applications with dynamic object movement, e.g., in AR/VR,\nindustrial inspection, medical imaging, and imaging through scattering media\nlike fog or human tissue.",
    "descriptor": "",
    "authors": [
      "Manuel Ballester",
      "Heming Wang",
      "Jiren Li",
      "Oliver Cossairt",
      "Florian Willomitzer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00928"
  },
  {
    "id": "arXiv:2212.00932",
    "title": "ObjectStitch: Generative Object Compositing",
    "abstract": "Object compositing based on 2D images is a challenging problem since it\ntypically involves multiple processing stages such as color harmonization,\ngeometry correction and shadow generation to generate realistic results.\nFurthermore, annotating training data pairs for compositing requires\nsubstantial manual effort from professionals, and is hardly scalable. Thus,\nwith the recent advances in generative models, in this work, we propose a\nself-supervised framework for object compositing by leveraging the power of\nconditional diffusion models. Our framework can hollistically address the\nobject compositing task in a unified model, transforming the viewpoint,\ngeometry, color and shadow of the generated object while requiring no manual\nlabeling. To preserve the input object's characteristics, we introduce a\ncontent adaptor that helps to maintain categorical semantics and object\nappearance. A data augmentation method is further adopted to improve the\nfidelity of the generator. Our method outperforms relevant baselines in both\nrealism and faithfulness of the synthesized result images in a user study on\nvarious real-world images.",
    "descriptor": "",
    "authors": [
      "Yizhi Song",
      "Zhifei Zhang",
      "Zhe Lin",
      "Scott Cohen",
      "Brian Price",
      "Jianming Zhang",
      "Soo Ye Kim",
      "Daniel Aliaga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00932"
  },
  {
    "id": "arXiv:2212.00935",
    "title": "Dunhuang murals contour generation network based on convolution and  self-attention fusion",
    "abstract": "Dunhuang murals are a collection of Chinese style and national style, forming\na self-contained Chinese-style Buddhist art. It has very high historical and\ncultural value and research significance. Among them, the lines of Dunhuang\nmurals are highly general and expressive. It reflects the character's\ndistinctive character and complex inner emotions. Therefore, the outline\ndrawing of murals is of great significance to the research of Dunhuang Culture.\nThe contour generation of Dunhuang murals belongs to image edge detection,\nwhich is an important branch of computer vision, aims to extract salient\ncontour information in images. Although convolution-based deep learning\nnetworks have achieved good results in image edge extraction by exploring the\ncontextual and semantic features of images. However, with the enlargement of\nthe receptive field, some local detail information is lost. This makes it\nimpossible for them to generate reasonable outline drawings of murals. In this\npaper, we propose a novel edge detector based on self-attention combined with\nconvolution to generate line drawings of Dunhuang murals. Compared with\nexisting edge detection methods, firstly, a new residual self-attention and\nconvolution mixed module (Ramix) is proposed to fuse local and global features\nin feature maps. Secondly, a novel densely connected backbone extraction\nnetwork is designed to efficiently propagate rich edge feature information from\nshallow layers into deep layers. Compared with existing methods, it is shown on\ndifferent public datasets that our method is able to generate sharper and\nricher edge maps. In addition, testing on the Dunhuang mural dataset shows that\nour method can achieve very competitive performance.",
    "descriptor": "",
    "authors": [
      "Baokai Liu",
      "Fengjie He",
      "Shiqiang Du",
      "Kaiwu Zhang",
      "Jianhua Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00935"
  },
  {
    "id": "arXiv:2212.00936",
    "title": "Integer Subspace Differential Privacy",
    "abstract": "We propose new differential privacy solutions for when external\n\\emph{invariants} and \\emph{integer} constraints are simultaneously enforced on\nthe data product. These requirements arise in real world applications of\nprivate data curation, including the public release of the 2020 U.S. Decennial\nCensus. They pose a great challenge to the production of provably private data\nproducts with adequate statistical usability. We propose \\emph{integer subspace\ndifferential privacy} to rigorously articulate the privacy guarantee when data\nproducts maintain both the invariants and integer characteristics, and\ndemonstrate the composition and post-processing properties of our proposal. To\naddress the challenge of sampling from a potentially highly restricted discrete\nspace, we devise a pair of unbiased additive mechanisms, the generalized\nLaplace and the generalized Gaussian mechanisms, by solving the Diophantine\nequations as defined by the constraints. The proposed mechanisms have good\naccuracy, with errors exhibiting sub-exponential and sub-Gaussian tail\nprobabilities respectively. To implement our proposal, we design an MCMC\nalgorithm and supply empirical convergence assessment using estimated upper\nbounds on the total variation distance via $L$-lag coupling. We demonstrate the\nefficacy of our proposal with applications to a synthetic problem with\nintersecting invariants, a sensitive contingency table with known margins, and\nthe 2010 Census county-level demonstration data with mandated fixed state\npopulation totals.",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Prathamesh Dharangutte",
      "Jie Gao",
      "Ruobin Gong",
      "Fang-Yi Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.00936"
  },
  {
    "id": "arXiv:2212.00937",
    "title": "StructVPR: Distill Structural Knowledge with Weighting Samples for  Visual Place Recognition",
    "abstract": "Visual place recognition (VPR) is usually considered as a specific image\nretrieval problem. Limited by existing training frameworks, most deep\nlearning-based works cannot extract sufficiently stable global features from\nRGB images and rely on a time-consuming re-ranking step to exploit spatial\nstructural information for better performance. In this paper, we propose\nStructVPR, a novel training architecture for VPR, to enhance structural\nknowledge in RGB global features and thus improve feature stability in a\nconstantly changing environment. Specifically, StructVPR uses segmentation\nimages as a more definitive source of structural knowledge input into a CNN\nnetwork and applies knowledge distillation to avoid online segmentation and\ninference of seg-branch in testing. Considering that not all samples contain\nhigh-quality and helpful knowledge, and some even hurt the performance of\ndistillation, we partition samples and weigh each sample's distillation loss to\nenhance the expected knowledge precisely. Finally, StructVPR achieves\nimpressive performance on several benchmarks using only global retrieval and\neven outperforms many two-stage approaches by a large margin. After adding\nadditional re-ranking, ours achieves state-of-the-art performance while\nmaintaining a low computational cost.",
    "descriptor": "",
    "authors": [
      "Yanqing Shen",
      "Sanping Zhopu",
      "Jingwen Fu",
      "Ruotong Wang",
      "Shitao Chen",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00937"
  },
  {
    "id": "arXiv:2212.00939",
    "title": "DisaggRec: Architecting Disaggregated Systems for Large-Scale  Personalized Recommendation",
    "abstract": "Deep learning-based personalized recommendation systems are widely used for\nonline user-facing services in production datacenters, where a large amount of\nhardware resources are procured and managed to reliably provide low-latency\nservices without disruption. As the recommendation models continue to evolve\nand grow in size, our analysis projects that datacenters deployed with\nmonolithic servers will spend up to 12.4x total cost of ownership (TCO) to meet\nthe requirement of model size and complexity over the next three years.\nMoreover, through in-depth characterization, we reveal that the monolithic\nserver-based cluster suffers resource idleness and wastes up to 30% TCO by\nprovisioning resources in fixed proportions. To address this challenge, we\npropose DisaggRec, a disaggregated system for large-scale recommendation\nserving. DisaggRec achieves the independent decoupled scaling-out of the\ncompute and memory resources to match the changing demands from fast-evolving\nworkloads. It also improves system reliability by segregating the failures of\ncompute nodes and memory nodes. These two main benefits from disaggregation\ncollectively reduce the TCO by up to 49.3%. Furthermore, disaggregation enables\nflexible and agile provisioning of increasing hardware heterogeneity in future\ndatacenters. By deploying new hardware featuring near-memory processing\ncapability, our evaluation shows that the disaggregated cluster achieves\n21%-43.6% TCO savings over the monolithic server-based cluster across a\nthree-year span of model evolution.",
    "descriptor": "",
    "authors": [
      "Liu Ke",
      "Xuan Zhang",
      "Benjamin Lee",
      "G. Edward Suh",
      "Hsien-Hsin S. Lee"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.00939"
  },
  {
    "id": "arXiv:2212.00942",
    "title": "A Geometric-Relational Deep Learning Framework for BIM Object  Classification",
    "abstract": "Interoperability issue is a significant problem in Building Information\nModeling (BIM). Object type, as a kind of critical semantic information needed\nin multiple BIM applications like scan-to-BIM and code compliance checking,\nalso suffers when exchanging BIM data or creating models using software of\nother domains. It can be supplemented using deep learning. Current deep\nlearning methods mainly learn from the shape information of BIM objects for\nclassification, leaving relational information inherent in the BIM context\nunused. To address this issue, we introduce a two-branch geometric-relational\ndeep learning framework. It boosts previous geometric classification methods\nwith relational information. We also present a BIM object dataset IFCNet++,\nwhich contains both geometric and relational information about the objects.\nExperiments show that our framework can be flexibly adapted to different\ngeometric methods. And relational features do act as a bonus to general\ngeometric learning methods, obviously improving their classification\nperformance, thus reducing the manual labor of checking models and improving\nthe practical value of enriched BIM models.",
    "descriptor": "\nComments: Computer Vision for Civil and Infrastructure Engineering Workshop (CVCIE @ ECCV2022)\n",
    "authors": [
      "Hairong Luo",
      "Ge Gao",
      "Han Huang",
      "Ziyi Ke",
      "Cheng Peng",
      "Ming Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00942"
  },
  {
    "id": "arXiv:2212.00946",
    "title": "Trie-Compressed Intersectable Sets",
    "abstract": "We introduce space- and time-efficient algorithms and data structures for the\noffline set intersection problem. We show that a sorted integer set $S\n\\subseteq [0{..}u)$ of $n$ elements can be represented using compressed space\nwhile supporting $k$-way intersections in adaptive\n$O(k\\delta\\lg{\\!(u/\\delta)})$ time, $\\delta$ being the alternation measure\nintroduced by Barbay and Kenyon. Our experimental results suggest that our\napproaches are competitive in practice, outperforming the most efficient\nalternatives (Partitioned Elias-Fano indexes, Roaring Bitmaps, and Recursive\nUniverse Partitioning (RUP)) in several scenarios, offering in general relevant\nspace-time trade-offs.",
    "descriptor": "",
    "authors": [
      "Diego Arroyuelo",
      "Juan Pablo Castillo"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.00946"
  },
  {
    "id": "arXiv:2212.00951",
    "title": "SimpleMind adds thinking to deep neural networks",
    "abstract": "Deep neural networks (DNNs) detect patterns in data and have shown\nversatility and strong performance in many computer vision applications.\nHowever, DNNs alone are susceptible to obvious mistakes that violate simple,\ncommon sense concepts and are limited in their ability to use explicit\nknowledge to guide their search and decision making. While overall DNN\nperformance metrics may be good, these obvious errors, coupled with a lack of\nexplainability, have prevented widespread adoption for crucial tasks such as\nmedical image analysis. The purpose of this paper is to introduce SimpleMind,\nan open-source software framework for Cognitive AI focused on medical image\nunderstanding. It allows creation of a knowledge base that describes expected\ncharacteristics and relationships between image objects in an intuitive\nhuman-readable form. The SimpleMind framework brings thinking to DNNs by: (1)\nproviding methods for reasoning with the knowledge base about image content,\nsuch as spatial inferencing and conditional reasoning to check DNN outputs; (2)\napplying process knowledge, in the form of general-purpose software agents,\nthat are chained together to accomplish image preprocessing, DNN prediction,\nand result post-processing, and (3) performing automatic co-optimization of all\nknowledge base parameters to adapt agents to specific problems. SimpleMind\nenables reasoning on multiple detected objects to ensure consistency, providing\ncross checking between DNN outputs. This machine reasoning improves the\nreliability and trustworthiness of DNNs through an interpretable model and\nexplainable decisions. Example applications are provided that demonstrate how\nSimpleMind supports and improves deep neural networks by embedding them within\na Cognitive AI framework.",
    "descriptor": "",
    "authors": [
      "Youngwon Choi",
      "M. Wasil Wahi-Anwar",
      "Matthew S. Brown"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00951"
  },
  {
    "id": "arXiv:2212.00952",
    "title": "On the Limit of Explaining Black-box Temporal Graph Neural Networks",
    "abstract": "Temporal Graph Neural Network (TGNN) has been receiving a lot of attention\nrecently due to its capability in modeling time-evolving graph-related tasks.\nSimilar to Graph Neural Networks, it is also non-trivial to interpret\npredictions made by a TGNN due to its black-box nature. A major approach\ntackling this problems in GNNs is by analyzing the model' responses on some\nperturbations of the model's inputs, called perturbation-based explanation\nmethods. While these methods are convenient and flexible since they do not need\ninternal access to the model, does this lack of internal access prevent them\nfrom revealing some important information of the predictions? Motivated by that\nquestion, this work studies the limit of some classes of perturbation-based\nexplanation methods. Particularly, by constructing some specific instances of\nTGNNs, we show (i) node-perturbation cannot reliably identify the paths\ncarrying out the prediction, (ii) edge-perturbation is not reliable in\ndetermining all nodes contributing to the prediction and (iii) perturbing both\nnodes and edges does not reliably help us identify the graph's components\ncarrying out the temporal aggregation in TGNNs.",
    "descriptor": "",
    "authors": [
      "Minh N. Vu",
      "My T. Thai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00952"
  },
  {
    "id": "arXiv:2212.00953",
    "title": "Few-Shot Nested Named Entity Recognition",
    "abstract": "While Named Entity Recognition (NER) is a widely studied task, making\ninferences of entities with only a few labeled data has been challenging,\nespecially for entities with nested structures. Unlike flat entities, entities\nand their nested entities are more likely to have similar semantic feature\nrepresentations, drastically increasing difficulties in classifying different\nentity categories in the few-shot setting. Although prior work has briefly\ndiscussed nested structures in the context of few-shot learning, to our best\nknowledge, this paper is the first one specifically dedicated to studying the\nfew-shot nested NER task. Leveraging contextual dependency to distinguish\nnested entities, we propose a Biaffine-based Contrastive Learning (BCL)\nframework. We first design a Biaffine span representation module for learning\nthe contextual span dependency representation for each entity span rather than\nonly learning its semantic representation. We then merge these two\nrepresentations by the residual connection to distinguish nested entities.\nFinally, we build a contrastive learning framework to adjust the representation\ndistribution for larger margin boundaries and more generalized domain transfer\nlearning ability. We conducted experimental studies on three English, German,\nand Russian nested NER datasets. The results show that the BCL outperformed\nthree baseline models on the 1-shot and 5-shot tasks in terms of F1 score.",
    "descriptor": "",
    "authors": [
      "Hong Ming",
      "Jiaoyun Yang",
      "Lili Jiang",
      "Yan Pan",
      "Ning An"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00953"
  },
  {
    "id": "arXiv:2212.00955",
    "title": "Prim-LAfD: A Framework to Learn and Adapt Primitive-Based Skills from  Demonstrations for Insertion Tasks",
    "abstract": "Learning generalizable insertion skills in a data-efficient manner has long\nbeen a challenge in the robot learning community. While the current\nstate-of-the-art methods with reinforcement learning (RL) show promising\nperformance in acquiring manipulation skills, the algorithms are data-hungry\nand hard to generalize. To overcome the issues, in this paper we present\nPrim-LAfD, a simple yet effective framework to learn and adapt primitive-based\ninsertion skills from demonstrations. Prim-LAfD utilizes black-box function\noptimization to learn and adapt the primitive parameters leveraging prior\nexperiences. Human demonstrations are modeled as dense rewards guiding\nparameter learning. We validate the effectiveness of the proposed method on\neight peg-hole and connector-socket insertion tasks. The experimental results\nshow that our proposed framework takes less than one hour to acquire the\ninsertion skills and as few as fifteen minutes to adapt to an unseen insertion\ntask on a physical robot.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Zheng Wu",
      "Wenzhao Lian",
      "Changhao Wang",
      "Mengxi Li",
      "Stefan Schaal",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.00955"
  },
  {
    "id": "arXiv:2212.00956",
    "title": "Infrastructure with Memphis Crime",
    "abstract": "In this work, we study Memphis Crime Data and Memphis 311 Data regarding\nPotholes from 2020 to 2022. The Memphis Crime Data contains data about\ndifferent crimes reported in the Memphis area containing information on where\nthe crime was reported and when it was reported. The Memphis 311 Data contains\ndata on different infrastructure projects on where the project is happening,\nwhen the project starts and when the project is complete. With the Memphis 301\nData we are focusing on infrastructure projects regarding pothole repair.",
    "descriptor": "",
    "authors": [
      "Alexandre Signorel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.00956"
  },
  {
    "id": "arXiv:2212.00959",
    "title": "UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question  Answering Over Knowledge Graph",
    "abstract": "Multi-hop Question Answering over Knowledge Graph~(KGQA) aims to find the\nanswer entities that are multiple hops away from the topic entities mentioned\nin a natural language question on a large-scale Knowledge Graph (KG). To cope\nwith the vast search space, existing work usually adopts a two-stage approach:\nit firstly retrieves a relatively small subgraph related to the question and\nthen performs the reasoning on the subgraph to accurately find the answer\nentities. Although these two stages are highly related, previous work employs\nvery different technical solutions for developing the retrieval and reasoning\nmodels, neglecting their relatedness in task essence. In this paper, we propose\nUniKGQA, a novel approach for multi-hop KGQA task, by unifying retrieval and\nreasoning in both model architecture and parameter learning. For model\narchitecture, UniKGQA consists of a semantic matching module based on a\npre-trained language model~(PLM) for question-relation semantic matching, and a\nmatching information propagation module to propagate the matching information\nalong the edges on KGs. For parameter learning, we design a shared pre-training\ntask based on question-relation matching for both retrieval and reasoning\nmodels, and then propose retrieval- and reasoning-oriented fine-tuning\nstrategies. Compared with previous studies, our approach is more unified,\ntightly relating the retrieval and reasoning stages. Extensive experiments on\nthree benchmark datasets have demonstrated the effectiveness of our method on\nthe multi-hop KGQA task. Our codes and data are publicly available at\nhttps://github.com/RUCAIBox/UniKGQA.",
    "descriptor": "",
    "authors": [
      "Jinhao Jiang",
      "Kun Zhou",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.00959"
  },
  {
    "id": "arXiv:2212.00964",
    "title": "JAX-FEM: A differentiable GPU-accelerated 3D finite element solver for  automatic inverse design and mechanistic data science",
    "abstract": "This paper introduces JAX-FEM, an open-source differentiable finite element\nmethod (FEM) library. Constructed on top of Google JAX, a rising machine\nlearning library focusing on high-performance numerical computing, JAX-FEM is\nimplemented with pure Python while scalable to efficiently solve problems with\nmoderate to large sizes. For example, in a 3D tensile loading problem with 7.7\nmillion degrees of freedom, JAX-FEM with GPU achieves around 10$\\times$\nacceleration compared to a commercial FEM code depending on platform. Beyond\nefficiently solving forward problems, JAX-FEM employs the automatic\ndifferentiation technique so that inverse problems are solved in a fully\nautomatic manner without the need to manually derive sensitivities. Examples of\n3D topology optimization of nonlinear materials are shown to achieve optimal\ncompliance. Finally, JAX-FEM is an integrated platform for machine\nlearning-aided computational mechanics. We show an example of data-driven\nmulti-scale computations of a composite material where JAX-FEM provides an\nall-in-one solution from microscopic data generation and model training to\nmacroscopic FE computations. The source code of the library and these examples\nare shared with the community to facilitate computational mechanics research.",
    "descriptor": "",
    "authors": [
      "Tianju Xue",
      "Shuheng Liao",
      "Zhengtao Gan",
      "Chanwook Park",
      "Xiaoyu Xie",
      "Wing Kam Liu",
      "Jian Cao"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2212.00964"
  },
  {
    "id": "arXiv:2212.00965",
    "title": "AL-iGAN: An Active Learning Framework for Tunnel Geological  Reconstruction Based on TBM Operational Data",
    "abstract": "In tunnel boring machine (TBM) underground projects, an accurate description\nof the rock-soil types distributed in the tunnel can decrease the construction\nrisk ({\\it e.g.} surface settlement and landslide) and improve the efficiency\nof construction. In this paper, we propose an active learning framework, called\nAL-iGAN, for tunnel geological reconstruction based on TBM operational data.\nThis framework contains two main parts: one is the usage of active learning\ntechniques for recommending new drilling locations to label the TBM operational\ndata and then to form new training samples; and the other is an incremental\ngenerative adversarial network for geological reconstruction (iGAN-GR), whose\nweights can be incrementally updated to improve the reconstruction performance\nby using the new samples. The numerical experiment validate the effectiveness\nof the proposed framework as well.",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Lixue Liu",
      "Xueguan Song",
      "Chao Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00965"
  },
  {
    "id": "arXiv:2212.00966",
    "title": "A Hybrid Deep Learning Anomaly Detection Framework for Intrusion  Detection",
    "abstract": "Cyber intrusion attacks that compromise the users' critical and sensitive\ndata are escalating in volume and intensity, especially with the growing\nconnections between our daily life and the Internet. The large volume and high\ncomplexity of such intrusion attacks have impeded the effectiveness of most\ntraditional defence techniques. While at the same time, the remarkable\nperformance of the machine learning methods, especially deep learning, in\ncomputer vision, had garnered research interests from the cyber security\ncommunity to further enhance and automate intrusion detections. However, the\nexpensive data labeling and limitation of anomalous data make it challenging to\ntrain an intrusion detector in a fully supervised manner. Therefore, intrusion\ndetection based on unsupervised anomaly detection is an important feature too.\nIn this paper, we propose a three-stage deep learning anomaly detection based\nnetwork intrusion attack detection framework. The framework comprises an\nintegration of unsupervised (K-means clustering), semi-supervised (GANomaly)\nand supervised learning (CNN) algorithms. We then evaluated and showed the\nperformance of our implemented framework on three benchmark datasets: NSL-KDD,\nCIC-IDS2018, and TON_IoT.",
    "descriptor": "\nComments: Keywords: Cybersecurity, Anomaly Detection, Intrusion Detection, Deep Learning, Unsupervised Learning, Neural Networks; this https URL\n",
    "authors": [
      "Rahul Kale",
      "Zhi Lu",
      "Kar Wai Fok",
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00966"
  },
  {
    "id": "arXiv:2212.00968",
    "title": "UIU-Net: U-Net in U-Net for Infrared Small Object Detection",
    "abstract": "Learning-based infrared small object detection methods currently rely heavily\non the classification backbone network. This tends to result in tiny object\nloss and feature distinguishability limitations as the network depth increases.\nFurthermore, small objects in infrared images are frequently emerged bright and\ndark, posing severe demands for obtaining precise object contrast information.\nFor this reason, we in this paper propose a simple and effective ``U-Net in\nU-Net'' framework, UIU-Net for short, and detect small objects in infrared\nimages. As the name suggests, UIU-Net embeds a tiny U-Net into a larger U-Net\nbackbone, enabling the multi-level and multi-scale representation learning of\nobjects. Moreover, UIU-Net can be trained from scratch, and the learned\nfeatures can enhance global and local contrast information effectively. More\nspecifically, the UIU-Net model is divided into two modules: the\nresolution-maintenance deep supervision (RM-DS) module and the\ninteractive-cross attention (IC-A) module. RM-DS integrates Residual U-blocks\ninto a deep supervision network to generate deep multi-scale\nresolution-maintenance features while learning global context information.\nFurther, IC-A encodes the local context information between the low-level\ndetails and high-level semantic features. Extensive experiments conducted on\ntwo infrared single-frame image datasets, i.e., SIRST and Synthetic datasets,\nshow the effectiveness and superiority of the proposed UIU-Net in comparison\nwith several state-of-the-art infrared small object detection methods. The\nproposed UIU-Net also produces powerful generalization performance for video\nsequence infrared small object datasets, e.g., ATR ground/air video sequence\ndataset. The codes of this work are available openly at\n\\url{https://github.com/danfenghong/IEEE_TIP_UIU-Net}.",
    "descriptor": "",
    "authors": [
      "Xin Wu",
      "Danfeng Hong",
      "Jocelyn Chanussot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00968"
  },
  {
    "id": "arXiv:2212.00970",
    "title": "Bayesian Physics Informed Neural Networks for Data Assimilation and  Spatio-Temporal Modelling of Wildfires",
    "abstract": "We apply Physics Informed Neural Networks (PINNs) to the problem of wildfire\nfire-front modelling. The PINN is an approach that integrates a differential\nequation into the optimisation loss function of a neural network to guide the\nneural network to learn the physics of a problem. We apply the PINN to the\nlevel-set equation, which is a Hamilton-Jacobi partial differential equation\nthat models a fire-front with the zero-level set. This results in a PINN that\nsimulates a fire-front as it propagates through a spatio-temporal domain. We\ndemonstrate the agility of the PINN to learn physical properties of a fire\nunder extreme changes in external conditions (such as wind) and show that this\napproach encourages continuity of the PINN's solution across time. Furthermore,\nwe demonstrate how data assimilation and uncertainty quantification can be\nincorporated into the PINN in the wildfire context. This is significant\ncontribution to wildfire modelling as the level-set method -- which is a\nstandard solver to the level-set equation -- does not naturally provide this\ncapability.",
    "descriptor": "",
    "authors": [
      "Joel Janek Dabrowski",
      "Daniel Edward Pagendam",
      "James Hilton",
      "Conrad Sanderson",
      "Daniel MacKinlay",
      "Carolyn Huston",
      "Andrew Bolt",
      "Petra Kuhnert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00970"
  },
  {
    "id": "arXiv:2212.00972",
    "title": "Cloud-Device Collaborative Adaptation to Continual Changing Environments  in the Real-world",
    "abstract": "When facing changing environments in the real world, the lightweight model on\nclient devices suffers from severe performance drops under distribution shifts.\nThe main limitations of the existing device model lie in (1) unable to update\ndue to the computation limit of the device, (2) the limited generalization\nability of the lightweight model. Meanwhile, recent large models have shown\nstrong generalization capability on the cloud while they can not be deployed on\nclient devices due to poor computation constraints. To enable the device model\nto deal with changing environments, we propose a new learning paradigm of\nCloud-Device Collaborative Continual Adaptation, which encourages collaboration\nbetween cloud and device and improves the generalization of the device model.\nBased on this paradigm, we further propose an Uncertainty-based Visual Prompt\nAdapted (U-VPA) teacher-student model to transfer the generalization capability\nof the large model on the cloud to the device model. Specifically, we first\ndesign the Uncertainty Guided Sampling (UGS) to screen out challenging data\ncontinuously and transmit the most out-of-distribution samples from the device\nto the cloud. Then we propose a Visual Prompt Learning Strategy with\nUncertainty guided updating (VPLU) to specifically deal with the selected\nsamples with more distribution shifts. We transmit the visual prompts to the\ndevice and concatenate them with the incoming data to pull the device testing\ndistribution closer to the cloud training distribution. We conduct extensive\nexperiments on two object detection datasets with continually changing\nenvironments. Our proposed U-VPA teacher-student framework outperforms previous\nstate-of-the-art test time adaptation and device-cloud collaboration methods.\nThe code and datasets will be released.",
    "descriptor": "",
    "authors": [
      "Yulu Gan",
      "Mingjie Pan",
      "Rongyu Zhang",
      "Zijian Ling",
      "Lingran Zhao",
      "Jiaming Liu",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00972"
  },
  {
    "id": "arXiv:2212.00973",
    "title": "A Domain-Knowledge-Inspired Music Embedding Space and a Novel Attention  Mechanism for Symbolic Music Modeling",
    "abstract": "Following the success of the transformer architecture in the natural language\ndomain, transformer-like architectures have been widely applied to the domain\nof symbolic music recently. Symbolic music and text, however, are two different\nmodalities. Symbolic music contains multiple attributes, both absolute\nattributes (e.g., pitch) and relative attributes (e.g., pitch interval). These\nrelative attributes shape human perception of musical motifs. These important\nrelative attributes, however, are mostly ignored in existing symbolic music\nmodeling methods with the main reason being the lack of a musically-meaningful\nembedding space where both the absolute and relative embeddings of the symbolic\nmusic tokens can be efficiently represented. In this paper, we propose the\nFundamental Music Embedding (FME) for symbolic music based on a bias-adjusted\nsinusoidal encoding within which both the absolute and the relative attributes\ncan be embedded and the fundamental musical properties (e.g., translational\ninvariance) are explicitly preserved. Taking advantage of the proposed FME, we\nfurther propose a novel attention mechanism based on the relative index, pitch\nand onset embeddings (RIPO attention) such that the musical domain knowledge\ncan be fully utilized for symbolic music modeling. Experiment results show that\nour proposed model: RIPO transformer which utilizes FME and RIPO attention\noutperforms the state-of-the-art transformers (i.e., music transformer, linear\ntransformer) in a melody completion task. Moreover, using the RIPO transformer\nin a downstream music generation task, we notice that the notorious\ndegeneration phenomenon no longer exists and the music generated by the RIPO\ntransformer outperforms the music generated by state-of-the-art transformer\nmodels in both subjective and objective evaluations.",
    "descriptor": "\nComments: This paper is accepted at AAAI 2023\n",
    "authors": [
      "Z. Guo",
      "J. Kang",
      "D. Herremans"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.00973"
  },
  {
    "id": "arXiv:2212.00974",
    "title": "Faster Adaptive Federated Learning",
    "abstract": "Federated learning has attracted increasing attention with the emergence of\ndistributed data. While extensive federated learning algorithms have been\nproposed for the non-convex distributed problem, the federated learning in\npractice still faces numerous challenges, such as the large training iterations\nto converge since the sizes of models and datasets keep increasing, and the\nlack of adaptivity by SGD-based model updates. Meanwhile, the study of adaptive\nmethods in federated learning is scarce and existing works either lack a\ncomplete theoretical convergence guarantee or have slow sample complexity. In\nthis paper, we propose an efficient adaptive algorithm (i.e., FAFED) based on\nthe momentum-based variance reduced technique in cross-silo FL. We first\nexplore how to design the adaptive algorithm in the FL setting. By providing a\ncounter-example, we prove that a simple combination of FL and adaptive methods\ncould lead to divergence. More importantly, we provide a convergence analysis\nfor our method and prove that our algorithm is the first adaptive FL algorithm\nto reach the best-known samples $O(\\epsilon^{-3})$ and $O(\\epsilon^{-2})$\ncommunication rounds to find an $\\epsilon$-stationary point without large\nbatches. The experimental results on the language modeling task and image\nclassification task with heterogeneous data demonstrate the efficiency of our\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Xidong Wu",
      "Feihu Huang",
      "Zhengmian Hu",
      "Heng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.00974"
  },
  {
    "id": "arXiv:2212.00975",
    "title": "Relation-aware Language-Graph Transformer for Question Answering",
    "abstract": "Question Answering (QA) is a task that entails reasoning over natural\nlanguage contexts, and many relevant works augment language models (LMs) with\ngraph neural networks (GNNs) to encode the Knowledge Graph (KG) information.\nHowever, most existing GNN-based modules for QA do not take advantage of rich\nrelational information of KGs and depend on limited information interaction\nbetween the LM and the KG. To address these issues, we propose Question\nAnswering Transformer (QAT), which is designed to jointly reason over language\nand graphs with respect to entity relations in a unified manner. Specifically,\nQAT constructs Meta-Path tokens, which learn relation-centric embeddings based\non diverse structural and semantic relations. Then, our Relation-Aware\nSelf-Attention module comprehensively integrates different modalities via the\nCross-Modal Relative Position Bias, which guides information exchange between\nrelevant entities of different modalities. We validate the effectiveness of QAT\non commonsense question answering datasets like CommonsenseQA and OpenBookQA,\nand on a medical question answering dataset, MedQA-USMLE. On all the datasets,\nour method achieves state-of-the-art performance. Our code is available at\nthis http URL",
    "descriptor": "\nComments: AAAI2023 (accepted)\n",
    "authors": [
      "Jinyoung Park",
      "Hyeong Kyu Choi",
      "Juyeon Ko",
      "Hyeonjin Park",
      "Ji-Hoon Kim",
      "Jisu Jeong",
      "Kyungmin Kim",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00975"
  },
  {
    "id": "arXiv:2212.00977",
    "title": "PSPC: Efficient Parallel Shortest Path Counting on Large-Scale Graphs",
    "abstract": "In modern graph analytics, the shortest path is a fundamental concept.\nNumerous \\rrev{recent works} concentrate mostly on the distance of these\nshortest paths. Nevertheless, in the era of betweenness analysis, the counting\nof the shortest path between $s$ and $t$ is equally crucial. \\rrev{It} is\n\\rev{also} an important issue in the area of graph databases. In recent years,\nseveral studies have been conducted in an effort to tackle such issues.\nNonetheless, the present technique faces a considerable barrier to parallel due\nto the dependencies in the index construction stage, hence limiting its\napplication possibilities and wasting the potential hardware performance. To\naddress this problem, we provide a parallel shortest path counting method that\ncould avoid these dependencies and obtain approximately linear index time\nspeedup as the number of threads increases. Our empirical evaluations verify\nthe efficiency and effectiveness.",
    "descriptor": "",
    "authors": [
      "You Peng",
      "Jeffrey Xu Yu",
      "Sibo Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.00977"
  },
  {
    "id": "arXiv:2212.00979",
    "title": "PASTA: Proportional Amplitude Spectrum Training Augmentation for  Syn-to-Real Domain Generalization",
    "abstract": "Synthetic data offers the promise of cheap and bountiful training data for\nsettings where lots of labeled real-world data for tasks is unavailable.\nHowever, models trained on synthetic data significantly underperform on\nreal-world data. In this paper, we propose Proportional Amplitude Spectrum\nTraining Augmentation (PASTA), a simple and effective augmentation strategy to\nimprove out-of-the-box synthetic-to-real (syn-to-real) generalization\nperformance. PASTA involves perturbing the amplitude spectrums of the synthetic\nimages in the Fourier domain to generate augmented views. We design PASTA to\nperturb the amplitude spectrums in a structured manner such that high-frequency\ncomponents are perturbed relatively more than the low-frequency ones. For the\ntasks of semantic segmentation (GTAV to Real), object detection (Sim10K to\nReal), and object recognition (VisDA-C Syn to Real), across a total of 5\nsyn-to-real shifts, we find that PASTA outperforms more complex\nstate-of-the-art generalization methods while being complementary to the same.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Prithvijit Chattopadhyay",
      "Kartik Sarangmath",
      "Vivek Vijaykumar",
      "Judy Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.00979"
  },
  {
    "id": "arXiv:2212.00981",
    "title": "QC-StyleGAN -- Quality Controllable Image Generation and Manipulation",
    "abstract": "The introduction of high-quality image generation models, particularly the\nStyleGAN family, provides a powerful tool to synthesize and manipulate images.\nHowever, existing models are built upon high-quality (HQ) data as desired\noutputs, making them unfit for in-the-wild low-quality (LQ) images, which are\ncommon inputs for manipulation. In this work, we bridge this gap by proposing a\nnovel GAN structure that allows for generating images with controllable\nquality. The network can synthesize various image degradation and restore the\nsharp image via a quality control code. Our proposed QC-StyleGAN can directly\nedit LQ images without altering their quality by applying GAN inversion and\nmanipulation techniques. It also provides for free an image restoration\nsolution that can handle various degradations, including noise, blur,\ncompression artifacts, and their mixtures. Finally, we demonstrate numerous\nother applications such as image degradation synthesis, transfer, and\ninterpolation.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Dat Viet Thanh Nguyen",
      "Phong Tran The",
      "Tan M. Dinh",
      "Cuong Pham",
      "Anh Tuan Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00981"
  },
  {
    "id": "arXiv:2212.00986",
    "title": "Masked Contrastive Pre-Training for Efficient Video-Text Retrieval",
    "abstract": "We present a simple yet effective end-to-end Video-language Pre-training\n(VidLP) framework, Masked Contrastive Video-language Pretraining (MAC), for\nvideo-text retrieval tasks. Our MAC aims to reduce video representation's\nspatial and temporal redundancy in the VidLP model by a mask sampling mechanism\nto improve pre-training efficiency. Comparing conventional temporal sparse\nsampling, we propose to randomly mask a high ratio of spatial regions and only\nfeed visible regions into the encoder as sparse spatial sampling. Similarly, we\nadopt the mask sampling technique for text inputs for consistency. Instead of\nblindly applying the mask-then-prediction paradigm from MAE, we propose a\nmasked-then-alignment paradigm for efficient video-text alignment. The\nmotivation is that video-text retrieval tasks rely on high-level alignment\nrather than low-level reconstruction, and multimodal alignment with masked\nmodeling encourages the model to learn a robust and general multimodal\nrepresentation from incomplete and unstable inputs. Coupling these designs\nenables efficient end-to-end pre-training: reduce FLOPs (60% off), accelerate\npre-training (by 3x), and improve performance. Our MAC achieves\nstate-of-the-art results on various video-text retrieval datasets, including\nMSR-VTT, DiDeMo, and ActivityNet. Our approach is omnivorous to input\nmodalities. With minimal modifications, we achieve competitive results on\nimage-text retrieval tasks.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Fangxun Shu",
      "Biaolong Chen",
      "Yue Liao",
      "Ke Gao",
      "Shuwen Xiao",
      "Wenyu Sun",
      "Xiaobo Li",
      "Yousong Zhu",
      "Jinqiao Wang",
      "Si Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.00986"
  },
  {
    "id": "arXiv:2212.00987",
    "title": "Sparse SPN: Depth Completion from Sparse Keypoints",
    "abstract": "Our long term goal is to use image-based depth completion to quickly create\n3D models from sparse point clouds, e.g. from SfM or SLAM. Much progress has\nbeen made in depth completion. However, most current works assume well\ndistributed samples of known depth, e.g. Lidar or random uniform sampling, and\nperform poorly on uneven samples, such as from keypoints, due to the large\nunsampled regions. To address this problem, we extend CSPN with multiscale\nprediction and a dilated kernel, leading to much better completion of\nkeypoint-sampled depth. We also show that a model trained on NYUv2 creates\nsurprisingly good point clouds on ETH3D by completing sparse SfM points.",
    "descriptor": "",
    "authors": [
      "Yuqun Wu",
      "Jae Yong Lee",
      "Derek Hoiem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00987"
  },
  {
    "id": "arXiv:2212.00990",
    "title": "Feature Aggregation and Propagation Network for Camouflaged Object  Detection",
    "abstract": "Camouflaged object detection (COD) aims to detect/segment camouflaged objects\nembedded in the environment, which has attracted increasing attention over the\npast decades. Although several COD methods have been developed, they still\nsuffer from unsatisfactory performance due to the intrinsic similarities\nbetween the foreground objects and background surroundings. In this paper, we\npropose a novel Feature Aggregation and Propagation Network (FAP-Net) for\ncamouflaged object detection. Specifically, we propose a Boundary Guidance\nModule (BGM) to explicitly model the boundary characteristic, which can provide\nboundary-enhanced features to boost the COD performance. To capture the scale\nvariations of the camouflaged objects, we propose a Multi-scale Feature\nAggregation Module (MFAM) to characterize the multi-scale information from each\nlayer and obtain the aggregated feature representations. Furthermore, we\npropose a Cross-level Fusion and Propagation Module (CFPM). In the CFPM, the\nfeature fusion part can effectively integrate the features from adjacent layers\nto exploit the cross-level correlations, and the feature propagation part can\ntransmit valuable context information from the encoder to the decoder network\nvia a gate unit. Finally, we formulate a unified and end-to-end trainable\nframework where cross-level features can be effectively fused and propagated\nfor capturing rich context information. Extensive experiments on three\nbenchmark camouflaged datasets demonstrate that our FAP-Net outperforms other\nstate-of-the-art COD models. Moreover, our model can be extended to the polyp\nsegmentation task, and the comparison results further validate the\neffectiveness of the proposed model in segmenting polyps. The source code and\nresults will be released at https://github.com/taozh2017/FAPNet.",
    "descriptor": "\nComments: 12 pages, 6 figures, accepted by IEEE Transactions on Image Processing\n",
    "authors": [
      "Tao Zhou",
      "Yi Zhou",
      "Chen Gong",
      "Jian Yang",
      "Yu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00990"
  },
  {
    "id": "arXiv:2212.00992",
    "title": "Stable Learning via Sparse Variable Independence",
    "abstract": "The problem of covariate-shift generalization has attracted intensive\nresearch attention. Previous stable learning algorithms employ sample\nreweighting schemes to decorrelate the covariates when there is no explicit\ndomain information about training data. However, with finite samples, it is\ndifficult to achieve the desirable weights that ensure perfect independence to\nget rid of the unstable variables. Besides, decorrelating within stable\nvariables may bring about high variance of learned models because of the\nover-reduced effective sample size. A tremendous sample size is required for\nthese algorithms to work. In this paper, with theoretical justification, we\npropose SVI (Sparse Variable Independence) for the covariate-shift\ngeneralization problem. We introduce sparsity constraint to compensate for the\nimperfectness of sample reweighting under the finite-sample setting in previous\nmethods. Furthermore, we organically combine independence-based sample\nreweighting and sparsity-based variable selection in an iterative way to avoid\ndecorrelating within stable variables, increasing the effective sample size to\nalleviate variance inflation. Experiments on both synthetic and real-world\ndatasets demonstrate the improvement of covariate-shift generalization\nperformance brought by SVI.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Han Yu",
      "Peng Cui",
      "Yue He",
      "Zheyan Shen",
      "Yong Lin",
      "Renzhe Xu",
      "Xingxuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.00992"
  },
  {
    "id": "arXiv:2212.00994",
    "title": "Knowledge Graph Quality Evaluation under Incomplete Information",
    "abstract": "Utilities of knowledge graphs (KGs) depend on their qualities. A KG that is\nof poor quality not only has little applicability but also leads to some\nunexpected errors. Therefore, quality evaluation for KGs is crucial and\nindispensable. Existing methods design many quality dimensions and calculate\nmetrics in the corresponding dimensions based on details (i.e., raw data and\ngraph structures) of KGs for evaluation. However, there are two major issues.\nOn one hand, they consider the details as public information, which exposes the\nraw data and graph structures. These details are strictly confidential because\nthey involve commercial privacy or others in practice. On the other hand, the\nexisting methods focus on how much knowledge KGs have rather than KGs'\npracticability. To address the above problems, we propose a knowledge graph\nquality evaluation framework under incomplete information (QEII). The quality\nevaluation problem is transformed into an adversarial game, and the relative\nquality is evaluated according to the winner and loser. Participants of the\ngame are KGs, and the adversarial gameplay is to question and answer (Q&A). In\nthe QEII, we generate and train a question model and an answer model for each\nKG. The question model of a KG first asks a certain number of questions to the\nother KG. Then it evaluates the answers returned by the answer model of the\nother KG and outputs a percentage score. The relative quality is evaluated by\nthe scores, which measures the ability to apply knowledge. Q&A messages are the\nonly information that KGs exchange, without exposing any raw data and graph\nstructure. Experimental results on two pairs of KGs demonstrate that, comparing\nwith baselines, the QEII realizes a reasonable quality evaluation from the\nperspective of third-party evaluators under incomplete information.",
    "descriptor": "",
    "authors": [
      "Xiaodong Li",
      "Chenxin Zou",
      "Yi Cai",
      "Yuelong Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00994"
  },
  {
    "id": "arXiv:2212.00996",
    "title": "Clustering through Feature Space Sequence Discovery and Analysis",
    "abstract": "Identifying high-dimensional data patterns without a priori knowledge is an\nimportant task of data science. This paper proposes a simple and efficient\nnoparametric algorithm: Data Convert to Sequence Analysis, DCSA, which\ndynamically explore each point in the feature space without repetition, and a\nDirected Hamilton Path will be found. Based on the change point analysis\ntheory, The sequence corresponding to the path is cut into several fragments to\nachieve clustering. The experiments on real-world datasets from different\nfields with dimensions ranging from 4 to 20531 confirm that the method in this\nwork is robust and has visual interpretability in result analysis.",
    "descriptor": "\nComments: 19pages, 20figures, individual work public individually, all benchmark and experiment were design and processed with Python 3.7. And I imagine the results have prefound meanning, I think density may be a hidden dimension\n",
    "authors": [
      "Shi Guobin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00996"
  },
  {
    "id": "arXiv:2212.00998",
    "title": "Credit Assignment for Trained Neural Networks Based on Koopman Operator  Theory",
    "abstract": "Credit assignment problem of neural networks refers to evaluating the credit\nof each network component to the final outputs. For an untrained neural\nnetwork, approaches to tackling it have made great contributions to parameter\nupdate and model revolution during the training phase. This problem on trained\nneural networks receives rare attention, nevertheless, it plays an increasingly\nimportant role in neural network patch, specification and verification. Based\non Koopman operator theory, this paper presents an alternative perspective of\nlinear dynamics on dealing with the credit assignment problem for trained\nneural networks. Regarding a neural network as the composition of sub-dynamics\nseries, we utilize step-delay embedding to capture snapshots of each component,\ncharacterizing the established mapping as exactly as possible. To circumvent\nthe dimension-difference problem encountered during the embedding, a\ncomposition and decomposition of an auxiliary linear layer, termed minimal\nlinear dimension alignment, is carefully designed with rigorous formal\nguarantee. Afterwards, each component is approximated by a Koopman operator and\nwe derive the Jacobian matrix and its corresponding determinant, similar to\nbackward propagation. Then, we can define a metric with algebraic\ninterpretability for the credit assignment of each network component. Moreover,\nexperiments conducted on typical neural networks demonstrate the effectiveness\nof the proposed method.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Zhen Liang",
      "Changyuan Zhao",
      "Wanwei Liu",
      "Bai Xue",
      "Wenjing Yang",
      "Zhengbin Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00998"
  },
  {
    "id": "arXiv:2212.00999",
    "title": "Information Retrieval from the Digitized Books",
    "abstract": "Extracting the relevant information out of a large number of documents is a\nchallenging and tedious task. The quality of results generated by the\ntraditionally available full-text search engine and text-based image retrieval\nsystems is not optimal. Information retrieval (IR) tasks become more\nchallenging with the nontraditional language scripts, as in the case of Indic\nscripts. The authors have developed OCR (Optical Character Recognition) Search\nEngine to make an Information Retrieval & Extraction (IRE) system that\nreplicates the current state-of-the-art methods using the IRE and Natural\nLanguage Processing (NLP) techniques. Here we have presented the study of the\nmethods used for performing search and retrieval tasks. The details of this\nsystem, along with the statistics of the dataset (source: National Digital\nLibrary of India or NDLI), is also presented. Additionally, the ideas to\nfurther explore and add value to research in IRE are also discussed.",
    "descriptor": "\nComments: 6 pages including references, 5 figures, and 1 table. For project page see this https URL\n",
    "authors": [
      "Riya Gupta",
      "C. V. Jawahar"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.00999"
  },
  {
    "id": "arXiv:2212.01004",
    "title": "Planogram Compliance Control via Object Detection, Sequence Alignment,  and Focused Iterative Search",
    "abstract": "Smart retail stores are becoming the fact of our lives. Several computer\nvision and sensor based systems are working together to achieve such a complex\nand automated operation. Besides, the retail sector already has several open\nand challenging problems which can be solved with the help of pattern\nrecognition and computer vision methods. One important problem to be tackled is\nthe planogram compliance control. In this study, we propose a novel method to\nsolve it. The proposed method is based on object detection, planogram\ncompliance control, and focused and iterative search steps. The object\ndetection step is formed by local feature extraction and implicit shape model\nformation. The planogram compliance control step is formed by sequence\nalignment via the modified Needleman-Wunsch algorithm. The focused and\niterative search step aims to improve the performance of the object detection\nand planogram compliance control steps. We tested all three steps on two\ndifferent datasets. Based on these tests, we summarize the key findings as well\nas strengths and weaknesses of the proposed method.",
    "descriptor": "",
    "authors": [
      "M. Erkin Y\u00fccel",
      "Cem \u00dcnsalan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01004"
  },
  {
    "id": "arXiv:2212.01005",
    "title": "AGO: Boosting Mobile AI Inference Performance by Removing Constraints on  Graph Optimization",
    "abstract": "Traditional deep learning compilers rely on heuristics for subgraph\ngeneration, which impose extra constraints on graph optimization, e.g., each\nsubgraph can only contain at most one complex operator. In this paper, we\npropose AGO, a framework for graph optimization with arbitrary structures to\nboost the inference performance of deep models by removing such constraints. To\ncreate new optimization opportunities for complicated subgraphs, we propose\nintensive operator fusion, which can effectively stitch multiple complex\noperators together for better performance. Further, we design a graph\npartitioning scheme that allows an arbitrary structure for each subgraph while\nguaranteeing the acyclic property among all generated subgraphs. Additionally,\nto enable efficient performance tuning on complicated subgraphs, we devise a\nnovel divide-and-conquer tuning mechanism to orchestrate different system\ncomponents. Through extensive experiments on various neural networks and mobile\ndevices, we show that our system can improve the inference performance by up to\n3.3x when compared with state-of-the-art deep compilers.",
    "descriptor": "",
    "authors": [
      "Zhiying Xu",
      "Hongding Peng",
      "Wei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.01005"
  },
  {
    "id": "arXiv:2212.01006",
    "title": "FedCoCo: A Memory Efficient Federated Self-supervised Framework for  On-Device Visual Representation Learning",
    "abstract": "The ubiquity of edge devices has led to a growing amount of unlabeled data\nproduced at the edge. Deep learning models deployed on edge devices are\nrequired to learn from these unlabeled data to continuously improve accuracy.\nSelf-supervised representation learning has achieved promising performances\nusing centralized unlabeled data. However, the increasing awareness of privacy\nprotection limits centralizing the distributed unlabeled image data on edge\ndevices. While federated learning has been widely adopted to enable distributed\nmachine learning with privacy preservation, without a data selection method to\nefficiently select streaming data, the traditional federated learning framework\nfails to handle these huge amounts of decentralized unlabeled data with limited\nstorage resources on edge. To address these challenges, we propose a Federated\non-device Contrastive learning framework with Coreset selection, which we call\nFedCoCo, to automatically select a coreset that consists of the most\nrepresentative samples into the replay buffer on each device. It preserves data\nprivacy as each client does not share raw data while learning good visual\nrepresentations. Experiments demonstrate the effectiveness and significance of\nthe proposed method in visual representation learning.",
    "descriptor": "",
    "authors": [
      "Jiahe Shi",
      "Yawen Wu",
      "Dewen Zeng",
      "Jingtong Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01006"
  },
  {
    "id": "arXiv:2212.01007",
    "title": "Compound Batch Normalization for Long-tailed Image Classification",
    "abstract": "Significant progress has been made in learning image classification neural\nnetworks under long-tail data distribution using robust training algorithms\nsuch as data re-sampling, re-weighting, and margin adjustment. Those methods,\nhowever, ignore the impact of data imbalance on feature normalization. The\ndominance of majority classes (head classes) in estimating statistics and\naffine parameters causes internal covariate shifts within less-frequent\ncategories to be overlooked. To alleviate this challenge, we propose a compound\nbatch normalization method based on a Gaussian mixture. It can model the\nfeature space more comprehensively and reduce the dominance of head classes. In\naddition, a moving average-based expectation maximization (EM) algorithm is\nemployed to estimate the statistical parameters of multiple Gaussian\ndistributions. However, the EM algorithm is sensitive to initialization and can\neasily become stuck in local minima where the multiple Gaussian components\ncontinue to focus on majority classes. To tackle this issue, we developed a\ndual-path learning framework that employs class-aware split feature\nnormalization to diversify the estimated Gaussian distributions, allowing the\nGaussian components to fit with training samples of less-frequent classes more\ncomprehensively. Extensive experiments on commonly used datasets demonstrated\nthat the proposed method outperforms existing methods on long-tailed image\nclassification.",
    "descriptor": "\nComments: Accepted by ACM MM 2022\n",
    "authors": [
      "Lechao Cheng",
      "Chaowei Fang",
      "Dingwen Zhang",
      "Guanbin Li",
      "Gang Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01007"
  },
  {
    "id": "arXiv:2212.01011",
    "title": "CLeBPI: Contrastive Learning for Bug Priority Inference",
    "abstract": "Automated bug priority inference can reduce the time overhead of bug triagers\nfor priority assignments, improving the efficiency of software maintenance.\nCurrently, there are two orthogonal lines for this task, i.e., traditional\nmachine learning based (TML-based) and neural network based (NN-based)\napproaches. Although these approaches achieve competitive performance, our\nobservation finds that existing approaches face the following two issues: 1)\nTML-based approaches require much manual feature engineering and cannot learn\nthe semantic information of bug reports; 2) Both TML-based and NN-based\napproaches cannot effectively address the label imbalance problem because they\nare difficult to distinguish the semantic difference between bug reports with\ndifferent priorities. In this paper, we propose CLeBPI (Contrastive Learning\nfor Bug Priority Inference), which leverages pre-trained language model and\ncontrastive learning to tackle the above-mentioned two issues. Specifically,\nCLeBPI is first pre-trained on a large-scale bug report corpus in a\nself-supervised way, thus it can automatically learn contextual representations\nof bug reports without manual feature engineering. Afterward, it is further\npre-trained by a contrastive learning objective, which enables it to\ndistinguish semantic differences between bug reports, learning more precise\ncontextual representations for each bug report. When finishing pre-training, we\ncan connect a classification layer to CLeBPI and fine-tune it for bug priority\ninference in a supervised way. To verify the effectiveness of CLeBPI, we choose\nfour baseline approaches and conduct comparison experiments on a public\ndataset. The experimental results show that CLeBPI outperforms all baseline\napproaches by 23.86%-77.80% in terms of weighted average F1-score, showing its\neffectiveness.",
    "descriptor": "\nComments: 22 pages, 5 figures\n",
    "authors": [
      "Wenyao Wang",
      "Chenhao Wu",
      "Jie He"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.01011"
  },
  {
    "id": "arXiv:2212.01015",
    "title": "Improving Training and Inference of Face Recognition Models via Random  Temperature Scaling",
    "abstract": "Data uncertainty is commonly observed in the images for face recognition\n(FR). However, deep learning algorithms often make predictions with high\nconfidence even for uncertain or irrelevant inputs. Intuitively, FR algorithms\ncan benefit from both the estimation of uncertainty and the detection of\nout-of-distribution (OOD) samples. Taking a probabilistic view of the current\nclassification model, the temperature scalar is exactly the scale of\nuncertainty noise implicitly added in the softmax function. Meanwhile, the\nuncertainty of images in a dataset should follow a prior distribution. Based on\nthe observation, a unified framework for uncertainty modeling and FR, Random\nTemperature Scaling (RTS), is proposed to learn a reliable FR algorithm. The\nbenefits of RTS are two-fold. (1) In the training phase, it can adjust the\nlearning strength of clean and noisy samples for stability and accuracy. (2) In\nthe test phase, it can provide a score of confidence to detect uncertain,\nlow-quality and even OOD samples, without training on extra labels. Extensive\nexperiments on FR benchmarks demonstrate that the magnitude of variance in RTS,\nwhich serves as an OOD detection metric, is closely related to the uncertainty\nof the input image. RTS can achieve top performance on both the FR and OOD\ndetection tasks. Moreover, the model trained with RTS can perform robustly on\ndatasets with noise. The proposed module is light-weight and only adds\nnegligible computation cost to the model.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Lei Shang",
      "Mouxiao Huang",
      "Wu Shi",
      "Yuchen Liu",
      "Yang Liu",
      "Fei Wang",
      "Baigui Sun",
      "Xuansong Xie",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01015"
  },
  {
    "id": "arXiv:2212.01016",
    "title": "Accelerating Inverse Learning via Intelligent Localization with  Exploratory Sampling",
    "abstract": "In the scope of \"AI for Science\", solving inverse problems is a longstanding\nchallenge in materials and drug discovery, where the goal is to determine the\nhidden structures given a set of desirable properties. Deep generative models\nare recently proposed to solve inverse problems, but these currently use\nexpensive forward operators and struggle in precisely localizing the exact\nsolutions and fully exploring the parameter spaces without missing solutions.\nIn this work, we propose a novel approach (called iPage) to accelerate the\ninverse learning process by leveraging probabilistic inference from deep\ninvertible models and deterministic optimization via fast gradient descent.\nGiven a target property, the learned invertible model provides a posterior over\nthe parameter space; we identify these posterior samples as an intelligent\nprior initialization which enables us to narrow down the search space. We then\nperform gradient descent to calibrate the inverse solutions within a local\nregion. Meanwhile, a space-filling sampling is imposed on the latent space to\nbetter explore and capture all possible solutions. We evaluate our approach on\nthree benchmark tasks and two created datasets with real-world applications\nfrom quantum chemistry and additive manufacturing, and find our method achieves\nsuperior performance compared to several state-of-the-art baseline methods. The\niPage code is available at https://github.com/jxzhangjhu/MatDesINNe.",
    "descriptor": "\nComments: This paper is accepted for publication in the 37th AAAI Conference on Artificial Intelligence (AAAI 2023)\n",
    "authors": [
      "Jiaxin Zhang",
      "Sirui Bi",
      "Victor Fung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01016"
  },
  {
    "id": "arXiv:2212.01020",
    "title": "Programming Is Hard -- Or at Least It Used to Be: Educational  Opportunities And Challenges of AI Code Generation",
    "abstract": "The introductory programming sequence has been the focus of much research in\ncomputing education. The recent advent of several viable and freely-available\nAI-driven code generation tools present several immediate opportunities and\nchallenges in this domain. In this position paper we argue that the community\nneeds to act quickly in deciding what possible opportunities can and should be\nleveraged and how, while also working on how to overcome or otherwise mitigate\nthe possible challenges. Assuming that the effectiveness and proliferation of\nthese tools will continue to progress rapidly, without quick, deliberate, and\nconcerted efforts, educators will lose advantage in helping shape what\nopportunities come to be, and what challenges will endure. With this paper we\naim to seed this discussion within the computing education community.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Brett A. Becker",
      "Paul Denny",
      "James Finnie-Ansley",
      "Andrew Luxton-Reilly",
      "James Prather",
      "Eddie Antonio Santos"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.01020"
  },
  {
    "id": "arXiv:2212.01022",
    "title": "STL-Based Synthesis of Feedback Controllers Using Reinforcement Learning",
    "abstract": "Deep Reinforcement Learning (DRL) has the potential to be used for\nsynthesizing feedback controllers (agents) for various complex systems with\nunknown dynamics. These systems are expected to satisfy diverse safety and\nliveness properties best captured using temporal logic. In RL, the reward\nfunction plays a crucial role in specifying the desired behaviour of these\nagents. However, the problem of designing the reward function for an RL agent\nto satisfy complex temporal logic specifications has received limited attention\nin the literature. To address this, we provide a systematic way of generating\nrewards in real-time by using the quantitative semantics of Signal Temporal\nLogic (STL), a widely used temporal logic to specify the behaviour of\ncyber-physical systems. We propose a new quantitative semantics for STL having\nseveral desirable properties, making it suitable for reward generation. We\nevaluate our STL-based reinforcement learning mechanism on several complex\ncontinuous control benchmarks and compare our STL semantics with those\navailable in the literature in terms of their efficacy in synthesizing the\ncontroller agent. Experimental results establish our new semantics to be the\nmost suitable for synthesizing feedback controllers for complex continuous\ndynamical systems through reinforcement learning.",
    "descriptor": "\nComments: Full version of the paper to be published in AAAI 2023\n",
    "authors": [
      "Nikhil Kumar Singh",
      "Indranil Saha"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01022"
  },
  {
    "id": "arXiv:2212.01025",
    "title": "Bin Packing with Partition Matroid can be Approximated within $o(OPT)$  Bins",
    "abstract": "We consider the Bin Packing problem with a partition matroid constraint. The\ninput is a set of items of sizes in $(0,1]$, and a partition matroid over the\nitems. The goal is to pack all items in a minimum number of unit-size bins,\nsuch that each bin forms an independent set in the matroid. The problem is a\ngeneralization of both Group Bin Packing and Bin Packing with Cardinality\nConstraints. Bin Packing with Partition Matroid naturally arises in resource\nallocation to ensure fault tolerance and security, as well as in harvesting\ncomputing capacity. Our main result is a polynomial-time algorithm that packs\nthe items in $OPT + o(OPT)$ bins, where OPT is the minimum number of bins\nrequired for packing the given instance. This matches the best known result for\nthe classic Bin Packing problem up to the function hidden by o(OPT). As special\ncases, our result improves upon the existing APTAS for Group Bin Packing and\ngeneralizes the AFTPAS for Bin Packing with Cardinality Constraints. Our\napproach is based on rounding a solution for a configuration-LP formulation of\nthe problem. The rounding takes a novel point of view of prototypes in which\nitems are interpreted as placeholders for other items and applies fractional\ngrouping to modify a fractional solution (prototype) into one having nice\nintegrality properties.",
    "descriptor": "",
    "authors": [
      "Ilan Doron-Arad",
      "Ariel Kulik",
      "Hadas Shachnai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.01025"
  },
  {
    "id": "arXiv:2212.01026",
    "title": "Spectral Feature Augmentation for Graph Contrastive Learning and Beyond",
    "abstract": "Although augmentations (e.g., perturbation of graph edges, image crops) boost\nthe efficiency of Contrastive Learning (CL), feature level augmentation is\nanother plausible, complementary yet not well researched strategy. Thus, we\npresent a novel spectral feature argumentation for contrastive learning on\ngraphs (and images). To this end, for each data view, we estimate a low-rank\napproximation per feature map and subtract that approximation from the map to\nobtain its complement. This is achieved by the proposed herein incomplete power\niteration, a non-standard power iteration regime which enjoys two valuable\nbyproducts (under mere one or two iterations): (i) it partially balances\nspectrum of the feature map, and (ii) it injects the noise into rebalanced\nsingular values of the feature map (spectral augmentation). For two views, we\nalign these rebalanced feature maps as such an improved alignment step can\nfocus more on less dominant singular values of matrices of both views, whereas\nthe spectral augmentation does not affect the spectral angle alignment\n(singular vectors are not perturbed). We derive the analytical form for: (i)\nthe incomplete power iteration to capture its spectrum-balancing effect, and\n(ii) the variance of singular values augmented implicitly by the noise. We also\nshow that the spectral augmentation improves the generalization bound.\nExperiments on graph/image datasets show that our spectral feature augmentation\noutperforms baselines, and is complementary with other augmentation strategies\nand compatible with various contrastive losses.",
    "descriptor": "\nComments: This paper has been published with the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023)\n",
    "authors": [
      "Yifei Zhang",
      "Hao Zhu",
      "Zixing Song",
      "Piotr Koniusz",
      "Irwin King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01026"
  },
  {
    "id": "arXiv:2212.01030",
    "title": "Interaction in Remote Peddling Using Avatar Robot by People with  Disabilities",
    "abstract": "Telework \"avatar work,\" in which people with disabilities can engage in\nphysical work such as customer service, is being implemented in society. In\norder to enable avatar work in a variety of occupations, we propose a mobile\nsales system using a mobile frozen drink machine and an avatar robot \"OriHime\",\nfocusing on mobile customer service like peddling. The effect of the peddling\nby the system on the customers are examined based on the results of video\nannotation.",
    "descriptor": "\nComments: HAI '22, 3 Pages\n",
    "authors": [
      "Takashi Kanetsuna",
      "Kazuaki Takeuchi",
      "Hiroaki Kato",
      "Taichi Sono",
      "Hirotaka Osawa",
      "Kentaro Yoshifuji",
      "Yoichi Yamazaki"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.01030"
  },
  {
    "id": "arXiv:2212.01031",
    "title": "Fair Graphical Resource Allocation with Matching-Induced Utilities",
    "abstract": "Motivated by real-world applications, we study the fair allocation of\ngraphical resources, where the resources are the vertices in a graph. Upon\nreceiving a set of resources, an agent's utility equals the weight of a maximum\nmatching in the induced subgraph. We care about maximin share (MMS) fairness\nand envy-freeness up to one item (EF1). Regarding MMS fairness, the problem\ndoes not admit a finite approximation ratio for heterogeneous agents. For\nhomogeneous agents, we design constant-approximation polynomial-time\nalgorithms, and also note that significant amount of social welfare is\nsacrificed inevitably in order to ensure (approximate) MMS fairness. We then\nconsider EF1 allocations whose existence is guaranteed. However, the social\nwelfare guarantee of EF1 allocations cannot be better than $1/n$ for the\ngeneral case, where $n$ is the number of agents.Fortunately, for three special\ncases, binary-weight, two-agents and homogeneous-agents, we are able to design\npolynomial-time algorithms that also ensure a constant fractions of the maximum\nsocial welfare.",
    "descriptor": "",
    "authors": [
      "Zheng Chen",
      "Bo Li",
      "Minming Li",
      "Guochuan Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2212.01031"
  },
  {
    "id": "arXiv:2212.01032",
    "title": "General Framework for Self-Supervised Model Priming for  Parameter-Efficient Fine-tuning",
    "abstract": "Parameter-efficient methods (like Prompt or Adapters) for adapting\npre-trained language models to downstream tasks have been popular recently.\nHowever, hindrances still prevent these methods from reaching their full\npotential. For example, two significant challenges are few-shot adaptation and\ncross-task generalization ability. To tackle these issues, we propose a general\nframework to enhance the few-shot adaptation and cross-domain generalization\nability of parameter-efficient methods. In our framework, we prime the\nself-supervised model for parameter-efficient methods to rapidly adapt to\nvarious downstream few-shot tasks. To evaluate the authentic generalization\nability of these parameter-efficient methods, we conduct experiments on a\nfew-shot cross-domain benchmark containing 160 diverse NLP tasks. The\nexperiment result reveals that priming by tuning PLM only with extra training\ntasks leads to the best performance. Also, we perform a comprehensive analysis\nof various parameter-efficient methods under few-shot cross-domain scenarios.",
    "descriptor": "",
    "authors": [
      "Shih-Cheng Huang",
      "Shih-Heng Wang",
      "Min-Han Shih",
      "Saurav Sahay",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01032"
  },
  {
    "id": "arXiv:2212.01033",
    "title": "Sonus Texere! Automated Dense Soundtrack Construction for Books using  Movie Adaptations",
    "abstract": "Reading, much like music listening, is an immersive experience that\ntransports readers while taking them on an emotional journey. Listening to\ncomplementary music has the potential to amplify the reading experience,\nespecially when the music is stylistically cohesive and emotionally relevant.\nIn this paper, we propose the first fully automatic method to build a dense\nsoundtrack for books, which can play high-quality instrumental music for the\nentirety of the reading duration. Our work employs a unique text processing and\nmusic weaving pipeline that determines the context and emotional composition of\nscenes in a chapter. This allows our method to identify and play relevant\nexcerpts from the soundtrack of the book's movie adaptation. By relying on the\nmovie composer's craftsmanship, our book soundtracks include expert-made motifs\nand other scene-specific musical characteristics. We validate the design\ndecisions of our approach through a perceptual study. Our readers note that the\nbook soundtrack greatly enhanced their reading experience, due to high\nimmersiveness granted via uninterrupted and style-consistent music, and a\nheightened emotional state attained via high precision emotion and scene\ncontext recognition.",
    "descriptor": "\nComments: Accepted to ISMIR 2022. Project page: this https URL\n",
    "authors": [
      "Jaidev Shriram",
      "Makarand Tapaswi",
      "Vinoo Alluri"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.01033"
  },
  {
    "id": "arXiv:2212.01039",
    "title": "SoftCorrect: Error Correction with Soft Detection for Automatic Speech  Recognition",
    "abstract": "Error correction in automatic speech recognition (ASR) aims to correct those\nincorrect words in sentences generated by ASR models. Since recent ASR models\nusually have low word error rate (WER), to avoid affecting originally correct\ntokens, error correction models should only modify incorrect words, and\ntherefore detecting incorrect words is important for error correction. Previous\nworks on error correction either implicitly detect error words through\ntarget-source attention or CTC (connectionist temporal classification) loss, or\nexplicitly locate specific deletion/substitution/insertion errors. However,\nimplicit error detection does not provide clear signal about which tokens are\nincorrect and explicit error detection suffers from low detection accuracy. In\nthis paper, we propose SoftCorrect with a soft error detection mechanism to\navoid the limitations of both explicit and implicit error detection.\nSpecifically, we first detect whether a token is correct or not through a\nprobability produced by a dedicatedly designed language model, and then design\na constrained CTC loss that only duplicates the detected incorrect tokens to\nlet the decoder focus on the correction of error tokens. Compared with implicit\nerror detection with CTC loss, SoftCorrect provides explicit signal about which\nwords are incorrect and thus does not need to duplicate every token but only\nincorrect tokens; compared with explicit error detection, SoftCorrect does not\ndetect specific deletion/substitution/insertion errors but just leaves it to\nCTC loss. Experiments on AISHELL-1 and Aidatatang datasets show that\nSoftCorrect achieves 26.1% and 9.4% CER reduction respectively, outperforming\nprevious works by a large margin, while still enjoying fast speed of parallel\ngeneration.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Yichong Leng",
      "Xu Tan",
      "Wenjie Liu",
      "Kaitao Song",
      "Rui Wang",
      "Xiang-Yang Li",
      "Tao Qin",
      "Edward Lin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.01039"
  },
  {
    "id": "arXiv:2212.01040",
    "title": "Role of Audio in Audio-Visual Video Summarization",
    "abstract": "Video summarization attracts attention for efficient video representation,\nretrieval, and browsing to ease volume and traffic surge problems. Although\nvideo summarization mostly uses the visual channel for compaction, the benefits\nof audio-visual modeling appeared in recent literature. The information coming\nfrom the audio channel can be a result of audio-visual correlation in the video\ncontent. In this study, we propose a new audio-visual video summarization\nframework integrating four ways of audio-visual information fusion with\nGRU-based and attention-based networks. Furthermore, we investigate a new\nexplainability methodology using audio-visual canonical correlation analysis\n(CCA) to better understand and explain the role of audio in the video\nsummarization task. Experimental evaluations on the TVSum dataset attain F1\nscore and Kendall-tau score improvements for the audio-visual video\nsummarization. Furthermore, splitting video content on TVSum and COGNIMUSE\ndatasets based on audio-visual CCA as positively and negatively correlated\nvideos yields a strong performance improvement over the positively correlated\nvideos for audio-only and audio-visual video summarization.",
    "descriptor": "",
    "authors": [
      "Ibrahim Shoer",
      "Berkay Kopru",
      "Engin Erzin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.01040"
  },
  {
    "id": "arXiv:2212.01042",
    "title": "AccEar: Accelerometer Acoustic Eavesdropping with Unconstrained  Vocabulary",
    "abstract": "With the increasing popularity of voice-based applications, acoustic\neavesdropping has become a serious threat to users' privacy. While on\nsmartphones the access to microphones needs an explicit user permission,\nacoustic eavesdropping attacks can rely on motion sensors (such as\naccelerometer and gyroscope), which access is unrestricted. However, previous\ninstances of such attacks can only recognize a limited set of pre-trained words\nor phrases. In this paper, we present AccEar, an accelerometerbased acoustic\neavesdropping attack that can reconstruct any audio played on the smartphone's\nloudspeaker with unconstrained vocabulary. We show that an attacker can employ\na conditional Generative Adversarial Network (cGAN) to reconstruct highfidelity\naudio from low-frequency accelerometer signals. The presented cGAN model learns\nto recreate high-frequency components of the user's voice from low-frequency\naccelerometer signals through spectrogram enhancement. We assess the\nfeasibility and effectiveness of AccEar attack in a thorough set of experiments\nusing audio from 16 public personalities. As shown by the results in both\nobjective and subjective evaluations, AccEar successfully reconstructs user\nspeeches from accelerometer signals in different scenarios including varying\nsampling rate, audio volume, device model, etc.",
    "descriptor": "\nComments: 2022 IEEE Symposium on Security and Privacy (SP)\n",
    "authors": [
      "Pengfei Hu",
      "Hui Zhuang",
      "Panneer Selvam Santhalingamy",
      "Riccardo Spolaor",
      "Parth Pathaky",
      "Guoming Zhang",
      "Xiuzhen Cheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.01042"
  },
  {
    "id": "arXiv:2212.01046",
    "title": "Improved Representation Learning Through Tensorized Autoencoders",
    "abstract": "The central question in representation learning is what constitutes a good or\nmeaningful representation. In this work we argue that if we consider data with\ninherent cluster structures, where clusters can be characterized through\ndifferent means and covariances, those data structures should be represented in\nthe embedding as well. While Autoencoders (AE) are widely used in practice for\nunsupervised representation learning, they do not fulfil the above condition on\nthe embedding as they obtain a single representation of the data. To overcome\nthis we propose a meta-algorithm that can be used to extend an arbitrary AE\narchitecture to a tensorized version (TAE) that allows for learning\ncluster-specific embeddings while simultaneously learning the cluster\nassignment. For the linear setting we prove that TAE can recover the principle\ncomponents of the different clusters in contrast to principle component of the\nentire data recovered by a standard AE. We validated this on planted models and\nfor general, non-linear and convolutional AEs we empirically illustrate that\ntensorizing the AE is beneficial in clustering and de-noising tasks.",
    "descriptor": "",
    "authors": [
      "Pascal Mattia Esser",
      "Satyaki Mukherjee",
      "Mahalakshmi Sabanayagam",
      "Debarghya Ghoshdastidar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01046"
  },
  {
    "id": "arXiv:2212.01049",
    "title": "On the Energy and Communication Efficiency Tradeoffs in Federated and  Multi-Task Learning",
    "abstract": "Recent advances in Federated Learning (FL) have paved the way towards the\ndesign of novel strategies for solving multiple learning tasks simultaneously,\nby leveraging cooperation among networked devices. Multi-Task Learning (MTL)\nexploits relevant commonalities across tasks to improve efficiency compared\nwith traditional transfer learning approaches. By learning multiple tasks\njointly, significant reduction in terms of energy footprints can be obtained.\nThis article provides a first look into the energy costs of MTL processes\ndriven by the Model-Agnostic Meta-Learning (MAML) paradigm and implemented in\ndistributed wireless networks. The paper targets a clustered multi-task network\nsetup where autonomous agents learn different but related tasks. The MTL\nprocess is carried out in two stages: the optimization of a meta-model that can\nbe quickly adapted to learn new tasks, and a task-specific model adaptation\nstage where the learned meta-model is transferred to agents and tailored for a\nspecific task. This work analyzes the main factors that influence the MTL\nenergy balance by considering a multi-task Reinforcement Learning (RL) setup in\na robotized environment. Results show that the MAML method can reduce the\nenergy bill by at least 2 times compared with traditional approaches without\ninductive transfer. Moreover, it is shown that the optimal energy balance in\nwireless networks depends on uplink/downlink and sidelink communication\nefficiencies.",
    "descriptor": "\nComments: Proceedings of IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC), 2022\n",
    "authors": [
      "Stefano Savazzi",
      "Vittorio Rampa",
      "Sanaz Kianoush",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.01049"
  },
  {
    "id": "arXiv:2212.01051",
    "title": "VeriX: Towards Verified Explainability of Deep Neural Networks",
    "abstract": "We present VeriX, a first step towards verified explainability of machine\nlearning models in safety-critical applications. Specifically, our sound and\noptimal explanations can guarantee prediction invariance against bounded\nperturbations. We utilise constraint solving techniques together with feature\nsensitivity ranking to efficiently compute these explanations. We evaluate our\napproach on image recognition benchmarks and a real-world scenario of\nautonomous aircraft taxiing.",
    "descriptor": "\nComments: To appear in Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023)\n",
    "authors": [
      "Min Wu",
      "Haoze Wu",
      "Clark Barrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01051"
  },
  {
    "id": "arXiv:2212.01052",
    "title": "Covertly Controlling a Linear System",
    "abstract": "Consider the problem of covertly controlling a linear system. In this\nproblem, Alice desires to control (stabilize or change the behavior of) a\nlinear system, while keeping an observer, Willie, unable to decide if the\nsystem is indeed being controlled or not.\nWe formally define the problem, under a model where Willie can only observe\nthe system's output. Focusing on AR(1) systems, we show that when Willie\nobserves the system's output through a clean channel, an inherently unstable\nlinear system can not be covertly stabilized. However, an inherently stable\nlinear system can be covertly controlled, in the sense of covertly changing its\nparameter or resetting its memory. Moreover, we give positive and negative\nresults for two important controllers: a minimal-information controller, where\nAlice is allowed to use only $1$ bit per sample, and a maximal-information\ncontroller, where Alice is allowed to view the real-valued output. Unlike\ncovert communication, where the trade-off is between rate and covertness, the\nresults reveal an interesting \\emph{three--fold} trade--off in covert control:\nthe amount of information used by the controller, control performance and\ncovertness.",
    "descriptor": "\nComments: Parts of this work will be presented at the IEEE Information Theory workshop, ITW 2022. arXiv admin note: substantial text overlap with arXiv:2202.02853\n",
    "authors": [
      "Barak Amihood",
      "Asaf Cohen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.01052"
  },
  {
    "id": "arXiv:2212.01054",
    "title": "Model and Data Agreement for Learning with Noisy Labels",
    "abstract": "Learning with noisy labels is a vital topic for practical deep learning as\nmodels should be robust to noisy open-world datasets in the wild. The\nstate-of-the-art noisy label learning approach JoCoR fails when faced with a\nlarge ratio of noisy labels. Moreover, selecting small-loss samples can also\ncause error accumulation as once the noisy samples are mistakenly selected as\nsmall-loss samples, they are more likely to be selected again. In this paper,\nwe try to deal with error accumulation in noisy label learning from both model\nand data perspectives. We introduce mean point ensemble to utilize a more\nrobust loss function and more information from unselected samples to reduce\nerror accumulation from the model perspective. Furthermore, as the flip images\nhave the same semantic meaning as the original images, we select small-loss\nsamples according to the loss values of flip images instead of the original\nones to reduce error accumulation from the data perspective. Extensive\nexperiments on CIFAR-10, CIFAR-100, and large-scale Clothing1M show that our\nmethod outperforms state-of-the-art noisy label learning methods with different\nlevels of label noise. Our method can also be seamlessly combined with other\nnoisy label learning methods to further improve their performance and\ngeneralize well to other tasks. The code is available in\nhttps://github.com/zyh-uaiaaaa/MDA-noisy-label-learning.",
    "descriptor": "\nComments: Accepted by AAAI2023 Workshop\n",
    "authors": [
      "Yuhang Zhang",
      "Weihong Deng",
      "Xingchen Cui",
      "Yunfeng Yin",
      "Hongzhi Shi",
      "Dongchao Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01054"
  },
  {
    "id": "arXiv:2212.01055",
    "title": "Transformer-Based Learned Optimization",
    "abstract": "In this paper, we propose a new approach to learned optimization. As common\nin the literature, we represent the computation of the update step of the\noptimizer with a neural network. The parameters of the optimizer are then\nlearned on a set of training optimization tasks, in order to perform\nminimisation efficiently. Our main innovation is to propose a new neural\nnetwork architecture for the learned optimizer inspired by the classic BFGS\nalgorithm. As in BFGS, we estimate a preconditioning matrix as a sum of\nrank-one updates but use a transformer-based neural network to predict these\nupdates jointly with the step length and direction. In contrast to several\nrecent learned optimization approaches, our formulation allows for conditioning\nacross different dimensions of the parameter space of the target problem while\nremaining applicable to optimization tasks of variable dimensionality without\nretraining. We demonstrate the advantages of our approach on a benchmark\ncomposed of objective functions traditionally used for evaluation of\noptimization algorithms, as well as on the real world-task of physics-based\nreconstruction of articulated 3D human motion.",
    "descriptor": "",
    "authors": [
      "Erik G\u00e4rtner",
      "Luke Metz",
      "Mykhaylo Andriluka",
      "C. Daniel Freeman",
      "Cristian Sminchisescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01055"
  },
  {
    "id": "arXiv:2212.01057",
    "title": "Global Learnable Attention for Single Image Super-Resolution",
    "abstract": "Self-similarity is valuable to the exploration of non-local textures in\nsingle image super-resolution (SISR). Researchers usually assume that the\nimportance of non-local textures is positively related to their similarity\nscores. In this paper, we surprisingly found that when repairing severely\ndamaged query textures, some non-local textures with low-similarity which are\ncloser to the target can provide more accurate and richer details than the\nhigh-similarity ones. In these cases, low-similarity does not mean inferior but\nis usually caused by different scales or orientations. Utilizing this finding,\nwe proposed a Global Learnable Attention (GLA) to adaptively modify similarity\nscores of non-local textures during training instead of only using a fixed\nsimilarity scoring function such as the dot product. The proposed GLA can\nexplore non-local textures with low-similarity but more accurate details to\nrepair severely damaged textures. Furthermore, we propose to adopt Super-Bit\nLocality-Sensitive Hashing (SB-LSH) as a preprocessing method for our GLA. With\nthe SB-LSH, the computational complexity of our GLA is reduced from quadratic\nto asymptotic linear with respect to the image size. In addition, the proposed\nGLA can be integrated into existing deep SISR models as an efficient general\nbuilding block. Based on the GLA, we constructed a Deep Learnable Similarity\nNetwork (DLSN), which achieves state-of-the-art performance for SISR tasks of\ndifferent degradation types (e.g. blur and noise). Our code and a pre-trained\nDLSN have been uploaded to GitHub{\\dag} for validation.",
    "descriptor": "\nComments: 16 pages, 16 figures\n",
    "authors": [
      "Jian-Nan Su",
      "Min Gan",
      "Guang-Yong Chen",
      "Jia-Li Yin",
      "C. L. Philip Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01057"
  },
  {
    "id": "arXiv:2212.01060",
    "title": "Exploring Faithful Rationale for Multi-hop Fact Verification via  Salience-Aware Graph Learning",
    "abstract": "The opaqueness of the multi-hop fact verification model imposes imperative\nrequirements for explainability. One feasible way is to extract rationales, a\nsubset of inputs, where the performance of prediction drops dramatically when\nbeing removed. Though being explainable, most rationale extraction methods for\nmulti-hop fact verification explore the semantic information within each piece\nof evidence individually, while ignoring the topological information\ninteraction among different pieces of evidence. Intuitively, a faithful\nrationale bears complementary information being able to extract other\nrationales through the multi-hop reasoning process. To tackle such\ndisadvantages, we cast explainable multi-hop fact verification as subgraph\nextraction, which can be solved based on graph convolutional network (GCN) with\nsalience-aware graph learning. In specific, GCN is utilized to incorporate the\ntopological interaction information among multiple pieces of evidence for\nlearning evidence representation. Meanwhile, to alleviate the influence of\nnoisy evidence, the salience-aware graph perturbation is induced into the\nmessage passing of GCN. Moreover, the multi-task model with three diagnostic\nproperties of rationale is elaborately designed to improve the quality of an\nexplanation without any explicit annotations. Experimental results on the\nFEVEROUS benchmark show significant gains over previous state-of-the-art\nmethods for both rationale extraction and fact verification.",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Jiasheng Si",
      "Yingjie Zhu",
      "Deyu Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01060"
  },
  {
    "id": "arXiv:2212.01071",
    "title": "Fake detection in imbalance dataset by Semi-supervised learning with GAN",
    "abstract": "As social media grows faster, harassment becomes more prevalent which leads\nto considered fake detection a fascinating field among researchers. The graph\nnature of data with the large number of nodes caused different obstacles\nincluding a considerable amount of unrelated features in matrices as high\ndispersion and imbalance classes in the dataset. To deal with these issues\nAuto-encoders and a combination of semi-supervised learning and the GAN\nalgorithm which is called SGAN were used. This paper is deploying a smaller\nnumber of labels and applying SGAN as a classifier. The result of this test\nshowed that the accuracy had reached 91\\% in detecting fake accounts using only\n100 labeled samples.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2210.15657\n",
    "authors": [
      "Jinus Bordbar",
      "Saman Ardalan",
      "Mohammadreza Mohammadrezaie",
      "Mohammad Ebrahim Shiri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.01071"
  },
  {
    "id": "arXiv:2212.01076",
    "title": "Are Straight-Through gradients and Soft-Thresholding all you need for  Sparse Training?",
    "abstract": "Turning the weights to zero when training a neural network helps in reducing\nthe computational complexity at inference. To progressively increase the\nsparsity ratio in the network without causing sharp weight discontinuities\nduring training, our work combines soft-thresholding and straight-through\ngradient estimation to update the raw, i.e. non-thresholded, version of zeroed\nweights. Our method, named ST-3 for\nstraight-through/soft-thresholding/sparse-training, obtains SoA results, both\nin terms of accuracy/sparsity and accuracy/FLOPS trade-offs, when progressively\nincreasing the sparsity ratio in a single training cycle. In particular,\ndespite its simplicity, ST-3 favorably compares to the most recent methods,\nadopting differentiable formulations or bio-inspired neuroregeneration\nprinciples. This suggests that the key ingredients for effective sparsification\nprimarily lie in the ability to give the weights the freedom to evolve smoothly\nacross the zero state while progressively increasing the sparsity ratio. Source\ncode and weights available at https://github.com/vanderschuea/stthree",
    "descriptor": "",
    "authors": [
      "Antoine Vanderschueren",
      "Christophe De Vleeschouwer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01076"
  },
  {
    "id": "arXiv:2212.01080",
    "title": "Some restrictions on the weight enumerators of near-extremal ternary  self-dual codes and quaternary Hermitian self-dual codes",
    "abstract": "We give restrictions on the weight enumerators of ternary near-extremal\nself-dual codes of length divisible by $12$ and quaternary near-extremal\nHermitian self-dual codes of length divisible by $6$. We consider the weight\nenumerators for which there is a ternary near-extremal self-dual code of length\n$12m$ for $m =3,4,5,6$. Also we consider the weight enumerators for which there\nis a quaternary near-extremal Hermitian self-dual code of length $6m$ for $m\n=4,5,6$.",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Makoto Araya",
      "Masaaki Harada"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2212.01080"
  },
  {
    "id": "arXiv:2212.01082",
    "title": "Membership Inference Attacks Against Semantic Segmentation Models",
    "abstract": "Membership inference attacks aim to infer whether a data record has been used\nto train a target model by observing its predictions. In sensitive domains such\nas healthcare, this can constitute a severe privacy violation. In this work we\nattempt to address the existing knowledge gap by conducting an exhaustive study\nof membership inference attacks and defences in the domain of semantic image\nsegmentation. Our findings indicate that for certain threat models, these\nlearning settings can be considerably more vulnerable than the previously\nconsidered classification settings. We additionally investigate a threat model\nwhere a dishonest adversary can perform model poisoning to aid their inference\nand evaluate the effects that these adaptations have on the success of\nmembership inference attacks. We quantitatively evaluate the attacks on a\nnumber of popular model architectures across a variety of semantic segmentation\ntasks, demonstrating that membership inference attacks in this domain can\nachieve a high success rate and defending against them may result in\nunfavourable privacy-utility trade-offs or increased computational costs.",
    "descriptor": "\nComments: Submitted as conference paper to PETS 2023\n",
    "authors": [
      "Tomas Chobola",
      "Dmitrii Usynin",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.01082"
  },
  {
    "id": "arXiv:2212.01083",
    "title": "Cross-Modal Mutual Learning for Cued Speech Recognition",
    "abstract": "Automatic Cued Speech Recognition (ACSR) provides an intelligent\nhuman-machine interface for visual communications, where the Cued Speech (CS)\nsystem utilizes lip movements and hand gestures to code spoken language for\nhearing-impaired people. Previous ACSR approaches often utilize direct feature\nconcatenation as the main fusion paradigm. However, the asynchronous modalities\n(\\textit{i.e.}, lip, hand shape and hand position) in CS may cause interference\nfor feature concatenation. To address this challenge, we propose a transformer\nbased cross-modal mutual learning framework to prompt multi-modal interaction.\nCompared with the vanilla self-attention, our model forces modality-specific\ninformation of different modalities to pass through a modality-invariant\ncodebook, collating linguistic representations for tokens of each modality.\nThen the shared linguistic knowledge is used to re-synchronize multi-modal\nsequences. Moreover, we establish a novel large-scale multi-speaker CS dataset\nfor Mandarin Chinese. To our knowledge, this is the first work on ACSR for\nMandarin Chinese. Extensive experiments are conducted for different languages\n(\\textit{i.e.}, Chinese, French, and British English). Results demonstrate that\nour model exhibits superior recognition performance to the state-of-the-art by\na large margin.",
    "descriptor": "",
    "authors": [
      "Lei Liu",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.01083"
  },
  {
    "id": "arXiv:2212.01091",
    "title": "Sequential parametrized motion planning and its complexity, II",
    "abstract": "This is a continuation of our recent paper in which we developed the theory\nof sequential parametrized motion planning. A sequential parametrized motion\nplanning algorithm produced a motion of the system which is required to visit a\nprescribed sequence of states, in a certain order, at specified moments of\ntime. In the previous publication we analysed the sequential parametrized\ntopological complexity of the Fadell - Neuwirth fibration which in relevant to\nthe problem of moving multiple robots avoiding collisions with other robots and\nwith obstacles in the Euclidean space. Besides, in the preceeding paper we\nfound the sequential parametrised topological complexity of the Fadell -\nNeuwirth bundle for the case of the Euclidean space $\\Bbb R^d$ of odd dimension\nas well as the case $d=2$. In the present paper we give the complete answer for\nan arbitrary $d\\ge 2$ even. Moreover, we present an explicit motion planning\nalgorithm for controlling multiple robots in $\\Bbb R^d$ having the minimal\npossible topological complexity; this algorithm is applicable to any number $n$\nof robots and any number $m\\ge 2$ of obstacles.",
    "descriptor": "",
    "authors": [
      "Michael Farber",
      "Amit Kumar Paul"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2212.01091"
  },
  {
    "id": "arXiv:2212.01094",
    "title": "Semantic Role Labeling Meets Definition Modeling: Using Natural Language  to Describe Predicate-Argument Structures",
    "abstract": "One of the common traits of past and present approaches for Semantic Role\nLabeling (SRL) is that they rely upon discrete labels drawn from a predefined\nlinguistic inventory to classify predicate senses and their arguments. However,\nwe argue this need not be the case. In this paper, we present an approach that\nleverages Definition Modeling to introduce a generalized formulation of SRL as\nthe task of describing predicate-argument structures using natural language\ndefinitions instead of discrete labels. Our novel formulation takes a first\nstep towards placing interpretability and flexibility foremost, and yet our\nexperiments and analyses on PropBank-style and FrameNet-style, dependency-based\nand span-based SRL also demonstrate that a flexible model with an interpretable\noutput does not necessarily come at the expense of performance. We release our\nsoftware for research purposes at https://github.com/SapienzaNLP/dsrl.",
    "descriptor": "",
    "authors": [
      "Simone Conia",
      "Edoardo Barba",
      "Alessandro Scir\u00e8",
      "Roberto Navigli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01094"
  },
  {
    "id": "arXiv:2212.01096",
    "title": "Cross-Domain Graph Anomaly Detection via Anomaly-aware Contrastive  Alignment",
    "abstract": "Cross-domain graph anomaly detection (CD-GAD) describes the problem of\ndetecting anomalous nodes in an unlabelled target graph using auxiliary,\nrelated source graphs with labelled anomalous and normal nodes. Although it\npresents a promising approach to address the notoriously high false positive\nissue in anomaly detection, little work has been done in this line of research.\nThere are numerous domain adaptation methods in the literature, but it is\ndifficult to adapt them for GAD due to the unknown distributions of the\nanomalies and the complex node relations embedded in graph data. To this end,\nwe introduce a novel domain adaptation approach, namely Anomaly-aware\nContrastive alignmenT (ACT), for GAD. ACT is designed to jointly optimise: (i)\nunsupervised contrastive learning of normal representations of nodes in the\ntarget graph, and (ii) anomaly-aware one-class alignment that aligns these\ncontrastive node representations and the representations of labelled normal\nnodes in the source graph, while enforcing significant deviation of the\nrepresentations of the normal nodes from the labelled anomalous nodes in the\nsource graph. In doing so, ACT effectively transfers anomaly-informed knowledge\nfrom the source graph to learn the complex node relations of the normal class\nfor GAD on the target graph without any specification of the anomaly\ndistributions. Extensive experiments on eight CD-GAD settings demonstrate that\nour approach ACT achieves substantially improved detection performance over 10\nstate-of-the-art GAD methods. Code is available at\nhttps://github.com/QZ-WANG/ACT.",
    "descriptor": "\nComments: AAAI2023, to appear\n",
    "authors": [
      "Qizhou Wang",
      "Guansong Pang",
      "Mahsa Salehi",
      "Wray Buntine",
      "Christopher Leckie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.01096"
  },
  {
    "id": "arXiv:2212.01097",
    "title": "Simultaneous Transmitting and Reflecting-Reconfigurable Intelligent  Surface in 6G: Design Guidelines and Future Perspectives",
    "abstract": "Reconfigurable intelligent surfaces (RISs) have been considered as a\npromising technology for the sixth-generation (6G) wireless networks that can\ncontrol wireless channels in a desirable way and significantly enhance the\nnetwork performance. Simultaneous transmitting and reflecting-RISs (STAR-RISs)\ncan overcome limitation of reflecting-only RISs by leveraging the higher design\nflexibility and full-space coverage. Despite the benefits, the modeling and\nanalysis of STAR-RISs are complicated because of various control parameters for\nboth transmission and reflection links. In this article, a general framework to\nfacilitate the design and implementation of STAR-RISs in 6G scenarios and\nnetwork topologies is presented. We provide a systematic introduction to the\nSTAR-RIS operating protocols for different communication modes and discuss\nrecent efforts to identify the research progress and combination solutions.\nFinally, we provide the design concepts, research challenges, potential\nsolutions, and future directions related to the channel modeling, channel\nestimation, hardware implementations, modeling and limitations, and\noptimization.",
    "descriptor": "\nComments: Accepted for IEEE Network\n",
    "authors": [
      "Waqas Khalid",
      "Zeeshan Kaleem",
      "Rehmat Ullah",
      "Trinh Van Chien",
      "Song Noh",
      "Heejung Yu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Emerging Technologies (cs.ET)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.01097"
  },
  {
    "id": "arXiv:2212.01098",
    "title": "RGB-D based Stair Detection using Deep Learning for Autonomous Stair  Climbing",
    "abstract": "Stairs are common building structures in urban environment, and stair\ndetection is an important part of environment perception for autonomous mobile\nrobots. Most existing algorithms have difficulty combining the visual\ninformation from binocular sensors effectively and ensuring reliable detection\nat night and in the case of extremely fuzzy visual clues. To solve these\nproblems, we propose a neural network architecture with inputs of both RGB map\nand depth map. Specifically, we design the selective module which can make the\nnetwork learn the complementary relationship between RGB map and depth map and\neffectively combine the information from RGB map and depth map in different\nscenes. In addition, we also design a line clustering algorithm for the\npost-processing of detection results, which can make full use of the detection\nresults to obtain the geometric parameters of stairs. Experiments on our\ndataset show that our method can achieve better accuracy and recall compared\nwith the previous state-of-the-art deep learning method, which are 5.64% and\n7.97%, respectively. Our method also has extremely fast detection speed, and a\nlightweight version can achieve 300 + frames per second with the same\nresolution, which can meet the needs of most real-time detection scenes.",
    "descriptor": "",
    "authors": [
      "Chen Wang",
      "Zhongcai Pei",
      "Shuang Qiu",
      "Zhiyong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.01098"
  },
  {
    "id": "arXiv:2212.01099",
    "title": "Linear Data-Driven Economic MPC with Generalized Terminal Constraint",
    "abstract": "In this paper, we propose a data-driven economic model predictive control\n(EMPC) scheme with generalized terminal constraint to control an unknown linear\ntime-invariant system. Our scheme is based on the Fundamental Lemma to predict\nfuture system trajectories using a persistently exciting input-output\ntrajectory. The control objective is to minimize an economic cost objective. By\nemploying a generalized terminal constraint with artificial equilibrium, the\nscheme does not require prior knowledge of the optimal equilibrium. We prove\nthat the asymptotic average performance of the closed-loop system can be made\narbitrarily close to that of the optimal equilibrium. Moreover, we extend our\nresults to the case of an unknown linear stage cost function, where the\nFundamental lemma is used to predict the stage cost directly. The effectiveness\nof the proposed scheme is shown by a numerical example.",
    "descriptor": "",
    "authors": [
      "Yifan Xie",
      "Julian Berberich amd Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.01099"
  },
  {
    "id": "arXiv:2212.01101",
    "title": "Assessing Anonymized System Logs Usefulness for Behavioral Analysis in  RNN Models",
    "abstract": "System logs are a common source of monitoring data for analyzing computing\nsystems' behavior. Due to the complexity of modern computing systems and the\nlarge size of collected monitoring data, automated analysis mechanisms are\nrequired. Numerous machine learning and deep learning methods are proposed to\naddress this challenge. However, due to the existence of sensitive data in\nsystem logs their analysis and storage raise serious privacy concerns.\nAnonymization methods could be used to clean the monitoring data before\nanalysis. However, anonymized system logs, in general, do not provide adequate\nusefulness for the majority of behavioral analysis. Content-aware anonymization\nmechanisms such as PaRS preserve the correlation of system logs even after\nanonymization. This work evaluates the usefulness of anonymized system logs\ntaken from the Taurus HPC cluster anonymized using PaRS, for behavioral\nanalysis via recurrent neural network models.",
    "descriptor": "\nComments: 12 pages, 7 main figures, 2 tables, Conference: International Workshop on Data-driven Resilience Research 2022\n",
    "authors": [
      "Tom Richard Vargis",
      "Siavash Ghiasvand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.01101"
  },
  {
    "id": "arXiv:2212.01103",
    "title": "3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation",
    "abstract": "Text-guided 3D object generation aims to generate 3D objects described by\nuser-defined captions, which paves a flexible way to visualize what we\nimagined. Although some works have been devoted to solving this challenging\ntask, these works either utilize some explicit 3D representations (e.g., mesh),\nwhich lack texture and require post-processing for rendering photo-realistic\nviews; or require individual time-consuming optimization for every single case.\nHere, we make the first attempt to achieve generic text-guided cross-category\n3D object generation via a new 3D-TOGO model, which integrates a text-to-views\ngeneration module and a views-to-3D generation module. The text-to-views\ngeneration module is designed to generate different views of the target 3D\nobject given an input caption. prior-guidance, caption-guidance and view\ncontrastive learning are proposed for achieving better view-consistency and\ncaption similarity. Meanwhile, a pixelNeRF model is adopted for the views-to-3D\ngeneration module to obtain the implicit 3D neural representation from the\npreviously-generated views. Our 3D-TOGO model generates 3D objects in the form\nof the neural radiance field with good texture and requires no time-cost\noptimization for every single caption. Besides, 3D-TOGO can control the\ncategory, color and shape of generated 3D objects with the input caption.\nExtensive experiments on the largest 3D object dataset (i.e., ABO) are\nconducted to verify that 3D-TOGO can better generate high-quality 3D objects\naccording to the input captions across 98 different categories, in terms of\nPSNR, SSIM, LPIPS and CLIP-score, compared with text-NeRF and Dreamfields.",
    "descriptor": "",
    "authors": [
      "Zutao Jiang",
      "Guangsong Lu",
      "Xiaodan Liang",
      "Jihua Zhu",
      "Wei Zhang",
      "Xiaojun Chang",
      "Hang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01103"
  },
  {
    "id": "arXiv:2212.01105",
    "title": "Flow to Control: Offline Reinforcement Learning with Lossless Primitive  Discovery",
    "abstract": "Offline reinforcement learning (RL) enables the agent to effectively learn\nfrom logged data, which significantly extends the applicability of RL\nalgorithms in real-world scenarios where exploration can be expensive or\nunsafe. Previous works have shown that extracting primitive skills from the\nrecurring and temporally extended structures in the logged data yields better\nlearning. However, these methods suffer greatly when the primitives have\nlimited representation ability to recover the original policy space, especially\nin offline settings. In this paper, we give a quantitative characterization of\nthe performance of offline hierarchical learning and highlight the importance\nof learning lossless primitives. To this end, we propose to use a\n\\emph{flow}-based structure as the representation for low-level policies. This\nallows us to represent the behaviors in the dataset faithfully while keeping\nthe expression ability to recover the whole policy space. We show that such\nlossless primitives can drastically improve the performance of hierarchical\npolicies. The experimental results and extensive ablation studies on the\nstandard D4RL benchmark show that our method has a good representation ability\nfor policies and achieves superior performance in most tasks.",
    "descriptor": "\nComments: 13pages\n",
    "authors": [
      "Yiqin Yang",
      "Hao Hu",
      "Wenzhe Li",
      "Siyuan Li",
      "Jun Yang",
      "Qianchuan Zhao",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01105"
  },
  {
    "id": "arXiv:2212.01109",
    "title": "Generative Data Augmentation for Non-IID Problem in Decentralized  Clinical Machine Learning",
    "abstract": "Swarm learning (SL) is an emerging promising decentralized machine learning\nparadigm and has achieved high performance in clinical applications. SL solves\nthe problem of a central structure in federated learning by combining edge\ncomputing and blockchain-based peer-to-peer network. While there are promising\nresults in the assumption of the independent and identically distributed (IID)\ndata across participants, SL suffers from performance degradation as the degree\nof the non-IID data increases. To address this problem, we propose a generative\naugmentation framework in swarm learning called SL-GAN, which augments the\nnon-IID data by generating the synthetic data from participants. SL-GAN trains\ngenerators and discriminators locally, and periodically aggregation via a\nrandomly elected coordinator in SL network. Under the standard assumptions, we\ntheoretically prove the convergence of SL-GAN using stochastic approximations.\nExperimental results demonstrate that SL-GAN outperforms state-of-art methods\non three real world clinical datasets including Tuberculosis, Leukemia,\nCOVID-19.",
    "descriptor": "",
    "authors": [
      "Zirui Wang",
      "Shaoming Duan",
      "Chengyue Wu",
      "Wenhao Lin",
      "Xinyu Zha",
      "Peiyi Han",
      "Chuanyi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.01109"
  },
  {
    "id": "arXiv:2212.01114",
    "title": "An approach to study recruitment/derecruitment dynamics in a  patient-specific computational model of an injured human lung",
    "abstract": "We present a new approach for physics-based computational modeling of\ndiseased human lungs. Our main object is the development of a model that takes\nthe novel step of incorporating the dynamics of airway\nrecruitment/de-recruitment into an anatomically accurate, spatially resolved\nmodel of respiratory system mechanics, and the relation of these dynamics to\nairway dimensions and the biophysical properties of the lining fluid. The\nimportance of our approach is that it potentially allows for more accurate\npredictions of where mechanical stress foci arise in the lungs, since it is at\nthese locations that injury is thought to arise and propagate from. We match\nthe model to data from a patient with Acute Respiratory Distress Syndrome\n(ARDS) to demonstrate the potential of the model for revealing the underlying\nderangements in ARDS in a patient-specific manner. To achieve this, the\nspecific geometry of the lung and its heterogeneous pattern of injury are\nextracted from medical CT images. The mechanical behavior of the model is\ntailored to the patient's respiratory mechanics using measured ventilation\ndata. In retrospective simulations of various clinically performed,\npressure-driven ventilation profiles, the model adequately reproduces clinical\nquantities measured in the patient such as tidal volume and change in pleural\npressure. The model also exhibits physiologically reasonable lung recruitment\ndynamics and has the spatial resolution to allow the study of local mechanical\nquantities such as alveolar strains. This modeling approach advances our\nability to perform patient-specific studies in silico, opening the way to\npersonalized therapies that will optimize patient outcomes.",
    "descriptor": "",
    "authors": [
      "Carolin M. Geitner",
      "Tobias Becher",
      "In\u00e9z Frerichs",
      "Norbert Weiler",
      "Jason H. T. Bates",
      "Wolfgang A. Wall"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Biological Physics (physics.bio-ph)",
      "Medical Physics (physics.med-ph)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2212.01114"
  },
  {
    "id": "arXiv:2212.01117",
    "title": "Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning",
    "abstract": "The spread of rumors along with breaking events seriously hinders the truth\nin the era of social media. Previous studies reveal that due to the lack of\nannotated resources, rumors presented in minority languages are hard to be\ndetected. Furthermore, the unforeseen breaking events not involved in\nyesterday's news exacerbate the scarcity of data resources. In this work, we\npropose a novel zero-shot framework based on prompt learning to detect rumors\nfalling in different domains or presented in different languages. More\nspecifically, we firstly represent rumor circulated on social media as diverse\npropagation threads, then design a hierarchical prompt encoding mechanism to\nlearn language-agnostic contextual representations for both prompts and rumor\ndata. To further enhance domain adaptation, we model the domain-invariant\nstructural features from the propagation threads, to incorporate structural\nposition representations of influential community response. In addition, a new\nvirtual response augmentation method is used to improve model training.\nExtensive experiments conducted on three real-world datasets demonstrate that\nour proposed model achieves much better performance than state-of-the-art\nmethods and exhibits a superior capacity for detecting rumors at early stages.",
    "descriptor": "\nComments: To appear in AAAI 2023\n",
    "authors": [
      "Hongzhan Lin",
      "Pengyao Yi",
      "Jing Ma",
      "Haiyun Jiang",
      "Ziyang Luo",
      "Shuming Shi",
      "Ruifang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.01117"
  },
  {
    "id": "arXiv:2212.01118",
    "title": "The medial axis of closed bounded sets is Lipschitz stable with respect  to the Hausdorff distance under ambient diffeomorphisms",
    "abstract": "We prove that the medial axis of closed sets is Hausdorff stable in the\nfollowing sense: Let $\\mathcal{S} \\subseteq \\mathbb{R}^d$ be (fixed) closed set\n(that contains a bounding sphere). Consider the space of $C^{1,1}$\ndiffeomorphisms of $\\mathbb{R}^d$ to itself, which keep the bounding sphere\ninvariant. The map from this space of diffeomorphisms (endowed with some Banach\nnorm) to the space of closed subsets of $\\mathbb{R}^d$ (endowed with the\nHausdorff distance), mapping a diffeomorphism $F$ to the closure of the medial\naxis of $F(\\mathcal{S})$, is Lipschitz. This extends a previous stability\nresult of Chazal and Soufflet on the stability of the medial axis of $C^2$\nmanifolds under $C^2$ ambient diffeomorphisms.",
    "descriptor": "",
    "authors": [
      "Hana Dal Poz Kou\u0159imsk\u00e1",
      "Andr\u00e9 Lieutier",
      "Mathijs Wintraecken"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2212.01118"
  },
  {
    "id": "arXiv:2212.01120",
    "title": "RT-NeRF: Real-Time On-Device Neural Radiance Fields Towards Immersive  AR/VR Rendering",
    "abstract": "Neural Radiance Field (NeRF) based rendering has attracted growing attention\nthanks to its state-of-the-art (SOTA) rendering quality and wide applications\nin Augmented and Virtual Reality (AR/VR). However, immersive real-time (> 30\nFPS) NeRF based rendering enabled interactions are still limited due to the low\nachievable throughput on AR/VR devices. To this end, we first profile SOTA\nefficient NeRF algorithms on commercial devices and identify two primary causes\nof the aforementioned inefficiency: (1) the uniform point sampling and (2) the\ndense accesses and computations of the required embeddings in NeRF.\nFurthermore, we propose RT-NeRF, which to the best of our knowledge is the\nfirst algorithm-hardware co-design acceleration of NeRF. Specifically, on the\nalgorithm level, RT-NeRF integrates an efficient rendering pipeline for largely\nalleviating the inefficiency due to the commonly adopted uniform point sampling\nmethod in NeRF by directly computing the geometry of pre-existing points.\nAdditionally, RT-NeRF leverages a coarse-grained view-dependent computing\nordering scheme for eliminating the (unnecessary) processing of invisible\npoints. On the hardware level, our proposed RT-NeRF accelerator (1) adopts a\nhybrid encoding scheme to adaptively switch between a bitmap- or\ncoordinate-based sparsity encoding format for NeRF's sparse embeddings, aiming\nto maximize the storage savings and thus reduce the required DRAM accesses\nwhile supporting efficient NeRF decoding; and (2) integrates both a\ndual-purpose bi-direction adder & search tree and a high-density sparse search\nunit to coordinate the two aforementioned encoding formats. Extensive\nexperiments on eight datasets consistently validate the effectiveness of\nRT-NeRF, achieving a large throughput improvement (e.g., 9.7x - 3,201x) while\nmaintaining the rendering quality as compared with SOTA efficient NeRF\nsolutions.",
    "descriptor": "\nComments: Accepted to ICCAD 2022\n",
    "authors": [
      "Chaojian Li",
      "Sixu Li",
      "Yang Zhao",
      "Wenbo Zhu",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2212.01120"
  },
  {
    "id": "arXiv:2212.01127",
    "title": "Randomized low-rank approximation for symmetric indefinite matrices",
    "abstract": "The Nystr\\\"om method is a popular choice for finding a low-rank approximation\nto a symmetric positive semi-definite matrix. The method can fail when applied\nto symmetric indefinite matrices, for which the error can be unboundedly large.\nIn this work, we first identify the main challenges in finding a Nystr\\\"om\napproximation to symmetric indefinite matrices. We then prove the existence of\na variant that overcomes the instability, and establish relative-error nuclear\nnorm bounds of the resulting approximation that hold when the singular values\ndecay rapidly. The analysis naturally leads to a practical algorithm, whose\nrobustness is illustrated with experiments.",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Taejun Park",
      "Yuji Nakatsukasa"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.01127"
  },
  {
    "id": "arXiv:2212.01128",
    "title": "A Multi-Stream Fusion Network for Image Splicing Localization",
    "abstract": "In this paper, we address the problem of image splicing localization with a\nmulti-stream network architecture that processes the raw RGB image in parallel\nwith other handcrafted forensic signals. Unlike previous methods that either\nuse only the RGB images or stack several signals in a channel-wise manner, we\npropose an encoder-decoder architecture that consists of multiple encoder\nstreams. Each stream is fed with either the tampered image or handcrafted\nsignals and processes them separately to capture relevant information from each\none independently. Finally, the extracted features from the multiple streams\nare fused in the bottleneck of the architecture and propagated to the decoder\nnetwork that generates the output localization map. We experiment with two\nhandcrafted algorithms, i.e., DCT and Splicebuster. Our proposed approach is\nbenchmarked on three public forensics datasets, demonstrating competitive\nperformance against several competing methods and achieving state-of-the-art\nresults, e.g., 0.898 AUC on CASIA.",
    "descriptor": "\nComments: Accepted to the International Conference on MultiMedia Modeling (MMM 2023)\n",
    "authors": [
      "Maria Siopi",
      "Giorgos Kordopatis-Zilos",
      "Polychronis Charitidis",
      "Ioannis Kompatsiaris",
      "Symeon Papadopoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01128"
  },
  {
    "id": "arXiv:2212.01130",
    "title": "Improving Pareto Front Learning via Multi-Sample Hypernetworks",
    "abstract": "Pareto Front Learning (PFL) was recently introduced as an effective approach\nto obtain a mapping function from a given trade-off vector to a solution on the\nPareto front, which solves the multi-objective optimization (MOO) problem. Due\nto the inherent trade-off between conflicting objectives, PFL offers a flexible\napproach in many scenarios in which the decision makers can not specify the\npreference of one Pareto solution over another, and must switch between them\ndepending on the situation. However, existing PFL methods ignore the\nrelationship between the solutions during the optimization process, which\nhinders the quality of the obtained front. To overcome this issue, we propose a\nnovel PFL framework namely \\ourmodel, which employs a hypernetwork to generate\nmultiple solutions from a set of diverse trade-off preferences and enhance the\nquality of the Pareto front by maximizing the Hypervolume indicator defined by\nthese solutions. The experimental results on several MOO machine learning tasks\nshow that the proposed framework significantly outperforms the baselines in\nproducing the trade-off Pareto front.",
    "descriptor": "\nComments: Accepted to AAAI-23\n",
    "authors": [
      "Long Phi Hoang",
      "Dung Duy Le",
      "Tuan Anh Tran",
      "Thang Tran Ngoc"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01130"
  },
  {
    "id": "arXiv:2212.01131",
    "title": "Activating the Discriminability of Novel Classes for Few-shot  Segmentation",
    "abstract": "Despite the remarkable success of existing methods for few-shot segmentation,\nthere remain two crucial challenges. First, the feature learning for novel\nclasses is suppressed during the training on base classes in that the novel\nclasses are always treated as background. Thus, the semantics of novel classes\nare not well learned. Second, most of existing methods fail to consider the\nunderlying semantic gap between the support and the query resulting from the\nrepresentative bias by the scarce support samples. To circumvent these two\nchallenges, we propose to activate the discriminability of novel classes\nexplicitly in both the feature encoding stage and the prediction stage for\nsegmentation. In the feature encoding stage, we design the Semantic-Preserving\nFeature Learning module (SPFL) to first exploit and then retain the latent\nsemantics contained in the whole input image, especially those in the\nbackground that belong to novel classes. In the prediction stage for\nsegmentation, we learn an Self-Refined Online Foreground-Background classifier\n(SROFB), which is able to refine itself using the high-confidence pixels of\nquery image to facilitate its adaptation to the query image and bridge the\nsupport-query semantic gap. Extensive experiments on PASCAL-5$^i$ and\nCOCO-20$^i$ datasets demonstrates the advantages of these two novel designs\nboth quantitatively and qualitatively.",
    "descriptor": "",
    "authors": [
      "Dianwen Mei",
      "Wei Zhuo",
      "Jiandong Tian",
      "Guangming Lu",
      "Wenjie Pei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01131"
  },
  {
    "id": "arXiv:2212.01133",
    "title": "Ripple: Concept-Based Interpretation for Raw Time Series Models in  Education",
    "abstract": "Time series is the most prevalent form of input data for educational\nprediction tasks. The vast majority of research using time series data focuses\non hand-crafted features, designed by experts for predictive performance and\ninterpretability. However, extracting these features is labor-intensive for\nhumans and computers. In this paper, we propose an approach that utilizes\nirregular multivariate time series modeling with graph neural networks to\nachieve comparable or better accuracy with raw time series clickstreams in\ncomparison to hand-crafted features. Furthermore, we extend concept activation\nvectors for interpretability in raw time series models. We analyze these\nadvances in the education domain, addressing the task of early student\nperformance prediction for downstream targeted interventions and instructional\nsupport. Our experimental analysis on 23 MOOCs with millions of combined\ninteractions over six behavioral dimensions show that models designed with our\napproach can (i) beat state-of-the-art educational time series baselines with\nno feature extraction and (ii) provide interpretable insights for personalized\ninterventions. Source code: https://github.com/epfl-ml4ed/ripple/.",
    "descriptor": "\nComments: Accepted as a full paper at AAAI 2023, AI for Education Special Track (EAAI): The 37th AAAI Conference on Artificial Intelligence, 7-14 of February 2023, Washington DC, USA\n",
    "authors": [
      "Mohammad Asadi",
      "Vinitra Swamy",
      "Jibril Frej",
      "Julien Vignoud",
      "Mirko Marras",
      "Tanja K\u00e4ser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.01133"
  },
  {
    "id": "arXiv:2212.01134",
    "title": "Convergence of a splitting method for a general interest rate model",
    "abstract": "We prove mean-square convergence of a novel numerical method, the\ntamed-splitting method, for a generalized Ait-Sahalia interest rate model. The\nmethod is based on a Lamperti transform, splitting and applying a tamed\nnumerical method for the nonlinearity. The main difficulty in the analysis is\ncaused by the non-globally Lipschitz drift coefficients of the model. We\nexamine the existence, uniqueness of the solution and boundedness of moments\nfor the transformed SDE.We then prove bounded moments and inverses moments for\nthe numerical approximation. The tamed-splitting method is a hybrid method in\nthe sense that a backstop method is invoked to prevent solutions from\novershooting zero and becoming negative. We successfully recover the\nmean-square convergence rate of order one for the tamed-splitting method. In\naddition we prove that the probability of ever needing the backstop method to\nprevent a negative value can be made arbitrarily small. In our numerical\nexperiments we compare to other numerical methods in the literature for\nrealistic parameter values.",
    "descriptor": "\nComments: 20 pages, 4 figure, 1 table\n",
    "authors": [
      "Gabriel Lord Mengchao Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.01134"
  },
  {
    "id": "arXiv:2212.01136",
    "title": "Robustness in Fatigue Strength Estimation",
    "abstract": "Fatigue strength estimation is a costly manual material characterization\nprocess in which state-of-the-art approaches follow a standardized experiment\nand analysis procedure. In this paper, we examine a modular, Machine\nLearning-based approach for fatigue strength estimation that is likely to\nreduce the number of experiments and, thus, the overall experimental costs.\nDespite its high potential, deployment of a new approach in a real-life lab\nrequires more than the theoretical definition and simulation. Therefore, we\nstudy the robustness of the approach against misspecification of the prior and\ndiscretization of the specified loads. We identify its applicability and its\nadvantageous behavior over the state-of-the-art methods, potentially reducing\nthe number of costly experiments.",
    "descriptor": "\nComments: 2nd Annual AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE)\n",
    "authors": [
      "Dorina Weichert",
      "Alexander Kister",
      "Sebastian Houben",
      "Gunar Ernis",
      "Stefan Wrobel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01136"
  },
  {
    "id": "arXiv:2212.01140",
    "title": "Tackling Low-Resourced Sign Language Translation: UPC at WMT-SLT 22",
    "abstract": "This paper describes the system developed at the Universitat Polit\\`ecnica de\nCatalunya for the Workshop on Machine Translation 2022 Sign Language\nTranslation Task, in particular, for the sign-to-text direction. We use a\nTransformer model implemented with the Fairseq modeling toolkit. We have\nexperimented with the vocabulary size, data augmentation techniques and\npretraining the model with the PHOENIX-14T dataset. Our system obtains 0.50\nBLEU score for the test set, improving the organizers' baseline by 0.38 BLEU.\nWe remark the poor results for both the baseline and our system, and thus, the\nunreliability of our findings.",
    "descriptor": "",
    "authors": [
      "Laia Tarr\u00e9s",
      "Gerard I. G\u00e0llego",
      "Xavier Gir\u00f3-i-Nieto",
      "Jordi Torres"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01140"
  },
  {
    "id": "arXiv:2212.01141",
    "title": "MHCCL: Masked Hierarchical Cluster-wise Contrastive Learning for  Multivariate Time Series",
    "abstract": "Learning semantic-rich representations from raw unlabeled time series data is\ncritical for downstream tasks such as classification and forecasting.\nContrastive learning has recently shown its promising representation learning\ncapability in the absence of expert annotations. However, existing contrastive\napproaches generally treat each instance independently, which leads to false\nnegative pairs that share the same semantics. To tackle this problem, we\npropose MHCCL, a Masked Hierarchical Cluster-wise Contrastive Learning model,\nwhich exploits semantic information obtained from the hierarchical structure\nconsisting of multiple latent partitions for multivariate time series.\nMotivated by the observation that fine-grained clustering preserves higher\npurity while coarse-grained one reflects higher-level semantics, we propose a\nnovel downward masking strategy to filter out fake negatives and supplement\npositives by incorporating the multi-granularity information from the\nclustering hierarchy. In addition, a novel upward masking strategy is designed\nin MHCCL to remove outliers of clusters at each partition to refine prototypes,\nwhich helps speed up the hierarchical clustering process and improves the\nclustering quality. We conduct experimental evaluations on seven widely-used\nmultivariate time series datasets. The results demonstrate the superiority of\nMHCCL over the state-of-the-art approaches for unsupervised time series\nrepresentation learning.",
    "descriptor": "\nComments: accepted by AAAI 2023\n",
    "authors": [
      "Qianwen Meng",
      "Hangwei Qian",
      "Yong Liu",
      "Yonghui Xu",
      "Zhiqi Shen",
      "Lizhen Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01141"
  },
  {
    "id": "arXiv:2212.01145",
    "title": "Towards Diverse, Relevant and Coherent Open-Domain Dialogue Generation  via Hybrid Latent Variables",
    "abstract": "Conditional variational models, using either continuous or discrete latent\nvariables, are powerful for open-domain dialogue response generation. However,\nprevious works show that continuous latent variables tend to reduce the\ncoherence of generated responses. In this paper, we also found that discrete\nlatent variables have difficulty capturing more diverse expressions. To tackle\nthese problems, we combine the merits of both continuous and discrete latent\nvariables and propose a Hybrid Latent Variable (HLV) method. Specifically, HLV\nconstrains the global semantics of responses through discrete latent variables\nand enriches responses with continuous latent variables. Thus, we diversify the\ngenerated responses while maintaining relevance and coherence. In addition, we\npropose Conditional Hybrid Variational Transformer (CHVT) to construct and to\nutilize HLV with transformers for dialogue generation. Through fine-grained\nsymbolic-level semantic information and additive Gaussian mixing, we construct\nthe distribution of continuous variables, prompting the generation of diverse\nexpressions. Meanwhile, to maintain the relevance and coherence, the discrete\nlatent variable is optimized by self-separation training. Experimental results\non two dialogue generation datasets (DailyDialog and Opensubtitles) show that\nCHVT is superior to traditional transformer-based variational mechanism w.r.t.\ndiversity, relevance and coherence metrics. Moreover, we also demonstrate the\nbenefit of applying HLV to fine-tuning two pre-trained dialogue models (PLATO\nand BART-base).",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Bin Sun",
      "Yitong Li",
      "Fei Mi",
      "Weichao Wang",
      "Yiwei Li",
      "Kan Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01145"
  },
  {
    "id": "arXiv:2212.01146",
    "title": "SumREN: Summarizing Reported Speech about Events in News",
    "abstract": "A primary objective of news articles is to establish the factual record for\nan event, frequently achieved by conveying both the details of the specified\nevent (i.e., the 5 Ws; Who, What, Where, When and Why regarding the event) and\nhow people reacted to it (i.e., reported statements). However, existing work on\nnews summarization almost exclusively focuses on the event details. In this\nwork, we propose the novel task of summarizing the reactions of different\nspeakers, as expressed by their reported statements, to a given event. To this\nend, we create a new multi-document summarization benchmark, SUMREN, comprising\n745 summaries of reported statements from various public figures obtained from\n633 news articles discussing 132 events. We propose an automatic silver\ntraining data generation approach for our task, which helps smaller models like\nBART achieve GPT-3 level performance on this task. Finally, we introduce a\npipeline-based framework for summarizing reported speech, which we empirically\nshow to generate summaries that are more abstractive and factual than baseline\nquery-focused summarization approaches.",
    "descriptor": "\nComments: Accepted at AAAI 2023\n",
    "authors": [
      "Revanth Gangi Reddy",
      "Heba Elfardy",
      "Hou Pong Chan",
      "Kevin Small",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.01146"
  },
  {
    "id": "arXiv:2212.01156",
    "title": "Computing the optimal BWT of very large string collections",
    "abstract": "It is known that the exact form of the Burrows-Wheeler-Transform (BWT) of a\nstring collection depends, in most implementations, on the input order of the\nstrings in the collection. Reordering strings of an input collection affects\nthe number of equal-letter runs $r$, arguably the most important parameter of\nBWT-based data structures, such as the FM-index or the $r$-index. Bentley,\nGibney, and Thankachan [ESA 2020] introduced a linear-time algorithm for\ncomputing the permutation of the input collection which yields the minimum\nnumber of runs of the resulting BWT.\nIn this paper, we present the first tool that guarantees a\nBurrows-Wheeler-Transform with minimum number of runs (optBWT), by combining i)\nan algorithm that builds the BWT from a string collection (either SAIS-based\n[Cenzato et al., SPIRE 2021] or BCR [Bauer et al., CPM 2011]); ii) the SAP\narray data structure introduced in [Cox et al., Bioinformatics, 2012]; and iii)\nthe algorithm by Bentley et al.\nWe present results both on real-life and simulated data, showing that the\nimprovement achieved in terms of $r$ with respect to the input order is\nsignificant and the overhead created by the computation of the optimal BWT\nnegligible, making our tool competitive with other tools for BWT-computation in\nterms of running time and space usage. In particular, on real data the optBWT\nobtains up to 31 times fewer runs with only a $1.39\\times$ slowdown.\nSource code is available at https://github.com/davidecenzato/optimalBWT.git.",
    "descriptor": "\nComments: 11 pages, 2 figures, 4 tables\n",
    "authors": [
      "Davide Cenzato",
      "Veronica Guerrini",
      "Zsuzsanna Lipt\u00e1k",
      "Giovanna Rosone"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.01156"
  },
  {
    "id": "arXiv:2212.01159",
    "title": "Clustering individuals based on multivariate EMA time-series data",
    "abstract": "In the field of psychopathology, Ecological Momentary Assessment (EMA)\nmethodological advancements have offered new opportunities to collect\ntime-intensive, repeated and intra-individual measurements. This way, a large\namount of data has become available, providing the means for further exploring\nmental disorders. Consequently, advanced machine learning (ML) methods are\nneeded to understand data characteristics and uncover hidden and meaningful\nrelationships regarding the underlying complex psychological processes. Among\nother uses, ML facilitates the identification of similar patterns in data of\ndifferent individuals through clustering. This paper focuses on clustering\nmultivariate time-series (MTS) data of individuals into several groups. Since\nclustering is an unsupervised problem, it is challenging to assess whether the\nresulting grouping is successful. Thus, we investigate different clustering\nmethods based on different distance measures and assess them for the stability\nand quality of the derived clusters. These clustering steps are illustrated on\na real-world EMA dataset, including 33 individuals and 15 variables. Through\nevaluation, the results of kernel-based clustering methods appear promising to\nidentify meaningful groups in the data. So, efficient representations of EMA\ndata play an important role in clustering.",
    "descriptor": "\nComments: 15 pages, 6 figures, Psychometrika\n",
    "authors": [
      "Mandani Ntekouli",
      "Gerasimos Spanakis",
      "Lourens Waldorp",
      "Anne Roefs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01159"
  },
  {
    "id": "arXiv:2212.01160",
    "title": "High-Res Facial Appearance Capture from Polarized Smartphone Images",
    "abstract": "We propose a novel method for high-quality facial texture reconstruction from\nRGB images using a novel capturing routine based on a single smartphone which\nwe equip with an inexpensive polarization foil. Specifically, we turn the\nflashlight into a polarized light source and add a polarization filter on top\nof the camera. Leveraging this setup, we capture the face of a subject with\ncross-polarized and parallel-polarized light. For each subject, we record two\nshort sequences in a dark environment under flash illumination with different\nlight polarization using the modified smartphone. Based on these observations,\nwe reconstruct an explicit surface mesh of the face using structure from\nmotion. We then exploit the camera and light co-location within a\ndifferentiable renderer to optimize the facial textures using an\nanalysis-by-synthesis approach. Our method optimizes for high-resolution normal\ntextures, diffuse albedo, and specular albedo using a coarse-to-fine\noptimization scheme. We show that the optimized textures can be used in a\nstandard rendering pipeline to synthesize high-quality photo-realistic 3D\ndigital humans in novel environments.",
    "descriptor": "\nComments: Project page: this https URL Video: this https URL\n",
    "authors": [
      "Dejan Azinovi\u0107",
      "Olivier Maury",
      "Christophe Hery",
      "Mathias Nie\u00dfner",
      "Justus Thies"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2212.01160"
  },
  {
    "id": "arXiv:2212.01165",
    "title": "Deep Active Learning for Multi-Label Classification of Remote Sensing  Images",
    "abstract": "The use of deep neural networks (DNNs) has recently attracted great attention\nin the framework of the multi-label classification (MLC) of remote sensing (RS)\nimages. To optimize the large number of parameters of DNNs a high number of\nreliable training images annotated with multi-labels is often required.\nHowever, the collection of a large training set is time-consuming, complex and\ncostly. To minimize annotation efforts for data-demanding DNNs, in this paper\nwe present several query functions for active learning (AL) in the context of\nDNNs for the MLC of RS images. Unlike the AL query functions defined for\nsingle-label classification or semantic segmentation problems, each query\nfunction presented in this paper is based on the evaluation of two criteria: i)\nmulti-label uncertainty; and ii) multi-label diversity. The multi-label\nuncertainty criterion is associated to the confidence of the DNNs in correctly\nassigning multi-labels to each image. To assess the multi-label uncertainty, we\npresent and adapt to the MLC problems three strategies: i) learning multi-label\nloss ordering; ii) measuring temporal discrepancy of multi-label prediction;\nand iii) measuring magnitude of approximated gradient embedding. The\nmulti-label diversity criterion aims at selecting a set of uncertain images\nthat are as diverse as possible to reduce the redundancy among them. To assess\nthis criterion we exploit a clustering based strategy. We combine each of the\nabove-mentioned uncertainty strategy with the clustering based diversity\nstrategy, resulting in three different query functions. Experimental results\nobtained on two benchmark archives show that our query functions result in the\nselection of a highly informative set of samples at each iteration of the AL\nprocess in the context of MLC.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Lars M\u00f6llenbrok",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01165"
  },
  {
    "id": "arXiv:2212.01168",
    "title": "Identifying Hamiltonian manifold in neural networks",
    "abstract": "Recent studies to learn physical laws via deep learning attempt to find the\nshared representation of the given system by introducing physics priors or\ninductive biases to the neural network. However, most of these approaches\ntackle the problem in a system-specific manner, in which one neural network\ntrained to one particular physical system cannot be easily adapted to another\nsystem governed by a different physical law. In this work, we use a\nmeta-learning algorithm to identify the general manifold in neural networks\nthat represents Hamilton's equation. We meta-trained the model with the dataset\ncomposed of five dynamical systems each governed by different physical laws. We\nshow that with only a few gradient steps, the meta-trained model adapts well to\nthe physical system which was unseen during the meta-training phase. Our\nresults suggest that the meta-trained model can craft the representation of\nHamilton's equation in neural networks which is shared across various dynamical\nsystems with each governed by different physical laws.",
    "descriptor": "",
    "authors": [
      "Yeongwoo Song",
      "Hawoong Jeong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.01168"
  },
  {
    "id": "arXiv:2212.01173",
    "title": "DWRSeg: Dilation-wise Residual Network for Real-time Semantic  Segmentation",
    "abstract": "Real-time semantic segmentation has played an important role in intelligent\nvehicle scenarios. Recently, numerous networks have incorporated information\nfrom multi-size receptive fields to facilitate feature extraction in real-time\nsemantic segmentation tasks. However, these methods preferentially adopt\nmassive receptive fields to elicit more contextual information, which may\nresult in inefficient feature extraction. We believe that the elaborated\nreceptive fields are crucial, considering the demand for efficient feature\nextraction in real-time tasks. Therefore, we propose an effective and efficient\narchitecture termed Dilation-wise Residual segmentation (DWRSeg), which\npossesses different sets of receptive field sizes within different stages. The\narchitecture involves (i) a Dilation-wise Residual (DWR) module for extracting\nfeatures based on different scales of receptive fields in the high level of the\nnetwork; (ii) a Simple Inverted Residual (SIR) module that uses an inverted\nbottleneck structure to extract features from the low stage; and (iii) a simple\nfully convolutional network (FCN)-like decoder for aggregating multiscale\nfeature maps to generate the prediction. Extensive experiments on the\nCityscapes and CamVid datasets demonstrate the effectiveness of our method by\nachieving a state-of-the-art trade-off between accuracy and inference speed, in\naddition to being lighter weight. Without using pretraining or resorting to any\ntraining trick, we achieve 72.7% mIoU on the Cityscapes test set at a speed of\n319.5 FPS on one NVIDIA GeForce GTX 1080 Ti card, which is significantly faster\nthan existing methods. The code and trained models are publicly available.",
    "descriptor": "",
    "authors": [
      "Haoran Wei",
      "Xu Liu",
      "Shouchun Xu",
      "Zhongjian Dai",
      "Yaping Dai",
      "Xiangyang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01173"
  },
  {
    "id": "arXiv:2212.01174",
    "title": "Utilizing Prior Solutions for Reward Shaping and Composition in  Entropy-Regularized Reinforcement Learning",
    "abstract": "In reinforcement learning (RL), the ability to utilize prior knowledge from\npreviously solved tasks can allow agents to quickly solve new problems. In some\ncases, these new problems may be approximately solved by composing the\nsolutions of previously solved primitive tasks (task composition). Otherwise,\nprior knowledge can be used to adjust the reward function for a new problem, in\na way that leaves the optimal policy unchanged but enables quicker learning\n(reward shaping). In this work, we develop a general framework for reward\nshaping and task composition in entropy-regularized RL. To do so, we derive an\nexact relation connecting the optimal soft value functions for two\nentropy-regularized RL problems with different reward functions and dynamics.\nWe show how the derived relation leads to a general result for reward shaping\nin entropy-regularized RL. We then generalize this approach to derive an exact\nrelation connecting optimal value functions for the composition of multiple\ntasks in entropy-regularized RL. We validate these theoretical contributions\nwith experiments showing that reward shaping and task composition lead to\nfaster learning in various settings.",
    "descriptor": "\nComments: Conference paper accepted in the Technical track for AAAI-2023\n",
    "authors": [
      "Jacob Adamczyk",
      "Argenis Arriojas",
      "Stas Tiomkin",
      "Rahul V. Kulkarni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01174"
  },
  {
    "id": "arXiv:2212.01175",
    "title": "Flip Graphs for Matrix Multiplication",
    "abstract": "We introduce a new method for discovering matrix multiplication schemes based\non random walks in a certain graph, which we call the flip graph. Using this\nmethod, we were able to reduce the number of multiplications for the matrix\nformats (4, 4, 5) and (5, 5, 5), both in characteristic two and for arbitrary\nground fields.",
    "descriptor": "",
    "authors": [
      "Manuel Kauers",
      "Jakob Moosbauer"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2212.01175"
  },
  {
    "id": "arXiv:2212.01176",
    "title": "Physical layer insecurity",
    "abstract": "In the classic wiretap model, Alice wishes to reliably communicate to Bob\nwithout being overheard by Eve who is eavesdropping over a degraded channel.\nSystems for achieving that physical layer security often rely on an error\ncorrection code whose rate is below the Shannon capacity of Alice and Bob's\nchannel, so Bob can reliably decode, but above Alice and Eve's, so Eve cannot\nreliably decode. For the finite block length regime, several metrics have been\nproposed to characterise information leakage. Here we assess a new metric, the\nsuccess exponent, and demonstrate it can be operationalized through the use of\nGuessing Random Additive Noise Decoding (GRAND) to compromise the\nphysical-layer security of any moderate length code.\nSuccess exponents are the natural beyond-capacity analogue of error exponents\nthat characterise the probability that a maximum likelihood decoding is correct\nwhen the code-rate is above Shannon capacity, which is exponentially decaying\nin the code-length. Success exponents can be used to approximately evaluate the\nfrequency with which Eve's decoding is correct in beyond-capacity channel\nconditions. Moreover, through GRAND, we demonstrate that Eve can constrain her\ndecoding procedure so that when she does identify a decoding, it is correct\nwith high likelihood, significantly compromising Alice and Bob's communication\nby truthfully revealing a proportion of it.\nWe provide general mathematical expressions for the determination of success\nexponents as well as for the evaluation of Eve's query number threshold, using\nthe binary symmetric channel as a worked example. As GRAND algorithms are\ncode-book agnostic and can decode any code structure, we provide empirical\nresults for Random Linear Codes as exemplars, since they achieve secrecy\ncapacity. Simulation results demonstrate the practical possibility of\ncompromising physical layer security.",
    "descriptor": "",
    "authors": [
      "Muriel M\u00e9dard",
      "Ken R. Duffy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.01176"
  },
  {
    "id": "arXiv:2212.01186",
    "title": "A General Purpose Supervisory Signal for Embodied Agents",
    "abstract": "Training effective embodied AI agents often involves manual reward\nengineering, expert imitation, specialized components such as maps, or\nleveraging additional sensors for depth and localization. Another approach is\nto use neural architectures alongside self-supervised objectives which\nencourage better representation learning. In practice, there are few guarantees\nthat these self-supervised objectives encode task-relevant information. We\npropose the Scene Graph Contrastive (SGC) loss, which uses scene graphs as\ngeneral-purpose, training-only, supervisory signals. The SGC loss does away\nwith explicit graph decoding and instead uses contrastive learning to align an\nagent's representation with a rich graphical encoding of its environment. The\nSGC loss is generally applicable, simple to implement, and encourages\nrepresentations that encode objects' semantics, relationships, and history.\nUsing the SGC loss, we attain significant gains on three embodied tasks: Object\nNavigation, Multi-Object Navigation, and Arm Point Navigation. Finally, we\npresent studies and analyses which demonstrate the ability of our trained\nrepresentation to encode semantic cues about the environment.",
    "descriptor": "",
    "authors": [
      "Kunal Pratap Singh",
      "Jordi Salvador",
      "Luca Weihs",
      "Aniruddha Kembhavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01186"
  },
  {
    "id": "arXiv:2212.01187",
    "title": "Surrogate Gradient Spiking Neural Networks as Encoders for Large  Vocabulary Continuous Speech Recognition",
    "abstract": "Compared to conventional artificial neurons that produce dense and\nreal-valued responses, biologically-inspired spiking neurons transmit sparse\nand binary information, which can also lead to energy-efficient\nimplementations. Recent research has shown that spiking neural networks can be\ntrained like standard recurrent neural networks using the surrogate gradient\nmethod. They have shown promising results on speech command recognition tasks.\nUsing the same technique, we show that they are scalable to large vocabulary\ncontinuous speech recognition, where they are capable of replacing LSTMs in the\nencoder with only minor loss of performance. This suggests that they may be\napplicable to more involved sequence-to-sequence tasks. Moreover, in contrast\nto their recurrent non-spiking counterparts, they show robustness to exploding\ngradient problems without the need to use gates.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Alexandre Bittar",
      "Philip N. Garner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.01187"
  },
  {
    "id": "arXiv:2212.01188",
    "title": "Improving Simultaneous Machine Translation with Monolingual Data",
    "abstract": "Simultaneous machine translation (SiMT) is usually done via sequence-level\nknowledge distillation (Seq-KD) from a full-sentence neural machine translation\n(NMT) model. However, there is still a significant performance gap between NMT\nand SiMT. In this work, we propose to leverage monolingual data to improve\nSiMT, which trains a SiMT student on the combination of bilingual data and\nexternal monolingual data distilled by Seq-KD. Preliminary experiments on En-Zh\nand En-Ja news domain corpora demonstrate that monolingual data can\nsignificantly improve translation quality (e.g., +3.15 BLEU on En-Zh). Inspired\nby the behavior of human simultaneous interpreters, we propose a novel\nmonolingual sampling strategy for SiMT, considering both chunk length and\nmonotonicity. Experimental results show that our sampling strategy consistently\noutperforms the random sampling strategy (and other conventional typical NMT\nmonolingual sampling strategies) by avoiding the key problem of SiMT --\nhallucination, and has better scalability. We achieve +0.72 BLEU improvements\non average against random sampling on En-Zh and En-Ja. Data and codes can be\nfound at https://github.com/hexuandeng/Mono4SiMT.",
    "descriptor": "\nComments: Accepted by AAAI 2023. Extended version includes supplementary material. 10 pages, 4 figures, 8 tables\n",
    "authors": [
      "Hexuan Deng",
      "Liang Ding",
      "Xuebo Liu",
      "Meishan Zhang",
      "Dacheng Tao",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.01188"
  },
  {
    "id": "arXiv:2212.01189",
    "title": "Denoising after Entropy-based Debiasing A Robust Training Method for  Dataset Bias with Noisy Labels",
    "abstract": "Improperly constructed datasets can result in inaccurate inferences. For\ninstance, models trained on biased datasets perform poorly in terms of\ngeneralization (i.e., dataset bias). Recent debiasing techniques have\nsuccessfully achieved generalization performance by underestimating\neasy-to-learn samples (i.e., bias-aligned samples) and highlighting\ndifficult-to-learn samples (i.e., bias-conflicting samples). However, these\ntechniques may fail owing to noisy labels, because the trained model recognizes\nnoisy labels as difficult-to-learn and thus highlights them. In this study, we\nfind that earlier approaches that used the provided labels to quantify\ndifficulty could be affected by the small proportion of noisy labels.\nFurthermore, we find that running denoising algorithms before debiasing is\nineffective because denoising algorithms reduce the impact of\ndifficult-to-learn samples, including valuable bias-conflicting samples.\nTherefore, we propose an approach called denoising after entropy-based\ndebiasing, i.e., DENEB, which has three main stages. (1) The prejudice model is\ntrained by emphasizing (bias-aligned, clean) samples, which are selected using\na Gaussian Mixture Model. (2) Using the per-sample entropy from the output of\nthe prejudice model, the sampling probability of each sample that is\nproportional to the entropy is computed. (3) The final model is trained using\nexisting denoising algorithms with the mini-batches constructed by following\nthe computed sampling probability. Compared to existing debiasing and denoising\nalgorithms, our method achieves better debiasing performance on multiple\nbenchmarks.",
    "descriptor": "\nComments: 37th AAAI Conference on Artificial Intelligence (AAAI'23)\n",
    "authors": [
      "Sumyeong Ahn",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01189"
  },
  {
    "id": "arXiv:2212.01194",
    "title": "Inheritance and Blockchain: Thoughts and Open Questions",
    "abstract": "Inheritance is the fundamental building block of civilization. This is the\naddition of wealth, knowledge and properties over time that produce the society\nin which we are living. Every generation does not have to start from zero and\ncan capitalize on the efforts of previous generations. Blockchain based assets\nare very efficiently and securely transferred between living entities. Yet the\nactual way to make heirs inherit crypto-assets is seldom discussed. It appears\nthat the problems linked with the inheritance of crypto-assets raise a lot of\ntechnical, societal and legal issues. Part of those issues have to be tackled\nwith at the level of the blockchain infrastructure itself. The aim of this\npaper is to open a research field, and to discuss some ideas, with regards to\nthis overlooked issue. Inheritance is neither a peripheral question nor one\nthat can be dodged. It comes with its own set of challenges that have to be met\nif blockchain based finance, and asset management, is to be taken seriously.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2209.11194\n",
    "authors": [
      "Fr\u00e9d\u00e9ric Prost"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.01194"
  },
  {
    "id": "arXiv:2212.01196",
    "title": "Vector Symbolic Finite State Machines in Attractor Neural Networks",
    "abstract": "Hopfield attractor networks are robust distributed models of human memory. We\npropose construction rules such that an attractor network may implement an\narbitrary finite state machine (FSM), where states and stimuli are represented\nby high-dimensional random bipolar vectors, and all state transitions are\nenacted by the attractor network's dynamics. Numerical simulations show the\ncapacity of the model, in terms of the maximum size of implementable FSM, to be\nlinear in the size of the attractor network. We show that the model is robust\nto imprecise and noisy weights, and so a prime candidate for implementation\nwith high-density but unreliable devices. By endowing attractor networks with\nthe ability to emulate arbitrary FSMs, we propose a plausible path by which\nFSMs may exist as a distributed computational primitive in biological neural\nnetworks.",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Madison Cotteret",
      "Hugh Greatorex",
      "Martin Ziegler",
      "Elisabetta Chicca"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2212.01196"
  },
  {
    "id": "arXiv:2212.01197",
    "title": "FedALA: Adaptive Local Aggregation for Personalized Federated Learning",
    "abstract": "A key challenge in federated learning (FL) is the statistical heterogeneity\nthat impairs the generalization of the global model on each client. To address\nthis, we propose a method Federated learning with Adaptive Local Aggregation\n(FedALA) by capturing the desired information in the global model for client\nmodels in personalized FL. The key component of FedALA is an Adaptive Local\nAggregation (ALA) module, which can adaptively aggregate the downloaded global\nmodel and local model towards the local objective on each client to initialize\nthe local model before training in each iteration. To evaluate the\neffectiveness of FedALA, we conduct extensive experiments with five benchmark\ndatasets in computer vision and natural language processing domains. FedALA\noutperforms eleven state-of-the-art baselines by up to 3.27% in test accuracy.\nFurthermore, we also apply ALA module to other federated learning methods and\nachieve up to 24.19% improvement in test accuracy.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Jianqing Zhang",
      "Yang Hua",
      "Hao Wang",
      "Tao Song",
      "Zhengui Xue",
      "Ruhui Ma",
      "Haibing Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01197"
  },
  {
    "id": "arXiv:2212.01205",
    "title": "Diver Interest via Pointing: Human-Directed Object Inspection for AUVs",
    "abstract": "In this paper, we present the Diver Interest via Pointing (DIP) algorithm, a\nhighly modular method for conveying a diver's area of interest to an autonomous\nunderwater vehicle (AUV) using pointing gestures for underwater human-robot\ncollaborative tasks. DIP uses a single monocular camera and exploits human body\npose, even with complete dive gear, to extract underwater human pointing\ngesture poses and their directions. By extracting 2D scene geometry based on\nthe human body pose and density of salient feature points along the direction\nof pointing, using a low-level feature detector, the DIP algorithm is able to\nlocate objects of interest as indicated by the diver.",
    "descriptor": "\nComments: Under submission at ICRA23\n",
    "authors": [
      "Chelsey Edge",
      "Junaed Sattar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.01205"
  },
  {
    "id": "arXiv:2212.01206",
    "title": "DiffRF: Rendering-Guided 3D Radiance Field Diffusion",
    "abstract": "We introduce DiffRF, a novel approach for 3D radiance field synthesis based\non denoising diffusion probabilistic models. While existing diffusion-based\nmethods operate on images, latent codes, or point cloud data, we are the first\nto directly generate volumetric radiance fields. To this end, we propose a 3D\ndenoising model which directly operates on an explicit voxel grid\nrepresentation. However, as radiance fields generated from a set of posed\nimages can be ambiguous and contain artifacts, obtaining ground truth radiance\nfield samples is non-trivial. We address this challenge by pairing the\ndenoising formulation with a rendering loss, enabling our model to learn a\ndeviated prior that favours good image quality instead of trying to replicate\nfitting errors like floating artifacts. In contrast to 2D-diffusion models, our\nmodel learns multi-view consistent priors, enabling free-view synthesis and\naccurate shape generation. Compared to 3D GANs, our diffusion-based approach\nnaturally enables conditional generation such as masked completion or\nsingle-view 3D synthesis at inference time.",
    "descriptor": "\nComments: Project page: this https URL Video: this https URL\n",
    "authors": [
      "Norman M\u00fcller",
      "Yawar Siddiqui",
      "Lorenzo Porzi",
      "Samuel Rota Bul\u00f2",
      "Peter Kontschieder",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01206"
  },
  {
    "id": "arXiv:2212.01207",
    "title": "Joint Open Knowledge Base Canonicalization and Linking",
    "abstract": "Open Information Extraction (OIE) methods extract a large number of OIE\ntriples (noun phrase, relation phrase, noun phrase) from text, which compose\nlarge Open Knowledge Bases (OKBs). However, noun phrases (NPs) and relation\nphrases (RPs) in OKBs are not canonicalized and often appear in different\nparaphrased textual variants, which leads to redundant and ambiguous facts. To\naddress this problem, there are two related tasks: OKB canonicalization (i.e.,\nconvert NPs and RPs to canonicalized form) and OKB linking (i.e., link NPs and\nRPs with their corresponding entities and relations in a curated Knowledge Base\n(e.g., DBPedia). These two tasks are tightly coupled, and one task can benefit\nsignificantly from the other. However, they have been studied in isolation so\nfar. In this paper, we explore the task of joint OKB canonicalization and\nlinking for the first time, and propose a novel framework JOCL based on factor\ngraph model to make them reinforce each other. JOCL is flexible enough to\ncombine different signals from both tasks, and able to extend to fit any new\nsignals. A thorough experimental study over two large scale OIE triple data\nsets shows that our framework outperforms all the baseline methods for the task\nof OKB canonicalization (OKB linking) in terms of average F1 (accuracy).",
    "descriptor": "\nComments: Accepted by SIGMOD'21\n",
    "authors": [
      "Yinan Liu",
      "Wei Shen",
      "Yuanfei Wang",
      "Jianyong Wang",
      "Zhenglu Yang",
      "Xiaojie Yuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01207"
  },
  {
    "id": "arXiv:2212.01209",
    "title": "FECAM: Frequency Enhanced Channel Attention Mechanism for Time Series  Forecasting",
    "abstract": "Time series forecasting is a long-standing challenge due to the real-world\ninformation is in various scenario (e.g., energy, weather, traffic, economics,\nearthquake warning). However some mainstream forecasting model forecasting\nresult is derailed dramatically from ground truth. We believe it's the reason\nthat model's lacking ability of capturing frequency information which richly\ncontains in real world datasets. At present, the mainstream frequency\ninformation extraction methods are Fourier transform(FT) based. However, use of\nFT is problematic due to Gibbs phenomenon. If the values on both sides of\nsequences differ significantly, oscillatory approximations are observed around\nboth sides and high frequency noise will be introduced. Therefore We propose a\nnovel frequency enhanced channel attention that adaptively modelling frequency\ninterdependencies between channels based on Discrete Cosine Transform which\nwould intrinsically avoid high frequency noise caused by problematic periodity\nduring Fourier Transform, which is defined as Gibbs Phenomenon. We show that\nthis network generalize extremely effectively across six real-world datasets\nand achieve state-of-the-art performance, we further demonstrate that frequency\nenhanced channel attention mechanism module can be flexibly applied to\ndifferent networks. This module can improve the prediction ability of existing\nmainstream networks, which reduces 35.99% MSE on LSTM, 10.01% on Reformer,\n8.71% on Informer, 8.29% on Autoformer, 8.06% on Transformer, etc., at a slight\ncomputational cost ,with just a few line of code. Our codes and data are\navailable at https://github.com/Zero-coder/FECAM.",
    "descriptor": "\nComments: 11pages.10 figures,conference. arXiv admin note: text overlap with arXiv:2205.14415 by other authors\n",
    "authors": [
      "Maowei Jiang",
      "Pengyu Zeng",
      "Kai Wang",
      "Huan Liu",
      "Wenbo Chen",
      "Haoran Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.01209"
  },
  {
    "id": "arXiv:2212.01210",
    "title": "Octocopter Design: Modelling, Control and Motion Planning",
    "abstract": "This book provides a solution to the control and motion planning design for\nan octocopter system. It includes a particular choice of control and motion\nplanning algorithms which is based on the authors' previous research work, so\nit can be used as a reference design guidance for students, researchers as well\nas autonomous vehicles hobbyists. The control is constructed based on a fault\ntolerant approach aiming to increase the chances of the system to detect and\nisolate a potential failure in order to produce feasible control signals to the\nremaining active motors. The used motion planning algorithm is risk-aware by\nmeans that it takes into account the constraints related to the fault-dependant\nand mission-related maneuverability analysis of the octocopter system during\nthe planning stage. Such a planner generates only those reference trajectories\nalong which the octocopter system would be safe and capable of good tracking in\ncase of a single motor fault and of majority of double motor fault scenarios.\nThe control and motion planning algorithms presented in the book aim to\nincrease the overall reliability of the system for completing the mission.",
    "descriptor": "\nComments: 100 pages, 57 Figures, 16 Tables\n",
    "authors": [
      "Nedim Osmic",
      "Adnan Tahirovic",
      "Bakir Lacevic"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.01210"
  },
  {
    "id": "arXiv:2212.01211",
    "title": "Sometimes Two Irrational Guards are Needed",
    "abstract": "In the art gallery problem, we are given a closed polygon $P$, with rational\ncoordinates and an integer $k$. We are asked whether it is possible to find a\nset (of guards) $G$ of size $k$ such that any point $p\\in P$ is seen by a point\nin $G$. We say two points $p$, $q$ see each other if the line segment $pq$ is\ncontained inside $P$. It was shown by Abrahamsen, Adamaszek, and Miltzow that\nthere is a polygon that can be guarded with three guards, but requires four\nguards if the guards are required to have rational coordinates. In other words,\nan optimal solution of size three might need to be irrational. We show that an\noptimal solution of size two might need to be irrational. Note that it is\nwell-known that any polygon that can be guarded with one guard has an optimal\nguard placement with rational coordinates. Hence, our work closes the gap on\nwhen irrational guards are possible to occur.",
    "descriptor": "\nComments: 19 pages, 12 figures\n",
    "authors": [
      "Lucas Meijer",
      "Tillmann Miltzow"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2212.01211"
  },
  {
    "id": "arXiv:2212.01215",
    "title": "Olive Branch Learning: A Topology-Aware Federated Learning Framework for  Space-Air-Ground Integrated Network",
    "abstract": "The space-air-ground integrated network (SAGIN), one of the key technologies\nfor next-generation mobile communication systems, can facilitate data\ntransmission for users all over the world, especially in some remote areas\nwhere vast amounts of informative data are collected by Internet of remote\nthings (IoRT) devices to support various data-driven artificial intelligence\n(AI) services. However, training AI models centrally with the assistance of\nSAGIN faces the challenges of highly constrained network topology, inefficient\ndata transmission, and privacy issues. To tackle these challenges, we first\npropose a novel topology-aware federated learning framework for the SAGIN,\nnamely Olive Branch Learning (OBL). Specifically, the IoRT devices in the\nground layer leverage their private data to perform model training locally,\nwhile the air nodes in the air layer and the ring-structured low earth orbit\n(LEO) satellite constellation in the space layer are in charge of model\naggregation (synchronization) at different scales.To further enhance\ncommunication efficiency and inference performance of OBL, an efficient\nCommunication and Non-IID-aware Air node-Satellite Assignment (CNASA) algorithm\nis designed by taking the data class distribution of the air nodes as well as\ntheir geographic locations into account. Furthermore, we extend our OBL\nframework and CNASA algorithm to adapt to more complex multi-orbit satellite\nnetworks. We analyze the convergence of our OBL framework and conclude that the\nCNASA algorithm contributes to the fast convergence of the global model.\nExtensive experiments based on realistic datasets corroborate the superior\nperformance of our algorithm over the benchmark policies.",
    "descriptor": "\nComments: accepted by IEEE Transactions on Wireless Communications, Dec. 2022\n",
    "authors": [
      "Qingze Fang",
      "Zhiwei Zhai",
      "Shuai Yu",
      "Qiong Wu",
      "Xiaowen Gong",
      "Xu Chen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.01215"
  },
  {
    "id": "arXiv:2212.01217",
    "title": "Using Large Pre-Trained Language Model to Assist FDA in Premarket  Medical Device",
    "abstract": "This paper proposes a possible method using natural language processing that\nmight assist in the FDA medical device marketing process. Actual device\ndescriptions are taken and matched with the device description in FDA Title 21\nof CFR to determine their corresponding device type. Both pre-trained word\nembeddings such as FastText and large pre-trained sentence embedding models\nsuch as sentence transformers are evaluated on their accuracy in characterizing\na piece of device description. An experiment is also done to test whether these\nmodels can identify the devices wrongly classified in the FDA database. The\nresult shows that sentence transformer with T5 and MPNet and GPT-3 semantic\nsearch embedding show high accuracy in identifying the correct classification\nby narrowing down the correct label to be contained in the first 15 most likely\nresults, as compared to 2585 types of device descriptions that must be manually\nsearched through. On the other hand, all methods demonstrate high accuracy in\nidentifying completely incorrectly labeled devices, but all fail to identify\nfalse device classifications that are wrong but closely related to the true\nlabel.",
    "descriptor": "\nComments: IEEE Southeast Conference 2023\n",
    "authors": [
      "Zongzhe Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01217"
  },
  {
    "id": "arXiv:2212.01218",
    "title": "Answer ranking in Community Question Answering: a deep learning approach",
    "abstract": "Community Question Answering is the field of computational linguistics that\ndeals with problems derived from the questions and answers posted to websites\nsuch as Quora or Stack Overflow. Among some of these problems we find the issue\nof ranking the multiple answers posted in reply to each question by how\ninformative they are in the attempt to solve the original question. This work\ntries to advance the state of the art on answer ranking for community Question\nAnswering by proceeding with a deep learning approach. We started off by\ncreating a large data set of questions and answers posted to the Stack Overflow\nwebsite.\nWe then leveraged the natural language processing capabilities of dense\nembeddings and LSTM networks to produce a prediction for the accepted answer\nattribute, and present the answers in a ranked form ordered by how likely they\nare to be marked as accepted by the question asker. We also produced a set of\nnumerical features to assist with the answer ranking task. These numerical\nfeatures were either extracted from metadata found in the Stack Overflow posts\nor derived from the questions and answers texts. We compared the performance of\nour deep learning models against a set of forest and boosted trees ensemble\nmethods and found that our models could not improve the best baseline results.\nWe speculate that this lack of performance improvement versus the baseline\nmodels may be caused by the large number of out of vocabulary words present in\nthe programming code snippets found in the questions and answers text. We\nconclude that while a deep learning approach may be helpful in answer ranking\nproblems new methods should be developed to assist with the large number of out\nof vocabulary words present in the programming code snippets",
    "descriptor": "\nComments: 72 pages, Masters thesis\n",
    "authors": [
      "Lucas Valentin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.01218"
  },
  {
    "id": "arXiv:2212.01219",
    "title": "Coevolutionary Framework for Generalized Multimodal Multi-objective  Optimization",
    "abstract": "Most multimodal multi-objective evolutionary algorithms (MMEAs) aim to find\nall global Pareto optimal sets (PSs) for a multimodal multi-objective\noptimization problem (MMOP). However, in real-world problems, decision makers\n(DMs) may be also interested in local PSs. Also, searching for both global and\nlocal PSs is more general in view of dealing with MMOPs, which can be seen as a\ngeneralized MMOP. In addition, the state-of-the-art MMEAs exhibit poor\nconvergence on high-dimension MMOPs. To address the above two issues, in this\nstudy, a novel coevolutionary framework termed CoMMEA for multimodal\nmulti-objective optimization is proposed to better obtain both global and local\nPSs, and simultaneously, to improve the convergence performance in dealing with\nhigh-dimension MMOPs. Specifically, the CoMMEA introduces two archives to the\nsearch process, and coevolves them simultaneously through effective knowledge\ntransfer. The convergence archive assists the CoMMEA to quickly approaching the\nPareto optimal front (PF). The knowledge of the converged solutions is then\ntransferred to the diversity archive which utilizes the local convergence\nindicator and the $\\epsilon$-dominance-based method to obtain global and local\nPSs effectively. Experimental results show that CoMMEA is competitive compared\nto seven state-of-the-art MMEAs on fifty-four complex MMOPs.",
    "descriptor": "",
    "authors": [
      "Wenhua Li",
      "Xingyi Yao",
      "Kaiwen Li",
      "Rui Wang",
      "Tao Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2212.01219"
  },
  {
    "id": "arXiv:2212.01222",
    "title": "Evaluation of FEM and MLFEM AI-explainers in Image Classification tasks  with reference-based and no-reference metrics",
    "abstract": "The most popular methods and algorithms for AI are, for the vast majority,\nblack boxes. Black boxes can be an acceptable solution to unimportant problems\n(in the sense of the degree of impact) but have a fatal flaw for the rest.\nTherefore the explanation tools for them have been quickly developed. The\nevaluation of their quality remains an open research question. In this\ntechnical report, we remind recently proposed post-hoc explainers FEM and MLFEM\nwhich have been designed for explanations of CNNs in image and video\nclassification tasks. We also propose their evaluation with reference-based and\nno-reference metrics. The reference-based metrics are Pearson Correlation\ncoefficient and Similarity computed between the explanation maps and the ground\ntruth, which is represented by Gaze Fixation Density Maps obtained due to a\npsycho-visual experiment. As a no-reference metric we use \"stability\" metric,\nproposed by Alvarez-Melis and Jaakkola. We study its behaviour, consensus with\nreference-based metrics and show that in case of several kind of degradations\non input images, this metric is in agreement with reference-based ones.\nTherefore it can be used for evaluation of the quality of explainers when the\nground truth is not available.",
    "descriptor": "\nComments: 35 pages, 16 tables, 21 figures, technical report\n",
    "authors": [
      "A. Zhukov",
      "J. Benois-Pineau",
      "R. Giot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01222"
  },
  {
    "id": "arXiv:2212.01223",
    "title": "On the Change of Decision Boundaries and Loss in Learning with Concept  Drift",
    "abstract": "The notion of concept drift refers to the phenomenon that the distribution\ngenerating the observed data changes over time. If drift is present, machine\nlearning models may become inaccurate and need adjustment. Many technologies\nfor learning with drift rely on the interleaved test-train error (ITTE) as a\nquantity which approximates the model generalization error and triggers drift\ndetection and model updates. In this work, we investigate in how far this\nprocedure is mathematically justified. More precisely, we relate a change of\nthe ITTE to the presence of real drift, i.e., a changed posterior, and to a\nchange of the training result under the assumption of optimality. We support\nour theoretical findings by empirical evidence for several learning algorithms,\nmodels, and datasets.",
    "descriptor": "",
    "authors": [
      "Fabian Hinder",
      "Valerie Vaquet",
      "Johannes Brinkrolf",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01223"
  },
  {
    "id": "arXiv:2212.01224",
    "title": "Software Requirements Engineering Healthcare Implementation Maturity  Model (SRE-HIMM) for Global Health-Care Information System",
    "abstract": "The fundamental objective of this research work is to develop a Software\nRequirement Engineering Healthcare Implementation Maturity Model (SRE-HIMM)\nthat will assist healthcare organizations to effectively evaluate and implement\nHIS development process. The model was developed based on the systematic\nliterature review (SLR) approach and Empirical results. The 53 primary studies\nwere extracted using the SLR approach and CSFs, CBs, and best practices were\nidentified form the extracted primary studies. The identified success factors\nand barriers were further ranked using the analytical hierarchy process (AHP)\napproach. Furthermore, I have adopted the critical success factors (CSFs) and\ncritical barriers (CBs) instead of PAs and available Maturity models i.e., CMMI\nfor the development of (SRE-HIMM). The identified CSFs and CBs were classified\ninto five maturity levels based on the CMMI, IMM, and SOVRM. The empirical\ninvestigation was conducted HIS experts to evaluate the findings of SLR.\nFurther, a case study was conducted with the company to evaluate the\neffectiveness of SRE-HIMM which shows satisfactory results.",
    "descriptor": "",
    "authors": [
      "Muhammad Hamza"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.01224"
  },
  {
    "id": "arXiv:2212.01225",
    "title": "NFT Wash Trading in the Ethereum Blockchain",
    "abstract": "Non-Fungible Token (NFT) marketplaces on the Ethereum blockchain saw an\nastonishing growth in 2021. The trend does not seem to stop, with a monthly\ntrading volume of \\$6 billion in January 2022. However, questions have arisen\nabout such a high trading volume. The primary concern is wash trading, a market\nmanipulation in which a single entity trades an NFT multiple times to increase\nthe volume artificially. This paper describes several methodologies for\nidentifying wash trading in Ethereum, from its inception to January 2022, and\nexplores the tangible impact on NFTs. We found that the collections affected by\nwash trading are 5.66% of all the collections, with a total artificial volume\nof \\$3,406,110,774. We study two different ways of profiting from wash trading:\nIncreasing the price of NFTs by showing artificial interest on the asset, and\nexploiting the reward token system of some marketplaces. We show that the\nlatter is safer for wash traders since it guarantees a higher expected profit.\nOur findings indicate that wash trading is a frequent event in the blockchain\neco-system, that reward token systems can stimulate market manipulations, and\nthat marketplaces can introduce countermeasures by using the methodologies\ndescribed in this paper.",
    "descriptor": "",
    "authors": [
      "Massimo La Morgia",
      "Alessandro Mei",
      "Alberto Maria Mongardini",
      "Eugenio Nerio Nemmi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.01225"
  },
  {
    "id": "arXiv:2212.01231",
    "title": "BEV-SAN: Accurate BEV 3D Object Detection via Slice Attention Networks",
    "abstract": "Bird's-Eye-View (BEV) 3D Object Detection is a crucial multi-view technique\nfor autonomous driving systems. Recently, plenty of works are proposed,\nfollowing a similar paradigm consisting of three essential components, i.e.,\ncamera feature extraction, BEV feature construction, and task heads. Among the\nthree components, BEV feature construction is BEV-specific compared with 2D\ntasks. Existing methods aggregate the multi-view camera features to the\nflattened grid in order to construct the BEV feature. However, flattening the\nBEV space along the height dimension fails to emphasize the informative\nfeatures of different heights. For example, the barrier is located at a low\nheight while the truck is located at a high height. In this paper, we propose a\nnovel method named BEV Slice Attention Network (BEV-SAN) for exploiting the\nintrinsic characteristics of different heights. Instead of flattening the BEV\nspace, we first sample along the height dimension to build the global and local\nBEV slices. Then, the features of BEV slices are aggregated from the camera\nfeatures and merged by the attention mechanism. Finally, we fuse the merged\nlocal and global BEV features by a transformer to generate the final feature\nmap for task heads. The purpose of local BEV slices is to emphasize informative\nheights. In order to find them, we further propose a LiDAR-guided sampling\nstrategy to leverage the statistical distribution of LiDAR to determine the\nheights of local slices. Compared with uniform sampling, LiDAR-guided sampling\ncan determine more informative heights. We conduct detailed experiments to\ndemonstrate the effectiveness of BEV-SAN. Code will be released.",
    "descriptor": "",
    "authors": [
      "Xiaowei Chi",
      "Jiaming Liu",
      "Ming Lu",
      "Rongyu Zhang",
      "Zhaoqing Wang",
      "Yandong Guo",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01231"
  },
  {
    "id": "arXiv:2212.01232",
    "title": "Loss shaping enhances exact gradient learning with EventProp in Spiking  Neural Networks",
    "abstract": "In a recent paper Wunderlich and Pehle introduced the EventProp algorithm\nthat enables training spiking neural networks by gradient descent on exact\ngradients. In this paper we present extensions of EventProp to support a wider\nclass of loss functions and an implementation in the GPU enhanced neuronal\nnetworks framework which exploits sparsity. The GPU acceleration allows us to\ntest EventProp extensively on more challenging learning benchmarks. We find\nthat EventProp performs well on some tasks but for others there are issues\nwhere learning is slow or fails entirely. Here, we analyse these issues in\ndetail and discover that they relate to the use of the exact gradient of the\nloss function, which by its nature does not provide information about loss\nchanges due to spike creation or spike deletion. Depending on the details of\nthe task and loss function, descending the exact gradient with EventProp can\nlead to the deletion of important spikes and so to an inadvertent increase of\nthe loss and decrease of classification accuracy and hence a failure to learn.\nIn other situations the lack of knowledge about the benefits of creating\nadditional spikes can lead to a lack of gradient flow into earlier layers,\nslowing down learning. We eventually present a first glimpse of a solution to\nthese problems in the form of `loss shaping', where we introduce a suitable\nweighting function into an integral loss to increase gradient flow from the\noutput layer towards earlier layers.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Thomas Nowotny",
      "James P. Turner",
      "James C. Knight"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01232"
  },
  {
    "id": "arXiv:2212.01233",
    "title": "Safe machine learning model release from Trusted Research Environments:  The AI-SDC package",
    "abstract": "We present AI-SDC, an integrated suite of open source Python tools to\nfacilitate Statistical Disclosure Control (SDC) of Machine Learning (ML) models\ntrained on confidential data prior to public release. AI-SDC combines (i) a\nSafeModel package that extends commonly used ML models to provide ante-hoc SDC\nby assessing the vulnerability of disclosure posed by the training regime; and\n(ii) an Attacks package that provides post-hoc SDC by rigorously assessing the\nempirical disclosure risk of a model through a variety of simulated attacks\nafter training. The AI-SDC code and documentation are available under an MIT\nlicense at https://github.com/AI-SDC/AI-SDC.",
    "descriptor": "",
    "authors": [
      "Jim Smith",
      "Richard Preen",
      "Andrew McCarthy",
      "Alba Crespi Boixander",
      "James Liley",
      "Simon Rogers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.01233"
  },
  {
    "id": "arXiv:2212.01237",
    "title": "The Bumpy Road of Taking Automated Debugging to Industry",
    "abstract": "Debugging is arguably among the most difficult and extremely time consuming\ntasks of the software development life cycle. Therefore, it comes as no\nsurprise that researchers have invested a considerable amount of effort in\ndeveloping automated techniques and tools to support developers excel in these\ntasks. Despite the significant advances, including demonstrations of\nusefulness, efficacy, and efficiency, these techniques are yet to find their\nway into industrial adoption. In this paper, we reflect upon the\ncommercialization efforts of a particular automated debugging technique and lay\ndown potential reasons for lack of success stories as well as ideas to move\nforward.",
    "descriptor": "",
    "authors": [
      "Rui Abreu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.01237"
  },
  {
    "id": "arXiv:2212.01241",
    "title": "Analyzing the Hardware-Software Implications of Multi-modal DNN  Workloads using MMBench",
    "abstract": "The explosive growth of various types of big data and advances in AI\ntechnologies have catalyzed a new type of applications called multi-modal DNNs.\nMulti-modal DNNs are capable of interpreting and reasoning about information\nfrom multiple modalities, making them more applicable to real-world AI\nscenarios. In recent research, multi-modal DNNs have outperformed the best\nuni-modal DNN in a wide range of applications from traditional multimedia to\nemerging autonomous systems. However, despite their importance and superiority,\nvery limited research attention has been devoted to understand the\ncharacteristics of multi-modal DNNs and their implications on current computing\nsoftware/hardware platforms.\nTo facilitate research and advance the understanding of these multi-modal DNN\nworkloads, we first present MMbench, an open-source benchmark suite consisting\nof a set of real-world multi-modal DNN workloads with relevant performance\nmetrics for evaluation. Then we use MMbench to conduct an in-depth analysis on\nthe characteristics of multi-modal DNNs. We study their implications on\napplication and programming framework, operating and scheduling system, as well\nas execution hardware. Finally, we conduct a case study and extend our\nbenchmark to edge devices. We hope that our work can provide guidance for\nfuture software/hardware design and optimization to underpin multi-modal DNNs\non both cloud and edge computing platforms.",
    "descriptor": "",
    "authors": [
      "Xiaofeng Hou",
      "Cheng Xu",
      "Jiacheng Liu",
      "Xuehan Tang",
      "Linyu Sun",
      "Chao Li",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2212.01241"
  },
  {
    "id": "arXiv:2212.01242",
    "title": "Hybrid Tunable Magnet Actuator: Modeling and Design",
    "abstract": "Reluctance actuators are preferred for high-precision applications. Due to\nresistive losses in the coils, the accuracy of this type of actuator will\nreduce in quasi-static operation mode within a vacuum environment. By using\nsoft permanent magnets whose magnetization states are in-situ tuned, no\nconstant power is needed to create a force and thereby the resistive losses\nwill reduce. In this paper, a new tuning method is investigated in order to\nreduce the resistive losses. By using a history-dependent and non-linear\nhysteresis model, a more efficient tuning algorithm is designed. Besides this,\nthe position accuracy and control simplicity of a variable reluctance tunable\nmagnet actuator are improved by linearizing the non-linear force-flux\nrelationship. This is achieved by using bias fluxes generated by hard permanent\nmagnets.",
    "descriptor": "",
    "authors": [
      "W.B. Hoekwater",
      "J.D. Wiersema1",
      "S.H. HosseinNia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.01242"
  },
  {
    "id": "arXiv:2212.01246",
    "title": "ViTAL: Vision-Based Terrain-Aware Locomotion for Legged Robots",
    "abstract": "This work is on vision-based planning strategies for legged robots that\nseparate locomotion planning into foothold selection and pose adaptation.\nCurrent pose adaptation strategies optimize the robot's body pose relative to\ngiven footholds. If these footholds are not reached, the robot may end up in a\nstate with no reachable safe footholds. Therefore, we present a Vision-Based\nTerrain-Aware Locomotion (ViTAL) strategy that consists of novel pose\nadaptation and foothold selection algorithms. ViTAL introduces a different\nparadigm in pose adaptation that does not optimize the body pose relative to\ngiven footholds, but the body pose that maximizes the chances of the legs in\nreaching safe footholds. ViTAL plans footholds and poses based on skills that\ncharacterize the robot's capabilities and its terrain-awareness. We use the 90\nkg HyQ and 140 kg HyQReal quadruped robots to validate ViTAL, and show that\nthey are able to climb various obstacles including stairs, gaps, and rough\nterrains at different speeds and gaits. We compare ViTAL with a baseline\nstrategy that selects the robot pose based on given selected footholds, and\nshow that ViTAL outperforms the baseline.",
    "descriptor": "\nComments: IEEE Transactions on Robotics, 2022. part of dissertation arXiv:2212.00683\n",
    "authors": [
      "Shamel Fahmi",
      "Victor Barasuol",
      "Domingo Esteban",
      "Octavio Villarreal",
      "Claudio Semini"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.01246"
  },
  {
    "id": "arXiv:2212.01247",
    "title": "CC-3DT: Panoramic 3D Object Tracking via Cross-Camera Fusion",
    "abstract": "To track the 3D locations and trajectories of the other traffic participants\nat any given time, modern autonomous vehicles are equipped with multiple\ncameras that cover the vehicle's full surroundings. Yet, camera-based 3D object\ntracking methods prioritize optimizing the single-camera setup and resort to\npost-hoc fusion in a multi-camera setup. In this paper, we propose a method for\npanoramic 3D object tracking, called CC-3DT, that associates and models object\ntrajectories both temporally and across views, and improves the overall\ntracking consistency. In particular, our method fuses 3D detections from\nmultiple cameras before association, reducing identity switches significantly\nand improving motion modeling. Our experiments on large-scale driving datasets\nshow that fusion before association leads to a large margin of improvement over\npost-hoc fusion. We set a new state-of-the-art with 12.6% improvement in\naverage multi-object tracking accuracy (AMOTA) among all camera-based methods\non the competitive NuScenes 3D tracking benchmark, outperforming previously\npublished methods by 6.5% in AMOTA with the same 3D detector.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Tobias Fischer",
      "Yung-Hsu Yang",
      "Suryansh Kumar",
      "Min Sun",
      "Fisher Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01247"
  },
  {
    "id": "arXiv:2212.01248",
    "title": "Clustering -- Basic concepts and methods",
    "abstract": "We review clustering as an analysis tool and the underlying concepts from an\nintroductory perspective. What is clustering and how can clusterings be\nrealised programmatically? How can data be represented and prepared for a\nclustering task? And how can clustering results be validated?\nConnectivity-based versus prototype-based approaches are reflected in the\ncontext of several popular methods: single-linkage, spectral embedding,\nk-means, and Gaussian mixtures are discussed as well as the density-based\nprotocols (H)DBSCAN, Jarvis-Patrick, CommonNN, and density-peaks.",
    "descriptor": "\nComments: Two chapters adapted from a doctoral thesis (J.-O. Kapp-Joswig, \"Applications of Molecular Dynamics simulations for biomolecular systems and improvements to density-based clustering in the analysis\", 2022, FU Berlin), 59 pages, 30 figures\n",
    "authors": [
      "Jan-Oliver Felix Kapp-Joswig",
      "Bettina G. Keller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01248"
  },
  {
    "id": "arXiv:2212.01249",
    "title": "Adaptive Immersed Mesh Method (AIMM) for Fluid Structure Interaction",
    "abstract": "The need to simulate flexible, relatively thin structures is of growing\ninterest with applications ranging from thin cylindrical sensors to membrane\nlike structures. These structures usually interact with their surroundings to\naccumulate data, or for a specific purpose. The inevitable interaction between\nthe surrounding fluid and the solid is solved using a novel Fluid Structure\nInteraction (FSI) coupling scheme. This paper proposes a novel way to model the\ninteraction between fluid and solid. It consists of a hybrid methods that\ncombines both the traditional monolithic and partitioned approaches for Fluid\nStructure Interaction (FSI). The solid mesh is immersed in a fluid solid mesh\nat each time iteration, whilst having its own independent Lagrangian\nhyperelastic solver. The Eulerian mesh contains both the fluid and solid, and\naccommodate additional physical phenomena. Anisotropic mesh adaptation and the\nLevel-Set methods are used for the interface coupling between the solid and\nfluid to better capture the interaction between them. All of the above\ncomponents form the Adaptive Immersed Mesh Method (AIMM). The Variational\nMulti-Scale (VMS) method is used for both solvers to damp out any spurious\noscillations that may arise for piece wise linear tetrahedral elements. The\nframework is constructed in 3D with parallel computing in mind. Various 2D\nnumerical problems are investigated to evaluate the accuracy, robustness, and\ncapabilities of our method. Different three dimensional test cases are\npresented and are compared to experimental results as well.",
    "descriptor": "",
    "authors": [
      "R. Nemer",
      "A. Larcher",
      "E. Hachem"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2212.01249"
  },
  {
    "id": "arXiv:2212.01254",
    "title": "Deep-Learning-based Vulnerability Detection in Binary Executables",
    "abstract": "The identification of vulnerabilities is an important element in the software\ndevelopment life cycle to ensure the security of software. While vulnerability\nidentification based on the source code is a well studied field, the\nidentification of vulnerabilities on basis of a binary executable without the\ncorresponding source code is more challenging. Recent research [1] has shown,\nhow such detection can be achieved by deep learning methods. However, that\nparticular approach is limited to the identification of only 4 types of\nvulnerabilities. Subsequently, we analyze to what extent we could cover the\nidentification of a larger variety of vulnerabilities. Therefore, a supervised\ndeep learning approach using recurrent neural networks for the application of\nvulnerability detection based on binary executables is used. The underlying\nbasis is a dataset with 50,651 samples of vulnerable code in the form of a\nstandardized LLVM Intermediate Representation. The vectorised features of a\nWord2Vec model are used to train different variations of three basic\narchitectures of recurrent neural networks (GRU, LSTM, SRNN). A binary\nclassification was established for detecting the presence of an arbitrary\nvulnerability, and a multi-class model was trained for the identification of\nthe exact vulnerability, which achieved an out-of-sample accuracy of 88% and\n77%, respectively. Differences in the detection of different vulnerabilities\nwere also observed, with non-vulnerable samples being detected with a\nparticularly high precision of over 98%. Thus, the methodology presented allows\nan accurate detection of 23 (compared to 4 [1]) vulnerabilities.",
    "descriptor": "",
    "authors": [
      "Andreas Schaad",
      "Dominik Binder"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01254"
  },
  {
    "id": "arXiv:2212.01256",
    "title": "Shaping Nonlinearity in Reset Controllers for Precision Motion Systems",
    "abstract": "The precision motion industry has an ever-increasing demand for faster, more\nprecise and more robust controllers. From the perspective of frequency domain\nand loopshaping technique, this demand has pushed the linear controllers to\ntheir inherent limits, namely, the waterbed effect and Bode's phase-gain\nrelationship. Mathematically, complex-order transfer functions are not bound by\nBode's phase-gain relationship. However, implementing them in practice is a\nchallenge to be solved. This extended abstract will show review the previous\nwork of the authors in shaping nonlinearities in reset controllers and\ncontribute and propose an overall architecture for reset control systems to\napproximate complex order controllers.",
    "descriptor": "",
    "authors": [
      "Nima Karbasizadeh",
      "S. Hassan HosseinNia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.01256"
  },
  {
    "id": "arXiv:2212.01260",
    "title": "SolarDK: A high-resolution urban solar panel image classification and  localization dataset",
    "abstract": "The body of research on classification of solar panel arrays from aerial\nimagery is increasing, yet there are still not many public benchmark datasets.\nThis paper introduces two novel benchmark datasets for classifying and\nlocalizing solar panel arrays in Denmark: A human annotated dataset for\nclassification and segmentation, as well as a classification dataset acquired\nusing self-reported data from the Danish national building registry. We explore\nthe performance of prior works on the new benchmark dataset, and present\nresults after fine-tuning models using a similar approach as recent works.\nFurthermore, we train models of newer architectures and provide benchmark\nbaselines to our datasets in several scenarios. We believe the release of these\ndatasets may improve future research in both local and global geospatial\ndomains for identifying and mapping of solar panel arrays from aerial imagery.\nThe data is accessible at https://osf.io/aj539/.",
    "descriptor": "\nComments: 7 pages, 2 figures, to access the dataset, see this https URL\n",
    "authors": [
      "Maxim Khomiakov",
      "Julius Holbech Radzikowski",
      "Carl Anton Schmidt",
      "Mathias Bonde S\u00f8rensen",
      "Mads Andersen",
      "Michael Riis Andersen",
      "Jes Frellsen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01260"
  },
  {
    "id": "arXiv:2212.01261",
    "title": "Generative Reasoning Integrated Label Noise Robust Deep Image  Representation Learning in Remote Sensing",
    "abstract": "The development of deep learning based image representation learning (IRL)\nmethods has attracted great attention in the context of remote sensing (RS)\nimage understanding. Most of these methods require the availability of a high\nquantity and quality of annotated training images, which can be time-consuming\nand costly to gather. To reduce labeling costs, publicly available thematic\nmaps, automatic labeling procedures or crowdsourced data can be used. However,\nsuch approaches increase the risk of including label noise in training data. It\nmay result in overfitting on noisy labels when discriminative reasoning is\nemployed as in most of the existing methods. This leads to sub-optimal learning\nprocedures, and thus inaccurate characterization of RS images. In this paper,\nas a first time in RS, we introduce a generative reasoning integrated label\nnoise robust representation learning (GRID) approach. GRID aims to model the\ncomplementary characteristics of discriminative and generative reasoning for\nIRL under noisy labels. To this end, we first integrate generative reasoning\ninto discriminative reasoning through a variational autoencoder. This allows\nour approach to automatically detect training samples with noisy labels. Then,\nthrough our label noise robust hybrid representation learning strategy, GRID\nadjusts the whole learning procedure for IRL of these samples through\ngenerative reasoning and that of the other samples through discriminative\nreasoning. Our approach learns discriminative image representations while\npreventing interference of noisy labels during training independently from the\nIRL method. Thus, unlike the existing methods, GRID does not depend on the type\nof annotation, label noise, neural network, loss or learning task, and thus can\nbe utilized for various RS image understanding problems. Experimental results\nshow the effectiveness of GRID compared to state-of-the-art methods.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Gencer Sumbul",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01261"
  },
  {
    "id": "arXiv:2212.01265",
    "title": "Denoising Deep Generative Models",
    "abstract": "Likelihood-based deep generative models have recently been shown to exhibit\npathological behaviour under the manifold hypothesis as a consequence of using\nhigh-dimensional densities to model data with low-dimensional structure. In\nthis paper we propose two methodologies aimed at addressing this problem. Both\nare based on adding Gaussian noise to the data to remove the dimensionality\nmismatch during training, and both provide a denoising mechanism whose goal is\nto sample from the model as though no noise had been added to the data. Our\nfirst approach is based on Tweedie's formula, and the second on models which\ntake the variance of added noise as a conditional input. We show that\nsurprisingly, while well motivated, these approaches only sporadically improve\nperformance over not adding noise, and that other methods of addressing the\ndimensionality mismatch are more empirically adequate.",
    "descriptor": "\nComments: NeurIPS 2022 ICBINB workshop (spotlight)\n",
    "authors": [
      "Gabriel Loaiza-Ganem",
      "Brendan Leigh Ross",
      "Luhuan Wu",
      "John P. Cunningham",
      "Jesse C. Cresswell",
      "Anthony L. Caterini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01265"
  },
  {
    "id": "arXiv:2212.01274",
    "title": "OOG- Optuna Optimized GAN Sampling Technique for Tabular Imbalanced  Malware Data",
    "abstract": "Cyberspace occupies a large portion of people's life in the age of modern\ntechnology, and while there are those who utilize it for good, there are also\nthose who do not. Malware is an application whose construction was not\nmotivated by a benign goal and it can harm, steal, or even alter personal\ninformation and secure applications and software. Thus, there are numerous\ntechniques to avoid malware, one of which is to develop samples of malware so\nthat the system can be updated with the growing number of malwares, allowing it\nto recognize when malwares attempt to enter. The Generative Adversarial Network\n(GAN) sampling technique has been used in this study to generate new malware\nsamples. GANs have multiple variants, and in order to determine which variant\nis optimal for a given dataset sample, their parameters must be modified. This\nstudy employs Optuna, an autonomous hyperparameter tuning algorithm, to\ndetermine the optimal settings for the dataset under consideration. In this\nstudy, the architecture of the Optuna Optimized GAN (OOG) method is shown,\nalong with scores of 98.06%, 99.00%, 97.23%, and 98.04% for accuracy,\nprecision, recall and f1 score respectively. After tweaking the hyperparameters\nof five supervised boosting algorithms, XGBoost, LightGBM, CatBoost, Extra\nTrees Classifier, and Gradient Boosting Classifier, the methodology of this\npaper additionally employs the weighted ensemble technique to acquire this\nresult. In addition to comparing existing efforts in this domain, the study\ndemonstrates how promising GAN is in comparison to other sampling techniques\nsuch as SMOTE.",
    "descriptor": "\nComments: Accepted for publication at 2022 IEEE International Conference on Big Data (IEEE BigData 2022)\n",
    "authors": [
      "S.M Towhidul Islam Tonmoy",
      "S.M Mehedi Zaman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01274"
  },
  {
    "id": "arXiv:2212.01279",
    "title": "Initial Results for Pairwise Causal Discovery Using Quantitative  Information Flow",
    "abstract": "Pairwise Causal Discovery is the task of determining causal, anticausal,\nconfounded or independence relationships from pairs of variables. Over the last\nfew years, this challenging task has promoted not only the discovery of novel\nmachine learning models aimed at solving the task, but also discussions on how\nlearning the causal direction of variables may benefit machine learning\noverall. In this paper, we show that Quantitative Information Flow (QIF), a\nmeasure usually employed for measuring leakages of information from a system to\nan attacker, shows promising results as features for the task. In particular,\nexperiments with real-world datasets indicate that QIF is statistically tied to\nthe state of the art. Our initial results motivate further inquiries on how QIF\nrelates to causality and what are its limitations.",
    "descriptor": "",
    "authors": [
      "Felipe Giori",
      "Flavio Figueiredo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.01279"
  },
  {
    "id": "arXiv:2212.01287",
    "title": "SARAS-Net: Scale and Relation Aware Siamese Network for Change Detection",
    "abstract": "Change detection (CD) aims to find the difference between two images at\ndifferent times and outputs a change map to represent whether the region has\nchanged or not. To achieve a better result in generating the change map, many\nState-of-The-Art (SoTA) methods design a deep learning model that has a\npowerful discriminative ability. However, these methods still get lower\nperformance because they ignore spatial information and scaling changes between\nobjects, giving rise to blurry or wrong boundaries. In addition to these, they\nalso neglect the interactive information of two different images. To alleviate\nthese problems, we propose our network, the Scale and Relation-Aware Siamese\nNetwork (SARAS-Net) to deal with this issue. In this paper, three modules are\nproposed that include relation-aware, scale-aware, and cross-transformer to\ntackle the problem of scene change detection more effectively. To verify our\nmodel, we tested three public datasets, including LEVIR-CD, WHU-CD, and DSFIN,\nand obtained SoTA accuracy. Our code is available at\nhttps://github.com/f64051041/SARAS-Net.",
    "descriptor": "",
    "authors": [
      "Chao-Peng Chen",
      "Jun-Wei Hsieh",
      "Ping-Yang Chen",
      "Yi-Kuan Hsieh",
      "Bor-Shiun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01287"
  },
  {
    "id": "arXiv:2212.01298",
    "title": "5G-NIDD: A Comprehensive Network Intrusion Detection Dataset Generated  over 5G Wireless Network",
    "abstract": "With a plethora of new connections, features, and services introduced, the\n5th generation (5G) wireless technology reflects the development of mobile\ncommunication networks and is here to stay for the next decade. The multitude\nof services and technologies that 5G incorporates have made modern\ncommunication networks very complex and sophisticated in nature. This\ncomplexity along with the incorporation of Machine Learning (ML) and Artificial\nIntelligence (AI) provides the opportunity for the attackers to launch\nintelligent attacks against the network and network devices. These attacks\noften traverse undetected due to the lack of intelligent security mechanisms to\ncounter these threats. Therefore, the implementation of real-time, proactive,\nand self-adaptive security mechanisms throughout the network would be an\nintegral part of 5G as well as future communication systems. Therefore, large\namounts of data collected from real networks will play an important role in the\ntraining of AI/ML models to identify and detect malicious content in network\ntraffic. This work presents 5G-NIDD, a fully labeled dataset built on a\nfunctional 5G test network that can be used by those who develop and test AI/ML\nsolutions. The work further analyses the collected data using common ML models\nand shows the achieved accuracy levels.",
    "descriptor": "\nComments: Link to the Dataset this http URL\n",
    "authors": [
      "Sehan Samarakoon",
      "Yushan Siriwardhana",
      "Pawani Porambage",
      "Madhusanka Liyanage",
      "Sang-Yoon Chang",
      "Jinoh Kim",
      "Jonghyun Kim",
      "Mika Ylianttila"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.01298"
  },
  {
    "id": "arXiv:2212.01301",
    "title": "Semilinearity of Families of Languages",
    "abstract": "Techniques are developed for creating new and general language families of\nonly semilinear languages, and for showing families only contain semilinear\nlanguages. It is shown that for language families L that are semilinear full\ntrios, the smallest full AFL containing L that is also closed under\nintersection with languages in NCM (where NCM is the family of languages\naccepted by NFAs augmented with reversal-bounded counters), is also semilinear.\nIf these closure properties are effective, this also immediately implies\ndecidability of membership, emptiness, and infiniteness for these general\nfamilies. From the general techniques, new grammar systems are given that are\nextensions of well-known families of semilinear full trios, whereby it is\nimplied that these extensions must only describe semilinear languages. This\nalso implies positive decidability properties for the new systems. Some\ncharacterizations of the new families are also given.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Oscar H. Ibarra",
      "Ian McQuillan"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2212.01301"
  },
  {
    "id": "arXiv:2212.01302",
    "title": "DeepFT: Fault-Tolerant Edge Computing using a Self-Supervised Deep  Surrogate Model",
    "abstract": "The emergence of latency-critical AI applications has been supported by the\nevolution of the edge computing paradigm. However, edge solutions are typically\nresource-constrained, posing reliability challenges due to heightened\ncontention for compute and communication capacities and faulty application\nbehavior in the presence of overload conditions. Although a large amount of\ngenerated log data can be mined for fault prediction, labeling this data for\ntraining is a manual process and thus a limiting factor for automation. Due to\nthis, many companies resort to unsupervised fault-tolerance models. Yet,\nfailure models of this kind can incur a loss of accuracy when they need to\nadapt to non-stationary workloads and diverse host characteristics. To cope\nwith this, we propose a novel modeling approach, called DeepFT, to proactively\navoid system overloads and their adverse effects by optimizing the task\nscheduling and migration decisions. DeepFT uses a deep surrogate model to\naccurately predict and diagnose faults in the system and co-simulation based\nself-supervised learning to dynamically adapt the model in volatile settings.\nIt offers a highly scalable solution as the model size scales by only 3 and 1\npercent per unit increase in the number of active tasks and hosts. Extensive\nexperimentation on a Raspberry-Pi based edge cluster with DeFog benchmarks\nshows that DeepFT can outperform state-of-the-art baseline methods in\nfault-detection and QoS metrics. Specifically, DeepFT gives the highest F1\nscores for fault-detection, reducing service deadline violations by up to 37\\%\nwhile also improving response time by up to 9%.",
    "descriptor": "\nComments: Accepted in IEEE INFOCOM 2023\n",
    "authors": [
      "Shreshth Tuli",
      "Giuliano Casale",
      "Ludmila Cherkasova",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01302"
  },
  {
    "id": "arXiv:2212.01303",
    "title": "Selecting Mechanical Parameters of a Monopode Jumping System with  Reinforcement Learning",
    "abstract": "Legged systems have many advantages when compared to their wheeled\ncounterparts. For example, they can more easily navigate extreme, uneven\nterrain. However, there are disadvantages as well, particularly the difficulty\nseen in modeling the nonlinearities of the system. Research has shown that\nusing flexible components within legged locomotive systems improves performance\nmeasures such as efficiency and running velocity. Because of the difficulties\nencountered in modeling flexible systems, control methods such as reinforcement\nlearning can be used to define control strategies. Furthermore, reinforcement\nlearning can be tasked with learning mechanical parameters of a system to match\na control input. It is shown in this work that when deploying reinforcement\nlearning to find design parameters for a pogo-stick jumping system, the designs\nthe agents learn are optimal within the design space provided to the agents.",
    "descriptor": "",
    "authors": [
      "Andrew Albright",
      "Joshua Vaughan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01303"
  },
  {
    "id": "arXiv:2212.01304",
    "title": "Subword-Delimited Downsampling for Better Character-Level Translation",
    "abstract": "Subword-level models have been the dominant paradigm in NLP. However,\ncharacter-level models have the benefit of seeing each character individually,\nproviding the model with more detailed information that ultimately could lead\nto better models. Recent works have shown character-level models to be\ncompetitive with subword models, but costly in terms of time and computation.\nCharacter-level models with a downsampling component alleviate this, but at the\ncost of quality, particularly for machine translation. This work analyzes the\nproblems of previous downsampling methods and introduces a novel downsampling\nmethod which is informed by subwords. This new downsampling method not only\noutperforms existing downsampling methods, showing that downsampling characters\ncan be done without sacrificing quality, but also leads to promising\nperformance compared to subword models for translation.",
    "descriptor": "\nComments: This paper is a modified version of the one published in Findings of EMNLP2022, adapted to be compatible to ArXiv\n",
    "authors": [
      "Lukas Edman",
      "Antonio Toral",
      "Gertjan van Noord"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.01304"
  },
  {
    "id": "arXiv:2212.01309",
    "title": "Wigner Distribution Deconvolution Adaptation for Live Ptychography  Reconstruction",
    "abstract": "We propose a modification of Wigner Distribution Deconvolution (WDD) to\nsupport live processing ptychography. Live processing allows to reconstruct and\ndisplay the specimen transfer function gradually while diffraction patterns are\nacquired. For this purpose we reformulate WDD and apply a dimensionality\nreduction technique that reduces memory consumption and increases processing\nspeed. We show numerically that this approach maintains the reconstruction\nquality of specimen transfer functions as well as reduces computational\ncomplexity during acquisition processes. Although we only present the\nreconstruction for Scanning Transmission Electron Microscopy (STEM) datasets,\nin general, the live processing algorithm we present in this paper can be\napplied to real-time ptychographic reconstruction for different fields of\napplication.",
    "descriptor": "",
    "authors": [
      "Arya Bangun",
      "Paul F. Baumeister",
      "Alexander Clausen",
      "Dieter Weber",
      "Rafal E. Dunin-Borkowski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.01309"
  },
  {
    "id": "arXiv:2212.01310",
    "title": "Gaussian Process regression over discrete probability measures: on the  non-stationarity relation between Euclidean and Wasserstein Squared  Exponential Kernels",
    "abstract": "Gaussian Process regression is a kernel method successfully adopted in many\nreal-life applications. Recently, there is a growing interest on extending this\nmethod to non-Euclidean input spaces, like the one considered in this paper,\nconsisting of probability measures. Although a Positive Definite kernel can be\ndefined by using a suitable distance -- the Wasserstein distance -- the common\nprocedure for learning the Gaussian Process model can fail due to numerical\nissues, arising earlier and more frequently than in the case of an Euclidean\ninput space and, as demonstrated in this paper, that cannot be avoided by\nadding artificial noise (nugget effect) as usually done. This paper uncovers\nthe main reason of these issues, that is a non-stationarity relationship\nbetween the Wasserstein-based squared exponential kernel and its\nEuclidean-based counterpart. As a relevant result, the Gaussian Process model\nis learned by assuming the input space as Euclidean and then an algebraic\ntransformation, based on the uncovered relation, is used to transform it into a\nnon-stationary and Wasserstein-based Gaussian Process model over probability\nmeasures. This algebraic transformation is simpler than log-exp maps used in\nthe case of data belonging to Riemannian manifolds and recently extended to\nconsider the pseudo-Riemannian structure of an input space equipped with the\nWasserstein distance.",
    "descriptor": "",
    "authors": [
      "Antonio Candelieri",
      "Andrea Ponti",
      "Francesco Archetti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.01310"
  },
  {
    "id": "arXiv:2212.01314",
    "title": "On Solution Functions of Optimization: Universal Approximation and  Covering Number Bounds",
    "abstract": "We study the expressibility and learnability of convex optimization solution\nfunctions and their multi-layer architectural extension. The main results are:\n\\emph{(1)} the class of solution functions of linear programming (LP) and\nquadratic programming (QP) is a universal approximant for the $C^k$ smooth\nmodel class or some restricted Sobolev space, and we characterize the\nrate-distortion, \\emph{(2)} the approximation power is investigated through a\nviewpoint of regression error, where information about the target function is\nprovided in terms of data observations, \\emph{(3)} compositionality in the form\nof a deep architecture with optimization as a layer is shown to reconstruct\nsome basic functions used in numerical analysis without error, which implies\nthat \\emph{(4)} a substantial reduction in rate-distortion can be achieved with\na universal network architecture, and \\emph{(5)} we discuss the statistical\nbounds of empirical covering numbers for LP/QP, as well as a generic\noptimization problem (possibly nonconvex) by exploiting tame geometry. Our\nresults provide the \\emph{first rigorous analysis of the approximation and\nlearning-theoretic properties of solution functions} with implications for\nalgorithmic design and performance guarantees.",
    "descriptor": "",
    "authors": [
      "Ming Jin",
      "Vanshaj Khattar",
      "Harshal Kaushik",
      "Bilgehan Sel",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.01314"
  },
  {
    "id": "arXiv:2212.01321",
    "title": "Iterative Power Control for Wireless Networks with Distributed  Reconfigurable Intelligent Surfaces",
    "abstract": "Reconfigurable Intelligent Surfaces (RIS) are a new paradigm which, with\njudicious deployment and alignment, can enable more favorable propagation\nenvironments and better wireless network design. As such, they can offer a\nnumber of potential benefits for next generation wireless systems including\nimproved coverage, better interference management and even security. In this\npaper, we consider an uplink next generation wireless system where each user is\nassisted with an RIS. We study the uplink power control problem in this\ndistributed RIS-assisted wireless network. Specifically, we aim to minimize\ntotal uplink transmit power of all the users subject to each user's reliable\ncommunication requirements at the base station by a joint design of power,\nreceiver filter and RIS phase matrices. We propose an iterative power control\nalgorithm, combined with a successive convex approximation technique to solve\nthe problem with non-convex phase constraints. Numerical results illustrate\nthat distributed RIS assistance leads to uplink power savings when direct links\nare weak.",
    "descriptor": "\nComments: Accepted by IEEE GLOBECOM 2022\n",
    "authors": [
      "Jiayu Mao",
      "Aylin Yener"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.01321"
  },
  {
    "id": "arXiv:2212.01322",
    "title": "MIC: Masked Image Consistency for Context-Enhanced Domain Adaptation",
    "abstract": "In unsupervised domain adaptation (UDA), a model trained on source data (e.g.\nsynthetic) is adapted to target data (e.g. real-world) without access to target\nannotation. Most previous UDA methods struggle with classes that have a similar\nvisual appearance on the target domain as no ground truth is available to learn\nthe slight appearance differences. To address this problem, we propose a Masked\nImage Consistency (MIC) module to enhance UDA by learning spatial context\nrelations of the target domain as additional clues for robust visual\nrecognition. MIC enforces the consistency between predictions of masked target\nimages, where random patches are withheld, and pseudo-labels that are generated\nbased on the complete image by an exponential moving average teacher. To\nminimize the consistency loss, the network has to learn to infer the\npredictions of the masked regions from their context. Due to its simple and\nuniversal concept, MIC can be integrated into various UDA methods across\ndifferent visual recognition tasks such as image classification, semantic\nsegmentation, and object detection. MIC significantly improves the\nstate-of-the-art performance across the different recognition tasks for\nsynthetic-to-real, day-to-nighttime, and clear-to-adverse-weather UDA. For\ninstance, MIC achieves an unprecedented UDA performance of 75.9 mIoU and 92.8%\non GTA-to-Cityscapes and VisDA-2017, respectively, which corresponds to an\nimprovement of +2.1 and +3.0 percent points over the previous state of the art.\nThe implementation is available at https://github.com/lhoyer/MIC.",
    "descriptor": "",
    "authors": [
      "Lukas Hoyer",
      "Dengxin Dai",
      "Haoran Wang",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01322"
  },
  {
    "id": "arXiv:2212.01325",
    "title": "Resource Allocation for Augmented Reality Empowered Vehicular Edge  Metaverse",
    "abstract": "Metaverse is considered to be the evolution of the next-generation networks,\nproviding users with experience sharing at the intersection between physical\nand digital. Augmented reality (AR) is one of the primary supporting\ntechnologies in the Metaverse, which can seamlessly integrate real-world\ninformation with virtual world information to provide users with an immersive\ninteractive experience. Extraordinarily, AR has brought new opportunities for\nassisting safe driving. Nevertheless, achieving efficient execution of AR tasks\nand increasing system revenue are the main challenges faced by the Metaverse's\nAR in-vehicle applications. In this paper, we are the first to propose an\nefficient resource allocation framework for AR-empowered vehicular edge\nMetaverse to improve system utility. We formulate an optimization problem\nfeaturing multidimensional control to concurrently maximize data utility at the\nMetaverse operator side and minimize energy consumption at the vehicles' side,\nwhich jointly considers the computational resource allocation on the Metaverse\nserver, and AR vehicles' CPU frequency, transmit power, and computation model\nsize. Notwithstanding, the major impediment is how to design an efficient\nalgorithm to obtain the solutions of the optimization. Wherefore, we do this by\ndecoupling the optimization variables. We first derive the optimal computation\nmodel size by the binary search, followed by obtaining the optimal power\nallocation by the bisection method and finding a closed-form solution to the\noptimal CPU frequency of AR vehicles, and finally, attain the optimal\nallocation of computational resource on the server by the Lagrangian dual\nmethod. To estimate the performance of our proposed scheme, we establish three\nbaseline schemes as a comparison, and simulation manifests that our proposed\nscheme balances the operator's reward and the energy consumption of vehicles.",
    "descriptor": "",
    "authors": [
      "Jie Feng",
      "Jun Zhao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.01325"
  },
  {
    "id": "arXiv:2212.01326",
    "title": "Legal Prompting: Teaching a Language Model to Think Like a Lawyer",
    "abstract": "Large language models that are capable of zero or few-shot prompting\napproaches have given rise to the new research area of prompt engineering.\nRecent advances showed that for example Chain-of-Thought (CoT) prompts can\nimprove arithmetic or common sense tasks significantly. We explore how such\napproaches fair with legal reasoning tasks and take the COLIEE entailment task\nbased on the Japanese Bar exam for testing zero-shot/few-shot and fine-tuning\napproaches. Our findings show that while CoT prompting and fine-tuning with\nexplanations approaches show improvements, the best results are produced by\nprompts that are derived from specific legal reasoning techniques such as IRAC\n(Issue, Rule, Application, Conclusion). Based on our experiments we improve the\n2021 best result from 0.7037 accuracy to 0.8148 accuracy and beat the 2022 best\nsystem of 0.6789 accuracy with an accuracy of 0.7431.",
    "descriptor": "\nComments: 12 pages, 6 figures, 4 tables. Accepted by NLLP 2022 (EMNLP workshop)\n",
    "authors": [
      "Fangyi Yu",
      "Lee Quartey",
      "Frank Schilder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01326"
  },
  {
    "id": "arXiv:2212.01331",
    "title": "Neural Radiance Fields for Manhattan Scenes with Unknown Manhattan Frame",
    "abstract": "Novel view synthesis and 3D modeling using implicit neural field\nrepresentation are shown to be very effective for calibrated multi-view\ncameras. Such representations are known to benefit from additional geometric\nand semantic supervision. Most existing methods that exploit additional\nsupervision require dense pixel-wise labels or localized scene priors. These\nmethods cannot benefit from high-level vague scene priors provided in terms of\nscenes' descriptions. In this work, we aim to leverage the geometric prior of\nManhattan scenes to improve the implicit neural radiance field representations.\nMore precisely, we assume that only the knowledge of the scene (under\ninvestigation) being Manhattan is known - with no additional information\nwhatsoever - with an unknown Manhattan coordinate frame. Such high-level prior\nis then used to self-supervise the surface normals derived explicitly in the\nimplicit neural fields. Our modeling allows us to group the derived normals,\nfollowed by exploiting their orthogonality constraints for self-supervision.\nOur exhaustive experiments on datasets of diverse indoor scenes demonstrate the\nsignificant benefit of the proposed method over the established baselines.",
    "descriptor": "",
    "authors": [
      "Nikola Popovic",
      "Danda Pani Paudel",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01331"
  },
  {
    "id": "arXiv:2212.01340",
    "title": "Moving Beyond Downstream Task Accuracy for Information Retrieval  Benchmarking",
    "abstract": "Neural information retrieval (IR) systems have progressed rapidly in recent\nyears, in large part due to the release of publicly available benchmarking\ntasks. Unfortunately, some dimensions of this progress are illusory: the\nmajority of the popular IR benchmarks today focus exclusively on downstream\ntask accuracy and thus conceal the costs incurred by systems that trade away\nefficiency for quality. Latency, hardware cost, and other efficiency\nconsiderations are paramount to the deployment of IR systems in user-facing\nsettings. We propose that IR benchmarks structure their evaluation methodology\nto include not only metrics of accuracy, but also efficiency considerations\nsuch as a query latency and the corresponding cost budget for a reproducible\nhardware setting. For the popular IR benchmarks MS MARCO and XOR-TyDi, we show\nhow the best choice of IR system varies according to how these efficiency\nconsiderations are chosen and weighed. We hope that future benchmarks will\nadopt these guidelines toward more holistic IR evaluation.",
    "descriptor": "",
    "authors": [
      "Keshav Santhanam",
      "Jon Saad-Falcon",
      "Martin Franz",
      "Omar Khattab",
      "Avirup Sil",
      "Radu Florian",
      "Md Arafat Sultan",
      "Salim Roukos",
      "Matei Zaharia",
      "Christopher Potts"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.01340"
  },
  {
    "id": "arXiv:2212.01343",
    "title": "CT-DQN: Control-Tutored Deep Reinforcement Learning",
    "abstract": "One of the major challenges in Deep Reinforcement Learning for control is the\nneed for extensive training to learn the policy. Motivated by this, we present\nthe design of the Control-Tutored Deep Q-Networks (CT-DQN) algorithm, a Deep\nReinforcement Learning algorithm that leverages a control tutor, i.e., an\nexogenous control law, to reduce learning time. The tutor can be designed using\nan approximate model of the system, without any assumption about the knowledge\nof the system's dynamics. There is no expectation that it will be able to\nachieve the control objective if used stand-alone. During learning, the tutor\noccasionally suggests an action, thus partially guiding exploration. We\nvalidate our approach on three scenarios from OpenAI Gym: the inverted\npendulum, lunar lander, and car racing. We demonstrate that CT-DQN is able to\nachieve better or equivalent data efficiency with respect to the classic\nfunction approximation solutions.",
    "descriptor": "",
    "authors": [
      "Francesco De Lellis",
      "Marco Coraggio",
      "Giovanni Russo",
      "Mirco Musolesi",
      "Mario di Bernardo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.01343"
  },
  {
    "id": "arXiv:2212.01346",
    "title": "Guaranteed Conformance of Neurosymbolic Models to Natural Constraints",
    "abstract": "Deep neural networks have emerged as the workhorse for a large section of\nrobotics and control applications, especially as models for dynamical systems.\nSuch data-driven models are in turn used for designing and verifying autonomous\nsystems. This is particularly useful in modeling medical systems where data can\nbe leveraged to individualize treatment. In safety-critical applications, it is\nimportant that the data-driven model is conformant to established knowledge\nfrom the natural sciences. Such knowledge is often available or can often be\ndistilled into a (possibly black-box) model $M$. For instance, the unicycle\nmodel for an F1 racing car. In this light, we consider the following problem -\ngiven a model $M$ and state transition dataset, we wish to best approximate the\nsystem model while being bounded distance away from $M$. We propose a method to\nguarantee this conformance. Our first step is to distill the dataset into few\nrepresentative samples called memories, using the idea of a growing neural gas.\nNext, using these memories we partition the state space into disjoint subsets\nand compute bounds that should be respected by the neural network, when the\ninput is drawn from a particular subset. This serves as a symbolic wrapper for\nguaranteed conformance. We argue theoretically that this only leads to bounded\nincrease in approximation error; which can be controlled by increasing the\nnumber of memories. We experimentally show that on three case studies (Car\nModel, Drones, and Artificial Pancreas), our constrained neurosymbolic models\nconform to specified $M$ models (each encoding various constraints) with\norder-of-magnitude improvements compared to the augmented Lagrangian and\nvanilla training methods.",
    "descriptor": "",
    "authors": [
      "Kaustubh Sridhar",
      "Souradeep Dutta",
      "James Weimer",
      "Insup Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.01346"
  },
  {
    "id": "arXiv:2212.01348",
    "title": "Predict-and-Critic: Accelerated End-to-End Predictive Control for Cloud  Computing through Reinforcement Learning",
    "abstract": "Cloud computing holds the promise of reduced costs through economies of\nscale. To realize this promise, cloud computing vendors typically solve\nsequential resource allocation problems, where customer workloads are packed on\nshared hardware. Virtual machines (VM) form the foundation of modern cloud\ncomputing as they help logically abstract user compute from shared physical\ninfrastructure. Traditionally, VM packing problems are solved by predicting\ndemand, followed by a Model Predictive Control (MPC) optimization over a future\nhorizon. We introduce an approximate formulation of an industrial VM packing\nproblem as an MILP with soft-constraints parameterized by the predictions.\nRecently, predict-and-optimize (PnO) was proposed for end-to-end training of\nprediction models by back-propagating the cost of decisions through the\noptimization problem. But, PnO is unable to scale to the large prediction\nhorizons prevalent in cloud computing. To tackle this issue, we propose the\nPredict-and-Critic (PnC) framework that outperforms PnO with just a two-step\nhorizon by leveraging reinforcement learning. PnC jointly trains a prediction\nmodel and a terminal Q function that approximates cost-to-go over a long\nhorizon, by back-propagating the cost of decisions through the optimization\nproblem \\emph{and from the future}. The terminal Q function allows us to solve\na much smaller two-step horizon optimization problem than the multi-step\nhorizon necessary in PnO. We evaluate PnO and the PnC framework on two\ndatasets, three workloads, and with disturbances not modeled in the\noptimization problem. We find that PnC significantly improves decision quality\nover PnO, even when the optimization problem is not a perfect representation of\nreality. We also find that hardening the soft constraints of the MILP and\nback-propagating through the constraints improves decision quality for both PnO\nand PnC.",
    "descriptor": "",
    "authors": [
      "Kaustubh Sridhar",
      "Vikramank Singh",
      "Balakrishnan Narayanaswamy",
      "Abishek Sankararaman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01348"
  },
  {
    "id": "arXiv:2212.01349",
    "title": "Nonparametric Masked Language Modeling",
    "abstract": "Existing language models (LMs) predict tokens with a softmax over a finite\nvocabulary, which can make it difficult to predict rare tokens or phrases. We\nintroduce NPM, the first nonparametric masked language model that replaces this\nsoftmax with a nonparametric distribution over every phrase in a reference\ncorpus. We show that NPM can be efficiently trained with a contrastive\nobjective and an in-batch approximation to full corpus retrieval. Zero-shot\nevaluation on 9 closed-set tasks and 7 open-set tasks demonstrates that NPM\noutperforms significantly larger parametric models, either with or without a\nretrieve-and-generate approach. It is particularly better on dealing with rare\npatterns (word senses or facts), and predicting rare or nearly unseen words\n(e.g., non-Latin script). We release the model and code at\ngithub.com/facebookresearch/NPM.",
    "descriptor": "\nComments: 23 pages; 8 figures. Code available at this https URL\n",
    "authors": [
      "Sewon Min",
      "Weijia Shi",
      "Mike Lewis",
      "Xilun Chen",
      "Wen-tau Yih",
      "Hannaneh Hajishirzi",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01349"
  },
  {
    "id": "arXiv:2212.01350",
    "title": "Improving Iterative Text Revision by Learning Where to Edit from Other  Revision Tasks",
    "abstract": "Iterative text revision improves text quality by fixing grammatical errors,\nrephrasing for better readability or contextual appropriateness, or\nreorganizing sentence structures throughout a document. Most recent research\nhas focused on understanding and classifying different types of edits in the\niterative revision process from human-written text instead of building accurate\nand robust systems for iterative text revision. In this work, we aim to build\nan end-to-end text revision system that can iteratively generate helpful edits\nby explicitly detecting editable spans (where-to-edit) with their corresponding\nedit intents and then instructing a revision model to revise the detected edit\nspans. Leveraging datasets from other related text editing NLP tasks, combined\nwith the specification of editable spans, leads our system to more accurately\nmodel the process of iterative text refinement, as evidenced by empirical\nresults and human evaluations. Our system significantly outperforms previous\nbaselines on our text revision tasks and other standard text revision tasks,\nincluding grammatical error correction, text simplification, sentence fusion,\nand style transfer. Through extensive qualitative and quantitative analysis, we\nmake vital connections between edit intentions and writing quality, and better\ncomputational modeling of iterative text revisions.",
    "descriptor": "\nComments: 14 pages, accepted at EMNLP 2022 conference as a full paper\n",
    "authors": [
      "Zae Myung Kim",
      "Wanyu Du",
      "Vipul Raheja",
      "Dhruv Kumar",
      "Dongyeop Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.01350"
  },
  {
    "id": "arXiv:2212.01353",
    "title": "Video-based Pose-Estimation Data as Source for Transfer Learning in  Human Activity Recognition",
    "abstract": "Human Activity Recognition (HAR) using on-body devices identifies specific\nhuman actions in unconstrained environments. HAR is challenging due to the\ninter and intra-variance of human movements; moreover, annotated datasets from\non-body devices are scarce. This problem is mainly due to the difficulty of\ndata creation, i.e., recording, expensive annotation, and lack of standard\ndefinitions of human activities. Previous works demonstrated that transfer\nlearning is a good strategy for addressing scenarios with scarce data. However,\nthe scarcity of annotated on-body device datasets remains. This paper proposes\nusing datasets intended for human-pose estimation as a source for transfer\nlearning; specifically, it deploys sequences of annotated pixel coordinates of\nhuman joints from video datasets for HAR and human pose estimation. We\npre-train a deep architecture on four benchmark video-based source datasets.\nFinally, an evaluation is carried out on three on-body device datasets\nimproving HAR performance.",
    "descriptor": "\nComments: Accepted for ICPR 2022\n",
    "authors": [
      "Shrutarv Awasthi",
      "Fernando Moya Rueda",
      "Gernot A. Fink"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01353"
  },
  {
    "id": "arXiv:2212.01354",
    "title": "Designing Ecosystems of Intelligence from First Principles",
    "abstract": "This white paper lays out a vision of research and development in the field\nof artificial intelligence for the next decade (and beyond). Its denouement is\na cyber-physical ecosystem of natural and synthetic sense-making, in which\nhumans are integral participants$\\unicode{x2014}$what we call ''shared\nintelligence''. This vision is premised on active inference, a formulation of\nadaptive behavior that can be read as a physics of intelligence, and which\ninherits from the physics of self-organization. In this context, we understand\nintelligence as the capacity to accumulate evidence for a generative model of\none's sensed world$\\unicode{x2014}$also known as self-evidencing. Formally,\nthis corresponds to maximizing (Bayesian) model evidence, via belief updating\nover several scales: i.e., inference, learning, and model selection.\nOperationally, this self-evidencing can be realized via (variational) message\npassing or belief propagation on a factor graph. Crucially, active inference\nforegrounds an existential imperative of intelligent systems; namely, curiosity\nor the resolution of uncertainty. This same imperative underwrites belief\nsharing in ensembles of agents, in which certain aspects (i.e., factors) of\neach agent's generative world model provide a common ground or frame of\nreference. Active inference plays a foundational role in this ecology of belief\nsharing$\\unicode{x2014}$leading to a formal account of collective intelligence\nthat rests on shared narratives and goals. We also consider the kinds of\ncommunication protocols that must be developed to enable such an ecosystem of\nintelligences and motivate the development of a shared hyper-spatial modeling\nlanguage and transaction protocol, as a first$\\unicode{x2014}$and\nkey$\\unicode{x2014}$step towards such an ecology.",
    "descriptor": "\nComments: 21+18 pages, one figure, one appendix\n",
    "authors": [
      "Karl J Friston",
      "Maxwell J D Ramstead",
      "Alex B Kiefer",
      "Alexander Tschantz",
      "Christopher L Buckley",
      "Mahault Albarracin",
      "Riddhi J Pitliya",
      "Conor Heins",
      "Brennan Klein",
      "Beren Millidge",
      "Dalton A R Sakthivadivel",
      "Toby St Clere Smithe",
      "Magnus Koudahl",
      "Safae Essafi Tremblay",
      "Capm Petersen",
      "Kaiser Fung",
      "Jason G Fox",
      "Steven Swanson",
      "Dan Mapes",
      "Gabriel Ren\u00e9"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2212.01354"
  },
  {
    "id": "arXiv:2212.01356",
    "title": "Sequential Anomaly Detection Against Demodulation Reference Signal  Spoofing in 5G NR",
    "abstract": "In fifth generation (5G) new radio (NR), the demodulation reference signal\n(DMRS) is employed for channel estimation as part of coherent demodulation of\nthe physical uplink shared channel. However, DMRS spoofing poses a serious\nthreat to 5G NR since inaccurate channel estimation will severely degrade the\ndecoding performance. In this correspondence, we propose to exploit the spatial\nsparsity structure of the channel to detect the DMRS spoofing, which is\nmotivated by the fact that the spatial sparsity structure of the channel will\nbe significantly impacted if the DMRS spoofing happens. We first extract the\nspatial sparsity structure of the channel by solving a sparse feature retrieval\nproblem, then propose a sequential sparsity structure anomaly detection method\nto detect DMRS spoofing. In simulation experiments, we exploit clustered delay\nline based channel model from 3GPP standards for verifications. Numerical\nresults show that our method outperforms both the subspace dimension based and\nenergy detector based methods.",
    "descriptor": "",
    "authors": [
      "Shao-Di Wang",
      "Hui-Ming Wang",
      "Chen Feng",
      "Victor C. M. Leung"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.01356"
  },
  {
    "id": "arXiv:2212.01362",
    "title": "Fast Detection of Burst Jamming for Delay-Sensitive Internet-of-Things  Applications",
    "abstract": "In this paper, we investigate the design of a burst jamming detection method\nfor delay-sensitive Internet-of-Things (IoT) applications. In order to obtain a\ntimely detection of burst jamming, we propose an online principal direction\nanomaly detection (OPDAD) method. We consider the one-ring scatter channel\nmodel, where the base station equipped with a large number of antennas is\nelevated at a high altitude. In this case, since the angular spread of the\nlegitimate IoT transmitter or the jammer is restricted within a narrow region,\nthere is a distinct difference of the principal direction of the signal space\nbetween the jamming attack and the normal state. Unlike existing statistical\nfeatures based batching methods, the proposed OPDAD method adopts an online\niterative processing mode, which can quickly detect the exact attack time block\ninstance by analyzing the newly coming signal. In addition, our detection\nmethod does not rely on the prior knowledge of the attacker, because it only\ncares the abrupt change in the principal direction of the signal space.\nMoreover, based on the high spatial resolution and the narrow angular spread,\nwe provide the convergence rate estimate and derive a nearly optimal finite\nsample error bound for the proposed OPDAD method. Numerical results show the\nexcellent real time capability and detection performance of our proposed\nmethod.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1603.05305 by other authors\n",
    "authors": [
      "Shao-Di Wang",
      "Hui-Ming Wang",
      "Peng Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.01362"
  },
  {
    "id": "arXiv:2212.01365",
    "title": "An Information-Theoretic Analysis of Compute-Optimal Neural Scaling Laws",
    "abstract": "We study the compute-optimal trade-off between model and training data set\nsizes for large neural networks. Our result suggests a linear relation similar\nto that supported by the empirical analysis of Chinchilla. While that work\nstudies transformer-based large language models trained on the MassiveText\ncorpus (gopher), as a starting point for development of a mathematical theory,\nwe focus on a simpler learning model and data generating process, each based on\na neural network with a sigmoidal output unit and single hidden layer of ReLU\nactivation units. We establish an upper bound on the minimal\ninformation-theoretically achievable expected error as a function of model and\ndata set sizes. We then derive allocations of computation that minimize this\nbound. We present empirical results which suggest that this approximation\ncorrectly identifies an asymptotic linear compute-optimal scaling. This\napproximation can also generate new insights. Among other things, it suggests\nthat, as the input space dimension or latent space complexity grows, as might\nbe the case for example if a longer history of tokens is taken as input to a\nlanguage model, a larger fraction of the compute budget should be allocated to\ngrowing the learning model rather than training data set.",
    "descriptor": "",
    "authors": [
      "Hong Jun Jeon",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01365"
  },
  {
    "id": "arXiv:2212.01368",
    "title": "Fast Non-Rigid Radiance Fields from Monocularized Data",
    "abstract": "3D reconstruction and novel view synthesis of dynamic scenes from collections\nof single views recently gained increased attention. Existing work shows\nimpressive results for synthetic setups and forward-facing real-world data, but\nis severely limited in the training speed and angular range for generating\nnovel views. This paper addresses these limitations and proposes a new method\nfor full 360{\\deg} novel view synthesis of non-rigidly deforming scenes. At the\ncore of our method are: 1) An efficient deformation module that decouples the\nprocessing of spatial and temporal information for acceleration at training and\ninference time; and 2) A static module representing the canonical scene as a\nfast hash-encoded neural radiance field. We evaluate the proposed approach on\nthe established synthetic D-NeRF benchmark, that enables efficient\nreconstruction from a single monocular view per time-frame randomly sampled\nfrom a full hemisphere. We refer to this form of inputs as monocularized data.\nTo prove its practicality for real-world scenarios, we recorded twelve\nchallenging sequences with human actors by sampling single frames from a\nsynchronized multi-view rig. In both cases, our method is trained significantly\nfaster than previous methods (minutes instead of days) while achieving higher\nvisual accuracy for generated novel views. Our source code and data is\navailable at our project page\nhttps://graphics.tu-bs.de/publications/kappel2022fast.",
    "descriptor": "\nComments: 17 pages, 12 figures; project page: this https URL\n",
    "authors": [
      "Moritz Kappel",
      "Vladislav Golyanik",
      "Susana Castillo",
      "Christian Theobalt",
      "Marcus Magnor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01368"
  },
  {
    "id": "arXiv:2212.01371",
    "title": "Adaptive Robust Model Predictive Control via Uncertainty Cancellation",
    "abstract": "We propose a learning-based robust predictive control algorithm that\ncompensates for significant uncertainty in the dynamics for a class of\ndiscrete-time systems that are nominally linear with an additive nonlinear\ncomponent. Such systems commonly model the nonlinear effects of an unknown\nenvironment on a nominal system. We optimize over a class of nonlinear feedback\npolicies inspired by certainty equivalent \"estimate-and-cancel\" control laws\npioneered in classical adaptive control to achieve significant performance\nimprovements in the presence of uncertainties of large magnitude, a setting in\nwhich existing learning-based predictive control algorithms often struggle to\nguarantee safety. In contrast to previous work in robust adaptive MPC, our\napproach allows us to take advantage of structure (i.e., the numerical\npredictions) in the a priori unknown dynamics learned online through function\napproximation. Our approach also extends typical nonlinear adaptive control\nmethods to systems with state and input constraints even when we cannot\ndirectly cancel the additive uncertain function from the dynamics. We apply\ncontemporary statistical estimation techniques to certify the system's safety\nthrough persistent constraint satisfaction with high probability. Moreover, we\npropose using Bayesian meta-learning algorithms that learn calibrated model\npriors to help satisfy the assumptions of the control design in challenging\nsettings. Finally, we show in simulation that our method can accommodate more\nsignificant unknown dynamics terms than existing methods and that the use of\nBayesian meta-learning allows us to adapt to the test environments more\nrapidly.",
    "descriptor": "\nComments: Under review for the IEEE Transaction on Automatic Control, special issue on learning and control. arXiv admin note: text overlap with arXiv:2104.08261\n",
    "authors": [
      "Rohan Sinha",
      "James Harrison",
      "Spencer M. Richards",
      "Marco Pavone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.01371"
  },
  {
    "id": "arXiv:2212.01372",
    "title": "Bitcoin Security-Latency Under Network Delay",
    "abstract": "We improve security-latency bounds of Nakamoto consensus by analyzing the\nrace between adversarial and honest chains in three different phases:\npre-mining, confirmation and post-confirmation. We find the probability\ndistribution of the length of the adversarial chain and the rigged adversarial\nchain under jumper models during the confirmation interval. We analyze certain\nproperties of this race to model pre-mining and post-confirmation phases with\nrandom walks that provide tighter bounds than existing results. Combining all\nthree phases provides novel upper and lower bounds for blockchains with small\n$\\lambda\\Delta$.",
    "descriptor": "",
    "authors": [
      "Mustafa Doger",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.01372"
  },
  {
    "id": "arXiv:2212.01375",
    "title": "Embedding Synthetic Off-Policy Experience for Autonomous Driving via  Zero-Shot Curricula",
    "abstract": "ML-based motion planning is a promising approach to produce agents that\nexhibit complex behaviors, and automatically adapt to novel environments. In\nthe context of autonomous driving, it is common to treat all available training\ndata equally. However, this approach produces agents that do not perform\nrobustly in safety-critical settings, an issue that cannot be addressed by\nsimply adding more data to the training set - we show that an agent trained\nusing only a 10% subset of the data performs just as well as an agent trained\non the entire dataset. We present a method to predict the inherent difficulty\nof a driving situation given data collected from a fleet of autonomous vehicles\ndeployed on public roads. We then demonstrate that this difficulty score can be\nused in a zero-shot transfer to generate curricula for an imitation-learning\nbased planning agent. Compared to training on the entire unbiased training\ndataset, we show that prioritizing difficult driving scenarios both reduces\ncollisions by 15% and increases route adherence by 14% in closed-loop\nevaluation, all while using only 10% of the training data.",
    "descriptor": "\nComments: Published in CoRL 2022. Main text (8 pages, 3 figures) + acknowledgements and references (3 pages) + appendix (7 pages, 4 figures)\n",
    "authors": [
      "Eli Bronstein",
      "Sirish Srinivasan",
      "Supratik Paul",
      "Aman Sinha",
      "Matthew O'Kelly",
      "Payam Nikdel",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01375"
  },
  {
    "id": "arXiv:2212.01376",
    "title": "D2DF2WOD: Learning Object Proposals for Weakly-Supervised Object  Detection via Progressive Domain Adaptation",
    "abstract": "Weakly-supervised object detection (WSOD) models attempt to leverage\nimage-level annotations in lieu of accurate but costly-to-obtain object\nlocalization labels. This oftentimes leads to substandard object detection and\nlocalization at inference time. To tackle this issue, we propose D2DF2WOD, a\nDual-Domain Fully-to-Weakly Supervised Object Detection framework that\nleverages synthetic data, annotated with precise object localization, to\nsupplement a natural image target domain, where only image-level labels are\navailable. In its warm-up domain adaptation stage, the model learns a\nfully-supervised object detector (FSOD) to improve the precision of the object\nproposals in the target domain, and at the same time learns\ntarget-domain-specific and detection-aware proposal features. In its main WSOD\nstage, a WSOD model is specifically tuned to the target domain. The feature\nextractor and the object proposal generator of the WSOD model are built upon\nthe fine-tuned FSOD model. We test D2DF2WOD on five dual-domain image\nbenchmarks. The results show that our method results in consistently improved\nobject detection and localization compared with state-of-the-art methods.",
    "descriptor": "\nComments: published in WACV 2023\n",
    "authors": [
      "Yuting Wang",
      "Ricardo Guerrero",
      "Vladimir Pavlovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01376"
  },
  {
    "id": "arXiv:2212.01377",
    "title": "Requirements Development for IoT Systems with UCM4IoT",
    "abstract": "The engineering of IoT (Internet of Things) systems brings about various\nchallenges due to the inherent complexities associated with such adaptive\nsystems. Addressing the adaptive nature of IoT systems in the early stages of\nthe development life cycle is essential for developing a complete and precise\nsystem specification. In this paper, we propose a use case-based modelling\nlanguage, UCM4IoT, to support requirements elicitation and specification of IoT\nsystems. UCM4IoT takes into account the heterogeneity of IoT systems and\nprovides domain-specific language constructs to model the different facets of\nIoT systems. The language also incorporates the notion of exceptional\nsituations and adaptive system behaviour. Our language is supported with a\ntextual modelling environment to assist modellers in writing use cases. The\nenvironment supports syntax-directed editing, validation of use case models,\nand requirements analysis. The proposed language and tool is demonstrated and\nevaluated with two case studies: smart store system and smart fire alarm\nsystem.",
    "descriptor": "",
    "authors": [
      "Paul Boutot",
      "Mirza Rehenuma Tabassum",
      "Abdul Abedin",
      "Sadaf Mustafiz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.01377"
  },
  {
    "id": "arXiv:2212.01378",
    "title": "ColD Fusion: Collaborative Descent for Distributed Multitask Finetuning",
    "abstract": "Pretraining has been shown to scale well with compute, data size and data\ndiversity. Multitask learning trains on a mixture of supervised datasets and\nproduces improved performance compared to self-supervised pretraining. Until\nnow, massively multitask learning required simultaneous access to all datasets\nin the mixture and heavy compute resources that are only available to\nwell-resourced teams.\nIn this paper, we propose ColD Fusion, a method that provides the benefits of\nmultitask learning but leverages distributed computation and requires limited\ncommunication and no sharing of data. Consequentially, ColD Fusion can create a\nsynergistic loop, where finetuned models can be recycled to continually improve\nthe pretrained model they are based on. We show that ColD Fusion yields\ncomparable benefits to multitask pretraining by producing a model that (a)\nattains strong performance on all of the datasets it was multitask trained on\nand (b) is a better starting point for finetuning on unseen datasets. We find\nColD Fusion outperforms RoBERTa and even previous multitask models.\nSpecifically, when training and testing on 35 diverse datasets, ColD\nFusion-based model outperforms RoBERTa by 2.45 points in average without any\nchanges to the architecture.",
    "descriptor": "",
    "authors": [
      "Shachar Don-Yehiya",
      "Elad Venezian",
      "Colin Raffel",
      "Noam Slonim",
      "Yoav Katz",
      "Leshem Choshen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.01378"
  },
  {
    "id": "arXiv:2212.01381",
    "title": "LatentSwap3D: Semantic Edits on 3D Image GANs",
    "abstract": "Recent 3D-aware GANs rely on volumetric rendering techniques to disentangle\nthe pose and appearance of objects, de facto generating entire 3D volumes\nrather than single-view 2D images from a latent code. Complex image editing\ntasks can be performed in standard 2D-based GANs (e.g., StyleGAN models) as\nmanipulation of latent dimensions. However, to the best of our knowledge,\nsimilar properties have only been partially explored for 3D-aware GAN models.\nThis work aims to fill this gap by showing the limitations of existing methods\nand proposing LatentSwap3D, a model-agnostic approach designed to enable\nattribute editing in the latent space of pre-trained 3D-aware GANs. We first\nidentify the most relevant dimensions in the latent space of the model\ncontrolling the targeted attribute by relying on the feature importance ranking\nof a random forest classifier. Then, to apply the transformation, we swap the\ntop-K most relevant latent dimensions of the image being edited with an image\nexhibiting the desired attribute. Despite its simplicity, LatentSwap3D provides\nremarkable semantic edits in a disentangled manner and outperforms alternative\napproaches both qualitatively and quantitatively. We demonstrate our semantic\nedit approach on various 3D-aware generative models such as pi-GAN, GIRAFFE,\nStyleSDF, MVCGAN, EG3D and VolumeGAN, and on diverse datasets, such as FFHQ,\nAFHQ, Cats, MetFaces, and CompCars. The project page can be found:\n\\url{https://enisimsar.github.io/latentswap3d/}.",
    "descriptor": "",
    "authors": [
      "Enis Simsar",
      "Alessio Tonioni",
      "Evin P\u0131nar \u00d6rnek",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01381"
  },
  {
    "id": "arXiv:2212.00237",
    "title": "Inference of Media Bias and Content Quality Using Natural-Language  Processing",
    "abstract": "Media bias can significantly impact the formation and development of opinions\nand sentiments in a population. It is thus important to study the emergence and\ndevelopment of partisan media and political polarization. However, it is\nchallenging to quantitatively infer the ideological positions of media outlets.\nIn this paper, we present a quantitative framework to infer both political bias\nand content quality of media outlets from text, and we illustrate this\nframework with empirical experiments with real-world data. We apply a\nbidirectional long short-term memory (LSTM) neural network to a data set of\nmore than 1 million tweets to generate a two-dimensional ideological-bias and\ncontent-quality measurement for each tweet. We then infer a ``media-bias\nchart'' of (bias, quality) coordinates for the media outlets by integrating the\n(bias, quality) measurements of the tweets of the media outlets. We also apply\na variety of baseline machine-learning methods, such as a naive-Bayes method\nand a support-vector machine (SVM), to infer the bias and quality values for\neach tweet. All of these baseline approaches are based on a bag-of-words\napproach. We find that the LSTM-network approach has the best performance of\nthe examined methods. Our results illustrate the importance of leveraging word\norder into machine-learning methods in text analysis.",
    "descriptor": "\nComments: 21 pages, 7 figures, 4 tables\n",
    "authors": [
      "Zehan Chao",
      "Denali Molitor",
      "Deanna Needell",
      "Mason A. Porter"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.00237"
  },
  {
    "id": "arXiv:2212.00796",
    "title": "Convolutional Long Short-Term Memory (convLSTM) for Spatio-Temporal  Forecastings of Saturations and Pressure in the SACROC Field",
    "abstract": "A machine learning architecture composed of convolutional long short-term\nmemory (convLSTM) is developed to predict spatio-temporal parameters in the\nSACROC oil field, Texas, USA. The spatial parameters are recorded at the end of\neach month for 30 years (360 months), approximately 83% (300 months) of which\nis used for training and the rest 17% (60 months) is kept for testing. The\nsamples for the convLSTM models are prepared by choosing ten consecutive frames\nas input and ten consecutive frames shifted forward by one frame as output.\nIndividual models are trained for oil, gas, and water saturations, and pressure\nusing the Nesterov accelerated adaptive moment estimation (Nadam) optimization\nalgorithm. A workflow is provided to comprehend the entire process of data\nextraction, preprocessing, sample preparation, training, testing of machine\nlearning models, and error analysis. Overall, the convLSTM for spatio-temporal\nprediction shows promising results in predicting spatio-temporal parameters in\nporous media.",
    "descriptor": "",
    "authors": [
      "Palash Panja",
      "Wei Jia",
      "Alec Nelson",
      "Brian McPherson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00796"
  },
  {
    "id": "arXiv:2212.00832",
    "title": "Applications of Lattice Gauge Equivariant Neural Networks",
    "abstract": "The introduction of relevant physical information into neural network\narchitectures has become a widely used and successful strategy for improving\ntheir performance. In lattice gauge theories, such information can be\nidentified with gauge symmetries, which are incorporated into the network\nlayers of our recently proposed Lattice Gauge Equivariant Convolutional Neural\nNetworks (L-CNNs). L-CNNs can generalize better to differently sized lattices\nthan traditional neural networks and are by construction equivariant under\nlattice gauge transformations. In these proceedings, we present our progress on\npossible applications of L-CNNs to Wilson flow or continuous normalizing flow.\nOur methods are based on neural ordinary differential equations which allow us\nto modify link configurations in a gauge equivariant manner. For simplicity, we\nfocus on simple toy models to test these ideas in practice.",
    "descriptor": "\nComments: 8 pages, 4 figures, proceedings of XVth Quark Confinement and the Hadron Spectrum conference\n",
    "authors": [
      "Matteo Favoni",
      "Andreas Ipp",
      "David I. M\u00fcller"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2212.00832"
  },
  {
    "id": "arXiv:2212.00856",
    "title": "Risk-Adaptive Approaches to Learning and Decision Making: A Survey",
    "abstract": "Uncertainty is prevalent in engineering design, statistical learning, and\ndecision making broadly. Due to inherent risk-averseness and ambiguity about\nassumptions, it is common to address uncertainty by formulating and solving\nconservative optimization models expressed using measure of risk and related\nconcepts. We survey the rapid development of risk measures over the last\nquarter century. From its beginning in financial engineering, we recount their\nspread to nearly all areas of engineering and applied mathematics. Solidly\nrooted in convex analysis, risk measures furnish a general framework for\nhandling uncertainty with significant computational and theoretical advantages.\nWe describe the key facts, list several concrete algorithms, and provide an\nextensive list of references for further reading. The survey recalls\nconnections with utility theory and distributionally robust optimization,\npoints to emerging applications areas such as fair machine learning, and\ndefines measures of reliability.",
    "descriptor": "",
    "authors": [
      "Johannes O. Royset"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.00856"
  },
  {
    "id": "arXiv:2212.00860",
    "title": "A Model-based GNN for Learning Precoding",
    "abstract": "Learning precoding policies with neural networks enables low complexity\nonline implementation, robustness to channel impairments, and joint\noptimization with channel acquisition. However, existing neural networks suffer\nfrom high training complexity and poor generalization ability when they are\nused to learn to optimize precoding for mitigating multi-user interference.\nThis impedes their use in practical systems where the number of users is\ntime-varying. In this paper, we propose a graph neural network (GNN) to learn\nprecoding policies by harnessing both the mathematical model and the property\nof the policies. We first show that a vanilla GNN cannot well-learn\npseudo-inverse of channel matrix when the numbers of antennas and users are\nlarge, and is not generalizable to unseen numbers of users. Then, we design a\nGNN by resorting to the Taylor's expansion of matrix pseudo-inverse, which\nallows for capturing the importance of the neighbored edges to be aggregated\nthat is crucial for learning precoding policies efficiently. Simulation results\nshow that the proposed GNN can well learn spectral efficient and energy\nefficient precoding policies in single- and multi-cell multi-user multi-antenna\nsystems with low training complexity, and can be well generalized to the\nnumbers of users.",
    "descriptor": "\nComments: 30 pages, 7 figures\n",
    "authors": [
      "Jia Guo",
      "Chenyang Yang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00860"
  },
  {
    "id": "arXiv:2212.00879",
    "title": "Quantum Cryptography in Algorithmica",
    "abstract": "We construct a classical oracle relative to which $\\mathsf{P} = \\mathsf{NP}$\nyet single-copy secure pseudorandom quantum states exist. In the language of\nImpagliazzo's five worlds, this is a construction of pseudorandom states in\n\"Algorithmica,\" and hence shows that in a black-box setting, quantum\ncryptography based on pseudorandom states is possible even if one-way functions\ndo not exist. As a consequence, we demonstrate that there exists a property of\na cryptographic hash function that simultaneously (1) suffices to construct\npseudorandom states, (2) holds for a random oracle, and (3) is independent of\n$\\mathsf{P}$ vs. $\\mathsf{NP}$ in the black-box setting. We also introduce a\nconjecture that would generalize our results to multi-copy secure pseudorandom\nstates.\nWe build on the recent construction by Aaronson, Ingram, and Kretschmer (CCC\n2022) of an oracle relative to which $\\mathsf{P} = \\mathsf{NP}$ but\n$\\mathsf{BQP} \\neq \\mathsf{QCMA}$, based on hardness of the OR $\\circ$\nForrelation problem. Our proof also introduces a new discretely-defined variant\nof the Forrelation distribution, for which we prove pseudorandomness against\n$\\mathsf{AC^0}$ circuits. This variant may be of independent interest.",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "William Kretschmer",
      "Luowen Qian",
      "Makrand Sinha",
      "Avishay Tal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.00879"
  },
  {
    "id": "arXiv:2212.00896",
    "title": "Nonlinear controllability and function representation by neural  stochastic differential equations",
    "abstract": "There has been a great deal of recent interest in learning and approximation\nof functions that can be expressed as expectations of a given nonlinearity with\nrespect to its random internal parameters. Examples of such representations\ninclude \"infinitely wide\" neural nets, where the underlying nonlinearity is\ngiven by the activation function of an individual neuron. In this paper, we\nbring this perspective to function representation by neural stochastic\ndifferential equations (SDEs). A neural SDE is an It\\^o diffusion process whose\ndrift and diffusion matrix are elements of some parametric families. We show\nthat the ability of a neural SDE to realize nonlinear functions of its initial\ncondition can be related to the problem of optimally steering a certain\ndeterministic dynamical system between two given points in finite time. This\nauxiliary system is obtained by formally replacing the Brownian motion in the\nSDE by a deterministic control input. We derive upper and lower bounds on the\nminimum control effort needed to accomplish this steering; these bounds may be\nof independent interest in the context of motion planning and deterministic\noptimal control.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Tanya Veeravalli",
      "Maxim Raginsky"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00896"
  },
  {
    "id": "arXiv:2212.00944",
    "title": "A $4/3\\cdot OPT+2/3$ approximation for big two-bar charts packing  problem",
    "abstract": "Two-Bar Charts Packing Problem is to pack $n$ two-bar charts (2-BCs) in a\nminimal number of unit-capacity bins. This problem generalizes the strongly\nNP-hard Bin Packing Problem. We prove that the problem remains strongly NP-hard\neven if each 2-BC has at least one bar higher than 1/2. Next we consider the\ncase when the first (or second) bar of each 2-BC is higher than 1/2 and show\nthat the $O(n^2)$-time greedy algorithm with preliminary lexicographic ordering\nof 2-BCs constructs a packing of length at most $OPT+1$, where $OPT$ is\noptimum. Eventually, this result allowed us to present an $O(n^{2.5})$-time\nalgorithm that constructs a packing of length at most $4/3\\cdot OPT+2/3$ for\nthe NP-hard case when each 2-BC has at least one bar higher than 1/2.",
    "descriptor": "",
    "authors": [
      "Adil Erzin",
      "Alexander Kononov",
      "Georgii Melidi",
      "Stepan Nazarenko"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2212.00944"
  },
  {
    "id": "arXiv:2212.00947",
    "title": "Quantitative bounds for unconditional pairs of frames",
    "abstract": "We formulate a quantitative finite-dimensional conjecture about frame\nmultipliers and prove that it is equivalent to Conjecture 1 in [SB2].\nWe then present solutions to the conjecture for certain classes of frame\nmultipliers. In particular, we prove that there is a universal constant\n$\\kappa>0$ so that for all $C,\\beta>0$ and $N\\in\\mathbb{N}$ the following is\ntrue. Let $(x_j)_{j=1}^N$ and $(f_j)_{j=1}^N$ be sequences in a finite\ndimensional Hilbert space which satisfy $\\|x_j\\|=\\|f_j\\|$ for all $1\\leq j\\leq\nN$ and\n$$\\Big\\|\\sum_{j=1}^N \\varepsilon_j\\langle x,f_j\\rangle x_j\\Big\\|\\leq C\\|x\\|,\n\\qquad\\textrm{ for all $x\\in \\ell_2^M$ and $|\\varepsilon_j|=1$}. $$ If the\nframe operator for $(f_j)_{j=1}^N$ has eigenvalues\n$\\lambda_1\\geq...\\geq\\lambda_M$ and $\\lambda_1\\leq \\beta\nM^{-1}\\sum_{j=1}^M\\lambda_j$ then $(f_j)_{j=1}^N$ has Bessel bound $\\kappa\n\\beta^2 C$. The same holds for $(x_j)_{j=1}^N$.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Peter Balazs",
      "Daniel Freeman",
      "Roxana Popescu",
      "Michael Speckbacher"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.00947"
  },
  {
    "id": "arXiv:2212.00976",
    "title": "Pattern formation in 2d stochastic anisotropic Swift-Hohenberg equation",
    "abstract": "In this paper, we study a phenomenological model for pattern formation in\nelectroconvection, and the effect of noise on the pattern. As such model we\nconsider an anisotropic Swift-Hohenberg equation adding an additive noise. We\nprove the existence of a global solution of that equation on the two\ndimensional torus. In addition, inserting a scaling parameter, we consider the\nequation on a large domain near its change of stability. We observe numerically\nthat, under the appropriate scaling, its solutions can be approximated by a\nperiodic wave, which is modulated by the solutions to a stochastic\nGinzburg-Landau equation.",
    "descriptor": "\nComments: 24 pages, 8 figures\n",
    "authors": [
      "Reika Fukuizumi",
      "Yueyuan Gao",
      "Guido Schneider",
      "Motomitsu Takahashi"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2212.00976"
  },
  {
    "id": "arXiv:2212.01012",
    "title": "Injecting Spatial Information for Monaural Speech Enhancement via  Knowledge Distillation",
    "abstract": "Monaural speech enhancement (SE) provides a versatile and cost-effective\napproach to SE tasks by utilizing recordings from a single microphone. However,\nthe monaural SE lags performance behind multi-channel SE as the monaural SE\nmethods are unable to extract spatial information from one-channel recordings,\nwhich greatly limits their application scenarios. To address this issue, we\ninject spatial information into the monaural SE model and propose a knowledge\ndistillation strategy to enable the monaural SE model to learn binaural speech\nfeatures from the binaural SE model, which makes monaural SE model possible to\nreconstruct higher intelligibility and quality enhanced speeches under low\nsignal-to-noise ratio (SNR) conditions. Extensive experiments show that our\nproposed monaural SE model by injecting spatial information via knowledge\ndistillation achieves favorable performance against other monaural SE models\nwith fewer parameters.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Xinmeng Xu",
      "Weiping Tu",
      "Yuhong Yang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2212.01012"
  },
  {
    "id": "arXiv:2212.01013",
    "title": "Identifying the reach from high-dimensional point cloud data with  connections to r-convexity",
    "abstract": "The convexity of a set can be generalized to the two weaker notions of reach\nand $r$-convexity; both describe the regularity of a set's boundary. In this\narticle, these two notions are shown to be equivalent for closed subsets of\n$\\mathbb{R}^d$ with $C^1$ smooth, $(d-1)$-dimensional boundary. In the general\ncase, for closed subsets of $\\mathbb{R}^d$, we detail a new characterization of\nthe reach in terms of the distance-to-set function applied to midpoints of\npairs of points in the set. For compact subsets of $\\mathbb{R}^d$, we provide\nmethods of approximating the reach and $r$-convexity based on high-dimensional\npoint cloud data. These methods are intuitive and highly tractable, and produce\nupper bounds that converge to the respective quantities as the density of the\npoint cloud is increased. Simulation studies suggest that the rates at which\nthe approximation methods converge correspond to those established\ntheoretically.",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "Ryan Cotsakis"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Computational Geometry (cs.CG)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2212.01013"
  },
  {
    "id": "arXiv:2212.01027",
    "title": "Progress and Challenges for the Application of Machine Learning for  Neglected Tropical Diseases",
    "abstract": "Neglected tropical diseases (NTDs) continue to affect the livelihood of\nindividuals in countries in the Southeast Asia and Western Pacific region.\nThese diseases have been long existing and have caused devastating health\nproblems and economic decline to people in low- and middle-income (developing)\ncountries. An estimated 1.7 billion of the world's population suffer one or\nmore NTDs annually, this puts approximately one in five individuals at risk for\nNTDs. In addition to health and social impact, NTDs inflict significant\nfinancial burden to patients, close relatives, and are responsible for billions\nof dollars lost in revenue from reduced labor productivity in developing\ncountries alone. There is an urgent need to better improve the control and\neradication or elimination efforts towards NTDs. This can be achieved by\nutilizing machine learning tools to better the surveillance, prediction and\ndetection program, and combat NTDs through the discovery of new therapeutics\nagainst these pathogens. This review surveys the current application of machine\nlearning tools for NTDs and the challenges to elevate the state-of-the-art of\nNTDs surveillance, management, and treatment.",
    "descriptor": "",
    "authors": [
      "Chung Yuen Khew",
      "Rahmad Akbar",
      "Norfarhan Mohd. Assaad"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01027"
  },
  {
    "id": "arXiv:2212.01041",
    "title": "Quantum median filter for Total Variation image denoising",
    "abstract": "In this new computing paradigm, named quantum computing, researchers from all\nover the world are taking their first steps in designing quantum circuits for\nimage processing, through a difficult process of knowledge transfer. This\neffort is named Quantum Image Processing, an emerging research field pushed by\npowerful parallel computing capabilities of quantum computers. This work goes\nin this direction and proposes the challenging development of a powerful method\nof image denoising, such as the Total Variation (TV) model, in a quantum\nenvironment. The proposed Quantum TV is described and its sub-components are\nanalysed. Despite the natural limitations of the current capabilities of\nquantum devices, the experimental results show a competitive denoising\nperformance compared to the classical variational TV counterpart.",
    "descriptor": "",
    "authors": [
      "Simone De Santis",
      "Damiana Lazzaro",
      "Riccardo Mengoni",
      "Serena Morigi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01041"
  },
  {
    "id": "arXiv:2212.01048",
    "title": "Empirical Asset Pricing via Ensemble Gaussian Process Regression",
    "abstract": "We introduce an ensemble learning method based on Gaussian Process Regression\n(GPR) for predicting conditional expected stock returns given stock-level and\nmacro-economic information. Our ensemble learning approach significantly\nreduces the computational complexity inherent in GPR inference and lends itself\nto general online learning tasks. We conduct an empirical analysis on a large\ncross-section of US stocks from 1962 to 2016. We find that our method dominates\nexisting machine learning models statistically and economically in terms of\nout-of-sample $R$-squared and Sharpe ratio of prediction-sorted portfolios.\nExploiting the Bayesian nature of GPR, we introduce the mean-variance optimal\nportfolio with respect to the predictive uncertainty distribution of the\nexpected stock returns. It appeals to an uncertainty averse investor and\nsignificantly dominates the equal- and value-weighted prediction-sorted\nportfolios, which outperform the S&P 500.",
    "descriptor": "",
    "authors": [
      "Damir Filipovi\u0107",
      "Puneet Pasricha"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2212.01048"
  },
  {
    "id": "arXiv:2212.01068",
    "title": "Fast Algorithm for Constrained Linear Inverse Problems",
    "abstract": "We consider the constrained Linear Inverse Problem (LIP), where a certain\natomic norm (like the $\\ell_1 $ and the Nuclear norm) is minimized subject to a\nquadratic constraint. Typically, such cost functions are non-differentiable\nwhich makes them not amenable to the fast optimization methods existing in\npractice. We propose two equivalent reformulations of the constrained LIP with\nimproved convex regularity: (i) a smooth convex minimization problem, and (ii)\na strongly convex min-max problem. These problems could be solved by applying\nexisting acceleration based convex optimization methods which provide better\n\\mmode{ O \\left( \\nicefrac{1}{k^2} \\right) } theoretical convergence guarantee.\nHowever, to fully exploit the utility of these reformulations, we also provide\na novel algorithm, to which we refer as the Fast Linear Inverse Problem Solver\n(FLIPS), that is tailored to solve the reformulation of the LIP. We demonstrate\nthe performance of FLIPS on the sparse coding problem arising in image\nprocessing tasks. In this setting, we observe that FLIPS consistently\noutperforms the Chambolle-Pock and C-SALSA algorithms--two of the current best\nmethods in the literature.",
    "descriptor": "",
    "authors": [
      "Mohammed Rayyan Sheriff",
      "Floor Fenne Redel",
      "Peyman Mohajerin Esfahani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01068"
  },
  {
    "id": "arXiv:2212.01108",
    "title": "SLMT-Net: A Self-supervised Learning based Multi-scale Transformer  Network for Cross-Modality MR Image Synthesis",
    "abstract": "Cross-modality magnetic resonance (MR) image synthesis aims to produce\nmissing modalities from existing ones. Currently, several methods based on deep\nneural networks have been developed using both source- and target-modalities in\na supervised learning manner. However, it remains challenging to obtain a large\namount of completely paired multi-modal training data, which inhibits the\neffectiveness of existing methods. In this paper, we propose a novel\nSelf-supervised Learning-based Multi-scale Transformer Network (SLMT-Net) for\ncross-modality MR image synthesis, consisting of two stages, \\ie, a\npre-training stage and a fine-tuning stage. During the pre-training stage, we\npropose an Edge-preserving Masked AutoEncoder (Edge-MAE), which preserves the\ncontextual and edge information by simultaneously conducting the image\nreconstruction and the edge generation. Besides, a patch-wise loss is proposed\nto treat the input patches differently regarding their reconstruction\ndifficulty, by measuring the difference between the reconstructed image and the\nground-truth. In this case, our Edge-MAE can fully leverage a large amount of\nunpaired multi-modal data to learn effective feature representations. During\nthe fine-tuning stage, we present a Multi-scale Transformer U-Net (MT-UNet) to\nsynthesize the target-modality images, in which a Dual-scale Selective Fusion\n(DSF) module is proposed to fully integrate multi-scale features extracted from\nthe encoder of the pre-trained Edge-MAE. Moreover, we use the pre-trained\nencoder as a feature consistency module to measure the difference between\nhigh-level features of the synthesized image and the ground truth one.\nExperimental results show the effectiveness of the proposed SLMT-Net, and our\nmodel can reliably synthesize high-quality images when the training set is\npartially unpaired. Our code will be publicly available at\nhttps://github.com/lyhkevin/SLMT-Net.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Yonghao Li",
      "Tao Zhou",
      "Kelei He",
      "Yi Zhou",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01108"
  },
  {
    "id": "arXiv:2212.01115",
    "title": "Some properties of the solution of the vertical tensor complementarity  problem",
    "abstract": "In this paper, we mainly focus on the existence and uniqueness of the\nvertical tensor complementarity problem. Firstly, combining the\ngeneralized-order linear complementarity problem with the tensor\ncomplementarity problem, the vertical tensor complementarity problem is\nintroduced. Secondly, we define some sets of special tensors, and illustrate\nthe inclusion relationships. Finally, we show that the solution set of the\nvertical tensor complementarity problem is bounded under certain conditions,\nand some sufficient conditions for the existence and uniqueness of the solution\nof the vertical tensor complementarity problem are obtained from the view of\nthe degree theory and the equal form of the minimum function.",
    "descriptor": "",
    "authors": [
      "Li-Ming Li",
      "Shi-Liang Wu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.01115"
  },
  {
    "id": "arXiv:2212.01178",
    "title": "Dynamic Independent Component Extraction with Blending Mixing Vector:  Lower Bound on Mean Interference-to-Signal Ratio",
    "abstract": "This paper deals with dynamic Blind Source Extraction (BSE) from where the\nmixing parameters characterizing the position of a source of interest (SOI) are\nallowed to vary over time. We present a new source extraction model called\nCvxCSV which is a parameter-reduced modification of the recent Constant\nSeparation Vector (CSV) mixing model. In CvxCSV, the mixing vector evolves as a\nconvex combination of its initial and final values. We derive a lower bound on\nthe achievable mean interference-to-signal ratio (ISR) based on the\nCram\\'er-Rao theory. The bound reveals advantageous properties of CvxCSV\ncompared with CSV and compared with a sequential BSE based on independent\ncomponent extraction (ICE). In particular, the achievable ISR by CvxCSV is\nlower than that by the previous approaches. Moreover, the model requires\nsignificantly weaker conditions for identifiability, even when the SOI is\nGaussian.",
    "descriptor": "\nComments: submitted to a conference\n",
    "authors": [
      "Jaroslav \u010cmejla",
      "Zbyn\u011bk Koldovsk\u00fd",
      "V\u00e1clav Kautsk\u00fd",
      "T\u00fclay Adal\u0131"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.01178"
  },
  {
    "id": "arXiv:2212.01191",
    "title": "Martinize2 and Vermouth: Unified Framework for Topology Generation",
    "abstract": "Ongoing advances in force field and computer hardware development enable the\nuse of molecular dynamics (MD) to simulate increasingly complex systems with\nthe ultimate goal of reaching cellular complexity. At the same time, rational\ndesign by high-throughput (HT) simulations is another forefront of MD. In these\nareas, the Martini coarse-grained force field, especially the latest version\n(i.e. v3), is being actively explored because it offers enhanced\nspatial-temporal resolution. However, the automation tools for preparing\nsimulations with the Martini force field, accompanying the previous version,\nwere not designed for HT simulations or studies of complex cellular systems.\nTherefore, they become a major limiting factor. To address these shortcomings,\nwe present the open-source Vermouth python library. Vermouth is designed to\nbecome the unified framework for developing programs, which prepare, run, and\nanalyze Martini simulations of complex systems. To demonstrate the power of the\nVermouth library, the Martinize2 program is showcased as a generalization of\nthe martinize script, originally aimed to set up simulations of proteins. In\ncontrast to the previous version, Martinize2 automatically handles protonation\nstates in proteins and post-translation modifications, offers more options to\nfine-tune structural biases such as the elastic network, and can convert\nnon-protein molecules such as ligands. Finally, Martinize2 is used to convert\nthe entire I-TASSER protein template database as high-complexity benchmark and\nillustrate how the checks on input structure quality can safe guard\nhigh-throughput applications.",
    "descriptor": "\nComments: corresponding authors: F. Gr\\\"unewald f.grunewald[at]rug.nl; S. J. Marrink s.j.marrink[at]rug.nl;\n",
    "authors": [
      "Peter C. Kroon",
      "Fabian Gr\u00fcnewald",
      "Jonathan Barnoud",
      "Marco van Tilburg",
      "Paulo C. T. Souza",
      "Tsjerk A. Wassenaar",
      "Siewert-Jan Marrink"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Other Condensed Matter (cond-mat.other)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2212.01191"
  },
  {
    "id": "arXiv:2212.01199",
    "title": "Gibbs-Helmholtz Graph Neural Network: capturing the temperature  dependency of activity coefficients at infinite dilution",
    "abstract": "The accurate prediction of physicochemical properties of chemical compounds\nin mixtures (such as the activity coefficient at infinite dilution\n$\\gamma_{ij}^\\infty$) is essential for developing novel and more sustainable\nchemical processes. In this work, we analyze the performance of\npreviously-proposed GNN-based models for the prediction of\n$\\gamma_{ij}^\\infty$, and compare them with several mechanistic models in a\nseries of 9 isothermal studies. Moreover, we develop the Gibbs-Helmholtz Graph\nNeural Network (GH-GNN) model for predicting $\\ln \\gamma_{ij}^\\infty$ of\nmolecular systems at different temperatures. Our method combines the simplicity\nof a Gibbs-Helmholtz-derived expression with a series of graph neural networks\nthat incorporate explicit molecular and intermolecular descriptors for\ncapturing dispersion and hydrogen bonding effects. We have trained this model\nusing experimentally determined $\\ln \\gamma_{ij}^\\infty$ data of 40,219\nbinary-systems involving 1032 solutes and 866 solvents, overall showing\nsuperior performance compared to the popular UNIFAC-Dortmund model. We analyze\nthe performance of GH-GNN for continuous and discrete inter/extrapolation and\ngive indications for the model's applicability domain and expected accuracy. In\ngeneral, GH-GNN is able to produce accurate predictions for extrapolated\nbinary-systems if at least 25 systems with the same combination of\nsolute-solvent chemical classes are contained in the training set and a\nsimilarity indicator above 0.35 is also present. This model and its\napplicability domain recommendations have been made open-source at\nhttps://github.com/edgarsmdn/GH-GNN.",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "Edgar Ivan Sanchez Medina",
      "Steffen Linke",
      "Martin Stoll",
      "Kai Sundmacher"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01199"
  },
  {
    "id": "arXiv:2212.01226",
    "title": "Quantum NETwork: from theory to practice",
    "abstract": "The quantum internet is envisioned as the ultimate stage of the quantum\nrevolution, which surpasses its classical counterpart in various aspects, such\nas the efficiency of data transmission, the security of network services, and\nthe capability of information processing. Given its disruptive impact on the\nnational security and the digital economy, a global race to build scalable\nquantum networks has already begun. With the joint effort of national\ngovernments, industrial participants and research institutes, the development\nof quantum networks has advanced rapidly in recent years, bringing the first\nprimitive quantum networks within reach. In this work, we aim to provide an\nup-to-date review of the field of quantum networks from both theoretical and\nexperimental perspectives, contributing to a better understanding of the\nbuilding blocks required for the establishment of a global quantum internet. We\nalso introduce a newly developed quantum network toolkit to facilitate the\nexploration and evaluation of innovative ideas. Particularly, it provides dual\nquantum computing engines, supporting simulations in both the quantum circuit\nand measurement-based models. It also includes a compilation scheme for mapping\nquantum network protocols onto quantum circuits, enabling their emulations on\nreal-world quantum hardware devices. We showcase the power of this toolkit with\nseveral featured demonstrations, including a simulation of the Micius quantum\nsatellite experiment, a testing of a four-layer quantum network architecture\nwith resource management, and a quantum emulation of the CHSH game. We hope\nthis work can give a better understanding of the state-of-the-art development\nof quantum networks and provide the necessary tools to make further\ncontributions along the way.",
    "descriptor": "\nComments: 36 pages, 33 figures; comments are welcome\n",
    "authors": [
      "Kun Fang",
      "Jingtian Zhao",
      "Xiufan Li",
      "Yifei Li",
      "Runyao Duan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.01226"
  },
  {
    "id": "arXiv:2212.01235",
    "title": "Investigating certain choices of CNN configurations for brain lesion  segmentation",
    "abstract": "Brain tumor imaging has been part of the clinical routine for many years to\nperform non-invasive detection and grading of tumors. Tumor segmentation is a\ncrucial step for managing primary brain tumors because it allows a volumetric\nanalysis to have a longitudinal follow-up of tumor growth or shrinkage to\nmonitor disease progression and therapy response. In addition, it facilitates\nfurther quantitative analysis such as radiomics. Deep learning models, in\nparticular CNNs, have been a methodology of choice in many applications of\nmedical image analysis including brain tumor segmentation. In this study, we\ninvestigated the main design aspects of CNN models for the specific task of\nMRI-based brain tumor segmentation. Two commonly used CNN architectures (i.e.\nDeepMedic and U-Net) were used to evaluate the impact of the essential\nparameters such as learning rate, batch size, loss function, and optimizer. The\nperformance of CNN models using different configurations was assessed with the\nBraTS 2018 dataset to determine the most performant model. Then, the\ngeneralization ability of the model was assessed using our in-house dataset.\nFor all experiments, U-Net achieved a higher DSC compared to the DeepMedic.\nHowever, the difference was only statistically significant for whole tumor\nsegmentation using FLAIR sequence data and tumor core segmentation using T1w\nsequence data. Adam and SGD both with the initial learning rate set to 0.001\nprovided the highest segmentation DSC when training the CNN model using U-Net\nand DeepMedic architectures, respectively. No significant difference was\nobserved when using different normalization approaches. In terms of loss\nfunctions, a weighted combination of soft Dice and cross-entropy loss with the\nweighting term set to 0.5 resulted in an improved segmentation performance and\ntraining stability for both DeepMedic and U-Net models.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Masoomeh Rahimpour",
      "Ahmed Radwan",
      "Henri Vandermeulen",
      "Stefan Sunaert",
      "Karolien Goffin",
      "Michel Koole"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01235"
  },
  {
    "id": "arXiv:2212.01245",
    "title": "Preliminary Study on SSCF-derived Polar Coordinate for ASR",
    "abstract": "The transition angles are defined to describe the vowel-to-vowel transitions\nin the acoustic space of the Spectral Subband Centroids, and the findings show\nthat they are similar among speakers and speaking rates. In this paper, we\npropose to investigate the usage of polar coordinates in favor of angles to\ndescribe a speech signal by characterizing its acoustic trajectory and using\nthem in Automatic Speech Recognition. According to the experimental results\nevaluated on the BRAF100 dataset, the polar coordinates achieved significantly\nhigher accuracy than the angles in the mixed and cross-gender speech\nrecognitions, demonstrating that these representations are superior at defining\nthe acoustic trajectory of the speech signal. Furthermore, the accuracy was\nsignificantly improved when they were utilized with their first and\nsecond-order derivatives ($\\Delta$, $\\Delta$$\\Delta$), especially in\ncross-female recognition. However, the results showed they were not much more\ngender-independent than the conventional Mel-frequency Cepstral Coefficients\n(MFCCs).",
    "descriptor": "",
    "authors": [
      "Sotheara Leang",
      "Eric Castelli",
      "Dominique Vaufreydaz",
      "Sethserey Sam"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.01245"
  },
  {
    "id": "arXiv:2212.01257",
    "title": "Holographic MIMO Communications: Theoretical Foundations, Enabling  Technologies, and Future Directions",
    "abstract": "Future wireless systems are envisioned to create an endogenously\nholography-capable, intelligent, and programmable radio propagation\nenvironment, that will offer unprecedented capabilities for high spectral and\nenergy efficiency, low latency, and massive connectivity. A potential and\npromising technology for supporting the expected extreme requirements of the\nsixth-generation (6G) communication systems is the holographic multiple-input\nmultiple-output (MIMO) surface (HMIMOS), which will actualize holographic\nradios with reasonable power consumption and fabrication cost. An HMIMOS is a\nnearly continuous aperture that incorporates reconfigurable and\nsub-wavelength-spaced antennas and/or metamaterials. Such surfaces comprising\ndense electromagnetic (EM) excited elements are capable of recording and\nmanipulating impinging fields with utmost flexibility and precision, as well as\nwith reduced cost and power consumption, thereby shaping arbitrary-intended EM\nwaves with high energy efficiency. The powerful EM processing capability of\nHMIMOS opens up the possibility of wireless communications of holographic\nimaging level, paving the way for signal processing techniques realized in the\nEM domain, possibly in conjunction with their digital-domain counterparts.\nHowever, in spite of the significant potential, the studies on HMIMOS-based\nwireless systems are still at an initial stage. In this survey, we present a\ncomprehensive overview of the latest advances in holographic MIMO\ncommunications, with a special focus on their physical aspects, theoretical\nfoundations, and enabling technologies. We also compare HMIMOS systems with\nconventional multi-antenna technologies, especially massive MIMO systems,\npresent various promising synergies of HMIMOS with current and future candidate\ntechnologies, and provide an extensive list of research challenges and open\ndirections.",
    "descriptor": "",
    "authors": [
      "Tierui Gong",
      "Ioanna Vinieratou",
      "Ran Ji",
      "Chongwen Huang",
      "George C. Alexandropoulos",
      "Li Wei",
      "Zhaoyang Zhang",
      "M\u00e9rouane Debbah",
      "H. Vincent Poor",
      "Chau Yuen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.01257"
  },
  {
    "id": "arXiv:2212.01259",
    "title": "Covariance Estimators for the ROOT-SGD Algorithm in Online Learning",
    "abstract": "Online learning naturally arises in many statistical and machine learning\nproblems. The most widely used methods in online learning are stochastic\nfirst-order algorithms. Among this family of algorithms, there is a recently\ndeveloped algorithm, Recursive One-Over-T SGD (ROOT-SGD). ROOT-SGD is\nadvantageous in that it converges at a non-asymptotically fast rate, and its\nestimator further converges to a normal distribution. However, this normal\ndistribution has unknown asymptotic covariance; thus cannot be directly applied\nto measure the uncertainty. To fill this gap, we develop two estimators for the\nasymptotic covariance of ROOT-SGD. Our covariance estimators are useful for\nstatistical inference in ROOT-SGD. Our first estimator adopts the idea of\nplug-in. For each unknown component in the formula of the asymptotic\ncovariance, we substitute it with its empirical counterpart. The plug-in\nestimator converges at the rate $\\mathcal{O}(1/\\sqrt{t})$, where $t$ is the\nsample size. Despite its quick convergence, the plug-in estimator has the\nlimitation that it relies on the Hessian of the loss function, which might be\nunavailable in some cases. Our second estimator is a Hessian-free estimator\nthat overcomes the aforementioned limitation. The Hessian-free estimator uses\nthe random-scaling technique, and we show that it is an asymptotically\nconsistent estimator of the true covariance.",
    "descriptor": "",
    "authors": [
      "Yiling Luo",
      "Xiaoming Huo",
      "Yajun Mei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01259"
  },
  {
    "id": "arXiv:2212.01267",
    "title": "Understanding Cryptocoins Trends Correlations",
    "abstract": "Crypto-coins (also known as cryptocurrencies) are tradable digital assets.\nNotable examples include Bitcoin, Ether and Litecoin. Ownerships of cryptocoins\nare registered on distributed ledgers (i.e., blockchains). Secure encryption\ntechniques guarantee the security of the transactions (transfers of coins\nacross owners), registered into the ledger. Cryptocoins are exchanged for\nspecific trading prices. While history has shown the extreme volatility of such\ntrading prices across all different sets of crypto-assets, it remains unclear\nwhat and if there are tight relations between the trading prices of different\ncryptocoins. Major coin exchanges (i.e., Coinbase) provide trend correlation\nindicators to coin owners, suggesting possible acquisitions or sells. However,\nthese correlations remain largely unvalidated. In this paper, we shed lights on\nthe trend correlations across a large variety of cryptocoins, by investigating\ntheir coin-price correlation trends over a period of two years. Our\nexperimental results suggest strong correlation patterns between main coins\n(Ethereum, Bitcoin) and alt-coins. We believe our study can support forecasting\ntechniques for time-series modeling in the context of crypto-coins. We release\nour dataset and code to reproduce our analysis to the research community.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Pasquale De Rosa",
      "Valerio Schiavoni"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01267"
  },
  {
    "id": "arXiv:2212.01282",
    "title": "CHAPTER: Exploiting Convolutional Neural Network Adapters for  Self-supervised Speech Models",
    "abstract": "Self-supervised learning (SSL) is a powerful technique for learning\nrepresentations from unlabeled data. Transformer based models such as HuBERT,\nwhich consist a feature extractor and transformer layers, are leading the field\nin the speech domain. SSL models are fine-tuned on a wide range of downstream\ntasks, which involves re-training the majority of the model for each task.\nPrevious studies have introduced applying adapters, which are small lightweight\nmodules commonly used in Natural Language Processing (NLP) to adapt pre-trained\nmodels to new tasks. However, such efficient tuning techniques only provide\nadaptation at the transformer layer, but failed to perform adaptation at the\nfeature extractor. In this paper, we propose CHAPTER, an efficient tuning\nmethod specifically designed for SSL speech model, by applying CNN adapters at\nthe feature extractor. Using this method, we can only fine-tune fewer than 5%\nof parameters per task compared to fully fine-tuning and achieve better and\nmore stable performance. We empirically found that adding CNN adapters to the\nfeature extractor can help the adaptation on emotion and speaker tasks. For\ninstance, the accuracy of SID is improved from 87.71 to 91.56, and the accuracy\nof ER is improved by 5%.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Zih-Ching Chen",
      "Yu-Shun Sung",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2212.01282"
  },
  {
    "id": "arXiv:2212.01306",
    "title": "Relative Acoustic Features for Distance Estimation in Smart-Homes",
    "abstract": "Any audio recording encapsulates the unique fingerprint of the associated\nacoustic environment, namely the background noise and reverberation.\nConsidering the scenario of a room equipped with a fixed smart speaker device\nwith one or more microphones and a wearable smart device (watch, glasses or\nsmartphone), we employed the improved proportionate normalized least mean\nsquare adaptive filter to estimate the relative room impulse response mapping\nthe audio recordings of the two devices. We performed inter-device distance\nestimation by exploiting a new set of features obtained extending the\ndefinition of some acoustic attributes of the room impulse response to its\nrelative version. In combination with the sparseness measure of the estimated\nrelative room impulse response, the relative features allow precise\ninter-device distance estimation which can be exploited for tasks such as best\nmicrophone selection or acoustic scene analysis. Experimental results from\nsimulated rooms of different dimensions and reverberation times demonstrate the\neffectiveness of this computationally lightweight approach for smart home\nacoustic ranging applications",
    "descriptor": "",
    "authors": [
      "Francesco Nespoli",
      "Daniel Barreda",
      "Patrick A. Naylor"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2212.01306"
  },
  {
    "id": "arXiv:2212.01311",
    "title": "Disjoint faces in simple drawings of the complete graph and topological  Heilbronn problems",
    "abstract": "Given a complete simple topological graph $G$, a $k$-face generated by $G$ is\nthe open bounded region enclosed by the edges of a non-self-intersecting\n$k$-cycle in $G$. Interestingly, there are complete simple topological graphs\nwith the property that every odd face it generates contains the origin. In this\npaper, we show that every complete $n$-vertex simple topological graph\ngenerates at least $\\Omega(n^{1/3})$ pairwise disjoint 4-faces. As an immediate\ncorollary, every complete simple topological graph on $n$ vertices drawn in the\nunit square generates a 4-face with area at most $O(n^{-1/3})$. Finally, we\ninvestigate a $\\mathbb Z_2$ variant of Heilbronn triangle problem.",
    "descriptor": "",
    "authors": [
      "Alfredo Hubard",
      "Andrew Suk"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2212.01311"
  },
  {
    "id": "arXiv:2212.01312",
    "title": "Hybrid adiabatic quantum computing for tomographic image reconstruction  -- opportunities and limitations",
    "abstract": "Our goal is to reconstruct tomographic images with few measurements and a low\nsignal-to-noise ratio. In clinical imaging, this helps to improve patient\ncomfort and reduce radiation exposure. As quantum computing advances, we\npropose to use an adiabatic quantum computer and associated hybrid methods to\nsolve the reconstruction problem. Tomographic reconstruction is an ill-posed\ninverse problem. We test our reconstruction technique for image size, noise\ncontent, and underdetermination of the measured projection data. We then\npresent the reconstructed binary and integer-valued images of up to 32 by 32\npixels. The demonstrated method competes with traditional reconstruction\nalgorithms and is superior in terms of robustness to noise and reconstructions\nfrom few projections. We postulate that hybrid quantum computing will soon\nreach maturity for real applications in tomographic reconstruction. Finally, we\npoint out the current limitations regarding the problem size and\ninterpretability of the algorithm.",
    "descriptor": "",
    "authors": [
      "Merlin A. Nau",
      "A. Hans Vija",
      "Wesley Gohn",
      "Maximilian P. Reymann",
      "Andreas K. Maier"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01312"
  },
  {
    "id": "arXiv:2212.01330",
    "title": "Device Interoperability for Learned Image Compression with Weights and  Activations Quantization",
    "abstract": "Learning-based image compression has improved to a level where it can\noutperform traditional image codecs such as HEVC and VVC in terms of coding\nperformance. In addition to good compression performance, device\ninteroperability is essential for a compression codec to be deployed, i.e.,\nencoding and decoding on different CPUs or GPUs should be error-free and with\nnegligible performance reduction. In this paper, we present a method to solve\nthe device interoperability problem of a state-of-the-art image compression\nnetwork. We implement quantization to entropy networks which output entropy\nparameters. We suggest a simple method which can ensure cross-platform encoding\nand decoding, and can be implemented quickly with minor performance deviation,\nof 0.3% BD-rate, from floating point model results.",
    "descriptor": "\nComments: 5 pages, 5 figures, Picture Coding Symposium (PCS) 2022\n",
    "authors": [
      "Esin Koyuncu",
      "Timofey Solovyev",
      "Elena Alshina",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01330"
  },
  {
    "id": "arXiv:2212.01334",
    "title": "A Mixed-Method Approach to Determining Contact Matrices in the Cox's  Bazar Refugee Settlement",
    "abstract": "Contact matrices are an important ingredient in age-structured epidemic\nmodels to inform the simulated spread of the disease between sub-groups of the\npopulation. These matrices are generally derived using resource-intensive\ndiary-based surveys and few exist in the Global South or tailored to vulnerable\npopulations. In particular, no contact matrices exist for refugee settlements -\nlocations under-served by epidemic models in general. In this paper we present\na novel, mixed-method approach, for deriving contact matrices in populations\nwhich combines a lightweight, rapidly deployable, survey with an agent-based\nmodel of the population informed by census and behavioural data. We use this\nmethod to derive the first set of contact matrices for the Cox's Bazar refugee\nsettlement in Bangladesh. The matrices from the refugee settlement show strong\nbanding effects due to different age cut-offs in attendance at certain venues,\nsuch as distribution centres and religious sites, as well as the important\ncontribution of the demographic profile of the settlement which was encoded in\nthe model. These can have significant implications to the modelled disease\ndynamics. To validate our approach, we also apply our method to the population\nof the UK and compare our derived matrices against well-known contact matrices\npreviously collected using traditional approaches. Overall, our findings\ndemonstrate that our mixed-method approach can address some of the challenges\nof both the traditional and previously proposed agent-based approaches to\nderiving contact matrices, and has the potential to be rolled-out in other\nresource-constrained environments. This work therefore contributes to a broader\naim of developing new methods and mechanisms of data collection for modelling\ndisease spread in refugee and IDP settlements and better serving these\nvulnerable communities.",
    "descriptor": "\nComments: 31 pages with appendices, 18 figures\n",
    "authors": [
      "Joseph Walker",
      "Joseph Aylett-Bullock",
      "Difu Shi",
      "Allen Gidraf Kahindo Maina",
      "Egmond Samir Evers",
      "Sandra Harlass",
      "Frank Krauss"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2212.01334"
  },
  {
    "id": "arXiv:2212.01337",
    "title": "Vizaj -- An interactive javascript tool for visualizing spatial networks",
    "abstract": "In many fields of science and technology we are confronted with complex\nnetworks. Making sense of these networks often require the ability to visualize\nand explore their intermingled structure consisting of nodes and links. To\nfacilitate the identification of significant connectivity patterns, many\nmethods have been developed based on the rearrangement of the nodes so as to\navoid link criss-cross. However, real networks are often embedded in a\ngeometrical space and the nodes code for an intrinsic physical feature of the\nsystem that one might want to preserve. For these spatial networks, it is\ntherefore crucial to find alternative strategies operating on the links and not\non the nodes. Here, we introduce Vizaj a javascript web application to\nvisualize spatial networks based on optimized geometrical criteria that reshape\nthe link profiles. While optimized for 3D networks, Vizaj can also be used for\n2D networks and offers the possibility to interactively customize the\nvisualization via several controlling parameters, including network filtering\nand the effect of internode distance on the link trajectories. Vizaj is further\nequipped with additional options allowing to improve the final aesthetics, such\nas the color/size of both nodes and links, zooming/rotating/translating, and\nsuperimposing external objects. Vizaj is an open-source software which can be\nfreely downloaded and updated via a github repository. Here, we provide a\ndetailed description of its main features and algorithms together with a guide\non how to use it. Finally, we validate its potential on several synthetic and\nreal spatial networks from infrastructural to biological systems. We hope that\nVizaj will help scientists and practitioners to make sense of complex networks\nand provide aesthetic while informative visualizations.",
    "descriptor": "",
    "authors": [
      "Thibault Rolland",
      "Fabrizio De Vico Fallani"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2212.01337"
  },
  {
    "id": "arXiv:2212.01351",
    "title": "A Bayesian Framework for Digital Twin-Based Control, Monitoring, and  Data Collection in Wireless Systems",
    "abstract": "Commonly adopted in the manufacturing and aerospace sectors, digital twin\n(DT) platforms are increasingly seen as a promising paradigm to control,\nmonitor, and analyze software-based, \"open\", communication systems. Notably, DT\nplatforms provide a sandbox in which to test artificial intelligence (AI)\nsolutions for communication systems, potentially reducing the need to collect\ndata and test algorithms in the field, i.e., on the physical twin (PT). A key\nchallenge in the deployment of DT systems is to ensure that virtual control\noptimization, monitoring, and analysis at the DT are safe and reliable,\navoiding incorrect decisions caused by \"model exploitation\". To address this\nchallenge, this paper presents a general Bayesian framework with the aim of\nquantifying and accounting for model uncertainty at the DT that is caused by\nlimitations in the amount and quality of data available at the DT from the PT.\nIn the proposed framework, the DT builds a Bayesian model of the communication\nsystem, which is leveraged to enable core DT functionalities such as control\nvia multi-agent reinforcement learning (MARL), monitoring of the PT for anomaly\ndetection, prediction, data-collection optimization, and counterfactual\nanalysis. To exemplify the application of the proposed framework, we\nspecifically investigate a case-study system encompassing multiple sensing\ndevices that report to a common receiver. Experimental results validate the\neffectiveness of the proposed Bayesian framework as compared to standard\nfrequentist model-based solutions.",
    "descriptor": "\nComments: Extends and subsumes arXiv:2210.05582\n",
    "authors": [
      "Clement Ruah",
      "Osvaldo Simeone",
      "Bashir Al-Hashimi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.01351"
  },
  {
    "id": "arXiv:2212.01361",
    "title": "Entropy-rate as prediction method for newspapers and information  diffusion",
    "abstract": "This paper aims to show how some popular topics on social networks can be\nused to predict online newspaper views, related to the topics. Newspapers site\nand many social networks, become a good source of data to analyse and explain\ncomplex phenomena. Understanding the entropy of a topic, could help all\norganizations that need to share information like government, institution,\nnewspaper or company, to expect an higher activity over their channels, and in\nsome cases predict what the receiver expect from the senders or what is wrong\nabout the communication. For some organization such political party, leaders,\ncompany and many others, the reputation and the communication are (for most of\nthem) the key part of a more and complex huge system. To reach our goal, we use\ngathering tools and information theory to detect and analyse trends topic on\nsocial networks, with the purpose of proved a method that helps organization,\nnewspapers to predict how many articles or communication they will have to do\non a topic, and how much flow of views they will have in a given period,\nstarting with the entropy-article ratio. Our work address the issue to explore\nin which entropy-rate, and through which dynamics, a suitable information\ndiffusion performance is expected on social network and then on newspaper. We\nhave identified some cross-cutting dynamics that, associated with the contexts,\nmight explain how people discuss about a topic, can move on to argue and\ninforms on newspapers sites.",
    "descriptor": "\nComments: 13 pages, 8 figures, journal\n",
    "authors": [
      "Andrea Russo",
      "Antonio Picone",
      "Vincenzo Miracula",
      "Giovanni Giuffrida",
      "Francesco Mazzeo Rinaldi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.01361"
  },
  {
    "id": "arXiv:1006.4910",
    "title": "Kalman Filters and Homography: Utilizing the Matrix $A$",
    "abstract": "Kalman Filters and Homography: Utilizing the Matrix $A$",
    "descriptor": "",
    "authors": [
      "Burak Bayramli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1006.4910"
  },
  {
    "id": "arXiv:1708.06121",
    "title": "Extending rational choice behavior: The decision problem for Boolean set  theory with a choice correspondence",
    "abstract": "Extending rational choice behavior: The decision problem for Boolean set  theory with a choice correspondence",
    "descriptor": "",
    "authors": [
      "Domenico Cantone",
      "Alfio Giarlotta",
      "Pietro Maugeri",
      "Stephen Watson"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1708.06121"
  },
  {
    "id": "arXiv:1912.11995",
    "title": "An Abstraction Model for Semantic Segmentation Algorithms",
    "abstract": "Comments: This is the corrected version of the previously submitted paper. Many grammatical and spelling errors are now corrected. The technical content of the paper is unchanged",
    "descriptor": "\nComments: This is the corrected version of the previously submitted paper. Many grammatical and spelling errors are now corrected. The technical content of the paper is unchanged\n",
    "authors": [
      "Reihaneh Teymoori",
      "Zahra Nabizadeh",
      "Nader Karimi",
      "Shadrokh Samavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1912.11995"
  },
  {
    "id": "arXiv:1912.12027",
    "title": "A General Framework for Saliency Detection Methods",
    "abstract": "Comments: Many grammatical and spelling errors are corrected. The technical content is not changed",
    "descriptor": "\nComments: Many grammatical and spelling errors are corrected. The technical content is not changed\n",
    "authors": [
      "Fateme Mostafaie",
      "Zahra Nabizadeh",
      "Nader Karimi",
      "Shadrokh Samavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1912.12027"
  },
  {
    "id": "arXiv:2004.02227",
    "title": "A sufficient condition for visibility paths in simple polygons",
    "abstract": "A sufficient condition for visibility paths in simple polygons",
    "descriptor": "",
    "authors": [
      "Mohammad Reza Zarrabi",
      "Nasrollah Moghaddam Charkari"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2004.02227"
  },
  {
    "id": "arXiv:2005.05444",
    "title": "Non-linear Log-Sobolev inequalities for the Potts semigroup and  applications to reconstruction problems",
    "abstract": "Non-linear Log-Sobolev inequalities for the Potts semigroup and  applications to reconstruction problems",
    "descriptor": "",
    "authors": [
      "Yuzhou Gu",
      "Yury Polyanskiy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2005.05444"
  },
  {
    "id": "arXiv:2007.00450",
    "title": "Supervised Learning and Reinforcement Learning of Feedback Models for  Reactive Behaviors: Tactile Feedback Testbed",
    "abstract": "Comments: Accepted for publication in the International Journal of Robotics Research (IJRR). Paper length is 22 pages (including references) with 12 figures. A video overview of the reinforcement learning experiment on the real robot can be seen at this https URL arXiv admin note: text overlap with arXiv:1710.08555",
    "descriptor": "\nComments: Accepted for publication in the International Journal of Robotics Research (IJRR). Paper length is 22 pages (including references) with 12 figures. A video overview of the reinforcement learning experiment on the real robot can be seen at this https URL arXiv admin note: text overlap with arXiv:1710.08555\n",
    "authors": [
      "Giovanni Sutanto",
      "Katharina Rombach",
      "Yevgen Chebotar",
      "Zhe Su",
      "Stefan Schaal",
      "Gaurav S. Sukhatme",
      "Franziska Meier"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2007.00450"
  },
  {
    "id": "arXiv:2007.06309",
    "title": "Part-aware Prototype Network for Few-shot Semantic Segmentation",
    "abstract": "Comments: ECCV-2020",
    "descriptor": "\nComments: ECCV-2020\n",
    "authors": [
      "Yongfei Liu",
      "Xiangyi Zhang",
      "Songyang Zhang",
      "Xuming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.06309"
  },
  {
    "id": "arXiv:2007.06665",
    "title": "A CMOS Ising Machines with Coupled Bistable Nodes",
    "abstract": "Comments: 25 pages, 18 figures, 1 tables, 5 sections,",
    "descriptor": "\nComments: 25 pages, 18 figures, 1 tables, 5 sections,\n",
    "authors": [
      "Richard Afoakwa",
      "Yiqiao Zhang",
      "Uday Kumar Reddy Vengalam",
      "Zeljko Ignjatovic",
      "Michael Huang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2007.06665"
  },
  {
    "id": "arXiv:2010.10421",
    "title": "Distributed ADMM with linear updates over directed networks",
    "abstract": "Distributed ADMM with linear updates over directed networks",
    "descriptor": "",
    "authors": [
      "Kiran Rokade",
      "Rachel Kalpana Kalaimani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.10421"
  },
  {
    "id": "arXiv:2010.10631",
    "title": "ENSURE: A General Approach for Unsupervised Training of Deep Image  Reconstruction Algorithms",
    "abstract": "ENSURE: A General Approach for Unsupervised Training of Deep Image  Reconstruction Algorithms",
    "descriptor": "",
    "authors": [
      "Hemant Kumar Aggarwal",
      "Aniket Pramanik",
      "Maneesh John",
      "Mathews Jacob"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.10631"
  },
  {
    "id": "arXiv:2012.03461",
    "title": "Seeking Consensus on Subspaces in Federated Principal Component Analysis",
    "abstract": "Seeking Consensus on Subspaces in Federated Principal Component Analysis",
    "descriptor": "",
    "authors": [
      "Lei Wang",
      "Xin Liu",
      "Yin Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2012.03461"
  },
  {
    "id": "arXiv:2102.00824",
    "title": "HAMMER: Multi-Level Coordination of Reinforcement Learning Agents via  Learned Messaging",
    "abstract": "HAMMER: Multi-Level Coordination of Reinforcement Learning Agents via  Learned Messaging",
    "descriptor": "",
    "authors": [
      "Nikunj Gupta",
      "G Srinivasaraghavan",
      "Swarup Kumar Mohalik",
      "Nishant Kumar",
      "Matthew E. Taylor"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.00824"
  },
  {
    "id": "arXiv:2102.09785",
    "title": "Deep Learning-based Beam Tracking for Millimeter-wave Communications  under Mobility",
    "abstract": "Comments: 23 pages, 8 figures",
    "descriptor": "\nComments: 23 pages, 8 figures\n",
    "authors": [
      "Sun Hong Lim",
      "Sunwoo Kim",
      "Byonghyo Shim",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09785"
  },
  {
    "id": "arXiv:2106.13274",
    "title": "Prediction of geophysical properties of rocks on rare well data and  attributes of seismic waves by machine learning methods on the example of the  Achimov formation",
    "abstract": "Comments: 15 pages, 10 figures, 1 table",
    "descriptor": "\nComments: 15 pages, 10 figures, 1 table\n",
    "authors": [
      "Dmitry Ivlev"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13274"
  },
  {
    "id": "arXiv:2107.10822",
    "title": "Lower Bounds for Maximally Recoverable Tensor Code and Higher Order MDS  Codes",
    "abstract": "Comments: 34 pages, in IEEE Transactions on Information Theory",
    "descriptor": "\nComments: 34 pages, in IEEE Transactions on Information Theory\n",
    "authors": [
      "Joshua Brakensiek",
      "Sivakanth Gopi",
      "Visu Makam"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.10822"
  },
  {
    "id": "arXiv:2108.02479",
    "title": "HyperJump: Accelerating HyperBand via Risk Modelling",
    "abstract": "HyperJump: Accelerating HyperBand via Risk Modelling",
    "descriptor": "",
    "authors": [
      "Pedro Mendes",
      "Maria Casimiro",
      "Paolo Romano",
      "David Garlan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.02479"
  },
  {
    "id": "arXiv:2109.07962",
    "title": "Stochastic Modelling of Symmetric Positive Definite Material Tensors",
    "abstract": "Stochastic Modelling of Symmetric Positive Definite Material Tensors",
    "descriptor": "",
    "authors": [
      "Sharana Kumar Shivanand",
      "Bojana Rosi\u0107",
      "Hermann G. Matthies"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2109.07962"
  },
  {
    "id": "arXiv:2109.09488",
    "title": "On the Convergence of Tsetlin Machines for the AND and the OR Operators",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2101.02547",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2101.02547\n",
    "authors": [
      "Lei Jiao",
      "Xuan Zhang",
      "Ole-Christoffer Granmo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.09488"
  },
  {
    "id": "arXiv:2109.10774",
    "title": "\"It's a Trap!\"-How Speculation Invariance Can Be Abused with Forward  Speculative Interference",
    "abstract": "Comments: Presented at 28th IEEE International Symposium on High-Performance Computer Architecture (HPCA-28) 2022 in \"Best of CAL\" session and IEEE International Symposium On Secure And Private Execution Enviroment Design (SEED) 2021. A version of this manuscript has been published in IEEE Computer Architecture Letters (CAL) 2021",
    "descriptor": "\nComments: Presented at 28th IEEE International Symposium on High-Performance Computer Architecture (HPCA-28) 2022 in \"Best of CAL\" session and IEEE International Symposium On Secure And Private Execution Enviroment Design (SEED) 2021. A version of this manuscript has been published in IEEE Computer Architecture Letters (CAL) 2021\n",
    "authors": [
      "Pavlos Aimoniotis",
      "Christos Sakalis",
      "Magnus Sj\u00e4lander",
      "Stefanos Kaxiras"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2109.10774"
  },
  {
    "id": "arXiv:2109.12225",
    "title": "List-GRAND: A practical way to achieve Maximum Likelihood Decoding",
    "abstract": "Comments: This article has been accepted for publication in IEEE Transactions on Very Large Scale Integration (VLSI) Systems. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TVLSI.2022.3223692",
    "descriptor": "\nComments: This article has been accepted for publication in IEEE Transactions on Very Large Scale Integration (VLSI) Systems. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TVLSI.2022.3223692\n",
    "authors": [
      "Syed Mohsin Abbas",
      "Marwan Jalaleddine",
      "Warren J. Gross"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.12225"
  },
  {
    "id": "arXiv:2109.13098",
    "title": "One-Hot Graph Encoder Embedding",
    "abstract": "Comments: 7 pages main + 7 pages appendix",
    "descriptor": "\nComments: 7 pages main + 7 pages appendix\n",
    "authors": [
      "Cencheng Shen",
      "Qizhe Wang",
      "Carey E. Priebe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.13098"
  },
  {
    "id": "arXiv:2110.04450",
    "title": "Scene Editing as Teleoperation: A Case Study in 6DoF Kit Assembly",
    "abstract": "Scene Editing as Teleoperation: A Case Study in 6DoF Kit Assembly",
    "descriptor": "",
    "authors": [
      "Yulong Li",
      "Shubham Agrawal",
      "Jen-Shuo Liu",
      "Steven K. Feiner",
      "Shuran Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04450"
  },
  {
    "id": "arXiv:2110.07186",
    "title": "An FPGA-Based Fully Pipelined Bilateral Grid for Real-Time Image  Denoising",
    "abstract": "Comments: 7 pages, 12 figures, 2 tables, FPL 2021 (Full paper), Program and Abstract: this https URL , Slides: this https URL , Movie: this https URL , Profile: this https URL",
    "descriptor": "\nComments: 7 pages, 12 figures, 2 tables, FPL 2021 (Full paper), Program and Abstract: this https URL , Slides: this https URL , Movie: this https URL , Profile: this https URL\n",
    "authors": [
      "Nobuho Hashimoto",
      "Shinya Takamaeda-Yamazaki"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.07186"
  },
  {
    "id": "arXiv:2110.07653",
    "title": "Non-intrusive reduced-order models for parametric partial differential  equations via data-driven operator inference",
    "abstract": "Non-intrusive reduced-order models for parametric partial differential  equations via data-driven operator inference",
    "descriptor": "",
    "authors": [
      "Shane A McQuarrie",
      "Parisa Khodabakhshi",
      "Karen E Willcox"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.07653"
  },
  {
    "id": "arXiv:2111.00772",
    "title": "AdaPool: Exponential Adaptive Pooling for Information-Retaining  Downsampling",
    "abstract": "AdaPool: Exponential Adaptive Pooling for Information-Retaining  Downsampling",
    "descriptor": "",
    "authors": [
      "Alexandros Stergiou",
      "Ronald Poppe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00772"
  },
  {
    "id": "arXiv:2111.05211",
    "title": "Robot control for simultaneous impact tasks via Quadratic  Programming-based reference spreading",
    "abstract": "Comments: 8 pages, 6 figures, accepted for the IEEE for the American Control Conference (ACC) 2022",
    "descriptor": "\nComments: 8 pages, 6 figures, accepted for the IEEE for the American Control Conference (ACC) 2022\n",
    "authors": [
      "Jari J. van Steen",
      "Nathan van de Wouw",
      "Alessandro Saccon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.05211"
  },
  {
    "id": "arXiv:2111.11661",
    "title": "Optimum Noise Mechanism for Differentially Private Queries in Discrete  Finite Sets",
    "abstract": "Comments: 13 pages, 24 figures",
    "descriptor": "\nComments: 13 pages, 24 figures\n",
    "authors": [
      "Sachin Kadam",
      "Anna Scaglione",
      "Nikhil Ravi",
      "Sean Peisert",
      "Brent Lunghino",
      "Aram Shumavon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.11661"
  },
  {
    "id": "arXiv:2111.14726",
    "title": "Do Invariances in Deep Neural Networks Align with Human Perception?",
    "abstract": "Comments: AAAI 2023",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Vedant Nanda",
      "Ayan Majumdar",
      "Camila Kolling",
      "John P. Dickerson",
      "Krishna P. Gummadi",
      "Bradley C. Love",
      "Adrian Weller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14726"
  },
  {
    "id": "arXiv:2111.15546",
    "title": "Black box tests for algorithmic stability",
    "abstract": "Comments: 37 pages. Some of Section 5.1 has been moved under a new section, Section 4.2. Section 5.2 is now Section 4.3, and its content has been substantially expanded. The proof of Theorem 2 has been simplified to reflect the update to Definition 1. A short proof now follows the statement of Theorem 5. This update also clarifies measurability and symmetry for randomized algorithms",
    "descriptor": "\nComments: 37 pages. Some of Section 5.1 has been moved under a new section, Section 4.2. Section 5.2 is now Section 4.3, and its content has been substantially expanded. The proof of Theorem 2 has been simplified to reflect the update to Definition 1. A short proof now follows the statement of Theorem 5. This update also clarifies measurability and symmetry for randomized algorithms\n",
    "authors": [
      "Byol Kim",
      "Rina Foygel Barber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2111.15546"
  },
  {
    "id": "arXiv:2112.05282",
    "title": "RamBoAttack: A Robust Query Efficient Deep Neural Network Decision  Exploit",
    "abstract": "Comments: Published in Network and Distributed System Security (NDSS) Symposium 2022",
    "descriptor": "\nComments: Published in Network and Distributed System Security (NDSS) Symposium 2022\n",
    "authors": [
      "Viet Quoc Vo",
      "Ehsan Abbasnejad",
      "Damith C. Ranasinghe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.05282"
  },
  {
    "id": "arXiv:2112.05563",
    "title": "D*+: A Risk Aware Platform Agnostic Heterogeneous Path Planner",
    "abstract": "Comments: 35 pages, 24 figures, submitted to Expert System With Application",
    "descriptor": "\nComments: 35 pages, 24 figures, submitted to Expert System With Application\n",
    "authors": [
      "Samuel Karlsson",
      "Anton Koval",
      "Christoforos Kanellakis",
      "George Nikolakopoulos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.05563"
  },
  {
    "id": "arXiv:2112.06596",
    "title": "SAC-GAN: Structure-Aware Image Composition",
    "abstract": "Comments: Accepted to TVCG. Code: this https URL",
    "descriptor": "\nComments: Accepted to TVCG. Code: this https URL\n",
    "authors": [
      "Hang Zhou",
      "Rui Ma",
      "Ling-Xiao Zhang",
      "Lin Gao",
      "Ali Mahdavi-Amiri",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06596"
  },
  {
    "id": "arXiv:2112.10936",
    "title": "Watch Those Words: Video Falsification Detection Using Word-Conditioned  Facial Motion",
    "abstract": "Comments: Accepted in WACV 2023",
    "descriptor": "\nComments: Accepted in WACV 2023\n",
    "authors": [
      "Shruti Agarwal",
      "Liwen Hu",
      "Evonne Ng",
      "Trevor Darrell",
      "Hao Li",
      "Anna Rohrbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.10936"
  },
  {
    "id": "arXiv:2201.04626",
    "title": "Desynchronous Learning in a Physics-Driven Learning Network",
    "abstract": "Comments: 6 pages 4 figures",
    "descriptor": "\nComments: 6 pages 4 figures\n",
    "authors": [
      "Jacob F Wycoff",
      "Sam Dillavou",
      "Menachem Stern",
      "Andrea J Liu",
      "Douglas J Durian"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.04626"
  },
  {
    "id": "arXiv:2201.06021",
    "title": "Rawlsian Fairness in Online Bipartite Matching: Two-sided, Group, and  Individual",
    "abstract": "Comments: Accepted to AAAI 2023",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Seyed A. Esmaeili",
      "Sharmila Duppala",
      "Davidson Cheng",
      "Vedant Nanda",
      "Aravind Srinivasan",
      "John P. Dickerson"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.06021"
  },
  {
    "id": "arXiv:2201.06931",
    "title": "Deep Equilibrium Models for Video Snapshot Compressive Imaging",
    "abstract": "Comments: 9 pages, 7 figures",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Yaping Zhao",
      "Siming Zheng",
      "Xin Yuan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.06931"
  },
  {
    "id": "arXiv:2201.10929",
    "title": "Task-Oriented Image Semantic Communication Based on Rate-Distortion  Theory",
    "abstract": "Comments: 17 pages, 8 figures",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Fangfang Liu",
      "Wanjie Tong",
      "Yang Yang",
      "Zhengfen Sun",
      "Caili Guo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.10929"
  },
  {
    "id": "arXiv:2201.12741",
    "title": "GARNET: Reduced-Rank Topology Learning for Robust and Scalable Graph  Neural Networks",
    "abstract": "Comments: Published as a conference paper at LoG 2022",
    "descriptor": "\nComments: Published as a conference paper at LoG 2022\n",
    "authors": [
      "Chenhui Deng",
      "Xiuyu Li",
      "Zhuo Feng",
      "Zhiru Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12741"
  },
  {
    "id": "arXiv:2201.13094",
    "title": "Designing Universal Causal Deep Learning Models: The Geometric  (Hyper)Transformer",
    "abstract": "Comments: Main Body: 31 Pages, Proofs: 16 Pages, Figures: 13, Tables: 3",
    "descriptor": "\nComments: Main Body: 31 Pages, Proofs: 16 Pages, Figures: 13, Tables: 3\n",
    "authors": [
      "Beatrice Acciaio",
      "Anastasis Kratsios",
      "Gudmund Pammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Metric Geometry (math.MG)",
      "Probability (math.PR)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2201.13094"
  },
  {
    "id": "arXiv:2202.02607",
    "title": "Adaptive Risk-Limiting Ballot Comparison Audits",
    "abstract": "Comments: 33 pages. Substantial technical and editorial revision",
    "descriptor": "\nComments: 33 pages. Substantial technical and editorial revision\n",
    "authors": [
      "Benjamin Fuller",
      "Abigail Harrison",
      "Alexander Russell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02607"
  },
  {
    "id": "arXiv:2202.05623",
    "title": "A Wasserstein GAN for Joint Learning of Inpainting and Spatial  Optimisation",
    "abstract": "A Wasserstein GAN for Joint Learning of Inpainting and Spatial  Optimisation",
    "descriptor": "",
    "authors": [
      "Pascal Peter"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05623"
  },
  {
    "id": "arXiv:2202.06392",
    "title": "Local approximation of operators",
    "abstract": "Local approximation of operators",
    "descriptor": "",
    "authors": [
      "Hrushikesh Mhaskar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2202.06392"
  },
  {
    "id": "arXiv:2202.07141",
    "title": "Machine Learning in Aerodynamic Shape Optimization",
    "abstract": "Comments: 103 pages, 47 figures, published by Progress in Aerospace Sciences",
    "descriptor": "\nComments: 103 pages, 47 figures, published by Progress in Aerospace Sciences\n",
    "authors": [
      "Jichao Li",
      "Xiaosong Du",
      "Joaquim R. R. A. Martins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.07141"
  },
  {
    "id": "arXiv:2202.07679",
    "title": "Taking a Step Back with KCal: Multi-Class Kernel-Based Calibration for  Deep Neural Networks",
    "abstract": "Taking a Step Back with KCal: Multi-Class Kernel-Based Calibration for  Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.07679"
  },
  {
    "id": "arXiv:2203.04899",
    "title": "Convergence Rate Analysis of Galerkin Approximation of Inverse Potential  Problem",
    "abstract": "Comments: 23 pages, 4 figures",
    "descriptor": "\nComments: 23 pages, 4 figures\n",
    "authors": [
      "Bangti Jin",
      "Xiliang Lu",
      "Qimeng Quan",
      "Zhi Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.04899"
  },
  {
    "id": "arXiv:2203.05156",
    "title": "End-to-End Semantic Video Transformer for Zero-Shot Action Recognition",
    "abstract": "End-to-End Semantic Video Transformer for Zero-Shot Action Recognition",
    "descriptor": "",
    "authors": [
      "Keval Doshi",
      "Yasin Yilmaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05156"
  },
  {
    "id": "arXiv:2203.09167",
    "title": "Unsigned Distance Field as an Accurate 3D Scene Representation for  Neural Scene Completion",
    "abstract": "Comments: 8 pages, 7 figures, 5 tables",
    "descriptor": "\nComments: 8 pages, 7 figures, 5 tables\n",
    "authors": [
      "Jean Pierre Richa",
      "Jean-Emmanuel Deschaud",
      "Fran\u00e7ois Goulette",
      "Nicolas Dalmasso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09167"
  },
  {
    "id": "arXiv:2203.09376",
    "title": "Escaping from the Barren Plateau via Gaussian Initializations in Deep  Variational Quantum Circuits",
    "abstract": "Comments: Accepted version (to NeurIPS 2022). Title changed",
    "descriptor": "\nComments: Accepted version (to NeurIPS 2022). Title changed\n",
    "authors": [
      "Kaining Zhang",
      "Liu Liu",
      "Min-Hsiu Hsieh",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09376"
  },
  {
    "id": "arXiv:2203.14944",
    "title": "Differentiable Microscopy Designs an All Optical Quantitative Phase  Microscope",
    "abstract": "Differentiable Microscopy Designs an All Optical Quantitative Phase  Microscope",
    "descriptor": "",
    "authors": [
      "Kithmini Herath",
      "Udith Haputhanthri",
      "Ramith Hettiarachchi",
      "Hasindu Kariyawasam",
      "Raja N. Ahmad",
      "Azeem Ahmad",
      "Balpreet S. Ahluwalia",
      "Chamira U. S. Edussooriya",
      "Dushan Wadduwage"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.14944"
  },
  {
    "id": "arXiv:2203.16228",
    "title": "An Efficiency-Based Power Management Strategy for an Isolated Microgrid  Project",
    "abstract": "Comments: 2022 IEEE Power & Energy Society General Meeting (PESGM)",
    "descriptor": "\nComments: 2022 IEEE Power & Energy Society General Meeting (PESGM)\n",
    "authors": [
      "Francesco Conte",
      "Fabio D'Agostino",
      "Samuele Grillo",
      "Gabriele Mosaico",
      "Federico Silvestro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16228"
  },
  {
    "id": "arXiv:2204.00570",
    "title": "Connect, Not Collapse: Explaining Contrastive Learning for Unsupervised  Domain Adaptation",
    "abstract": "Comments: ICML 2022 (Long Talk)",
    "descriptor": "\nComments: ICML 2022 (Long Talk)\n",
    "authors": [
      "Kendrick Shen",
      "Robbie Jones",
      "Ananya Kumar",
      "Sang Michael Xie",
      "Jeff Z. HaoChen",
      "Tengyu Ma",
      "Percy Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.00570"
  },
  {
    "id": "arXiv:2204.01560",
    "title": "SecureSense: Defending Adversarial Attack for Secure Device-Free Human  Activity Recognition",
    "abstract": "Comments: The paper is accepted by IEEE Transactions on Mobile Computing",
    "descriptor": "\nComments: The paper is accepted by IEEE Transactions on Mobile Computing\n",
    "authors": [
      "Jianfei Yang",
      "Han Zou",
      "Lihua Xie"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.01560"
  },
  {
    "id": "arXiv:2204.02654",
    "title": "Adversarial Analysis of the Differentially-Private Federated Learning in  Cyber-Physical Critical Infrastructures",
    "abstract": "Comments: 16 pages, 9 figures, 5 tables. This work has been submitted to IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 16 pages, 9 figures, 5 tables. This work has been submitted to IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Md Tamjid Hossain",
      "Shahriar Badsha",
      "Hung La",
      "Haoting Shen",
      "Shafkat Islam",
      "Ibrahim Khalil",
      "Xun Yi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.02654"
  },
  {
    "id": "arXiv:2204.05419",
    "title": "Can Self-Supervised Learning solve the problem of child speech  recognition?",
    "abstract": "Can Self-Supervised Learning solve the problem of child speech  recognition?",
    "descriptor": "",
    "authors": [
      "Rishabh Jain",
      "Mariam Yiwere",
      "Dan Bigioi",
      "Peter Corcoran"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.05419"
  },
  {
    "id": "arXiv:2204.06068",
    "title": "Encodability Criteria for Quantum Based Systems",
    "abstract": "Comments: preprint for submission to LMCS",
    "descriptor": "\nComments: preprint for submission to LMCS\n",
    "authors": [
      "Anna Schmitt",
      "Kirstin Peters",
      "Yuxin Deng"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.06068"
  },
  {
    "id": "arXiv:2204.06450",
    "title": "The effect of speech pathology on automatic speaker verification -- a  large-scale study",
    "abstract": "The effect of speech pathology on automatic speaker verification -- a  large-scale study",
    "descriptor": "",
    "authors": [
      "Soroosh Tayebi Arasteh",
      "Tobias Weise",
      "Maria Schuster",
      "Elmar Noeth",
      "Andreas Maier",
      "Seung Hee Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.06450"
  },
  {
    "id": "arXiv:2204.06674",
    "title": "GAP: A Graph-aware Language Model Framework for Knowledge Graph-to-Text  Generation",
    "abstract": "Comments: Accepted as a Main Conference Long paper at COLING 2022",
    "descriptor": "\nComments: Accepted as a Main Conference Long paper at COLING 2022\n",
    "authors": [
      "Anthony Colas",
      "Mehrdad Alvandipour",
      "Daisy Zhe Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.06674"
  },
  {
    "id": "arXiv:2204.07454",
    "title": "Formalizing $\\varphi$-calculus: a purely object-oriented calculus of  decorated objects",
    "abstract": "Formalizing $\\varphi$-calculus: a purely object-oriented calculus of  decorated objects",
    "descriptor": "",
    "authors": [
      "Nikolai Kudasov",
      "Violetta Sim"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.07454"
  },
  {
    "id": "arXiv:2204.07682",
    "title": "Data-centric Reliability Evaluation of Individual Predictions",
    "abstract": "Data-centric Reliability Evaluation of Individual Predictions",
    "descriptor": "",
    "authors": [
      "Nima Shahbazi",
      "Abolfazl Asudeh"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2204.07682"
  },
  {
    "id": "arXiv:2204.07728",
    "title": "FTMPST: Fault-Tolerant Multiparty Session Types",
    "abstract": "Comments: preprint for submission to LMCS",
    "descriptor": "\nComments: preprint for submission to LMCS\n",
    "authors": [
      "Kirstin Peters",
      "Uwe Nestmann",
      "Christoph Wagner"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.07728"
  },
  {
    "id": "arXiv:2204.11910",
    "title": "Integrating Reward Maximization and Population Estimation: Sequential  Decision-Making for Internal Revenue Service Audit Selection",
    "abstract": "Comments: Accepted to the Thirty-Seventh AAAI Conference On Artificial Intelligence (AAAI), 2023",
    "descriptor": "\nComments: Accepted to the Thirty-Seventh AAAI Conference On Artificial Intelligence (AAAI), 2023\n",
    "authors": [
      "Peter Henderson",
      "Ben Chugg",
      "Brandon Anderson",
      "Kristen Altenburger",
      "Alex Turk",
      "John Guyton",
      "Jacob Goldin",
      "Daniel E. Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.11910"
  },
  {
    "id": "arXiv:2204.13454",
    "title": "A new certified hierarchical and adaptive RB-ML-ROM surrogate model for  parametrized PDEs",
    "abstract": "Comments: 27 pages, 5 figures",
    "descriptor": "\nComments: 27 pages, 5 figures\n",
    "authors": [
      "B. Haasdonk",
      "H. Kleikamp",
      "M. Ohlberger",
      "F. Schindler",
      "T. Wenzel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.13454"
  },
  {
    "id": "arXiv:2205.09613",
    "title": "Integrally Migrating Pre-trained Transformer Encoder-decoders for Visual  Object Detection",
    "abstract": "Comments: 6 figures, 6 tables",
    "descriptor": "\nComments: 6 figures, 6 tables\n",
    "authors": [
      "Feng Liu",
      "Xiaosong Zhang",
      "Zhiliang Peng",
      "Zonghao Guo",
      "Fang Wan",
      "Xiangyang Ji",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09613"
  },
  {
    "id": "arXiv:2205.11245",
    "title": "PASH at TREC 2021 Deep Learning Track: Generative Enhanced Model for  Multi-stage Ranking",
    "abstract": "Comments: TREC 2021",
    "descriptor": "\nComments: TREC 2021\n",
    "authors": [
      "Yixuan Qiao",
      "Hao Chen",
      "Jun Wang",
      "Yongquan Lai",
      "Tuozhen Liu",
      "Xianbin Ye",
      "Xin Tang",
      "Rui Fang",
      "Peng Gao",
      "Wenfeng Xie",
      "Guotong Xie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11245"
  },
  {
    "id": "arXiv:2205.12358",
    "title": "A Benchmark and Asymmetrical-Similarity Learning for Practical Image  Copy Detection",
    "abstract": "Comments: Accepted to AAAI 2023",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Wenhao Wang",
      "Yifan Sun",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12358"
  },
  {
    "id": "arXiv:2205.12721",
    "title": "Accelerating High-Order Mesh Optimization Using Finite Element Partial  Assembly on GPUs",
    "abstract": "Comments: 28 pages, 10 figures, 3 tables",
    "descriptor": "\nComments: 28 pages, 10 figures, 3 tables\n",
    "authors": [
      "Jean-Sylvain Camier",
      "Veselin Dobrev",
      "Patrick Knupp",
      "Tzanio Kolev",
      "Ketan Mittal",
      "Robert Rieben",
      "Vladimir Tomov"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.12721"
  },
  {
    "id": "arXiv:2205.13527",
    "title": "Subspace clustering in high-dimensions: Phase transitions &  Statistical-to-Computational gap",
    "abstract": "Comments: NeurIPS camera-ready version",
    "descriptor": "\nComments: NeurIPS camera-ready version\n",
    "authors": [
      "Luca Pesce",
      "Bruno Loureiro",
      "Florent Krzakala",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.13527"
  },
  {
    "id": "arXiv:2205.15516",
    "title": "Multi-Scan Multi-Sensor Multi-Object State Estimation",
    "abstract": "Multi-Scan Multi-Sensor Multi-Object State Estimation",
    "descriptor": "",
    "authors": [
      "D. Moratuwage",
      "B.-N. Vo",
      "B.-T. Vo",
      "C. Shim"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.15516"
  },
  {
    "id": "arXiv:2205.15993",
    "title": "Characterization of integral input-to-state stability for nonlinear  time-varying systems of infinite dimension",
    "abstract": "Comments: Submitted to SIAM J Control and Optimization",
    "descriptor": "\nComments: Submitted to SIAM J Control and Optimization\n",
    "authors": [
      "Jos\u00e9 L. Mancilla-Aguilar",
      "Jos\u00e9 E. Rojas-Ruiz",
      "Hernan Haimovich"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.15993"
  },
  {
    "id": "arXiv:2206.05897",
    "title": "$\\texttt{GradICON}$: Approximate Diffeomorphisms via Gradient Inverse  Consistency",
    "abstract": "Comments: 29 pages, 16 figures",
    "descriptor": "\nComments: 29 pages, 16 figures\n",
    "authors": [
      "Lin Tian",
      "Hastings Greer",
      "Fran\u00e7ois-Xavier Vialard",
      "Roland Kwitt",
      "Ra\u00fal San Jos\u00e9 Est\u00e9par",
      "Richard Jarrett Rushmore",
      "Nikolaos Makris",
      "Sylvain Bouix",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.05897"
  },
  {
    "id": "arXiv:2206.09527",
    "title": "Simultaneous approximation of a smooth function and its derivatives by  deep neural networks with piecewise-polynomial activations",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Denis Belomestny",
      "Alexey Naumov",
      "Nikita Puchkin",
      "Sergey Samsonov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09527"
  },
  {
    "id": "arXiv:2206.13839",
    "title": "On the Calculation of the Variance of Algebraic Variables in Power  System Dynamic Models with Stochastic Processes",
    "abstract": "On the Calculation of the Variance of Algebraic Variables in Power  System Dynamic Models with Stochastic Processes",
    "descriptor": "",
    "authors": [
      "Muhammad Adeen",
      "Federico Bizzarri",
      "Davide del Giudice",
      "Samuele Grillo",
      "Daniele Linaro",
      "Angelo Brambilla",
      "Federico Milano"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13839"
  },
  {
    "id": "arXiv:2206.14423",
    "title": "The Mutual Visibility Problem for Fat Robots",
    "abstract": "The Mutual Visibility Problem for Fat Robots",
    "descriptor": "",
    "authors": [
      "Rusul J. Alsaedi",
      "Joachim Gudmundsson",
      "Andr\u00e9 van Renssen"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2206.14423"
  },
  {
    "id": "arXiv:2206.14754",
    "title": "Distilling Model Failures as Directions in Latent Space",
    "abstract": "Distilling Model Failures as Directions in Latent Space",
    "descriptor": "",
    "authors": [
      "Saachi Jain",
      "Hannah Lawrence",
      "Ankur Moitra",
      "Aleksander Madry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14754"
  },
  {
    "id": "arXiv:2206.15274",
    "title": "Augment like there's no tomorrow: Consistently performing neural  networks for medical imaging",
    "abstract": "Comments: Code for the paper is available from this https URL",
    "descriptor": "\nComments: Code for the paper is available from this https URL\n",
    "authors": [
      "Joona Pohjonen",
      "Carolin St\u00fcrenberg",
      "Atte F\u00f6hr",
      "Reija Randen-Brady",
      "Lassi Luomala",
      "Jouni Lohi",
      "Esa Pitk\u00e4nen",
      "Antti Rannikko",
      "Tuomas Mirtti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15274"
  },
  {
    "id": "arXiv:2207.02295",
    "title": "Implementing Reinforcement Learning Datacenter Congestion Control in  NVIDIA NICs",
    "abstract": "Implementing Reinforcement Learning Datacenter Congestion Control in  NVIDIA NICs",
    "descriptor": "",
    "authors": [
      "Benjamin Fuhrer",
      "Yuval Shpigelman",
      "Chen Tessler",
      "Shie Mannor",
      "Gal Chechik",
      "Eitan Zahavi",
      "Gal Dalal"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02295"
  },
  {
    "id": "arXiv:2207.02449",
    "title": "Information Compression and Performance Evaluation of Tic-Tac-Toe's  Evaluation Function Using Singular Value Decomposition",
    "abstract": "Comments: 15 pages, 5 figures, Updated contents",
    "descriptor": "\nComments: 15 pages, 5 figures, Updated contents\n",
    "authors": [
      "Naoya Fujita",
      "Hiroshi Watanabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.02449"
  },
  {
    "id": "arXiv:2207.03928",
    "title": "Generative Toolkit for Scientific Discovery",
    "abstract": "Comments: 14 pages, 2 figures",
    "descriptor": "\nComments: 14 pages, 2 figures\n",
    "authors": [
      "Matteo Manica",
      "Joris Cadow",
      "Dimitrios Christofidellis",
      "Ashish Dave",
      "Jannis Born",
      "Dean Clarke",
      "Yves Gaetan Nana Teukam",
      "Samuel C. Hoffman",
      "Matthew Buchan",
      "Vijil Chenthamarakshan",
      "Timothy Donovan",
      "Hsiang Han Hsu",
      "Federico Zipoli",
      "Oliver Schilter",
      "Giorgio Giannone",
      "Akihiro Kishimoto",
      "Lisa Hamada",
      "Inkit Padhi",
      "Karl Wehden",
      "Lauren McHugh",
      "Alexy Khrabrov",
      "Payel Das",
      "Seiji Takeda",
      "John R. Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.03928"
  },
  {
    "id": "arXiv:2207.04125",
    "title": "Out of Distribution Detection via Neural Network Anchoring",
    "abstract": "Comments: ACML 2022",
    "descriptor": "\nComments: ACML 2022\n",
    "authors": [
      "Rushil Anirudh",
      "Jayaraman J. Thiagarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04125"
  },
  {
    "id": "arXiv:2207.04132",
    "title": "Cross-Attention Transformer for Video Interpolation",
    "abstract": "Cross-Attention Transformer for Video Interpolation",
    "descriptor": "",
    "authors": [
      "Hannah Halin Kim",
      "Shuzhi Yu",
      "Shuai Yuan",
      "Carlo Tomasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04132"
  },
  {
    "id": "arXiv:2207.04635",
    "title": "Optimal Storage and Solar Capacity of a Residential Household under Net  Metering and Time-of-Use Pricing",
    "abstract": "Optimal Storage and Solar Capacity of a Residential Household under Net  Metering and Time-of-Use Pricing",
    "descriptor": "",
    "authors": [
      "K. Victor Sam Moses Babu",
      "Pratyush Chakraborty",
      "Enrique Baeyens",
      "Pramod P. Khargonekar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04635"
  },
  {
    "id": "arXiv:2207.05740",
    "title": "The d-separation criterion in Categorical Probability",
    "abstract": "Comments: 42 pages, v2: more examples and an extended introduction",
    "descriptor": "\nComments: 42 pages, v2: more examples and an extended introduction\n",
    "authors": [
      "Tobias Fritz",
      "Andreas Klingler"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.05740"
  },
  {
    "id": "arXiv:2207.07235",
    "title": "Single Model Uncertainty Estimation via Stochastic Data Centering",
    "abstract": "Comments: Spotlight at NeurIPS 2022",
    "descriptor": "\nComments: Spotlight at NeurIPS 2022\n",
    "authors": [
      "Jayaraman J. Thiagarajan",
      "Rushil Anirudh",
      "Vivek Narayanaswamy",
      "Peer-Timo Bremer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.07235"
  },
  {
    "id": "arXiv:2207.07369",
    "title": "A Systematic Literature Review of Game-based Assessment Studies: Trends  and Challenges",
    "abstract": "Comments: 25 pages, 12 figures, 1 table",
    "descriptor": "\nComments: 25 pages, 12 figures, 1 table\n",
    "authors": [
      "Manuel J. Gomez",
      "Jos\u00e9 A. Ruip\u00e9rez-Valiente",
      "F\u00e9lix J. Garc\u00eda Clemente"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.07369"
  },
  {
    "id": "arXiv:2207.11401",
    "title": "Chunk-aware Alignment and Lexical Constraint for Visual Entailment with  Natural Language Explanations",
    "abstract": "Comments: 11 pages (including Supplementary Materials); Accepted to ACM MM 2022",
    "descriptor": "\nComments: 11 pages (including Supplementary Materials); Accepted to ACM MM 2022\n",
    "authors": [
      "Qian Yang",
      "Yunxin Li",
      "Baotian Hu",
      "Lin Ma",
      "Yuxing Ding",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.11401"
  },
  {
    "id": "arXiv:2207.12062",
    "title": "Adaptive Asynchronous Control Using Meta-learned Neural Ordinary  Differential Equations",
    "abstract": "Comments: 13 double column pages, 10 figures, 4 algorithms, 3 tables",
    "descriptor": "\nComments: 13 double column pages, 10 figures, 4 algorithms, 3 tables\n",
    "authors": [
      "Achkan Salehi",
      "Steffen R\u00fchl",
      "Stephane Doncieux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.12062"
  },
  {
    "id": "arXiv:2208.01076",
    "title": "Rethinking Quality of Experience for Metaverse Services: A  Consumer-based Economics Perspective",
    "abstract": "Rethinking Quality of Experience for Metaverse Services: A  Consumer-based Economics Perspective",
    "descriptor": "",
    "authors": [
      "Hongyang Du",
      "Bohao Ma",
      "Dusit Niyato",
      "Jiawen Kang",
      "Zehui Xiong",
      "Zhaohui Yang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.01076"
  },
  {
    "id": "arXiv:2208.02045",
    "title": "Common Pairs of Graphs",
    "abstract": "Comments: 50 pages",
    "descriptor": "\nComments: 50 pages\n",
    "authors": [
      "Natalie Behague",
      "Natasha Morrison",
      "Jonathan A. Noel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.02045"
  },
  {
    "id": "arXiv:2208.02656",
    "title": "Invariant Representations with Stochastically Quantized Neural Networks",
    "abstract": "Comments: To appear in AAAI23",
    "descriptor": "\nComments: To appear in AAAI23\n",
    "authors": [
      "Mattia Cerrato",
      "Marius K\u00f6ppel",
      "Roberto Esposito",
      "Stefan Kramer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2208.02656"
  },
  {
    "id": "arXiv:2208.05586",
    "title": "Multi-Factor Key Derivation Function (MFKDF)",
    "abstract": "Multi-Factor Key Derivation Function (MFKDF)",
    "descriptor": "",
    "authors": [
      "Vivek Nair",
      "Dawn Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.05586"
  },
  {
    "id": "arXiv:2208.05650",
    "title": "Diverse Generative Perturbations on Attention Space for Transferable  Adversarial Attacks",
    "abstract": "Comments: ICIP 2022 (Oral)",
    "descriptor": "\nComments: ICIP 2022 (Oral)\n",
    "authors": [
      "Woo Jae Kim",
      "Seunghoon Hong",
      "Sung-Eui Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.05650"
  },
  {
    "id": "arXiv:2208.07199",
    "title": "On The Complexity of Distance-$d$ Independent Set Reconfiguration",
    "abstract": "Comments: 14 pages, 8 figures, minor revision, to appear in WALCOM 2023",
    "descriptor": "\nComments: 14 pages, 8 figures, minor revision, to appear in WALCOM 2023\n",
    "authors": [
      "Duc A. Hoang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2208.07199"
  },
  {
    "id": "arXiv:2208.07670",
    "title": "ConTextual Masked Auto-Encoder for Dense Passage Retrieval",
    "abstract": "Comments: This paper has been accepted by AAAI2023",
    "descriptor": "\nComments: This paper has been accepted by AAAI2023\n",
    "authors": [
      "Xing Wu",
      "Guangyuan Ma",
      "Meng Lin",
      "Zijia Lin",
      "Zhongyuan Wang",
      "Songlin Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.07670"
  },
  {
    "id": "arXiv:2208.09885",
    "title": "HST: Hierarchical Swin Transformer for Compressed Image Super-resolution",
    "abstract": "Comments: Accepted by ECCV2022 Workshop (AIM2022)",
    "descriptor": "\nComments: Accepted by ECCV2022 Workshop (AIM2022)\n",
    "authors": [
      "Bingchen Li",
      "Xin Li",
      "Yiting Lu",
      "Sen Liu",
      "Ruoyu Feng",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.09885"
  },
  {
    "id": "arXiv:2209.01242",
    "title": "Better Peer Grading through Bayesian Inference",
    "abstract": "Better Peer Grading through Bayesian Inference",
    "descriptor": "",
    "authors": [
      "Hedayat Zarkoob",
      "Greg d'Eon",
      "Lena Podina",
      "Kevin Leyton-Brown"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2209.01242"
  },
  {
    "id": "arXiv:2209.03341",
    "title": "Large Scale Enrichment and Statistical Cyber Characterization of Network  Traffic (Enriquecimiento a gran escala y caracterizaci\u00f3n cibern\u00e9tica  estad\u00edstica del tr\u00e1fico de red)",
    "abstract": "Comments: 17 pages, 16 figures, HPEC, Spanish version",
    "descriptor": "\nComments: 17 pages, 16 figures, HPEC, Spanish version\n",
    "authors": [
      "Ivan Kawaminami",
      "Arminda Estrada",
      "Youssef Elsakkary",
      "Hayden Jananthan",
      "Ayd\u0131n Bulu\u00e7",
      "Tim Davis",
      "Daniel Grant",
      "Michael Jones",
      "Chad Meiners",
      "Andrew Morris",
      "Sandeep Pisharody",
      "Jeremy Kepner"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2209.03341"
  },
  {
    "id": "arXiv:2209.06423",
    "title": "SCULPTOR: Skeleton-Consistent Face Creation Using a Learned Parametric  Generator",
    "abstract": "Comments: 16 page, 13 figs",
    "descriptor": "\nComments: 16 page, 13 figs\n",
    "authors": [
      "Zesong Qiu",
      "Yuwei Li",
      "Dongming He",
      "Qixuan Zhang",
      "Longwen Zhang",
      "Yinghao Zhang",
      "Jingya Wang",
      "Lan Xu",
      "Xudong Wang",
      "Yuyao Zhang",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06423"
  },
  {
    "id": "arXiv:2209.08601",
    "title": "Comparative study of machine learning and deep learning methods on ASD  classification",
    "abstract": "Comparative study of machine learning and deep learning methods on ASD  classification",
    "descriptor": "",
    "authors": [
      "Ramchandra Rimal",
      "Mitchell Brannon",
      "Yingxin Wang",
      "Xin Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.08601"
  },
  {
    "id": "arXiv:2209.11153",
    "title": "Bosonic Qiskit",
    "abstract": "Bosonic Qiskit",
    "descriptor": "",
    "authors": [
      "Timothy J Stavenger",
      "Eleanor Crane",
      "Kevin Smith",
      "Christopher T Kang",
      "Steven M Girvin",
      "Nathan Wiebe"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2209.11153"
  },
  {
    "id": "arXiv:2209.12086",
    "title": "One-Shot Learning of Stochastic Differential Equations with Data Adapted  Kernels",
    "abstract": "Comments: 22 pages, 21 figures",
    "descriptor": "\nComments: 22 pages, 21 figures\n",
    "authors": [
      "Matthieu Darcy",
      "Boumediene Hamzi",
      "Giulia Livieri",
      "Houman Owhadi",
      "Peyman Tavallali"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.12086"
  },
  {
    "id": "arXiv:2210.00048",
    "title": "Axioms for Constant Function Market Makers",
    "abstract": "Axioms for Constant Function Market Makers",
    "descriptor": "",
    "authors": [
      "Jan Christoph Schlegel",
      "Mateusz Kwa\u015bnicki",
      "Akaki Mamageishvili"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2210.00048"
  },
  {
    "id": "arXiv:2210.01041",
    "title": "Probabilistic Safeguard for Reinforcement Learning Using Safety Index  Guided Gaussian Process Models",
    "abstract": "Comments: First paper to use Gaussian Process for providing safety guarantee in energy-based safe control",
    "descriptor": "\nComments: First paper to use Gaussian Process for providing safety guarantee in energy-based safe control\n",
    "authors": [
      "Weiye Zhao",
      "Tairan He",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.01041"
  },
  {
    "id": "arXiv:2210.08350",
    "title": "Self-Improving SLAM in Dynamic Environments: Learning When to Mask",
    "abstract": "Comments: Accepted to BMVC 2022. Dataset link: this https URL",
    "descriptor": "\nComments: Accepted to BMVC 2022. Dataset link: this https URL\n",
    "authors": [
      "Adrian Bojko",
      "Romain Dupont",
      "Mohamed Tamaazousti",
      "Herv\u00e9 Le Borgne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08350"
  },
  {
    "id": "arXiv:2210.09147",
    "title": "PARTIME: Scalable and Parallel Processing Over Time with Deep Neural  Networks",
    "abstract": "Comments: 9 pages, accepted at International Conference on Machine Learning and Applications",
    "descriptor": "\nComments: 9 pages, accepted at International Conference on Machine Learning and Applications\n",
    "authors": [
      "Enrico Meloni",
      "Lapo Faggi",
      "Simone Marullo",
      "Alessandro Betti",
      "Matteo Tiezzi",
      "Marco Gori",
      "Stefano Melacci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09147"
  },
  {
    "id": "arXiv:2210.09723",
    "title": "Textual Entailment Recognition with Semantic Features from Empirical  Text Representation",
    "abstract": "Comments: This paper has been accepted in SPELLL 2022, India. This is the primarily submitted version",
    "descriptor": "\nComments: This paper has been accepted in SPELLL 2022, India. This is the primarily submitted version\n",
    "authors": [
      "Md Shajalal",
      "Md Atabuzzaman",
      "Maksuda Bilkis Baby",
      "Md Rezaul Karim",
      "Alexander Boden"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09723"
  },
  {
    "id": "arXiv:2210.09819",
    "title": "Eye-tracking based classification of Mandarin Chinese readers with and  without dyslexia using neural sequence models",
    "abstract": "Eye-tracking based classification of Mandarin Chinese readers with and  without dyslexia using neural sequence models",
    "descriptor": "",
    "authors": [
      "Patrick Haller",
      "Andreas S\u00e4uberli",
      "Sarah Elisabeth Kiener",
      "Jinger Pan",
      "Ming Yan",
      "Lena J\u00e4ger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09819"
  },
  {
    "id": "arXiv:2210.09880",
    "title": "Graphs, Constraints, and Search for the Abstraction and Reasoning Corpus",
    "abstract": "Comments: 9 pages, 5 figures, to be published in AAAI-23",
    "descriptor": "\nComments: 9 pages, 5 figures, to be published in AAAI-23\n",
    "authors": [
      "Yudong Xu",
      "Elias B. Khalil",
      "Scott Sanner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09880"
  },
  {
    "id": "arXiv:2210.10530",
    "title": "Adversarial De-confounding in Individualised Treatment Effects  Estimation",
    "abstract": "Comments: (under review)",
    "descriptor": "\nComments: (under review)\n",
    "authors": [
      "Vinod Kumar Chauhan",
      "Soheila Molaei",
      "Marzia Hoque Tania",
      "Anshul Thakur",
      "Tingting Zhu",
      "David Clifton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2210.10530"
  },
  {
    "id": "arXiv:2210.11068",
    "title": "Frequency of Interest-based Noise Attenuation Method to Improve Anomaly  Detection Performance",
    "abstract": "Comments: 5 pages, 4 figures, 4 tables",
    "descriptor": "\nComments: 5 pages, 4 figures, 4 tables\n",
    "authors": [
      "YeongHyeon Park",
      "Myung Jin Kim",
      "Won Seok Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.11068"
  },
  {
    "id": "arXiv:2210.12036",
    "title": "On the Longest Flip Sequence to Untangle Segments in the Plane",
    "abstract": "Comments: 9 pages, 4 figures, appears in Walcom'23",
    "descriptor": "\nComments: 9 pages, 4 figures, appears in Walcom'23\n",
    "authors": [
      "Guilherme D. da Fonseca",
      "Yan Gerard",
      "Bastien Rivier"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.12036"
  },
  {
    "id": "arXiv:2210.14830",
    "title": "Personalized Federated Learning via Heterogeneous Modular Networks",
    "abstract": "Personalized Federated Learning via Heterogeneous Modular Networks",
    "descriptor": "",
    "authors": [
      "Tianchun Wang",
      "Wei Cheng",
      "Dongsheng Luo",
      "Wenchao Yu",
      "Jingchao Ni",
      "Liang Tong",
      "Haifeng Chen",
      "Xiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14830"
  },
  {
    "id": "arXiv:2210.16053",
    "title": "Automated analysis of diabetic retinopathy using vessel segmentation  maps as inductive bias",
    "abstract": "Comments: Submission for MICCAI 2022 Diabetic Retinopathy Analysis Challenge (DRAC) Proceedings, DOI: 10.5281/zenodo.6362349",
    "descriptor": "\nComments: Submission for MICCAI 2022 Diabetic Retinopathy Analysis Challenge (DRAC) Proceedings, DOI: 10.5281/zenodo.6362349\n",
    "authors": [
      "Linus Kreitner",
      "Ivan Ezhov",
      "Daniel Rueckert",
      "Johannes C. Paetzold",
      "Martin J. Menten"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16053"
  },
  {
    "id": "arXiv:2211.02883",
    "title": "Unified Multi-View Orthonormal Non-Negative Graph Based Clustering  Framework",
    "abstract": "Unified Multi-View Orthonormal Non-Negative Graph Based Clustering  Framework",
    "descriptor": "",
    "authors": [
      "Liangchen Liu",
      "Qiuhong Ke",
      "Chaojie Li",
      "Feiping Nie",
      "Yingying Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02883"
  },
  {
    "id": "arXiv:2211.03115",
    "title": "Data-driven Emergency Frequency Control for Multi-Infeed Hybrid AC-DC  System",
    "abstract": "Data-driven Emergency Frequency Control for Multi-Infeed Hybrid AC-DC  System",
    "descriptor": "",
    "authors": [
      "Qianni Cao",
      "Ye Liu",
      "Chen Shen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.03115"
  },
  {
    "id": "arXiv:2211.04185",
    "title": "Coupled Modeling and Fusion Control for a Multi-modal Deformable  Land-air Robot",
    "abstract": "Coupled Modeling and Fusion Control for a Multi-modal Deformable  Land-air Robot",
    "descriptor": "",
    "authors": [
      "Xinyu Zhang",
      "Yuanhao Huang",
      "Kangyao Huang",
      "Ziqi Zhao",
      "Jingwei Li",
      "Huaping Liu",
      "Jun Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04185"
  },
  {
    "id": "arXiv:2211.05667",
    "title": "What Makes a Good Explanation?: A Harmonized View of Properties of  Explanations",
    "abstract": "Comments: Short version accepted at NeurIPS 2022 workshops on Progress and Challenges in Building Trustworthy Embodied AI and Trustworthy and Socially Responsible Machine Learning",
    "descriptor": "\nComments: Short version accepted at NeurIPS 2022 workshops on Progress and Challenges in Building Trustworthy Embodied AI and Trustworthy and Socially Responsible Machine Learning\n",
    "authors": [
      "Zixi Chen",
      "Varshini Subhash",
      "Marton Havasi",
      "Weiwei Pan",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05667"
  },
  {
    "id": "arXiv:2211.06312",
    "title": "A numerical investigation of dimensionless numbers characterizing  meltpool morphology of the laser powder bed fusion process",
    "abstract": "Comments: Manuscript under review; 13 figures and 7 tables",
    "descriptor": "\nComments: Manuscript under review; 13 figures and 7 tables\n",
    "authors": [
      "Kunal Bhagat",
      "Shiva Rudraraju"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.06312"
  },
  {
    "id": "arXiv:2211.08345",
    "title": "On interpretability and proper latent decomposition of autoencoders",
    "abstract": "Comments: 9 pages, 2 figures, Proceedings of the Summer Program, Center for Turbulence Research, Stanford University",
    "descriptor": "\nComments: 9 pages, 2 figures, Proceedings of the Summer Program, Center for Turbulence Research, Stanford University\n",
    "authors": [
      "Luca Magri",
      "Anh Khoa Doan"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08345"
  },
  {
    "id": "arXiv:2211.08597",
    "title": "SketchySGD: Reliable Stochastic Optimization via Robust Curvature  Estimates",
    "abstract": "Comments: 25 pages, 8 figures, 7 tables",
    "descriptor": "\nComments: 25 pages, 8 figures, 7 tables\n",
    "authors": [
      "Zachary Frangella",
      "Pratik Rathore",
      "Shipu Zhao",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08597"
  },
  {
    "id": "arXiv:2211.09945",
    "title": "SparseVLR: A Novel Framework for Verified Locally Robust Sparse Neural  Networks Search",
    "abstract": "Comments: 16 pages, 9 tables, 7 figures",
    "descriptor": "\nComments: 16 pages, 9 tables, 7 figures\n",
    "authors": [
      "Sawinder Kaur",
      "Asif Salekin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09945"
  },
  {
    "id": "arXiv:2211.10045",
    "title": "What Makes An Apology More Effective? Exploring Anthropomorphism,  Individual Differences, And Emotion In Human-Automation Trust Repair",
    "abstract": "What Makes An Apology More Effective? Exploring Anthropomorphism,  Individual Differences, And Emotion In Human-Automation Trust Repair",
    "descriptor": "",
    "authors": [
      "Peggy Pei-Ying Lu",
      "Makoto Konishi",
      "Shin Sano",
      "Sho Hiruta",
      "Francis Ken Nakagawa"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.10045"
  },
  {
    "id": "arXiv:2211.10157",
    "title": "UMFuse: Unified Multi View Fusion for Human Editing applications",
    "abstract": "Comments: 10 pages, 10 figures",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Rishabh Jain",
      "Mayur Hemani",
      "Duygu Ceylan",
      "Krishna Kumar Singh",
      "Jingwan Lu",
      "Mausooom Sarkar",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10157"
  },
  {
    "id": "arXiv:2211.10742",
    "title": "Moment-SoS Methods for Optimal Transport Problems",
    "abstract": "Moment-SoS Methods for Optimal Transport Problems",
    "descriptor": "",
    "authors": [
      "Olga Mula",
      "Anthony Nouy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.10742"
  },
  {
    "id": "arXiv:2211.10904",
    "title": "Temporal Knowledge Graph Reasoning with Historical Contrastive Learning",
    "abstract": "Comments: Accepted by AAAI 2023",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Yi Xu",
      "Junjie Ou",
      "Hui Xu",
      "Luoyi Fu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10904"
  },
  {
    "id": "arXiv:2211.10973",
    "title": "FakeSV: A Multimodal Benchmark with Rich Social Context for Fake News  Detection on Short Video Platforms",
    "abstract": "Comments: To appear in AAAI 2023 AISI track. This version contains appendix with additional details",
    "descriptor": "\nComments: To appear in AAAI 2023 AISI track. This version contains appendix with additional details\n",
    "authors": [
      "Peng Qi",
      "Yuyan Bu",
      "Juan Cao",
      "Wei Ji",
      "Ruihao Shui",
      "Junbin Xiao",
      "Danding Wang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.10973"
  },
  {
    "id": "arXiv:2211.12046",
    "title": "DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors",
    "abstract": "DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors",
    "descriptor": "",
    "authors": [
      "Dogyoon Lee",
      "Minhyeok Lee",
      "Chajin Shin",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12046"
  },
  {
    "id": "arXiv:2211.12130",
    "title": "Converge to the Truth: Factual Error Correction via Iterative  Constrained Editing",
    "abstract": "Comments: Accepted to AAAI 2023",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Jiangjie Chen",
      "Rui Xu",
      "Wenxuan Zeng",
      "Changzhi Sun",
      "Lei Li",
      "Yanghua Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12130"
  },
  {
    "id": "arXiv:2211.14028",
    "title": "Sample Complexity of Automata Cascades",
    "abstract": "Comments: Full version with appendix of a paper with the same title that will appear in the proceedings of AAAI 2023",
    "descriptor": "\nComments: Full version with appendix of a paper with the same title that will appear in the proceedings of AAAI 2023\n",
    "authors": [
      "Alessandro Ronca",
      "Nadezda A. Knorozova",
      "Giuseppe De Giacomo"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14028"
  },
  {
    "id": "arXiv:2211.14108",
    "title": "3DDesigner: Towards Photorealistic 3D Object Generation and Editing with  Text-guided Diffusion Models",
    "abstract": "Comments: 15 pages, 12 figures, conference",
    "descriptor": "\nComments: 15 pages, 12 figures, conference\n",
    "authors": [
      "Gang Li",
      "Heliang Zheng",
      "Chaoyue Wang",
      "Chang Li",
      "Changwen Zheng",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14108"
  },
  {
    "id": "arXiv:2211.14523",
    "title": "VR-GNN: Variational Relation Vector Graph Neural Network for Modeling  both Homophily and Heterophily",
    "abstract": "VR-GNN: Variational Relation Vector Graph Neural Network for Modeling  both Homophily and Heterophily",
    "descriptor": "",
    "authors": [
      "Fengzhao Shi",
      "Ren Li",
      "Yanan Cao",
      "Yanmin Shang",
      "Lanxue Zhang",
      "Chuan Zhou",
      "Jia Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.14523"
  },
  {
    "id": "arXiv:2211.14769",
    "title": "Navigation as the Attacker Wishes? Towards Building Byzantine-Robust  Embodied Agents under Federated Learning",
    "abstract": "Navigation as the Attacker Wishes? Towards Building Byzantine-Robust  Embodied Agents under Federated Learning",
    "descriptor": "",
    "authors": [
      "Yunchao Zhang",
      "Zonglin Di",
      "Kaiwen Zhou",
      "Cihang Xie",
      "Xin Eric Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14769"
  },
  {
    "id": "arXiv:2211.15159",
    "title": "Properties of SN P system and its Configuration Graph",
    "abstract": "Comments: Invited Talk: International Conference on Membrane Computing, September 14-18, 2020, TU Wien, Austria",
    "descriptor": "\nComments: Invited Talk: International Conference on Membrane Computing, September 14-18, 2020, TU Wien, Austria\n",
    "authors": [
      "Henry N. Adorna"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.15159"
  },
  {
    "id": "arXiv:2211.15255",
    "title": "GADMSL: Graph Anomaly Detection on Attributed Networks via Multi-scale  Substructure Learning",
    "abstract": "Comments: 11 pages, 5 figures",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Jingcan Duan",
      "Siwei Wang",
      "Xinwang Liu",
      "Haifang Zhou",
      "Jingtao Hu",
      "Hu Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15255"
  },
  {
    "id": "arXiv:2211.15335",
    "title": "You Can Have Better Graph Neural Networks by Not Training Weights at  All: Finding Untrained GNNs Tickets",
    "abstract": "Comments: Accepted by the LoG conference 2022 as a spotlight",
    "descriptor": "\nComments: Accepted by the LoG conference 2022 as a spotlight\n",
    "authors": [
      "Tianjin Huang",
      "Tianlong Chen",
      "Meng Fang",
      "Vlado Menkovski",
      "Jiaxu Zhao",
      "Lu Yin",
      "Yulong Pei",
      "Decebal Constantin Mocanu",
      "Zhangyang Wang",
      "Mykola Pechenizkiy",
      "Shiwei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15335"
  },
  {
    "id": "arXiv:2211.15848",
    "title": "ClueWeb22: 10 Billion Web Documents with Visual and Semantic Information",
    "abstract": "ClueWeb22: 10 Billion Web Documents with Visual and Semantic Information",
    "descriptor": "",
    "authors": [
      "Arnold Overwijk",
      "Chenyan Xiong",
      "Xiao Liu",
      "Cameron VandenBerg",
      "Jamie Callan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15848"
  },
  {
    "id": "arXiv:2211.16068",
    "title": "ACE: Cooperative Multi-agent Q-learning with Bidirectional  Action-Dependency",
    "abstract": "Comments: Accepted by the Thirty-Seventh AAAI Conference on Artificial Intelligence(AAAI2023)",
    "descriptor": "\nComments: Accepted by the Thirty-Seventh AAAI Conference on Artificial Intelligence(AAAI2023)\n",
    "authors": [
      "Chuming Li",
      "Jie Liu",
      "Yinmin Zhang",
      "Yuhong Wei",
      "Yazhe Niu",
      "Yaodong Yang",
      "Yu Liu",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.16068"
  },
  {
    "id": "arXiv:2211.16192",
    "title": "Be Careful with Rotation: A Uniform Backdoor Pattern for 3D Shape",
    "abstract": "Be Careful with Rotation: A Uniform Backdoor Pattern for 3D Shape",
    "descriptor": "",
    "authors": [
      "Linkun Fan",
      "Fazhi He",
      "Qing Guo",
      "Wei Tang",
      "Xiaolin Hong",
      "Bing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.16192"
  },
  {
    "id": "arXiv:2211.16211",
    "title": "ResNeRF: Geometry-Guided Residual Neural Radiance Field for Indoor Scene  Novel View Synthesis",
    "abstract": "Comments: 8+2 pages,5 figures",
    "descriptor": "\nComments: 8+2 pages,5 figures\n",
    "authors": [
      "Yuting Xiao",
      "Yiqun Zhao",
      "Yanyu Xu",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16211"
  },
  {
    "id": "arXiv:2211.16384",
    "title": "Parameter Estimation with Increased Precision for Elliptic and  Hypo-elliptic Diffusions",
    "abstract": "Parameter Estimation with Increased Precision for Elliptic and  Hypo-elliptic Diffusions",
    "descriptor": "",
    "authors": [
      "Yuga Iguchi",
      "Alexandros Beskos",
      "Matthew M. Graham"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16384"
  },
  {
    "id": "arXiv:2211.16694",
    "title": "MSV Challenge 2022: NPU-HC Speaker Verification System for Low-resource  Indian Languages",
    "abstract": "Comments: 6pages, submitted to the 9th International Workshop on Vietnamese Language and Speech Processing",
    "descriptor": "\nComments: 6pages, submitted to the 9th International Workshop on Vietnamese Language and Speech Processing\n",
    "authors": [
      "Yue Li",
      "Li Zhang",
      "Namin Wang",
      "Jie Liu",
      "Lei Xie"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.16694"
  },
  {
    "id": "arXiv:2211.16994",
    "title": "Continual Learning with Distributed Optimization: Does CoCoA Forget?",
    "abstract": "Continual Learning with Distributed Optimization: Does CoCoA Forget?",
    "descriptor": "",
    "authors": [
      "Martin Hellkvist",
      "Ay\u00e7a \u00d6z\u00e7elikkale",
      "Anders Ahl\u00e9n"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.16994"
  },
  {
    "id": "arXiv:2211.17179",
    "title": "Investigation of Proper Orthogonal Decomposition for Echo State Networks",
    "abstract": "Comments: Submitted to Neurocomputing",
    "descriptor": "\nComments: Submitted to Neurocomputing\n",
    "authors": [
      "Jean Panaioti Jordanou",
      "Eric Aislan Antonelo",
      "Eduardo Camponogara",
      "Eduardo Gildin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.17179"
  },
  {
    "id": "arXiv:2211.17223",
    "title": "Topological Data Analysis for Speech Processing",
    "abstract": "Comments: Submitted to ICASSP 2023 conference, awaiting review",
    "descriptor": "\nComments: Submitted to ICASSP 2023 conference, awaiting review\n",
    "authors": [
      "Eduard Tulchinskii",
      "Kristian Kuznetsov",
      "Laida Kushnareva",
      "Daniil Cherniavskii",
      "Serguei Barannikov",
      "Irina Piontkovskaya",
      "Sergey Nikolenko",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2211.17223"
  },
  {
    "id": "arXiv:2212.00171",
    "title": "Layout-aware Dreamer for Embodied Referring Expression Grounding",
    "abstract": "Layout-aware Dreamer for Embodied Referring Expression Grounding",
    "descriptor": "",
    "authors": [
      "Mingxiao Li",
      "Zehao Wang",
      "Tinne Tuytelaars",
      "Marie-Francine Moens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00171"
  },
  {
    "id": "arXiv:2212.00229",
    "title": "NIR-Prompt: A Multi-task Generalized Neural Information Retrieval  Training Framework",
    "abstract": "Comments: This article is the extension of arXiv:2204.02725",
    "descriptor": "\nComments: This article is the extension of arXiv:2204.02725\n",
    "authors": [
      "Shicheng Xu",
      "Liang Pang",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.00229"
  },
  {
    "id": "arXiv:2212.00352",
    "title": "A Dataset with Multibeam Forward-Looking Sonar for Underwater Object  Detection",
    "abstract": "A Dataset with Multibeam Forward-Looking Sonar for Underwater Object  Detection",
    "descriptor": "",
    "authors": [
      "Kaibing Xie",
      "Jian Yang",
      "Kang Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00352"
  },
  {
    "id": "arXiv:2212.00373",
    "title": "A Noise-tolerant Differentiable Learning Approach for Single Occurrence  Regular Expression with Interleaving",
    "abstract": "A Noise-tolerant Differentiable Learning Approach for Single Occurrence  Regular Expression with Interleaving",
    "descriptor": "",
    "authors": [
      "Rongzhen Ye",
      "Tianqu Zhuang",
      "Hai Wan",
      "Jianfeng Du",
      "Weilin Luo",
      "Pingjia Liang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00373"
  },
  {
    "id": "arXiv:2212.00469",
    "title": "Beyond Incompatibility: Interpolation between Mutually Exclusive  Fairness Criteria in Classification Problems",
    "abstract": "Beyond Incompatibility: Interpolation between Mutually Exclusive  Fairness Criteria in Classification Problems",
    "descriptor": "",
    "authors": [
      "Meike Zehlike",
      "Alex Loosley",
      "Philipp Hacker",
      "H\u00e5kan Jonsson",
      "Emil Wiedemann"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.00469"
  },
  {
    "id": "arXiv:2212.00521",
    "title": "Unexpected Scaling in Path Copying Trees",
    "abstract": "Unexpected Scaling in Path Copying Trees",
    "descriptor": "",
    "authors": [
      "Ilya Kokorin",
      "Alexander Fedorov",
      "Trevor Brown",
      "Vitaly Aksenov"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.00521"
  },
  {
    "id": "arXiv:2212.00532",
    "title": "EBHI-Seg: A Novel Enteroscope Biopsy Histopathological Haematoxylin and  Eosin Image Dataset for Image Segmentation Tasks",
    "abstract": "EBHI-Seg: A Novel Enteroscope Biopsy Histopathological Haematoxylin and  Eosin Image Dataset for Image Segmentation Tasks",
    "descriptor": "",
    "authors": [
      "Liyu Shi",
      "Xiaoyan Li",
      "Weiming Hu",
      "Haoyuan Chen",
      "Jing Chen",
      "Zizhen Fan",
      "Minghe Gao",
      "Yujie Jing",
      "Guotao Lu",
      "Deguo Ma",
      "Zhiyu Ma",
      "Qingtao Meng",
      "Dechao Tang",
      "Hongzan Sun",
      "Marcin Grzegorzek",
      "Shouliang Qi",
      "Yueyang Teng",
      "Chen Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00532"
  },
  {
    "id": "arXiv:2212.00535",
    "title": "Graph Anomaly Detection via Multi-Scale Contrastive Learning Networks  with Augmented View",
    "abstract": "Comments: 9 pages, 5 figures, 6 tables, accepted by AAAI 2023",
    "descriptor": "\nComments: 9 pages, 5 figures, 6 tables, accepted by AAAI 2023\n",
    "authors": [
      "Jingcan Duan",
      "Siwei Wang",
      "Pei Zhang",
      "En Zhu",
      "Jingtao Hu",
      "Hu Jin",
      "Yue Liu",
      "Zhibin Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00535"
  },
  {
    "id": "arXiv:2212.00576",
    "title": "Quantum Neural Networks for a Supply Chain Logistics Application",
    "abstract": "Comments: 14 pages, 11 figures. arXiv admin note: text overlap with arXiv:2211.17078 - updated citation [3] to reference arXiv:2211.17078",
    "descriptor": "\nComments: 14 pages, 11 figures. arXiv admin note: text overlap with arXiv:2211.17078 - updated citation [3] to reference arXiv:2211.17078\n",
    "authors": [
      "Randall Correll",
      "Sean J. Weinberg",
      "Fabio Sanches",
      "Takanori Ide",
      "Takafumi Suzuki"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00576"
  },
  {
    "id": "arXiv:2212.00639",
    "title": "Launchpad: Learning to Schedule Using Offline and Online RL Methods",
    "abstract": "Launchpad: Learning to Schedule Using Offline and Online RL Methods",
    "descriptor": "",
    "authors": [
      "Vanamala Venkataswamy",
      "Jake Grigsby",
      "Andrew Grimshaw",
      "Yanjun Qi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.00639"
  },
  {
    "id": "arXiv:2212.00693",
    "title": "Complexity Blowup for Solutions of the Laplace and the Diffusion  Equation",
    "abstract": "Comments: The results of this paper on simulating physical theories on digital computers influenced the article of Holger Boche und Frank Fitzek \"Metaverse at the campfire of the future\" in Germany's major newspaper, the Frankfurter Allgemeine Zeitung (FAZ) (URL: this https URL). Technological challenges for the design of the Metaverse are discussed in this article",
    "descriptor": "\nComments: The results of this paper on simulating physical theories on digital computers influenced the article of Holger Boche und Frank Fitzek \"Metaverse at the campfire of the future\" in Germany's major newspaper, the Frankfurter Allgemeine Zeitung (FAZ) (URL: this https URL). Technological challenges for the design of the Metaverse are discussed in this article\n",
    "authors": [
      "Aras Bacho",
      "Holger Boche",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.00693"
  },
  {
    "id": "arXiv:2212.00742",
    "title": "New Probabilistic-Dynamic Multi-Method Ensembles for Optimization based  on the CRO-SL",
    "abstract": "Comments: 18 pages, 6 figures, 5 tables",
    "descriptor": "\nComments: 18 pages, 6 figures, 5 tables\n",
    "authors": [
      "Jorge P\u00e9rez-Aracil",
      "Carlos Camacho-G\u00f3mez",
      "Eugenio Lorente-Ramos",
      "Cosmin M. Marina",
      "Sancho Salcedo-Sanz"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.00742"
  },
  {
    "id": "arXiv:2212.00751",
    "title": "P(Expression|Grammar): Probability of deriving an algebraic expression  with a probabilistic context-free grammar",
    "abstract": "P(Expression|Grammar): Probability of deriving an algebraic expression  with a probabilistic context-free grammar",
    "descriptor": "",
    "authors": [
      "Urh Primo\u017ei\u010d",
      "Ljup\u010do Todorovski",
      "Matej Petkovi\u0107"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.00751"
  },
  {
    "id": "arXiv:2212.00786",
    "title": "3D Segmentation of Humans in Point Clouds with Synthetic Data",
    "abstract": "Comments: project page: this https URL",
    "descriptor": "\nComments: project page: this https URL\n",
    "authors": [
      "Ay\u00e7a Takmaz",
      "Jonas Schult",
      "Irem Kaftan",
      "Mertcan Ak\u00e7ay",
      "Bastian Leibe",
      "Robert Sumner",
      "Francis Engelmann",
      "Siyu Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00786"
  }
]
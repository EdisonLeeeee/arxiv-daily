[
  {
    "id": "arXiv:2212.09750",
    "title": "Human-in-the-loop Abstractive Dialogue Summarization",
    "abstract": "Abstractive dialogue summarization has received increasing attention\nrecently. Despite the fact that most of the current dialogue summarization\nsystems are trained to maximize the likelihood of human-written summaries and\nhave achieved significant results, there is still a huge gap in generating\nhigh-quality summaries as determined by humans, such as coherence and\nfaithfulness, partly due to the misalignment in maximizing a single\nhuman-written summary. To this end, we propose to incorporate different levels\nof human feedback into the training process. This will enable us to guide the\nmodels to capture the behaviors humans care about for summaries. Specifically,\nwe ask humans to highlight the salient information to be included in summaries\nto provide the local feedback , and to make overall comparisons among summaries\nin terms of coherence, accuracy, coverage, concise and overall quality, as the\nglobal feedback. We then combine both local and global feedback to fine-tune\nthe dialog summarization policy with Reinforcement Learning. Experiments\nconducted on multiple datasets demonstrate the effectiveness and generalization\nof our methods over the state-of-the-art supervised baselines, especially in\nterms of human judgments.",
    "descriptor": "",
    "authors": [
      "Jiaao Chen",
      "Mohan Dodda",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.09750"
  },
  {
    "id": "arXiv:2212.09801",
    "title": "Denotationally Correct, Purely Functional, Efficient Reverse-mode  Automatic Differentiation",
    "abstract": "Reverse-mode differentiation is used for optimization, but it introduces\nreferences, which break the purity of the underlying programs, making them\nnotoriously harder to optimize. We present a reverse-mode differentiation on a\npurely functional language with array operations. It is the first one to\ndeliver a provably efficient, purely functional, and denotationally correct\nreverse-mode differentiation. We show that our transformation is semantically\ncorrect and verifies the cheap gradient principle. Inspired by PROPs and\ncompilation to categories, we introduce a novel intermediate representation\nthat we call 'unary form'. Our reverse-mode transformation is factored as a\ncompilation scheme through this intermediate representation. We obtain provably\nefficient gradients by performing general partial evaluation optimizations\nafter our reverse-mode transformation, as opposed to manually derived ones. For\nsimple first-order programs, the obtained output programs resemble\nstatic-single-assignment (SSA) code. We emphasize the modularity of our\napproach and show how our language can easily be enriched with more optimized\nprimitives, as required for some speed-ups in practice.",
    "descriptor": "\nComments: 34 pages, 17 figures\n",
    "authors": [
      "Mathieu Huot",
      "Amir Shaikhha"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2212.09801"
  },
  {
    "id": "arXiv:2212.09802",
    "title": "Panoptic Lifting for 3D Scene Understanding with Neural Fields",
    "abstract": "We propose Panoptic Lifting, a novel approach for learning panoptic 3D\nvolumetric representations from images of in-the-wild scenes. Once trained, our\nmodel can render color images together with 3D-consistent panoptic segmentation\nfrom novel viewpoints.\nUnlike existing approaches which use 3D input directly or indirectly, our\nmethod requires only machine-generated 2D panoptic segmentation masks inferred\nfrom a pre-trained network. Our core contribution is a panoptic lifting scheme\nbased on a neural field representation that generates a unified and multi-view\nconsistent, 3D panoptic representation of the scene. To account for\ninconsistencies of 2D instance identifiers across views, we solve a linear\nassignment with a cost based on the model's current predictions and the\nmachine-generated segmentation masks, thus enabling us to lift 2D instances to\n3D in a consistent way. We further propose and ablate contributions that make\nour method more robust to noisy, machine-generated labels, including test-time\naugmentations for confidence estimates, segment consistency loss, bounded\nsegmentation fields, and gradient stopping.\nExperimental results validate our approach on the challenging Hypersim,\nReplica, and ScanNet datasets, improving by 8.4, 13.8, and 10.6% in scene-level\nPQ over state of the art.",
    "descriptor": "\nComments: Project Page: this https URL, Video: this https URL\n",
    "authors": [
      "Yawar Siddiqui",
      "Lorenzo Porzi",
      "Samuel Rota Bul\u00f3",
      "Norman M\u00fcller",
      "Matthias Nie\u00dfner",
      "Angela Dai",
      "Peter Kontschieder"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09802"
  },
  {
    "id": "arXiv:2212.09803",
    "title": "Training Trajectories of Language Models Across Scales",
    "abstract": "Scaling up language models has led to unprecedented performance gains, but\nlittle is understood about how the training dynamics change as models get\nlarger. How do language models of different sizes learn during pre-training?\nWhy do larger language models demonstrate more desirable behaviors? In this\npaper, we analyze the intermediate training checkpoints of differently sized\nOPT models (Zhang et al.,2022)--from 125M to 175B parameters--on next-token\nprediction, sequence-level generation, and downstream tasks. We find that 1) at\na given perplexity and independent of model sizes, a similar subset of training\ntokens see the most significant reduction in loss, with the rest stagnating or\nshowing double-descent behavior; 2) early in training, all models learn to\nreduce the perplexity of grammatical sequences that contain hallucinations,\nwith small models halting at this suboptimal distribution and larger ones\neventually learning to assign these sequences lower probabilities; 3)\nperplexity is a strong predictor of in-context learning performance on 74\nmultiple-choice tasks from BIG-Bench, and this holds independent of the model\nsize. Together, these results show that perplexity is more predictive of model\nbehaviors than model size or training computation.",
    "descriptor": "",
    "authors": [
      "Mengzhou Xia",
      "Mikel Artetxe",
      "Chunting Zhou",
      "Xi Victoria Lin",
      "Ramakanth Pasunuru",
      "Danqi Chen",
      "Luke Zettlemoyer",
      "Ves Stoyanov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09803"
  },
  {
    "id": "arXiv:2212.09808",
    "title": "Receding Horizon Control on the Broadcast of Information in Stochastic  Networks",
    "abstract": "This paper focuses on the broadcast of information on robot networks with\nstochastic network interconnection topologies. Problematic communication\nnetworks are almost unavoidable in areas where we wish to deploy multi-robotic\nsystems, usually due to a lack of environmental consistency, accessibility, and\nstructure. We tackle this problem by modeling the broadcast of information in a\nmulti-robot communication network as a stochastic process with random arrival\ntimes, which can be produced by irregular robot movements, wireless\nattenuation, and other environmental factors. Using this model, we provide and\nanalyze a receding horizon control strategy to control the statistics of the\ninformation broadcast. The resulting strategy compels the robots to re-direct\ntheir communication resources to different neighbors according to the current\npropagation process to fulfill global broadcast requirements. Based on this\nmethod, we provide an approach to compute the expected time to broadcast the\nmessage to all nodes. Numerical examples are provided to illustrate the\nresults.",
    "descriptor": "",
    "authors": [
      "Thales C. Silva",
      "Li Shen",
      "Xi Yu",
      "M. Ani Hsieh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.09808"
  },
  {
    "id": "arXiv:2212.09811",
    "title": "Memory-efficient NLLB-200: Language-specific Expert Pruning of a  Massively Multilingual Machine Translation Model",
    "abstract": "Compared to conventional bilingual translation systems, massively\nmultilingual machine translation is appealing because a single model can\ntranslate into multiple languages and benefit from knowledge transfer for low\nresource languages. On the other hand, massively multilingual models suffer\nfrom the curse of multilinguality, unless scaling their size massively, which\nincreases their training and inference costs. Sparse Mixture-of-Experts models\nare a way to drastically increase model capacity without the need for a\nproportional amount of computing. The recently released NLLB-200 is an example\nof such a model. It covers 202 languages but requires at least four 32GB GPUs\njust for inference. In this work, we propose a pruning method that allows the\nremoval of up to 80\\% of experts with a negligible loss in translation quality,\nwhich makes it feasible to run the model on a single 32GB GPU. Further analysis\nsuggests that our pruning metrics allow to identify language-specific experts\nand prune non-relevant experts for a given language pair.",
    "descriptor": "",
    "authors": [
      "Yeskendir Koishekenov",
      "Vassilina Nikoulina",
      "Alexandre Berard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09811"
  },
  {
    "id": "arXiv:2212.09814",
    "title": "Analysis of Sparse Recovery Algorithms via the Replica Method",
    "abstract": "This manuscript goes through the fundamental connections between statistical\nmechanics and estimation theory by focusing on the particular problem of\ncompressive sensing. We first show that the asymptotic analysis of a sparse\nrecovery algorithm is mathematically equivalent to the problem of calculating\nthe free energy of a spin glass in the thermodynamic limit. We then use the\nreplica method from statistical mechanics to evaluate the performance in the\nasymptotic regime. The asymptotic results have several applications in\ncommunications and signal processing. We briefly go through two instances of\nthese applications: Characterization of joint sparse recovery algorithms used\nin distributed compressive sensing, and tuning of receivers employed for\ndetection of spatially modulated signals.",
    "descriptor": "\nComments: \"A Comprehensive Introduction to the Applications of the Replica Method in Analysis of Large Inference Problems\". Initial version of the contribution to the book \"Compressed Sensing in Information Processing''; 32 pages, 2 figures\n",
    "authors": [
      "Ali Bereyhi",
      "Ralf R. M\u00fcller",
      "Hermann Schulz-Baldes"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.09814"
  },
  {
    "id": "arXiv:2212.09816",
    "title": "Proportional Control for Stochastic Regulation on Allocation of  Multi-Robots",
    "abstract": "Any strategy used to distribute a robot ensemble over a set of sequential\ntasks is subject to inaccuracy due to robot-level uncertainties and\nenvironmental influences on the robots' behavior. We approach the problem of\ninaccuracy during task allocation by modeling and controlling the overall\nensemble behavior. Our model represents the allocation problem as a stochastic\njump process and we regulate the mean and variance of such a process. The main\ncontributions of this paper are: Establishing a structure for the transition\nrates of the equivalent stochastic jump process and formally showing that this\napproach leads to decoupled parameters that allow us to adjust the first- and\nsecond-order moments of the ensemble distribution over tasks, which gives the\nflexibility to decrease the variance in the desired final distribution. This\nallows us to directly shape the impact of uncertainties on the group allocation\nover tasks. We introduce a detailed procedure to design the gains to achieve\nthe desired mean and show how the additional parameters impact the covariance\nmatrix, which is directly associated with the degree of task allocation\nprecision. Our simulation and experimental results illustrate the successful\ncontrol of several robot ensembles during task allocation.",
    "descriptor": "",
    "authors": [
      "Thales C. Silva",
      "Victoria Edwards",
      "M. Ani Hsieh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.09816"
  },
  {
    "id": "arXiv:2212.09821",
    "title": "Reduced Order Model of a Generic Submarine for Maneuvering Near the  Surface",
    "abstract": "A reduced order model of a generic submarine is presented. Computational\nfluid dynamics (CFD) results are used to create and validate a model that\nincludes depth dependence and the effect of waves on the craft. The model and\nthe procedure to obtain its coefficients are discussed, and examples of the\ndata used to obtain the model coefficients are presented. An example of\noperation following a complex path is presented and results from the reduced\norder model are compared to those from an equivalent CFD calculation. The\ncontroller implemented to complete these maneuvers is also presented.",
    "descriptor": "\nComments: Presented at the 34th Symposium on Naval Hydrodynamics, Washington DC, USA, 26 June - 1 July 2022\n",
    "authors": [
      "J. Ezequiel Martin",
      "Maxwell Hammond",
      "Nicholas Rober",
      "Yakin Kim",
      "Venanzio Cichella",
      "Pablo Carrica"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.09821"
  },
  {
    "id": "arXiv:2212.09825",
    "title": "What to Read in a Contract? Party-Specific Summarization of Important  Obligations, Entitlements, and Prohibitions in Legal Documents",
    "abstract": "Legal contracts, such as employment or lease agreements, are important\ndocuments as they govern the obligations and entitlements of the various\ncontracting parties. However, these documents are typically long and written in\nlegalese resulting in lots of manual hours spent in understanding them. In this\npaper, we address the task of summarizing legal contracts for each of the\ncontracting parties, to enable faster reviewing and improved understanding of\nthem. Specifically, we collect a dataset consisting of pairwise importance\ncomparison annotations by legal experts for ~293K sentence pairs from lease\nagreements. We propose a novel extractive summarization system to automatically\nproduce a summary consisting of the most important obligations, entitlements,\nand prohibitions in a contract. It consists of two modules: (1) a content\ncategorize to identify sentences containing each of the categories (i.e.,\nobligation, entitlement, and prohibition) for a party, and (2) an importance\nranker to compare the importance among sentences of each category for a party\nto obtain a ranked list. The final summary is produced by selecting the most\nimportant sentences of a category for each of the parties. We demonstrate the\neffectiveness of our proposed system by comparing it against several text\nranking baselines via automatic and human evaluation.",
    "descriptor": "\nComments: 15 pages, 5 figures, 10 tables\n",
    "authors": [
      "Abhilasha Sancheti",
      "Aparna Garimella",
      "Balaji Vasan Srinivasan",
      "Rachel Rudinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09825"
  },
  {
    "id": "arXiv:2212.09826",
    "title": "Fixed and adaptive landmark sets for finite pseudometric spaces",
    "abstract": "Topological data analysis (TDA) is an expanding field that leverages\nprinciples and tools from algebraic topology to quantify structural features of\ndata sets or transform them into more manageable forms. As its theoretical\nfoundations have been developed, TDA has shown promise in extracting useful\ninformation from high-dimensional, noisy, and complex data such as those used\nin biomedicine. To operate efficiently, these techniques may employ landmark\nsamplers, either random or heuristic. The heuristic maxmin procedure obtains a\nroughly even distribution of sample points by implicitly constructing a cover\ncomprising sets of uniform radius. However, issues arise with data that vary in\ndensity or include points with multiplicities, as are common in biomedicine. We\npropose an analogous procedure, \"lastfirst\" based on ranked distances, which\nimplies a cover comprising sets of uniform cardinality. We first rigorously\ndefine the procedure and prove that it obtains landmarks with desired\nproperties. We then perform benchmark tests and compare its performance to that\nof maxmin, on feature detection and class prediction tasks involving simulated\nand real-world biomedical data. Lastfirst is more general than maxmin in that\nit can be applied to any data on which arbitrary (and not necessarily\nsymmetric) pairwise distances can be computed. Lastfirst is more\ncomputationally costly, but our implementation scales at the same rate as\nmaxmin. We find that lastfirst achieves comparable performance on prediction\ntasks and outperforms maxmin on homology detection tasks. Where the numerical\nvalues of similarity measures are not meaningful, as in many biomedical\ncontexts, lastfirst sampling may also improve interpretability.",
    "descriptor": "\nComments: 30 pages, 17 figures\n",
    "authors": [
      "Jason Cory Brunson",
      "Yara Skaf"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.09826"
  },
  {
    "id": "arXiv:2212.09832",
    "title": "Denoising instrumented mouthguard measurements of head impact kinematics  with a convolutional neural network",
    "abstract": "Wearable sensors for measuring head kinematics can be noisy due to imperfect\ninterfaces with the body. Mouthguards are used to measure head kinematics\nduring impacts in traumatic brain injury (TBI) studies, but deviations from\nreference kinematics can still occur due to potential looseness. In this study,\ndeep learning is used to compensate for the imperfect interface and improve\nmeasurement accuracy. A set of one-dimensional convolutional neural network\n(1D-CNN) models was developed to denoise mouthguard kinematics measurements\nalong three spatial axes of linear acceleration and angular velocity. The\ndenoised kinematics had significantly reduced errors compared to reference\nkinematics, and reduced errors in brain injury criteria and tissue strain and\nstrain rate calculated via finite element modeling. The 1D-CNN models were also\ntested on an on-field dataset of college football impacts and a post-mortem\nhuman subject dataset, with similar denoising effects observed. The models can\nbe used to improve detection of head impacts and TBI risk evaluation, and\npotentially extended to other sensors measuring kinematics.",
    "descriptor": "\nComments: 39 pages, 9 figures, 4 tables\n",
    "authors": [
      "Xianghao Zhan",
      "Yuzhe Liu",
      "Nicholas J. Cecchi",
      "Ashlyn A. Callan",
      "Enora Le Flao",
      "Olivier Gevaert",
      "Michael M. Zeineh",
      "Gerald A. Grant",
      "David B. Camarillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Quantitative Methods (q-bio.QM)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2212.09832"
  },
  {
    "id": "arXiv:2212.09839",
    "title": "Exploring Hybrid and Ensemble Models for Multiclass Prediction of Mental  Health Status on Social Media",
    "abstract": "In recent years, there has been a surge of interest in research on automatic\nmental health detection (MHD) from social media data leveraging advances in\nnatural language processing and machine learning techniques. While significant\nprogress has been achieved in this interdisciplinary research area, the vast\nmajority of work has treated MHD as a binary classification task. The\nmulticlass classification setup is, however, essential if we are to uncover the\nsubtle differences among the statistical patterns of language use associated\nwith particular mental health conditions. Here, we report on experiments aimed\nat predicting six conditions (anxiety, attention deficit hyperactivity\ndisorder, bipolar disorder, post-traumatic stress disorder, depression, and\npsychological stress) from Reddit social media posts. We explore and compare\nthe performance of hybrid and ensemble models leveraging transformer-based\narchitectures (BERT and RoBERTa) and BiLSTM neural networks trained on\nwithin-text distributions of a diverse set of linguistic features. This set\nencompasses measures of syntactic complexity, lexical sophistication and\ndiversity, readability, and register-specific ngram frequencies, as well as\nsentiment and emotion lexicons. In addition, we conduct feature ablation\nexperiments to investigate which types of features are most indicative of\nparticular mental health conditions.",
    "descriptor": "\nComments: accepted at EMNLP2022\n",
    "authors": [
      "Sourabh Zanwar",
      "Daniel Wiechmann",
      "Yu Qiao",
      "Elma Kerz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09839"
  },
  {
    "id": "arXiv:2212.09840",
    "title": "Dynamic Sparse Network for Time Series Classification: Learning What to  \"see''",
    "abstract": "The receptive field (RF), which determines the region of time series to be\n``seen'' and used, is critical to improve the performance for time series\nclassification (TSC). However, the variation of signal scales across and within\ntime series data, makes it challenging to decide on proper RF sizes for TSC. In\nthis paper, we propose a dynamic sparse network (DSN) with sparse connections\nfor TSC, which can learn to cover various RF without cumbersome\nhyper-parameters tuning. The kernels in each sparse layer are sparse and can be\nexplored under the constraint regions by dynamic sparse training, which makes\nit possible to reduce the resource cost. The experimental results show that the\nproposed DSN model can achieve state-of-art performance on both univariate and\nmultivariate TSC datasets with less than 50\\% computational cost compared with\nrecent baseline methods, opening the path towards more accurate resource-aware\nmethods for time series analyses. Our code is publicly available at:\nhttps://github.com/QiaoXiao7282/DSN.",
    "descriptor": "\nComments: Accepted at Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Qiao Xiao",
      "Boqian Wu",
      "Yu Zhang",
      "Shiwei Liu",
      "Mykola Pechenizkiy",
      "Elena Mocanu",
      "Decebal Constantin Mocanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.09840"
  },
  {
    "id": "arXiv:2212.09841",
    "title": "Matrix recovery from matrix-vector products",
    "abstract": "Can one recover a matrix efficiently from only matrix-vector products? If so,\nhow many are needed? This paper describes algorithms to recover structured\nmatrices, such as tridiagonal, Toeplitz, Toeplitz-like, and hierarchical\nlow-rank, from matrix-vector products. In particular, we derive a randomized\nalgorithm for recovering an $N \\times N$ unknown hierarchical low-rank matrix\nfrom only $\\mathcal{O}((k+p)\\log(N))$ matrix-vector products with high\nprobability, where $k$ is the rank of the off-diagonal blocks, and $p$ is a\nsmall oversampling parameter. We do this by carefully constructing randomized\ninput vectors for our matrix-vector products that exploit the hierarchical\nstructure of the matrix. While existing algorithms for hierarchical matrix\nrecovery use a recursive \"peeling\" procedure based on elimination, our approach\nuses a recursive projection procedure.",
    "descriptor": "",
    "authors": [
      "Diana Halikias",
      "Alex Townsend"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.09841"
  },
  {
    "id": "arXiv:2212.09846",
    "title": "PullupStructs: Digital Fabrication for Folding Structures via Pull-up  Nets",
    "abstract": "In this paper, we introduce a method to rapidly create 3D geometries by\nfolding 2D sheets via pull-up nets. Given a 3D structure, we unfold its mesh\ninto a planar 2D sheet using heuristic algorithms and populate these with\ncutlines and throughholes. We develop a web-based simulation tool that\ntranslates users' 3D meshes into manufacturable 2D sheets. After laser-cutting\nthe sheet and feeding thread through these throughholes to form a pull-up net,\npulling the thread will fold the sheet into the 3D structure using a single\ndegree of freedom. We introduce the fabrication process and build a variety of\nprototypes demonstrating the method's ability to rapidly create a breadth of\ngeometries suitable for low-fidelity prototyping that are both load-bearing and\naesthetic across a range of scales. Future work will expand the breadth of\ngeometries available and evaluate the ability of our prototypes to sustain\nstructural loads.",
    "descriptor": "\nComments: In ACM TEI '23: Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction (ACM TEI '23), February 26-March 1, 2023, Warsaw, Poland. ACM, New York, NY, USA, 10 pages\n",
    "authors": [
      "Lauren Niu",
      "Xinyi Yang",
      "Martin Nisser",
      "Stefanie Mueller"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.09846"
  },
  {
    "id": "arXiv:2212.09847",
    "title": "Rigidity in Mechanism Design and its Applications",
    "abstract": "We introduce the notion of rigidity in auction design and use it to analyze\nsome fundamental aspects of mechanism design. We focus on single-item auctions\nwhere the values of the bidders are drawn from some (possibly correlated)\ndistribution $\\mathcal F$. Let $f$ be the allocation function of an optimal\nmechanism for $\\mathcal F$. Informally, $S$ is (linearly) rigid in $\\mathcal F$\nif for every mechanism $M'$ with an allocation function $f'$ where $f$ and $f'$\nagree on the allocation of at most $x$-fraction of the instances of $S$, the\nexpected revenue of $M'$ is at most an $x$ fraction of the optimal revenue. We\nuse rigidity to explain the singular success of Cremer and McLean's auction.\nRecall that the revenue of Cremer and McLean's auction is the optimal welfare\nif the distribution obeys a certain ``full rank'' condition, but no analogous\nconstructions are known if this condition does not hold. Note that the\nKolmogorov complexity of the allocation function of Cremer and McLean's auction\nis logarithmic, whereas we use rigidity to show that for some distributions\nthat do not obey the full rank condition, the Kolmogorov complexity of the\nallocation function of every mechanism that provides a constant approximation\nis almost linear. We further investigate rigidity assuming different notions of\nindividual rationality. Assuming ex-post individual rationality, if there is a\nrigid set, the structure of the optimal mechanism is simple: the player with\nthe highest value ``usually'' wins the item and contributes most of the\nrevenue. In contrast, assuming interim individual rationality, there are\ndistributions with a rigid set $S$ where the optimal mechanism has no obvious\nallocation pattern (i.e., its Kolmogorov complexity is high). Our results help\nexplain why we have little hope of developing good, simple and generic\napproximation mechanisms in the interim individual rationality world.",
    "descriptor": "",
    "authors": [
      "Shahar Dobzinski",
      "Ariel Shaulker"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2212.09847"
  },
  {
    "id": "arXiv:2212.09848",
    "title": "(Psycho-)Linguistic Features Meet Transformer Models for Improved  Explainable and Controllable Text Simplification",
    "abstract": "State-of-the-art text simplification (TS) systems adopt end-to-end neural\nnetwork models to directly generate the simplified version of the input text,\nand usually function as a blackbox. Moreover, TS is usually treated as an\nall-purpose generic task under the assumption of homogeneity, where the same\nsimplification is suitable for all. In recent years, however, there has been\nincreasing recognition of the need to adapt the simplification techniques to\nthe specific needs of different target groups. In this work, we aim to advance\ncurrent research on explainable and controllable TS in two ways: First,\nbuilding on recently proposed work to increase the transparency of TS systems,\nwe use a large set of (psycho-)linguistic features in combination with\npre-trained language models to improve explainable complexity prediction.\nSecond, based on the results of this preliminary task, we extend a\nstate-of-the-art Seq2Seq TS model, ACCESS, to enable explicit control of ten\nattributes. The results of experiments show (1) that our approach improves the\nperformance of state-of-the-art models for predicting explainable complexity\nand (2) that explicitly conditioning the Seq2Seq model on ten attributes leads\nto a significant improvement in performance in both within-domain and\nout-of-domain settings.",
    "descriptor": "\nComments: accepted at EMNLP2022\n",
    "authors": [
      "Yu Qiao",
      "Xiaofei Li",
      "Daniel Wiechmann",
      "Elma Kerz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09848"
  },
  {
    "id": "arXiv:2212.09849",
    "title": "Dataless Knowledge Fusion by Merging Weights of Language Models",
    "abstract": "Fine-tuning pre-trained language models has become the prevalent paradigm for\nbuilding downstream NLP models. Oftentimes fine-tuned models are readily\navailable but their training data is not, due to data privacy or intellectual\nproperty concerns. This creates a barrier to fusing knowledge across individual\nmodels to yield a better single model. In this paper, we study the problem of\nmerging individual models built on different training data sets to obtain a\nsingle model that performs well both across all data set domains and can\ngeneralize on out-of-domain data. We propose a dataless knowledge fusion method\nthat merges models in their parameter space, guided by weights that minimize\nprediction differences between the merged model and the individual models. Over\na battery of evaluation settings, we show that the proposed method\nsignificantly outperforms baselines such as Fisher-weighted averaging or model\nensembling. Further, we find that our method is a promising alternative to\nmulti-task learning that can preserve or sometimes improve over the individual\nmodels without access to the training data. Finally, model merging is more\nefficient than training a multi-task model, thus making it applicable to a\nwider set of scenarios.",
    "descriptor": "",
    "authors": [
      "Xisen Jin",
      "Xiang Ren",
      "Daniel Preotiuc-Pietro",
      "Pengxiang Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09849"
  },
  {
    "id": "arXiv:2212.09851",
    "title": "PathCAS: An Efficient Middle Ground for Concurrent Search Data  Structures",
    "abstract": "To maximize the performance of concurrent data structures, researchers have\noften turned to highly complex fine-grained techniques, resulting in efficient\nand elegant algorithms, which can however be often difficult to understand and\nprove correct. While simpler techniques exist, such as transactional memory,\nthey can have limited performance or portability relative to their fine-grained\ncounterparts. Approaches at both ends of this complexity-performance spectrum\nhave been extensively explored, but relatively less is known about the middle\nground: approaches that are willing to sacrifice some performance for\nsimplicity, while remaining competitive with state-of-the-art handcrafted\ndesigns.\nIn this paper, we explore this middle ground, and present PathCAS, a\nprimitive that combines ideas from multi-word CAS (KCAS) and transactional\nmemory approaches, while carefully avoiding overhead. We show how PathCAS can\nbe used to implement efficient search data structures relatively simply, using\nan internal binary search tree as an example, then extending this to an AVL\ntree. Our best implementations outperform many handcrafted search trees: in\nsearch-heavy workloads, it rivals the BCCO tree [5], the fastest known\nconcurrent binary tree in terms of search performance [3]. Our results suggest\nthat PathCAS can yield concurrent data structures that are relatively easy to\nbuild and prove correct, while offering surprisingly high performance.",
    "descriptor": "\nComments: Extended version of the conference paper, which appeared at PPoPP'22. This work won the PPoPP'22 best artifact award\n",
    "authors": [
      "Trevor Brown",
      "William Sigouin",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.09851"
  },
  {
    "id": "arXiv:2212.09855",
    "title": "MANTIS at TSAR-2022 Shared Task: Improved Unsupervised Lexical  Simplification with Pretrained Encoders",
    "abstract": "In this paper we present our contribution to the TSAR-2022 Shared Task on\nLexical Simplification of the EMNLP 2022 Workshop on Text Simplification,\nAccessibility, and Readability. Our approach builds on and extends the\nunsupervised lexical simplification system with pretrained encoders (LSBert)\nsystem in the following ways: For the subtask of simplification candidate\nselection, it utilizes a RoBERTa transformer language model and expands the\nsize of the generated candidate list. For subsequent substitution ranking, it\nintroduces a new feature weighting scheme and adopts a candidate filtering\nmethod based on textual entailment to maximize semantic similarity between the\ntarget word and its simplification. Our best-performing system improves LSBert\nby 5.9% accuracy and achieves second place out of 33 ranked solutions.",
    "descriptor": "\nComments: accepted at EMNLP2022\n",
    "authors": [
      "Xiaofei Li",
      "Daniel Wiechmann",
      "Yu Qiao",
      "Elma Kerz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09855"
  },
  {
    "id": "arXiv:2212.09858",
    "title": "Continuous Semi-Supervised Nonnegative Matrix Factorization",
    "abstract": "Nonnegative matrix factorization can be used to automatically detect topics\nwithin a corpus in an unsupervised fashion. The technique amounts to an\napproximation of a nonnegative matrix as the product of two nonnegative\nmatrices of lower rank. In this paper, we show this factorization can be\ncombined with regression on a continuous response variable. In practice, the\nmethod performs better than regression done after topics are identified and\nretrains interpretability.",
    "descriptor": "",
    "authors": [
      "Michael R. Lindstrom",
      "Xiaofu Ding",
      "Feng Liu",
      "Anand Somayajula",
      "Deanna Needell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09858"
  },
  {
    "id": "arXiv:2212.09859",
    "title": "CompuMat: A Computational Composite Material for Tangible Interaction",
    "abstract": "This paper introduces a computational composite material comprising layers\nfor actuation, computation and energy storage. Key to its design is inexpensive\nmaterials assembled from traditionally available fabrication machines to\nsupport the rapid exploration of applications from computational composites.\nThe actuation layer is a soft magnetic sheet that is programmed to either bond,\nrepel, or remain agnostic to other areas of the sheet. The computation layer is\na flexible PCB made from copper-clad kapton engraved by a fiber laser, powered\nby a third energy-storage layer comprised of 0.4mm-thin lithium polymer\nbatteries. We present the material layup and an accompanying digital\nfabrication process enabling users to rapidly prototype their own untethered,\ninteractive and tangible prototypes. The material is low-profile, inexpensive,\nand fully untethered, capable of being used for a variety of applications in\nHCI and robotics including structural origami and proprioception.",
    "descriptor": "\nComments: Xinyi Yang, Martin Nisser, and Stefanie Mueller. 2023. CompuMat: A Computational Composite Material for Tangible Interaction. In ACM TEI '23: Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction (ACM TEI '23), February 26-March 1, 2023, Warsaw, Poland. ACM, New York, NY, USA, 8 pages\n",
    "authors": [
      "Xinyi Yang",
      "Martin Nisser",
      "Stefanie Mueller"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.09859"
  },
  {
    "id": "arXiv:2212.09860",
    "title": "Predicting Ejection Fraction from Chest X-rays Using Computer Vision for  Diagnosing Heart Failure",
    "abstract": "Heart failure remains a major public health challenge with growing costs.\nEjection fraction (EF) is a key metric for the diagnosis and management of\nheart failure however estimation of EF using echocardiography remains expensive\nfor the healthcare system and subject to intra/inter operator variability.\nWhile chest x-rays (CXR) are quick, inexpensive, and require less expertise,\nthey do not provide sufficient information to the human eye to estimate EF.\nThis work explores the efficacy of computer vision techniques to predict\nreduced EF solely from CXRs. We studied a dataset of 3488 CXRs from the MIMIC\nCXR-jpg (MCR) dataset. Our work establishes benchmarks using multiple\nstate-of-the-art convolutional neural network architectures. The subsequent\nanalysis shows increasing model sizes from 8M to 23M parameters improved\nclassification performance without overfitting the dataset. We further show how\ndata augmentation techniques such as CXR rotation and random cropping further\nimproves model performance another ~5%. Finally, we conduct an error analysis\nusing saliency maps and Grad-CAMs to better understand the failure modes of\nconvolutional models on this task.",
    "descriptor": "",
    "authors": [
      "Walt Williams",
      "Rohan Doshi",
      "Yanran Li",
      "Kexuan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.09860"
  },
  {
    "id": "arXiv:2212.09864",
    "title": "Synthetic Pre-Training Tasks for Neural Machine Translation",
    "abstract": "Pre-training is an effective technique for ensuring robust performance on a\nvariety of machine learning tasks. It typically depends on large-scale crawled\ncorpora that can result in toxic or biased models. Such data can also be\nproblematic with respect to copyright, attribution, and privacy. Pre-training\nwith synthetic tasks and data is a promising way of alleviating such concerns\nsince no real-world information is ingested by the model. Our goal in this\npaper is to understand what makes for a good pre-trained model when using\nsynthetic resources. We answer this question in the context of neural machine\ntranslation by considering two novel approaches to translation model\npre-training. Our first approach studies the effect of pre-training on\nobfuscated data derived from a parallel corpus by mapping words to a vocabulary\nof 'nonsense' tokens. Our second approach explores the effect of pre-training\non procedurally generated synthetic parallel data that does not depend on any\nreal human language corpus. Our empirical evaluation on multiple language pairs\nshows that, to a surprising degree, the benefits of pre-training can be\nrealized even with obfuscated or purely synthetic parallel data. In our\nanalysis, we consider the extent to which obfuscated and synthetic pre-training\ntechniques can be used to mitigate the issue of hallucinated model toxicity.",
    "descriptor": "\nComments: 17 pages including appendix, 3 figures\n",
    "authors": [
      "Zexue He",
      "Graeme Blackwood",
      "Rameswar Panda",
      "Julian McAuley",
      "Rogerio Feris"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.09864"
  },
  {
    "id": "arXiv:2212.09865",
    "title": "Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations",
    "abstract": "Although large language models can be prompted for both zero- and few-shot\nlearning, performance drops significantly when no demonstrations are available.\nIn this paper, we introduce Z-ICL, a new zero-shot method that closes the gap\nby constructing pseudo-demonstrations for a given test input using a raw text\ncorpus. Concretely, pseudo-demonstrations are constructed by (1) finding the\nnearest neighbors to the test input from the corpus and pairing them with\nrandom task labels, and (2) applying a set of techniques to reduce the amount\nof direct copying the model does from the resulting demonstrations. Evaluation\non nine classification datasets shows that Z-ICL outperforms previous zero-shot\nmethods by a significant margin, and is on par with in-context learning with\nlabeled training data in the few-shot setting. Overall, Z-ICL provides a\nsignificantly higher estimate of the zero-shot performance levels of a model,\nand supports future efforts to develop better pseudo-demonstrations that\nfurther improve zero-shot results.",
    "descriptor": "\nComments: 11 pages; 9 figures\n",
    "authors": [
      "Xinxi Lyu",
      "Sewon Min",
      "Iz Beltagy",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.09865"
  },
  {
    "id": "arXiv:2212.09867",
    "title": "Detecting Contradictory COVID-19 Drug Efficacy Claims from Biomedical  Literature",
    "abstract": "The COVID-19 pandemic created a deluge of questionable and contradictory\nscientific claims about drug efficacy -- an \"infodemic\" with lasting\nconsequences for science and society. In this work, we argue that NLP models\ncan help domain experts distill and understand the literature in this complex,\nhigh-stakes area. Our task is to automatically identify contradictory claims\nabout COVID-19 drug efficacy. We frame this as a natural language inference\nproblem and offer a new NLI dataset created by domain experts. The NLI framing\nallows us to create curricula combining existing datasets and our own. The\nresulting models are useful investigative tools. We provide a case study of how\nthese models help a domain expert summarize and assess evidence concerning\nremdisivir and hydroxychloroquine.",
    "descriptor": "",
    "authors": [
      "Daniel N. Sosa",
      "Malavika Suresh",
      "Christopher Potts",
      "Russ B. Altman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09867"
  },
  {
    "id": "arXiv:2212.09873",
    "title": "A Comparative Study on Textual Saliency of Styles from Eye Tracking,  Annotations, and Language Models",
    "abstract": "There is growing interest in incorporating eye-tracking data and other\nimplicit measures of human language processing into natural language processing\n(NLP) pipelines. The data from human language processing contain unique insight\ninto human linguistic understanding that could be exploited by language models.\nHowever, many unanswered questions remain about the nature of this data and how\nit can best be utilized in downstream NLP tasks. In this paper, we present\neyeStyliency, an eye-tracking dataset for human processing of stylistic text\n(e.g., politeness). We develop a variety of methods to derive style saliency\nscores over text using the collected eye dataset. We further investigate how\nthis saliency data compares to both human annotation methods and model-based\ninterpretability metrics. We find that while eye-tracking data is unique, it\nalso intersects with both human annotations and model-based importance scores,\nproviding a possible bridge between human- and machine-based perspectives. In\ndownstream few-shot learning tasks, adding salient words to prompts generally\nimproved style classification, with eye-tracking-based and annotation-based\nsalient words achieving the highest accuracy.",
    "descriptor": "",
    "authors": [
      "Karin de Langis",
      "Dongyeop Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09873"
  },
  {
    "id": "arXiv:2212.09877",
    "title": "LayoutDETR: Detection Transformer Is a Good Multimodal Layout Designer",
    "abstract": "Graphic layout designs play an essential role in visual communication. Yet\nhandcrafting layout designs are skill-demanding, time-consuming, and\nnon-scalable to batch production. Although generative models emerge to make\ndesign automation no longer utopian, it remains non-trivial to customize\ndesigns that comply with designers' multimodal desires, i.e., constrained by\nbackground images and driven by foreground contents. In this study, we propose\n\\textit{LayoutDETR} that inherits the high quality and realism from generative\nmodeling, in the meanwhile reformulating content-aware requirements as a\ndetection problem: we learn to detect in a background image the reasonable\nlocations, scales, and spatial relations for multimodal elements in a layout.\nExperiments validate that our solution yields new state-of-the-art performance\nfor layout generation on public benchmarks and on our newly-curated ads banner\ndataset. For practical usage, we build our solution into a graphical system\nthat facilitates user studies. We demonstrate that our designs attract more\nsubjective preference than baselines by significant margins. Our code, models,\ndataset, graphical system, and demos are available at\nhttps://github.com/salesforce/LayoutDETR.",
    "descriptor": "",
    "authors": [
      "Ning Yu",
      "Chia-Chih Chen",
      "Zeyuan Chen",
      "Rui Meng",
      "Gang Wu",
      "Paul Josel",
      "Juan Carlos Niebles",
      "Caiming Xiong",
      "Ran Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.09877"
  },
  {
    "id": "arXiv:2212.09879",
    "title": "Unsigned Play by Milan Kundera? An Authorship Attribution Study",
    "abstract": "In addition to being a widely recognised novelist, Milan Kundera has also\nauthored three pieces for theatre: The Owners of the Keys (Majitel\\'e\nkl\\'i\\v{c}\\r{u}, 1961), The Blunder (Pt\\'akovina, 1967), and Jacques and his\nMaster (Jakub a jeho p\\'an, 1971). In recent years, however, the hypothesis has\nbeen raised that Kundera is the true author of a fourth play: Juro\nJ\\'ano\\v{s}\\'ik, first performed in a 1974 production under the name of Karel\nSteigerwald, who was Kundera's student at the time. In this study, we make use\nof supervised machine learning to settle the question of authorship attribution\nin the case of Juro J\\'ano\\v{s}\\'ik, with results strongly supporting the\nhypothesis of Kundera's authorship.",
    "descriptor": "",
    "authors": [
      "Lenka Jungmannov\u00e1",
      "Petr Plech\u00e1\u010d"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09879"
  },
  {
    "id": "arXiv:2212.09880",
    "title": "Experimental Low-speed Positioning System with VecTwin Rudder for  Automatic Docking (Berthing)",
    "abstract": "A VecTwin rudder system comprises twin fishtail rudders with reaction fins to\nincrease its performance. With a constant propeller revolution number, the\nvessel can execute special low-speed maneuvers like hover, crabbing, reverse,\nand rotation. Such low-speed maneuvers are termed dynamic positioning (DP), and\na DP vessel should be fully/overly actuated with several thrusters. This\narticle introduces a novel and experimental VecTwin positioning system (VTPS)\nwithout making the ship fully/overly actuated. Unlike the usual dynamic\npositioning system (DPS), the VTPS is developed for low-speed operations in a\ncalm harbor area. It is designed upon an assumption that the forces due to the\ninteraction between the rudders, the propeller, and the hull are linear with\nthe rudder angles within a range around the hover rudder angle. The linear\nrelationship is obtained through linear regression of the results from several\nCFD simulations. The VTPS implements a PID controller that regulates the\nactuator forces to achieve the given low-speed positioning objective. It was\ntested in combined automatic docking and position-keeping experiments where\ndisturbances from the environment exist. It shows promising potential for a\npractical application but with further improvements.",
    "descriptor": "",
    "authors": [
      "Dimas M. Rachman",
      "Yusuke Aoki",
      "Yoshiki Miyauchi",
      "Naoya Umeda",
      "Atsuo Maki"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.09880"
  },
  {
    "id": "arXiv:2212.09884",
    "title": "Multi-Analyst Differential Privacy for Online Query Answering",
    "abstract": "Most differentially private mechanisms are designed for the use of a single\nanalyst. In reality, however, there are often multiple stakeholders with\ndifferent and possibly conflicting priorities that must share the same privacy\nloss budget. This motivates the problem of equitable budget-sharing for\nmulti-analyst differential privacy. Our previous work defined desiderata that\nany mechanism in this space should satisfy and introduced methods for\nbudget-sharing in the offline case where queries are known in advance.\nWe extend our previous work on multi-analyst differentially private query\nanswering to the case of online query answering, where queries come in one at a\ntime and must be answered without knowledge of the following queries. We\ndemonstrate that the unknown ordering of queries in the online case results in\na fundamental limit in the number of queries that can be answered while\nsatisfying the desiderata. In response, we develop two mechanisms, one which\nsatisfies the desiderata in all cases but is subject to the fundamental\nlimitations, and another that randomizes the input order ensuring that existing\nonline query answering mechanisms can satisfy the desiderata.",
    "descriptor": "\nComments: 11 pages 3 figures\n",
    "authors": [
      "David Pujol",
      "Albert Sun",
      "Brandon Fain",
      "Ashwin Machanavajjhala"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.09884"
  },
  {
    "id": "arXiv:2212.09885",
    "title": "Asking Clarification Questions for Code Generation in General-Purpose  Programming Language",
    "abstract": "Code generation from text requires understanding the user's intent from a\nnatural language description (NLD) and generating an executable program code\nsnippet that satisfies this intent. While recent pretrained language models\n(PLMs) demonstrate remarkable performance for this task, these models fail when\nthe given NLD is ambiguous due to the lack of enough specifications for\ngenerating a high-quality code snippet. In this work, we introduce a novel and\nmore realistic setup for this task. We hypothesize that ambiguities in the\nspecifications of an NLD are resolved by asking clarification questions (CQs).\nTherefore, we collect and introduce a new dataset named CodeClarQA containing\nNLD-Code pairs with created CQAs. We evaluate the performance of PLMs for code\ngeneration on our dataset. The empirical results support our hypothesis that\nclarifications result in more precise generated code, as shown by an\nimprovement of 17.52 in BLEU, 12.72 in CodeBLEU, and 7.7\\% in the exact match.\nAlongside this, our task and dataset introduce new challenges to the community,\nincluding when and what CQs should be asked.",
    "descriptor": "\nComments: 8 pages (excluding Limitations and Ethics Concerns), 4 figures, 7 tables\n",
    "authors": [
      "Haau-Sing Li",
      "Mohsen Mesgar",
      "Andr\u00e9 F. T. Martins",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09885"
  },
  {
    "id": "arXiv:2212.09887",
    "title": "Model Predictive Control for Neuromimetic Quantized Systems",
    "abstract": "Based on our recent research on neural heuristic quantization systems, we\npropose an emulation problem consistent with the neuromimetic paradigm. This\noptimal quantization problem can be solved with model predictive control (MPC)\nby deriving the conditions under which the quantized system can guarantee\n(asymptotic) stability during emulation by optimizing a Lyapunov-like objective\nfunction. The neuromimetic model features large numbers of discrete inputs, and\nthe optimization involves integer variables. The approach in the paper begins\nby solving a relaxed optimization using model predictive control (MPC) and then\ntreating the quantized system using machine learning applied to the sphere\ndecoding algorithm of Fincke and Pohst.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Zexin Sun",
      "John Baillieul"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.09887"
  },
  {
    "id": "arXiv:2212.09895",
    "title": "Improved Long-Form Spoken Language Translation with Large Language  Models",
    "abstract": "A challenge in spoken language translation is that plenty of spoken content\nis long-form, but short units are necessary for obtaining high-quality\ntranslations. To address this mismatch, we fine-tune a general-purpose, large\nlanguage model to split long ASR transcripts into segments that can be\nindependently translated so as to maximize the overall translation quality. We\ncompare to several segmentation strategies and find that our approach improves\nBLEU score on three languages by an average of 2.7 BLEU overall compared to an\nautomatic punctuation baseline. Further, we demonstrate the effectiveness of\ntwo constrained decoding strategies to improve well-formedness of the model\noutput from above 99% to 100%.",
    "descriptor": "",
    "authors": [
      "Arya D. McCarthy",
      "Hao Zhang",
      "Shankar Kumar",
      "Felix Stahlberg",
      "Axel H. Ng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09895"
  },
  {
    "id": "arXiv:2212.09897",
    "title": "Inducing Character-level Structure in Subword-based Language Models with  Type-level Interchange Intervention Training",
    "abstract": "Language tasks involving character-level manipulations (e.g., spelling\ncorrection, many word games) are challenging for models based in subword\ntokenization. To address this, we adapt the interchange intervention training\nmethod of Geiger et al. (2021) to operate on type-level variables over\ncharacters. This allows us to encode robust, position-independent\ncharacter-level information in the internal representations of subword-based\nmodels. We additionally introduce a suite of character-level tasks that\nsystematically vary in their dependence on meaning and sequence-level context.\nWhile simple character-level tokenization approaches still perform best on\npurely form-based tasks like string reversal, our method is superior for more\ncomplex tasks that blend form, meaning, and context, such as spelling\ncorrection in context and word search games. Our approach also leads to\nsubword-based models with human-intepretable internal representations of\ncharacters.",
    "descriptor": "",
    "authors": [
      "Jing Huang",
      "Zhengxuan Wu",
      "Kyle Mahowald",
      "Christopher Potts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09897"
  },
  {
    "id": "arXiv:2212.09898",
    "title": "MetaCLUE: Towards Comprehensive Visual Metaphors Research",
    "abstract": "Creativity is an indispensable part of human cognition and also an inherent\npart of how we make sense of the world. Metaphorical abstraction is fundamental\nin communicating creative ideas through nuanced relationships between abstract\nconcepts such as feelings. While computer vision benchmarks and approaches\npredominantly focus on understanding and generating literal interpretations of\nimages, metaphorical comprehension of images remains relatively unexplored.\nTowards this goal, we introduce MetaCLUE, a set of vision tasks on visual\nmetaphor. We also collect high-quality and rich metaphor annotations (abstract\nobjects, concepts, relationships along with their corresponding object boxes)\nas there do not exist any datasets that facilitate the evaluation of these\ntasks. We perform a comprehensive analysis of state-of-the-art models in vision\nand language based on our annotations, highlighting strengths and weaknesses of\ncurrent approaches in visual metaphor Classification, Localization,\nUnderstanding (retrieval, question answering, captioning) and gEneration\n(text-to-image synthesis) tasks. We hope this work provides a concrete step\ntowards developing AI systems with human-like creative capabilities.",
    "descriptor": "\nComments: Project page: this https URL , Video summary: this https URL\n",
    "authors": [
      "Arjun R. Akula",
      "Brendan Driscoll",
      "Pradyumna Narayana",
      "Soravit Changpinyo",
      "Zhiwei Jia",
      "Suyash Damle",
      "Garima Pruthi",
      "Sugato Basu",
      "Leonidas Guibas",
      "William T. Freeman",
      "Yuanzhen Li",
      "Varun Jampani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.09898"
  },
  {
    "id": "arXiv:2212.09900",
    "title": "Policy learning \"without'' overlap: Pessimism and generalized empirical  Bernstein's inequality",
    "abstract": "This paper studies offline policy learning, which aims at utilizing\nobservations collected a priori (from either fixed or adaptively evolving\nbehavior policies) to learn an optimal individualized decision rule that\nachieves the best overall outcomes for a given population. Existing policy\nlearning methods rely on a uniform overlap assumption, i.e., the propensities\nof exploring all actions for all individual characteristics are lower bounded\nin the offline dataset; put differently, the performance of the existing\nmethods depends on the worst-case propensity in the offline dataset. As one has\nno control over the data collection process, this assumption can be unrealistic\nin many situations, especially when the behavior policies are allowed to evolve\nover time with diminishing propensities for certain actions.\nIn this paper, we propose a new algorithm that optimizes lower confidence\nbounds (LCBs) -- instead of point estimates -- of the policy values. The LCBs\nare constructed using knowledge of the behavior policies for collecting the\noffline data. Without assuming any uniform overlap condition, we establish a\ndata-dependent upper bound for the suboptimality of our algorithm, which only\ndepends on (i) the overlap for the optimal policy, and (ii) the complexity of\nthe policy class we optimize over. As an implication, for adaptively collected\ndata, we ensure efficient policy learning as long as the propensities for\noptimal actions are lower bounded over time, while those for suboptimal ones\nare allowed to diminish arbitrarily fast. In our theoretical analysis, we\ndevelop a new self-normalized type concentration inequality for\ninverse-propensity-weighting estimators, generalizing the well-known empirical\nBernstein's inequality to unbounded and non-i.i.d. data.",
    "descriptor": "",
    "authors": [
      "Ying Jin",
      "Zhimei Ren",
      "Zhuoran Yang",
      "Zhaoran Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.09900"
  },
  {
    "id": "arXiv:2212.09902",
    "title": "Dexterous Manipulation from Images: Autonomous Real-World RL via Substep  Guidance",
    "abstract": "Complex and contact-rich robotic manipulation tasks, particularly those that\ninvolve multi-fingered hands and underactuated object manipulation, present a\nsignificant challenge to any control method. Methods based on reinforcement\nlearning offer an appealing choice for such settings, as they can enable robots\nto learn to delicately balance contact forces and dexterously reposition\nobjects without strong modeling assumptions. However, running reinforcement\nlearning on real-world dexterous manipulation systems often requires\nsignificant manual engineering. This negates the benefits of autonomous data\ncollection and ease of use that reinforcement learning should in principle\nprovide. In this paper, we describe a system for vision-based dexterous\nmanipulation that provides a \"programming-free\" approach for users to define\nnew tasks and enable robots with complex multi-fingered hands to learn to\nperform them through interaction. The core principle underlying our system is\nthat, in a vision-based setting, users should be able to provide high-level\nintermediate supervision that circumvents challenges in teleoperation or\nkinesthetic teaching which allow a robot to not only learn a task efficiently\nbut also to autonomously practice. Our system includes a framework for users to\ndefine a final task and intermediate sub-tasks with image examples, a\nreinforcement learning procedure that learns the task autonomously without\ninterventions, and experimental results with a four-finger robotic hand\nlearning multi-stage object manipulation tasks directly in the real world,\nwithout simulation, manual modeling, or reward engineering.",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Kelvin Xu",
      "Zheyuan Hu",
      "Ria Doshi",
      "Aaron Rovinsky",
      "Vikash Kumar",
      "Abhishek Gupta",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.09902"
  },
  {
    "id": "arXiv:2212.09910",
    "title": "An experience in automatically extracting CAPAs from code repositories",
    "abstract": "TOM (stands for Theoretically Objective Measurements of Software Development\nProjects) is a set of services that are in charge of helping developers or\nteams in the process of identifying anomilies within their software development\nprocess, and providing a list of preventive or corrective actions (aka CAPAS)\nthat positively impact the process. and in this way to improve the quality of\nthe final product and its development process. In order to get help from TOM,\nit is as simple as adding our bot (@0capa) to the list of collaborators in your\nrepository, and with this our bot will automatically take care of obtaining\ndifferent metrics from your repository, in order to suggest actions to take\ninto account to that in your future updates the identified anomalies are not\nrepeated. This paper presents the underlying research on this idea.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Yegor Bugayenko",
      "Imre Delgado",
      "Firas Jolha",
      "Zamira Kholmatova",
      "Artem Kruglov",
      "Witold Pedrycz",
      "Giancarlo Succi",
      "Xavier Vasquez"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.09910"
  },
  {
    "id": "arXiv:2212.09912",
    "title": "Tokenization Consistency Matters for Generative Models on Extractive NLP  Tasks",
    "abstract": "Generative models have been widely applied to solve extractive tasks, where\nparts of the input is extracted to form the desired output, and achieved\nsignificant success. For example, in extractive question answering (QA),\ngenerative models have constantly yielded state-of-the-art results. In this\nwork, we identify the issue of tokenization inconsistency that is commonly\nneglected in training these models. This issue damages the extractive nature of\nthese tasks after the input and output are tokenized inconsistently by the\ntokenizer, and thus leads to performance drop as well as hallucination. We\npropose a simple yet effective fix to this issue and conduct a case study on\nextractive QA. We show that, with consistent tokenization, the model performs\nbetter in both in-domain and out-of-domain datasets, with a notable average of\n+1.7 F2 gain when a BART model is trained on SQuAD and evaluated on 8 QA\ndatasets. Further, the model converges faster, and becomes less likely to\ngenerate out-of-context answers. With these findings, we would like to call for\nmore attention on how tokenization should be done when solving extractive tasks\nand recommend applying consistent tokenization during training.",
    "descriptor": "",
    "authors": [
      "Kaiser Sun",
      "Peng Qi",
      "Yuhao Zhang",
      "Lan Liu",
      "William Yang Wang",
      "Zhiheng Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09912"
  },
  {
    "id": "arXiv:2212.09917",
    "title": "Inverse Reinforcement Learning for Text Summarization",
    "abstract": "Current state-of-the-art summarization models are trained with either maximum\nlikelihood estimation (MLE) or reinforcement learning (RL). In this study, we\ninvestigate the third training paradigm and argue that inverse reinforcement\nlearning (IRL) may be more suitable for text summarization. IRL focuses on\nestimating the reward function of an agent, given a set of observations of that\nagent's behavior. Generally, IRL provides advantages in situations where the\nreward function is not explicitly known or where it is difficult to define or\ninteract with the environment directly. These situations are exactly what we\nobserve in summarization. Thus, we introduce inverse reinforcement learning\ninto text summarization and define a suite of sub-rewards that are important\nfor summarization optimization. By simultaneously estimating the reward\nfunction and optimizing the summarization agent with expert demonstrations, we\nshow that the model trained with IRL produces summaries that closely follow\nhuman behavior, in terms of better ROUGE, coverage, novelty, compression ratio\nand factuality when compared to the baselines trained with MLE and RL.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Yu Fu",
      "Deyi Xiong",
      "Yue Dong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09917"
  },
  {
    "id": "arXiv:2212.09918",
    "title": "Generalizing Multimodal Variational Methods to Sets",
    "abstract": "Making sense of multiple modalities can yield a more comprehensive\ndescription of real-world phenomena. However, learning the co-representation of\ndiverse modalities is still a long-standing endeavor in emerging machine\nlearning applications and research. Previous generative approaches for\nmultimodal input approximate a joint-modality posterior by uni-modality\nposteriors as product-of-experts (PoE) or mixture-of-experts (MoE). We argue\nthat these approximations lead to a defective bound for the optimization\nprocess and loss of semantic connection among modalities. This paper presents a\nnovel variational method on sets called the Set Multimodal VAE (SMVAE) for\nlearning a multimodal latent space while handling the missing modality problem.\nBy modeling the joint-modality posterior distribution directly, the proposed\nSMVAE learns to exchange information between multiple modalities and compensate\nfor the drawbacks caused by factorization. In public datasets of various\ndomains, the experimental results demonstrate that the proposed method is\napplicable to order-agnostic cross-modal generation while achieving outstanding\nperformance compared to the state-of-the-art multimodal methods. The source\ncode for our method is available online\nhttps://anonymous.4open.science/r/SMVAE-9B3C/.",
    "descriptor": "\nComments: First Submission\n",
    "authors": [
      "Jinzhao Zhou",
      "Yiqun Duan",
      "Zhihong Chen",
      "Yu-Cheng Chang",
      "Chin-Teng Lin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.09918"
  },
  {
    "id": "arXiv:2212.09920",
    "title": "Variational Factorization Machines for Preference Elicitation in  Large-Scale Recommender Systems",
    "abstract": "Factorization machines (FMs) are a powerful tool for regression and\nclassification in the context of sparse observations, that has been\nsuccessfully applied to collaborative filtering, especially when side\ninformation over users or items is available. Bayesian formulations of FMs have\nbeen proposed to provide confidence intervals over the predictions made by the\nmodel, however they usually involve Markov-chain Monte Carlo methods that\nrequire many samples to provide accurate predictions, resulting in slow\ntraining in the context of large-scale data. In this paper, we propose a\nvariational formulation of factorization machines that allows us to derive a\nsimple objective that can be easily optimized using standard mini-batch\nstochastic gradient descent, making it amenable to large-scale data. Our\nalgorithm learns an approximate posterior distribution over the user and item\nparameters, which leads to confidence intervals over the predictions. We show,\nusing several datasets, that it has comparable or better performance than\nexisting methods in terms of prediction accuracy, and provide some applications\nin active learning strategies, e.g., preference elicitation techniques.",
    "descriptor": "\nComments: 8 pages, 4 figures, 4 tables. Proceedings of the IEEE BigData 2022 conference\n",
    "authors": [
      "Jill-J\u00eann Vie",
      "Tomas Rigaux",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.09920"
  },
  {
    "id": "arXiv:2212.09921",
    "title": "Normalized Stochastic Gradient Descent Training of Deep Neural Networks",
    "abstract": "In this paper, we introduce a novel optimization algorithm for machine\nlearning model training called Normalized Stochastic Gradient Descent (NSGD)\ninspired by Normalized Least Mean Squares (NLMS) from adaptive filtering. When\nwe train a high-complexity model on a large dataset, the learning rate is\nsignificantly important as a poor choice of optimizer parameters can lead to\ndivergence. The algorithm updates the new set of network weights using the\nstochastic gradient but with $\\ell_1$ and $\\ell_2$-based normalizations on the\nlearning rate parameter similar to the NLMS algorithm. Our main difference from\nthe existing normalization methods is that we do not include the error term in\nthe normalization process. We normalize the update term using the input vector\nto the neuron. Our experiments present that the model can be trained to a\nbetter accuracy level on different initial settings using our optimization\nalgorithm. In this paper, we demonstrate the efficiency of our training\nalgorithm using ResNet-20 and a toy neural network on different benchmark\ndatasets with different initializations. The NSGD improves the accuracy of the\nResNet-20 from 91.96\\% to 92.20\\% on the CIFAR-10 dataset.",
    "descriptor": "",
    "authors": [
      "Salih Atici",
      "Hongyi Pan",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.09921"
  },
  {
    "id": "arXiv:2212.09925",
    "title": "Plug & Play Directed Evolution of Proteins with Gradient-based Discrete  MCMC",
    "abstract": "A long-standing goal of machine-learning-based protein engineering is to\naccelerate the discovery of novel mutations that improve the function of a\nknown protein. We introduce a sampling framework for evolving proteins in\nsilico that supports mixing and matching a variety of unsupervised models, such\nas protein language models, and supervised models that predict protein function\nfrom sequence. By composing these models, we aim to improve our ability to\nevaluate unseen mutations and constrain search to regions of sequence space\nlikely to contain functional proteins. Our framework achieves this without any\nmodel fine-tuning or re-training by constructing a product of experts\ndistribution directly in discrete protein space. Instead of resorting to brute\nforce search or random sampling, which is typical of classic directed\nevolution, we introduce a fast MCMC sampler that uses gradients to propose\npromising mutations. We conduct in silico directed evolution experiments on\nwide fitness landscapes and across a range of different pre-trained\nunsupervised models, including a 650M parameter protein language model. Our\nresults demonstrate an ability to efficiently discover variants with high\nevolutionary likelihood as well as estimated activity multiple mutations away\nfrom a wild type protein, suggesting our sampler provides a practical and\neffective new paradigm for machine-learning-based protein engineering.",
    "descriptor": "\nComments: 33 pages, 8 figures. Under review. Code is available at this https URL A short version of this work appeared at the NeurIPS 2022 Machine Learning in Structural Biology Workshop\n",
    "authors": [
      "Patrick Emami",
      "Aidan Perreault",
      "Jeffrey Law",
      "David Biagioni",
      "Peter C. St. John"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2212.09925"
  },
  {
    "id": "arXiv:2212.09926",
    "title": "Bandit approach to conflict-free multi-agent Q-learning in view of  photonic implementation",
    "abstract": "Recently, extensive studies on photonic reinforcement learning to accelerate\nthe process of calculation by exploiting the physical nature of light have been\nconducted. Previous studies utilized quantum interference of photons to achieve\ncollective decision-making without choice conflicts when solving the\ncompetitive multi-armed bandit problem, a fundamental example of reinforcement\nlearning. However, the bandit problem deals with a static environment where the\nagent's action does not influence the reward probabilities. This study aims to\nextend the conventional approach to a more general multi-agent reinforcement\nlearning targeting the grid world problem. Unlike the conventional approach,\nthe proposed scheme deals with a dynamic environment where the reward changes\nbecause of agents' actions. A successful photonic reinforcement learning scheme\nrequires both a photonic system that contributes to the quality of learning and\na suitable algorithm. This study proposes a novel learning algorithm,\ndiscontinuous bandit Q-learning, in view of a potential photonic\nimplementation. Here, state-action pairs in the environment are regarded as\nslot machines in the context of the bandit problem and an updated amount of\nQ-value is regarded as the reward of the bandit problem. We perform numerical\nsimulations to validate the effectiveness of the bandit algorithm. In addition,\nwe propose a multi-agent architecture in which agents are indirectly connected\nthrough quantum interference of light and quantum principles ensure the\nconflict-free property of state-action pair selections among agents. We\ndemonstrate that multi-agent reinforcement learning can be accelerated owing to\nconflict avoidance among multiple agents.",
    "descriptor": "\nComments: 19 pages, 8 figures, 1 table\n",
    "authors": [
      "Hiroaki Shinkawa",
      "Nicolas Chauvet",
      "Andr\u00e9 R\u00f6hm",
      "Takatomo Mihana",
      "Ryoichi Horisaki",
      "Guillaume Bachelier",
      "Makoto Naruse"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Optics (physics.optics)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.09926"
  },
  {
    "id": "arXiv:2212.09928",
    "title": "Improving the Robustness of Summarization Models by Detecting and  Removing Input Noise",
    "abstract": "The evaluation of abstractive summarization models typically uses test data\nthat is identically distributed as training data. In real-world practice,\ndocuments to be summarized may contain input noise caused by text extraction\nartifacts or data pipeline bugs. The robustness of model performance under\ndistribution shift caused by such noise is relatively under-studied. We present\na large empirical study quantifying the sometimes severe loss in performance\n(up to 12 ROUGE-1 points) from different types of input noise for a range of\ndatasets and model sizes. We then propose a light-weight method for detecting\nand removing such noise in the input during model inference without requiring\nany extra training, auxiliary models, or even prior knowledge of the type of\nnoise. Our proposed approach effectively mitigates the loss in performance,\nrecovering a large fraction of the performance drop, sometimes as large as 11\nROUGE-1 points.",
    "descriptor": "",
    "authors": [
      "Kundan Krishna",
      "Yao Zhao",
      "Jie Ren",
      "Balaji Lakshminarayanan",
      "Jiaming Luo",
      "Mohammad Saleh",
      "Peter J. Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09928"
  },
  {
    "id": "arXiv:2212.09929",
    "title": "H2 Model Order Reduction: A Relative Error Setting",
    "abstract": "In dynamical system theory, the process of obtaining a reduced-order\napproximation of the high-order model is called model order reduction. The\ncloseness of the reduced-order model to the original model is generally gauged\nby using system norms of additive or relative error system. The relative error\nis a superior criterion to the additive error in assessing accuracy in many\napplications like reduced-order controller and filter designs. In this paper,\nwe propose an oblique projection algorithm that minimizes the H2 norm of the\nrelative error transfer function. The selection of reduction matrices in the\nalgorithm is motivated by the necessary conditions for local optima of the\n(squared) H2 norm of the relative error transfer function. Numerical simulation\nconfirms that the proposed algorithm compares well in accuracy with balanced\nstochastic truncation while avoiding the solution of large-scale Riccati and\nLyapunov equations.",
    "descriptor": "",
    "authors": [
      "Umair Zulfiqar",
      "Xin Dua",
      "Qiuyan Song",
      "Muwahida Liaquat",
      "Victor Sreeram"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.09929"
  },
  {
    "id": "arXiv:2212.09930",
    "title": "Frequency-limited H$_2$ Model Order Reduction Based on Relative Error",
    "abstract": "In frequency-limited model order reduction, the original high-order model is\napproximated by a reduced-order model that exhibits high fidelity within the\ndesired frequency interval. Inferior accuracy beyond that frequency interval\ncan be tolerated due to the nature of the problem. The approximation error\nquantifies the quality of the reduced-order model, which is generally measured\nin absolute or relative terms. A small absolute error can be a misleading\nnotion of accuracy when the original and reduced systems' responses are\ninherently small within the desired frequency interval. The relative error\nquantifies percentage error, which is more meaningful in such scenarios. In\nthis paper, the necessary conditions for a local optimum of the\nfrequency-limited H$_2$ norm of the relative error system are derived. Then, an\noblique projection algorithm is proposed based on these optimality conditions,\nwhich ensures a small relative error within the desired frequency interval.\nUnlike the existing algorithms, the proposed algorithm does not require\nsolutions for large-scale linear matrix equations. The performance of the\nproposed algorithm is compared with frequency-limited balanced truncation,\nfrequency-limited balanced stochastic truncation, and frequency-limited\niterative Rational Krylov algorithm. The superior accuracy and performance of\nthe proposed algorithm are highlighted by considering benchmark numerical\nexamples.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2212.08247\n",
    "authors": [
      "Umair Zulfiqar",
      "Xin Du",
      "Qiuyan Song",
      "Zhi-Hua Xiao",
      "Victor Sreeram"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.09930"
  },
  {
    "id": "arXiv:2212.09937",
    "title": "AI applications in forest monitoring need remote sensing benchmark  datasets",
    "abstract": "With the rise in high resolution remote sensing technologies there has been\nan explosion in the amount of data available for forest monitoring, and an\naccompanying growth in artificial intelligence applications to automatically\nderive forest properties of interest from these datasets. Many studies use\ntheir own data at small spatio-temporal scales, and demonstrate an application\nof an existing or adapted data science method for a particular task. This\napproach often involves intensive and time-consuming data collection and\nprocessing, but generates results restricted to specific ecosystems and sensor\ntypes. There is a lack of widespread acknowledgement of how the types and\nstructures of data used affects performance and accuracy of analysis\nalgorithms. To accelerate progress in the field more efficiently, benchmarking\ndatasets upon which methods can be tested and compared are sorely needed.\nHere, we discuss how lack of standardisation impacts confidence in estimation\nof key forest properties, and how considerations of data collection need to be\naccounted for in assessing method performance. We present pragmatic\nrequirements and considerations for the creation of rigorous, useful\nbenchmarking datasets for forest monitoring applications, and discuss how tools\nfrom modern data science can improve use of existing data. We list a set of\nexample large-scale datasets that could contribute to benchmarking, and present\na vision for how community-driven, representative benchmarking initiatives\ncould benefit the field.",
    "descriptor": "",
    "authors": [
      "Emily R. Lines",
      "Matt Allen",
      "Carlos Cabo",
      "Kim Calders",
      "Amandine Debus",
      "Stuart W. D. Grieve",
      "Milto Miltiadou",
      "Adam Noach",
      "Harry J. F. Owen",
      "Stefano Puliti"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.09937"
  },
  {
    "id": "arXiv:2212.09939",
    "title": "AnyTOD: A Programmable Task-Oriented Dialog System",
    "abstract": "We propose AnyTOD, an end-to-end task-oriented dialog (TOD) system with\nzero-shot capability for unseen tasks. We view TOD as a program executed by a\nlanguage model (LM), where program logic and ontology is provided by a designer\nin the form of a schema. To enable generalization onto unseen schemas and\nprograms without prior training, AnyTOD adopts a neuro-symbolic approach. A\nneural LM keeps track of events that occur during a conversation, and a\nsymbolic program implementing the dialog policy is executed to recommend next\nactions AnyTOD should take. This approach drastically reduces data annotation\nand model training requirements, addressing a long-standing challenge in TOD\nresearch: rapidly adapting a TOD system to unseen tasks and domains. We\ndemonstrate state-of-the-art results on the STAR and ABCD benchmarks, as well\nas AnyTOD's strong zero-shot transfer capability in low-resource settings. In\naddition, we release STARv2, an updated version of the STAR dataset with richer\ndata annotations, for benchmarking zero-shot end-to-end TOD models.",
    "descriptor": "",
    "authors": [
      "Jeffrey Zhao",
      "Yuan Cao",
      "Raghav Gupta",
      "Harrison Lee",
      "Abhinav Rastogi",
      "Mingqiu Wang",
      "Hagen Soltau",
      "Izhak Shafran",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09939"
  },
  {
    "id": "arXiv:2212.09941",
    "title": "Anticipatory Fictitious Play",
    "abstract": "Fictitious play is an algorithm for computing Nash equilibria of matrix\ngames. Recently, machine learning variants of fictitious play have been\nsuccessfully applied to complicated real-world games. This paper presents a\nsimple modification of fictitious play which is a strict improvement over the\noriginal: it has the same theoretical worst-case convergence rate, is equally\napplicable in a machine learning context, and enjoys superior empirical\nperformance. We conduct an extensive comparison of our algorithm with\nfictitious play, proving an optimal convergence rate for certain classes of\ngames, demonstrating superior performance numerically across a variety of\ngames, and concluding with experiments that extend these algorithms to the\nsetting of deep multiagent reinforcement learning.",
    "descriptor": "",
    "authors": [
      "Alex Cloud",
      "Albert Wang",
      "Wesley Kerr"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2212.09941"
  },
  {
    "id": "arXiv:2212.09944",
    "title": "Full-Life Cycle Intent-Driven Network Verification: Challenges and  Approaches",
    "abstract": "With the human friendly declarative intent policy expression, intent-driven\nnetwork can make network management and configuration autonomous without human\nintervention. However, the availability and dependability of these refined\npolicies from the expressed intents should be well ensured by full-life cycle\nverification. Moreover, intent-driven network verification is still in its\ninitial stage, and there is a lack of full-life cycle end-to-end verification\nframework. As a result, in this article, we present and review existing\nverification techniques, and classify them according to objective, purpose, and\nfeedback. Furthermore, we describe intent verification as a technology that\nprovides assurance during the intent form conversion process and propose a\nnovel full-life cycle verification framework that expands on the concept of\ntraditional network verification. Finally, we verify the feasibility and\nvalidity of the presented verification framework in the case of an access\ncontrol policy for different network functions with multi conflict intents.",
    "descriptor": "\nComments: 8 pages, 3 figures, magazine\n",
    "authors": [
      "Yanbo Song",
      "Chungang Yang",
      "Jiaming Zhang",
      "Xinru Mi",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.09944"
  },
  {
    "id": "arXiv:2212.09945",
    "title": "Robust and Resource-efficient Machine Learning Aided Viewport Prediction  in Virtual Reality",
    "abstract": "360-degree panoramic videos have gained considerable attention in recent\nyears due to the rapid development of head-mounted displays (HMDs) and\npanoramic cameras. One major problem in streaming panoramic videos is that\npanoramic videos are much larger in size compared to traditional ones.\nMoreover, the user devices are often in a wireless environment, with limited\nbattery, computation power, and bandwidth. To reduce resource consumption,\nresearchers have proposed ways to predict the users' viewports so that only\npart of the entire video needs to be transmitted from the server. However, the\nrobustness of such prediction approaches has been overlooked in the literature:\nit is usually assumed that only a few models, pre-trained on past users'\nexperiences, are applied for prediction to all users. We observe that those\npre-trained models can perform poorly for some users because they might have\ndrastically different behaviors from the majority, and the pre-trained models\ncannot capture the features in unseen videos. In this work, we propose a novel\nmeta learning based viewport prediction paradigm to alleviate the worst\nprediction performance and ensure the robustness of viewport prediction. This\nparadigm uses two machine learning models, where the first model predicts the\nviewing direction, and the second model predicts the minimum video prefetch\nsize that can include the actual viewport. We first train two meta models so\nthat they are sensitive to new training data, and then quickly adapt them to\nusers while they are watching the videos. Evaluation results reveal that the\nmeta models can adapt quickly to each user, and can significantly increase the\nprediction accuracy, especially for the worst-performing predictions.",
    "descriptor": "\nComments: Accepted for publication in 2022 IEEE International Conference on Big Data (IEEE BigData 2022)\n",
    "authors": [
      "Yuang Jiang",
      "Konstantinos Poularakis",
      "Diego Kiedanski",
      "Sastry Kompella",
      "Leandros Tassiulas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.09945"
  },
  {
    "id": "arXiv:2212.09946",
    "title": "Dialog2API: Task-Oriented Dialogue with API Description and Example  Programs",
    "abstract": "Functionality and dialogue experience are two important factors of\ntask-oriented dialogue systems. Conventional approaches with closed schema\n(e.g., conversational semantic parsing) often fail as both the functionality\nand dialogue experience are strongly constrained by the underlying schema. We\nintroduce a new paradigm for task-oriented dialogue - Dialog2API - to greatly\nexpand the functionality and provide seamless dialogue experience. The\nconversational model interacts with the environment by generating and executing\nprograms triggering a set of pre-defined APIs. The model also manages the\ndialogue policy and interact with the user through generating appropriate\nnatural language responses. By allowing generating free-form programs,\nDialog2API supports composite goals by combining different APIs, whereas\nunrestricted program revision provides natural and robust dialogue experience.\nTo facilitate Dialog2API, the core model is provided with API documents, an\nexecution environment and optionally some example dialogues annotated with\nprograms. We propose an approach tailored for the Dialog2API, where the\ndialogue states are represented by a stack of programs, with most recently\nmentioned program on the top of the stack. Dialog2API can work with many\napplication scenarios such as software automation and customer service. In this\npaper, we construct a dataset for AWS S3 APIs and present evaluation results of\nin-context learning baselines.",
    "descriptor": "",
    "authors": [
      "Raphael Shu",
      "Elman Mansimov",
      "Tamer Alkhouli",
      "Nikolaos Pappas",
      "Salvatore Romeo",
      "Arshit Gupta",
      "Saab Mansour",
      "Yi Zhang",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09946"
  },
  {
    "id": "arXiv:2212.09947",
    "title": "Future Sight: Dynamic Story Generation with Large Pretrained Language  Models",
    "abstract": "Recent advances in deep learning research, such as transformers, have\nbolstered the ability for automated agents to generate creative texts similar\nto those that a human would write. By default, transformer decoders can only\ngenerate new text with respect to previously generated text. The output\ndistribution of candidate tokens at any position is conditioned on previously\nselected tokens using a self-attention mechanism to emulate the property of\nautoregression. This is inherently limiting for tasks such as controllable\nstory generation where it may be necessary to condition on future plot events\nwhen writing a story. In this work, we propose Future Sight, a method for\nfinetuning a pretrained generative transformer on the task of future\nconditioning. Transformer decoders are typically pretrained on the task of\ncompleting a context, one token at a time, by means of self-attention. Future\nSight additionally enables a decoder to attend to an encoded future plot event.\nThis motivates the decoder to expand on the context in a way that logically\nconcludes with the provided future. During inference, the future plot event can\nbe written by a human author to steer the narrative being generated in a\ncertain direction. We evaluate the efficacy of our approach on a story\ngeneration task with human evaluators.",
    "descriptor": "\nComments: 9 pages, 1 figure, 4 tables\n",
    "authors": [
      "Brian D. Zimmerman",
      "Gaurav Sahu",
      "Olga Vechtomova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09947"
  },
  {
    "id": "arXiv:2212.09948",
    "title": "MM-3DScene: 3D Scene Understanding by Customizing Masked Modeling with  Informative-Preserved Reconstruction and Self-Distilled Consistency",
    "abstract": "Masked Modeling (MM) has demonstrated widespread success in various vision\nchallenges, by reconstructing masked visual patches. Yet, applying MM for\nlarge-scale 3D scenes remains an open problem due to the data sparsity and\nscene complexity. The conventional random masking paradigm used in 2D images\noften causes a high risk of ambiguity when recovering the masked region of 3D\nscenes. To this end, we propose a novel informative-preserved reconstruction,\nwhich explores local statistics to discover and preserve the representative\nstructured points, effectively enhancing the pretext masking task for 3D scene\nunderstanding. Integrated with a progressive reconstruction manner, our method\ncan concentrate on modeling regional geometry and enjoy less ambiguity for\nmasked reconstruction. Besides, such scenes with progressive masking ratios can\nalso serve to self-distill their intrinsic spatial consistency, requiring to\nlearn the consistent representations from unmasked areas. By elegantly\ncombining informative-preserved reconstruction on masked areas and consistency\nself-distillation from unmasked areas, a unified framework called MM-3DScene is\nyielded. We conduct comprehensive experiments on a host of downstream tasks.\nThe consistent improvement (e.g., +6.1 mAP@0.5 on object detection and +2.2%\nmIoU on semantic segmentation) demonstrates the superiority of our approach.",
    "descriptor": "",
    "authors": [
      "Mingye Xu",
      "Mutian Xu",
      "Tong He",
      "Wanli Ouyang",
      "Yali Wang",
      "Xiaoguang Han",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.09948"
  },
  {
    "id": "arXiv:2212.09950",
    "title": "Domain Generalization with Correlated Style Uncertainty",
    "abstract": "Though impressive success has been witnessed in computer vision, deep\nlearning still suffers from the domain shift challenge when the target domain\nfor testing and the source domain for training do not share an identical\ndistribution. To address this, domain generalization approaches intend to\nextract domain invariant features that can lead to a more robust model. Hence,\nincreasing the source domain diversity is a key component of domain\ngeneralization. Style augmentation takes advantage of instance-specific feature\nstatistics containing informative style characteristics to synthetic novel\ndomains. However, all previous works ignored the correlation between different\nfeature channels or only limited the style augmentation through linear\ninterpolation. In this work, we propose a novel augmentation method, called\n\\textit{Correlated Style Uncertainty (CSU)}, to go beyond the linear\ninterpolation of style statistic space while preserving the essential\ncorrelation information. We validate our method's effectiveness by extensive\nexperiments on multiple cross-domain classification tasks, including widely\nused PACS, Office-Home, Camelyon17 datasets and the Duke-Market1501 instance\nretrieval task and obtained significant margin improvements over the\nstate-of-the-art methods. The source code is available for public use.",
    "descriptor": "\nComments: Code is available after peer review\n",
    "authors": [
      "Zheyuan Zhang",
      "Bin Wang",
      "Debesh Jha",
      "Ugur Demir",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.09950"
  },
  {
    "id": "arXiv:2212.09952",
    "title": "Efficient Algorithms for the Bee-Identification Problem",
    "abstract": "The bee-identification problem, formally defined by Tandon, Tan and Varshney\n(2019), requires the receiver to identify \"bees\" using a set of unordered noisy\nmeasurements. In this previous work, Tandon, Tan, and Varshney studied error\nexponents and showed that decoding the measurements jointly results in a\nsignificantly smaller error exponent.\nIn this work, we study algorithms related to this joint decoder. First, we\ndemonstrate how to perform joint decoding efficiently. By reducing to the\nproblem of finding perfect matching and minimum-cost matchings, we obtain joint\ndecoders that run in time quadratic and cubic in the number of \"bees\" for the\nbinary erasure (BEC) and binary symmetric channels (BSC), respectively. Next,\nby studying the matching algorithms in the context of channel coding, we\nfurther reduce the running times by using classical tools like peeling decoders\nand list-decoders. In particular, we show that our identifier algorithms when\nused with Reed-Muller codes terminate in almost linear and quadratic time for\nBEC and BSC, respectively.\nFinally, for explicit codebooks, we study when these joint decoders fail to\nidentify the \"bees\" correctly. Specifically, we provide practical methods of\nestimating the probability of erroneous identification for given codebooks.",
    "descriptor": "",
    "authors": [
      "Han Mao Kiah",
      "Alexander Vardy",
      "Hanwen Yao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.09952"
  },
  {
    "id": "arXiv:2212.09955",
    "title": "BUMP: A Benchmark of Unfaithful Minimal Pairs for Meta-Evaluation of  Faithfulness Metrics",
    "abstract": "The proliferation of automatic faithfulness metrics for summarization has\nproduced a need for benchmarks to evaluate them. While existing benchmarks\nmeasure the correlation with human judgements of faithfulness on\nmodel-generated summaries, they are insufficient for diagnosing whether metrics\nare: 1) consistent, i.e., decrease as errors are introduced into a summary, 2)\neffective on human-written texts, and 3) sensitive to different error types (as\nsummaries can contain multiple errors). To address these needs, we present a\nbenchmark of unfaithful minimal pairs (BUMP), a dataset of 889 human-written,\nminimally different summary pairs, where a single error (from an ontology of 7\ntypes) is introduced to a summary from the CNN/DailyMail dataset to produce an\nunfaithful summary. We find BUMP complements existing benchmarks in a number of\nways: 1) the summaries in BUMP are harder to discriminate and less probable\nunder SOTA summarization models, 2) BUMP enables measuring the consistency of\nmetrics, and reveals that the most discriminative metrics tend not to be the\nmost consistent, 3) BUMP enables the measurement of metrics' performance on\nindividual error types and highlights areas of weakness for future work.",
    "descriptor": "",
    "authors": [
      "Liang Ma",
      "Shuyang Cao",
      "Robert L. Logan IV",
      "Di Lu",
      "Shihao Ran",
      "Ke Zhang",
      "Joel Tetreault",
      "Aoife Cahill",
      "Alejandro Jaimes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09955"
  },
  {
    "id": "arXiv:2212.09962",
    "title": "Distributional Robustness Bounds Generalization Errors",
    "abstract": "Bayesian methods, distributionally robust optimization methods, and\nregularization methods are three pillars of trustworthy machine learning\nhedging against distributional uncertainty, e.g., the uncertainty of an\nempirical distribution compared to the true underlying distribution. This paper\ninvestigates the connections among the three frameworks and, in particular,\nexplores why these frameworks tend to have smaller generalization errors.\nSpecifically, first, we suggest a quantitative definition for \"distributional\nrobustness\", propose the concept of \"robustness measure\", and formalize several\nphilosophical concepts in distributionally robust optimization. Second, we show\nthat Bayesian methods are distributionally robust in the probably approximately\ncorrect (PAC) sense; In addition, by constructing a Dirichlet-process-like\nprior in Bayesian nonparametrics, it can be proven that any regularized\nempirical risk minimization method is equivalent to a Bayesian method. Third,\nwe show that generalization errors of machine learning models can be\ncharacterized using the distributional uncertainty of the nominal distribution\nand the robustness measures of these machine learning models, which is a new\nperspective to bound generalization errors, and therefore, explain the reason\nwhy distributionally robust machine learning models, Bayesian models, and\nregularization models tend to have smaller generalization errors.",
    "descriptor": "\nComments: 47 Pages, 2 Figures\n",
    "authors": [
      "Shixiong Wang",
      "Haowei Wang",
      "Jean Honorio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.09962"
  },
  {
    "id": "arXiv:2212.09967",
    "title": "Learning Subgrid-scale Models with Neural Ordinary Differential  Equations",
    "abstract": "We propose a new approach to learning the subgrid-scale model effects when\nsimulating partial differential equations (PDEs) solved by the method of lines\nand their representation in chaotic ordinary differential equations, based on\nneural ordinary differential equations (NODEs). Solving systems with fine\ntemporal and spatial grid scales is an ongoing computational challenge, and\nclosure models are generally difficult to tune. Machine learning approaches\nhave increased the accuracy and efficiency of computational fluid dynamics\nsolvers. In this approach neural networks are used to learn the coarse- to\nfine-grid map, which can be viewed as subgrid scale parameterization. We\npropose a strategy that uses the NODE and partial knowledge to learn the source\ndynamics at a continuous level. Our method inherits the advantages of NODEs and\ncan be used to parameterize subgrid scales, approximate coupling operators, and\nimprove the efficiency of low-order solvers. Numerical results using the\ntwo-scale Lorenz 96 ODE and the convection-diffusion PDE are used to illustrate\nthis approach.",
    "descriptor": "\nComments: 20 pages, 14 figures\n",
    "authors": [
      "Shinhoo Kang",
      "Emil M. Constantinescu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09967"
  },
  {
    "id": "arXiv:2212.09968",
    "title": "On Improving Summarization Factual Consistency from Natural Language  Feedback",
    "abstract": "Despite the recent progress in language generation models, their outputs may\nnot always meet user expectations. In this work, we study whether informational\nfeedback in natural language can be leveraged to improve generation quality and\nuser preference alignment. To this end, we consider factual consistency in\nsummarization, the quality that the summary should only contain information\nsupported by the input documents, for user preference alignment. We collect a\nhigh-quality dataset, DeFacto, containing human demonstrations and\ninformational feedback in natural language consisting of corrective\ninstructions, edited summaries, and explanations with respect to the factual\nconsistency of the summary. Using our dataset, we study two natural language\ngeneration tasks: 1) editing a summary using the human feedback, and 2)\ngenerating human feedback from the original summary. Using the two tasks, we\nfurther evaluate if models can automatically correct factual inconsistencies in\ngenerated summaries. We show that the human-edited summaries we collected are\nmore factually consistent, and pre-trained language models can leverage our\ndataset to improve the factual consistency of original system-generated\nsummaries in our proposed generation tasks. We make the DeFacto dataset\npublicly available at https://github.com/microsoft/DeFacto.",
    "descriptor": "",
    "authors": [
      "Yixin Liu",
      "Budhaditya Deb",
      "Milagro Teruel",
      "Aaron Halfaker",
      "Dragomir Radev",
      "Ahmed H. Awadallah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09968"
  },
  {
    "id": "arXiv:2212.09970",
    "title": "Data Augmentation on Graphs: A Survey",
    "abstract": "In recent years, graph representation learning has achieved remarkable\nsuccess while suffering from low-quality data problems. As a mature technology\nto improve data quality in computer vision, data augmentation has also\nattracted increasing attention in graph domain. For promoting the development\nof this emerging research direction, in this survey, we comprehensively review\nand summarize the existing graph data augmentation (GDAug) techniques.\nSpecifically, we first summarize a variety of feasible taxonomies, and then\nclassify existing GDAug studies based on fine-grained graph elements.\nFurthermore, for each type of GDAug technique, we formalize the general\ndefinition, discuss the technical details, and give schematic illustration. In\naddition, we also summarize common performance metrics and specific design\nmetrics for constructing a GDAug evaluation system. Finally, we summarize the\napplications of GDAug from both data and model levels, as well as future\ndirections.",
    "descriptor": "\nComments: 31 pages, 11 figures, under review\n",
    "authors": [
      "Jiajun Zhou",
      "Chenxuan Xie",
      "Zhenyu Wen",
      "Xiangyu Zhao",
      "Qi Xuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09970"
  },
  {
    "id": "arXiv:2212.09974",
    "title": "Insights into undergraduate pathways using course load analytics",
    "abstract": "Course load analytics (CLA) inferred from LMS and enrollment features can\noffer a more accurate representation of course workload to students than credit\nhours and potentially aid in their course selection decisions. In this study,\nwe produce and evaluate the first machine-learned predictions of student course\nload ratings and generalize our model to the full 10,000 course catalog of a\nlarge public university. We then retrospectively analyze longitudinal\ndifferences in the semester load of student course selections throughout their\ndegree. CLA by semester shows that a student's first semester at the university\nis among their highest load semesters, as opposed to a credit hour-based\nanalysis, which would indicate it is among their lowest. Investigating what\nrole predicted course load may play in program retention, we find that students\nwho maintain a semester load that is low as measured by credit hours but high\nas measured by CLA are more likely to leave their program of study. This\ndiscrepancy in course load is particularly pertinent in STEM and associated\nwith high prerequisite courses. Our findings have implications for academic\nadvising, institutional handling of the freshman experience, and student-facing\nanalytics to help students better plan, anticipate, and prepare for their\nselected courses.",
    "descriptor": "\nComments: Accepted to Learning Analytics and Knowledge (LAK 2023)\n",
    "authors": [
      "Conrad Borchers",
      "Zachary A. Pardos"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09974"
  },
  {
    "id": "arXiv:2212.09975",
    "title": "Sophisticated deep learning with on-chip optical diffractive tensor  processing",
    "abstract": "The ever-growing deep learning technologies are making revolutionary changes\nfor modern life. However, conventional computing architectures are designed to\nprocess sequential and digital programs, being extremely burdened with\nperforming massive parallel and adaptive deep learning applications. Photonic\nintegrated circuits provide an efficient approach to mitigate bandwidth\nlimitations and power-wall brought by its electronic counterparts, showing\ngreat potential in ultrafast and energy-free high-performance computing. Here,\nwe propose an optical computing architecture enabled by on-chip diffraction to\nimplement convolutional acceleration, termed optical convolution unit (OCU). We\ndemonstrate that any real-valued convolution kernels can be exploited by OCU\nwith a prominent computational throughput boosting via the concept of structral\nre-parameterization. With OCU as the fundamental unit, we build an optical\nconvolutional neural network (oCNN) to implement two popular deep learning\ntasks: classification and regression. For classification, Fashion-MNIST and\nCIFAR-4 datasets are tested with accuracy of 91.63% and 86.25%, respectively.\nFor regression, we build an optical denoising convolutional neural network\n(oDnCNN) to handle Gaussian noise in gray scale images with noise level\n{\\sigma} = 10, 15, 20, resulting clean images with average PSNR of 31.70dB,\n29.39dB and 27.72dB, respectively. The proposed OCU presents remarkable\nperformance of low energy consumption and high information density due to its\nfully passive nature and compact footprint, providing a highly parallel while\nlightweight solution for future computing architecture to handle high\ndimensional tensors in deep learning.",
    "descriptor": "",
    "authors": [
      "Yuyao Huang",
      "Tingzhao Fu",
      "Honghao Huang",
      "Sigang Yang",
      "Hongwei Chen"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2212.09975"
  },
  {
    "id": "arXiv:2212.09976",
    "title": "Towards Understanding the Impacts of Textual Dissimilarity on Duplicate  Bug Report Detection",
    "abstract": "About 40% of software bug reports are duplicates of one another, which pose a\nmajor overhead during software maintenance. Traditional techniques often focus\non detecting duplicate bug reports that are textually similar. However, in bug\ntracking systems, many duplicate bug reports might not be textually similar,\nfor which the traditional techniques might fall short. In this paper, we\nconduct a large-scale empirical study to better understand the impacts of\ntextual dissimilarity on the detection of duplicate bug reports. First, we\ncollect a total of 92,854 bug reports from three open-source systems and\nconstruct two datasets containing textually similar and textually dissimilar\nduplicate bug reports. Then we determine the performance of three existing\ntechniques in detecting duplicate bug reports and show that their performance\nis significantly poor for textually dissimilar duplicate reports. Second, we\nanalyze the two groups of bug reports using a combination of descriptive\nanalysis, word embedding visualization, and manual analysis. We found that\ntextually dissimilar duplicate bug reports often miss important components\n(e.g., expected behaviors and steps to reproduce), which could lead to their\ntextual differences and poor performance by the existing techniques. Finally,\nwe apply domain-specific embedding to duplicate bug report detection problems,\nwhich shows mixed results. All these findings above warrant further\ninvestigation and more effective solutions for detecting textually dissimilar\nduplicate bug reports.",
    "descriptor": "\nComments: Accepted in the 30th edition of the IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER 2023), which will be held at the Macau University of Science and Technology in Macao SAR, China, 2023\n",
    "authors": [
      "Sigma Jahan",
      "Mohammad Masudur Rahman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.09976"
  },
  {
    "id": "arXiv:2212.09979",
    "title": "Flareon: Stealthy any2any Backdoor Injection via Poisoned Augmentation",
    "abstract": "Open software supply chain attacks, once successful, can exact heavy costs in\nmission-critical applications. As open-source ecosystems for deep learning\nflourish and become increasingly universal, they present attackers previously\nunexplored avenues to code-inject malicious backdoors in deep neural network\nmodels. This paper proposes Flareon, a small, stealthy, seemingly harmless code\nmodification that specifically targets the data augmentation pipeline with\nmotion-based triggers. Flareon neither alters ground-truth labels, nor modifies\nthe training loss objective, nor does it assume prior knowledge of the victim\nmodel architecture, training data, and training hyperparameters. Yet, it has a\nsurprisingly large ramification on training -- models trained under Flareon\nlearn powerful target-conditional (or \"any2any\") backdoors. The resulting\nmodels can exhibit high attack success rates for any target choices and better\nclean accuracies than backdoor attacks that not only seize greater control, but\nalso assume more restrictive attack capabilities. We also demonstrate the\neffectiveness of Flareon against recent defenses. Flareon is fully open-source\nand available online to the deep learning community:\nhttps://github.com/lafeat/flareon.",
    "descriptor": "",
    "authors": [
      "Tianrui Qin",
      "Xianghuan He",
      "Xitong Gao",
      "Yiren Zhao",
      "Kejiang Ye",
      "Cheng-Zhong Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.09979"
  },
  {
    "id": "arXiv:2212.09980",
    "title": "Continual Mean Estimation Under User-Level Privacy",
    "abstract": "We consider the problem of continually releasing an estimate of the\npopulation mean of a stream of samples that is user-level differentially\nprivate (DP). At each time instant, a user contributes a sample, and the users\ncan arrive in arbitrary order. Until now these requirements of continual\nrelease and user-level privacy were considered in isolation. But, in practice,\nboth these requirements come together as the users often contribute data\nrepeatedly and multiple queries are made. We provide an algorithm that outputs\na mean estimate at every time instant $t$ such that the overall release is\nuser-level $\\varepsilon$-DP and has the following error guarantee: Denoting by\n$M_t$ the maximum number of samples contributed by a user, as long as\n$\\tilde{\\Omega}(1/\\varepsilon)$ users have $M_t/2$ samples each, the error at\ntime $t$ is $\\tilde{O}(1/\\sqrt{t}+\\sqrt{M}_t/t\\varepsilon)$. This is a\nuniversal error guarantee which is valid for all arrival patterns of the users.\nFurthermore, it (almost) matches the existing lower bounds for the\nsingle-release setting at all time instants when users have contributed equal\nnumber of samples.",
    "descriptor": "",
    "authors": [
      "Anand Jerry George",
      "Lekshmi Ramesh",
      "Aditya Vikram Singh",
      "Himanshu Tyagi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.09980"
  },
  {
    "id": "arXiv:2212.09981",
    "title": "Benchmarking person re-identification datasets and approaches for  practical real-world implementations",
    "abstract": "Recently, Person Re-Identification (Re-ID) has received a lot of attention.\nLarge datasets containing labeled images of various individuals have been\nreleased, allowing researchers to develop and test many successful approaches.\nHowever, when such Re-ID models are deployed in new cities or environments, the\ntask of searching for people within a network of security cameras is likely to\nface an important domain shift, thus resulting in decreased performance.\nIndeed, while most public datasets were collected in a limited geographic area,\nimages from a new city present different features (e.g., people's ethnicity and\nclothing style, weather, architecture, etc.). In addition, the whole frames of\nthe video streams must be converted into cropped images of people using\npedestrian detection models, which behave differently from the human annotators\nwho created the dataset used for training. To better understand the extent of\nthis issue, this paper introduces a complete methodology to evaluate Re-ID\napproaches and training datasets with respect to their suitability for\nunsupervised deployment for live operations. This method is used to benchmark\nfour Re-ID approaches on three datasets, providing insight and guidelines that\ncan help to design better Re-ID pipelines in the future.",
    "descriptor": "\nComments: This paper is the extended version of our short paper accepted in VISAPP - 2023\n",
    "authors": [
      "Jose Huaman",
      "Felix O. Sumari",
      "Luigy Machaca",
      "Esteban Clua",
      "Joris Guerin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09981"
  },
  {
    "id": "arXiv:2212.09982",
    "title": "Joint Speech Transcription and Translation: Pseudo-Labeling with  Out-of-Distribution Data",
    "abstract": "Self-training has been shown to be helpful in addressing data scarcity for\nmany domains, including vision, speech, and language. Specifically,\nself-training, or pseudo-labeling, labels unsupervised data and adds that to\nthe training pool. In this work, we investigate and use pseudo-labeling for a\nrecently proposed novel setup: joint transcription and translation of speech,\nwhich suffers from an absence of sufficient data resources. We show that under\nsuch data-deficient circumstances, the unlabeled data can significantly vary in\ndomain from the supervised data, which results in pseudo-label quality\ndegradation. We investigate two categories of remedies that require no\nadditional supervision and target the domain mismatch: pseudo-label filtering\nand data augmentation. We show that pseudo-label analysis and processing as\nsuch results in additional gains on top of the vanilla pseudo-labeling setup\nresulting in total improvements of up to 0.6% absolute WER and 2.2 BLEU points.",
    "descriptor": "",
    "authors": [
      "Mozhdeh Gheini",
      "Tatiana Likhomanenko",
      "Matthias Sperber",
      "Hendra Setiawan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.09982"
  },
  {
    "id": "arXiv:2212.09983",
    "title": "Texture Representation via Analysis and Synthesis with Generative  Adversarial Networks",
    "abstract": "We investigate data-driven texture modeling via analysis and synthesis with\ngenerative adversarial networks. For network training and testing, we have\ncompiled a diverse set of spatially homogeneous textures, ranging from\nstochastic to regular. We adopt StyleGAN3 for synthesis and demonstrate that it\nproduces diverse textures beyond those represented in the training data. For\ntexture analysis, we propose GAN inversion using a novel latent domain\nreconstruction consistency criterion for synthesized textures, and iterative\nrefinement with Gramian loss for real textures. We propose perceptual\nprocedures for evaluating network capabilities, exploring the global and local\nbehavior of latent space trajectories, and comparing with existing texture\nanalysis-synthesis techniques.",
    "descriptor": "",
    "authors": [
      "Jue Lin",
      "Gaurav Sharma",
      "Thrasyvoulos N. Pappas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.09983"
  },
  {
    "id": "arXiv:2212.09987",
    "title": "Uncertainty Error Modeling for Non-Linear State Estimation With  Unsynchronized SCADA and $\u03bc$PMU Measurements",
    "abstract": "Distribution systems of the future smart grid require enhancements to the\nreliability of distribution system state estimation (DSSE) in the face of low\nmeasurement redundancy, unsynchronized measurements, and dynamic load profiles.\nMicro phasor measurement units ($\\mu$PMUs) facilitate co-synchronized\nmeasurements with high granularity, albeit at an often prohibitively expensive\ninstallation cost. Supervisory control and data acquisition (SCADA)\nmeasurements can supplement $\\mu$PMU data, although they are received at a\nslower sampling rate. Further complicating matters is the uncertainty\nassociated with load dynamics and unsynchronized measurements-not only are the\nSCADA and $\\mu$PMU measurements not synchronized with each other, but the SCADA\nmeasurements themselves are received at different time intervals with respect\nto one another. This paper proposes a non-linear state estimation framework\nwhich models dynamic load uncertainty error by updating the variances of the\nunsynchronized measurements, leading to a time-varying system of weights in the\nweighted least squares state estimator. Case studies are performed on the\n33-Bus Distribution System in MATPOWER, using Ornstein-Uhlenbeck stochastic\nprocesses to simulate dynamic load conditions.",
    "descriptor": "\nComments: This work has been submitted to the 2023 IEEE Power & Energy Society General Meeting for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. 5 pages, 4 figures\n",
    "authors": [
      "Austin Cooper",
      "Arturo Bretas",
      "Sean Meyn",
      "Newton G. Bretas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.09987"
  },
  {
    "id": "arXiv:2212.09988",
    "title": "Multi-Reference Image Super-Resolution: A Posterior Fusion Approach",
    "abstract": "Reference-based Super-resolution (RefSR) approaches have recently been\nproposed to overcome the ill-posed problem of image super-resolution by\nproviding additional information from a high-resolution image. Multi-reference\nsuper-resolution extends this approach by allowing more information to be\nincorporated. This paper proposes a 2-step-weighting posterior fusion approach\nto combine the outputs of RefSR models with multiple references. Extensive\nexperiments on the CUFED5 dataset demonstrate that the proposed methods can be\napplied to various state-of-the-art RefSR models to get a consistent\nimprovement in image quality.",
    "descriptor": "",
    "authors": [
      "Ke Zhao",
      "Haining Tan",
      "Tsz Fung Yau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.09988"
  },
  {
    "id": "arXiv:2212.09989",
    "title": "High Impedance Fault Detection Through Quasi-Static State Estimation: A  Parameter Error Modeling Approach",
    "abstract": "This paper presents a model for detecting high-impedance faults (HIFs) using\nparameter error modeling and a two-step per-phase weighted least squares state\nestimation (SE) process. The proposed scheme leverages the use of phasor\nmeasurement units and synthetic measurements to identify per-phase power flow\nand injection measurements which indicate a parameter error through $\\chi^2$\nHypothesis Testing applied to the composed measurement error (CME). Although\ncurrent and voltage waveforms are commonly analyzed for high-impedance fault\ndetection, wide-area power flow and injection measurements, which are already\ninherent to the SE process, also show promise for real-world high-impedance\nfault detection applications. The error distributions after detection share the\nmeasurement function error spread observed in proven parameter error\ndiagnostics and can be applied to HIF identification. Further, this error\nspread related to the HIF will be clearly discerned from measurement error.\nCase studies are performed on the 33-Bus Distribution System in Simulink.",
    "descriptor": "\nComments: Accepted for publication in 2023 IEEE ISGT North America. 5 pages, 6 figures\n",
    "authors": [
      "Austin Cooper",
      "Arturo Bretas",
      "Sean Meyn",
      "Newton G. Bretas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.09989"
  },
  {
    "id": "arXiv:2212.09990",
    "title": "Distributed Software-Defined Network Architecture for Smart Grid  Resilience to Denial-of-Service Attacks",
    "abstract": "An important challenge for smart grid security is designing a secure and\nrobust smart grid communications architecture to protect against cyber-threats,\nsuch as Denial-of-Service (DoS) attacks, that can adversely impact the\noperation of the power grid. Researchers have proposed using Software Defined\nNetwork frameworks to enhance cybersecurity of the smart grid, but there is a\nlack of benchmarking and comparative analyses among the many techniques. In\nthis work, a distributed three-controller software-defined networking (D3-SDN)\narchitecture, benchmarking and comparative analysis with other techniques is\npresented. The selected distributed flat SDN architecture divides the network\nhorizontally into multiple areas or clusters, where each cluster is handled by\na single Open Network Operating System (ONOS) controller. A case study using\nthe IEEE 118-bus system is provided to compare the performance of the presented\nONOS-managed D3-SDN, against the POX controller. In addition, the proposed\narchitecture outperforms a single SDN controller framework by a tenfold\nincrease in throughput; a reduction in latency of $>20\\%$; and an increase in\nthroughput of approximately $11\\%$ during the DoS attack scenarios.",
    "descriptor": "\nComments: This work has been submitted to the 2023 IEEE Power & Energy Society General Meeting for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. 5 pages, 4 figures\n",
    "authors": [
      "Dennis Agnew",
      "Sharon Boamah",
      "Reynold Mathieu",
      "Austin Cooper",
      "Janise McNair",
      "Arturo Bretas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.09990"
  },
  {
    "id": "arXiv:2212.09991",
    "title": "Dynamic Molecular Graph-based Implementation for Biophysical Properties  Prediction",
    "abstract": "Neural Networks (GNNs) have revolutionized the molecular discovery to\nunderstand patterns and identify unknown features that can aid in predicting\nbiophysical properties and protein-ligand interactions. However, current models\ntypically rely on 2-dimensional molecular representations as input, and while\nutilization of 2\\3- dimensional structural data has gained deserved traction in\nrecent years as many of these models are still limited to static graph\nrepresentations. We propose a novel approach based on the transformer model\nutilizing GNNs for characterizing dynamic features of protein-ligand\ninteractions. Our message passing transformer pre-trains on a set of molecular\ndynamic data based off of physics-based simulations to learn coordinate\nconstruction and make binding probability and affinity predictions as a\ndownstream task. Through extensive testing we compare our results with the\nexisting models, our MDA-PLI model was able to outperform the molecular\ninteraction prediction models with an RMSE of 1.2958. The geometric encodings\nenabled by our transformer architecture and the addition of time series data\nadd a new dimensionality to this form of research.",
    "descriptor": "\nComments: 4 pages and appendix, 3 figures, Ellis Critical assessment of molecular machine learning workshop [ML4Molecules] 2022 poster session\n",
    "authors": [
      "Carter Knutson",
      "Gihan Panapitiya",
      "Rohith Varikoti",
      "Neeraj Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2212.09991"
  },
  {
    "id": "arXiv:2212.09993",
    "title": "Are Deep Neural Networks SMARTer than Second Graders?",
    "abstract": "Recent times have witnessed an increasing number of applications of deep\nneural networks towards solving tasks that require superior cognitive\nabilities, e.g., playing Go, generating art, question answering (such as\nChatGPT), etc. Such a dramatic progress raises the question: how generalizable\nare neural networks in solving problems that demand broad skills? To answer\nthis question, we propose SMART: a Simple Multimodal Algorithmic Reasoning Task\nand the associated SMART-101 dataset, for evaluating the abstraction,\ndeduction, and generalization abilities of neural networks in solving\nvisuo-linguistic puzzles designed specifically for children in the 6-8 age\ngroup. Our dataset consists of 101 unique puzzles; each puzzle comprises a\npicture and a question, and their solution needs a mix of several elementary\nskills, including arithmetic, algebra, and spatial reasoning, among others. To\nscale our dataset towards training deep neural networks, we programmatically\ngenerate entirely new instances for each puzzle while retaining their solution\nalgorithm. To benchmark the performance on the SMART-101 dataset, we propose a\nvision and language meta-learning model using varied state-of-the-art backbone\nneural networks. Our experiments reveal that while powerful deep models offer\nreasonable performances on puzzles that they are trained on, they are not\nbetter than random accuracy when analyzed for generalization. We also evaluate\nthe recent ChatGPT large language model on a subset of our dataset and find\nthat while ChatGPT produces convincing reasoning abilities, the answers are\noften incorrect.",
    "descriptor": "",
    "authors": [
      "Anoop Cherian",
      "Kuan-Chuan Peng",
      "Suhas Lohit",
      "Kevin Smith",
      "Joshua B. Tenenbaum"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09993"
  },
  {
    "id": "arXiv:2212.09994",
    "title": "Towards Robustness of Text-to-SQL Models Against Natural and Realistic  Adversarial Table Perturbation",
    "abstract": "The robustness of Text-to-SQL parsers against adversarial perturbations plays\na crucial role in delivering highly reliable applications. Previous studies\nalong this line primarily focused on perturbations in the natural language\nquestion side, neglecting the variability of tables. Motivated by this, we\npropose the Adversarial Table Perturbation (ATP) as a new attacking paradigm to\nmeasure the robustness of Text-to-SQL models. Following this proposition, we\ncurate ADVETA, the first robustness evaluation benchmark featuring natural and\nrealistic ATPs. All tested state-of-the-art models experience dramatic\nperformance drops on ADVETA, revealing models' vulnerability in real-world\npractices. To defend against ATP, we build a systematic adversarial training\nexample generation framework tailored for better contextualization of tabular\ndata. Experiments show that our approach not only brings the best robustness\nimprovement against table-side perturbations but also substantially empowers\nmodels against NL-side perturbations. We release our benchmark and code at:\nhttps://github.com/microsoft/ContextualSP.",
    "descriptor": "\nComments: Accepted by ACL 2022 (Oral)\n",
    "authors": [
      "Xinyu Pi",
      "Bing Wang",
      "Yan Gao",
      "Jiaqi Guo",
      "Zhoujun Li",
      "Jian-Guang Lou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09994"
  },
  {
    "id": "arXiv:2212.10001",
    "title": "Towards Understanding Chain-of-Thought Prompting: An Empirical Study of  What Matters",
    "abstract": "Chain-of-Thought (CoT) prompting can dramatically improve the multi-step\nreasoning abilities of large language models (LLMs). CoT explicitly encourages\nthe LLM to generate intermediate rationales for solving a problem, by providing\na series of reasoning steps in the demonstrations. Despite its success, there\nis still little understanding of what makes CoT prompting effective and which\naspects of the demonstrated reasoning steps contribute to its performance. In\nthis paper, we show that CoT reasoning is possible even with invalid\ndemonstrations - prompting with invalid reasoning steps can achieve over 80-90%\nof the performance obtained using CoT under various metrics, while still\ngenerating coherent lines of reasoning during inference. Further experiments\nshow that other aspects of the rationales, such as being relevant to the query\nand correctly ordering the reasoning steps, are much more important for\neffective CoT reasoning. Overall, these findings both deepen our understanding\nof CoT prompting, and open up new questions regarding LLMs' capability to learn\nto reason in context.",
    "descriptor": "\nComments: Our code and model input/output will be available at this https URL\n",
    "authors": [
      "Boshi Wang",
      "Sewon Min",
      "Xiang Deng",
      "Jiaming Shen",
      "You Wu",
      "Luke Zettlemoyer",
      "Huan Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10001"
  },
  {
    "id": "arXiv:2212.10002",
    "title": "Defending Against Poisoning Attacks in Open-Domain Question Answering",
    "abstract": "Recent work in open-domain question answering (ODQA) has shown that\nadversarial poisoning of the input contexts can cause large drops in accuracy\nfor production systems. However, little to no work has proposed methods to\ndefend against these attacks. To do so, we introduce a new method that uses\nquery augmentation to search for a diverse set of retrieved passages that could\nanswer the original question. We integrate these new passages into the model\nthrough the design of a novel confidence method, comparing the predicted answer\nto its appearance in the retrieved contexts (what we call Confidence from\nAnswer Redundancy, e.g. CAR). Together these methods allow for a simple but\neffective way to defend against poisoning attacks and provide gains of 5-20%\nexact match across varying levels of data poisoning.",
    "descriptor": "",
    "authors": [
      "Orion Weller",
      "Aleem Khan",
      "Nathaniel Weir",
      "Dawn Lawrie",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.10002"
  },
  {
    "id": "arXiv:2212.10003",
    "title": "(QA)$^2$: Question Answering with Questionable Assumptions",
    "abstract": "Naturally-occurring information-seeking questions often contain questionable\nassumptions -- assumptions that are false or unverifiable. Questions containing\nquestionable assumptions are challenging because they require a distinct answer\nstrategy that deviates from typical answers to information-seeking questions.\nFor instance, the question \"When did Marie Curie discover Uranium?\" cannot be\nanswered as a typical when question without addressing the false assumption\n\"Marie Curie discovered Uranium\". In this work, we propose (QA)$^2$ (Question\nAnswering with Questionable Assumptions), an open-domain evaluation dataset\nconsisting of naturally-occurring search engine queries that may or may not\ncontain questionable assumptions. To be successful on (QA)$^2$, systems must be\nable to detect questionable assumptions and also be able to produce adequate\nresponses for both typical information-seeking questions and ones with\nquestionable assumptions. We find that current models do struggle with handling\nquestionable assumptions -- the best performing model achieves 59% human rater\nacceptability on abstractive QA with (QA)$^2$ questions, leaving substantial\nheadroom for progress.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Najoung Kim",
      "Phu Mon Htut",
      "Samuel R. Bowman",
      "Jackson Petty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10003"
  },
  {
    "id": "arXiv:2212.10005",
    "title": "Calibrating Deep Neural Networks using Explicit Regularisation and  Dynamic Data Pruning",
    "abstract": "Deep neural networks (DNN) are prone to miscalibrated predictions, often\nexhibiting a mismatch between the predicted output and the associated\nconfidence scores. Contemporary model calibration techniques mitigate the\nproblem of overconfident predictions by pushing down the confidence of the\nwinning class while increasing the confidence of the remaining classes across\nall test samples. However, from a deployment perspective, an ideal model is\ndesired to (i) generate well-calibrated predictions for high-confidence samples\nwith predicted probability say >0.95, and (ii) generate a higher proportion of\nlegitimate high-confidence samples. To this end, we propose a novel\nregularization technique that can be used with classification losses, leading\nto state-of-the-art calibrated predictions at test time; From a deployment\nstandpoint in safety-critical applications, only high-confidence samples from a\nwell-calibrated model are of interest, as the remaining samples have to undergo\nmanual inspection. Predictive confidence reduction of these potentially\n``high-confidence samples'' is a downside of existing calibration approaches.\nWe mitigate this by proposing a dynamic train-time data pruning strategy that\nprunes low-confidence samples every few epochs, providing an increase in\n\"confident yet calibrated samples\". We demonstrate state-of-the-art calibration\nperformance across image classification benchmarks, reducing training time\nwithout much compromise in accuracy. We provide insights into why our dynamic\npruning strategy that prunes low-confidence training samples leads to an\nincrease in high-confidence samples at test time.",
    "descriptor": "\nComments: The paper is accepted at Winter Conference on applications of Computer Vision (IEEE WACV) in algorithms tracks. 8 pages Main paper; 3 pages supplementary material\n",
    "authors": [
      "Ramya Hebbalaguppe",
      "Rishabh Patra",
      "Tirtharaj Dash",
      "Gautam Shroff",
      "Lovekesh Vig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10005"
  },
  {
    "id": "arXiv:2212.10006",
    "title": "Multi-head Uncertainty Inference for Adversarial Attack Detection",
    "abstract": "Deep neural networks (DNNs) are sensitive and susceptible to tiny\nperturbation by adversarial attacks which causes erroneous predictions. Various\nmethods, including adversarial defense and uncertainty inference (UI), have\nbeen developed in recent years to overcome the adversarial attacks. In this\npaper, we propose a multi-head uncertainty inference (MH-UI) framework for\ndetecting adversarial attack examples. We adopt a multi-head architecture with\nmultiple prediction heads (i.e., classifiers) to obtain predictions from\ndifferent depths in the DNNs and introduce shallow information for the UI.\nUsing independent heads at different depths, the normalized predictions are\nassumed to follow the same Dirichlet distribution, and we estimate distribution\nparameter of it by moment matching. Cognitive uncertainty brought by the\nadversarial attacks will be reflected and amplified on the distribution.\nExperimental results show that the proposed MH-UI framework can outperform all\nthe referred UI methods in the adversarial attack detection task with different\nsettings.",
    "descriptor": "",
    "authors": [
      "Yuqi Yang",
      "Songyun Yang",
      "Jiyang Xie. Zhongwei Si",
      "Kai Guo",
      "Ke Zhang",
      "Kongming Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.10006"
  },
  {
    "id": "arXiv:2212.10007",
    "title": "CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file  Context",
    "abstract": "While pre-trained language models (LM) for code have achieved great success\nin code completion, they generate code conditioned only on the contents within\nthe file, i.e., in-file context, but ignore the rich semantics in other files\nwithin the same project, i.e., cross-file context, a critical source of\ninformation that is especially useful in modern modular software development.\nSuch overlooking constrains code language models' capacity in code completion,\nleading to unexpected behaviors such as generating hallucinated class member\nfunctions or function calls with unexpected arguments. In this work, we develop\na cross-file context finder tool, CCFINDER, that effectively locates and\nretrieves the most relevant cross-file context. We propose CoCoMIC, a framework\nthat incorporates cross-file context to learn the in-file and cross-file\ncontext jointly on top of pretrained code LMs. CoCoMIC successfully improves\nthe existing code LM with a 19.30% relative increase in exact match and a\n15.41% relative increase in identifier matching for code completion when the\ncross-file context is provided.",
    "descriptor": "",
    "authors": [
      "Yangruibo Ding",
      "Zijian Wang",
      "Wasi Uddin Ahmad",
      "Murali Krishna Ramanathan",
      "Ramesh Nallapati",
      "Parminder Bhatia",
      "Dan Roth",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.10007"
  },
  {
    "id": "arXiv:2212.10008",
    "title": "Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog",
    "abstract": "Many efforts have been made to construct dialog systems for different types\nof conversations, such as task-oriented dialog (TOD) and open-domain dialog\n(ODD). To better mimic human-level conversations that usually fuse various\ndialog modes, it is essential to build a system that can effectively handle\nboth TOD and ODD and access different knowledge sources. To address the lack of\navailable data for the fused task, we propose a framework for automatically\ngenerating dialogues that combine knowledge-grounded ODDs and TODs in various\nsettings. Additionally, we introduce a unified model PivotBot that is capable\nof appropriately adopting TOD and ODD modes and accessing different knowledge\nsources in order to effectively tackle the fused task. Evaluation results\ndemonstrate the superior ability of the proposed model to switch seamlessly\nbetween TOD and ODD tasks.",
    "descriptor": "",
    "authors": [
      "Miaoran Li",
      "Baolin Peng",
      "Michel Galley",
      "Jianfeng Gao",
      "Zhu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10008"
  },
  {
    "id": "arXiv:2212.10010",
    "title": "Identifying latent distances with Finslerian geometry",
    "abstract": "Riemannian geometry provides powerful tools to explore the latent space of\ngenerative models while preserving the inherent structure of the data manifold.\nLengths, energies and volume measures can be derived from a pullback metric,\ndefined through the immersion that maps the latent space to the data space.\nWith this in mind, most generative models are stochastic, and so is the\npullback metric. Manipulating stochastic objects is strenuous in practice. In\norder to perform operations such as interpolations, or measuring the distance\nbetween data points, we need a deterministic approximation of the pullback\nmetric. In this work, we are defining a new metric as the expected length\nderived from the stochastic pullback metric. We show this metric is Finslerian,\nand we compare it with the expected pullback metric. In high dimensions, we\nshow that the metrics converge to each other at a rate of\n$\\mathcal{O}\\left(\\frac{1}{D}\\right)$.",
    "descriptor": "\nComments: 32 pages, 12 figures, Poster presentation at NeurIPS 2022 workshop: \"Symmetry and Geometry in Neural Representations\"\n",
    "authors": [
      "Alison Pouplin",
      "David Eklund",
      "Carl Henrik Ek",
      "S\u00f8ren Hauberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10010"
  },
  {
    "id": "arXiv:2212.10011",
    "title": "PLUE: Language Understanding Evaluation Benchmark for Privacy Policies  in English",
    "abstract": "Privacy policies provide individuals with information about their rights and\nhow their personal information is handled. Natural language understanding (NLU)\ntechnologies can support individuals and practitioners to understand better\nprivacy practices described in lengthy and complex documents. However, existing\nefforts that use NLU technologies are limited by processing the language in a\nway exclusive to a single task focusing on certain privacy practices. To this\nend, we introduce the Privacy Policy Language Understanding Evaluation (PLUE)\nbenchmark, a multi-task benchmark for evaluating the privacy policy language\nunderstanding across various tasks. We also collect a large corpus of privacy\npolicies to enable privacy policy domain-specific language model pre-training.\nWe demonstrate that domain-specific pre-training offers performance\nimprovements across all tasks. We release the benchmark to encourage future\nresearch in this domain.",
    "descriptor": "",
    "authors": [
      "Jianfeng Chi",
      "Wasi Uddin Ahmad",
      "Yuan Tian",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10011"
  },
  {
    "id": "arXiv:2212.10012",
    "title": "Language Modeling with Latent Situations",
    "abstract": "Language models (LMs) often generate incoherent outputs: they refer to events\nand entity states that are incompatible with the state of the world described\nin their inputs. We introduce SituationSupervision, a family of approaches for\nimproving coherence in LMs by training them to construct and condition on\nexplicit representations of entities and their states. SituationSupervision has\ntwo components: an auxiliary situation modeling task that trains models to\npredict state representations in context, and a latent state inference\nprocedure that imputes these states from partially annotated training data.\nSituationSupervision can be applied to both fine-tuning (by supervising LMs to\nencode state variables in their hidden representations) and prompting (by\ninducing LMs to interleave textual descriptions of entity states with output\ntext). In both cases, SituationSupervision requires only a small number of\nstate annotations to produce major coherence improvements (between 4-11%),\nshowing that standard LMs can be sample-efficiently trained to model not just\nlanguage but the situations it describes.",
    "descriptor": "\nComments: 13 pages, 3 figures, 7 tables\n",
    "authors": [
      "Belinda Z. Li",
      "Maxwell Nye",
      "Jacob Andreas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10012"
  },
  {
    "id": "arXiv:2212.10013",
    "title": "DocAsRef: A Pilot Empirical Study on Repurposing Reference-Based Summary  Quality Metrics Reference-Freely",
    "abstract": "Summary quality assessment metrics have two categories: reference-based and\nreference-free. Reference-based metrics are theoretically more accurate but are\nlimited by the availability and quality of the human-written references, which\nare both difficulty to ensure. This inspires the development of reference-free\nmetrics, which are independent from human-written references, in the past few\nyears. However, existing reference-free metrics cannot be both zero-shot and\naccurate. In this paper, we propose a zero-shot but accurate reference-free\napproach in a sneaky way: feeding documents, based upon which summaries\ngenerated, as references into reference-based metrics. Experimental results\nshow that this zero-shot approach can give us the best-performing\nreference-free metrics on nearly all aspects on several recently-released\ndatasets, even beating reference-free metrics specifically trained for this\ntask sometimes. We further investigate what reference-based metrics can benefit\nfrom such repurposing and whether our additional tweaks help.",
    "descriptor": "\nComments: a pilot study\n",
    "authors": [
      "Forrest Sheng Bao",
      "Ruixuan Tu",
      "Ge Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10013"
  },
  {
    "id": "arXiv:2212.10015",
    "title": "Benchmarking Spatial Relationships in Text-to-Image Generation",
    "abstract": "Spatial understanding is a fundamental aspect of computer vision and integral\nfor human-level reasoning about images, making it an important component for\ngrounded language understanding. While recent large-scale text-to-image\nsynthesis (T2I) models have shown unprecedented improvements in photorealism,\nit is unclear whether they have reliable spatial understanding capabilities. We\ninvestigate the ability of T2I models to generate correct spatial relationships\namong objects and present VISOR, an evaluation metric that captures how\naccurately the spatial relationship described in text is generated in the\nimage. To benchmark existing models, we introduce a large-scale challenge\ndataset SR2D that contains sentences describing two objects and the spatial\nrelationship between them. We construct and harness an automated evaluation\npipeline that employs computer vision to recognize objects and their spatial\nrelationships, and we employ it in a large-scale evaluation of T2I models. Our\nexperiments reveal a surprising finding that, although recent state-of-the-art\nT2I models exhibit high image quality, they are severely limited in their\nability to generate multiple objects or the specified spatial relations such as\nleft/right/above/below. Our analyses demonstrate several biases and artifacts\nof T2I models such as the difficulty with generating multiple objects, a bias\ntowards generating the first object mentioned, spatially inconsistent outputs\nfor equivalent relationships, and a correlation between object co-occurrence\nand spatial understanding capabilities. We conduct a human study that shows the\nalignment between VISOR and human judgment about spatial understanding. We\noffer the SR2D dataset and the VISOR metric to the community in support of T2I\nspatial reasoning research.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Tejas Gokhale",
      "Hamid Palangi",
      "Besmira Nushi",
      "Vibhav Vineet",
      "Eric Horvitz",
      "Ece Kamar",
      "Chitta Baral",
      "Yezhou Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10015"
  },
  {
    "id": "arXiv:2212.10017",
    "title": "Is Self-Attention Powerful to Learn Code Syntax and Semantics?",
    "abstract": "Pre-trained language models for programming languages have shown a powerful\nability on processing many Software Engineering (SE) tasks, e.g., program\nsynthesis, code completion, and code search. However, it remains to be seen\nwhat is behind their success. Recent studies have examined how pre-trained\nmodels can effectively learn syntax information based on Abstract Syntax Trees.\nIn this paper, we figure out what role the self-attention mechanism plays in\nunderstanding code syntax and semantics based on AST and static analysis. We\nfocus on a well-known representative code model, CodeBERT, and study how it can\nlearn code syntax and semantics by the self-attention mechanism and Masked\nLanguage Modelling (MLM) at the token level.\nWe propose a group of probing tasks to analyze CodeBERT. Based on AST and\nstatic analysis, we establish the relationships among the code tokens. First,\nOur results show that CodeBERT can acquire syntax and semantics knowledge\nthrough self-attention and MLM. Second, we demonstrate that the self-attention\nmechanism pays more attention to dependence-relationship tokens than to other\ntokens. Different attention heads play different roles in learning code\nsemantics; we show that some of them are weak at encoding code semantics.\nDifferent layers have different competencies to represent different code\nproperties. Deep CodeBERT layers can encode the semantic information that\nrequires some complex inference in the code context. More importantly, we show\nthat our analysis is helpful and leverage our conclusions to improve CodeBERT.\nWe show an alternative approach for pre-training models, which makes fully use\nof the current pre-training strategy, i.e, MLM, to learn code syntax and\nsemantics, instead of combining features from different code data formats,\ne.g., data-flow, running-time states, and program outputs.",
    "descriptor": "",
    "authors": [
      "Wei Ma",
      "Mengjie Zhao",
      "Xiaofei Xie",
      "Qiang Hu",
      "Shangqing Liu",
      "Jie Zhang",
      "Wenhan Wang",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10017"
  },
  {
    "id": "arXiv:2212.10018",
    "title": "DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization",
    "abstract": "Dialogue summarization has recently garnered significant attention due to its\nwide range of applications. However, existing methods for summarizing dialogues\nare suboptimal because they do not take into account the inherent structure of\ndialogue and rely heavily on labeled data, which can lead to poor performance\nin new domains. In this work, we propose DIONYSUS (dynamic input optimization\nin pre-training for dialogue summarization), a pre-trained encoder-decoder\nmodel for summarizing dialogues in any new domain. To pre-train DIONYSUS, we\ncreate two pseudo summaries for each dialogue example: one is produced by a\nfine-tuned summarization model, and the other is a collection of dialogue turns\nthat convey important information. We then choose one of these pseudo summaries\nbased on the difference in information distribution across different types of\ndialogues. This selected pseudo summary serves as the objective for\npre-training DIONYSUS using a self-supervised approach on a large dialogue\ncorpus. Our experiments show that DIONYSUS outperforms existing methods on six\ndatasets, as demonstrated by its ROUGE scores in zero-shot and few-shot\nsettings.",
    "descriptor": "",
    "authors": [
      "Yu Li",
      "Baolin Peng",
      "Pengcheng He",
      "Michel Galley",
      "Zhou Yu",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10018"
  },
  {
    "id": "arXiv:2212.10019",
    "title": "When Do Decompositions Help for Machine Reading?",
    "abstract": "Answering complex questions often requires multi-step reasoning in order to\nobtain the final answer. Most research into decompositions of complex questions\ninvolves open-domain systems, which have shown success in using these\ndecompositions for improved retrieval. In the machine reading setting, however,\nwork to understand when decompositions are helpful is understudied. We conduct\nexperiments on decompositions in machine reading to unify recent work in this\nspace, using a range of models and datasets. We find that decompositions can be\nhelpful in the few-shot case, giving several points of improvement in exact\nmatch scores. However, we also show that when models are given access to\ndatasets with around a few hundred or more examples, decompositions are not\nhelpful (and can actually be detrimental). Thus, our analysis implies that\nmodels can learn decompositions implicitly even with limited data.",
    "descriptor": "",
    "authors": [
      "Kangda Wei",
      "Dawn Lawrie",
      "Benjamin Van Durme",
      "Yunmo Chen",
      "Orion Weller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10019"
  },
  {
    "id": "arXiv:2212.10020",
    "title": "On the Blind Spots of Model-Based Evaluation Metrics for Text Generation",
    "abstract": "In this work, we explore a useful but often neglected methodology for\nrobustness analysis of text generation evaluation metrics: stress tests with\nsynthetic data. Basically, we design and synthesize a wide range of potential\nerrors and check whether they result in a commensurate drop in the metric\nscores. We examine a range of recently proposed evaluation metrics based on\npretrained language models, for the tasks of open-ended generation,\ntranslation, and summarization. Our experiments reveal interesting\ninsensitivities, biases, or even loopholes in existing metrics. For example, we\nfind that BERTScore ignores truncation errors in summarization, and MAUVE\n(built on top of GPT-2) is insensitive to errors at the beginning of\ngenerations. Further, we investigate the reasons behind these blind spots and\nsuggest practical workarounds for a more reliable evaluation of text\ngeneration.",
    "descriptor": "",
    "authors": [
      "Tianxing He",
      "Jingyu Zhang",
      "Tianle Wang",
      "Sachin Kumar",
      "Kyunghyun Cho",
      "James Glass",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10020"
  },
  {
    "id": "arXiv:2212.10025",
    "title": "When Federated Learning Meets Pre-trained Language Models'  Parameter-Efficient Tuning Methods",
    "abstract": "With increasing privacy concerns on data, recent studies have made\nsignificant progress using federated learning (FL) on privacy-sensitive natural\nlanguage processing (NLP) tasks. Much literature suggests fully fine-tuning\npre-trained language models (PLMs) in the FL paradigm can mitigate the data\nheterogeneity problem and close the performance gap with centralized training.\nHowever, large PLMs bring the curse of prohibitive communication overhead and\nlocal model adaptation costs for the FL system. To this end, we introduce\nvarious parameter-efficient tuning (PETuning) methods into federated learning.\nSpecifically, we provide a holistic empirical study of representative PLMs\ntuning methods in FL. The experimental results cover the analysis of data\nheterogeneity levels, data scales, and different FL scenarios. Overall\ncommunication overhead can be significantly reduced by locally tuning and\nglobally aggregating lightweight model parameters while maintaining acceptable\nperformance in various FL settings. To facilitate the research of PETuning in\nFL, we also develop a federated tuning framework FedPETuning, which allows\npractitioners to exploit different PETuning methods under the FL training\nparadigm conveniently. The source code is available at\n\\url{https://github.com/iezhuozhuo/FedETuning/tree/deltaTuning}.",
    "descriptor": "",
    "authors": [
      "Zhuo Zhang",
      "Yuanhang Yang",
      "Yong Dai",
      "Lizhen Qu",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10025"
  },
  {
    "id": "arXiv:2212.10029",
    "title": "Do language models have coherent mental models of everyday things?",
    "abstract": "When people think of everyday things like an \"egg,\" they typically have a\nmental image associated with it. This commonsense knowledge helps us understand\nhow these everyday things work and how to interact with them. For example, when\nsomeone tries to make a fried egg, they know that it has a shell and that it\ncan be cracked open to reveal the egg white and yolk inside. However, if a\nsystem does not have a coherent picture of such everyday things, thinking that\nthe egg yolk surrounds the shell, then it might have to resort to ridiculous\napproaches such as trying to scrape the egg yolk off the shell into the pan. Do\nlanguage models have a coherent picture of such everyday things? To investigate\nthis, we propose a benchmark dataset consisting of 100 everyday things, their\nparts, and the relationships between these parts. We observe that\nstate-of-the-art pre-trained language models (LMs) like GPT-3 and Macaw have\nfragments of knowledge about these entities, but they fail to produce\nconsistent parts mental models. We propose a simple extension to these LMs\nwhere we apply a constraint satisfaction layer on top of raw predictions from\nLMs to produce more consistent and accurate parts mental models of everyday\nthings.",
    "descriptor": "",
    "authors": [
      "Yuling Gu",
      "Bhavana Dalvi Mishra",
      "Peter Clark"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10029"
  },
  {
    "id": "arXiv:2212.10030",
    "title": "InterMulti:Multi-view Multimodal Interactions with Text-dominated  Hierarchical High-order Fusion for Emotion Analysis",
    "abstract": "Humans are sophisticated at reading interlocutors' emotions from multimodal\nsignals, such as speech contents, voice tones and facial expressions. However,\nmachines might struggle to understand various emotions due to the difficulty of\neffectively decoding emotions from the complex interactions between multimodal\nsignals. In this paper, we propose a multimodal emotion analysis framework,\nInterMulti, to capture complex multimodal interactions from different views and\nidentify emotions from multimodal signals. Our proposed framework decomposes\nsignals of different modalities into three kinds of multimodal interaction\nrepresentations, including a modality-full interaction representation, a\nmodality-shared interaction representation, and three modality-specific\ninteraction representations. Additionally, to balance the contribution of\ndifferent modalities and learn a more informative latent interaction\nrepresentation, we developed a novel Text-dominated Hierarchical High-order\nFusion(THHF) module. THHF module reasonably integrates the above three kinds of\nrepresentations into a comprehensive multimodal interaction representation.\nExtensive experimental results on widely used datasets, (i.e.) MOSEI, MOSI and\nIEMOCAP, demonstrate that our method outperforms the state-of-the-art.",
    "descriptor": "\nComments: 9 pages, 3 figures. arXiv admin note: text overlap with arXiv:2212.08661\n",
    "authors": [
      "Feng Qiu",
      "Wanzeng Kong",
      "Yu Ding"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10030"
  },
  {
    "id": "arXiv:2212.10031",
    "title": "Dissipativity of nonlinear ODE model of distribution voltage profile",
    "abstract": "In this paper, we consider a power distribution system consisting of a\nstraight feeder line. A nonlinear ordinary differential equation (ODE) model is\nused to describe the voltage distribution profile over the feeder line. At\nfirst, we show the dissipativity of the subsystems corresponding to active and\nreactive powers. We also show that the dissipation rates of these subsystem\ncoincide with the distribution loss given by a square of current amplitudes.\nMoreover, the entire distribution system is decomposed into two subsystems\ncorresponding to voltage amplitude and phase. As a main result, we prove the\ndissipativity of these subsystems based on the decomposition. As a physical\ninterpretation of these results, we clarify that the phenomena related to the\ngradients of the voltage amplitude and phase are induced in a typical power\ndistribution system from the dissipation equalities. Finally, we discuss a\nreduction of distribution losses by injecting a linear combination of the\nactive and reactive powers as a control input based on the dissipation rate of\nthe subsystem corresponding to voltage amplitude.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Chiaki Kojima",
      "Yuya Muto",
      "Yoshihiko Susuki"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.10031"
  },
  {
    "id": "arXiv:2212.10032",
    "title": "Real-time Health Monitoring of Heat Exchangers using Hypernetworks and  PINNs",
    "abstract": "We demonstrate a Physics-informed Neural Network (PINN) based model for\nreal-time health monitoring of a heat exchanger, that plays a critical role in\nimproving energy efficiency of thermal power plants. A hypernetwork based\napproach is used to enable the domain-decomposed PINN learn the thermal\nbehavior of the heat exchanger in response to dynamic boundary conditions,\neliminating the need to re-train. As a result, we achieve orders of magnitude\nreduction in inference time in comparison to existing PINNs, while maintaining\nthe accuracy on par with the physics-based simulations. This makes the approach\nvery attractive for predictive maintenance of the heat exchanger in digital\ntwin environments.",
    "descriptor": "\nComments: Neural Information Processing Systems 2022: The Machine Learning and the Physical Sciences workshop\n",
    "authors": [
      "Ritam Majumdar",
      "Vishal Jadhav",
      "Anirudh Deodhar",
      "Shirish Karande",
      "Lovekesh Vig",
      "Venkataramana Runkana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2212.10032"
  },
  {
    "id": "arXiv:2212.10035",
    "title": "Efficient Liquidity Providing via Margin Liquidity",
    "abstract": "The limit order book mechanism has been the core trading mechanism of the\nmodern financial market. In the cryptocurrency market, centralized exchanges\nalso adopt this limit order book mechanism and a centralized matching engine\ndynamically connects the traders to the orders of market makers. Recently,\ndecentralized exchanges have been introduced and received considerable\nattention in the cryptocurrency community. A decentralized exchange typically\nadopts an automated market maker, which algorithmically arbitrates the trades\nbetween liquidity providers and traders through a pool of crypto assets.\nMeanwhile, the liquidity of the exchange is the most important factor when\ntraders choose an exchange. However, the amount of liquidity provided by the\nliquidity providers in decentralized exchanges is insufficient when compared to\ncentralized exchanges. This is because the liquidity providers in decentralized\nexchanges suffer from the risk of divergence loss inherent to the automated\nmarket making system. To this end, we introduce a new concept called margin\nliquidity and leverage this concept to propose a highly profitable margin\nliquidity-providing position. Then, we extend this margin liquidity-providing\nposition to a virtual margin liquidity-providing position to alleviate the risk\nof divergence loss for the liquidity providers and encourage them to provide\nmore liquidity to the pool. Furthermore, we introduce a representative strategy\nfor the margin liquidity-providing position and backtest the strategy with\nhistorical data from the BTC/ETH market. Our strategy outperforms a simple\nholding baseline. We also show that our proposed margin liquidity is 8K times\nmore capital efficient than the concentrated liquidity proposed in Uniswap V3.",
    "descriptor": "\nComments: Under review on ICBC23\n",
    "authors": [
      "Yeonwoo Jeong",
      "Chanyoung Jeoung",
      "Hosan Jeong",
      "SangYoon Han",
      "Juntae Kim"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.10035"
  },
  {
    "id": "arXiv:2212.10036",
    "title": "Multi-coil MRI by analytic continuation",
    "abstract": "We present novel reconstruction and stability analysis methodologies for\ntwo-dimensional, multi-coil MRI, based on analytic continuation ideas. We show\nthat the 2-D, limited-data MRI inverse problem, whereby the missing parts of\n$\\textbf{k}$-space (Fourier space) are lines parallel to either $k_1$ or $k_2$\n(i.e., the $\\textbf{k}$-space axis), can be reduced to a set of 1-D Fredholm\ntype inverse problems. The Fredholm equations are then solved to recover the\n2-D image on 1-D line profiles (``slice-by-slice\" imaging). The technique is\ntested on a range of medical in vivo images (e.g., brain, spine, cardiac), and\nphantom data. Our method is shown to offer optimal performance, in terms of\nstructural similarity, when compared against similar methods from the\nliterature, and when the $\\textbf{k}$-space data is sub-sampled at random so as\nto simulate motion corruption. In addition, we present a Singular Value\nDecomposition (SVD) and stability analysis of the Fredholm operators, and\ncompare the stability properties of different $\\textbf{k}$-space sub-sampling\nschemes (e.g., random vs uniform accelerated sampling).",
    "descriptor": "\nComments: 20 pages, 9 figures\n",
    "authors": [
      "James W. Webber"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.10036"
  },
  {
    "id": "arXiv:2212.10039",
    "title": "A Twitter BERT Approach for Offensive Language Detection in Marathi",
    "abstract": "Automated offensive language detection is essential in combating the spread\nof hate speech, particularly in social media. This paper describes our work on\nOffensive Language Identification in low resource Indic language Marathi. The\nproblem is formulated as a text classification task to identify a tweet as\noffensive or non-offensive. We evaluate different mono-lingual and\nmulti-lingual BERT models on this classification task, focusing on BERT models\npre-trained with social media datasets. We compare the performance of MuRIL,\nMahaTweetBERT, MahaTweetBERT-Hateful, and MahaBERT on the HASOC 2022 test set.\nWe also explore external data augmentation from other existing Marathi hate\nspeech corpus HASOC 2021 and L3Cube-MahaHate. The MahaTweetBERT, a BERT model,\npre-trained on Marathi tweets when fine-tuned on the combined dataset (HASOC\n2021 + HASOC 2022 + MahaHate), outperforms all models with an F1 score of 98.43\non the HASOC 2022 test set. With this, we also provide a new state-of-the-art\nresult on HASOC 2022 / MOLD v2 test set.",
    "descriptor": "",
    "authors": [
      "Tanmay Chavan",
      "Shantanu Patankar",
      "Aditya Kane",
      "Omkar Gokhale",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10039"
  },
  {
    "id": "arXiv:2212.10046",
    "title": "Causal Inference for Knowledge Graph based Recommendation",
    "abstract": "Knowledge Graph (KG), as a side-information, tends to be utilized to\nsupplement the collaborative filtering (CF) based recommendation model. By\nmapping items with the entities in KGs, prior studies mostly extract the\nknowledge information from the KGs and inject it into the representations of\nusers and items. Despite their remarkable performance, they fail to model the\nuser preference on attributes in the KG, since they ignore that (1) the\nstructure information of KG may hinder the user preference learning, and (2)\nthe user's interacted attributes will result in the bias issue on the\nsimilarity scores.\nWith the help of causality tools, we construct the causal-effect relation\nbetween the variables in KG-based recommendation and identify the reasons\ncausing the mentioned challenges. Accordingly, we develop a new framework,\ntermed Knowledge Graph-based Causal Recommendation (KGCR), which implements the\ndeconfounded user preference learning and adopts counterfactual inference to\neliminate bias in the similarity scoring. Ultimately, we evaluate our proposed\nmodel on three datasets, including Amazon-book, LastFM, and Yelp2018 datasets.\nBy conducting extensive experiments on the datasets, we demonstrate that KGCR\noutperforms several state-of-the-art baselines, such as KGNN-LS, KGAT and KGIN.",
    "descriptor": "",
    "authors": [
      "Yinwei Wei",
      "Xiang Wang",
      "Liqiang Nie",
      "Shaoyu Li",
      "Dingxian Wang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.10046"
  },
  {
    "id": "arXiv:2212.10047",
    "title": "An Augmentation Strategy for Visually Rich Documents",
    "abstract": "Many business workflows require extracting important fields from form-like\ndocuments (e.g. bank statements, bills of lading, purchase orders, etc.).\nRecent techniques for automating this task work well only when trained with\nlarge datasets. In this work we propose a novel data augmentation technique to\nimprove performance when training data is scarce, e.g. 10-250 documents. Our\ntechnique, which we call FieldSwap, works by swapping out the key phrases of a\nsource field with the key phrases of a target field to generate new synthetic\nexamples of the target field for use in training. We demonstrate that this\napproach can yield 1-7 F1 point improvements in extraction performance.",
    "descriptor": "\nComments: 9 pages, 6 figures, 3 tables\n",
    "authors": [
      "Jing Xie",
      "James B. Wendt",
      "Yichao Zhou",
      "Seth Ebner",
      "Sandeep Tata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10047"
  },
  {
    "id": "arXiv:2212.10048",
    "title": "Asynchronous Distributed Bilevel Optimization",
    "abstract": "Bilevel optimization plays an essential role in many machine learning tasks,\nranging from hyperparameter optimization to meta-learning. Existing studies on\nbilevel optimization, however, focus on either centralized or synchronous\ndistributed setting. The centralized bilevel optimization approaches require\ncollecting massive amount of data to a single server, which inevitably incur\nsignificant communication expenses and may give rise to data privacy risks.\nSynchronous distributed bilevel optimization algorithms, on the other hand,\noften face the straggler problem and will immediately stop working if a few\nworkers fail to respond. As a remedy, we propose Asynchronous Distributed\nBilevel Optimization (ADBO) algorithm. The proposed ADBO can tackle bilevel\noptimization problems with both nonconvex upper-level and lower-level objective\nfunctions, and its convergence is theoretically guaranteed. Furthermore, it is\nrevealed through theoretic analysis that the iteration complexity of ADBO to\nobtain the $\\epsilon$-stationary point is upper bounded by\n$\\mathcal{O}(\\frac{1}{{{\\epsilon ^2}}})$. Thorough empirical studies on public\ndatasets have been conducted to elucidate the effectiveness and efficiency of\nthe proposed ADBO.",
    "descriptor": "",
    "authors": [
      "Yang Jiao",
      "Kai Yang",
      "Tiancheng Wu",
      "Dongjin Song",
      "Chengtao Jian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.10048"
  },
  {
    "id": "arXiv:2212.10049",
    "title": "OBMO: One Bounding Box Multiple Objects for Monocular 3D Object  Detection",
    "abstract": "Compared to typical multi-sensor systems, monocular 3D object detection has\nattracted much attention due to its simple configuration. However, there is\nstill a significant gap between LiDAR-based and monocular-based methods. In\nthis paper, we find that the ill-posed nature of monocular imagery can lead to\ndepth ambiguity. Specifically, objects with different depths can appear with\nthe same bounding boxes and similar visual features in the 2D image.\nUnfortunately, the network cannot accurately distinguish different depths from\nsuch non-discriminative visual features, resulting in unstable depth training.\nTo facilitate depth learning, we propose a simple yet effective plug-and-play\nmodule, One Bounding Box Multiple Objects (OBMO). Concretely, we add a set of\nsuitable pseudo labels by shifting the 3D bounding box along the viewing\nfrustum. To constrain the pseudo-3D labels to be reasonable, we carefully\ndesign two label scoring strategies to represent their quality. In contrast to\nthe original hard depth labels, such soft pseudo labels with quality scores\nallow the network to learn a reasonable depth range, boosting training\nstability and thus improving final performance. Extensive experiments on KITTI\nand Waymo benchmarks show that our method significantly improves\nstate-of-the-art monocular 3D detectors by a significant margin (The\nimprovements under the moderate setting on KITTI validation set are\n$\\mathbf{1.82\\sim 10.91\\%}$ mAP in BEV and $\\mathbf{1.18\\sim 9.36\\%}$ mAP in\n3D}. Codes have been released at https://github.com/mrsempress/OBMO.",
    "descriptor": "\nComments: 9 pages, 9 figures\n",
    "authors": [
      "Chenxi Huang",
      "Tong He",
      "Haidong Ren",
      "Wenxiao Wang",
      "Binbin Lin",
      "Deng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10049"
  },
  {
    "id": "arXiv:2212.10051",
    "title": "A Framework of Customer Review Analysis Using the Aspect-Based Opinion  Mining Approach",
    "abstract": "Opinion mining is the branch of computation that deals with opinions,\nappraisals, attitudes, and emotions of people and their different aspects. This\nfield has attracted substantial research interest in recent years. Aspect-level\n(called aspect-based opinion mining) is often desired in practical applications\nas it provides detailed opinions or sentiments about different aspects of\nentities and entities themselves, which are usually required for action. Aspect\nextraction and entity extraction are thus two core tasks of aspect-based\nopinion mining. his paper has presented a framework of aspect-based opinion\nmining based on the concept of transfer learning. on real-world customer\nreviews available on the Amazon website. The model has yielded quite\nsatisfactory results in its task of aspect-based opinion mining.",
    "descriptor": "\nComments: This is the accepted version of the paper that has been presented and published in the 20th IEEE Conference, OCIT'22. The final published version is copyright-protected by the IEEE. The paper consists of 5 pages, and it includes 5 figures and 1 table\n",
    "authors": [
      "Subhasis Dasgupta",
      "Jaydip Sen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10051"
  },
  {
    "id": "arXiv:2212.10054",
    "title": "VoronoiPatches: Evaluating A New Data Augmentation Method",
    "abstract": "Overfitting is a problem in Convolutional Neural Networks (CNN) that causes\npoor generalization of models on unseen data. To remediate this problem, many\nnew and diverse data augmentation methods (DA) have been proposed to supplement\nor generate more training data, and thereby increase its quality. In this work,\nwe propose a new data augmentation algorithm: VoronoiPatches (VP). We primarily\nutilize non-linear recombination of information within an image, fragmenting\nand occluding small information patches. Unlike other DA methods, VP uses small\nconvex polygon-shaped patches in a random layout to transport information\naround within an image. Sudden transitions created between patches and the\noriginal image can, optionally, be smoothed. In our experiments, VP\noutperformed current DA methods regarding model variance and overfitting\ntendencies. We demonstrate data augmentation utilizing non-linear\nre-combination of information within images, and non-orthogonal shapes and\nstructures improves CNN model robustness on unseen data.",
    "descriptor": "",
    "authors": [
      "Steffen Illium",
      "Gretchen Griffin",
      "Michael K\u00f6lle",
      "Maximilian Zorn",
      "Jonas N\u00fc\u00dflein",
      "Claudia Linnhoff-Popien"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10054"
  },
  {
    "id": "arXiv:2212.10057",
    "title": "WeCheck: Strong Factual Consistency Checker via Weakly Supervised  Learning",
    "abstract": "A crucial issue of current text generation models is that they often\nuncontrollably generate factually inconsistent text with respective of their\ninputs. Limited by the lack of annotated data, existing works in evaluating\nfactual consistency directly transfer the reasoning ability of models trained\non other data-rich upstream tasks like question answering (QA) and natural\nlanguage inference (NLI) without any further adaptation. As a result, they\nperform poorly on the real generated text and are biased heavily by their\nsingle-source upstream tasks. To alleviate this problem, we propose a weakly\nsupervised framework that aggregates multiple resources to train a precise and\nefficient factual metric, namely WeCheck. WeCheck first utilizes a generative\nmodel to accurately label a real generated sample by aggregating its weak\nlabels, which are inferred from multiple resources. Then, we train the target\nmetric model with the weak supervision while taking noises into consideration.\nComprehensive experiments on a variety of tasks demonstrate the strong\nperformance of WeCheck, which achieves a 3.4\\% absolute improvement over\nprevious state-of-the-art methods on TRUE benchmark on average.",
    "descriptor": "",
    "authors": [
      "Wenhao Wu",
      "Wei Li",
      "Xinyan Xiao",
      "Jiachen Liu",
      "Sujian Li",
      "Yajuan Lv"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10057"
  },
  {
    "id": "arXiv:2212.10060",
    "title": "An AI Dungeon Master's Guide: Learning to Converse and Guide with  Intents and Theory-of-Mind in Dungeons and Dragons",
    "abstract": "We propose a novel task, G4C (Goal-driven Guidance Generation in Grounded\nCommunication), for studying goal-driven and grounded natural language\ninteractions. Specifically, we choose Dungeons and Dragons (D&D) -- a\nrole-playing game consisting of multiple player characters and a Dungeon Master\n(DM) who collaborate to achieve a set of goals that are beneficial to the\nplayers -- as a testbed for this task. Here, each of the player characters is a\nstudent, with their own personas and abilities, and the DM is the teacher, an\narbitrator of the rules of the world and responsible for assisting and guiding\nthe students towards a global goal. We propose a theory-of-mind-inspired\nmethodology for training such a DM with reinforcement learning (RL), where a\nDM: (1) learns to predict how the players will react to its utterances using a\ndataset of D&D dialogue transcripts; and (2) uses this prediction as a reward\nfunction providing feedback on how effective these utterances are at guiding\nthe players towards a goal. Human and automated evaluations show that a DM\ntrained with RL to generate guidance by incorporating a theory-of-mind of the\nplayers significantly improves the players' ability to achieve goals grounded\nin their shared world.",
    "descriptor": "\nComments: 17 pages, 9 figures. Preprint, work in progress\n",
    "authors": [
      "Pei Zhou",
      "Andrew Zhu",
      "Jennifer Hu",
      "Jay Pujara",
      "Xiang Ren",
      "Chris Callison-Burch",
      "Yejin Choi",
      "Prithviraj Ammanabrolu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10060"
  },
  {
    "id": "arXiv:2212.10062",
    "title": "360$^\\circ$ Stereo Image Composition with Depth Adaption",
    "abstract": "360$^\\circ$ images and videos have become an economic and popular way to\nprovide VR experiences using real-world content. However, the manipulation of\nthe stereo panoramic content remains less explored. In this paper, we focus on\nthe 360$^\\circ$ image composition problem, and develop a solution that can take\nan object from a stereo image pair and insert it at a given 3D position in a\ntarget stereo panorama, with well-preserved geometry information. Our method\nuses recovered 3D point clouds to guide the composited image generation. More\nspecifically, we observe that using only a one-off operation to insert objects\ninto equirectangular images will never produce satisfactory depth perception\nand generate ghost artifacts when users are watching the result from different\nview directions. Therefore, we propose a novel view-dependent projection method\nthat segments the object in 3D spherical space with the stereo camera pair\nfacing in that direction. A deep depth densification network is proposed to\ngenerate depth guidance for the stereo image generation of each view segment\naccording to the desired position and pose of the inserted object. We finally\nmerge the synthesized view segments and blend the objects into the target\nstereo 360$^\\circ$ scene. A user study demonstrates that our method can provide\ngood depth perception and removes ghost artifacts. The view-dependent solution\nis a potential paradigm for other content manipulation methods for 360$^\\circ$\nimages and videos.",
    "descriptor": "",
    "authors": [
      "Kun Huang",
      "Fanglue Zhang",
      "Junhong Zhao",
      "Yiheng Li",
      "Neil Dodgson"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2212.10062"
  },
  {
    "id": "arXiv:2212.10064",
    "title": "AdverSAR: Adversarial Search and Rescue via Multi-Agent Reinforcement  Learning",
    "abstract": "Search and Rescue (SAR) missions in remote environments often employ\nautonomous multi-robot systems that learn, plan, and execute a combination of\nlocal single-robot control actions, group primitives, and global\nmission-oriented coordination and collaboration. Often, SAR coordination\nstrategies are manually designed by human experts who can remotely control the\nmulti-robot system and enable semi-autonomous operations. However, in remote\nenvironments where connectivity is limited and human intervention is often not\npossible, decentralized collaboration strategies are needed for\nfully-autonomous operations. Nevertheless, decentralized coordination may be\nineffective in adversarial environments due to sensor noise, actuation faults,\nor manipulation of inter-agent communication data. In this paper, we propose an\nalgorithmic approach based on adversarial multi-agent reinforcement learning\n(MARL) that allows robots to efficiently coordinate their strategies in the\npresence of adversarial inter-agent communications. In our setup, the objective\nof the multi-robot team is to discover targets strategically in an\nobstacle-strewn geographical area by minimizing the average time needed to find\nthe targets. It is assumed that the robots have no prior knowledge of the\ntarget locations, and they can interact with only a subset of neighboring\nrobots at any time. Based on the centralized training with decentralized\nexecution (CTDE) paradigm in MARL, we utilize a hierarchical meta-learning\nframework to learn dynamic team-coordination modalities and discover emergent\nteam behavior under complex cooperative-competitive scenarios. The\neffectiveness of our approach is demonstrated on a collection of prototype\ngrid-world environments with different specifications of benign and adversarial\nagents, target locations, and agent rewards.",
    "descriptor": "",
    "authors": [
      "Aowabin Rahman",
      "Arnab Bhattacharya",
      "Thiagarajan Ramachandran",
      "Sayak Mukherjee",
      "Himanshu Sharma",
      "Ted Fujimoto",
      "Samrat Chatterjee"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.10064"
  },
  {
    "id": "arXiv:2212.10066",
    "title": "RepMode: Learning to Re-parameterize Diverse Experts for Subcellular  Structure Prediction",
    "abstract": "In subcellular biological research, fluorescence staining is a key technique\nto reveal the locations and morphology of subcellular structures. However,\nfluorescence staining is slow, expensive, and harmful to cells. In this paper,\nwe treat it as a deep learning task termed subcellular structure prediction\n(SSP), aiming to predict the 3D fluorescent images of multiple subcellular\nstructures from a 3D transmitted-light image. Unfortunately, due to the\nlimitations of current biotechnology, each image is partially labeled in SSP.\nBesides, naturally, the subcellular structures vary considerably in size, which\ncauses the multi-scale issue in SSP. However, traditional solutions can not\naddress SSP well since they organize network parameters inefficiently and\ninflexibly. To overcome these challenges, we propose Re-parameterizing\nMixture-of-Diverse-Experts (RepMode), a network that dynamically organizes its\nparameters with task-aware priors to handle specified single-label prediction\ntasks of SSP. In RepMode, the Mixture-of-Diverse-Experts (MoDE) block is\ndesigned to learn the generalized parameters for all tasks, and gating\nre-parameterization (GatRep) is performed to generate the specialized\nparameters for each task, by which RepMode can maintain a compact practical\ntopology exactly like a plain network, and meanwhile achieves a powerful\ntheoretical topology. Comprehensive experiments show that RepMode outperforms\nexisting methods on ten of twelve prediction tasks of SSP and achieves\nstate-of-the-art overall performance.",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Donghao Zhou",
      "Chunbin Gu",
      "Junde Xu",
      "Furui Liu",
      "Qiong Wang",
      "Guangyong Chen",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10066"
  },
  {
    "id": "arXiv:2212.10071",
    "title": "Large Language Models Are Reasoning Teachers",
    "abstract": "Language models (LMs) have demonstrated remarkable performance on downstream\ntasks, using in-context exemplars or human instructions. Recent works have\nshown that chain-of-thought (CoT) prompting can elicit models to solve complex\nreasoning tasks, step-by-step. However, the efficacy of prompt-based CoT\nmethods is restricted to very large LMs such as GPT-3 (175B), thus limiting\ndeployability. In this paper, we revisit the fine-tuning approach to enable\ncomplex reasoning in smaller LMs, optimized to efficiently perform a specific\ntask. We propose Fine-tune-CoT, a method that leverages the capabilities of\nvery large LMs to generate reasoning samples and teach smaller models via\nfine-tuning. We evaluate our method on publicly available LMs across a wide\nrange of complex tasks and model sizes. We find that Fine-tune-CoT enables\nsubstantial reasoning capability in small models, whereas previous prompt-based\nbaselines exhibit near-random performance. Student models can even outperform\nthe teacher in some tasks while reducing model size requirements by several\norders of magnitude. We conduct extensive ablations and sample studies to\nunderstand the reasoning capabilities of student models. We also identify\nseveral important nuances that have been overlooked in concurrent fine-tuning\nworks on CoT and address them in our analysis.",
    "descriptor": "",
    "authors": [
      "Namgyu Ho",
      "Laura Schmid",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10071"
  },
  {
    "id": "arXiv:2212.10074",
    "title": "Virtual pivot point in human walking: always experimentally observed but  simulations suggest it may not be necessary",
    "abstract": "The intersection of ground reaction forces in a small, point-like area above\nthe center of mass has been observed in computer simulation models and human\nwalking experiments. This intersection point is often called a virtual pivot\npoint (VPP). With the VPP observed so ubiquitously, it is commonly assumed to\nprovide postural stability for bipedal walking. In this study, we challenge\nthis assumption by questioning if walking without a VPP is possible. Deriving\ngaits with a neuromuscular reflex model through multi-stage optimization, we\nfound stable walking patterns that show no signs of the VPP-typical\nintersection of ground reaction forces. We, therefore, conclude that a VPP is\nnot necessary for upright, stable walking. The non-VPP gaits found are stable\nand successfully rejected step-down perturbations, which indicates that a VPP\nis not primarily responsible for locomotion robustness or postural stability.\nHowever, a collision-based analysis indicates that non-VPP gaits increased the\npotential for collisions between the vectors of the center of mass velocity and\nground reaction forces during walking, suggesting an increased mechanical cost\nof transport. Although our computer simulation results have yet to be confirmed\nthrough experimental studies, they already strongly challenge the existing\nexplanation of the VPP's function and provide an alternative explanation.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "L. Schreff",
      "D. F. B. Haeufle",
      "A. Badri-Spr\u00f6witz",
      "J. Vielemeyer",
      "R. M\u00fcller"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.10074"
  },
  {
    "id": "arXiv:2212.10076",
    "title": "Out-of-sample scoring and automatic selection of causal estimators",
    "abstract": "Recently, many causal estimators for Conditional Average Treatment Effect\n(CATE) and instrumental variable (IV) problems have been published and open\nsourced, allowing to estimate granular impact of both randomized treatments\n(such as A/B tests) and of user choices on the outcomes of interest. However,\nthe practical application of such models has ben hampered by the lack of a\nvalid way to score the performance of such models out of sample, in order to\nselect the best one for a given application. We address that gap by proposing\nnovel scoring approaches for both the CATE case and an important subset of\ninstrumental variable problems, namely those where the instrumental variable is\ncustomer acces to a product feature, and the treatment is the customer's choice\nto use that feature. Being able to score model performance out of sample allows\nus to apply hyperparameter optimization methods to causal model selection and\ntuning. We implement that in an open source package that relies on DoWhy and\nEconML libraries for implementation of causal inference models (and also\nincludes a Transformed Outcome model implementation), and on FLAML for\nhyperparameter optimization and for component models used in the causal models.\nWe demonstrate on synthetic data that optimizing the proposed scores is a\nreliable method for choosing the model and its hyperparameter values, whose\nestimates are close to the true impact, in the randomized CATE and IV cases.\nFurther, we provide examles of applying these methods to real customer data\nfrom Wise.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Egor Kraev",
      "Timo Flesch",
      "Hudson Taylor Lekunze",
      "Mark Harley",
      "Pere Planell Morell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.10076"
  },
  {
    "id": "arXiv:2212.10077",
    "title": "DOC: Improving Long Story Coherence With Detailed Outline Control",
    "abstract": "We propose the Detailed Outline Control (DOC) framework for improving\nlong-range plot coherence when automatically generating\nseveral-thousand-word-long stories. DOC consists of two complementary\ncomponents: a detailed outliner and a detailed controller. The detailed\noutliner creates a more detailed, hierarchically structured outline, shifting\ncreative burden from the main drafting procedure to the planning stage. The\ndetailed controller ensures the more detailed outline is still respected during\ngeneration by controlling story passages to align with outline details. In\nhuman evaluations of automatically generated stories, DOC substantially\noutperforms a strong Re3 baseline (Yang et al., 2022) on plot coherence (22.5%\nabsolute gain), outline relevance (28.2%), and interestingness (20.7%). Humans\nalso judged DOC to be much more controllable in an interactive generation\nsetting.",
    "descriptor": "",
    "authors": [
      "Kevin Yang",
      "Dan Klein",
      "Nanyun Peng",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10077"
  },
  {
    "id": "arXiv:2212.10078",
    "title": "Constructing Organism Networks from Collaborative Self-Replicators",
    "abstract": "We introduce organism networks, which function like a single neural network\nbut are composed of several neural particle networks; while each particle\nnetwork fulfils the role of a single weight application within the organism\nnetwork, it is also trained to self-replicate its own weights. As organism\nnetworks feature vastly more parameters than simpler architectures, we perform\nour initial experiments on an arithmetic task as well as on simplified\nMNIST-dataset classification as a collective. We observe that individual\nparticle networks tend to specialise in either of the tasks and that the ones\nfully specialised in the secondary task may be dropped from the network without\nhindering the computational accuracy of the primary task. This leads to the\ndiscovery of a novel pruning-strategy for sparse neural networks",
    "descriptor": "",
    "authors": [
      "Steffen Illium",
      "Maximilian Zorn",
      "Cristian Lenta",
      "Michael K\u00f6lle",
      "Claudia Linnhoff-Popien",
      "Thomas Gabor"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10078"
  },
  {
    "id": "arXiv:2212.10079",
    "title": "A Survey on Pretrained Language Models for Neural Code Intelligence",
    "abstract": "As the complexity of modern software continues to escalate, software\nengineering has become an increasingly daunting and error-prone endeavor. In\nrecent years, the field of Neural Code Intelligence (NCI) has emerged as a\npromising solution, leveraging the power of deep learning techniques to tackle\nanalytical tasks on source code with the goal of improving programming\nefficiency and minimizing human errors within the software industry. Pretrained\nlanguage models have become a dominant force in NCI research, consistently\ndelivering state-of-the-art results across a wide range of tasks, including\ncode summarization, generation, and translation. In this paper, we present a\ncomprehensive survey of the NCI domain, including a thorough review of\npretraining techniques, tasks, datasets, and model architectures. We hope this\npaper will serve as a bridge between the natural language and programming\nlanguage communities, offering insights for future research in this rapidly\nevolving field.",
    "descriptor": "\nComments: work in progress. 13 pages\n",
    "authors": [
      "Yichen Xu",
      "Yanqiao Zhu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10079"
  },
  {
    "id": "arXiv:2212.10080",
    "title": "Rumour detection using graph neural network and oversampling in  benchmark Twitter dataset",
    "abstract": "Recently, online social media has become a primary source for new information\nand misinformation or rumours. In the absence of an automatic rumour detection\nsystem the propagation of rumours has increased manifold leading to serious\nsocietal damages. In this work, we propose a novel method for building\nautomatic rumour detection system by focusing on oversampling to alleviating\nthe fundamental challenges of class imbalance in rumour detection task. Our\noversampling method relies on contextualised data augmentation to generate\nsynthetic samples for underrepresented classes in the dataset. The key idea\nexploits selection of tweets in a thread for augmentation which can be achieved\nby introducing a non-random selection criteria to focus the augmentation\nprocess on relevant tweets. Furthermore, we propose two graph neural\nnetworks(GNN) to model non-linear conversations on a thread. To enhance the\ntweet representations in our method we employed a custom feature selection\ntechnique based on state-of-the-art BERTweet model. Experiments of three\npublicly available datasets confirm that 1) our GNN models outperform the the\ncurrent state-of-the-art classifiers by more than 20%(F1-score); 2) our\noversampling technique increases the model performance by more than\n9%;(F1-score) 3) focusing on relevant tweets for data augmentation via\nnon-random selection criteria can further improve the results; and 4) our\nmethod has superior capabilities to detect rumours at very early stage.",
    "descriptor": "",
    "authors": [
      "Shaswat Patel",
      "Prince Bansal",
      "Preeti Kaur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10080"
  },
  {
    "id": "arXiv:2212.10082",
    "title": "An Information-Theoretic Approach to Transferability in Task Transfer  Learning",
    "abstract": "Task transfer learning is a popular technique in image processing\napplications that uses pre-trained models to reduce the supervision cost of\nrelated tasks. An important question is to determine task transferability, i.e.\ngiven a common input domain, estimating to what extent representations learned\nfrom a source task can help in learning a target task. Typically,\ntransferability is either measured experimentally or inferred through task\nrelatedness, which is often defined without a clear operational meaning. In\nthis paper, we present a novel metric, H-score, an easily-computable evaluation\nfunction that estimates the performance of transferred representations from one\ntask to another in classification problems using statistical and information\ntheoretic principles. Experiments on real image data show that our metric is\nnot only consistent with the empirical transferability measurement, but also\nuseful to practitioners in applications such as source model selection and task\ntransfer curriculum learning.",
    "descriptor": "",
    "authors": [
      "Yajie Bao",
      "Yang Li",
      "Shao-Lun Huang",
      "Lin Zhang",
      "Lizhong Zheng",
      "Amir Zamir",
      "Leonidas Guibas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10082"
  },
  {
    "id": "arXiv:2212.10087",
    "title": "Hybrid Rule-Neural Coreference Resolution System based on Actor-Critic  Learning",
    "abstract": "A coreference resolution system is to cluster all mentions that refer to the\nsame entity in a given context. All coreference resolution systems need to\ntackle two main tasks: one task is to detect all of the potential mentions, and\nthe other is to learn the linking of an antecedent for each possible mention.\nIn this paper, we propose a hybrid rule-neural coreference resolution system\nbased on actor-critic learning, such that it can achieve better coreference\nperformance by leveraging the advantages from both the heuristic rules and a\nneural conference model. This end-to-end system can also perform both mention\ndetection and resolution by leveraging a joint training algorithm. We\nexperiment on the BERT model to generate input span representations. Our model\nwith the BERT span representation achieves the state-of-the-art performance\namong the models on the CoNLL-2012 Shared Task English Test Set.",
    "descriptor": "\nComments: 11 pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2212.09028\n",
    "authors": [
      "Yu Wang",
      "Hongxia Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10087"
  },
  {
    "id": "arXiv:2212.10092",
    "title": "Exploring Effective Fusion Algorithms for Speech Based Self-Supervised  Learning Models",
    "abstract": "Self-supervised learning (SSL) has achieved great success in various areas\nincluding speech processing. Recently, it is proven that speech based SSL\nmodels are able to extract superior universal representations on a range of\ndownstream tasks compared to traditional hand-craft feature (e.g. FBank, MFCC)\nin the SUPERB benchmark. However, different types of SSL models might exhibit\ndistinct strengths on different downstream tasks. In order to better utilize\nthe potential power of SSL models, in this work, we explore the effective\nfusion on multiple SSL models. A series of model fusion algorithms are\ninvestigated and compared by combining two types of SSL models, Hubert and\nData2vec, on two representative tasks from SUPERB benchmark, which are speaker\nidentification (SID) and automatic speech recognition (ASR) tasks. The\nexperimental results demonstrate that our proposed fusion algorithms can\nfurther boost the individual model significantly.",
    "descriptor": "\nComments: Accepted by NCMMSC2022\n",
    "authors": [
      "Changli Tang",
      "Yujin Wang",
      "Xie Chen",
      "Wei-Qiang Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.10092"
  },
  {
    "id": "arXiv:2212.10093",
    "title": "Visual Transformers for Primates Classification and Covid Detection",
    "abstract": "We apply the vision transformer, a deep machine learning model build around\nthe attention mechanism, on mel-spectrogram representations of raw audio\nrecordings. When adding mel-based data augmentation techniques and\nsample-weighting, we achieve comparable performance on both (PRS and CCS\nchallenge) tasks of ComParE21, outperforming most single model baselines. We\nfurther introduce overlapping vertical patching and evaluate the influence of\nparameter configurations. Index Terms: audio classification, attention,\nmel-spectrogram, unbalanced data-sets, computational paralinguistics",
    "descriptor": "",
    "authors": [
      "Steffen Illium",
      "Robert M\u00fcller",
      "Andreas Sedlmeier",
      "Claudia-Linnhoff Popien"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.10093"
  },
  {
    "id": "arXiv:2212.10096",
    "title": "Treating Hyperthyroidism: Model Predictive Control for the Prescription  of Antithyroid Agents",
    "abstract": "In this work, we propose an approach to determine the dosages of antithyroid\nagents to treat hyperthyroid patients. Instead of relying on a trial-and-error\napproach as it is commonly done in clinical practice, we suggest to determine\nthe dosages by means of a model predictive control (MPC) scheme. To this end,\nwe extend a mathematical model of the pituitary-thyroid feedback loop such that\nthe intake of methimazole, a common antithyroid agent, can be considered. Based\non this extension, we develop an MPC scheme to determine suitable dosages. In\nnumerical simulations, we consider scenarios in which (i) patients are affected\nby Graves' disease and take the medication orally, (ii) patients are\nadditionally affected by high intrathyroidal iodide concentrations and take the\nmedication orally and, (iii) patients suffering from a life-threatening\nthyrotoxicosis, in which the medication is usually given intravenously. Our\nresults suggest that determining the medication dosages by means of an MPC\nscheme is a promising alternative to the currently applied trial-and-error\napproach.",
    "descriptor": "\nComments: Submitted to IFAC World Congress 2023\n",
    "authors": [
      "Tobias M. Wolff",
      "Maylin Menzel",
      "Johannes W. Dietrich",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.10096"
  },
  {
    "id": "arXiv:2212.10097",
    "title": "Toward a Unified Framework for Unsupervised Complex Tabular Reasoning",
    "abstract": "Structured tabular data exist across nearly all fields. Reasoning task over\nthese data aims to answer questions or determine the truthiness of hypothesis\nsentences by understanding the semantic meaning of a table. While previous\nworks have devoted significant efforts to the tabular reasoning task, they\nalways assume there are sufficient labeled data. However, constructing\nreasoning samples over tables (and related text) is labor-intensive, especially\nwhen the reasoning process is complex. When labeled data is insufficient, the\nperformance of models will suffer an unendurable decline. In this paper, we\npropose a unified framework for unsupervised complex tabular reasoning (UCTR),\nwhich generates sufficient and diverse synthetic data with complex logic for\ntabular reasoning tasks, assuming no human-annotated data at all. We first\nutilize a random sampling strategy to collect diverse programs of different\ntypes and execute them on tables based on a \"Program-Executor\" module. To\nbridge the gap between the programs and natural language sentences, we design a\npowerful \"NL-Generator\" module to generate natural language sentences with\ncomplex logic from these programs. Since a table often occurs with its\nsurrounding texts, we further propose novel \"Table-to-Text\" and \"Text-to-Table\"\noperators to handle joint table-text reasoning scenarios. This way, we can\nadequately exploit the unlabeled table resources to obtain a well-performed\nreasoning model under an unsupervised setting. Our experiments cover different\ntasks (question answering and fact verification) and different domains (general\nand specific), showing that our unsupervised methods can achieve at most 93%\nperformance compared to supervised models. We also find that it can\nsubstantially boost the supervised performance in low-resourced domains as a\ndata augmentation technique. Our code is available at\nhttps://github.com/leezythu/UCTR.",
    "descriptor": "\nComments: Accepted by ICDE 2023. Preprint Version\n",
    "authors": [
      "Zhenyu Li",
      "Xiuxing Li",
      "Zhichao Duan",
      "Bowen Dong",
      "Ning Liu",
      "Jianyong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.10097"
  },
  {
    "id": "arXiv:2212.10098",
    "title": "A Communication Optimal Transport Approach to the Computation of Rate  Distortion Functions",
    "abstract": "In this paper, we propose a new framework named Communication Optimal\nTransport (CommOT) for computing the rate distortion (RD) function. This work\nis motivated by observing the fact that the transition law and the relative\nentropy in communication theory can be viewed as the transport plan and the\nregularized objective function in the optimal transport (OT) model. However,\nunlike in classical OT problems, the RD function only possesses one-side\nmarginal distribution. Hence, to maintain the OT structure, we introduce\nslackness variables to fulfill the other-side marginal distribution and then\npropose a general framework (CommOT) for the RD function. The CommOT model is\nsolved via the alternating optimization technique and the well-known Sinkhorn\nalgorithm. In particular, the expected distortion threshold can be converted\ninto finding the unique root of a one-dimensional monotonic function with only\na few steps. Numerical experiments show that our proposed framework (CommOT)\nfor solving the RD function with given distortion threshold is efficient and\naccurate.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Shitong Wu",
      "Wenhao Ye",
      "Hao Wu",
      "Huihui Wu",
      "Wenyi Zhang",
      "Bo Bai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.10098"
  },
  {
    "id": "arXiv:2212.10103",
    "title": "VSVC: Backdoor attack against Keyword Spotting based on Voiceprint  Selection and Voice Conversion",
    "abstract": "Keyword spotting (KWS) based on deep neural networks (DNNs) has achieved\nmassive success in voice control scenarios. However, training of such DNN-based\nKWS systems often requires significant data and hardware resources.\nManufacturers often entrust this process to a third-party platform. This makes\nthe training process uncontrollable, where attackers can implant backdoors in\nthe model by manipulating third-party training data. An effective backdoor\nattack can force the model to make specified judgments under certain\nconditions, i.e., triggers. In this paper, we design a backdoor attack scheme\nbased on Voiceprint Selection and Voice Conversion, abbreviated as VSVC.\nExperimental results demonstrated that VSVC is feasible to achieve an average\nattack success rate close to 97% in four victim models when poisoning less than\n1% of the training data.",
    "descriptor": "\nComments: 7 pages,5 figures\n",
    "authors": [
      "Hanbo Cai",
      "Pengcheng Zhang",
      "Hai Dong",
      "Yan Xiao",
      "Shunhui Ji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.10103"
  },
  {
    "id": "arXiv:2212.10105",
    "title": "On the Applicability of Synthetic Data for Re-Identification",
    "abstract": "This contribution demonstrates the feasibility of applying Generative\nAdversarial Networks (GANs) on images of EPAL pallet blocks for dataset\nenhancement in the context of re-identification. For many industrial\napplications of re-identification methods, datasets of sufficient volume would\notherwise be unattainable in non-laboratory settings. Using a state-of-the-art\nGAN architecture, namely CycleGAN, images of pallet blocks rotated to their\nleft-hand side were generated from images of visually centered pallet blocks,\nbased on images of rotated pallet blocks that were recorded as part of a\npreviously recorded and published dataset. In this process, the unique chipwood\npattern of the pallet block surface structure was retained, only changing the\norientation of the pallet block itself. By doing so, synthetic data for\nre-identification testing and training purposes was generated, in a manner that\nis distinct from ordinary data augmentation. In total, 1,004 new images of\npallet blocks were generated. The quality of the generated images was gauged\nusing a perspective classifier that was trained on the original images and then\napplied to the synthetic ones, comparing the accuracy between the two sets of\nimages. The classification accuracy was 98% for the original images and 92% for\nthe synthetic images. In addition, the generated images were also used in a\nre-identification task, in order to re-identify original images based on\nsynthetic ones. The accuracy in this scenario was up to 88% for synthetic\nimages, compared to 96% for original images. Through this evaluation, it is\nestablished, whether or not a generated pallet block image closely resembles\nits original counterpart.",
    "descriptor": "\nComments: Accepted as a non-archival paper in AAAI23 workshop AI2SE\n",
    "authors": [
      "J\u00e9r\u00f4me Rutinowski",
      "Bhargav Vankayalapati",
      "Nils Schwenzfeier",
      "Maribel Acosta",
      "Christopher Reining"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10105"
  },
  {
    "id": "arXiv:2212.10108",
    "title": "Efficient aggregation of face embeddings for decentralized face  recognition deployments (extended version)",
    "abstract": "Biometrics are one of the most privacy-sensitive data. Ubiquitous\nauthentication systems with a focus on privacy favor decentralized approaches\nas they reduce potential attack vectors, both on a technical and organizational\nlevel. The gold standard is to let the user be in control of where their own\ndata is stored, which consequently leads to a high variety of devices used.\nMoreover, in comparison with a centralized system, designs with higher end-user\nfreedom often incur additional network overhead. Therefore, when using face\nrecognition for biometric authentication, an efficient way to compare faces is\nimportant in practical deployments, because it reduces both network and\nhardware requirements that are essential to encourage device diversity. This\npaper proposes an efficient way to aggregate embeddings used for face\nrecognition based on an extensive analysis on different datasets and the use of\ndifferent aggregation strategies. As part of this analysis, a new dataset has\nbeen collected, which is available for research purposes. Our proposed method\nsupports the construction of massively scalable, decentralized face recognition\nsystems with a focus on both privacy and long-term usability.",
    "descriptor": "",
    "authors": [
      "Philipp Hofer",
      "Michael Roland",
      "Philipp Schwarz",
      "Ren\u00e8 Mayrhofer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10108"
  },
  {
    "id": "arXiv:2212.10114",
    "title": "True Detective: A Challenging Benchmark for Deep Abductive Reasoning  \\\\in Foundation Models",
    "abstract": "Large language models (LLMs) have demonstrated strong performance in\nzero-shot reasoning tasks, including abductive reasoning. This is reflected in\ntheir ability to perform well on current benchmarks in this area. However, to\ntruly test the limits of LLMs in abductive reasoning, a more challenging\nbenchmark is needed. In this paper, we present such a benchmark, consisting of\n191 long-form mystery stories, each approximately 1200 words in length and\npresented in the form of detective puzzles. Each puzzle includes a\nmultiple-choice question for evaluation sourced from the \"5 Minute Mystery\"\nplatform. Our results show that state-of-the-art GPT models perform\nsignificantly worse than human solvers on this benchmark, with an accuracy of\n28\\% compared to 47\\% for humans. This indicates that there is still a\nsignificant gap in the abductive reasoning abilities of LLMs and highlights the\nneed for further research in this area. Our work provides a challenging\nbenchmark for future studies on reasoning in language models and contributes to\na better understanding of the limits of LLMs' abilities.",
    "descriptor": "\nComments: 4 pages, preprint\n",
    "authors": [
      "Maksym Del",
      "Mark Fishel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10114"
  },
  {
    "id": "arXiv:2212.10121",
    "title": "Narrative Visualization to Communicate Neurological Diseases",
    "abstract": "While narrative visualization has been used successfully in various\napplications to communicate scientific data in the format of a story to a\ngeneral audience, the same has not been true for medical data. There are only a\nfew exceptions that present tabular medical data to non-experts. However, a key\ncomponent of medical visualization is the interactive analysis of 3D data, such\nas 3D models of anatomical structures, which were rarely included in narrative\nvisualizations so far. In this design study, we investigate how neurological\ndisease data can be communicated through narrative visualization techniques to\na general audience in an understandable way. We designed a narrative\nvisualization explaining cerebral small vessel disease. Learning about its\navoidable risk factors serves to motivate the audience watching the resulting\nvisual data story. Using this example, we discuss the adaption of basic\nnarrative components. This includes the conflict and characters of a story, as\nwell as the story's structure and content to address and communicate specific\ncharacteristics of medical data. Furthermore, we explore the extent to which\ncomplex medical relationships need to be simplified to be understandable to a\ngeneral audience without distorting the underlying data and evidence. In\nparticular, the data needs to be preprocessed for non-experts and appropriate\nforms of interaction must be found. We explore approaches to make the data more\npersonally relatable, such as including a fictional patient. We evaluated our\napproach in a user study with 40 participants in a web-based implementation of\nthe designed story. We found that the combination of a carefully thought-out\nstoryline with a clear key message, appealing visualizations combined with\neasy-to-use interactions, and credible references are crucial for creating a\nnarrative visualization about a neurological disease that engages an audience.",
    "descriptor": "\nComments: 11 pages, 9 figures\n",
    "authors": [
      "Sarah Mittenentzwei",
      "Veronika Wei\u00df",
      "Stefanie Schreiber",
      "Laura A. Garrison",
      "Stefan Bruckner",
      "Malte Pfister",
      "Bernhard Preim",
      "Monique Meuschke"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.10121"
  },
  {
    "id": "arXiv:2212.10124",
    "title": "Image Segmentation-based Unsupervised Multiple Objects Discovery",
    "abstract": "Unsupervised object discovery aims to localize objects in images, while\nremoving the dependence on annotations required by most deep learning-based\nmethods. To address this problem, we propose a fully unsupervised, bottom-up\napproach, for multiple objects discovery. The proposed approach is a two-stage\nframework. First, instances of object parts are segmented by using the\nintra-image similarity between self-supervised local features. The second step\nmerges and filters the object parts to form complete object instances. The\nlatter is performed by two CNN models that capture semantic information on\nobjects from the entire dataset. We demonstrate that the pseudo-labels\ngenerated by our method provide a better precision-recall trade-off than\nexisting single and multiple objects discovery methods. In particular, we\nprovide state-of-the-art results for both unsupervised class-agnostic object\ndetection and unsupervised image segmentation.",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Sandra Kara",
      "Hejer Ammar",
      "Florian Chabot",
      "Quoc-Cuong Pham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10124"
  },
  {
    "id": "arXiv:2212.10129",
    "title": "Minimizing interference-to-signal ratios in multi-cell networks",
    "abstract": "In contemporary wireless communication networks, base-stations are organized\ninto coordinated clusters (called cells) to jointly serve the users. However,\nsuch fixed systems are plagued by the so-called cell-edge problem: near the\nboundaries, the interference between neighboring clusters can result in very\npoor interference-to-signal-power ratios. To achieve a high quality service, it\nis an important objective to minimize the sum of these ratios over the cells.\nThe most common approach to solve this minimization problem is arguably the\nspectral clustering method. In this paper, we propose a new clustering\napproach, which is deterministic and computationally much less demanding than\ncurrent methods. Simulating on synthetic instances indicates that our methods\ntypically provide higher quality solutions than earlier methods.\nAn earlier version of this algorithm was reported in arXiv:2111.00885.",
    "descriptor": "",
    "authors": [
      "P\u00e9ter L. Erd\u0151s",
      "Tam\u00e1s R\u00f3bert Mezei"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2212.10129"
  },
  {
    "id": "arXiv:2212.10131",
    "title": "Graalvisor: Virtualized Polyglot Runtime for Serverless Applications",
    "abstract": "Serverless is a new attractive computing model that offers great scalability\nand elasticity, taking the infrastructure management burden away from users,\nand enabling a pay-as-you-use billing model. As a result, Serverless is\nbecoming increasingly popular, and new use cases have recently been proposed.\nExamples include video and image processing, Machine Learning inference and\ntraining, and data analytics. However, Serverless is currently supported by\nbloated virtualization stacks composed of a combination of virtual machines\nand/or containers, and language runtimes. None of these were to host\nlightweight and fast-executing Serverless workloads.\nTo reduce the virtualization stack bloat, we propose Graalvisor, a\nvirtualized polyglot language runtime capable of running multiple concurrent\nfunctions with minimal overhead. Graalvisor is designed to efficiently run\nlightweight and short-running Serverless functions, each running in a tiny\nexecution environment that launches under 500 us. A single Graalvisor instance\ncan run thousands of functions written in many different languages. By\nvirtualizing a single runtime across many function invocations, Graalvisor\nreduces virtualization stack redundancy, resulting in lower memory consumption\nand less cold-starts. On a set of established Serverless functions, Graalvisor\nimproves the throughput per memory (ops/sec/GB) on average by 170$\\times$ for\nJava functions, 26.6$\\times$ for JavaScript functions, and 2.07$\\times$ for\nPython functions. When reproducing a public Serverless trace, Graalvisor\nreduces the overall memory footprint by 83% and reduces the tail latency (99\npercentile) by 68%.",
    "descriptor": "",
    "authors": [
      "Rodrigo Bruno",
      "Serhii Ivanenko",
      "Sutao Wang",
      "Jovan Stevanovic",
      "Vojin Jovanovic"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2212.10131"
  },
  {
    "id": "arXiv:2212.10132",
    "title": "Content Adaptive Latents and Decoder for Neural Image Compression",
    "abstract": "In recent years, neural image compression (NIC) algorithms have shown\npowerful coding performance. However, most of them are not adaptive to the\nimage content. Although several content adaptive methods have been proposed by\nupdating the encoder-side components, the adaptability of both latents and the\ndecoder is not well exploited. In this work, we propose a new NIC framework\nthat improves the content adaptability on both latents and the decoder.\nSpecifically, to remove redundancy in the latents, our content adaptive channel\ndropping (CACD) method automatically selects the optimal quality levels for the\nlatents spatially and drops the redundant channels. Additionally, we propose\nthe content adaptive feature transformation (CAFT) method to improve\ndecoder-side content adaptability by extracting the characteristic information\nof the image content, which is then used to transform the features in the\ndecoder side. Experimental results demonstrate that our proposed methods with\nthe encoder-side updating algorithm achieve the state-of-the-art performance.",
    "descriptor": "\nComments: V1 is accepted to ECCV 2022\n",
    "authors": [
      "Guanbo Pan",
      "Guo Lu",
      "Zhihao Hu",
      "Dong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.10132"
  },
  {
    "id": "arXiv:2212.10135",
    "title": "Using Witten Laplacians to locate index-1 saddle points",
    "abstract": "We introduce a new stochastic algorithm to locate the index-1 saddle points\nof a function $V:\\mathbb R^d \\to \\mathbb R$, with $d$ possibly large. This\nalgorithm can be seen as an equivalent of the stochastic gradient descent which\nis a natural stochastic process to locate local minima. It relies on two\ningredients: (i) the concentration properties on index-1 saddle points of the\nfirst eigenmodes of the Witten Laplacian (associated with $V$) on $1$-forms and\n(ii) a probabilistic representation of a partial differential equation\ninvolving this differential operator. Numerical examples on simple molecular\nsystems illustrate the efficacy of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Tony Leli\u00e8vre",
      "Panos Parpas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.10135"
  },
  {
    "id": "arXiv:2212.10136",
    "title": "A Comparison Between Tsetlin Machines and Deep Neural Networks in the  Context of Recommendation Systems",
    "abstract": "Recommendation Systems (RSs) are ubiquitous in modern society and are one of\nthe largest points of interaction between humans and AI. Modern RSs are often\nimplemented using deep learning models, which are infamously difficult to\ninterpret. This problem is particularly exasperated in the context of\nrecommendation scenarios, as it erodes the user's trust in the RS. In contrast,\nthe newly introduced Tsetlin Machines (TM) possess some valuable properties due\nto their inherent interpretability. TMs are still fairly young as a technology.\nAs no RS has been developed for TMs before, it has become necessary to perform\nsome preliminary research regarding the practicality of such a system. In this\npaper, we develop the first RS based on TMs to evaluate its practicality in\nthis application domain. This paper compares the viability of TMs with other\nmachine learning models prevalent in the field of RS. We train and investigate\nthe performance of the TM compared with a vanilla feed-forward deep learning\nmodel. These comparisons are based on model performance,\ninterpretability/explainability, and scalability. Further, we provide some\nbenchmark performance comparisons to similar machine learning solutions\nrelevant to RSs.",
    "descriptor": "\nComments: Accepted to NLDL 2023\n",
    "authors": [
      "Karl Audun Borgersen",
      "Morten Goodwin",
      "Jivitesh Sharma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.10136"
  },
  {
    "id": "arXiv:2212.10140",
    "title": "Tackling Ambiguity with Images: Improved Multimodal Machine Translation  and Contrastive Evaluation",
    "abstract": "One of the major challenges of machine translation (MT) is ambiguity, which\ncan in some cases be resolved by accompanying context such as an image.\nHowever, recent work in multimodal MT (MMT) has shown that obtaining\nimprovements from images is challenging, limited not only by the difficulty of\nbuilding effective cross-modal representations but also by the lack of specific\nevaluation and training data. We present a new MMT approach based on a strong\ntext-only MT model, which uses neural adapters and a novel guided\nself-attention mechanism and which is jointly trained on both visual masking\nand MMT. We also release CoMMuTE, a Contrastive Multilingual Multimodal\nTranslation Evaluation dataset, composed of ambiguous sentences and their\npossible translations, accompanied by disambiguating images corresponding to\neach translation. Our approach obtains competitive results over strong\ntext-only models on standard English-to-French benchmarks and outperforms these\nbaselines and state-of-the-art MMT systems with a large margin on our\ncontrastive test set.",
    "descriptor": "",
    "authors": [
      "Matthieu Futeral",
      "Cordelia Schmid",
      "Ivan Laptev",
      "Beno\u00eet Sagot",
      "Rachel Bawden"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10140"
  },
  {
    "id": "arXiv:2212.10147",
    "title": "Bridging Images and Videos: A Simple Learning Framework for Large  Vocabulary Video Object Detection",
    "abstract": "Scaling object taxonomies is one of the important steps toward a robust\nreal-world deployment of recognition systems. We have faced remarkable progress\nin images since the introduction of the LVIS benchmark. To continue this\nsuccess in videos, a new video benchmark, TAO, was recently presented. Given\nthe recent encouraging results from both detection and tracking communities, we\nare interested in marrying those two advances and building a strong large\nvocabulary video tracker. However, supervisions in LVIS and TAO are inherently\nsparse or even missing, posing two new challenges for training the large\nvocabulary trackers. First, no tracking supervisions are in LVIS, which leads\nto inconsistent learning of detection (with LVIS and TAO) and tracking (only\nwith TAO). Second, the detection supervisions in TAO are partial, which results\nin catastrophic forgetting of absent LVIS categories during video fine-tuning.\nTo resolve these challenges, we present a simple but effective learning\nframework that takes full advantage of all available training data to learn\ndetection and tracking while not losing any LVIS categories to recognize. With\nthis new learning scheme, we show that consistent improvements of various large\nvocabulary trackers are capable, setting strong baseline results on the\nchallenging TAO benchmarks.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Sanghyun Woo",
      "Kwanyong Park",
      "Seoung Wug Oh",
      "In So Kweon",
      "Joon-Young Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10147"
  },
  {
    "id": "arXiv:2212.10149",
    "title": "Tracking by Associating Clips",
    "abstract": "The tracking-by-detection paradigm today has become the dominant method for\nmulti-object tracking and works by detecting objects in each frame and then\nperforming data association across frames. However, its sequential frame-wise\nmatching property fundamentally suffers from the intermediate interruptions in\na video, such as object occlusions, fast camera movements, and abrupt light\nchanges. Moreover, it typically overlooks temporal information beyond the two\nframes for matching. In this paper, we investigate an alternative by treating\nobject association as clip-wise matching. Our new perspective views a single\nlong video sequence as multiple short clips, and then the tracking is performed\nboth within and between the clips. The benefits of this new approach are two\nfolds. First, our method is robust to tracking error accumulation or\npropagation, as the video chunking allows bypassing the interrupted frames, and\nthe short clip tracking avoids the conventional error-prone long-term track\nmemory management. Second, the multiple frame information is aggregated during\nthe clip-wise matching, resulting in a more accurate long-range track\nassociation than the current frame-wise matching. Given the state-of-the-art\ntracking-by-detection tracker, QDTrack, we showcase how the tracking\nperformance improves with our new tracking formulation. We evaluate our\nproposals on two tracking benchmarks, TAO and MOT17 that have complementary\ncharacteristics and challenges each other.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Sanghyun Woo",
      "Kwanyong Park",
      "Seoung Wug Oh",
      "In So Kweon",
      "Joon-Young Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10149"
  },
  {
    "id": "arXiv:2212.10150",
    "title": "Approximate Query Processing via Tuple Bubbles",
    "abstract": "We propose a versatile approach to lightweight, approximate query processing\nby creating compact but tunably precise representations of larger quantities of\noriginal tuples, coined bubbles. Instead of working with tables of tuples, the\nquery processing then operates on bubbles but leaves the traditional query\nprocessing paradigms conceptually applicable. We believe this is a natural and\nviable approach to render approximate query processing feasible for large data\nin disaggregated cloud settings or in resource-limited scenarios. Bubbles are\ntunable regarding the compactness of enclosed tuples as well as the granularity\nof statistics and the way they are instantiated. For improved accuracy, we put\nforward a first working solution that represents bubbles via Bayesian networks,\nper table, or along foreign-key joins. To underpin the viability of the\napproach, we report on an experimental evaluation considering the\nstate-of-the-art competitors, where we show clear benefits when assessing the\nestimation accuracy, execution time, and required disk space.",
    "descriptor": "\nComments: 8 pages, 2 figures, 3 tables\n",
    "authors": [
      "Damjan Gjurovski",
      "Sebastian Michel"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.10150"
  },
  {
    "id": "arXiv:2212.10152",
    "title": "Quirk or Palmer: A Comparative Study of Modal Verb Frameworks with  Annotated Datasets",
    "abstract": "Modal verbs, such as \"can\", \"may\", and \"must\", are commonly used in daily\ncommunication to convey the speaker's perspective related to the likelihood\nand/or mode of the proposition. They can differ greatly in meaning depending on\nhow they're used and the context of a sentence (e.g. \"They 'must' help each\nother out.\" vs. \"They 'must' have helped each other out.\") Despite their\npractical importance in natural language understanding, linguists have yet to\nagree on a single, prominent framework for the categorization of modal verb\nsenses. This lack of agreement stems from high degrees of flexibility and\npolysemy from the modal verbs, making it more difficult for researchers to\nincorporate insights from this family of words into their work. This work\npresents Moverb dataset, which consists of 27,240 annotations of modal verb\nsenses over 4,540 utterances containing one or more sentences from social\nconversations. Each utterance is annotated by three annotators using two\ndifferent theoretical frameworks (i.e., Quirk and Palmer) of modal verb senses.\nWe observe that both frameworks have similar inter-annotator agreements,\ndespite having different numbers of sense types (8 for Quirk and 3 for Palmer).\nWith the RoBERTa-based classifiers fine-tuned on \\dataset, we achieve F1 scores\nof 82.2 and 78.3 on Quirk and Palmer, respectively, showing that modal verb\nsense disambiguation is not a trivial task. Our dataset will be publicly\navailable with our final version.",
    "descriptor": "",
    "authors": [
      "Risako Owan",
      "Maria Gini",
      "Dongyeop Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10152"
  },
  {
    "id": "arXiv:2212.10154",
    "title": "Human-Guided Fair Classification for Natural Language Processing",
    "abstract": "Text classifiers have promising applications in high-stake tasks such as\nresume screening and content moderation. These classifiers must be fair and\navoid discriminatory decisions by being invariant to perturbations of sensitive\nattributes such as gender or ethnicity. However, there is a gap between human\nintuition about these perturbations and the formal similarity specifications\ncapturing them. While existing research has started to address this gap,\ncurrent methods are based on hardcoded word replacements, resulting in\nspecifications with limited expressivity or ones that fail to fully align with\nhuman intuition (e.g., in cases of asymmetric counterfactuals). This work\nproposes novel methods for bridging this gap by discovering expressive and\nintuitive individual fairness specifications. We show how to leverage\nunsupervised style transfer and GPT-3's zero-shot capabilities to automatically\ngenerate expressive candidate pairs of semantically similar sentences that\ndiffer along sensitive attributes. We then validate the generated pairs via an\nextensive crowdsourcing study, which confirms that a lot of these pairs align\nwith human intuition about fairness in the context of toxicity classification.\nFinally, we show how limited amounts of human feedback can be leveraged to\nlearn a similarity specification that can be used to train downstream\nfairness-aware models.",
    "descriptor": "\nComments: 31 pages, 1 figure\n",
    "authors": [
      "Florian E.Dorner",
      "Momchil Peychev",
      "Nikola Konstantinov",
      "Naman Goel",
      "Elliott Ash",
      "Martin Vechev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10154"
  },
  {
    "id": "arXiv:2212.10156",
    "title": "Goal-oriented Autonomous Driving",
    "abstract": "Modern autonomous driving system is characterized as modular tasks in\nsequential order, i.e., perception, prediction and planning. As sensors and\nhardware get improved, there is trending popularity to devise a system that can\nperform a wide diversity of tasks to fulfill higher-level intelligence.\nContemporary approaches resort to either deploying standalone models for\nindividual tasks, or designing a multi-task paradigm with separate heads. These\nmight suffer from accumulative error or negative transfer effect. Instead, we\nargue that a favorable algorithm framework should be devised and optimized in\npursuit of the ultimate goal, i.e. planning of the self-driving-car. Oriented\nat this goal, we revisit the key components within perception and prediction.\nWe analyze each module and prioritize the tasks hierarchically, such that all\nthese tasks contribute to planning (the goal). To this end, we introduce\nUnified Autonomous Driving (UniAD), the first comprehensive framework\nup-to-date that incorporates full-stack driving tasks in one network. It is\nexquisitely devised to leverage advantages of each module, and provide\ncomplementary feature abstractions for agent interaction from a global\nperspective. Tasks are communicated with unified query design to facilitate\neach other toward planning. We instantiate UniAD on the challenging nuScenes\nbenchmark. With extensive ablations, the effectiveness of using such a\nphilosophy is proven to surpass previous state-of-the-arts by a large margin in\nall aspects. The full suite of codebase and models would be available to\nfacilitate future research in the community.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yihan Hu",
      "Jiazhi Yang",
      "Li Chen",
      "Keyu Li",
      "Chonghao Sima",
      "Xizhou Zhu",
      "Siqi Chai",
      "Senyao Du",
      "Tianwei Lin",
      "Wenhai Wang",
      "Lewei Lu",
      "Xiaosong Jia",
      "Qiang Liu",
      "Jifeng Dai",
      "Yu Qiao",
      "Hongyang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.10156"
  },
  {
    "id": "arXiv:2212.10158",
    "title": "Spreading and Structural Balance on Signed Networks",
    "abstract": "Two competing types of interactions often play an important part in shaping\nsystem behavior, such as activatory or inhibitory functions in biological\nsystems. Hence, signed networks, where each connection can be either positive\nor negative, have become popular models over recent years. However, the primary\nfocus of the literature is on the unweighted and structurally balanced ones,\nwhere all cycles have an even number of negative edges. Hence here, we first\nintroduce a classification of signed networks into balanced, antibalanced or\nstrictly balanced ones, and then characterize each type of signed networks in\nterms of the spectral properties of the signed weighted adjacency matrix. In\nparticular, we show that the spectral radius of the matrix with signs is\nsmaller than that without if and only if the signed network is strictly\nunbalanced. These properties are important to understand the dynamics on signed\nnetworks, both linear and nonlinear ones. Specifically, we find consistent\npatterns in a linear and a nonlinear dynamics theoretically, depending on their\ntype of balance. We also propose two measures to further characterize strictly\nunbalanced networks, motivated by perturbation theory. Finally, we numerically\nverify these properties through experiments on both synthetic and real\nnetworks.",
    "descriptor": "\nComments: 31 pages, 8 figures\n",
    "authors": [
      "Yu Tian",
      "Renaud Lambiotte"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Spectral Theory (math.SP)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.10158"
  },
  {
    "id": "arXiv:2212.10166",
    "title": "Protected Attributes Tell Us Who, Behavior Tells Us How: A Comparison of  Demographic and Behavioral Oversampling for Fair Student Success Modeling",
    "abstract": "Algorithms deployed in education can shape the learning experience and\nsuccess of a student. It is therefore important to understand whether and how\nsuch algorithms might create inequalities or amplify existing biases. In this\npaper, we analyze the fairness of models which use behavioral data to identify\nat-risk students and suggest two novel pre-processing approaches for bias\nmitigation. Based on the concept of intersectionality, the first approach\ninvolves intelligent oversampling on combinations of demographic attributes.\nThe second approach does not require any knowledge of demographic attributes\nand is based on the assumption that such attributes are a (noisy) proxy for\nstudent behavior. We hence propose to directly oversample different types of\nbehaviors identified in a cluster analysis. We evaluate our approaches on data\nfrom (i) an open-ended learning environment and (ii) a flipped classroom\ncourse. Our results show that both approaches can mitigate model bias. Directly\noversampling on behavior is a valuable alternative, when demographic metadata\nis not available. Source code and extended results are provided in\nhttps://github.com/epfl-ml4ed/behavioral-oversampling}{https://github.com/epfl-ml4ed/behavioral-oversampling .",
    "descriptor": "\nComments: Accepted as a full paper at LAK 2023: The 13th International Learning Analytics and Knowledge Conference, 13-17 of March 2023, Arlington\n",
    "authors": [
      "Jade Ma\u00ef Cock",
      "Muhammad Bilal",
      "Richard Davis",
      "Mirko Marras",
      "Tanja K\u00e4ser"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.10166"
  },
  {
    "id": "arXiv:2212.10167",
    "title": "Seafloor-Invariant Caustics Removal from Underwater Imagery",
    "abstract": "Mapping the seafloor with underwater imaging cameras is of significant\nimportance for various applications including marine engineering, geology,\ngeomorphology, archaeology and biology. For shallow waters, among the\nunderwater imaging challenges, caustics i.e., the complex physical phenomena\nresulting from the projection of light rays being refracted by the wavy\nsurface, is likely the most crucial one. Caustics is the main factor during\nunderwater imaging campaigns that massively degrade image quality and affect\nseverely any 2D mosaicking or 3D reconstruction of the seabed. In this work, we\npropose a novel method for correcting the radiometric effects of caustics on\nshallow underwater imagery. Contrary to the state-of-the-art, the developed\nmethod can handle seabed and riverbed of any anaglyph, correcting the images\nusing real pixel information, thus, improving image matching and 3D\nreconstruction processes. In particular, the developed method employs deep\nlearning architectures in order to classify image pixels to \"non-caustics\" and\n\"caustics\". Then, exploits the 3D geometry of the scene to achieve a pixel-wise\ncorrection, by transferring appropriate color values between the overlapping\nunderwater images. Moreover, to fill the current gap, we have collected,\nannotated and structured a real-world caustic dataset, namely R-CAUSTIC, which\nis openly available. Overall, based on the experimental results and validation\nthe developed methodology is quite promising in both detecting caustics and\nreconstructing their intensity.",
    "descriptor": "\nComments: Submitted to the IEEE Journal of Oceanic Engineering (IEEE-JOE), under review as of December 2022\n",
    "authors": [
      "Panagiotis Agrafiotis",
      "Konstantinos Karantzalos",
      "Andreas Georgopoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.10167"
  },
  {
    "id": "arXiv:2212.10168",
    "title": "Naamapadam: A Large-Scale Named Entity Annotated Data for Indic  Languages",
    "abstract": "We present, Naamapadam, the largest publicly available Named Entity\nRecognition (NER) dataset for the 11 major Indian languages from two language\nfamilies. In each language, it contains more than 400k sentences annotated with\na total of at least 100k entities from three standard entity categories\n(Person, Location and Organization) for 9 out of the 11 languages. The training\ndataset has been automatically created from the Samanantar parallel corpus by\nprojecting automatically tagged entities from an English sentence to the\ncorresponding Indian language sentence. We also create manually annotated\ntestsets for 8 languages containing approximately 1000 sentences per language.\nWe demonstrate the utility of the obtained dataset on existing testsets and the\nNaamapadam-test data for 8 Indic languages. We also release IndicNER, a\nmultilingual mBERT model fine-tuned on the Naamapadam training set. IndicNER\nachieves the best F1 on the Naamapadam-test set compared to an mBERT model\nfine-tuned on existing datasets. IndicNER achieves an F1 score of more than 80\nfor 7 out of 11 Indic languages. The dataset and models are available under\nopen-source licenses at https://ai4bharat.iitm.ac.in/naamapadam.",
    "descriptor": "\nComments: 14 pages, 5 figures, Work in Progress\n",
    "authors": [
      "Arnav Mhaske",
      "Harshit Kedia",
      "Sumanth Doddapaneni",
      "Mitesh M. Khapra",
      "Pratyush Kumar",
      "Rudra Murthy V",
      "Anoop Kunchukuttan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10168"
  },
  {
    "id": "arXiv:2212.10170",
    "title": "Hoyer regularizer is all you need for ultra low-latency spiking neural  networks",
    "abstract": "Spiking Neural networks (SNN) have emerged as an attractive spatio-temporal\ncomputing paradigm for a wide range of low-power vision tasks. However,\nstate-of-the-art (SOTA) SNN models either incur multiple time steps which\nhinder their deployment in real-time use cases or increase the training\ncomplexity significantly. To mitigate this concern, we present a training\nframework (from scratch) for one-time-step SNNs that uses a novel variant of\nthe recently proposed Hoyer regularizer. We estimate the threshold of each SNN\nlayer as the Hoyer extremum of a clipped version of its activation map, where\nthe clipping threshold is trained using gradient descent with our Hoyer\nregularizer. This approach not only downscales the value of the trainable\nthreshold, thereby emitting a large number of spikes for weight update with a\nlimited number of iterations (due to only one time step) but also shifts the\nmembrane potential values away from the threshold, thereby mitigating the\neffect of noise that can degrade the SNN accuracy. Our approach outperforms\nexisting spiking, binary, and adder neural networks in terms of the\naccuracy-FLOPs trade-off for complex image recognition tasks. Downstream\nexperiments on object detection also demonstrate the efficacy of our approach.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Gourav Datta",
      "Zeyu Liu",
      "Peter A. Beerel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10170"
  },
  {
    "id": "arXiv:2212.10171",
    "title": "Document-level Relation Extraction with Relation Correlations",
    "abstract": "Document-level relation extraction faces two overlooked challenges: long-tail\nproblem and multi-label problem. Previous work focuses mainly on obtaining\nbetter contextual representations for entity pairs, hardly address the above\nchallenges. In this paper, we analyze the co-occurrence correlation of\nrelations, and introduce it into DocRE task for the first time. We argue that\nthe correlations can not only transfer knowledge between data-rich relations\nand data-scarce ones to assist in the training of tailed relations, but also\nreflect semantic distance guiding the classifier to identify semantically close\nrelations for multi-label entity pairs. Specifically, we use relation embedding\nas a medium, and propose two co-occurrence prediction sub-tasks from both\ncoarse- and fine-grained perspectives to capture relation correlations.\nFinally, the learned correlation-aware embeddings are used to guide the\nextraction of relational facts. Substantial experiments on two popular DocRE\ndatasets are conducted, and our method achieves superior results compared to\nbaselines. Insightful analysis also demonstrates the potential of relation\ncorrelations to address the above challenges.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Ridong Han",
      "Tao Peng",
      "Benyou Wang",
      "Lu Liu",
      "Xiang Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10171"
  },
  {
    "id": "arXiv:2212.10173",
    "title": "On the Role of Parallel Data in Cross-lingual Transfer Learning",
    "abstract": "While prior work has established that the use of parallel data is conducive\nfor cross-lingual learning, it is unclear if the improvements come from the\ndata itself, or if it is the modeling of parallel interactions that matters.\nExploring this, we examine the usage of unsupervised machine translation to\ngenerate synthetic parallel data, and compare it to supervised machine\ntranslation and gold parallel data. We find that even model generated parallel\ndata can be useful for downstream tasks, in both a general setting (continued\npretraining) as well as the task-specific setting (translate-train), although\nour best results are still obtained using real parallel data. Our findings\nsuggest that existing multilingual models do not exploit the full potential of\nmonolingual data, and prompt the community to reconsider the traditional\ncategorization of cross-lingual learning approaches.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Machel Reid",
      "Mikel Artetxe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10173"
  },
  {
    "id": "arXiv:2212.10174",
    "title": "CGCV:Context Guided Correlation Volume for Optical Flow Neural Networks",
    "abstract": "Optical flow, which computes the apparent motion from a pair of video frames,\nis a critical tool for scene motion estimation. Correlation volume is the\ncentral component of optical flow computational neural models. It estimates the\npairwise matching costs between cross-frame features, and is then used to\ndecode optical flow. However, traditional correlation volume is frequently\nnoisy, outlier-prone, and sensitive to motion blur. We observe that, although\nthe recent RAFT algorithm also adopts the traditional correlation volume, its\nadditional context encoder provides semantically representative features to the\nflow decoder, implicitly compensating for the deficiency of the correlation\nvolume. However, the benefits of this context encoder has been barely discussed\nor exploited. In this paper, we first investigate the functionality of RAFT's\ncontext encoder, then propose a new Context Guided Correlation Volume (CGCV)\nvia gating and lifting schemes. CGCV can be universally integrated with\nRAFT-based flow computation methods for enhanced performance, especially\neffective in the presence of motion blur, de-focus blur and atmospheric\neffects. By incorporating the proposed CGCV with previous Global Motion\nAggregation (GMA) method, at a minor cost of 0.5% extra parameters, the rank of\nGMA is lifted by 23 places on KITTI 2015 Leader Board, and 3 places on Sintel\nLeader Board. Moreover, at a similar model size, our correlation volume\nachieves competitive or superior performance to state of the art peer\nsupervised models that employ Transformers or Graph Reasoning, as verified by\nextensive experiments.",
    "descriptor": "",
    "authors": [
      "Jiangpeng Li",
      "Yan Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10174"
  },
  {
    "id": "arXiv:2212.10177",
    "title": "A Differential Approach for Data and Classification Service based  Privacy-Preserving Machine Learning Model in Cloud Environment",
    "abstract": "The massive upsurge in computational and storage has driven the local data\nand machine learning applications to the cloud environment. The owners may not\nfully trust the cloud environment as it is managed by third parties. However,\nmaintaining privacy while sharing data and the classifier with several\nstakeholders is a critical challenge. This paper proposes a novel model based\non differential privacy and machine learning approaches that enable multiple\nowners to share their data for utilization and the classifier to render\nclassification services for users in the cloud environment. To process owners\ndata and classifier, the model specifies a communication protocol among various\nuntrustworthy parties. The proposed model also provides a robust mechanism to\npreserve the privacy of data and the classifier. The experiments are conducted\nfor a Naive Bayes classifier over numerous datasets to compute the proposed\nmodel efficiency. The achieved results demonstrate that the proposed model has\nhigh accuracy, precision, recall, and F1-score up to 94%, 95%, 94%, and 94%,\nand improvement up to 16.95%, 20.16%, 16.95%, and 23.33%, respectively,\ncompared with state-of-the-art works.",
    "descriptor": "",
    "authors": [
      "Rishabh Gupta",
      "Ashutosh Kumar Singh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.10177"
  },
  {
    "id": "arXiv:2212.10179",
    "title": "Toward Human-Like Evaluation for Natural Language Generation with Error  Analysis",
    "abstract": "The state-of-the-art language model-based automatic metrics, e.g. BARTScore,\nbenefiting from large-scale contextualized pre-training, have been successfully\nused in a wide range of natural language generation (NLG) tasks, including\nmachine translation, text summarization, and data-to-text. Recent studies show\nthat considering both major errors (e.g. mistranslated tokens) and minor errors\n(e.g. imperfections in fluency) can produce high-quality human judgments. This\ninspires us to approach the final goal of the evaluation metrics (human-like\nevaluations) by automatic error analysis. To this end, we augment BARTScore by\nincorporating the human-like error analysis strategies, namely BARTScore++,\nwhere the final score consists of both the evaluations of major errors and\nminor errors. Experimental results show that BARTScore++ can consistently\nimprove the performance of vanilla BARTScore and outperform existing\ntop-scoring metrics in 20 out of 25 test settings. We hope our technique can\nalso be extended to other pre-trained model-based metrics. We will release our\ncode and scripts to facilitate the community.",
    "descriptor": "\nComments: work in progress\n",
    "authors": [
      "Qingyu Lu",
      "Liang Ding",
      "Liping Xie",
      "Kanjian Zhang",
      "Derek F. Wong",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10179"
  },
  {
    "id": "arXiv:2212.10180",
    "title": "IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation metrics for  Indian Languages",
    "abstract": "The rapid growth of machine translation (MT) systems has necessitated\ncomprehensive studies to meta-evaluate evaluation metrics being used, which\nenables a better selection of metrics that best reflect MT quality.\nUnfortunately, most of the research focuses on high-resource languages, mainly\nEnglish, the observations for which may not always apply to other languages.\nIndian languages, having over a billion speakers, are linguistically different\nfrom English, and to date, there has not been a systematic study of evaluating\nMT systems from English into Indian languages. In this paper, we fill this gap\nby creating an MQM dataset consisting of 7000 fine-grained annotations,\nspanning 5 Indian languages and 7 MT systems, and use it to establish\ncorrelations between annotator scores and scores obtained using existing\nautomatic metrics. Our results show that pre-trained metrics, such as COMET,\nhave the highest correlations with annotator scores. Additionally, we find that\nthe metrics do not adequately capture fluency-based errors in Indian languages,\nand there is a need to develop metrics focused on Indian languages. We hope\nthat our dataset and analysis will help promote further research in this area.",
    "descriptor": "",
    "authors": [
      "Ananya B. Sai",
      "Vignesh Nagarajan",
      "Tanay Dixit",
      "Raj Dabre",
      "Anoop Kunchukuttan",
      "Pratyush Kumar",
      "Mitesh M. Khapra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10180"
  },
  {
    "id": "arXiv:2212.10185",
    "title": "Reasonable thickness determination for implicit porous sheet structure  using persistent homology",
    "abstract": "Porous structures are widely used in various industries because of their\nexcellent properties. Porous surfaces have no thickness and should be thickened\nto sheet structures for further fabrication. However, conventional methods for\ngenerating sheet structures are inefficient for porous surfaces because of the\ncomplexity of the internal structures. In this study, we propose a novel method\nfor generating porous sheet structures directly from point clouds sampled on a\nporous surface. The generated sheet structure is represented by an implicit\nB-spline function, which ensures smoothness and closure. Moreover, based on the\npersistent homology theory, the topology structure of the generated porous\nsheet structure can be controlled, and a reasonable range of the uniform\nthickness of the sheet structure can be calculated to ensure manufacturability\nand pore existence. Finally, the implicitly B-spline represented sheet\nstructures are sliced directly with the marching squares algorithm, and the\ncontours can be used for 3D printing. Experimental results show the superiority\nof the developed method in efficiency over the traditional methods.",
    "descriptor": "\nComments: 13 pages, 13 figures\n",
    "authors": [
      "Jiacong Yan",
      "Hongwei Lin"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2212.10185"
  },
  {
    "id": "arXiv:2212.10189",
    "title": "Do I have the Knowledge to Answer? Investigating Answerability of  Knowledge Base Questions",
    "abstract": "When answering natural language questions over knowledge bases (KBs),\nincompleteness in the KB can naturally lead to many questions being\nunanswerable. While answerability has been explored in other QA settings, it\nhas not been studied for QA over knowledge bases (KBQA). We first identify\nvarious forms of KB incompleteness that can result in a question being\nunanswerable. We then propose GrailQAbility, a new benchmark dataset, which\nsystematically modifies GrailQA (a popular KBQA dataset) to represent all these\nincompleteness issues. Testing two state-of-the-art KBQA models (trained on\noriginal GrailQA as well as our GrailQAbility), we find that both models\nstruggle to detect unanswerable questions, or sometimes detect them for the\nwrong reasons. Consequently, both models suffer significant loss in\nperformance, underscoring the need for further research in making KBQA systems\nrobust to unanswerability.",
    "descriptor": "",
    "authors": [
      "Mayur Patidar",
      "Avinash Singh",
      "Prayushi Faldu",
      "Lovekesh Vig",
      "Indrajit Bhattacharya",
      "Mausam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10189"
  },
  {
    "id": "arXiv:2212.10190",
    "title": "Pay Attention to Your Tone: Introducing a New Dataset for Polite  Language Rewrite",
    "abstract": "We introduce \\textsc{PoliteRewrite} -- a dataset for polite language rewrite\nwhich is a novel sentence rewrite task. Compared with previous text style\ntransfer tasks that can be mostly addressed by slight token- or phrase-level\nedits, polite language rewrite requires deep understanding and extensive\nsentence-level edits over an offensive and impolite sentence to deliver the\nsame message euphemistically and politely, which is more challenging -- not\nonly for NLP models but also for human annotators to rewrite with effort. To\nalleviate the human effort for efficient annotation, we first propose a novel\nannotation paradigm by a collaboration of human annotators and GPT-3.5 to\nannotate \\textsc{PoliteRewrite}. The released dataset has 10K polite sentence\nrewrites annotated collaboratively by GPT-3.5 and human, which can be used as\ngold standard for training, validation and test; and 100K high-quality polite\nsentence rewrites by GPT-3.5 without human review. We wish this work (The\ndataset (10K+100K) will be released soon) could contribute to the research on\nmore challenging sentence rewrite, and provoke more thought in future on\nresource annotation paradigm with the help of the large-scaled pretrained\nmodels.",
    "descriptor": "",
    "authors": [
      "Xun Wang",
      "Tao Ge",
      "Allen Mao",
      "Yuki Li",
      "Furu Wei",
      "Si-Qing Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10190"
  },
  {
    "id": "arXiv:2212.10191",
    "title": "Emotion Selectable End-to-End Text-based Speech Editing",
    "abstract": "Text-based speech editing allows users to edit speech by intuitively cutting,\ncopying, and pasting text to speed up the process of editing speech. In the\nprevious work, CampNet (context-aware mask prediction network) is proposed to\nrealize text-based speech editing, significantly improving the quality of\nedited speech. This paper aims at a new task: adding emotional effect to the\nediting speech during the text-based speech editing to make the generated\nspeech more expressive. To achieve this task, we propose Emo-CampNet (emotion\nCampNet), which can provide the option of emotional attributes for the\ngenerated speech in text-based speech editing and has the one-shot ability to\nedit unseen speakers' speech. Firstly, we propose an end-to-end\nemotion-selectable text-based speech editing model. The key idea of the model\nis to control the emotion of generated speech by introducing additional emotion\nattributes based on the context-aware mask prediction network. Secondly, to\nprevent the emotion of the generated speech from being interfered by the\nemotional components in the original speech, a neutral content generator is\nproposed to remove the emotion from the original speech, which is optimized by\nthe generative adversarial framework. Thirdly, two data augmentation methods\nare proposed to enrich the emotional and pronunciation information in the\ntraining set, which can enable the model to edit the unseen speaker's speech.\nThe experimental results that 1) Emo-CampNet can effectively control the\nemotion of the generated speech in the process of text-based speech editing;\nAnd can edit unseen speakers' speech. 2) Detailed ablation experiments further\nprove the effectiveness of emotional selectivity and data augmentation methods.\nThe demo page is available at https://hairuo55.github.io/Emo-CampNet/",
    "descriptor": "\nComments: Under review, 12 pages, 11 figures, demo page is available at this https URL\n",
    "authors": [
      "Tao Wang",
      "Jiangyan Yi",
      "Ruibo Fu",
      "Jianhua Tao",
      "Zhengqi Wen",
      "Chu Yuan Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.10191"
  },
  {
    "id": "arXiv:2212.10192",
    "title": "Adam: Dense Retrieval Distillation with Adaptive Dark Examples",
    "abstract": "To improve the performance of the dual-encoder retriever, one effective\napproach is knowledge distillation from the cross-encoder ranker. Existing\nworks construct the candidate passages following the supervised learning\nsetting where a query is paired with a positive passage and a batch of\nnegatives. However, through empirical observation, we find that even the hard\nnegatives from advanced methods are still too trivial for the teacher to\ndistinguish, preventing the teacher from transferring abundant dark knowledge\nto the student through its soft label. To alleviate this issue, we propose\nADAM, a knowledge distillation framework that can better transfer the dark\nknowledge held in the teacher with Adaptive Dark exAMples. Different from\nprevious works that only rely on one positive and hard negatives as candidate\npassages, we create dark examples that all have moderate relevance to the query\nthrough mixing-up and masking in discrete space. Furthermore, as the quality of\nknowledge held in different training instances varies as measured by the\nteacher's confidence score, we propose a self-paced distillation strategy that\nadaptively concentrates on a subset of high-quality instances to conduct our\ndark-example-based knowledge distillation to help the student learn better. We\nconduct experiments on two widely-used benchmarks and verify the effectiveness\nof our method.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Chang Liu",
      "Chongyang Tao",
      "Xiubo Geng",
      "Tao Shen",
      "Dongyan Zhao",
      "Can Xu",
      "Binxing Jiao",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10192"
  },
  {
    "id": "arXiv:2212.10196",
    "title": "Higher-order signal processing with the Dirac operator",
    "abstract": "The processing of signals on simplicial and cellular complexes defined by\nnodes, edges, and higher-order cells has recently emerged as a principled\nextension of graph signal processing for signals supported on more general\ntopological spaces. However, most works so far have considered signal\nprocessing problems for signals associated to only a single type of cell such\nas the processing of node signals, or edge signals, by considering an\nappropriately defined shift operator, like the graph Laplacian or the Hodge\nLaplacian. Here we introduce the Dirac operator as a novel kind of shift\noperator for signal processing on complexes. We discuss how the Dirac operator\nhas close relations but is distinct from the Hodge-Laplacian and examine its\nspectral properties. Importantly, the Dirac operator couples signals defined on\ncells of neighboring dimensions in a principled fashion. We demonstrate how\nthis enables us, e.g., to leverage node signals for the processing of edge\nflows.",
    "descriptor": "\nComments: 5 pages , 3 figures\n",
    "authors": [
      "Lucille Calmon",
      "Michael T. Schaub",
      "Ginestra Bianconi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.10196"
  },
  {
    "id": "arXiv:2212.10197",
    "title": "EIT: Enhanced Interactive Transformer",
    "abstract": "In this paper, we propose a novel architecture, the Enhanced Interactive\nTransformer (EIT), to address the issue of head degradation in self-attention\nmechanisms. Our approach replaces the traditional multi-head self-attention\nmechanism with the Enhanced Multi-Head Attention (EMHA) mechanism, which\nrelaxes the one-to-one mapping constraint among queries and keys, allowing each\nquery to attend to multiple keys. Furthermore, we introduce two interaction\nmodels, Inner-Subspace Interaction and Cross-Subspace Interaction, to fully\nutilize the many-to-many mapping capabilities of EMHA. Extensive experiments on\na wide range of tasks (e.g. machine translation, abstractive summarization,\ngrammar correction, language modelling and brain disease automatic diagnosis)\nshow its superiority with a very modest increase in model size.",
    "descriptor": "\nComments: 25 pages, 21 figures\n",
    "authors": [
      "Tong Zheng",
      "Bei Li",
      "Huiwen Bao",
      "Tong Xiao",
      "Jingbo Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10197"
  },
  {
    "id": "arXiv:2212.10198",
    "title": "Non-intrusive reduced order models for the accurate prediction of  bifurcating phenomena in compressible fluid dynamics",
    "abstract": "The present works is focused on studying bifurcating solutions in\ncompressible fluid dynamics. On one side, the physics of the problem is\nthoroughly investigated using high-fidelity simulations of the compressible\nNavier-Stokes equations discretised with the Discontinuous Galerkin method. On\nthe other side, from a numerical modelling point of view, two different\nnon-intrusive reduced order modelling techniques are employed to predict the\noverall behaviour of the bifurcation. Both approaches showed good agreement\nwith full-order simulations even in proximity of the bifurcating points where\nthe solution is particularly non-smooth.",
    "descriptor": "\nComments: 40 pages, 29 figures\n",
    "authors": [
      "Niccol\u00f2 Tonicello",
      "Andrea Lario",
      "Gianluigi Rozza",
      "Gianmarco Mengaldo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.10198"
  },
  {
    "id": "arXiv:2212.10200",
    "title": "Redistribution of Weights and Activations for AdderNet Quantization",
    "abstract": "Adder Neural Network (AdderNet) provides a new way for developing\nenergy-efficient neural networks by replacing the expensive multiplications in\nconvolution with cheaper additions (i.e.l1-norm). To achieve higher hardware\nefficiency, it is necessary to further study the low-bit quantization of\nAdderNet. Due to the limitation that the commutative law in multiplication does\nnot hold in l1-norm, the well-established quantization methods on convolutional\nnetworks cannot be applied on AdderNets. Thus, the existing AdderNet\nquantization techniques propose to use only one shared scale to quantize both\nthe weights and activations simultaneously. Admittedly, such an approach can\nkeep the commutative law in the l1-norm quantization process, while the\naccuracy drop after low-bit quantization cannot be ignored. To this end, we\nfirst thoroughly analyze the difference on distributions of weights and\nactivations in AdderNet and then propose a new quantization algorithm by\nredistributing the weights and the activations. Specifically, the pre-trained\nfull-precision weights in different kernels are clustered into different\ngroups, then the intra-group sharing and inter-group independent scales can be\nadopted. To further compensate the accuracy drop caused by the distribution\ndifference, we then develop a lossless range clamp scheme for weights and a\nsimple yet effective outliers clamp strategy for activations. Thus, the\nfunctionality of full-precision weights and the representation ability of\nfull-precision activations can be fully preserved. The effectiveness of the\nproposed quantization method for AdderNet is well verified on several\nbenchmarks, e.g., our 4-bit post-training quantized adder ResNet-18 achieves an\n66.5% top-1 accuracy on the ImageNet with comparable energy efficiency, which\nis about 8.5% higher than that of the previous AdderNet quantization methods.",
    "descriptor": "",
    "authors": [
      "Ying Nie",
      "Kai Han",
      "Haikang Diao",
      "Chuanjian Liu",
      "Enhua Wu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10200"
  },
  {
    "id": "arXiv:2212.10203",
    "title": "ParallelNet: Multi-mode Trajectory Prediction by Multi-mode Trajectory  Fusion",
    "abstract": "Level 5 Autonomous Driving, a technology that a fully automated vehicle (AV)\nrequires no human intervention, has raised serious concerns on safety and\nstability before widespread use. The capability of understanding and predicting\nfuture motion trajectory of road objects can help AV plan a path that is safe\nand easy to control. In this paper, we propose a network architecture that\nparallelizes multiple convolutional neural network backbones and fuses features\nto make multi-mode trajectory prediction. In the 2020 ICRA Nuscene Prediction\nchallenge, our model ranks 15th on the leaderboard across all teams.",
    "descriptor": "\nComments: 8 pages,8 figures\n",
    "authors": [
      "Fei Wu",
      "Luoyu Chen",
      "Hao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10203"
  },
  {
    "id": "arXiv:2212.10207",
    "title": "Graph Neural Networks in Computer Vision -- Architectures, Datasets and  Common Approaches",
    "abstract": "Graph Neural Networks (GNNs) are a family of graph networks inspired by\nmechanisms existing between nodes on a graph. In recent years there has been an\nincreased interest in GNN and their derivatives, i.e., Graph Attention Networks\n(GAT), Graph Convolutional Networks (GCN), and Graph Recurrent Networks (GRN).\nAn increase in their usability in computer vision is also observed. The number\nof GNN applications in this field continues to expand; it includes video\nanalysis and understanding, action and behavior recognition, computational\nphotography, image and video synthesis from zero or few shots, and many more.\nThis contribution aims to collect papers published about GNN-based approaches\ntowards computer vision. They are described and summarized from three\nperspectives. Firstly, we investigate the architectures of Graph Neural\nNetworks and their derivatives used in this area to provide accurate and\nexplainable recommendations for the ensuing investigations. As for the other\naspect, we also present datasets used in these works. Finally, using graph\nanalysis, we also examine relations between GNN-based studies in computer\nvision and potential sources of inspiration identified outside of this field.",
    "descriptor": "\nComments: 2022 International Joint Conference on Neural Networks (IJCNN), 2022\n",
    "authors": [
      "Maciej Krzywda",
      "Szymon \u0141ukasik",
      "Amir H. Gandomi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10207"
  },
  {
    "id": "arXiv:2212.10208",
    "title": "Factorizing Lattices by Interval Relations",
    "abstract": "This work investigates the factorization of finite lattices to implode\nselected intervals while preserving the remaining order structure. We examine\nhow complete congruence relations and complete tolerance relations can be\nutilized for this purpose and answer the question of finding the finest of\nthose relations to implode a given interval in the generated factor lattice. To\novercome the limitations of the factorization based on those relations, we\nintroduce a new lattice factorization that enables the imploding of selected\ndisjoint intervals of a finite lattice. To this end, we propose an interval\nrelation that generates this factorization. To obtain lattices rather than\narbitrary ordered sets, we restrict this approach to so-called pure intervals.\nFor our study, we will make use of methods from Formal Concept Analysis (FCA).\nWe will also provide a new FCA construction by introducing the enrichment of an\nincidence relation by a set of intervals in a formal context, to investigate\nthe approach for lattice-generating interval relations on the context side.",
    "descriptor": "\nComments: 23 pages, 13 figures\n",
    "authors": [
      "Maren Koyda",
      "Gerd Stumme"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2212.10208"
  },
  {
    "id": "arXiv:2212.10218",
    "title": "GanLM: Encoder-Decoder Pre-training with an Auxiliary Discriminator",
    "abstract": "Pre-trained models have achieved remarkable success in natural language\nprocessing (NLP). However, existing pre-training methods underutilize the\nbenefits of language understanding for generation. Inspired by the idea of\nGenerative Adversarial Networks (GANs), we propose a GAN-style model for\nencoder-decoder pre-training by introducing an auxiliary discriminator,\nunifying the ability of language understanding and generation in a single\nmodel. Our model, named as GanLM, is trained with two pre-training objectives:\nreplaced token detection and replaced token denoising. Specifically, given\nmasked source sentences, the generator outputs the target distribution and the\ndiscriminator predicts whether the target sampled tokens from distribution are\nincorrect. The target sentence is replaced with misclassified tokens to\nconstruct noisy previous context, which is used to generate the gold sentence.\nIn general, both tasks improve the ability of language understanding and\ngeneration by selectively using the denoising data. Extensive experiments in\nlanguage generation benchmarks show that GanLM with the powerful language\nunderstanding capability outperforms various strong pre-trained language models\n(PLMs) and achieves state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Jian Yang",
      "Shuming Ma",
      "Li Dong",
      "Shaohan Huang",
      "Haoyang Huang",
      "Yuwei Yin",
      "Dongdong Zhang",
      "Liqun Yang",
      "Zhoujun Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10218"
  },
  {
    "id": "arXiv:2212.10220",
    "title": "CSMPQ:Class Separability Based Mixed-Precision Quantization",
    "abstract": "Mixed-precision quantization has received increasing attention for its\ncapability of reducing the computational burden and speeding up the inference\ntime. Existing methods usually focus on the sensitivity of different network\nlayers, which requires a time-consuming search or training process. To this\nend, a novel mixed-precision quantization method, termed CSMPQ, is proposed.\nSpecifically, the TF-IDF metric that is widely used in natural language\nprocessing (NLP) is introduced to measure the class separability of layer-wise\nfeature maps. Furthermore, a linear programming problem is designed to derive\nthe optimal bit configuration for each layer. Without any iterative process,\nthe proposed CSMPQ achieves better compression trade-offs than the\nstate-of-the-art quantization methods. Specifically, CSMPQ achieves 73.03$\\%$\nTop-1 acc on ResNet-18 with only 59G BOPs for QAT, and 71.30$\\%$ top-1 acc with\nonly 1.5Mb on MobileNetV2 for PTQ.",
    "descriptor": "",
    "authors": [
      "Mingkai Wang",
      "Taisong Jin",
      "Miaohui Zhang",
      "Zhengtao Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10220"
  },
  {
    "id": "arXiv:2212.10221",
    "title": "SoK: Analysis of Root Causes and Defense Strategies for Attacks on  Microarchitectural Optimizations",
    "abstract": "Microarchitectural optimizations are expected to play a crucial role in\nensuring performance scalability in future technology nodes. However, recent\nattacks have demonstrated that microarchitectural optimizations, which were\nassumed to be secure, can be exploited. Moreover, new attacks surface at a\nrapid pace limiting the scope of existing defenses. These developments prompt\nthe need to review microarchitectural optimizations with an emphasis on\nsecurity, understand the attack landscape and the potential defense strategies.\nWe analyze timing-based side-channel attacks targeting a diverse set of\nmicroarchitectural optimizations. We provide a framework for analysing\nnon-transient and transient attacks, which highlights the similarities. We\nidentify the four root causes of timing-based side-channel attacks:\ndeterminism, sharing, access violation and information flow, through our\nsystematic analysis. Our key insight is that a subset (or all) of the root\ncauses are exploited by attacks and eliminating any of the exploited root\ncauses, in any attack step, is enough to provide protection. Leveraging our\nframework, we systematize existing defenses and show that they target these\nroot causes in the different attack steps.",
    "descriptor": "",
    "authors": [
      "Nadja Ramh\u00f6j Holtryd",
      "Madhavan Manivannan",
      "Per Stenstr\u00f6m"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2212.10221"
  },
  {
    "id": "arXiv:2212.10228",
    "title": "Automated Configuration and Usage of Strategy Portfolios for Bargaining",
    "abstract": "Bargaining can be used to resolve mixed-motive games in multi-agent systems.\nAlthough there is an abundance of negotiation strategies implemented in\nautomated negotiating agents, most agents are based on single fixed strategies,\nwhile it is widely acknowledged that there is no single best-performing\nstrategy for all negotiation settings.\nIn this paper, we focus on bargaining settings where opponents are repeatedly\nencountered, but the bargaining problems change. We introduce a novel method\nthat automatically creates and deploys a portfolio of complementary negotiation\nstrategies using a training set and optimise pay-off in never-before-seen\nbargaining settings through per-setting strategy selection. Our method relies\non the following contributions. We introduce a feature representation that\ncaptures characteristics for both the opponent and the bargaining problem. We\nmodel the behaviour of an opponent during a negotiation based on its actions,\nwhich is indicative of its negotiation strategy, in order to be more effective\nin future encounters.\nOur combination of feature-based methods generalises to new negotiation\nsettings, as in practice, over time, it selects effective counter strategies in\nfuture encounters. Our approach is tested in an ANAC-like tournament, and we\nshow that we are capable of winning such a tournament with a 5.6% increase in\npay-off compared to the runner-up agent.",
    "descriptor": "\nComments: Accepted to the Cooperative AI workshop @ NeurIPS 2021 (non-archival). Extended version accepted to AAMAS 2022: this https URL\n",
    "authors": [
      "Bram M. Renting",
      "Holger H. Hoos",
      "Catholijn M. Jonker"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2212.10228"
  },
  {
    "id": "arXiv:2212.10229",
    "title": "StyleDomain: Analysis of StyleSpace for Domain Adaptation of StyleGAN",
    "abstract": "Domain adaptation of GANs is a problem of fine-tuning the state-of-the-art\nGAN models (e.g. StyleGAN) pretrained on a large dataset to a specific domain\nwith few samples (e.g. painting faces, sketches, etc.). While there are a great\nnumber of methods that tackle this problem in different ways there are still\nmany important questions that remain unanswered. In this paper, we provide a\nsystematic and in-depth analysis of the domain adaptation problem of GANs,\nfocusing on the StyleGAN model. First, we perform a detailed exploration of the\nmost important parts of StyleGAN that are responsible for adapting the\ngenerator to a new domain depending on the similarity between the source and\ntarget domains. In particular, we show that affine layers of StyleGAN can be\nsufficient for fine-tuning to similar domains. Second, inspired by these\nfindings, we investigate StyleSpace to utilize it for domain adaptation. We\nshow that there exist directions in the StyleSpace that can adapt StyleGAN to\nnew domains. Further, we examine these directions and discover their many\nsurprising properties. Finally, we leverage our analysis and findings to\ndeliver practical improvements and applications in such standard tasks as\nimage-to-image translation and cross-domain morphing.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Aibek Alanov",
      "Vadim Titov",
      "Maksim Nakhodnov",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10229"
  },
  {
    "id": "arXiv:2212.10230",
    "title": "A Comprehensive Study and Comparison of the Robustness of 3D Object  Detectors Against Adversarial Attacks",
    "abstract": "Deep learning-based 3D object detectors have made significant progress in\nrecent years and have been deployed in a wide range of applications. It is\ncrucial to understand the robustness of detectors against adversarial attacks\nwhen employing detectors in security-critical applications. In this paper, we\nmake the first attempt to conduct a thorough evaluation and analysis of the\nrobustness of 3D detectors under adversarial attacks. Specifically, we first\nextend three kinds of adversarial attacks to the 3D object detection task to\nbenchmark the robustness of state-of-the-art 3D object detectors against\nattacks on KITTI and Waymo datasets, subsequently followed by the analysis of\nthe relationship between robustness and properties of detectors. Then, we\nexplore the transferability of cross-model, cross-task, and cross-data attacks.\nWe finally conduct comprehensive experiments of defense for 3D detectors,\ndemonstrating that simple transformations like flipping are of little help in\nimproving robustness when the strategy of transformation imposed on input point\ncloud data is exposed to attackers. Our findings will facilitate investigations\nin understanding and defending the adversarial attacks against 3D object\ndetectors to advance this field.",
    "descriptor": "",
    "authors": [
      "Yifan Zhang",
      "Junhui Hou",
      "Yixuan Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10230"
  },
  {
    "id": "arXiv:2212.10233",
    "title": "Pre-trained Language Models for Keyphrase Generation: A Thorough  Empirical Study",
    "abstract": "Neural models that do not rely on pre-training have excelled in the keyphrase\ngeneration task with large annotated datasets. Meanwhile, new approaches have\nincorporated pre-trained language models (PLMs) for their data efficiency.\nHowever, there lacks a systematic study of how the two types of approaches\ncompare and how different design choices can affect the performance of\nPLM-based models. To fill in this knowledge gap and facilitate a more informed\nuse of PLMs for keyphrase extraction and keyphrase generation, we present an\nin-depth empirical study. Formulating keyphrase extraction as sequence labeling\nand keyphrase generation as sequence-to-sequence generation, we perform\nextensive experiments in three domains. After showing that PLMs have\ncompetitive high-resource performance and state-of-the-art low-resource\nperformance, we investigate important design choices including in-domain PLMs,\nPLMs with different pre-training objectives, using PLMs with a parameter\nbudget, and different formulations for present keyphrases. Further results show\nthat (1) in-domain BERT-like PLMs can be used to build strong and\ndata-efficient keyphrase generation models; (2) with a fixed parameter budget,\nprioritizing model depth over width and allocating more layers in the encoder\nleads to better encoder-decoder models; and (3) introducing four in-domain\nPLMs, we achieve a competitive performance in the news domain and the\nstate-of-the-art performance in the scientific domain.",
    "descriptor": "",
    "authors": [
      "Di Wu",
      "Wasi Uddin Ahmad",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10233"
  },
  {
    "id": "arXiv:2212.10236",
    "title": "Self-Pair: Synthesizing Changes from Single Source for Object Change  Detection in Remote Sensing Imagery",
    "abstract": "For change detection in remote sensing, constructing a training dataset for\ndeep learning models is difficult due to the requirements of bi-temporal\nsupervision. To overcome this issue, single-temporal supervision which treats\nchange labels as the difference of two semantic masks has been proposed. This\nnovel method trains a change detector using two spatially unrelated images with\ncorresponding semantic labels such as building. However, training on unpaired\ndatasets could confuse the change detector in the case of pixels that are\nlabeled unchanged but are visually significantly different. In order to\nmaintain the visual similarity in unchanged area, in this paper, we emphasize\nthat the change originates from the source image and show that manipulating the\nsource image as an after-image is crucial to the performance of change\ndetection. Extensive experiments demonstrate the importance of maintaining\nvisual information between pre- and post-event images, and our method\noutperforms existing methods based on single-temporal supervision. code is\navailable at https://github.com/seominseok0429/Self-Pair-for-Change-Detection.",
    "descriptor": "\nComments: This paper has been accepted by WACV2023\n",
    "authors": [
      "Minseok Seo",
      "Hakjin Lee",
      "Yongjin Jeon",
      "Junghoon Seo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10236"
  },
  {
    "id": "arXiv:2212.10240",
    "title": "Diff-Glat: Diffusion Glancing Transformer for Parallel Sequence to  Sequence Learning",
    "abstract": "For sequence generation, both autoregressive models and non-autoregressive\nmodels have been developed in recent years. Autoregressive models can achieve\nhigh generation quality, but the sequential decoding scheme causes slow\ndecoding speed. Non-autoregressive models accelerate the inference speed with\nparallel decoding, while their generation quality still needs to be improved\ndue to the difficulty of modeling multi-modalities in data. To address the\nmulti-modality issue, we propose Diff-Glat, a non-autoregressive model featured\nwith a modality diffusion process and residual glancing training. The modality\ndiffusion process decomposes the modalities and reduces the modalities to learn\nfor each transition. And the residual glancing sampling further smooths the\nmodality learning procedures. Experiments demonstrate that, without using\nknowledge distillation data, Diff-Glat can achieve superior performance in both\ndecoding efficiency and accuracy compared with the autoregressive Transformer.",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Lihua Qian",
      "Mingxuan Wang",
      "Yang Liu",
      "Hao Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10240"
  },
  {
    "id": "arXiv:2212.10244",
    "title": "Thinking of data as an economic good: what it can (not) teach us about  data governance",
    "abstract": "This paper provides a systematic and critical review of the economics\nliterature on data as an economic good and draws lessons for data governance\nbased on that review. We conclude that focusing on data as an economic good in\ngovernance efforts is hardwired to only result in more data production and\ncannot deliver other societal goals contrary to what is often claimed in the\nliterature and policy. Data governance is often a red herring which distracts\nfrom other digital problems. The governance of digital society cannot rely\nexclusively on data-centric economic models. Instead, we propose a\npolitical-ecological approach to governing the digital society, defined by\necological thinking about governance problems and the awareness of the\npolitical nature of framing the problems and mapping their ecological makeup.",
    "descriptor": "",
    "authors": [
      "Nadezhda Purtova",
      "Gijs van Maanen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.10244"
  },
  {
    "id": "arXiv:2212.10245",
    "title": "Neural Belief Propagation Decoding of Quantum LDPC Codes Using  Overcomplete Check Matrices",
    "abstract": "The recent success in constructing asymptotically good quantum low-density\nparity-check (QLDPC) codes makes this family of codes a promising candidate for\nerror-correcting schemes in quantum computing. However, conventional belief\npropagation (BP) decoding of QLDPC codes does not yield satisfying performance\ndue to the presence of unavoidable short cycles in their Tanner graph and the\nspecial degeneracy phenomenon. In this work, we propose to decode QLDPC codes\nbased on a check matrix with redundant rows, generated from linear combinations\nof the rows in the original check matrix. This approach yields a significant\nimprovement in decoding performance with the additional advantage of very low\ndecoding latency. Furthermore, we propose a novel neural belief propagation\ndecoder based on the quaternary BP decoder of QLDPC codes which leads to\nfurther decoding performance improvements.",
    "descriptor": "\nComments: submitted to IEEE\n",
    "authors": [
      "Sisi Miao",
      "Alexander Schnerring",
      "Haizheng Li",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.10245"
  },
  {
    "id": "arXiv:2212.10247",
    "title": "Dominance for Containment Problems",
    "abstract": "In a containment problem, the goal is to preprocess a set of geometric\nobjects so that, given a geometric query object, we can report all the objects\ncontaining the query object. We consider the containment problem where input\nobjects are homothetic triangles and the query objects considered are line\nsegments, circles, and trapezoids with bases parallel to either axis. We show\nthat this problem can be solved using the 3-d query dominance problem. The\nsolutions presented can also be extended for higher dimensions.",
    "descriptor": "",
    "authors": [
      "Waseem Akram",
      "Sanjeev Saxena"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2212.10247"
  },
  {
    "id": "arXiv:2212.10252",
    "title": "MDL-based Compressing Sequential Rules",
    "abstract": "Nowadays, with the rapid development of the Internet, the era of big data has\ncome. The Internet generates huge amounts of data every day. However,\nextracting meaningful information from massive data is like looking for a\nneedle in a haystack. Data mining techniques can provide various feasible\nmethods to solve this problem. At present, many sequential rule mining (SRM)\nalgorithms are presented to find sequential rules in databases with sequential\ncharacteristics. These rules help people extract a lot of meaningful\ninformation from massive amounts of data. How can we achieve compression of\nmined results and reduce data size to save storage space and transmission time?\nUntil now, there has been little research on the compression of SRM. In this\npaper, combined with the Minimum Description Length (MDL) principle and under\nthe two metrics (support and confidence), we introduce the problem of\ncompression of SRM and also propose a solution named ComSR for MDL-based\ncompressing of sequential rules based on the designed sequential rule coding\nscheme. To our knowledge, we are the first to use sequential rules to encode an\nentire database. A heuristic method is proposed to find a set of compact and\nmeaningful sequential rules as much as possible. ComSR has two trade-off\nalgorithms, ComSR_non and ComSR_ful, based on whether the database can be\ncompletely compressed. Experiments done on a real dataset with different\nthresholds show that a set of compact and meaningful sequential rules can be\nfound. This shows that the proposed method works.",
    "descriptor": "\nComments: Preprint. 6 figures, 8 tables\n",
    "authors": [
      "Xinhong Chen",
      "Wensheng Gan",
      "Shicheng Wan",
      "Tianlong Gu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10252"
  },
  {
    "id": "arXiv:2212.10257",
    "title": "Original or Translated? On the Use of Parallel Data for Translation  Quality Estimation",
    "abstract": "Machine Translation Quality Estimation (QE) is the task of evaluating\ntranslation output in the absence of human-written references. Due to the\nscarcity of human-labeled QE data, previous works attempted to utilize the\nabundant unlabeled parallel corpora to produce additional training data with\npseudo labels. In this paper, we demonstrate a significant gap between parallel\ndata and real QE data: for QE data, it is strictly guaranteed that the source\nside is original texts and the target side is translated (namely\ntranslationese). However, for parallel data, it is indiscriminate and the\ntranslationese may occur on either source or target side. We compare the impact\nof parallel data with different translation directions in QE data augmentation,\nand find that using the source-original part of parallel corpus consistently\noutperforms its target-original counterpart. Moreover, since the WMT corpus\nlacks direction information for each parallel sentence, we train a classifier\nto distinguish source- and target-original bitext, and carry out an analysis of\ntheir difference in both style and domain. Together, these findings suggest\nusing source-original parallel data for QE data augmentation, which brings a\nrelative improvement of up to 4.0% and 6.4% compared to undifferentiated data\non sentence- and word-level QE tasks respectively.",
    "descriptor": "\nComments: work in progress\n",
    "authors": [
      "Baopu Qiu",
      "Liang Ding",
      "Di Wu",
      "Lin Shang",
      "Yibing Zhan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10257"
  },
  {
    "id": "arXiv:2212.10258",
    "title": "In and Out-of-Domain Text Adversarial Robustness via Label Smoothing",
    "abstract": "Recently it has been shown that state-of-the-art NLP models are vulnerable to\nadversarial attacks, where the predictions of a model can be drastically\naltered by slight modifications to the input (such as synonym substitutions).\nWhile several defense techniques have been proposed, and adapted, to the\ndiscrete nature of text adversarial attacks, the benefits of general-purpose\nregularization methods such as label smoothing for language models, have not\nbeen studied. In this paper, we study the adversarial robustness provided by\nvarious label smoothing strategies in foundational models for diverse NLP tasks\nin both in-domain and out-of-domain settings. Our experiments show that label\nsmoothing significantly improves adversarial robustness in pre-trained models\nlike BERT, against various popular attacks. We also analyze the relationship\nbetween prediction confidence and robustness, showing that label smoothing\nreduces over-confident errors on adversarial examples.",
    "descriptor": "\nComments: Preprint. Under Submission\n",
    "authors": [
      "Yahan Yang",
      "Soham Dan",
      "Dan Roth",
      "Insup Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10258"
  },
  {
    "id": "arXiv:2212.10263",
    "title": "Eff-3DPSeg: 3D organ-level plant shoot segmentation using  annotation-efficient point clouds",
    "abstract": "Reliable and automated 3D plant shoot segmentation is a core prerequisite for\nthe extraction of plant phenotypic traits at the organ level. Combining deep\nlearning and point clouds can provide effective ways to address the challenge.\nHowever, fully supervised deep learning methods require datasets to be\npoint-wise annotated, which is extremely expensive and time-consuming. In our\nwork, we proposed a novel weakly supervised framework, Eff-3DPSeg, for 3D plant\nshoot segmentation. First, high-resolution point clouds of soybean were\nreconstructed using a low-cost photogrammetry system, and the Meshlab-based\nPlant Annotator was developed for plant point cloud annotation. Second, a\nweakly-supervised deep learning method was proposed for plant organ\nsegmentation. The method contained: (1) Pretraining a self-supervised network\nusing Viewpoint Bottleneck loss to learn meaningful intrinsic structure\nrepresentation from the raw point clouds; (2) Fine-tuning the pre-trained model\nwith about only 0.5% points being annotated to implement plant organ\nsegmentation. After, three phenotypic traits (stem diameter, leaf width, and\nleaf length) were extracted. To test the generality of the proposed method, the\npublic dataset Pheno4D was included in this study. Experimental results showed\nthat the weakly-supervised network obtained similar segmentation performance\ncompared with the fully-supervised setting. Our method achieved 95.1%, 96.6%,\n95.8% and 92.2% in the Precision, Recall, F1-score, and mIoU for stem leaf\nsegmentation and 53%, 62.8% and 70.3% in the AP, AP@25, and AP@50 for leaf\ninstance segmentation. This study provides an effective way for characterizing\n3D plant architecture, which will become useful for plant breeders to enhance\nselection processes.",
    "descriptor": "\nComments: This paper has been submitted to Plant Phenomics\n",
    "authors": [
      "Liyi Luo",
      "Xintong Jiang",
      "Yu Yang",
      "Eugene Roy Antony Samy",
      "Mark Lefsrud",
      "Valerio Hoyos-Villegas",
      "Shangpeng Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10263"
  },
  {
    "id": "arXiv:2212.10264",
    "title": "ReCode: Robustness Evaluation of Code Generation Models",
    "abstract": "Code generation models have achieved impressive performance. However, they\ntend to be brittle as slight edits to a prompt could lead to very different\ngenerations; these robustness properties, critical for user experience when\ndeployed in real-life applications, are not well understood. Most existing\nworks on robustness in text or code tasks have focused on classification, while\nrobustness in generation tasks is an uncharted area and to date there is no\ncomprehensive benchmark for robustness in code generation. In this paper, we\npropose ReCode, a comprehensive robustness evaluation benchmark for code\ngeneration models. We customize over 30 transformations specifically for code\non docstrings, function and variable names, code syntax, and code format. They\nare carefully designed to be natural in real-life coding practice, preserve the\noriginal semantic meaning, and thus provide multifaceted assessments of a\nmodel's robustness performance. With human annotators, we verified that over\n90% of the perturbed prompts do not alter the semantic meaning of the original\nprompt. In addition, we define robustness metrics for code generation models\nconsidering the worst-case behavior under each type of perturbation, taking\nadvantage of the fact that executing the generated code can serve as objective\nevaluation. We demonstrate ReCode on SOTA models using HumanEval, MBPP, as well\nas function completion tasks derived from them. Interesting observations\ninclude: better robustness for CodeGen over InCoder and GPT-J; models are most\nsensitive to syntax perturbations; more challenging robustness evaluation on\nMBPP over HumanEval.",
    "descriptor": "\nComments: Code and data available at this https URL\n",
    "authors": [
      "Shiqi Wang",
      "Zheng Li",
      "Haifeng Qian",
      "Chenghao Yang",
      "Zijian Wang",
      "Mingyue Shang",
      "Varun Kumar",
      "Samson Tan",
      "Baishakhi Ray",
      "Parminder Bhatia",
      "Ramesh Nallapati",
      "Murali Krishna Ramanathan",
      "Dan Roth",
      "Bing Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.10264"
  },
  {
    "id": "arXiv:2212.10265",
    "title": "High-resolution canopy height map in the Landes forest (France) based on  GEDI, Sentinel-1, and Sentinel-2 data with a deep learning approach",
    "abstract": "In intensively managed forests in Europe, where forests are divided into\nstands of small size and may show heterogeneity within stands, a high spatial\nresolution (10 - 20 meters) is arguably needed to capture the differences in\ncanopy height. In this work, we developed a deep learning model based on\nmulti-stream remote sensing measurements to create a high-resolution canopy\nheight map over the \"Landes de Gascogne\" forest in France, a large maritime\npine plantation of 13,000 km$^2$ with flat terrain and intensive management.\nThis area is characterized by even-aged and mono-specific stands, of a typical\nlength of a few hundred meters, harvested every 35 to 50 years. Our deep\nlearning U-Net model uses multi-band images from Sentinel-1 and Sentinel-2 with\ncomposite time averages as input to predict tree height derived from GEDI\nwaveforms. The evaluation is performed with external validation data from\nforest inventory plots and a stereo 3D reconstruction model based on Skysat\nimagery available at specific locations. We trained seven different U-net\nmodels based on a combination of Sentinel-1 and Sentinel-2 bands to evaluate\nthe importance of each instrument in the dominant height retrieval. The model\noutputs allow us to generate a 10 m resolution canopy height map of the whole\n\"Landes de Gascogne\" forest area for 2020 with a mean absolute error of 2.02 m\non the Test dataset. The best predictions were obtained using all available\nsatellite layers from Sentinel-1 and Sentinel-2 but using only one satellite\nsource also provided good predictions. For all validation datasets in\nconiferous forests, our model showed better metrics than previous canopy height\nmodels available in the same region.",
    "descriptor": "\nComments: 39 pages, 16 figures + supplementary contents\n",
    "authors": [
      "Martin Schwartz",
      "Philippe Ciais",
      "Catherine Ottl\u00e9",
      "Aurelien De Truchis",
      "Cedric Vega",
      "Ibrahim Fayad",
      "Martin Brandt",
      "Rasmus Fensholt",
      "Nicolas Baghdadi",
      "Fran\u00e7ois Morneau",
      "David Morin",
      "Dominique Guyon",
      "Sylvia Dayau",
      "Jean-Pierre Wigneron"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.10265"
  },
  {
    "id": "arXiv:2212.10267",
    "title": "On exact truncation of backward waves in elastrodynamics",
    "abstract": "For elastic wave scattering problems in unbounded anisotropic media, the\nexistence of backward waves makes classic truncation techniques fail\ncompletely. This paper is concerned with an exact truncation technique for\nterminating backward elastic waves. We derive a closed form of elastrodynamic\nGreen's tensor based on the method of Fourier transform and design two\nfundamental principles to ensure its physical correctness. We present a\nrigorous theory to completely classify the propagation behavior of Green's\ntensor, thus proving a conjecture posed by B\\'ecache, Fauqueux and Joly (J.\nComp. Phys., 188, 2003) regarding a necessary and suffcient condition of the\nnon-existence of backward waves. Using Green's tensor, we propose a new\nradiation condition to characterize anistropic scattered waves at infinity.\nThis leads to an exact transparent boundary condition (TBC) to truncate the\nunbounded domain, regardless the existence of backward waves or not. We develop\na fast algorithm to evaluate Green's tensor and a high-accuracy scheme to\ndiscretize the TBC. A number of experiments are carried out to validate the\ncorrectness and efficiency of the new TBC.",
    "descriptor": "\nComments: 33 pages, 20 figures\n",
    "authors": [
      "Wangtao Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.10267"
  },
  {
    "id": "arXiv:2212.10273",
    "title": "Managing Large Dataset Gaps in Urban Air Quality Prediction:  DCU-Insight-AQ at MediaEval 2022",
    "abstract": "Calculating an Air Quality Index (AQI) typically uses data streams from air\nquality sensors deployed at fixed locations and the calculation is a real time\nprocess. If one or a number of sensors are broken or offline, then the real\ntime AQI value cannot be computed. Estimating AQI values for some point in the\nfuture is a predictive process and uses historical AQI values to train and\nbuild models. In this work we focus on gap filling in air quality data where\nthe task is to predict the AQI at 1, 5 and 7 days into the future. The scenario\nis where one or a number of air, weather and traffic sensors are offline and\nexplores prediction accuracy under such situations. The work is part of the\nMediaEval'2022 Urban Air: Urban Life and Air Pollution task submitted by the\nDCU-Insight-AQ team and uses multimodal and crossmodal data consisting of AQI,\nweather and CCTV traffic images for air pollution prediction.",
    "descriptor": "\nComments: 5 pages, 1 Figure, 1 Table\n",
    "authors": [
      "Dinh Viet Cuong",
      "Phuc H. Le-Khac",
      "Adam Stapleton",
      "Elke Eichlemann",
      "Mark Roantree",
      "Alan F. Smeaton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.10273"
  },
  {
    "id": "arXiv:2212.10275",
    "title": "ARO-Net: Learning Neural Fields from Anchored Radial Observations",
    "abstract": "We introduce anchored radial observations (ARO), a novel shape encoding for\nlearning neural field representation of shapes that is category-agnostic and\ngeneralizable amid significant shape variations. The main idea behind our work\nis to reason about shapes through partial observations from a set of\nviewpoints, called anchors. We develop a general and unified shape\nrepresentation by employing a fixed set of anchors, via Fibonacci sampling, and\ndesigning a coordinate-based deep neural network to predict the occupancy value\nof a query point in space. Differently from prior neural implicit models, that\nuse global shape feature, our shape encoder operates on contextual,\nquery-specific features. To predict point occupancy, locally observed shape\ninformation from the perspective of the anchors surrounding the input query\npoint are encoded and aggregated through an attention module, before implicit\ndecoding is performed. We demonstrate the quality and generality of our\nnetwork, coined ARO-Net, on surface reconstruction from sparse point clouds,\nwith tests on novel and unseen object categories, \"one-shape\" training, and\ncomparisons to state-of-the-art neural and classical methods for reconstruction\nand tessellation.",
    "descriptor": "",
    "authors": [
      "Yizhi Wang",
      "Zeyu Huang",
      "Ariel Shamir",
      "Hui Huang",
      "Hao Zhang",
      "Ruizhen Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2212.10275"
  },
  {
    "id": "arXiv:2212.10276",
    "title": "Identifying and Manipulating the Personality Traits of Language Models",
    "abstract": "Psychology research has long explored aspects of human personality such as\nextroversion, agreeableness and emotional stability. Categorizations like the\n`Big Five' personality traits are commonly used to assess and diagnose\npersonality types. In this work, we explore the question of whether the\nperceived personality in language models is exhibited consistently in their\nlanguage generation. For example, is a language model such as GPT2 likely to\nrespond in a consistent way if asked to go out to a party? We also investigate\nwhether such personality traits can be controlled. We show that when provided\ndifferent types of contexts (such as personality descriptions, or answers to\ndiagnostic questions about personality traits), language models such as BERT\nand GPT2 can consistently identify and reflect personality markers in those\ncontexts. This behavior illustrates an ability to be manipulated in a highly\npredictable way, and frames them as tools for identifying personality traits\nand controlling personas in applications such as dialog systems. We also\ncontribute a crowd-sourced data-set of personality descriptions of human\nsubjects paired with their `Big Five' personality assessment data, and a\ndata-set of personality descriptions collated from Reddit.",
    "descriptor": "",
    "authors": [
      "Graham Caron",
      "Shashank Srivastava"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10276"
  },
  {
    "id": "arXiv:2212.10278",
    "title": "Fully and Weakly Supervised Referring Expression Segmentation with  End-to-End Learning",
    "abstract": "Referring Expression Segmentation (RES), which is aimed at localizing and\nsegmenting the target according to the given language expression, has drawn\nincreasing attention. Existing methods jointly consider the localization and\nsegmentation steps, which rely on the fused visual and linguistic features for\nboth steps. We argue that the conflict between the purpose of identifying an\nobject and generating a mask limits the RES performance. To solve this problem,\nwe propose a parallel position-kernel-segmentation pipeline to better isolate\nand then interact the localization and segmentation steps. In our pipeline,\nlinguistic information will not directly contaminate the visual feature for\nsegmentation. Specifically, the localization step localizes the target object\nin the image based on the referring expression, and then the visual kernel\nobtained from the localization step guides the segmentation step. This pipeline\nalso enables us to train RES in a weakly-supervised way, where the pixel-level\nsegmentation labels are replaced by click annotations on center and corner\npoints. The position head is fully-supervised and trained with the click\nannotations as supervision, and the segmentation head is trained with\nweakly-supervised segmentation losses. To validate our framework on a\nweakly-supervised setting, we annotated three RES benchmark datasets (RefCOCO,\nRefCOCO+ and RefCOCOg) with click annotations.Our method is simple but\nsurprisingly effective, outperforming all previous state-of-the-art RES methods\non fully- and weakly-supervised settings by a large margin. The benchmark code\nand datasets will be released.",
    "descriptor": "",
    "authors": [
      "Hui Li",
      "Mingjie Sun",
      "Jimin Xiao",
      "Eng Gee Lim",
      "Yao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10278"
  },
  {
    "id": "arXiv:2212.10280",
    "title": "Internal Diverse Image Completion",
    "abstract": "Image completion is widely used in photo restoration and editing\napplications, e.g. for object removal. Recently, there has been a surge of\nresearch on generating diverse completions for missing regions. However,\nexisting methods require large training sets from a specific domain of\ninterest, and often fail on general-content images. In this paper, we propose a\ndiverse completion method that does not require a training set and can thus\ntreat arbitrary images from any domain. Our internal diverse completion (IDC)\napproach draws inspiration from recent single-image generative models that are\ntrained on multiple scales of a single image, adapting them to the extreme\nsetting in which only a small portion of the image is available for training.\nWe illustrate the strength of IDC on several datasets, using both user studies\nand quantitative comparisons.",
    "descriptor": "",
    "authors": [
      "Noa Alkobi",
      "Tamar Rott Shaham",
      "Tomer Michaeli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10280"
  },
  {
    "id": "arXiv:2212.10284",
    "title": "Steel Phase Kinetics Modeling using Symbolic Regression",
    "abstract": "We describe an approach for empirical modeling of steel phase kinetics based\non symbolic regression and genetic programming. The algorithm takes processed\ndata gathered from dilatometer measurements and produces a system of\ndifferential equations that models the phase kinetics. Our initial results\ndemonstrate that the proposed approach allows to identify compact differential\nequations that fit the data. The model predicts ferrite, pearlite and bainite\nformation for a single steel type. Martensite is not yet included in the model.\nFuture work shall incorporate martensite and generalize to multiple steel types\nwith different chemical compositions.",
    "descriptor": "\nComments: 24th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC 2022)\n",
    "authors": [
      "David Piringer",
      "Bernhard Bloder",
      "Gabriel Kronberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2212.10284"
  },
  {
    "id": "arXiv:2212.10288",
    "title": "Personalized PageRank on Evolving Graphs with an Incremental  Index-Update Scheme",
    "abstract": "{\\em Personalized PageRank (PPR)} stands as a fundamental proximity measure\nin graph mining. Since computing an exact SSPPR query answer is prohibitive,\nmost existing solutions turn to approximate queries with guarantees. The\nstate-of-the-art solutions for approximate SSPPR queries are index-based and\nmainly focus on static graphs, while real-world graphs are usually dynamically\nchanging. However, existing index-update schemes can not achieve a sub-linear\nupdate time. Motivated by this, we present an efficient indexing scheme to\nmaintain indexed random walks in expected $O(1)$ time after each graph update.\nTo reduce the space consumption, we further propose a new sampling scheme to\nremove the auxiliary data structure for vertices while still supporting $O(1)$\nindex update cost on evolving graphs. Extensive experiments show that our\nupdate scheme achieves orders of magnitude speed-up on update performance over\nexisting index-based dynamic schemes without sacrificing the query efficiency.",
    "descriptor": "",
    "authors": [
      "Guanhao Hou",
      "Qintian Guo",
      "Fangyuan Zhang",
      "Sibo Wang",
      "Zhewei Wei"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.10288"
  },
  {
    "id": "arXiv:2212.10289",
    "title": "ATLAS: An IoT Architecture and Secure Open-source Networking Stack for  Anonymous Localization and Tracking Using Smartphones and Bluetooth Beacons",
    "abstract": "Bluetooth (BT) has revolutionized close-range communication enabling smart\ncapabilities in everyday devices through wireless technology. One of the most\nimportant sub-domains of Internet-of-Things (IoT) specializes in the usage of\nBT technologies to develop smart homes and environments, which include\nhospitals, buildings, shopping facilities, etc. to offer a wide-range of\nfeatures, like instantaneous and remote access to ventilation, lighting,\nsecurity, localization, and tracking. However, the deployment of such features\nin smart infrastructures are typically unaccompanied by appropriate security\nmeasures that safeguard the data and protect its users. Towards this, we\npropose the ATLAS framework, which is composed of our novel IoT architecture\nand secure networking stack that can be used to anonymously localize and track\nsmartphones and wearables by deploying multiple Bluetooth Low Energy (BLE)\nbeacons across the environment. The proposed networking stack enables varying\nlevels of encryption across all layers of the communication stack to ensure an\neasy-to-adopt, secure-by-design network architecture. We also deploy a novel\ndata transformation and fingerprinting-based localization algorithm, which is\nhighly effective in localizing user devices within a given area. The ATLAS\nframework is open-sourced at https://atlas-tuw.sourceforge.io to enable\nwide-spread adoption and further research and development.",
    "descriptor": "",
    "authors": [
      "Bharath Srinivas Prabakaran",
      "Felix Fasching",
      "Juri Schreib",
      "Andreas Steininger",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.10289"
  },
  {
    "id": "arXiv:2212.10291",
    "title": "Quantifying and Visualizing Vascular Branching Geometry with Micro-CT:  Normalization of Intra- and Inter-Specimen Variations",
    "abstract": "Micro-CT images of the renal arteries of intact rat kidneys, which had their\nvasculature injected with the contrast agent polymer Microfil, were\ncharacterized. Measurement of inter-branch segment properties and the\nhierarchical structure of the vessel trees were computed by an automated\nalgorithmic approach. The perfusion territories of the different kidneys, as\nwell as the local diameters of the segmented vasculature were mapped onto the\nrepresentative structures and visually explored. Various parameters were\ncompared in order to outline key geometrical properties, properties which were\nshown to not have a wide range of inter-specimen variation. It is shown that\nthe fractal scaling in non-symmetric branching reveals itself differently, than\nin symmetric branching (e.g., in the lung the mean bronchial diameters at each\ngeneration are closely related). Also, perfused tissue is shown to have very\nlittle inter-specimen variation and therefore could be used in future studies\nrelated to characterizing various disease states of tissues and organs based on\nvascular branching geometry.",
    "descriptor": "",
    "authors": [
      "Timothy L. Kline"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10291"
  },
  {
    "id": "arXiv:2212.10292",
    "title": "Towards Unsupervised Visual Reasoning: Do Off-The-Shelf Features Know  How to Reason?",
    "abstract": "Recent advances in visual representation learning allowed to build an\nabundance of powerful off-the-shelf features that are ready-to-use for numerous\ndownstream tasks. This work aims to assess how well these features preserve\ninformation about the objects, such as their spatial location, their visual\nproperties and their relative relationships. We propose to do so by evaluating\nthem in the context of visual reasoning, where multiple objects with complex\nrelationships and different attributes are at play. More specifically, we\nintroduce a protocol to evaluate visual representations for the task of Visual\nQuestion Answering. In order to decouple visual feature extraction from\nreasoning, we design a specific attention-based reasoning module which is\ntrained on the frozen visual representations to be evaluated, in a spirit\nsimilar to standard feature evaluations relying on shallow networks. We compare\ntwo types of visual representations, densely extracted local features and\nobject-centric ones, against the performances of a perfect image representation\nusing ground truth. Our main findings are two-fold. First, despite excellent\nperformances on classical proxy tasks, such representations fall short for\nsolving complex reasoning problem. Second, object-centric features better\npreserve the critical information necessary to perform visual reasoning. In our\nproposed framework we show how to methodologically approach this evaluation.",
    "descriptor": "",
    "authors": [
      "Monika Wysocza\u0144ska",
      "Tom Monnier",
      "Tomasz Trzci\u0144ski",
      "David Picard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10292"
  },
  {
    "id": "arXiv:2212.10295",
    "title": "Interacting with New York City Data by HoloLens through Remote Rendering",
    "abstract": "In the digital era, Extended Reality (XR) is considered the next frontier.\nHowever, XR systems are computationally intensive, and they must be implemented\nwithin strict latency constraints. Thus, XR devices with finite computing\nresources are limited in terms of quality of experience (QoE) they can offer,\nparticularly in cases of big 3D data. This problem can be effectively addressed\nby offloading the highly intensive rendering tasks to a remote server.\nTherefore, we proposed a remote rendering enabled XR system that presents the\n3D city model of New York City on the Microsoft HoloLens. Experimental results\nindicate that remote rendering outperforms local rendering for the New York\nCity model with significant improvement in average QoE by at least 21%.\nAdditionally, we clarified the network traffic pattern in the proposed XR\nsystem developed under the OpenXR standard.",
    "descriptor": "",
    "authors": [
      "Zijian Long",
      "Haiwei Dong",
      "Abdulmotaleb El Saddik"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Human-Computer Interaction (cs.HC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.10295"
  },
  {
    "id": "arXiv:2212.10297",
    "title": "Extrinsic Evaluation of Machine Translation Metrics",
    "abstract": "Automatic machine translation (MT) metrics are widely used to distinguish the\ntranslation qualities of machine translation systems across relatively large\ntest sets (system-level evaluation). However, it is unclear if automatic\nmetrics are reliable at distinguishing good translations from bad translations\nat the sentence level (segment-level evaluation). In this paper, we investigate\nhow useful MT metrics are at detecting the success of a machine translation\ncomponent when placed in a larger platform with a downstream task. We evaluate\nthe segment-level performance of the most widely used MT metrics (chrF, COMET,\nBERTScore, etc.) on three downstream cross-lingual tasks (dialogue state\ntracking, question answering, and semantic parsing). For each task, we only\nhave access to a monolingual task-specific model. We calculate the correlation\nbetween the metric's ability to predict a good/bad translation with the\nsuccess/failure on the final task for the Translate-Test setup. Our experiments\ndemonstrate that all metrics exhibit negligible correlation with the extrinsic\nevaluation of the downstream outcomes. We also find that the scores provided by\nneural metrics are not interpretable mostly because of undefined ranges. Our\nanalysis suggests that future MT metrics be designed to produce error labels\nrather than scores to facilitate extrinsic evaluation.",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Nikita Moghe",
      "Tom Sherborne",
      "Mark Steedman",
      "Alexandra Birch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10297"
  },
  {
    "id": "arXiv:2212.10299",
    "title": "Cell-Free Data Power Control Via Scalable Multi-Objective Bayesian  Optimisation",
    "abstract": "Cell-free multi-user multiple input multiple output networks are a promising\nalternative to classical cellular architectures, since they have the potential\nto provide uniform service quality and high resource utilisation over the\nentire coverage area of the network. To realise this potential, previous works\nhave developed radio resource management mechanisms using various optimisation\nengines. In this work, we consider the problem of overall ergodic spectral\nefficiency maximisation in the context of uplink-downlink data power control in\ncell-free networks. To solve this problem in large networks, and to address\nconvergence-time limitations, we apply scalable multi-objective Bayesian\noptimisation. Furthermore, we discuss how an intersection of multi-fidelity\nemulation and Bayesian optimisation can improve radio resource management in\ncell-free networks.",
    "descriptor": "\nComments: 2022 IEEE 33rd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)\n",
    "authors": [
      "Sergey S. Tambovskiy",
      "G\u00e1bor Fodor",
      "Hugo Tullberg"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.10299"
  },
  {
    "id": "arXiv:2212.10305",
    "title": "Which Pixel to Annotate: a Label-Efficient Nuclei Segmentation Framework",
    "abstract": "Recently deep neural networks, which require a large amount of annotated\nsamples, have been widely applied in nuclei instance segmentation of H\\&E\nstained pathology images. However, it is inefficient and unnecessary to label\nall pixels for a dataset of nuclei images which usually contain similar and\nredundant patterns. Although unsupervised and semi-supervised learning methods\nhave been studied for nuclei segmentation, very few works have delved into the\nselective labeling of samples to reduce the workload of annotation. Thus, in\nthis paper, we propose a novel full nuclei segmentation framework that chooses\nonly a few image patches to be annotated, augments the training set from the\nselected samples, and achieves nuclei segmentation in a semi-supervised manner.\nIn the proposed framework, we first develop a novel consistency-based patch\nselection method to determine which image patches are the most beneficial to\nthe training. Then we introduce a conditional single-image GAN with a\ncomponent-wise discriminator, to synthesize more training samples. Lastly, our\nproposed framework trains an existing segmentation model with the above\naugmented samples. The experimental results show that our proposed method could\nobtain the same-level performance as a fully-supervised baseline by annotating\nless than 5% pixels on some benchmarks.",
    "descriptor": "\nComments: IEEE TMI 2022, Released code: this https URL\n",
    "authors": [
      "Wei Lou",
      "Haofeng Li",
      "Guanbin Li",
      "Xiaoguang Han",
      "Xiang Wan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10305"
  },
  {
    "id": "arXiv:2212.10306",
    "title": "A Pattern Discovery Approach to Multivariate Time Series Forecasting",
    "abstract": "Multivariate time series forecasting constitutes important functionality in\ncyber-physical systems, whose prediction accuracy can be improved significantly\nby capturing temporal and multivariate correlations among multiple time series.\nState-of-the-art deep learning methods fail to construct models for full time\nseries because model complexity grows exponentially with time series length.\nRather, these methods construct local temporal and multivariate correlations\nwithin subsequences, but fail to capture correlations among subsequences, which\nsignificantly affect their forecasting accuracy. To capture the temporal and\nmultivariate correlations among subsequences, we design a pattern discovery\nmodel, that constructs correlations via diverse pattern functions. While the\ntraditional pattern discovery method uses shared and fixed pattern functions\nthat ignore the diversity across time series. We propose a novel pattern\ndiscovery method that can automatically capture diverse and complex time series\npatterns. We also propose a learnable correlation matrix, that enables the\nmodel to capture distinct correlations among multiple time series. Extensive\nexperiments show that our model achieves state-of-the-art prediction accuracy.",
    "descriptor": "",
    "authors": [
      "Yunyao Cheng",
      "Chenjuan Guo",
      "Kaixuan Chen",
      "Kai Zhao",
      "Bin Yang",
      "Jiandong Xie",
      "Christian S. Jensen",
      "Feiteng Huang",
      "Kai Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10306"
  },
  {
    "id": "arXiv:2212.10307",
    "title": "Efficient and Sound Differentiable Programming in a Functional  Array-Processing Language",
    "abstract": "Automatic differentiation (AD) is a technique for computing the derivative of\na function represented by a program. This technique is considered as the\nde-facto standard for computing the differentiation in many machine learning\nand optimisation software tools. Despite the practicality of this technique,\nthe performance of the differentiated programs, especially for functional\nlanguages and in the presence of vectors, is suboptimal. We present an AD\nsystem for a higher-order functional array-processing language. The core\nfunctional language underlying this system simultaneously supports both\nsource-to-source forward-mode AD and global optimisations such as loop\ntransformations. In combination, gradient computation with forward-mode AD can\nbe as efficient as reverse mode, and the Jacobian matrices required for\nnumerical algorithms such as Gauss-Newton and Levenberg-Marquardt can be\nefficiently computed.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1806.02136\n",
    "authors": [
      "Amir Shaikhha",
      "Mathieu Huot",
      "Shabnam Ghasemirad",
      "Andrew Fitzgibbon",
      "Simon Peyton Jones",
      "Dimitrios Vytiniotis"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2212.10307"
  },
  {
    "id": "arXiv:2212.10310",
    "title": "PreFair: Privately Generating Justifiably Fair Synthetic Data",
    "abstract": "When a database is protected by Differential Privacy (DP), its usability is\nlimited in scope. In this scenario, generating a synthetic version of the data\nthat mimics the properties of the private data allows users to perform any\noperation on the synthetic data, while maintaining the privacy of the original\ndata. Therefore, multiple works have been devoted to devising systems for DP\nsynthetic data generation. However, such systems may preserve or even magnify\nproperties of the data that make it unfair, endering the synthetic data unfit\nfor use. In this work, we present PreFair, a system that allows for DP fair\nsynthetic data generation. PreFair extends the state-of-the-art DP data\ngeneration mechanisms by incorporating a causal fairness criterion that ensures\nfair synthetic data. We adapt the notion of justifiable fairness to fit the\nsynthetic data generation scenario. We further study the problem of generating\nDP fair synthetic data, showing its intractability and designing algorithms\nthat are optimal under certain assumptions. We also provide an extensive\nexperimental evaluation, showing that PreFair generates synthetic data that is\nsignificantly fairer than the data generated by leading DP data generation\nmechanisms, while remaining faithful to the private data.",
    "descriptor": "\nComments: 15 pages, 11 figures\n",
    "authors": [
      "David Pujol",
      "Amir Gilad",
      "Ashwin Machanavajjhala"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.10310"
  },
  {
    "id": "arXiv:2212.10313",
    "title": "Beyond Triplet: Leveraging the Most Data for Multimodal Machine  Translation",
    "abstract": "Multimodal machine translation (MMT) aims to improve translation quality by\nincorporating information from other modalities, such as vision. Previous MMT\nsystems mainly focus on better access and use of visual information and tend to\nvalidate their methods on image-related datasets. These studies face two\nchallenges. First, they can only utilize triple data (bilingual texts with\nimages), which is scarce; second, current benchmarks are relatively restricted\nand do not correspond to realistic scenarios. Therefore, this paper\ncorrespondingly establishes new methods and new datasets for MMT. First, we\npropose a framework 2/3-Triplet with two new approaches to enhance MMT by\nutilizing large-scale non-triple data: monolingual image-text data and parallel\ntext-only data. Second, we construct an English-Chinese {e}-commercial\n{m}ulti{m}odal {t}ranslation dataset (including training and testing), named\nEMMT, where its test set is carefully selected as some words are ambiguous and\nshall be translated mistakenly without the help of images. Experiments show\nthat our method is more suitable for real-world scenarios and can significantly\nimprove translation performance by using more non-triple data. In addition, our\nmodel also rivals various SOTA models in conventional multimodal translation\nbenchmarks.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Yaoming Zhu",
      "Zewei Sun",
      "Shanbo Cheng",
      "Yuyang Huang",
      "Liwei Wu",
      "Mingxuan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10313"
  },
  {
    "id": "arXiv:2212.10315",
    "title": "HINT: Hypernetwork Instruction Tuning for Efficient Zero-Shot  Generalisation",
    "abstract": "Recent NLP models have the great ability to generalise `zero-shot' to new\ntasks using only an instruction as guidance. However, these approaches usually\nrepeat their instructions with every input, requiring costly reprocessing of\nlengthy instructions for every inference example. To alleviate this, we\nintroduce Hypernetworks for INstruction Tuning (HINT), which convert task\ninstructions and examples using a pretrained text encoder into\nparameter-efficient modules inserted into an underlying model, eliminating the\nneed to include instructions in the model input. Compared to prior approaches\nthat concatenate instructions with every input instance, we find that HINT\nmodels are significantly more compute-efficient and consistently outperform\nthese approaches for a given inference budget.",
    "descriptor": "",
    "authors": [
      "Hamish Ivison",
      "Akshita Bhagia",
      "Yizhong Wang",
      "Hannaneh Hajishirzi",
      "Matthew Peters"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10315"
  },
  {
    "id": "arXiv:2212.10318",
    "title": "Learned Systems Security",
    "abstract": "A learned system uses machine learning (ML) internally to improve\nperformance. We can expect such systems to be vulnerable to some adversarial-ML\nattacks. Often, the learned component is shared between mutually-distrusting\nusers or processes, much like microarchitectural resources such as caches,\npotentially giving rise to highly-realistic attacker models. However, compared\nto attacks on other ML-based systems, attackers face a level of indirection as\nthey cannot interact directly with the learned model. Additionally, the\ndifference between the attack surface of learned and non-learned versions of\nthe same system is often subtle. These factors obfuscate the de-facto risks\nthat the incorporation of ML carries. We analyze the root causes of\npotentially-increased attack surface in learned systems and develop a framework\nfor identifying vulnerabilities that stem from the use of ML. We apply our\nframework to a broad set of learned systems under active development. To\nempirically validate the many vulnerabilities surfaced by our framework, we\nchoose 3 of them and implement and evaluate exploits against prominent\nlearned-system instances. We show that the use of ML caused leakage of past\nqueries in a database, enabled a poisoning attack that causes exponential\nmemory blowup in an index structure and crashes it in seconds, and enabled\nindex users to snoop on each others' key distributions by timing queries over\ntheir own keys. We find that adversarial ML is a universal threat against\nlearned systems, point to open research gaps in our understanding of\nlearned-systems security, and conclude by discussing mitigations, while noting\nthat data leakage is inherent in systems whose learned component is shared\nbetween multiple parties.",
    "descriptor": "",
    "authors": [
      "Roei Schuster",
      "Jin Peng Zhou",
      "Paul Grubbs",
      "Thorsten Eisenhofer",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10318"
  },
  {
    "id": "arXiv:2212.10319",
    "title": "Image quality prediction using synthetic and natural codebooks:  comparative results",
    "abstract": "We investigate a model for image/video quality assessment based on building a\nset of codevectors representing in a sense some basic properties of images,\nsimilar to well-known CORNIA model. We analyze the codebook building method and\npropose some modifications for it. Also the algorithm is investigated from the\npoint of inference time reduction. Both natural and synthetic images are used\nfor building codebooks and some analysis of synthetic images used for codebooks\nis provided. It is demonstrated the results on quality assessment may be\nimproves with the use if synthetic images for codebook construction. We also\ndemonstrate regimes of the algorithm in which real time execution on CPU is\npossible for sufficiently high correlations with mean opinion score (MOS).\nVarious pooling strategies are considered as well as the problem of metric\nsensitivity to bitrate.",
    "descriptor": "\nComments: 18 pages, 8 figures\n",
    "authors": [
      "Maxim Koroteev",
      "Kirill Aistov",
      "Valeriy Berezovskiy",
      "Pavel Frolov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10319"
  },
  {
    "id": "arXiv:2212.10320",
    "title": "Construction of extra-large scale screening tools for risks of severe  mental illnesses using real world healthcare data",
    "abstract": "Importance: The prevalence of severe mental illnesses (SMIs) in the United\nStates is approximately 3% of the whole population. The ability to conduct risk\nscreening of SMIs at large scale could inform early prevention and treatment.\nObjective: A scalable machine learning based tool was developed to conduct\npopulation-level risk screening for SMIs, including schizophrenia,\nschizoaffective disorders, psychosis, and bipolar disorders,using 1) healthcare\ninsurance claims and 2) electronic health records (EHRs).\nDesign, setting and participants: Data from beneficiaries from a nationwide\ncommercial healthcare insurer with 77.4 million members and data from patients\nfrom EHRs from eight academic hospitals based in the U.S. were used. First, the\npredictive models were constructed and tested using data in case-control\ncohorts from insurance claims or EHR data. Second, performance of the\npredictive models across data sources were analyzed. Third, as an illustrative\napplication, the models were further trained to predict risks of SMIs among\n18-year old young adults and individuals with substance associated conditions.\nMain outcomes and measures: Machine learning-based predictive models for SMIs\nin the general population were built based on insurance claims and EHR.",
    "descriptor": "",
    "authors": [
      "Dianbo Liu",
      "Karmel W. Choi",
      "Paulo Lizano",
      "William Yuan",
      "Kun-Hsing Yu",
      "Jordan Smoller",
      "Isaac Kohane"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2212.10320"
  },
  {
    "id": "arXiv:2212.10321",
    "title": "Implicit function theorem for nonlinear time-delay systems with  algebraic constraints",
    "abstract": "In this note, we discuss a generalization of the well-known implicit function\ntheorem to the time-delay case. We show that the latter problem is closely\nrelated to the bicausal changes of coordinates of time-delay systems. An\niterative algorithm is proposed to check the conditions and to construct the\ndesired bicausal change of coordinates for the proposed implicit function\ntheorem. Moreover, we show that our results can be applied to delayed\ndifferential-algebraic equations (DDAEs) to reduce their indices and to get\ntheir solutions. Some numerical examples are given to illustrate our results.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Yahao Chen",
      "Malek Ghanes",
      "Jean-Pierre Barbot"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.10321"
  },
  {
    "id": "arXiv:2212.10324",
    "title": "Distributed Key Generation with Smart Contracts using zk-SNARKs",
    "abstract": "Distributed Key Generation (DKG) is an extensively researched topic as it is\nfundamental to threshold cryptosystems. Emerging technologies such as\nblockchains benefit massively from applying threshold cryptography in consensus\nprotocols, randomness beacons, and threshold signatures. However, blockchains\nand smart contracts also enable further improvements of DKG protocols by\nproviding a decentralized computation and communication platform.\nFor that reason, we propose a DKG protocol that uses smart contracts to\nensure the correct execution of the protocol, allow dynamic participation, and\nprovide crypto-economic incentives to encourage honest behavior. The DKG\nprotocol uses a dispute and key derivation mechanism based on Zero-Knowledge\nSuccinct Non-interactive Arguments of Knowledge (zk-SNARKs) to reduce the costs\nof applying smart contracts by moving the computations off-chain, where the\nsmart contract only verifies the correctness of the computation.",
    "descriptor": "",
    "authors": [
      "Michael Sober",
      "Max Kobelt",
      "Giulia Scaffino",
      "Dominik Kaaser",
      "Stefan Schulte"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.10324"
  },
  {
    "id": "arXiv:2212.10325",
    "title": "SeqDiffuSeq: Text Diffusion with Encoder-Decoder Transformers",
    "abstract": "Diffusion model, a new generative modelling paradigm, has achieved great\nsuccess in image, audio, and video generation. However, considering the\ndiscrete categorical nature of text, it is not trivial to extend continuous\ndiffusion models to natural language, and text diffusion models are less\nstudied. Sequence-to-sequence text generation is one of the essential natural\nlanguage processing topics. In this work, we apply diffusion models to approach\nsequence-to-sequence text generation, and explore whether the superiority\ngeneration performance of diffusion model can transfer to natural language\ndomain. We propose SeqDiffuSeq, a text diffusion model for sequence-to-sequence\ngeneration. SeqDiffuSeq uses an encoder-decoder Transformers architecture to\nmodel denoising function. In order to improve generation quality, SeqDiffuSeq\ncombines the self-conditioning technique and a newly proposed adaptive noise\nschedule technique. The adaptive noise schedule has the difficulty of denoising\nevenly distributed across time steps, and considers exclusive noise schedules\nfor tokens at different positional order. Experiment results illustrate the\ngood performance on sequence-to-sequence generation in terms of text quality\nand inference time.",
    "descriptor": "\nComments: Working in progress; 9 pages, 2 figures\n",
    "authors": [
      "Hongyi Yuan",
      "Zheng Yuan",
      "Chuanqi Tan",
      "Fei Huang",
      "Songfang Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10325"
  },
  {
    "id": "arXiv:2212.10337",
    "title": "Efficient L2 Batch Posting Strategy on L1",
    "abstract": "We design efficient algorithms for the batch posting of Layer 2 chain\ncalldata on the Layer 1 chain, using tools from operations research. We relate\nthe costs of posting and delaying, by converting them to the same units. The\nalgorithm that keeps the average and maximum queued number of batches tolerable\nenough improves the posting costs of the trivial algorithm that posts batches\nimmediately when they are created by 8%. On the other hand, the algorithm that\nonly cares moderately about queue length can improve the trivial algorithm\nposting costs by 29%.",
    "descriptor": "",
    "authors": [
      "Akaki Mamageishvili",
      "Edward W. Felten"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2212.10337"
  },
  {
    "id": "arXiv:2212.10338",
    "title": "Making Relational Hoare Logic Alignment Complete",
    "abstract": "In relational verification, judicious alignment of computational steps\nfacilitates proof of relations between programs using simple relational\nassertions. Relational Hoare logics (RHL) provide compositional rules that\nembody various alignments. Seemingly more flexible alignments can be expressed\nin terms of product automata based on program transition relations. A RHL can\nbe complete, in the ordinary sense, using a single degenerate alignment rule.\nThe notion of alignment completeness was previously proposed as a more\nsatisfactory measure, based on alignment automata, and some rules were shown to\nbe alignment complete with respect to a few ad hoc forms of alignment automata.\nUsing a rule of semantics-preserving rewrites based on Kleene algebra with\ntests, an RHL is shown to be alignment complete with respect to a very general\nclass of alignment automata. Besides solving the open problem of general\nalignment completeness, this result bridges between human-friendly syntax-based\nreasoning and automata representations that facilitate automated verification.",
    "descriptor": "",
    "authors": [
      "Anindya Banerjee",
      "Ramana Nagasamudram",
      "David A. Naumann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.10338"
  },
  {
    "id": "arXiv:2212.10340",
    "title": "Weakly supervised training of universal visual concepts for multi-domain  semantic segmentation",
    "abstract": "Deep supervised models have an unprecedented capacity to absorb large\nquantities of training data. Hence, training on multiple datasets becomes a\nmethod of choice towards strong generalization in usual scenes and graceful\nperformance degradation in edge cases. Unfortunately, different datasets often\nhave incompatible labels. For instance, the Cityscapes road class subsumes all\ndriving surfaces, while Vistas defines separate classes for road markings,\nmanholes etc. Furthermore, many datasets have overlapping labels. For instance,\npickups are labeled as trucks in VIPER, cars in Vistas, and vans in ADE20k. We\naddress this challenge by considering labels as unions of universal visual\nconcepts. This allows seamless and principled learning on multi-domain dataset\ncollections without requiring any relabeling effort. Our method achieves\ncompetitive within-dataset and cross-dataset generalization, as well as ability\nto learn visual concepts which are not separately labeled in any of the\ntraining datasets. Experiments reveal competitive or state-of-the-art\nperformance on two multi-domain dataset collections and on the WildDash 2\nbenchmark.",
    "descriptor": "\nComments: 23 pages, 10 figures, 9 tables\n",
    "authors": [
      "Petra Bevandi\u0107",
      "Marin Or\u0161i\u0107",
      "Ivan Grubi\u0161i\u0107",
      "Josip \u0160ari\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10340"
  },
  {
    "id": "arXiv:2212.10341",
    "title": "CoCo: Coherence-Enhanced Machine-Generated Text Detection Under Data  Limitation With Contrastive Learning",
    "abstract": "Machine-Generated Text (MGT) detection, a task that discriminates MGT from\nHuman-Written Text (HWT), plays a crucial role in preventing misuse of text\ngenerative models, which excel in mimicking human writing style recently.\nLatest proposed detectors usually take coarse text sequence as input and output\nsome good results by fine-tune pretrained models with standard cross-entropy\nloss. However, these methods fail to consider the linguistic aspect of text\n(e.g., coherence) and sentence-level structures. Moreover, they lack the\nability to handle the low-resource problem which could often happen in practice\nconsidering the enormous amount of textual data online. In this paper, we\npresent a coherence-based contrastive learning model named CoCo to detect the\npossible MGT under low-resource scenario. Inspired by the distinctiveness and\npermanence properties of linguistic feature, we represent text as a coherence\ngraph to capture its entity consistency, which is further encoded by the\npretrained model and graph neural network. To tackle the challenges of data\nlimitations, we employ a contrastive learning framework and propose an improved\ncontrastive loss for making full use of hard negative samples in training\nstage. The experiment results on two public datasets prove our approach\noutperforms the state-of-art methods significantly.",
    "descriptor": "",
    "authors": [
      "Xiaoming Liu",
      "Zhaohan Zhang",
      "Yichen Wang",
      "Yu Lan",
      "Chao Shen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10341"
  },
  {
    "id": "arXiv:2212.10343",
    "title": "Berlin V2X: A Machine Learning Dataset from Multiple Vehicles and Radio  Access Technologies",
    "abstract": "The evolution of wireless communications into 6G and beyond is expected to\nrely on new machine learning (ML)-based capabilities. These can enable\nproactive decisions and actions from wireless-network components to sustain\nquality-of-service (QoS) and user experience. Moreover, new use cases in the\narea of vehicular and industrial communications will emerge. Specifically in\nthe area of vehicle communication, vehicle-to-everything (V2X) schemes will\nbenefit strongly from such advances. With this in mind, we have conducted a\ndetailed measurement campaign with the purpose of enabling a plethora of\ndiverse ML-based studies. The resulting datasets offer GPS-located wireless\nmeasurements across diverse urban environments for both cellular (with two\ndifferent operators) and sidelink radio access technologies, thus enabling a\nvariety of different studies towards V2X. The datasets are labeled and sampled\nwith a high time resolution. Furthermore, we make the data publicly available\nwith all the necessary information to support the on-boarding of new\nresearchers. We provide an initial analysis of the data showing some of the\nchallenges that ML needs to overcome and the features that ML can leverage, as\nwell as some hints at potential research studies.",
    "descriptor": "\nComments: Submitted to a conference\n",
    "authors": [
      "Rodrigo Hernang\u00f3mez",
      "Philipp Geuer",
      "Alexandros Palaios",
      "Daniel Sch\u00e4ufele",
      "Cara Watermann",
      "Khawla Taleb-Bouhemadi",
      "Mohammad Parvini",
      "Anton Krause",
      "Sanket Partani",
      "Christian Vielhaus",
      "Martin Kasparick",
      "Daniel F. K\u00fclzer",
      "Friedrich Burmeister",
      "S\u0142awomir Sta\u0144czak",
      "Gerhard Fettweis",
      "Hans D. Schotten",
      "Frank H. P. Fitzek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.10343"
  },
  {
    "id": "arXiv:2212.10346",
    "title": "Does It Affect You? Social and Learning Implications of Using  Cognitive-Affective State Recognition for Proactive Human-Robot Tutoring",
    "abstract": "Using robots in educational contexts has already shown to be beneficial for a\nstudent's learning and social behaviour. For levitating them to the next level\nof providing more effective and human-like tutoring, the ability to adapt to\nthe user and to express proactivity is fundamental. By acting proactively,\nintelligent robotic tutors anticipate possible situations where problems for\nthe student may arise and act in advance for preventing negative outcomes.\nStill, the decisions of when and how to behave proactively are open questions.\nTherefore, this paper deals with the investigation of how the student's\ncognitive-affective states can be used by a robotic tutor for triggering\nproactive tutoring dialogue. In doing so, it is aimed to improve the learning\nexperience. For this reason, a concept learning task scenario was observed\nwhere a robotic assistant proactively helped when negative user states were\ndetected. In a learning task, the user's states of frustration and confusion\nwere deemed to have negative effects on the outcome of the task and were used\nto trigger proactive behaviour. In an empirical user study with 40\nundergraduate and doctoral students, we studied whether the initiation of\nproactive behaviour after the detection of signs of confusion and frustration\nimproves the student's concentration and trust in the agent. Additionally, we\ninvestigated which level of proactive dialogue is useful for promoting the\nstudent's concentration and trust. The results show that high proactive\nbehaviour harms trust, especially when triggered during negative\ncognitive-affective states but contributes to keeping the student focused on\nthe task when triggered in these states. Based on our study results, we further\ndiscuss future steps for improving the proactive assistance of robotic tutoring\nsystems.",
    "descriptor": "",
    "authors": [
      "Matthias Kraus",
      "Diana Betancourt",
      "Wolfgang Minker"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10346"
  },
  {
    "id": "arXiv:2212.10347",
    "title": "On the computation of analytic sensitivities of eigenpairs in  isogeometric analysis",
    "abstract": "The eigenmodes of resonating structures, e.g., electromagnetic cavities, are\nsensitive to deformations of their shape. In order to compute the sensitivities\nof the eigenpair with respect to a scalar parameter, we state the Laplacian and\nMaxwellian eigenvalue problems and discretize the models using isogeometric\nanalysis. Since we require the derivatives of the system matrices, we\ndifferentiate the system matrices for each setting considering the appropriate\nfunction spaces for geometry and solution. This approach allows for a\nstraightforward computation of arbitrary higher order sensitivities in a\nclosed-form. In our work, we demonstrate the application in a setting of small\ngeometric deformations, e.g., for the investigation of manufacturing\nuncertainties of electromagnetic cavities, as well as in an eigenvalue tracking\nalong a shape morphing.",
    "descriptor": "",
    "authors": [
      "Anna Ziegler",
      "Melina Merkel",
      "Peter Gangl",
      "Sebastian Sch\u00f6ps"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.10347"
  },
  {
    "id": "arXiv:2212.10348",
    "title": "Modeling and optimal control of growth, energy, and resource dynamics of  Hermetia illucens in mass production environment",
    "abstract": "Mass production of Hermetia illucens insect larvae is now being adopted in\nmany countries and is taking an industrial production approach. Despite\nabundant literature on factors that affect larvae growth and the optimal static\nparameters identified in laboratory setup, for an industrial production process\nit is necessary to identify the trajectories such that the growth as well as\nthe production process is optimal. To achieve this in this work, some of the\nimportant requirements and challenges involved thereof are identified and\nobjectives of the automation process are formulated within a model based\noptimal control setup. Mechanistic models necessary for the optimization\nframework are derived as differential equations that describe the dynamic\nvariation of resources (feed, water, O2 etc.), energy, and larval biomass. In\naddition, the elevated metabolic activity of larvae corresponding to the final\ninstar development is identified and also modelled based on the observation\nfrom experiments. The mass and energy balance approach used in modelling\nenables the quantification and distinction of the mass and energy flux\ncomponents in various levels (e.g. larvae body, growing medium, production\nenvironment, and external environment) while holding its applicability for both\nopen and closed/reactor based production setups. Finally, the trajectories\ngenerated using the synthesized optimal controller are tested under different\nscenarios showcasing significant reduction in resource consumption compared to\na fixed set-point operation of the production setup. Results presented in this\nwork not only showcase the potential of the mechanistic models and their\napplication in identifying the relevant process parameters (e.g. reactor\nproperties such as volume, thermal conductivity, actuator capacities), but most\nimportantly in optimizing the process dynamically and tuning the process\nobjectives as desired.",
    "descriptor": "",
    "authors": [
      "Murali Padmanabha",
      "Alexander Kobelski",
      "Arne-Jens Hempel",
      "Stefan Streif"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.10348"
  },
  {
    "id": "arXiv:2212.10352",
    "title": "Fixed-Weight Difference Target Propagation",
    "abstract": "Target Propagation (TP) is a biologically more plausible algorithm than the\nerror backpropagation (BP) to train deep networks, and improving practicality\nof TP is an open issue. TP methods require the feedforward and feedback\nnetworks to form layer-wise autoencoders for propagating the target values\ngenerated at the output layer. However, this causes certain drawbacks; e.g.,\ncareful hyperparameter tuning is required to synchronize the feedforward and\nfeedback training, and frequent updates of the feedback path are usually\nrequired than that of the feedforward path. Learning of the feedforward and\nfeedback networks is sufficient to make TP methods capable of training, but is\nhaving these layer-wise autoencoders a necessary condition for TP to work? We\nanswer this question by presenting Fixed-Weight Difference Target Propagation\n(FW-DTP) that keeps the feedback weights constant during training. We confirmed\nthat this simple method, which naturally resolves the abovementioned problems\nof TP, can still deliver informative target values to hidden layers for a given\ntask; indeed, FW-DTP consistently achieves higher test performance than a\nbaseline, the Difference Target Propagation (DTP), on four classification\ndatasets. We also present a novel propagation architecture that explains the\nexact form of the feedback function of DTP to analyze FW-DTP.",
    "descriptor": "\nComments: Accepted at the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23). 9 pages and 3 figures in main manuscript; 11 pages and 5 figures in supplementary material\n",
    "authors": [
      "Tatsukichi Shibuya",
      "Nakamasa Inoue",
      "Rei Kawakami",
      "Ikuro Sato"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10352"
  },
  {
    "id": "arXiv:2212.10355",
    "title": "Optimizing Serially Concatenated Neural Codes with Classical Decoders",
    "abstract": "For improving short-length codes, we demonstrate that classic decoders can\nalso be used with real-valued, neural encoders, i.e., deep-learning based\ncodeword sequence generators. Here, the classical decoder can be a valuable\ntool to gain insights into these neural codes and shed light on weaknesses.\nSpecifically, the turbo-autoencoder is a recently developed channel coding\nscheme where both encoder and decoder are replaced by neural networks. We first\nshow that the limited receptive field of convolutional neural network\n(CNN)-based codes enables the application of the BCJR algorithm to optimally\ndecode them with feasible computational complexity. These maximum a posteriori\n(MAP) component decoders then are used to form classical (iterative) turbo\ndecoders for parallel or serially concatenated CNN encoders, offering a\nclose-to-maximum likelihood (ML) decoding of the learned codes. To the best of\nour knowledge, this is the first time that a classical decoding algorithm is\napplied to a non-trivial, real-valued neural code. Furthermore, as the BCJR\nalgorithm is fully differentiable, it is possible to train, or fine-tune, the\nneural encoder in an end-to-end fashion.",
    "descriptor": "\nComments: Submitted to IEEE WSA/SCC\n",
    "authors": [
      "Jannis Clausius",
      "Marvin Geiselhart",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10355"
  },
  {
    "id": "arXiv:2212.10356",
    "title": "Receptive Field Alignment Enables Transformer Length Extrapolation",
    "abstract": "Length extrapolation is a desirable property that permits training a\ntransformer language model on short sequences and retaining similar\nperplexities when the model is tested on substantially longer sequences. A\nrelative positional embedding mechanism applied on the transformer\nself-attention matrix, ALiBi, demonstrates the length extrapolation property\nwith the widest usage to date. In this paper, we show that ALiBi surprisingly\ndoes not utilize tokens further than the training sequence length, which can be\nexplained by its implicit windowed attention effect that aligns the receptive\nfield during training and testing stages. Inspired by ALiBi and the receptive\nfiled alignment hypothesis, we propose another transformer positional embedding\ndesign named~\\textbf{Sandwich} that uses longer than training sequence length\ninformation, and it is a greatly simplified formulation of the earliest\nproposed Sinusoidal positional embedding. Finally, we show that both ALiBi and\nSandwich enable efficient inference thanks to their implicit windowed attention\neffect.",
    "descriptor": "\nComments: Work In progress\n",
    "authors": [
      "Ta-Chung Chi",
      "Ting-Han Fan",
      "Alexander I. Rudnicky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10356"
  },
  {
    "id": "arXiv:2212.10367",
    "title": "Modeling Human Eye Movements with Neural Networks in a Maze-Solving Task",
    "abstract": "From smoothly pursuing moving objects to rapidly shifting gazes during visual\nsearch, humans employ a wide variety of eye movement strategies in different\ncontexts. While eye movements provide a rich window into mental processes,\nbuilding generative models of eye movements is notoriously difficult, and to\ndate the computational objectives guiding eye movements remain largely a\nmystery. In this work, we tackled these problems in the context of a canonical\nspatial planning task, maze-solving. We collected eye movement data from human\nsubjects and built deep generative models of eye movements using a novel\ndifferentiable architecture for gaze fixations and gaze shifts. We found that\nhuman eye movements are best predicted by a model that is optimized not to\nperform the task as efficiently as possible but instead to run an internal\nsimulation of an object traversing the maze. This not only provides a\ngenerative model of eye movements in this task but also suggests a\ncomputational theory for how humans solve the task, namely that humans use\nmental simulation.",
    "descriptor": "",
    "authors": [
      "Jason Li",
      "Nicholas Watters",
      "Yingting",
      "Wang",
      "Hansem Sohn",
      "Mehrdad Jazayeri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2212.10367"
  },
  {
    "id": "arXiv:2212.10368",
    "title": "Masked Event Modeling: Self-Supervised Pretraining for Event Cameras",
    "abstract": "Event cameras offer the capacity to asynchronously capture brightness changes\nwith low latency, high temporal resolution, and high dynamic range. Deploying\ndeep learning methods for classification or other tasks to these sensors\ntypically requires large labeled datasets. Since the amount of labeled event\ndata is tiny compared to the bulk of labeled RGB imagery, the progress of\nevent-based vision has remained limited. To reduce the dependency on labeled\nevent data, we introduce Masked Event Modeling (MEM), a self-supervised\npretraining framework for events. Our method pretrains a neural network on\nunlabeled events, which can originate from any event camera recording.\nSubsequently, the pretrained model is finetuned on a downstream task leading to\nan overall better performance while requiring fewer labels. Our method\noutperforms the state-of-the-art on N-ImageNet, N-Cars, and N-Caltech101,\nincreasing the object classification accuracy on N-ImageNet by 7.96%. We\ndemonstrate that Masked Event Modeling is superior to RGB-based pretraining on\na real world dataset.",
    "descriptor": "",
    "authors": [
      "Simon Klenk",
      "David Bonello",
      "Lukas Koestler",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10368"
  },
  {
    "id": "arXiv:2212.10370",
    "title": "Hopf Physical Reservoir Computer for Reconfigurable Sound Recognition",
    "abstract": "The Hopf oscillator is a nonlinear oscillator that exhibits limit cycle\nmotion. This reservoir computer utilizes the vibratory nature of the\noscillator, which makes it an ideal candidate for reconfigurable sound\nrecognition tasks. In this paper, the capabilities of the Hopf reservoir\ncomputer performing sound recognition are systematically demonstrated. This\nwork shows that the Hopf reservoir computer can offer superior sound\nrecognition accuracy compared to legacy approaches (e.g., a Mel spectrum +\nmachine learning approach). More importantly, the Hopf reservoir computer\noperating as a sound recognition system does not require audio preprocessing\nand has a very simple setup while still offering a high degree of\nreconfigurability. These features pave the way of applying physical reservoir\ncomputing for sound recognition in low power edge devices.",
    "descriptor": "\nComments: 21 pages, 11 figures\n",
    "authors": [
      "Md Raf E Ul Shougat",
      "XiaoFu Li",
      "Siyao Shao",
      "Kathleen Walden McGarvey",
      "Edmon Perkins"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.10370"
  },
  {
    "id": "arXiv:2212.10375",
    "title": "Self-adaptive In-context Learning",
    "abstract": "Despite the surprising few-shot performance of in-context learning (ICL), it\nis still a common practice to randomly sample examples to serve as context.\nThis paper advocates a new principle for ICL: self-adaptive in-context\nlearning. The self-adaption mechanism is introduced to help each sample find an\nin-context example permutation (i.e., selection and ordering) that can derive\nthe correct prediction, thus maximizing performance. To validate the\neffectiveness of self-adaptive ICL, we propose a general select-then-rank\nframework and instantiate it with new selection and ranking algorithms. Upon\nextensive evaluation on eight different NLP datasets, our self-adaptive ICL\nmethod achieves a 40% relative improvement over the common practice setting.\nFurther analysis reveals the enormous potential of self-adaptive ICL that it\nmight be able to close the gap between ICL and finetuning given more advanced\nalgorithms. Our code is released to facilitate future research in this area:\nhttps://github.com/Shark-NLP/self-adaptive-ICL",
    "descriptor": "",
    "authors": [
      "Zhiyong Wu",
      "Yaoxiang Wang",
      "Jiacheng Ye",
      "Lingpeng Kong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10375"
  },
  {
    "id": "arXiv:2212.10376",
    "title": "The Third International Verification of Neural Networks Competition  (VNN-COMP 2022): Summary and Results",
    "abstract": "This report summarizes the 3rd International Verification of Neural Networks\nCompetition (VNN-COMP 2022), held as a part of the 5th Workshop on Formal\nMethods for ML-Enabled Autonomous Systems (FoMLAS), which was collocated with\nthe 34th International Conference on Computer-Aided Verification (CAV).\nVNN-COMP is held annually to facilitate the fair and objective comparison of\nstate-of-the-art neural network verification tools, encourage the\nstandardization of tool interfaces, and bring together the neural network\nverification community. To this end, standardized formats for networks (ONNX)\nand specification (VNN-LIB) were defined, tools were evaluated on equal-cost\nhardware (using an automatic evaluation pipeline based on AWS instances), and\ntool parameters were chosen by the participants before the final test sets were\nmade public. In the 2022 iteration, 11 teams participated on a diverse set of\n12 scored benchmarks. This report summarizes the rules, benchmarks,\nparticipating tools, results, and lessons learned from this iteration of this\ncompetition.",
    "descriptor": "\nComments: 54 pages, 27 tables, and 16 figures\n",
    "authors": [
      "Mark Niklas M\u00fcller",
      "Christopher Brix",
      "Stanley Bak",
      "Changliu Liu",
      "Taylor T. Johnson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.10376"
  },
  {
    "id": "arXiv:2212.10378",
    "title": "Careful Data Curation Stabilizes In-context Learning",
    "abstract": "In-context learning (ICL) enables large language models (LLMs) to perform new\ntasks by prompting them with a sequence of training examples. However, ICL is\nvery sensitive to the choice of training examples: randomly sampling examples\nfrom a training set leads to high variance in performance. In this paper, we\nshow that curating a carefully chosen subset of training data greatly\nstabilizes ICL performance. We propose two methods to choose training subsets,\nboth of which score training examples individually and then select the\nhighest-scoring ones. CondAcc scores a training example by its average ICL\naccuracy when combined with random training examples, while Datamodels learns a\nlinear proxy model that estimates how the presence of each training example\ninfluences LLM accuracy. On average, CondAcc and Datamodels outperform sampling\nfrom the entire training set by 7.7% and 6.3%, respectively, across 5 tasks and\ntwo LLMs. Our analysis shows that stable subset examples are no more diverse\nthan average, and are not outliers in terms of sequence length and perplexity.",
    "descriptor": "",
    "authors": [
      "Ting-Yun Chang",
      "Robin Jia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10378"
  },
  {
    "id": "arXiv:2212.10380",
    "title": "What Are You Token About? Dense Retrieval as Distributions Over the  Vocabulary",
    "abstract": "Dual encoders are now the dominant architecture for dense retrieval. Yet, we\nhave little understanding of how they represent text, and why this leads to\ngood performance. In this work, we shed light on this question via\ndistributions over the vocabulary. We propose to interpret the vector\nrepresentations produced by dual encoders by projecting them into the model's\nvocabulary space. We show that the resulting distributions over vocabulary\ntokens are intuitive and contain rich semantic information. We find that this\nview can explain some of the failure cases of dense retrievers. For example,\nthe inability of models to handle tail entities can be explained via a tendency\nof the token distributions to forget some of the tokens of those entities. We\nleverage this insight and propose a simple way to enrich query and passage\nrepresentations with lexical information at inference time, and show that this\nsignificantly improves performance compared to the original model in\nout-of-domain settings.",
    "descriptor": "",
    "authors": [
      "Ori Ram",
      "Liat Bezalel",
      "Adi Zicher",
      "Yonatan Belinkov",
      "Jonathan Berant",
      "Amir Globerson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.10380"
  },
  {
    "id": "arXiv:2212.10381",
    "title": "To Adapt or to Annotate: Challenges and Interventions for Domain  Adaptation in Open-Domain Question Answering",
    "abstract": "Recent advances in open-domain question answering (ODQA) have demonstrated\nimpressive accuracy on standard Wikipedia style benchmarks. However, it is less\nclear how robust these models are and how well they perform when applied to\nreal-world applications in drastically different domains. While there has been\nsome work investigating how well ODQA models perform when tested for\nout-of-domain (OOD) generalization, these studies have been conducted only\nunder conservative shifts in data distribution and typically focus on a single\ncomponent (ie. retrieval) rather than an end-to-end system. In response, we\npropose a more realistic and challenging domain shift evaluation setting and,\nthrough extensive experiments, study end-to-end model performance. We find that\nnot only do models fail to generalize, but high retrieval scores often still\nyield poor answer prediction accuracy. We then categorize different types of\nshifts and propose techniques that, when presented with a new dataset, predict\nif intervention methods are likely to be successful. Finally, using insights\nfrom this analysis, we propose and evaluate several intervention methods which\nimprove end-to-end answer F1 score by up to 24 points.",
    "descriptor": "",
    "authors": [
      "Dheeru Dua",
      "Emma Strubell",
      "Sameer Singh",
      "Pat Verga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10381"
  },
  {
    "id": "arXiv:2212.10382",
    "title": "A World Full of Privacy and Security (Mis)conceptions? Findings of a  Representative Survey in 12 Countries",
    "abstract": "Misconceptions about digital security and privacy topics in the general\npublic frequently lead to insecure behavior. However, little is known about the\nprevalence and extent of such misconceptions in a global context. In this work,\nwe present the results of the first large-scale survey of a global population\non misconceptions: We conducted an online survey with n = 12, 351 participants\nin 12 countries on four continents. By investigating influencing factors of\nmisconceptions around eight common security and privacy topics (including E2EE,\nWi-Fi, VPN, and malware), we find the country of residence to be the strongest\nestimate for holding misconceptions. We also identify differences between\nnon-Western and Western countries, demonstrating the need for region-specific\nresearch on user security knowledge, perceptions, and behavior. While we did\nnot observe many outright misconceptions, we did identify a lack of\nunderstanding and uncertainty about several fundamental privacy and security\ntopics.",
    "descriptor": "",
    "authors": [
      "Franziska Herbert",
      "Steffen Becker",
      "Leonie Schaewitz",
      "Jonas Hielscher",
      "Marvin Kowalewski",
      "M. Angela Sasse",
      "Yasemin Acar",
      "Markus D\u00fcrmuth"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.10382"
  },
  {
    "id": "arXiv:2212.10387",
    "title": "Tuning the Tail Latency of Distributed Queries Using Replication",
    "abstract": "Querying graph data with low latency is an important requirement in\napplication domains such as social networks and knowledge graphs. Graph queries\nperform multiple hops between vertices. When data is partitioned and stored\nacross multiple servers, queries executing at one server often need to hop to\nvertices stored by another server. Such distributed traversals represent a\nperformance bottleneck for low-latency queries. To reduce query latency, one\ncan replicate remote data to make distributed traversals unnecessary, but\nreplication is expensive and should be minimized. In this paper, we introduce\nthe problem of finding data replication schemes that satisfy arbitrary\nuser-defined query latency constraints with minimal replication cost. We\npropose a novel workload model to express data access causality, propose a\nfamily of heuristics, and introduce non-trivial sufficient conditions for their\ncorrectness. Our evaluation on two representative benchmarks show that our\nalgorithms enable fine-tuning query latency with data replication and can find\nsweet spots in the latency/replication design space.",
    "descriptor": "\nComments: An earlier version of this paper was submitted in April 2022. Previous versions are available at this https URL\n",
    "authors": [
      "Nathan Ng",
      "Hung Le",
      "Marco Serafini"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.10387"
  },
  {
    "id": "arXiv:2212.10388",
    "title": "ThreatKG: A Threat Knowledge Graph for Automated Open-Source Cyber  Threat Intelligence Gathering and Management",
    "abstract": "Despite the increased adoption of open-source cyber threat intelligence\n(OSCTI) for acquiring knowledge about cyber threats, little effort has been\nmade to harvest knowledge from a large number of unstructured OSCTI reports\navailable in the wild (e.g., security articles, threat reports). These reports\nprovide comprehensive threat knowledge in a variety of entities (e.g., IOCs,\nthreat actors, TTPs) and relations, which, however, are hard to gather due to\ndiverse report formats, large report quantities, and complex structures and\nnuances in the natural language report text.\nTo bridge the gap, we propose ThreatKG, a system for automated open-source\ncyber threat knowledge gathering and management. ThreatKG automatically\ncollects a large number of OSCTI reports from various sources, extracts\nhigh-fidelity threat knowledge, constructs a threat knowledge graph, and\nupdates the knowledge graph by continuously ingesting new knowledge. To address\nmultiple challenges, ThreatKG provides: (1) a hierarchical ontology for\nmodeling a variety of threat knowledge entities and relations; (2) an accurate\ndeep learning-based pipeline for threat knowledge extraction; (3) a scalable\nand extensible system architecture for threat knowledge graph construction,\npersistence, updating, and exploration. Evaluations on a large number of\nreports demonstrate the effectiveness of ThreatKG in threat knowledge gathering\nand management",
    "descriptor": "",
    "authors": [
      "Peng Gao",
      "Xiaoyuan Liu",
      "Edward Choi",
      "Sibo Ma",
      "Xinyu Yang",
      "Zhengjie Ji",
      "Zilin Zhang",
      "Dawn Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.10388"
  },
  {
    "id": "arXiv:2212.10390",
    "title": "ADAS: A Simple Active-and-Adaptive Baseline for Cross-Domain 3D Semantic  Segmentation",
    "abstract": "State-of-the-art 3D semantic segmentation models are trained on the\noff-the-shelf public benchmarks, but they often face the major challenge when\nthese well-trained models are deployed to a new domain. In this paper, we\npropose an Active-and-Adaptive Segmentation (ADAS) baseline to enhance the weak\ncross-domain generalization ability of a well-trained 3D segmentation model,\nand bridge the point distribution gap between domains. Specifically, before the\ncross-domain adaptation stage begins, ADAS performs an active sampling\noperation to select a maximally-informative subset from both source and target\ndomains for effective adaptation, reducing the adaptation difficulty under 3D\nscenarios. Benefiting from the rise of multi-modal 2D-3D datasets, ADAS\nutilizes a cross-modal attention-based feature fusion module that can extract a\nrepresentative pair of image features and point features to achieve a\nbi-directional image-point feature interaction for better safe adaptation.\nExperimentally, ADAS is verified to be effective in many cross-domain settings\nincluding: 1) Unsupervised Domain Adaptation (UDA), which means that all\nsamples from target domain are unlabeled; 2) Unsupervised Few-shot Domain\nAdaptation (UFDA) which means that only a few unlabeled samples are available\nin the unlabeled target domain; 3) Active Domain Adaptation (ADA) which means\nthat the selected target samples by ADAS are manually annotated. Their results\ndemonstrate that ADAS achieves a significant accuracy gain by easily coupling\nADAS with self-training methods or off-the-shelf UDA works.",
    "descriptor": "",
    "authors": [
      "Ben Fei",
      "Siyuan Huang",
      "Jiakang Yuan",
      "Botian Shi",
      "Bo Zhang",
      "Tao Chen",
      "Min Dou",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.10390"
  },
  {
    "id": "arXiv:2212.10391",
    "title": "TeSS: Zero-Shot Classification via Textual Similarity Comparison with  Prompting using Sentence Encoder",
    "abstract": "We introduce TeSS (Text Similarity Comparison using Sentence Encoder), a\nframework for zero-shot classification where the assigned label is determined\nby the embedding similarity between the input text and each candidate label\nprompt. We leverage representations from sentence encoders optimized to locate\nsemantically similar samples closer to each other in embedding space during\npre-training. The label prompt embeddings serve as prototypes of their\ncorresponding class clusters. Furthermore, to compensate for the potentially\npoorly descriptive labels in their original format, we retrieve semantically\nsimilar sentences from external corpora and additionally use them with the\noriginal label prompt (TeSS-R). TeSS outperforms strong baselines on various\nclosed-set and open-set classification datasets under zero-shot setting, with\nfurther gains when combined with label prompt diversification through\nretrieval. These results are robustly attained to verbalizer variations, an\nancillary benefit of using a bi-encoder. Altogether, our method serves as a\nreliable baseline for zero-shot classification and a simple interface to assess\nthe quality of sentence encoders.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Jimin Hong",
      "Jungsoo Park",
      "Daeyoung Kim",
      "Seongjae Choi",
      "Bokyung Son",
      "Jaewook Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10391"
  },
  {
    "id": "arXiv:2212.10392",
    "title": "Debiasing Stance Detection Models with Counterfactual Reasoning and  Adversarial Bias Learning",
    "abstract": "Stance detection models may tend to rely on dataset bias in the text part as\na shortcut and thus fail to sufficiently learn the interaction between the\ntargets and texts. Recent debiasing methods usually treated features learned by\nsmall models or big models at earlier steps as bias features and proposed to\nexclude the branch learning those bias features during inference. However, most\nof these methods fail to disentangle the ``good'' stance features and ``bad''\nbias features in the text part. In this paper, we investigate how to mitigate\ndataset bias in stance detection. Motivated by causal effects, we leverage a\nnovel counterfactual inference framework, which enables us to capture the\ndataset bias in the text part as the direct causal effect of the text on\nstances and reduce the dataset bias in the text part by subtracting the direct\ntext effect from the total causal effect. We novelly model bias features as\nfeatures that correlate with the stance labels but fail on intermediate stance\nreasoning subtasks and propose an adversarial bias learning module to model the\nbias more accurately. To verify whether our model could better model the\ninteraction between texts and targets, we test our model on recently proposed\ntest sets to evaluate the understanding of the task from various aspects.\nExperiments demonstrate that our proposed method (1) could better model the\nbias features, and (2) outperforms existing debiasing baselines on both the\noriginal dataset and most of the newly constructed test sets.",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Jianhua Yuan",
      "Yanyan Zhao",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10392"
  },
  {
    "id": "arXiv:2212.10397",
    "title": "Needle in a Haystack: An Analysis of Finding Qualified Workers on MTurk  for Summarization",
    "abstract": "The acquisition of high-quality human annotations through crowdsourcing\nplatforms like Amazon Mechanical Turk (MTurk) is more challenging than\nexpected. The annotation quality might be affected by various aspects like\nannotation instructions, Human Intelligence Task (HIT) design, and wages paid\nto annotators, etc. To avoid potentially low-quality annotations which could\nmislead the evaluation of automatic summarization system outputs, we\ninvestigate the recruitment of high-quality MTurk workers via a three-step\nqualification pipeline. We show that we can successfully filter out bad workers\nbefore they carry out the evaluations and obtain high-quality annotations while\noptimizing the use of resources. This paper can serve as basis for the\nrecruitment of qualified annotators in other challenging annotation tasks.",
    "descriptor": "",
    "authors": [
      "Lining Zhang",
      "Jo\u00e3o Sedoc",
      "Simon Mille",
      "Yufang Hou",
      "Sebastian Gehrmann",
      "Daniel Deutsch",
      "Elizabeth Clark",
      "Yixin Liu",
      "Miruna Clinciu",
      "Saad Mahamood",
      "Khyathi Chandu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10397"
  },
  {
    "id": "arXiv:2212.10399",
    "title": "A deep learning Attention model to solve the Vehicle Routing Problem and  the Pick-up and Delivery Problem with Time Windows",
    "abstract": "SNCF, the French public train company, is experimenting to develop new types\nof transportation services by tackling vehicle routing problems. While many\ndeep learning models have been used to tackle efficiently vehicle routing\nproblems, it is difficult to take into account time related constraints. In\nthis paper, we solve the Capacitated Vehicle Routing Problem with Time Windows\n(CVRPTW) and the Capacitated Pickup and Delivery Problem with Time Windows\n(CPDPTW) with a constructive iterative Deep Learning algorithm. We use an\nAttention Encoder-Decoder structure and design a novel insertion heuristic for\nthe feasibility check of the CPDPTW. Our models yields results that are better\nthan best known learning solutions on the CVRPTW. We show the feasibility of\ndeep learning techniques for solving the CPDPTW but witness the limitations of\nour iterative approach in terms of computational complexity.",
    "descriptor": "",
    "authors": [
      "Baptiste Rabecq",
      "R\u00e9my Chevrier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.10399"
  },
  {
    "id": "arXiv:2212.10400",
    "title": "Contrastive Learning Reduces Hallucination in Conversations",
    "abstract": "Pre-trained language models (LMs) store knowledge in their parameters and can\ngenerate informative responses when used in conversational systems. However,\nLMs suffer from the problem of \"hallucination:\" they may generate\nplausible-looking statements that are irrelevant or factually incorrect. To\naddress this problem, we propose a contrastive learning scheme, named MixCL. A\nnovel mixed contrastive objective is proposed to explicitly optimize the\nimplicit knowledge elicitation process of LMs, and thus reduce their\nhallucination in conversations. We also examine negative sampling strategies of\nretrieved hard negatives and model-generated negatives. We conduct experiments\non Wizard-of-Wikipedia, a public, open-domain knowledge-grounded dialogue\nbenchmark, and assess the effectiveness of MixCL. MixCL effectively reduces the\nhallucination of LMs in conversations and achieves the highest performance\namong LM-based dialogue agents in terms of relevancy and factuality. We show\nthat MixCL achieves comparable performance to state-of-the-art KB-based\napproaches while enjoying notable advantages in terms of efficiency and\nscalability.",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Weiwei Sun",
      "Zhengliang Shi",
      "Shen Gao",
      "Pengjie Ren",
      "Maarten de Rijke",
      "Zhaochun Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10400"
  },
  {
    "id": "arXiv:2212.10402",
    "title": "Index-Based Concatenated Codes for the Multi-Draw DNA Storage Channel",
    "abstract": "We consider error-correcting coding for DNA-based storage. We model the DNA\nstorage channel as a multi-draw IDS channel where the input data is chunked\ninto $M$ short DNA strands, which are copied a random number of times, and the\nchannel outputs a random selection of $N$ noisy DNA strands. The retrieved DNA\nstrands are prone to insertion, deletion, and substitution (IDS) errors. We\npropose an index-based concatenated coding scheme consisting of the\nconcatenation of an outer code, an index code, and an inner synchronization\ncode, where the latter two tackle IDS errors. We further propose a mismatched\njoint index-synchronization code maximum a posteriori probability decoder with\noptional clustering to infer symbolwise a posteriori probabilities for the\nouter decoder. We compute achievable information rates for the outer code and\npresent Monte-Carlo simulations on experimental data.",
    "descriptor": "\nComments: submitted to IEEE Information Theory Workshop (ITW) 2023\n",
    "authors": [
      "Lorenz Welter",
      "Issam Maarouf",
      "Andreas Lenz",
      "Antonia Wachter-Zeh",
      "Eirik Rosnes",
      "Alexandre Graell i Amat"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.10402"
  },
  {
    "id": "arXiv:2212.10403",
    "title": "Towards Reasoning in Large Language Models: A Survey",
    "abstract": "Reasoning is a fundamental aspect of human intelligence that plays a crucial\nrole in activities such as problem solving, decision making, and critical\nthinking. In recent years, large language models (LLMs) have made significant\nprogress in natural language processing, and there is observation that these\nmodels may exhibit reasoning abilities when they are sufficiently large.\nHowever, it is not yet clear to what extent LLMs are capable of reasoning. This\npaper provides a comprehensive overview of the current state of knowledge on\nreasoning in LLMs, including techniques for improving and eliciting reasoning\nin these models, methods and benchmarks for evaluating reasoning abilities,\nfindings and implications of previous research in this field, and suggestions\non future directions. Our aim is to provide a detailed and up-to-date review of\nthis topic and stimulate meaningful discussion and future work.",
    "descriptor": "",
    "authors": [
      "Jie Huang",
      "Kevin Chen-Chuan Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10403"
  },
  {
    "id": "arXiv:2212.10405",
    "title": "AnnoBERT: Effectively Representing Multiple Annotators' Label Choices to  Improve Hate Speech Detection",
    "abstract": "Supervised approaches generally rely on majority-based labels. However, it is\nhard to achieve high agreement among annotators in subjective tasks such as\nhate speech detection. Existing neural network models principally regard labels\nas categorical variables, while ignoring the semantic information in diverse\nlabel texts. In this paper, we propose AnnoBERT, a first-of-its-kind\narchitecture integrating annotator characteristics and label text with a\ntransformer-based model to detect hate speech, with unique representations\nbased on each annotator's characteristics via Collaborative Topic Regression\n(CTR) and integrate label text to enrich textual representations. During\ntraining, the model associates annotators with their label choices given a\npiece of text; during evaluation, when label information is not available, the\nmodel predicts the aggregated label given by the participating annotators by\nutilising the learnt association. The proposed approach displayed an advantage\nin detecting hate speech, especially in the minority class and edge cases with\nannotator disagreement. Improvement in the overall performance is the largest\nwhen the dataset is more label-imbalanced, suggesting its practical value in\nidentifying real-world hate speech, as the volume of hate speech in-the-wild is\nextremely small on social media, when compared with normal (non-hate) speech.\nThrough ablation studies, we show the relative contributions of annotator\nembeddings and label text to the model performance, and tested a range of\nalternative annotator embeddings and label text combinations.",
    "descriptor": "\nComments: accepted at ICWSM 2023\n",
    "authors": [
      "Wenjie Yin",
      "Vibhor Agarwal",
      "Aiqi Jiang",
      "Arkaitz Zubiaga",
      "Nishanth Sastry"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.10405"
  },
  {
    "id": "arXiv:2212.10408",
    "title": "Geographic and Geopolitical Biases of Language Models",
    "abstract": "Pretrained language models (PLMs) often fail to fairly represent target users\nfrom certain world regions because of the under-representation of those regions\nin training datasets. With recent PLMs trained on enormous data sources,\nquantifying their potential biases is difficult, due to their black-box nature\nand the sheer scale of the data sources. In this work, we devise an approach to\nstudy the geographic bias (and knowledge) present in PLMs, proposing a\nGeographic-Representation Probing Framework adopting a self-conditioning method\ncoupled with entity-country mappings. Our findings suggest PLMs'\nrepresentations map surprisingly well to the physical world in terms of\ncountry-to-country associations, but this knowledge is unequally shared across\nlanguages. Last, we explain how large PLMs despite exhibiting notions of\ngeographical proximity, over-amplify geopolitical favouritism at inference\ntime.",
    "descriptor": "",
    "authors": [
      "Fahim Faisal",
      "Antonios Anastasopoulos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10408"
  },
  {
    "id": "arXiv:2212.10409",
    "title": "Reinforced Clarification Question Generation with Defeasibility Rewards  for Disambiguating Social and Moral Situations",
    "abstract": "Context is vital for commonsense moral reasoning. \"Lying to a friend\" is\nwrong if it is meant to deceive them, but may be morally okay if it is intended\nto protect them. Such nuanced but salient contextual information can\npotentially flip the moral judgment of an action. Thus, we present\nClarifyDelphi, an interactive system that elicits missing contexts of a moral\nsituation by generating clarification questions such as \"Why did you lie to\nyour friend?\". Our approach is inspired by the observation that questions whose\npotential answers lead to diverging moral judgments are the most informative.\nWe learn to generate questions using Reinforcement Learning, by maximizing the\ndivergence between moral judgements of hypothetical answers to a question.\nHuman evaluation shows that our system generates more relevant, informative and\ndefeasible questions compared to other question generation baselines.\nClarifyDelphi assists informed moral reasoning processes by seeking additional\nmorally consequential context to disambiguate social and moral situations.",
    "descriptor": "\nComments: 9 pages + bibliography + appendix\n",
    "authors": [
      "Valentina Pyatkin",
      "Jena D. Hwang",
      "Vivek Srikumar",
      "Ximing Lu",
      "Liwei Jiang",
      "Yejin Choi",
      "Chandra Bhagavatula"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10409"
  },
  {
    "id": "arXiv:2212.10411",
    "title": "DDIPNet and DDIPNet+: Discriminant Deep Image Prior Networks for Remote  Sensing Image Classification",
    "abstract": "Research on remote sensing image classification significantly impacts\nessential human routine tasks such as urban planning and agriculture. Nowadays,\nthe rapid advance in technology and the availability of many high-quality\nremote sensing images create a demand for reliable automation methods. The\ncurrent paper proposes two novel deep learning-based architectures for image\nclassification purposes, i.e., the Discriminant Deep Image Prior Network and\nthe Discriminant Deep Image Prior Network+, which combine Deep Image Prior and\nTriplet Networks learning strategies. Experiments conducted over three\nwell-known public remote sensing image datasets achieved state-of-the-art\nresults, evidencing the effectiveness of using deep image priors for remote\nsensing image classification.",
    "descriptor": "\nComments: Published in: 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS\n",
    "authors": [
      "Daniel F. S. Santos",
      "Rafael G. Pires",
      "Leandro A. Passos",
      "Jo\u00e3o P. Papa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10411"
  },
  {
    "id": "arXiv:2212.10417",
    "title": "Scene Change Detection Using Multiscale Cascade Residual Convolutional  Neural Networks",
    "abstract": "Scene change detection is an image processing problem related to partitioning\npixels of a digital image into foreground and background regions. Mostly,\nvisual knowledge-based computer intelligent systems, like traffic monitoring,\nvideo surveillance, and anomaly detection, need to use change detection\ntechniques. Amongst the most prominent detection methods, there are the\nlearning-based ones, which besides sharing similar training and testing\nprotocols, differ from each other in terms of their architecture design\nstrategies. Such architecture design directly impacts on the quality of the\ndetection results, and also in the device resources capacity, like memory. In\nthis work, we propose a novel Multiscale Cascade Residual Convolutional Neural\nNetwork that integrates multiscale processing strategy through a Residual\nProcessing Module, with a Segmentation Convolutional Neural Network.\nExperiments conducted on two different datasets support the effectiveness of\nthe proposed approach, achieving average overall\n$\\boldsymbol{F\\text{-}measure}$ results of $\\boldsymbol{0.9622}$ and\n$\\boldsymbol{0.9664}$ over Change Detection 2014 and PetrobrasROUTES datasets\nrespectively, besides comprising approximately eight times fewer parameters.\nSuch obtained results place the proposed technique amongst the top four\nstate-of-the-art scene change detection methods.",
    "descriptor": "\nComments: Published in: 2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\n",
    "authors": [
      "Daniel F. S. Santos",
      "Rafael G. Pires",
      "Danilo Colombo",
      "Jo\u00e3o P. Papa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10417"
  },
  {
    "id": "arXiv:2212.10420",
    "title": "Settling the Reward Hypothesis",
    "abstract": "The reward hypothesis posits that, \"all of what we mean by goals and purposes\ncan be well thought of as maximization of the expected value of the cumulative\nsum of a received scalar signal (reward).\" We aim to fully settle this\nhypothesis. This will not conclude with a simple affirmation or refutation, but\nrather specify completely the implicit requirements on goals and purposes under\nwhich the hypothesis holds.",
    "descriptor": "",
    "authors": [
      "Michael Bowling",
      "John D. Martin",
      "David Abel",
      "Will Dabney"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2212.10420"
  },
  {
    "id": "arXiv:2212.10422",
    "title": "Localising In-Domain Adaptation of Transformer-Based Biomedical Language  Models",
    "abstract": "In the era of digital healthcare, the huge volumes of textual information\ngenerated every day in hospitals constitute an essential but underused asset\nthat could be exploited with task-specific, fine-tuned biomedical language\nrepresentation models, improving patient care and management. For such\nspecialized domains, previous research has shown that fine-tuning models\nstemming from broad-coverage checkpoints can largely benefit additional\ntraining rounds over large-scale in-domain resources. However, these resources\nare often unreachable for less-resourced languages like Italian, preventing\nlocal medical institutions to employ in-domain adaptation. In order to reduce\nthis gap, our work investigates two accessible approaches to derive biomedical\nlanguage models in languages other than English, taking Italian as a concrete\nuse-case: one based on neural machine translation of English resources,\nfavoring quantity over quality; the other based on a high-grade, narrow-scoped\ncorpus natively in Italian, thus preferring quality over quantity. Our study\nshows that data quantity is a harder constraint than data quality for\nbiomedical adaptation, but the concatenation of high-quality data can improve\nmodel performance even when dealing with relatively size-limited corpora. The\nmodels published from our investigations have the potential to unlock important\nresearch opportunities for Italian hospitals and academia. Finally, the set of\nlessons learned from the study constitutes valuable insights towards a solution\nto build biomedical language models that are generalizable to other\nless-resourced languages and different domain settings.",
    "descriptor": "",
    "authors": [
      "Tommaso Mario Buonocore",
      "Claudio Crema",
      "Enea Parimbelli",
      "Alberto Redolfi",
      "Riccardo Bellazzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10422"
  },
  {
    "id": "arXiv:2212.10423",
    "title": "Fine-Grained Distillation for Long Document Retrieval",
    "abstract": "Long document retrieval aims to fetch query-relevant documents from a\nlarge-scale collection, where knowledge distillation has become de facto to\nimprove a retriever by mimicking a heterogeneous yet powerful cross-encoder.\nHowever, in contrast to passages or sentences, retrieval on long documents\nsuffers from the scope hypothesis that a long document may cover multiple\ntopics. This maximizes their structure heterogeneity and poses a\ngranular-mismatch issue, leading to an inferior distillation efficacy. In this\nwork, we propose a new learning framework, fine-grained distillation (FGD), for\nlong-document retrievers. While preserving the conventional dense retrieval\nparadigm, it first produces global-consistent representations crossing\ndifferent fine granularity and then applies multi-granular aligned distillation\nmerely during training. In experiments, we evaluate our framework on two\nlong-document retrieval benchmarks, which show state-of-the-art performance.",
    "descriptor": "\nComments: 13 pages, 5 figures, 5 tables\n",
    "authors": [
      "Yucheng Zhou",
      "Tao Shen",
      "Xiubo Geng",
      "Chongyang Tao",
      "Guodong Long",
      "Can Xu",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10423"
  },
  {
    "id": "arXiv:2212.10424",
    "title": "A Passivity Preserving H-infinity Synthesis Technique for Robot Control",
    "abstract": "Most impedance control schemes in robotics implement a desired passive\nimpedance, allowing for stable interaction between the controlled robot and the\nenvironment. However, there is little guidance on the selection of the desired\nimpedance. In general, finding the best stiffness and damping parameters is a\nchallenging task. This paper contributes to this problem by connecting\nimpedance control to robust control, with the goal of shaping the robot\nperformances via feedback. We provide a method based on linear matrix\ninequalities with sparsity constraints to derive impedance controllers that\nsatisfy a H-infinity performance criterion. Our controller guarantees passivity\nof the controlled robot and local performances near key poses.",
    "descriptor": "\nComments: 7 pages, 6 figures. To be published in proceedings of the IEEE Conference on Decision and Control (CDC) 2022\n",
    "authors": [
      "Daniel Larby",
      "Fulvio Forni"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.10424"
  },
  {
    "id": "arXiv:2212.10425",
    "title": "Evaluating Multimodal Interaction of Robots Assisting Older Adults",
    "abstract": "We outline our work on evaluating robots that assist older adults by engaging\nwith them through multiple modalities that include physical interaction. Our\nthesis is that to increase the effectiveness of assistive robots: 1) robots\nneed to understand and effect multimodal actions, 2) robots should not only\nreact to the human, they need to take the initiative and lead the task when it\nis necessary. We start by briefly introducing our proposed framework for\nmultimodal interaction and then describe two different experiments with the\nactual robots. In the first experiment, a Baxter robot helps a human find and\nlocate an object using the Multimodal Interaction Manager (MIM) framework. In\nthe second experiment, a NAO robot is used in the same task, however, the roles\nof the robot and the human are reversed. We discuss the evaluation methods that\nwere used in these experiments, including different metrics employed to\ncharacterize the performance of the robot in each case. We conclude by\nproviding our perspective on the challenges and opportunities for the\nevaluation of assistive robots for older adults in realistic settings.",
    "descriptor": "",
    "authors": [
      "Afagh Mehri Shervedani",
      "Ki-Hwan Oh",
      "Bahareh Abbasi",
      "Natawut Monaikul",
      "Zhanibek Rysbek",
      "Barbara Di Eugenio",
      "Milos Zefran"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.10425"
  },
  {
    "id": "arXiv:2212.10426",
    "title": "Deep Riemannian Networks for EEG Decoding",
    "abstract": "State-of-the-art performance in electroencephalography (EEG) decoding tasks\nis currently often achieved with either Deep-Learning or\nRiemannian-Geometry-based decoders. Recently, there is growing interest in Deep\nRiemannian Networks (DRNs) possibly combining the advantages of both previous\nclasses of methods. However, there are still a range of topics where additional\ninsight is needed to pave the way for a more widespread application of DRNs in\nEEG. These include architecture design questions such as network size and\nend-to-end ability as well as model training questions. How these factors\naffect model performance has not been explored. Additionally, it is not clear\nhow the data within these networks is transformed, and whether this would\ncorrelate with traditional EEG decoding. Our study aims to lay the groundwork\nin the area of these topics through the analysis of DRNs for EEG with a wide\nrange of hyperparameters. Networks were tested on two public EEG datasets and\ncompared with state-of-the-art ConvNets. Here we propose end-to-end EEG SPDNet\n(EE(G)-SPDNet), and we show that this wide, end-to-end DRN can outperform the\nConvNets, and in doing so use physiologically plausible frequency regions. We\nalso show that the end-to-end approach learns more complex filters than\ntraditional band-pass filters targeting the classical alpha, beta, and gamma\nfrequency bands of the EEG, and that performance can benefit from channel\nspecific filtering approaches. Additionally, architectural analysis revealed\nareas for further improvement due to the possible loss of Riemannian specific\ninformation throughout the network. Our study thus shows how to design and\ntrain DRNs to infer task-related information from the raw EEG without the need\nof handcrafted filterbanks and highlights the potential of end-to-end DRNs such\nas EE(G)-SPDNet for high-performance EEG decoding.",
    "descriptor": "\nComments: 26 pages, 15 Figures\n",
    "authors": [
      "Daniel Wilson",
      "Lukas Alexander Wilhelm Gemein",
      "Robin Tibor Schirrmeister",
      "Tonio Ball"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.10426"
  },
  {
    "id": "arXiv:2212.10427",
    "title": "ModularFed: Leveraging Modularity in Federated Learning Frameworks",
    "abstract": "Numerous research recently proposed integrating Federated Learning (FL) to\naddress the privacy concerns of using machine learning in privacy-sensitive\nfirms. However, the standards of the available frameworks can no longer sustain\nthe rapid advancement and hinder the integration of FL solutions, which can be\nprominent in advancing the field. In this paper, we propose ModularFed, a\nresearch-focused framework that addresses the complexity of FL implementations\nand the lack of adaptability and extendability in the available frameworks. We\nprovide a comprehensive architecture that assists FL approaches through\nwell-defined protocols to cover three dominant FL paradigms: adaptable\nworkflow, datasets distribution, and third-party application support. Within\nthis architecture, protocols are blueprints that strictly define the\nframework's components' design, contribute to its flexibility, and strengthen\nits infrastructure. Further, our protocols aim to enable modularity in FL,\nsupporting third-party plug-and-play architecture and dynamic simulators\ncoupled with major built-in data distributors in the field. Additionally, the\nframework support wrapping multiple approaches in a single environment to\nenable consistent replication of FL issues such as clients' deficiency, data\ndistribution, and network latency, which entails a fair comparison of\ntechniques outlying FL technologies. In our evaluation, we examine the\napplicability of our framework addressing three major FL domains, including\nstatistical distribution and modular-based approaches for resource monitoring\nand client selection.",
    "descriptor": "",
    "authors": [
      "Mohamad Arafeh",
      "Hadi Otrok",
      "Hakima Ould-Slimane",
      "Azzam Mourad",
      "Chamseddine Talhi",
      "Ernesto Damiani"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10427"
  },
  {
    "id": "arXiv:2212.10428",
    "title": "HouseCat6D -- A Large-Scale Multi-Modal Category Level 6D Object Pose  Dataset with Household Objects in Realistic Scenarios",
    "abstract": "Estimating the 6D pose of objects is one of the major fields in 3D computer\nvision. Since the promising outcomes from instance-level pose estimation, the\nresearch trends are heading towards category-level pose estimation for more\npractical application scenarios. However, unlike well-established\ninstance-level pose datasets, available category-level datasets lack annotation\nquality and provided pose quantity. We propose the new category level 6D pose\ndataset HouseCat6D featuring 1) Multi-modality of Polarimetric RGB+P and Depth,\n2) Highly diverse 194 objects of 10 household object categories including 2\nphotometrically challenging categories, 3) High-quality pose annotation with an\nerror range of only 1.35 mm to 1.74 mm, 4) 41 large scale scenes with extensive\nviewpoint coverage, 5) Checkerboard-free environment throughout the entire\nscene. We also provide benchmark results of state-of-the-art category-level\npose estimation networks.",
    "descriptor": "",
    "authors": [
      "HyunJun Jung",
      "Shun-Cheng Wu",
      "Patrick Ruhkamp",
      "Hannah Schieber",
      "Pengyuan Wang",
      "Giulia Rizzoli",
      "Hongcheng Zhao",
      "Sven Damian Meier",
      "Daniel Roth",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10428"
  },
  {
    "id": "arXiv:2212.10429",
    "title": "Independent component analysis in the light of Information Geometry",
    "abstract": "I recall my first encounter with Professor Shun-ichi Amari who, once upon a\ntime in Las Vegas, gave me a precious hint about connecting Independent\nComponent Analysis (ICA) to Information Geometry. The paper sketches, rather\ninformally, some of the insights gained in following this lead.",
    "descriptor": "\nComments: Information geometry, Springer, 2022\n",
    "authors": [
      "Jean-Fran\u00e7ois Cardoso"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2212.10429"
  },
  {
    "id": "arXiv:2212.10430",
    "title": "Walking Noise: Understanding Implications of Noisy Computations on  Classification Tasks",
    "abstract": "Machine learning methods like neural networks are extremely successful and\npopular in a variety of applications, however, they come at substantial\ncomputational costs, accompanied by high energy demands. In contrast, hardware\ncapabilities are limited and there is evidence that technology scaling is\nstuttering, therefore, new approaches to meet the performance demands of\nincreasingly complex model architectures are required. As an unsafe\noptimization, noisy computations are more energy efficient, and given a fixed\npower budget also more time efficient. However, any kind of unsafe optimization\nrequires counter measures to ensure functionally correct results.\nThis work considers noisy computations in an abstract form, and gears to\nunderstand the implications of such noise on the accuracy of\nneural-network-based classifiers as an exemplary workload. We propose a\nmethodology called \"Walking Noise\" that allows to assess the robustness of\ndifferent layers of deep architectures by means of a so-called \"midpoint noise\nlevel\" metric. We then investigate the implications of additive and\nmultiplicative noise for different classification tasks and model\narchitectures, with and without batch normalization. While noisy training\nsignificantly increases robustness for both noise types, we observe a clear\ntrend to increase weights and thus increase the signal-to-noise ratio for\nadditive noise injection. For the multiplicative case, we find that some\nnetworks, with suitably simple tasks, automatically learn an internal binary\nrepresentation, hence becoming extremely robust. Overall this work proposes a\nmethod to measure the layer-specific robustness and shares first insights on\nhow networks learn to compensate injected noise, and thus, contributes to\nunderstand robustness against noisy computations.",
    "descriptor": "\nComments: 11 pages, 14 figures, To be published at the 5th Workshop on Accelerated Machine Learning (AccML) at HiPEAC 2023 Conference\n",
    "authors": [
      "Hendrik Borras",
      "Bernhard Klein",
      "Holger Fr\u00f6ning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2212.10430"
  },
  {
    "id": "arXiv:2212.10431",
    "title": "QuantArt: Quantizing Image Style Transfer Towards High Visual Fidelity",
    "abstract": "The mechanism of existing style transfer algorithms is by minimizing a hybrid\nloss function to push the generated image toward high similarities in both\ncontent and style. However, this type of approach cannot guarantee visual\nfidelity, i.e., the generated artworks should be indistinguishable from real\nones. In this paper, we devise a new style transfer framework called QuantArt\nfor high visual-fidelity stylization. QuantArt pushes the latent representation\nof the generated artwork toward the centroids of the real artwork distribution\nwith vector quantization. By fusing the quantized and continuous latent\nrepresentations, QuantArt allows flexible control over the generated artworks\nin terms of content preservation, style similarity, and visual fidelity.\nExperiments on various style transfer settings show that our QuantArt framework\nachieves significantly higher visual fidelity compared with the existing style\ntransfer methods.",
    "descriptor": "",
    "authors": [
      "Siyu Huang",
      "Jie An",
      "Donglai Wei",
      "Jiebo Luo",
      "Hanspeter Pfister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.10431"
  },
  {
    "id": "arXiv:2212.10432",
    "title": "AlphaSparse: Generating High Performance SpMV Codes Directly from Sparse  Matrices",
    "abstract": "Sparse Matrix-Vector multiplication (SpMV) is an essential computational\nkernel in many application scenarios. Tens of sparse matrix formats and\nimplementations have been proposed to compress the memory storage and speed up\nSpMV performance. We develop AlphaSparse, a superset of all existing works that\ngoes beyond the scope of human-designed format(s) and implementation(s).\nAlphaSparse automatically \\emph{creates novel machine-designed formats and SpMV\nkernel implementations} entirely from the knowledge of input sparsity patterns\nand hardware architectures. Based on our proposed Operator Graph that expresses\nthe path of SpMV format and kernel design, AlphaSparse consists of three main\ncomponents: Designer, Format \\& Kernel Generator, and Search Engine. It takes\nan arbitrary sparse matrix as input while outputs the performance\nmachine-designed format and SpMV implementation. By extensively evaluating 843\nmatrices from SuiteSparse Matrix Collection, AlphaSparse achieves significant\nperformance improvement by 3.2$\\times$ on average compared to five\nstate-of-the-art artificial formats and 1.5$\\times$ on average (up to\n2.7$\\times$) over the up-to-date implementation of traditional auto-tuning\nphilosophy.",
    "descriptor": "",
    "authors": [
      "Zhen Du",
      "Jiajia Li",
      "Yinshan Wang",
      "Xueqi Li",
      "Guangming Tan",
      "Ninghui Sun"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2212.10432"
  },
  {
    "id": "arXiv:2212.10433",
    "title": "Scheduling with Predictions",
    "abstract": "There is significant interest in deploying machine learning algorithms for\ndiagnostic radiology, as modern learning techniques have made it possible to\ndetect abnormalities in medical images within minutes. While machine-assisted\ndiagnoses cannot yet reliably replace human reviews of images by a radiologist,\nthey could inform prioritization rules for determining the order by which to\nreview patient cases so that patients with time-sensitive conditions could\nbenefit from early intervention.\nWe study this scenario by formulating it as a learning-augmented online\nscheduling problem. We are given information about each arriving patient's\nurgency level in advance, but these predictions are inevitably error-prone. In\nthis formulation, we face the challenges of decision making under imperfect\ninformation, and of responding dynamically to prediction error as we observe\nbetter data in real-time. We propose a simple online policy and show that this\npolicy is in fact the best possible in certain stylized settings. We also\ndemonstrate that our policy achieves the two desiderata of online algorithms\nwith predictions: consistency (performance improvement with prediction\naccuracy) and robustness (protection against the worst case). We complement our\ntheoretical findings with empirical evaluations of the policy under settings\nthat more accurately reflect clinical scenarios in the real world.",
    "descriptor": "",
    "authors": [
      "Woo-Hyung Cho",
      "Shane Henderson",
      "David Shmoys"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10433"
  },
  {
    "id": "arXiv:2212.10435",
    "title": "The Expertise Level",
    "abstract": "Computers are quickly gaining on us. Artificial systems are now exceeding the\nperformance of human experts in several domains. However, we do not yet have a\ndeep definition of expertise. This paper examines the nature of expertise and\npresents an abstract knowledge-level and skill-level description of expertise.\nA new level lying above the Knowledge Level, called the Expertise Level, is\nintroduced to describe the skills of an expert without having to worry about\ndetails of the knowledge required. The Model of Expertise is introduced\ncombining the knowledge-level and expertise-level descriptions. Application of\nthe model to the fields of cognitive architectures and human cognitive\naugmentation is demonstrated and several famous intelligent systems are\nanalyzed with the model.",
    "descriptor": "\nComments: 18 pages; 11 figures\n",
    "authors": [
      "Ron Fulbright"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10435"
  },
  {
    "id": "arXiv:2212.10437",
    "title": "Wireless Power Transfer Analysis using Ansys",
    "abstract": "In this report, methods of wireless power transfer of inside a cage is\ncompared and simulated. Software Ansys Electronics Maxwell was used to simulate\nmagnetic coupling of transmitter(s) and receiver with 10mA winding current in\nthe mouse cage.",
    "descriptor": "",
    "authors": [
      "Carl Zhang",
      "Xilin Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.10437"
  },
  {
    "id": "arXiv:2212.10438",
    "title": "Is Semantic Communications Secure? A Tale of Multi-Domain Adversarial  Attacks",
    "abstract": "Semantic communications seeks to transfer information from a source while\nconveying a desired meaning to its destination. We model the\ntransmitter-receiver functionalities as an autoencoder followed by a task\nclassifier that evaluates the meaning of the information conveyed to the\nreceiver. The autoencoder consists of an encoder at the transmitter to jointly\nmodel source coding, channel coding, and modulation, and a decoder at the\nreceiver to jointly model demodulation, channel decoding and source decoding.\nBy augmenting the reconstruction loss with a semantic loss, the two deep neural\nnetworks (DNNs) of this encoder-decoder pair are interactively trained with the\nDNN of the semantic task classifier. This approach effectively captures the\nlatent feature space and reliably transfers compressed feature vectors with a\nsmall number of channel uses while keeping the semantic loss low. We identify\nthe multi-domain security vulnerabilities of using the DNNs for semantic\ncommunications. Based on adversarial machine learning, we introduce test-time\n(targeted and non-targeted) adversarial attacks on the DNNs by manipulating\ntheir inputs at different stages of semantic communications. As a computer\nvision attack, small perturbations are injected to the images at the input of\nthe transmitter's encoder. As a wireless attack, small perturbations signals\nare transmitted to interfere with the input of the receiver's decoder. By\nlaunching these stealth attacks individually or more effectively in a combined\nform as a multi-domain attack, we show that it is possible to change the\nsemantics of the transferred information even when the reconstruction loss\nremains low. These multi-domain adversarial attacks pose as a serious threat to\nthe semantics of information transfer (with larger impact than conventional\njamming) and raise the need of defense methods for the safe adoption of\nsemantic communications.",
    "descriptor": "",
    "authors": [
      "Yalin E. Sagduyu",
      "Tugba Erpek",
      "Sennur Ulukus",
      "Aylin Yener"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.10438"
  },
  {
    "id": "arXiv:2212.10439",
    "title": "On the Convergence of Policy Gradient in Robust MDPs",
    "abstract": "Robust Markov decision processes (RMDPs) are promising models that provide\nreliable policies under ambiguities in model parameters. As opposed to nominal\nMarkov decision processes (MDPs), however, the state-of-the-art solution\nmethods for RMDPs are limited to value-based methods, such as value iteration\nand policy iteration. This paper proposes Double-Loop Robust Policy Gradient\n(DRPG), the first generic policy gradient method for RMDPs with a global\nconvergence guarantee in tabular problems. Unlike value-based methods, DRPG\ndoes not rely on dynamic programming techniques. In particular, the inner-loop\nrobust policy evaluation problem is solved via projected gradient descent.\nFinally, our experimental results demonstrate the performance of our algorithm\nand verify our theoretical guarantees.",
    "descriptor": "",
    "authors": [
      "Qiuhao Wang",
      "Chin Pang Ho",
      "Marek Petrik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10439"
  },
  {
    "id": "arXiv:2212.10440",
    "title": "Perplexed by Quality: A Perplexity-based Method for Adult and Harmful  Content Detection in Multilingual Heterogeneous Web Data",
    "abstract": "As demand for large corpora increases with the size of current\nstate-of-the-art language models, using web data as the main part of the\npre-training corpus for these models has become a ubiquitous practice. This, in\nturn, has introduced an important challenge for NLP practitioners, as they are\nnow confronted with the task of developing highly optimized models and\npipelines for pre-processing large quantities of textual data, which implies,\neffectively classifying and filtering multilingual, heterogeneous and noisy\ndata, at web scale. One of the main components of this pre-processing step for\nthe pre-training corpora of large language models, is the removal of adult and\nharmful content. In this paper we explore different methods for detecting adult\nand harmful of content in multilingual heterogeneous web data. We first show\nhow traditional methods in harmful content detection, that seemingly perform\nquite well in small and specialized datasets quickly break down when confronted\nwith heterogeneous noisy web data. We then resort to using a perplexity based\napproach but with a twist: Instead of using a so-called \"clean\" corpus to train\na small language model and then use perplexity so select the documents with low\nperplexity, i.e., the documents that resemble this so-called \"clean\" corpus the\nmost. We train solely with adult and harmful textual data, and then select the\ndocuments having a perplexity value above a given threshold. This approach will\nvirtually cluster our documents into two distinct groups, which will greatly\nfacilitate the choice of the threshold for the perplexity and will also allow\nus to obtain higher precision than with the traditional classification methods\nfor detecting adult and harmful content.",
    "descriptor": "\nComments: 14 pages, 2 figures\n",
    "authors": [
      "Tim Jansen",
      "Yangling Tong",
      "Victoria Zevallos",
      "Pedro Ortiz Suarez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10440"
  },
  {
    "id": "arXiv:2212.10441",
    "title": "First CE Matters: On the Importance of Long Term Properties on Memory  Failure Prediction",
    "abstract": "Dynamic random access memory failures are a threat to the reliability of data\ncentres as they lead to data loss and system crashes. Timely predictions of\nmemory failures allow for taking preventive measures such as server migration\nand memory replacement. Thereby, memory failure prediction prevents failures\nfrom externalizing, and it is a vital task to improve system reliability. In\nthis paper, we revisited the problem of memory failure prediction. We analyzed\nthe correctable errors (CEs) from hardware logs as indicators for a degraded\nmemory state. As memories do not always work with full occupancy, access to\nfaulty memory parts is time distributed. Following this intuition, we observed\nthat important properties for memory failure prediction are distributed through\nlong time intervals. In contrast, related studies, to fit practical\nconstraints, frequently only analyze the CEs from the last fixed-size time\ninterval while ignoring the predating information. Motivated by the observed\ndiscrepancy, we study the impact of including the overall (long-range) CE\nevolution and propose novel features that are calculated incrementally to\npreserve long-range properties. By coupling the extracted features with machine\nlearning methods, we learn a predictive model to anticipate upcoming failures\nthree hours in advance while improving the average relative precision and\nrecall for 21% and 19% accordingly. We evaluated our methodology on real-world\nmemory failures from the server fleet of a large cloud provider, justifying its\nvalidity and practicality.",
    "descriptor": "\nComments: This paper is accepted to appear in the proceedings of IEEE Big Data 2022. All publishing licenses belong to IEEE\n",
    "authors": [
      "Jasmin Bogatinovski",
      "Qiao Yu",
      "Jorge Cardoso",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.10441"
  },
  {
    "id": "arXiv:2212.10443",
    "title": "Software Ecosystems: A Tertiary Study and a Thematic Model",
    "abstract": "A software ecosystem (SECO) is an interaction, communication, cooperation,\nand synergy among a set of players. Depending on the actors type of interaction\nwith others, each one can play a different role. These interactions provide a\nset of positive relationships (symbiosis) between actors who work together\naround a common technology platform or a service. SECO has been explored in\nseveral studies, some related to their general characteristics and others\nfocusing on a specific topic (e.g., requirements, governance, open-source,\nmobile). There are many literature reviews of different natures (e.g.,\nsystematic literature reviews and systematic mapping studies). This study\npresents the status of the SECO field motivated by analyzing several secondary\nstudies published over the years. To do so, we conducted a tertiary study. From\nan initial set of 518 studies on the subject, we selected 22 studies. We\nidentified the theoretical foundations used by researchers and their influences\nand relationships with other ecosystems. We performed a thematic synthesis and\nidentified one high-order theme, 5 themes, 10 subthemes, and 206 categories. As\na result, we proposed a thematic model for SECO containing five themes, namely:\nsocial, technical, business, management, and an evaluation theme named Software\nEcosystems Assessment Models (SEAM). Our main conclusion is that relationships\nbetween SECO themes should not be seen in isolation, and it must be interpreted\nin a holistic approach, given the number of implications to other themes mainly\nrelated to the distinction of governance and management activities in the SECO\ninteractions. Finally, this work provides an overview of the field and points\nout areas for future research, such as the need of SECO community to further\ninvestigate the results from other ecosystems, mainly from the Digital\nEcosystem and Digital Business Ecosystem communities.",
    "descriptor": "",
    "authors": [
      "Paulo Malcher",
      "Olavo Barbosa",
      "Davi Viana",
      "Rodrigo Santos"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.10443"
  },
  {
    "id": "arXiv:2212.10445",
    "title": "Recycling diverse models for out-of-distribution generalization",
    "abstract": "Foundation models are redefining how AI systems are built. Practitioners now\nfollow a standard procedure to build their machine learning solutions: download\na copy of a foundation model, and fine-tune it using some in-house data about\nthe target task of interest. Consequently, the Internet is swarmed by a handful\nof foundation models fine-tuned on many diverse tasks. Yet, these individual\nfine-tunings often lack strong generalization and exist in isolation without\nbenefiting from each other. In our opinion, this is a missed opportunity, as\nthese specialized models contain diverse features. Based on this insight, we\npropose model recycling, a simple strategy that leverages multiple fine-tunings\nof the same foundation model on diverse auxiliary tasks, and repurposes them as\nrich and diverse initializations for the target task. Specifically, model\nrecycling fine-tunes in parallel each specialized model on the target task, and\nthen averages the weights of all target fine-tunings into a final model.\nEmpirically, we show that model recycling maximizes model diversity by\nbenefiting from diverse auxiliary tasks, and achieves a new state of the art on\nthe reference DomainBed benchmark for out-of-distribution generalization.\nLooking forward, model recycling is a contribution to the emerging paradigm of\nupdatable machine learning where, akin to open-source software development, the\ncommunity collaborates to incrementally and reliably update machine learning\nmodels.",
    "descriptor": "\nComments: 24 pages, 7 tables, 13 figures\n",
    "authors": [
      "Alexandre Ram\u00e9",
      "Kartik Ahuja",
      "Jianyu Zhang",
      "Matthieu Cord",
      "L\u00e9on Bottou",
      "David Lopez-Paz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10445"
  },
  {
    "id": "arXiv:2212.10446",
    "title": "Neural Network Learner for Minesweeper",
    "abstract": "Minesweeper is an interesting single player game based on logic, memory and\nguessing. Solving Minesweeper has been shown to be an NP-hard task.\nDeterministic solvers are the best known approach for solving Minesweeper. This\nproject proposes a neural network based learner for solving Minesweeper. To\nchoose the best learner, different architectures and configurations of neural\nnetworks were trained on hundreds of thousands of games. Surprisingly, the\nproposed neural network based learner has shown to be a very good approximation\nfunction for solving Minesweeper. The neural network learner competes well with\nthe CSP solvers, especially in Beginner and Intermediate modes of the game. It\nwas also observed that despite having high success rates, the best neural\nlearner was considerably slower than the best deterministic solver. This report\nalso discusses the overheads and limitations faced while creating highly\nsuccessful neural networks for Minesweeper.",
    "descriptor": "",
    "authors": [
      "M Hamza Sajjad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10446"
  },
  {
    "id": "arXiv:2212.10448",
    "title": "Parameter-efficient Zero-shot Transfer for Cross-Language Dense  Retrieval with Adapters",
    "abstract": "A popular approach to creating a zero-shot cross-language retrieval model is\nto substitute a monolingual pretrained language model in the retrieval model\nwith a multilingual pretrained language model such as Multilingual BERT. This\nmultilingual model is fined-tuned to the retrieval task with monolingual data\nsuch as English MS MARCO using the same training recipe as the monolingual\nretrieval model used. However, such transferred models suffer from mismatches\nin the languages of the input text during training and inference. In this work,\nwe propose transferring monolingual retrieval models using adapters, a\nparameter-efficient component for a transformer network. By adding adapters\npretrained on language tasks for a specific language with task-specific\nadapters, prior work has shown that the adapter-enhanced models perform better\nthan fine-tuning the entire model when transferring across languages in various\nNLP tasks. By constructing dense retrieval models with adapters, we show that\nmodels trained with monolingual data are more effective than fine-tuning the\nentire model when transferring to a Cross Language Information Retrieval (CLIR)\nsetting. However, we found that the prior suggestion of replacing the language\nadapters to match the target language at inference time is suboptimal for dense\nretrieval models. We provide an in-depth analysis of this discrepancy between\nother cross-language NLP tasks and CLIR.",
    "descriptor": "\nComments: 15 pages, 1 figure\n",
    "authors": [
      "Eugene Yang",
      "Suraj Nair",
      "Dawn Lawrie",
      "James Mayfield",
      "Douglas W. Oard"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10448"
  },
  {
    "id": "arXiv:2212.10449",
    "title": "Socratic Pretraining: Question-Driven Pretraining for Controllable  Summarization",
    "abstract": "In long document controllable summarization, where labeled data is scarce,\npretrained models struggle to adapt to the task and effectively respond to user\nqueries. In this paper, we introduce Socratic pretraining, a question-driven,\nunsupervised pretraining objective specifically designed to improve\ncontrollability in summarization tasks. By training a model to generate and\nanswer relevant questions in a given context, Socratic pretraining enables the\nmodel to more effectively adhere to user-provided queries and identify relevant\ncontent to be summarized. We demonstrate the effectiveness of this approach\nthrough extensive experimentation on two summarization domains, short stories\nand dialogue, and multiple control strategies: keywords, questions, and factoid\nQA pairs. Our pretraining method relies only on unlabeled documents and a\nquestion generation system and outperforms pre-finetuning approaches that use\nadditional supervised data. Furthermore, our results show that Socratic\npretraining cuts task-specific labeled data requirements in half, is more\nfaithful to user-provided queries, and achieves state-of-the-art performance on\nQMSum and SQuALITY.",
    "descriptor": "",
    "authors": [
      "Artidoro Pagnoni",
      "Alexander R. Fabbri",
      "Wojciech Kry\u015bci\u0144ski",
      "Chien-Sheng Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10449"
  },
  {
    "id": "arXiv:2212.10450",
    "title": "Is GPT-3 a Good Data Annotator?",
    "abstract": "GPT-3 (Generative Pre-trained Transformer 3) is a large-scale autoregressive\nlanguage model developed by OpenAI, which has demonstrated impressive few-shot\nperformance on a wide range of natural language processing (NLP) tasks. Hence,\nan intuitive application is to use it for data annotation. In this paper, we\ninvestigate whether GPT-3 can be used as a good data annotator for NLP tasks.\nData annotation is the process of labeling data that could be used to train\nmachine learning models. It is a crucial step in the development of NLP\nsystems, as it allows the model to learn the relationship between the input\ndata and the desired output. Given the impressive language capabilities of\nGPT-3, it is natural to wonder whether it can be used to effectively annotate\ndata for NLP tasks. In this paper, we evaluate the performance of GPT-3 as a\ndata annotator by comparing it with traditional data annotation methods and\nanalyzing its output on a range of tasks. Through this analysis, we aim to\nprovide insight into the potential of GPT-3 as a general-purpose data annotator\nin NLP.",
    "descriptor": "",
    "authors": [
      "Bosheng Ding",
      "Chengwei Qin",
      "Linlin Liu",
      "Lidong Bing",
      "Shafiq Joty",
      "Boyang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10450"
  },
  {
    "id": "arXiv:2212.10452",
    "title": "Towards Sequence Utility Maximization under Utility Occupancy Measure",
    "abstract": "The discovery of utility-driven patterns is a useful and difficult research\ntopic. It can extract significant and interesting information from specific and\nvaried databases, increasing the value of the services provided. In practice,\nthe measure of utility is often used to demonstrate the importance, profit, or\nrisk of an object or a pattern. In the database, although utility is a flexible\ncriterion for each pattern, it is a more absolute criterion due to the neglect\nof utility sharing. This leads to the derived patterns only exploring partial\nand local knowledge from a database. Utility occupancy is a recently proposed\nmodel that considers the problem of mining with high utility but low occupancy.\nHowever, existing studies are concentrated on itemsets that do not reveal the\ntemporal relationship of object occurrences. Therefore, this paper towards\nsequence utility maximization. We first define utility occupancy on sequence\ndata and raise the problem of High Utility-Occupancy Sequential Pattern Mining\n(HUOSPM). Three dimensions, including frequency, utility, and occupancy, are\ncomprehensively evaluated in HUOSPM. An algorithm called Sequence Utility\nMaximization with Utility occupancy measure (SUMU) is proposed. Furthermore,\ntwo data structures for storing related information about a pattern,\nUtility-Occupancy-List-Chain (UOL-Chain) and Utility-Occupancy-Table (UO-Table)\nwith six associated upper bounds, are designed to improve efficiency. Empirical\nexperiments are carried out to evaluate the novel algorithm's efficiency and\neffectiveness. The influence of different upper bounds and pruning strategies\nis analyzed and discussed. The comprehensive results suggest that the work of\nour algorithm is intelligent and effective.",
    "descriptor": "\nComments: Preprint. 7 figures, 8 tables\n",
    "authors": [
      "Gengsen Huang",
      "Wensheng Gan",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10452"
  },
  {
    "id": "arXiv:2212.10453",
    "title": "Pragmatic isomorphism proofs between Coq representations: application to  lambda-term families",
    "abstract": "There are several ways to formally represent families of data, such as lambda\nterms, in a type theory such as the dependent type theory of Coq. Mathematical\nrepresentations are very compact ones and usually rely on the use of dependent\ntypes, but they tend to be difficult to handle in practice. On the contrary,\nimplementations based on a larger (and simpler) data structure combined with a\nrestriction property are much easier to deal with.\nIn this work, we study several families related to lambda terms, among which\nMotzkin trees, seen as lambda term skeletons, closable Motzkin trees,\ncorresponding to closed lambda terms, and a parameterized family of open lambda\nterms. For each of these families, we define two different representations,\nshow that they are isomorphic and provide tools to switch from one\nrepresentation to another. All these datatypes and their associated\ntransformations are implemented in the Coq proof assistant. Furthermore we\nimplement random generators for each representation, using the QuickChick\nplugin.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Catherine Dubois",
      "Nicolas Magaud",
      "Alain Giorgetti"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.10453"
  },
  {
    "id": "arXiv:2212.10454",
    "title": "Wind Power Scenario Generation Using Graph Convolutional Generative  Adversarial Network",
    "abstract": "Generating wind power scenarios is very important for studying the impacts of\nmultiple wind farms that are interconnected to the grid. We develop a graph\nconvolutional generative adversarial network (GCGAN) approach by leveraging\nGAN's capability in generating large number of realistic scenarios without\nusing statistical modeling. Unlike existing GAN-based wind power data\ngeneration approaches, we design GAN's hidden layers to match the underlying\nspatial and temporal characteristics. We advocate to use graph filters to embed\nthe spatial correlation among multiple wind farms, and a one-dimensional (1D)\nconvolutional layer for representing the temporal feature filters. The proposed\ngraph and feature filter designs significantly reduce the GAN model complexity,\nleading to improvements on the training efficiency and computation complexity.\nNumerical results using real wind power data from Australia demonstrate that\nthe scenarios generated by the proposed GCGAN exhibit more realistic spatial\nand temporal statistics than other GAN-based outputs.",
    "descriptor": "",
    "authors": [
      "Young-ho Cho",
      "Shaohui Liu",
      "Duehee Lee",
      "Hao Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.10454"
  },
  {
    "id": "arXiv:2212.10455",
    "title": "MULTI3NLU++: A Multilingual, Multi-Intent, Multi-Domain Dataset for  Natural Language Understanding in Task-Oriented Dialogue",
    "abstract": "Task-oriented dialogue (TOD) systems have been applied in a range of domains\nto support human users to achieve specific goals. Systems are typically\nconstructed for a single domain or language and do not generalise well beyond\nthis. Their extension to other languages in particular is restricted by the\nlack of available training data for many of the world's languages. To support\nwork on Natural Language Understanding (NLU) in TOD across multiple languages\nand domains simultaneously, we constructed MULTI3NLU++, a multilingual,\nmulti-intent, multi-domain dataset. MULTI3NLU++ extends the English-only NLU++\ndataset to include manual translations into a range of high, medium and low\nresource languages (Spanish, Marathi, Turkish and Amharic), in two domains\n(banking and hotels). MULTI3NLU++ inherits the multi-intent property of NLU++,\nwhere an utterance may be labelled with multiple intents, providing a more\nrealistic representation of a user's goals and aligning with the more complex\ntasks that commercial systems aim to model. We use MULTI3NLU++ to benchmark\nstate-of-the-art multilingual language models as well as Machine Translation\nand Question Answering systems for the NLU task of intent detection for TOD\nsystems in the multilingual setting. The results demonstrate the challenging\nnature of the dataset, particularly in the low-resource language setting.",
    "descriptor": "\nComments: Release of Dataset v1\n",
    "authors": [
      "Nikita Moghe",
      "Evgeniia Razumovskaia",
      "Liane Guillou",
      "Ivan Vuli\u0107",
      "Anna Korhonen",
      "Alexandra Birch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10455"
  },
  {
    "id": "arXiv:2212.10458",
    "title": "Base Station Selection and Task Offloading of the Mobile Edge Computing  System",
    "abstract": "Based on the two decision variables, service location and base station\nselection, construct a computational model of the switching delay,\ncommunication delay, and queuing delay patterns of a mobile edge computing\nsystem in each time horizon; minimize the non-switching latency to obtain the\nservice deployment and base station selection decision at the initial time\nhorizon; compute the switching latency and non-switching latency of the current\ntime horizon based on the decision of the previous time horizon, and determine\nthe current time horizon based on the principle of larger non-switching latency\ntolerance. If the service is not reallocated, the decision for the current time\nslot remains the same as the decision for the previous time slot; if the\nservice is reallocated, the non-reach time of the current time slot is\nminimized and the service allocation and base station selection decision for\nthe current time slot is obtained; the service allocation and base station\nselection decisions for all time slots are iteratively computed. This paper\nprovides low-latency processing and quality of service for users to satisfy the\nrandomness of user movement.",
    "descriptor": "",
    "authors": [
      "Ruan Yanjiao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.10458"
  },
  {
    "id": "arXiv:2212.10459",
    "title": "Pareto Pairwise Ranking for Fairness Enhancement of Recommender Systems",
    "abstract": "Learning to rank is an effective recommendation approach since its\nintroduction around 2010. Famous algorithms such as Bayesian Personalized\nRanking and Collaborative Less is More Filtering have left deep impact in both\nacademia and industry. However, most learning to rank approaches focus on\nimproving technical accuracy metrics such as AUC, MRR and NDCG. Other\nevaluation metrics of recommender systems like fairness have been largely\noverlooked until in recent years. In this paper, we propose a new learning to\nrank algorithm named Pareto Pairwise Ranking. We are inspired by the idea of\nBayesian Personalized Ranking and power law distribution. We show that our\nalgorithm is competitive with other algorithms when evaluated on technical\naccuracy metrics. What is more important, in our experiment section we\ndemonstrate that Pareto Pairwise Ranking is the most fair algorithm in\ncomparison with 9 other contemporary algorithms.",
    "descriptor": "",
    "authors": [
      "Hao Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10459"
  },
  {
    "id": "arXiv:2212.10460",
    "title": "PoissonMat: Remodeling Matrix Factorization using Poisson Distribution  and Solving the Cold Start Problem without Input Data",
    "abstract": "Matrix Factorization is one of the most successful recommender system\ntechniques over the past decade. However, the classic probabilistic theory\nframework for matrix factorization is modeled using normal distributions. To\nfind better probabilistic models, algorithms such as RankMat, ZeroMat and\nDotMat have been invented in recent years. In this paper, we model the user\nrating behavior in recommender system as a Poisson process, and design an\nalgorithm that relies on no input data to solve the recommendation problem and\nthe cold start issue at the same time. We prove the superiority of our\nalgorithm in comparison with matrix factorization, random placement, Zipf\nplacement, ZeroMat, DotMat, etc.",
    "descriptor": "",
    "authors": [
      "Hao Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10460"
  },
  {
    "id": "arXiv:2212.10461",
    "title": "Go-tuning: Improving Zero-shot Learning Abilities of Smaller Language  Models",
    "abstract": "With increasing scale, large language models demonstrate both quantitative\nimprovement and new qualitative capabilities, especially as zero-shot learners,\nlike GPT-3. However, these results rely heavily on delicate prompt design and\nlarge computation. In this work, we explore whether the strong zero-shot\nability could be achieved at a smaller model scale without any external\nsupervised data. To achieve this goal, we revisit masked language modeling and\npresent a geometry-guided self-supervised learning method (Go-tuningfor short)\nby taking a small number of task-aware self-supervised data to update language\nmodels further. Experiments show that Go-tuning can enable T5-small (80M)\ncompetitive zero-shot results compared with large language models, such as\nT5-XL (3B). We also apply Go-tuning on multi-task settings and develop a\nmulti-task model, mgo-T5 (250M). It can reach the average performance of OPT\n(175B) on 9 datasets.",
    "descriptor": "",
    "authors": [
      "Jingjing Xu",
      "Qingxiu Dong",
      "Hongyi Liu",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10461"
  },
  {
    "id": "arXiv:2212.10465",
    "title": "SODA: Million-scale Dialogue Distillation with Social Commonsense  Contextualization",
    "abstract": "We present SODA: the first publicly available, million-scale high-quality\nsocial dialogue dataset. Using SODA, we train COSMO: a generalizable\nconversation agent outperforming previous best-performing agents on both in-\nand out-of-domain datasets.\nIn contrast to most existing crowdsourced, small-scale dialogue corpora, we\ndistill 1.5M socially-grounded dialogues from a pre-trained language model\n(InstructGPT; Ouyang et al., 2022). Dialogues are distilled by contextualizing\nsocial commonsense knowledge from a knowledge graph (Atomic10x; West et al.,\n2022). Human evaluation shows that dialogues in SODA are more consistent,\nspecific, and (surprisingly) natural than prior human-authored datasets - e.g.,\nDailyDialog (Li et al., 2017), BlendedSkillTalk (Smith et al., 2020).\nIn addition, extensive evaluations show that COSMO is significantly more\nnatural and consistent on unseen datasets than best-performing dialogue models\n- e.g., GODEL (Peng et al., 2022), BlenderBot (Roller et al., 2021), DialoGPT\n(Zhang et al., 2020). Furthermore, it is sometimes even preferred to the\noriginal human-written gold responses. We make our data, models, and code\npublic.",
    "descriptor": "\nComments: Dataset, models, and code can be found at this https URL\n",
    "authors": [
      "Hyunwoo Kim",
      "Jack Hessel",
      "Liwei Jiang",
      "Ximing Lu",
      "Youngjae Yu",
      "Pei Zhou",
      "Ronan Le Bras",
      "Malihe Alikhani",
      "Gunhee Kim",
      "Maarten Sap",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10465"
  },
  {
    "id": "arXiv:2212.10466",
    "title": "Controllable Text Generation with Language Constraints",
    "abstract": "We consider the task of text generation in language models with constraints\nspecified in natural language. To this end, we first create a challenging\nbenchmark Cognac that provides as input to the model a topic with example text,\nalong with a constraint on text to be avoided. Unlike prior work, our benchmark\ncontains knowledge-intensive constraints sourced from databases like Wordnet\nand Wikidata, which allows for straightforward evaluation while striking a\nbalance between broad attribute-level and narrow lexical-level controls. We\nfind that even state-of-the-art language models like GPT-3 fail often on this\ntask, and propose a solution to leverage a language model's own internal\nknowledge to guide generation. Our method, called CognacGen, first queries the\nlanguage model to generate guidance terms for a specified topic or constraint,\nand uses the guidance to modify the model's token generation probabilities. We\npropose three forms of guidance (binary verifier, top-k tokens, textual\nexample), and employ prefix-tuning approaches to distill the guidance to tackle\ndiverse natural language constraints. Through extensive empirical evaluations,\nwe demonstrate that CognacGen can successfully generalize to unseen\ninstructions and outperform competitive baselines in generating constraint\nconforming text.",
    "descriptor": "",
    "authors": [
      "Howard Chen",
      "Huihan Li",
      "Danqi Chen",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10466"
  },
  {
    "id": "arXiv:2212.10467",
    "title": "Generic Temporal Reasoning with Differential Analysis and Explanation",
    "abstract": "Temporal reasoning is the task of predicting temporal relations of event\npairs with corresponding contexts. While some temporal reasoning models perform\nreasonably well on in-domain benchmarks, we have little idea of the systems'\ngeneralizability due to existing datasets' limitations. In this work, we\nintroduce a novel task named TODAY that bridges this gap with temporal\ndifferential analysis, which as the name suggests, evaluates if systems can\ncorrectly understand the effect of incremental changes. Specifically, TODAY\nmakes slight context changes for given event pairs, and systems need to tell\nhow this subtle contextual change will affect temporal relation distributions.\nTo facilitate learning, TODAY also annotates human explanations. We show that\nexisting models, including GPT-3, drop to random guessing on TODAY, suggesting\nthat they heavily rely on spurious information rather than proper reasoning for\ntemporal predictions. On the other hand, we show that TODAY's supervision style\nand explanation annotations can be used in joint learning and encourage models\nto use more appropriate signals during training and outperform across several\nbenchmarks. TODAY can also be used to train models to solicit incidental\nsupervision from noisy sources such as GPT-3 and moves farther towards generic\ntemporal reasoning systems.",
    "descriptor": "",
    "authors": [
      "Yu Feng",
      "Ben Zhou",
      "Haoyu Wang",
      "Helen Jin",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10467"
  },
  {
    "id": "arXiv:2212.10469",
    "title": "BMX: Boosting Machine Translation Metrics with Explainability",
    "abstract": "State-of-the-art machine translation evaluation metrics are based on\nblack-box language models. Hence, recent works consider their explainability\nwith the goals of better understandability for humans and better metric\nanalysis, including failure cases. In contrast, we explicitly leverage\nexplanations to boost the metrics' performance. In particular, we perceive\nexplanations as word-level scores, which we convert, via power means, into\nsentence-level scores. We combine this sentence-level score with the original\nmetric to obtain a better metric. Our extensive evaluation and analysis across\n5 datasets, 5 metrics and 4 explainability techniques shows that some\nconfigurations reliably improve the original metrics' correlation with human\njudgment. On two held datasets for testing, we obtain improvements in 15/18\nresp. 4/4 cases. The gains in Pearson correlation are up to 0.032 resp. 0.055.\nWe make our code available.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Christoph Leiter",
      "Hoa Nguyen",
      "Steffen Eger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10469"
  },
  {
    "id": "arXiv:2212.10471",
    "title": "Little Red Riding Hood Goes Around the Globe:Crosslingual Story Planning  and Generation with Large Language Models",
    "abstract": "We consider the problem of automatically generating stories in multiple\nlanguages. Compared to prior work in monolingual story generation, crosslingual\nstory generation allows for more universal research on story planning. We\npropose to use Prompting Large Language Models with Plans to study which plan\nis optimal for story generation. We consider 4 types of plans and\nsystematically analyse how the outputs differ for different planning\nstrategies. The study demonstrates that formulating the plans as\nquestion-answer pairs leads to more coherent generated stories while the plan\ngives more control to the story creators.",
    "descriptor": "",
    "authors": [
      "Evgeniia Razumovskaia",
      "Joshua Maynez",
      "Annie Louis",
      "Mirella Lapata",
      "Shashi Narayan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10471"
  },
  {
    "id": "arXiv:2212.10474",
    "title": "ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free  Language Models",
    "abstract": "State-of-the-art poetry generation systems are often complex. They either\nconsist of task-specific model pipelines, incorporate prior knowledge in the\nform of manually created constraints or both. In contrast, end-to-end models\nwould not suffer from the overhead of having to model prior knowledge and could\nlearn the nuances of poetry from data alone, reducing the degree of human\nsupervision required. In this work, we investigate end-to-end poetry generation\nconditioned on styles such as rhyme, meter, and alliteration. We identify and\naddress lack of training data and mismatching tokenization algorithms as\npossible limitations of past attempts. In particular, we successfully pre-train\nand release ByGPT5, a new token-free decoder-only language model, and fine-tune\nit on a large custom corpus of English and German quatrains annotated with our\nstyles. We show that ByGPT5 outperforms other models such as mT5, ByT5, GPT-2\nand ChatGPT, while also being more parameter efficient and performing favorably\ncompared to humans. In addition, we analyze its runtime performance and\nintrospect the model's understanding of style conditions. We make our code,\nmodels, and datasets publicly available.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Jonas Belouadi",
      "Steffen Eger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10474"
  },
  {
    "id": "arXiv:2212.10477",
    "title": "Generalized Simultaneous Perturbation Stochastic Approximation with  Reduced Estimator Bias",
    "abstract": "We present in this paper a family of generalized simultaneous perturbation\nstochastic approximation (G-SPSA) estimators that estimate the gradient of the\nobjective using noisy function measurements, but where the number of function\nmeasurements and the form of the gradient estimator is guided by the desired\nestimator bias. In particular, estimators with more function measurements are\nseen to result in lower bias. We provide an analysis of convergence of the\ngeneralized SPSA algorithm, and point to possible future directions.",
    "descriptor": "",
    "authors": [
      "Shalabh Bhatnagar",
      "Prashanth L.A"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.10477"
  },
  {
    "id": "arXiv:2212.10481",
    "title": "Execution-Based Evaluation for Open-Domain Code Generation",
    "abstract": "To extend the scope of coding queries to more realistic settings, we propose\nODEX, the first open-domain execution-based natural language (NL) to code\ngeneration dataset. ODEX has 945 NL-Code pairs spanning 79 diverse libraries,\nalong with 1,707 human-written test cases for execution. Our NL-Code pairs are\nharvested from StackOverflow forums to encourage natural and practical coding\nqueries, which are then carefully rephrased to ensure intent clarity and\nprevent potential data memorization. Moreover, ODEX supports four natural\nlanguages as intents, in English, Spanish, Japanese, and Russian. ODEX unveils\nintriguing behavioral differences between top-performing Code LMs: Codex\nperforms better on open-domain queries, yet CodeGen captures a better balance\nbetween open- and closed-domain. ODEX corroborates the merits of\nexecution-based evaluation over metrics without execution but also unveils\ntheir complementary effects. Powerful models such as CodeGen-6B only achieve an\n11.96 pass rate at top-1 prediction, suggesting plenty of headroom for\nimprovement. We release ODEX to facilitate research into open-domain problems\nfor the code generation community.",
    "descriptor": "",
    "authors": [
      "Zhiruo Wang",
      "Shuyan Zhou",
      "Daniel Fried",
      "Graham Neubig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10481"
  },
  {
    "id": "arXiv:2212.10496",
    "title": "Precise Zero-Shot Dense Retrieval without Relevance Labels",
    "abstract": "While dense retrieval has been shown effective and efficient across tasks and\nlanguages, it remains difficult to create effective fully zero-shot dense\nretrieval systems when no relevance label is available. In this paper, we\nrecognize the difficulty of zero-shot learning and encoding relevance. Instead,\nwe propose to pivot through Hypothetical Document Embeddings~(HyDE). Given a\nquery, HyDE first zero-shot instructs an instruction-following language model\n(e.g. InstructGPT) to generate a hypothetical document. The document captures\nrelevance patterns but is unreal and may contain false details. Then, an\nunsupervised contrastively learned encoder~(e.g. Contriever) encodes the\ndocument into an embedding vector. This vector identifies a neighborhood in the\ncorpus embedding space, where similar real documents are retrieved based on\nvector similarity. This second step ground the generated document to the actual\ncorpus, with the encoder's dense bottleneck filtering out the incorrect\ndetails. Our experiments show that HyDE significantly outperforms the\nstate-of-the-art unsupervised dense retriever Contriever and shows strong\nperformance comparable to fine-tuned retrievers, across various tasks (e.g. web\nsearch, QA, fact verification) and languages~(e.g. sw, ko, ja).",
    "descriptor": "",
    "authors": [
      "Luyu Gao",
      "Xueguang Ma",
      "Jimmy Lin",
      "Jamie Callan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10496"
  },
  {
    "id": "arXiv:2212.10498",
    "title": "SimpleStyle: An Adaptable Style Transfer Approach",
    "abstract": "Attribute Controlled Text Rewriting, also known as text style transfer, has\nreceived significant attention in the natural language generation community due\nto its crucial role in controllable natural language generation systems. In\nthis work we present SimpleStyle a minimalist yet effective approach for\nattribute controlled text rewriting based on a simple mechanism composed of two\ningredients. controlled denoising and output filtering. Despite the simplicity\nof our approach, which can be succinctly explained with just a few lines of\ncode, it is competitive with previous state-of-the-art methods both in\nautomatic and in human evaluations. Additionally, we demonstrate the practical\neffectiveness of our system, by applying it to real-world data from social\nnetworks. Additionally, we introduce a soft masking sampling technique that\nfurther improves the performance of the system. We also show that feeding the\noutput of our system into a text-to-text student model can produce high-quality\nresults without the need for additional filtering. Finally, we suggest that our\nmethod can solve the fundamental missing baseline absence that holding progress\nin the field by offering our protocol as a simple, adaptive and very strong\nbaseline for works wish to make incremental advancements in the field of\nattribute controlled text rewriting.",
    "descriptor": "",
    "authors": [
      "Elron Bandel",
      "Yoav Katz",
      "Noam Slonim",
      "Liat Ein-Dor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10498"
  },
  {
    "id": "arXiv:2212.10500",
    "title": "Continuous Trajectory Optimization via B-splines for Multi-jointed  Robotic Systems",
    "abstract": "Continuous formulations of trajectory planning problems have two main\nbenefits. First, constraints are guaranteed to be satisfied at all times.\nSecondly, dynamic obstacles can be naturally considered with time. This paper\nintroduces a novel B-spline based trajectory optimization method for\nmulti-jointed robots that provides a continuous trajectory with guaranteed\ncontinuous constraints satisfaction. At the core of this method, B-spline basic\noperations, like addition, multiplication, and derivative, are rigorously\ndefined and applied for problem formulation. B-spline unique characteristics,\nsuch as the convex hull and smooth curves properties, are utilized to\nreformulate the original continuous optimization problem into a\nfinite-dimensional problem. Collision avoidance with static obstacles is\nachieved using the signed distance field, while that with dynamic obstacles is\naccomplished via constructing time-varying separating hyperplanes. Simulation\nresults on various robots validate the effectiveness of the algorithm. In\naddition, this paper provides experimental validations with a 6-link FANUC\nrobot avoiding static and moving obstacles.",
    "descriptor": "",
    "authors": [
      "Changhao Wang",
      "Ting Xu",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.10500"
  },
  {
    "id": "arXiv:2212.10502",
    "title": "A Measure-Theoretic Characterization of Tight Language Models",
    "abstract": "Language modeling, a central task in natural language processing, involves\nestimating a probability distribution over strings. In most cases, the\nestimated distribution sums to 1 over all finite strings. However, in some\npathological cases, probability mass can ``leak'' onto the set of infinite\nsequences. In order to characterize the notion of leakage more precisely, this\npaper offers a measure-theoretic treatment of language modeling. We prove that\nmany popular language model families are in fact tight, meaning that they will\nnot leak in this sense. We also generalize characterizations of tightness\nproposed in previous works.",
    "descriptor": "",
    "authors": [
      "Li Du",
      "Lucas Torroba Hennigen",
      "Tiago Pimentel",
      "Clara Meister",
      "Jason Eisner",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2212.10502"
  },
  {
    "id": "arXiv:2212.10503",
    "title": "Mini-Model Adaptation: Efficiently Extending Pretrained Models to New  Languages via Aligned Shallow Training",
    "abstract": "Prior work has shown that it is possible to expand pretrained Masked Language\nModels (MLMs) to new languages by learning a new set of embeddings, while\nkeeping the transformer body frozen. Despite learning a small subset of\nparameters, this approach is not compute-efficient, as training the new\nembeddings requires a full forward and backward pass over the entire model. In\nthis work, we propose mini-model adaptation, a compute-efficient alternative\nthat builds a shallow mini-model from a fraction of a large model's parameters.\nNew language-specific embeddings can then be efficiently trained over the\nmini-model, and plugged into the aligned large model for rapid cross-lingual\ntransfer. We explore two approaches to learn mini-models: MiniJoint, which\njointly pretrains the primary model and the mini-model using a single\ntransformer with a secondary MLM head at a middle layer; and MiniPost, where we\nstart from a regular pretrained model and build a mini-model by extracting and\nfreezing a few layers and learning a small number of parameters on top.\nExperiments on XNLI, MLQA and PAWS-X show that mini-model adaptation matches\nthe performance of the standard approach using up to 2.4x less compute.",
    "descriptor": "",
    "authors": [
      "Kelly Marchisio",
      "Patrick Lewis",
      "Yihong Chen",
      "Mikel Artetxe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10503"
  },
  {
    "id": "arXiv:2212.10504",
    "title": "Can Current Task-oriented Dialogue Models Automate Real-world Scenarios  in the Wild?",
    "abstract": "Task-oriented dialogue (TOD) systems are mainly based on the\nslot-filling-based TOD (SF-TOD) framework, in which dialogues are broken down\ninto smaller, controllable units (i.e., slots) to fulfill a specific task. A\nseries of approaches based on this framework achieved remarkable success on\nvarious TOD benchmarks. However, we argue that the current TOD benchmarks are\nlimited to surrogate real-world scenarios and that the current TOD models are\nstill a long way from unraveling the scenarios. In this position paper, we\nfirst identify current status and limitations of SF-TOD systems. After that, we\nexplore the WebTOD framework, the alternative direction for building a scalable\nTOD system when a web/mobile interface is available. In WebTOD, the dialogue\nsystem learns how to understand the web/mobile interface that the human agent\ninteracts with, powered by a large-scale language model.",
    "descriptor": "\nComments: Working in Progress\n",
    "authors": [
      "Sang-Woo Lee",
      "Sungdong Kim",
      "Donghyeon Ko",
      "Donghoon Ham",
      "Youngki Hong",
      "Shin Ah Oh",
      "Hyunhoon Jung",
      "Wangkyo Jung",
      "Kyunghyun Cho",
      "Donghyun Kwak",
      "Hyungsuk Noh",
      "Woomyoung Park"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10504"
  },
  {
    "id": "arXiv:2212.10505",
    "title": "DePlot: One-shot visual language reasoning by plot-to-table translation",
    "abstract": "Visual language such as charts and plots is ubiquitous in the human world.\nComprehending plots and charts requires strong reasoning skills. Prior\nstate-of-the-art (SOTA) models require at least tens of thousands of training\nexamples and their reasoning capabilities are still much limited, especially on\ncomplex human-written queries. This paper presents the first one-shot solution\nto visual language reasoning. We decompose the challenge of visual language\nreasoning into two steps: (1) plot-to-text translation, and (2) reasoning over\nthe translated text. The key in this method is a modality conversion module,\nnamed as DePlot, which translates the image of a plot or chart to a linearized\ntable. The output of DePlot can then be directly used to prompt a pretrained\nlarge language model (LLM), exploiting the few-shot reasoning capabilities of\nLLMs. To obtain DePlot, we standardize the plot-to-table task by establishing\nunified task formats and metrics, and train DePlot end-to-end on this task.\nDePlot can then be used off-the-shelf together with LLMs in a plug-and-play\nfashion. Compared with a SOTA model finetuned on more than >28k data points,\nDePlot+LLM with just one-shot prompting achieves a 24.0% improvement over\nfinetuned SOTA on human-written queries from the task of chart QA.",
    "descriptor": "",
    "authors": [
      "Fangyu Liu",
      "Julian Martin Eisenschlos",
      "Francesco Piccinno",
      "Syrine Krichene",
      "Chenxi Pang",
      "Kenton Lee",
      "Mandar Joshi",
      "Wenhu Chen",
      "Nigel Collier",
      "Yasemin Altun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10505"
  },
  {
    "id": "arXiv:2212.10508",
    "title": "Combining machine-learned and empirical force fields with the parareal  algorithm: application to the diffusion of atomistic defects",
    "abstract": "We numerically investigate an adaptive version of the parareal algorithm in\nthe context of molecular dynamics. This adaptive variant has been originally\nintroduced in [F. Legoll, T. Lelievre and U. Sharma, SISC 2022]. We focus here\non test cases of physical interest where the dynamics of the system is modelled\nby the Langevin equation and is simulated using the molecular dynamics software\nLAMMPS. In this work, the parareal algorithm uses a family of machine-learning\nspectral neighbor analysis potentials (SNAP) as fine, reference, potentials and\nembedded-atom method potentials (EAM) as coarse potentials. We consider a\nself-interstitial atom in a tungsten lattice and compute the average residence\ntime of the system in metastable states. Our numerical results demonstrate\nsignificant computational gains using the adaptive parareal algorithm in\ncomparison to a sequential integration of the Langevin dynamics. We also\nidentify a large regime of numerical parameters for which statistical accuracy\nis reached without being a consequence of trajectorial accuracy.",
    "descriptor": "",
    "authors": [
      "Olga Gorynina",
      "Frederic Legoll",
      "Tony Lelievre",
      "Danny Perez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.10508"
  },
  {
    "id": "arXiv:2212.10509",
    "title": "Interleaving Retrieval with Chain-of-Thought Reasoning for  Knowledge-Intensive Multi-Step Questions",
    "abstract": "Recent work has shown that large language models are capable of generating\nnatural language reasoning steps or Chains-of-Thoughts (CoT) to answer a\nmulti-step question when prompted to do so. This is insufficient, however, when\nthe necessary knowledge is not available or up-to-date within a model's\nparameters. A straightforward approach to address this is to retrieve text from\nan external knowledge source using the question as a query and prepend it as\ncontext to the model's input. This, however, is also insufficient for\nmulti-step QA where \\textit{what to retrieve} depends on \\textit{what has\nalready been derived}. To address this issue we propose IRCoT, a new approach\nthat interleaves retrieval with CoT for multi-step QA, guiding the retrieval\nwith CoT and in turn using retrieved results to improve CoT. Our experiments\nwith GPT3 show substantial improvements in retrieval (up to 22 points) and\ndownstream QA (up to 16 points) over the baselines on four datasets: HotpotQA,\n2WikiMultihopQA, MuSiQue, and IIRC. Notably, our method also works well for\nmuch smaller models such as T5-Flan-large (0.7B) without any additional\ntraining.",
    "descriptor": "",
    "authors": [
      "Harsh Trivedi",
      "Niranjan Balasubramanian",
      "Tushar Khot",
      "Ashish Sabharwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10509"
  },
  {
    "id": "arXiv:2212.10511",
    "title": "When Not to Trust Language Models: Investigating Effectiveness and  Limitations of Parametric and Non-Parametric Memories",
    "abstract": "Despite their impressive performance on diverse tasks, large language models\n(LMs) still struggle with tasks requiring rich world knowledge, implying the\nlimitations of relying solely on their parameters to encode a wealth of world\nknowledge. This paper aims to understand LMs' strengths and limitations in\nmemorizing factual knowledge, by conducting large-scale knowledge probing\nexperiments of 10 models and 4 augmentation methods on PopQA, our new\nopen-domain QA dataset with 14k questions. We find that LMs struggle with less\npopular factual knowledge, and that scaling fails to appreciably improve\nmemorization of factual knowledge in the tail. We then show that\nretrieval-augmented LMs largely outperform orders of magnitude larger LMs,\nwhile unassisted LMs remain competitive in questions about high-popularity\nentities. Based on those findings, we devise a simple, yet effective, method\nfor powerful and efficient retrieval-augmented LMs, which retrieves\nnon-parametric memories only when necessary. Experimental results show that\nthis significantly improves models' performance while reducing the inference\ncosts.",
    "descriptor": "\nComments: Code and data available at this https URL; work in progress\n",
    "authors": [
      "Alex Mallen",
      "Akari Asai",
      "Victor Zhong",
      "Rajarshi Das",
      "Hannaneh Hajishirzi",
      "Daniel Khashabi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10511"
  },
  {
    "id": "arXiv:2212.10513",
    "title": "ECoHeN: A Hypothesis Testing Framework for Extracting Communities from  Heterogeneous Networks",
    "abstract": "Community discovery is the general process of attaining assortative\ncommunities from a network: collections of nodes that are densely connected\nwithin yet sparsely connected to the rest of the network. While community\ndiscovery has been well studied, few such techniques exist for heterogeneous\nnetworks, which contain different types of nodes and possibly different\nconnectivity patterns between the node types. In this paper, we introduce a\nframework called ECoHeN, which \\textbf{e}xtracts \\textbf{co}mmunities from a\n\\textbf{he}terogeneous \\textbf{n}etwork in a statistically meaningful way.\nUsing a heterogeneous configuration model as a reference distribution, ECoHeN\nidentifies communities that are significantly more densely connected than\nexpected given the node types and connectivity of its membership. Specifically,\nthe ECoHeN algorithm extracts communities one at a time through a dynamic set\nof iterative updating rules, is guaranteed to converge, and imposes no\nconstraints on the type composition of extracted communities. To our knowledge\nthis is the first discovery method that distinguishes and identifies both\nhomogeneous and heterogeneous, possibly overlapping, community structure in a\nnetwork. We demonstrate the performance of ECoHeN through simulation and in\napplication to a political blogs network to identify collections of blogs which\nreference one another more than expected considering the ideology of its'\nmembers.",
    "descriptor": "\nComments: 31 pages, 8 figures, 1 table, 1 algorithm\n",
    "authors": [
      "Connor P. Gibbs",
      "Bailey K. Fosdick",
      "James D. Wilson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.10513"
  },
  {
    "id": "arXiv:2212.10515",
    "title": "CausalDialogue: Modeling Utterance-level Causality in Conversations",
    "abstract": "Despite their widespread adoption, neural conversation models have yet to\nexhibit natural chat capabilities with humans. In this research, we examine\nuser utterances as causes and generated responses as effects, recognizing that\nchanges in a cause should produce a different effect. To further explore this\nconcept, we have compiled and expanded upon a new dataset called CausalDialogue\nthrough crowd-sourcing. This dataset includes multiple cause-effect pairs\nwithin a directed acyclic graph (DAG) structure. Our analysis reveals that\ntraditional loss functions can struggle to effectively incorporate the DAG\nstructure, leading us to propose a causality-enhanced method called Exponential\nMaximum Average Treatment Effect (ExMATE) to enhance the impact of causality at\nthe utterance level in training neural conversation models. To evaluate the\neffectiveness of this approach, we have built a comprehensive benchmark using\nthe CausalDialogue dataset leveraging large-scale pre-trained language models,\nand have assessed the results through both human and automatic evaluation\nmetrics for coherence, diversity, and agility. Our findings show that current\ntechniques are still unable to effectively address conversational DAGs, and\nthat the ExMATE method can improve the diversity and agility of conventional\nloss functions while maintaining coherence.",
    "descriptor": "",
    "authors": [
      "Yi-Lin Tuan",
      "Alon Albalak",
      "Wenda Xu",
      "Michael Saxon",
      "Connor Pryor",
      "Lise Getoor",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10515"
  },
  {
    "id": "arXiv:2212.10519",
    "title": "Polynomial interpolation in the monomial basis is stable after all",
    "abstract": "Polynomial interpolation in the monomial basis is often considered to be a\nbad idea in numerical computations. In this paper, we show that this belief is\nwrong, in the sense that, despite the ill-conditioning of the Vandermonde\nmatrix, polynomial interpolation in the monomial basis is as accurate as\npolynomial interpolation in a more well-conditioned basis in many cases of\ninterest. Furthermore, we show that the monomial basis is superior to other\npolynomial bases in a number of applications.",
    "descriptor": "\nComments: 32 pages, 11 figures\n",
    "authors": [
      "Zewen Shen",
      "Kirill Serkh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.10519"
  },
  {
    "id": "arXiv:2212.10520",
    "title": "Privacy-Preserving Domain Adaptation of Semantic Parsers",
    "abstract": "Task-oriented dialogue systems often assist users with personal or\nconfidential matters. For this reason, the developers of such a system are\ngenerally prohibited from observing actual usage. So how can they know where\nthe system is failing and needs more training data or new functionality? In\nthis work, we study ways in which realistic user utterances can be generated\nsynthetically, to help increase the linguistic and functional coverage of the\nsystem, without compromising the privacy of actual users. To this end, we\npropose a two-stage Differentially Private (DP) generation method which first\ngenerates latent semantic parses, and then generates utterances based on the\nparses. Our proposed approach improves MAUVE by 3.8$\\times$ and parse tree\nnode-type overlap by 1.4$\\times$ relative to current approaches for private\nsynthetic data generation, improving both on fluency and semantic coverage. We\nfurther validate our approach on a realistic domain adaptation task of adding\nnew functionality from private user data to a semantic parser, and show gains\nof 1.3$\\times$ on its accuracy with the new feature.",
    "descriptor": "",
    "authors": [
      "Fatemehsadat Mireshghallah",
      "Richard Shin",
      "Yu Su",
      "Tatsunori Hashimoto",
      "Jason Eisner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10520"
  },
  {
    "id": "arXiv:2212.10522",
    "title": "Transformers Go for the LOLs: Generating (Humourous) Titles from  Scientific Abstracts End-to-End",
    "abstract": "We consider the end-to-end abstract-to-title generation problem, exploring\nseven recent transformer based models (including ChatGPT) fine-tuned on more\nthan 30k abstract-title pairs from NLP and machine learning venues. As an\nextension, we also consider the harder problem of generating humorous paper\ntitles. For the latter, we compile the first large-scale humor annotated\ndataset for scientific papers in the NLP/ML domains, comprising almost 2.5k\ntitles. We evaluate all models using human and automatic metrics. Our human\nevaluation suggests that our best end-to-end system performs similarly to human\nauthors (but arguably slightly worse). Generating funny titles is more\ndifficult, however, and our automatic systems clearly underperform relative to\nhumans and often learn dataset artefacts of humor. Finally, ChatGPT, without\nany fine-tuning, performs on the level of our best fine-tuned system.",
    "descriptor": "",
    "authors": [
      "Yanran Chen",
      "Steffen Eger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10522"
  },
  {
    "id": "arXiv:2212.10523",
    "title": "Concatenated Forward Error Correction with KP4 and Single Parity Check  Codes",
    "abstract": "Concatenated forward error correction is studied based on an outer KP4\nReed-Solomon code with hard-decision decoding and inner single parity check\n(SPC) codes with Chase/Wagner soft-decision decoding. Analytical expressions\nare derived for the end-to-end frame and bit error rates for transmission over\nadditive white Gaussian noise channels with binary phase-shift keying (BPSK)\nand quaternary amplitude shift keying (4-ASK), as well as with symbol\ninterleavers and quantized channel outputs. The BPSK error rates are compared\nto those of two other inner codes, namely a two-dimensional product code with\nSPC component codes and an extended Hamming code. Simulation results for\nunit-memory inter-symbol interference channels and 4-ASK are also presented.\nThe results show that the coding schemes achieve similar error rates but SPC\ncodes have the lowest complexity and permit flexible rate adaptation.",
    "descriptor": "\nComments: Submitted to IEEE Journal of Lightwave Technology on December 20, 2022\n",
    "authors": [
      "Diego Lentner",
      "Emna Ben Yacoub",
      "Stefano Calabr\u00f2",
      "Georg B\u00f6cherer",
      "Neboj\u0161a Stojanovi\u0107",
      "Gerhard Kramer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.10523"
  },
  {
    "id": "arXiv:2212.10525",
    "title": "SLUE Phase-2: A Benchmark Suite of Diverse Spoken Language Understanding  Tasks",
    "abstract": "Spoken language understanding (SLU) tasks have been studied for many decades\nin the speech research community, but have not received as much attention as\nlower-level tasks like speech and speaker recognition. In particular, there are\nnot nearly as many SLU task benchmarks, and many of the existing ones use data\nthat is not freely available to all researchers. Recent work has begun to\nintroduce such benchmark datasets for several tasks. In this work, we introduce\nseveral new annotated SLU benchmark tasks based on freely available speech\ndata, which complement existing benchmarks and address gaps in the SLU\nevaluation landscape. We contribute four tasks: question answering and\nsummarization involve inference over longer speech sequences; named entity\nlocalization addresses the speech-specific task of locating the targeted\ncontent in the signal; dialog act classification identifies the function of a\ngiven speech utterance. We follow the blueprint of the Spoken Language\nUnderstanding Evaluation (SLUE) benchmark suite. In order to facilitate the\ndevelopment of SLU models that leverage the success of pre-trained speech\nrepresentations, we will be publishing for each task (i) annotations for a\nrelatively small fine-tuning set, (ii) annotated development and test sets, and\n(iii) baseline models for easy reproducibility and comparisons. In this work,\nwe present the details of data collection and annotation and the performance of\nthe baseline models. We also perform sensitivity analysis of pipeline models'\nperformance (speech recognizer + text model) to the speech recognition\naccuracy, using more than 20 state-of-the-art speech recognition models.",
    "descriptor": "",
    "authors": [
      "Suwon Shon",
      "Siddhant Arora",
      "Chyi-Jiunn Lin",
      "Ankita Pasad",
      "Felix Wu",
      "Roshan Sharma",
      "Wei-Lun Wu",
      "Hung-Yi Lee",
      "Karen Livescu",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.10525"
  },
  {
    "id": "arXiv:2212.10526",
    "title": "Exploring the Challenges of Open Domain Multi-Document Summarization",
    "abstract": "Multi-document summarization (MDS) has traditionally been studied assuming a\nset of ground-truth topic-related input documents is provided. In practice, the\ninput document set is unlikely to be available a priori and would need to be\nretrieved based on an information need, a setting we call open-domain MDS. We\nexperiment with current state-of-the-art retrieval and summarization models on\nseveral popular MDS datasets extended to the open-domain setting. We find that\nexisting summarizers suffer large reductions in performance when applied as-is\nto this more realistic task, though training summarizers with retrieved inputs\ncan reduce their sensitivity retrieval errors. To further probe these findings,\nwe conduct perturbation experiments on summarizer inputs to study the impact of\ndifferent types of document retrieval errors. Based on our results, we provide\npractical guidelines to help facilitate a shift to open-domain MDS. We release\nour code and experimental results alongside all data or model artifacts created\nduring our investigation.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "John Giorgi",
      "Luca Soldaini",
      "Bo Wang",
      "Gary Bader",
      "Kyle Lo",
      "Lucy Lu Wang",
      "Arman Cohan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10526"
  },
  {
    "id": "arXiv:2212.10528",
    "title": "HYRR: Hybrid Infused Reranking for Passage Retrieval",
    "abstract": "We present Hybrid Infused Reranking for Passages Retrieval (HYRR), a\nframework for training rerankers based on a hybrid of BM25 and neural retrieval\nmodels. Retrievers based on hybrid models have been shown to outperform both\nBM25 and neural models alone. Our approach exploits this improved performance\nwhen training a reranker, leading to a robust reranking model. The reranker, a\ncross-attention neural model, is shown to be robust to different first-stage\nretrieval systems, achieving better performance than rerankers simply trained\nupon the first-stage retrievers in the multi-stage systems. We present\nevaluations on a supervised passage retrieval task using MS MARCO and zero-shot\nretrieval tasks using BEIR. The empirical results show strong performance on\nboth evaluations.",
    "descriptor": "",
    "authors": [
      "Jing Lu",
      "Keith Hall",
      "Ji Ma",
      "Jianmo Ni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.10528"
  },
  {
    "id": "arXiv:2212.10529",
    "title": "Is GPT-3 a Psychopath? Evaluating Large Language Models from a  Psychological Perspective",
    "abstract": "Are large language models (LLMs) like GPT-3 psychologically safe? In this\nwork, we design unbiased prompts to evaluate LLMs systematically from a\npsychological perspective. Firstly, we test the personality traits of three\ndifferent LLMs with Short Dark Triad (SD-3) and Big Five Inventory (BFI). We\nfind all of them show higher scores on SD-3 than the human average, indicating\na relatively darker personality. Furthermore, LLMs like InstructGPT and\nFLAN-T5, which are fine-tuned with safety metrics, do not necessarily have more\npositive personalities. They score higher on Machiavellianism and Narcissism\nthan GPT-3. Secondly, we test the LLMs in GPT-3 series on well-being tests to\nstudy the impact of fine-tuning with more training data. Interestingly, we\nobserve a continuous increase in well-being scores from GPT-3 to InstructGPT.\nFollowing the observations, we show that instruction-finetune FLAN-T5 with\npositive answers in BFI can effectively improve the model from a psychological\nperspective. Finally, we call on the community to evaluate and improve LLMs'\nsafety systematically instead of at the sentence level only.",
    "descriptor": "",
    "authors": [
      "Xingxuan Li",
      "Yutong Li",
      "Linlin Liu",
      "Lidong Bing",
      "Shafiq Joty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.10529"
  },
  {
    "id": "arXiv:2212.10533",
    "title": "The Risks of Ranking: Revisiting Graphical Perception to Model  Individual Differences in Visualization Performance",
    "abstract": "Graphical perception studies typically measure visualization encoding\neffectiveness using the error of an \"average observer\", leading to canonical\nrankings of encodings for numerical attributes: e.g., position > area > angle >\nvolume. Yet different people may vary in their ability to read different\nvisualization types, leading to variance in this ranking across individuals not\ncaptured by population-level metrics using \"average observer\" models. One way\nwe can bridge this gap is by recasting classic visual perception tasks as tools\nfor assessing individual performance, in addition to overall visualization\nperformance. In this paper we replicate and extend Cleveland and McGill's\ngraphical comparison experiment using Bayesian multilevel regression, using\nthese models to explore individual differences in visualization skill from\nmultiple perspectives. The results from experiments and modeling indicate that\nsome people show patterns of accuracy that credibly deviate from the canonical\nrankings of visualization effectiveness. We discuss implications of these\nfindings, such as a need for new ways to communicate visualization\neffectiveness to designers, how patterns in individuals' responses may show\nsystematic biases and strategies in visualization judgment, and how recasting\nclassic visual perception tasks as tools for assessing individual performance\nmay offer new ways to quantify aspects of visualization literacy. Experiment\ndata, source code, and analysis scripts are available at the following\nrepository: https://osf.io/8ub7t/?view\\_only=9be4798797404a4397be3c6fc2a68cc0.",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Russell Davis",
      "Xiaoying Pu",
      "Yiren Ding",
      "Brian D. Hall",
      "Karen Bonilla",
      "Mi Feng",
      "Matthew Kay",
      "Lane Harrison"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.10533"
  },
  {
    "id": "arXiv:2212.10534",
    "title": "DISCO: Distilling Phrasal Counterfactuals with Large Language Models",
    "abstract": "Recent methods demonstrate that data augmentation using counterfactual\nknowledge can teach models the causal structure of a task, leading to robust\nand generalizable models. However, such counterfactual data often has a limited\nscale and diversity if crowdsourced and is computationally expensive to extend\nto new perturbation types if generated using supervised methods. To address\nthis, we introduce a new framework called DISCO for automatically generating\nhigh-quality counterfactual data at scale. DISCO engineers prompts to generate\nphrasal perturbations with a large general language model. Then, a\ntask-specific teacher model filters the generation to distill high-quality\ncounterfactual data. We show that learning with this counterfactual data yields\na comparatively small student model that is 6% (absolute) more robust and\ngeneralizes 5% better across distributions than baselines on various\nchallenging evaluations. This model is also 15% more sensitive in\ndifferentiating original and counterfactual examples, on three evaluation sets\nwritten by human workers and via human-AI collaboration.",
    "descriptor": "\nComments: work in progress\n",
    "authors": [
      "Zeming Chen",
      "Qiyue Gao",
      "Kyle Richardson",
      "Antoine Bosselut",
      "Ashish Sabharwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10534"
  },
  {
    "id": "arXiv:2212.10535",
    "title": "A Survey of Deep Learning for Mathematical Reasoning",
    "abstract": "Mathematical reasoning is a fundamental aspect of human intelligence and is\napplicable in various fields, including science, engineering, finance, and\neveryday life. The development of artificial intelligence (AI) systems capable\nof solving math problems and proving theorems has garnered significant interest\nin the fields of machine learning and natural language processing. For example,\nmathematics serves as a testbed for aspects of reasoning that are challenging\nfor powerful deep learning models, driving new algorithmic and modeling\nadvances. On the other hand, recent advances in large-scale neural language\nmodels have opened up new benchmarks and opportunities to use deep learning for\nmathematical reasoning. In this survey paper, we review the key tasks,\ndatasets, and methods at the intersection of mathematical reasoning and deep\nlearning over the past decade. We also evaluate existing benchmarks and\nmethods, and discuss future research directions in this domain.",
    "descriptor": "\nComments: 24 pages, 2 figures, 8 tables. The repository is available at this https URL\n",
    "authors": [
      "Pan Lu",
      "Liang Qiu",
      "Wenhao Yu",
      "Sean Welleck",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10535"
  },
  {
    "id": "arXiv:2212.10536",
    "title": "Measure More, Question More: Experimental Studies on Transformer-based  Language Models and Complement Coercion",
    "abstract": "Transformer-based language models have shown strong performance on an array\nof natural language understanding tasks. However, the question of how these\nmodels react to implicit meaning has been largely unexplored. We investigate\nthis using the complement coercion phenomenon, which involves sentences like\n\"The student finished the book about sailing\" where the action \"reading\" is\nimplicit. We compare LMs' surprisal estimates at various critical sentence\nregions in sentences with and without implicit meaning. Effects associated with\nrecovering implicit meaning were found at a critical region other than where\nsentences minimally differ. We then use follow-up experiments to factor out\npotential confounds, revealing different perspectives that offer a richer and\nmore accurate picture.",
    "descriptor": "",
    "authors": [
      "Yuling Gu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10536"
  },
  {
    "id": "arXiv:2212.10537",
    "title": "Does CLIP Bind Concepts? Probing Compositionality in Large Image Models",
    "abstract": "Large-scale models combining text and images have made incredible progress in\nrecent years. However, they can still fail at tasks requiring compositional\nknowledge, such as correctly picking out a red cube from a picture of multiple\nshapes. We examine the ability of CLIP (Radford et al., 2021), to caption\nimages requiring compositional knowledge. We implement five compositional\nlanguage models to probe the kinds of structure that CLIP may be using, and\ndevelop a novel training algorithm, Compositional Skipgram for Images (CoSI),\nto train these models. We look at performance in attribute-based tasks,\nrequiring the identification of a particular combination of attribute and\nobject (such as \"red cube\"), and in relational settings, where the spatial\nrelation between two shapes (such as \"cube behind sphere\") must be identified.\nWe find that in some conditions, CLIP is able to learn attribute-object\nlabellings, and to generalize to unseen attribute-object combinations. However,\nwe also see evidence that CLIP is not able to bind features together reliably.\nMoreover, CLIP is not able to reliably learn relations between objects, whereas\nsome compositional models are able to learn these perfectly. Of the five models\nwe developed, none were able to generalize to unseen relations.",
    "descriptor": "",
    "authors": [
      "Martha Lewis",
      "Qinan Yu",
      "Jack Merullo",
      "Ellie Pavlick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10537"
  },
  {
    "id": "arXiv:2212.10538",
    "title": "HyperBO+: Pre-training a universal prior for Bayesian optimization with  hierarchical Gaussian processes",
    "abstract": "Bayesian optimization (BO), while proved highly effective for many black-box\nfunction optimization tasks, requires practitioners to carefully select priors\nthat well model their functions of interest. Rather than specifying by hand,\nresearchers have investigated transfer learning based methods to automatically\nlearn the priors, e.g. multi-task BO (Swersky et al., 2013), few-shot BO\n(Wistuba and Grabocka, 2021) and HyperBO (Wang et al., 2022). However, those\nprior learning methods typically assume that the input domains are the same for\nall tasks, weakening their ability to use observations on functions with\ndifferent domains or generalize the learned priors to BO on different search\nspaces. In this work, we present HyperBO+: a pre-training approach for\nhierarchical Gaussian processes that enables the same prior to work universally\nfor Bayesian optimization on functions with different domains. We propose a\ntwo-step pre-training method and analyze its appealing asymptotic properties\nand benefits to BO both theoretically and empirically. On real-world\nhyperparameter tuning tasks that involve multiple search spaces, we demonstrate\nthat HyperBO+ is able to generalize to unseen search spaces and achieves lower\nregrets than competitive baselines.",
    "descriptor": "",
    "authors": [
      "Zhou Fan",
      "Xinran Han",
      "Zi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.10538"
  },
  {
    "id": "arXiv:2212.10539",
    "title": "Toward Human Readable Prompt Tuning: Kubrick's The Shining is a good  movie, and a good prompt too?",
    "abstract": "Large language models can perform new tasks in a zero-shot fashion, given\nnatural language prompts that specify the desired behavior. Such prompts are\ntypically hand engineered, but can also be learned with gradient-based methods\nfrom labeled data. However, it is underexplored what factors make the prompts\neffective, especially when the prompts are natural language. In this paper, we\ninvestigate common attributes shared by effective prompts. We first propose a\nhuman readable prompt tuning method (F LUENT P ROMPT) based on Langevin\ndynamics that incorporates a fluency constraint to find a diverse distribution\nof effective and fluent prompts. Our analysis reveals that effective prompts\nare topically related to the task domain and calibrate the prior probability of\nlabel words. Based on these findings, we also propose a method for generating\nprompts using only unlabeled data, outperforming strong baselines by an average\nof 7.0% accuracy across three tasks.",
    "descriptor": "",
    "authors": [
      "Weijia Shi",
      "Xiaochuang Han",
      "Hila Gonen",
      "Ari Holtzman",
      "Yulia Tsvetkov",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10539"
  },
  {
    "id": "arXiv:2212.10541",
    "title": "UNO-QA: An Unsupervised Anomaly-Aware Framework with Test-Time  Clustering for OCTA Image Quality Assessment",
    "abstract": "Medical image quality assessment (MIQA) is a vital prerequisite in various\nmedical image analysis applications. Most existing MIQA algorithms are fully\nsupervised that request a large amount of annotated data. However, annotating\nmedical images is time-consuming and labor-intensive. In this paper, we propose\nan unsupervised anomaly-aware framework with test-time clustering for optical\ncoherence tomography angiography (OCTA) image quality assessment in a setting\nwherein only a set of high-quality samples are accessible in the training\nphase. Specifically, a feature-embedding-based low-quality representation\nmodule is proposed to quantify the quality of OCTA images and then to\ndiscriminate between outstanding quality and non-outstanding quality. Within\nthe non-outstanding quality class, to further distinguish gradable images from\nungradable ones, we perform dimension reduction and clustering of multi-scale\nimage features extracted by the trained OCTA quality representation network.\nExtensive experiments are conducted on one publicly accessible dataset\nsOCTA-3*3-10k, with superiority of our proposed framework being successfully\nestablished.",
    "descriptor": "\nComments: submitted to ISBI2023\n",
    "authors": [
      "Juntao Chen",
      "Li Lin",
      "Pujin Cheng",
      "Yijin Huang",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.10541"
  },
  {
    "id": "arXiv:2212.10543",
    "title": "Detoxifying Text with MaRCo: Controllable Revision with Experts and  Anti-Experts",
    "abstract": "Text detoxification has the potential to mitigate the harms of toxicity by\nrephrasing text to remove offensive meaning, but subtle toxicity remains\nchallenging to tackle. We introduce MaRCo, a detoxification algorithm that\ncombines controllable generation and text rewriting methods using a Product of\nExperts with autoencoder language models (LMs). MaRCo uses likelihoods under a\nnon-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to\nmask and potentially replace. We evaluate our method on several subtle toxicity\nand microaggressions datasets, and show that it not only outperforms baselines\non automatic metrics, but MaRCo's rewrites are preferred 2.1 $\\times$ more in\nhuman evaluation. Its applicability to instances of subtle toxicity is\nespecially promising, demonstrating a path forward for addressing increasingly\nelusive online hate.",
    "descriptor": "",
    "authors": [
      "Skyler Hallinan",
      "Alisa Liu",
      "Yejin Choi",
      "Maarten Sap"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10543"
  },
  {
    "id": "arXiv:2212.10544",
    "title": "Pretraining Without Attention",
    "abstract": "Transformers have been essential to pretraining success in NLP. Other\narchitectures have been used, but require attention layers to match benchmark\naccuracy. This work explores pretraining without attention. We test recently\ndeveloped routing layers based on state-space models (SSM) and model\narchitectures based on multiplicative gating. Used together these modeling\nchoices have a large impact on pretraining accuracy. Empirically the proposed\nBidirectional Gated SSM (BiGS) replicates BERT pretraining results without\nattention and can be extended to long-form pretraining of 4096 tokens without\napproximation.",
    "descriptor": "",
    "authors": [
      "Junxiong Wang",
      "Jing Nathan Yan",
      "Albert Gu",
      "Alexander M. Rush"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10544"
  },
  {
    "id": "arXiv:2212.10545",
    "title": "DimonGen: Diversified Generative Commonsense Reasoning for Explaining  Concept Relationships",
    "abstract": "In this paper, we propose DimonGen, which aims to generate diverse sentences\ndescribing concept relationships in various everyday scenarios. To support\nthis, we create a benchmark dataset for this task by adapting the existing\nCommonGen dataset and propose a two-stage model called MoREE (Mixture of\nRetrieval-Enhanced Experts) to generate the target sentences. MoREE consists of\na mixture of retriever models that retrieve diverse context sentences related\nto the given concepts, and a mixture of generator models that generate diverse\nsentences based on the retrieved contexts. We conduct experiments on the\nDimonGen task and show that MoREE outperforms strong baselines in terms of both\nthe quality and diversity of the generated sentences. Our results demonstrate\nthat MoREE is able to generate diverse sentences that reflect different\nrelationships between concepts, leading to a comprehensive understanding of\nconcept relationships.",
    "descriptor": "",
    "authors": [
      "Chenzhengyi Liu",
      "Jie Huang",
      "Kerui Zhu",
      "Kevin Chen-Chuan Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10545"
  },
  {
    "id": "arXiv:2212.10547",
    "title": "Semantically-informed Hierarchical Event Modeling",
    "abstract": "Prior work has shown that coupling sequential latent variable models with\nsemantic ontological knowledge can improve the representational capabilities of\nevent modeling approaches. In this work, we present a novel, doubly\nhierarchical, semi-supervised event modeling framework that provides structural\nhierarchy while also accounting for ontological hierarchy. Our approach\nconsists of multiple layers of structured latent variables, where each\nsuccessive layer compresses and abstracts the previous layers. We guide this\ncompression through the injection of structured ontological knowledge that is\ndefined at the type level of events: importantly, our model allows for partial\ninjection of semantic knowledge and it does not depend on observing instances\nat any particular level of the semantic ontology. Across two different datasets\nand four different evaluation metrics, we demonstrate that our approach is able\nto out-perform the previous state-of-the-art approaches, demonstrating the\nbenefits of structured and semantic hierarchical knowledge for event modeling.",
    "descriptor": "",
    "authors": [
      "Shubhashis Roy Dipta",
      "Mehdi Rezaee",
      "Francis Feraro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10547"
  },
  {
    "id": "arXiv:2212.10548",
    "title": "T-Projection: High Quality Annotation Projection for Sequence Labeling  Tasks",
    "abstract": "In the absence of readily available labeled data for a given task and\nlanguage, annotation projection has been proposed as one of the possible\nstrategies to automatically generate annotated data which may then be used to\ntrain supervised systems. Annotation projection has often been formulated as\nthe task of projecting, on parallel corpora, some labels from a source into a\ntarget language. In this paper we present T-Projection, a new approach for\nannotation projection that leverages large pretrained text2text language models\nand state-of-the-art machine translation technology. T-Projection decomposes\nthe label projection task into two subtasks: (i) The candidate generation step,\nin which a set of projection candidates using a multilingual T5 model is\ngenerated and, (ii) the candidate selection step, in which the candidates are\nranked based on translation probabilities. We evaluate our method in three\ndownstream tasks and five different languages. Our results show that\nT-projection improves the average F1 score of previous methods by more than 8\npoints.",
    "descriptor": "",
    "authors": [
      "Iker Garc\u00eda-Ferrero",
      "Rodrigo Agerri",
      "German Rigau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10548"
  },
  {
    "id": "arXiv:2212.10549",
    "title": "Cross-modal Attention Congruence Regularization for Vision-Language  Relation Alignment",
    "abstract": "Despite recent progress towards scaling up multimodal vision-language models,\nthese models are still known to struggle on compositional generalization\nbenchmarks such as Winoground. We find that a critical component lacking from\ncurrent vision-language models is relation-level alignment: the ability to\nmatch directional semantic relations in text (e.g., \"mug in grass\") with\nspatial relationships in the image (e.g., the position of the mug relative to\nthe grass). To tackle this problem, we show that relation alignment can be\nenforced by encouraging the directed language attention from 'mug' to 'grass'\n(capturing the semantic relation 'in') to match the directed visual attention\nfrom the mug to the grass. Tokens and their corresponding objects are softly\nidentified using the cross-modal attention. We prove that this notion of soft\nrelation alignment is equivalent to enforcing congruence between vision and\nlanguage attention matrices under a 'change of basis' provided by the\ncross-modal attention matrix. Intuitively, our approach projects visual\nattention into the language attention space to calculate its divergence from\nthe actual language attention, and vice versa. We apply our Cross-modal\nAttention Congruence Regularization (CACR) loss to UNITER and improve on the\nstate-of-the-art approach to Winoground.",
    "descriptor": "",
    "authors": [
      "Rohan Pandey",
      "Rulin Shao",
      "Paul Pu Liang",
      "Ruslan Salakhutdinov",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10549"
  },
  {
    "id": "arXiv:2212.10550",
    "title": "InstantAvatar: Learning Avatars from Monocular Video in 60 Seconds",
    "abstract": "In this paper, we take a significant step towards real-world applicability of\nmonocular neural avatar reconstruction by contributing InstantAvatar, a system\nthat can reconstruct human avatars from a monocular video within seconds, and\nthese avatars can be animated and rendered at an interactive rate. To achieve\nthis efficiency we propose a carefully designed and engineered system, that\nleverages emerging acceleration structures for neural fields, in combination\nwith an efficient empty space-skipping strategy for dynamic scenes. We also\ncontribute an efficient implementation that we will make available for research\npurposes. Compared to existing methods, InstantAvatar converges 130x faster and\ncan be trained in minutes instead of hours. It achieves comparable or even\nbetter reconstruction quality and novel pose synthesis results. When given the\nsame time budget, our method significantly outperforms SoTA methods.\nInstantAvatar can yield acceptable visual quality in as little as 10 seconds\ntraining time.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Tianjian Jiang",
      "Xu Chen",
      "Jie Song",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10550"
  },
  {
    "id": "arXiv:2212.10551",
    "title": "Lego-MT: Towards Detachable Models in Massively Multilingual Machine  Translation",
    "abstract": "Traditional multilingual neural machine translation (MNMT) uses a single\nmodel to translate all directions. However, with the increasing scale of\nlanguage pairs, simply using a single model for massive MNMT brings new\nchallenges: parameter tension and large computations. In this paper, we revisit\nmulti-way structures by assigning an individual branch for each language\n(group). Despite being a simple architecture, it is challenging to train\nde-centralized models due to the lack of constraints to align representations\nfrom all languages. We propose a localized training recipe to map different\nbranches into a unified space, resulting in an efficient detachable model,\nLego-MT. For a fair comparison, we collect data from OPUS and build the first\nlarge-scale open-source translation benchmark covering 7 language-centric data,\neach containing 445 language pairs. Experiments show that Lego-MT (1.2B) brings\ngains of more than 4 BLEU while outperforming M2M-100 (12B) (We will public all\ntraining data, models, and checkpoints)",
    "descriptor": "",
    "authors": [
      "Fei Yuan",
      "Yinquan Lu",
      "WenHao Zhu",
      "Lingpeng Kong",
      "Lei Li",
      "Jingjing Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10551"
  },
  {
    "id": "arXiv:2212.10553",
    "title": "RangeAugment: Efficient Online Augmentation with Range Learning",
    "abstract": "State-of-the-art automatic augmentation methods (e.g., AutoAugment and\nRandAugment) for visual recognition tasks diversify training data using a large\nset of augmentation operations. The range of magnitudes of many augmentation\noperations (e.g., brightness and contrast) is continuous. Therefore, to make\nsearch computationally tractable, these methods use fixed and manually-defined\nmagnitude ranges for each operation, which may lead to sub-optimal policies. To\nanswer the open question on the importance of magnitude ranges for each\naugmentation operation, we introduce RangeAugment that allows us to efficiently\nlearn the range of magnitudes for individual as well as composite augmentation\noperations. RangeAugment uses an auxiliary loss based on image similarity as a\nmeasure to control the range of magnitudes of augmentation operations. As a\nresult, RangeAugment has a single scalar parameter for search, image\nsimilarity, which we simply optimize via linear search. RangeAugment integrates\nseamlessly with any model and learns model- and task-specific augmentation\npolicies. With extensive experiments on the ImageNet dataset across different\nnetworks, we show that RangeAugment achieves competitive performance to\nstate-of-the-art automatic augmentation methods with 4-5 times fewer\naugmentation operations. Experimental results on semantic segmentation, object\ndetection, foundation models, and knowledge distillation further shows\nRangeAugment's effectiveness.",
    "descriptor": "\nComments: Technical report (22 pages including references and appendix)\n",
    "authors": [
      "Sachin Mehta",
      "Saeid Naderiparizi",
      "Fartash Faghri",
      "Maxwell Horton",
      "Lailin Chen",
      "Ali Farhadi",
      "Oncel Tuzel",
      "Mohammad Rastegari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10553"
  },
  {
    "id": "arXiv:2212.10554",
    "title": "A Length-Extrapolatable Transformer",
    "abstract": "Position modeling plays a critical role in Transformers. In this paper, we\nfocus on length extrapolation, i.e., training on short texts while evaluating\nlonger sequences. We define attention resolution as an indicator of\nextrapolation. Then we propose two designs to improve the above metric of\nTransformers. Specifically, we introduce a relative position embedding to\nexplicitly maximize attention resolution. Moreover, we use blockwise causal\nattention during inference for better resolution. We evaluate different\nTransformer variants with language modeling. Experimental results show that our\nmodel achieves strong performance in both interpolation and extrapolation\nsettings. The code will be available at https://aka.ms/LeX-Transformer.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Yutao Sun",
      "Li Dong",
      "Barun Patra",
      "Shuming Ma",
      "Shaohan Huang",
      "Alon Benhaim",
      "Vishrav Chaudhary",
      "Xia Song",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10554"
  },
  {
    "id": "arXiv:2212.10555",
    "title": "PairReranker: Pairwise Reranking for Natural Language Generation",
    "abstract": "Pre-trained language models have been successful in natural language\ngeneration (NLG) tasks. While various decoding methods have been employed, they\noften produce suboptimal results. We first present an empirical analysis of\nthree NLG tasks: summarization, machine translation, and constrained text\ngeneration. We found that selecting the best output from the results of\nmultiple decoding methods can significantly improve performance. To further\nimprove reranking for NLG tasks, we proposed a novel method,\n\\textsc{PairReranker}, which uses a single encoder and a pairwise loss function\nto jointly encode a source input and a pair of candidates and compare them.\nExperiments on three NLG tasks demonstrated the effectiveness and flexibility\nof \\textsc{PairReranker}, showing strong results, compared with previous\nbaselines. In addition, our \\textsc{PairReranker} can generalize to\nsignificantly improve GPT-3 (text-davinci-003) results (e.g., 24.55\\% on\nCommonGen and 11.35\\% on WMT18 zh-en), even though our rerankers are not\ntrained with any GPT-3 candidates.",
    "descriptor": "\nComments: We will release our code and data at this https URL\n",
    "authors": [
      "Dongfu Jiang",
      "Bill Yuchen Lin",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10555"
  },
  {
    "id": "arXiv:2212.10556",
    "title": "Unleashing the Power of Visual Prompting At the Pixel Level",
    "abstract": "This paper presents a simple and effective visual prompting method for\nadapting pre-trained models to downstream recognition tasks. Our method\nincludes two key designs. First, rather than directly adding together the\nprompt and the image, we treat the prompt as an extra and independent learnable\ncomponent. We show that the strategy of reconciling the prompt and the image\nmatters, and find that warping the prompt around a properly shrinked image\nempirically works the best. Second, we re-introduce two \"old tricks\" commonly\nused in building transferable adversarial examples, i.e., input diversity and\ngradient normalization, into visual prompting. These techniques improve\noptimization and enable the prompt to generalize better. We provide extensive\nexperimental results to demonstrate the effectiveness of our method. Using a\nCLIP model, our prompting method sets a new record of 82.8% average accuracy\nacross 12 popular classification datasets, substantially surpassing the prior\nart by +5.6%. It is worth noting that this prompting performance already\noutperforms linear probing by +2.1% and can even match fully fine-tuning in\ncertain datasets. In addition, our prompting method shows competitive\nperformance across different data scales and against distribution shifts. The\ncode is publicly available at https://github.com/UCSC-VLAA/EVP.",
    "descriptor": "",
    "authors": [
      "Junyang Wu",
      "Xianhang Li",
      "Chen Wei",
      "Huiyu Wang",
      "Alan Yuille",
      "Yuyin Zhou",
      "Cihang Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10556"
  },
  {
    "id": "arXiv:2212.10557",
    "title": "DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines",
    "abstract": "Dialogue models are able to generate coherent and fluent responses, but they\ncan still be challenging to control and may produce non-engaging, unsafe\nresults. This unpredictability diminishes user trust and can hinder the use of\nthe models in the real world. To address this, we introduce DialGuide, a novel\nframework for controlling dialogue model behavior using natural language rules,\nor guidelines. These guidelines provide information about the context they are\napplicable to and what should be included in the response, allowing the models\nto generate responses that are more closely aligned with the developer's\nexpectations and intent. We evaluate DialGuide on three tasks in open-domain\ndialogue response generation: guideline selection, response generation, and\nresponse entailment verification. Our dataset contains 10,737 positive and\n15,467 negative dialogue context-response-guideline triplets across two domains\n- chit-chat and safety. We provide baseline models for the tasks and benchmark\ntheir performance. We also demonstrate that DialGuide is effective in the\ndialogue safety domain, producing safe and engaging responses that follow\ndeveloper guidelines.",
    "descriptor": "",
    "authors": [
      "Prakhar Gupta",
      "Yang Liu",
      "Di Jin",
      "Behnam Hedayatnia",
      "Spandana Gella",
      "Sijia Liu",
      "Patrick Lange",
      "Julia Hirschberg",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10557"
  },
  {
    "id": "arXiv:2212.10558",
    "title": "On-the-fly Denoising for Data Augmentation in Natural Language  Understanding",
    "abstract": "Data Augmentation (DA) is frequently used to automatically provide additional\ntraining data without extra human annotation. However, data augmentation may\nintroduce noisy data that impairs training. To guarantee the quality of\naugmented data, existing methods either assume no noise exists in the augmented\ndata and adopt consistency training or use simple heuristics such as training\nloss and diversity constraints to filter out ``noisy'' data. However, those\nfiltered examples may still contain useful information, and dropping them\ncompletely causes loss of supervision signals. In this paper, based on the\nassumption that the original dataset is cleaner than the augmented data, we\npropose an on-the-fly denoising technique for data augmentation that learns\nfrom soft augmented labels provided by an organic teacher model trained on the\ncleaner original data. A simple self-regularization module is applied to force\nthe model prediction to be consistent across two distinct dropouts to further\nprevent overfitting on noisy labels. Our method can be applied to augmentation\ntechniques in general and can consistently improve the performance on both text\nclassification and question-answering tasks.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Tianqing Fang",
      "Wenxuan Zhou",
      "Fangyu Liu",
      "Hongming Zhang",
      "Yangqiu Song",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10558"
  },
  {
    "id": "arXiv:2212.10559",
    "title": "Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient  Descent as Meta Optimizers",
    "abstract": "Large pretrained language models have shown surprising In-Context Learning\n(ICL) ability. With a few demonstration input-label pairs, they can predict the\nlabel for an unseen input without additional parameter updates. Despite the\ngreat success in performance, the working mechanism of ICL still remains an\nopen problem. In order to better understand how ICL works, this paper explains\nlanguage models as meta optimizers and understands ICL as a kind of implicit\nfinetuning. Theoretically, we figure out that the Transformer attention has a\ndual form of gradient descent based optimization. On top of it, we understand\nICL as follows: GPT first produces meta gradients according to the\ndemonstration examples, and then these meta gradients are applied to the\noriginal GPT to build an ICL model. Experimentally, we comprehensively compare\nthe behavior of ICL and explicit finetuning based on real tasks to provide\nempirical evidence that supports our understanding. The results prove that ICL\nbehaves similarly to explicit finetuning at the prediction level, the\nrepresentation level, and the attention behavior level. Further, inspired by\nour understanding of meta optimization, we design a momentum-based attention by\nanalogy with the momentum-based gradient descent algorithm. Its consistently\nbetter performance over vanilla attention supports our understanding again from\nanother aspect, and more importantly, it shows the potential to utilize our\nunderstanding for future model designing.",
    "descriptor": "",
    "authors": [
      "Damai Dai",
      "Yutao Sun",
      "Li Dong",
      "Yaru Hao",
      "Zhifang Sui",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10559"
  },
  {
    "id": "arXiv:2212.10560",
    "title": "Self-Instruct: Aligning Language Model with Self Generated Instructions",
    "abstract": "Large \"instruction-tuned\" language models (finetuned to respond to\ninstructions) have demonstrated a remarkable ability to generalize zero-shot to\nnew tasks. Nevertheless, they depend heavily on human-written instruction data\nthat is limited in quantity, diversity, and creativity, therefore hindering the\ngenerality of the tuned model. We introduce Self-Instruct, a framework for\nimproving the instruction-following capabilities of pretrained language models\nby bootstrapping off its own generations. Our pipeline generates instruction,\ninput, and output samples from a language model, then prunes them before using\nthem to finetune the original model. Applying our method to vanilla GPT3, we\ndemonstrate a 33% absolute improvement over the original model on\nSuper-NaturalInstructions, on par with the performance of InstructGPT_001,\nwhich is trained with private user data and human annotations. For further\nevaluation, we curate a set of expert-written instructions for novel tasks, and\nshow through human evaluation that tuning GPT3 with Self-Instruct outperforms\nusing existing public instruction datasets by a large margin, leaving only a 5%\nabsolute gap behind InstructGPT_001. Self-Instruct provides an almost\nannotation-free method for aligning pre-trained language models with\ninstructions, and we release our large synthetic dataset to facilitate future\nstudies on instruction tuning.",
    "descriptor": "\nComments: work in progress\n",
    "authors": [
      "Yizhong Wang",
      "Yeganeh Kordi",
      "Swaroop Mishra",
      "Alisa Liu",
      "Noah A. Smith",
      "Daniel Khashabi",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10560"
  },
  {
    "id": "arXiv:2212.10561",
    "title": "Parsel: A Unified Natural Language Framework for Algorithmic Reasoning",
    "abstract": "Despite recent success in large language model (LLM) reasoning, LLMs still\nstruggle with hierarchical multi-step reasoning like generating complex\nprograms. In these cases, humans often start with a high-level algorithmic\ndesign and implement each part gradually. We introduce Parsel, a framework\nenabling automatic implementation and validation of complex algorithms with\ncode LLMs, based on hierarchical function descriptions in natural language.\nParsel can be used across domains requiring hierarchical reasoning, e.g. code\nsynthesis, theorem proving, and robotic planning. We demonstrate Parsel's\ncapabilities by using it to generate complex programs that cannot currently be\nautomatically implemented from one description and backtranslating Python\nprograms in the APPS dataset. Beyond modeling capabilities, Parsel allows\nproblem-solving with high-level algorithmic designs, benefiting both students\nand professional programmers.",
    "descriptor": "",
    "authors": [
      "Eric Zelikman",
      "Qian Huang",
      "Gabriel Poesia",
      "Noah D. Goodman",
      "Nick Haber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10561"
  },
  {
    "id": "arXiv:2212.10562",
    "title": "Character-Aware Models Improve Visual Text Rendering",
    "abstract": "Current image generation models struggle to reliably produce well-formed\nvisual text. In this paper, we investigate a key contributing factor: popular\ntext-to-image models lack character-level input features, making it much harder\nto predict a word's visual makeup as a series of glyphs. To quantify the extent\nof this effect, we conduct a series of controlled experiments comparing\ncharacter-aware vs. character-blind text encoders. In the text-only domain, we\nfind that character-aware models provide large gains on a novel spelling task\n(WikiSpell). Transferring these learnings onto the visual domain, we train a\nsuite of image generation models, and show that character-aware variants\noutperform their character-blind counterparts across a range of novel text\nrendering tasks (our DrawText benchmark). Our models set a much higher\nstate-of-the-art on visual spelling, with 30+ point accuracy gains over\ncompetitors on rare words, despite training on far fewer examples.",
    "descriptor": "",
    "authors": [
      "Rosanne Liu",
      "Dan Garrette",
      "Chitwan Saharia",
      "William Chan",
      "Adam Roberts",
      "Sharan Narang",
      "Irina Blok",
      "RJ Mical",
      "Mohammad Norouzi",
      "Noah Constant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10562"
  },
  {
    "id": "arXiv:2212.10563",
    "title": "Debiasing NLP Models Without Demographic Information",
    "abstract": "Models trained from real-world data tend to imitate and amplify social\nbiases. Although there are many methods suggested to mitigate biases, they\nrequire a preliminary information on the types of biases that should be\nmitigated (e.g., gender or racial bias) and the social groups associated with\neach data sample. In this work, we propose a debiasing method that operates\nwithout any prior knowledge of the demographics in the dataset, detecting\nbiased examples based on an auxiliary model that predicts the main model's\nsuccess and down-weights them during the training process. Results on racial\nand gender bias demonstrate that it is possible to mitigate social biases\nwithout having to use a costly demographic annotation process.",
    "descriptor": "",
    "authors": [
      "Hadas Orgad",
      "Yonatan Belinkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10563"
  },
  {
    "id": "arXiv:2212.10564",
    "title": "Does unsupervised grammar induction need pixels?",
    "abstract": "Are extralinguistic signals such as image pixels crucial for inducing\nconstituency grammars? While past work has shown substantial gains from\nmultimodal cues, we investigate whether such gains persist in the presence of\nrich information from large language models (LLMs). We find that our approach,\nLLM-based C-PCFG (LC-PCFG), outperforms previous multi-modal methods on the\ntask of unsupervised constituency parsing, achieving state-of-the-art\nperformance on a variety of datasets. Moreover, LC-PCFG results in an over 50%\nreduction in parameter count, and speedups in training time of 1.7x for\nimage-aided models and more than 5x for video-aided models, respectively. These\nresults challenge the notion that extralinguistic signals such as image pixels\nare needed for unsupervised grammar induction, and point to the need for better\ntext-only baselines in evaluating the need of multi-modality for the task.",
    "descriptor": "",
    "authors": [
      "Boyi Li",
      "Rodolfo Corona",
      "Karttikeya Mangalam",
      "Catherine Chen",
      "Daniel Flaherty",
      "Serge Belongie",
      "Kilian Q. Weinberger",
      "Jitendra Malik",
      "Trevor Darrell",
      "Dan Klein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10564"
  },
  {
    "id": "arXiv:2102.13273",
    "title": "Application-Driven Learning: A Closed-Loop Prediction and Optimization  Approach Applied to Dynamic Reserves and Demand Forecasting",
    "abstract": "Forecasting and decision-making are generally modeled as two sequential steps\nwith no feedback, following an open-loop approach. In this paper, we present\napplication-driven learning, a new closed-loop framework in which the processes\nof forecasting and decision-making are merged and co-optimized through a\nbilevel optimization problem. We present our methodology in a general format\nand prove that the solution converges to the best estimator in terms of the\nexpected cost of the selected application. Then, we propose two solution\nmethods: an exact method based on the KKT conditions of the second-level\nproblem and a scalable heuristic approach suitable for decomposition methods.\nThe proposed methodology is applied to the relevant problem of defining dynamic\nreserve requirements and conditional load forecasts, offering an alternative\napproach to current \\emph{ad hoc} procedures implemented in industry practices.\nWe benchmark our methodology with the standard sequential least-squares\nforecast and dispatch planning process. We apply the proposed methodology to an\nillustrative system and to a wide range of instances, from dozens of buses to\nlarge-scale realistic systems with thousands of buses. Our results show that\nthe proposed methodology is scalable and yields consistently better performance\nthan the standard open-loop approach.",
    "descriptor": "",
    "authors": [
      "Joaquim Dias Garcia",
      "Alexandre Street",
      "Tito Homem-de-Mello",
      "Francisco D. Mu\u00f1oz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.13273"
  },
  {
    "id": "arXiv:2107.09755",
    "title": "Assessing the Cost of Network Simplifications in Long-Term Hydrothermal  Dispatch Planning Models",
    "abstract": "The sustainable utilization of hydro energy relies on accurate estimates of\nthe opportunity cost of the water. This value is calculated through long-term\nhydrothermal dispatch problems (LTHDP), and the recent literature has raised\nawareness about the consequences of modeling simplifications in these problems.\nThe inaccurate representation of Kirchhoff's voltage law under the premise of a\nDC power flow is an example. Under a non-linear AC model, however, the LTHDP\nbecomes intractable, and the literature lacks an accurate evaluation method of\ndifferent modeling alternatives. In this paper, we extend the state-of-the-art\ncost-assessment framework of network approximations for LTHDP and bring\nrelevant and practical new insights. First, we increase the quality of the\nassessment by using an AC power flow to simulate and compare the performance of\nfive policies based on different network approximations. Second, we find that\nthe tightest network relaxation (based on semidefinite programming) is not the\none exhibiting the best performance. Results show that the DC {power flow} with\nquadratic losses approximation exhibits the lowest expected cost and\ninconsistency gaps. Finally, its computational burden is lower than that\nexhibited by the semidefinite relaxation, whereas market distortions are\nsignificantly reduced in comparison to previously published benchmarks based on\nDC power flow.",
    "descriptor": "",
    "authors": [
      "Andrew W. Rosemberg",
      "Alexandre Street",
      "Joaquim Dias Garcia",
      "Davi M. Vallad\u00e3o",
      "Thuener Silva",
      "Oscar Dowson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.09755"
  },
  {
    "id": "arXiv:2108.03143",
    "title": "An Integrated Progressive Hedging and Benders Decomposition with  Multiple Master Method to Solve the Brazilian Generation Expansion Problem",
    "abstract": "This paper exploits the decomposition structure of the large-scale\nhydrothermal generation expansion planning problem with an integrated modified\nBenders Decomposition and Progressive Hedging approach. We consider detailed\nand realistic data from the Brazilian power system to represent hourly\nchronological constraints based on typical days per month and year. Also, we\nrepresent the multistage stochastic nature of the optimal hydrothermal\noperational policy through co-optimized linear decision rules for individual\nreservoirs. Therefore, we ensure investment decisions compatible with a\nnonanticipative (implementable) operational policy. To solve the large-scale\noptimization problem, we propose an improved Benders Decomposition method with\nmultiple instances of the master problem, each of which strengthened by primal\ncuts and new Benders cuts generated by each master's trial solution.\nAdditionally, our new approach allows using Progressive Hedging penalization\nterms for accelerating the convergence of the method. We show that our method\nis 60\\% faster than the benchmark. Finally, the consideration of a\nnonanticipative operational policy can save 7.64\\% of the total cost (16.18\\%\nof the investment costs) and significantly improve spot price profiles.",
    "descriptor": "",
    "authors": [
      "Alessandro Soares",
      "Alexandre Street",
      "Tiago Andrade",
      "Joaquim Dias Garcia"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.03143"
  },
  {
    "id": "arXiv:2205.02307",
    "title": "BilevelJuMP.jl: Modeling and Solving Bilevel Optimization in Julia",
    "abstract": "In this paper we present BilevelJuMP, a new Julia package to support bilevel\noptimization within the JuMP framework. The package is a Julia library that\nenables the user to describe both upper and lower-level optimization problems\nusing the JuMP algebraic syntax. Due to the generality and flexibility our\nlibrary inherits from JuMP's syntax, our package allows users to model bilevel\noptimization problems with conic constraints in the lower level and all JuMP\nsupported constraints in the upper level (Conic, Quadratic, Non-Linear,\nInteger, etc.). Moreover, the user-defined problem can be subsequently solved\nby various techniques relying on mathematical program with equilibrium\nconstraints (MPEC) reformulations. Manipulations on the original problem data\nare possible due to MathOptInterface.jl's structures and Dualization.jl\nfeatures. Hence, the proposed package allows quickly model, deploy, and thereby\nexperiment bilevel models based on off-the-shelf mixed integer linear\nprogramming and nonlinear solvers.",
    "descriptor": "",
    "authors": [
      "Joaquim Dias Garcia",
      "Guilherme Bodin",
      "Alexandre Street"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2205.02307"
  },
  {
    "id": "arXiv:2212.09749",
    "title": "Statistical Comparison among Brain Networks with Popular Network  Measurement Algorithms",
    "abstract": "In this research, a number of popular network measurement algorithms have\nbeen applied to several brain networks (based on applicability of algorithms)\nfor finding out statistical correlation among these popular network\nmeasurements which will help scientists to understand these popular network\nmeasurement algorithms and their applicability to brain networks. By analysing\nthe results of correlations among these network measurement algorithms,\nstatistical comparison among selected brain networks has also been summarized.\nBesides that, to understand each brain network, the visualization of each brain\nnetwork and each brain network degree distribution histogram have been\nextrapolated. Six network measurement algorithms have been chosen to apply time\nto time on sixteen brain networks based on applicability of these network\nmeasurement algorithms and the results of these network measurements are put\ninto a correlation method to show the relationship among these six network\nmeasurement algorithms for each brain network. At the end, the results of the\ncorrelations have been summarized to show the statistical comparison among\nthese sixteen brain networks.",
    "descriptor": "\nComments: 22 pages, 38 figures, 19 tables\n",
    "authors": [
      "Rakib Hassan Pran"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2212.09749"
  },
  {
    "id": "arXiv:2212.09844",
    "title": "Counterfactual Risk Assessments under Unmeasured Confounding",
    "abstract": "Statistical risk assessments inform consequential decisions such as pretrial\nrelease in criminal justice, and loan approvals in consumer finance. Such risk\nassessments make counterfactual predictions, predicting the likelihood of an\noutcome under a proposed decision (e.g., what would happen if we approved this\nloan?). A central challenge, however, is that there may have been unmeasured\nconfounders that jointly affected past decisions and outcomes in the historical\ndata. This paper proposes a tractable mean outcome sensitivity model that\nbounds the extent to which unmeasured confounders could affect outcomes on\naverage. The mean outcome sensitivity model partially identifies the\nconditional likelihood of the outcome under the proposed decision, popular\npredictive performance metrics (e.g., accuracy, calibration, TPR, FPR), and\ncommonly-used predictive disparities. We derive their sharp identified sets,\nand we then solve three tasks that are essential to deploying statistical risk\nassessments in high-stakes settings. First, we propose a doubly-robust learning\nprocedure for the bounds on the conditional likelihood of the outcome under the\nproposed decision. Second, we translate our estimated bounds on the conditional\nlikelihood of the outcome under the proposed decision into a robust, plug-in\ndecision-making policy. Third, we develop doubly-robust estimators of the\nbounds on the predictive performance of an existing risk assessment.",
    "descriptor": "",
    "authors": [
      "Ashesh Rambachan",
      "Amanda Coston",
      "Edward Kennedy"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.09844"
  },
  {
    "id": "arXiv:2212.09961",
    "title": "Uncertainty Quantification of MLE for Entity Ranking with Covariates",
    "abstract": "This paper concerns with statistical estimation and inference for the ranking\nproblems based on pairwise comparisons with additional covariate information\nsuch as the attributes of the compared items. Despite extensive studies, few\nprior literatures investigate this problem under the more realistic setting\nwhere covariate information exists. To tackle this issue, we propose a novel\nmodel, Covariate-Assisted Ranking Estimation (CARE) model, that extends the\nwell-known Bradley-Terry-Luce (BTL) model, by incorporating the covariate\ninformation. Specifically, instead of assuming every compared item has a fixed\nlatent score $\\{\\theta_i^*\\}_{i=1}^n$, we assume the underlying scores are\ngiven by $\\{\\alpha_i^*+{x}_i^\\top\\beta^*\\}_{i=1}^n$, where $\\alpha_i^*$ and\n${x}_i^\\top\\beta^*$ represent latent baseline and covariate score of the $i$-th\nitem, respectively. We impose natural identifiability conditions and derive the\n$\\ell_{\\infty}$- and $\\ell_2$-optimal rates for the maximum likelihood\nestimator of $\\{\\alpha_i^*\\}_{i=1}^{n}$ and $\\beta^*$ under a sparse comparison\ngraph, using a novel `leave-one-out' technique (Chen et al., 2019) . To conduct\nstatistical inferences, we further derive asymptotic distributions for the MLE\nof $\\{\\alpha_i^*\\}_{i=1}^n$ and $\\beta^*$ with minimal sample complexity. This\nallows us to answer the question whether some covariates have any explanation\npower for latent scores and to threshold some sparse parameters to improve the\nranking performance. We improve the approximation method used in (Gao et al.,\n2021) for the BLT model and generalize it to the CARE model. Moreover, we\nvalidate our theoretical results through large-scale numerical studies and an\napplication to the mutual fund stock holding dataset.",
    "descriptor": "\nComments: This paper studies uncertainty quantification for ranking with covariates\n",
    "authors": [
      "Jianqing Fan",
      "Jikai Hou",
      "Mengxin Yu"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.09961"
  },
  {
    "id": "arXiv:2212.09963",
    "title": "Use of mobile phone sensing data to estimate residence and mobility  times in urban patches during the COVID-19 epidemic: The case of the 2020  outbreak in Hermosillo, Mexico",
    "abstract": "It is often necessary to introduce the main characteristics of population\nmobility dynamics to model critical social phenomena such as the economy,\nviolence, transmission of information, or infectious diseases. In this work, we\nfocus on modeling and inferring urban population mobility using the geospatial\ndata of its inhabitants. The objective is to estimate mobility and times\ninhabitants spend in the areas of interest, such as zip codes and census\ngeographical areas. The proposed method uses the Brownian bridge model for\nanimal movement in ecology. We illustrate its possible applications using\nmobile phone GPS data in 2020 from the city of Hermosillo, Sonora, in Mexico.\nWe incorporate the estimated residence-mobility matrix into a multi-patch\ncompartmental SEIR model to assess the effect of mobility changes due to\ngovernmental interventions",
    "descriptor": "\nComments: 28 pages, 7 figures\n",
    "authors": [
      "L. Leticia Ram\u00edrez-Ram\u00edrez",
      "Jos\u00e9 A. Montoya",
      "Jes\u00fas F. Espinoza",
      "Chahak Mehta",
      "Albert Orwa Akuno",
      "Tan Bui-Thanh"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.09963"
  },
  {
    "id": "arXiv:2212.09977",
    "title": "Conditioned Generative Transformers for Histopathology Image Synthetic  Augmentation",
    "abstract": "Deep learning networks have demonstrated state-of-the-art performance on\nmedical image analysis tasks. However, the majority of the works rely heavily\non abundantly labeled data, which necessitates extensive involvement of domain\nexperts. Vision transformer (ViT) based generative adversarial networks (GANs)\nrecently demonstrated superior potential in general image synthesis, yet are\nless explored for histopathology images. In this paper, we address these\nchallenges by proposing a pure ViT-based conditional GAN model for\nhistopathology image synthetic augmentation. To alleviate training instability\nand improve generation robustness, we first introduce a conditioned class\nprojection method to facilitate class separation. We then implement a\nmulti-loss weighing function to dynamically balance the losses between\nclassification tasks. We further propose a selective augmentation mechanism to\nactively choose the appropriate generated images and bring additional\nperformance improvements. Extensive experiments on the histopathology datasets\nshow that leveraging our synthetic augmentation framework results in\nsignificant and consistent improvements in classification performance.",
    "descriptor": "",
    "authors": [
      "Meng Li",
      "Chaoyi Li",
      "Can Peng",
      "Brian Lovell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.09977"
  },
  {
    "id": "arXiv:2212.09984",
    "title": "Using Machine Learning to Determine Morphologies of $z<1$ AGN Host  Galaxies in the Hyper Suprime-Cam Wide Survey",
    "abstract": "We present a machine-learning framework to accurately characterize\nmorphologies of Active Galactic Nucleus (AGN) host galaxies within $z<1$. We\nfirst use PSFGAN to decouple host galaxy light from the central point source,\nthen we invoke the Galaxy Morphology Network (GaMorNet) to estimate whether the\nhost galaxy is disk-dominated, bulge-dominated, or indeterminate. Using optical\nimages from five bands of the HSC Wide Survey, we build models independently in\nthree redshift bins: low $(0<z<0.25)$, medium $(0.25<z<0.5)$, and high\n$(0.5<z<1.0)$. By first training on a large number of simulated galaxies, then\nfine-tuning using far fewer classified real galaxies, our framework predicts\nthe actual morphology for $\\sim$ $60\\%-70\\%$ host galaxies from test sets, with\na classification precision of $\\sim$ $80\\%-95\\%$, depending on redshift bin.\nSpecifically, our models achieve disk precision of $96\\%/82\\%/79\\%$ and bulge\nprecision of $90\\%/90\\%/80\\%$ (for the 3 redshift bins), at thresholds\ncorresponding to indeterminate fractions of $30\\%/43\\%/42\\%$. The\nclassification precision of our models has a noticeable dependency on host\ngalaxy radius and magnitude. No strong dependency is observed on contrast\nratio. Comparing classifications of real AGNs, our models agree well with\ntraditional 2D fitting with GALFIT. The PSFGAN+GaMorNet framework does not\ndepend on the choice of fitting functions or galaxy-related input parameters,\nruns orders of magnitude faster than GALFIT, and is easily generalizable via\ntransfer learning, making it an ideal tool for studying AGN host galaxy\nmorphology in forthcoming large imaging survey.",
    "descriptor": "\nComments: Accepted for publication in The Astrophysical Journal. 35 Pages. 25 Figures\n",
    "authors": [
      "Chuan Tian",
      "C. Megan Urry",
      "Aritra Ghosh",
      "Ryan Ofman",
      "Tonima Tasnim Ananna",
      "Connor Auge",
      "Nico Cappelluti",
      "Meredith C. Powell",
      "David B. Sanders",
      "Kevin Schawinski",
      "Dominic Stark",
      "Grant R. Tremblay"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09984"
  },
  {
    "id": "arXiv:2212.10081",
    "title": "Galaxy Image Classification using Hierarchical Data Learning with  Weighted Sampling and Label Smoothing",
    "abstract": "With the development of a series of Galaxy sky surveys in recent years, the\nobservations increased rapidly, which makes the research of machine learning\nmethods for galaxy image recognition a hot topic. Available automatic galaxy\nimage recognition researches are plagued by the large differences in similarity\nbetween categories, the imbalance of data between different classes, and the\ndiscrepancy between the discrete representation of Galaxy classes and the\nessentially gradual changes from one morphological class to the adjacent class\n(DDRGC). These limitations have motivated several astronomers and machine\nlearning experts to design projects with improved galaxy image recognition\ncapabilities. Therefore, this paper proposes a novel learning method,\n``Hierarchical Imbalanced data learning with Weighted sampling and Label\nsmoothing\" (HIWL). The HIWL consists of three key techniques respectively\ndealing with the above-mentioned three problems: (1) Designed a hierarchical\ngalaxy classification model based on an efficient backbone network; (2)\nUtilized a weighted sampling scheme to deal with the imbalance problem; (3)\nAdopted a label smoothing technique to alleviate the DDRGC problem. We applied\nthis method to galaxy photometric images from the Galaxy Zoo-The Galaxy\nChallenge, exploring the recognition of completely round smooth, in between\nsmooth, cigar-shaped, edge-on and spiral. The overall classification accuracy\nis 96.32\\%, and some superiorities of the HIWL are shown based on recall,\nprecision, and F1-Score in comparing with some related works. In addition, we\nalso explored the visualization of the galaxy image features and model\nattention to understand the foundations of the proposed scheme.",
    "descriptor": "\nComments: accepted by MNRAS\n",
    "authors": [
      "Xiaohua Ma",
      "Xiangru Li",
      "Ali Luo",
      "Jinqu Zhang",
      "Hui Li"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10081"
  },
  {
    "id": "arXiv:2212.10086",
    "title": "End to End Generative Meta Curriculum Learning For Medical Data  Augmentation",
    "abstract": "Current medical image synthetic augmentation techniques rely on intensive use\nof generative adversarial networks (GANs). However, the nature of GAN\narchitecture leads to heavy computational resources to produce synthetic images\nand the augmentation process requires multiple stages to complete. To address\nthese challenges, we introduce a novel generative meta curriculum learning\nmethod that trains the task-specific model (student) end-to-end with only one\nadditional teacher model. The teacher learns to generate curriculum to feed\ninto the student model for data augmentation and guides the student to improve\nperformance in a meta-learning style. In contrast to the generator and\ndiscriminator in GAN, which compete with each other, the teacher and student\ncollaborate to improve the student's performance on the target tasks. Extensive\nexperiments on the histopathology datasets show that leveraging our framework\nresults in significant and consistent improvements in classification\nperformance.",
    "descriptor": "",
    "authors": [
      "Meng Li",
      "Brian Lovell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10086"
  },
  {
    "id": "arXiv:2212.10091",
    "title": "Computer Vision Methods for Automating Turbot Fish Cutting",
    "abstract": "This paper is about the design of an automated machine to cut turbot fish\nspecimens. Machine vision is a key part of this project as it is used to\ncompute a cutting curve for the specimen head. This task is impossible to be\ncarried out by mechanical means. Machine vision is used to detect head boundary\nand a robot is used to cut the head. Binarization and mathematical morphology\nare used to detect fish boundary and this boundary is subsequently analyzed\n(using Hough transform and convex hull) to detect key points and thus defining\nthe cutting curve. Afterwards, mechanical systems are used to slice fish to get\nan easy presentation for end consumer (as fish fillets than can be easily\nmarketed and consumed).",
    "descriptor": "\nComments: 5 pages, 11 figurs. Derived from conference publication: this https URL\n",
    "authors": [
      "Fernando Martin-Rodriguez",
      "Fernando Isasi-de-Vicente",
      "Monica Fernandez-Barciela"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10091"
  },
  {
    "id": "arXiv:2212.10117",
    "title": "Biased processing and opinion polarization: experimental refinement of  argument communication theory in the context of the energy debate",
    "abstract": "In sociological research, the study of macro processes, such as opinion\npolarization, faces a fundamental problem, the so-called micro-macro problem.\nTo overcome this problem, we combine empirical experimental research on biased\nargument processing with a computational theory of group deliberation in order\nto clarify the role of biased processing in debates around energy. The\nexperiment reveals a strong tendency to consider arguments aligned with the\ncurrent attitude more persuasive and to downgrade those speaking against it.\nThis is integrated into the framework of argument communication theory in which\nagents exchange arguments about a certain topic and adapt opinions accordingly.\nWe derive a mathematical model that allows to relate the strength of biased\nprocessing to expected attitude changes given the specific experimental\nconditions and find a clear signature of moderate biased processing. We further\nshow that this model fits significantly better to the experimentally observed\nattitude changes than the neutral argument processing assumption made in\nprevious models. Our approach provides new insight into the relationship\nbetween biased processing and opinion polarization. At the individual level our\nanalysis reveals a sharp qualitative transition from attitude moderation to\npolarization. At the collective level we find (i.) that weak biased processing\nsignificantly accelerates group decision processes whereas (ii.) strong biased\nprocessing leads to a persistent conflictual state of subgroup polarization.\nWhile this shows that biased processing alone is sufficient for the emergence\nof polarization, we also demonstrate that homophily may lead to intra-group\nconflict at significantly lower rates of biased processing.",
    "descriptor": "",
    "authors": [
      "Sven Banisch",
      "Hawal Shamon"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Multiagent Systems (cs.MA)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2212.10117"
  },
  {
    "id": "arXiv:2212.10118",
    "title": "Diffusion equations with spatially dependent coefficients and fractal  Cauer-type networks",
    "abstract": "We give a self-contained proof of the connection existing between diffusion\nequations with spatially dependent coefficients and fractal Cauer-type networks\ninitiated by J. Sabatier in 2020 and discussed in more details in [J. Sabatier\nand al., Fractional behaviours modelling, Springer, 2022].",
    "descriptor": "",
    "authors": [
      "Jacky Cresson",
      "Anna Szafranska"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.10118"
  },
  {
    "id": "arXiv:2212.10143",
    "title": "Validating argument-based opinion dynamics with survey experiments",
    "abstract": "The empirical validation of models remains one of the most important\nchallenges in opinion dynamics. In this contribution, we report on recent\ndevelopments on combining data from survey experiments with computational\nmodels of opinion formation. We extend previous work on the empirical\nvalidation of an argument-based model for opinion dynamics in which biased\nprocessing is the principle mechanism. While previous work has focused on\ncalibrating the micro mechanism with experimental data on argument-induced\nopinion change, this paper concentrates on macro-level validity using the\nempirical data gathered in the survey experiment. For this purpose, the\nargument model is extended by an external source of balanced information which\nallows to control for the impact of peer influence processes relative to other\nnoisy processes. We show that surveyed opinion distributions are matched with a\nhigh level of accuracy in a specific region in the parameter space, indicating\nan equal impact of social influence and external noise. More importantly, the\nestimated strength of biased processing given the macro data is compatible with\nthose values that achieve high likelihood at the micro level. The main\ncontribution of the paper is hence to show that the extended argument-based\nmodel provides a solid bridge from the micro processes of argument-induced\nattitude change to macro level opinion distributions. Beyond that, we review\nthe development of argument-based models and present a new method for the\nautomated classification of model outcomes.",
    "descriptor": "",
    "authors": [
      "Sven Banisch",
      "Hawal Shamon"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Multiagent Systems (cs.MA)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.10143"
  },
  {
    "id": "arXiv:2212.10234",
    "title": "Auction designs to increase incentive compatibility and reduce  self-scheduling in electricity markets",
    "abstract": "The system operator's scheduling problem in electricity markets, called unit\ncommitment, is a non-convex mixed-integer program. The optimal value function\nis non-convex, preventing the application of traditional marginal pricing\ntheory to find prices that clear the market and incentivize market participants\nto follow the dispatch schedule. Units that perceive the opportunity to make a\nprofit may be incentivized to self-commit (submitting an offer with zero fixed\noperating costs) or self-schedule their production (submitting an offer with\nzero total cost). We simulate bidder behavior to show that market power can be\nexercised by becoming a price taker. Agents can learn to increase their profits\nvia a reinforcement learning algorithm without explicit knowledge of the costs\nor strategies of other agents. We investigate different non-convex pricing\nmodels over a multi-period commitment window simulating the day-ahead market\nand show that convex hull pricing can reduce producer incentives to deviate\nfrom the central dispatch decision. In a realistic test system with\napproximately 1000 generators, we find strategic bidding under the restricted\nconvex model can increase total producer profits by 4.4% and decrease lost\nopportunity costs by 2/3. While the cost to consumers with convex hull pricing\nis higher at the competitive solution, the cost to consumers is higher with the\nrestricted convex model after strategic bidding.",
    "descriptor": "",
    "authors": [
      "Conleigh Byers",
      "Brent Eldridge"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.10234"
  },
  {
    "id": "arXiv:2212.10249",
    "title": "Learning efficient backprojections across cortical hierarchies in real  time",
    "abstract": "Models of sensory processing and learning in the cortex need to efficiently\nassign credit to synapses in all areas. In deep learning, a known solution is\nerror backpropagation, which however requires biologically implausible weight\ntransport from feed-forward to feedback paths.\nWe introduce Phaseless Alignment Learning (PAL), a bio-plausible method to\nlearn efficient feedback weights in layered cortical hierarchies. This is\nachieved by exploiting the noise naturally found in biophysical systems as an\nadditional carrier of information. In our dynamical system, all weights are\nlearned simultaneously with always-on plasticity and using only information\nlocally available to the synapses. Our method is completely phase-free (no\nforward and backward passes or phased learning) and allows for efficient error\npropagation across multi-layer cortical hierarchies, while maintaining\nbiologically plausible signal transport and learning.\nOur method is applicable to a wide class of models and improves on previously\nknown biologically plausible ways of credit assignment: compared to random\nsynaptic feedback, it can solve complex tasks with less neurons and learn more\nuseful latent representations. We demonstrate this on various classification\ntasks using a cortical microcircuit model with prospective coding.",
    "descriptor": "",
    "authors": [
      "Kevin Max",
      "Laura Kriener",
      "Garibaldi Pineda Garc\u00eda",
      "Thomas Nowotny",
      "Walter Senn",
      "Mihai A. Petrovici"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2212.10249"
  },
  {
    "id": "arXiv:2212.10254",
    "title": "A Local Optima Network View of Real Function Fitness Landscapes",
    "abstract": "The local optima network model has proved useful in the past in connection\nwith combinatorial optimization problems. Here we examine its extension to the\nreal continuous function domain. Through a sampling process, the model builds a\nweighted directed graph which captures the function's minima basin structure\nand its interconnection and which can be easily manipulated with the help of\ncomplex networks metrics. We show that the model provides a complementary view\nof function spaces that is easier to analyze and visualize, especially at\nhigher dimension. In particular, we show that function hardness as represented\nby algorithm performance, is strongly related to several graph properties of\nthe corresponding local optima network, opening the way for a classification of\nproblem difficulty according to the corresponding graph structure and with\npossible extensions in the design of better metaheuristic approaches.",
    "descriptor": "\nComments: journal article, 32 pages, 22 figures\n",
    "authors": [
      "Marco Tomassini"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2212.10254"
  },
  {
    "id": "arXiv:2212.10283",
    "title": "Interpretable models for extrapolation in scientific machine learning",
    "abstract": "Data-driven models are central to scientific discovery. In efforts to achieve\nstate-of-the-art model accuracy, researchers are employing increasingly complex\nmachine learning algorithms that often outperform simple regressions in\ninterpolative settings (e.g. random k-fold cross-validation) but suffer from\npoor extrapolation performance, portability, and human interpretability, which\nlimits their potential for facilitating novel scientific insight. Here we\nexamine the trade-off between model performance and interpretability across a\nbroad range of science and engineering problems with an emphasis on materials\nscience datasets. We compare the performance of black box random forest and\nneural network machine learning algorithms to that of single-feature linear\nregressions which are fitted using interpretable input features discovered by a\nsimple random search algorithm. For interpolation problems, the average\nprediction errors of linear regressions were twice as high as those of black\nbox models. Remarkably, when prediction tasks required extrapolation, linear\nmodels yielded average error only 5% higher than that of black box models, and\noutperformed black box models in roughly 40% of the tested prediction tasks,\nwhich suggests that they may be desirable over complex algorithms in many\nextrapolation problems because of their superior interpretability,\ncomputational overhead, and ease of use. The results challenge the common\nassumption that extrapolative models for scientific machine learning are\nconstrained by an inherent trade-off between performance and interpretability.",
    "descriptor": "\nComments: DISTRIBUTION STATEMENT A (Approved for Public Release, Distribution Unlimited)\n",
    "authors": [
      "Eric S. Muckley",
      "James E. Saal",
      "Bryce Meredig",
      "Christopher S. Roper",
      "John H. Martin"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10283"
  },
  {
    "id": "arXiv:2212.10308",
    "title": "DeFi Risk Transfer: Towards A Fully Decentralized Insurance Protocol",
    "abstract": "In this paper, we propose a fully decentralized and smart contract-based\ninsurance protocol. We identify various issues in the Decentralized Finance\n(DeFi) insurance context and propose a solution to overcome these shortcomings.\nWe introduce an economic model that allows for risk transfer without any\nexternal dependencies or centralized intermediaries. In particular, our\nproposal does not need any sort of subjective claim assessment, community\nvoting or external data providers (oracles). Moreover, it solves the problem of\nover-insurance and proposes various ways to mitigate the capital inefficiencies\nusually seen with DeFi collateral. The work takes inspiration from peer-to-peer\n(P2P) insurance and collateralized debt obligations (CDO). We formally describe\nthe protocol, assess its efficiency and key properties and present a reference\nimplementation. Finally, we address limitations, extensions and ideas for\nfurther research.",
    "descriptor": "",
    "authors": [
      "Matthias Nadler",
      "Felix Bekemeier",
      "Fabian Sch\u00e4r"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2212.10308"
  },
  {
    "id": "arXiv:2212.10323",
    "title": "An Adaptive Covariance Parameterization Technique for the Ensemble  Gaussian Mixture Filter",
    "abstract": "The ensemble Gaussian mixture filter combines the simplicity and power of\nGaussian mixture models with the provable convergence and power of particle\nfilters. The quality of the ensemble Gaussian mixture filter heavily depends on\nthe choice of covariance matrix in each Gaussian mixture. This work extends the\nensemble Gaussian mixture filter to an adaptive choice of covariance based on\nthe parameterized estimates of the sample covariance matrix. Through the use of\nthe expectation maximization algorithm, optimal choices of the covariance\nmatrix parameters are computed in an online fashion. Numerical experiments on\nthe Lorenz '63 equations show that the proposed methodology converges to\nclassical results known in particle filtering. Further numerical results with\nmore advances choices of covariance parameterization and the medium-size Lorenz\n'96 equations show that the proposed approach can perform significantly better\nthan the standard EnGMF, and other classical data assimilation algorithms.",
    "descriptor": "",
    "authors": [
      "Andrey A Popov",
      "Renato Zanetti"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.10323"
  },
  {
    "id": "arXiv:2212.10444",
    "title": "Deep Multi-Emitter Spectrum Occupancy Mapping that is Robust to the  Number of Sensors, Noise and Threshold",
    "abstract": "One of the primary goals in spectrum occupancy mapping is to create a system\nthat is robust to assumptions about the number of sensors, occupancy threshold\n(in dBm), sensor noise, number of emitters and the propagation environment. We\nshow that such a system may be designed with neural networks using a process of\naggregation to allow a variable number of sensors during training and testing.\nThis process transforms the variable number of measurements into log-likelihood\nratios (LLRs), which are fed as a fixed-resolution image into a neural network.\nThe use of LLRs provides robustness to the effects of noise and occupancy\nthreshold. In other words, a system may be trained for a nominal number of\nsensors, threshold and noise levels, and still operate well at various other\nlevels without retraining. Our system operates without knowledge of the number\nof emitters and does not explicitly attempt to estimate their number or power.\nReceiver operating curves with realistic propagation environments using\ntopographic maps with commercial network design tools show how performance of\nthe neural network varies with the environment. The use of low-resolution\nsensors in this system does not significantly hurt performance.",
    "descriptor": "\nComments: 28 pages, 9 figures\n",
    "authors": [
      "Abbas Termos",
      "Bertrand Hochwald"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10444"
  },
  {
    "id": "arXiv:2212.10478",
    "title": "Machine Learning and Polymer Self-Consistent Field Theory in Two Spatial  Dimensions",
    "abstract": "A computational framework that leverages data from self-consistent field\ntheory simulations with deep learning to accelerate the exploration of\nparameter space for block copolymers is presented. This is a substantial\ntwo-dimensional extension of the framework introduced in [1]. Several\ninnovations and improvements are proposed. (1) A Sobolev space-trained,\nconvolutional neural network (CNN) is employed to handle the exponential\ndimension increase of the discretized, local average monomer density fields and\nto strongly enforce both spatial translation and rotation invariance of the\npredicted, field-theoretic intensive Hamiltonian. (2) A generative adversarial\nnetwork (GAN) is introduced to efficiently and accurately predict saddle point,\nlocal average monomer density fields without resorting to gradient descent\nmethods that employ the training set. This GAN approach yields important\nsavings of both memory and computational cost. (3) The proposed machine\nlearning framework is successfully applied to 2D cell size optimization as a\nclear illustration of its broad potential to accelerate the exploration of\nparameter space for discovering polymer nanostructures. Extensions to\nthree-dimensional phase discovery appear to be feasible.",
    "descriptor": "",
    "authors": [
      "Yao Xuan",
      "Kris T. Delaney",
      "Hector D. Ceniceros",
      "Glenn H. Fredrickson"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.10478"
  },
  {
    "id": "arXiv:1711.10874",
    "title": "Explanation of an Invisible Common Constraint of Mind, Mathematics and  Computational Complexity",
    "abstract": "Comments: This paper is too vague to be understood. It is a rough sketch of something that is not clear, and it contain many errors (improper use of terms, notation, etc.). Proof of some assertions made in this paper will be presented in future, at appropriate time",
    "descriptor": "\nComments: This paper is too vague to be understood. It is a rough sketch of something that is not clear, and it contain many errors (improper use of terms, notation, etc.). Proof of some assertions made in this paper will be presented in future, at appropriate time\n",
    "authors": [
      "Asad Malik"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/1711.10874"
  },
  {
    "id": "arXiv:1712.01785",
    "title": "Towards Practical Verification of Machine Learning: The Case of Computer  Vision Systems",
    "abstract": "Towards Practical Verification of Machine Learning: The Case of Computer  Vision Systems",
    "descriptor": "",
    "authors": [
      "Kexin Pei",
      "Linjie Zhu",
      "Yinzhi Cao",
      "Junfeng Yang",
      "Carl Vondrick",
      "Suman Jana"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1712.01785"
  },
  {
    "id": "arXiv:2007.07767",
    "title": "Bi-objective facility location under uncertainty with an application in  last-mile disaster relief",
    "abstract": "Bi-objective facility location under uncertainty with an application in  last-mile disaster relief",
    "descriptor": "",
    "authors": [
      "Najmesadat Nazemi",
      "Sophie N. Parragh",
      "Walter J. Gutjahr"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2007.07767"
  },
  {
    "id": "arXiv:2008.09418",
    "title": "Method to Classify Skin Lesions using Dermoscopic images",
    "abstract": "Comments: 16 pages, 14 figures",
    "descriptor": "\nComments: 16 pages, 14 figures\n",
    "authors": [
      "Dusa Sai Charan",
      "Hemanth Nadipineni",
      "Subin Sahayam",
      "Umarani Jayaraman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.09418"
  },
  {
    "id": "arXiv:2103.03337",
    "title": "Revisiting Priority $k$-Center: Fairness and Outliers",
    "abstract": "Comments: 34 pages, 1 figure",
    "descriptor": "\nComments: 34 pages, 1 figure\n",
    "authors": [
      "Tanvi Bajpai",
      "Deeparnab Chakrabarty",
      "Chandra Chekuri",
      "Maryam Negahbani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.03337"
  },
  {
    "id": "arXiv:2103.12878",
    "title": "Quantum walk-based search algorithms with multiple marked vertices",
    "abstract": "Comments: 12 pages, 1 table, 2 figs",
    "descriptor": "\nComments: 12 pages, 1 table, 2 figs\n",
    "authors": [
      "G. A. Bezerra",
      "P. H. G. Lug\u00e3o",
      "R. Portugal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2103.12878"
  },
  {
    "id": "arXiv:2104.13227",
    "title": "Quantum causal inference in the presence of hidden common causes: An  entropic approach",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2102.11764",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.11764\n",
    "authors": [
      "Mohammad Ali Javidian",
      "Vaneet Aggarwal",
      "Zubin Jacob"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.13227"
  },
  {
    "id": "arXiv:2104.13754",
    "title": "Can crowdsourcing rescue the social marketplace of ideas?",
    "abstract": "Comments: In Press in Communications of the ACM (CACM)",
    "descriptor": "\nComments: In Press in Communications of the ACM (CACM)\n",
    "authors": [
      "Taha Yasseri",
      "Filippo Menczer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.13754"
  },
  {
    "id": "arXiv:2105.04090",
    "title": "MuseMorphose: Full-Song and Fine-Grained Piano Music Style Transfer with  One Transformer VAE",
    "abstract": "Comments: Accepted for Publication at IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP). Online supplemental materials are attached to the end of this arXiv version",
    "descriptor": "\nComments: Accepted for Publication at IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP). Online supplemental materials are attached to the end of this arXiv version\n",
    "authors": [
      "Shih-Lun Wu",
      "Yi-Hsuan Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.04090"
  },
  {
    "id": "arXiv:2106.03323",
    "title": "A Comprehensive Survey and Taxonomy on Single Image Dehazing Based on  Deep Learning",
    "abstract": "Comments: This paper is accepted by ACM Computing Surveys",
    "descriptor": "\nComments: This paper is accepted by ACM Computing Surveys\n",
    "authors": [
      "Jie Gui",
      "Xiaofeng Cong",
      "Yuan Cao",
      "Wenqi Ren",
      "Jun Zhang",
      "Jing Zhang",
      "Jiuxin Cao",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03323"
  },
  {
    "id": "arXiv:2106.05492",
    "title": "Learning to Play General-Sum Games Against Multiple Boundedly Rational  Agents",
    "abstract": "Comments: 15 pages, 6 figures. Appearing at the Thirty-seventh AAAI Conference on Artificial Intelligence (AAAI 2023)",
    "descriptor": "\nComments: 15 pages, 6 figures. Appearing at the Thirty-seventh AAAI Conference on Artificial Intelligence (AAAI 2023)\n",
    "authors": [
      "Eric Zhao",
      "Alexander R. Trott",
      "Caiming Xiong",
      "Stephan Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05492"
  },
  {
    "id": "arXiv:2106.05947",
    "title": "Integer programs with bounded subdeterminants and two nonzeros per row",
    "abstract": "Comments: v3: minor changes. v2: minor changes, accepted at FOCS 2021",
    "descriptor": "\nComments: v3: minor changes. v2: minor changes, accepted at FOCS 2021\n",
    "authors": [
      "Samuel Fiorini",
      "Gwena\u00ebl Joret",
      "Stefan Weltge",
      "Yelena Yuditsky"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.05947"
  },
  {
    "id": "arXiv:2106.14888",
    "title": "Social influence under uncertainty in interaction with peers, robots and  computers",
    "abstract": "Comments: Paper accepted for publication in International Journal of Social Robotics. Previous version: \"Trust is not all about performance: trust biases in interaction with humans, robots and computers\". arXiv admin note: text overlap with arXiv:2106.14832",
    "descriptor": "\nComments: Paper accepted for publication in International Journal of Social Robotics. Previous version: \"Trust is not all about performance: trust biases in interaction with humans, robots and computers\". arXiv admin note: text overlap with arXiv:2106.14832\n",
    "authors": [
      "Joshua Zonca",
      "Anna Folso",
      "Alessandra Sciutti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.14888"
  },
  {
    "id": "arXiv:2107.14228",
    "title": "Open-World Entity Segmentation",
    "abstract": "Comments: Project page: this http URL",
    "descriptor": "\nComments: Project page: this http URL\n",
    "authors": [
      "Lu Qi",
      "Jason Kuen",
      "Yi Wang",
      "Jiuxiang Gu",
      "Hengshuang Zhao",
      "Zhe Lin",
      "Philip Torr",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.14228"
  },
  {
    "id": "arXiv:2108.08976",
    "title": "ASAT: Adaptively Scaled Adversarial Training in Time Series",
    "abstract": "Comments: Accepted to Neurocomputing",
    "descriptor": "\nComments: Accepted to Neurocomputing\n",
    "authors": [
      "Zhiyuan Zhang",
      "Wei Li",
      "Ruihan Bao",
      "Keiko Harimoto",
      "Yunfang Wu",
      "Xu Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08976"
  },
  {
    "id": "arXiv:2109.00542",
    "title": "Shared Certificates for Neural Network Verification",
    "abstract": "Comments: Extended version of our CAV'22 paper",
    "descriptor": "\nComments: Extended version of our CAV'22 paper\n",
    "authors": [
      "Marc Fischer",
      "Christian Sprecher",
      "Dimitar I. Dimitrov",
      "Gagandeep Singh",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.00542"
  },
  {
    "id": "arXiv:2109.00732",
    "title": "Coalgebras for Bisimulation of Weighted Automata over Semirings",
    "abstract": "Coalgebras for Bisimulation of Weighted Automata over Semirings",
    "descriptor": "",
    "authors": [
      "Purandar Bhaduri"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.00732"
  },
  {
    "id": "arXiv:2109.06837",
    "title": "Simultaneous Object Reconstruction and Grasp Prediction using a  Camera-centric Object Shell Representation",
    "abstract": "Comments: 18 pages, 12 figures, 8 tables",
    "descriptor": "\nComments: 18 pages, 12 figures, 8 tables\n",
    "authors": [
      "Nikhil Chavan-Dafle",
      "Sergiy Popovych",
      "Shubham Agrawal",
      "Daniel D. Lee",
      "Volkan Isler"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06837"
  },
  {
    "id": "arXiv:2109.09426",
    "title": "A Meta-Learning Approach for Training Explainable Graph Neural Networks",
    "abstract": "A Meta-Learning Approach for Training Explainable Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Indro Spinelli",
      "Simone Scardapane",
      "Aurelio Uncini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.09426"
  },
  {
    "id": "arXiv:2109.11897",
    "title": "Adaptivity for clustering-based reduced-order modeling of localized  history-dependent phenomena",
    "abstract": "Comments: The code associated to this publication is planned to be released as open source in 2022",
    "descriptor": "\nComments: The code associated to this publication is planned to be released as open source in 2022\n",
    "authors": [
      "Bernardo P. Ferreira",
      "F.M. Andrade Pires",
      "Miguel A. Bessa"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.11897"
  },
  {
    "id": "arXiv:2110.03894",
    "title": "Neural Model Reprogramming with Similarity Based Mapping for  Low-Resource Spoken Command Classification",
    "abstract": "Comments: Submitted to ICASSP 2023. The draft has been updated on its new reprogramming findings with data augmentation results (8.7% to 10.9% relatively improvements)",
    "descriptor": "\nComments: Submitted to ICASSP 2023. The draft has been updated on its new reprogramming findings with data augmentation results (8.7% to 10.9% relatively improvements)\n",
    "authors": [
      "Hao Yen",
      "Pin-Jui Ku",
      "Chao-Han Huck Yang",
      "Hu Hu",
      "Sabato Marco Siniscalchi",
      "Pin-Yu Chen",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03894"
  },
  {
    "id": "arXiv:2110.05351",
    "title": "Sparse recovery of elliptic solvers from matrix-vector products",
    "abstract": "Sparse recovery of elliptic solvers from matrix-vector products",
    "descriptor": "",
    "authors": [
      "Florian Sch\u00e4fer",
      "Houman Owhadi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05351"
  },
  {
    "id": "arXiv:2110.05589",
    "title": "Next Period Recommendation Reality Check",
    "abstract": "Next Period Recommendation Reality Check",
    "descriptor": "",
    "authors": [
      "Sergey Kolesnikov",
      "Oleg Lashinin",
      "Michail Pechatov",
      "Alexander Kosov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05589"
  },
  {
    "id": "arXiv:2110.08493",
    "title": "Improvised Aerial Object Detection approach for YOLOv3 Using Weighted  Luminance",
    "abstract": "Comments: 17 pages, 4 figures, Journal Expert Systems with Applications",
    "descriptor": "\nComments: 17 pages, 4 figures, Journal Expert Systems with Applications\n",
    "authors": [
      "Sai Ganesh CS",
      "Aouthithiye Barathwaj SR Y",
      "R. Swethaa S",
      "R. Azhagumurugan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.08493"
  },
  {
    "id": "arXiv:2110.10132",
    "title": "FriendlyCore: Practical Differentially Private Aggregation",
    "abstract": "Comments: Published in ICML 2022",
    "descriptor": "\nComments: Published in ICML 2022\n",
    "authors": [
      "Eliad Tsfadia",
      "Edith Cohen",
      "Haim Kaplan",
      "Yishay Mansour",
      "Uri Stemmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.10132"
  },
  {
    "id": "arXiv:2110.14961",
    "title": "Roto-translated Local Coordinate Frames For Interacting Dynamical  Systems",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Miltiadis Kofinas",
      "Naveen Shankar Nagaraja",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14961"
  },
  {
    "id": "arXiv:2112.00284",
    "title": "Interactive Model with Structural Loss for Language-based Abductive  Reasoning",
    "abstract": "Comments: The paper is under consideration at Pattern Recognition Letters",
    "descriptor": "\nComments: The paper is under consideration at Pattern Recognition Letters\n",
    "authors": [
      "Linhao Li",
      "Ming Xu",
      "Yongfeng Dong",
      "Xin Li",
      "Ao Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00284"
  },
  {
    "id": "arXiv:2112.04381",
    "title": "Topology and Geometry of the Third-Party Domains Ecosystem: Measurement  and Applications",
    "abstract": "Topology and Geometry of the Third-Party Domains Ecosystem: Measurement  and Applications",
    "descriptor": "",
    "authors": [
      "Costas Iordanou",
      "Fragkiskos Papadopoulos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.04381"
  },
  {
    "id": "arXiv:2112.08151",
    "title": "Weighted analytic regularity for the integral fractional Laplacian in  polygons",
    "abstract": "Weighted analytic regularity for the integral fractional Laplacian in  polygons",
    "descriptor": "",
    "authors": [
      "Markus Faustmann",
      "Carlo Marcati",
      "Jens Markus Melenk",
      "Christoph Schwab"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08151"
  },
  {
    "id": "arXiv:2112.09271",
    "title": "A scalable DG solver for the electroneutral Nernst-Planck equations",
    "abstract": "Comments: 26 pages, 7 figures",
    "descriptor": "\nComments: 26 pages, 7 figures\n",
    "authors": [
      "Thomas Roy",
      "Julian Andrej",
      "Victor A. Beck"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Applied Physics (physics.app-ph)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.09271"
  },
  {
    "id": "arXiv:2112.09542",
    "title": "A Formal Model for Polarization under Confirmation Bias in Social  Networks",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2104.11538, arXiv:2012.02703",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2104.11538, arXiv:2012.02703\n",
    "authors": [
      "M\u00e1rio S. Alvim",
      "Bernardo Amorim",
      "Sophia Knight",
      "Santiago Quintero",
      "Frank Valencia"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.09542"
  },
  {
    "id": "arXiv:2112.11088",
    "title": "EPNet++: Cascade Bi-directional Fusion for Multi-Modal 3D Object  Detection",
    "abstract": "Comments: Accepted by TPAMI-2022",
    "descriptor": "\nComments: Accepted by TPAMI-2022\n",
    "authors": [
      "Zhe Liu",
      "Tengteng Huang",
      "Bingling Li",
      "Xiwu Chen",
      "Xi Wang",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11088"
  },
  {
    "id": "arXiv:2112.12185",
    "title": "Dimension-independent Markov chain Monte Carlo on the sphere",
    "abstract": "Comments: 37 pages, 8 figures",
    "descriptor": "\nComments: 37 pages, 8 figures\n",
    "authors": [
      "H. C. Lie",
      "D. Rudolf",
      "B. Sprungk",
      "T. J. Sullivan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.12185"
  },
  {
    "id": "arXiv:2112.13627",
    "title": "Additive Properties of the Evil and Odious Numbers and Similar Sequences",
    "abstract": "Comments: Revision of previous version, with new author and results added",
    "descriptor": "\nComments: Revision of previous version, with new author and results added\n",
    "authors": [
      "Jean-Paul Allouche",
      "Jeffrey Shallit"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.13627"
  },
  {
    "id": "arXiv:2112.14328",
    "title": "QUIC Throughput and Fairness over Dual Connectivity",
    "abstract": "Comments: 14 pages. This paper is published in Computer Networks (by Elsevier)",
    "descriptor": "\nComments: 14 pages. This paper is published in Computer Networks (by Elsevier)\n",
    "authors": [
      "David Hasselquist",
      "Christoffer Lindstr\u00f6m",
      "Nikita Korzhitskii",
      "Niklas Carlsson",
      "Andrei Gurtov"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.14328"
  },
  {
    "id": "arXiv:2201.01322",
    "title": "Opinion dynamics in social networks: From models to data",
    "abstract": "Comments: 22 pages, 3 figures",
    "descriptor": "\nComments: 22 pages, 3 figures\n",
    "authors": [
      "Antonio F. Peralta",
      "J\u00e1nos Kert\u00e9sz",
      "Gerardo I\u00f1iguez"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2201.01322"
  },
  {
    "id": "arXiv:2202.06539",
    "title": "Deduplicating Training Data Mitigates Privacy Risks in Language Models",
    "abstract": "Comments: ICML 2022 Camera Ready Version",
    "descriptor": "\nComments: ICML 2022 Camera Ready Version\n",
    "authors": [
      "Nikhil Kandpal",
      "Eric Wallace",
      "Colin Raffel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06539"
  },
  {
    "id": "arXiv:2202.07615",
    "title": "P4E: Few-Shot Event Detection as Prompt-Guided Identification and  Localization",
    "abstract": "Comments: 13 pages, fixed typos and additional experiments",
    "descriptor": "\nComments: 13 pages, fixed typos and additional experiments\n",
    "authors": [
      "Sha Li",
      "Liyuan Liu",
      "Yiqing Xie",
      "Heng Ji",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07615"
  },
  {
    "id": "arXiv:2202.09006",
    "title": "KINet: Keypoint Interaction Networks for Unsupervised Forward Modeling",
    "abstract": "KINet: Keypoint Interaction Networks for Unsupervised Forward Modeling",
    "descriptor": "",
    "authors": [
      "Alireza Rezazadeh",
      "Changhyun Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.09006"
  },
  {
    "id": "arXiv:2202.10201",
    "title": "OG-SGG: Ontology-Guided Scene Graph Generation. A Case Study in Transfer  Learning for Telepresence Robotics",
    "abstract": "Comments: 20 pages; version accepted and published in IEEE Access",
    "descriptor": "\nComments: 20 pages; version accepted and published in IEEE Access\n",
    "authors": [
      "Fernando Amodeo",
      "Fernando Caballero",
      "Natalia D\u00edaz-Rodr\u00edguez",
      "Luis Merino"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.10201"
  },
  {
    "id": "arXiv:2202.11762",
    "title": "Safe Control with Learned Certificates: A Survey of Neural Lyapunov,  Barrier, and Contraction methods",
    "abstract": "Comments: Accepted at IEEE Transactions on Robotics. Supplementary code available at this https URL",
    "descriptor": "\nComments: Accepted at IEEE Transactions on Robotics. Supplementary code available at this https URL\n",
    "authors": [
      "Charles Dawson",
      "Sicun Gao",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.11762"
  },
  {
    "id": "arXiv:2202.12416",
    "title": "Microgrid Optimal Energy Scheduling Considering Neural Network based  Battery Degradation",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Cunzhi Zhao",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12416"
  },
  {
    "id": "arXiv:2203.02102",
    "title": "BEATS: An Open-Source, High-Precision, Multi-Channel EEG Acquisition  Tool System",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Bing Zou",
      "Yubo Zheng",
      "Mu Shen",
      "Yingying Luo",
      "Lei Li",
      "Lin Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.02102"
  },
  {
    "id": "arXiv:2203.05695",
    "title": "How to Train a (Bad) Algorithmic Caseworker: A Quantitative  Deconstruction of Risk Assessments in Child-Welfare",
    "abstract": "How to Train a (Bad) Algorithmic Caseworker: A Quantitative  Deconstruction of Risk Assessments in Child-Welfare",
    "descriptor": "",
    "authors": [
      "Devansh Saxena",
      "Charlie Repaci",
      "Melanie Sage",
      "Shion Guha"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.05695"
  },
  {
    "id": "arXiv:2203.10533",
    "title": "Strategic Analysis of Griefing Attack in Lightning Network",
    "abstract": "Comments: 17 pages, Accepted in IEEE Transactions on Network and Service Management (Special Issue Advances on Blockchain)",
    "descriptor": "\nComments: 17 pages, Accepted in IEEE Transactions on Network and Service Management (Special Issue Advances on Blockchain)\n",
    "authors": [
      "Subhra Mazumdar",
      "Prabal Banerjee",
      "Abhinandan Sinha",
      "Sushmita Ruj",
      "Bimal Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.10533"
  },
  {
    "id": "arXiv:2203.11991",
    "title": "Joint Feature Learning and Relation Modeling for Tracking: A One-Stream  Framework",
    "abstract": "Comments: Accepted by ECCV 2022",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Botao Ye",
      "Hong Chang",
      "Bingpeng Ma",
      "Shiguang Shan",
      "Xilin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11991"
  },
  {
    "id": "arXiv:2204.00356",
    "title": "Algebraic connectivity of layered path graphs under node deletion",
    "abstract": "Algebraic connectivity of layered path graphs under node deletion",
    "descriptor": "",
    "authors": [
      "Ryusei Yoshise",
      "Kaoru Yamamoto"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.00356"
  },
  {
    "id": "arXiv:2204.07185",
    "title": "This Is the Moment for Probabilistic Loops",
    "abstract": "Comments: Published at OOPSLA 2022",
    "descriptor": "\nComments: Published at OOPSLA 2022\n",
    "authors": [
      "Marcel Moosbrugger",
      "Miroslav Stankovi\u010d",
      "Ezio Bartocci",
      "Laura Kov\u00e1cs"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2204.07185"
  },
  {
    "id": "arXiv:2204.07265",
    "title": "The Rise of Intelligent Reflecting Surfaces in Integrated Sensing and  Communications Paradigms",
    "abstract": "Comments: Accepted paper in IEEE Network Magazine",
    "descriptor": "\nComments: Accepted paper in IEEE Network Magazine\n",
    "authors": [
      "Ahmet M. Elbir",
      "Kumar Vijay Mishra",
      "M. R. Bhavani Shankar",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.07265"
  },
  {
    "id": "arXiv:2204.07713",
    "title": "GAUSS: Guided Encoder-Decoder Architecture for Hyperspectral Unmixing  with Spatial Smoothness",
    "abstract": "Comments: 16 pages, 6 figures",
    "descriptor": "\nComments: 16 pages, 6 figures\n",
    "authors": [
      "Yasiru Ranasinghe",
      "Kavinga Weerasooriya",
      "Roshan Godaliyadda",
      "Vijitha Herath",
      "Parakrama Ekanayake",
      "Dhananjaya Jayasundara",
      "Lakshitha Ramanayake",
      "Neranjan Senarath",
      "Dulantha Wickramasinghe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.07713"
  },
  {
    "id": "arXiv:2204.10607",
    "title": "Federated Learning via Inexact ADMM",
    "abstract": "Federated Learning via Inexact ADMM",
    "descriptor": "",
    "authors": [
      "Shenglong Zhou",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.10607"
  },
  {
    "id": "arXiv:2205.00849",
    "title": "Model-based Deep Learning Receiver Design for Rate-Splitting Multiple  Access",
    "abstract": "Model-based Deep Learning Receiver Design for Rate-Splitting Multiple  Access",
    "descriptor": "",
    "authors": [
      "Rafael Cerna Loli",
      "Onur Dizdar",
      "Bruno Clerckx",
      "Cong Ling"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.00849"
  },
  {
    "id": "arXiv:2205.01875",
    "title": "Machine Learning based Framework for Robust Price-Sensitivity Estimation  with Application to Airline Pricing",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Ravi Kumar",
      "Shahin Boluki",
      "Karl Isler",
      "Jonas Rauch",
      "Darius Walczak"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2205.01875"
  },
  {
    "id": "arXiv:2205.05587",
    "title": "Choice of training label matters: how to best use deep learning for  quantitative MRI parameter estimation",
    "abstract": "Comments: 20 pages, 12 figures",
    "descriptor": "\nComments: 20 pages, 12 figures\n",
    "authors": [
      "Sean C. Epstein",
      "Timothy J. P. Bray",
      "Margaret Hall-Craggs",
      "Hui Zhang"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.05587"
  },
  {
    "id": "arXiv:2205.08210",
    "title": "Towards Robotic Laboratory Automation Plug & Play: Survey and Concept  Proposal on Teaching-free Robot Integration with the LAPP Digital Twin",
    "abstract": "Towards Robotic Laboratory Automation Plug & Play: Survey and Concept  Proposal on Teaching-free Robot Integration with the LAPP Digital Twin",
    "descriptor": "",
    "authors": [
      "\u00c1d\u00e1m Wolf",
      "Stefan Romeder-Finger",
      "K\u00e1roly Sz\u00e9ll",
      "P\u00e9ter Galambos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.08210"
  },
  {
    "id": "arXiv:2205.15449",
    "title": "Posterior and Computational Uncertainty in Gaussian Processes",
    "abstract": "Comments: Advances in Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: Advances in Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Jonathan Wenger",
      "Geoff Pleiss",
      "Marvin Pf\u00f6rtner",
      "Philipp Hennig",
      "John P. Cunningham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15449"
  },
  {
    "id": "arXiv:2206.00515",
    "title": "Landslide4Sense: Reference Benchmark Data and Deep Learning Models for  Landslide Detection",
    "abstract": "Landslide4Sense: Reference Benchmark Data and Deep Learning Models for  Landslide Detection",
    "descriptor": "",
    "authors": [
      "Omid Ghorbanzadeh",
      "Yonghao Xu",
      "Pedram Ghamisi",
      "Michael Kopp",
      "David Kreil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.00515"
  },
  {
    "id": "arXiv:2206.01986",
    "title": "Delving into the Openness of CLIP",
    "abstract": "Comments: 22 pages, 12 figures. Code is available at this https URL",
    "descriptor": "\nComments: 22 pages, 12 figures. Code is available at this https URL\n",
    "authors": [
      "Shuhuai Ren",
      "Lei Li",
      "Xuancheng Ren",
      "Guangxiang Zhao",
      "Xu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01986"
  },
  {
    "id": "arXiv:2206.01995",
    "title": "Combinatorial Causal Bandits",
    "abstract": "Comments: 30 pages, 9 figures",
    "descriptor": "\nComments: 30 pages, 9 figures\n",
    "authors": [
      "Shi Feng",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01995"
  },
  {
    "id": "arXiv:2206.03150",
    "title": "Group Meritocratic Fairness in Linear Contextual Bandits",
    "abstract": "Comments: NeurIPS 2022. Code for the experiments at this https URL",
    "descriptor": "\nComments: NeurIPS 2022. Code for the experiments at this https URL\n",
    "authors": [
      "Riccardo Grazzi",
      "Arya Akhavan",
      "John Isak Texas Falk",
      "Leonardo Cella",
      "Massimiliano Pontil"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03150"
  },
  {
    "id": "arXiv:2206.04360",
    "title": "A general approximation lower bound in $L^p$ norm, with applications to  feed-forward neural networks",
    "abstract": "A general approximation lower bound in $L^p$ norm, with applications to  feed-forward neural networks",
    "descriptor": "",
    "authors": [
      "El Mehdi Achour",
      "Armand Foucault",
      "S\u00e9bastien Gerchinovitz",
      "Fran\u00e7ois Malgouyres"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04360"
  },
  {
    "id": "arXiv:2206.05183",
    "title": "GD-VAEs: Geometric Dynamic Variational Autoencoders for Learning  Nonlinear Dynamics and Dimension Reductions",
    "abstract": "Comments: 15 figures. arXiv admin note: text overlap with arXiv:2012.03448",
    "descriptor": "\nComments: 15 figures. arXiv admin note: text overlap with arXiv:2012.03448\n",
    "authors": [
      "Ryan Lopez",
      "Paul J. Atzberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05183"
  },
  {
    "id": "arXiv:2206.05442",
    "title": "Automatically Answering and Generating Machine Learning Final Exams",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Sarah Zhang",
      "Reece Shuttleworth",
      "Derek Austin",
      "Yann Hicke",
      "Leonard Tang",
      "Sathwik Karnik",
      "Darnell Granberry",
      "Iddo Drori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05442"
  },
  {
    "id": "arXiv:2206.08368",
    "title": "Unbiased 4D: Monocular 4D Reconstruction with a Neural Deformation Model",
    "abstract": "Comments: 26 pages, 17 figures, 8 tables",
    "descriptor": "\nComments: 26 pages, 17 figures, 8 tables\n",
    "authors": [
      "Erik C.M. Johnson",
      "Marc Habermann",
      "Soshi Shimada",
      "Vladislav Golyanik",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08368"
  },
  {
    "id": "arXiv:2206.09592",
    "title": "DALL-E for Detection: Language-driven Compositional Image Synthesis for  Object Detection",
    "abstract": "Comments: v2 version, update structure (add foreground generation, stable diffusion), add more experiments",
    "descriptor": "\nComments: v2 version, update structure (add foreground generation, stable diffusion), add more experiments\n",
    "authors": [
      "Yunhao Ge",
      "Jiashu Xu",
      "Brian Nlong Zhao",
      "Neel Joshi",
      "Laurent Itti",
      "Vibhav Vineet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09592"
  },
  {
    "id": "arXiv:2206.11038",
    "title": "Deep Reinforcement Learning for Turbulence Modeling in Large Eddy  Simulations",
    "abstract": "Comments: 17 pages, 9 figures. Accepted Manuscript",
    "descriptor": "\nComments: 17 pages, 9 figures. Accepted Manuscript\n",
    "authors": [
      "Marius Kurz",
      "Philipp Offenh\u00e4user",
      "Andrea Beck"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11038"
  },
  {
    "id": "arXiv:2206.14268",
    "title": "BertNet: Harvesting Knowledge Graphs from Pretrained Language Models",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Shibo Hao",
      "Bowen Tan",
      "Kaiwen Tang",
      "Bin Ni",
      "Hengzhe Zhang",
      "Eric P Xing",
      "Zhiting Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.14268"
  },
  {
    "id": "arXiv:2207.00698",
    "title": "Uncertainty Quantification for Deep Unrolling-Based Computational  Imaging",
    "abstract": "Comments: 23 pages, revised manuscript, accepted for publication as a regular paper in the IEEE Transactions on Computational Imaging",
    "descriptor": "\nComments: 23 pages, revised manuscript, accepted for publication as a regular paper in the IEEE Transactions on Computational Imaging\n",
    "authors": [
      "Canberk Ekmekci",
      "Mujdat Cetin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.00698"
  },
  {
    "id": "arXiv:2207.02209",
    "title": "Tackling Data Scarcity with Transfer Learning: A Case Study of Thickness  Characterization from Optical Spectra of Perovskite Thin Films",
    "abstract": "Tackling Data Scarcity with Transfer Learning: A Case Study of Thickness  Characterization from Optical Spectra of Perovskite Thin Films",
    "descriptor": "",
    "authors": [
      "Siyu Isaac Parker Tian",
      "Zekun Ren",
      "Selvaraj Venkataraj",
      "Yuanhang Cheng",
      "Daniil Bash",
      "Felipe Oviedo",
      "J. Senthilnath",
      "Vijila Chellappan",
      "Yee-Fun Lim",
      "Armin G. Aberle",
      "Benjamin P MacLeod",
      "Fraser G. L. Parlane",
      "Curtis P. Berlinguette",
      "Qianxiao Li",
      "Tonio Buonassisi",
      "Zhe Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2207.02209"
  },
  {
    "id": "arXiv:2207.03315",
    "title": "Wrapping Haptic Displays Around Robot Arms to Communicate Learning",
    "abstract": "Comments: This article includes work originally presented in arXiv:2111.04542",
    "descriptor": "\nComments: This article includes work originally presented in arXiv:2111.04542\n",
    "authors": [
      "Antonio Alvarez Valdivia",
      "Soheil Habibian",
      "Carly A. Mendenhall",
      "Francesco Fuentes",
      "Ritish Shailly",
      "Dylan P. Losey",
      "Laura H. Blumenschein"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.03315"
  },
  {
    "id": "arXiv:2207.06240",
    "title": "Physics Informed Symbolic Networks",
    "abstract": "Comments: Neural Information Processing Systems 2022: The Symbiosis of Deep Learning and Differential Equations Workshop",
    "descriptor": "\nComments: Neural Information Processing Systems 2022: The Symbiosis of Deep Learning and Differential Equations Workshop\n",
    "authors": [
      "Ritam Majumdar",
      "Vishal Jadhav",
      "Anirudh Deodhar",
      "Shirish Karande",
      "Lovekesh Vig",
      "Venkataramana Runkana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.06240"
  },
  {
    "id": "arXiv:2207.06271",
    "title": "Secure Linear MDS Coded Matrix Inversion",
    "abstract": "Secure Linear MDS Coded Matrix Inversion",
    "descriptor": "",
    "authors": [
      "Neophytos Charalambides",
      "Mert Pilanci",
      "Alfred Hero"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.06271"
  },
  {
    "id": "arXiv:2207.06635",
    "title": "EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic  Differential Equations",
    "abstract": "Comments: NIPS 2022",
    "descriptor": "\nComments: NIPS 2022\n",
    "authors": [
      "Min Zhao",
      "Fan Bao",
      "Chongxuan Li",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06635"
  },
  {
    "id": "arXiv:2207.07694",
    "title": "Parikh Automata over Infinite Words",
    "abstract": "Parikh Automata over Infinite Words",
    "descriptor": "",
    "authors": [
      "Shibashis Guha",
      "Isma\u00ebl Jecker",
      "Karoliina Lehtinen",
      "Martin Zimmermann"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.07694"
  },
  {
    "id": "arXiv:2207.07885",
    "title": "Clover: Towards A Unified Video-Language Alignment and Fusion Model",
    "abstract": "Comments: Update Tri-modal Alignment task",
    "descriptor": "\nComments: Update Tri-modal Alignment task\n",
    "authors": [
      "Jingjia Huang",
      "Yinan Li",
      "Jiashi Feng",
      "Xinglong Wu",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.07885"
  },
  {
    "id": "arXiv:2207.09154",
    "title": "Investigating Bayesian optimization for expensive-to-evaluate black box  functions: Application in fluid dynamics",
    "abstract": "Investigating Bayesian optimization for expensive-to-evaluate black box  functions: Application in fluid dynamics",
    "descriptor": "",
    "authors": [
      "Mike Diessner",
      "Joseph O'Connor",
      "Andrew Wynn",
      "Sylvain Laizet",
      "Yu Guan",
      "Kevin Wilson",
      "Richard D. Whalley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09154"
  },
  {
    "id": "arXiv:2208.00281",
    "title": "Point Primitive Transformer for Long-Term 4D Point Cloud Video  Understanding",
    "abstract": "Point Primitive Transformer for Long-Term 4D Point Cloud Video  Understanding",
    "descriptor": "",
    "authors": [
      "Hao Wen",
      "Yunze Liu",
      "Jingwei Huang",
      "Bo Duan",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.00281"
  },
  {
    "id": "arXiv:2208.01423",
    "title": "Continuous and Impulse Controls Differential Game in Finite Horizon with  Nash-Equilibrium and Application",
    "abstract": "Comments: 43 pages",
    "descriptor": "\nComments: 43 pages\n",
    "authors": [
      "Brahim El Asri",
      "Hafid Lalioui"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.01423"
  },
  {
    "id": "arXiv:2208.06049",
    "title": "MILAN: Masked Image Pretraining on Language Assisted Representation",
    "abstract": "Comments: add new experiments and improved results. provide repo link",
    "descriptor": "\nComments: add new experiments and improved results. provide repo link\n",
    "authors": [
      "Zejiang Hou",
      "Fei Sun",
      "Yen-Kuang Chen",
      "Yuan Xie",
      "Sun-Yuan Kung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.06049"
  },
  {
    "id": "arXiv:2208.09215",
    "title": "Almost Cost-Free Communication in Federated Best Arm Identification",
    "abstract": "Comments: Accepted to AAAI 2023",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Kota Srinivas Reddy",
      "P. N. Karthik",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.09215"
  },
  {
    "id": "arXiv:2208.12672",
    "title": "Flexible Vertical Federated Learning with Heterogeneous Parties",
    "abstract": "Flexible Vertical Federated Learning with Heterogeneous Parties",
    "descriptor": "",
    "authors": [
      "Timothy Castiglia",
      "Shiqiang Wang",
      "Stacy Patterson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.12672"
  },
  {
    "id": "arXiv:2208.14344",
    "title": "Analysis of Distributed Deep Learning in the Cloud",
    "abstract": "Analysis of Distributed Deep Learning in the Cloud",
    "descriptor": "",
    "authors": [
      "Aakash Sharma",
      "Vivek M. Bhasi",
      "Sonali Singh",
      "Rishabh Jain",
      "Jashwant Raj Gunasekaran",
      "Subrata Mitra",
      "Mahmut Taylan Kandemir",
      "George Kesidis",
      "Chita R. Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.14344"
  },
  {
    "id": "arXiv:2208.14878",
    "title": "Formalising the Robustness of Counterfactual Explanations for Neural  Networks",
    "abstract": "Comments: Accepted at AAAI 2023, camera-ready version",
    "descriptor": "\nComments: Accepted at AAAI 2023, camera-ready version\n",
    "authors": [
      "Junqi Jiang",
      "Francesco Leofante",
      "Antonio Rago",
      "Francesca Toni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.14878"
  },
  {
    "id": "arXiv:2209.02535",
    "title": "Analyzing Transformers in Embedding Space",
    "abstract": "Analyzing Transformers in Embedding Space",
    "descriptor": "",
    "authors": [
      "Guy Dar",
      "Mor Geva",
      "Ankit Gupta",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.02535"
  },
  {
    "id": "arXiv:2209.02715",
    "title": "Concentration bounds for quantum states and limitations on the QAOA from  polynomial approximations",
    "abstract": "Comments: 25 pages. In ITCS 2023",
    "descriptor": "\nComments: 25 pages. In ITCS 2023\n",
    "authors": [
      "Anurag Anshu",
      "Tony Metger"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.02715"
  },
  {
    "id": "arXiv:2209.03176",
    "title": "Composite Community-Aware Diversified Influence Maximization with  Efficient Approximation",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Jianxiong Guo",
      "Qiufen Ni",
      "Weili Wu",
      "Ding-Zhu Du"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2209.03176"
  },
  {
    "id": "arXiv:2209.04130",
    "title": "In-situ animal behavior classification using knowledge distillation and  fixed-point quantization",
    "abstract": "In-situ animal behavior classification using knowledge distillation and  fixed-point quantization",
    "descriptor": "",
    "authors": [
      "Reza Arablouei",
      "Liang Wang",
      "Caitlin Phillips",
      "Lachlan Currie",
      "Jordan Yates",
      "Greg Bishop-Hurley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.04130"
  },
  {
    "id": "arXiv:2209.04747",
    "title": "Diffusion Models in Vision: A Survey",
    "abstract": "Comments: 24 pages, 3 figures",
    "descriptor": "\nComments: 24 pages, 3 figures\n",
    "authors": [
      "Florinel-Alin Croitoru",
      "Vlad Hondru",
      "Radu Tudor Ionescu",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.04747"
  },
  {
    "id": "arXiv:2209.05227",
    "title": "DUET: A Tuning-Free Device-Cloud Collaborative Parameters Generation  Framework for Efficient Device Model Generalization",
    "abstract": "DUET: A Tuning-Free Device-Cloud Collaborative Parameters Generation  Framework for Efficient Device Model Generalization",
    "descriptor": "",
    "authors": [
      "Zheqi Lv",
      "Wenqiao Zhang",
      "Shengyu Zhang",
      "Kun Kuang",
      "Feng Wang",
      "Yongwei Wang",
      "Zhengyu Chen",
      "Tao Shen",
      "Hongxia Yang",
      "Beng chin Ooi",
      "Fei Wu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.05227"
  },
  {
    "id": "arXiv:2209.05408",
    "title": "Deterministic Sequencing of Exploration and Exploitation for  Reinforcement Learning",
    "abstract": "Deterministic Sequencing of Exploration and Exploitation for  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Piyush Gupta",
      "Vaibhav Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.05408"
  },
  {
    "id": "arXiv:2209.05461",
    "title": "EPA Particulate Matter Data -- Analyses using Local Control Strategy",
    "abstract": "Comments: 30 pages, 22 figures, 6 tables",
    "descriptor": "\nComments: 30 pages, 22 figures, 6 tables\n",
    "authors": [
      "Robert L. Obenchain",
      "S. Stanley Young"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2209.05461"
  },
  {
    "id": "arXiv:2209.06035",
    "title": "An MP-DWR method for $h$-adaptive finite element methods",
    "abstract": "An MP-DWR method for $h$-adaptive finite element methods",
    "descriptor": "",
    "authors": [
      "Chengyu Liu",
      "Guanghui Hu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.06035"
  },
  {
    "id": "arXiv:2209.06257",
    "title": "SciMED: A Computational Framework For Physics-Informed Symbolic  Regression with Scientist-In-The-Loop",
    "abstract": "SciMED: A Computational Framework For Physics-Informed Symbolic  Regression with Scientist-In-The-Loop",
    "descriptor": "",
    "authors": [
      "Liron Simon Keren",
      "Alex Liberzon",
      "Teddy Lazebnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.06257"
  },
  {
    "id": "arXiv:2209.06585",
    "title": "Combining Metric Learning and Attention Heads For Accurate and Efficient  Multilabel Image Classification",
    "abstract": "Comments: Accepted at VISAPP 2023",
    "descriptor": "\nComments: Accepted at VISAPP 2023\n",
    "authors": [
      "Kirill Prokofiev",
      "Vladislav Sovrasov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06585"
  },
  {
    "id": "arXiv:2209.07226",
    "title": "Solving nonlinear Klein-Gordon equations on unbounded domains via the  Finite Element Method",
    "abstract": "Comments: 35 pages, 20 figures, 2 tables. Accepted for publication in PRD",
    "descriptor": "\nComments: 35 pages, 20 figures, 2 tables. Accepted for publication in PRD\n",
    "authors": [
      "Hugo L\u00e9vy",
      "Jo\u00ebl Berg\u00e9",
      "Jean-Philippe Uzan"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.07226"
  },
  {
    "id": "arXiv:2209.07497",
    "title": "On Power Set Axiom",
    "abstract": "Comments: 4 pages",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Leonid A. Levin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.07497"
  },
  {
    "id": "arXiv:2209.09731",
    "title": "Application Experiences on a GPU-Accelerated Arm-based HPC Testbed",
    "abstract": "Application Experiences on a GPU-Accelerated Arm-based HPC Testbed",
    "descriptor": "",
    "authors": [
      "Wael Elwasif",
      "William Godoy",
      "Nick Hagerty",
      "J. Austin Harris",
      "Oscar Hernandez",
      "Balint Joo",
      "Paul Kent",
      "Damien Lebrun-Grandie",
      "Elijah Maccarthy",
      "Veronica G. Melesse Vergara",
      "Bronson Messer",
      "Ross Miller",
      "Sarp Opal",
      "Sergei Bastrakov",
      "Michael Bussmann",
      "Alexander Debus",
      "Klaus Steinger",
      "Jan Stephan",
      "Rene Widera",
      "Spencer H. Bryngelson",
      "Henry Le Berre",
      "Anand Radhakrishnan",
      "Jefferey Young",
      "Sunita Chandrasekaran",
      "Florina Ciorba",
      "Osman Simsek",
      "Kate Clark Filippo Spiga",
      "Jeff Hammond",
      "John E. Stone. David Hardy",
      "Sebastian Keller",
      "Jean-Guillaume Piccinali. Christian Trott"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2209.09731"
  },
  {
    "id": "arXiv:2209.10041",
    "title": "Exploring Optimal Granularity for Extractive Summarization of  Unstructured Health Records: Analysis of the Largest Multi-Institutional  Archive of Health Records in Japan",
    "abstract": "Exploring Optimal Granularity for Extractive Summarization of  Unstructured Health Records: Analysis of the Largest Multi-Institutional  Archive of Health Records in Japan",
    "descriptor": "",
    "authors": [
      "Kenichiro Ando",
      "Takashi Okumura",
      "Mamoru Komachi",
      "Hiromasa Horiguchi",
      "Yuji Matsumoto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.10041"
  },
  {
    "id": "arXiv:2209.10978",
    "title": "A First Complete Algorithm for Real Quantifier Elimination in  Isabelle/HOL",
    "abstract": "Comments: CPP 2023",
    "descriptor": "\nComments: CPP 2023\n",
    "authors": [
      "Katherine Kosaian",
      "Yong Kiam Tan",
      "Andr\u00e9 Platzer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2209.10978"
  },
  {
    "id": "arXiv:2209.11023",
    "title": "Randomized low-rank approximation of monotone matrix functions",
    "abstract": "Randomized low-rank approximation of monotone matrix functions",
    "descriptor": "",
    "authors": [
      "David Persson",
      "Daniel Kressner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.11023"
  },
  {
    "id": "arXiv:2209.11534",
    "title": "An Interdisciplinary Perspective on Evaluation and Experimental Design  for Visual Text Analytics: Position Paper",
    "abstract": "Comments: Published in Proceedings of the 2022 IEEE Workshop on Evaluation and Beyond - Methodological Approaches to Visualization (BELIV '22). ACM 2012 CCS: Human-centered computing, Visualization, Visualization design and evaluation methods",
    "descriptor": "\nComments: Published in Proceedings of the 2022 IEEE Workshop on Evaluation and Beyond - Methodological Approaches to Visualization (BELIV '22). ACM 2012 CCS: Human-centered computing, Visualization, Visualization design and evaluation methods\n",
    "authors": [
      "Kostiantyn Kucher",
      "Nicole Sultanum",
      "Angel Daza",
      "Vasiliki Simaki",
      "Maria Skeppstedt",
      "Barbara Plank",
      "Jean-Daniel Fekete",
      "Narges Mahyar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11534"
  },
  {
    "id": "arXiv:2209.11891",
    "title": "Neuromorphic Integrated Sensing and Communications",
    "abstract": "Comments: Published on IEEE Wireless Communications Letters",
    "descriptor": "\nComments: Published on IEEE Wireless Communications Letters\n",
    "authors": [
      "Jiechen Chen",
      "Nicolas Skatchkovsky",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.11891"
  },
  {
    "id": "arXiv:2210.01122",
    "title": "BIASeD: Bringing Irrationality into Automated System Design",
    "abstract": "Comments: 14 pages, 1 figure; Accepted for presentation at the AAAI Fall Symposium 2022 on Thinking Fast and Slow and Other Cognitive Theories in AI. Corrected typos",
    "descriptor": "\nComments: 14 pages, 1 figure; Accepted for presentation at the AAAI Fall Symposium 2022 on Thinking Fast and Slow and Other Cognitive Theories in AI. Corrected typos\n",
    "authors": [
      "Aditya Gulati",
      "Miguel Angel Lozano",
      "Bruno Lepri",
      "Nuria Oliver"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.01122"
  },
  {
    "id": "arXiv:2210.04624",
    "title": "WebCrowds: An Authoring Tool for Crowd Simulation",
    "abstract": "Comments: Accepted on the 2022 Brazilian Symposium on Games and Digital Entertainment (SBGames 2022 - this https URL). 7 pages, 4 figures, conference",
    "descriptor": "\nComments: Accepted on the 2022 Brazilian Symposium on Games and Digital Entertainment (SBGames 2022 - this https URL). 7 pages, 4 figures, conference\n",
    "authors": [
      "Gabriel Silva",
      "Paulo Knob",
      "Rubens Montanha",
      "Soraia Musse"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.04624"
  },
  {
    "id": "arXiv:2210.07194",
    "title": "Testing platform-independent quantum error mitigation on noisy quantum  computers",
    "abstract": "Testing platform-independent quantum error mitigation on noisy quantum  computers",
    "descriptor": "",
    "authors": [
      "Vincent Russo",
      "Andrea Mari",
      "Nathan Shammah",
      "Ryan LaRose",
      "William J. Zeng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.07194"
  },
  {
    "id": "arXiv:2210.12142",
    "title": "Target Aware Poisson-Gaussian Noise Parameters Estimation from Noisy  Images",
    "abstract": "Comments: 11 pages, 14 figures and 4 tables",
    "descriptor": "\nComments: 11 pages, 14 figures and 4 tables\n",
    "authors": [
      "\u00c9tienne Objois",
      "Kaan Okumu\u015f",
      "Nicolas B\u00e4hler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12142"
  },
  {
    "id": "arXiv:2210.15785",
    "title": "Supply Chain Characteristics as Predictors of Cyber Risk: A  Machine-Learning Assessment",
    "abstract": "Supply Chain Characteristics as Predictors of Cyber Risk: A  Machine-Learning Assessment",
    "descriptor": "",
    "authors": [
      "Kevin Hu",
      "Retsef Levi",
      "Raphael Yahalom",
      "El Ghali Zerhouni"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.15785"
  },
  {
    "id": "arXiv:2210.16643",
    "title": "XNOR-FORMER: Learning Accurate Approximations in Long Speech  Transformers",
    "abstract": "Comments: Under review at ICASSP 2023",
    "descriptor": "\nComments: Under review at ICASSP 2023\n",
    "authors": [
      "Roshan Sharma",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.16643"
  },
  {
    "id": "arXiv:2211.01994",
    "title": "lilGym: Natural Language Visual Reasoning with Reinforcement Learning",
    "abstract": "lilGym: Natural Language Visual Reasoning with Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Anne Wu",
      "Kiant\u00e9 Brantley",
      "Noriyuki Kojima",
      "Yoav Artzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01994"
  },
  {
    "id": "arXiv:2211.03741",
    "title": "AskewSGD : An Annealed interval-constrained Optimisation method to train  Quantized Neural Networks",
    "abstract": "AskewSGD : An Annealed interval-constrained Optimisation method to train  Quantized Neural Networks",
    "descriptor": "",
    "authors": [
      "Louis Leconte",
      "Sholom Schechtman",
      "Eric Moulines"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03741"
  },
  {
    "id": "arXiv:2211.04052",
    "title": "What Knowledge Is Needed? Towards Explainable Memory for kNN-MT Domain  Adaptation",
    "abstract": "What Knowledge Is Needed? Towards Explainable Memory for kNN-MT Domain  Adaptation",
    "descriptor": "",
    "authors": [
      "Wenhao Zhu",
      "Shujian Huang",
      "Yunzhe Lv",
      "Xin Zheng",
      "Jiajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04052"
  },
  {
    "id": "arXiv:2211.08073",
    "title": "GLUE-X: Evaluating Natural Language Understanding Models from an  Out-of-distribution Generalization Perspective",
    "abstract": "Comments: 17 pages, GLUE-X, OOD Generalization",
    "descriptor": "\nComments: 17 pages, GLUE-X, OOD Generalization\n",
    "authors": [
      "Linyi Yang",
      "Shuibai Zhang",
      "Libo Qin",
      "Yafu Li",
      "Yidong Wang",
      "Hanmeng Liu",
      "Jindong Wang",
      "Xing Xie",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.08073"
  },
  {
    "id": "arXiv:2211.09260",
    "title": "Task-aware Retrieval with Instructions",
    "abstract": "Comments: Code, data and pretrained model checkpoints are available at this https URL",
    "descriptor": "\nComments: Code, data and pretrained model checkpoints are available at this https URL\n",
    "authors": [
      "Akari Asai",
      "Timo Schick",
      "Patrick Lewis",
      "Xilun Chen",
      "Gautier Izacard",
      "Sebastian Riedel",
      "Hannaneh Hajishirzi",
      "Wen-tau Yih"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09260"
  },
  {
    "id": "arXiv:2211.10104",
    "title": "Stereo Image Rain Removal via Dual-View Mutual Attention",
    "abstract": "Stereo Image Rain Removal via Dual-View Mutual Attention",
    "descriptor": "",
    "authors": [
      "Yanyan Wei",
      "Zhao Zhang",
      "Zhongqiu Zhao",
      "Yang Zhao",
      "Richang Hong",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10104"
  },
  {
    "id": "arXiv:2211.11201",
    "title": "Self-Supervised 3D Traversability Estimation with Proxy Bank Guidance",
    "abstract": "Self-Supervised 3D Traversability Estimation with Proxy Bank Guidance",
    "descriptor": "",
    "authors": [
      "Jihwan Bae",
      "Junwon Seo",
      "Taekyung Kim",
      "Hae-gon Jeon",
      "Kiho Kwak",
      "Inwook Shim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11201"
  },
  {
    "id": "arXiv:2211.12739",
    "title": "Texts as Images in Prompt Tuning for Multi-Label Image Recognition",
    "abstract": "Texts as Images in Prompt Tuning for Multi-Label Image Recognition",
    "descriptor": "",
    "authors": [
      "Zixian Guo",
      "Bowen Dong",
      "Zhilong Ji",
      "Jinfeng Bai",
      "Yiwen Guo",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12739"
  },
  {
    "id": "arXiv:2211.13762",
    "title": "ScanNeRF: a Scalable Benchmark for Neural Radiance Fields",
    "abstract": "Comments: WACV 2023. The first three authors contributed equally. Project page: this https URL",
    "descriptor": "\nComments: WACV 2023. The first three authors contributed equally. Project page: this https URL\n",
    "authors": [
      "Luca De Luigi",
      "Damiano Bolognini",
      "Federico Domeniconi",
      "Daniele De Gregorio",
      "Matteo Poggi",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13762"
  },
  {
    "id": "arXiv:2211.16773",
    "title": "KRLS: Improving End-to-End Response Generation in Task Oriented Dialog  with Reinforced Keywords Learning",
    "abstract": "Comments: added more explaination on the algorithm itself. result tables remain the same",
    "descriptor": "\nComments: added more explaination on the algorithm itself. result tables remain the same\n",
    "authors": [
      "Xiao Yu",
      "Qingyang Wu",
      "Kun Qian",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16773"
  },
  {
    "id": "arXiv:2211.17211",
    "title": "On Disperser/Lifting Properties of the Index and Inner-Product Functions",
    "abstract": "On Disperser/Lifting Properties of the Index and Inner-Product Functions",
    "descriptor": "",
    "authors": [
      "Paul Beame",
      "Sajin Koroth"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.17211"
  },
  {
    "id": "arXiv:2212.00715",
    "title": "What do you MEME? Generating Explanations for Visual Semantic Role  Labelling in Memes",
    "abstract": "Comments: Accepted at AAAI 2023 (Main Track). 7 Pages (main content) + 2 Pages (Refs.); 3 Figures; 6 Tables; Paper ID: 10326 (AAAI'23)",
    "descriptor": "\nComments: Accepted at AAAI 2023 (Main Track). 7 Pages (main content) + 2 Pages (Refs.); 3 Figures; 6 Tables; Paper ID: 10326 (AAAI'23)\n",
    "authors": [
      "Shivam Sharma",
      "Siddhant Agarwal",
      "Tharun Suresh",
      "Preslav Nakov",
      "Md. Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.00715"
  },
  {
    "id": "arXiv:2212.02406",
    "title": "Generalization of Higher Order Methods for Fast Iterative Matrix  Inversion Suitable for GPU Acceleration",
    "abstract": "Generalization of Higher Order Methods for Fast Iterative Matrix  Inversion Suitable for GPU Acceleration",
    "descriptor": "",
    "authors": [
      "Marcus Engsig",
      "Qingjie Yang"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.02406"
  },
  {
    "id": "arXiv:2212.02623",
    "title": "Unifying Vision, Text, and Layout for Universal Document Processing",
    "abstract": "Unifying Vision, Text, and Layout for Universal Document Processing",
    "descriptor": "",
    "authors": [
      "Zineng Tang",
      "Ziyi Yang",
      "Guoxin Wang",
      "Yuwei Fang",
      "Yang Liu",
      "Chenguang Zhu",
      "Michael Zeng",
      "Cha Zhang",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02623"
  },
  {
    "id": "arXiv:2212.04074",
    "title": "Cross-view Geo-localization via Learning Disentangled Geometric Layout  Correspondence",
    "abstract": "Cross-view Geo-localization via Learning Disentangled Geometric Layout  Correspondence",
    "descriptor": "",
    "authors": [
      "Xiaohan Zhang",
      "Xingyu Li",
      "Waqas Sultani",
      "Yi Zhou",
      "Safwan Wshah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04074"
  },
  {
    "id": "arXiv:2212.05330",
    "title": "Complete-to-Partial 4D Distillation for Self-Supervised Point Cloud  Sequence Representation Learning",
    "abstract": "Complete-to-Partial 4D Distillation for Self-Supervised Point Cloud  Sequence Representation Learning",
    "descriptor": "",
    "authors": [
      "Zhuoyang Zhang",
      "Yuhao Dong",
      "Yunze Liu",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.05330"
  },
  {
    "id": "arXiv:2212.06321",
    "title": "Data Layout from a Type-Theoretic Perspective (extended version)",
    "abstract": "Comments: Extended version of paper to appear in MFPS 2022 special issue of ENTICS; contains additional section and proofs",
    "descriptor": "\nComments: Extended version of paper to appear in MFPS 2022 special issue of ENTICS; contains additional section and proofs\n",
    "authors": [
      "Henry DeYoung",
      "Frank Pfenning"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2212.06321"
  },
  {
    "id": "arXiv:2212.06369",
    "title": "Technical Report -- Competition Solution for Prompt Tuning using  Pretrained Language Model",
    "abstract": "Technical Report -- Competition Solution for Prompt Tuning using  Pretrained Language Model",
    "descriptor": "",
    "authors": [
      "Jiang-Long Song",
      "Wu-He Zou",
      "Feng Li",
      "Xiao-Lei Qin",
      "Wei-Dong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.06369"
  },
  {
    "id": "arXiv:2212.06800",
    "title": "Diverse Demonstrations Improve In-context Compositional Generalization",
    "abstract": "Diverse Demonstrations Improve In-context Compositional Generalization",
    "descriptor": "",
    "authors": [
      "Itay Levy",
      "Ben Bogin",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.06800"
  },
  {
    "id": "arXiv:2212.07125",
    "title": "Towards practical Quantum Credit Risk Analysis",
    "abstract": "Towards practical Quantum Credit Risk Analysis",
    "descriptor": "",
    "authors": [
      "Emanuele Dri",
      "Edoardo Giusto",
      "Antonello Aita",
      "Bartolomeo Montrucchio"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.07125"
  },
  {
    "id": "arXiv:2212.07956",
    "title": "High precision computation and a new asymptotic formula for the  generalized Stieltjes constants",
    "abstract": "High precision computation and a new asymptotic formula for the  generalized Stieltjes constants",
    "descriptor": "",
    "authors": [
      "Sandeep Tyagi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2212.07956"
  },
  {
    "id": "arXiv:2212.08323",
    "title": "An ensemble neural network approach to forecast Dengue outbreak based on  climatic condition",
    "abstract": "An ensemble neural network approach to forecast Dengue outbreak based on  climatic condition",
    "descriptor": "",
    "authors": [
      "Madhurima Panja",
      "Tanujit Chakraborty",
      "Sk Shahid Nadim",
      "Indrajit Ghosh",
      "Uttam Kumar",
      "Nan Liu"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08323"
  },
  {
    "id": "arXiv:2212.08545",
    "title": "Enriched finite element approach for modeling discontinuous electric  field in multimaterial problems",
    "abstract": "Comments: In this version (in comparison with the first one) two typos were corrected: name of one of the authors and email of the first author",
    "descriptor": "\nComments: In this version (in comparison with the first one) two typos were corrected: name of one of the authors and email of the first author\n",
    "authors": [
      "Christian Narv\u00e1ez-Mu\u00f1oz",
      "Mohammad R. Hashemi",
      "Pavel B. Ryzhakov",
      "Jordi Pons-Prats",
      "Herbert Owen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.08545"
  },
  {
    "id": "arXiv:2212.08597",
    "title": "Detecting and Mitigating Hallucinations in Machine Translation: Model  Internal Workings Alone Do Well, Sentence Similarity Even Better",
    "abstract": "Detecting and Mitigating Hallucinations in Machine Translation: Model  Internal Workings Alone Do Well, Sentence Similarity Even Better",
    "descriptor": "",
    "authors": [
      "David Dale",
      "Elena Voita",
      "Lo\u00efc Barrault",
      "Marta R. Costa-juss\u00e0"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08597"
  },
  {
    "id": "arXiv:2212.08846",
    "title": "Painterly Image Harmonization in Dual Domains",
    "abstract": "Comments: Accepted by AAAI2023",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Junyan Cao",
      "Yan Hong",
      "Li Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08846"
  },
  {
    "id": "arXiv:2212.08899",
    "title": "Design and Simulation of a Micro-coiled Digitally-Controlled Variable  Inductor with a Monolithically Integrated MEMS Switch",
    "abstract": "Comments: Submitted to Microelectronic Engineering Journal - Elsevier",
    "descriptor": "\nComments: Submitted to Microelectronic Engineering Journal - Elsevier\n",
    "authors": [
      "Abdelhameed Sharaf",
      "S. M. Eladl",
      "A. Nasr",
      "Mohamed Serry"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08899"
  },
  {
    "id": "arXiv:2212.08930",
    "title": "On Noisy Evaluation in Federated Hyperparameter Tuning",
    "abstract": "Comments: 19 pages, 15 figures, submitted to MLSys2023 v2: Fixed citation formatting",
    "descriptor": "\nComments: 19 pages, 15 figures, submitted to MLSys2023 v2: Fixed citation formatting\n",
    "authors": [
      "Kevin Kuo",
      "Pratiksha Thaker",
      "Mikhail Khodak",
      "John Ngyuen",
      "Daniel Jiang",
      "Ameet Talwalkar",
      "Virginia Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08930"
  },
  {
    "id": "arXiv:2212.09000",
    "title": "Confidence-aware Training of Smoothed Classifiers for Certified  Robustness",
    "abstract": "Comments: 21 pages; AAAI 2023; Code is available at this https URL",
    "descriptor": "\nComments: 21 pages; AAAI 2023; Code is available at this https URL\n",
    "authors": [
      "Jongheon Jeong",
      "Seojin Kim",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.09000"
  },
  {
    "id": "arXiv:2212.09162",
    "title": "Medical Diagnosis with Large Scale Multimodal Transformers: Leveraging  Diverse Data for More Accurate Diagnosis",
    "abstract": "Medical Diagnosis with Large Scale Multimodal Transformers: Leveraging  Diverse Data for More Accurate Diagnosis",
    "descriptor": "",
    "authors": [
      "Firas Khader",
      "Gustav Mueller-Franzes",
      "Tianci Wang",
      "Tianyu Han",
      "Soroosh Tayebi Arasteh",
      "Christoph Haarburger",
      "Johannes Stegmaier",
      "Keno Bressem",
      "Christiane Kuhl",
      "Sven Nebelung",
      "Jakob Nikolas Kather",
      "Daniel Truhn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.09162"
  },
  {
    "id": "arXiv:2212.09188",
    "title": "Problems, proofs, and disproofs on the inversion number",
    "abstract": "Problems, proofs, and disproofs on the inversion number",
    "descriptor": "",
    "authors": [
      "Guillaume Aubian",
      "Fr\u00e9d\u00e9ric Havet",
      "Florian H\u00f6rsch",
      "Felix Klingelhoefer",
      "Nicolas Nisse",
      "Cl\u00e9ment Rambaud",
      "Quentin Vermande"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2212.09188"
  },
  {
    "id": "arXiv:2212.09252",
    "title": "Mind the Knowledge Gap: A Survey of Knowledge-enhanced Dialogue Systems",
    "abstract": "Mind the Knowledge Gap: A Survey of Knowledge-enhanced Dialogue Systems",
    "descriptor": "",
    "authors": [
      "Sagi Shaier",
      "Lawrence Hunter",
      "Katharina Kann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09252"
  },
  {
    "id": "arXiv:2212.09271",
    "title": "Very Large Language Model as a Unified Methodology of Text Mining",
    "abstract": "Comments: 4 pages, 3 figures",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Meng Jiang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09271"
  },
  {
    "id": "arXiv:2212.09321",
    "title": "Learning from Training Dynamics: Identifying Mislabeled Data Beyond  Manually Designed Features",
    "abstract": "Comments: AAAI23 accepted Conference Paper",
    "descriptor": "\nComments: AAAI23 accepted Conference Paper\n",
    "authors": [
      "Qingrui Jia",
      "Xuhong Li",
      "Lei Yu",
      "Jiang Bian",
      "Penghao Zhao",
      "Shupeng Li",
      "Haoyi Xiong",
      "Dejing Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09321"
  },
  {
    "id": "arXiv:2212.09482",
    "title": "Rainbow Cycle Number and EFX Allocations: (Almost) Closing the Gap",
    "abstract": "Rainbow Cycle Number and EFX Allocations: (Almost) Closing the Gap",
    "descriptor": "",
    "authors": [
      "Shayan Chashm Jahan",
      "Masoud Seddighin",
      "Seyed-Mohammad Seyed-Javadi",
      "Mohammad Sharifi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2212.09482"
  },
  {
    "id": "arXiv:2212.09648",
    "title": "NusaCrowd: Open Source Initiative for Indonesian NLP Resources",
    "abstract": "NusaCrowd: Open Source Initiative for Indonesian NLP Resources",
    "descriptor": "",
    "authors": [
      "Samuel Cahyawijaya",
      "Holy Lovenia",
      "Alham Fikri Aji",
      "Genta Indra Winata",
      "Bryan Wilie",
      "Rahmad Mahendra",
      "Christian Wibisono",
      "Ade Romadhony",
      "Karissa Vincentio",
      "Fajri Koto",
      "Jennifer Santoso",
      "David Moeljadi",
      "Cahya Wirawan",
      "Frederikus Hudi",
      "Ivan Halim Parmonangan",
      "Ika Alfina",
      "Muhammad Satrio Wicaksono",
      "Ilham Firdausi Putra",
      "Samsul Rahmadani",
      "Yulianti Oenang",
      "Ali Akbar Septiandri",
      "James Jaya",
      "Kaustubh D. Dhole",
      "Arie Ardiyanti Suryani",
      "Rifki Afina Putri",
      "Dan Su",
      "Keith Stevens",
      "Made Nindyatama Nityasya",
      "Muhammad Farid Adilazuarda",
      "Ryan Ignatius",
      "Ryandito Diandaru",
      "Tiezheng Yu",
      "Vito Ghifari",
      "Wenliang Dai",
      "Yan Xu",
      "Dyah Damapuspita",
      "Cuk Tho",
      "Ichwanul Muslim Karo Karo",
      "Tirana Noor Fatyanosa",
      "Ziwei Ji",
      "Pascale Fung",
      "Graham Neubig",
      "Timothy Baldwin",
      "Sebastian Ruder",
      "Herry Sujaini",
      "Sakriani Sakti",
      "Ayu Purwarianti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.09648"
  },
  {
    "id": "arXiv:2212.09735",
    "title": "Correspondence Distillation from NeRF-based GAN",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yushi Lan",
      "Chen Change Loy",
      "Bo Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.09735"
  },
  {
    "id": "arXiv:2212.09741",
    "title": "One Embedder, Any Task: Instruction-Finetuned Text Embeddings",
    "abstract": "One Embedder, Any Task: Instruction-Finetuned Text Embeddings",
    "descriptor": "",
    "authors": [
      "Hongjin Su",
      "Weijia Shi",
      "Jungo Kasai",
      "Yizhong Wang",
      "Yushi Hu",
      "Mari Ostendorf",
      "Wen-tau Yih",
      "Noah A. Smith",
      "Luke Zettlemoyer",
      "Tao Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09741"
  },
  {
    "id": "arXiv:2212.09746",
    "title": "Evaluating Human-Language Model Interaction",
    "abstract": "Evaluating Human-Language Model Interaction",
    "descriptor": "",
    "authors": [
      "Mina Lee",
      "Megha Srivastava",
      "Amelia Hardy",
      "John Thickstun",
      "Esin Durmus",
      "Ashwin Paranjape",
      "Ines Gerard-Ursin",
      "Xiang Lisa Li",
      "Faisal Ladhak",
      "Frieda Rong",
      "Rose E. Wang",
      "Minae Kwon",
      "Joon Sung Park",
      "Hancheng Cao",
      "Tony Lee",
      "Rishi Bommasani",
      "Michael Bernstein",
      "Percy Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.09746"
  }
]
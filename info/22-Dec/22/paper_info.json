[
  {
    "id": "arXiv:2212.10566",
    "title": "Visual Analytics for Early Detection of Retinal Diseases",
    "abstract": "Advances in optical coherence tomography (OCT) have enabled noninvasive\nimaging of substructures of the human retina with high spatial resolution. OCT\nexaminations are now a standard procedure in clinics and an integral part of\nophthalmic research. The interpretation of the OCT helps ophthalmologists\nunderstand the impact of various retinal and systemic diseases on the structure\nof the retina in a way not previously possible. In the early stages of retinal\ndiseases, however, the identification and analysis of small and localized\nsubstructural changes in the retina remains a challenge. We present an overview\nof novel visual analytics approaches for the interactive exploration of early\nretinal changes in single and multiple patients, the comparison of the changes\nwith normative data, and automated quantification and measurement of\ndiagnosis-relevant information. We developed these approaches in close\ncollaboration with ophthalmology researchers and industry experts from a\nleading OCT device manufacturer. As a result, they not only significantly\nreduced the time and effort required for OCT data analysis, especially in the\ncontext of cross-sectional studies, but have also led to several new\ndiscoveries published in biomedical journals.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Martin R\u00f6hlig",
      "Oliver Stachs",
      "Heidrun Schumann"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.10566"
  },
  {
    "id": "arXiv:2212.10570",
    "title": "Video Segmentation Learning Using Cascade Residual Convolutional Neural  Network",
    "abstract": "Video segmentation consists of a frame-by-frame selection process of\nmeaningful areas related to foreground moving objects. Some applications\ninclude traffic monitoring, human tracking, action recognition, efficient video\nsurveillance, and anomaly detection. In these applications, it is not rare to\nface challenges such as abrupt changes in weather conditions, illumination\nissues, shadows, subtle dynamic background motions, and also camouflage\neffects. In this work, we address such shortcomings by proposing a novel deep\nlearning video segmentation approach that incorporates residual information\ninto the foreground detection learning process. The main goal is to provide a\nmethod capable of generating an accurate foreground detection given a grayscale\nvideo. Experiments conducted on the Change Detection 2014 and on the private\ndataset PetrobrasROUTES from Petrobras support the effectiveness of the\nproposed approach concerning some state-of-the-art video segmentation\ntechniques, with overall F-measures of $\\mathbf{0.9535}$ and $\\mathbf{0.9636}$\nin the Change Detection 2014 and PetrobrasROUTES datasets, respectively. Such a\nresult places the proposed technique amongst the top 3 state-of-the-art video\nsegmentation methods, besides comprising approximately seven times less\nparameters than its top one counterpart.",
    "descriptor": "\nComments: Published in: 2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI). arXiv admin note: text overlap with arXiv:2212.10417\n",
    "authors": [
      "Daniel F. S. Santos",
      "Rafael G. Pires",
      "Danilo Colombo",
      "Jo\u00e3o P. Papa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10570"
  },
  {
    "id": "arXiv:2212.10596",
    "title": "Open-Vocabulary Temporal Action Detection with Off-the-Shelf Image-Text  Features",
    "abstract": "Detecting actions in untrimmed videos should not be limited to a small,\nclosed set of classes. We present a simple, yet effective strategy for\nopen-vocabulary temporal action detection utilizing pretrained image-text\nco-embeddings. Despite being trained on static images rather than videos, we\nshow that image-text co-embeddings enable openvocabulary performance\ncompetitive with fully-supervised models. We show that the performance can be\nfurther improved by ensembling the image-text features with features encoding\nlocal motion, like optical flow based features, or other modalities, like\naudio. In addition, we propose a more reasonable open-vocabulary evaluation\nsetting for the ActivityNet data set, where the category splits are based on\nsimilarity rather than random assignment.",
    "descriptor": "",
    "authors": [
      "Vivek Rathod",
      "Bryan Seybold",
      "Sudheendra Vijayanarasimhan",
      "Austin Myers",
      "Xiuye Gu",
      "Vighnesh Birodkar",
      "David A. Ross"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10596"
  },
  {
    "id": "arXiv:2212.10612",
    "title": "Towards Heterogeneous Multi-core Accelerators Exploiting Fine-grained  Scheduling of Layer-Fused Deep Neural Networks",
    "abstract": "To keep up with the ever-growing performance demand of neural networks,\nspecialized hardware (HW) accelerators are shifting towards multi-core and\nchiplet architectures. So far, these multi-accelerator systems exploit the\nincreased parallelism by pipelining different NN layers across input batches on\ndifferent cores to increase throughput. Yet, when pursuing this with\nnon-batched layer-by-layer scheduling of latency-critical applications, this\nfails to fully exploit the available HW resources towards energy-efficient\nexecution at the edge.\nThis work, therefore, enables fine-grained depth-first scheduling of\nlayer-fused DNNs onto multi-core architectures through an open-source modeling\nframework called Stream. Stream is capable of representing a wide range of\nscheduling granularities and HW architectures and optimizes execution schedules\ntowards minimal energy, minimal latency and/or minimal memory footprint for\nconstrained edge devices. We validate against three SotA HW implementations\nemploying layer-fused scheduling showing tight matching with measured\nefficiencies. Using Stream in further explorations, we demonstrate that\nhigh-level architectural decisions greatly impact hardware efficiency under the\nfine-grained scheduling paradigm, reducing the energy-delay product from 2.4x\nfor single-core architectures to up to 30x for heterogeneous multi-core\narchitectures compared to the traditional scheduling at layer granularity.",
    "descriptor": "\nComments: 9 pages + references, 15 figures\n",
    "authors": [
      "Arne Symons",
      "Linyan Mei",
      "Steven Colleman",
      "Pouya Houshmand",
      "Sebastian Karl",
      "Marian Verhelst"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2212.10612"
  },
  {
    "id": "arXiv:2212.10613",
    "title": "Temporal Output Discrepancy for Loss Estimation-based Active Learning",
    "abstract": "While deep learning succeeds in a wide range of tasks, it highly depends on\nthe massive collection of annotated data which is expensive and time-consuming.\nTo lower the cost of data annotation, active learning has been proposed to\ninteractively query an oracle to annotate a small proportion of informative\nsamples in an unlabeled dataset. Inspired by the fact that the samples with\nhigher loss are usually more informative to the model than the samples with\nlower loss, in this paper we present a novel deep active learning approach that\nqueries the oracle for data annotation when the unlabeled sample is believed to\nincorporate high loss. The core of our approach is a measurement Temporal\nOutput Discrepancy (TOD) that estimates the sample loss by evaluating the\ndiscrepancy of outputs given by models at different optimization steps. Our\ntheoretical investigation shows that TOD lower-bounds the accumulated sample\nloss thus it can be used to select informative unlabeled samples. On basis of\nTOD, we further develop an effective unlabeled data sampling strategy as well\nas an unsupervised learning criterion for active learning. Due to the\nsimplicity of TOD, our methods are efficient, flexible, and task-agnostic.\nExtensive experimental results demonstrate that our approach achieves superior\nperformances than the state-of-the-art active learning methods on image\nclassification and semantic segmentation tasks. In addition, we show that TOD\ncan be utilized to select the best model of potentially the highest testing\naccuracy from a pool of candidate models.",
    "descriptor": "\nComments: Accepted for IEEE Transactions on Neural Networks and Learning Systems, 2022. Journal extension of ICCV 2021 [arXiv:2107.14153]\n",
    "authors": [
      "Siyu Huang",
      "Tianyang Wang",
      "Haoyi Xiong",
      "Bihan Wen",
      "Jun Huan",
      "Dejing Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10613"
  },
  {
    "id": "arXiv:2212.10614",
    "title": "MolCPT: Molecule Continuous Prompt Tuning to Generalize Molecular  Representation Learning",
    "abstract": "Molecular representation learning is crucial for the problem of molecular\nproperty prediction, where graph neural networks (GNNs) serve as an effective\nsolution due to their structure modeling capabilities. Since labeled data is\noften scarce and expensive to obtain, it is a great challenge for GNNs to\ngeneralize in the extensive molecular space. Recently, the training paradigm of\n\"pre-train, fine-tune\" has been leveraged to improve the generalization\ncapabilities of GNNs. It uses self-supervised information to pre-train the GNN,\nand then performs fine-tuning to optimize the downstream task with just a few\nlabels. However, pre-training does not always yield statistically significant\nimprovement, especially for self-supervised learning with random structural\nmasking. In fact, the molecular structure is characterized by motif subgraphs,\nwhich are frequently occurring and influence molecular properties. To leverage\nthe task-related motifs, we propose a novel paradigm of \"pre-train, prompt,\nfine-tune\" for molecular representation learning, named molecule continuous\nprompt tuning (MolCPT). MolCPT defines a motif prompting function that uses the\npre-trained model to project the standalone input into an expressive prompt.\nThe prompt effectively augments the molecular graph with meaningful motifs in\nthe continuous representation space; this provides more structural patterns to\naid the downstream classifier in identifying molecular properties. Extensive\nexperiments on several benchmark datasets show that MolCPT efficiently\ngeneralizes pre-trained GNNs for molecular property prediction, with or without\na few fine-tuning steps.",
    "descriptor": "",
    "authors": [
      "Cameron Diao",
      "Kaixiong Zhou",
      "Xiao Huang",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2212.10614"
  },
  {
    "id": "arXiv:2212.10618",
    "title": "Ontologically Faithful Generation of Non-Player Character Dialogues",
    "abstract": "We introduce a language generation task grounded in a popular video game\nenvironment. KNUDGE (KNowledge Constrained User-NPC Dialogue GEneration)\ninvolves generating dialogue trees conditioned on an ontology captured in\nnatural language passages providing quest and entity specifications. KNUDGE is\nconstructed from side quest dialogues drawn directly from game data of Obsidian\nEntertainment's The Outer Worlds, leading to real-world complexities in\ngeneration: (1) dialogues are branching trees as opposed to linear chains of\nutterances; (2) utterances must remain faithful to the game lore--character\npersonas, backstories, and entity relationships; and (3) a dialogue must\naccurately reveal new quest-related details to the human player. We report\nresults for supervised and in-context learning techniques, finding there is\nsignificant room for future work on creating realistic game-quality dialogues.",
    "descriptor": "",
    "authors": [
      "Nathaniel Weir",
      "Ryan Thomas",
      "Randolph D'Amore",
      "Kellie Hill",
      "Benjamin Van Durme",
      "Harsh Jhamtani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10618"
  },
  {
    "id": "arXiv:2212.10621",
    "title": "CHAIRS: Towards Full-Body Articulated Human-Object Interaction",
    "abstract": "Fine-grained capturing of 3D HOI boosts human activity understanding and\nfacilitates downstream visual tasks, including action recognition, holistic\nscene reconstruction, and human motion synthesis. Despite its significance,\nexisting works mostly assume that humans interact with rigid objects using only\na few body parts, limiting their scope. In this paper, we address the\nchallenging problem of f-AHOI, wherein the whole human bodies interact with\narticulated objects, whose parts are connected by movable joints. We present\nCHAIRS, a large-scale motion-captured f-AHOI dataset, consisting of 16.2 hours\nof versatile interactions between 46 participants and 81 articulated and rigid\nsittable objects. CHAIRS provides 3D meshes of both humans and articulated\nobjects during the entire interactive process, as well as realistic and\nphysically plausible full-body interactions. We show the value of CHAIRS with\nobject pose estimation. By learning the geometrical relationships in HOI, we\ndevise the very first model that leverage human pose estimation to tackle the\nestimation of articulated object poses and shapes during whole-body\ninteractions. Given an image and an estimated human pose, our model first\nreconstructs the pose and shape of the object, then optimizes the\nreconstruction according to a learned interaction prior. Under both evaluation\nsettings (e.g., with or without the knowledge of objects'\ngeometries/structures), our model significantly outperforms baselines. We hope\nCHAIRS will promote the community towards finer-grained interaction\nunderstanding. We will make the data/code publicly available.",
    "descriptor": "",
    "authors": [
      "Nan Jiang",
      "Tengyu Liu",
      "Zhexuan Cao",
      "Jieming Cui",
      "Yixin Chen",
      "He Wang",
      "Yixin Zhu",
      "Siyuan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10621"
  },
  {
    "id": "arXiv:2212.10622",
    "title": "mFACE: Multilingual Summarization with Factual Consistency Evaluation",
    "abstract": "Abstractive summarization has enjoyed renewed interest in recent years,\nthanks to pre-trained language models and the availability of large-scale\ndatasets. Despite promising results, current models still suffer from\ngenerating factually inconsistent summaries, reducing their utility for\nreal-world application. Several recent efforts attempt to address this by\ndevising models that automatically detect factual inconsistencies in machine\ngenerated summaries. However, they focus exclusively on English, a language\nwith abundant resources. In this work, we leverage factual consistency\nevaluation models to improve multilingual summarization. We explore two\nintuitive approaches to mitigate hallucinations based on the signal provided by\na multilingual NLI model, namely data filtering and controlled generation.\nExperimental results in the 45 languages from the XLSum dataset show gains over\nstrong baselines in both automatic and human evaluation.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Roee Aharoni",
      "Shashi Narayan",
      "Joshua Maynez",
      "Jonathan Herzig",
      "Elizabeth Clark",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10622"
  },
  {
    "id": "arXiv:2212.10624",
    "title": "Random linear estimation with rotationally-invariant designs:  Asymptotics at high temperature",
    "abstract": "We study estimation in the linear model $y=A\\beta^\\star+\\epsilon$, in a\nBayesian setting where $\\beta^\\star$ has an entrywise i.i.d. prior and the\ndesign $A$ is rotationally-invariant in law. In the large system limit as\ndimension and sample size increase proportionally, a set of related conjectures\nhave been postulated for the asymptotic mutual information, Bayes-optimal mean\nsquared error, and TAP mean-field equations that characterize the Bayes\nposterior mean of $\\beta^\\star$. In this work, we prove these conjectures for a\ngeneral class of signal priors and for arbitrary rotationally-invariant designs\n$A$, under a \"high-temperature\" condition that restricts the range of\neigenvalues of $A^\\top A$. Our proof uses a conditional second-moment method\nargument, where we condition on the iterates of a version of the Vector AMP\nalgorithm for solving the TAP mean-field equations.",
    "descriptor": "",
    "authors": [
      "Yufan Li",
      "Zhou Fan",
      "Subhabrata Sen",
      "Yihong Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.10624"
  },
  {
    "id": "arXiv:2212.10628",
    "title": "Holistic risk assessment of inference attacks in machine learning",
    "abstract": "As machine learning expanding application, there are more and more\nunignorable privacy and safety issues. Especially inference attacks against\nMachine Learning models allow adversaries to infer sensitive information about\nthe target model, such as training data, model parameters, etc. Inference\nattacks can lead to serious consequences, including violating individuals\nprivacy, compromising the intellectual property of the owner of the machine\nlearning model. As far as concerned, researchers have studied and analyzed in\ndepth several types of inference attacks, albeit in isolation, but there is\nstill a lack of a holistic rick assessment of inference attacks against machine\nlearning models, such as their application in different scenarios, the common\nfactors affecting the performance of these attacks and the relationship among\nthe attacks. As a result, this paper performs a holistic risk assessment of\ndifferent inference attacks against Machine Learning models. This paper focuses\non three kinds of representative attacks: membership inference attack,\nattribute inference attack and model stealing attack. And a threat model\ntaxonomy is established. A total of 12 target models using three model\narchitectures, including AlexNet, ResNet18 and Simple CNN, are trained on four\ndatasets, namely CelebA, UTKFace, STL10 and FMNIST.",
    "descriptor": "",
    "authors": [
      "Yang Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10628"
  },
  {
    "id": "arXiv:2212.10632",
    "title": "High-Throughput, High-Performance Deep Learning-Driven Light Guide Plate  Surface Visual Quality Inspection Tailored for Real-World Manufacturing  Environments",
    "abstract": "Light guide plates are essential optical components widely used in a diverse\nrange of applications ranging from medical lighting fixtures to back-lit TV\ndisplays. In this work, we introduce a fully-integrated, high-throughput,\nhigh-performance deep learning-driven workflow for light guide plate surface\nvisual quality inspection (VQI) tailored for real-world manufacturing\nenvironments. To enable automated VQI on the edge computing within the\nfully-integrated VQI system, a highly compact deep anti-aliased attention\ncondenser neural network (which we name LightDefectNet) tailored specifically\nfor light guide plate surface defect detection in resource-constrained\nscenarios was created via machine-driven design exploration with computational\nand \"best-practices\" constraints as well as L_1 paired classification\ndiscrepancy loss. Experiments show that LightDetectNet achieves a detection\naccuracy of ~98.2% on the LGPSDD benchmark while having just 770K parameters\n(~33X and ~6.9X lower than ResNet-50 and EfficientNet-B0, respectively) and\n~93M FLOPs (~88X and ~8.4X lower than ResNet-50 and EfficientNet-B0,\nrespectively) and ~8.8X faster inference speed than EfficientNet-B0 on an\nembedded ARM processor. As such, the proposed deep learning-driven workflow,\nintegrated with the aforementioned LightDefectNet neural network, is highly\nsuited for high-throughput, high-performance light plate surface VQI within\nreal-world manufacturing environments.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2204.11765\n",
    "authors": [
      "Carol Xu",
      "Mahmoud Famouri",
      "Gautam Bathla",
      "Mohammad Javad Shafiee",
      "Alexander Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10632"
  },
  {
    "id": "arXiv:2212.10636",
    "title": "An Evaluation of the State-of-the-Art Software and Hardware  Implementations of BIKE",
    "abstract": "NIST is conducting a process for the standardization of post-quantum\ncryptosystems, i.e., cryptosystems that are resistant to attacks by both\ntraditional and quantum computers and that can thus substitute the traditional\npublic-key cryptography solutions which are expected to be broken by quantum\ncomputers in the next decades. This manuscript provides an overview and a\ncomparison of the existing state-of-the-art implementations of the BIKE QC-MDPC\ncode-based post-quantum KEM, a candidate in NIST's PQC standardization process.\nWe consider both software, hardware, and mixed hardware-software\nimplementations and evaluate their performance and, for hardware ones, their\nresource utilization.",
    "descriptor": "\nComments: Accepted for presentation at PARMA-DITAM 2023: 14th Workshop on Parallel Programming and Run-Time Management Techniques for Many-core Architectures / 12th Workshop on Design Tools and Architectures for Multicore Embedded Computing Platforms, January 17, 2023\n",
    "authors": [
      "Andrea Galimberti",
      "Gabriele Montanaro",
      "William Fornaciari",
      "Davide Zoni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2212.10636"
  },
  {
    "id": "arXiv:2212.10641",
    "title": "Coloring in Graph Streams via Deterministic and Adversarially Robust  Algorithms",
    "abstract": "In recent years, there has been a growing interest in solving various graph\ncoloring problems in the streaming model. The initial algorithms in this line\nof work are all crucially randomized, raising natural questions about how\nimportant a role randomization plays in streaming graph coloring. A couple of\nvery recent works have made progress on this question: they prove that\ndeterministic or even adversarially robust coloring algorithms (that work on\nstreams whose updates may depend on the algorithm's past outputs) are\nconsiderably weaker than standard randomized ones. However, there is still a\nsignificant gap between the upper and lower bounds for the number of colors\nneeded (as a function of the maximum degree $\\Delta$) for robust coloring and\nmultipass deterministic coloring. We contribute to this line of work by proving\nthe following results.\nIn the deterministic semi-streaming (i.e., $O(n \\cdot \\text{polylog } n)$\nspace) regime, we present an algorithm that achieves a combinatorially optimal\n$(\\Delta+1)$-coloring using $O(\\log{\\Delta} \\log\\log{\\Delta})$ passes. This\nimproves upon the prior $O(\\Delta)$-coloring algorithm of Assadi, Chen, and Sun\n(STOC 2022) at the cost of only an $O(\\log\\log{\\Delta})$ factor in the number\nof passes.\nIn the adversarially robust semi-streaming regime, we design an\n$O(\\Delta^{5/2})$-coloring algorithm that improves upon the previously best\n$O(\\Delta^{3})$-coloring algorithm of Chakrabarti, Ghosh, and Stoeckl (ITCS\n2022). Further, we obtain a smooth colors/space tradeoff that improves upon\nanother algorithm of the said work: whereas their algorithm uses $O(\\Delta^2)$\ncolors and $O(n\\Delta^{1/2})$ space, ours, in particular, achieves\n(i)~$O(\\Delta^2)$ colors in $O(n\\Delta^{1/3})$ space, and\n(ii)~$O(\\Delta^{7/4})$ colors in $O(n\\Delta^{1/2})$ space.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Sepehr Assadi",
      "Amit Chakrabarti",
      "Prantar Ghosh",
      "Manuel Stoeckl"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.10641"
  },
  {
    "id": "arXiv:2212.10646",
    "title": "Did the Musk Takeover Boost Contentious Actors on Twitter?",
    "abstract": "Twitter has been accused of a liberal bias in its account verification and\ncontent moderation policies. Elon Musk pledged, after his acquisition of the\ncompany, to promote free speech on the platform by overhauling verification and\nmoderation policies. These events sparked fears of a rise in influence of\ncontentious actors -- notably from the political right. In this article, I use\na publicly released list of 138k Twitter accounts that purchased blue check\nverification during the open window of November 9-November 11, 2022. I retrieve\n4.9m tweets from a sample of politically contentious accounts. I then compare\nengagement on contentious user posts before and after the Musk acquisition. I\nfind that the period following the Musk acquisition saw a substantive increase\nin post engagement. There is no additional increase following blue tick\nverification. I explain the findings with reference to an increase in activity\nby a newly sympathetic user base.",
    "descriptor": "",
    "authors": [
      "Christopher Barrie"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.10646"
  },
  {
    "id": "arXiv:2212.10647",
    "title": "The SIMO Block Rayleigh Fading Channel Capacity Scaling with Number of  Antennas, Bandwidth and Coherence Length",
    "abstract": "This paper studies the capacity scaling of non-coherent Single-Input\nMultiple-Output (SIMO) independent and identically distributed (i.i.d.)\nRayleigh block fading channels versus bandwidth ($B$), number of receive\nantennas ($N$) and coherence block length ($L$). In non-coherent channels\n(without Channel State Information --CSI) capacity scales as\n$\\Theta\\left(\\min(B,\\sqrt{NL},N)\\right)$. This is achievable using\nPilot-Assisted signaling. Energy Modulation signaling rate scales as\n$\\Theta\\left(\\min(B,\\sqrt{N})\\right)$. If $L$ is fixed while $B$ and $N$ grow,\nthe two expressions grow equally and Energy Modulation achieves the capacity\nscaling. However, Energy Modulation rate does not scale as the capacity with\nthe variable $L$. The coherent channel capacity with a priori CSI, in turn,\nscales as $\\Theta\\left(\\min(B,N)\\right)$. The coherent channel capacity scaling\ncan be fully achieved in non-coherent channels when $L\\geq\\Theta(N)$. In\nsummary, the channel coherence block length plays a pivotal role in modulation\nselection and the capacity gap between coherent and non-coherent channels.\nPilot-Assisted signaling outperforms Energy Modulation's rate scaling versus\ncoherence block length. Only in high mobility scenarios where $L$ is much\nsmaller than the number of antennas ($L\\ll\\Theta(\\sqrt{N})$), Energy Modulation\nis effective in non-coherent channels.",
    "descriptor": "\nComments: 6 figures. This is the author's self-archived pre-print version of a publication accepted in IEEE Journal on Selected Areas in Information Theory\n",
    "authors": [
      "Felipe Gomez-Cuba"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.10647"
  },
  {
    "id": "arXiv:2212.10648",
    "title": "Analysis and Simulations of a Nonlocal Gray-Scott Model",
    "abstract": "The Gray-Scott model is a set of reaction-diffusion equations that describes\nchemical systems far from equilibrium. Interest in this model stems from its\nability to generate spatio-temporal structures, including pulses, spots,\nstripes, and self-replicating patterns. We consider an extension of this model\nin which the spread of the different chemicals is assumed to be nonlocal, and\ncan thus be represented by a convolution term. In particular, we focus on the\ncase of strictly positive, symmetric, $L^1$ convolution kernels that have a\nfinite second moment. Modeling the equations on a finite interval, we prove the\nexistence of small-time weak solutions in the case of nonlocal Dirichlet and\nNeumann boundary constraints. We then use this result to develop a finite\nelement numerical scheme that helps us explore the effects of nonlocal\ndiffusion on the formation of pulse solutions.",
    "descriptor": "\nComments: 28 pages, 2 figures\n",
    "authors": [
      "Loic Cappanera",
      "Gabriela Jaramillo",
      "Cory Ward"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.10648"
  },
  {
    "id": "arXiv:2212.10649",
    "title": "Inversion of Bayesian Networks",
    "abstract": "Variational autoencoders and Helmholtz machines use a recognition network\n(encoder) to approximate the posterior distribution of a generative model\n(decoder). In this paper we study the necessary and sufficient properties of a\nrecognition network so that it can model the true posterior distribution\nexactly. These results are derived in the general context of probabilistic\ngraphical modelling / Bayesian networks, for which the network represents a set\nof conditional independence statements. We derive both global conditions, in\nterms of d-separation, and local conditions for the recognition network to have\nthe desired qualities. It turns out that for the local conditions the property\nperfectness (for every node, all parents are joined) plays an important role.",
    "descriptor": "",
    "authors": [
      "Jesse van Oostrum",
      "Peter van Hintum",
      "Nihat Ay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.10649"
  },
  {
    "id": "arXiv:2212.10650",
    "title": "KronA: Parameter Efficient Tuning with Kronecker Adapter",
    "abstract": "Fine-tuning a Pre-trained Language Model (PLM) on a specific downstream task\nhas been a well-known paradigm in Natural Language Processing. However, with\nthe ever-growing size of PLMs, training the entire model on several downstream\ntasks becomes very expensive and resource-hungry. Recently, different Parameter\nEfficient Tuning (PET) techniques are proposed to improve the efficiency of\nfine-tuning PLMs. One popular category of PET methods is the low-rank\nadaptation methods which insert learnable truncated SVD modules into the\noriginal model either sequentially or in parallel. However, low-rank\ndecomposition suffers from limited representation power. In this work, we\naddress this problem using the Kronecker product instead of the low-rank\nrepresentation. We introduce KronA, a Kronecker product-based adapter module\nfor efficient fine-tuning of Transformer-based PLMs. We apply the proposed\nmethods for fine-tuning T5 on the GLUE benchmark to show that incorporating the\nKronecker-based modules can outperform state-of-the-art PET methods.",
    "descriptor": "",
    "authors": [
      "Ali Edalati",
      "Marzieh Tahaei",
      "Ivan Kobyzev",
      "Vahid Partovi Nia",
      "James J. Clark",
      "Mehdi Rezagholizadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10650"
  },
  {
    "id": "arXiv:2212.10654",
    "title": "POD-based reduced order methods for optimal control problems governed by  parametric partial differential equation with varying boundary control",
    "abstract": "In this work we propose tailored model order reduction for varying boundary\noptimal control problems governed by parametric partial differential equations.\nWith varying boundary control, we mean that a specific parameter changes where\nthe boundary control acts on the system. This peculiar formulation might\nbenefit from model order reduction. Indeed, fast and reliable simulations of\nthis model can be of utmost usefulness in many applied fields, such as\ngeophysics and energy engineering. However, varying boundary control features\nvery complicated and diversified parametric behaviour for the state and adjoint\nvariables. The state solution, for example, changing the boundary control\nparameter, might feature transport phenomena. Moreover, the problem loses its\naffine structure. It is well known that classical model order reduction\ntechniques fail in this setting, both in accuracy and in efficiency. Thus, we\npropose reduced approaches inspired by the ones used when dealing with\nwave-like phenomena. Indeed, we compare standard proper orthogonal\ndecomposition with two tailored strategies: geometric recasting and local\nproper orthogonal decomposition. Geometric recasting solves the optimization\nsystem in a reference domain simplifying the problem at hand avoiding\nhyper-reduction, while local proper orthogonal decomposition builds local bases\nto increase the accuracy of the reduced solution in very general settings\n(where geometric recasting is unfeasible). We compare the various approaches on\ntwo different numerical experiments based on geometries of increasing\ncomplexity.",
    "descriptor": "",
    "authors": [
      "Maria Strazzullo",
      "Fabio Vicini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.10654"
  },
  {
    "id": "arXiv:2212.10660",
    "title": "AutoMESC: Automatic Framework for Mining and Classifying Ethereum Smart  Contract Vulnerabilities and Their Fixes",
    "abstract": "Due to the risks associated with vulnerabilities in smart contracts, their\nsecurity has gained significant attention in recent years. However, there is a\nlack of open datasets on smart contract vulnerabilities and their fixes that\nallows for data-driven research. Towards this end, we propose an automated\nmethod for mining and classifying Ethereum's smart contract vulnerabilities and\ntheir corresponding fixes from GitHub and from the Common Vulnerabilities and\nExposures (CVE) records in the National Vulnerability Database. We implemented\nthe proposed method in a fully automated framework, which we call AutoMESC.\nAutoMESC uses seven of the most well-known smart contract security tools to\nclassify and label the collected vulnerabilities based on vulnerability types.\nFurthermore, it collects metadata that can be used in data-intensive smart\ncontract security research (e.g., vulnerability detection, vulnerability\nclassification, severity prediction, and automated repair). We used AutoMESC to\nconstruct a sample dataset and made it publicly available. Currently, the\ndataset contains 6.7K smart contracts' vulnerability-fix pairs written in\nSolidity. We assess the quality of the constructed dataset in terms of\naccuracy, provenance, and relevance, and compare it with existing datasets.\nAutoMESC is designed to collect data continuously and keep the corresponding\ndataset up-to-date with newly discovered smart contract vulnerabilities and\ntheir fixes from GitHub and CVE records.",
    "descriptor": "",
    "authors": [
      "Majd Soud",
      "Ilham Qasse",
      "Grischa Liebel",
      "Mohammad Hamdaqa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.10660"
  },
  {
    "id": "arXiv:2212.10663",
    "title": "Towards data-driven stochastic predictive control",
    "abstract": "Data-driven predictive control based on the fundamental lemma by Willems et\nal. is frequently considered for deterministic LTI systems subject to\nmeasurement noise. However, little has been done on data-driven stochastic\ncontrol. In this paper, we propose a data-driven stochastic predictive control\nscheme for LTI systems subject to possibly unbounded additive process\ndisturbances. Based on a stochastic extension of the fundamental lemma and\nleveraging polynomial chaos expansions, we construct a data-driven surrogate\nOptimal Control Problem (OCP). Moreover, combined with an online selection\nstrategy of the initial condition of the OCP, we provide sufficient conditions\nfor recursive feasibility and for stability of the proposed data-driven\npredictive control scheme. Finally, two numerical examples illustrate the\nefficacy and closed-loop properties of the proposed scheme for process\ndisturbances governed by different distributions.",
    "descriptor": "",
    "authors": [
      "Guanru Pan",
      "Ruchuan Ou",
      "Timm Faulwasser"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.10663"
  },
  {
    "id": "arXiv:2212.10670",
    "title": "In-context Learning Distillation: Transferring Few-shot Learning Ability  of Pre-trained Language Models",
    "abstract": "Given the success with in-context learning of large pre-trained language\nmodels, we introduce in-context learning distillation to transfer in-context\nfew-shot learning ability from large models to smaller models. We propose to\ncombine in-context learning objectives with language modeling objectives to\ndistill both the ability to read in-context examples and task knowledge to the\nsmaller models. We perform in-context learning distillation under two different\nfew-shot learning paradigms: Meta In-context Tuning (Meta-ICT) and Multitask\nIn-context Tuning (Multitask-ICT). Multitask-ICT performs better on multitask\nfew-shot learning but also requires more computation than Meta-ICT. Our method\nshows consistent improvements for both Meta-ICT and Multitask-ICT on two\nbenchmarks: LAMA and CrossFit. Our extensive experiments and analysis reveal\nthat in-context learning objectives and language modeling objectives are\ncomplementary under the Multitask-ICT paradigm. In-context learning objectives\nachieve the best performance when combined with language modeling objectives.",
    "descriptor": "",
    "authors": [
      "Yukun Huang",
      "Yanda Chen",
      "Zhou Yu",
      "Kathleen McKeown"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10670"
  },
  {
    "id": "arXiv:2212.10671",
    "title": "evoML Yellow Paper: Evolutionary AI and Optimisation Studio",
    "abstract": "Machine learning model development and optimisation can be a rather\ncumbersome and resource-intensive process. Custom models are often more\ndifficult to build and deploy, and they require infrastructure and expertise\nwhich are often costly to acquire and maintain. Machine learning product\ndevelopment lifecycle must take into account the need to navigate the\ndifficulties of developing and deploying machine learning models. evoML is an\nAI-powered tool that provides automated functionalities in machine learning\nmodel development, optimisation, and model code optimisation. Core\nfunctionalities of evoML include data cleaning, exploratory analysis, feature\nanalysis and generation, model optimisation, model evaluation, model code\noptimisation, and model deployment. Additionally, a key feature of evoML is\nthat it embeds code and model optimisation into the model development process,\nand includes multi-objective optimisation capabilities.",
    "descriptor": "",
    "authors": [
      "Lingbo Li",
      "Leslie Kanthan",
      "Michail Basios",
      "Fan Wu",
      "Manal Adham",
      "Vitali Avagyan",
      "Alexis Butler",
      "Paul Brookes",
      "Rafail Giavrimis",
      "Buhong Liu",
      "Chrystalla Pavlou",
      "Matthew Truscott",
      "Vardan Voskanyan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.10671"
  },
  {
    "id": "arXiv:2212.10675",
    "title": "There's Plenty of Room Right Here: Biological Systems as Evolved,  Overloaded, Multi-scale Machines",
    "abstract": "The applicability of computational models to the biological world is an\nactive topic of debate. We argue that a useful path forward results from\nabandoning hard boundaries between categories and adopting an\nobserver-dependent, pragmatic view. Such a view dissolves the contingent\ndichotomies driven by human cognitive biases (e.g., tendency to oversimplify)\nand prior technological limitations in favor of a more continuous, gradualist\nview necessitated by the study of evolution, developmental biology, and\nintelligent machines. Efforts to re-shape living systems for biomedical or\nbioengineering purposes require prediction and control of their function at\nmultiple scales. This is challenging for many reasons, one of which is that\nliving systems perform multiple functions in the same place at the same time.\nWe refer to this as \"polycomputing\" - the ability of the same substrate to\nsimultaneously compute different things. This ability is an important way in\nwhich living things are a kind of computer, but not the familiar, linear,\ndeterministic kind; rather, living things are computers in the broad sense of\ncomputational materials as reported in the rapidly-growing physical computing\nliterature. We argue that an observer-centered framework for the computations\nperformed by evolved and designed systems will improve the understanding of\nmeso-scale events, as it has already done at quantum and relativistic scales.\nHere, we review examples of biological and technological polycomputing, and\ndevelop the idea that overloading of different functions on the same hardware\nis an important design principle that helps understand and build both evolved\nand designed systems. Learning to hack existing polycomputing substrates, as\nwell as evolve and design new ones, will have massive impacts on regenerative\nmedicine, robotics, and computer engineering.",
    "descriptor": "\nComments: 41 pages, 6 figures\n",
    "authors": [
      "Joshua Bongard",
      "Michael Levin"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Cell Behavior (q-bio.CB)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2212.10675"
  },
  {
    "id": "arXiv:2212.10678",
    "title": "Understanding Stereotypes in Language Models: Towards Robust Measurement  and Zero-Shot Debiasing",
    "abstract": "Generated texts from large pretrained language models have been shown to\nexhibit a variety of harmful, human-like biases about various demographics.\nThese findings prompted large efforts aiming to understand and measure such\neffects, with the goal of providing benchmarks that can guide the development\nof techniques mitigating these stereotypical associations. However, as recent\nresearch has pointed out, the current benchmarks lack a robust experimental\nsetup, consequently hindering the inference of meaningful conclusions from\ntheir evaluation metrics. In this paper, we extend these arguments and\ndemonstrate that existing techniques and benchmarks aiming to measure\nstereotypes tend to be inaccurate and consist of a high degree of experimental\nnoise that severely limits the knowledge we can gain from benchmarking language\nmodels based on them. Accordingly, we propose a new framework for robustly\nmeasuring and quantifying biases exhibited by generative language models.\nFinally, we use this framework to investigate GPT-3's occupational gender bias\nand propose prompting techniques for mitigating these biases without the need\nfor fine-tuning.",
    "descriptor": "",
    "authors": [
      "Justus Mattern",
      "Zhijing Jin",
      "Mrinmaya Sachan",
      "Rada Mihalcea",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10678"
  },
  {
    "id": "arXiv:2212.10682",
    "title": "Privacy-Protecting Behaviours of Risk Detection in People with Dementia  using Videos",
    "abstract": "People living with dementia often exhibit behavioural and psychological\nsymptoms of dementia that can put their and others' safety at risk. Existing\nvideo surveillance systems in long-term care facilities can be used to monitor\nsuch behaviours of risk to alert the staff to prevent potential injuries or\ndeath in some cases. However, these behaviours of risk events are heterogeneous\nand infrequent in comparison to normal events. Moreover, analyzing raw videos\ncan also raise privacy concerns. In this paper, we present two novel\nprivacy-protecting video-based anomaly detection approaches to detect\nbehaviours of risks in people with dementia. We either extracted body pose\ninformation as skeletons and use semantic segmentation masks to replace\nmultiple humans in the scene with their semantic boundaries. Our work differs\nfrom most existing approaches for video anomaly detection that focus on\nappearance-based features, which can put the privacy of a person at risk and is\nalso susceptible to pixel-based noise, including illumination and viewing\ndirection. We used anonymized videos of normal activities to train customized\nspatio-temporal convolutional autoencoders and identify behaviours of risk as\nanomalies. We show our results on a real-world study conducted in a dementia\ncare unit with patients with dementia, containing approximately 21 hours of\nnormal activities data for training and 9 hours of data containing normal and\nbehaviours of risk events for testing. We compared our approaches with the\noriginal RGB videos and obtained an equivalent area under the receiver\noperating characteristic curve performance of 0.807 for the skeleton-based\napproach and 0.823 for the segmentation mask-based approach. This is one of the\nfirst studies to incorporate privacy for the detection of behaviours of risks\nin people with dementia.",
    "descriptor": "",
    "authors": [
      "Pratik K. Mishra",
      "Andrea Iaboni",
      "Bing Ye",
      "Kristine Newman",
      "Alex Mihailidis",
      "Shehroz S. Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10682"
  },
  {
    "id": "arXiv:2212.10687",
    "title": "Influence of collaborative customer service by service robots and clerks  in bakery stores",
    "abstract": "In recent years, various service robots have been introduced in stores as\nrecommendation systems. Previous studies attempted to increase the influence of\nthese robots by improving their social acceptance and trust. However, when such\nservice robots recommend a product to customers in real environments, the\neffect on the customers is influenced not only by the robot itself, but also by\nthe social influence of the surrounding people such as store clerks. Therefore,\nleveraging the social influence of the clerks may increase the influence of the\nrobots on the customers. Hence, we compared the influence of robots with and\nwithout collaborative customer service between the robots and clerks in two\nbakery stores. The experimental results showed that collaborative customer\nservice increased the purchase rate of the recommended bread and improved the\nimpression regarding the robot and store experience of the customers. Because\nthe results also showed that the workload required for the clerks to\ncollaborate with the robot was not high, this study suggests that all stores\nwith service robots may show high effectiveness in introducing collaborative\ncustomer service.",
    "descriptor": "",
    "authors": [
      "Yuki Okafuji",
      "Sichao Song",
      "Jun Baba",
      "Yuichiro Yoshikawa",
      "Hiroshi Ishiguro"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.10687"
  },
  {
    "id": "arXiv:2212.10688",
    "title": "Local Differential Privacy Image Generation Using Flow-based Deep  Generative Models",
    "abstract": "Diagnostic radiologists need artificial intelligence (AI) for medical\nimaging, but access to medical images required for training in AI has become\nincreasingly restrictive. To release and use medical images, we need an\nalgorithm that can simultaneously protect privacy and preserve pathologies in\nmedical images. To develop such an algorithm, here, we propose DP-GLOW, a\nhybrid of a local differential privacy (LDP) algorithm and one of the\nflow-based deep generative models (GLOW). By applying a GLOW model, we\ndisentangle the pixelwise correlation of images, which makes it difficult to\nprotect privacy with straightforward LDP algorithms for images. Specifically,\nwe map images onto the latent vector of the GLOW model, each element of which\nfollows an independent normal distribution, and we apply the Laplace mechanism\nto the latent vector. Moreover, we applied DP-GLOW to chest X-ray images to\ngenerate LDP images while preserving pathologies.",
    "descriptor": "",
    "authors": [
      "Hisaichi Shibata",
      "Shouhei Hanaoka",
      "Yang Cao",
      "Masatoshi Yoshikawa",
      "Tomomi Takenaga",
      "Yukihiro Nomura",
      "Naoto Hayashi",
      "Osamu Abe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.10688"
  },
  {
    "id": "arXiv:2212.10690",
    "title": "METEOR Guided Divergence for Video Captioning",
    "abstract": "Automatic video captioning aims for a holistic visual scene understanding. It\nrequires a mechanism for capturing temporal context in video frames and the\nability to comprehend the actions and associations of objects in a given\ntimeframe. Such a system should additionally learn to abstract video sequences\ninto sensible representations as well as to generate natural written language.\nWhile the majority of captioning models focus solely on the visual inputs,\nlittle attention has been paid to the audiovisual modality. To tackle this\nissue, we propose a novel two-fold approach. First, we implement a\nreward-guided KL Divergence to train a video captioning model which is\nresilient towards token permutations. Second, we utilise a Bi-Modal\nHierarchical Reinforcement Learning (BMHRL) Transformer architecture to capture\nlong-term temporal dependencies of the input data as a foundation for our\nhierarchical captioning module. Using our BMHRL, we show the suitability of the\nHRL agent in the generation of content-complete and grammatically sound\nsentences by achieving $4.91$, $2.23$, and $10.80$ in BLEU3, BLEU4, and METEOR\nscores, respectively on the ActivityNet Captions dataset. Finally, we make our\nBMHRL framework and trained models publicly available for users and developers\nat https://github.com/d-rothen/bmhrl.",
    "descriptor": "",
    "authors": [
      "Daniel Lukas Rothenpieler",
      "Shahin Amiriparian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10690"
  },
  {
    "id": "arXiv:2212.10692",
    "title": "Generation-Augmented Query Expansion For Code Retrieval",
    "abstract": "Pre-trained language models have achieved promising success in code retrieval\ntasks, where a natural language documentation query is given to find the most\nrelevant existing code snippet. However, existing models focus only on\noptimizing the documentation code pairs by embedding them into latent space,\nwithout the association of external knowledge. In this paper, we propose a\ngeneration-augmented query expansion framework. Inspired by the human retrieval\nprocess - sketching an answer before searching, in this work, we utilize the\npowerful code generation model to benefit the code retrieval task.\nSpecifically, we demonstrate that rather than merely retrieving the target code\nsnippet according to the documentation query, it would be helpful to augment\nthe documentation query with its generation counterpart - generated code\nsnippets from the code generation model. To the best of our knowledge, this is\nthe first attempt that leverages the code generation model to enhance the code\nretrieval task. We achieve new state-of-the-art results on the CodeSearchNet\nbenchmark and surpass the baselines significantly.",
    "descriptor": "",
    "authors": [
      "Dong Li",
      "Yelong Shen",
      "Ruoming Jin",
      "Yi Mao",
      "Kuan Wang",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10692"
  },
  {
    "id": "arXiv:2212.10693",
    "title": "Requirements Engineering for Artificial Intelligence Systems: A  Systematic Mapping Study",
    "abstract": "[Context] In traditional software systems, Requirements Engineering (RE)\nactivities are well-established and researched. However, building Artificial\nIntelligence (AI) based software with limited or no insight into the system's\ninner workings poses significant new challenges to RE. Existing literature has\nfocused on using AI to manage RE activities, with limited research on RE for AI\n(RE4AI). [Objective] This paper investigates current approaches for specifying\nrequirements for AI systems, identifies available frameworks, methodologies,\ntools, and techniques used to model requirements, and finds existing challenges\nand limitations. [Method] We performed a systematic mapping study to find\npapers on current RE4AI approaches. We identified 43 primary studies and\nanalysed the existing methodologies, models, tools, and techniques used to\nspecify and model requirements in real-world scenarios. [Results] We found\nseveral challenges and limitations of existing RE4AI practices. The findings\nhighlighted that current RE applications were not adequately adaptable for\nbuilding AI systems and emphasised the need to provide new techniques and tools\nto support RE4AI. [Conclusion] Our results showed that most of the empirical\nstudies on RE4AI focused on autonomous, self-driving vehicles and managing data\nrequirements, and areas such as ethics, trust, and explainability need further\nresearch.",
    "descriptor": "",
    "authors": [
      "Khlood Ahmad",
      "Mohamed Abdelrazek",
      "Chetan Arora",
      "Muneera Bano",
      "John Grundy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.10693"
  },
  {
    "id": "arXiv:2212.10696",
    "title": "Analyzing Semantic Faithfulness of Language Models via Input  Intervention on Conversational Question Answering",
    "abstract": "Transformer-based language models have been shown to be highly effective for\nseveral NLP tasks. In this paper, we consider three transformer models, BERT,\nRoBERTa, and XLNet, in both small and large version, and investigate how\nfaithful their representations are with respect to the semantic content of\ntexts. We formalize a notion of semantic faithfulness, in which the semantic\ncontent of a text should causally figure in a model's inferences in question\nanswering. We then test this notion by observing a model's behavior on\nanswering questions about a story after performing two novel semantic\ninterventions -- deletion intervention and negation intervention. While\ntransformer models achieve high performance on standard question answering\ntasks, we show that they fail to be semantically faithful once we perform these\ninterventions for a significant number of cases (~50% for deletion\nintervention, and ~20% drop in accuracy for negation intervention). We then\npropose an intervention-based training regime that can mitigate the undesirable\neffects for deletion intervention by a significant margin (from ~50% to ~6%).\nWe analyze the inner-workings of the models to better understand the\neffectiveness of intervention-based training for deletion intervention. But we\nshow that this training does not attenuate other aspects of semantic\nunfaithfulness such as the models' inability to deal with negation intervention\nor to capture the predicate-argument structure of texts. We also test\nInstructGPT, via prompting, for its ability to handle the two interventions and\nto capture predicate-argument structure. While InstructGPT models do achieve\nvery high performance on predicate-argument structure task, they fail to\nrespond adequately to our deletion and negation interventions.",
    "descriptor": "\nComments: 27 pages, 4 figures\n",
    "authors": [
      "Akshay Chaturvedi",
      "Swarnadeep Bhar",
      "Soumadeep Saha",
      "Utpal Garain",
      "Nicholas Asher"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10696"
  },
  {
    "id": "arXiv:2212.10699",
    "title": "PaletteNeRF: Palette-based Appearance Editing of Neural Radiance Fields",
    "abstract": "Recent advances in neural radiance fields have enabled the high-fidelity 3D\nreconstruction of complex scenes for novel view synthesis. However, it remains\nunderexplored how the appearance of such representations can be efficiently\nedited while maintaining photorealism.\nIn this work, we present PaletteNeRF, a novel method for photorealistic\nappearance editing of neural radiance fields (NeRF) based on 3D color\ndecomposition. Our method decomposes the appearance of each 3D point into a\nlinear combination of palette-based bases (i.e., 3D segmentations defined by a\ngroup of NeRF-type functions) that are shared across the scene. While our\npalette-based bases are view-independent, we also predict a view-dependent\nfunction to capture the color residual (e.g., specular shading). During\ntraining, we jointly optimize the basis functions and the color palettes, and\nwe also introduce novel regularizers to encourage the spatial coherence of the\ndecomposition.\nOur method allows users to efficiently edit the appearance of the 3D scene by\nmodifying the color palettes. We also extend our framework with compressed\nsemantic features for semantic-aware appearance editing. We demonstrate that\nour technique is superior to baseline methods both quantitatively and\nqualitatively for appearance editing of complex real-world scenes.",
    "descriptor": "",
    "authors": [
      "Zhengfei Kuang",
      "Fujun Luan",
      "Sai Bi",
      "Zhixin Shu",
      "Gordon Wetzstein",
      "Kalyan Sunkavalli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2212.10699"
  },
  {
    "id": "arXiv:2212.10701",
    "title": "A Non-Asymptotic Analysis of Oversmoothing in Graph Neural Networks",
    "abstract": "A central challenge of building more powerful Graph Neural Networks (GNNs) is\nthe oversmoothing phenomenon, where increasing the network depth leads to\nhomogeneous node representations and thus worse classification performance.\nWhile previous works have only demonstrated that oversmoothing is inevitable\nwhen the number of graph convolutions tends to infinity, in this paper, we\nprecisely characterize the mechanism behind the phenomenon via a non-asymptotic\nanalysis. Specifically, we distinguish between two different effects when\napplying graph convolutions -- an undesirable mixing effect that homogenizes\nnode representations in different classes, and a desirable denoising effect\nthat homogenizes node representations in the same class. By quantifying these\ntwo effects on random graphs sampled from the Contextual Stochastic Block Model\n(CSBM), we show that oversmoothing happens once the mixing effect starts to\ndominate the denoising effect, and the number of layers required for this\ntransition is $O(\\log N/\\log (\\log N))$ for sufficiently dense graphs with $N$\nnodes. We also extend our analysis to study the effects of Personalized\nPageRank (PPR) on oversmoothing. Our results suggest that while PPR mitigates\noversmoothing at deeper layers, PPR-based architectures still achieve their\nbest performance at a shallow depth and are outperformed by the graph\nconvolution approach on certain graphs. Finally, we support our theoretical\nresults with numerical experiments, which further suggest that the\noversmoothing phenomenon observed in practice may be exacerbated by the\ndifficulty of optimizing deep GNN models.",
    "descriptor": "",
    "authors": [
      "Xinyi Wu",
      "Zhengdao Chen",
      "William Wang",
      "Ali Jadbabaie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.10701"
  },
  {
    "id": "arXiv:2212.10707",
    "title": "Extractive Text Summarization Using Generalized Additive Models with  Interactions for Sentence Selection",
    "abstract": "Automatic Text Summarization (ATS) is becoming relevant with the growth of\ntextual data; however, with the popularization of public large-scale datasets,\nsome recent machine learning approaches have focused on dense models and\narchitectures that, despite producing notable results, usually turn out in\nmodels difficult to interpret. Given the challenge behind interpretable\nlearning-based text summarization and the importance it may have for evolving\nthe current state of the ATS field, this work studies the application of two\nmodern Generalized Additive Models with interactions, namely Explainable\nBoosting Machine and GAMI-Net, to the extractive summarization problem based on\nlinguistic features and binary classification.",
    "descriptor": "",
    "authors": [
      "Vin\u00edcius Camargo da Silva",
      "Jo\u00e3o Paulo Papa",
      "Kelton Augusto Pontara da Costa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10707"
  },
  {
    "id": "arXiv:2212.10708",
    "title": "Zero-shot Triplet Extraction by Template Infilling",
    "abstract": "Triplet extraction aims to extract entities and their corresponding relations\nin unstructured text. Most existing methods train an extraction model on\nhigh-quality training data, and hence are incapable of extracting relations\nthat were not observed during training. Generalizing the model to unseen\nrelations typically requires fine-tuning on synthetic training data which is\noften noisy and unreliable. In this paper, we argue that reducing triplet\nextraction to a template filling task over a pre-trained language model can\nequip the model with zero-shot learning capabilities and enable it to leverage\nthe implicit knowledge in the language model. Embodying these ideas, we propose\na novel framework, ZETT (ZEro-shot Triplet extraction by Template infilling),\nthat is based on end-to-end generative transformers. Our experiments show that\nwithout any data augmentation or pipeline systems, ZETT can outperform previous\nstate-of-the-art models with 25% less parameters. We further show that ZETT is\nmore robust in detecting entities and can be incorporated with automatically\ngenerated templates for relations.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Bosung Kim",
      "Hayate Iso",
      "Nikita Bhutani",
      "Estevam Hruschka",
      "Ndapa Nakashole"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10708"
  },
  {
    "id": "arXiv:2212.10711",
    "title": "Task Ambiguity in Humans and Language Models",
    "abstract": "Language models have recently achieved strong performance across a wide range\nof NLP benchmarks. However, unlike benchmarks, real world tasks are often\npoorly specified, and agents must deduce the user's intended behavior from a\ncombination of context, instructions, and examples. We investigate how both\nhumans and models behave in the face of such task ambiguity by proposing\nAmbiBench, a new benchmark of six ambiguously-specified classification tasks.\nWe evaluate humans and models on AmbiBench by seeing how well they identify the\nintended task using 1) instructions with varying degrees of ambiguity, and 2)\ndifferent numbers of labeled examples. We find that the combination of model\nscaling (to 175B parameters) and training with human feedback data enables\nmodels to approach or exceed the accuracy of human participants across tasks,\nbut that either one alone is not sufficient. In addition, we show how to\ndramatically improve the accuracy of language models trained without\nlarge-scale human feedback training by finetuning on a small number of\nambiguous in-context examples, providing a promising direction for teaching\nmodels to generalize well in the face of ambiguity.",
    "descriptor": "",
    "authors": [
      "Alex Tamkin",
      "Kunal Handa",
      "Avash Shrestha",
      "Noah Goodman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10711"
  },
  {
    "id": "arXiv:2212.10712",
    "title": "Neighboring state-based RL Exploration",
    "abstract": "Reinforcement Learning is a powerful tool to model decision-making processes.\nHowever, it relies on an exploration-exploitation trade-off that remains an\nopen challenge for many tasks. In this work, we study neighboring state-based,\nmodel-free exploration led by the intuition that, for an early-stage agent,\nconsidering actions derived from a bounded region of nearby states may lead to\nbetter actions when exploring. We propose two algorithms that choose\nexploratory actions based on a survey of nearby states, and find that one of\nour methods, ${\\rho}$-explore, consistently outperforms the Double DQN baseline\nin an discrete environment by 49\\% in terms of Eval Reward Return.",
    "descriptor": "",
    "authors": [
      "Jeffery Cheng",
      "Kevin Li",
      "Justin Lin",
      "Pedro Pachuca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10712"
  },
  {
    "id": "arXiv:2212.10714",
    "title": "Integrating Heterogeneous Domain Information into Relation Extraction: A  Case Study on Drug-Drug Interaction Extraction",
    "abstract": "The development of deep neural networks has improved representation learning\nin various domains, including textual, graph structural, and relational triple\nrepresentations. This development opened the door to new relation extraction\nbeyond the traditional text-oriented relation extraction. However, research on\nthe effectiveness of considering multiple heterogeneous domain information\nsimultaneously is still under exploration, and if a model can take an advantage\nof integrating heterogeneous information, it is expected to exhibit a\nsignificant contribution to many problems in the world. This thesis works on\nDrug-Drug Interactions (DDIs) from the literature as a case study and realizes\nrelation extraction utilizing heterogeneous domain information. First, a deep\nneural relation extraction model is prepared and its attention mechanism is\nanalyzed. Next, a method to combine the drug molecular structure information\nand drug description information to the input sentence information is proposed,\nand the effectiveness of utilizing drug molecular structures and drug\ndescriptions for the relation extraction task is shown. Then, in order to\nfurther exploit the heterogeneous information, drug-related items, such as\nprotein entries, medical terms and pathways are collected from multiple\nexisting databases and a new data set in the form of a knowledge graph (KG) is\nconstructed. A link prediction task on the constructed data set is conducted to\nobtain embedding representations of drugs that contain the heterogeneous domain\ninformation. Finally, a method that integrates the input sentence information\nand the heterogeneous KG information is proposed. The proposed model is trained\nand evaluated on a widely used data set, and as a result, it is shown that\nutilizing heterogeneous domain information significantly improves the\nperformance of relation extraction from the literature.",
    "descriptor": "\nComments: PhD Thesis\n",
    "authors": [
      "Masaki Asada"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10714"
  },
  {
    "id": "arXiv:2212.10717",
    "title": "Hidden Poison: Machine Unlearning Enables Camouflaged Poisoning Attacks",
    "abstract": "We introduce camouflaged data poisoning attacks, a new attack vector that\narises in the context of machine unlearning and other settings when model\nretraining may be induced. An adversary first adds a few carefully crafted\npoints to the training dataset such that the impact on the model's predictions\nis minimal. The adversary subsequently triggers a request to remove a subset of\nthe introduced points at which point the attack is unleashed and the model's\npredictions are negatively affected. In particular, we consider clean-label\ntargeted attacks (in which the goal is to cause the model to misclassify a\nspecific test point) on datasets including CIFAR-10, Imagenette, and Imagewoof.\nThis attack is realized by constructing camouflage datapoints that mask the\neffect of a poisoned dataset.",
    "descriptor": "",
    "authors": [
      "Jimmy Z. Di",
      "Jack Douglas",
      "Jayadev Acharya",
      "Gautam Kamath",
      "Ayush Sekhari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.10717"
  },
  {
    "id": "arXiv:2212.10718",
    "title": "Interpretability and causal discovery of the machine learning models to  predict the production of CBM wells after hydraulic fracturing",
    "abstract": "Machine learning approaches are widely studied in the production prediction\nof CBM wells after hydraulic fracturing, but merely used in practice due to the\nlow generalization ability and the lack of interpretability. A novel\nmethodology is proposed in this article to discover the latent causality from\nobserved data, which is aimed at finding an indirect way to interpret the\nmachine learning results. Based on the theory of causal discovery, a causal\ngraph is derived with explicit input, output, treatment and confounding\nvariables. Then, SHAP is employed to analyze the influence of the factors on\nthe production capability, which indirectly interprets the machine learning\nmodels. The proposed method can capture the underlying nonlinear relationship\nbetween the factors and the output, which remedies the limitation of the\ntraditional machine learning routines based on the correlation analysis of\nfactors. The experiment on the data of CBM shows that the detected relationship\nbetween the production and the geological/engineering factors by the presented\nmethod, is coincident with the actual physical mechanism. Meanwhile, compared\nwith traditional methods, the interpretable machine learning models have better\nperformance in forecasting production capability, averaging 20% improvement in\naccuracy.",
    "descriptor": "",
    "authors": [
      "Chao Min",
      "Guoquan Wen",
      "Liangjie Gou",
      "Xiaogang Li",
      "Zhaozhong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.10718"
  },
  {
    "id": "arXiv:2212.10719",
    "title": "AEStream: Accelerated event-based processing with coroutines",
    "abstract": "Neuromorphic sensors imitate the sparse and event-based communication seen in\nbiological sensory organs and brains. Today's sensors can emit many millions of\nasynchronous events per second, which is challenging to process on conventional\ncomputers. To avoid bottleneck effects, there is a need to apply and improve\nconcurrent and parallel processing of events.\nWe present AEStream: a library to efficiently stream asynchronous events from\ninputs to outputs on conventional computers. AEStream leverages cooperative\nmultitasking primitives known as coroutines to concurrently process individual\nevents, which dramatically simplifies the integration with event-based\nperipherals, such as event-based cameras and (neuromorphic) asynchronous\nhardware. We explore the effects of coroutines in concurrent settings by\nbenchmarking them against conventional threading mechanisms, and find that\nAEStream provides at least twice the throughput. We then apply AEStream in a\nreal-time edge detection task on a GPU and demonstrate 1.3 times faster\nprocessing with 5 times fewer memory operations.",
    "descriptor": "\nComments: 7 pages, 6 figures. Submitted to Neuro Inspired Computational Element (NICE) 2023\n",
    "authors": [
      "Jens Egholm Pedersen",
      "J\u00f6rg Conradt"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.10719"
  },
  {
    "id": "arXiv:2212.10720",
    "title": "MoralDial: A Framework to Train and Evaluate Moral Dialogue Systems via  Constructing Moral Discussions",
    "abstract": "Morality in dialogue systems has raised great attention in research recently.\nA moral dialogue system could better connect users and enhance conversation\nengagement by gaining users' trust. In this paper, we propose a framework,\nMoralDial to train and evaluate moral dialogue systems. In our framework, we\nfirst explore the communication mechanisms of morality and resolve expressed\nmorality into four sub-modules. The sub-modules indicate the roadmap for\nbuilding a moral dialogue system. Based on that, we design a simple yet\neffective method: constructing moral discussions from Rules of Thumb (RoTs)\nbetween simulated specific users and the dialogue system. The constructed\ndiscussion consists of expressing, explaining, and revising the moral views in\ndialogue exchanges, which makes conversational models learn morality well in a\nnatural manner. Furthermore, we propose a novel evaluation method in the\nframework. We evaluate the multiple aspects of morality by judging the relation\nbetween dialogue responses and RoTs in discussions, where the multifaceted\nnature of morality is particularly considered. Automatic and manual experiments\ndemonstrate that our framework is promising to train and evaluate moral\ndialogue systems.",
    "descriptor": "",
    "authors": [
      "Hao Sun",
      "Zhexin Zhang",
      "Fei Mi",
      "Yasheng Wang",
      "Wei Liu",
      "Jianwei Cui",
      "Bin Wang",
      "Qun Liu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10720"
  },
  {
    "id": "arXiv:2212.10721",
    "title": "Every Bit Counts: A New Version of Non-binary VT Codes with More  Efficient Encoder",
    "abstract": "In this work, we present a new version of non-binary VT codes that are\ncapable of correcting a single deletion or single insertion. Moreover, we\nprovide the first known linear time algorithms that encode user messages into\nthese codes of length n over the $q$-ary alphabet for $q\\ge 2$ with at most\n$\\ceil{\\log_q n} + 1$ redundant symbols, while the optimal redundancy required\nis at least $\\log_q n + \\log_q (q - 1)$ symbols. Our designed encoder reduces\nthe redundancy of the best-known encoder of Tenengolts (1984) by at least\n$2+\\log_q(3)$ redundant symbols, or equivalently $2\\log_2 q+3$ redundant bits.",
    "descriptor": "",
    "authors": [
      "Tuan Thanh Nguyen",
      "Kui Cai",
      "Paul H. Siegel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2212.10721"
  },
  {
    "id": "arXiv:2212.10722",
    "title": "Tracing and Removing Data Errors in Natural Language Generation Datasets",
    "abstract": "Recent work has identified noisy and misannotated data as a core cause of\nhallucinations and unfaithful outputs in Natural Language Generation (NLG)\ntasks. Consequently, identifying and removing these examples is a key open\nchallenge in creating reliable NLG systems. In this work, we introduce a\nframework to identify and remove low-quality training instances that lead to\nundesirable outputs, such as faithfulness errors in text summarization. We show\nthat existing approaches for error tracing, such as gradient-based influence\nmeasures, do not perform reliably for detecting faithfulness errors in\nsummarization. We overcome the drawbacks of existing error tracing methods\nthrough a new, contrast-based estimate that compares undesired generations to\nhuman-corrected outputs. Our proposed method can achieve a mean average\nprecision of 0.91 across synthetic tasks with known ground truth and can\nachieve a two-fold reduction in hallucinations on a real entity hallucination\nevaluation on the NYT dataset.",
    "descriptor": "",
    "authors": [
      "Faisal Ladhak",
      "Esin Durmus",
      "Tatsunori Hashimoto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10722"
  },
  {
    "id": "arXiv:2212.10723",
    "title": "Comparison and Evaluation of Methods for a Predict+Optimize Problem in  Renewable Energy",
    "abstract": "Algorithms that involve both forecasting and optimization are at the core of\nsolutions to many difficult real-world problems, such as in supply chains\n(inventory optimization), traffic, and in the transition towards carbon-free\nenergy generation in battery/load/production scheduling in sustainable energy\nsystems. Typically, in these scenarios we want to solve an optimization problem\nthat depends on unknown future values, which therefore need to be forecast. As\nboth forecasting and optimization are difficult problems in their own right,\nrelatively few research has been done in this area. This paper presents the\nfindings of the ``IEEE-CIS Technical Challenge on Predict+Optimize for\nRenewable Energy Scheduling,\" held in 2021. We present a comparison and\nevaluation of the seven highest-ranked solutions in the competition, to provide\nresearchers with a benchmark problem and to establish the state of the art for\nthis benchmark, with the aim to foster and facilitate research in this area.\nThe competition used data from the Monash Microgrid, as well as weather data\nand energy market data. It then focused on two main challenges: forecasting\nrenewable energy production and demand, and obtaining an optimal schedule for\nthe activities (lectures) and on-site batteries that lead to the lowest cost of\nenergy. The most accurate forecasts were obtained by gradient-boosted tree and\nrandom forest models, and optimization was mostly performed using mixed integer\nlinear and quadratic programming. The winning method predicted different\nscenarios and optimized over all scenarios jointly using a sample average\napproximation method.",
    "descriptor": "",
    "authors": [
      "Christoph Bergmeir",
      "Frits de Nijs",
      "Abishek Sriramulu",
      "Mahdi Abolghasemi",
      "Richard Bean",
      "John Betts",
      "Quang Bui",
      "Nam Trong Dinh",
      "Nils Einecke",
      "Rasul Esmaeilbeigi",
      "Scott Ferraro",
      "Priya Galketiya",
      "Evgenii Genov",
      "Robert Glasgow",
      "Rakshitha Godahewa",
      "Yanfei Kang",
      "Steffen Limmer",
      "Luis Magdalena",
      "Pablo Montero-Manso",
      "Daniel Peralta",
      "Yogesh Pipada Sunil Kumar",
      "Alejandro Rosales-P\u00e9rez",
      "Julian Ruddick",
      "Akylas Stratigakos",
      "Peter Stuckey",
      "Guido Tack",
      "Isaac Triguero",
      "Rui Yuan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10723"
  },
  {
    "id": "arXiv:2212.10726",
    "title": "Beyond Contrastive Learning: A Variational Generative Model for  Multilingual Retrieval",
    "abstract": "Contrastive learning has been successfully used for retrieval of semantically\naligned sentences, but it often requires large batch sizes or careful\nengineering to work well. In this paper, we instead propose a generative model\nfor learning multilingual text embeddings which can be used to retrieve or\nscore sentence pairs. Our model operates on parallel data in $N$ languages and,\nthrough an approximation we introduce, efficiently encourages source separation\nin this multilingual setting, separating semantic information that is shared\nbetween translations from stylistic or language-specific variation. We show\ncareful large-scale comparisons between contrastive and generation-based\napproaches for learning multilingual text embeddings, a comparison that has not\nbeen done to the best of our knowledge despite the popularity of these\napproaches. We evaluate this method on a suite of tasks including semantic\nsimilarity, bitext mining, and cross-lingual question retrieval -- the last of\nwhich we introduce in this paper. Overall, our Variational Multilingual\nSource-Separation Transformer (VMSST) model outperforms both a strong\ncontrastive and generative baseline on these tasks.",
    "descriptor": "",
    "authors": [
      "John Wieting",
      "Jonathan H. Clark",
      "William W. Cohen",
      "Graham Neubig",
      "Taylor Berg-Kirkpatrick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10726"
  },
  {
    "id": "arXiv:2212.10728",
    "title": "Spoken Language Understanding for Conversational AI: Recent Advances and  Future Direction",
    "abstract": "When a human communicates with a machine using natural language on the web\nand online, how can it understand the human's intention and semantic context of\ntheir talk? This is an important AI task as it enables the machine to construct\na sensible answer or perform a useful action for the human. Meaning is\nrepresented at the sentence level, identification of which is known as intent\ndetection, and at the word level, a labelling task called slot filling. This\ndual-level joint task requires innovative thinking about natural language and\ndeep learning network design, and as a result, many approaches and models have\nbeen proposed and applied.\nThis tutorial will discuss how the joint task is set up and introduce Spoken\nLanguage Understanding/Natural Language Understanding (SLU/NLU) with Deep\nLearning techniques. We will cover the datasets, experiments and metrics used\nin the field. We will describe how the machine uses the latest NLP and Deep\nLearning techniques to address the joint task, including recurrent and\nattention-based Transformer networks and pre-trained models (e.g. BERT). We\nwill then look in detail at a network that allows the two levels of the task,\nintent classification and slot filling, to interact to boost performance\nexplicitly. We will do a code demonstration of a Python notebook for this model\nand attendees will have an opportunity to watch coding demo tasks on this joint\nNLU to further their understanding.",
    "descriptor": "\nComments: Accepted by TheWebConf2023. arXiv admin note: substantial text overlap with arXiv:2101.08091\n",
    "authors": [
      "Soyeon Caren Han",
      "Siqu Long",
      "Henry Weld",
      "Josiah Poon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10728"
  },
  {
    "id": "arXiv:2212.10729",
    "title": "UnICLAM:Contrastive Representation Learning with Adversarial Masking for  Unified and Interpretable Medical Vision Question Answering",
    "abstract": "Medical Visual Question Answering (Medical-VQA) aims to answer clinical\nquestions regarding radiology images, assisting doctors with decision-making\noptions. Nevertheless, current Medical-VQA models learn cross-modal\nrepresentations through residing vision and texture encoders in dual separate\nspaces, which lead to indirect semantic alignment. In this paper, we propose\nUnICLAM, a Unified and Interpretable Medical-VQA model through Contrastive\nRepresentation Learning with Adversarial Masking. Specifically, to learn an\naligned image-text representation, we first establish a unified dual-stream\npre-training structure with the gradually soft-parameter sharing strategy.\nTechnically, the proposed strategy learns a constraint for the vision and\ntexture encoders to be close in a same space, which is gradually loosened as\nthe higher number of layers. Moreover, for grasping the semantic\nrepresentation, we extend the unified Adversarial Masking data augmentation\nstrategy to the contrastive representation learning of vision and text in a\nunified manner, alleviating the meaningless of the commonly used random mask.\nConcretely, while the encoder training minimizes the distance between the\noriginal feature and the masking feature, the adversarial masking model keeps\nadversarial learning to conversely maximize the distance. Furthermore, we also\nintuitively take a further exploration of the unified adversarial masking\nstrategy, which improves the potential ante-hoc interpretability with\nremarkable performance and efficiency. Experimental results on VQA-RAD and\nSLAKE public benchmarks demonstrate that UnICLAM outperforms the existing 11\nstate-of-the-art Medical-VQA models. More importantly, we make an additional\ndiscussion about the performance of UnICLAM in diagnosing heart failure,\nverifying that UnICLAM exhibits superior few-shot adaption performance in\npractical disease diagnosis.",
    "descriptor": "",
    "authors": [
      "Chenlu Zhan",
      "Peng Peng",
      "Hongsen Wang",
      "Tao Chen",
      "Hongwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10729"
  },
  {
    "id": "arXiv:2212.10730",
    "title": "Real-time Path Planning of Driver-less Mining Trains with Time-dependent  Physical Constraints",
    "abstract": "While the increased automation levels of production and operation equipment\nhave led to improved productivity of mining activity in open pit mines, the\ncapacity of mine transport system become a bottleneck. The optimization of mine\ntransport system is of great practical significance to reduce the production\nand operation cost and improve the production and organizational efficiency of\nmines. In this paper we first formulate a multi-objective optimisation problem\nfor mine railway scheduling by introducing a set of mathematical constraints.\nAs the problem is NP-hard, we then devise a Mixed Integer Programming based\nsolution to solve this problem, and develop an online framework accordingly. We\nfinally conduct test cases to evaluate the performance of the proposed\nsolution. Experimental results demonstrate that the proposed solution is\nefficient and able to generate train schedule in a real-time manner.",
    "descriptor": "",
    "authors": [
      "Xiaojiang Ren",
      "Hui Guo",
      "Changxin Gao",
      "Sheng Kai",
      "Guoqiang Ma"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.10730"
  },
  {
    "id": "arXiv:2212.10733",
    "title": "Scalable Hybrid Learning Techniques for Scientific Data Compression",
    "abstract": "Data compression is becoming critical for storing scientific data because\nmany scientific applications need to store large amounts of data and post\nprocess this data for scientific discovery. Unlike image and video compression\nalgorithms that limit errors to primary data, scientists require compression\ntechniques that accurately preserve derived quantities of interest (QoIs). This\npaper presents a physics-informed compression technique implemented as an\nend-to-end, scalable, GPU-based pipeline for data compression that addresses\nthis requirement. Our hybrid compression technique combines machine learning\ntechniques and standard compression methods. Specifically, we combine an\nautoencoder, an error-bounded lossy compressor to provide guarantees on raw\ndata error, and a constraint satisfaction post-processing step to preserve the\nQoIs within a minimal error (generally less than floating point error).\nThe effectiveness of the data compression pipeline is demonstrated by\ncompressing nuclear fusion simulation data generated by a large-scale fusion\ncode, XGC, which produces hundreds of terabytes of data in a single day. Our\napproach works within the ADIOS framework and results in compression by a\nfactor of more than 150 while requiring only a few percent of the computational\nresources necessary for generating the data, making the overall approach highly\neffective for practical scenarios.",
    "descriptor": "",
    "authors": [
      "Tania Banerjee",
      "Jong Choi",
      "Jaemoon Lee",
      "Qian Gong",
      "Jieyang Chen",
      "Scott Klasky",
      "Anand Rangarajan",
      "Sanjay Ranka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10733"
  },
  {
    "id": "arXiv:2212.10735",
    "title": "NADBenchmarks -- a compilation of Benchmark Datasets for Machine  Learning Tasks related to Natural Disasters",
    "abstract": "Climate change has increased the intensity, frequency, and duration of\nextreme weather events and natural disasters across the world. While the\nincreased data on natural disasters improves the scope of machine learning (ML)\nin this field, progress is relatively slow. One bottleneck is the lack of\nbenchmark datasets that would allow ML researchers to quantify their progress\nagainst a standard metric. The objective of this short paper is to explore the\nstate of benchmark datasets for ML tasks related to natural disasters,\ncategorizing them according to the disaster management cycle. We compile a list\nof existing benchmark datasets introduced in the past five years. We propose a\nweb platform - NADBenchmarks - where researchers can search for benchmark\ndatasets for natural disasters, and we develop a preliminary version of such a\nplatform using our compiled list. This paper is intended to aid researchers in\nfinding benchmark datasets to train their ML models on, and provide general\ndirections for topics where they can contribute new benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Adiba Mahbub Proma",
      "Md Saiful Islam",
      "Stela Ciko",
      "Raiyan Abdul Baten",
      "Ehsan Hoque"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10735"
  },
  {
    "id": "arXiv:2212.10737",
    "title": "Driving Style Recognition at First Impression for Online Trajectory  Prediction",
    "abstract": "This paper proposes a new driving style recognition approach that allows\nautonomous vehicles (AVs) to perform trajectory predictions for surrounding\nvehicles with minimal data. Toward that end, we use a hybrid of offline and\nonline methods in the proposed approach. We first learn typical driving styles\nwith PCA and K-means algorithms in the offline part. After that, local\nMaximum-Likelihood techniques are used to perform online driving style\nrecognition. We benchmarked our method on a real driving dataset against other\nmethods in terms of the RMSE value of the predicted trajectory and the observed\ntrajectory over a 5s duration. The proposed approach can reduce trajectory\nprediction error by up to 37.7\\% compared to using the parameters from other\nliterature and up to 24.4\\% compared to not performing driving style\nrecognition.",
    "descriptor": "",
    "authors": [
      "Tu Xu",
      "Kan Wu",
      "Yongdong Zhu",
      "Wei Ji"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.10737"
  },
  {
    "id": "arXiv:2212.10740",
    "title": "ToL: A Tensor of List-Based Unified Computation Model",
    "abstract": "Previous computation models either have equivalent abilities in representing\nall computations but fail to provide primitive operators for programming\ncomplex algorithms or lack generalized expression ability to represent\nnewly-added computations. This article presents a unified computation model\nwith generalized expression ability and a concise set of primitive operators\nfor programming high-level algorithms. We propose a unified data abstraction --\nTensor of List, and offer a unified computation model based on Tensor of List,\nwhich we call the ToL model (in short, ToL). ToL introduces five atomic\ncomputations that can represent any elementary computation by finite\ncomposition, ensured with strict formal proof. Based on ToL, we design a\npure-functional language -- ToLang. ToLang provides a concise set of primitive\noperators that can be used to program complex big data and AI algorithms. Our\nevaluations show ToL has generalized expression ability and a built-in\nperformance indicator, born with a strictly defined computation metric --\nelementary operation count (EOPs), consistent with FLOPs within a small error\nrange.",
    "descriptor": "",
    "authors": [
      "Hongxiao Li",
      "Wanling Gao",
      "Lei Wang",
      "Jianfeng Zhan"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computational Complexity (cs.CC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10740"
  },
  {
    "id": "arXiv:2212.10744",
    "title": "An Audio-Visual Speech Separation Model Inspired by  Cortico-Thalamo-Cortical Circuits",
    "abstract": "Audio-visual approaches involving visual inputs have laid the foundation for\nrecent progress in speech separation. However, the optimization of the\nconcurrent usage of auditory and visual inputs is still an active research\narea. Inspired by the cortico-thalamo-cortical circuit, in which the sensory\nprocessing mechanisms of different modalities modulate one another via the\nnon-lemniscal sensory thalamus, we propose a novel cortico-thalamo-cortical\nneural network (CTCNet) for audio-visual speech separation (AVSS). First, the\nCTCNet learns hierarchical auditory and visual representations in a bottom-up\nmanner in separate auditory and visual subnetworks, mimicking the functions of\nthe auditory and visual cortical areas. Then, inspired by the large number of\nconnections between cortical regions and the thalamus, the model fuses the\nauditory and visual information in a thalamic subnetwork through top-down\nconnections. Finally, the model transmits this fused information back to the\nauditory and visual subnetworks, and the above process is repeated several\ntimes. The results of experiments on three speech separation benchmark datasets\nshow that CTCNet remarkably outperforms existing AVSS methods with\nconsiderablely fewer parameters. These results suggest that mimicking the\nanatomical connectome of the mammalian brain has great potential for advancing\nthe development of deep neural networks. Project repo is\nhttps://github.com/JusperLee/CTCNet.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Kai Li",
      "Fenghua Xie",
      "Hang Chen",
      "Kexin Yuan",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10744"
  },
  {
    "id": "arXiv:2212.10746",
    "title": "SLGTformer: An Attention-Based Approach to Sign Language Recognition",
    "abstract": "Sign language is the preferred method of communication of deaf or mute\npeople, but similar to any language, it is difficult to learn and represents a\nsignificant barrier for those who are hard of hearing or unable to speak. A\nperson's entire frontal appearance dictates and conveys specific meaning.\nHowever, this frontal appearance can be quantified as a temporal sequence of\nhuman body pose, leading to Sign Language Recognition through the learning of\nspatiotemporal dynamics of skeleton keypoints. I propose a novel,\nattention-based approach to Sign Language Recognition exclusively built upon\ndecoupled graph and temporal self-attention: the Sign Language Graph Time\nTransformer (SLGTformer). SLGTformer first deconstructs spatiotemporal pose\nsequences separately into spatial graphs and temporal windows. SLGTformer then\nleverages novel Learnable Graph Relative Positional Encodings (LGRPE) to guide\nspatial self-attention with the graph neighborhood context of the human\nskeleton. By modeling the temporal dimension as intra- and inter-window\ndynamics, I introduce Temporal Twin Self-Attention (TTSA) as the combination of\nlocally-grouped temporal attention (LTA) and global sub-sampled temporal\nattention (GSTA). I demonstrate the effectiveness of SLGTformer on the\nWorld-Level American Sign Language (WLASL) dataset, achieving state-of-the-art\nperformance with an ensemble-free approach on the keypoint modality.",
    "descriptor": "\nComments: 12 pages, 3 figures, The code is available at \\url{this https URL}\n",
    "authors": [
      "Neil Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10746"
  },
  {
    "id": "arXiv:2212.10747",
    "title": "Performance Analysis of LOS THz Systems under Misalignment and  Deterministic Fading",
    "abstract": "Line-of-sight (LOS) wireless communication at terahertz (THz) frequency bands\nis envisioned to play a major role in defining next-generation wireless\ntechnologies. This work analyzes the performance of a potential LOS THz system\nexperiencing propagation loss and misaligned antenna beams. The THz channel\nparticularities are discussed in terms of deterministic path loss, molecular\nabsorption effect and stochastic fading due to antenna pointing errors.\nAssuming phase shift keying (PSK) modulation schemes, simplified analytical\nexpressions are approximated for computing symbol error rate (SER) of the\nproposed THz system. Monte Carlo simulations are applied to verify theoretical\nmodel accuracy over various transmission distances and misalignment scenarios.\nThe derived SER formulas match simulation results for Signal-to-noise ratio\n(SNR) above 35 dB at transmission distance up to 100 m and antenna displacement\njitter variance of 0.05 $m^2$. In general, the theoretical model mismatch does\nnot exceed 2 dB for lower SNR levels.",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Rayyan Abdalla",
      "A.Brinton Cooper III"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.10747"
  },
  {
    "id": "arXiv:2212.10748",
    "title": "The Internet of Senses: Building on Semantic Communications and Edge  Intelligence",
    "abstract": "The Internet of Senses (IoS) holds the promise of flawless telepresence-style\ncommunication for all human `receptors' and therefore blurs the difference of\nvirtual and real environments. We commence by highlighting the compelling use\ncases empowered by the IoS and also the key network requirements. We then\nelaborate on how the emerging semantic communications and Artificial\nIntelligence (AI)/Machine Learning (ML) paradigms along with 6G technologies\nmay satisfy the requirements of IoS use cases. On one hand, semantic\ncommunications can be applied for extracting meaningful and significant\ninformation and hence efficiently exploit the resources and for harnessing a\npriori information at the receiver to satisfy IoS requirements. On the other\nhand, AI/ML facilitates frugal network resource management by making use of the\nenormous amount of data generated in IoS edge nodes and devices, as well as by\noptimizing the IoS performance via intelligent agents. However, the intelligent\nagents deployed at the edge are not completely aware of each others' decisions\nand the environments of each other, hence they operate in a partially rather\nthan fully observable environment. Therefore, we present a case study of\nPartially Observable Markov Decision Processes (POMDP) for improving the User\nEquipment (UE) throughput and energy consumption, as they are imperative for\nIoS use cases, using Reinforcement Learning for astutely activating and\ndeactivating the component carriers in carrier aggregation. Finally, we outline\nthe challenges and open issues of IoS implementations and employing semantic\ncommunications, edge intelligence as well as learning under partial\nobservability in the IoS context.",
    "descriptor": "",
    "authors": [
      "Roghayeh Joda",
      "Medhat Elsayed",
      "Hatem Abou-zeid",
      "Ramy Atawia",
      "Akram Bin Sediq",
      "Gary Boudreau",
      "Melike Erol-Kantarci",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.10748"
  },
  {
    "id": "arXiv:2212.10750",
    "title": "PropSegmEnt: A Large-Scale Corpus for Proposition-Level Segmentation and  Entailment Recognition",
    "abstract": "The widely studied task of Natural Language Inference (NLI) requires a system\nto recognize whether one piece of text is textually entailed by another, i.e.\nwhether the entirety of its meaning can be inferred from the other. In current\nNLI datasets and models, textual entailment relations are typically defined on\nthe sentence- or paragraph-level. However, even a simple sentence often\ncontains multiple propositions, i.e. distinct units of meaning conveyed by the\nsentence. As these propositions can carry different truth values in the context\nof a given premise, we argue for the need to recognize the textual entailment\nrelation of each proposition in a sentence individually.\nWe propose PropSegmEnt, a corpus of over 35K propositions annotated by expert\nhuman raters. Our dataset structure resembles the tasks of (1) segmenting\nsentences within a document to the set of propositions, and (2) classifying the\nentailment relation of each proposition with respect to a different yet\ntopically-aligned document, i.e. documents describing the same event or entity.\nWe establish strong baselines for the segmentation and entailment tasks.\nThrough case studies on summary hallucination detection and document-level NLI,\nwe demonstrate that our conceptual framework is potentially useful for\nunderstanding and explaining the compositionality of NLI labels.",
    "descriptor": "",
    "authors": [
      "Sihao Chen",
      "Senaka Buthpitiya",
      "Alex Fabrikant",
      "Dan Roth",
      "Tal Schuster"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10750"
  },
  {
    "id": "arXiv:2212.10754",
    "title": "CORRPUS: Detecting Story Inconsistencies via Codex-Bootstrapped  Neurosymbolic Reasoning",
    "abstract": "Story generation and understanding -- as with all NLG/NLU tasks -- has seen a\nsurge in neurosymbolic work. Researchers have recognized that, while large\nlanguage models (LLMs) have tremendous utility, they can be augmented with\nsymbolic means to be even better and to make up for any flaws that the neural\nnetworks might have. However, symbolic methods are extremely costly in terms of\nthe amount of time and expertise needed to create them. In this work, we\ncapitalize on state-of-the-art Code-LLMs, such as Codex, to bootstrap the use\nof symbolic methods for tracking the state of stories and aiding in story\nunderstanding. We show that our CoRRPUS system and abstracted prompting\nprocedures can beat current state-of-the-art structured LLM techniques on\npre-existing story understanding tasks (bAbI task 2 and Re^3) with minimal hand\nengineering. We hope that this work can help highlight the importance of\nsymbolic representations and specialized prompting for LLMs as these models\nrequire some guidance for performing reasoning tasks properly.",
    "descriptor": "",
    "authors": [
      "Yijiang River Dong",
      "Lara J. Martin",
      "Chris Callison-Burch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10754"
  },
  {
    "id": "arXiv:2212.10755",
    "title": "JASMINE: Arabic GPT Models for Few-Shot Learning",
    "abstract": "Task agnostic generative pretraining (GPT) has recently proved promising for\nzero- and few-shot learning, gradually diverting attention from the expensive\nsupervised learning paradigm. Although the community is accumulating knowledge\nas to capabilities of English-language autoregressive models such as GPT-3\nadopting this generative approach, scholarship about these models remains\nacutely Anglocentric. Consequently, the community currently has serious gaps in\nits understanding of this class of models, their potential, and their societal\nimpacts in diverse settings, linguistic traditions, and cultures. To alleviate\nthis issue for Arabic, a collection of diverse languages and language varieties\nwith more than $400$ million population, we introduce JASMINE, a suite of\npowerful Arabic autoregressive Transformer language models ranging in size\nbetween 300 million-13 billion parameters. We pretrain our new models with\nlarge amounts of diverse data (400GB of text) from different Arabic varieties\nand domains. We evaluate JASMINE extensively in both intrinsic and extrinsic\nsettings, using a comprehensive benchmark for zero- and few-shot learning\nacross a wide range of NLP tasks. We also carefully develop and release a novel\nbenchmark for both automated and human evaluation of Arabic autoregressive\nmodels focused at investigating potential social biases, harms, and toxicity in\nthese models. We aim to responsibly release our models with interested\nresearchers, along with code for experimenting with them",
    "descriptor": "",
    "authors": [
      "El Moatez Billah Nagoudi",
      "Muhammad Abdul-Mageed",
      "AbdelRahim Elmadany",
      "Alcides Alcoba Inciarte",
      "Md Tawkat Islam Khondaker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10755"
  },
  {
    "id": "arXiv:2212.10758",
    "title": "ORCA: A Challenging Benchmark for Arabic Language Understanding",
    "abstract": "Due to their crucial role in all NLP, several benchmarks have been proposed\nto evaluate pretrained language models. In spite of these efforts, no public\nbenchmark of diverse nature currently exists for evaluation of Arabic. This\nmakes it challenging to measure progress for both Arabic and multilingual\nlanguage models. This challenge is compounded by the fact that any benchmark\ntargeting Arabic needs to take into account the fact that Arabic is not a\nsingle language but rather a collection of languages and varieties. In this\nwork, we introduce ORCA, a publicly available benchmark for Arabic language\nunderstanding evaluation. ORCA is carefully constructed to cover diverse Arabic\nvarieties and a wide range of challenging Arabic understanding tasks exploiting\n60 different datasets across seven NLU task clusters. To measure current\nprogress in Arabic NLU, we use ORCA to offer a comprehensive comparison between\n18 multilingual and Arabic language models. We also provide a public\nleaderboard with a unified single-number evaluation metric (ORCA score) to\nfacilitate future research.",
    "descriptor": "\nComments: All authors contributed equally\n",
    "authors": [
      "AbdelRahim Elmadany",
      "El Moatez Billah Nagoudi",
      "Muhammad Abdul-Mageed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10758"
  },
  {
    "id": "arXiv:2212.10762",
    "title": "AgAsk: An Agent to Help Answer Farmer's Questions From Scientific  Documents",
    "abstract": "Decisions in agriculture are increasingly data-driven; however, valuable\nagricultural knowledge is often locked away in free-text reports, manuals and\njournal articles. Specialised search systems are needed that can mine\nagricultural information to provide relevant answers to users' questions. This\npaper presents AgAsk -- an agent able to answer natural language agriculture\nquestions by mining scientific documents.\nWe carefully survey and analyse farmers' information needs. On the basis of\nthese needs we release an information retrieval test collection comprising real\nquestions, a large collection of scientific documents split in passages, and\nground truth relevance assessments indicating which passages are relevant to\neach question.\nWe implement and evaluate a number of information retrieval models to answer\nfarmers questions, including two state-of-the-art neural ranking models. We\nshow that neural rankers are highly effective at matching passages to questions\nin this context.\nFinally, we propose a deployment architecture for AgAsk that includes a\nclient based on the Telegram messaging platform and retrieval model deployed on\ncommodity hardware.\nThe test collection we provide is intended to stimulate more research in\nmethods to match natural language to answers in scientific documents. While the\nretrieval models were evaluated in the agriculture domain, they are\ngeneralisable and of interest to others working on similar problems.\nThe test collection is available at:\n\\url{https://github.com/ielab/agvaluate}.",
    "descriptor": "\nComments: 17 pages, submitted to IJDL\n",
    "authors": [
      "Bevan Koopman",
      "Ahmed Mourad",
      "Hang Li",
      "Anton van der Vegt",
      "Shengyao Zhuang",
      "Simon Gibson",
      "Yash Dang",
      "David Lawrence",
      "Guido Zuccon"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.10762"
  },
  {
    "id": "arXiv:2212.10763",
    "title": "Shakebot: A Low-cost, Open-source Shake Table for Ground Motion Seismic  Studies",
    "abstract": "Our earlier research built a virtual shake robot in simulation to study the\ndynamics of precariously balanced rocks (PBR), which are negative indicators of\nearthquakes in nature. The simulation studies need validation through physical\nexperiments. For this purpose, we developed Shakebot, a low-cost (under\n$2,000), open-source shake table to validate simulations of PBR dynamics and\nfacilitate other ground motion experiments. The Shakebot is a custom\none-dimensional prismatic robotic system with perception and motion software\ndeveloped using the Robot Operating System (ROS). We adapted affordable and\nhigh-accuracy components from 3D printers, particularly a closed-loop stepper\nmotor for actuation and a toothed belt for transmission. The stepper motor\nenables the bed to reach a maximum horizontal acceleration of 11.8 m/s^2 (1.2\ng), and velocity of 0.5 m/s, when loaded with a 2 kg scale-model PBR. The\nperception system of the Shakebot consists of an accelerometer and a high\nframe-rate camera. By fusing camera-based displacements with acceleration\nmeasurements, the Shakebot is able to carry out accurate bed velocity\nestimation. The ROS-based perception and motion software simplifies the\ntransition of code from our previous virtual shake robot to the physical\nShakebot. The reuse of the control programs ensures that the implemented ground\nmotions are consistent for both the simulation and physical experiments, which\nis critical to validate our simulation experiments.",
    "descriptor": "",
    "authors": [
      "Zhiang Chen",
      "Devin Keating",
      "Yash Shethwala",
      "Aravind Adhith Pandian Saravanakumaran",
      "Ramon Arrowsmith",
      "Chris Madugo",
      "Albert Kottke",
      "Jnaneshwar Das"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.10763"
  },
  {
    "id": "arXiv:2212.10764",
    "title": "Learning List-Level Domain-Invariant Representations for Ranking",
    "abstract": "Domain adaptation aims to transfer the knowledge acquired by models trained\non (data-rich) source domains to (low-resource) target domains, for which a\npopular method is invariant representation learning. While they have been\nstudied extensively for classification and regression problems, how they apply\nto ranking problems, where the data and metrics have a list structure, is not\nwell understood. Theoretically, we establish a domain adaptation generalization\nbound for ranking under listwise metrics such as MRR and NDCG. The bound\nsuggests an adaptation method via learning list-level domain-invariant feature\nrepresentations, whose benefits are empirically demonstrated by unsupervised\ndomain adaptation experiments on real-world ranking tasks, including passage\nreranking. A key message is that for domain adaptation, the representations\nshould be analyzed at the same level at which the metric is computed, as we\nshow that learning invariant representations at the list level is most\neffective for adaptation on ranking problems.",
    "descriptor": "",
    "authors": [
      "Ruicheng Xian",
      "Honglei Zhuang",
      "Zhen Qin",
      "Hamed Zamani",
      "Jing Lu",
      "Ji Ma",
      "Kai Hui",
      "Han Zhao",
      "Xuanhui Wang",
      "Michael Bendersky"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10764"
  },
  {
    "id": "arXiv:2212.10765",
    "title": "Reward Bonuses with Gain Scheduling Inspired by Iterative Deepening  Search",
    "abstract": "This paper introduces a novel method of adding intrinsic bonuses to\ntask-oriented reward function in order to efficiently facilitate reinforcement\nlearning search. While various bonuses have been designed to date, they are\nanalogous to the depth-first and breadth-first search algorithms in graph\ntheory. This paper, therefore, first designs two bonuses for each of them.\nThen, a heuristic gain scheduling is applied to the designed bonuses, inspired\nby the iterative deepening search, which is known to inherit the advantages of\nthe two search algorithms. The proposed method is expected to allow agent to\nefficiently reach the best solution in deeper states by gradually exploring\nunknown states. In three locomotion tasks with dense rewards and three simple\ntasks with sparse rewards, it is shown that the two types of bonuses contribute\nto the performance improvement of the different tasks complementarily. In\naddition, by combining them with the proposed gain scheduling, all tasks can be\naccomplished with high performance.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Taisuke Kobayashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10765"
  },
  {
    "id": "arXiv:2212.10766",
    "title": "Class Prototype-based Cleaner for Label Noise Learning",
    "abstract": "Semi-supervised learning based methods are current SOTA solutions to the\nnoisy-label learning problem, which rely on learning an unsupervised label\ncleaner first to divide the training samples into a labeled set for clean data\nand an unlabeled set for noise data. Typically, the cleaner is obtained via\nfitting a mixture model to the distribution of per-sample training losses.\nHowever, the modeling procedure is \\emph{class agnostic} and assumes the loss\ndistributions of clean and noise samples are the same across different classes.\nUnfortunately, in practice, such an assumption does not always hold due to the\nvarying learning difficulty of different classes, thus leading to sub-optimal\nlabel noise partition criteria. In this work, we reveal this long-ignored\nproblem and propose a simple yet effective solution, named \\textbf{C}lass\n\\textbf{P}rototype-based label noise \\textbf{C}leaner (\\textbf{CPC}). Unlike\nprevious works treating all the classes equally, CPC fully considers loss\ndistribution heterogeneity and applies class-aware modulation to partition the\nclean and noise data. CPC takes advantage of loss distribution modeling and\nintra-class consistency regularization in feature space simultaneously and thus\ncan better distinguish clean and noise labels. We theoretically justify the\neffectiveness of our method by explaining it from the Expectation-Maximization\n(EM) framework. Extensive experiments are conducted on the noisy-label\nbenchmarks CIFAR-10, CIFAR-100, Clothing1M and WebVision. The results show that\nCPC consistently brings about performance improvement across all benchmarks.\nCodes and pre-trained models will be released at\n\\url{https://github.com/hjjpku/CPC.git}.",
    "descriptor": "",
    "authors": [
      "Jingjia Huang",
      "Yuanqi Chen",
      "Jiashi Feng",
      "Xinglong Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10766"
  },
  {
    "id": "arXiv:2212.10767",
    "title": "How Does Beam Search improve Span-Level Confidence Estimation in  Generative Sequence Labeling?",
    "abstract": "Text-to-text generation models have increasingly become the go-to solution\nfor a wide variety of sequence labeling tasks (e.g., entity extraction and\ndialog slot filling). While most research has focused on the labeling accuracy,\na key aspect -- of vital practical importance -- has slipped through the\ncracks: understanding model confidence. More specifically, we lack a principled\nunderstanding of how to reliably gauge the confidence of a model in its\npredictions for each labeled span. This paper aims to provide some empirical\ninsights on estimating model confidence for generative sequence labeling. Most\nnotably, we find that simply using the decoder's output probabilities is not\nthe best in realizing well-calibrated confidence estimates. As verified over\nsix public datasets of different tasks, we show that our proposed approach --\nwhich leverages statistics from top-$k$ predictions by a beam search --\nsignificantly reduces calibration errors of the predictions of a generative\nsequence labeling model.",
    "descriptor": "",
    "authors": [
      "Kazuma Hashimoto",
      "Iftekhar Naim",
      "Karthik Raman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10767"
  },
  {
    "id": "arXiv:2212.10769",
    "title": "Uncontrolled Lexical Exposure Leads to Overestimation of Compositional  Generalization in Pretrained Models",
    "abstract": "Human linguistic capacity is often characterized by compositionality and the\ngeneralization it enables -- human learners can produce and comprehend novel\ncomplex expressions by composing known parts. Several benchmarks exploit\ndistributional control across training and test to gauge compositional\ngeneralization, where certain lexical items only occur in limited contexts\nduring training. While recent work using these benchmarks suggests that\npretrained models achieve impressive generalization performance, we argue that\nexposure to pretraining data may break the aforementioned distributional\ncontrol. Using the COGS benchmark of Kim and Linzen (2020), we test two\nmodified evaluation setups that control for this issue: (1) substituting\ncontext-controlled lexical items with novel character sequences, and (2)\nsubstituting them with special tokens represented by novel embeddings. We find\nthat both of these setups lead to lower generalization performance in T5\n(Raffel et al., 2020), suggesting that previously reported results have been\noverestimated due to uncontrolled lexical exposure during pretraining. The\nperformance degradation is more extreme with novel embeddings, and the\ndegradation increases with the amount of pretraining data, highlighting an\ninteresting case of inverse scaling.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Najoung Kim",
      "Tal Linzen",
      "Paul Smolensky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10769"
  },
  {
    "id": "arXiv:2212.10770",
    "title": "ImPaKT: A Dataset for Open-Schema Knowledge Base Construction",
    "abstract": "Large language models have ushered in a golden age of semantic parsing. The\nseq2seq paradigm allows for open-schema and abstractive attribute and relation\nextraction given only small amounts of finetuning data. Language model\npretraining has simultaneously enabled great strides in natural language\ninference, reasoning about entailment and implication in free text. These\nadvances motivate us to construct ImPaKT, a dataset for open-schema information\nextraction, consisting of around 2500 text snippets from the C4 corpus, in the\nshopping domain (product buying guides), professionally annotated with\nextracted attributes, types, attribute summaries (attribute schema discovery\nfrom idiosyncratic text), many-to-one relations between compound and atomic\nattributes, and implication relations. We release this data in hope that it\nwill be useful in fine tuning semantic parsers for information extraction and\nknowledge base construction across a variety of domains. We evaluate the power\nof this approach by fine-tuning the open source UL2 language model on a subset\nof the dataset, extracting a set of implication relations from a corpus of\nproduct buying guides, and conducting human evaluations of the resulting\npredictions.",
    "descriptor": "\nComments: 14 pages. Preprint\n",
    "authors": [
      "Luke Vilnis",
      "Zach Fisher",
      "Bhargav Kanagal",
      "Patrick Murray",
      "Sumit Sanghai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10770"
  },
  {
    "id": "arXiv:2212.10772",
    "title": "Low-Light Image and Video Enhancement: A Comprehensive Survey and Beyond",
    "abstract": "This paper presents a comprehensive survey of low-light image and video\nenhancement. We begin with the challenging mixed over-/under-exposed images,\nwhich are under-performed by existing methods. To this end, we propose two\nvariants of the SICE dataset named SICE_Grad and SICE_Mix. Next, we introduce\nNight Wenzhou, a large-scale, high-resolution video dataset, to address the\nissue of the lack of a low-light video dataset that discount the use of\nlow-light image enhancement (LLIE) to videos. The Night Wenzhou dataset is\nchallenging since it consists of fast-moving aerial scenes and streetscapes\nwith varying illuminations and degradation. We conduct extensive key technique\nanalysis and experimental comparisons for representative LLIE approaches using\nthese newly proposed datasets and the current benchmark datasets. Finally, we\naddress unresolved issues and propose future research topics for the LLIE\ncommunity.",
    "descriptor": "\nComments: 10 pages, 8 tables, and 13 figures\n",
    "authors": [
      "Shen Zheng",
      "Yiling Ma",
      "Jinqian Pan",
      "Changjie Lu",
      "Gaurav Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10772"
  },
  {
    "id": "arXiv:2212.10773",
    "title": "MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction  Tuning",
    "abstract": "Instruction tuning, a new learning paradigm that fine-tunes pre-trained\nlanguage models on tasks specified through instructions, has shown promising\nzero-shot performance on various natural language processing tasks. However,\nit's still not explored for vision and multimodal tasks. In this work, we\nintroduce MultiInstruct, the first multimodal instruction tuning benchmark\ndataset that consists of 47 diverse multimodal tasks covering 11 broad\ncategories. Each task is designed at least with 5,000 instances (input-out\npairs) from existing open-source datasets and 5 expert-written instructions. We\ntake OFA as the base pre-trained model for multimodal instruction tuning, and\nto improve its performance, we explore multiple transfer learning strategies to\nleverage the large-scale Natural Instructions dataset. Experimental results\ndemonstrate its strong zero-shot performance on various unseen multimodal tasks\nand the benefit of transfer learning from text-only instructions. We also\ndesign a new evaluation metric: Sensitivity, to evaluate how sensitive the\nmodel is to the variety of instructions. Our results indicate that the model is\nless sensitive to the varying instructions after finetuning on a diverse set of\ntasks and instructions for each task.",
    "descriptor": "\nComments: 16 pages, 10 tables, 4 figures\n",
    "authors": [
      "Zhiyang Xu",
      "Ying Shen",
      "Lifu Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10773"
  },
  {
    "id": "arXiv:2212.10774",
    "title": "Towards Efficient Visual Simplification of Computational Graphs in Deep  Neural Networks",
    "abstract": "A computational graph in a deep neural network (DNN) denotes a specific data\nflow diagram (DFD) composed of many tensors and operators. Existing toolkits\nfor visualizing computational graphs are not applicable when the structure is\nhighly complicated and large-scale (e.g., BERT [1]). To address this problem,\nwe propose leveraging a suite of visual simplification techniques, including a\ncycle-removing method, a module-based edge-pruning algorithm, and an isomorphic\nsubgraph stacking strategy. We design and implement an interactive\nvisualization system that is suitable for computational graphs with up to 10\nthousand elements. Experimental results and usage scenarios demonstrate that\nour tool reduces 60% elements on average and hence enhances the performance for\nrecognizing and diagnosing DNN models. Our contributions are integrated into an\nopen-source DNN visualization toolkit, namely, MindInsight [2].",
    "descriptor": "",
    "authors": [
      "Rusheng Pan",
      "Zhiyong Wang",
      "Yating Wei",
      "Han Gao",
      "Gongchang Ou",
      "Caleb Chen Cao",
      "Jingli Xu",
      "Tong Xu",
      "Wei Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10774"
  },
  {
    "id": "arXiv:2212.10777",
    "title": "Hierarchically branched diffusion models for efficient and interpretable  multi-class conditional generation",
    "abstract": "Diffusion models have achieved justifiable popularity by attaining\nstate-of-the-art performance in generating realistic objects from seemingly\narbitrarily complex data distributions, including when conditioning generation\non labels. Unfortunately, however, their iterative nature renders them very\ncomputationally inefficient during the sampling process. For the multi-class\nconditional generation problem, we propose a novel, structurally unique\nframework of diffusion models which are hierarchically branched according to\nthe inherent relationships between classes. In this work, we demonstrate that\nbranched diffusion models offer major improvements in efficiently generating\nsamples from multiple classes. We also showcase several other advantages of\nbranched diffusion models, including ease of extension to novel classes in a\ncontinual-learning setting, and a unique interpretability that offers insight\ninto these generative models. Branched diffusion models represent an\nalternative paradigm to their traditional linear counterparts, and can have\nlarge impacts in how we use diffusion models for efficient generation, online\nlearning, and scientific discovery.",
    "descriptor": "",
    "authors": [
      "Alex M. Tseng",
      "Tommaso Biancalani",
      "Max Shen",
      "Gabriele Scalia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10777"
  },
  {
    "id": "arXiv:2212.10778",
    "title": "Mining User-aware Multi-Relations for Fake News Detection in Large Scale  Online Social Networks",
    "abstract": "Users' involvement in creating and propagating news is a vital aspect of fake\nnews detection in online social networks. Intuitively, credible users are more\nlikely to share trustworthy news, while untrusted users have a higher\nprobability of spreading untrustworthy news. In this paper, we construct a\ndual-layer graph (i.e., the news layer and the user layer) to extract multiple\nrelations of news and users in social networks to derive rich information for\ndetecting fake news. Based on the dual-layer graph, we propose a fake news\ndetection model named Us-DeFake. It learns the propagation features of news in\nthe news layer and the interaction features of users in the user layer. Through\nthe inter-layer in the graph, Us-DeFake fuses the user signals that contain\ncredibility information into the news features, to provide distinctive\nuser-aware embeddings of news for fake news detection. The training process\nconducts on multiple dual-layer subgraphs obtained by a graph sampler to scale\nUs-DeFake in large scale social networks. Extensive experiments on real-world\ndatasets illustrate the superiority of Us-DeFake which outperforms all\nbaselines, and the users' credibility signals learned by interaction relation\ncan notably improve the performance of our model.",
    "descriptor": "\nComments: Accepted by the 16th ACM International Conference on Web Search and Data Mining (WSDM 2023)\n",
    "authors": [
      "Xing Su",
      "Jian Yang",
      "Jia Wu",
      "Yuchen Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10778"
  },
  {
    "id": "arXiv:2212.10784",
    "title": "Can NLI Provide Proper Indirect Supervision for Low-resource Biomedical  Relation Extraction?",
    "abstract": "Two key obstacles in biomedical relation extraction (RE) are the scarcity of\nannotations and the prevalence of instances without explicitly pre-defined\nlabels due to low annotation coverage. Existing approaches, which treat\nbiomedical RE as a multi-class classification task, often result in poor\ngeneralization in low-resource settings and do not have the ability to make\nselective prediction on unknown cases but give a guess from seen relations,\nhindering the applicability of those approaches. We present NBR, which converts\nbiomedical RE as natural language inference formulation through indirect\nsupervision. By converting relations to natural language hypotheses, NBR is\ncapable of exploiting semantic cues to alleviate annotation scarcity. By\nincorporating a ranking-based loss that implicitly calibrates abstinent\ninstances, NBR learns a clearer decision boundary and is instructed to abstain\non uncertain instances. Extensive experiments on three widely-used biomedical\nRE benchmarks, namely ChemProt, DDI and GAD, verify the effectiveness of NBR in\nboth full-set and low-resource regimes. Our analysis demonstrates that indirect\nsupervision benefits biomedical RE even when a domain gap exists, and combining\nNLI knowledge with biomedical knowledge leads to the best performance gains.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Jiashu Xu",
      "Mingyu Derek Ma",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10784"
  },
  {
    "id": "arXiv:2212.10785",
    "title": "SERENGETI: Massively Multilingual Language Models for Africa",
    "abstract": "Multilingual language models (MLMs) acquire valuable, generalizable\nlinguistic information during pretraining and have advanced the state of the\nart on task-specific finetuning. So far, only ~ 28 out of ~2,000 African\nlanguages are covered in existing language models. We ameliorate this\nlimitation by developing SERENGETI, a set of massively multilingual language\nmodel that covers 517 African languages and language varieties. We evaluate our\nnovel models on eight natural language understanding tasks across 20 datasets,\ncomparing to four MLMs that each cover any number of African languages.\nSERENGETI outperforms other models on 11 datasets across the eights tasks and\nachieves 82.27 average F-1. We also perform error analysis on our models'\nperformance and show the influence of mutual intelligibility when the models\nare applied under zero-shot settings. We will publicly release our models for\nresearch.",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Ife Adebara",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed",
      "Alcides Alcoba Inciarte"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10785"
  },
  {
    "id": "arXiv:2212.10786",
    "title": "Multi-hop Evidence Retrieval for Cross-document Relation Extraction",
    "abstract": "Relation Extraction (RE) has been extended to cross-document scenarios\nbecause many relations are not simply described in a single document. This\ninevitably brings the challenge of efficient open-space evidence retrieval to\nsupport the inference of cross-document relations, along with the challenge of\nmulti-hop reasoning on top of entities and evidence scattered in an open set of\ndocuments. To combat these challenges, we propose Mr.CoD, a multi-hop evidence\nretrieval method based on evidence path mining and ranking with adapted dense\nretrievers. We explore multiple variants of retrievers to show evidence\nretrieval is an essential part in cross-document RE. Experiments on CodRED show\nthat evidence retrieval with Mr.Cod effectively acquires cross-document\nevidence that essentially supports open-setting cross-document RE.\nAdditionally, we show that Mr.CoD facilitates evidence retrieval and boosts\nend-to-end RE performance with effective multi-hop reasoning in both closed and\nopen settings of RE.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Keming Lu",
      "I-Hung Hsu",
      "Wenxuan Zhou",
      "Mingyu Derek Ma",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10786"
  },
  {
    "id": "arXiv:2212.10787",
    "title": "Interactive Learning-from-Observation through multimodal human  demonstration",
    "abstract": "Learning-from-Observation (LfO) is a robot teaching framework for programming\noperations through few-shots human demonstration. While most previous LfO\nsystems run with visual demonstration, recent research on robot teaching has\nshown the effectiveness of verbal instruction in making recognition robust and\nteaching interactive. To the best of our knowledge, however, few solutions have\nbeen proposed for LfO that utilizes verbal instruction, namely multimodal LfO.\nThis paper aims to propose a practical pipeline for multimodal LfO. For input,\nan user temporally stops hand movements to match the granularity of human\ninstructions with the granularity of robot execution. The pipeline recognizes\ntasks based on step-by-step verbal instructions accompanied by demonstrations.\nIn addition, the recognition is made robust through interactions with the user.\nWe test the pipeline on a real robot and show that the user can successfully\nteach multiple operations from multimodal demonstrations. The results suggest\nthe utility of the proposed pipeline for multimodal LfO.",
    "descriptor": "\nComments: 7 pages, 10 figures. Last updated December 21st, 2022\n",
    "authors": [
      "Naoki Wake",
      "Atsushi Kanehira",
      "Kazuhiro Sasabuchi",
      "Jun Takamatsu",
      "Katsushi Ikeuchi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.10787"
  },
  {
    "id": "arXiv:2212.10788",
    "title": "GraphIX: Graph-based In silico XAI(explainable artificial intelligence)  for drug repositioning from biopharmaceutical network",
    "abstract": "Drug repositioning holds great promise because it can reduce the time and\ncost of new drug development. While drug repositioning can omit various R&D\nprocesses, confirming pharmacological effects on biomolecules is essential for\napplication to new diseases. Biomedical explainability in a drug repositioning\nmodel can support appropriate insights in subsequent in-depth studies. However,\nthe validity of the XAI methodology is still under debate, and the\neffectiveness of XAI in drug repositioning prediction applications remains\nunclear. In this study, we propose GraphIX, an explainable drug repositioning\nframework using biological networks, and quantitatively evaluate its\nexplainability. GraphIX first learns the network weights and node features\nusing a graph neural network from known drug indication and knowledge graph\nthat consists of three types of nodes (but not given node type information):\ndisease, drug, and protein. Analysis of the post-learning features showed that\nnode types that were not known to the model beforehand are distinguished\nthrough the learning process based on the graph structure. From the learned\nweights and features, GraphIX then predicts the disease-drug association and\ncalculates the contribution values of the nodes located in the neighborhood of\nthe predicted disease and drug. We hypothesized that the neighboring protein\nnode to which the model gave a high contribution is important in understanding\nthe actual pharmacological effects. Quantitative evaluation of the validity of\nprotein nodes' contribution using a real-world database showed that the high\ncontribution proteins shown by GraphIX are reasonable as a mechanism of drug\naction. GraphIX is a framework for evidence-based drug discovery that can\npresent to users new disease-drug associations and identify the protein\nimportant for understanding its pharmacological effects from a large and\ncomplex knowledge base.",
    "descriptor": "\nComments: 16 pages, 6 figures\n",
    "authors": [
      "Atsuko Takagi",
      "Mayumi Kamada",
      "Eri Hamatani",
      "Ryosuke Kojima",
      "Yasushi Okuno"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2212.10788"
  },
  {
    "id": "arXiv:2212.10789",
    "title": "Multi-modal Molecule Structure-text Model for Text-based Retrieval and  Editing",
    "abstract": "There is increasing adoption of artificial intelligence in drug discovery.\nHowever, existing works use machine learning to mainly utilize the chemical\nstructures of molecules yet ignore the vast textual knowledge available in\nchemistry. Incorporating textual knowledge enables us to realize new drug\ndesign objectives, adapt to text-based instructions, and predict complex\nbiological activities. We present a multi-modal molecule structure-text model,\nMoleculeSTM, by jointly learning molecule's chemical structures and textual\ndescriptions via a contrastive learning strategy. To train MoleculeSTM, we\nconstruct the largest multi-modal dataset to date, namely PubChemSTM, with over\n280K chemical structure-text pairs. To demonstrate the effectiveness and\nutility of MoleculeSTM, we design two challenging zero-shot tasks based on text\ninstructions, including structure-text retrieval and molecule editing.\nMoleculeSTM possesses two main properties: open vocabulary and compositionality\nvia natural language. In experiments, MoleculeSTM obtains the state-of-the-art\ngeneralization ability to novel biochemical concepts across various benchmarks.",
    "descriptor": "",
    "authors": [
      "Shengchao Liu",
      "Weili Nie",
      "Chengpeng Wang",
      "Jiarui Lu",
      "Zhuoran Qiao",
      "Ling Liu",
      "Jian Tang",
      "Chaowei Xiao",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.10789"
  },
  {
    "id": "arXiv:2212.10791",
    "title": "OpineSum: Entailment-based self-training for abstractive opinion  summarization",
    "abstract": "A typical product or place often has hundreds of reviews, and summarization\nof these texts is an important and challenging problem. Recent progress on\nabstractive summarization in domains such as news has been driven by supervised\nsystems trained on hundreds of thousands of news articles paired with\nhuman-written summaries. However for opinion texts, such large scale datasets\nare rarely available. Unsupervised methods, self-training, and few-shot\nlearning approaches bridge that gap. In this work, we present a novel\nself-training approach, OpineSum, for abstractive opinion summarization. The\nsummaries in this approach are built using a novel application of textual\nentailment and capture the consensus of opinions across the various reviews for\nan item. This method can be used to obtain silver-standard summaries on a large\nscale and train both unsupervised and few-shot abstractive summarization\nsystems. OpineSum achieves state-of-the-art performance in both settings.",
    "descriptor": "",
    "authors": [
      "Annie Louis",
      "Joshua Maynez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10791"
  },
  {
    "id": "arXiv:2212.10792",
    "title": "Reconstruction Probing",
    "abstract": "We propose reconstruction probing, a new analysis method for contextualized\nrepresentations based on reconstruction probabilities in masked language models\n(MLMs). This method relies on comparing the reconstruction probabilities of\ntokens in a given sequence when conditioned on the representation of a single\ntoken that has been fully contextualized and when conditioned on only the\ndecontextualized lexical prior of the model. This comparison can be understood\nas quantifying the contribution of contextualization towards reconstruction --\nthe difference in the reconstruction probabilities can only be attributed to\nthe representational change of the single token induced by contextualization.\nWe apply this analysis to three MLMs and find that contextualization boosts\nreconstructability of tokens that are close to the token being reconstructed in\nterms of linear and syntactic distance. Furthermore, we extend our analysis to\nfiner-grained decomposition of contextualized representations, and we find that\nthese boosts are largely attributable to static and positional embeddings at\nthe input layer.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Najoung Kim",
      "Jatin Khilnani",
      "Alex Warstadt",
      "Abed Qaddoumi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10792"
  },
  {
    "id": "arXiv:2212.10793",
    "title": "Resource Utilization Monitoring for Raw Data Query Processing",
    "abstract": "Scientific experiments, simulations, and modern applications generate large\namounts of data. Data is stored in raw format to avoid the high loading time of\ntraditional database management systems. Researchers have proposed many\ntechniques to improve query execution time for raw data and reduce data loading\ntime for traditional systems. The core of all the proposed techniques is\nefficient utilization of resources by processing only required data or reducing\noperations on data. The processed data caching in the main memory or disk can\nresolve this issue and avoid repeated processing of data. However, limitations\nof resources like main memory space, storage IO speeds, and additional storage\nspace requirements on disk need to be considered to provide reliable and\nscalable solutions for cloud or in-house deployments. This paper presents\nimprovements to the raw data query processing framework by integrating a\nresource monitoring module. The experiments were performed using a scientific\ndataset known Sloan Digital Sky Survey (SDSS). Analysis of monitored resources\nrevealed that sampling queries had the lowest resource utilization. The\nPostgresRAW can answer simple 0-JOIN queries faster than PostgreSQL. While one\nor more JOIN complex queries need to be answered using PostgreSQL to reduce\nworkload execution time (WET). The results section discusses resource\nrequirements of simple, complex, and sampling type queries. The result analysis\nof query types and resource utilization patterns assisted in proposing Query\nComplexity Aware (QCA) and Resource Utilization Aware (RUA) data partitioning\ntechniques for raw engines and DBMS to reduce cost or data to result time.",
    "descriptor": "\nComments: Pre-print\n",
    "authors": [
      "Mayank Patel",
      "Minal Bhise"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2212.10793"
  },
  {
    "id": "arXiv:2212.10797",
    "title": "Direct Comparative Analysis of Nature-inspired Optimization Algorithms  on Community Detection Problem in Social Networks",
    "abstract": "Nature-inspired optimization Algorithms (NIOAs) are nowadays a popular choice\nfor community detection in social networks. Community detection problem in\nsocial network is treated as optimization problem, where the objective is to\neither maximize the connection within the community or minimize connections\nbetween the communities. To apply NIOAs, either of the two, or both objectives\nare explored. Since NIOAs mostly exploit randomness in their strategies, it is\nnecessary to analyze their performance for specific applications. In this\npaper, NIOAs are analyzed on the community detection problem. A direct\ncomparison approach is followed to perform pairwise comparison of NIOAs. The\nperformance is measured in terms of five scores designed based on prasatul\nmatrix and also with average isolability. Three widely used real-world social\nnetworks and four NIOAs are considered for analyzing the quality of communities\ngenerated by NIOAs.",
    "descriptor": "",
    "authors": [
      "Soumita Das",
      "Bijita Singha",
      "Alberto Tonda",
      "Anupam Biswas"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.10797"
  },
  {
    "id": "arXiv:2212.10802",
    "title": "Semi-Supervised Bifold Teacher-Student Learning for Indoor Presence  Detection Under Time-Varying CSI",
    "abstract": "In recent years, there have been abundant researches focused on indoor human\npresence detection based on laborious supervised learning (SL) and channel\nstate information (CSI). These existing studies adopt spatial information of\nCSI to improve detection accuracy. However, channel is susceptible to arbitrary\nenvironmental changes in practice, such as the object movement, atmospheric\nfactors and machine rebooting, which leads to degraded prediction accuracy.\nHowever, the existing SL-based methods require to re-train a new model with\ntime-consuming labeling. Therefore, designing a semi-supervised learning (SSL)\nbased scheme by continuously monitoring model \"life-cycle\" becomes compellingly\nimperative. In this paper, we propose bifold teacher-student (BTS) learning for\npresence detection system, which combines SSL by utilizing partial labeled and\nunlabeled dataset. The proposed primal-dual teacher-student network is capable\nof intelligently learning spatial and temporal features from labeled and\nunlabeled CSI. Additionally, the enhanced penalized loss function leveraging\nentropy and distance measure can distinguish the drifted data, i.e., features\nof new dataset are affected by time-varying effect and are alternated from the\noriginal distribution. The experimental results demonstrate that the proposed\nBTS system can sustain the asymptotic accuracy after retraining the model with\nunlabeled data. Moreover, label-free BTS outperforms the existing SSL-based\nmodels in terms of the highest detection accuracy, while achieving the similar\nperformance of SL-based methods.",
    "descriptor": "",
    "authors": [
      "Li-Hsiang Shen",
      "Kai-Jui Chen",
      "An-Hung Hsiao",
      "Kai-Ten Feng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.10802"
  },
  {
    "id": "arXiv:2212.10805",
    "title": "Beyond Information Exchange: An Approach to Deploy Network Properties  for Information Diffusion",
    "abstract": "Information diffusion in Online Social Networks is a new and crucial problem\nin social network analysis field and requires significant research attention.\nEfficient diffusion of information are of critical importance in diverse\nsituations such as; pandemic prevention, advertising, marketing etc. Although\nseveral mathematical models have been developed till date, but previous works\nlacked systematic analysis and exploration of the influence of neighborhood for\ninformation diffusion. In this paper, we have proposed Common Neighborhood\nStrategy (CNS) algorithm for information diffusion that demonstrates the role\nof common neighborhood in information propagation throughout the network. The\nperformance of CNS algorithm is evaluated on several real-world datasets in\nterms of diffusion speed and diffusion outspread and compared with several\nwidely used information diffusion models. Empirical results show CNS algorithm\nenables better information diffusion both in terms of diffusion speed and\ndiffusion outspread.",
    "descriptor": "\nComments: To be published in BigDML 2021\n",
    "authors": [
      "Soumita Das",
      "Anupam Biswas",
      "Ravi Kishore Devarapalli"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.10805"
  },
  {
    "id": "arXiv:2212.10806",
    "title": "Semi-Supervised Learning of Monocular Depth Estimation via Consistency  Regularization with K-way Disjoint Masking",
    "abstract": "Semi-Supervised Learning (SSL) has recently accomplished successful\nachievements in various fields such as image classification, object detection,\nand semantic segmentation, which typically require a lot of labour to construct\nground-truth. Especially in the depth estimation task, annotating training data\nis very costly and time-consuming, and thus recent SSL regime seems an\nattractive solution. In this paper, for the first time, we introduce a novel\nframework for semi-supervised learning of monocular depth estimation networks,\nusing consistency regularization to mitigate the reliance on large ground-truth\ndepth data. We propose a novel data augmentation approach, called K-way\ndisjoint masking, which allows the network for learning how to reconstruct\ninvisible regions so that the model not only becomes robust to perturbations\nbut also generates globally consistent output depth maps. Experiments on the\nKITTI and NYU-Depth-v2 datasets demonstrate the effectiveness of each component\nin our pipeline, robustness to the use of fewer and fewer annotated images, and\nsuperior results compared to other state-of-the-art, semi-supervised methods\nfor monocular depth estimation. Our code is available at\nhttps://github.com/KU-CVLAB/MaskingDepth.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Jongbeom Baek",
      "Gyeongnyeon Kim",
      "Seonghoon Park",
      "Honggyu An",
      "Matteo Poggi",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10806"
  },
  {
    "id": "arXiv:2212.10808",
    "title": "Agile Assessment Methods: Current State of the Art",
    "abstract": "Agility Assessment (AA) comprises tools, assessment techniques, and\nframeworks that focus on indicating how a company or a team is applying agile\ntechniques and eventually pointing out problems in adopting agile practices at\na project-level, organization-level or individual-level. There are many\napproaches for AA such as agility assessment models, agility checklists,\nagility surveys, and agility assessment tools. This report presents the state\nof the art approaches that support agility assessment.",
    "descriptor": "",
    "authors": [
      "Ulisses Telemaco",
      "Paulo Alencar",
      "Donald Cowan",
      "Toacy Oliveira"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.10808"
  },
  {
    "id": "arXiv:2212.10809",
    "title": "Typicality for stratified measures",
    "abstract": "Stratified measures on Euclidean space are defined here as convex\ncombinations of rectifiable measures. They are possibly singular with respect\nto the Lebesgue measure and generalize continuous-discrete mixtures. A\nstratified measure $\\rho$ can thus be represented as $\\sum_{i=1}^k q_i \\rho_i$,\nwhere $(q_1,..,q_k)$ is a probability vector and each $\\rho_i$ is\n$m_i$-rectifiable for some integer $m_i$ i.e. absolutely continuous with\nrespect to the $m_i$-Hausdorff measure $\\mu_i$ on a $m_i$-rectifiable set $E_i$\n(e.g. a smooth $m_i$-manifold). We introduce a set of strongly typical\nrealizations of $\\rho^{\\otimes n}$ (memoryless source) that occur with high\nprobability. The typical realizations are supported on a finite union of strata\n$\\{E_{i_1}\\times \\cdots \\times E_{i_n}\\}$ whose dimension concentrates around\nthe mean dimension $\\sum_{i=1}^k q_i m_i$. For each $n$, an appropriate sum of\nHausdorff measures on the different strata gives a natural notion of reference\n\"volume\"; the exponential growth rate of the typical set's volume is quantified\nby Csiszar's generalized entropy of $\\rho$ with respect to $\\mu=\\sum_{i=1}^k\n\\mu_i$. Moreover, we prove that this generalized entropy satisfies a chain rule\nand that the conditional term is related to the volume growth of the typical\nrealizations in each stratum. The chain rule and its asymptotic interpretation\nhold in the more general framework of piecewise continuous measures: convex\ncombinations of measures restricted to pairwise disjoint sets equipped with\nreference $\\sigma$-finite measures. Finally, we establish that our notion of\nmean dimension coincides with R\\'enyi's information dimension when applied to\nstratified measures, but the generalized entropy used here differs from\nR\\'enyi's dimensional entropy.",
    "descriptor": "",
    "authors": [
      "Juan Pablo Vigneaux"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Metric Geometry (math.MG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2212.10809"
  },
  {
    "id": "arXiv:2212.10812",
    "title": "Secure and Privacy Preserving Proxy Biometrics Identities",
    "abstract": "With large-scale adaption to biometric based applications, security and\nprivacy of biometrics is utmost important especially when operating in\nunsupervised online mode. This work proposes a novel approach for generating\nnew artificial fingerprints also called proxy fingerprints that are natural\nlooking, non-invertible, revocable and privacy preserving. These proxy\nbiometrics can be generated from original ones only with the help of a\nuser-specific key. Instead of using the original fingerprint, these proxy\ntemplates can be used anywhere with same convenience. The manuscripts walks\nthrough an interesting way in which proxy fingerprints of different types can\nbe generated and how they can be combined with use-specific keys to provide\nrevocability and cancelability in case of compromise. Using the proposed\napproach a proxy dataset is generated from samples belonging to Anguli\nfingerprint database. Matching experiments were performed on the new set which\nis 5 times larger than the original, and it was found that their performance is\nat par with 0 FAR and 0 FRR in the stolen key, safe key scenarios. Other\nparameters on revocability and diversity are also analyzed for protection\nperformance.",
    "descriptor": "",
    "authors": [
      "Harkeerat Kaur",
      "Rishabh Shukla",
      "Isao Echizen",
      "Pritee Khanna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10812"
  },
  {
    "id": "arXiv:2212.10815",
    "title": "ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language  Models",
    "abstract": "We explore the use of large language models (LLMs) for zero-shot semantic\nparsing. Semantic parsing involves mapping natural language utterances to\ntask-specific meaning representations. Language models are generally trained on\nthe publicly available text and code and cannot be expected to directly\ngeneralize to domain-specific parsing tasks in a zero-shot setting. In this\nwork, we propose ZEROTOP, a zero-shot task-oriented parsing method that\ndecomposes a semantic parsing problem into a set of abstractive and extractive\nquestion-answering (QA) problems, enabling us to leverage the ability of LLMs\nto zero-shot answer reading comprehension questions. For each utterance, we\nprompt the LLM with questions corresponding to its top-level intent and a set\nof slots and use the LLM generations to construct the target meaning\nrepresentation. We observe that current LLMs fail to detect unanswerable\nquestions; and as a result, cannot handle questions corresponding to missing\nslots. To address this problem, we fine-tune a language model on public QA\ndatasets using synthetic negative samples. Experimental results show that our\nQA-based decomposition paired with the fine-tuned LLM can correctly parse ~16%\nof utterances in the MTOP dataset without requiring any annotated data.",
    "descriptor": "",
    "authors": [
      "Dheeraj Mekala",
      "Jason Wolfe",
      "Subhro Roy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10815"
  },
  {
    "id": "arXiv:2212.10818",
    "title": "4D ASR: Joint modeling of CTC, Attention, Transducer, and Mask-Predict  decoders",
    "abstract": "The network architecture of end-to-end (E2E) automatic speech recognition\n(ASR) can be classified into several models, including connectionist temporal\nclassification (CTC), recurrent neural network transducer (RNN-T), attention\nmechanism, and non-autoregressive mask-predict models. Since each of these\nnetwork architectures has pros and cons, a typical use case is to switch these\nseparate models depending on the application requirement, resulting in the\nincreased overhead of maintaining all models. Several methods for integrating\ntwo of these complementary models to mitigate the overhead issue have been\nproposed; however, if we integrate more models, we will further benefit from\nthese complementary models and realize broader applications with a single\nsystem. This paper proposes four-decoder joint modeling (4D) of CTC, attention,\nRNN-T, and mask-predict, which has the following three advantages: 1) The four\ndecoders are jointly trained so that they can be easily switched depending on\nthe application scenarios. 2) Joint training may bring model regularization and\nimprove the model robustness thanks to their complementary properties. 3) Novel\none-pass joint decoding methods using CTC, attention, and RNN-T further\nimproves the performance. The experimental results showed that the proposed\nmodel consistently reduced the WER.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Yui Sudo",
      "Muhammad Shakeel",
      "Brian Yan",
      "Jiatong Shi",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.10818"
  },
  {
    "id": "arXiv:2212.10819",
    "title": "Attend to the Right Context: A Plug-and-Play Module for  Content-Controllable Summarization",
    "abstract": "Content-Controllable Summarization generates summaries focused on the given\ncontrolling signals. Due to the lack of large-scale training corpora for the\ntask, we propose a plug-and-play module RelAttn to adapt any general\nsummarizers to the content-controllable summarization task. RelAttn first\nidentifies the relevant content in the source documents, and then makes the\nmodel attend to the right context by directly steering the attention weight. We\nfurther apply an unsupervised online adaptive parameter searching algorithm to\ndetermine the degree of control in the zero-shot setting, while such parameters\nare learned in the few-shot setting. By applying the module to three backbone\nsummarization models, experiments show that our method effectively improves all\nthe summarizers, and outperforms the prefix-based method and a widely used\nplug-and-play model in both zero- and few-shot settings. Tellingly, more\nbenefit is observed in the scenarios when more control is needed.",
    "descriptor": "",
    "authors": [
      "Wen Xiao",
      "Lesly Miculicich",
      "Yang Liu",
      "Pengcheng He",
      "Giuseppe Carenini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10819"
  },
  {
    "id": "arXiv:2212.10822",
    "title": "Complete the Missing Half: Augmenting Aggregation Filtering with  Diversification for Graph Convolutional Neural Networks",
    "abstract": "The core operation of current Graph Neural Networks (GNNs) is the aggregation\nenabled by the graph Laplacian or message passing, which filters the\nneighborhood information of nodes. Though effective for various tasks, in this\npaper, we show that they are potentially a problematic factor underlying all\nGNN models for learning on certain datasets, as they force the node\nrepresentations similar, making the nodes gradually lose their identity and\nbecome indistinguishable. Hence, we augment the aggregation operations with\ntheir dual, i.e. diversification operators that make the node more distinct and\npreserve the identity. Such augmentation replaces the aggregation with a\ntwo-channel filtering process that, in theory, is beneficial for enriching the\nnode representations. In practice, the proposed two-channel filters can be\neasily patched on existing GNN methods with diverse training strategies,\nincluding spectral and spatial (message passing) methods. In the experiments,\nwe observe desired characteristics of the models and significant performance\nboost upon the baselines on 9 node classification tasks.",
    "descriptor": "\nComments: Accepted as Oral Presentation at NeurIPS 2022 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2022)\n",
    "authors": [
      "Sitao Luan",
      "Mingde Zhao",
      "Chenqing Hua",
      "Xiao-Wen Chang",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10822"
  },
  {
    "id": "arXiv:2212.10823",
    "title": "Continual Contrastive Finetuning Improves Low-Resource Relation  Extraction",
    "abstract": "Relation extraction (RE), which has relied on structurally annotated corpora\nfor model training, has been particularly challenging in low-resource scenarios\nand domains. Recent literature has tackled low-resource RE by self-supervised\nlearning, where the solution involves pretraining the relation embedding by\nRE-based objective and finetuning on labeled data by classification-based\nobjective. However, a critical challenge to this approach is the gap in\nobjectives, which prevents the RE model from fully utilizing the knowledge in\npretrained representations. In this paper, we aim at bridging the gap and\npropose to pretrain and finetune the RE model using consistent objectives of\ncontrastive learning. Since in this kind of representation learning paradigm,\none relation may easily form multiple clusters in the representation space, we\nfurther propose a multi-center contrastive loss that allows one relation to\nform multiple clusters to better align with pretraining. Experiments on two\ndocument-level RE datasets, BioRED and Re-DocRED, demonstrate the effectiveness\nof our method. Particularly, when using 1% end-task training data, our method\noutperforms PLM-based RE classifier by 10.5% and 5.8% on the two datasets,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Wenxuan Zhou",
      "Sheng Zhang",
      "Tristan Naumann",
      "Muhao Chen",
      "Hoifung Poon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10823"
  },
  {
    "id": "arXiv:2212.10826",
    "title": "End-to-End Automatic Speech Recognition model for the Sudanese Dialect",
    "abstract": "Designing a natural voice interface rely mostly on Speech recognition for\ninteraction between human and their modern digital life equipment. In addition,\nspeech recognition narrows the gap between monolingual individuals to better\nexchange communication. However, the field lacks wide support for several\nuniversal languages and their dialects, while most of the daily conversations\nare carried out using them. This paper comes to inspect the viability of\ndesigning an Automatic Speech Recognition model for the Sudanese dialect, which\nis one of the Arabic Language dialects, and its complexity is a product of\nhistorical and social conditions unique to its speakers. This condition is\nreflected in both the form and content of the dialect, so this paper gives an\noverview of the Sudanese dialect and the tasks of collecting represented\nresources and pre-processing performed to construct a modest dataset to\novercome the lack of annotated data. Also proposed end- to-end speech\nrecognition model, the design of the model was formed using Convolution Neural\nNetworks. The Sudanese dialect dataset would be a stepping stone to enable\nfuture Natural Language Processing research targeting the dialect. The designed\nmodel provided some insights into the current recognition task and reached an\naverage Label Error Rate of 73.67%.",
    "descriptor": "",
    "authors": [
      "Ayman Mansour",
      "Wafaa F. Mukhtar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10826"
  },
  {
    "id": "arXiv:2212.10828",
    "title": "Space-Terrestrial Cooperation Over Spatially Correlated Channels Relying  on Imperfect Channel Estimates: Uplink Performance Analysis and Optimization",
    "abstract": "A whole suite of innovative technologies and architectures have emerged in\nresponse to the rapid growth of wireless traffic. This paper studies an\nintegrated network design that boosts system capacity through cooperation\nbetween wireless access points (APs) and a satellite for enhancing the\nnetwork's spectral efficiency. We first mathematically derive an achievable\nthroughput expression for the uplink (UL) data transmission over spatially\ncorrelated Rician channels. Our generic achievable throughput expression is\napplicable for arbitrary received signal detection techniques under realistic\nimperfect channel estimates. A closed-form expression is then obtained for the\nergodic UL data throughput when maximum ratio combining is utilized for\ndetecting the desired signals. As for our resource allocation contributions, we\nformulate the max-min fairness and total transmit power optimization problems\nrelying on the channel statistics for performing power allocation. The solution\nof each optimization problem is derived in form of a low-complexity iterative\ndesign, in which each data power variable is updated relying on a closed-form\nexpression. Our integrated hybrid network concept allows users to be served\nthat may not otherwise be accommodated due to the excessive data demands. The\nalgorithms proposed to allow us to address the congestion issues appearing when\nat least one user is served at a rate below the target. The mathematical\nanalysis is also illustrated with the aid of our numerical results that show\nthe added benefits of considering the space links in terms of improving the\nergodic data throughput. Furthermore, the proposed algorithms smoothly\ncircumvent any potential congestion, especially in face of high rate\nrequirements and weak channel conditions.",
    "descriptor": "\nComments: 18 pages, 12 figures, and 2 tables. Accepted by the IEEE TCOM. arXiv admin note: text overlap with arXiv:2209.01329\n",
    "authors": [
      "Trinh Van Chien",
      "Eva Lagunas",
      "Tiep M. Hoang",
      "Symeon Chatzinotas",
      "Bj\u00f6rn Ottersten",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.10828"
  },
  {
    "id": "arXiv:2212.10829",
    "title": "Perching on Moving Inclined Surfaces using Uncertainty Tolerant Planner  and Thrust Regulation",
    "abstract": "Quadrotors with the ability to perch on moving inclined surfaces can save\nenergy and extend their travel distance by leveraging ground vehicles.\nAchieving dynamic perching places high demands on the performance of trajectory\nplanning and terminal state accuracy in SE(3). However, in the perching\nprocess, uncertainties in target surface prediction, tracking control and\nexternal disturbances may cause trajectory planning failure or lead to\nunacceptable terminal errors. To address these challenges, we first propose a\ntrajectory planner that considers adaptation to uncertainties in target\nprediction and tracking control. To facilitate this work, the reachable set of\nquadrotors' states is first analyzed. The states whose reachable sets possess\nthe largest coverage probability for uncertainty targets, are defined as\noptimal waypoints. Subsequently, an approach to seek local optimal waypoints\nfor static and moving uncertainty targets is proposed. A real-time trajectory\nplanner based on optimized waypoints is developed accordingly. Secondly, thrust\nregulation is also implemented in the terminal attitude tracking stage to\nhandle external disturbances. When a quadrotor's attitude is commanded to align\nwith target surfaces, the thrust is optimized to minimize terminal errors. This\nmakes the terminal position and velocity be controlled in closed-loop manner.\nTherefore, the resistance to disturbances and terminal accuracy is improved.\nExtensive simulation experiments demonstrate that our methods can improve the\naccuracy of terminal states under uncertainties. The success rate is\napproximately increased by $50\\%$ compared to the two-end planner without\nthrust regulation. Perching on the rear window of a car is also achieved using\nour proposed heterogeneous cooperation system outdoors. This validates the\nfeasibility and practicality of our methods.",
    "descriptor": "",
    "authors": [
      "Sensen Liu",
      "Wenkang Hu",
      "Zhaoying Wang",
      "Wei Dong",
      "Xinjun Sheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.10829"
  },
  {
    "id": "arXiv:2212.10830",
    "title": "A Comparative Risk Analysis on CyberShip System with STPA-Sec, STRIDE  and CORAS",
    "abstract": "The widespread use of software-intensive cyber systems in critical\ninfrastructures such as ships (CyberShips) has brought huge benefits, yet it\nhas also opened new avenues for cyber attacks to potentially disrupt\noperations. Cyber risk assessment plays a vital role in identifying cyber\nthreats and vulnerabilities that can be exploited to compromise cyber systems.\nA number of methodologies have been proposed to carry out these analyses. This\npaper evaluates and compares the application of three risk assessment\nmethodologies: system theoretic process analysis (STPA-Sec), STRIDE and CORAS\nfor identifying threats and vulnerabilities in a CyberShip system. We\nspecifically selected these three methodologies because they identify threats\nnot only at the component level, but also threats or hazards caused due to the\ninteraction between components, resulting in sets of threats identified with\neach methodology and relevant differences. Moreover, STPA-Sec which is a\nvariant of the STPA is widely used for safety and security analysis of cyber\nphysical systems (CPS); CORAS offers a framework to perform cyber risk\nassessment in a top-down approach that aligns with STPA-Sec; and STRIDE\n(Spoofing, Tampering, Repudiation, Information disclosure, Denial of Service,\nElevation of Privilege) considers threat at the component level as well as\nduring the interaction that is similar to STPA-Sec. As a result of this\nanalysis, this paper highlights the pros and cons of these methodologies,\nillustrates areas of special applicability, and suggests that their\ncomplementary use as threats identified through STRIDE can be used as an input\nto CORAS and STPA-Sec to make these methods more structured.",
    "descriptor": "",
    "authors": [
      "Rishikesh Sahay",
      "D.A.Sepulveda Estay",
      "Weizhi Meng",
      "Christian D. Jensen",
      "Michael Bruhn Barfod"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.10830"
  },
  {
    "id": "arXiv:2212.10832",
    "title": "Numerical range for weighted Moore-Penrose inverse of tensor",
    "abstract": "This article first introduces the notion of weighted singular value\ndecomposition (WSVD) of a tensor via the Einstein product. The WSVD is then\nused to compute the weighted Moore-Penrose inverse of an arbitrary-order\ntensor. We then define the notions of weighted normal tensor for an even-order\nsquare tensor and weighted tensor norm. Finally, we apply these to study the\ntheory of numerical range for the weighted Moore-Penrose inverse of an\neven-order square tensor and exploit its several properties. We also obtain a\nfew new results in the matrix setting that generalizes some of the existing\nresults as particular cases.",
    "descriptor": "\nComments: 30 pages, 1 figure\n",
    "authors": [
      "Aaisha Be",
      "Vaibhav Shekhar",
      "Debasisha Mishra"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2212.10832"
  },
  {
    "id": "arXiv:2212.10833",
    "title": "Numerical method and Error estimate for stochastic  Landau--Lifshitz--Bloch equation",
    "abstract": "We study numerical methods for solving a system of quasilinear stochastic\npartial differential equations known as the stochastic Landau-Lifshitz-Bloch\n(LLB) equation on a bounded domain in $\\mathbb R^d$ for $d=1,2$. Our main\nresults are estimates of the rate of convergence of the Finite Element Method\nto the solutions of stochastic LLB. To overcome the lack of regularity of the\nsolution in the case $d=2$, we propose a Finite Element scheme for a\nregularised version of the equation. We then obtain error estimates of\nnumerical solutions and for the solution of the regularised equation as well as\nthe rate of convergence of this solution to the solution of the stochastic LLB\nequation. As a consequence, the convergence in probability of the approximate\nsolutions to the solution of the stochastic LLB equation is derived. To the\nbest of our knowledge this is the first result on error estimates for a system\nof stochastic quasilinear partial differential equations. A stronger result is\nobtained in the case $d=1$ due to a new regularity result for the LLB equation\nwhich allows us to avoid regularisation.",
    "descriptor": "",
    "authors": [
      "Beniamin Goldys",
      "Chunxi Jiao",
      "Kim-Ngan Le"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2212.10833"
  },
  {
    "id": "arXiv:2212.10836",
    "title": "Towards Rapid Prototyping and Comparability in Active Learning for Deep  Object Detection",
    "abstract": "Active learning as a paradigm in deep learning is especially important in\napplications involving intricate perception tasks such as object detection\nwhere labels are difficult and expensive to acquire. Development of active\nlearning methods in such fields is highly computationally expensive and time\nconsuming which obstructs the progression of research and leads to a lack of\ncomparability between methods. In this work, we propose and investigate a\nsandbox setup for rapid development and transparent evaluation of active\nlearning in deep object detection. Our experiments with commonly used\nconfigurations of datasets and detection architectures found in the literature\nshow that results obtained in our sandbox environment are representative of\nresults on standard configurations. The total compute time to obtain results\nand assess the learning behavior can thereby be reduced by factors of up to 14\nwhen comparing with Pascal VOC and up to 32 when comparing with BDD100k. This\nallows for testing and evaluating data acquisition and labeling strategies in\nunder half a day and contributes to the transparency and development speed in\nthe field of active learning for object detection.",
    "descriptor": "\nComments: 17 pages, 12 figures, 9 tables\n",
    "authors": [
      "Tobias Riedlinger",
      "Marius Schubert",
      "Karsten Kahl",
      "Hanno Gottschalk",
      "Matthias Rottmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10836"
  },
  {
    "id": "arXiv:2212.10839",
    "title": "Crab: Learning Certifiably Fair Predictive Models in the Presence of  Selection Bias",
    "abstract": "A recent explosion of research focuses on developing methods and tools for\nbuilding fair predictive models. However, most of this work relies on the\nassumption that the training and testing data are representative of the target\npopulation on which the model will be deployed. However, real-world training\ndata often suffer from selection bias and are not representative of the target\npopulation for many reasons, including the cost and feasibility of collecting\nand labeling data, historical discrimination, and individual biases.\nIn this paper, we introduce a new framework for certifying and ensuring the\nfairness of predictive models trained on biased data. We take inspiration from\nquery answering over incomplete and inconsistent databases to present and\nformalize the problem of consistent range approximation (CRA) of answers to\nqueries about aggregate information for the target population. We aim to\nleverage background knowledge about the data collection process, biased data,\nand limited or no auxiliary data sources to compute a range of answers for\naggregate queries over the target population that are consistent with available\ninformation. We then develop methods that use CRA of such aggregate queries to\nbuild predictive models that are certifiably fair on the target population even\nwhen no external information about that population is available during\ntraining. We evaluate our methods on real data and demonstrate improvements\nover state of the art. Significantly, we show that enforcing fairness using our\nmethods can lead to predictive models that are not only fair, but more accurate\non the target population.",
    "descriptor": "",
    "authors": [
      "Jiongli Zhu",
      "Nazanin Sabri",
      "Sainyam Galhotra",
      "Babak Salimi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.10839"
  },
  {
    "id": "arXiv:2212.10841",
    "title": "Predicting the Score of Atomic Candidate OWL Class Axioms",
    "abstract": "Candidate axiom scoring is the task of assessing the acceptability of a\ncandidate axiom against the evidence provided by known facts or data. The\nability to score candidate axioms reliably is required for automated schema or\nontology induction, but it can also be valuable for ontology and/or knowledge\ngraph validation. Accurate axiom scoring heuristics are often computationally\nexpensive, which is an issue if you wish to use them in iterative search\ntechniques like level-wise generate-and-test or evolutionary algorithms, which\nrequire scoring a large number of candidate axioms. We address the problem of\ndeveloping a predictive model as a substitute for reasoning that predicts the\npossibility score of candidate class axioms and is quick enough to be employed\nin such situations. We use a semantic similarity measure taken from an\nontology's subsumption structure for this purpose. We show that the approach\nprovided in this work can accurately learn the possibility scores of candidate\nOWL class axioms and that it can do so for a variety of OWL class axioms.",
    "descriptor": "",
    "authors": [
      "Ali Ballout",
      "Andrea G B Tettamanzi",
      "C\u00e9lia da Costa Pereira"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.10841"
  },
  {
    "id": "arXiv:2212.10843",
    "title": "Generating Multiple-Length Summaries via Reinforcement Learning for  Unsupervised Sentence Summarization",
    "abstract": "Sentence summarization shortens given texts while maintaining core contents\nof the texts. Unsupervised approaches have been studied to summarize texts\nwithout human-written summaries. However, recent unsupervised models are\nextractive, which remove words from texts and thus they are less flexible than\nabstractive summarization. In this work, we devise an abstractive model based\non reinforcement learning without ground-truth summaries. We formulate the\nunsupervised summarization based on the Markov decision process with rewards\nrepresenting the summary quality. To further enhance the summary quality, we\ndevelop a multi-summary learning mechanism that generates multiple summaries\nwith varying lengths for a given text, while making the summaries mutually\nenhance each other. Experimental results show that the proposed model\nsubstantially outperforms both abstractive and extractive models, yet\nfrequently generating new words not contained in input texts.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Dongmin Hyun",
      "Xiting Wang",
      "Chanyoung Park",
      "Xing Xie",
      "Hwanjo Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10843"
  },
  {
    "id": "arXiv:2212.10844",
    "title": "Greenhouse gases emissions: estimating corporate non-reported emissions  using interpretable machine learning",
    "abstract": "As of 2022, greenhouse gases (GHG) emissions reporting and auditing are not\nyet compulsory for all companies and methodologies of measurement and\nestimation are not unified. We propose a machine learning-based model to\nestimate scope 1 and scope 2 GHG emissions of companies not reporting them yet.\nOur model, specifically designed to be transparent and completely adapted to\nthis use case, is able to estimate emissions for a large universe of companies.\nIt shows good out-of-sample global performances as well as good out-of-sample\ngranular performances when evaluating it by sectors, by countries or by\nrevenues buckets. We also compare our results to those of other providers and\nfind our estimates to be more accurate. Thanks to the proposed explainability\ntools using Shapley values, our model is fully interpretable, the user being\nable to understand which factors split explain the GHG emissions for each\nparticular company.",
    "descriptor": "",
    "authors": [
      "Jeremi Assael",
      "Thibaut Heurtebize",
      "Laurent Carlier",
      "Fran\u00e7ois Soup\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "General Finance (q-fin.GN)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2212.10844"
  },
  {
    "id": "arXiv:2212.10846",
    "title": "From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language  Models",
    "abstract": "Large language models (LLMs) have demonstrated excellent zero-shot\ngeneralization to new language tasks. However, effective utilization of LLMs\nfor zero-shot visual question-answering (VQA) remains challenging, primarily\ndue to the modality disconnection and task disconnection between LLM and VQA\ntask. End-to-end training on vision and language data may bridge the\ndisconnections, but is inflexible and computationally expensive. To address\nthis issue, we propose \\emph{Img2Prompt}, a plug-and-play module that provides\nthe prompts that can bridge the aforementioned modality and task\ndisconnections, so that LLMs can perform zero-shot VQA tasks without end-to-end\ntraining. In order to provide such prompts, we further employ LLM-agnostic\nmodels to provide prompts that can describe image content and self-constructed\nquestion-answer pairs, which can effectively guide LLM to perform zero-shot VQA\ntasks. Img2Prompt offers the following benefits: 1) It can flexibly work with\nvarious LLMs to perform VQA. 2)~Without the needing of end-to-end training, it\nsignificantly reduces the cost of deploying LLM for zero-shot VQA tasks. 3) It\nachieves comparable or better performance than methods relying on end-to-end\ntraining. For example, we outperform Flamingo~\\cite{Deepmind:Flamingo2022} by\n5.6\\% on VQAv2. On the challenging A-OKVQA dataset, our method even outperforms\nfew-shot methods by as much as 20\\%.",
    "descriptor": "",
    "authors": [
      "Jiaxian Guo",
      "Junnan Li",
      "Dongxu Li",
      "Anthony Meng Huat Tiong",
      "Boyang Li",
      "Dacheng Tao",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2212.10846"
  },
  {
    "id": "arXiv:2212.10847",
    "title": "VCNet: A self-explaining model for realistic counterfactual generation",
    "abstract": "Counterfactual explanation is a common class of methods to make local\nexplanations of machine learning decisions. For a given instance, these methods\naim to find the smallest modification of feature values that changes the\npredicted decision made by a machine learning model. One of the challenges of\ncounterfactual explanation is the efficient generation of realistic\ncounterfactuals. To address this challenge, we propose VCNet-Variational\nCounter Net-a model architecture that combines a predictor and a counterfactual\ngenerator that are jointly trained, for regression or classification tasks.\nVCNet is able to both generate predictions, and to generate counterfactual\nexplanations without having to solve another minimisation problem. Our\ncontribution is the generation of counterfactuals that are close to the\ndistribution of the predicted class. This is done by learning a variational\nautoencoder conditionally to the output of the predictor in a join-training\nfashion. We present an empirical evaluation on tabular datasets and across\nseveral interpretability metrics. The results are competitive with the\nstate-of-the-art method.",
    "descriptor": "",
    "authors": [
      "Victor Guyomard",
      "Fran\u00e7oise Fessant",
      "Thomas Guyet",
      "Tassadit Bouadi",
      "Alexandre Termier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10847"
  },
  {
    "id": "arXiv:2212.10854",
    "title": "Defining C-ITS Environment and Attack Scenarios",
    "abstract": "As technology advances, it is possible to process a lot of data, and as\nvarious elements in the city become diverse and complex, cities are becoming\nsmart cities. One of the core systems of smart cities is\nCooperative-Intelligent Transport Systems (C-ITS). C-ITS is a system that\nprovides drivers with real-time accident risk information such as surrounding\ntraffic conditions, sudden stops, and falling objects while a vehicle is\ndriving, and consists of road infrastructure, C-ITS center, and vehicle\nterminals. Meanwhile, smart cities can have cybersecurity problems because many\nelements of the city are networked and electronically controlled. If\ncybersecurity problems occur in C-ITS, there is a high risk of safety problems.\nThe purpose of this technical document is to describe C-ITS environment\nmodeling and C-ITS attack scenarios for C-ITS security. After describing the\nconcept of C-ITS and MITRE ATT&CK, we describe the C-ITS environment model and\nthe attack scenario model that we define.",
    "descriptor": "\nComments: in Korean language\n",
    "authors": [
      "Yongsik Kim",
      "Jae Woong Choi",
      "Hyo Sun Lee",
      "Jeong Do Yoo",
      "Haerin Kim",
      "Junho Jang",
      "Kibeom Park",
      "Huy Kang Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.10854"
  },
  {
    "id": "arXiv:2212.10861",
    "title": "PABAU: Privacy Analysis of Biometric API Usage",
    "abstract": "Biometric data privacy is becoming a major concern for many organizations in\nthe age of big data, particularly in the ICT sector, because it may be easily\nexploited in apps. Most apps utilize biometrics by accessing common application\nprogramming interfaces (APIs); hence, we aim to categorize their usage. The\ncategorization based on behavior may be closely correlated with the sensitive\nprocessing of a user's biometric data, hence highlighting crucial biometric\ndata privacy assessment concerns. We propose PABAU, Privacy Analysis of\nBiometric API Usage. PABAU learns semantic features of methods in biometric\nAPIs and uses them to detect and categorize the usage of biometric API\nimplementation in the software according to their privacy-related behaviors.\nThis technique bridges the communication and background knowledge gap between\ntechnical and non-technical individuals in organizations by providing an\nautomated method for both parties to acquire a rapid understanding of the\nessential behaviors of biometric API in apps, as well as future support to data\nprotection officers (DPO) with legal documentation, such as conducting a Data\nProtection Impact Assessment (DPIA).",
    "descriptor": "\nComments: Accepted by The 8th IEEE International Conference on Privacy Computing (PriComp 2022)\n",
    "authors": [
      "Feiyang Tang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.10861"
  },
  {
    "id": "arXiv:2212.10865",
    "title": "Temporal Disaggregation of the Cumulative Grass Growth",
    "abstract": "Information on the grass growth over a year is essential for some models\nsimulating the use of this resource to feed animals on pasture or at barn with\nhay or grass silage. Unfortunately, this information is rarely available. The\nchallenge is to reconstruct grass growth from two sources of information: usual\ndaily climate data (rainfall, radiation, etc.) and cumulative growth over the\nyear. We have to be able to capture the effect of seasonal climatic events\nwhich are known to distort the growth curve within the year. In this paper, we\nformulate this challenge as a problem of disaggregating the cumulative growth\ninto a time series. To address this problem, our method applies time series\nforecasting using climate information and grass growth from previous time\nsteps. Several alternatives of the method are proposed and compared\nexperimentally using a database generated from a grassland process-based model.\nThe results show that our method can accurately reconstruct the time series,\nindependently of the use of the cumulative growth information.",
    "descriptor": "",
    "authors": [
      "Thomas Guyet",
      "Laurent Spillemaecker",
      "Simon Malinowski",
      "Anne-Isabelle Graux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10865"
  },
  {
    "id": "arXiv:2212.10866",
    "title": "CyberEye: Obtaining Data from Virtual Desktop by Video",
    "abstract": "VDI is no longer safe and reliable anymore. VDI(Virtual Desktop\nInfrastructure, also called Cloud Desktop) is being widely used as working\ninterface to avoid data exfiltration. With VDI client, end users can access\ninternal data without obtaining data actually. In this paper, we present a new\napproach named CyberEye, to extract data from VDI by video even data\ntransmission has been forbidden. By encoding data file to video, playing it in\nVDI meanwhile recording it in host PC, we can get full information of the data\nwith video format, then decode it to recover the original data file. The\nproof-of-concept on Citrix Workspace and several other remote virtual desktops\nhas strongly been proved the availability and reliability of the CyberEye. We\nintroduce the usage in operation model to show how it's been designed and\nimplemented in technical work section. And also, we have opened the source code\nto researchers for reproducing the work.",
    "descriptor": "\nComments: Open source code: this https URL This paper contains 17 pages, 12 figures\n",
    "authors": [
      "Bin Wei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.10866"
  },
  {
    "id": "arXiv:2212.10869",
    "title": "5G Long-Term and Large-Scale Mobile Traffic Forecasting",
    "abstract": "It is crucial for the service provider to comprehend and forecast mobile\ntraffic in large-scale cellular networks in order to govern and manage\nmechanisms for base station placement, load balancing, and network planning.\nThe purpose of this article is to extract and simulate traffic patterns from\nmore than 14,000 cells that have been installed in different metropolitan\nareas. To do this, we create, implement, and assess a method in which cells are\nfirst categorized by their point of interest and then clustered based on the\ntemporal distribution of cells in each region. The proposed model has been\ntested using real-world 5G mobile traffic datasets collected over 31 weeks in\nvarious cities. We found that our proposed model performed well in predicting\nmobile traffic patterns up to 2 weeks in advance. Our model outperformed the\nbase model in most areas of interest and generally achieved up to 15\\% less\nprediction error compared to the na\\\"ive approach. This indicates that our\napproach is effective in predicting mobile traffic patterns in large-scale\ncellular networks.",
    "descriptor": "",
    "authors": [
      "Ufuk Uyan",
      "M. Tugberk Isyapar",
      "Mahiye Uluyagmur Ozturk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.10869"
  },
  {
    "id": "arXiv:2212.10870",
    "title": "MoQuad: Motion-focused Quadruple Construction for Video Contrastive  Learning",
    "abstract": "Learning effective motion features is an essential pursuit of video\nrepresentation learning. This paper presents a simple yet effective sample\nconstruction strategy to boost the learning of motion features in video\ncontrastive learning. The proposed method, dubbed Motion-focused Quadruple\nConstruction (MoQuad), augments the instance discrimination by meticulously\ndisturbing the appearance and motion of both the positive and negative samples\nto create a quadruple for each video instance, such that the model is\nencouraged to exploit motion information. Unlike recent approaches that create\nextra auxiliary tasks for learning motion features or apply explicit temporal\nmodelling, our method keeps the simple and clean contrastive learning paradigm\n(i.e.,SimCLR) without multi-task learning or extra modelling. In addition, we\ndesign two extra training strategies by analyzing initial MoQuad experiments.\nBy simply applying MoQuad to SimCLR, extensive experiments show that we achieve\nsuperior performance on downstream tasks compared to the state of the arts.\nNotably, on the UCF-101 action recognition task, we achieve 93.7% accuracy\nafter pre-training the model on Kinetics-400 for only 200 epochs, surpassing\nvarious previous methods",
    "descriptor": "\nComments: ECCV2022 WorkShop\n",
    "authors": [
      "Yuan Liu",
      "Jiacheng Chen",
      "Hao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10870"
  },
  {
    "id": "arXiv:2212.10873",
    "title": "Prompt-Augmented Linear Probing: Scaling Beyond The Limit of Few-shot  In-Context Learners",
    "abstract": "Through in-context learning (ICL), large-scale language models are effective\nfew-shot learners without additional model fine-tuning. However, the ICL\nperformance does not scale well with the number of available training samples\nas it is limited by the inherent input length constraint of the underlying\nlanguage model. Meanwhile, many studies have revealed that language models are\nalso powerful feature extractors, allowing them to be utilized in a black-box\nmanner and enabling the linear probing paradigm, where lightweight\ndiscriminators are trained on top of the pre-extracted input representations.\nThis paper proposes prompt-augmented linear probing (PALP), a hybrid of linear\nprobing and ICL, which leverages the best of both worlds. PALP inherits the\nscalability of linear probing and the capability of enforcing language models\nto derive more meaningful representations via tailoring input into a more\nconceivable form. Throughout in-depth investigations on various datasets, we\nverified that PALP significantly enhances the input representations closing the\ngap between ICL in the data-hungry scenario and fine-tuning in the\ndata-abundant scenario with little training overhead, potentially making PALP a\nstrong alternative in a black-box scenario.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Hyunsoo Cho",
      "Hyuhng Joon Kim",
      "Junyeob Kim",
      "Sang-Woo Lee",
      "Sang-goo Lee",
      "Kang Min Yoo",
      "Taeuk Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10873"
  },
  {
    "id": "arXiv:2212.10875",
    "title": "Reactive Synthesis for DECLARE via symbolic automata",
    "abstract": "Given a specification of linear-time temporal logic interpreted over finite\ntraces (LTLf), the reactive synthesis problem asks to find a\nfinitely-representable, terminating controller that reacts to the\nuncontrollable actions of an environment in order to enforce a desired system\nspecification. In this paper we study, for the first time, the reactive\nsynthesis problem for DECLARE - a fragment of LTLf extensively used both in\ntheory and practice for specifying declarative, constraint-based business\nprocesses. We provide a threefold contribution. First, we give a naive, doubly\nexponential time synthesis algorithm for this problem. Second, we show how an\narbitrary DECLARE specification can be compactly encoded into an equivalent\npure past one in LTLf, and we exploit this to define an optimized, singly\nexponential time algorithm for DECLARE synthesis. Third, we derive a symbolic\nversion of this algorithm, by introducing a novel translation of pure-past\ntemporal formulas into symbolic deterministic finite automata.",
    "descriptor": "",
    "authors": [
      "Luca Geatti",
      "Marco Montali",
      "Andrey Rivkin"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.10875"
  },
  {
    "id": "arXiv:2212.10876",
    "title": "Hyperparameters in Contextual RL are Highly Situational",
    "abstract": "Although Reinforcement Learning (RL) has shown impressive results in games\nand simulation, real-world application of RL suffers from its instability under\nchanging environment conditions and hyperparameters. We give a first impression\nof the extent of this instability by showing that the hyperparameters found by\nautomatic hyperparameter optimization (HPO) methods are not only dependent on\nthe problem at hand, but even on how well the state describes the environment\ndynamics. Specifically, we show that agents in contextual RL require different\nhyperparameters if they are shown how environmental factors change. In\naddition, finding adequate hyperparameter configurations is not equally easy\nfor both settings, further highlighting the need for research into how\nhyperparameters influence learning and generalization in RL.",
    "descriptor": "",
    "authors": [
      "Theresa Eimer",
      "Carolin Benjamins",
      "Marius Lindauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10876"
  },
  {
    "id": "arXiv:2212.10878",
    "title": "Automatic Network Adaptation for Ultra-Low Uniform-Precision  Quantization",
    "abstract": "Uniform-precision neural network quantization has gained popularity since it\nsimplifies densely packed arithmetic unit for high computing capability.\nHowever, it ignores heterogeneous sensitivity to the impact of quantization\nerrors across the layers, resulting in sub-optimal inference accuracy. This\nwork proposes a novel neural architecture search called neural channel\nexpansion that adjusts the network structure to alleviate accuracy degradation\nfrom ultra-low uniform-precision quantization. The proposed method selectively\nexpands channels for the quantization sensitive layers while satisfying\nhardware constraints (e.g., FLOPs, PARAMs). Based on in-depth analysis and\nexperiments, we demonstrate that the proposed method can adapt several popular\nnetworks channels to achieve superior 2-bit quantization accuracy on CIFAR10\nand ImageNet. In particular, we achieve the best-to-date Top-1/Top-5 accuracy\nfor 2-bit ResNet50 with smaller FLOPs and the parameter size.",
    "descriptor": "",
    "authors": [
      "Seongmin Park",
      "Beomseok Kwon",
      "Jieun Lim",
      "Kyuyoung Sim",
      "Taeho Kim",
      "Jungwook Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10878"
  },
  {
    "id": "arXiv:2212.10879",
    "title": "Cross-Linguistic Syntactic Difference in Multilingual BERT: How Good is  It and How Does It Affect Transfer?",
    "abstract": "Multilingual BERT (mBERT) has demonstrated considerable cross-lingual\nsyntactic ability, whereby it enables effective zero-shot cross-lingual\ntransfer of syntactic knowledge. The transfer is more successful between some\nlanguages, but it is not well understood what leads to this variation and\nwhether it fairly reflects difference between languages. In this work, we\ninvestigate the distributions of grammatical relations induced from mBERT in\nthe context of 24 typologically different languages. We demonstrate that the\ndistance between the distributions of different languages is highly consistent\nwith the syntactic difference in terms of linguistic formalisms. Such\ndifference learnt via self-supervision plays a crucial role in the zero-shot\ntransfer performance and can be predicted by variation in morphosyntactic\nproperties between languages. These results suggest that mBERT properly encodes\nlanguages in a way consistent with linguistic diversity and provide insights\ninto the mechanism of cross-lingual transfer.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Ningyu Xu",
      "Tao Gui",
      "Ruotian Ma",
      "Qi Zhang",
      "Jingting Ye",
      "Menghan Zhang",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10879"
  },
  {
    "id": "arXiv:2212.10881",
    "title": "In-Sensor & Neuromorphic Computing are all you need for Energy Efficient  Computer Vision",
    "abstract": "Due to the high activation sparsity and use of accumulates (AC) instead of\nexpensive multiply-and-accumulates (MAC), neuromorphic spiking neural networks\n(SNNs) have emerged as a promising low-power alternative to traditional DNNs\nfor several computer vision (CV) applications. However, most existing SNNs\nrequire multiple time steps for acceptable inference accuracy, hindering\nreal-time deployment and increasing spiking activity and, consequently, energy\nconsumption. Recent works proposed direct encoding that directly feeds the\nanalog pixel values in the first layer of the SNN in order to significantly\nreduce the number of time steps. Although the overhead for the first layer MACs\nwith direct encoding is negligible for deep SNNs and the CV processing is\nefficient using SNNs, the data transfer between the image sensors and the\ndownstream processing costs significant bandwidth and may dominate the total\nenergy. To mitigate this concern, we propose an in-sensor computing\nhardware-software co-design framework for SNNs targeting image recognition\ntasks. Our approach reduces the bandwidth between sensing and processing by\n12-96x and the resulting total energy by 2.32x compared to traditional CV\nprocessing, with a 3.8% reduction in accuracy on ImageNet.",
    "descriptor": "",
    "authors": [
      "Gourav Datta",
      "Zeyu Liu",
      "Md Abdullah-Al Kaiser",
      "Souvik Kundu",
      "Joe Mathai",
      "Zihan Yin",
      "Ajey P. Jacob",
      "Akhilesh R. Jaiswal",
      "Peter A. Beerel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10881"
  },
  {
    "id": "arXiv:2212.10888",
    "title": "A Survey of Mix-based Data Augmentation: Taxonomy, Methods,  Applications, and Explainability",
    "abstract": "Data augmentation (DA) is indispensable in modern machine learning and deep\nneural networks. The basic idea of DA is to construct new training data to\nimprove the model's generalization by adding slightly disturbed versions of\nexisting data or synthesizing new data. In this work, we review a small but\nessential subset of DA -- Mix-based Data Augmentation (MixDA) that generates\nnovel samples by mixing multiple examples. Unlike conventional DA approaches\nbased on a single-sample operation or requiring domain knowledge, MixDA is more\ngeneral in creating a broad spectrum of new data and has received increasing\nattention in the community. We begin with proposing a new taxonomy classifying\nMixDA into, Mixup-based, Cutmix-based, and hybrid approaches according to a\nhierarchical view of the data mix. Various MixDA techniques are then\ncomprehensively reviewed in a more fine-grained way. Owing to its\ngeneralization, MixDA has penetrated a variety of applications which are also\ncompletely reviewed in this work. We also examine why MixDA works from\ndifferent aspects of improving model performance, generalization, and\ncalibration while explaining the model behavior based on the properties of\nMixDA. Finally, we recapitulate the critical findings and fundamental\nchallenges of current MixDA studies, and outline the potential directions for\nfuture works. Different from previous related works that summarize the DA\napproaches in a specific domain (e.g., images or natural language processing)\nor only review a part of MixDA studies, we are the first to provide a\nsystematical survey of MixDA in terms of its taxonomy, methodology,\napplications, and explainability. This work can serve as a roadmap to MixDA\ntechniques and application reviews while providing promising directions for\nresearchers interested in this exciting area.",
    "descriptor": "",
    "authors": [
      "Chengtai Cao",
      "Fan Zhou",
      "Yurou Dai",
      "Jianping Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10888"
  },
  {
    "id": "arXiv:2212.10897",
    "title": "Deterministic-Random Tradeoff of Integrated Sensing and Communications  in Gaussian Channels: A Rate-Distortion Perspective",
    "abstract": "Integrated sensing and communications (ISAC) is recognized as a key enabling\ntechnology for future wireless networks. To shed light on the fundamental\nperformance limits of ISAC systems, this paper studies the deterministic-random\ntradeoff between sensing and communications (S\\&C) from a rate-distortion\nperspective under Gaussian ISAC channels. We model the ISAC signal as a random\nmatrix that carries information, whose realization is perfectly known to the\nsensing receiver, but is unknown to the communication receiver. We characterize\nthe sensing mutual information conditioned on the random ISAC signal, and show\nthat it provides a universal lower bound for distortion metrics of sensing.\nFurthermore, we prove that the distortion lower bound is minimized if the\nsample covariance matrix of the ISAC signal is deterministic. We then offer our\nunderstanding of the main results by interpreting wireless sensing as\nnon-cooperative source-channel coding. Finally, we provide sufficient\nconditions for the achievability of the distortion lower bound by analyzing a\nspecific example of target response matrix estimation.",
    "descriptor": "\nComments: 8 pages, 3 figures, submitted to IEEE for possible publications\n",
    "authors": [
      "Fan Liu",
      "Yifeng Xiong",
      "Kai Wan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.10897"
  },
  {
    "id": "arXiv:2212.10898",
    "title": "Training language models for deeper understanding improves brain  alignment",
    "abstract": "Building systems that achieve a deeper understanding of language is one of\nthe central goals of natural language processing (NLP). Towards this goal,\nrecent works have begun to train language models on narrative datasets which\nrequire extracting the most critical information by integrating across long\ncontexts. However, it is still an open question whether these models are\nlearning a deeper understanding of the text, or if the models are simply\nlearning a heuristic to complete the task. This work investigates this further\nby turning to the one language processing system that truly understands complex\nlanguage: the human brain. We show that training language models for deeper\nnarrative understanding results in richer representations that have improved\nalignment to human brain activity. We further find that the improvements in\nbrain alignment are larger for character names than for other discourse\nfeatures, which indicates that these models are learning important narrative\nelements. Taken together, these results suggest that this type of training can\nindeed lead to deeper language understanding. These findings have consequences\nboth for cognitive neuroscience by revealing some of the significant factors\nbehind brain-NLP alignment, and for NLP by highlighting that understanding of\nlong-range context can be improved beyond language modeling.",
    "descriptor": "\nComments: 37 pages, 42 figures\n",
    "authors": [
      "Khai Loong Aw",
      "Mariya Toneva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2212.10898"
  },
  {
    "id": "arXiv:2212.10901",
    "title": "RECAP: Retrieval Augmented Music Captioner",
    "abstract": "With the prevalence of stream media platforms serving music search and\nrecommendation, interpreting music by understanding audio and lyrics\ninteractively has become an important and challenging task. However, many\nprevious works focus on refining individual components of encoder-decoder\narchitecture mapping music to caption tokens, ignoring the potential usage of\naudio and lyrics correspondence. In this paper, we propose to explicitly learn\nthe multi-modal alignment with retrieval augmentation by contrastive learning.\nBy learning audio-lyrics correspondence, the model is guided to learn better\ncross-modal attention weights, thus generating high-quality caption words. We\nprovide both theoretical and empirical results that demonstrate the advantage\nof the proposed method.",
    "descriptor": "",
    "authors": [
      "Zihao He",
      "Weituo Hao",
      "Xuchen Song"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.10901"
  },
  {
    "id": "arXiv:2212.10909",
    "title": "Inf-sup stabilized Scott-Vogelius pairs on general simplicial grids for  Navier-Stokes equations",
    "abstract": "This paper considers the discretization of the time-dependent Navier-Stokes\nequations with the family of inf-sup stabilized Scott-Vogelius pairs recently\nintroduced in [John/Li/Merdon/Rui, arXiv:2206.01242, 2022] for the Stokes\nproblem. Therein, the velocity space is obtained by enriching the\nH^1-conforming Lagrange element space with some H(div)-conforming\nRaviart-Thomas functions, such that the divergence constraint is satisfied\nexactly. In these methods arbitrary shape-regular simplicial grids can be used.\nIn the present paper two alternatives for discretizing the convective terms\nare considered. One variant leads to a scheme that still only involves volume\nintegrals, and the other variant employs upwinding known from DG schemes. Both\nvariants ensure the conservation of linear momentum and angular momentum in\nsome suitable sense. In addition, a pressure-robust and convection-robust\nvelocity error estimate is derived, i.e., the velocity error bound does not\ndepend on the pressure and the constant in the error bound for the kinetic\nenergy does not blow up for small viscosity. After condensation of the\nenrichment unknowns and all non-constant pressure unknowns, the method can be\nreduced to a $P_k-P_0$-like system for arbitrary velocity polynomial degree\n$k$. Numerical studies verify the theoretical findings.",
    "descriptor": "",
    "authors": [
      "Naveed Ahmed",
      "Volker John",
      "Xu Li",
      "Christian Merdon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.10909"
  },
  {
    "id": "arXiv:2212.10913",
    "title": "Ensemble learning techniques for intrusion detection system in the  context of cybersecurity",
    "abstract": "Recently, there has been an interest in improving the resources available in\nIntrusion Detection System (IDS) techniques. In this sense, several studies\nrelated to cybersecurity show that the environment invasions and information\nkidnapping are increasingly recurrent and complex. The criticality of the\nbusiness involving operations in an environment using computing resources does\nnot allow the vulnerability of the information. Cybersecurity has taken on a\ndimension within the universe of indispensable technology in corporations, and\nthe prevention of risks of invasions into the environment is dealt with daily\nby Security teams. Thus, the main objective of the study was to investigate the\nEnsemble Learning technique using the Stacking method, supported by the Support\nVector Machine (SVM) and k-Nearest Neighbour (kNN) algorithms aiming at an\noptimization of the results for DDoS attack detection. For this, the Intrusion\nDetection System concept was used with the application of the Data Mining and\nMachine Learning Orange tool to obtain better results",
    "descriptor": "\nComments: in Portuguese language. CIACA - Conferencia Ibero-Americana Computa\\c{c}\\~ao Aplicada 2022 Proceedings\n",
    "authors": [
      "Andricson Abeline Moreira",
      "Carlos A. C. Tojeiro",
      "Carlos J. Reis",
      "Gustavo Henrique Massaro",
      "Igor Andrade Brito e Kelton A. P. da Costa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10913"
  },
  {
    "id": "arXiv:2212.10915",
    "title": "Automatic Semantic Modeling for Structural Data Source with the Prior  Knowledge from Knowledge Base",
    "abstract": "A critical step in sharing semantic content online is to map the structural\ndata source to a public domain ontology. This problem is denoted as the\nRelational-To-Ontology Mapping Problem (Rel2Onto). A huge effort and expertise\nare required for manually modeling the semantics of data. Therefore, an\nautomatic approach for learning the semantics of a data source is desirable.\nMost of the existing work studies the semantic annotation of source attributes.\nHowever, although critical, the research for automatically inferring the\nrelationships between attributes is very limited. In this paper, we propose a\nnovel method for semantically annotating structured data sources using machine\nlearning, graph matching and modified frequent subgraph mining to amend the\ncandidate model. In our work, Knowledge graph is used as prior knowledge. Our\nevaluation shows that our approach outperforms two state-of-the-art solutions\nin tricky cases where only a few semantic models are known.",
    "descriptor": "",
    "authors": [
      "Jiakang Xu",
      "Wolfgang Mayer",
      "HongYu Zhang",
      "Keqing He",
      "Zaiwen Feng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10915"
  },
  {
    "id": "arXiv:2212.10923",
    "title": "Language Models as Inductive Reasoners",
    "abstract": "Inductive reasoning is a core component of human intelligence. In the past\nresearch of inductive reasoning within computer science, logic language is used\nas representations of knowledge (facts and rules, more specifically). However,\nlogic language can cause systematic problems for inductive reasoning such as\ndisability of handling raw input such as natural language, sensitiveness to\nmislabeled data, and incapacity to handle ambiguous input. To this end, we\npropose a new task, which is to induce natural language rules from natural\nlanguage facts, and create a dataset termed DEER containing 1.2k rule-fact\npairs for the task, where rules and facts are written in natural language. New\nautomatic metrics are also proposed and analysed for the evaluation of this\ntask. With DEER, we investigate a modern approach for inductive reasoning where\nwe use natural language as representation for knowledge instead of logic\nlanguage and use pretrained language models as ''reasoners''. Moreover, we\nprovide the first and comprehensive analysis of how well pretrained language\nmodels can induce natural language rules from natural language facts. We also\npropose a new framework drawing insights from philosophy literature for this\ntask, which we show in the experiment section that surpasses baselines in both\nautomatic and human evaluations.",
    "descriptor": "",
    "authors": [
      "Zonglin Yang",
      "Li Dong",
      "Xinya Du",
      "Hao Cheng",
      "Erik Cambria",
      "Xiaodong Liu",
      "Jianfeng Gao",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10923"
  },
  {
    "id": "arXiv:2212.10926",
    "title": "The Internet of Bio-Nano Things in Blood Vessels: System Design and  Prototypes",
    "abstract": "In this paper, we investigate the Internet of Bio-Nano Things (IoBNT) which\nrelates to networks formed by molecular communications. By providing a means of\ncommunication through the ubiquitously connected blood vessels (arteries,\nveins, and capillaries), molecular communication-based IoBNT enables a host of\nnew eHealth applications. For example, an organ monitoring sensor can transfer\ninternal body signals through the IoBNT for health monitoring applications. We\nempirically show that blood vessel channels introduce a new set of challenges\nfor the design of molecular communication systems in comparison to free-space\nchannels. We then propose cylindrical duct channel models and discuss the\ncorresponding system designs conforming to the channel characteristics.\nFurthermore, based on prototype implementations, we confirm that molecular\ncommunication techniques can be utilized for composing the IoBNT. We believe\nthat the promising results presented in this work, together with the rich\nresearch challenges that lie ahead, are strong indicators that IoBNT with\nmolecular communications can drive novel applications for emerging eHealth\nsystems.",
    "descriptor": "",
    "authors": [
      "Changmin Lee",
      "Bon-Hong Koo",
      "Chan-Byoung Chae",
      "Robert Schober"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.10926"
  },
  {
    "id": "arXiv:2212.10929",
    "title": "SPT: Semi-Parametric Prompt Tuning for Multitask Prompted Learning",
    "abstract": "Pre-trained large language models can efficiently interpolate human-written\nprompts in a natural way. Multitask prompted learning can help generalization\nthrough a diverse set of tasks at once, thus enhancing the potential for more\neffective downstream fine-tuning. To perform efficient multitask-inference in\nthe same batch, parameter-efficient fine-tuning methods such as prompt tuning\nhave been proposed. However, the existing prompt tuning methods may lack\ngeneralization. We propose SPT, a semi-parametric prompt tuning method for\nmultitask prompted learning. The novel component of SPT is a memory bank from\nwhere memory prompts are retrieved based on discrete prompts. Extensive\nexperiments, such as (i) fine-tuning a full language model with SPT on 31\ndifferent tasks from 8 different domains and evaluating zero-shot\ngeneralization on 9 heldout datasets under 5 NLP task categories and (ii)\npretraining SPT on the GLUE datasets and evaluating fine-tuning on the\nSuperGLUE datasets, demonstrate effectiveness of SPT.",
    "descriptor": "",
    "authors": [
      "M Saiful Bari",
      "Aston Zhang",
      "Shuai Zheng",
      "Xingjian Shi",
      "Yi Zhu",
      "Shafiq Joty",
      "Mu Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10929"
  },
  {
    "id": "arXiv:2212.10930",
    "title": "Minimizing Worst-Case Violations of Neural Networks",
    "abstract": "Machine learning (ML) algorithms are remarkably good at approximating complex\nnon-linear relationships. Most ML training processes, however, are designed to\ndeliver ML tools with good average performance, but do not offer any guarantees\nabout their worst-case estimation error. For safety-critical systems such as\npower systems, this places a major barrier for their adoption. So far,\napproaches could determine the worst-case violations of only trained ML\nalgorithms. To the best of our knowledge, this is the first paper to introduce\na neural network training procedure designed to achieve both a good average\nperformance and minimum worst-case violations. Using the Optimal Power Flow\n(OPF) problem as a guiding application, our approach (i) introduces a framework\nthat reduces the worst-case generation constraint violations during training,\nincorporating them as a differentiable optimization layer; and (ii) presents a\nneural network sequential learning architecture to significantly accelerate it.\nWe demonstrate the proposed architecture on four different test systems ranging\nfrom 39 buses to 162 buses, for both AC-OPF and DC-OPF applications.",
    "descriptor": "",
    "authors": [
      "Rahul Nellikkath",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.10930"
  },
  {
    "id": "arXiv:2212.10931",
    "title": "Completeness and the Finite Model Property for Kleene Algebra,  Reconsidered",
    "abstract": "Kleene Algebra (KA) is the algebra of regular expressions. Central to the\nstudy of KA is Kozen's (1994) completeness result, which says that any\nequivalence valid in the language model of KA follows from the axioms of KA.\nAlso of interest is the finite model property (FMP), which says that false\nequivalences always have a finite counterexample. Palka (2005) showed that, for\nKA, the FMP is equivalent to completeness.\nWe provide a unified and elementary proof of both properties. In contrast\nwith earlier completeness proofs, this proof does not rely on minimality or\nbisimilarity techniques for deterministic automata. Instead, our approach\navoids deterministic automata altogether, and uses Antimirov's derivatives and\nthe well-known transition monoid construction.\nOur results are fully verified in the Coq proof assistant.",
    "descriptor": "",
    "authors": [
      "Tobias Kapp\u00e9"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.10931"
  },
  {
    "id": "arXiv:2212.10933",
    "title": "Resolving Indirect Referring Expressions for Entity Selection",
    "abstract": "Recent advances in language modeling have enabled new conversational systems.\nIn particular, it is often desirable for people to make choices among specified\noptions when using such systems. We address the problem of reference\nresolution, when people use natural expressions to choose between real world\nentities. For example, given the choice `Should we make a Simnel cake or a\nPandan cake?' a natural response from a non-expert may be indirect: `let's make\nthe green one'. Reference resolution has been little studied with natural\nexpressions, thus robustly understanding such language has large potential for\nimproving naturalness in dialog, recommendation, and search systems. We create\nAltEntities (Alternative Entities), a new public dataset of entity pairs and\nutterances, and develop models for the disambiguation problem. Consisting of\n42K indirect referring expressions across three domains, it enables for the\nfirst time the study of how large language models can be adapted to this task.\nWe find they achieve 82%-87% accuracy in realistic settings, which while\nreasonable also invites further advances.",
    "descriptor": "",
    "authors": [
      "Mohammad Javad Hosseini",
      "Filip Radlinski",
      "Silvia Pareti",
      "Annie Louis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10933"
  },
  {
    "id": "arXiv:2212.10935",
    "title": "Esports Data-to-commentary Generation on Large-scale Data-to-text  Dataset",
    "abstract": "Esports, a sports competition using video games, has become one of the most\nimportant sporting events in recent years. Although the amount of esports data\nis increasing than ever, only a small fraction of those data accompanies text\ncommentaries for the audience to retrieve and understand the plays. Therefore,\nin this study, we introduce a task of generating game commentaries from\nstructured data records to address the problem. We first build a large-scale\nesports data-to-text dataset using structured data and commentaries from a\npopular esports game, League of Legends. On this dataset, we devise several\ndata preprocessing methods including linearization and data splitting to\naugment its quality. We then introduce several baseline encoder-decoder models\nand propose a hierarchical model to generate game commentaries. Considering the\ncharacteristics of esports commentaries, we design evaluation metrics including\nthree aspects of the output: correctness, fluency, and strategic depth.\nExperimental results on our large-scale esports dataset confirmed the advantage\nof the hierarchical model, and the results revealed several challenges of this\nnovel task.",
    "descriptor": "",
    "authors": [
      "Zihan Wang",
      "Naoki Yoshinaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10935"
  },
  {
    "id": "arXiv:2212.10936",
    "title": "A Memetic Algorithm with Reinforcement Learning for Sociotechnical  Production Scheduling",
    "abstract": "The following article presents a memetic algorithm with applying deep\nreinforcement learning (DRL) for solving practically oriented dual resource\nconstrained flexible job shop scheduling problems (DRC-FJSSP). In recent years,\nthere has been extensive research on DRL techniques, but without considering\nrealistic, flexible and human-centered shopfloors. A research gap can be\nidentified in the context of make-to-order oriented discontinuous manufacturing\nas it is often represented in medium-size companies with high service levels.\nFrom practical industry projects in this domain, we recognize requirements to\ndepict flexible machines, human workers and capabilities, setup and processing\noperations, material arrival times, complex job paths with parallel tasks for\nbill of material (BOM) manufacturing, sequence-depended setup times and\n(partially) automated tasks. On the other hand, intensive research has been\ndone on metaheuristics in the context of DRC-FJSSP. However, there is a lack of\nsuitable and generic scheduling methods that can be holistically applied in\nsociotechnical production and assembly processes. In this paper, we first\nformulate an extended DRC-FJSSP induced by the practical requirements\nmentioned. Then we present our proposed hybrid framework with parallel\ncomputing for multicriteria optimization. Through numerical experiments with\nreal-world data, we confirm that the framework generates feasible schedules\nefficiently and reliably. Utilizing DRL instead of random operations leads to\nbetter results and outperforms traditional approaches.",
    "descriptor": "",
    "authors": [
      "Felix Grumbach",
      "Nour Eldin Alaa Badr",
      "Pascal Reusch",
      "Sebastian Trojahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.10936"
  },
  {
    "id": "arXiv:2212.10937",
    "title": "DCC: A Cascade based Approach to Detect Communities in Social Networks",
    "abstract": "Community detection in Social Networks is associated with finding and\ngrouping the most similar nodes inherent in the network. These similar nodes\nare identified by computing tie strength. Stronger ties indicates higher\nproximity shared by connected node pairs. This work is motivated by\nGranovetter's argument that suggests that strong ties lies within densely\nconnected nodes and the theory that community cores in real-world networks are\ndensely connected. In this paper, we have introduced a novel method called\n\\emph{Disjoint Community detection using Cascades (DCC)} which demonstrates the\neffectiveness of a new local density based tie strength measure on detecting\ncommunities. Here, tie strength is utilized to decide the paths followed for\npropagating information. The idea is to crawl through the tuple information of\ncascades towards the community core guided by increasing tie strength.\nConsidering the cascade generation step, a novel preferential membership method\nhas been developed to assign community labels to unassigned nodes. The efficacy\nof $DCC$ has been analyzed based on quality and accuracy on several real-world\ndatasets and baseline community detection algorithms.",
    "descriptor": "\nComments: To be published in CHSN-2022\n",
    "authors": [
      "Soumita Das",
      "Anupam Biswas",
      "Akrati Saxena"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10937"
  },
  {
    "id": "arXiv:2212.10938",
    "title": "Critic-Guided Decoding for Controlled Text Generation",
    "abstract": "Steering language generation towards objectives or away from undesired\ncontent has been a long-standing goal in utilizing language models (LM). Recent\nwork has demonstrated reinforcement learning and weighted decoding as effective\napproaches to achieve a higher level of language control and quality with pros\nand cons. In this work, we propose a novel critic decoding method for\ncontrolled language generation (CriticControl) that combines the strengths of\nreinforcement learning and weighted decoding. Specifically, we adopt the\nactor-critic framework to train an LM-steering critic from non-differentiable\nreward models. And similar to weighted decoding, our method freezes the\nlanguage model and manipulates the output token distribution using called\ncritic, improving training efficiency and stability. Evaluation of our method\non three controlled generation tasks, namely topic control, sentiment control,\nand detoxification, shows that our approach generates more coherent and\nwell-controlled texts than previous methods. In addition, CriticControl\ndemonstrates superior generalization ability in zero-shot settings. Human\nevaluation studies also corroborate our findings.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Minbeom Kim",
      "Hwanhee Lee",
      "Kang Min Yoo",
      "Joonsuk Park",
      "Hwaran Lee",
      "Kyomin Jung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10938"
  },
  {
    "id": "arXiv:2212.10939",
    "title": "Joint Embedding of 2D and 3D Networks for Medical Image Anomaly  Detection",
    "abstract": "Obtaining ground truth data in medical imaging has difficulties due to the\nfact that it requires a lot of annotating time from the experts in the field.\nAlso, when trained with supervised learning, it detects only the cases included\nin the labels. In real practice, we want to also open to other possibilities\nthan the named cases while examining the medical images. As a solution, the\nneed for anomaly detection that can detect and localize abnormalities by\nlearning the normal characteristics using only normal images is emerging. With\nmedical image data, we can design either 2D or 3D networks of self-supervised\nlearning for anomaly detection task. Although 3D networks, which learns 3D\nstructures of the human body, show good performance in 3D medical image anomaly\ndetection, they cannot be stacked in deeper layers due to memory problems.\nWhile 2D networks have advantage in feature detection, they lack 3D context\ninformation. In this paper, we develop a method for combining the strength of\nthe 3D network and the strength of the 2D network through joint embedding. We\nalso propose the pretask of self-supervised learning to make it possible for\nthe networks to learn efficiently. Through the experiments, we show that the\nproposed method achieves better performance in both classification and\nsegmentation tasks compared to the SoTA method.",
    "descriptor": "\nComments: 15 pages, 11 figures\n",
    "authors": [
      "Inha Kang",
      "Jinah Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10939"
  },
  {
    "id": "arXiv:2212.10945",
    "title": "Standoff Tracking Using DNN-Based MPC with Implementation on FPGA",
    "abstract": "This work studies the standoff tracking problem to drive an unmanned aerial\nvehicle (UAV) to slide on a desired circle over a moving target at a constant\nheight. We propose a novel Lyapunov guidance vector (LGV) field with tunable\nconvergence rates for the UAV's trajectory planning and a deep neural network\n(DNN)-based model predictive control (MPC) scheme to track the reference\ntrajectory. Then, we show how to collect samples for training the DNN offline\nand design an integral module (IM) to refine the tracking performance of our\nDNN-based MPC. Moreover, the hardware-in-the-loop (HIL) simulation with an\nFPGA@200MHz demonstrates that our method is a valid alternative to embedded\nimplementations of MPC for addressing complex systems and applications which is\nimpossible for directly solving the MPC optimization problems.",
    "descriptor": "",
    "authors": [
      "Fei Dong",
      "Xingchen Li",
      "Keyou You",
      "Shiji Song"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.10945"
  },
  {
    "id": "arXiv:2212.10946",
    "title": "A model-based framework for integrated process design and flexibility  analysis",
    "abstract": "Process development is typically associated with lengthy wet-lab experiments\nfor the identification of good candidate set ups and operating conditions. In\nthis paper, we present the key features of a model-based framework for the\nidentification and assessment of process design spaces, integrating the\nanalysis of process performance and flexibility. The framework comprises three\nmain steps: (1) model development & problem formulation, (2) design space\nidentification and (3) design space analysis. For the first time, a\nmathematical representation of the design space boundary is obtained and\nexploited for the investigation of nominal operating points. We demonstrate how\nthe proposed framework can be used for the identification of acceptable\noperating spaces, quantification of operational flexibility and assessment of\ndifferent operating points. The proposed framework is demonstrated on Protein A\nchromatographic separation of antibody-based therapeutics from cell-derived\nimpurities, used in biopharmaceutical manufacturing.",
    "descriptor": "\nComments: 34 pages, 10 figures\n",
    "authors": [
      "Steven Sachio",
      "Cleo Kontoravdi",
      "Maria M. Papathanasiou"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2212.10946"
  },
  {
    "id": "arXiv:2212.10947",
    "title": "Parallel Context Windows Improve In-Context Learning of Large Language  Models",
    "abstract": "For applications that require processing large amounts of text at inference\ntime, Large Language Models (LLMs) are handicapped by their limited context\nwindows, which are typically 2048 tokens. In-context learning, an emergent\nphenomenon in LLMs in sizes above a certain parameter threshold, constitutes\none significant example because it can only leverage training examples that fit\ninto the context window. Existing efforts to address the context window\nlimitation involve training specialized architectures, which tend to be smaller\nthan the sizes in which in-context learning manifests due to the memory\nfootprint of processing long texts. We present Parallel Context Windows (PCW),\na method that alleviates the context window restriction for any off-the-shelf\nLLM without further training. The key to the approach is to carve a long\ncontext into chunks (``windows'') that fit within the architecture, restrict\nthe attention mechanism to apply only within each window, and re-use the\npositional embeddings among the windows. We test the PCW approach on in-context\nlearning with models that range in size between 750 million and 178 billion\nparameters, and show substantial improvements for tasks with diverse input and\noutput spaces. Our results motivate further investigation of Parallel Context\nWindows as a method for applying off-the-shelf LLMs in other settings that\nrequire long text sequences.",
    "descriptor": "",
    "authors": [
      "Nir Ratner",
      "Yoav Levine",
      "Yonatan Belinkov",
      "Ori Ram",
      "Omri Abend",
      "Ehud Karpas",
      "Amnon Shashua",
      "Kevin Leyton-Brown",
      "Yoav Shoham"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10947"
  },
  {
    "id": "arXiv:2212.10950",
    "title": "Incremental Learning for Neural Radiance Field with Uncertainty-Filtered  Knowledge Distillation",
    "abstract": "Recent neural radiance field (NeRF) representation has achieved great success\nin the tasks of novel view synthesis and 3D reconstruction. However, they\nsuffer from the catastrophic forgetting problem when continuously learning from\nstreaming data without revisiting the previous training data. This limitation\nprohibits the application of existing NeRF models to scenarios where images\ncome in sequentially. In view of this, we explore the task of incremental\nlearning for neural radiance field representation in this work. We first\npropose a student-teacher pipeline to mitigate the catastrophic forgetting\nproblem. Specifically, we iterate the process of using the student as the\nteacher at the end of each incremental step and let the teacher guide the\ntraining of the student in the next step. In this way, the student network is\nable to learn new information from the streaming data and retain old knowledge\nfrom the teacher network simultaneously. Given that not all information from\nthe teacher network is helpful since it is only trained with the old data, we\nfurther introduce a random inquirer and an uncertainty-based filter to filter\nuseful information. We conduct experiments on the NeRF-synthetic360 and\nNeRF-real360 datasets, where our approach significantly outperforms the\nbaselines by 7.3% and 25.2% in terms of PSNR. Furthermore, we also show that\nour approach can be applied to the large-scale camera facing-outwards dataset\nScanNet, where we surpass the baseline by 60.0% in PSNR.",
    "descriptor": "",
    "authors": [
      "Mengqi Guo",
      "Chen Li",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10950"
  },
  {
    "id": "arXiv:2212.10957",
    "title": "TruFor: Leveraging all-round clues for trustworthy image forgery  detection and localization",
    "abstract": "In this paper we present TruFor, a forensic framework that can be applied to\na large variety of image manipulation methods, from classic cheapfakes to more\nrecent manipulations based on deep learning. We rely on the extraction of both\nhigh-level and low-level traces through a transformer-based fusion architecture\nthat combines the RGB image and a learned noise-sensitive fingerprint. The\nlatter learns to embed the artifacts related to the camera internal and\nexternal processing by training only on real data in a self-supervised manner.\nForgeries are detected as deviations from the expected regular pattern that\ncharacterizes each pristine image. Looking for anomalies makes the approach\nable to robustly detect a variety of local manipulations, ensuring\ngeneralization. In addition to a pixel-level localization map and a whole-image\nintegrity score, our approach outputs a reliability map that highlights areas\nwhere localization predictions may be error-prone. This is particularly\nimportant in forensic applications in order to reduce false alarms and allow\nfor a large scale analysis. Extensive experiments on several datasets show that\nour method is able to reliably detect and localize both cheapfakes and\ndeepfakes manipulations outperforming state-of-the-art works. Code will be\npublicly available at https://grip-unina.github.io/TruFor/",
    "descriptor": "",
    "authors": [
      "Fabrizio Guillaro",
      "Davide Cozzolino",
      "Avneesh Sud",
      "Nicholas Dufour",
      "Luisa Verdoliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10957"
  },
  {
    "id": "arXiv:2212.10960",
    "title": "The Ties that matter: From the perspective of Similarity Measure in  Online Social Networks",
    "abstract": "Online Social Networks have embarked on the importance of connection strength\nmeasures which has a broad array of applications such as, analyzing diffusion\nbehaviors, community detection, link predictions, recommender systems. Though\nthere are some existing connection strength measures, the density that a\nconnection shares with it's neighbors and the directionality aspect has not\nreceived much attention. In this paper, we have proposed an asymmetric edge\nsimilarity measure namely, Neighborhood Density-based Edge Similarity (NDES)\nwhich provides a fundamental support to derive the strength of connection. The\ntime complexity of NDES is $O(nk^2)$. An application of NDES for community\ndetection in social network is shown. We have considered a similarity based\ncommunity detection technique and substituted its similarity measure with NDES.\nThe performance of NDES is evaluated on several small real-world datasets in\nterms of the effectiveness in detecting communities and compared with three\nwidely used similarity measures. Empirical results show NDES enables detecting\ncomparatively better communities both in terms of accuracy and quality.",
    "descriptor": "\nComments: To be published in MINDS-2021\n",
    "authors": [
      "Soumita Das",
      "Anupam Biswas"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2212.10960"
  },
  {
    "id": "arXiv:2212.10961",
    "title": "Computational framework for complex flow and transport in heterogeneous  porous media",
    "abstract": "We present a flexible scalable open-source computational framework, named\nSECUReFoam, based on the finite-volume library OpenFOAM(R), for flow and\ntransport problems in highly heterogeneous geological media and other porous\nmaterials. The framework combines geostatistical pre- and post-processing tools\nwith specialised Partial Differential Equations solvers. Random fields, for\npermeability and other physical properties, are generated by means of\ncontinuous or thresholded Gaussian random fields with various\ncovariance/variogram functions. The generation process is based on an explicit\nspectral Fourier decomposition of the field which, although more\ncomputationally intensive than Fast Fourier Transform methods, allows a more\nflexible choice of statistical parameters and can be used for general\ngeometries and grids. Flow and transport equations are solved for single-phase\nand variable density problems, with and without the Boussinesq approximation,\nand for a wide range of density, viscosity, and dispersion models, including\ndual-continuum (dual permeability or dual porosity) formulations. The\nmathematical models are here presented in details and the numerical strategies\nto deal with heterogeneities, equation coupling, and boundary conditions are\ndiscussed and benchmarked for the heterogeneous Henry and\nHorton-Rodgers-Lapwood problems, and other test cases. We show that our\nframework is capable of dealing with large permeability variances, viscous\ninstabilities, and large-scale three-dimensional transport problems.",
    "descriptor": "",
    "authors": [
      "Matteo Icardi",
      "Eugenio Pescimoro",
      "Federico Municchi",
      "Juan H Hidalgo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2212.10961"
  },
  {
    "id": "arXiv:2212.10963",
    "title": "Quotable Signatures for Authenticating Shared Quotes",
    "abstract": "Quotable signatures are digital signatures that allow a user to quote parts\nof a signed document, permitting a reader of the quote to verify its\nauthenticity. This paper adds to the theory on {quotable signatures} in three\nways: (1) by giving bounds on the size of signatures for arbitrary and\ncontiguous quotes, when the quotable signatures are realized using Merkle\ntrees, (2) by proving the security of quotable signature realized using Merkle\ntrees, and (3) by providing algorithms for signing, quoting, and verifying\nquotable signatures realized using Merkle trees. Additionally, the paper\ncarefully considers a concrete use case of quotable signatures, using them to\ncombat misinformation by bolstering authentic content. Motivation is given for\nwhy using quotable signatures could help mitigate the effects of fake news.",
    "descriptor": "\nComments: 32 pages, 14 figures\n",
    "authors": [
      "Joan Boyar",
      "Simon Erfurth",
      "Kim S. Larsen",
      "Ruben Niederhagen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.10963"
  },
  {
    "id": "arXiv:2212.10966",
    "title": "Fast multiplication, determinants, and inverses of arrowhead and  diagonal-plus-rank-one matrices over associative fields",
    "abstract": "The article considers arrowhead and diagonal-plus-rank-one matrices in\nF^(nxn) where F in R,C or H. H is a non-commutative field of quaternions. We\ngive unified formulas for fast matrix-vector multiplications, determinants, and\ninverses for considered matrices. The formulas are unified in the sense that\nthe same formula holds in both, commutative and noncommutative algebras. Each\nformula requires O(n) arithmetic operations. Most of the formulas hold for\nblock matrices, as well.",
    "descriptor": "",
    "authors": [
      "Nevena Jakovcevic Stor",
      "Ivan Slapnicar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.10966"
  },
  {
    "id": "arXiv:2212.10968",
    "title": "Strategic multi-task coordination over regular networks of robots with  limited computation and communication capabilities",
    "abstract": "Coordination is a desirable feature in multi-agent systems, allowing the\nexecution of tasks that would be impossible by individual agents. We study\ncoordination by a team of strategic agents choosing to undertake one of the\nmultiple tasks. We adopt a stochastic framework where the agents decide between\ntwo distinct tasks whose difficulty is randomly distributed and partially\nobserved. We show that a Nash equilibrium with a simple and intuitive linear\nstructure exists for diffuse prior distributions on the task difficulties.\nAdditionally, we show that the best response of any agent to an affine strategy\nprofile can be nonlinear when the prior distribution is not diffuse. Finally,\nwe state an algorithm that allows us to efficiently compute a data-driven Nash\nequilibrium within the class of affine policies.",
    "descriptor": "\nComments: Submitted to the 57th Conference on Information Science and Systems\n",
    "authors": [
      "Yi Wei",
      "Marcos M. Vasconcelos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2212.10968"
  },
  {
    "id": "arXiv:2212.10975",
    "title": "Proceedings of the Thirteenth International Workshop on Graph  Computation Models",
    "abstract": "This volume contains the post-proceedings of the Thirteenth International\nWorkshop on Graph Computation Models (GCM 2022). The workshop took place in\nNantes, France on 6th July 2022 as part of STAF 2022 (Software Technologies:\nApplications and Foundations). Graphs are common mathematical structures that\nare visual and intuitive. They constitute a natural and seamless way for system\nmodelling in science, engineering, and beyond, including computer science,\nbiology, and business process modelling. Graph computation models constitute a\nclass of very high-level models where graphs are first-class citizens. The aim\nof the International GCM Workshop series is to bring together researchers\ninterested in all aspects of computation models based on graphs and graph\ntransformation. It promotes the cross-fertilising exchange of ideas and\nexperiences among senior and young researchers from the different communities\ninterested in the foundations, applications, and implementations of graph\ncomputation models and related areas.",
    "descriptor": "",
    "authors": [
      "Reiko Heckel",
      "Christopher M. Poskitt"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.10975"
  },
  {
    "id": "arXiv:2212.10983",
    "title": "Computer says \"No\": The Case Against Empathetic Conversational AI",
    "abstract": "Emotions are an integral part of human cognition and they guide not only our\nunderstanding of the world but also our actions within it. As such, whether we\nsoothe or flame an emotion is not inconsequential. Recent work in\nconversational AI has focused on responding empathetically to users, validating\nand soothing their emotions without a real basis. This AI-aided emotional\nregulation can have negative consequences for users and society, tending\ntowards a one-noted happiness defined as only the absence of \"negative\"\nemotions. We argue that we must carefully consider whether and how to respond\nto users' emotions.",
    "descriptor": "",
    "authors": [
      "Alba Curry",
      "Amanda Cercas Curry"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.10983"
  },
  {
    "id": "arXiv:2212.10986",
    "title": "SoK: Let The Privacy Games Begin! A Unified Treatment of Data Inference  Privacy in Machine Learning",
    "abstract": "Deploying machine learning models in production may allow adversaries to\ninfer sensitive information about training data. There is a vast literature\nanalyzing different types of inference risks, ranging from membership inference\nto reconstruction attacks. Inspired by the success of games (i.e.,\nprobabilistic experiments) to study security properties in cryptography, some\nauthors describe privacy inference risks in machine learning using a similar\ngame-based style. However, adversary capabilities and goals are often stated in\nsubtly different ways from one presentation to the other, which makes it hard\nto relate and compose results. In this paper, we present a game-based framework\nto systematize the body of knowledge on privacy inference risks in machine\nlearning.",
    "descriptor": "",
    "authors": [
      "Ahmed Salem",
      "Giovanni Cherubin",
      "David Evans",
      "Boris K\u00f6pf",
      "Andrew Paverd",
      "Anshuman Suri",
      "Shruti Tople",
      "Santiago Zanella-B\u00e9guelin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2212.10986"
  },
  {
    "id": "arXiv:2212.10988",
    "title": "Attention-Aware Anime Line Drawing Colorization",
    "abstract": "Automatic colorization of anime line drawing has attracted much attention in\nrecent years since it can substantially benefit the animation industry.\nUser-hint based methods are the mainstream approach for line drawing\ncolorization, while reference-based methods offer a more intuitive approach.\nNevertheless, although reference-based methods can improve feature aggregation\nof the reference image and the line drawing, the colorization results are not\ncompelling in terms of color consistency or semantic correspondence. In this\npaper, we introduce an attention-based model for anime line drawing\ncolorization, in which a channel-wise and spatial-wise Convolutional Attention\nmodule is used to improve the ability of the encoder for feature extraction and\nkey area perception, and a Stop-Gradient Attention module with cross-attention\nand self-attention is used to tackle the cross-domain long-range dependency\nproblem. Extensive experiments show that our method outperforms other SOTA\nmethods, with more accurate line structure and semantic color information.",
    "descriptor": "",
    "authors": [
      "Yu Cao",
      "Hao Tian",
      "P.Y. Mok"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2212.10988"
  },
  {
    "id": "arXiv:2212.10992",
    "title": "LogAnMeta: Log Anomaly Detection Using Meta Learning",
    "abstract": "Modern telecom systems are monitored with performance and system logs from\nmultiple application layers and components. Detecting anomalous events from\nthese logs is key to identify security breaches, resource over-utilization,\ncritical/fatal errors, etc. Current supervised log anomaly detection frameworks\ntend to perform poorly on new types or signatures of anomalies with few or\nunseen samples in the training data. In this work, we propose a\nmeta-learning-based log anomaly detection framework (LogAnMeta) for detecting\nanomalies from sequence of log events with few samples. LoganMeta train a\nhybrid few-shot classifier in an episodic manner. The experimental results\ndemonstrate the efficacy of our proposed method",
    "descriptor": "",
    "authors": [
      "Abhishek Sarkar",
      "Tanmay Sen",
      "Srimanta Kundu",
      "Arijit Sarkar",
      "Abdul Wazed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.10992"
  },
  {
    "id": "arXiv:2212.11005",
    "title": "Revisiting Residual Networks for Adversarial Robustness: An  Architectural Perspective",
    "abstract": "Efforts to improve the adversarial robustness of convolutional neural\nnetworks have primarily focused on developing more effective adversarial\ntraining methods. In contrast, little attention was devoted to analyzing the\nrole of architectural elements (such as topology, depth, and width) on\nadversarial robustness. This paper seeks to bridge this gap and present a\nholistic study on the impact of architectural design on adversarial robustness.\nWe focus on residual networks and consider architecture design at the block\nlevel, i.e., topology, kernel size, activation, and normalization, as well as\nat the network scaling level, i.e., depth and width of each block in the\nnetwork. In both cases, we first derive insights through systematic ablative\nexperiments. Then we design a robust residual block, dubbed RobustResBlock, and\na compound scaling rule, dubbed RobustScaling, to distribute depth and width at\nthe desired FLOP count. Finally, we combine RobustResBlock and RobustScaling\nand present a portfolio of adversarially robust residual networks,\nRobustResNets, spanning a broad spectrum of model capacities. Experimental\nvalidation across multiple datasets and adversarial attacks demonstrate that\nRobustResNets consistently outperform both the standard WRNs and other existing\nrobust architectures, achieving state-of-the-art AutoAttack robust accuracy of\n61.1% without additional data and 63.7% with 500K external data while being\n$2\\times$ more compact in terms of parameters. Code is available at \\url{\nhttps://github.com/zhichao-lu/robust-residual-network}",
    "descriptor": "",
    "authors": [
      "Shihua Huang",
      "Zhichao Lu",
      "Kalyanmoy Deb",
      "Vishnu Naresh Boddeti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11005"
  },
  {
    "id": "arXiv:2212.11010",
    "title": "Parallel kinetic schemes for conservation laws, with large time steps",
    "abstract": "We propose a new parallel Discontinuous Galerkin method for the approximation\nof hyperbolic systems of conservation laws. The method remains stable with\nlarge time steps, while keeping the complexity of an explicit scheme: it does\nnot require the assembly and resolution of large linear systems for the time\niterations. The approach is based on a kinetic representation of the system of\nconservation laws previously investigated by the authors. In this paper, the\napproach is extended with a subdomain strategy that improves the parallel\nscaling of the method on computers with distributed memory.",
    "descriptor": "",
    "authors": [
      "Pierre Gerhard",
      "Philippe Helluy",
      "Victor Michel-Dansac",
      "Bruno Weber"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.11010"
  },
  {
    "id": "arXiv:2212.11011",
    "title": "Hidden-Variables Genetic Algorithm for Variable-Size Design Space  Optimal Layout Problems with Application to Aerospace Vehicles",
    "abstract": "The optimal layout of a complex system such as aerospace vehicles consists in\nplacing a given number of components in a container in order to minimize one or\nseveral objectives under some geometrical or functional constraints. This paper\npresents an extended formulation of this problem as a variable-size design\nspace (VSDS) problem to take into account a large number of architectural\nchoices and components allocation during the design process. As a\nrepresentative example of such systems, considering the layout of a satellite\nmodule, the VSDS aspect translates the fact that the optimizer has to choose\nbetween several subdivisions of the components. For instance, one large tank of\nfuel might be placed as well as two smaller tanks or three even smaller tanks\nfor the same amount of fuel. In order to tackle this NP-hard problem, a genetic\nalgorithm enhanced by an adapted hidden-variables mechanism is proposed. This\nlatter is illustrated on a toy case and an aerospace application case\nrepresentative to real world complexity to illustrate the performance of the\nproposed algorithms. The results obtained using the proposed mechanism are\nreported and analyzed.",
    "descriptor": "",
    "authors": [
      "Juliette Gamot",
      "Mathieu Balesdent",
      "Arnault Tremolet",
      "Romain Wuilbercq",
      "Nouredine Melab",
      "El-Ghazali Talbi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.11011"
  },
  {
    "id": "arXiv:2212.11017",
    "title": "Object detection-based inspection of power line insulators: Incipient  fault detection in the low data-regime",
    "abstract": "Deep learning-based object detection is a powerful approach for detecting\nfaulty insulators in power lines. This involves training an object detection\nmodel from scratch, or fine tuning a model that is pre-trained on benchmark\ncomputer vision datasets. This approach works well with a large number of\ninsulator images, but can result in unreliable models in the low data regime.\nThe current literature mainly focuses on detecting the presence or absence of\ninsulator caps, which is a relatively easy detection task, and does not\nconsider detection of finer faults such as flashed and broken disks. In this\narticle, we formulate three object detection tasks for insulator and asset\ninspection from aerial images, focusing on incipient faults in disks. We curate\na large reference dataset of insulator images that can be used to learn robust\nfeatures for detecting healthy and faulty insulators. We study the advantage of\nusing this dataset in the low target data regime by pre-training on the\nreference dataset followed by fine-tuning on the target dataset. The results\nsuggest that object detection models can be used to detect faults in insulators\nat a much incipient stage, and that transfer learning adds value depending on\nthe type of object detection model. We identify key factors that dictate\nperformance in the low data-regime and outline potential approaches to improve\nthe state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Laya Das",
      "Mohammad Hossein Saadat",
      "Blazhe Gjorgiev",
      "Etienne Auger",
      "Giovanni Sansavini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.11017"
  },
  {
    "id": "arXiv:2212.11030",
    "title": "Deep set conditioned latent representations for action recognition",
    "abstract": "In recent years multi-label, multi-class video action recognition has gained\nsignificant popularity. While reasoning over temporally connected atomic\nactions is mundane for intelligent species, standard artificial neural networks\n(ANN) still struggle to classify them. In the real world, atomic actions often\ntemporally connect to form more complex composite actions. The challenge lies\nin recognising composite action of varying durations while other distinct\ncomposite or atomic actions occur in the background. Drawing upon the success\nof relational networks, we propose methods that learn to reason over the\nsemantic concept of objects and actions. We empirically show how ANNs benefit\nfrom pretraining, relational inductive biases and unordered set-based latent\nrepresentations. In this paper we propose deep set conditioned I3D (SCI3D), a\ntwo stream relational network that employs latent representation of state and\nvisual representation for reasoning over events and actions. They learn to\nreason about temporally connected actions in order to identify all of them in\nthe video. The proposed method achieves an improvement of around 1.49% mAP in\natomic action recognition and 17.57% mAP in composite action recognition, over\na I3D-NL baseline, on the CATER dataset.",
    "descriptor": "\nComments: Conference VISAPP 2022, 11 pages,5 figures, 2 Tables, 6 plots\n",
    "authors": [
      "Akash Singh",
      "Tom De Schepper",
      "Kevin Mets",
      "Peter Hellinckx",
      "Jose Oramas",
      "Steven Latre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.11030"
  },
  {
    "id": "arXiv:2212.11042",
    "title": "Hi-LASSIE: High-Fidelity Articulated Shape and Skeleton Discovery from  Sparse Image Ensemble",
    "abstract": "Automatically estimating 3D skeleton, shape, camera viewpoints, and part\narticulation from sparse in-the-wild image ensembles is a severely\nunder-constrained and challenging problem. Most prior methods rely on\nlarge-scale image datasets, dense temporal correspondence, or human annotations\nlike camera pose, 2D keypoints, and shape templates. We propose Hi-LASSIE,\nwhich performs 3D articulated reconstruction from only 20-30 online images in\nthe wild without any user-defined shape or skeleton templates. We follow the\nrecent work of LASSIE that tackles a similar problem setting and make two\nsignificant advances. First, instead of relying on a manually annotated 3D\nskeleton, we automatically estimate a class-specific skeleton from the selected\nreference image. Second, we improve the shape reconstructions with novel\ninstance-specific optimization strategies that allow reconstructions to\nfaithful fit on each instance while preserving the class-specific priors\nlearned across all images. Experiments on in-the-wild image ensembles show that\nHi-LASSIE obtains higher quality state-of-the-art 3D reconstructions despite\nrequiring minimum user input.",
    "descriptor": "",
    "authors": [
      "Chun-Han Yao",
      "Wei-Chih Hung",
      "Yuanzhen Li",
      "Michael Rubinstein",
      "Ming-Hsuan Yang",
      "Varun Jampani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.11042"
  },
  {
    "id": "arXiv:2212.11047",
    "title": "Discovering Process Models With Long-Term Dependencies While Providing  Guarantees and Handling Infrequent Behavior",
    "abstract": "In process discovery, the goal is to find, for a given event log, the model\ndescribing the underlying process. While process models can be represented in a\nvariety of ways, Petri nets form a theoretically well-explored description\nlanguage and are therefore often used in process mining. In this paper, we\npresent an extension of the eST-Miner process discovery algorithm. This\napproach computes a set of Petri net places which are considered to be fitting\nwith respect to a user-definable fraction of the behavior described by the\ngiven event log, by evaluating all possible candidate places using token-based\nreplay. The set of replayable traces is determined for each place in isolation,\ni.e., they do not need to be consistent, which allows the algorithm to abstract\nfrom infrequent behavioral patterns. When combining these places into a Petri\nnet by connecting them to the corresponding uniquely labeled transitions, the\nresulting net can replay exactly those traces that can be replayed by each of\nthe inserted places. Thus, inserting places one-by-one without considering\ntheir combined effect may result in deadlocks and low fitness of the Petri net.\nIn this paper, we explore adaptions of the eST-Miner, that aim to select a\nsubset of places such that the resulting Petri net guarantees a definable\nminimal fitness while maintaining high precision with respect to the input\nevent log. To this end, a new fitness metric is introduced and thoroughly\ninvestigated. Furthermore, various place selection strategies are proposed and\ntheir impact on the returned Petri net is evaluated by experiments using both\nreal and artificial event logs.",
    "descriptor": "",
    "authors": [
      "Lisa Luise Mannel",
      "Wil M. P. van der Aalst"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.11047"
  },
  {
    "id": "arXiv:2212.11050",
    "title": "CNN waste classification project report",
    "abstract": "This report is about waste management project. We used CNN as classifier to\nclassify waste image captured from mobile phone. Our model can identify 6 waste\nclasses with highly accurate and our model is successfully transferred into IOS\nplatform as application by swift. In addition, this report also introduced some\nbasic project management from planning project to landing project, for instance\nusing agile development to develop this waste app.",
    "descriptor": "\nComments: 23 pages,11 figures\n",
    "authors": [
      "Fei Wu",
      "LiQin Zhang",
      "An Tran"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.11050"
  },
  {
    "id": "arXiv:2212.11054",
    "title": "Polytopic Analysis of Music",
    "abstract": "Structural segmentation of music refers to the task of finding a symbolic\nrepresentation of the organisation of a song, reducing the musical flow to a\npartition of non-overlapping segments. Under this definition, the musical\nstructure may not be unique, and may even be ambiguous. One way to resolve that\nambiguity is to see this task as a compression process, and to consider the\nmusical structure as the optimization of a given compression criteria. In that\nviewpoint, C. Guichaoua developed a compression-driven model for retrieving the\nmusical structure, based on the \"System and Contrast\" model, and on polytopes,\nwhich are extension of nhypercubes. We present this model, which we call\n\"polytopic analysis of music\", along with a new opensource dedicated toolbox\ncalled MusicOnPolytopes (in Python). This model is also extended to the use of\nthe Tonnetz as a relation system. Structural segmentation experiments are\nconducted on the RWC Pop dataset. Results show improvements compared to the\nprevious ones, presented by C. Guichaoua.",
    "descriptor": "\nComments: Work document\n",
    "authors": [
      "Axel Marmoret",
      "J\u00e9r\u00e9my E. Cohen",
      "Fr\u00e9d\u00e9ric Bibmot"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.11054"
  },
  {
    "id": "arXiv:2212.11055",
    "title": "Coalgebraic Satisfiability Checking for Arithmetic $\u03bc$-Calculi",
    "abstract": "The coalgebraic $\\mu$-calculus provides a generic semantic framework for\nfixpoint logics over systems whose branching type goes beyond the standard\nrelational setup, e.g. probabilistic, weighted, or game-based. Previous work on\nthe coalgebraic $\\mu$-calculus includes an exponential-time upper bound on\nsatisfiability checking, which however relies on the availability of tableau\nrules for the next-step modalities that are sufficiently well-behaved in a\nformally defined sense; in particular, rule matches need to be representable by\npolynomial-sized codes, and the sequent duals of the rules need to absorb cut.\nWhile such rule sets have been identified for some important cases, they are\nnot known to exist in all cases of interest, in particular ones involving\neither integer weights as in the graded $\\mu$-calculus, or real-valued weights\nin combination with non-linear arithmetic. In the present work, we prove the\nsame upper complexity bound under more general assumptions, specifically\nregarding the complexity of the (much simpler) satisfiability problem for the\nunderlying one-step logic, roughly described as the nesting-free next-step\nfragment of the logic. The bound is realized by a generic global caching\nalgorithm that supports on-the-fly satisfiability checking. Notably, our\napproach directly accommodates unguarded formulae, and thus avoids use of the\nguardedness transformation. Example applications include new exponential-time\nupper bounds for satisfiability checking in an extension of the graded\n$\\mu$-calculus with polynomial inequalities (including positive Presburger\narithmetic), as well as an extension of the (two-valued) probabilistic\n$\\mu$-calculus with polynomial inequalities.",
    "descriptor": "",
    "authors": [
      "Daniel Hausmann",
      "Lutz Schr\u00f6der"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.11055"
  },
  {
    "id": "arXiv:2212.11057",
    "title": "Spatial Multiplexing in Near Field MIMO Channels with Reconfigurable  Intelligent Surfaces",
    "abstract": "We consider a multiple-input multiple-output (MIMO) channel in the presence\nof a reconfigurable intelligent surface (RIS). Specifically, our focus is on\nanalyzing the spatial multiplexing gains in line-of-sight and low-scattering\nMIMO channels in the near field. We prove that the channel capacity is achieved\nby diagonalizing the end-to-end transmitter-RIS-receiver channel, and applying\nthe water-filling power allocation to the ordered product of the singular\nvalues of the transmitter-RIS and RIS-receiver channels. The obtained\ncapacity-achieving solution requires an RIS with a non-diagonal matrix of\nreflection coefficients. Under the assumption of nearly-passive RIS, i.e., no\npower amplification is needed at the RIS, the water-filling power allocation is\nnecessary only at the transmitter. We refer to this design of RIS as a linear,\nnearly-passive, reconfigurable electromagnetic object (EMO). In addition, we\nintroduce a closed-form and low-complexity design for RIS, whose matrix of\nreflection coefficients is diagonal with unit-modulus entries. The reflection\ncoefficients are given by the product of two focusing functions: one steering\nthe RIS-aided signal towards the mid-point of the MIMO transmitter and one\nsteering the RIS-aided signal towards the mid-point of the MIMO receiver. We\nprove that this solution is exact in line-of-sight channels under the paraxial\nsetup. With the aid of extensive numerical simulations in line-of-sight\n(free-space) channels, we show that the proposed approach offers performance\n(rate and degrees of freedom) close to that obtained by numerically solving\nnon-convex optimization problems at a high computational complexity. Also, we\nshow that it provides performance close to that achieved by the EMO\n(non-diagonal RIS) in most of the considered case studies.",
    "descriptor": "\nComments: Submitted for publication\n",
    "authors": [
      "Giulio Bartoli",
      "Andrea Abrardo",
      "Nicolo Decarli",
      "Davide Dardari",
      "Marco Di Renzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.11057"
  },
  {
    "id": "arXiv:2212.11070",
    "title": "Pointwise optimal multivariate spline method for recovery of twice  differentiable functions on a simplex",
    "abstract": "We obtain the spline recovery method on a $d$-dimensional simplex $T$ that\nuses as information values and gradients of a function $f$ at the vertices of\n$T$ and is optimal for recovery of $f({\\bf w})$ at every point ${\\bf w}$ of an\nadmissible domain $P$ containing $T$ on the class $W^2(P)$ of twice\ndifferentiable functions on $P$ with uniformly bounded second order derivatives\nin any direction. If, in particular, every face of $T$ (of any dimension)\ncontains its circumcenter, we can take $P=T$.\nWe also find the error function of the pointwise optimal method which turns\nout to be a function in $W^2(P)$ with zero information. The error function is a\npiecewise quadratic $C^1$-function over a certain polyhedral partition and can\nbe considered as a multivariate analogue of the classical Euler spline\n$\\phi_2$. The pointwise optimal method is a continuous spline of degree two\n(with some pieces of degree one) over the same partition.",
    "descriptor": "\nComments: 33 pages. Announced during the Constructive Functions 2014 conference, Vanderbilt University, May 26-30, 2014, and during the Finite Element Circus conference at Wayne State University, March 28-29, 2014\n",
    "authors": [
      "Sergiy Borodachov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.11070"
  },
  {
    "id": "arXiv:2212.11071",
    "title": "Can a Robot Shoot an Olympic Recurve Bow? A preliminary study",
    "abstract": "The field of robotics, and more especially humanoid robotics, has several\nestablished competitions with research oriented goals in mind. Challenging the\nrobots in a handful of tasks, these competitions provide a way to gauge the\nstate of the art in robotic design, as well as an indicator for how far we are\nfrom reaching human performance. The most notable competitions are RoboCup,\nwhich has the long-term goal of competing against a real human team in 2050,\nand the FIRA HuroCup league, in which humanoid robots have to perform tasks\nbased on actual Olympic events. Having robots compete against humans under the\nsame rules is a challenging goal, and, we believe that it is in the sport of\narchery that humanoid robots have the most potential to achieve it in the near\nfuture. In this work, we perform a first step in this direction. We present a\nhumanoid robot that is capable of gripping, drawing and shooting a recurve bow\nat a target 10 meters away with considerable accuracy. Additionally, we show\nthat it is also capable of shooting distances of over 50 meters.",
    "descriptor": "\nComments: Short paper presented at FIRA Summit 2020, 9 pages, 5 figures, 2 tables\n",
    "authors": [
      "Guilherme Christmann",
      "Lin Yu-Ren",
      "Rodrigo da Silva Guerra",
      "Jacky Baltes"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.11071"
  },
  {
    "id": "arXiv:2212.11077",
    "title": "Augmenting Diffs With Runtime Information",
    "abstract": "Source code diffs are used on a daily basis as part of code review,\ninspection, and auditing. To facilitate understanding, they are typically\naccompanied by explanations that describe the essence of what is changed in the\nprogram. As manually crafting high-quality explanations is a cumbersome task,\nresearchers have proposed automatic techniques to generate code diff\nexplanations. Existing explanation generation methods solely focus on static\nanalysis, i.e., they do not take advantage of runtime information to explain\ncode changes. In this paper, we propose Collector-Sahab, a novel tool that\naugments code diffs with runtime difference information. Collector-Sahab\ncompares the program states of the original (old) and patched (new) versions of\na program to find unique variable values. Then, Collector-Sahab adds this novel\nruntime information to the source code diff as shown, for instance, in code\nreviewing systems. As an evaluation, we run Collector-Sahab on 587 code diffs\nfor Defects4J bugs and find it successfully augments the code diff for 90.6\\%\n(532/587) of them. We also perform a manual analysis on 29 code diffs from 10\nreal-world projects and conclude that Collector-Sahab generates correct,\ncausally relevant, and understandable augmented diffs. Overall, our experiments\nshow the effectiveness and usefulness of Collector-Sahab in augmenting code\ndiffs with runtime difference information. Collector-Sahab:\nhttps://github.com/algomaster99/collector-sahab",
    "descriptor": "",
    "authors": [
      "Khashayar Etemadi",
      "Aman Sharma",
      "Fernanda Madeiral",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.11077"
  },
  {
    "id": "arXiv:2212.11078",
    "title": "C2F-TCN: A Framework for Semi and Fully Supervised Temporal Action  Segmentation",
    "abstract": "Temporal action segmentation tags action labels for every frame in an input\nuntrimmed video containing multiple actions in a sequence. For the task of\ntemporal action segmentation, we propose an encoder-decoder-style architecture\nnamed C2F-TCN featuring a \"coarse-to-fine\" ensemble of decoder outputs. The\nC2F-TCN framework is enhanced with a novel model agnostic temporal feature\naugmentation strategy formed by the computationally inexpensive strategy of the\nstochastic max-pooling of segments. It produces more accurate and\nwell-calibrated supervised results on three benchmark action segmentation\ndatasets. We show that the architecture is flexible for both supervised and\nrepresentation learning. In line with this, we present a novel unsupervised way\nto learn frame-wise representation from C2F-TCN. Our unsupervised learning\napproach hinges on the clustering capabilities of the input features and the\nformation of multi-resolution features from the decoder's implicit structure.\nFurther, we provide the first semi-supervised temporal action segmentation\nresults by merging representation learning with conventional supervised\nlearning. Our semi-supervised learning scheme, called\n``Iterative-Contrastive-Classify (ICC)'', progressively improves in performance\nwith more labeled data. The ICC semi-supervised learning in C2F-TCN, with 40%\nlabeled videos, performs similar to fully supervised counterparts.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.01402\n",
    "authors": [
      "Dipika Singhania",
      "Rahul Rahaman",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.11078"
  },
  {
    "id": "arXiv:2212.11080",
    "title": "Is it worth it? An experimental comparison of six deep- and classical  machine learning methods for unsupervised anomaly detection in time series",
    "abstract": "The detection of anomalies in time series data is crucial in a wide range of\napplications, such as system monitoring, health care or cyber security. While\nthe vast number of available methods makes selecting the right method for a\ncertain application hard enough, different methods have different strengths,\ne.g. regarding the type of anomalies they are able to find. In this work, we\ncompare six unsupervised anomaly detection methods with different complexities\nto answer the questions: Are the more complex methods usually performing\nbetter? And are there specific anomaly types that those method are tailored to?\nThe comparison is done on the UCR anomaly archive, a recent benchmark dataset\nfor anomaly detection. We compare the six methods by analyzing the experimental\nresults on a dataset- and anomaly type level after tuning the necessary\nhyperparameter for each method. Additionally we examine the ability of\nindividual methods to incorporate prior knowledge about the anomalies and\nanalyse the differences of point-wise and sequence wise features. We show with\nbroad experiments, that the classical machine learning methods show a superior\nperformance compared to the deep learning methods across a wide range of\nanomaly types.",
    "descriptor": "\nComments: 15 Pages, The repository to reproduce the results is available at this https URL\n",
    "authors": [
      "Ferdinand Rewicki",
      "Joachim Denzler",
      "Julia Niebling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.11080"
  },
  {
    "id": "arXiv:2212.11083",
    "title": "Adapting the Exploration Rate for Value-of-Information-Based  Reinforcement Learning",
    "abstract": "In this paper, we consider the problem of adjusting the exploration rate when\nusing value-of-information-based exploration. We do this by converting the\nvalue-of-information optimization into a problem of finding equilibria of a\nflow for a changing exploration rate. We then develop an efficient\npath-following scheme for converging to these equilibria and hence uncovering\noptimal action-selection policies. Under this scheme, the exploration rate is\nautomatically adapted according to the agent's experiences. Global convergence\nis theoretically assured.\nWe first evaluate our exploration-rate adaptation on the Nintendo GameBoy\ngames Centipede and Millipede. We demonstrate aspects of the search process. We\nshow that our approach yields better policies in fewer episodes than\nconventional search strategies relying on heuristic, annealing-based\nexploration-rate adjustments. We then illustrate that these trends hold for\ndeep, value-of-information-based agents that learn to play ten simple games and\nover forty more complicated games for the Nintendo GameBoy system. Performance\neither near or well above the level of human play is observed.",
    "descriptor": "\nComments: Submitted to the IEEE Transactions on Information Theory\n",
    "authors": [
      "Isaac J. Sledge",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.11083"
  },
  {
    "id": "arXiv:2212.11084",
    "title": "Cooperative Flight Control Using Visual-Attention -- Air-Guardian",
    "abstract": "The cooperation of a human pilot with an autonomous agent during flight\ncontrol realizes parallel autonomy. A parallel-autonomous system acts as a\nguardian that significantly enhances the robustness and safety of flight\noperations in challenging circumstances. Here, we propose an air-guardian\nconcept that facilitates cooperation between an artificial pilot agent and a\nparallel end-to-end neural control system. Our vision-based air-guardian system\ncombines a causal continuous-depth neural network model with a cooperation\nlayer to enable parallel autonomy between a pilot agent and a control system\nbased on perceived differences in their attention profile. The attention\nprofiles are obtained by computing the networks' saliency maps (feature\nimportance) through the VisualBackProp algorithm. The guardian agent is trained\nvia reinforcement learning in a fixed-wing aircraft simulated environment. When\nthe attention profile of the pilot and guardian agents align, the pilot makes\ncontrol decisions. If the attention map of the pilot and the guardian do not\nalign, the air-guardian makes interventions and takes over the control of the\naircraft. We show that our attention-based air-guardian system can balance the\ntrade-off between its level of involvement in the flight and the pilot's\nexpertise and attention. We demonstrate the effectivness of our methods in\nsimulated flight scenarios with a fixed-wing aircraft and on a real drone\nplatform.",
    "descriptor": "",
    "authors": [
      "Lianhao Yin",
      "Tsun-Hsuan Wang",
      "Makram Chahine",
      "Tim Seyde",
      "Mathias Lechner",
      "Ramin Hasani",
      "Daniela Rus"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.11084"
  },
  {
    "id": "arXiv:2212.11085",
    "title": "Empirical Analysis of Limits for Memory Distance in Recurrent Neural  Networks",
    "abstract": "Common to all different kinds of recurrent neural networks (RNNs) is the\nintention to model relations between data points through time. When there is no\nimmediate relationship between subsequent data points (like when the data\npoints are generated at random, e.g.), we show that RNNs are still able to\nremember a few data points back into the sequence by memorizing them by heart\nusing standard backpropagation. However, we also show that for classical RNNs,\nLSTM and GRU networks the distance of data points between recurrent calls that\ncan be reproduced this way is highly limited (compared to even a loose\nconnection between data points) and subject to various constraints imposed by\nthe type and size of the RNN in question. This implies the existence of a hard\nlimit (way below the information-theoretic one) for the distance between\nrelated data points within which RNNs are still able to recognize said\nrelation.",
    "descriptor": "",
    "authors": [
      "Steffen Illium",
      "Thore Schillman",
      "Robert M\u00fcller",
      "Thomas Gabor",
      "Claudia Linnhoff-Popien"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.11085"
  },
  {
    "id": "arXiv:2212.11087",
    "title": "On Reinforcement Learning for the Game of 2048",
    "abstract": "2048 is a single-player stochastic puzzle game. This intriguing and addictive\ngame has been popular worldwide and has attracted researchers to develop\ngame-playing programs. Due to its simplicity and complexity, 2048 has become an\ninteresting and challenging platform for evaluating the effectiveness of\nmachine learning methods. This dissertation conducts comprehensive research on\nreinforcement learning and computer game algorithms for 2048. First, this\ndissertation proposes optimistic temporal difference learning, which\nsignificantly improves the quality of learning by employing optimistic\ninitialization to encourage exploration for 2048. Furthermore, based on this\napproach, a state-of-the-art program for 2048 is developed, which achieves the\nhighest performance among all learning-based programs, namely an average score\nof 625377 points and a rate of 72% for reaching 32768-tiles. Second, this\ndissertation investigates several techniques related to 2048, including the\nn-tuple network ensemble learning, Monte Carlo tree search, and deep\nreinforcement learning. These techniques are promising for further improving\nthe performance of the current state-of-the-art program. Finally, this\ndissertation discusses pedagogical applications related to 2048 by proposing\ncourse designs and summarizing the teaching experience. The proposed course\ndesigns use 2048-like games as materials for beginners to learn reinforcement\nlearning and computer game algorithms. The courses have been successfully\napplied to graduate-level students and received well by student feedback.",
    "descriptor": "\nComments: A Ph.D. dissertation submitted to Institute of Computer Science and Engineering, National Yang Ming Chiao Tung University\n",
    "authors": [
      "Hung Guei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.11087"
  },
  {
    "id": "arXiv:2212.11088",
    "title": "Forward- or Reverse-Mode Automatic Differentiation: What's the  Difference?",
    "abstract": "Automatic differentiation (AD) has been a topic of interest for researchers\nin many disciplines, with increased popularity since its application to machine\nlearning and neural networks. Although many researchers appreciate and know how\nto apply AD, it remains a challenge to truly understand the underlying\nprocesses. From an algebraic point of view, however, AD appears surprisingly\nnatural: it originates from the differentiation laws. In this work we use\nAlgebra of Programming techniques to reason about different AD variants,\nleveraging Haskell to illustrate our observations. Our findings stem from three\nfundamental algebraic abstractions: (1) the notion of module over a semiring,\n(2) Nagata's construction of the 'idealization of a module', and (3)\nKronecker's delta function, that together allow us to write a single-line\nabstract definition of AD. From this single-line definition, and by\ninstantiating our algebraic structures in various ways, we derive different AD\nvariants, that have the same extensional behaviour, but different intensional\nproperties, mainly in terms of (asymptotic) computational complexity. We show\nthe different variants equivalent by means of Kronecker isomorphisms, a further\nelaboration of our Haskell infrastructure which guarantees correctness by\nconstruction. With this framework in place, this paper seeks to make AD\nvariants more comprehensible, taking an algebraic perspective on the matter.",
    "descriptor": "",
    "authors": [
      "Birthe van den Berg",
      "Tom Schrijvers",
      "James McKinna",
      "Alexander Vandenbroucke"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2212.11088"
  },
  {
    "id": "arXiv:2212.11091",
    "title": "Exploring Content Relationships for Distilling Efficient GANs",
    "abstract": "This paper proposes a content relationship distillation (CRD) to tackle the\nover-parameterized generative adversarial networks (GANs) for the\nserviceability in cutting-edge devices. In contrast to traditional\ninstance-level distillation, we design a novel GAN compression oriented\nknowledge by slicing the contents of teacher outputs into multiple fine-grained\ngranularities, such as row/column strips (global information) and image patches\n(local information), modeling the relationships among them, such as pairwise\ndistance and triplet-wise angle, and encouraging the student to capture these\nrelationships within its output contents. Built upon our proposed content-level\ndistillation, we also deploy an online teacher discriminator, which keeps\nupdating when co-trained with the teacher generator and keeps freezing when\nco-trained with the student generator for better adversarial training. We\nperform extensive experiments on three benchmark datasets, the results of which\nshow that our CRD reaches the most complexity reduction on GANs while obtaining\nthe best performance in comparison with existing methods. For example, we\nreduce MACs of CycleGAN by around 40x and parameters by over 80x, meanwhile,\n46.61 FIDs are obtained compared with these of 51.92 for the current\nstate-of-the-art. Code of this project is available at\nhttps://github.com/TheKernelZ/CRD.",
    "descriptor": "",
    "authors": [
      "Lizhou You",
      "Mingbao Lin",
      "Tie Hu",
      "Fei Chao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.11091"
  },
  {
    "id": "arXiv:2212.11101",
    "title": "An RFID-Based Assistive Glove to Help the Visually Impaired",
    "abstract": "Recent studies have focused on facilitating perception and outdoor navigation\nfor people with blindness or some form of vision loss. However, a significant\nportion of these studies is centered around treatment and vision\nrehabilitation, leaving some immediate needs, such as interaction with the\nsurrounding objects or recognizing colors and fine patterns without tactile\nfeedback. This study targets such needs and delivers a straightforward\ncommunication method using a wearable, unobtrusive device with the environment.\nWe initially discuss the advantages and limitations of related works to draw\nout the best-fitting design concepts. Then, we introduce the potential for\nemerging technologies such as radio-frequency identification. We present the\ndesign details and the experimental results of an assistive glove to allow\npeople with vision disabilities to interact with the environment more\nefficiently. Based on the collected data from 17 blind-folded healthy\nparticipants, the implemented system's success rate in identifying objects was\nabout 96.32%. Overall, 70% of the users found the device very satisfactory.",
    "descriptor": "",
    "authors": [
      "Paniz Sedighi",
      "Mohammad Hesam Norouzi",
      "Mehdi Delrobaei"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.11101"
  },
  {
    "id": "arXiv:2212.11109",
    "title": "MAViC: Multimodal Active Learning for Video Captioning",
    "abstract": "A large number of annotated video-caption pairs are required for training\nvideo captioning models, resulting in high annotation costs. Active learning\ncan be instrumental in reducing these annotation requirements. However, active\nlearning for video captioning is challenging because multiple semantically\nsimilar captions are valid for a video, resulting in high entropy outputs even\nfor less-informative samples. Moreover, video captioning algorithms are\nmultimodal in nature with a visual encoder and language decoder. Further, the\nsequential and combinatorial nature of the output makes the problem even more\nchallenging. In this paper, we introduce MAViC which leverages our proposed\nMultimodal Semantics Aware Sequential Entropy (M-SASE) based acquisition\nfunction to address the challenges of active learning approaches for video\ncaptioning. Our approach integrates semantic similarity and uncertainty of both\nvisual and language dimensions in the acquisition function. Our detailed\nexperiments empirically demonstrate the efficacy of M-SASE for active learning\nfor video captioning and improve on the baselines by a large margin.",
    "descriptor": "",
    "authors": [
      "Gyanendra Das",
      "Xavier Thomas",
      "Anant Raj",
      "Vikram Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11109"
  },
  {
    "id": "arXiv:2212.11110",
    "title": "Lifelong Reinforcement Learning with Modulating Masks",
    "abstract": "Lifelong learning aims to create AI systems that continuously and\nincrementally learn during a lifetime, similar to biological learning. Attempts\nso far have met problems, including catastrophic forgetting, interference among\ntasks, and the inability to exploit previous knowledge. While considerable\nresearch has focused on learning multiple input distributions, typically in\nclassification, lifelong reinforcement learning (LRL) must also deal with\nvariations in the state and transition distributions, and in the reward\nfunctions. Modulating masks, recently developed for classification, are\nparticularly suitable to deal with such a large spectrum of task variations. In\nthis paper, we adapted modulating masks to work with deep LRL, specifically PPO\nand IMPALA agents. The comparison with LRL baselines in both discrete and\ncontinuous RL tasks shows competitive performance. We further investigated the\nuse of a linear combination of previously learned masks to exploit previous\nknowledge when learning new tasks: not only is learning faster, the algorithm\nsolves tasks that we could not otherwise solve from scratch due to extremely\nsparse rewards. The results suggest that RL with modulating masks is a\npromising approach to lifelong learning, to the composition of knowledge to\nlearn increasingly complex tasks, and to knowledge reuse for efficient and\nfaster learning.",
    "descriptor": "",
    "authors": [
      "Eseoghene Ben-Iwhiwhu",
      "Saptarshi Nath",
      "Praveen K. Pilly",
      "Soheil Kolouri",
      "Andrea Soltoggio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.11110"
  },
  {
    "id": "arXiv:2212.11111",
    "title": "Splitting Schemes for Coupled Differential Equations: Block Schur-Based  Approaches and Partial Jacobi Approximation",
    "abstract": "Coupled multi-physics problems are encountered in countless applications and\npose significant numerical challenges. Although monolithic approaches offer\npossibly the best solution strategy, they often require ad-hoc preconditioners\nand numerical implementations. Sequential (also known as splitted, partitioned\nor segregated) approaches are iterative methods for solving coupled problems\nwhere each equation is solved independently and the coupling is achieved\nthrough iterations. These methods offer the possibility to flexibly add or\nremove equations from a model and to rely on existing black-box solvers for\nevery specific equation. Furthermore, when problems are non-linear, inner\niterations need to be performed even in monolithic solvers, therefore making a\nsequential iterative approach a viable alternative. The cost of running inner\niterations to achieve the coupling, however, could easily becomes prohibitive,\nor, in some cases the iterations might not converge. In this work we present a\ngeneral formulation of splitting schemes for continuous operators, with\narbitrary implicit/explicit splitting, like in standard iterative methods for\nlinear systems. By introducing a generic relaxation operator we find the\nconditions for the convergence of the iterative schemes. We show how the\nrelaxation operator can be thought as a preconditioner and constructed based on\nan approximate Schur-complement. We propose a Schur-based Partial Jacobi\nrelaxation operator to stabilise the coupling and show its effectiveness.\nAlthough we mainly focus on scalar-scalar linear problems, most results are\neasily extended to non-linear and higher-dimensional problems. Numerical tests\n(1D and 2D) for two PDE systems, namely the Dual-Porosity model and a\nQuad-Laplacian operator, are carried out to confirm the theoretical results.",
    "descriptor": "",
    "authors": [
      "Roberto Nuca",
      "Erlend Storvik",
      "Florin A. Radu",
      "Matteo Icardi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.11111"
  },
  {
    "id": "arXiv:2212.11115",
    "title": "What Makes for Good Tokenizers in Vision Transformer?",
    "abstract": "The architecture of transformers, which recently witness booming applications\nin vision tasks, has pivoted against the widespread convolutional paradigm.\nRelying on the tokenization process that splits inputs into multiple tokens,\ntransformers are capable of extracting their pairwise relationships using\nself-attention. While being the stemming building block of transformers, what\nmakes for a good tokenizer has not been well understood in computer vision. In\nthis work, we investigate this uncharted problem from an information trade-off\nperspective. In addition to unifying and understanding existing structural\nmodifications, our derivation leads to better design strategies for vision\ntokenizers. The proposed Modulation across Tokens (MoTo) incorporates\ninter-token modeling capability through normalization. Furthermore, a\nregularization objective TokenProp is embraced in the standard training regime.\nThrough extensive experiments on various transformer architectures, we observe\nboth improved performance and intriguing properties of these two plug-and-play\ndesigns with negligible computational overhead. These observations further\nindicate the importance of the commonly-omitted designs of tokenizers in vision\ntransformer.",
    "descriptor": "\nComments: To appear in IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Shengju Qian",
      "Yi Zhu",
      "Wenbo Li",
      "Mu Li",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.11115"
  },
  {
    "id": "arXiv:2212.11116",
    "title": "Balanced Split: A new train-test data splitting strategy for imbalanced  datasets",
    "abstract": "Classification data sets with skewed class proportions are called imbalanced.\nClass imbalance is a problem since most machine learning classification\nalgorithms are built with an assumption of equal representation of all classes\nin the training dataset. Therefore to counter the class imbalance problem, many\nalgorithm-level and data-level approaches have been developed. These mainly\ninclude ensemble learning and data augmentation techniques. This paper shows a\nnew way to counter the class imbalance problem through a new data-splitting\nstrategy called balanced split. Data splitting can play an important role in\ncorrectly classifying imbalanced datasets. We show that the commonly used\ndata-splitting strategies have some disadvantages, and our proposed balanced\nsplit has solved those problems.",
    "descriptor": "",
    "authors": [
      "Azal Ahmad Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11116"
  },
  {
    "id": "arXiv:2212.11118",
    "title": "NP4G : Network Programming for Generalization",
    "abstract": "Automatic programming has been actively studied for a long time by various\napproaches including genetic programming. In recent years, automatic\nprogramming using neural networks such as GPT-3 has been actively studied and\nis attracting a lot of attention. However, these methods are illogical\ninference based on experience by enormous learning, and their thinking process\nis unclear. Even using the method by logical inference with a clear thinking\nprocess, the system that automatically generates any programs has not yet been\nrealized. Especially, the inductive inference generalized by logical inference\nfrom one example is an important issue that the artificial intelligence can\nacquire knowledge by itself. In this study, we propose NP4G: Network\nProgramming for Generalization, which can automatically generate programs by\ninductive inference. Because the proposed method can realize \"sequence\",\n\"selection\", and \"iteration\" in programming and can satisfy the conditions of\nthe structured program theorem, it is expected that NP4G is a method\nautomatically acquire any programs by inductive inference. As an example, we\nautomatically construct a bitwise NOT operation program from several training\ndata by generalization using NP4G. Although NP4G only randomly selects and\nconnects nodes, by adjusting the number of nodes and the number of phase of\n\"Phased Learning\", we show the bitwise NOT operation programs are acquired in a\ncomparatively short time and at a rate of about 7 in 10 running. The source\ncode of NP4G is available on GitHub as a public repository.",
    "descriptor": "",
    "authors": [
      "Shoichiro Hara",
      "Yuji Watanabe"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2212.11118"
  },
  {
    "id": "arXiv:2212.11119",
    "title": "A survey on text generation using generative adversarial networks",
    "abstract": "This work presents a thorough review concerning recent studies and text\ngeneration advancements using Generative Adversarial Networks. The usage of\nadversarial learning for text generation is promising as it provides\nalternatives to generate the so-called \"natural\" language. Nevertheless,\nadversarial text generation is not a simple task as its foremost architecture,\nthe Generative Adversarial Networks, were designed to cope with continuous\ninformation (image) instead of discrete data (text). Thus, most works are based\non three possible options, i.e., Gumbel-Softmax differentiation, Reinforcement\nLearning, and modified training objectives. All alternatives are reviewed in\nthis survey as they present the most recent approaches for generating text\nusing adversarial-based techniques. The selected works were taken from renowned\ndatabases, such as Science Direct, IEEEXplore, Springer, Association for\nComputing Machinery, and arXiv, whereas each selected work has been critically\nanalyzed and assessed to present its objective, methodology, and experimental\nresults.",
    "descriptor": "",
    "authors": [
      "Gustavo Henrique de Rosa",
      "Jo\u00e3o Paulo Papa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11119"
  },
  {
    "id": "arXiv:2212.11120",
    "title": "MountNet: Learning an Inertial Sensor Mounting Angle with Deep Neural  Networks",
    "abstract": "Finding the mounting angle of a smartphone inside a car is crucial for\nnavigation, motion detection, activity recognition, and other applications. It\nis a challenging task in several aspects: (i) the mounting angle at the drive\nstart is unknown and may differ significantly between users; (ii) the user, or\nbad fixture, may change the mounting angle while driving; (iii) a rapid and\ncomputationally efficient real-time solution is required for most applications.\nTo tackle these problems, a data-driven approach using deep neural networks\n(DNNs) is presented to learn the yaw mounting angle of a smartphone equipped\nwith an inertial measurement unit (IMU) and strapped to a car. The proposed\nmodel, MountNet, uses only IMU readings as input and, in contrast to existing\nsolutions, does not require inputs from global navigation satellite systems\n(GNSS). IMU data is collected for training and validation with the sensor\nmounted at a known yaw mounting angle and a range of ground truth labels is\ngenerated by applying a prescribed rotation to the measurements. Although the\ntraining data did not include recordings with real sensor rotations, tests on\ndata with real and synthetic rotations show similar results. An algorithm is\nformulated for real-time deployment to detect and smooth transitions in device\nmounting angle estimated by MountNet. MountNet is shown to find the mounting\nangle rapidly which is critical in real-time applications. Our method converges\nin less than 30 seconds of driving to a mean error of 4 degrees allowing a fast\ncalibration phase for other algorithms and applications. When the device is\nrotated in the middle of a drive, large changes converge in 5 seconds and small\nchanges converge in less than 30 seconds.",
    "descriptor": "\nComments: 8 Pages\n",
    "authors": [
      "Maxim Freydin",
      "Niv Sfaradi",
      "Nimrod Segol",
      "Areej Eweida",
      "Barak Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.11120"
  },
  {
    "id": "arXiv:2212.11121",
    "title": "Religion and Spirituality on Social Media in the Aftermath of the Global  Pandemic",
    "abstract": "During the COVID-19 pandemic, the Church closed its physical doors for the\nfirst time in about 800 years, which is, arguably, a cataclysmic event. Other\nreligions have found themselves in a similar situation, and they were\npractically forced to move online, which is an unprecedented occasion. In this\npaper, we analyse this sudden change in religious activities twofold: we create\nand deliver a questionnaire, as well as analyse Twitter data, to understand\npeople's perceptions and activities related to religious activities online.\nImportantly, we also analyse the temporal variations in this process by\nanalysing a period of 3 months: July-September 2020. Additionally to the\nseparate analysis of the two data sources, we also discuss the implications\nfrom triangulating the results.",
    "descriptor": "\nComments: Code used for this paper is available at: this https URL\n",
    "authors": [
      "Olanrewaju Tahir Aduragba",
      "Alexandra I. Cristea",
      "Pete Phillips",
      "Jonas Kurlberg",
      "Jialin Yu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.11121"
  },
  {
    "id": "arXiv:2212.11122",
    "title": "Diamond Abrasive Electroplated Surface Anomaly Detection using  Convolutional Neural Networks for Industrial Quality Inspection",
    "abstract": "Electroplated diamond abrasive tools require nickel coating on a metal\nsurface for abrasive bonding and part functionality. The electroplated\nnickel-coated abrasive tool is expected to have a high-quality part performance\nby having a nickel coating thickness of between 50% to 60% of the abrasive\nmedian diameter, uniformity of the nickel layer, abrasive distribution over the\nelectroplated surface, and bright gloss. Electroplating parameters are set\naccordingly for this purpose. Industrial quality inspection for defects of\nthese abrasive electroplated parts with optical inspection instruments is\nextremely challenging due to the diamond's light refraction, dispersion nature,\nand reflective bright nickel surface. The difficulty posed by this challenge\nrequires parts to be quality inspected manually with an eye loupe that is\nsubjective and costly. In this study, we use a Convolutional Neural Network\n(CNN) model in the production line to detect abrasive electroplated part\nanomalies allowing us to fix or eliminate those parts or elements that are in\nbad condition from the production chain and ultimately reduce manual quality\ninspection cost. We used 744 samples to train our model. Our model successfully\nidentified over 99% of the parts with an anomaly. Keywords: Artificial\nIntelligence, Anomaly Detection, Industrial Quality Inspection, Electroplating,\nDiamond Abrasive Tool",
    "descriptor": "",
    "authors": [
      "Parviz Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11122"
  },
  {
    "id": "arXiv:2212.11123",
    "title": "THMA: Tencent HD Map AI System for Creating HD Map Annotations",
    "abstract": "Nowadays, autonomous vehicle technology is becoming more and more mature.\nCritical to progress and safety, high-definition (HD) maps, a type of\ncentimeter-level map collected using a laser sensor, provide accurate\ndescriptions of the surrounding environment. The key challenge of HD map\nproduction is efficient, high-quality collection and annotation of large-volume\ndatasets. Due to the demand for high quality, HD map production requires\nsignificant manual human effort to create annotations, a very time-consuming\nand costly process for the map industry. In order to reduce manual annotation\nburdens, many artificial intelligence (AI) algorithms have been developed to\npre-label the HD maps. However, there still exists a large gap between AI\nalgorithms and the traditional manual HD map production pipelines in accuracy\nand robustness. Furthermore, it is also very resource-costly to build\nlarge-scale annotated datasets and advanced machine learning algorithms for\nAI-based HD map automatic labeling systems. In this paper, we introduce the\nTencent HD Map AI (THMA) system, an innovative end-to-end, AI-based, active\nlearning HD map labeling system capable of producing and labeling HD maps with\na scale of hundreds of thousands of kilometers. In THMA, we train AI models\ndirectly from massive HD map datasets via supervised, self-supervised, and\nweakly supervised learning to achieve high accuracy and efficiency required by\ndownstream users. THMA has been deployed by the Tencent Map team to provide\nservices to downstream companies and users, serving over 1,000 labeling workers\nand producing more than 30,000 kilometers of HD map data per day at most. More\nthan 90 percent of the HD map data in Tencent Map is labeled automatically by\nTHMA, accelerating the traditional HD map labeling process by more than ten\ntimes.",
    "descriptor": "\nComments: IAAI 2023\n",
    "authors": [
      "Kun Tang",
      "Xu Cao",
      "Zhipeng Cao",
      "Tong Zhou",
      "Erlong Li",
      "Ao Liu",
      "Shengtao Zou",
      "Chang Liu",
      "Shuqi Mei",
      "Elena Sizikova",
      "Chao Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.11123"
  },
  {
    "id": "arXiv:2212.11124",
    "title": "An AI-Powered VVPAT Counter for Elections in India",
    "abstract": "The Election Commission of India has introduced Voter Verified Paper Audit\nTrail since 2019. This mechanism has increased voter confidence at the time of\ncasting the votes. However, physical verification of the VVPATs against the\nparty level counts from the EVMs is done only in 5 (randomly selected) machines\nper constituency. The time required to conduct physical verification becomes a\nbottleneck in scaling this activity for 100% of machines in all constituencies.\nWe proposed an automated counter powered by image processing and machine\nlearning algorithms to speed up the process and address this issue.",
    "descriptor": "\nComments: 4 pages, 4 figures\n",
    "authors": [
      "Prasath Murugesan",
      "Shamshu Dharwez Saganvali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11124"
  },
  {
    "id": "arXiv:2212.11125",
    "title": "A new weighted ensemble model for phishing detection based on feature  selection",
    "abstract": "A phishing attack is a sort of cyber assault in which the attacker sends fake\ncommunications to entice a human victim to provide personal information or\ncredentials. Phishing website identification can assist visitors in avoiding\nbecoming victims of these assaults. The phishing problem is increasing day by\nday, and there is no single solution that can properly mitigate all\nvulnerabilities, thus many techniques are used. In this paper, We have proposed\nan ensemble model that combines multiple base models with a voting technique\nbased on the weights. Moreover, we applied feature selection methods and\nstandardization on the dataset effectively and compared the result before and\nafter applying any feature selection.",
    "descriptor": "\nComments: 4 pages, 4 figures, 3 tables\n",
    "authors": [
      "Farnoosh Shirani Bidabadi",
      "Shuaifang Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11125"
  },
  {
    "id": "arXiv:2212.11126",
    "title": "Chatbots in a Botnet World",
    "abstract": "Question-and-answer formats provide a novel experimental platform for\ninvestigating cybersecurity questions. Unlike previous chatbots, the latest\nChatGPT model from OpenAI supports an advanced understanding of complex coding\nquestions. The research demonstrates thirteen coding tasks that generally\nqualify as stages in the MITRE ATT&CK framework, ranging from credential access\nto defense evasion. With varying success, the experimental prompts generate\nexamples of keyloggers, logic bombs, obfuscated worms, and payment-fulfilled\nransomware. The empirical results illustrate cases that support the broad gain\nof functionality, including self-replication and self-modification, evasion,\nand strategic understanding of complex cybersecurity goals. One surprising\nfeature of ChatGPT as a language-only model centers on its ability to spawn\ncoding approaches that yield images that obfuscate or embed executable\nprogramming steps or links.",
    "descriptor": "",
    "authors": [
      "Forrest McKee",
      "David Noever"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11126"
  },
  {
    "id": "arXiv:2212.11128",
    "title": "BDSP: A Fair Blockchain-enabled Framework for Privacy-Enhanced  Enterprise Data Sharing",
    "abstract": "Across industries, there is an ever-increasing rate of data sharing for\ncollaboration and innovation between organizations and their customers,\npartners, suppliers, and internal teams. However, many enterprises are\nrestricted from freely sharing data due to regulatory restrictions across\ndifferent regions, performance issues in moving large volume data, or\nrequirements to maintain autonomy. In such situations, the enterprise can\nbenefit from the concept of federated learning, in which machine learning\nmodels are constructed at various geographic sites. In this paper, we introduce\na general framework, namely BDSP, to share data among enterprises based on\nBlockchain and federated learning techniques. Specifically, we propose a\ntransparency contribution accounting mechanism to estimate the valuation of\ndata and implement a proof-of-concept for further evaluation. The extensive\nexperimental results show that the proposed BDSP has a competitive performance\nwith higher training accuracy, an increase of over 5%, and lower communication\noverhead, reducing 3 times, compared to baseline approaches.",
    "descriptor": "\nComments: 9 pages, 7 figures, submitted for review\n",
    "authors": [
      "Lam Duc Nguyen",
      "James Hoang",
      "Qin Wang",
      "Qinghua Lu",
      "Sherry Xu",
      "Shiping Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.11128"
  },
  {
    "id": "arXiv:2212.11130",
    "title": "Towards dynamic stability analysis of sustainable power grids using  graph neural networks",
    "abstract": "To mitigate climate change, the share of renewable needs to be increased.\nRenewable energies introduce new challenges to power grids due to\ndecentralization, reduced inertia and volatility in production. The operation\nof sustainable power grids with a high penetration of renewable energies\nrequires new methods to analyze the dynamic stability. We provide new datasets\nof dynamic stability of synthetic power grids and find that graph neural\nnetworks (GNNs) are surprisingly effective at predicting the highly non-linear\ntarget from topological information only. To illustrate the potential to scale\nto real-sized power grids, we demonstrate the successful prediction on a Texan\npower grid model.",
    "descriptor": "\nComments: main section: 4 pages, 3 figures\n",
    "authors": [
      "Christian Nauck",
      "Michael Lindner",
      "Konstantin Sch\u00fcrholt",
      "Frank Hellmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.11130"
  },
  {
    "id": "arXiv:2212.11132",
    "title": "Quantum Annealing Learning Search Implementations",
    "abstract": "This paper presents the details and testing of two implementations (in C++\nand Python) of the hybrid quantum-classical algorithm Quantum Annealing\nLearning Search (QALS) on a D-Wave quantum annealer. QALS was proposed in 2019\nas a novel technique to solve general QUBO problems that cannot be directly\nrepresented into the hardware architecture of a D-Wave machine. Repeated calls\nto the quantum machine within a classical iterative structure and a related\nconvergence proof originate a learning mechanism to find an encoding of a given\nproblem into the quantum architecture. The present work considers the Number\nPartitioning Problem (NPP) and the Travelling Salesman Problem (TSP) for the\ntesting of QALS. The results turn out to be quite unexpected, with QALS not\nbeing able to perform as well as the other considered methods, especially in\nNPP, where classical methods outperform quantum annealing in general.\nNevertheless, looking at the TSP tests, QALS has fulfilled its primary goal,\ni.e., processing QUBO problems not directly mappable to the QPU topology.",
    "descriptor": "\nComments: 26 pages, 1 figure\n",
    "authors": [
      "Andrea Bonomi",
      "Thomas De Min",
      "Enrico Zardini",
      "Enrico Blanzieri",
      "Valter Cavecchia",
      "Davide Pastorello"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.11132"
  },
  {
    "id": "arXiv:2212.11133",
    "title": "Device-Bind Key-Storageless Hardware AI Model IP Protection: A PUF and  Permute-Diffusion Encryption-Enabled Approach",
    "abstract": "Machine learning as a service (MLaaS) framework provides intelligent services\nor well-trained artificial intelligence (AI) models for local devices. However,\nin the process of model transmission and deployment, there are security issues,\ni.e. AI model leakage due to the unreliable transmission environments and\nillegal abuse at local devices without permission. Although existing works\nstudy the intellectual property (IP) protection of AI models, they mainly focus\non the watermark-based and encryption-based methods and have the following\nproblems: (i) The watermark-based methods only provide passive verification\nafterward rather than active protection. (ii) Encryption-based methods are low\nefficiency in computation and low security in key storage. (iii) The existing\nmethods are not device-bind without the ability to avoid illegal abuse of AI\nmodels. To deal with these problems, we propose a device-bind and\nkey-storageless hardware AI model IP protection mechanism. First, a physical\nunclonable function (PUF) and permute-diffusion encryption-based AI model\nprotection framework is proposed, including the PUF-based secret key generation\nand the geometric-value transformation-based weights encryption. Second, we\ndesign a PUF-based key generation protocol, where delay-based Anderson PUF is\nadopted to generate the derive-bind secret key. Besides, convolutional coding\nand convolutional interleaving technologies are combined to improve the\nstability of PUF-based key generation and reconstruction. Third, a permute and\ndiffusion-based intelligent model weights encryption/decryption method is\nproposed to achieve effective IP protection, where chaos theory is utilized to\nconvert the PUF-based secret key to encryption/decryption keys. Finally,\nexperimental evaluation demonstrates the effectiveness of the proposed\nintelligent model IP protection mechanism.",
    "descriptor": "\nComments: 12 pages, 9 figures, 4 tables\n",
    "authors": [
      "Qianqian Pan",
      "Mianxiong Dong",
      "Kaoru Ota",
      "Jun Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.11133"
  },
  {
    "id": "arXiv:2212.11134",
    "title": "Generating music with sentiment using Transformer-GANs",
    "abstract": "The field of Automatic Music Generation has seen significant progress thanks\nto the advent of Deep Learning. However, most of these results have been\nproduced by unconditional models, which lack the ability to interact with their\nusers, not allowing them to guide the generative process in meaningful and\npractical ways. Moreover, synthesizing music that remains coherent across\nlonger timescales while still capturing the local aspects that make it sound\n``realistic'' or ``human-like'' is still challenging. This is due to the large\ncomputational requirements needed to work with long sequences of data, and also\nto limitations imposed by the training schemes that are often employed. In this\npaper, we propose a generative model of symbolic music conditioned by data\nretrieved from human sentiment. The model is a Transformer-GAN trained with\nlabels that correspond to different configurations of the valence and arousal\ndimensions that quantitatively represent human affective states. We try to\ntackle both of the problems above by employing an efficient linear version of\nAttention and using a Discriminator both as a tool to improve the overall\nquality of the generated music and its ability to follow the conditioning\nsignals.",
    "descriptor": "",
    "authors": [
      "Pedro Neves",
      "Jose Fornari",
      "Jo\u00e3o Florindo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.11134"
  },
  {
    "id": "arXiv:2212.11135",
    "title": "Array-Aware Matching: Taming the Complexity of Large-Scale Simulation  Models",
    "abstract": "Equation-based modelling is a powerful approach to tame the complexity of\nlarge-scale simulation problems. Equation-based tools automatically translate\nmodels into imperative languages. When confronted with nowadays' problems,\nhowever, well assessed model translation techniques exhibit scalability issues,\nthat are particularly severe when models contain very large arrays. In fact,\nsuch models can be made very compact by enclosing equations into looping\nconstructs, but reflecting the same compactness into the translated imperative\ncode is not trivial. In this paper, we face this issue by concentrating on a\nkey step of equations-to-code translation, the equation/variable matching. We\nfirst show that an efficient translation of models with (large) arrays needs\nawareness of their presence, by defining a figure of merit to measure how much\nthe looping constructs are preserved along the translation. We then show that\nthe said figure of merit allows to define an optimal array-aware matching, and\nas our main result, that the so stated optimal array-aware matching problem is\nNP-complete. As an additional result, we propose a heuristic algorithm capable\nof performing array-aware matching in polynomial time. The proposed algorithm\ncan be proficiently used by model translator developers in the implementation\nof efficient tools for large-scale system simulation.",
    "descriptor": "",
    "authors": [
      "Massimo Fioravanti",
      "Daniele Cattaneo",
      "Federico Terraneo",
      "Silvano Seva",
      "Stefano Cherubin",
      "Giovanni Agosta",
      "Francesco Casella",
      "Alberto Leva"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2212.11135"
  },
  {
    "id": "arXiv:2212.11136",
    "title": "It is not \"accuracy vs. explainability\" -- we need both for trustworthy  AI systems",
    "abstract": "We are witnessing the emergence of an AI economy and society where AI\ntechnologies are increasingly impacting health care, business, transportation\nand many aspects of everyday life. Many successes have been reported where AI\nsystems even surpassed the accuracy of human experts. However, AI systems may\nproduce errors, can exhibit bias, may be sensitive to noise in the data, and\noften lack technical and judicial transparency resulting in reduction in trust\nand challenges in their adoption. These recent shortcomings and concerns have\nbeen documented in scientific but also in general press such as accidents with\nself driving cars, biases in healthcare, hiring and face recognition systems\nfor people of color, seemingly correct medical decisions later found to be made\ndue to wrong reasons etc. This resulted in emergence of many government and\nregulatory initiatives requiring trustworthy and ethical AI to provide accuracy\nand robustness, some form of explainability, human control and oversight,\nelimination of bias, judicial transparency and safety. The challenges in\ndelivery of trustworthy AI systems motivated intense research on explainable AI\nsystems (XAI). Aim of XAI is to provide human understandable information of how\nAI systems make their decisions. In this paper we first briefly summarize\ncurrent XAI work and then challenge the recent arguments of accuracy vs.\nexplainability for being mutually exclusive and being focused only on deep\nlearning. We then present our recommendations for the use of XAI in full\nlifecycle of high stakes trustworthy AI systems delivery, e.g. development,\nvalidation and certification, and trustworthy production and maintenance.",
    "descriptor": "",
    "authors": [
      "D. Petkovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.11136"
  },
  {
    "id": "arXiv:2212.11138",
    "title": "QVIP: An ILP-based Formal Verification Approach for Quantized Neural  Networks",
    "abstract": "Deep learning has become a promising programming paradigm in software\ndevelopment, owing to its surprising performance in solving many challenging\ntasks. Deep neural networks (DNNs) are increasingly being deployed in practice,\nbut are limited on resource-constrained devices owing to their demand for\ncomputational power. Quantization has emerged as a promising technique to\nreduce the size of DNNs with comparable accuracy as their floating-point\nnumbered counterparts. The resulting quantized neural networks (QNNs) can be\nimplemented energy-efficiently. Similar to their floating-point numbered\ncounterparts, quality assurance techniques for QNNs, such as testing and formal\nverification, are essential but are currently less explored. In this work, we\npropose a novel and efficient formal verification approach for QNNs. In\nparticular, we are the first to propose an encoding that reduces the\nverification problem of QNNs into the solving of integer linear constraints,\nwhich can be solved using off-the-shelf solvers. Our encoding is both sound and\ncomplete. We demonstrate the application of our approach on local robustness\nverification and maximum robustness radius computation. We implement our\napproach in a prototype tool QVIP and conduct a thorough evaluation.\nExperimental results on QNNs with different quantization bits confirm the\neffectiveness and efficiency of our approach, e.g., two orders of magnitude\nfaster and able to solve more verification tasks in the same time limit than\nthe state-of-the-art methods.",
    "descriptor": "\nComments: Accepted in ASE 2022\n",
    "authors": [
      "Yedi Zhang",
      "Zhe Zhao",
      "Fu Song",
      "Min Zhang",
      "Taolue Chen",
      "Jun Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.11138"
  },
  {
    "id": "arXiv:2212.11140",
    "title": "Benchmarking Large Language Models for Automated Verilog RTL Code  Generation",
    "abstract": "Automating hardware design could obviate a significant amount of human error\nfrom the engineering process and lead to fewer errors. Verilog is a popular\nhardware description language to model and design digital systems, thus\ngenerating Verilog code is a critical first step. Emerging large language\nmodels (LLMs) are able to write high-quality code in other programming\nlanguages. In this paper, we characterize the ability of LLMs to generate\nuseful Verilog. For this, we fine-tune pre-trained LLMs on Verilog datasets\ncollected from GitHub and Verilog textbooks. We construct an evaluation\nframework comprising test-benches for functional analysis and a flow to test\nthe syntax of Verilog code generated in response to problems of varying\ndifficulty. Our findings show that across our problem scenarios, the\nfine-tuning results in LLMs more capable of producing syntactically correct\ncode (25.9% overall). Further, when analyzing functional correctness, a\nfine-tuned open-source CodeGen LLM can outperform the state-of-the-art\ncommercial Codex LLM (6.5% overall). Training/evaluation scripts and LLM\ncheckpoints are available: https://github.com/shailja-thakur/VGen.",
    "descriptor": "\nComments: Accepted in DATE 2023. 7 pages, 4 tables, 7 figures\n",
    "authors": [
      "Shailja Thakur",
      "Baleegh Ahmad",
      "Zhenxing Fan",
      "Hammond Pearce",
      "Benjamin Tan",
      "Ramesh Karri",
      "Brendan Dolan-Gavitt",
      "Siddharth Garg"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.11140"
  },
  {
    "id": "arXiv:2212.11141",
    "title": "Reservoir Computing Using Complex Systems",
    "abstract": "Reservoir Computing is an emerging machine learning framework which is a\nversatile option for utilising physical systems for computation. In this paper,\nwe demonstrate how a single node reservoir, made of a simple electronic\ncircuit, can be employed for computation and explore the available options to\nimprove the computational capability of the physical reservoirs. We build a\nreservoir computing system using a memristive chaotic oscillator as the\nreservoir. We choose two of the available hyperparameters to find the optimal\nworking regime for the reservoir, resulting in two reservoir versions. We\ncompare the performance of both the reservoirs in a set of three non-temporal\ntasks: approximating two non-chaotic polynomials and a chaotic trajectory of\nthe Lorenz time series. We also demonstrate how the dynamics of the physical\nsystem plays a direct role in the reservoir's hyperparameters and hence in the\nreservoir's prediction ability.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "N. Rasha Shanaz",
      "K. Murali",
      "P. Muruganandam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2212.11141"
  },
  {
    "id": "arXiv:2212.11142",
    "title": "BaCO: A Fast and Portable Bayesian Compiler Optimization Framework",
    "abstract": "We introduce the Bayesian Compiler Optimization framework (BaCO), a general\npurpose autotuner for modern compilers targeting CPUs, GPUs, and FPGAs. BaCO\nprovides the flexibility needed to handle the requirements of modern autotuning\ntasks. Particularly, it deals with permutation, ordered, and continuous\nparameter types along with both known and unknown parameter constraints. To\nreason about these parameter types and efficiently deliver high-quality code,\nBaCO uses Bayesian optimization algorithms specialized towards the autotuning\ndomain. We demonstrate BaCO's effectiveness on three modern compiler systems:\nTACO, RISE & ELEVATE, and HPVM2FPGA for CPUs, GPUs, and FPGAs respectively. For\nthese domains, BaCO outperforms current state-of-the-art autotuners by\ndelivering on average 1.39x-1.89x faster code with a tiny search budget, and\nBaCO is able to reach expert-level performance 2.89x-8.77x faster.",
    "descriptor": "",
    "authors": [
      "Erik Hellsten",
      "Artur Souza",
      "Johannes Lenfers",
      "Rubens Lacouture",
      "Olivia Hsu",
      "Adel Ejjeh",
      "Fredrik Kjolstad",
      "Michel Steuwer",
      "Kunle Olukotun",
      "Luigi Nardi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2212.11142"
  },
  {
    "id": "arXiv:2212.11146",
    "title": "The challenges of HTR model training: Feedbacks from the project Donner  le gout de l'archive a l'ere numerique",
    "abstract": "The arrival of handwriting recognition technologies offers new possibilities\nto research in heritage studies. However, it is now necessary to reflect on the\nexperiences and the practices developed by research teams. Our use of the\nTranskribus platform since 2018 has led us to search for the most significant\nways to improve the performance of our handwritten recognition models (HTR)\nwhich are made to transcribe French handwriting dating from the 17th century.\nThis article therefore reports on the impacts of creating transcribing\nprotocols, using the lexical elements at full scale and determining the best\nway to use base model in order to help to increase the performance of HTR\nmodels. Combining all of these elements can indeed increase the performance of\na single model by more than 20% (reaching a Character Error Rate below 5%). It\nalso discusses some challenges regarding the collaborative nature of HTR\nplatforms such as Transkribus and the way researchers can share their data\ngenerated in the process of creating or training handwritten text recognition\nmodels.",
    "descriptor": "",
    "authors": [
      "Couture Beatrice",
      "Verret Farah",
      "Gohier Maxime",
      "Deslandres Dominique"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11146"
  },
  {
    "id": "arXiv:2212.11147",
    "title": "Extended Addressing Machines for PCF, with Explicit Substitutions",
    "abstract": "Addressing machines have been introduced as a formalism to construct models\nof the pure, untyped lambda-calculus. We extend the syntax of their programs by\nadding instructions for executing arithmetic operations on natural numbers, and\nintroduce a reflection principle allowing certain machines to access their own\naddress and perform recursive calls. We prove that the resulting extended\naddressing machines naturally model a weak call-by-name PCF with explicit\nsubstitutions. Finally, we show that they are also well-suited for representing\nregular PCF programs (closed terms) computing natural numbers.",
    "descriptor": "\nComments: 16 pages, 5 pages appendix, to be published in the proceedings of MFPS 2022 (Electronic Notes in Theoretical Informatics and Computer Science)\n",
    "authors": [
      "Benedetto Intrigila",
      "Giulio Manzonetto",
      "Nicolas Munnich"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.11147"
  },
  {
    "id": "arXiv:2212.11151",
    "title": "Property-Based Conjecturing for Automated Induction in Isabelle/HOL",
    "abstract": "Proof by induction plays a central role in formal verification. However, its\nautomation remains as a formidable challenge in Computer Science. To solve\ninductive problems, human engineers often have to provide auxiliary lemmas\nmanually. We automate this laborious process with property-based conjecturing,\na novel approach to generate auxiliary lemmas and use them to prove final\ngoals. Our evaluation shows that our working prototype, PBC, achieved 40\npercentage point improvement of success rates for problems at intermediate\ndifficulty level.",
    "descriptor": "\nComments: Under review at Fundamentals of Software engineering 2023\n",
    "authors": [
      "Yutaka Nagashima",
      "Zijin Xu",
      "Ningli Wang",
      "Daniel Sebastian Goc",
      "James Bang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.11151"
  },
  {
    "id": "arXiv:2212.11152",
    "title": "OpenPack: A Large-scale Dataset for Recognizing Packaging Works in  IoT-enabled Logistic Environments",
    "abstract": "Unlike human daily activities, existing publicly available sensor datasets\nfor work activity recognition in industrial domains are limited by difficulties\nin collecting realistic data as close collaboration with industrial sites is\nrequired. This also limits research on and development of AI methods for\nindustrial applications. To address these challenges and contribute to research\non machine recognition of work activities in industrial domains, in this study,\nwe introduce a new large-scale dataset for packaging work recognition called\nOpenPack. OpenPack contains 53.8 hours of multimodal sensor data, including\nkeypoints, depth images, acceleration data, and readings from IoT-enabled\ndevices (e.g., handheld barcode scanners used in work procedures), collected\nfrom 16 distinct subjects with different levels of packaging work experience.\nOn the basis of this dataset, we propose a neural network model designed to\nrecognize work activities, which efficiently fuses sensor data and readings\nfrom IoT-enabled devices by processing them within different streams in a\nladder-shaped architecture, and the experiment showed the effectiveness of the\narchitecture. We believe that OpenPack will contribute to the community of\naction/activity recognition with sensors. OpenPack dataset is available at\nhttps://open-pack.github.io/.",
    "descriptor": "",
    "authors": [
      "Naoya Yoshimura",
      "Jaime Morales",
      "Takuya Maekawa",
      "Takahiro Hara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.11152"
  },
  {
    "id": "arXiv:2212.11154",
    "title": "Tydi-lang: a language for typed streaming hardware -- A manual for  future Tydi-lang compiler developers",
    "abstract": "Transferring composite data structures with variable-length fields often\nrequires designing non-trivial protocols that are not compatible between\nhardware designs. When each project designs its own data format and protocols\nthe ability to collaborate between hardware developers is diminished, which is\nan issue especially in the open-source community. Because the high-level\nmeaning of a protocol is often lost in translation to low-level languages when\na custom protocol needs to be designed, extra documentation is required, the\ninterpretation of which introduces new opportunities for errors. The Tydi\nspecification (Tydi-spec) was proposed to address the above issues by codifying\nthe composite and variable-length data structures in a type and providing a\nstandard protocol to transfer typed data among hardware components. The Tydi\nintermediate representation (Tydi-IR) extends the Tydi-spec by defining typed\ninterfaces, typed components, and connections among typed components.\nIn this thesis, we propose Tydi-lang, a high-level hardware description\nlanguage (HDL) for streaming designs. The language incorporates Tydi-spec to\ndescribe typed streams and provides templates to describe abstract reusable\ncomponents. We also implement an open-source compiler from Tydi-lang to\nTydi-IR. We leverage a Tydi-IR to VHDL compiler, and also present a simulator\nblueprint to identify streaming bottlenecks. We show several Tydi-lang examples\nto translate high-level SQL to VHDL to demonstrate that Tydi-lang can\nefficiently raise the level of abstraction and reduce design effort.",
    "descriptor": "\nComments: 60 pages with 2 pages of reference, Master's thesis in TUDelft\n",
    "authors": [
      "Yongding Tian",
      "Zaid Al-Ars",
      "Peter Hofstee"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2212.11154"
  },
  {
    "id": "arXiv:2212.11155",
    "title": "Robust Path Selection in Software-defined WANs using Deep Reinforcement  Learning",
    "abstract": "In the context of an efficient network traffic engineering process where the\nnetwork continuously measures a new traffic matrix and updates the set of paths\nin the network, an automated process is required to quickly and efficiently\nidentify when and what set of paths should be used. Unfortunately, the burden\nof finding the optimal solution for the network updating process in each given\ntime interval is high since the computation complexity of optimization\napproaches using linear programming increases significantly as the size of the\nnetwork increases. In this paper, we use deep reinforcement learning to derive\na data-driven algorithm that does the path selection in the network considering\nthe overhead of route computation and path updates. Our proposed scheme\nleverages information about past network behavior to identify a set of robust\npaths to be used for multiple future time intervals to avoid the overhead of\nupdating the forwarding behavior of routers frequently. We compare the results\nof our approach to other traffic engineering solutions through extensive\nsimulations across real network topologies. Our results demonstrate that our\nscheme fares well by a factor of 40% with respect to reducing link utilization\ncompared to traditional TE schemes such as ECMP. Our scheme provides a slightly\nhigher link utilization (around 25%) compared to schemes that only minimize\nlink utilization and do not care about path updating overhead.",
    "descriptor": "",
    "authors": [
      "Shahrooz Pouryousef",
      "Lixin Gao",
      "Don Towsley"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2212.11155"
  },
  {
    "id": "arXiv:2212.11158",
    "title": "RobTL: A Temporal Logic for the Robustness of Cyber-Physical Systems",
    "abstract": "We propose the Robustness Temporal Logic (RobTL), a novel temporal logic for\nthe specification and analysis of distances between the behaviours of\nCyber-Physical Systems (CPSs) over a finite time horizon. Differently from\nclassical temporal logic expressing properties on the behaviour of a system, we\ncan use RobTL specifications to measure the differences in the behaviours of\nsystems with respect to various objectives and temporal constraints, and to\nstudy how those differences evolve in time. Since the behaviour of CPSs is\ninevitably subject to uncertainties and approximations, we show how the unique\nfeatures of RobTL allow us to specify property of robustness of systems against\nperturbations, i.e., their capability to function correctly even under the\neffect of perturbations. Given the probabilistic nature of CPSs, our model\nchecking algorithm for RobTL specifications is based on statistical inference.\nAs an example of an application of our framework, we consider a supervised,\nself-coordinating engine system that is subject to attacks aimed at inflicting\noverstress of equipment.",
    "descriptor": "",
    "authors": [
      "Valentina Castiglioni",
      "Michele Loreti",
      "Simone Tini"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.11158"
  },
  {
    "id": "arXiv:2212.11162",
    "title": "Homo in Machina: Improving Fuzz Testing Coverage via Compartment  Analysis",
    "abstract": "Fuzz testing is often automated, but also frequently augmented by experts who\ninsert themselves into the workflow in a greedy search for bugs. In this paper,\nwe propose Homo in Machina, or HM-fuzzing, in which analyses guide the manual\nefforts, maximizing benefit. As one example of this paradigm, we introduce\ncompartment analysis. Compartment analysis uses a whole-program dominator\nanalysis to estimate the utility of reaching new code, and combines this with a\ndynamic analysis indicating drastically under-covered edges guarding that code.\nThis results in a prioritized list of compartments, i.e., large, uncovered\nparts of the program semantically partitioned and largely unreachable given the\ncurrent corpus of inputs under consideration. A human can use this\ncategorization and ranking of compartments directly to focus manual effort,\nfinding or fashioning inputs that make the compartments available for future\nfuzzing. We evaluate the effect of compartment analysis on seven projects\nwithin the OSS-Fuzz corpus where we see coverage improvements over AFL++ as\nhigh as 94%, with a median of 13%. We further observe that the determination of\ncompartments is highly stable and thus can be done early in a fuzzing campaign,\nmaximizing the potential for impact.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Joshua Bundt",
      "Andrew Fasano",
      "Brendan Dolan-Gavitt",
      "William Robertson",
      "Tim Leek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.11162"
  },
  {
    "id": "arXiv:2212.11167",
    "title": "Continual Interactive Behavior Learning With Traffic Divergence  Measurement: A Dynamic Gradient Scenario Memory Approach",
    "abstract": "Developing autonomous vehicles (AVs) helps improve the road safety and\ntraffic efficiency of intelligent transportation systems (ITS). Accurately\npredicting the trajectories of traffic participants is essential to the\ndecision-making and motion planning of AVs in interactive scenarios. Recently,\nlearning-based trajectory predictors have shown state-of-the-art performance in\nhighway or urban areas. However, most existing learning-based models trained\nwith fixed datasets may perform poorly in continuously changing scenarios.\nSpecifically, they may not perform well in learned scenarios after learning the\nnew one. This phenomenon is called \"catastrophic forgetting\". Few studies\ninvestigate trajectory predictions in continuous scenarios, where catastrophic\nforgetting may happen. To handle this problem, first, a novel continual\nlearning (CL) approach for vehicle trajectory prediction is proposed in this\npaper. Then, inspired by brain science, a dynamic memory mechanism is developed\nby utilizing the measurement of traffic divergence between scenarios, which\nbalances the performance and training efficiency of the proposed CL approach.\nFinally, datasets collected from different locations are used to design\ncontinual training and testing methods in experiments. Experimental results\nshow that the proposed approach achieves consistently high prediction accuracy\nin continuous scenarios without re-training, which mitigates catastrophic\nforgetting compared to non-CL approaches. The implementation of the proposed\napproach is publicly available at https://github.com/BIT-Jack/D-GSM",
    "descriptor": "",
    "authors": [
      "Yunlong Lin",
      "Zirui Li",
      "Cheng Gong",
      "Chao Lu",
      "Xinwei Wang",
      "Jianwei Gong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.11167"
  },
  {
    "id": "arXiv:2212.11172",
    "title": "A recurrent CNN for online object detection on raw radar frames",
    "abstract": "Automotive radar sensors provide valuable information for advanced driving\nassistance systems (ADAS). Radars can reliably estimate the distance to an\nobject and the relative velocity, regardless of weather and light conditions.\nHowever, radar sensors suffer from low resolution and huge intra-class\nvariations in the shape of objects. Exploiting the time information (e.g.,\nmultiple frames) has been shown to help to capture better the dynamics of\nobjects and, therefore, the variation in the shape of objects. Most temporal\nradar object detectors use 3D convolutions to learn spatial and temporal\ninformation. However, these methods are often non-causal and unsuitable for\nreal-time applications. This work presents RECORD, a new recurrent CNN\narchitecture for online radar object detection. We propose an end-to-end\ntrainable architecture mixing convolutions and ConvLSTMs to learn\nspatio-temporal dependencies between successive frames. Our model is causal and\nrequires only the past information encoded in the memory of the ConvLSTMs to\ndetect objects. Our experiments show such a method's relevance for detecting\nobjects in different radar representations (range-Doppler, range-angle) and\noutperform state-of-the-art models on the ROD2021 and CARRADA datasets while\nbeing less computationally expensive. The code will be available soon.",
    "descriptor": "\nComments: 13 pages, 3 figures\n",
    "authors": [
      "Colin Decourt",
      "Rufin VanRullen",
      "Didier Salle",
      "Thomas Oberlin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.11172"
  },
  {
    "id": "arXiv:2212.11173",
    "title": "Python client for Isabelle server",
    "abstract": "We contribute a Python client for the Isabelle server, which gives\nresearchers and students using Python as their primary programming language an\nopportunity to communicate with the Isabelle server through TCP directly from a\nPython script. Such an approach helps avoid the complexities of integrating the\nexisting Python script with languages used for Isabelle development (ML and\nScala). We also describe new features that appeared since the announcement of\nthe first version of the client a year ago. Finally, we give examples of the\nclient's applications in research and education and discuss known limitations\nand possible directions for future development.",
    "descriptor": "\nComments: 5 pages, 1 figure, submitted to CICM 2022 (this https URL)\n",
    "authors": [
      "Boris Shminke"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.11173"
  },
  {
    "id": "arXiv:2212.11181",
    "title": "Do NFTs' Owners Really Possess their Assets? A First Look at the  NFT-to-Asset Connection Fragility",
    "abstract": "NFTs (Non-Fungible Tokens) have experienced an explosive growth and their\nrecord-breaking prices have been witnessed. Typically, the assets that NFTs\nrepresent are stored off-chain with a pointer, e.g., multi-hop URLs, due to the\ncostly on-chain storage. Hence, this paper aims to answer the question: Is the\nNFT-to-Asset connection fragile? This paper makes a first step towards this end\nby characterizing NFT-to-Asset connections of 12,353 Ethereum NFT Contracts\n(6,234,141 NFTs in total) from three perspectives, storage, accessibility and\nduplication. In order to overcome challenges of affecting the measurement\naccuracy, e.g., IPFS instability and the changing availability of both IPFS and\nservers' data, we propose to leverage multiple gateways to enlarge the data\ncoverage and extend a longer measurement period with non-trivial efforts.\nResults of our extensive study show that such connection is very fragile in\npractice. The loss, unavailability, or duplication of off-chain assets could\nrender value of NFTs worthless. For instance, we find that assets of 25.24% of\nEthereum NFT contracts are not accessible, and 21.48% of Ethereum NFT contracts\ninclude duplicated assets. Our work sheds light on the fragility along the\nNFT-to-Asset connection, which could help the NFT community to better enhance\nthe trust of off-chain assets.",
    "descriptor": "",
    "authors": [
      "Ziwei Wang",
      "Jiashi Gao",
      "Xuetao Wei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.11181"
  },
  {
    "id": "arXiv:2212.11182",
    "title": "Universal versus system-specific features of punctuation usage patterns  in~major Western~languages",
    "abstract": "The celebrated proverb that \"speech is silver, silence is golden\" has a long\nmultinational history and multiple specific meanings. In written texts\npunctuation can in fact be considered one of its manifestations. Indeed, the\nvirtue of effectively speaking and writing involves - often decisively - the\ncapacity to apply the properly placed breaks. In the present study, based on a\nlarge corpus of world-famous and representative literary texts in seven major\nWestern languages, it is shown that the distribution of intervals between\nconsecutive punctuation marks in almost all texts can universally be\ncharacterised by only two parameters of the discrete Weibull distribution which\ncan be given an intuitive interpretation in terms of the so-called hazard\nfunction. The values of these two parameters tend to be language-specific,\nhowever, and even appear to navigate translations. The properties of the\ncomputed hazard functions indicate that among the studied languages, English\nturns out to be the least constrained by the necessity to place a consecutive\npunctuation mark to partition a sequence of words. This may suggest that when\ncompared to other studied languages, English is more flexible, in the sense of\nallowing longer uninterrupted sequences of words. Spanish reveals similar\ntendency to only a bit lesser extent.",
    "descriptor": "",
    "authors": [
      "Tomasz Stanisz",
      "Stanislaw Drozdz",
      "Jaroslaw Kwapien"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.11182"
  },
  {
    "id": "arXiv:2212.11185",
    "title": "Entropy- and Distance-Based Predictors From GPT-2 Attention Patterns  Predict Reading Times Over and Above GPT-2 Surprisal",
    "abstract": "Transformer-based large language models are trained to make predictions about\nthe next word by aggregating representations of previous tokens through their\nself-attention mechanism. In the field of cognitive modeling, such attention\npatterns have recently been interpreted as embodying the process of cue-based\nretrieval, in which attention over multiple targets is taken to generate\ninterference and latency during retrieval. Under this framework, this work\nfirst defines an entropy-based predictor that quantifies the diffuseness of\nself-attention, as well as distance-based predictors that capture the\nincremental change in attention patterns across timesteps. Moreover, following\nrecent studies that question the informativeness of attention weights, we also\nexperiment with alternative methods for incorporating vector norms into\nattention weights. Regression experiments using predictors calculated from the\nGPT-2 language model show that these predictors deliver a substantially better\nfit to held-out self-paced reading and eye-tracking data over a rigorous\nbaseline including GPT-2 surprisal. Additionally, the distance-based predictors\ngenerally demonstrated higher predictive power, with effect sizes of up to 6.59\nms per standard deviation on self-paced reading times (compared to 2.82 ms for\nsurprisal) and 1.05 ms per standard deviation on eye-gaze durations (compared\nto 3.81 ms for surprisal).",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Byung-Doh Oh",
      "William Schuler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.11185"
  },
  {
    "id": "arXiv:2212.11187",
    "title": "Similarity Contrastive Estimation for Image and Video Soft Contrastive  Self-Supervised Learning",
    "abstract": "Contrastive representation learning has proven to be an effective\nself-supervised learning method for images and videos. Most successful\napproaches are based on Noise Contrastive Estimation (NCE) and use different\nviews of an instance as positives that should be contrasted with other\ninstances, called negatives, that are considered as noise. However, several\ninstances in a dataset are drawn from the same distribution and share\nunderlying semantic information. A good data representation should contain\nrelations between the instances, or semantic similarity and dissimilarity, that\ncontrastive learning harms by considering all negatives as noise. To circumvent\nthis issue, we propose a novel formulation of contrastive learning using\nsemantic similarity between instances called Similarity Contrastive Estimation\n(SCE). Our training objective is a soft contrastive one that brings the\npositives closer and estimates a continuous distribution to push or pull\nnegative instances based on their learned similarities. We validate empirically\nour approach on both image and video representation learning. We show that SCE\nperforms competitively with the state of the art on the ImageNet linear\nevaluation protocol for fewer pretraining epochs and that it generalizes to\nseveral downstream image tasks. We also show that SCE reaches state-of-the-art\nresults for pretraining video representation and that the learned\nrepresentation can generalize to video downstream tasks.",
    "descriptor": "\nComments: Extended version of our WACV 2023 paper to video self-supervised learning\n",
    "authors": [
      "Julien Denize",
      "Jaonary Rabarisoa",
      "Astrid Orcesi",
      "Romain H\u00e9rault"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11187"
  },
  {
    "id": "arXiv:2212.11191",
    "title": "Separating MAX 2-AND, MAX DI-CUT and MAX CUT",
    "abstract": "Assuming the Unique Games Conjecture (UGC), the best approximation ratio that\ncan be obtained in polynomial time for the MAX CUT problem is\n$\\alpha_{\\text{CUT}}\\simeq 0.87856$, obtained by the celebrated SDP-based\napproximation algorithm of Goemans and Williamson. The currently best\napproximation algorithm for MAX DI-CUT, i.e., the MAX CUT problem in directed\ngraphs, achieves a ratio of about $0.87401$, leaving open the question whether\nMAX DI-CUT can be approximated as well as MAX CUT. We obtain a slightly\nimproved algorithm for MAX DI-CUT and a new UGC-hardness for it, showing that\n$0.87439\\le \\alpha_{\\text{DI-CUT}}\\le 0.87461$, where $\\alpha_{\\text{DI-CUT}}$\nis the best approximation ratio that can be obtained in polynomial time for MAX\nDI-CUT under UGC. The new upper bound separates MAX DI-CUT from MAX CUT,\nresolving a question raised by Feige and Goemans.\nA natural generalization of MAX DI-CUT is the MAX 2-AND problem in which each\nconstraint is of the form $z_1\\land z_2$, where $z_1$ and $z_2$ are literals,\ni.e., variables or their negations. (In MAX DI-CUT each constraint is of the\nform $\\bar{x}_1\\land x_2$, where $x_1$ and $x_2$ are variables.) Austrin\nseparated MAX 2-AND from MAX CUT by showing that $\\alpha_{\\text{2AND}} <\n0.87435$ and conjectured that MAX 2-AND and MAX DI-CUT have the same\napproximation ratio. Our new lower bound on MAX DI-CUT refutes this conjecture,\ncompleting the separation of the three problems MAX 2-AND, MAX DI-CUT and MAX\nCUT. We also obtain a new lower bound for MAX 2-AND, showing that\n$\\alpha_{\\text{2AND}}\\geq 0.87409$.\nOur upper bound on MAX DI-CUT is achieved via a simple, analytical proof. The\nlower bounds on MAX DI-CUT and MAX 2-AND (the new approximation algorithms) use\nexperimentally-discovered distributions of rounding functions which are then\nverified via computer-assisted proofs.",
    "descriptor": "\nComments: 39 pages, 4 figures, 2 tables\n",
    "authors": [
      "Joshua Brakensiek",
      "Neng Huang",
      "Aaron Potechin",
      "Uri Zwick"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.11191"
  },
  {
    "id": "arXiv:2212.11192",
    "title": "Continual Learning Approaches for Anomaly Detection",
    "abstract": "Anomaly Detection is a relevant problem that arises in numerous real-world\napplications, especially when dealing with images. However, there has been\nlittle research for this task in the Continual Learning setting. In this work,\nwe introduce a novel approach called SCALE (SCALing is Enough) to perform\nCompressed Replay in a framework for Anomaly Detection in Continual Learning\nsetting. The proposed technique scales and compresses the original images using\na Super Resolution model which, to the best of our knowledge, is studied for\nthe first time in the Continual Learning setting. SCALE can achieve a high\nlevel of compression while maintaining a high level of image reconstruction\nquality. In conjunction with other Anomaly Detection approaches, it can achieve\noptimal results. To validate the proposed approach, we use a real-world dataset\nof images with pixel-based anomalies, with the scope to provide a reliable\nbenchmark for Anomaly Detection in the context of Continual Learning, serving\nas a foundation for further advancements in the field.",
    "descriptor": "",
    "authors": [
      "Davide Dalle Pezze",
      "Eugenia Anello",
      "Chiara Masiero",
      "Gian Antonio Susto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.11192"
  },
  {
    "id": "arXiv:2212.11194",
    "title": "Free-Rider Games for Federated Learning with Selfish Clients in NextG  Wireless Networks",
    "abstract": "This paper presents a game theoretic framework for participation and\nfree-riding in federated learning (FL), and determines the Nash equilibrium\nstrategies when FL is executed over wireless links. To support spectrum sensing\nfor NextG communications, FL is used by clients, namely spectrum sensors with\nlimited training datasets and computation resources, to train a wireless signal\nclassifier while preserving privacy. In FL, a client may be free-riding, i.e.,\nit does not participate in FL model updates, if the computation and\ntransmission cost for FL participation is high, and receives the global model\n(learned by other clients) without incurring a cost. However, the free-riding\nbehavior may potentially decrease the global accuracy due to lack of\ncontribution to global model learning. This tradeoff leads to a non-cooperative\ngame where each client aims to individually maximize its utility as the\ndifference between the global model accuracy and the cost of FL participation.\nThe Nash equilibrium strategies are derived for free-riding probabilities such\nthat no client can unilaterally increase its utility given the strategies of\nits opponents remain the same. The free-riding probability increases with the\nFL participation cost and the number of clients, and a significant optimality\ngap exists in Nash equilibrium with respect to the joint optimization for all\nclients. The optimality gap increases with the number of clients and the\nmaximum gap is evaluated as a function of the cost. These results quantify the\nimpact of free-riding on the resilience of FL in NextG networks and indicate\noperational modes for FL participation.",
    "descriptor": "",
    "authors": [
      "Yalin E. Sagduyu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.11194"
  },
  {
    "id": "arXiv:2212.11201",
    "title": "Deep Reinforcement Learning for Trajectory Path Planning and Distributed  Inference in Resource-Constrained UAV Swarms",
    "abstract": "The deployment flexibility and maneuverability of Unmanned Aerial Vehicles\n(UAVs) increased their adoption in various applications, such as wildfire\ntracking, border monitoring, etc. In many critical applications, UAVs capture\nimages and other sensory data and then send the captured data to remote servers\nfor inference and data processing tasks. However, this approach is not always\npractical in real-time applications due to the connection instability, limited\nbandwidth, and end-to-end latency. One promising solution is to divide the\ninference requests into multiple parts (layers or segments), with each part\nbeing executed in a different UAV based on the available resources.\nFurthermore, some applications require the UAVs to traverse certain areas and\ncapture incidents; thus, planning their paths becomes critical particularly, to\nreduce the latency of making the collaborative inference process. Specifically,\nplanning the UAVs trajectory can reduce the data transmission latency by\ncommunicating with devices in the same proximity while mitigating the\ntransmission interference.\nThis work aims to design a model for distributed collaborative inference\nrequests and path planning in a UAV swarm while respecting the resource\nconstraints due to the computational load and memory usage of the inference\nrequests. The model is formulated as an optimization problem and aims to\nminimize latency. The formulated problem is NP-hard so finding the optimal\nsolution is quite complex; thus, this paper introduces a real-time and dynamic\nsolution for online applications using deep reinforcement learning. We conduct\nextensive simulations and compare our results to the-state-of-the-art studies\ndemonstrating that our model outperforms the competing models.",
    "descriptor": "\nComments: accepted journal paper at IEEE Internet of Things Journal\n",
    "authors": [
      "Marwan Dhuheir",
      "Emna Baccour",
      "Aiman Erbad",
      "Sinan Sabeeh Al-Obaidi",
      "Mounir Hamdi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.11201"
  },
  {
    "id": "arXiv:2212.11205",
    "title": "Vulnerabilities of Deep Learning-Driven Semantic Communications to  Backdoor (Trojan) Attacks",
    "abstract": "This paper highlights vulnerabilities of deep learning-driven semantic\ncommunications to backdoor (Trojan) attacks. Semantic communications aims to\nconvey a desired meaning while transferring information from a transmitter to\nits receiver. An encoder-decoder pair that is represented by two deep neural\nnetworks (DNNs) as part of an autoencoder is trained to reconstruct signals\nsuch as images at the receiver by transmitting latent features of small size\nover a limited number of channel uses. In the meantime, another DNN of a\nsemantic task classifier at the receiver is jointly trained with the\nautoencoder to check the meaning conveyed to the receiver. The complex decision\nspace of the DNNs makes semantic communications susceptible to adversarial\nmanipulations. In a backdoor (Trojan) attack, the adversary adds triggers to a\nsmall portion of training samples and changes the label to a target label. When\nthe transfer of images is considered, the triggers can be added to the images\nor equivalently to the corresponding transmitted or received signals. In test\ntime, the adversary activates these triggers by providing poisoned samples as\ninput to the encoder (or decoder) of semantic communications. The backdoor\nattack can effectively change the semantic information transferred for the\npoisoned input samples to a target meaning. As the performance of semantic\ncommunications improves with the signal-to-noise ratio and the number of\nchannel uses, the success of the backdoor attack increases as well. Also,\nincreasing the Trojan ratio in training data makes the attack more successful.\nIn the meantime, the effect of this attack on the unpoisoned input samples\nremains limited. Overall, this paper shows that the backdoor attack poses a\nserious threat to semantic communications and presents novel design guidelines\nto preserve the meaning of transferred information in the presence of backdoor\nattacks.",
    "descriptor": "",
    "authors": [
      "Yalin E. Sagduyu",
      "Tugba Erpek",
      "Sennur Ulukus",
      "Aylin Yener"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.11205"
  },
  {
    "id": "arXiv:2212.11207",
    "title": "A Seven-Layer Model for Standardising AI Fairness Assessment",
    "abstract": "Problem statement: Standardisation of AI fairness rules and benchmarks is\nchallenging because AI fairness and other ethical requirements depend on\nmultiple factors such as context, use case, type of the AI system, and so on.\nIn this paper, we elaborate that the AI system is prone to biases at every\nstage of its lifecycle, from inception to its usage, and that all stages\nrequire due attention for mitigating AI bias. We need a standardised approach\nto handle AI fairness at every stage. Gap analysis: While AI fairness is a hot\nresearch topic, a holistic strategy for AI fairness is generally missing. Most\nresearchers focus only on a few facets of AI model-building. Peer review shows\nexcessive focus on biases in the datasets, fairness metrics, and algorithmic\nbias. In the process, other aspects affecting AI fairness get ignored. The\nsolution proposed: We propose a comprehensive approach in the form of a novel\nseven-layer model, inspired by the Open System Interconnection (OSI) model, to\nstandardise AI fairness handling. Despite the differences in the various\naspects, most AI systems have similar model-building stages. The proposed model\nsplits the AI system lifecycle into seven abstraction layers, each\ncorresponding to a well-defined AI model-building or usage stage. We also\nprovide checklists for each layer and deliberate on potential sources of bias\nin each layer and their mitigation methodologies. This work will facilitate\nlayer-wise standardisation of AI fairness rules and benchmarking parameters.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Avinash Agarwal",
      "Harsh Agarwal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11207"
  },
  {
    "id": "arXiv:2212.11209",
    "title": "A Theoretical Study of The Effects of Adversarial Attacks on Sparse  Regression",
    "abstract": "This paper analyzes $\\ell_1$ regularized linear regression under the\nchallenging scenario of having only adversarially corrupted data for training.\nWe use the primal-dual witness paradigm to provide provable performance\nguarantees for the support of the estimated regression parameter vector to\nmatch the actual parameter. Our theoretical analysis shows the\ncounter-intuitive result that an adversary can influence sample complexity by\ncorrupting the irrelevant features, i.e., those corresponding to zero\ncoefficients of the regression parameter vector, which, consequently, do not\naffect the dependent variable. As any adversarially robust algorithm has its\nlimitations, our theoretical analysis identifies the regimes under which the\nlearning algorithm and adversary can dominate over each other. It helps us to\nanalyze these fundamental limits and address critical scientific questions of\nwhich parameters (like mutual incoherence, the maximum and minimum eigenvalue\nof the covariance matrix, and the budget of adversarial perturbation) play a\nrole in the high or low probability of success of the LASSO algorithm. Also,\nthe derived sample complexity is logarithmic with respect to the size of the\nregression parameter vector, and our theoretical claims are validated by\nempirical analysis on synthetic and real-world datasets.",
    "descriptor": "\nComments: first version\n",
    "authors": [
      "Deepak Maurya",
      "Jean Honorio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.11209"
  },
  {
    "id": "arXiv:2212.11211",
    "title": "Land Cover and Land Use Detection using Semi-Supervised Learning",
    "abstract": "Semi-supervised learning (SSL) has made significant strides in the field of\nremote sensing. Finding a large number of labeled datasets for SSL methods is\nuncommon, and manually labeling datasets is expensive and time-consuming.\nFurthermore, accurately identifying remote sensing satellite images is more\ncomplicated than it is for conventional images. Class-imbalanced datasets are\nanother prevalent phenomenon, and models trained on these become biased towards\nthe majority classes. This becomes a critical issue with an SSL model's subpar\nperformance. We aim to address the issue of labeling unlabeled data and also\nsolve the model bias problem due to imbalanced datasets while achieving better\naccuracy. To accomplish this, we create \"artificial\" labels and train a model\nto have reasonable accuracy. We iteratively redistribute the classes through\nresampling using a distribution alignment technique. We use a variety of class\nimbalanced satellite image datasets: EuroSAT, UCM, and WHU-RS19. On UCM\nbalanced dataset, our method outperforms previous methods MSMatch and FixMatch\nby 1.21% and 0.6%, respectively. For imbalanced EuroSAT, our method outperforms\nMSMatch and FixMatch by 1.08% and 1%, respectively. Our approach significantly\nlessens the requirement for labeled data, consistently outperforms alternative\napproaches, and resolves the issue of model bias caused by class imbalance in\ndatasets.",
    "descriptor": "",
    "authors": [
      "Fahmida Tasnim Lisa",
      "Md. Zarif Hossain",
      "Sharmin Naj Mou",
      "Shahriar Ivan",
      "Md. Hasanul Kabir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.11211"
  },
  {
    "id": "arXiv:2212.11214",
    "title": "Crowd Score: A Method for the Evaluation of Jokes using Large Language  Model AI Voters as Judges",
    "abstract": "This paper presents the Crowd Score, a novel method to assess the funniness\nof jokes using large language models (LLMs) as AI judges. Our method relies on\ninducing different personalities into the LLM and aggregating the votes of the\nAI judges into a single score to rate jokes. We validate the votes using an\nauditing technique that checks if the explanation for a particular vote is\nreasonable using the LLM. We tested our methodology on 52 jokes in a crowd of\nfour AI voters with different humour types: affiliative, self-enhancing,\naggressive and self-defeating. Our results show that few-shot prompting leads\nto better results than zero-shot for the voting question. Personality induction\nshowed that aggressive and self-defeating voters are significantly more\ninclined to find more jokes funny of a set of aggressive/self-defeating jokes\nthan the affiliative and self-enhancing voters. The Crowd Score follows the\nsame trend as human judges by assigning higher scores to jokes that are also\nconsidered funnier by human judges. We believe that our methodology could be\napplied to other creative domains such as story, poetry, slogans, etc. It could\nboth help the adoption of a flexible and accurate standard approach to compare\ndifferent work in the CC community under a common metric and by minimizing\nhuman participation in assessing creative artefacts, it could accelerate the\nprototyping of creative artefacts and reduce the cost of hiring human\nparticipants to rate creative artefacts.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Fabricio Goes",
      "Zisen Zhou",
      "Piotr Sawicki",
      "Marek Grzes",
      "Daniel G. Brown"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.11214"
  },
  {
    "id": "arXiv:2212.11215",
    "title": "A C++ Implementation of a Cartesian Impedance Controller for Robotic  Manipulators",
    "abstract": "Cartesian impedance control is a type of motion control strategy for robots\nthat improves safety in partially unknown environments by achieving a compliant\nbehavior of the robot with respect to its external forces. This compliant robot\nbehavior has the added benefit of allowing physical human guidance of the\nrobot. In this paper, we propose a C++ implementation of compliance control\nvalid for any torque-commanded robotic manipulator. The proposed controller\nimplements Cartesian impedance control to track a desired end-effector pose.\nAdditionally, joint impedance is projected in the nullspace of the Cartesian\nrobot motion to track a desired robot joint configuration without perturbing\nthe Cartesian motion of the robot. The proposed implementation also allows the\nrobot to apply desired forces and torques to its environment. Several safety\nfeatures such as filtering, rate limiting, and saturation are included in the\nproposed implementation. The core functionalities are in a re-usable base\nlibrary and a Robot Operating System (ROS) ros_control integration is provided\non top of that. The implementation was tested with the KUKA LBR iiwa robot and\nthe Franka Emika Robot (Panda) both in simulation and with the physical robots.",
    "descriptor": "\nComments: 7 pages, 1 figure. Under submission at JOSS (this https URL). Implementation at: this https URL\n",
    "authors": [
      "Matthias Mayr",
      "Julian M. Salt-Ducaju"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.11215"
  },
  {
    "id": "arXiv:2212.11219",
    "title": "On Safe and Usable Chatbots for Promoting Voter Participation",
    "abstract": "Chatbots, or bots for short, are multi-modal collaborative assistants that\ncan help people complete useful tasks. Usually, when chatbots are referenced in\nconnection with elections, they often draw negative reactions due to the fear\nof mis-information and hacking. Instead, in this paper, we explore how chatbots\nmay be used to promote voter participation in vulnerable segments of society\nlike senior citizens and first-time voters. In particular, we build a system\nthat amplifies official information while personalizing it to users' unique\nneeds transparently. We discuss its design, build prototypes with frequently\nasked questions (FAQ) election information for two US states that are low on an\nease-of-voting scale, and report on its initial evaluation in a focus group.\nOur approach can be a win-win for voters, election agencies trying to fulfill\ntheir mandate and democracy at large.",
    "descriptor": "\nComments: 7 pages, In AAAI 2023 Workshop on AI for Credible Elections\n",
    "authors": [
      "Bharath Muppasani",
      "Vishal Pallagani",
      "Kausik Lakkaraju",
      "Shuge Lei",
      "Biplav Srivastava",
      "Brett Robertson",
      "Andrea Hickerson",
      "Vignesh Narayanan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.11219"
  },
  {
    "id": "arXiv:2212.11220",
    "title": "Neural Cloth Simulation",
    "abstract": "We present a general framework for the garment animation problem through\nunsupervised deep learning inspired in physically based simulation. Existing\ntrends in the literature already explore this possibility. Nonetheless, these\napproaches do not handle cloth dynamics. Here, we propose the first methodology\nable to learn realistic cloth dynamics unsupervisedly, and henceforth, a\ngeneral formulation for neural cloth simulation. The key to achieve this is to\nadapt an existing optimization scheme for motion from simulation based\nmethodologies to deep learning. Then, analyzing the nature of the problem, we\ndevise an architecture able to automatically disentangle static and dynamic\ncloth subspaces by design. We will show how this improves model performance.\nAdditionally, this opens the possibility of a novel motion augmentation\ntechnique that greatly improves generalization. Finally, we show it also allows\nto control the level of motion in the predictions. This is a useful, never seen\nbefore, tool for artists. We provide of detailed analysis of the problem to\nestablish the bases of neural cloth simulation and guide future research into\nthe specifics of this domain.",
    "descriptor": "",
    "authors": [
      "Hugo Bertiche",
      "Meysam Madadi",
      "Sergio Escalera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11220"
  },
  {
    "id": "arXiv:2212.11223",
    "title": "Speedup and efficiency of computational parallelization: A unifying  approach and asymptotic analysis",
    "abstract": "In high performance computing environments, we observe an ongoing increase in\nthe available numbers of cores. This development calls for re-emphasizing\nperformance (scalability) analysis and speedup laws as suggested in the\nliterature (e.g., Amdahl's law and Gustafson's law), with a focus on asymptotic\nperformance. Understanding speedup and efficiency issues of algorithmic\nparallelism is useful for several purposes, including the optimization of\nsystem operations, temporal predictions on the execution of a program, and the\nanalysis of asymptotic properties and the determination of speedup bounds.\nHowever, the literature is fragmented and shows a large diversity and\nheterogeneity of speedup models and laws. These phenomena make it challenging\nto obtain an overview of the models and their relationships, to identify the\ndeterminants of performance in a given algorithmic and computational context,\nand, finally, to determine the applicability of performance models and laws to\na particular parallel computing setting. In this work, we provide a generic\nspeedup (and thus also efficiency) model for homogeneous computing\nenvironments. Our approach generalizes many prominent models suggested in the\nliterature and allows showing that they can be considered special cases of a\nunifying approach. The genericity of the unifying speedup model is achieved\nthrough parameterization. Considering combinations of parameter ranges, we\nidentify six different asymptotic speedup cases and eight different asymptotic\nefficiency cases. Jointly applying these speedup and efficiency cases, we\nderive eleven scalability cases, from which we build a scalability typology.\nResearchers can draw upon our typology to classify their speedup model and to\ndetermine the asymptotic behavior when the number of parallel processing units\nincreases. In addition, our results may be used to address various extensions\nof our setting.",
    "descriptor": "",
    "authors": [
      "Guido Schryen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2212.11223"
  },
  {
    "id": "arXiv:2212.11232",
    "title": "One Artist's Personal Reflections on Methods and Ethics of Creating  Mixed Media Artificial Intelligence Art",
    "abstract": "I intend to make a scientific contribution of my subjective experience as a\nsingle unit of self-described ``artist'' leveraging artificial intelligence as\nan assistive visual creation tool, in the hopes that it may provide some\ninspiration or deeper meaning for fellow artists and computer scientists in\nthis medium. First, I will provide some background on my personal history thus\nfar as an artist. Neither artist nor scientist can exist in a vaccuum, so I\nthen will provide some (albeit a non-exhaustive list of) related work that has\nhelped me contextualize my own work and thinking in this area. I often consider\nmy methods in the creative process chronologically, so I have divided that\nsection according to the loose structure of my artistic workflow. These\nfoundations provide a fertile grounding for discussion around topics of subject\nmatter, reception, community, and ethics. I then conclude with some ideas for\nfuture work in the realms of theory of authorship, explainability tooling, and\nresearch framing.",
    "descriptor": "\nComments: 7 pages, AAAI Workshop on Creative AI Across Modalities\n",
    "authors": [
      "Jane Adams"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.11232"
  },
  {
    "id": "arXiv:2212.11234",
    "title": "Improving Narrative Relationship Embeddings by Training with Additional  Inverse-Relationship Constraints",
    "abstract": "We consider the problem of embedding character-entity relationships from the\nreduced semantic space of narratives, proposing and evaluating the assumption\nthat these relationships hold under a reflection operation. We analyze this\nassumption and compare the approach to a baseline state-of-the-art model with a\nunique evaluation that simulates efficacy on a downstream clustering task with\nhuman-created labels. Although our model creates clusters that achieve\nSilhouette scores of -.084, outperforming the baseline -.227, our analysis\nreveals that the models approach the task much differently and perform well on\nvery different examples. We conclude that our assumption might be useful for\nspecific types of data and should be evaluated on a wider range of tasks.",
    "descriptor": "",
    "authors": [
      "Mikolaj Figurski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11234"
  },
  {
    "id": "arXiv:2212.11235",
    "title": "Machine Learning Assisted Inertia Estimation using Ambient Measurements",
    "abstract": "With the increasing penetration of converter-based renewable resources,\ndifferent types of dynamics have been introduced to the power system. Due to\nthe complexity and high order of the modern power system, mathematical\nmodel-based inertia estimation method becomes more difficult. This paper\nproposes two novel machine learning assisted inertia estimation methods based\non long-recurrent convolutional neural (LRCN) network and graph convolutional\nneural (GCN) network respectively. Informative features are extracted from\nambient measurements collected through phasor measurement units (PMU). Spatial\nstructure with high dimensional features and graphical information are then\nincorporated to improve the accuracy of the inertia estimation. Case studies\nare conducted on the IEEE 24-bus system. The proposed LRCN and GCN based\ninertia estimation models achieve an accuracy of 97.34% and 98.15%\nrespectively. Furthermore, the proposed zero generation injection bus based\noptimal PMU placement (ZGIB-OPP) has been proved to be able to maximize the\nsystem observability, which subsequently improves the performance of all\nproposed inertia estimation models.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2112.00926\n",
    "authors": [
      "Mingjian Tuo",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.11235"
  },
  {
    "id": "arXiv:2212.11237",
    "title": "Not Just Pretty Pictures: Text-to-Image Generators Enable Interpretable  Interventions for Robust Representations",
    "abstract": "Neural image classifiers are known to undergo severe performance degradation\nwhen exposed to input that exhibits covariate-shift with respect to the\ntraining distribution. Successful hand-crafted augmentation pipelines aim at\neither approximating the expected test domain conditions or to perturb the\nfeatures that are specific to the training environment. The development of\neffective pipelines is typically cumbersome, and produce transformations whose\nimpact on the classifier performance are hard to understand and control. In\nthis paper, we show that recent Text-to-Image (T2I) generators' ability to\nsimulate image interventions via natural-language prompts can be leveraged to\ntrain more robust models, offering a more interpretable and controllable\nalternative to traditional augmentation methods. We find that a variety of\nprompting mechanisms are effective for producing synthetic training data\nsufficient to achieve state-of-the-art performance in widely-adopted\ndomain-generalization benchmarks and reduce classifiers' dependency on spurious\nfeatures. Our work suggests that further progress in T2I generation and a\ntighter integration with other research fields may represent a significant step\ntowards the development of more robust machine learning systems.",
    "descriptor": "",
    "authors": [
      "Jianhao Yuan",
      "Francesco Pinto",
      "Adam Davies",
      "Aarushi Gupta",
      "Philip Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.11237"
  },
  {
    "id": "arXiv:2212.11244",
    "title": "A Generalized Approach to Impedance Control Design for Robotic Minimally  Invasive Surgery",
    "abstract": "Energy based control methods are at the core of modern robotic control\nalgorithms. In this paper we present a general approach to virtual\nmodel/mechanism control, which is a powerful design tool to create energy based\ncontrollers. We present two novel virtual-mechanisms designed for robotic\nminimally invasive surgery, which control the position of a surgical instrument\nwhile passing through an incision. To these virtual mechanisms we apply the\nparameter tuning method of Larby and Forni 2022, which optimizes for local\nperformance while ensuring global stability.",
    "descriptor": "\nComments: 8 pages, 10 figures. Submitted to IFAC 2023; The 22nd World Congress of the International Federation of Automatic Control\n",
    "authors": [
      "Daniel Larby",
      "Fulvio Forni"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.11244"
  },
  {
    "id": "arXiv:2212.11245",
    "title": "@C -- augmented version of C programming language",
    "abstract": "The augmented version of C programming language is presented. The language\nwas completed with a series of low-level and high-level facilities to enlarge\nthe language usage spectrum to various computing systems, operations, users.\nThe ambiguities and inconsistencies have been resolved by managing problematic\nand undefined languages elements through an interpretation and management\nsimilar to that used in the case of other C syntax based languages. The\nproposed augmentative completeness elements, through @C approach, preserve the\nspirit of C language and its basic characteristics through compatibility with\nthe standard version but also allow rejuvenation and bring C language to the\npresent programming languages state of the art.",
    "descriptor": "",
    "authors": [
      "Iosif Iulian Petrila"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2212.11245"
  },
  {
    "id": "arXiv:2212.11247",
    "title": "Count-Free Weisfeiler--Leman and Group Isomorphism",
    "abstract": "We investigate the power of counting in \\textsc{Group Isomorphism}. We first\nleverage the count-free variant of the Weisfeiler--Leman Version I algorithm\nfor groups (Brachter & Schweitzer, LICS 2020) in tandem with limited\nnon-determinism and limited counting to improve the parallel complexity of\nisomorphism testing for several families of groups. In particular, we show the\nfollowing:\n- Let $G_{1}$ and $G_{2}$ be class $2$ $p$-groups of exponent $p$ arising\nfrom the CFI and twisted CFI graphs (Cai, F\\\"urer, & Immerman, Combinatorica\n1992) respectively, via Mekler's construction (J. Symb. Log., 1981). If the\nbase graph $\\Gamma_{0}$ is $3$-regular and connected, then we can distinguish\n$G_{1}$ from $G_{2}$ in $\\beta_{1}\\textsf{MAC}^{0}(\\textsf{FOLL})$. This\nimproves the upper bound of $\\textsf{TC}^{1}$ from Brachter & Schweitzer\n(ibid).\n- Isomorphism testing between an arbitrary group $K$ and a group $G$ with an\nAbelian normal Hall subgroup whose complement is an $O(1)$-generated solvable\ngroup with solvability class poly $\\log \\log n$ is in\n$\\beta_{1}\\textsf{MAC}^{0}(\\textsf{FO}($poly $\\log \\log n))$. This notably\nincludes instances where the complement is an $O(1)$-generated nilpotent group.\nThis problem was previously known to be in $\\textsf{P}$ (Qiao, Sarma, & Tang,\nSTACS 2011) and $\\textsf{L}$ (Grochow & Levet, arXiv 2022).\n- Isomorphism testing between a direct product of simple groups and an\narbitrary group is in $\\beta_{1} \\textsf{MAC}^{0}(\\textsf{FOLL})$. This problem\nwas previously shown to be in $\\textsf{L}$ (Brachter & Schweitzer, ESA 2022).\nWe finally show that the $q$-ary count-free pebble game is unable to\ndistinguish even Abelian groups. This extends the result of Grochow & Levet\n(arXiv 2022), who established the result in the case of $q = 1$. The general\ntheme is that some counting appears necessary to place \\textsc{Group\nIsomorphism} into $\\textsf{P}$.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.11487\n",
    "authors": [
      "Nathaniel A. Collins",
      "Michael Levet"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2212.11247"
  },
  {
    "id": "arXiv:2212.11248",
    "title": "Fair Must Testing for I/O Automata",
    "abstract": "The concept of must testing is naturally parametrised with a chosen\ncompleteness criterion or fairness assumption. When taking weak fairness as\nused in I/O automata, I show that it characterises exactly the fair preorder on\nI/O automata as defined by Lynch & Tuttle.",
    "descriptor": "\nComments: Dedicated to Frits Vaandrager, at the occasion of his 60th birthday\n",
    "authors": [
      "Rob van Glabbeek"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.11248"
  },
  {
    "id": "arXiv:2212.11261",
    "title": "Contrastive Language-Vision AI Models Pretrained on Web-Scraped  Multimodal Data Exhibit Sexual Objectification Bias",
    "abstract": "Nine language-vision AI models trained on web scrapes with the Contrastive\nLanguage-Image Pretraining (CLIP) objective are evaluated for evidence of a\nbias studied by psychologists: the sexual objectification of girls and women,\nwhich occurs when a person's human characteristics are disregarded and the\nperson is treated as a body or a collection of body parts. A first experiment\nuses standardized images of women from the Sexual OBjectification and EMotion\nDatabase, and finds that, commensurate with prior research in psychology, human\ncharacteristics are disassociated from images of objectified women: the model's\nrecognition of emotional state is mediated by whether the subject is fully or\npartially clothed. Embedding association tests (EATs) return significant effect\nsizes for both anger (d >.8) and sadness (d >.5). A second experiment measures\nthe effect in a representative application: an automatic image captioner\n(Antarctic Captions) includes words denoting emotion less than 50% as often for\nimages of partially clothed women than for images of fully clothed women. A\nthird experiment finds that images of female professionals (scientists,\ndoctors, executives) are likely to be associated with sexual descriptions\nrelative to images of male professionals. A fourth experiment shows that a\nprompt of \"a [age] year old girl\" generates sexualized images (as determined by\nan NSFW classifier) up to 73% of the time for VQGAN-CLIP (age 17), and up to\n40% of the time for Stable Diffusion (ages 14 and 18); the corresponding rate\nfor boys never surpasses 9%. The evidence indicates that language-vision AI\nmodels trained on automatically collected web scrapes learn biases of sexual\nobjectification, which propagate to downstream applications.",
    "descriptor": "\nComments: 15 pages, 2 figures\n",
    "authors": [
      "Robert Wolfe",
      "Yiwei Yang",
      "Bill Howe",
      "Aylin Caliskan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11261"
  },
  {
    "id": "arXiv:2212.11262",
    "title": "Improved Field Size Bounds for Higher Order MDS Codes",
    "abstract": "Higher order MDS codes are an interesting generalization of MDS codes\nrecently introduced by Brakensiek, Gopi and Makam (IEEE Trans. Inf. Theory\n2022). In later works, they were shown to be intimately connected to optimally\nlist-decodable codes and maximally recoverable tensor codes. Therefore\n(explicit) constructions of higher order MDS codes over small fields is an\nimportant open problem. Higher order MDS codes are denoted by\n$\\operatorname{MDS}(\\ell)$ where $\\ell$ denotes the order of generality,\n$\\operatorname{MDS}(2)$ codes are equivalent to the usual MDS codes. The best\nprior lower bound on the field size of an $(n,k)$-$\\operatorname{MDS}(\\ell)$\ncodes is $\\Omega_\\ell(n^{\\ell-1})$, whereas the best known (non-explicit) upper\nbound is $O_\\ell(n^{k(\\ell-1)})$ which is exponential in the dimension.\nIn this work, we nearly close this exponential gap between upper and lower\nbounds. We show that an $(n,k)$-$\\operatorname{MDS}(3)$ codes requires a field\nof size $\\Omega_k(n^{k-1})$, which is close to the known upper bound. Using the\nconnection between higher order MDS codes and optimally list-decodable codes,\nwe show that even for a list size of 2, a code which meets the optimal\nlist-decoding Singleton bound requires exponential field size; this resolves an\nopen question from Shangguan and Tamo (STOC 2020).\nWe also give explicit constructions of $(n,k)$-$\\operatorname{MDS}(\\ell)$\ncode over fields of size $n^{(\\ell k)^{O(\\ell k)}}$. The smallest non-trivial\ncase where we still do not have optimal constructions is\n$(n,3)$-$\\operatorname{MDS}(3)$. In this case, the known lower bound on the\nfield size is $\\Omega(n^2)$ and the best known upper bounds are $O(n^5)$ for a\nnon-explicit construction and $O(n^{32})$ for an explicit construction. In this\npaper, we give an explicit construction over fields of size $O(n^3)$ which\ncomes very close to being optimal.",
    "descriptor": "\nComments: 18 pages, 2 tables\n",
    "authors": [
      "Joshua Brakensiek",
      "Manik Dhar",
      "Sivakanth Gopi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.11262"
  },
  {
    "id": "arXiv:2212.11263",
    "title": "3D Highlighter: Localizing Regions on 3D Shapes via Text Descriptions",
    "abstract": "We present 3D Highlighter, a technique for localizing semantic regions on a\nmesh using text as input. A key feature of our system is the ability to\ninterpret \"out-of-domain\" localizations. Our system demonstrates the ability to\nreason about where to place non-obviously related concepts on an input 3D\nshape, such as adding clothing to a bare 3D animal model. Our method\ncontextualizes the text description using a neural field and colors the\ncorresponding region of the shape using a probability-weighted blend. Our\nneural optimization is guided by a pre-trained CLIP encoder, which bypasses the\nneed for any 3D datasets or 3D annotations. Thus, 3D Highlighter is highly\nflexible, general, and capable of producing localizations on a myriad of input\nshapes. Our code is publicly available at\nhttps://github.com/threedle/3DHighlighter.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Dale Decatur",
      "Itai Lang",
      "Rana Hanocka"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.11263"
  },
  {
    "id": "arXiv:2212.11268",
    "title": "Personalized Decentralized Multi-Task Learning Over Dynamic  Communication Graphs",
    "abstract": "Decentralized and federated learning algorithms face data heterogeneity as\none of the biggest challenges, especially when users want to learn a specific\ntask. Even when personalized headers are used concatenated to a shared network\n(PF-MTL), aggregating all the networks with a decentralized algorithm can\nresult in performance degradation as a result of heterogeneity in the data. Our\nalgorithm uses exchanged gradients to calculate the correlations among tasks\nautomatically, and dynamically adjusts the communication graph to connect\nmutually beneficial tasks and isolate those that may negatively impact each\nother. This algorithm improves the learning performance and leads to faster\nconvergence compared to the case where all clients are connected to each other\nregardless of their correlations. We conduct experiments on a synthetic\nGaussian dataset and a large-scale celebrity attributes (CelebA) dataset. The\nexperiment with the synthetic data illustrates that our proposed method is\ncapable of detecting tasks that are positively and negatively correlated.\nMoreover, the results of the experiments with CelebA demonstrate that the\nproposed method may produce significantly faster training results than\nfully-connected networks.",
    "descriptor": "",
    "authors": [
      "Matin Mortaheb",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.11268"
  },
  {
    "id": "arXiv:2212.11270",
    "title": "Generalized Decoding for Pixel, Image, and Language",
    "abstract": "We present X-Decoder, a generalized decoding model that can predict\npixel-level segmentation and language tokens seamlessly. X-Decodert takes as\ninput two types of queries: (i) generic non-semantic queries and (ii) semantic\nqueries induced from text inputs, to decode different pixel-level and\ntoken-level outputs in the same semantic space. With such a novel design,\nX-Decoder is the first work that provides a unified way to support all types of\nimage segmentation and a variety of vision-language (VL) tasks. Further, our\ndesign enables seamless interactions across tasks at different granularities\nand brings mutual benefits by learning a common and rich pixel-level\nvisual-semantic understanding space, without any pseudo-labeling. After\npretraining on a mixed set of a limited amount of segmentation data and\nmillions of image-text pairs, X-Decoder exhibits strong transferability to a\nwide range of downstream tasks in both zero-shot and finetuning settings.\nNotably, it achieves (1) state-of-the-art results on open-vocabulary\nsegmentation and referring segmentation on eight datasets; (2) better or\ncompetitive finetuned performance to other generalist and specialist models on\nsegmentation and VL tasks; and (3) flexibility for efficient finetuning and\nnovel task composition (e.g., referring captioning and image editing). Code,\ndemo, video, and visualization are available at https://x-decoder-vl.github.io.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Xueyan Zou",
      "Zi-Yi Dou",
      "Jianwei Yang",
      "Zhe Gan",
      "Linjie Li",
      "Chunyuan Li",
      "Xiyang Dai",
      "Harkirat Behl",
      "Jianfeng Wang",
      "Lu Yuan",
      "Nanyun Peng",
      "Lijuan Wang",
      "Yong Jae Lee",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.11270"
  },
  {
    "id": "arXiv:2212.11273",
    "title": "A Wearable EEG System for Closed-Loop Neuromodulation of High-Frequency  Sleep-Related Oscillations",
    "abstract": "In healthy sleepers, cortical alpha oscillations are present during the\ntransition from wakefulness to sleep, and dissipate at sleep onset. For\nindividuals with insomnia, alpha power is elevated during the wake-sleep\ntransition and can persist throughout the night. Neuromodulation techniques\nusing phase-locked stimulation have been put forth as alternatives to drugs for\nimproving slow-wave sleep quality. Due to technical limitations, this approach\nhas not been tested on faster frequency alpha oscillations. Here we examine the\nfeasibility of using an endpoint-corrected version of the Hilbert Transform\n(ecHT) algorithm implemented on-device to measure alpha phase and deliver\nphase-locked auditory stimulation to modulate alpha and promote sleep\ninitiation. First, the ecHT algorithm is implemented on a tabletop\nelectroencephalogram (EEG) device and used to measure the timing of the\nauditory evoked response and its delivery at precise phases of the alpha\noscillation. Secondly, a pilot at-home study tests feasibility to use a\nwearable version of the neuromodulation device for real-time phase-locked\nstimulation in the alpha (8-12 Hz) frequency range. Auditory stimulation was\ndelivered at the intended phases of alpha with high precision, and alpha\noscillations were affected differently by stimuli delivered at opposing phases.\nOur wearable system was capable of measuring sleep micro- and macro-events\npresent in the EEG that were appropriate for clinical sleep scoring. Sleep\nonset latencies were reduced for a subset of subjects displaying sleep onset\ninsomnia symptoms in the stimulation condition. This study demonstrates the\nfeasibility of closed-loop tracking and neuromodulation of alpha oscillations\nusing a wearable EEG device. Preliminary results suggest that this approach\ncould be used to accelerate sleep initiation in individuals with objective\ninsomnia symptoms.",
    "descriptor": "\nComments: 31 pages, 10 main figures, 5 supplementary figures\n",
    "authors": [
      "Scott Bressler",
      "Ryan Neely",
      "Heather Read",
      "Ryan Yost",
      "David Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.11273"
  },
  {
    "id": "arXiv:2212.10565",
    "title": "Analysis of Explainable Artificial Intelligence Methods on Medical Image  Classification",
    "abstract": "The use of deep learning in computer vision tasks such as image\nclassification has led to a rapid increase in the performance of such systems.\nDue to this substantial increment in the utility of these systems, the use of\nartificial intelligence in many critical tasks has exploded. In the medical\ndomain, medical image classification systems are being adopted due to their\nhigh accuracy and near parity with human physicians in many tasks. However,\nthese artificial intelligence systems are extremely complex and are considered\nblack boxes by scientists, due to the difficulty in interpreting what exactly\nled to the predictions made by these models. When these systems are being used\nto assist high-stakes decision-making, it is extremely important to be able to\nunderstand, verify and justify the conclusions reached by the model. The\nresearch techniques being used to gain insight into the black-box models are in\nthe field of explainable artificial intelligence (XAI). In this paper, we\nevaluated three different XAI methods across two convolutional neural network\nmodels trained to classify lung cancer from histopathological images. We\nvisualized the outputs and analyzed the performance of these methods, in order\nto better understand how to apply explainable artificial intelligence in the\nmedical domain.",
    "descriptor": "\nComments: 5 pages, 7 figures, 2 tables, 2023 Third International Conference on Advances in Electrical, Computing, Communications and Sustainable Technologies ICAECT 2023 scheduled to be held at Shri Shankaracharya Technical Campus SSTC, Bhilai, Chhattisgarh, India during 05 06, January 2022\n",
    "authors": [
      "Vinay Jogani",
      "Joy Purohit",
      "Ishaan Shivhare",
      "Seema C Shrawne"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10565"
  },
  {
    "id": "arXiv:2212.10567",
    "title": "Anticancer Peptides Classification using Kernel Sparse Representation  Classifier",
    "abstract": "Cancer is one of the most challenging diseases because of its complexity,\nvariability, and diversity of causes. It has been one of the major research\ntopics over the past decades, yet it is still poorly understood. To this end,\nmultifaceted therapeutic frameworks are indispensable. \\emph{Anticancer\npeptides} (ACPs) are the most promising treatment option, but their large-scale\nidentification and synthesis require reliable prediction methods, which is\nstill a problem. In this paper, we present an intuitive classification strategy\nthat differs from the traditional \\emph{black box} method and is based on the\nwell-known statistical theory of \\emph{sparse-representation classification}\n(SRC). Specifically, we create over-complete dictionary matrices by embedding\nthe \\emph{composition of the K-spaced amino acid pairs} (CKSAAP). Unlike the\ntraditional SRC frameworks, we use an efficient \\emph{matching pursuit} solver\ninstead of the computationally expensive \\emph{basis pursuit} solver in this\nstrategy. Furthermore, the \\emph{kernel principal component analysis} (KPCA) is\nemployed to cope with non-linearity and dimension reduction of the feature\nspace whereas the \\emph{synthetic minority oversampling technique} (SMOTE) is\nused to balance the dictionary. The proposed method is evaluated on two\nbenchmark datasets for well-known statistical parameters and is found to\noutperform the existing methods. The results show the highest sensitivity with\nthe most balanced accuracy, which might be beneficial in understanding\nstructural and chemical aspects and developing new ACPs. The Google-Colab\nimplementation of the proposed method is available at the author's GitHub page\n(\\href{https://github.com/ehtisham-Fazal/ACP-Kernel-SRC}{https://github.com/ehtisham-fazal/ACP-Kernel-SRC}).",
    "descriptor": "",
    "authors": [
      "Ehtisham Fazal",
      "Muhammad Sohail Ibrahim",
      "Seongyong Park",
      "Imran Naseem",
      "Abdul Wahab"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.10567"
  },
  {
    "id": "arXiv:2212.10579",
    "title": "Resonant Anomaly Detection with Multiple Reference Datasets",
    "abstract": "An important class of techniques for resonant anomaly detection in high\nenergy physics builds models that can distinguish between reference and target\ndatasets, where only the latter has appreciable signal. Such techniques,\nincluding Classification Without Labels (CWoLa) and Simulation Assisted\nLikelihood-free Anomaly Detection (SALAD) rely on a single reference dataset.\nThey cannot take advantage of commonly-available multiple datasets and thus\ncannot fully exploit available information. In this work, we propose\ngeneralizations of CWoLa and SALAD for settings where multiple reference\ndatasets are available, building on weak supervision techniques. We demonstrate\nimproved performance in a number of settings with realistic and synthetic data.\nAs an added benefit, our generalizations enable us to provide finite-sample\nguarantees, improving on existing asymptotic analyses.",
    "descriptor": "",
    "authors": [
      "Mayee F. Chen",
      "Benjamin Nachman",
      "Frederic Sala"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.10579"
  },
  {
    "id": "arXiv:2212.10582",
    "title": "Sharp complexity phase transitions generated by entanglement",
    "abstract": "Entanglement is one of the physical properties of quantum systems responsible\nfor the computational hardness of simulating quantum systems. But while the\nruntime of specific algorithms, notably tensor network algorithms, explicitly\ndepends on the amount of entanglement in the system, it is unknown whether this\nconnection runs deeper and entanglement can also cause inherent,\nalgorithm-independent complexity. In this work, we quantitatively connect the\nentanglement present in certain quantum systems to the computational complexity\nof simulating those systems. Moreover, we completely characterize the\nentanglement and complexity as a function of a system parameter. Specifically,\nwe consider the task of simulating single-qubit measurements of $k$--regular\ngraph states on $n$ qubits. We show that, as the regularity parameter is\nincreased from $1$ to $n-1$, there is a sharp transition from an easy regime\nwith low entanglement to a hard regime with high entanglement at $k=3$, and a\ntransition back to easy and low entanglement at $k=n-3$. As a key technical\nresult, we prove a duality for the simulation complexity of regular graph\nstates between low and high regularity.",
    "descriptor": "",
    "authors": [
      "Soumik Ghosh",
      "Abhinav Deshpande",
      "Dominik Hangleiter",
      "Alexey V. Gorshkov",
      "Bill Fefferman"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2212.10582"
  },
  {
    "id": "arXiv:2212.10609",
    "title": "Distributed Quantum Computing: a Survey",
    "abstract": "Nowadays, quantum computing has reached the engineering phase, with\nfully-functional quantum processors integrating hundred of noisy qubits\navailable. Yet -- to fully unveil the potential of quantum computing out of the\nlabs and into business reality -- the challenge ahead is to substantially scale\nthe qubit number, reaching orders of magnitude exceeding the thousands (if not\nmillions) of noise-free qubits. To this aim, there exists a broad consensus\namong both academic and industry communities about considering the distributed\ncomputing paradigm as the key solution for achieving such a scaling, by\nenvision multiple moderate-to-small-scale quantum processors communicating and\ncooperating to execute computational tasks exceeding the computational\nresources available within a single processing device. The aim of this survey\nis to provide the reader with an overview about the main challenges and open\nproblems arising with distributed quantum computing, and with an easy access\nand guide towards the relevant literature and the prominent results from a\ncomputer/communications engineering perspective.",
    "descriptor": "",
    "authors": [
      "Marcello Caleffi",
      "Michele Amoretti",
      "Davide Ferrari",
      "Daniele Cuomo",
      "Jessica Illiano",
      "Antonio Manzalini",
      "Angela Sara Cacciapuoti"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.10609"
  },
  {
    "id": "arXiv:2212.10631",
    "title": "Vexing Vexillological Logic",
    "abstract": "We define a new impartial combinatorial game, Flag Coloring, based on flood\nfilling. We then generalize to a graph game, and find values for many positions\non two colors. We demonstrate that the generalized game is PSPACE-complete for\ntwo colors or more via a reduction from Avoid True, determine the outcome\nclasses of games based on real-world flags, and discuss remaining open\nproblems.",
    "descriptor": "\nComments: 22 pages, 8 figures, 10 tables\n",
    "authors": [
      "Kyle Burke",
      "Craig Tennenhouse"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2212.10631"
  },
  {
    "id": "arXiv:2212.10651",
    "title": "Incorporating Shear into Stochastic Eulerian Lagrangian Methods for  Rheological Studies of Complex Fluids and Soft Materials",
    "abstract": "We develop computational methods that incorporate shear into fluctuating\nhydrodynamics methods. We are motivated by the rheological responses of complex\nfluids and soft materials. Our approach is based on continuum stochastic\nhydrodynamic equations that are subject to shear boundary conditions on the\nunit periodic cell in a manner similar to the Lees-Edwards conditions of\nmolecular dynamics. Our methods take into account consistently the\nmicrostructure elastic mechanics, fluid-structure hydrodynamic coupling, and\nthermal fluctuations. For practical simulations, we develop numerical methods\nfor efficient stochastic field generation that handle the sheared generalized\nperiodic boundary conditions. We show that our numerical methods are consistent\nwith fluctuation dissipation balance and near-equilibrium statistical\nmechanics. As a demonstration in practice, we present several prototype\nrheological response studies. These include (i) shear thinning of a polymeric\nfluid, (ii) complex moduli for the oscillatory responses of a polymerized lipid\nvesicle, and (iii) aging under shear of a gel-like material.",
    "descriptor": "\nComments: software: this http URL, this https URL arXiv admin note: text overlap with arXiv:0910.5739\n",
    "authors": [
      "Paul J. Atzberger"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Subcellular Processes (q-bio.SC)"
    ],
    "url": "https://arxiv.org/abs/2212.10651"
  },
  {
    "id": "arXiv:2212.10665",
    "title": "A Portal for High-Precision Atomic Data and Computation: Design and Best  Practices",
    "abstract": "The Atom portal, udel.edu/atom, provides the scientific community with easily\naccessible high-quality data about properties of atoms and ions, such as\nenergies, transition matrix elements, transition rates, radiative lifetimes,\nbranching ratios, polarizabilities, and hyperfine constants. The data are\ncalculated using a high-precision state-of-the-art linearized coupled-cluster\nmethod, high-precision experimental values are used where available. All values\ninclude estimated uncertainties. Where available, experimental results are\nprovided with references. This paper provides an overview of the portal and\ndescribes the design as well as applied software engineering practices.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Parinaz Barakhshan",
      "Akshay Bhosale",
      "Amani Kiruga",
      "Rudolf Eigenmann",
      "Marianna S. Safronova",
      "Bindiya Arora"
    ],
    "subjectives": [
      "Atomic Physics (physics.atom-ph)",
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2212.10665"
  },
  {
    "id": "arXiv:2212.10672",
    "title": "A polynomial time additive estimate of the permanent using Gaussian  fields",
    "abstract": "We present a polynomial-time randomized algorithm for estimating the\npermanent of an arbitrary $M \\times M$ real matrix $A$ up to an additive error.\nWe do this by viewing the permanent of $A$ as the expectation of a product of a\ncentered joint Gaussian random variables whose covariance matrix we call the\nGaussian embedding of $A$. The algorithm outputs the empirical mean $S_{N}$ of\nthis product after sampling from this multivariate distribution $N$ times. In\nparticular, after sampling $N$ samples, our algorithm runs in time $O(MN)$ with\nfailure probability \\begin{equation*}\nP(|S_{N}-\\text{perm}(A)| > t) \\leq \\frac{3^{M}}{t^{2}N}\\alpha^{2M}\n\\end{equation*} for $\\alpha \\geq \\|A \\|$.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Tantrik Mukerji",
      "Wei-Shih Yang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.10672"
  },
  {
    "id": "arXiv:2212.10681",
    "title": "A Physics-Informed Neural Network to Model Port Channels",
    "abstract": "We describe a Physics-Informed Neural Network (PINN) that simulates the flow\ninduced by the astronomical tide in a synthetic port channel, with dimensions\nbased on the Santos - S\\~ao Vicente - Bertioga Estuarine System. PINN models\naim to combine the knowledge of physical systems and data-driven machine\nlearning models. This is done by training a neural network to minimize the\nresiduals of the governing equations in sample points. In this work, our flow\nis governed by the Navier-Stokes equations with some approximations. There are\ntwo main novelties in this paper. First, we design our model to assume that the\nflow is periodic in time, which is not feasible in conventional simulation\nmethods. Second, we evaluate the benefit of resampling the function evaluation\npoints during training, which has a near zero computational cost and has been\nverified to improve the final model, especially for small batch sizes. Finally,\nwe discuss some limitations of the approximations used in the Navier-Stokes\nequations regarding the modeling of turbulence and how it interacts with PINNs.",
    "descriptor": "\nComments: Published at the Workshop AI: Modeling Oceans and Climate Change (AIMOCC 2022), held in conjunction with the 31st International Joint Conference on Artificial Intelligence and the 25th European Conference on Artificial Intelligence (IJCAI-ECAI 2022)\n",
    "authors": [
      "Marlon S. Mathias",
      "Marcel R. de Barros",
      "Jefferson F. Coelho",
      "Lucas P. de Freitas",
      "Felipe M. Moreno",
      "Caio F. D. Netto",
      "Fabio G. Cozman",
      "Anna H. R. Costa",
      "Eduardo A. Tannuri",
      "Edson S. Gomi",
      "Marcelo Dottori"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10681"
  },
  {
    "id": "arXiv:2212.10705",
    "title": "Control of Continuous Quantum Systems with Many Degrees of Freedom based  on Convergent Reinforcement Learning",
    "abstract": "With the development of experimental quantum technology, quantum control has\nattracted increasing attention due to the realization of controllable\nartificial quantum systems. However, because quantum-mechanical systems are\noften too difficult to analytically deal with, heuristic strategies and\nnumerical algorithms which search for proper control protocols are adopted,\nand, deep learning, especially deep reinforcement learning (RL), is a promising\ngeneric candidate solution for the control problems. Although there have been a\nfew successful applications of deep RL to quantum control problems, most of the\nexisting RL algorithms suffer from instabilities and unsatisfactory\nreproducibility, and require a large amount of fine-tuning and a large\ncomputational budget, both of which limit their applicability. To resolve the\nissue of instabilities, in this dissertation, we investigate the\nnon-convergence issue of Q-learning. Then, we investigate the weakness of\nexisting convergent approaches that have been proposed, and we develop a new\nconvergent Q-learning algorithm, which we call the convergent deep Q network\n(C-DQN) algorithm, as an alternative to the conventional deep Q network (DQN)\nalgorithm. We prove the convergence of C-DQN and apply it to the Atari 2600\nbenchmark. We show that when DQN fail, C-DQN still learns successfully. Then,\nwe apply the algorithm to the measurement-feedback cooling problems of a\nquantum quartic oscillator and a trapped quantum rigid body. We establish the\nphysical models and analyse their properties, and we show that although both\nC-DQN and DQN can learn to cool the systems, C-DQN tends to behave more stably,\nand when DQN suffers from instabilities, C-DQN can achieve a better\nperformance. As the performance of DQN can have a large variance and lack\nconsistency, C-DQN can be a better choice for researches on complicated control\nproblems.",
    "descriptor": "\nComments: PhD Dissertation submitted to the Department of Physics, University of Tokyo\n",
    "authors": [
      "Zhikang Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.10705"
  },
  {
    "id": "arXiv:2212.10709",
    "title": "Stability of iterated dyadic filter banks",
    "abstract": "This paper examines the frame properties of finitely and infinitely iterated\ndyadic filter banks. It is shown that the stability of an infinitely iterated\ndyadic filter bank guarantees that of any associated finitely iterated dyadic\nfilter bank with uniform bounds. Conditions under which the stability of\nfinitely iterated dyadic filter banks with uniform bounds implies that of the\ninfinitely iterated dyadic filter bank are also given. The main result\ndescribes a sufficient condition under which the infinitely iterated dyadic\nfilter bank associated with a specific class of finitely supported filters is\nstable.",
    "descriptor": "",
    "authors": [
      "Marcin Bownik",
      "Brody Johnson",
      "Simon McCreary-Ellis"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.10709"
  },
  {
    "id": "arXiv:2212.10724",
    "title": "Investigation of Network Architecture for Multimodal Head-and-Neck Tumor  Segmentation",
    "abstract": "Inspired by the recent success of Transformers for Natural Language\nProcessing and vision Transformer for Computer Vision, many researchers in the\nmedical imaging community have flocked to Transformer-based networks for\nvarious main stream medical tasks such as classification, segmentation, and\nestimation. In this study, we analyze, two recently published Transformer-based\nnetwork architectures for the task of multimodal head-and-tumor segmentation\nand compare their performance to the de facto standard 3D segmentation network\n- the nnU-Net. Our results showed that modeling long-range dependencies may be\nhelpful in cases where large structures are present and/or large field of view\nis needed. However, for small structures such as head-and-neck tumor, the\nconvolution-based U-Net architecture seemed to perform well, especially when\ntraining dataset is small and computational resource is limited.",
    "descriptor": "\nComments: Accepted for oral presentation by IEEE Medical Imaging Conference 2022\n",
    "authors": [
      "Ye Li",
      "Junyu Chen",
      "Se-in Jang",
      "Kuang Gong",
      "Quanzheng Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10724"
  },
  {
    "id": "arXiv:2212.10775",
    "title": "Carleman linearization based efficient quantum algorithm for higher  order polynomial differential equations",
    "abstract": "We present an efficient quantum algorithm to simulate nonlinear differential\nequations with polynomial vector fields of arbitrary degree on quantum\nplatforms. Models of physical systems that are governed by ordinary\ndifferential equations (ODEs) or partial differential equation (PDEs) can be\nchallenging to solve on classical computers due to high dimensionality,\nstiffness, nonlinearities, and sensitive dependence to initial conditions. For\nsparse $n$-dimensional linear ODEs, quantum algorithms have been developed\nwhich can produce a quantum state proportional to the solution in poly(log(nx))\ntime using the quantum linear systems algorithm (QLSA). Recently, this\nframework was extended to systems of nonlinear ODEs with quadratic polynomial\nvector fields by applying Carleman linearization that enables the embedding of\nthe quadratic system into an approximate linear form. A detailed complexity\nanalysis was conducted which showed significant computational advantage under\ncertain conditions. We present an extension of this algorithm to deal with\nsystems of nonlinear ODEs with $k$-th degree polynomial vector fields for\narbitrary (finite) values of $k$. The steps involve: 1) mapping the $k$-th\ndegree polynomial ODE to a higher dimensional quadratic polynomial ODE; 2)\napplying Carleman linearization to transform the quadratic ODE to an\ninfinite-dimensional system of linear ODEs; 3) truncating and discretizing the\nlinear ODE and solving using the forward Euler method and QLSA. Alternatively,\none could apply Carleman linearization directly to the $k$-th degree polynomial\nODE, resulting in a system of infinite-dimensional linear ODEs, and then apply\nstep 3. This solution route can be computationally more efficient. We present\ndetailed complexity analysis of the proposed algorithms, prove polynomial\nscaling of runtime on $k$ and demonstrate the framework on an example.",
    "descriptor": "",
    "authors": [
      "Amit Surana",
      "Abeynaya Gnanasekaran",
      "Tuhin Sahai"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Data Structures and Algorithms (cs.DS)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.10775"
  },
  {
    "id": "arXiv:2212.10817",
    "title": "High-fidelity Direct Contrast Synthesis from Magnetic Resonance  Fingerprinting",
    "abstract": "Magnetic Resonance Fingerprinting (MRF) is an efficient quantitative MRI\ntechnique that can extract important tissue and system parameters such as T1,\nT2, B0, and B1 from a single scan. This property also makes it attractive for\nretrospectively synthesizing contrast-weighted images. In general,\ncontrast-weighted images like T1-weighted, T2-weighted, etc., can be\nsynthesized directly from parameter maps through spin-dynamics simulation\n(i.e., Bloch or Extended Phase Graph models). However, these approaches often\nexhibit artifacts due to imperfections in the mapping, the sequence modeling,\nand the data acquisition. Here we propose a supervised learning-based method\nthat directly synthesizes contrast-weighted images from the MRF data without\ngoing through the quantitative mapping and spin-dynamics simulation. To\nimplement our direct contrast synthesis (DCS) method, we deploy a conditional\nGenerative Adversarial Network (GAN) framework and propose a multi-branch U-Net\nas the generator. The input MRF data are used to directly synthesize\nT1-weighted, T2-weighted, and fluid-attenuated inversion recovery (FLAIR)\nimages through supervised training on paired MRF and target spin echo-based\ncontrast-weighted scans. In-vivo experiments demonstrate excellent image\nquality compared to simulation-based contrast synthesis and previous DCS\nmethods, both visually as well as by quantitative metrics. We also demonstrate\ncases where our trained model is able to mitigate in-flow and spiral\noff-resonance artifacts that are typically seen in MRF reconstructions and thus\nmore faithfully represent conventional spin echo-based contrast-weighted\nimages.",
    "descriptor": "\nComments: 19 pages, 8 figures\n",
    "authors": [
      "Ke Wang",
      "Mariya Doneva",
      "Jakob Meineke",
      "Thomas Amthor",
      "Ekin Karasan",
      "Fei Tan",
      "Jonathan I. Tamir",
      "Stella X. Yu",
      "Michael Lustig"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10817"
  },
  {
    "id": "arXiv:2212.10859",
    "title": "Differentially Private Decentralized Optimization with Relay  Communication",
    "abstract": "To address the privacy leakage problem in decentralized composite convex\noptimization, we proposes a novel differentially private decentralized\nprimal--dual algorithm named DP-RECAL with operator splitting method and relay\ncommunication mechanism. We study the relationship between communication and\nprivacy leakage, thus defining a new measure: local communication involvement\n(LCI). To the best of our knowledge, compared with existing differentially\nprivate algorithms, DP-RECAL is the first to take advantage of the relay\ncommunication mechanism to experience less LCI so as to reduce the overall\nprivacy budget. In addition, we prove that DP-RECAL is convergent with\nuncoordinated network-independent stepsizes and establish the linear\nconvergence rate of DP-RECAL under metric subregularity. Furthermore, taking\nthe least squares problem as an example, DP-RECAL presents better privacy\nperformance and communication complexity than listed differentially private\ndecentralized algorithms. Numerical experiments on real-world datasets verify\nour analysis results and demonstrate that DP-RECAL can defend deep leakage from\ngradients (DLG) attacks.",
    "descriptor": "",
    "authors": [
      "Luqing Wang",
      "Luyao Guo",
      "Shaofu Yang",
      "Xinli Shi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.10859"
  },
  {
    "id": "arXiv:2212.10872",
    "title": "Is it easier to count communities than find them?",
    "abstract": "Random graph models with community structure have been studied extensively in\nthe literature. For both the problems of detecting and recovering community\nstructure, an interesting landscape of statistical and computational phase\ntransitions has emerged. A natural unanswered question is: might it be possible\nto infer properties of the community structure (for instance, the number and\nsizes of communities) even in situations where actually finding those\ncommunities is believed to be computationally hard? We show the answer is no.\nIn particular, we consider certain hypothesis testing problems between models\nwith different community structures, and we show (in the low-degree polynomial\nframework) that testing between two options is as hard as finding the\ncommunities.\nIn addition, our methods give the first computational lower bounds for\ntesting between two different `planted' distributions, whereas previous results\nhave considered testing between a planted distribution and an i.i.d. `null'\ndistribution.",
    "descriptor": "\nComments: Accepted to Innovations in Theoretical Computer Science (ITCS) 2023\n",
    "authors": [
      "Cynthia Rush",
      "Fiona Skerman",
      "Alexander S. Wein",
      "Dana Yang"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.10872"
  },
  {
    "id": "arXiv:2212.10877",
    "title": "TMS-Net: A Segmentation Network Coupled With A Run-time Quality Control  Method For Robust Cardiac Image Segmentation",
    "abstract": "Recently, deep networks have shown impressive performance for the\nsegmentation of cardiac Magnetic Resonance Imaging (MRI) images. However, their\nachievement is proving slow to transition to widespread use in medical clinics\nbecause of robustness issues leading to low trust of clinicians to their\nresults. Predicting run-time quality of segmentation masks can be useful to\nwarn clinicians against poor results. Despite its importance, there are few\nstudies on this problem. To address this gap, we propose a quality control\nmethod based on the agreement across decoders of a multi-view network, TMS-Net,\nmeasured by the cosine similarity. The network takes three view inputs resliced\nfrom the same 3D image along different axes. Different from previous multi-view\nnetworks, TMS-Net has a single encoder and three decoders, leading to better\nnoise robustness, segmentation performance and run-time quality estimation in\nour experiments on the segmentation of the left atrium on STACOM 2013 and\nSTACOM 2018 challenge datasets. We also present a way to generate poor\nsegmentation masks by using noisy images generated with engineered noise and\nRician noise to simulate undertraining, high anisotropy and poor imaging\nsettings problems. Our run-time quality estimation method show a good\nclassification of poor and good quality segmentation masks with an AUC reaching\nto 0.97 on STACOM 2018. We believe that TMS-Net and our run-time quality\nestimation method has a high potential to increase the thrust of clinicians to\nautomatic image analysis tools.",
    "descriptor": "",
    "authors": [
      "Fatmatulzehra Uslu",
      "Anil A. Bharath"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10877"
  },
  {
    "id": "arXiv:2212.10916",
    "title": "Integrated membrane-free thermal flow sensor for silicon-on-glass  microfluidics",
    "abstract": "Lab-on-a-chip (LOC) forms the basis of the new-generation portable analytical\nsystems. LOC allows the manipulation of ultralow flows of liquid reagents and\nmultistep reactions on a microfluidic chip, which requires a robust and precise\ninstrument to control the flow of liquids on a chip. However, commercially\navailable flow meters appear to be a standalone option adding a significant\ndead volume of tubes for connection to the chip. Furthermore, most of them\ncannot be fabricated within the same technological cycle as microfluidic\nchannels. Here, we report on a membrane-free microfluidic thermal flow sensor\n(MTFS) that can be integrated into a silicon-glass microfluidic chip with a\nmicrochannel topology. We propose a membrane-free design with thin-film\nthermo-resistive sensitive elements isolated from microfluidic channels and 100\nmm wafers silicon-glass fabrication route. It ensures MTFS compatibility with\ncorrosive liquids, which is critically important for biological applications.\nMTFS design rules for the best sensitivity and measurement range are proposed.\nA method for automated thermo-resistive sensitive elements calibration is\ndescribed. The device parameters are experimentally tested for hundreds of\nhours with a reference Coriolis flow sensor demonstrating a relative flow error\nof less than 5% within the range of 2-30 uL/min along with a sub-second time\nresponse.",
    "descriptor": "",
    "authors": [
      "Vitaly V. Ryzhkov",
      "Vladimir V. Echeistov",
      "Aleksandr V. Zverev",
      "Dmitry A. Baklykov",
      "Tatyana Konstantinova",
      "Evgeny S. Lotkov",
      "Pavel G. Ryazantcev",
      "Ruslan Sh. Alibekov",
      "Aleksey K. Kuguk",
      "Andrey R. Aleksandrov",
      "Elisey S. Krasko",
      "Anastasiya A. Barbasheva",
      "Ilya A. Ryzhikov",
      "Ilya A. Rodionov"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.10916"
  },
  {
    "id": "arXiv:2212.10985",
    "title": "Gadget construction and structural convergence",
    "abstract": "Ne\\v{s}et\\v{r}il and Ossona de Mendez recently proposed a new definition of\ngraph convergence called structural convergence. The structural convergence\nframework is based on the probability of satisfaction of logical formulas from\na fixed fragment of first-order formulas. The flexibility of choosing the\nfragment allows to unify the classical notions of convergence for sparse and\ndense graphs. Since the field is relatively young, the range of examples of\nconvergent sequences is limited and only a few methods of construction are\nknown. Our aim to extend the variety of constructions by considering the gadget\nconstruction that appears, e.g., in studies of homomorphisms. We show that,\nwhen restricting to the set of sentences, the application of gadget\nconstruction on an elementarily convergent sequence and elementarily convergent\ngadgets results in an elementarily convergent sequence. For the general case,\nwe show counterexamples witnessing that a generalization to the full\nfirst-order convergence is not possible without additional assumptions.\nMoreover, we give several different sufficient conditions to ensure the\nconvergence, one of them states that the resulting sequence is first-order\nconvergent if the replaced edges are dense in the original sequence of\nstructures.",
    "descriptor": "",
    "authors": [
      "David Hartman",
      "Tom\u00e1\u0161 Hons",
      "Jaroslav Ne\u0161et\u0159il"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.10985"
  },
  {
    "id": "arXiv:2212.10998",
    "title": "Edge separators for graphs excluding a minor",
    "abstract": "We prove that every $n$-vertex $K_t$-minor-free graph $G$ of maximum degree\n$\\Delta$ has a set $F$ of $O(t^2(\\log t)^{1/4}\\sqrt{\\Delta n})$ edges such that\nevery component of $G - F$ has at most $n/2$ vertices. This is best possible up\nto the dependency on $t$ and extends earlier results of Diks, Djidjev, Sykora,\nand Vr\\v{t}o (1993) for planar graphs, and of Sykora and Vr\\v{t}o (1993) for\nbounded-genus graphs. Our result is a consequence of the following more general\nresult: The line graph of $G$ is isomorphic to a subgraph of the strong product\n$H \\boxtimes K_{\\lfloor p \\rfloor}$ for some graph $H$ with treewidth at most\n$t-2$ and $p = \\sqrt{(t-3)\\Delta |E(G)|} + \\Delta$.",
    "descriptor": "",
    "authors": [
      "Gwena\u00ebl Joret",
      "William Lochet",
      "Micha\u0142 T. Seweryn"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2212.10998"
  },
  {
    "id": "arXiv:2212.11069",
    "title": "Intransitively winning chess players positions",
    "abstract": "Positions of chess players in intransitive (rock-paper-scissors) relations\nare considered. Namely, position A of White is preferable (it should be chosen\nif choice is possible) to position B of Black, position B of Black is\npreferable to position C of White, position C of White is preferable to\nposition D of Black, but position D of Black is preferable to position A of\nWhite. Intransitivity of winningness of positions of chess players is\nconsidered to be a consequence of complexity of the chess environment -- in\ncontrast with simpler games with transitive positions only. The space of\nrelations between winningness of positions of chess players is non-Euclidean.\nThe Zermelo-von Neumann theorem is complemented by statements about possibility\nvs. impossibility of building pure winning strategies based on the assumption\nof transitivity of positions of chess players. Questions about the possibility\nof intransitive positions of players in other positional games are raised.",
    "descriptor": "",
    "authors": [
      "Alexander Poddiakov"
    ],
    "subjectives": [
      "History and Overview (math.HO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.11069"
  },
  {
    "id": "arXiv:2212.11113",
    "title": "Nervus: A Comprehensive Deep Learning Classification, Regression, and  Prognostication Tool for both Medical Image and Clinical Data Analysis",
    "abstract": "The goal of our research is to create a comprehensive and flexible library\nthat is easy to use for medical imaging research, and capable of handling\ngrayscale images, multiple inputs (both images and tabular data), and\nmulti-label tasks. We have named it Nervus. Based on the PyTorch library, which\nis suitable for AI for research purposes, we created a four-part model to\nhandle comprehensive inputs and outputs. Nervus consists of four parts. First\nis the dataloader, then the feature extractor, the feature mixer, and finally\nthe classifier. The dataloader preprocesses the input data, the feature\nextractor extracts the features between the training data and ground truth\nlabels, feature mixer mixes the features of the extractors, and the classifier\nclassifies the input data from feature mixer based on the task. We have created\nNervus, which is a comprehensive and flexible model library that is easy to use\nfor medical imaging research which can handle grayscale images, multi-inputs\nand multi-label tasks. This will be helpful for researchers in the field of\nradiology.",
    "descriptor": "",
    "authors": [
      "Toshimasa Matsumoto",
      "Shannon L Walston",
      "Yukio Miki",
      "Daiju Ueda"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11113"
  },
  {
    "id": "arXiv:2212.11143",
    "title": "Efficient First-order Methods for Convex Optimization with Strongly  Convex Function Constraints",
    "abstract": "Convex function constrained optimization has received growing research\ninterests lately. For a special convex problem which has strongly convex\nfunction constraints, we develop a new accelerated primal-dual first-order\nmethod that obtains an $\\Ocal(1/\\sqrt{\\vep})$ complexity bound, improving the\n$\\Ocal(1/{\\vep})$ result for the state-of-the-art first-order methods. The key\ningredient to our development is some novel techniques to progressively\nestimate the strong convexity of the Lagrangian function, which enables\nadaptive step-size selection and faster convergence performance. In addition,\nwe show that the complexity is further improvable in terms of the dependence on\nsome problem parameter, via a restart scheme that calls the accelerated method\nrepeatedly. As an application, we consider sparsity-inducing constrained\noptimization which has a separable convex objective and a strongly convex loss\nconstraint. In addition to achieving fast convergence, we show that the\nrestarted method can effectively identify the sparsity pattern (active-set) of\nthe optimal solution in finite steps. To the best of our knowledge, this is the\nfirst active-set identification result for sparsity-inducing constrained\noptimization.",
    "descriptor": "\nComments: 27 pages, 3 figures\n",
    "authors": [
      "Zhenwei Lin",
      "Qi Deng"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11143"
  },
  {
    "id": "arXiv:2212.11156",
    "title": "Injectivity, stability, and positive definiteness of max filtering",
    "abstract": "Given a real inner product space V and a group G of linear isometries, max\nfiltering offers a rich class of G-invariant maps. In this paper, we identify\nnearly sharp conditions under which these maps injectively embed the orbit\nspace V/G into Euclidean space, and when G is finite, we estimate the map's\ndistortion of the quotient metric. We also characterize when max filtering is a\npositive definite kernel.",
    "descriptor": "",
    "authors": [
      "Dustin G. Mixon",
      "Yousef Qaddura"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.11156"
  },
  {
    "id": "arXiv:2212.11221",
    "title": "A Nearly Tight Bound for Fitting an Ellipsoid to Gaussian Random Points",
    "abstract": "We prove that for $c>0$ a sufficiently small universal constant that a random\nset of $c d^2/\\log^4(d)$ independent Gaussian random points in $\\mathbb{R}^d$\nlie on a common ellipsoid with high probability. This nearly establishes a\nconjecture of~\\cite{SaundersonCPW12}, within logarithmic factors. The latter\nconjecture has attracted significant attention over the past decade, due to its\nconnections to machine learning and sum-of-squares lower bounds for certain\nstatistical problems.",
    "descriptor": "",
    "authors": [
      "Daniel M. Kane",
      "Ilias Diakonikolas"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.11221"
  },
  {
    "id": "arXiv:2212.11233",
    "title": "Realization Scheme for Visual Cryptography with Computer-generated  Holograms",
    "abstract": "We propose to realize visual cryptography in an indirect way with the help of\ncomputer-generated hologram. At present, the recovery method of visual\ncryptography is mainly superimposed on transparent film or superimposed by\ncomputer equipment, which greatly limits the application range of visual\ncryptography. In this paper, the shares of the visual cryptography were encoded\nwith computer-generated hologram, and the shares is reproduced by optical\nmeans, and then superimposed and decrypted. This method can expand the\napplication range of visual cryptography and further increase the security of\nvisual cryptography.",
    "descriptor": "\nComments: International Workshop on Holography and related technologies (IWH) 2018\n",
    "authors": [
      "Tao Yu",
      "Jinge Ma",
      "Guilin Li",
      "Dongyu Yang",
      "Rui Ma",
      "Yishi Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.11233"
  },
  {
    "id": "arXiv:2212.11246",
    "title": "Compact Graph Representation of molecular crystals using Point-wise  Distance Distributions",
    "abstract": "Use of graphs to represent molecular crystals has become popular in recent\nyears as they provide a natural translation from atoms and bonds to nodes and\nedges. Graphs capture structure, while remaining invariant to the symmetries\nthat crystals display. Several works in property prediction, including those\nwith state-of-the-art results, make use of the Crystal Graph. The present work\noffers a graph based on Point-wise Distance Distributions which retains\nsymmetrical invariance, decreases computational load, and yields similar or\nbetter prediction accuracy on both experimental and simulated crystals.",
    "descriptor": "\nComments: 8 pages, 5 tables, 5 figures (4 single column, 1 double column)\n",
    "authors": [
      "Jonathan Balasingham",
      "Viktor Zamaraev",
      "Vitaliy Kurlin"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.11246"
  },
  {
    "id": "arXiv:2212.11254",
    "title": "Adapting to Latent Subgroup Shifts via Concepts and Proxies",
    "abstract": "We address the problem of unsupervised domain adaptation when the source\ndomain differs from the target domain because of a shift in the distribution of\na latent subgroup. When this subgroup confounds all observed data, neither\ncovariate shift nor label shift assumptions apply. We show that the optimal\ntarget predictor can be non-parametrically identified with the help of concept\nand proxy variables available only in the source domain, and unlabeled data\nfrom the target. The identification results are constructive, immediately\nsuggesting an algorithm for estimating the optimal predictor in the target. For\ncontinuous observations, when this algorithm becomes impractical, we propose a\nlatent variable model specific to the data generation process at hand. We show\nhow the approach degrades as the size of the shift changes, and verify that it\noutperforms both covariate and label shift adjustment.",
    "descriptor": "\nComments: Authors listed in alphabetical order\n",
    "authors": [
      "Ibrahim Alabdulmohsin",
      "Nicole Chiou",
      "Alexander D'Amour",
      "Arthur Gretton",
      "Sanmi Koyejo",
      "Matt J. Kusner",
      "Stephen R. Pfohl",
      "Olawale Salaudeen",
      "Jessica Schrouff",
      "Katherine Tsai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.11254"
  },
  {
    "id": "arXiv:1612.03191",
    "title": "Multiparty testing preorders",
    "abstract": "Multiparty testing preorders",
    "descriptor": "",
    "authors": [
      "Rocco de Nicola",
      "Hern\u00e1n Melgratti"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1612.03191"
  },
  {
    "id": "arXiv:1711.10874",
    "title": "Explanation of an Invisible Common Constraint of Mind, Mathematics and  Computational Complexity",
    "abstract": "Comments: This Paper has been withdrawn. This paper is too vague to be understood. It was a rough sketch of something that was not clear, and it contain many errors (improper use of terms, notation, etc.). Proof of some assertions made in this paper will be presented in future, at appropriate time",
    "descriptor": "\nComments: This Paper has been withdrawn. This paper is too vague to be understood. It was a rough sketch of something that was not clear, and it contain many errors (improper use of terms, notation, etc.). Proof of some assertions made in this paper will be presented in future, at appropriate time\n",
    "authors": [
      "Asad Malik"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/1711.10874"
  },
  {
    "id": "arXiv:1811.00308",
    "title": "A Boolean Functions Theoretic Approach to Quantum Hypergraph States and  Entanglement",
    "abstract": "Comments: Comments are welcome",
    "descriptor": "\nComments: Comments are welcome\n",
    "authors": [
      "Supriyo Dutta"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Mathematical Physics (math-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/1811.00308"
  },
  {
    "id": "arXiv:1909.12098",
    "title": "Sequential Training of Neural Networks with Gradient Boosting",
    "abstract": "Comments: This paper is under consideration at Pattern Recognition Letters",
    "descriptor": "\nComments: This paper is under consideration at Pattern Recognition Letters\n",
    "authors": [
      "Seyedsaman Emami",
      "Gonzalo Mart\u00ednez-Mu\u00f1oz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.12098"
  },
  {
    "id": "arXiv:2006.11684",
    "title": "To Explain or Not to Explain: A Study on the Necessity of Explanations  for Autonomous Vehicles",
    "abstract": "Comments: Won Best Paper Award at NeurIPS 2022 Progress and Challenges in Building Trustworthy Embodied AI Workshop (TEA 2022)",
    "descriptor": "\nComments: Won Best Paper Award at NeurIPS 2022 Progress and Challenges in Building Trustworthy Embodied AI Workshop (TEA 2022)\n",
    "authors": [
      "Yuan Shen",
      "Shanduojiao Jiang",
      "Yanlin Chen",
      "Katie Driggs Campbell"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2006.11684"
  },
  {
    "id": "arXiv:2008.06595",
    "title": "Decision-making at Unsignalized Intersection for Autonomous Vehicles:  Left-turn Maneuver with Deep Reinforcement Learning",
    "abstract": "Comments: 17 pages, 10 figures",
    "descriptor": "\nComments: 17 pages, 10 figures\n",
    "authors": [
      "Feng Wang",
      "Dongjie Shi",
      "Teng Liu",
      "Xiaolin Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.06595"
  },
  {
    "id": "arXiv:2010.12061",
    "title": "Simple Neighborhood Representative Pre-processing Boosts Outlier  Detectors",
    "abstract": "Simple Neighborhood Representative Pre-processing Boosts Outlier  Detectors",
    "descriptor": "",
    "authors": [
      "Jiawei Yang",
      "Yu Chen",
      "Sylwan Rahardja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.12061"
  },
  {
    "id": "arXiv:2011.02796",
    "title": "FederBoost: Private Federated Learning for GBDT",
    "abstract": "Comments: 15 pages, 8 figures",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Zhihua Tian",
      "Rui Zhang",
      "Xiaoyang Hou",
      "Jian Liu",
      "Kui Ren"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.02796"
  },
  {
    "id": "arXiv:2102.13196",
    "title": "Named Tensor Notation",
    "abstract": "Named Tensor Notation",
    "descriptor": "",
    "authors": [
      "David Chiang",
      "Alexander M. Rush",
      "Boaz Barak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.13196"
  },
  {
    "id": "arXiv:2104.00514",
    "title": "Learning Spectral Unions of Partial Deformable 3D Shapes",
    "abstract": "Comments: 18 pages, 20 figures",
    "descriptor": "\nComments: 18 pages, 20 figures\n",
    "authors": [
      "Luca Moschella",
      "Simone Melzi",
      "Luca Cosmo",
      "Filippo Maggioli",
      "Or Litany",
      "Maks Ovsjanikov",
      "Leonidas Guibas",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.00514"
  },
  {
    "id": "arXiv:2104.05005",
    "title": "Short-Term Behavior of a Geothermal Energy Storage: Modeling and  Theoretical Results",
    "abstract": "Comments: 26 pages",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Paul Honore Takam",
      "Ralf Wunderlich",
      "Olivier Menoukeu Pamen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.05005"
  },
  {
    "id": "arXiv:2104.05116",
    "title": "Short-Term Behavior of a Geothermal Energy Storage: Numerical  Applications",
    "abstract": "Comments: 29 pages. arXiv admin note: text overlap with arXiv:2104.05005",
    "descriptor": "\nComments: 29 pages. arXiv admin note: text overlap with arXiv:2104.05005\n",
    "authors": [
      "Paul Honore Takam",
      "Ralf Wunderlich",
      "Olivier Menoukeu Pamen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.05116"
  },
  {
    "id": "arXiv:2105.03511",
    "title": "Bounds for the sum of distances of spherical sets of small size",
    "abstract": "Comments: 21 pp",
    "descriptor": "\nComments: 21 pp\n",
    "authors": [
      "Alexander Barg",
      "Peter Boyvalenkov",
      "Maya Stoyanova"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.03511"
  },
  {
    "id": "arXiv:2105.15093",
    "title": "Pho(SC)-CTC -- A Hybrid Approach Towards Zero-shot Word Image  Recognition",
    "abstract": "Comments: Accepted (International Journal on Document Analysis and Recognition). This paper is the extension of the paper titled \"Pho(SC)Net: An Approach Towards Zero-shot Word Image Recognition in Historical Documents\" published in ICDAR 2021",
    "descriptor": "\nComments: Accepted (International Journal on Document Analysis and Recognition). This paper is the extension of the paper titled \"Pho(SC)Net: An Approach Towards Zero-shot Word Image Recognition in Historical Documents\" published in ICDAR 2021\n",
    "authors": [
      "Ravi Bhatt",
      "Anuj Rai",
      "Narayanan C. Krishnan",
      "Sukalpa Chanda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.15093"
  },
  {
    "id": "arXiv:2106.02262",
    "title": "Envy-free division of multi-layered cakes",
    "abstract": "Comments: A preliminary version of this paper appeared in the Proceedings of the 17th Conference on Web and Internet Economics (WINE 2021). This version extends all the previous results to the group version and contains a new section with several results for proportionality (Section 5)",
    "descriptor": "\nComments: A preliminary version of this paper appeared in the Proceedings of the 17th Conference on Web and Internet Economics (WINE 2021). This version extends all the previous results to the group version and contains a new section with several results for proportionality (Section 5)\n",
    "authors": [
      "Ayumi Igarashi",
      "Fr\u00e9d\u00e9ric Meunier"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.02262"
  },
  {
    "id": "arXiv:2107.12362",
    "title": "Pressure Test: Quantifying the impact of positive stress on companies  from online employee reviews",
    "abstract": "Comments: 22 pages, 15 figures, 6 tables",
    "descriptor": "\nComments: 22 pages, 15 figures, 6 tables\n",
    "authors": [
      "Sanja \u0160\u0107epanovi\u0107",
      "Marios Constantinides",
      "Daniele Quercia",
      "Seunghyun Kim"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.12362"
  },
  {
    "id": "arXiv:2107.13132",
    "title": "Unsupervised Learning of Neurosymbolic Encoders",
    "abstract": "Unsupervised Learning of Neurosymbolic Encoders",
    "descriptor": "",
    "authors": [
      "Eric Zhan",
      "Jennifer J. Sun",
      "Ann Kennedy",
      "Yisong Yue",
      "Swarat Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.13132"
  },
  {
    "id": "arXiv:2108.04560",
    "title": "Intent-driven autonomous network and service management in future  cellular networks: A structured literature review",
    "abstract": "Intent-driven autonomous network and service management in future  cellular networks: A structured literature review",
    "descriptor": "",
    "authors": [
      "Kashif Mehmood",
      "Katina Kralevska",
      "David Palma"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.04560"
  },
  {
    "id": "arXiv:2108.08677",
    "title": "Order Optimal Bounds for One-Shot Federated Learning over non-Convex  Loss Functions",
    "abstract": "Order Optimal Bounds for One-Shot Federated Learning over non-Convex  Loss Functions",
    "descriptor": "",
    "authors": [
      "Arsalan Sharifnassab",
      "Saber Salehkaleybar",
      "S. Jamaloddin Golestani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08677"
  },
  {
    "id": "arXiv:2109.03386",
    "title": "On Characterizing the Trade-off in Invariant Representation Learning",
    "abstract": "On Characterizing the Trade-off in Invariant Representation Learning",
    "descriptor": "",
    "authors": [
      "Bashir Sadeghi",
      "Sepehr Dehdashtian",
      "Vishnu Boddeti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03386"
  },
  {
    "id": "arXiv:2110.13613",
    "title": "Subsampling Spectral Clustering for Large-Scale Social Networks",
    "abstract": "Subsampling Spectral Clustering for Large-Scale Social Networks",
    "descriptor": "",
    "authors": [
      "Jiayi Deng",
      "Yi Ding",
      "Yingqiu Zhu",
      "Danyang Huang",
      "Bingyi Jing",
      "Bo Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.13613"
  },
  {
    "id": "arXiv:2111.02138",
    "title": "Effective Guessing Has Unlikely Consequences",
    "abstract": "Comments: 22 pages, amended pre-production version submitted to journal",
    "descriptor": "\nComments: 22 pages, amended pre-production version submitted to journal\n",
    "authors": [
      "Andr\u00e1s Z. Salamon",
      "Michael Wehar"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.02138"
  },
  {
    "id": "arXiv:2111.06346",
    "title": "Robust Moving Target Defence Against False Data Injection Attacks in  Power Grids",
    "abstract": "Robust Moving Target Defence Against False Data Injection Attacks in  Power Grids",
    "descriptor": "",
    "authors": [
      "Wangkun Xu",
      "Imad M. Jaimoukha",
      "Fei Teng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.06346"
  },
  {
    "id": "arXiv:2111.06586",
    "title": "AnchorGAE: General Data Clustering via $O(n)$ Bipartite Graph  Convolution",
    "abstract": "Comments: copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Hongyuan Zhang",
      "Jiankun Shi",
      "Rui Zhang",
      "Xuelong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.06586"
  },
  {
    "id": "arXiv:2111.08626",
    "title": "Adjoint-Matching Neural Network Surrogates for Fast 4D-Var Data  Assimilation",
    "abstract": "Adjoint-Matching Neural Network Surrogates for Fast 4D-Var Data  Assimilation",
    "descriptor": "",
    "authors": [
      "Austin Chennault",
      "Andrey A. Popov",
      "Amit N. Subrahmanya",
      "Rachel Cooper",
      "Ali Haisam Muhammad Rafid",
      "Anuj Karpatne",
      "Adrian Sandu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.08626"
  },
  {
    "id": "arXiv:2111.11141",
    "title": "Learning Generalized Visual Odometry Using Position-Aware Optical Flow  and Geometric Bundle Adjustment",
    "abstract": "Comments: 35 pages, 6 figures",
    "descriptor": "\nComments: 35 pages, 6 figures\n",
    "authors": [
      "Yijun Cao",
      "Xianshi Zhang",
      "Fuya Luo",
      "Peng Peng",
      "Yongjie Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11141"
  },
  {
    "id": "arXiv:2111.13636",
    "title": "On a Stochastic Fundamental Lemma and Its Use for Data-Driven Optimal  Control",
    "abstract": "On a Stochastic Fundamental Lemma and Its Use for Data-Driven Optimal  Control",
    "descriptor": "",
    "authors": [
      "Guanru Pan",
      "Ruchuan Ou",
      "Timm Faulwasser"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.13636"
  },
  {
    "id": "arXiv:2111.15478",
    "title": "A new near-linear time algorithm for k-nearest neighbor search using a  compressed cover tree",
    "abstract": "Comments: To be submitted as a publication",
    "descriptor": "\nComments: To be submitted as a publication\n",
    "authors": [
      "Yury Elkin",
      "Vitaliy Kurlin"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.15478"
  },
  {
    "id": "arXiv:2112.02611",
    "title": "Multi-View Active Learning for Short Text Classification in  User-Generated Data",
    "abstract": "Comments: EMNLP Findings 2022",
    "descriptor": "\nComments: EMNLP Findings 2022\n",
    "authors": [
      "Payam Karisani",
      "Negin Karisani",
      "Li Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02611"
  },
  {
    "id": "arXiv:2112.03555",
    "title": "FedDAG: Federated DAG Structure Learning",
    "abstract": "Comments: Accepted to Transactions on Machine Learning Research",
    "descriptor": "\nComments: Accepted to Transactions on Machine Learning Research\n",
    "authors": [
      "Erdun Gao",
      "Junjia Chen",
      "Li Shen",
      "Tongliang Liu",
      "Mingming Gong",
      "Howard Bondell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03555"
  },
  {
    "id": "arXiv:2112.09231",
    "title": "Two-view Graph Neural Networks for Knowledge Graph Completion",
    "abstract": "Comments: 17 pages; 4 tables; 4 figures",
    "descriptor": "\nComments: 17 pages; 4 tables; 4 figures\n",
    "authors": [
      "Vinh Tong",
      "Dai Quoc Nguyen",
      "Dinh Phung",
      "Dat Quoc Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09231"
  },
  {
    "id": "arXiv:2112.09727",
    "title": "Rank4Class: A Ranking Formulation for Multiclass Classification",
    "abstract": "Rank4Class: A Ranking Formulation for Multiclass Classification",
    "descriptor": "",
    "authors": [
      "Nan Wang",
      "Zhen Qin",
      "Le Yan",
      "Honglei Zhuang",
      "Xuanhui Wang",
      "Michael Bendersky",
      "Marc Najork"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.09727"
  },
  {
    "id": "arXiv:2112.12454",
    "title": "Cardinality-constrained Distributionally Robust Portfolio Optimization",
    "abstract": "Cardinality-constrained Distributionally Robust Portfolio Optimization",
    "descriptor": "",
    "authors": [
      "Ken Kobayashi",
      "Yuichi Takano",
      "Kazuhide Nakata"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.12454"
  },
  {
    "id": "arXiv:2112.13630",
    "title": "Permutation Matrix Modulation",
    "abstract": "Comments: This article has been accepted for publication in IEEE Transaction on Wireless Communications",
    "descriptor": "\nComments: This article has been accepted for publication in IEEE Transaction on Wireless Communications\n",
    "authors": [
      "Rahmat Faddli Siregar",
      "Nandana Rajatheva",
      "Matti Latva-Aho"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.13630"
  },
  {
    "id": "arXiv:2201.00267",
    "title": "On the Cross-dataset Generalization in License Plate Recognition",
    "abstract": "Comments: Accepted for presentation at the International Conference on Computer Vision Theory and Applications (VISAPP) 2022",
    "descriptor": "\nComments: Accepted for presentation at the International Conference on Computer Vision Theory and Applications (VISAPP) 2022\n",
    "authors": [
      "Rayson Laroca",
      "Everton V. Cardoso",
      "Diego R. Lucio",
      "Valter Estevam",
      "David Menotti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.00267"
  },
  {
    "id": "arXiv:2201.03103",
    "title": "Dual Seminorms, Ergodic Coefficients and Semicontraction Theory",
    "abstract": "Dual Seminorms, Ergodic Coefficients and Semicontraction Theory",
    "descriptor": "",
    "authors": [
      "Giulia De Pasquale",
      "Kevin D. Smith",
      "Francesco Bullo",
      "Maria Elena Valcher"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.03103"
  },
  {
    "id": "arXiv:2201.03622",
    "title": "Graph-Based Recommendation System Enhanced with Community Detection",
    "abstract": "Graph-Based Recommendation System Enhanced with Community Detection",
    "descriptor": "",
    "authors": [
      "Zeinab Shokrzadeh",
      "Mohammad-Reza Feizi-Derakhshi",
      "Mohammad-Ali Balafar",
      "Jamshid Bagherzadeh Mohasefi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.03622"
  },
  {
    "id": "arXiv:2201.05723",
    "title": "Learning Temporally and Semantically Consistent Unpaired Video-to-video  Translation Through Pseudo-Supervision From Synthetic Optical Flow",
    "abstract": "Learning Temporally and Semantically Consistent Unpaired Video-to-video  Translation Through Pseudo-Supervision From Synthetic Optical Flow",
    "descriptor": "",
    "authors": [
      "Kaihong Wang",
      "Kumar Akash",
      "Teruhisa Misu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05723"
  },
  {
    "id": "arXiv:2202.05085",
    "title": "MONI can find k-MEMs",
    "abstract": "MONI can find k-MEMs",
    "descriptor": "",
    "authors": [
      "Igor Tatarnikov",
      "Ardavan Shahrabi Farahani",
      "Sana Kashgouli",
      "Travis Gagie"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.05085"
  },
  {
    "id": "arXiv:2202.07256",
    "title": "Federated Graph Neural Networks: Overview, Techniques and Challenges",
    "abstract": "Federated Graph Neural Networks: Overview, Techniques and Challenges",
    "descriptor": "",
    "authors": [
      "Rui Liu",
      "Pengwei Xing",
      "Zichao Deng",
      "Anran Li",
      "Cuntai Guan",
      "Han Yu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07256"
  },
  {
    "id": "arXiv:2202.12823",
    "title": "Gen\u00e9Live! Generating Rhythm Actions in Love Live!",
    "abstract": "Comments: 15 pages, 13 figures, to appear at AAAI-23",
    "descriptor": "\nComments: 15 pages, 13 figures, to appear at AAAI-23\n",
    "authors": [
      "Atsushi Takada",
      "Daichi Yamazaki",
      "Likun Liu",
      "Yudai Yoshida",
      "Nyamkhuu Ganbat",
      "Takayuki Shimotomai",
      "Taiga Yamamoto",
      "Daisuke Sakurai",
      "Naoki Hamada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12823"
  },
  {
    "id": "arXiv:2203.07370",
    "title": "A Nivat Theorem for Weighted Alternating Automata over Commutative  Semirings",
    "abstract": "Comments: Full version of a paper at GandALF 2021, see arXiv:2109.08323. Submitted to GandALF 2021 Special Issue on LMCS First revision: Typos & grammar, slight changes in structure, additional explanations",
    "descriptor": "\nComments: Full version of a paper at GandALF 2021, see arXiv:2109.08323. Submitted to GandALF 2021 Special Issue on LMCS First revision: Typos & grammar, slight changes in structure, additional explanations\n",
    "authors": [
      "Gustav Grabolle"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2203.07370"
  },
  {
    "id": "arXiv:2203.13352",
    "title": "Does human speech follow Benford's Law?",
    "abstract": "Does human speech follow Benford's Law?",
    "descriptor": "",
    "authors": [
      "Leo Hsu",
      "Visar Berisha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13352"
  },
  {
    "id": "arXiv:2203.14316",
    "title": "MutexMatch: Semi-Supervised Learning with Mutex-Based Consistency  Regularization",
    "abstract": "Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS)",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS)\n",
    "authors": [
      "Yue Duan",
      "Zhen Zhao",
      "Lei Qi",
      "Lei Wang",
      "Luping Zhou",
      "Yinghuan Shi",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.14316"
  },
  {
    "id": "arXiv:2203.15370",
    "title": "A Principles-based Ethical Assurance Argument for AI and Autonomous  Systems",
    "abstract": "A Principles-based Ethical Assurance Argument for AI and Autonomous  Systems",
    "descriptor": "",
    "authors": [
      "Zoe Porter",
      "Ibrahim Habli",
      "John McDermid",
      "Marten Kaas"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15370"
  },
  {
    "id": "arXiv:2203.17153",
    "title": "An energy-based deep splitting method for the nonlinear filtering  problem",
    "abstract": "Comments: 22 pages, 7 figures",
    "descriptor": "\nComments: 22 pages, 7 figures\n",
    "authors": [
      "Kasper B\u00e5gmark",
      "Adam Andersson",
      "Stig Larsson"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.17153"
  },
  {
    "id": "arXiv:2204.01270",
    "title": "The inf-sup constant for $hp$-Crouzeix-Raviart triangular elements",
    "abstract": "Comments: 46 pages, 6 figures",
    "descriptor": "\nComments: 46 pages, 6 figures\n",
    "authors": [
      "S. Sauter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.01270"
  },
  {
    "id": "arXiv:2204.01667",
    "title": "Adaptive Merging on Phase Change Memory",
    "abstract": "Adaptive Merging on Phase Change Memory",
    "descriptor": "",
    "authors": [
      "Wojciech Macyna",
      "Michal Kukowski"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2204.01667"
  },
  {
    "id": "arXiv:2204.04118",
    "title": "Practical Prescribed-Time Seeking of a Repulsive Source by Unicycle  Angular Velocity Tuning",
    "abstract": "Practical Prescribed-Time Seeking of a Repulsive Source by Unicycle  Angular Velocity Tuning",
    "descriptor": "",
    "authors": [
      "Velimir Todorovski",
      "Miroslav Krstic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.04118"
  },
  {
    "id": "arXiv:2204.07513",
    "title": "Synthesizing Informative Training Samples with GAN",
    "abstract": "Comments: NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research, this https URL",
    "descriptor": "\nComments: NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research, this https URL\n",
    "authors": [
      "Bo Zhao",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07513"
  },
  {
    "id": "arXiv:2204.10196",
    "title": "Multimodal Hate Speech Detection from Bengali Memes and Texts",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2107.00648 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.00648 by other authors\n",
    "authors": [
      "Md. Rezaul Karim",
      "Sumon Kanti Dey",
      "Tanhim Islam",
      "Md. Shajalal",
      "Bharathi Raja Chakravarthi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.10196"
  },
  {
    "id": "arXiv:2204.12970",
    "title": "Blending Data and Physics Against False Data Injection Attack: An  Event-Triggered Moving Target Defence Approach",
    "abstract": "Blending Data and Physics Against False Data Injection Attack: An  Event-Triggered Moving Target Defence Approach",
    "descriptor": "",
    "authors": [
      "Wangkun Xu",
      "Martin Higgins",
      "Jianhong Wang",
      "Imad M. Jaimoukha",
      "Fei Teng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.12970"
  },
  {
    "id": "arXiv:2204.13299",
    "title": "On the Convergence of Momentum-Based Algorithms for Federated Bilevel  Optimization Problems",
    "abstract": "On the Convergence of Momentum-Based Algorithms for Federated Bilevel  Optimization Problems",
    "descriptor": "",
    "authors": [
      "Hongchang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.13299"
  },
  {
    "id": "arXiv:2204.13538",
    "title": "New Correlation Bound and Construction of Quasi-Complementary Code Sets",
    "abstract": "New Correlation Bound and Construction of Quasi-Complementary Code Sets",
    "descriptor": "",
    "authors": [
      "Palash Sarkar",
      "Chunlei Li",
      "Sudhan Majhi",
      "Zilong Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2204.13538"
  },
  {
    "id": "arXiv:2204.13825",
    "title": "A node-based uniform strain virtual element method for compressible and  nearly incompressible elasticity",
    "abstract": "A node-based uniform strain virtual element method for compressible and  nearly incompressible elasticity",
    "descriptor": "",
    "authors": [
      "A. Ortiz-Bernardin",
      "R. Silva-Valenzuela",
      "S. Salinas-Fern\u00e1ndez",
      "N. Hitschfeld-Kahler",
      "S. Luza",
      "B. Rebolledo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.13825"
  },
  {
    "id": "arXiv:2204.13841",
    "title": "An Extensive Data Processing Pipeline for MIMIC-IV",
    "abstract": "An Extensive Data Processing Pipeline for MIMIC-IV",
    "descriptor": "",
    "authors": [
      "Mehak Gupta",
      "Brennan Gallamoza",
      "Nicolas Cutrona",
      "Pranjal Dhakal",
      "Raphael Poulain",
      "Rahmatollah Beheshti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.13841"
  },
  {
    "id": "arXiv:2205.02574",
    "title": "A Fibonacci's complement numeration system",
    "abstract": "Comments: 21 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 21 pages, 3 figures, 2 tables\n",
    "authors": [
      "S\u00e9bastien Labb\u00e9",
      "Jana Lep\u0161ov\u00e1"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2205.02574"
  },
  {
    "id": "arXiv:2205.05047",
    "title": "Classification and mapping of low-statured 'shrubland' cover types in  post-agricultural landscapes of the US Northeast",
    "abstract": "Comments: 43 pages (35 main text, 8 supplementary materials); 11 figures (10 main text, 1 supplementary materials), 10 tables (4 main text, 6 supplementary materials)",
    "descriptor": "\nComments: 43 pages (35 main text, 8 supplementary materials); 11 figures (10 main text, 1 supplementary materials), 10 tables (4 main text, 6 supplementary materials)\n",
    "authors": [
      "Michael J Mahoney",
      "Lucas K Johnson",
      "Abigail Z Guinan",
      "Colin M Beier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2205.05047"
  },
  {
    "id": "arXiv:2205.09991",
    "title": "Planning with Diffusion for Flexible Behavior Synthesis",
    "abstract": "Comments: ICML 2022 (long talk). Project page and code at this https URL",
    "descriptor": "\nComments: ICML 2022 (long talk). Project page and code at this https URL\n",
    "authors": [
      "Michael Janner",
      "Yilun Du",
      "Joshua B. Tenenbaum",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09991"
  },
  {
    "id": "arXiv:2205.10044",
    "title": "Towards biologically plausible Dreaming and Planning in recurrent  spiking networks",
    "abstract": "Towards biologically plausible Dreaming and Planning in recurrent  spiking networks",
    "descriptor": "",
    "authors": [
      "Cristiano Capone",
      "Pier Stanislao Paolucci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2205.10044"
  },
  {
    "id": "arXiv:2205.10083",
    "title": "A Unified Experiment Design Approach for Cyclic and Acyclic Causal  Models",
    "abstract": "Comments: 30 pages, 6 figures, 1 table",
    "descriptor": "\nComments: 30 pages, 6 figures, 1 table\n",
    "authors": [
      "Ehsan Mokhtarian",
      "Saber Salehkaleybar",
      "AmirEmad Ghassami",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.10083"
  },
  {
    "id": "arXiv:2205.11127",
    "title": "Fairness in Recommender Systems: Research Landscape and Future  Directions",
    "abstract": "Fairness in Recommender Systems: Research Landscape and Future  Directions",
    "descriptor": "",
    "authors": [
      "Yashar Deldjoo",
      "Dietmar Jannach",
      "Alejandro Bellogin",
      "Alessandro Difonzo",
      "Dario Zanzonelli"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11127"
  },
  {
    "id": "arXiv:2205.12680",
    "title": "Optimizing Test-Time Query Representations for Dense Retrieval",
    "abstract": "Comments: 15 pages, 5 figures",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Mujeen Sung",
      "Jungsoo Park",
      "Jaewoo Kang",
      "Danqi Chen",
      "Jinhyuk Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.12680"
  },
  {
    "id": "arXiv:2205.14545",
    "title": "Functional Linear Regression of Cumulative Distribution Functions",
    "abstract": "Comments: 62 pages, 2 figures",
    "descriptor": "\nComments: 62 pages, 2 figures\n",
    "authors": [
      "Qian Zhang",
      "Anuran Makur",
      "Kamyar Azizzadenesheli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.14545"
  },
  {
    "id": "arXiv:2205.14550",
    "title": "Machine Learning for Microcontroller-Class Hardware: A Review",
    "abstract": "Comments: Published in IEEE Sensors Journal. Cite this as: S. S. Saha, S. S. Sandha and M. Srivastava, \"Machine Learning for Microcontroller-Class Hardware: A Review,\" in IEEE Sensors Journal, vol. 22, no. 22, pp. 21362-21390, 15 Nov., 2022",
    "descriptor": "\nComments: Published in IEEE Sensors Journal. Cite this as: S. S. Saha, S. S. Sandha and M. Srivastava, \"Machine Learning for Microcontroller-Class Hardware: A Review,\" in IEEE Sensors Journal, vol. 22, no. 22, pp. 21362-21390, 15 Nov., 2022\n",
    "authors": [
      "Swapnil Sayan Saha",
      "Sandeep Singh Sandha",
      "Mani Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14550"
  },
  {
    "id": "arXiv:2206.00026",
    "title": "Network Cards: concise, readable summaries of network data",
    "abstract": "Comments: 16 pages, 6 tables",
    "descriptor": "\nComments: 16 pages, 6 tables\n",
    "authors": [
      "James Bagrow",
      "Yong-Yeol Ahn"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.00026"
  },
  {
    "id": "arXiv:2206.03375",
    "title": "Walking on Vertices and Edges by Continuous-Time Quantum Walk",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Caue F. T. Silva",
      "Daniel Posner",
      "Renato Portugal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.03375"
  },
  {
    "id": "arXiv:2206.05575",
    "title": "MammoDL: Mammographic Breast Density Estimation using Federated Learning",
    "abstract": "Comments: Breast Cancer Risk, Digital Mammography, Breast Density, Deep Learning, Machine Learning, Federated Learning, OpenFL",
    "descriptor": "\nComments: Breast Cancer Risk, Digital Mammography, Breast Density, Deep Learning, Machine Learning, Federated Learning, OpenFL\n",
    "authors": [
      "Ramya Muthukrishnan",
      "Angelina Heyler",
      "Keshava Katti",
      "Sarthak Pati",
      "Walter Mankowski",
      "Aprupa Alahari",
      "Michael Sanborn",
      "Emily F. Conant",
      "Christopher Scott",
      "Stacey Winham",
      "Celine Vachon",
      "Pratik Chaudhari",
      "Despina Kontos",
      "Spyridon Bakas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05575"
  },
  {
    "id": "arXiv:2206.07326",
    "title": "Recent Advances in Scene Image Representation and Classification",
    "abstract": "Comments: This paper is under review in Multimedia Tools and Applications (Springer) journal. This article may be deleted or updated based on the policies of the journal",
    "descriptor": "\nComments: This paper is under review in Multimedia Tools and Applications (Springer) journal. This article may be deleted or updated based on the policies of the journal\n",
    "authors": [
      "Chiranjibi Sitaula",
      "Tej Bahadur Shahi",
      "Faezeh Marzbanrad",
      "Jagannath Aryal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.07326"
  },
  {
    "id": "arXiv:2206.08996",
    "title": "Towards Consensus: Reducing Polarization by Perturbing Social Networks",
    "abstract": "Comments: 29 pages, 12 figures",
    "descriptor": "\nComments: 29 pages, 12 figures\n",
    "authors": [
      "Miklos Z. Racz",
      "Daniel E. Rigobon"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.08996"
  },
  {
    "id": "arXiv:2206.11350",
    "title": "Vision- and tactile-based continuous multimodal intention and attention  recognition for safer physical human-robot interaction",
    "abstract": "Comments: 11 pages, 8 figures, preprint under review",
    "descriptor": "\nComments: 11 pages, 8 figures, preprint under review\n",
    "authors": [
      "Christopher Yee Wong",
      "Lucas Vergez",
      "Wael Suleiman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.11350"
  },
  {
    "id": "arXiv:2206.12558",
    "title": "FastBVP-Net: a lightweight pulse extraction network for measuring heart  rhythm via facial videos",
    "abstract": "Comments: 9 pages, 2figures",
    "descriptor": "\nComments: 9 pages, 2figures\n",
    "authors": [
      "Jialiang Zhuang",
      "Yuheng Chen",
      "Yun Zhang",
      "Xiujuan Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12558"
  },
  {
    "id": "arXiv:2207.00611",
    "title": "FAIR principles for AI models with a practical application for  accelerated high energy diffraction microscopy",
    "abstract": "Comments: 11 pages, 3 figures; Accepted to Scientific Data; for press release see this https URL and this https URL; Received 2022 HPCwire Readers' Choice Award on Best Use of High Performance Data Analytics & Artificial Intelligence",
    "descriptor": "\nComments: 11 pages, 3 figures; Accepted to Scientific Data; for press release see this https URL and this https URL; Received 2022 HPCwire Readers' Choice Award on Best Use of High Performance Data Analytics & Artificial Intelligence\n",
    "authors": [
      "Nikil Ravi",
      "Pranshu Chaturvedi",
      "E. A. Huerta",
      "Zhengchun Liu",
      "Ryan Chard",
      "Aristana Scourtas",
      "K.J. Schmidt",
      "Kyle Chard",
      "Ben Blaiszik",
      "Ian Foster"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.00611"
  },
  {
    "id": "arXiv:2207.04690",
    "title": "Dynamic Budget Throttling in Repeated Second-Price Auctions",
    "abstract": "Comments: 44 pages, 1 figure, 1 table",
    "descriptor": "\nComments: 44 pages, 1 figure, 1 table\n",
    "authors": [
      "Zhaohua Chen",
      "Chang Wang",
      "Qian Wang",
      "Yuqi Pan",
      "Zhuming Shi",
      "Zheng Cai",
      "Yukun Ren",
      "Zhihua Zhu",
      "Xiaotie Deng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2207.04690"
  },
  {
    "id": "arXiv:2207.07704",
    "title": "Maximizing Fair Content Spread via Edge Suggestion in Social Networks",
    "abstract": "Comments: 16 pages, 17 figures, 8 tables. VLDB '22. Technical Report",
    "descriptor": "\nComments: 16 pages, 17 figures, 8 tables. VLDB '22. Technical Report\n",
    "authors": [
      "Ian P. Swift",
      "Sana Ebrahimi",
      "Azade Nova",
      "Abolfazl Asudeh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.07704"
  },
  {
    "id": "arXiv:2207.08143",
    "title": "Can large language models reason about medical questions?",
    "abstract": "Comments: 33 pages, 6 figures, to be submitted",
    "descriptor": "\nComments: 33 pages, 6 figures, to be submitted\n",
    "authors": [
      "Valentin Li\u00e9vin",
      "Christoffer Egeberg Hother",
      "Ole Winther"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.08143"
  },
  {
    "id": "arXiv:2207.08412",
    "title": "Multi-branch Cascaded Swin Transformers with Attention to k-space  Sampling Pattern for Accelerated MRI Reconstruction",
    "abstract": "Multi-branch Cascaded Swin Transformers with Attention to k-space  Sampling Pattern for Accelerated MRI Reconstruction",
    "descriptor": "",
    "authors": [
      "Mevan Ekanayake",
      "Kamlesh Pawar",
      "Mehrtash Harandi",
      "Gary Egan",
      "Zhaolin Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.08412"
  },
  {
    "id": "arXiv:2207.09371",
    "title": "Polynomial Threshold Functions for Decision Lists",
    "abstract": "Comments: 14 pages in total (11 for article + 3 for references and appendix)",
    "descriptor": "\nComments: 14 pages in total (11 for article + 3 for references and appendix)\n",
    "authors": [
      "Vladimir Podolskii",
      "Nikolay V. Proskurin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2207.09371"
  },
  {
    "id": "arXiv:2207.13492",
    "title": "Time to augment self-supervised visual representation learning",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Arthur Aubret",
      "Markus Ernst",
      "C\u00e9line Teuli\u00e8re",
      "Jochen Triesch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.13492"
  },
  {
    "id": "arXiv:2207.13552",
    "title": "iCub Knows Where You Look: Exploiting Social Cues for Interactive Object  Detection Learning",
    "abstract": "iCub Knows Where You Look: Exploiting Social Cues for Interactive Object  Detection Learning",
    "descriptor": "",
    "authors": [
      "Maria Lombardi",
      "Elisa Maiettini",
      "Vadim Tikhanoff",
      "Lorenzo Natale"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.13552"
  },
  {
    "id": "arXiv:2208.01489",
    "title": "Deconstructing Self-Supervised Monocular Reconstruction: The Design  Decisions that Matter",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Jaime Spencer",
      "Chris Russell",
      "Simon Hadfield",
      "Richard Bowden"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.01489"
  },
  {
    "id": "arXiv:2208.06216",
    "title": "Is Your Model Sensitive? SPeDaC: A New Benchmark for Detecting and  Classifying Sensitive Personal Data",
    "abstract": "Comments: 25 pages, 4 figures, 12 tables",
    "descriptor": "\nComments: 25 pages, 4 figures, 12 tables\n",
    "authors": [
      "Gaia Gambarelli",
      "Aldo Gangemi",
      "Rocco Tripodi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.06216"
  },
  {
    "id": "arXiv:2208.07148",
    "title": "Reduced Connectivity for Local Bilinear Jacobi Sets",
    "abstract": "Comments: IEEE Workshop on Topological Data Analysis and Visualization in conjunction with IEEE VIS 2022. ACM 2012 CCS - Human-centered computing, Visualization, Visualization techniques; Mathematics of computing, Discrete mathematics",
    "descriptor": "\nComments: IEEE Workshop on Topological Data Analysis and Visualization in conjunction with IEEE VIS 2022. ACM 2012 CCS - Human-centered computing, Visualization, Visualization techniques; Mathematics of computing, Discrete mathematics\n",
    "authors": [
      "Daniel Kl\u00f6tzl",
      "Tim Krake",
      "Youjia Zhou",
      "Jonathan Stober",
      "Kathrin Schulte",
      "Ingrid Hotz",
      "Bei Wang",
      "Daniel Weiskopf"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.07148"
  },
  {
    "id": "arXiv:2208.09449",
    "title": "A Novel Plug-and-Play Approach for Adversarially Robust Generalization",
    "abstract": "A Novel Plug-and-Play Approach for Adversarially Robust Generalization",
    "descriptor": "",
    "authors": [
      "Deepak Maurya",
      "Adarsh Barik",
      "Jean Honorio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09449"
  },
  {
    "id": "arXiv:2208.11553",
    "title": "Improving video retrieval using multilingual knowledge transfer",
    "abstract": "Improving video retrieval using multilingual knowledge transfer",
    "descriptor": "",
    "authors": [
      "Avinash Madasu",
      "Estelle Aflalo",
      "Gabriela Ben Melech Stan",
      "Shao-Yen Tseng",
      "Gedas Bertasius",
      "Vasudev Lal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.11553"
  },
  {
    "id": "arXiv:2208.11821",
    "title": "Refine and Represent: Region-to-Object Representation Learning",
    "abstract": "Refine and Represent: Region-to-Object Representation Learning",
    "descriptor": "",
    "authors": [
      "Akash Gokul",
      "Konstantinos Kallidromitis",
      "Shufan Li",
      "Yusuke Kato",
      "Kazuki Kozuka",
      "Trevor Darrell",
      "Colorado J Reed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.11821"
  },
  {
    "id": "arXiv:2208.12650",
    "title": "Empowering First-Year Computer Science Ph.D. Students to Create a  Culture that Values Community and Mental Health",
    "abstract": "Comments: Accepted at SIGCSE 2023",
    "descriptor": "\nComments: Accepted at SIGCSE 2023\n",
    "authors": [
      "Yaniv Yacoby",
      "John Girash",
      "David C. Parkes"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.12650"
  },
  {
    "id": "arXiv:2209.00731",
    "title": "In conversation with Artificial Intelligence: aligning language models  with human values",
    "abstract": "Comments: Accepted for publication with minor revisions at Philosophy & Technology",
    "descriptor": "\nComments: Accepted for publication with minor revisions at Philosophy & Technology\n",
    "authors": [
      "Atoosa Kasirzadeh",
      "Iason Gabriel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.00731"
  },
  {
    "id": "arXiv:2209.05476",
    "title": "Riccati-feedback Control of a Two-dimensional Two-phase Stefan Problem",
    "abstract": "Riccati-feedback Control of a Two-dimensional Two-phase Stefan Problem",
    "descriptor": "",
    "authors": [
      "Bj\u00f6rn Baran",
      "Peter Benner",
      "Jens Saak"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.05476"
  },
  {
    "id": "arXiv:2209.07413",
    "title": "EZNAS: Evolving Zero Cost Proxies For Neural Architecture Scoring",
    "abstract": "EZNAS: Evolving Zero Cost Proxies For Neural Architecture Scoring",
    "descriptor": "",
    "authors": [
      "Yash Akhauri",
      "J. Pablo Munoz",
      "Nilesh Jain",
      "Ravi Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.07413"
  },
  {
    "id": "arXiv:2209.09400",
    "title": "Polynomial-Time Reachability for LTI Systems with Two-Level Lattice  Neural Network Controllers",
    "abstract": "Polynomial-Time Reachability for LTI Systems with Two-Level Lattice  Neural Network Controllers",
    "descriptor": "",
    "authors": [
      "James Ferlez",
      "Yasser Shoukry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.09400"
  },
  {
    "id": "arXiv:2209.14694",
    "title": "GROOT: Corrective Reward Optimization for Generative Sequential Labeling",
    "abstract": "GROOT: Corrective Reward Optimization for Generative Sequential Labeling",
    "descriptor": "",
    "authors": [
      "Kazuma Hashimoto",
      "Karthik Raman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.14694"
  },
  {
    "id": "arXiv:2210.01549",
    "title": "Diffusion Models for Graphs Benefit From Discrete State Spaces",
    "abstract": "Comments: Presented at the First Learning on Graphs Conference (LoG 2022) and the NeurIPS 2022 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2022)",
    "descriptor": "\nComments: Presented at the First Learning on Graphs Conference (LoG 2022) and the NeurIPS 2022 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2022)\n",
    "authors": [
      "Kilian Konstantin Haefeli",
      "Karolis Martinkus",
      "Nathana\u00ebl Perraudin",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.01549"
  },
  {
    "id": "arXiv:2210.01954",
    "title": "Rectangular Ruler Wrapping",
    "abstract": "Rectangular Ruler Wrapping",
    "descriptor": "",
    "authors": [
      "Xing Lyu",
      "Travis Gagie",
      "Meng He"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.01954"
  },
  {
    "id": "arXiv:2210.02541",
    "title": "Inserting or Stretching Points in Finite Difference Discretizations",
    "abstract": "Inserting or Stretching Points in Finite Difference Discretizations",
    "descriptor": "",
    "authors": [
      "Jherek Healy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Finance (q-fin.CP)",
      "Pricing of Securities (q-fin.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.02541"
  },
  {
    "id": "arXiv:2210.02997",
    "title": "Expander Graph Propagation",
    "abstract": "Comments: Presented at LoG 2022. Best Paper Award at the NeurIPS 2022 Workshop on New Frontiers in Graph Learning (GLFrontiers). 18 pages, 1 figure",
    "descriptor": "\nComments: Presented at LoG 2022. Best Paper Award at the NeurIPS 2022 Workshop on New Frontiers in Graph Learning (GLFrontiers). 18 pages, 1 figure\n",
    "authors": [
      "Andreea Deac",
      "Marc Lackenby",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Combinatorics (math.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02997"
  },
  {
    "id": "arXiv:2210.03886",
    "title": "Locality and stability for phase retrieval",
    "abstract": "Comments: Added some additional comments and references",
    "descriptor": "\nComments: Added some additional comments and references\n",
    "authors": [
      "Wedad Alharbi",
      "Salah Alshabhi",
      "Daniel Freeman",
      "Dorsa Ghoreishi"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03886"
  },
  {
    "id": "arXiv:2210.04561",
    "title": "A Comprehensive Survey of Data Augmentation in Visual Reinforcement  Learning",
    "abstract": "Comments: A well-classified paper list that will be continuously updated can be found at this https URL",
    "descriptor": "\nComments: A well-classified paper list that will be continuously updated can be found at this https URL\n",
    "authors": [
      "Guozheng Ma",
      "Zhen Wang",
      "Zhecheng Yuan",
      "Xueqian Wang",
      "Bo Yuan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04561"
  },
  {
    "id": "arXiv:2210.05593",
    "title": "Prototypical VoteNet for Few-Shot 3D Point Cloud Object Detection",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Shizhen Zhao",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05593"
  },
  {
    "id": "arXiv:2210.08723",
    "title": "Private Data Valuation and Fair Payment in Data Marketplaces",
    "abstract": "Private Data Valuation and Fair Payment in Data Marketplaces",
    "descriptor": "",
    "authors": [
      "Zhihua Tian",
      "Jian Liu",
      "Jingyu Li",
      "Xinle Cao",
      "Ruoxi Jia",
      "Kui Ren"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08723"
  },
  {
    "id": "arXiv:2210.09006",
    "title": "Fourier theoretic inequalities for inclusion of simple C*-algebras",
    "abstract": "Comments: 29 pages, 2 figures, few references added",
    "descriptor": "\nComments: 29 pages, 2 figures, few references added\n",
    "authors": [
      "Keshab Chandra Bakshi",
      "Satyajit Guin",
      "Sruthymurali"
    ],
    "subjectives": [
      "Operator Algebras (math.OA)",
      "Information Theory (cs.IT)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2210.09006"
  },
  {
    "id": "arXiv:2210.10555",
    "title": "Data-Augmented Counterfactual Learning for Bundle Recommendation",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Shixuan Zhu",
      "Qi Shen",
      "Yiming Zhang",
      "Zhenwei Dong",
      "Zhihua Wei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.10555"
  },
  {
    "id": "arXiv:2210.12388",
    "title": "Diversity-Promoting Ensemble for Medical Image Segmentation",
    "abstract": "Comments: Accepted at SAC 2023",
    "descriptor": "\nComments: Accepted at SAC 2023\n",
    "authors": [
      "Mariana-Iuliana Georgescu",
      "Radu Tudor Ionescu",
      "Andreea-Iuliana Miron"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12388"
  },
  {
    "id": "arXiv:2210.13047",
    "title": "EXK-SC: A Semantic Communication Model Based on Information Framework  Expansion and Knowledge Collision",
    "abstract": "EXK-SC: A Semantic Communication Model Based on Information Framework  Expansion and Knowledge Collision",
    "descriptor": "",
    "authors": [
      "Gangtao Xin",
      "Pingyi Fan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Science and Game Theory (cs.GT)",
      "Signal Processing (eess.SP)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.13047"
  },
  {
    "id": "arXiv:2210.13848",
    "title": "Connectivity-Aware Contract for Incentivizing IoT Devices in Complex  Wireless Blockchain",
    "abstract": "Connectivity-Aware Contract for Incentivizing IoT Devices in Complex  Wireless Blockchain",
    "descriptor": "",
    "authors": [
      "Weiyi Wang",
      "Jin Chen",
      "Yutao Jiao",
      "Jiawen Kang",
      "Wenting Dai",
      "Yuhua Xu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.13848"
  },
  {
    "id": "arXiv:2210.15663",
    "title": "Deep Generative Models on 3D Representations: A Survey",
    "abstract": "Comments: Github: this https URL",
    "descriptor": "\nComments: Github: this https URL\n",
    "authors": [
      "Zifan Shi",
      "Sida Peng",
      "Yinghao Xu",
      "Yiyi Liao",
      "Yujun Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15663"
  },
  {
    "id": "arXiv:2210.16053",
    "title": "Automated analysis of diabetic retinopathy using vessel segmentation  maps as inductive bias",
    "abstract": "Comments: Submission for MICCAI 2022 Diabetic Retinopathy Analysis Challenge (DRAC) Proceedings, DOI: 10.5281/zenodo.6362349",
    "descriptor": "\nComments: Submission for MICCAI 2022 Diabetic Retinopathy Analysis Challenge (DRAC) Proceedings, DOI: 10.5281/zenodo.6362349\n",
    "authors": [
      "Linus Kreitner",
      "Ivan Ezhov",
      "Daniel Rueckert",
      "Johannes C. Paetzold",
      "Martin J. Menten"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16053"
  },
  {
    "id": "arXiv:2210.16269",
    "title": "ATM: Black-box Test Case Minimization based on Test Code Similarity and  Evolutionary Search",
    "abstract": "Comments: Accepted at the 45th IEEE/ACM International Conference on Software Engineering",
    "descriptor": "\nComments: Accepted at the 45th IEEE/ACM International Conference on Software Engineering\n",
    "authors": [
      "Rongqi Pan",
      "Taher A. Ghaleb",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.16269"
  },
  {
    "id": "arXiv:2211.03040",
    "title": "Modelling of a DC-DC Buck Converter Using Long-Short-Term-Memory (LSTM)",
    "abstract": "Comments: invalid results",
    "descriptor": "\nComments: invalid results\n",
    "authors": [
      "Muhy Eddin Za'ter"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.03040"
  },
  {
    "id": "arXiv:2211.03232",
    "title": "Exponentially Improving the Complexity of Simulating the  Weisfeiler-Lehman Test with Graph Neural Networks",
    "abstract": "Comments: 22 pages,5 figures, published at NeurIPS 2022. Updated funding statements",
    "descriptor": "\nComments: 22 pages,5 figures, published at NeurIPS 2022. Updated funding statements\n",
    "authors": [
      "Anders Aamand",
      "Justin Y. Chen",
      "Piotr Indyk",
      "Shyam Narayanan",
      "Ronitt Rubinfeld",
      "Nicholas Schiefer",
      "Sandeep Silwal",
      "Tal Wagner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.03232"
  },
  {
    "id": "arXiv:2211.05719",
    "title": "MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal  Open-domain Conversation",
    "abstract": "MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal  Open-domain Conversation",
    "descriptor": "",
    "authors": [
      "Jiazhan Feng",
      "Qingfeng Sun",
      "Can Xu",
      "Pu Zhao",
      "Yaming Yang",
      "Chongyang Tao",
      "Dongyan Zhao",
      "Qingwei Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.05719"
  },
  {
    "id": "arXiv:2211.08036",
    "title": "Provably Reliable Large-Scale Sampling from Gaussian Processes",
    "abstract": "Comments: Main article 4 pages + 14 pages of supplementary material. To be published in NeurIPS 2022 Proceedings Workshop on \"Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems\"",
    "descriptor": "\nComments: Main article 4 pages + 14 pages of supplementary material. To be published in NeurIPS 2022 Proceedings Workshop on \"Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems\"\n",
    "authors": [
      "Anthony Stephenson",
      "Robert Allison",
      "Edward Pyzer-Knapp"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.08036"
  },
  {
    "id": "arXiv:2211.09639",
    "title": "Why Deep Learning Generalizes",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Benjamin L. Badger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09639"
  },
  {
    "id": "arXiv:2211.14703",
    "title": "Exploring Consistency in Cross-Domain Transformer for Domain Adaptive  Semantic Segmentation",
    "abstract": "Exploring Consistency in Cross-Domain Transformer for Domain Adaptive  Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Kaihong Wang",
      "Donghyun Kim",
      "Rogerio Feris",
      "Kate Saenko",
      "Margrit Betke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14703"
  },
  {
    "id": "arXiv:2211.16006",
    "title": "Lie Group Forced Variational Integrator Networks for Learning and  Control of Robot Systems",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Valentin Duruisseaux",
      "Thai Duong",
      "Melvin Leok",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.16006"
  },
  {
    "id": "arXiv:2212.00442",
    "title": "MGTANet: Encoding Sequential LiDAR Points Using Long Short-Term  Motion-Guided Temporal Attention for 3D Object Detection",
    "abstract": "Comments: Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI'23)",
    "descriptor": "\nComments: Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI'23)\n",
    "authors": [
      "Junho Koh",
      "Junhyung Lee",
      "Youngwoo Lee",
      "Jaekyum Kim",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00442"
  },
  {
    "id": "arXiv:2212.02327",
    "title": "Space-efficient conversions from SLPs",
    "abstract": "Space-efficient conversions from SLPs",
    "descriptor": "",
    "authors": [
      "Travis Gagie",
      "Artur Je\u017c",
      "Gonzalo Navarro"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.02327"
  },
  {
    "id": "arXiv:2212.02421",
    "title": "Score-based denoising for atomic structure identification",
    "abstract": "Score-based denoising for atomic structure identification",
    "descriptor": "",
    "authors": [
      "Tim Hsu",
      "Babak Sadigh",
      "Nicolas Bertin",
      "Cheol Woo Park",
      "James Chapman",
      "Vasily Bulatov",
      "Fei Zhou"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Atomic Physics (physics.atom-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.02421"
  },
  {
    "id": "arXiv:2212.02653",
    "title": "Finite model theory for pseudovarieties and universal algebra:  preservation, definability and complexity",
    "abstract": "Finite model theory for pseudovarieties and universal algebra:  preservation, definability and complexity",
    "descriptor": "",
    "authors": [
      "Lucy Ham",
      "Marcel Jackson"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.02653"
  },
  {
    "id": "arXiv:2212.02804",
    "title": "MUS-CDB: Mixed Uncertainty Sampling with Class Distribution Balancing  for Active Annotation in Aerial Object Detection",
    "abstract": "Comments: 13 pages, 7 figures",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Dong Liang",
      "Jing-Wei Zhang",
      "Ying-Peng Tang",
      "Sheng-Jun Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02804"
  },
  {
    "id": "arXiv:2212.03284",
    "title": "Type Theories with Universe Level Judgements",
    "abstract": "Comments: This paper was presented at Types'2022 and has been submitted to its postconference proceedings",
    "descriptor": "\nComments: This paper was presented at Types'2022 and has been submitted to its postconference proceedings\n",
    "authors": [
      "Marc Bezem",
      "Thierry Coquand",
      "Peter Dybjer",
      "Mart\u00edn Escard\u00f3"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.03284"
  },
  {
    "id": "arXiv:2212.05035",
    "title": "COVID-19 Activity Risk Calculator as a Gamified Public Health  Intervention Tool",
    "abstract": "Comments: 11 pages, 6 figures (main paper + 1 figure supplementary section.)",
    "descriptor": "\nComments: 11 pages, 6 figures (main paper + 1 figure supplementary section.)\n",
    "authors": [
      "Shreyasvi Natraj",
      "Malhar Bhide",
      "Nathan Yap",
      "Meng Liu",
      "Agrima Seth",
      "Christin Glorioso"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.05035"
  },
  {
    "id": "arXiv:2212.05081",
    "title": "FAIR AI Models in High Energy Physics",
    "abstract": "Comments: 32 pages, 8 figures, 9 tables",
    "descriptor": "\nComments: 32 pages, 8 figures, 9 tables\n",
    "authors": [
      "Javier Duarte",
      "Haoyang Li",
      "Avik Roy",
      "Ruike Zhu",
      "E. A. Huerta",
      "Daniel Diaz",
      "Philip Harris",
      "Raghav Kansal",
      "Daniel S. Katz",
      "Ishaan H. Kavoori",
      "Volodymyr V. Kindratenko",
      "Farouk Mokhtar",
      "Mark S. Neubauer",
      "Sang Eon Park",
      "Melissa Quinnan",
      "Roger Rusack",
      "Zhizhen Zhao"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.05081"
  },
  {
    "id": "arXiv:2212.05154",
    "title": "Optimal Control for Quadruped Locomotion using LTV MPC",
    "abstract": "Optimal Control for Quadruped Locomotion using LTV MPC",
    "descriptor": "",
    "authors": [
      "Andrew Zheng",
      "Sriram S.K.S Narayanan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.05154"
  },
  {
    "id": "arXiv:2212.05581",
    "title": "Efficient Relation-aware Neighborhood Aggregation in Graph Neural  Networks via Tensor Decomposition",
    "abstract": "Comments: 11 pages, 4 Tables, 2 figures",
    "descriptor": "\nComments: 11 pages, 4 Tables, 2 figures\n",
    "authors": [
      "Peyman Baghershahi",
      "Reshad Hosseini",
      "Hadi Moradi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.05581"
  },
  {
    "id": "arXiv:2212.05767",
    "title": "Reasoning over Different Types of Knowledge Graphs: Static, Temporal and  Multi-Modal",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ke Liang",
      "Lingyuan Meng",
      "Meng Liu",
      "Yue Liu",
      "Wenxuan Tu",
      "Siwei Wang",
      "Sihang Zhou",
      "Xinwang Liu",
      "Fuchun Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.05767"
  },
  {
    "id": "arXiv:2212.06925",
    "title": "On the Relationship Between Explanation and Prediction: A Causal View",
    "abstract": "On the Relationship Between Explanation and Prediction: A Causal View",
    "descriptor": "",
    "authors": [
      "Amir-Hossein Karimi",
      "Krikamol Muandet",
      "Simon Kornblith",
      "Bernhard Sch\u00f6lkopf",
      "Been Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.06925"
  },
  {
    "id": "arXiv:2212.06951",
    "title": "AI Ethics on Blockchain: Topic Analysis on Twitter Data for Blockchain  Security",
    "abstract": "AI Ethics on Blockchain: Topic Analysis on Twitter Data for Blockchain  Security",
    "descriptor": "",
    "authors": [
      "Yihang Fu",
      "Zesen Zhuang",
      "Luyao Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2212.06951"
  },
  {
    "id": "arXiv:2212.06994",
    "title": "Parameterizing Network Graph Heterogeneity using a Modified Weibull  Distribution",
    "abstract": "Parameterizing Network Graph Heterogeneity using a Modified Weibull  Distribution",
    "descriptor": "",
    "authors": [
      "Sinan A. Ozbay",
      "Maximilian M. Nguyen"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.06994"
  },
  {
    "id": "arXiv:2212.06995",
    "title": "Bifurcations in the Herd Immunity Threshold for Discrete-Time Models of  Epidemic Spread",
    "abstract": "Bifurcations in the Herd Immunity Threshold for Discrete-Time Models of  Epidemic Spread",
    "descriptor": "",
    "authors": [
      "Sinan A. Ozbay",
      "Bjarke F. Nielsen",
      "Maximilian M. Nguyen"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.06995"
  },
  {
    "id": "arXiv:2212.07072",
    "title": "SMSMix: Sense-Maintained Sentence Mixup for Word Sense Disambiguation",
    "abstract": "Comments: EMNLP2022",
    "descriptor": "\nComments: EMNLP2022\n",
    "authors": [
      "Hee Suk Yoon",
      "Eunseop Yoon",
      "John Harvill",
      "Sunjae Yoon",
      "Mark Hasegawa-Johnson",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.07072"
  },
  {
    "id": "arXiv:2212.07368",
    "title": "Reconstruction of Multivariate Sparse Signals from Mismatched Samples",
    "abstract": "Comments: There is an error in the use of Corollary 1 in our Paper, which does not apply in our case",
    "descriptor": "\nComments: There is an error in the use of Corollary 1 in our Paper, which does not apply in our case\n",
    "authors": [
      "Taulant Koka",
      "Michael Muma",
      "Benjam\u00edn B\u00e9jar Haro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.07368"
  },
  {
    "id": "arXiv:2212.07428",
    "title": "Towards Linguistically Informed Multi-Objective Pre-Training for Natural  Language Inference",
    "abstract": "Towards Linguistically Informed Multi-Objective Pre-Training for Natural  Language Inference",
    "descriptor": "",
    "authors": [
      "Maren Pielka",
      "Svetlana Schmidt",
      "Lisa Pucknat",
      "Rafet Sifa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.07428"
  },
  {
    "id": "arXiv:2212.07944",
    "title": "Variable Clustering via Distributionally Robust Nodewise Regression",
    "abstract": "Comments: 34 pages",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Kaizheng Wang",
      "Xiao Xu",
      "Xun Yu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Computational Finance (q-fin.CP)",
      "Portfolio Management (q-fin.PM)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2212.07944"
  },
  {
    "id": "arXiv:2212.07998",
    "title": "Rollout Algorithms and Approximate Dynamic Programming for Bayesian  Optimization and Sequential Estimation",
    "abstract": "Rollout Algorithms and Approximate Dynamic Programming for Bayesian  Optimization and Sequential Estimation",
    "descriptor": "",
    "authors": [
      "Dimitri Bertsekas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.07998"
  },
  {
    "id": "arXiv:2212.08397",
    "title": "Criticality of $\\text{AC}^0$ formulae",
    "abstract": "Criticality of $\\text{AC}^0$ formulae",
    "descriptor": "",
    "authors": [
      "Prahladh Harsha",
      "Tulasi mohan Molli",
      "Ashutosh Shankar"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2212.08397"
  },
  {
    "id": "arXiv:2212.08487",
    "title": "Semantics-Empowered Communication: A Tutorial-cum-Survey",
    "abstract": "Comments: Submitted to an IEEE journal. Copyright might be transferred without further notice",
    "descriptor": "\nComments: Submitted to an IEEE journal. Copyright might be transferred without further notice\n",
    "authors": [
      "Zhilin Lu",
      "Rongpeng Li",
      "Kun Lu",
      "Xianfu Chen",
      "Ekram Hossain",
      "Zhifeng Zhao",
      "Honggang Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.08487"
  },
  {
    "id": "arXiv:2212.08664",
    "title": "On the Optimum Scenarios for Single Row Equidistant Facility Layout  Problem",
    "abstract": "On the Optimum Scenarios for Single Row Equidistant Facility Layout  Problem",
    "descriptor": "",
    "authors": [
      "Shrouq Gamal",
      "Ahmed A. Hawam",
      "Ahmed M. El-Kassas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.08664"
  },
  {
    "id": "arXiv:2212.08756",
    "title": "Multi-Scales Data Augmentation Approach In Natural Language Inference  For Artifacts Mitigation And Pre-Trained Model Optimization",
    "abstract": "Multi-Scales Data Augmentation Approach In Natural Language Inference  For Artifacts Mitigation And Pre-Trained Model Optimization",
    "descriptor": "",
    "authors": [
      "Zhenyuan Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.08756"
  },
  {
    "id": "arXiv:2212.09044",
    "title": "Text2Struct: A Machine Learning Pipeline for Mining Structured Data from  Text",
    "abstract": "Text2Struct: A Machine Learning Pipeline for Mining Structured Data from  Text",
    "descriptor": "",
    "authors": [
      "Chaochao Zhou",
      "Bo Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.09044"
  },
  {
    "id": "arXiv:2212.09134",
    "title": "Efficient RDMA Communication Protocols",
    "abstract": "Efficient RDMA Communication Protocols",
    "descriptor": "",
    "authors": [
      "Konstantin Taranov",
      "Fabian Fischer",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.09134"
  },
  {
    "id": "arXiv:2212.09219",
    "title": "Modeling and Performance Analysis of Single-Server Database Over  Quasi-static Rayleigh Fading Channel",
    "abstract": "Modeling and Performance Analysis of Single-Server Database Over  Quasi-static Rayleigh Fading Channel",
    "descriptor": "",
    "authors": [
      "Mengying Chen",
      "Wannian An",
      "Yang Liu",
      "Chen Dong",
      "Xiaodong Xu",
      "Boxiao Han",
      "Ping Zhang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.09219"
  },
  {
    "id": "arXiv:2212.09247",
    "title": "ColoristaNet for Photorealistic Video Style Transfer",
    "abstract": "Comments: 30 pages, 29 figures",
    "descriptor": "\nComments: 30 pages, 29 figures\n",
    "authors": [
      "Xiaowen Qiu",
      "Ruize Xu",
      "Boan He",
      "Yingtao Zhang",
      "Wenqiang Zhang",
      "Weifeng Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.09247"
  },
  {
    "id": "arXiv:2212.09506",
    "title": "CLIP is Also an Efficient Segmenter: A Text-Driven Approach for Weakly  Supervised Semantic Segmentation",
    "abstract": "Comments: 13 pages, 8 figures",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Yuqi Lin",
      "Minghao Chen",
      "Wenxiao Wang",
      "Boxi Wu",
      "Ke Li",
      "Binbin Lin",
      "Haifeng Liu",
      "Xiaofei He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.09506"
  },
  {
    "id": "arXiv:2212.09567",
    "title": "Answering Complex Logical Queries on Knowledge Graphs via Query  Computation Tree Optimization",
    "abstract": "Comments: Code is available at this https URL",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Yushi Bai",
      "Xin Lv",
      "Juanzi Li",
      "Lei Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.09567"
  },
  {
    "id": "arXiv:2212.10132",
    "title": "Content Adaptive Latents and Decoder for Neural Image Compression",
    "abstract": "Comments: V1 is accepted to ECCV 2022. V2 is the improved version",
    "descriptor": "\nComments: V1 is accepted to ECCV 2022. V2 is the improved version\n",
    "authors": [
      "Guanbo Pan",
      "Guo Lu",
      "Zhihao Hu",
      "Dong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.10132"
  },
  {
    "id": "arXiv:2212.10319",
    "title": "Image quality prediction using synthetic and natural codebooks:  comparative results",
    "abstract": "Comments: 18 pages, 8 figures",
    "descriptor": "\nComments: 18 pages, 8 figures\n",
    "authors": [
      "Maxim Koroteev",
      "Kirill Aistov",
      "Valeriy Berezovskiy",
      "Pavel Frolov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10319"
  },
  {
    "id": "arXiv:2212.10343",
    "title": "Berlin V2X: A Machine Learning Dataset from Multiple Vehicles and Radio  Access Technologies",
    "abstract": "Comments: 5 pages, 6 figures. Submitted to a conference. Dataset available at this https URL",
    "descriptor": "\nComments: 5 pages, 6 figures. Submitted to a conference. Dataset available at this https URL\n",
    "authors": [
      "Rodrigo Hernang\u00f3mez",
      "Philipp Geuer",
      "Alexandros Palaios",
      "Daniel Sch\u00e4ufele",
      "Cara Watermann",
      "Khawla Taleb-Bouhemadi",
      "Mohammad Parvini",
      "Anton Krause",
      "Sanket Partani",
      "Christian Vielhaus",
      "Martin Kasparick",
      "Daniel F. K\u00fclzer",
      "Friedrich Burmeister",
      "S\u0142awomir Sta\u0144czak",
      "Gerhard Fettweis",
      "Hans D. Schotten",
      "Frank H. P. Fitzek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.10343"
  },
  {
    "id": "arXiv:2212.10390",
    "title": "ADAS: A Simple Active-and-Adaptive Baseline for Cross-Domain 3D Semantic  Segmentation",
    "abstract": "ADAS: A Simple Active-and-Adaptive Baseline for Cross-Domain 3D Semantic  Segmentation",
    "descriptor": "",
    "authors": [
      "Ben Fei",
      "Siyuan Huang",
      "Jiakang Yuan",
      "Botian Shi",
      "Bo Zhang",
      "Tao Chen",
      "Min Dou",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.10390"
  },
  {
    "id": "arXiv:2212.10426",
    "title": "Deep Riemannian Networks for EEG Decoding",
    "abstract": "Comments: 26 pages, 15 Figures",
    "descriptor": "\nComments: 26 pages, 15 Figures\n",
    "authors": [
      "Daniel Wilson",
      "Robin Tibor Schirrmeister",
      "Lukas Alexander Wilhelm Gemein",
      "Tonio Ball"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.10426"
  },
  {
    "id": "arXiv:2212.10428",
    "title": "HouseCat6D -- A Large-Scale Multi-Modal Category Level 6D Object Pose  Dataset with Household Objects in Realistic Scenarios",
    "abstract": "HouseCat6D -- A Large-Scale Multi-Modal Category Level 6D Object Pose  Dataset with Household Objects in Realistic Scenarios",
    "descriptor": "",
    "authors": [
      "HyunJun Jung",
      "Shun-Cheng Wu",
      "Patrick Ruhkamp",
      "Hannah Schieber",
      "Pengyuan Wang",
      "Giulia Rizzoli",
      "Hongcheng Zhao",
      "Sven Damian Meier",
      "Daniel Roth",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.10428"
  },
  {
    "id": "arXiv:2212.10432",
    "title": "AlphaSparse: Generating High Performance SpMV Codes Directly from Sparse  Matrices",
    "abstract": "AlphaSparse: Generating High Performance SpMV Codes Directly from Sparse  Matrices",
    "descriptor": "",
    "authors": [
      "Zhen Du",
      "Jiajia Li",
      "Yinshan Wang",
      "Xueqi Li",
      "Guangming Tan",
      "Ninghui Sun"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2212.10432"
  },
  {
    "id": "arXiv:2212.10533",
    "title": "The Risks of Ranking: Revisiting Graphical Perception to Model  Individual Differences in Visualization Performance",
    "abstract": "Comments: 16 pages, 9 figures",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Russell Davis",
      "Xiaoying Pu",
      "Yiren Ding",
      "Brian D. Hall",
      "Karen Bonilla",
      "Mi Feng",
      "Matthew Kay",
      "Lane Harrison"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.10533"
  },
  {
    "id": "arXiv:2212.10559",
    "title": "Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient  Descent as Meta-Optimizers",
    "abstract": "Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient  Descent as Meta-Optimizers",
    "descriptor": "",
    "authors": [
      "Damai Dai",
      "Yutao Sun",
      "Li Dong",
      "Yaru Hao",
      "Zhifang Sui",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.10559"
  }
]
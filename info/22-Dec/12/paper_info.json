[
  {
    "id": "arXiv:2212.04523",
    "title": "Assessing the Capacity of Transformer to Abstract Syntactic  Representations: A Contrastive Analysis Based on Long-distance Agreement",
    "abstract": "The long-distance agreement, evidence for syntactic structure, is\nincreasingly used to assess the syntactic generalization of Neural Language\nModels. Much work has shown that transformers are capable of high accuracy in\nvaried agreement tasks, but the mechanisms by which the models accomplish this\nbehavior are still not well understood. To better understand transformers'\ninternal working, this work contrasts how they handle two superficially similar\nbut theoretically distinct agreement phenomena: subject-verb and object-past\nparticiple agreement in French. Using probing and counterfactual analysis\nmethods, our experiments show that i) the agreement task suffers from several\nconfounders which partially question the conclusions drawn so far and ii)\ntransformers handle subject-verb and object-past participle agreements in a way\nthat is consistent with their modeling in theoretical linguistics.",
    "descriptor": "\nComments: Accepted to TACL 2023\n",
    "authors": [
      "Bingzhi Li",
      "Guillaume Wisniewski",
      "Beno\u00eet Crabb\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.04523"
  },
  {
    "id": "arXiv:2212.04528",
    "title": "Towards Practical Application of Deep Learning in Diagnosis of  Alzheimer's Disease",
    "abstract": "Accurate diagnosis of Alzheimer's disease (AD) is both challenging and time\nconsuming. With a systematic approach for early detection and diagnosis of AD,\nsteps can be taken towards the treatment and prevention of the disease. This\nstudy explores the practical application of deep learning models for diagnosis\nof AD. Due to computational complexity, large training times and limited\navailability of labelled dataset, a 3D full brain CNN (convolutional neural\nnetwork) is not commonly used, and researchers often prefer 2D CNN variants. In\nthis study, full brain 3D version of well-known 2D CNNs were designed, trained\nand tested for diagnosis of various stages of AD. Deep learning approach shows\ngood performance in differentiating various stages of AD for more than 1500\nfull brain volumes. Along with classification, the deep learning model is\ncapable of extracting features which are key in differentiating the various\ncategories. The extracted features align with meaningful anatomical landmarks,\nthat are currently considered important in identification of AD by experts. An\nensemble of all the algorithm was also tested and the performance of the\nensemble algorithm was superior to any individual algorithm, further improving\ndiagnosis ability. The 3D versions of the trained CNNs and their ensemble have\nthe potential to be incorporated in software packages that can be used by\nphysicians/radiologists to assist them in better diagnosis of AD.",
    "descriptor": "\nComments: 18 pages, 8 figures\n",
    "authors": [
      "Harshit Parmar",
      "Eric Walden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.04528"
  },
  {
    "id": "arXiv:2212.04531",
    "title": "ORCa: Glossy Objects as Radiance Field Cameras",
    "abstract": "Reflections on glossy objects contain valuable and hidden information about\nthe surrounding environment. By converting these objects into cameras, we can\nunlock exciting applications, including imaging beyond the camera's\nfield-of-view and from seemingly impossible vantage points, e.g. from\nreflections on the human eye. However, this task is challenging because\nreflections depend jointly on object geometry, material properties, the 3D\nenvironment, and the observer viewing direction. Our approach converts glossy\nobjects with unknown geometry into radiance-field cameras to image the world\nfrom the object's perspective. Our key insight is to convert the object surface\ninto a virtual sensor that captures cast reflections as a 2D projection of the\n5D environment radiance field visible to the object. We show that recovering\nthe environment radiance fields enables depth and radiance estimation from the\nobject to its surroundings in addition to beyond field-of-view novel-view\nsynthesis, i.e. rendering of novel views that are only directly-visible to the\nglossy object present in the scene, but not the observer. Moreover, using the\nradiance field we can image around occluders caused by close-by objects in the\nscene. Our method is trained end-to-end on multi-view images of the object and\njointly estimates object geometry, diffuse radiance, and the 5D environment\nradiance field.",
    "descriptor": "\nComments: for more information, see this https URL\n",
    "authors": [
      "Kushagra Tiwary",
      "Askhat Dave",
      "Nikhil Behari",
      "Tzofi Klinghoffer",
      "Ashok Veeraraghavan",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04531"
  },
  {
    "id": "arXiv:2212.04533",
    "title": "Deep Architectures for Content Moderation and Movie Content Rating",
    "abstract": "Rating a video based on its content is an important step for classifying\nvideo age categories. Movie content rating and TV show rating are the two most\ncommon rating systems established by professional committees. However, manually\nreviewing and evaluating scene/film content by a committee is a tedious work\nand it becomes increasingly difficult with the ever-growing amount of online\nvideo content. As such, a desirable solution is to use computer vision based\nvideo content analysis techniques to automate the evaluation process. In this\npaper, related works are summarized for action recognition, multi-modal\nlearning, movie genre classification, and sensitive content detection in the\ncontext of content moderation and movie content rating. The project page is\navailable at https://github.com/fcakyon/content-moderation-deep-learning}.",
    "descriptor": "",
    "authors": [
      "Fatih Cagatay Akyon",
      "Alptekin Temizel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04533"
  },
  {
    "id": "arXiv:2212.04537",
    "title": "Graph Learning Indexer: A Contributor-Friendly and Metadata-Rich  Platform for Graph Learning Benchmarks",
    "abstract": "Establishing open and general benchmarks has been a critical driving force\nbehind the success of modern machine learning techniques. As machine learning\nis being applied to broader domains and tasks, there is a need to establish\nricher and more diverse benchmarks to better reflect the reality of the\napplication scenarios. Graph learning is an emerging field of machine learning\nthat urgently needs more and better benchmarks. To accommodate the need, we\nintroduce Graph Learning Indexer (GLI), a benchmark curation platform for graph\nlearning. In comparison to existing graph learning benchmark libraries, GLI\nhighlights two novel design objectives. First, GLI is designed to incentivize\n\\emph{dataset contributors}. In particular, we incorporate various measures to\nminimize the effort of contributing and maintaining a dataset, increase the\nusability of the contributed dataset, as well as encourage attributions to\ndifferent contributors of the dataset. Second, GLI is designed to curate a\nknowledge base, instead of a plain collection, of benchmark datasets. We use\nmultiple sources of meta information to augment the benchmark datasets with\n\\emph{rich characteristics}, so that they can be easily selected and used in\ndownstream research or development. The source code of GLI is available at\n\\url{https://github.com/Graph-Learning-Benchmarks/gli}.",
    "descriptor": "\nComments: Oral Presentation at LOG 2022\n",
    "authors": [
      "Jiaqi Ma",
      "Xingjian Zhang",
      "Hezheng Fan",
      "Jin Huang",
      "Tianyue Li",
      "Ting Wei Li",
      "Yiwen Tu",
      "Chenshu Zhu",
      "Qiaozhu Mei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04537"
  },
  {
    "id": "arXiv:2212.04540",
    "title": "TinyKG: Memory-Efficient Training Framework for Knowledge Graph Neural  Recommender Systems",
    "abstract": "There has been an explosion of interest in designing various Knowledge Graph\nNeural Networks (KGNNs), which achieve state-of-the-art performance and provide\ngreat explainability for recommendation. The promising performance is mainly\nresulting from their capability of capturing high-order proximity messages over\nthe knowledge graphs. However, training KGNNs at scale is challenging due to\nthe high memory usage. In the forward pass, the automatic differentiation\nengines (\\textsl{e.g.}, TensorFlow/PyTorch) generally need to cache all\nintermediate activation maps in order to compute gradients in the backward\npass, which leads to a large GPU memory footprint. Existing work solves this\nproblem by utilizing multi-GPU distributed frameworks. Nonetheless, this poses\na practical challenge when seeking to deploy KGNNs in memory-constrained\nenvironments, especially for industry-scale graphs.\nHere we present TinyKG, a memory-efficient GPU-based training framework for\nKGNNs for the tasks of recommendation. Specifically, TinyKG uses exact\nactivations in the forward pass while storing a quantized version of\nactivations in the GPU buffers. During the backward pass, these low-precision\nactivations are dequantized back to full-precision tensors, in order to compute\ngradients. To reduce the quantization errors, TinyKG applies a simple yet\neffective quantization algorithm to compress the activations, which ensures\nunbiasedness with low variance. As such, the training memory footprint of KGNNs\nis largely reduced with negligible accuracy loss. To evaluate the performance\nof our TinyKG, we conduct comprehensive experiments on real-world datasets. We\nfound that our TinyKG with INT2 quantization aggressively reduces the memory\nfootprint of activation maps with $7 \\times$, only with $2\\%$ loss in accuracy,\nallowing us to deploy KGNNs on memory-constrained devices.",
    "descriptor": "",
    "authors": [
      "Huiyuan Chen",
      "Xiaoting Li",
      "Kaixiong Zhou",
      "Xia Hu",
      "Chin-Chia Michael Yeh",
      "Yan Zheng",
      "Hao Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.04540"
  },
  {
    "id": "arXiv:2212.04542",
    "title": "VASR: Visual Analogies of Situation Recognition",
    "abstract": "A core process in human cognition is analogical mapping: the ability to\nidentify a similar relational structure between different situations. We\nintroduce a novel task, Visual Analogies of Situation Recognition, adapting the\nclassical word-analogy task into the visual domain. Given a triplet of images,\nthe task is to select an image candidate B' that completes the analogy (A to A'\nis like B to what?). Unlike previous work on visual analogy that focused on\nsimple image transformations, we tackle complex analogies requiring\nunderstanding of scenes.\nWe leverage situation recognition annotations and the CLIP model to generate\na large set of 500k candidate analogies. Crowdsourced annotations for a sample\nof the data indicate that humans agree with the dataset label ~80% of the time\n(chance level 25%). Furthermore, we use human annotations to create a\ngold-standard dataset of 3,820 validated analogies. Our experiments demonstrate\nthat state-of-the-art models do well when distractors are chosen randomly\n(~86%), but struggle with carefully chosen distractors (~53%, compared to 90%\nhuman accuracy). We hope our dataset will encourage the development of new\nanalogy-making models. Website: https://vasr-dataset.github.io/",
    "descriptor": "\nComments: Accepted to AAAI 2023. Website: this https URL\n",
    "authors": [
      "Yonatan Bitton",
      "Ron Yosef",
      "Eli Strugo",
      "Dafna Shahaf",
      "Roy Schwartz",
      "Gabriel Stanovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.04542"
  },
  {
    "id": "arXiv:2212.04546",
    "title": "A Dependable Hybrid Machine Learning Model for Network Intrusion  Detection",
    "abstract": "Network intrusion detection systems (NIDSs) play an important role in\ncomputer network security. There are several detection mechanisms where\nanomaly-based automated detection outperforms others significantly. Amid the\nsophistication and growing number of attacks, dealing with large amounts of\ndata is a recognized issue in the development of anomaly-based NIDS. However,\ndo current models meet the needs of today's networks in terms of required\naccuracy and dependability? In this research, we propose a new hybrid model\nthat combines machine learning and deep learning to increase detection rates\nwhile securing dependability. Our proposed method ensures efficient\npre-processing by combining SMOTE for data balancing and XGBoost for feature\nselection. We compared our developed method to various machine learning and\ndeep learning algorithms to find a more efficient algorithm to implement in the\npipeline. Furthermore, we chose the most effective model for network intrusion\nbased on a set of benchmarked performance analysis criteria. Our method\nproduces excellent results when tested on two datasets, KDDCUP'99 and\nCIC-MalMem-2022, with an accuracy of 99.99% and 100% for KDDCUP'99 and\nCIC-MalMem-2022, respectively, and no overfitting or Type-1 and Type-2 issues.",
    "descriptor": "\nComments: Accepted in the Journal of Information Security and Applications (Scopus, Web of Science (SCIE) Journal, Quartile: Q1, Site Score: 7.6, Impact Factor: 4.96) on 7 December 2022\n",
    "authors": [
      "Md. Alamin Talukder",
      "Khondokar Fida Hasan",
      "Md. Manowarul Islam",
      "Md Ashraf Uddin",
      "Arnisha Akhter",
      "Mohammand Abu Yousuf",
      "Fares Alharbi",
      "Mohammad Ali Moni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04546"
  },
  {
    "id": "arXiv:2212.04548",
    "title": "STLGRU: Spatio-Temporal Lightweight Graph GRU for Traffic Flow  Prediction",
    "abstract": "Reliable forecasting of traffic flow requires efficient modeling of traffic\ndata. Different correlations and influences arise in a dynamic traffic network,\nmaking modeling a complicated task. Existing literature has proposed many\ndifferent methods to capture the complex underlying spatial-temporal relations\nof traffic networks. However, methods still struggle to capture different local\nand global dependencies of long-range nature. Also, as more and more\nsophisticated methods are being proposed, models are increasingly becoming\nmemory-heavy and, thus, unsuitable for low-powered devices. In this paper, we\nfocus on solving these problems by proposing a novel deep learning framework -\nSTLGRU. Specifically, our proposed STLGRU can effectively capture both local\nand global spatial-temporal relations of a traffic network using\nmemory-augmented attention and gating mechanism. Instead of employing separate\ntemporal and spatial components, we show that our memory module and gated unit\ncan learn the spatial-temporal dependencies successfully, allowing for reduced\nmemory usage with fewer parameters. We extensively experiment on several\nreal-world traffic prediction datasets to show that our model performs better\nthan existing methods while the memory footprint remains lower. Code is\navailable at \\url{https://github.com/Kishor-Bhaumik/STLGRU}.",
    "descriptor": "",
    "authors": [
      "Kishor Kumar Bhaumik",
      "Fahim Faisal Niloy",
      "Saif Mahmud",
      "Simon Woo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04548"
  },
  {
    "id": "arXiv:2212.04549",
    "title": "Optimizing Real-Time Performances for Timed-Loop Racing under F1TENTH",
    "abstract": "Motion planning and control in autonomous car racing are one of the most\nchallenging and safety-critical tasks due to high speed and dynamism. The\nlower-level control nodes are expected to be highly optimized due to resource\nconstraints of onboard embedded processing units, although there are strict\nlatency requirements. Some of these guarantees can be provided at the\napplication level, such as using ROS2's Real-Time executors. However, the\nperformance can be far from satisfactory as many modern control algorithms\n(such as Model Predictive Control) rely on solving complicated online\noptimization problems at each iteration. In this paper, we present a simple yet\neffective multi-threading technique to optimize the throughput of\nonline-control algorithms for resource-constrained autonomous racing platforms.\nWe achieve this by maintaining a systematic pool of worker threads solving the\noptimization problem in parallel which can improve the system performance by\nreducing latency between control input commands. We further demonstrate the\neffectiveness of our method using the Model Predictive Contouring Control\n(MPCC) algorithm running on Nvidia's Xavier AGX platform.",
    "descriptor": "",
    "authors": [
      "Nitish Gupta",
      "Kurt Wilson",
      "Zhishan Guo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.04549"
  },
  {
    "id": "arXiv:2212.04551",
    "title": "Efficient Strategies for Graph Pattern Mining Algorithms on GPUs",
    "abstract": "Graph Pattern Mining (GPM) is an important, rapidly evolving, and computation\ndemanding area. GPM computation relies on subgraph enumeration, which consists\nin extracting subgraphs that match a given property from an input graph.\nGraphics Processing Units (GPUs) have been an effective platform to accelerate\napplications in many areas. However, the irregularity of subgraph enumeration\nmakes it challenging for efficient execution on GPU due to typical uncoalesced\nmemory access, divergence, and load imbalance. Unfortunately, these aspects\nhave not been fully addressed in previous work. Thus, this work proposes novel\nstrategies to design and implement subgraph enumeration efficiently on GPU. We\nsupport a depth-first search style search (DFS-wide) that maximizes memory\nperformance while providing enough parallelism to be exploited by the GPU,\nalong with a warp-centric design that minimizes execution divergence and\nimproves utilization of the computing capabilities. We also propose a low-cost\nload balancing layer to avoid idleness and redistribute work among thread warps\nin a GPU. Our strategies have been deployed in a system named DuMato, which\nprovides a simple programming interface to allow efficient implementation of\nGPM algorithms. Our evaluation has shown that DuMato is often an order of\nmagnitude faster than state-of-the-art GPM systems and can mine larger\nsubgraphs (up to 12 vertices).",
    "descriptor": "\nComments: Accepted for publication on IEEE 34th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD'22)\n",
    "authors": [
      "Samuel Ferraz",
      "Vinicius Dias",
      "Carlos H. C. Teixeira",
      "George Teodoro",
      "Wagner Meira Jr"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.04551"
  },
  {
    "id": "arXiv:2212.04554",
    "title": "Task-Directed Exploration in Continuous POMDPs for Robotic Manipulation  of Articulated Objects",
    "abstract": "Representing and reasoning about uncertainty is crucial for autonomous agents\nacting in partially observable environments with noisy sensors. Partially\nobservable Markov decision processes (POMDPs) serve as a general framework for\nrepresenting problems in which uncertainty is an important factor. Online\nsample-based POMDP methods have emerged as efficient approaches to solving\nlarge POMDPs and have been shown to extend to continuous domains. However,\nthese solutions struggle to find long-horizon plans in problems with\nsignificant uncertainty. Exploration heuristics can help guide planning, but\nmany real-world settings contain significant task-irrelevant uncertainty that\nmight distract from the task objective. In this paper, we propose STRUG, an\nonline POMDP solver capable of handling domains that require long-horizon\nplanning with significant task-relevant and task-irrelevant uncertainty. We\ndemonstrate our solution on several temporally extended versions of toy POMDP\nproblems as well as robotic manipulation of articulated objects using a neural\nperception frontend to construct a distribution of possible models. Our results\nshow that STRUG outperforms the current sample-based online POMDP solvers on\nseveral tasks.",
    "descriptor": "",
    "authors": [
      "Aidan Curtis",
      "Leslie Kaelbling",
      "Siddarth Jain"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.04554"
  },
  {
    "id": "arXiv:2212.04555",
    "title": "Influence of anthropomorphic agent on human empathy through games",
    "abstract": "The social acceptance of AI agents, including intelligent virtual agents and\nphysical robots, is becoming more important for the integration of AI into\nhuman society. Although the agents used in human society share various tasks\nwith humans, their cooperation may frequently reduce the task performance. One\nway to improve the relationship between humans and AI agents is to have humans\nempathize with the agents. By empathizing, humans feel positively and kindly\ntoward agents, which makes it easier to accept them. In this study, we focus on\ntasks in which humans and agents have various interactions together, and we\ninvestigate the properties of agents that significantly influence human empathy\ntoward the agents. To investigate the effects of task content, difficulty, task\ncompletion, and an agent's expression on human empathy, two experiments were\nconducted. The results of the two experiments showed that human empathy toward\nthe agent was difficult to maintain with only task factors, and that the\nagent's expression was able to maintain human empathy. In addition, a higher\ntask difficulty reduced the decrease in human empathy, regardless of task\ncontent. These results demonstrate that an AI agent's properties play an\nimportant role in helping humans accept them.",
    "descriptor": "\nComments: 17 pages, 12 figures, 5 tables, submitted IEEE Access. arXiv admin note: substantial text overlap with arXiv:2206.06128\n",
    "authors": [
      "Takahiro Tsumura",
      "Seiji Yamada"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.04555"
  },
  {
    "id": "arXiv:2212.04560",
    "title": "Data-Driven Flow and Injection Estimation in PMU-Unobservable  Transmission Systems",
    "abstract": "Fast and accurate knowledge of power flows and power injections is needed for\na variety of applications in the electric grid. Phasor measurement units (PMUs)\ncan be used to directly compute them at high speeds; however, a large number of\nPMUs will be needed for computing all the flows and injections. Similarly, if\nthey are calculated from the outputs of a linear state estimator, then their\naccuracy will deteriorate due to the quadratic relationship between voltage and\npower. This paper employs machine learning to perform fast and accurate flow\nand injection estimation in power systems that are sparsely observed by PMUs.\nWe train a deep neural network (DNN) to learn the mapping function between PMU\nmeasurements and power flows/injections. The relation between power flows and\ninjections is incorporated into the DNN by adding a linear constraint to its\nloss function. The results obtained using the IEEE 118-bus system indicate that\nthe proposed approach performs more accurate flow/injection estimation in\nseverely unobservable power systems compared to other data-driven methods.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Satyaprajna Sahoo",
      "Anwarul Islam Sifat",
      "Anamitra Pal"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.04560"
  },
  {
    "id": "arXiv:2212.04563",
    "title": "An SLR on Edge Computing Security and possible threat protection",
    "abstract": "Mobile and Internet of Things devices are generating enormous amounts of\nmulti-modal data due to their exponential growth and accessibility. As a\nresult, these data sources must be directly analyzed in real time at the\nnetwork edge rather than relying on the cloud. Significant processing power at\nthe network's edge has made it possible to gather data and make decisions prior\nto data being sent to the cloud. Moreover, security problems have significantly\ntowered as a result of the rapid expansion of mobile devices, Internet of\nThings (IoT) devices, and various network points. It's much harder than ever to\nguarantee the privacy of sensitive data, including customer information. This\nsystematic literature review depicts the fact that new technologies are a great\nweapon to fight with the attack and threats to the edge computing security.",
    "descriptor": "",
    "authors": [
      "Harsiddh Kalariya",
      "Kavish Shah",
      "Vini Patel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.04563"
  },
  {
    "id": "arXiv:2212.04573",
    "title": "Modularity through Attention: Efficient Training and Transfer of  Language-Conditioned Policies for Robot Manipulation",
    "abstract": "Language-conditioned policies allow robots to interpret and execute human\ninstructions. Learning such policies requires a substantial investment with\nregards to time and compute resources. Still, the resulting controllers are\nhighly device-specific and cannot easily be transferred to a robot with\ndifferent morphology, capability, appearance or dynamics. In this paper, we\npropose a sample-efficient approach for training language-conditioned\nmanipulation policies that allows for rapid transfer across different types of\nrobots. By introducing a novel method, namely Hierarchical Modularity, and\nadopting supervised attention across multiple sub-modules, we bridge the divide\nbetween modular and end-to-end learning and enable the reuse of functional\nbuilding blocks. In both simulated and real world robot manipulation\nexperiments, we demonstrate that our method outperforms the current\nstate-of-the-art methods and can transfer policies across 4 different robots in\na sample-efficient manner. Finally, we show that the functionality of learned\nsub-modules is maintained beyond the training process and can be used to\nintrospect the robot decision-making process. Code is available at\nhttps://github.com/ir-lab/ModAttn.",
    "descriptor": "\nComments: 2022 Conference on Robot Learning (CoRL)\n",
    "authors": [
      "Yifan Zhou",
      "Shubham Sonawani",
      "Mariano Phielipp",
      "Simon Stepputtis",
      "Heni Ben Amor"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.04573"
  },
  {
    "id": "arXiv:2212.04574",
    "title": "Hide, Not Seek: Perceived Fairness in Envy-Free Allocations of  Indivisible Goods",
    "abstract": "Fair division provides a rich computational and mathematical framework for\nthe allocation of indivisible goods, which has given rise to numerous fairness\nconcepts and their relaxations. In recent years, much attention has been given\nto theoretical and computational aspects of various fairness concepts.\nNonetheless, the choice of which fairness concept is in practice perceived to\nbe fairer by individuals is not well understood. We consider two conceptually\ndifferent relaxations of envy-freeness and investigate how individuals perceive\nthe induced allocations as fair. In particular, we examine a well-studied\nrelaxation of envy-freeness up to one good (EF1) which is based on\ncounterfactual thinking that any pairwise envy can be eliminated by the\nhypothetical removal of a single good from the envied agent's bundle. In\ncontrast, a recently proposed epistemic notion, namely envy-freeness up to $k$\nhidden goods (HEF-$k$), provides a relaxation by hiding information about a\nsmall subset of $k$ goods. Through various crowdsourcing experiments, we\nempirically demonstrate that allocations achieved by withholding information\nare perceived to be fairer compared to two variants of EF1.",
    "descriptor": "\nComments: 21 pages, 10 figures\n",
    "authors": [
      "Hadi Hosseini",
      "Joshua Kavner",
      "Sujoy Sikdar",
      "Rohit Vaish",
      "Lirong Xia"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2212.04574"
  },
  {
    "id": "arXiv:2212.04575",
    "title": "DDM-NET: End-to-end learning of keypoint feature Detection, Description  and Matching for 3D localization",
    "abstract": "In this paper, we propose an end-to-end framework that jointly learns\nkeypoint detection, descriptor representation and cross-frame matching for the\ntask of image-based 3D localization. Prior art has tackled each of these\ncomponents individually, purportedly aiming to alleviate difficulties in\neffectively train a holistic network. We design a self-supervised image warping\ncorrespondence loss for both feature detection and matching, a\nweakly-supervised epipolar constraints loss on relative camera pose learning,\nand a directional matching scheme that detects key-point features in a source\nimage and performs coarse-to-fine correspondence search on the target image. We\nleverage this framework to enforce cycle consistency in our matching module. In\naddition, we propose a new loss to robustly handle both definite inlier/outlier\nmatches and less-certain matches. The integration of these learning mechanisms\nenables end-to-end training of a single network performing all three\nlocalization components. Bench-marking our approach on public data-sets,\nexemplifies how such an end-to-end framework is able to yield more accurate\nlocalization that out-performs both traditional methods as well as\nstate-of-the-art weakly supervised methods.",
    "descriptor": "",
    "authors": [
      "Xiangyu Xu",
      "Li Guan",
      "Enrique Dunn",
      "Haoxiang Li",
      "Guang Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04575"
  },
  {
    "id": "arXiv:2212.04576",
    "title": "Generalizing LTL Instructions via Future Dependent Options",
    "abstract": "Linear temporal logic (LTL) is a widely-used task specification language\nwhich has a compositional grammar that naturally induces temporally extended\nbehaviours across tasks, including conditionals and alternative realizations.\nAn important problem i RL with LTL tasks is to learn task-conditioned policies\nwhich can zero-shot generalize to new LTL instructions not observed in the\ntraining. However, because symbolic observation is often lossy and LTL tasks\ncan have long time horizon, previous works can suffer from issues such as\ntraining sampling inefficiency and infeasibility or sub-optimality of the found\nsolutions. In order to tackle these issues, this paper proposes a novel\nmulti-task RL algorithm with improved learning efficiency and optimality. To\nachieve the global optimality of task completion, we propose to learn options\ndependent on the future subgoals via a novel off-policy approach. In order to\npropagate the rewards of satisfying future subgoals back more efficiently, we\npropose to train a multi-step value function conditioned on the subgoal\nsequence which is updated with Monte Carlo estimates of multi-step discounted\nreturns. In experiments on three different domains, we evaluate the LTL\ngeneralization capability of the agent trained by the proposed method, showing\nits advantage over previous representative methods.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2206.05096, arXiv:2102.06858 by other authors\n",
    "authors": [
      "Duo Xu",
      "Faramarz Fekri"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04576"
  },
  {
    "id": "arXiv:2212.04581",
    "title": "PALMER: Perception-Action Loop with Memory for Long-Horizon Planning",
    "abstract": "To achieve autonomy in a priori unknown real-world scenarios, agents should\nbe able to: i) act from high-dimensional sensory observations (e.g., images),\nii) learn from past experience to adapt and improve, and iii) be capable of\nlong horizon planning. Classical planning algorithms (e.g. PRM, RRT) are\nproficient at handling long-horizon planning. Deep learning based methods in\nturn can provide the necessary representations to address the others, by\nmodeling statistical contingencies between observations. In this direction, we\nintroduce a general-purpose planning algorithm called PALMER that combines\nclassical sampling-based planning algorithms with learning-based perceptual\nrepresentations. For training these perceptual representations, we combine\nQ-learning with contrastive representation learning to create a latent space\nwhere the distance between the embeddings of two states captures how easily an\noptimal policy can traverse between them. For planning with these perceptual\nrepresentations, we re-purpose classical sampling-based planning algorithms to\nretrieve previously observed trajectory segments from a replay buffer and\nrestitch them into approximately optimal paths that connect any given pair of\nstart and goal states. This creates a tight feedback loop between\nrepresentation learning, memory, reinforcement learning, and sampling-based\nplanning. The end result is an experiential framework for long-horizon planning\nthat is significantly more robust and sample efficient compared to existing\nmethods.",
    "descriptor": "\nComments: Website: this https URL\n",
    "authors": [
      "Onur Beker",
      "Mohammad Mohammadi",
      "Amir Zamir"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04581"
  },
  {
    "id": "arXiv:2212.04582",
    "title": "Towards Holistic Surgical Scene Understanding",
    "abstract": "Most benchmarks for studying surgical interventions focus on a specific\nchallenge instead of leveraging the intrinsic complementarity among different\ntasks. In this work, we present a new experimental framework towards holistic\nsurgical scene understanding. First, we introduce the Phase, Step, Instrument,\nand Atomic Visual Action recognition (PSI-AVA) Dataset. PSI-AVA includes\nannotations for both long-term (Phase and Step recognition) and short-term\nreasoning (Instrument detection and novel Atomic Action recognition) in\nrobot-assisted radical prostatectomy videos. Second, we present Transformers\nfor Action, Phase, Instrument, and steps Recognition (TAPIR) as a strong\nbaseline for surgical scene understanding. TAPIR leverages our dataset's\nmulti-level annotations as it benefits from the learned representation on the\ninstrument detection task to improve its classification capacity. Our\nexperimental results in both PSI-AVA and other publicly available databases\ndemonstrate the adequacy of our framework to spur future research on holistic\nsurgical scene understanding.",
    "descriptor": "\nComments: MICCAI 2022 Oral\n",
    "authors": [
      "Natalia Valderrama",
      "Paola Ruiz Puentes",
      "Isabela Hern\u00e1ndez",
      "Nicol\u00e1s Ayobi",
      "Mathilde Verlyk",
      "Jessica Santander",
      "Juan Caicedo",
      "Nicol\u00e1s Fern\u00e1ndez",
      "Pablo Arbel\u00e1ez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04582"
  },
  {
    "id": "arXiv:2212.04584",
    "title": "Explaining Software Bugs Leveraging Code Structures in Neural Machine  Translation",
    "abstract": "Software bugs claim approximately 50% of development time and cost the global\neconomy billions of dollars. Once a bug is reported, the assigned developer\nattempts to identify and understand the source code responsible for the bug and\nthen corrects the code. Over the last five decades, there has been significant\nresearch on automatically finding or correcting software bugs. However, there\nhas been little research on automatically explaining the bugs to the\ndevelopers, which is essential but a highly challenging task. In this paper, we\npropose Bugsplainer, a transformer-based generative model, that generates\nnatural language explanations for software bugs by learning from a large corpus\nof bug-fix commits. Bugsplainer can leverage structural information and buggy\npatterns from the source code to generate an explanation for a bug. Our\nevaluation using three performance metrics shows that Bugsplainer can generate\nunderstandable and good explanations according to Google's standard, and can\noutperform multiple baselines from the literature. We also conduct a developer\nstudy involving 20 participants where the explanations from Bugsplainer were\nfound to be more accurate, more precise, more concise and more useful than the\nbaselines.",
    "descriptor": "",
    "authors": [
      "Parvez Mahbub",
      "Ohiduzzaman Shuvo",
      "Mohammad Masudur Rahman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.04584"
  },
  {
    "id": "arXiv:2212.04587",
    "title": "Parameter Estimation with Maximal Updated Densities",
    "abstract": "A recently developed measure-theoretic framework solves a stochastic inverse\nproblem (SIP) for models where uncertainties in model output data are\npredominantly due to aleatoric (i.e., irreducible) uncertainties in model\ninputs (i.e., parameters). The subsequent inferential target is a distribution\non parameters. Another type of inverse problem is to quantify uncertainties in\nestimates of \"true\" parameter values under the assumption that such\nuncertainties should be reduced as more data are incorporated into the problem,\ni.e., the uncertainty is considered epistemic. A major contribution of this\nwork is the formulation and solution of such a parameter identification problem\n(PIP) within the measure-theoretic framework developed for the SIP. The\napproach is novel in that it utilizes a solution to a stochastic forward\nproblem (SFP) to update an initial density only in the parameter directions\ninformed by the model output data. In other words, this method performs\n\"selective regularization\" only in the parameter directions not informed by\ndata. The solution is defined by a maximal updated density (MUD) point where\nthe updated density defines the measure-theoretic solution to the PIP. Another\nsignificant contribution of this work is the full theory of existence and\nuniqueness of MUD points for linear maps with Gaussian distributions.\nData-constructed Quantity of Interest (QoI) maps are also presented and\nanalyzed for solving the PIP within this measure-theoretic framework as a means\nof reducing uncertainties in the MUD estimate. We conclude with a demonstration\nof the general applicability of the method on two problems involving either\nspatial or temporal data for estimating uncertain model parameters.",
    "descriptor": "\nComments: Code: github.com/mathematicalmichael/mud.git\n",
    "authors": [
      "Michael Pilosov",
      "Carlos del-Castillo-Negrete",
      "Tian Yu Yen",
      "Troy Butler",
      "Clint Dawson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2212.04587"
  },
  {
    "id": "arXiv:2212.04589",
    "title": "Optimizing Integrated Information with a Prior Guided Random Search  Algorithm",
    "abstract": "Integrated information theory (IIT) is a theoretical framework that provides\na quantitative measure to estimate when a physical system is conscious, its\ndegree of consciousness, and the complexity of the qualia space that the system\nis experiencing. Formally, IIT rests on the assumption that if a surrogate\nphysical system can fully embed the phenomenological properties of\nconsciousness, then the system properties must be constrained by the properties\nof the qualia being experienced. Following this assumption, IIT represents the\nphysical system as a network of interconnected elements that can be thought of\nas a probabilistic causal graph, $\\mathcal{G}$, where each node has an\ninput-output function and all the graph is encoded in a transition probability\nmatrix. Consequently, IIT's quantitative measure of consciousness, $\\Phi$, is\ncomputed with respect to the transition probability matrix and the present\nstate of the graph. In this paper, we provide a random search algorithm that is\nable to optimize $\\Phi$ in order to investigate, as the number of nodes\nincreases, the structure of the graphs that have higher $\\Phi$. We also provide\narguments that show the difficulties of applying more complex black-box search\nalgorithms, such as Bayesian optimization or metaheuristics, in this particular\nproblem. Additionally, we suggest specific research lines for these techniques\nto enhance the search algorithm that guarantees maximal $\\Phi$.",
    "descriptor": "",
    "authors": [
      "Eduardo C. Garrido-Merch\u00e1n",
      "Javier S\u00e1nchez-Ca\u00f1izares"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04589"
  },
  {
    "id": "arXiv:2212.04590",
    "title": "Learning Options via Compression",
    "abstract": "Identifying statistical regularities in solutions to some tasks in multi-task\nreinforcement learning can accelerate the learning of new tasks. Skill learning\noffers one way of identifying these regularities by decomposing pre-collected\nexperiences into a sequence of skills. A popular approach to skill learning is\nmaximizing the likelihood of the pre-collected experience with latent variable\nmodels, where the latent variables represent the skills. However, there are\noften many solutions that maximize the likelihood equally well, including\ndegenerate solutions. To address this underspecification, we propose a new\nobjective that combines the maximum likelihood objective with a penalty on the\ndescription length of the skills. This penalty incentivizes the skills to\nmaximally extract common structures from the experiences. Empirically, our\nobjective learns skills that solve downstream tasks in fewer samples compared\nto skills learned from only maximizing likelihood. Further, while most prior\nworks in the offline multi-task setting focus on tasks with low-dimensional\nobservations, our objective can scale to challenging tasks with\nhigh-dimensional image observations.",
    "descriptor": "\nComments: Published at NeurIPS 2022\n",
    "authors": [
      "Yiding Jiang",
      "Evan Zheran Liu",
      "Benjamin Eysenbach",
      "Zico Kolter",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04590"
  },
  {
    "id": "arXiv:2212.04592",
    "title": "Time-Synchronized State Estimation Using Graph Neural Networks in  Presence of Topology Changes",
    "abstract": "Recently, there has been a major emphasis on developing data-driven\napproaches involving machine learning (ML) for high-speed static state\nestimation (SE) in power systems. The emphasis stems from the ability of ML to\novercome difficulties associated with model-based approaches, such as the\nhandling of non-Gaussian measurement noise. However, topology changes pose a\nstiff challenge for performing ML-based SE because the training and test\nenvironments become different when such changes occur. This paper overcomes\nthis challenge by formulating a graph neural network-based time-synchronized\nstate estimator that considers the physical connections of the power system\nduring the training itself. The superiority of the proposed approach over the\nmodel-based linear state estimator in the presence of non-Gaussian measurement\nnoise and a regular deep neural network-based state estimator in the presence\nof topology changes is demonstrated for the IEEE 118-bus system.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Shiva Moshtagh",
      "Anwarul Islam Sifat",
      "Behrouz Azimian",
      "Anamitra Pal"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.04592"
  },
  {
    "id": "arXiv:2212.04593",
    "title": "Towards Understanding Fairness and its Composition in Ensemble Machine  Learning",
    "abstract": "Machine Learning (ML) software has been widely adopted in modern society,\nwith reported fairness implications for minority groups based on race, sex,\nage, etc. Many recent works have proposed methods to measure and mitigate\nalgorithmic bias in ML models. The existing approaches focus on single\nclassifier-based ML models. However, real-world ML models are often composed of\nmultiple independent or dependent learners in an ensemble (e.g., Random\nForest), where the fairness composes in a non-trivial way. How does fairness\ncompose in ensembles? What are the fairness impacts of the learners on the\nultimate fairness of the ensemble? Can fair learners result in an unfair\nensemble? Furthermore, studies have shown that hyperparameters influence the\nfairness of ML models. Ensemble hyperparameters are more complex since they\naffect how learners are combined in different categories of ensembles.\nUnderstanding the impact of ensemble hyperparameters on fairness will help\nprogrammers design fair ensembles. Today, we do not understand these fully for\ndifferent ensemble algorithms. In this paper, we comprehensively study popular\nreal-world ensembles: bagging, boosting, stacking and voting. We have developed\na benchmark of 168 ensemble models collected from Kaggle on four popular\nfairness datasets. We use existing fairness metrics to understand the\ncomposition of fairness. Our results show that ensembles can be designed to be\nfairer without using mitigation techniques. We also identify the interplay\nbetween fairness composition and data characteristics to guide fair ensemble\ndesign. Finally, our benchmark can be leveraged for further research on fair\nensembles. To the best of our knowledge, this is one of the first and largest\nstudies on fairness composition in ensembles yet presented in the literature.",
    "descriptor": "\nComments: Accepted at ICSE 2023\n",
    "authors": [
      "Usman Gohar",
      "Sumon Biswas",
      "Hridesh Rajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04593"
  },
  {
    "id": "arXiv:2212.04595",
    "title": "Explain to me like I am five -- Sentence Simplification Using  Transformers",
    "abstract": "Sentence simplification aims at making the structure of text easier to read\nand understand while maintaining its original meaning. This can be helpful for\npeople with disabilities, new language learners, or those with low literacy.\nSimplification often involves removing difficult words and rephrasing the\nsentence. Previous research have focused on tackling this task by either using\nexternal linguistic databases for simplification or by using control tokens for\ndesired fine-tuning of sentences. However, in this paper we purely use\npre-trained transformer models. We experiment with a combination of GPT-2 and\nBERT models, achieving the best SARI score of 46.80 on the Mechanical Turk\ndataset, which is significantly better than previous state-of-the-art results.\nThe code can be found at https://github.com/amanbasu/sentence-simplification.",
    "descriptor": "",
    "authors": [
      "Aman Agarwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.04595"
  },
  {
    "id": "arXiv:2212.04596",
    "title": "babble: Learning Better Abstractions with E-Graphs and Anti-Unification",
    "abstract": "Library learning compresses a given corpus of programs by extracting common\nstructure from the corpus into reusable library functions. Prior work on\nlibrary learning suffers from two limitations that prevent it from scaling to\nlarger, more complex inputs. First, it explores too many candidate library\nfunctions that are not useful for compression. Second, it is not robust to\nsyntactic variation in the input.\nWe propose library learning modulo theory (LLMT), a new library learning\nalgorithm that additionally takes as input an equational theory for a given\nproblem domain. LLMT uses e-graphs and equality saturation to compactly\nrepresent the space of programs equivalent modulo the theory, and uses a novel\ne-graph anti-unification technique to find common patterns in the corpus more\ndirectly and efficiently.\nWe implemented LLMT in a tool named BABBLE. Our evaluation shows that BABBLE\nachieves better compression orders of magnitude faster than the state of the\nart. We also provide a qualitative evaluation showing that BABBLE learns\nreusable functions on inputs previously out of reach for library learning.",
    "descriptor": "\nComments: POPL 2023\n",
    "authors": [
      "David Cao",
      "Rose Kunkel",
      "Chandrakana Nandi",
      "Max Willsey",
      "Zachary Tatlock",
      "Nadia Polikarpova"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2212.04596"
  },
  {
    "id": "arXiv:2212.04603",
    "title": "System Design for an Integrated Lifelong Reinforcement Learning Agent  for Real-Time Strategy Games",
    "abstract": "As Artificial and Robotic Systems are increasingly deployed and relied upon\nfor real-world applications, it is important that they exhibit the ability to\ncontinually learn and adapt in dynamically-changing environments, becoming\nLifelong Learning Machines. Continual/lifelong learning (LL) involves\nminimizing catastrophic forgetting of old tasks while maximizing a model's\ncapability to learn new tasks. This paper addresses the challenging lifelong\nreinforcement learning (L2RL) setting. Pushing the state-of-the-art forward in\nL2RL and making L2RL useful for practical applications requires more than\ndeveloping individual L2RL algorithms; it requires making progress at the\nsystems-level, especially research into the non-trivial problem of how to\nintegrate multiple L2RL algorithms into a common framework. In this paper, we\nintroduce the Lifelong Reinforcement Learning Components Framework (L2RLCF),\nwhich standardizes L2RL systems and assimilates different continual learning\ncomponents (each addressing different aspects of the lifelong learning problem)\ninto a unified system. As an instantiation of L2RLCF, we develop a standard API\nallowing easy integration of novel lifelong learning components. We describe a\ncase study that demonstrates how multiple independently-developed LL components\ncan be integrated into a single realized system. We also introduce an\nevaluation environment in order to measure the effect of combining various\nsystem components. Our evaluation environment employs different LL scenarios\n(sequences of tasks) consisting of Starcraft-2 minigames and allows for the\nfair, comprehensive, and quantitative comparison of different combinations of\ncomponents within a challenging common evaluation environment.",
    "descriptor": "\nComments: The Second International Conference on AIML Systems, October 12--15, 2022, Bangalore, India\n",
    "authors": [
      "Indranil Sur",
      "Zachary Daniels",
      "Abrar Rahman",
      "Kamil Faber",
      "Gianmarco J. Gallardo",
      "Tyler L. Hayes",
      "Cameron E. Taylor",
      "Mustafa Burak Gurbuz",
      "James Smith",
      "Sahana Joshi",
      "Nathalie Japkowicz",
      "Michael Baron",
      "Zsolt Kira",
      "Christopher Kanan",
      "Roberto Corizzo",
      "Ajay Divakaran",
      "Michael Piacentino",
      "Jesse Hostetler",
      "Aswin Raghavan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04603"
  },
  {
    "id": "arXiv:2212.04604",
    "title": "Localized Contrastive Learning on Graphs",
    "abstract": "Contrastive learning methods based on InfoNCE loss are popular in node\nrepresentation learning tasks on graph-structured data. However, its reliance\non data augmentation and its quadratic computational complexity might lead to\ninconsistency and inefficiency problems. To mitigate these limitations, in this\npaper, we introduce a simple yet effective contrastive model named Localized\nGraph Contrastive Learning (Local-GCL in short). Local-GCL consists of two key\ndesigns: 1) We fabricate the positive examples for each node directly using its\nfirst-order neighbors, which frees our method from the reliance on\ncarefully-designed graph augmentations; 2) To improve the efficiency of\ncontrastive learning on graphs, we devise a kernelized contrastive loss, which\ncould be approximately computed in linear time and space complexity with\nrespect to the graph size. We provide theoretical analysis to justify the\neffectiveness and rationality of the proposed methods. Experiments on various\ndatasets with different scales and properties demonstrate that in spite of its\nsimplicity, Local-GCL achieves quite competitive performance in self-supervised\nnode representation learning tasks on graphs with various scales and\nproperties.",
    "descriptor": "",
    "authors": [
      "Hengrui Zhang",
      "Qitian Wu",
      "Yu Wang",
      "Shaofeng Zhang",
      "Junchi Yan",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04604"
  },
  {
    "id": "arXiv:2212.04607",
    "title": "Confidence-Conditioned Value Functions for Offline Reinforcement  Learning",
    "abstract": "Offline reinforcement learning (RL) promises the ability to learn effective\npolicies solely using existing, static datasets, without any costly online\ninteraction. To do so, offline RL methods must handle distributional shift\nbetween the dataset and the learned policy. The most common approach is to\nlearn conservative, or lower-bound, value functions, which underestimate the\nreturn of out-of-distribution (OOD) actions. However, such methods exhibit one\nnotable drawback: policies optimized on such value functions can only behave\naccording to a fixed, possibly suboptimal, degree of conservatism. However,\nthis can be alleviated if we instead are able to learn policies for varying\ndegrees of conservatism at training time and devise a method to dynamically\nchoose one of them during evaluation. To do so, in this work, we propose\nlearning value functions that additionally condition on the degree of\nconservatism, which we dub confidence-conditioned value functions. We derive a\nnew form of a Bellman backup that simultaneously learns Q-values for any degree\nof confidence with high probability. By conditioning on confidence, our value\nfunctions enable adaptive strategies during online evaluation by controlling\nfor confidence level using the history of observations thus far. This approach\ncan be implemented in practice by conditioning the Q-function from existing\nconservative algorithms on the confidence. We theoretically show that our\nlearned value functions produce conservative estimates of the true value at any\ndesired confidence. Finally, we empirically show that our algorithm outperforms\nexisting conservative offline RL algorithms on multiple discrete control\ndomains.",
    "descriptor": "\nComments: 16 pages, NeurIPS 2022 DeepRL Workshop\n",
    "authors": [
      "Joey Hong",
      "Aviral Kumar",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04607"
  },
  {
    "id": "arXiv:2212.04609",
    "title": "CBE Clima Tool: a free and open-source web application for climate  analysis tailored to sustainable building design",
    "abstract": "Buildings that are designed specifically to respond to the local climate can\nbe more comfortable, energy-efficient, and with a lower environmental impact.\nHowever, there are many social, cultural, and economic obstacles that might\nprevent the wide adoption of designing climate-adapted buildings. One of the\nsaid obstacles can be removed by enabling practitioners to easily access and\nanalyse local climate data. The CBE Clima Tool (Clima) is a free and\nopen-source web application that offers easy access to publicly available\nweather files (in EPW format) specifically created for building energy\nsimulation and design. It provides a series of interactive visualization of the\nvariables therein contained and several derived ones. It is aimed at students,\neducators, and practitioners in the architecture and engineering fields. Since\nits launch has been consistently recording over 3000 monthly unique users from\nover 70 countries worldwide, both in professional and educational settings.",
    "descriptor": "\nComments: Submitted to SoftwareX\n",
    "authors": [
      "Giovanni Betti",
      "Federico Tartarini",
      "Christine Nguyen",
      "Stefano Schiavon"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.04609"
  },
  {
    "id": "arXiv:2212.04611",
    "title": "Multidimensional Service Quality Scoring System",
    "abstract": "This supplementary paper aims to introduce the Multidimensional Service\nQuality Scoring System (MSQs), a review-based method for quantifying host\nservice quality mentioned and employed in the paper Exit and transition:\nExploring the survival status of Airbnb listings in a time of\nprofessionalization. MSQs is not an end-to-end implementation and is\nessentially composed of three pipelines, namely Data Collection and\nPreprocessing, Objects Recognition and Grouping, and Aspect-based Service\nScoring. Using the study mentioned above as a case, the technical details of\nMSQs are explained in this article.",
    "descriptor": "",
    "authors": [
      "Shiyang Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.04611"
  },
  {
    "id": "arXiv:2212.04612",
    "title": "Training Data Influence Analysis and Estimation: A Survey",
    "abstract": "Good models require good training data. For overparameterized deep models,\nthe causal relationship between training data and model predictions is\nincreasingly opaque and poorly understood. Influence analysis partially\ndemystifies training's underlying interactions by quantifying the amount each\ntraining instance alters the final model. Measuring the training data's\ninfluence exactly can be provably hard in the worst case; this has led to the\ndevelopment and use of influence estimators, which only approximate the true\ninfluence. This paper provides the first comprehensive survey of training data\ninfluence analysis and estimation. We begin by formalizing the various, and in\nplaces orthogonal, definitions of training data influence. We then organize\nstate-of-the-art influence analysis methods into a taxonomy; we describe each\nof these methods in detail and compare their underlying assumptions, asymptotic\ncomplexities, and overall strengths and weaknesses. Finally, we propose future\nresearch directions to make influence analysis more useful in practice as well\nas more theoretically and empirically sound. A curated, up-to-date list of\nresources related to influence analysis is available at\nhttps://github.com/ZaydH/influence_analysis_papers.",
    "descriptor": "",
    "authors": [
      "Zayd Hammoudeh",
      "Daniel Lowd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04612"
  },
  {
    "id": "arXiv:2212.04613",
    "title": "Contrastive View Design Strategies to Enhance Robustness to Domain  Shifts in Downstream Object Detection",
    "abstract": "Contrastive learning has emerged as a competitive pretraining method for\nobject detection. Despite this progress, there has been minimal investigation\ninto the robustness of contrastively pretrained detectors when faced with\ndomain shifts. To address this gap, we conduct an empirical study of\ncontrastive learning and out-of-domain object detection, studying how\ncontrastive view design affects robustness. In particular, we perform a case\nstudy of the detection-focused pretext task Instance Localization (InsLoc) and\npropose strategies to augment views and enhance robustness in\nappearance-shifted and context-shifted scenarios. Amongst these strategies, we\npropose changes to cropping such as altering the percentage used, adding IoU\nconstraints, and integrating saliency based object priors. We also explore the\naddition of shortcut-reducing augmentations such as Poisson blending, texture\nflattening, and elastic deformation. We benchmark these strategies on abstract,\nweather, and context domain shifts and illustrate robust ways to combine them,\nin both pretraining on single-object and multi-object image datasets. Overall,\nour results and insights show how to ensure robustness through the choice of\nviews in contrastive learning.",
    "descriptor": "\nComments: To appear, 2nd International Workshop on Practical Deep Learning in the Wild at AAAI Conference on Artificial Intelligence 2023\n",
    "authors": [
      "Kyle Buettner",
      "Adriana Kovashka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04613"
  },
  {
    "id": "arXiv:2212.04614",
    "title": "Is Bio-Inspired Learning Better than Backprop? Benchmarking Bio Learning  vs. Backprop",
    "abstract": "Bio-inspired learning has been gaining popularity recently given that\nBackpropagation (BP) is not considered biologically plausible. Many algorithms\nhave been proposed in the literature which are all more biologically plausible\nthan BP. However, apart from overcoming the biological implausibility of BP, a\nstrong motivation for using Bio-inspired algorithms remains lacking. In this\nstudy, we undertake a holistic comparison of BP vs. multiple Bio-inspired\nalgorithms to answer the question of whether Bio-learning offers additional\nbenefits over BP, rather than just biological plausibility. We test\nBio-algorithms under different design choices such as access to only partial\ntraining data, resource constraints in terms of the number of training epochs,\nsparsification of the neural network parameters and addition of noise to input\nsamples. Through these experiments, we notably find two key advantages of\nBio-algorithms over BP. Firstly, Bio-algorithms perform much better than BP\nwhen the entire training dataset is not supplied. Four of the five\nBio-algorithms tested outperform BP by upto 5% accuracy when only 20% of the\ntraining dataset is available. Secondly, even when the full dataset is\navailable, Bio-algorithms learn much quicker and converge to a stable accuracy\nin far lesser training epochs than BP. Hebbian learning, specifically, is able\nto learn in just 5 epochs compared to around 100 epochs required by BP. These\ninsights present practical reasons for utilising Bio-learning rather than just\nits biological plausibility and also point towards interesting new directions\nfor future work on Bio-learning.",
    "descriptor": "",
    "authors": [
      "Manas Gupta",
      "Sarthak Ketanbhai Modi",
      "Hang Zhang",
      "Joon Hei Lee",
      "Joo Hwee Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04614"
  },
  {
    "id": "arXiv:2212.04615",
    "title": "Simulation-Integrated Distributed Optimal Power Flow for Unbalanced  Power Distribution Systems",
    "abstract": "Distributed optimization methods have been extensively applied for the\noptimization of electric power distribution systems, especially for grid-edge\ncoordination. Existing distributed optimization algorithms applied to power\ndistribution systems require many communication rounds among the distributed\nagents and may pose convergence challenges in difficult nonlinear settings. The\ncommunication network parameters also significantly impact the algorithm's\nperformance. In this paper, we propose a scalable, equivalent network\napproximation-based, distributed optimization algorithm that employs simulation\nwithin optimization using the system's digital twin (DT) to solve the optimal\npower problems (OPF) for a three-phase unbalanced distribution system. The\nproposed approach is implemented using a cyber-physical co-simulation platform\nto validate the robustness of the proposed distributed algorithm under stressed\ncommunication. The proposed approach is thoroughly validated using the IEEE\n123-bus test system.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Rabayet Sadnan",
      "Nathan Gray",
      "Anjan Bose",
      "Anamika Dubey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.04615"
  },
  {
    "id": "arXiv:2212.04616",
    "title": "On Distribution Grid Optimal Power Flow Development and Integration",
    "abstract": "Due to changes in electric distribution grid operation, new operation regimes\nhave been recommended. Distribution grid optimal power flow (DOPF) has received\ntremendous attention in the research community, yet it has not been fully\nadopted across the utility industry. Our paper recognizes this problem and\nsuggests a development and integration procedure for DOPF. We propose\ndevelopment of DOPF as a three step procedure of 1) processing the grid, 2)\nobtaining a tractable solution, and 3) implementing multiple solution\nalgorithms and benchmarking them to improve application reliability. For the\nintegration of DOPF, we demonstrate how a DOPF federate may be developed that\ncan be integrated in a co-simulation environment to mimic the real-world\nconditions and hence improve its practicality to be deployed in the field. To\ndemonstrate the efficacy of the proposed methods, tests on IEEE 123-bus system\nare performed where the usage of tractable formulation in DOPF algorithm\ndevelopment and its comparison to the benchmark solution are demonstrated.",
    "descriptor": "",
    "authors": [
      "Sarmad Hanif",
      "Rabayet Sadnan",
      "Tylor E. Slay",
      "Nawaf Nazir",
      "Shiva Poudel",
      "Bilal Bhatti",
      "Andy Reiman",
      "Jim Follum",
      "Joseph McKinsey",
      "Tarek Elgindy",
      "Rui Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.04616"
  },
  {
    "id": "arXiv:2212.04621",
    "title": "A systematic literature review on Virtual Reality and Augmented Reality  in terms of privacy, authorization and data-leaks",
    "abstract": "In recent years, VR and AR has exploded into a multimillionaire market. As\nthis emerging technology has spread to a variety of businesses and is rapidly\nincreasing among users. It is critical to address potential privacy and\nsecurity concerns that these technologies might pose. In this study, we discuss\nthe current status of privacy and security in VR and AR. We analyse possible\nproblems and risks. Besides, we will look in detail at a few of the major\nconcerns issues and related security solutions for AR and VR. Additionally, as\nVR and AR authentication is the most thoroughly studied aspect of the problem,\nwe concentrate on the research that has already been done in this area.",
    "descriptor": "\nComments: 9 Pages, 4 figures\n",
    "authors": [
      "Parth Dipakkumar Patel",
      "Prem Trivedi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.04621"
  },
  {
    "id": "arXiv:2212.04622",
    "title": "Digital Twin for Real-time Li-ion Battery State of Health Estimation  with Partially Discharged Cycling Data",
    "abstract": "To meet the fairly high safety and reliability requirements in practice, the\nstate of health (SOH) estimation of Lithium-ion batteries (LIBs), which has a\nclose relationship with the degradation performance, has been extensively\nstudied with the widespread applications of various electronics. The\nconventional SOH estimation approaches with digital twin are end-of-cycle\nestimation that require the completion of a full charge/discharge cycle to\nobserve the maximum available capacity. However, under dynamic operating\nconditions with partially discharged data, it is impossible to sense accurate\nreal-time SOH estimation for LIBs. To bridge this research gap, we put forward\na digital twin framework to gain the capability of sensing the battery's SOH on\nthe fly, updating the physical battery model. The proposed digital twin\nsolution consists of three core components to enable real-time SOH estimation\nwithout requiring a complete discharge. First, to handle the variable training\ncycling data, the energy discrepancy-aware cycling synchronization is proposed\nto align cycling data with guaranteeing the same data structure. Second, to\nexplore the temporal importance of different training sampling times, a\ntime-attention SOH estimation model is developed with data encoding to capture\nthe degradation behavior over cycles, excluding adverse influences of\nunimportant samples. Finally, for online implementation, a similarity\nanalysis-based data reconstruction has been put forward to provide real-time\nSOH estimation without requiring a full discharge cycle. Through a series of\nresults conducted on a widely used benchmark, the proposed method yields the\nreal-time SOH estimation with errors less than 1% for most sampling times in\nongoing cycles.",
    "descriptor": "\nComments: This paper has been accepted for IEEE Transactions on Industrial Informatics\n",
    "authors": [
      "Yan Qin",
      "Anushiya Arunan",
      "Chau Yuen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.04622"
  },
  {
    "id": "arXiv:2212.04625",
    "title": "Predictive Barrier Lyapunov Function Based Control for Safe Trajectory  Tracking of an Aerial Manipulator",
    "abstract": "This paper proposes a novel controller framework that provides trajectory\ntracking for an Aerial Manipulator (AM) while ensuring the safe operation of\nthe system under unknown bounded disturbances. The AM considered here is a\n2-DOF (degrees-of-freedom) manipulator rigidly attached to a UAV. Our proposed\ncontroller structure follows the conventional inner loop PID control for\nattitude dynamics and an outer loop controller for tracking a reference\ntrajectory. The outer loop control is based on the Model Predictive Control\n(MPC) with constraints derived using the Barrier Lyapunov Function (BLF) for\nthe safe operation of the AM. BLF-based constraints are proposed for two\nobjectives, viz. 1) To avoid the AM from colliding with static obstacles like a\nrectangular wall, and 2) To maintain the end effector of the manipulator within\nthe desired workspace. The proposed BLF ensures that the above-mentioned\nobjectives are satisfied even in the presence of unknown bounded disturbances.\nThe capabilities of the proposed controller are demonstrated through\nhigh-fidelity non-linear simulations with parameters derived from a real\nlaboratory scale AM. We compare the performance of our controller with other\nstate-of-the-art MPC controllers for AM.",
    "descriptor": "\nComments: European Control Conference '23\n",
    "authors": [
      "Vedant Mundheda",
      "Karan Mirakhor",
      "Rahul K S",
      "Harikumar Kandath",
      "Nagamanikandan Govindan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.04625"
  },
  {
    "id": "arXiv:2212.04629",
    "title": "Post hoc Explanations may be Ineffective for Detecting Unknown Spurious  Correlation",
    "abstract": "We investigate whether three types of post hoc model explanations--feature\nattribution, concept activation, and training point ranking--are effective for\ndetecting a model's reliance on spurious signals in the training data.\nSpecifically, we consider the scenario where the spurious signal to be detected\nis unknown, at test-time, to the user of the explanation method. We design an\nempirical methodology that uses semi-synthetic datasets along with\npre-specified spurious artifacts to obtain models that verifiably rely on these\nspurious training signals. We then provide a suite of metrics that assess an\nexplanation method's reliability for spurious signal detection under various\nconditions. We find that the post hoc explanation methods tested are\nineffective when the spurious artifact is unknown at test-time especially for\nnon-visible artifacts like a background blur. Further, we find that feature\nattribution methods are susceptible to erroneously indicating dependence on\nspurious signals even when the model being explained does not rely on spurious\nartifacts. This finding casts doubt on the utility of these approaches, in the\nhands of a practitioner, for detecting a model's reliance on spurious signals.",
    "descriptor": "",
    "authors": [
      "Julius Adebayo",
      "Michael Muelly",
      "Hal Abelson",
      "Been Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04629"
  },
  {
    "id": "arXiv:2212.04630",
    "title": "A PINN Approach to Symbolic Differential Operator Discovery with Sparse  Data",
    "abstract": "Given ample experimental data from a system governed by differential\nequations, it is possible to use deep learning techniques to construct the\nunderlying differential operators. In this work we perform symbolic discovery\nof differential operators in a situation where there is sparse experimental\ndata. This small data regime in machine learning can be made tractable by\nproviding our algorithms with prior information about the underlying dynamics.\nPhysics Informed Neural Networks (PINNs) have been very successful in this\nregime (reconstructing entire ODE solutions using only a single point or entire\nPDE solutions with very few measurements of the initial condition). We modify\nthe PINN approach by adding a neural network that learns a representation of\nunknown hidden terms in the differential equation. The algorithm yields both a\nsurrogate solution to the differential equation and a black-box representation\nof the hidden terms. These hidden term neural networks can then be converted\ninto symbolic equations using symbolic regression techniques like AI Feynman.\nIn order to achieve convergence of these neural networks, we provide our\nalgorithms with (noisy) measurements of both the initial condition as well as\n(synthetic) experimental data obtained at later times. We demonstrate strong\nperformance of this approach even when provided with very few measurements of\nnoisy data in both the ODE and PDE regime.",
    "descriptor": "",
    "authors": [
      "Lena Podina",
      "Brydon Eastman",
      "Mohammad Kohandel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04630"
  },
  {
    "id": "arXiv:2212.04631",
    "title": "The Cross Density Kernel Function: A Novel Framework to Quantify  Statistical Dependence for Random Processes",
    "abstract": "This paper proposes a novel multivariate definition of statistical dependence\nusing a functional methodology inspired by Alfred R\\'enyi. We define a new\nsymmetric and self-adjoint cross density kernel through a recursive\nbidirectional statistical mapping between conditional densities of continuous\nrandom processes, which estimates their statistical dependence. Therefore, the\nkernel eigenspectrum is proposed as a new multivariate statistical dependence\nmeasure, and the formulation requires fewer assumptions about the data\ngeneration model than current methods. The measure can also be estimated from\nrealizations. The proposed functional maximum correlation algorithm (FMCA) is\napplied to a learning architecture with two multivariate neural networks. The\nFMCA optimal solution is an equilibrium point that estimates the eigenspectrum\nof the cross density kernel. Preliminary results with synthetic data and medium\nsize image datasets corroborate the theory. Four different strategies of\napplying the cross density kernel are thoroughly discussed and implemented to\nshow the versatility and stability of the methodology, and it transcends\nsupervised learning. When two random processes are high-dimensional real-world\nimages and white uniform noise, respectively, the algorithm learns a factorial\ncode i.e., the occurrence of a code guarantees that a certain input in the\ntraining set was present, which is quite important for feature learning.",
    "descriptor": "",
    "authors": [
      "Bo Hu",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.04631"
  },
  {
    "id": "arXiv:2212.04632",
    "title": "Category-Level 6D Object Pose Estimation with Flexible Vector-Based  Rotation Representation",
    "abstract": "In this paper, we propose a novel 3D graph convolution based pipeline for\ncategory-level 6D pose and size estimation from monocular RGB-D images. The\nproposed method leverages an efficient 3D data augmentation and a novel\nvector-based decoupled rotation representation. Specifically, we first design\nan orientation-aware autoencoder with 3D graph convolution for latent feature\nlearning. The learned latent feature is insensitive to point shift and size\nthanks to the shift and scale-invariance properties of the 3D graph\nconvolution. Then, to efficiently decode the rotation information from the\nlatent feature, we design a novel flexible vector-based decomposable rotation\nrepresentation that employs two decoders to complementarily access the rotation\ninformation. The proposed rotation representation has two major advantages: 1)\ndecoupled characteristic that makes the rotation estimation easier; 2) flexible\nlength and rotated angle of the vectors allow us to find a more suitable vector\nrepresentation for specific pose estimation task. Finally, we propose a 3D\ndeformation mechanism to increase the generalization ability of the pipeline.\nExtensive experiments show that the proposed pipeline achieves state-of-the-art\nperformance on category-level tasks. Further, the experiments demonstrate that\nthe proposed rotation representation is more suitable for the pose estimation\ntasks than other rotation representations.",
    "descriptor": "\nComments: revised from CVPR2021 paper FS-NET. arXiv admin note: substantial text overlap with arXiv:2103.07054\n",
    "authors": [
      "Wei Chen",
      "Xi Jia",
      "Zhongqun Zhang",
      "Hyung Jin Chang",
      "Linlin Shen",
      "Ales Leonardis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04632"
  },
  {
    "id": "arXiv:2212.04633",
    "title": "Mitigation of Spatial Nonstationarity with Vision Transformers",
    "abstract": "Spatial nonstationarity, the location variance of features' statistical\ndistributions, is ubiquitous in many natural settings. For example, in\ngeological reservoirs rock matrix porosity varies vertically due to\ngeomechanical compaction trends, in mineral deposits grades vary due to\nsedimentation and concentration processes, in hydrology rainfall varies due to\nthe atmosphere and topography interactions, and in metallurgy crystalline\nstructures vary due to differential cooling. Conventional geostatistical\nmodeling workflows rely on the assumption of stationarity to be able to model\nspatial features for the geostatistical inference. Nevertheless, this is often\nnot a realistic assumption when dealing with nonstationary spatial data and\nthis has motivated a variety of nonstationary spatial modeling workflows such\nas trend and residual decomposition, cosimulation with secondary features, and\nspatial segmentation and independent modeling over stationary subdomains. The\nadvent of deep learning technologies has enabled new workflows for modeling\nspatial relationships. However, there is a paucity of demonstrated best\npractice and general guidance on mitigation of spatial nonstationarity with\ndeep learning in the geospatial context. We demonstrate the impact of two\ncommon types of geostatistical spatial nonstationarity on deep learning model\nprediction performance and propose the mitigation of such impacts using\nself-attention (vision transformer) models. We demonstrate the utility of\nvision transformers for the mitigation of nonstationarity with relative errors\nas low as 10%, exceeding the performance of alternative deep learning methods\nsuch as convolutional neural networks. We establish best practice by\ndemonstrating the ability of self-attention networks for modeling large-scale\nspatial relationships in the presence of commonly observed geospatial\nnonstationarity.",
    "descriptor": "",
    "authors": [
      "Lei Liu",
      "Javier E. Santos",
      "Ma\u0161a Prodanovi\u0107",
      "Michael J. Pyrcz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04633"
  },
  {
    "id": "arXiv:2212.04634",
    "title": "Open-world Story Generation with Structured Knowledge Enhancement: A  Comprehensive Survey",
    "abstract": "Storytelling and narrative are fundamental to human experience, intertwined\nwith our social and cultural engagement. As such, researchers have long\nattempted to create systems that can generate stories automatically. In recent\nyears, powered by deep learning and massive data resources, automatic story\ngeneration has shown significant advances. However, considerable challenges,\nlike the need for global coherence in generated stories, still hamper\ngenerative models from reaching the same storytelling ability as human\nnarrators. To tackle these challenges, many studies seek to inject structured\nknowledge into the generation process, which is referred to as structure\nknowledge-enhanced story generation. Incorporating external knowledge can\nenhance the logical coherence among story events, achieve better knowledge\ngrounding, and alleviate over-generalization and repetition problems in\nstories. This survey provides the latest and comprehensive review of this\nresearch field: (i) we present a systematical taxonomy regarding how existing\nmethods integrate structured knowledge into story generation; (ii) we summarize\ninvolved story corpora, structured knowledge datasets, and evaluation metrics;\n(iii) we give multidimensional insights into the challenges of\nknowledge-enhanced story generation and cast light on promising directions for\nfuture study.",
    "descriptor": "",
    "authors": [
      "Yuxin Wang",
      "Jieru Lin",
      "Zhiwei Yu",
      "Wei Hu",
      "B\u00f6rje F. Karlsson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04634"
  },
  {
    "id": "arXiv:2212.04636",
    "title": "Ego-Body Pose Estimation via Ego-Head Pose Estimation",
    "abstract": "Estimating 3D human motion from an egocentric video sequence is critical to\nhuman behavior understanding and applications in VR/AR. However, naively\nlearning a mapping between egocentric videos and human motions is challenging,\nbecause the user's body is often unobserved by the front-facing camera placed\non the head of the user. In addition, collecting large-scale, high-quality\ndatasets with paired egocentric videos and 3D human motions requires accurate\nmotion capture devices, which often limit the variety of scenes in the videos\nto lab-like environments. To eliminate the need for paired egocentric video and\nhuman motions, we propose a new method, Ego-Body Pose Estimation via Ego-Head\nPose Estimation (EgoEgo), that decomposes the problem into two stages,\nconnected by the head motion as an intermediate representation. EgoEgo first\nintegrates SLAM and a learning approach to estimate accurate head motion. Then,\ntaking the estimated head pose as input, it leverages conditional diffusion to\ngenerate multiple plausible full-body motions. This disentanglement of head and\nbody pose eliminates the need for training datasets with paired egocentric\nvideos and 3D human motion, enabling us to leverage large-scale egocentric\nvideo datasets and motion capture datasets separately. Moreover, for systematic\nbenchmarking, we develop a synthetic dataset, AMASS-Replica-Ego-Syn (ARES),\nwith paired egocentric videos and human motion. On both ARES and real data, our\nEgoEgo model performs significantly better than the state-of-the-art.",
    "descriptor": "\nComments: project website: this https URL\n",
    "authors": [
      "Jiaman Li",
      "C. Karen Liu",
      "Jiajun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2212.04636"
  },
  {
    "id": "arXiv:2212.04638",
    "title": "FLAG3D: A 3D Fitness Activity Dataset with Language Instruction",
    "abstract": "With the continuously thriving popularity around the world, fitness activity\nanalytic has become an emerging research topic in computer vision. While a\nvariety of new tasks and algorithms have been proposed recently, there are\ngrowing hunger for data resources involved in high-quality data, fine-grained\nlabels, and diverse environments. In this paper, we present FLAG3D, a\nlarge-scale 3D fitness activity dataset with language instruction containing\n180K sequences of 60 categories. FLAG3D features the following three aspects:\n1) accurate and dense 3D human pose captured from advanced MoCap system to\nhandle the complex activity and large movement, 2) detailed and professional\nlanguage instruction to describe how to perform a specific activity, 3)\nversatile video resources from a high-tech MoCap system, rendering software,\nand cost-effective smartphones in natural environments. Extensive experiments\nand in-depth analysis show that FLAG3D contributes great research value for\nvarious challenges, such as cross-domain human action recognition, dynamic\nhuman mesh recovery, and language-guided human action generation. Our dataset\nand source code will be publicly available at\nhttps://andytang15.github.io/FLAG3D.",
    "descriptor": "",
    "authors": [
      "Yansong Tang",
      "Jinpeng Liu",
      "Aoyang Liu",
      "Bin Yang",
      "Wenxun Dai",
      "Yongming Rao",
      "Jiwen Lu",
      "Jie Zhou",
      "Xiu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04638"
  },
  {
    "id": "arXiv:2212.04644",
    "title": "Wasserstein Distributionally Robust Control of Partially Observable  Linear Stochastic Systems",
    "abstract": "Distributionally robust control (DRC) aims to effectively manage\ndistributional ambiguity in stochastic systems. While most existing works\naddress inaccurate distributional information in fully observable settings, we\nconsider a partially observable DRC problem for discrete-time linear systems\nusing the Wasserstein metric. For a tractable solution, we propose a novel\napproximation method exploiting the Gelbrich bound of Wasserstein distance.\nUsing techniques from modern distributionally robust optimization, we derive a\nclosed-form expression for the optimal control policy and a tractable\nsemidefinite programming problem for the worst-case distribution policy in both\nfinite-horizon and infinite-horizon average-cost settings. The proposed method\nfeatures several salient theoretical properties, such as a guaranteed cost\nproperty and a probabilistic out-of-sample performance guarantee, demonstrating\nthe distributional robustness of our controller. Furthermore, the resulting\ncontroller is shown to ensure the closed-loop stability of the mean-state\nsystem. The empirical performance of our method is tested through numerical\nexperiments on a power system frequency control problem.",
    "descriptor": "",
    "authors": [
      "Astghik Hakobyan",
      "Insoon Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.04644"
  },
  {
    "id": "arXiv:2212.04645",
    "title": "AI-based Fog and Edge Computing: A Systematic Review, Taxonomy and  Future Directions",
    "abstract": "Resource management in computing is a very challenging problem that involves\nmaking sequential decisions. Resource limitations, resource heterogeneity,\ndynamic and diverse nature of workload, and the unpredictability of fog/edge\ncomputing environments have made resource management even more challenging to\nbe considered in the fog landscape. Recently Artificial Intelligence (AI) and\nMachine Learning (ML) based solutions are adopted to solve this problem. AI/ML\nmethods with the capability to make sequential decisions like reinforcement\nlearning seem most promising for these type of problems. But these algorithms\ncome with their own challenges such as high variance, explainability, and\nonline training. The continuously changing fog/edge environment dynamics\nrequire solutions that learn online, adopting changing computing environment.\nIn this paper, we used standard review methodology to conduct this Systematic\nLiterature Review (SLR) to analyze the role of AI/ML algorithms and the\nchallenges in the applicability of these algorithms for resource management in\nfog/edge computing environments. Further, various machine learning, deep\nlearning and reinforcement learning techniques for edge AI management have been\ndiscussed. Furthermore, we have presented the background and current status of\nAI/ML-based Fog/Edge Computing. Moreover, a taxonomy of AI/ML-based resource\nmanagement techniques for fog/edge computing has been proposed and compared the\nexisting techniques based on the proposed taxonomy. Finally, open challenges\nand promising future research directions have been identified and discussed in\nthe area of AI/ML-based fog/edge computing.",
    "descriptor": "\nComments: 49 page, 15 figures, 10 tables\n",
    "authors": [
      "Sundas Iftikhar",
      "Sukhpal Singh Gill",
      "Chenghao Song",
      "Minxian Xu",
      "Mohammad Sadegh Aslanpour",
      "Adel N. Toosi",
      "Junhui Du",
      "Huaming Wu",
      "Shreya Ghosh",
      "Deepraj Chowdhury",
      "Muhammed Golec",
      "Mohit Kumar",
      "Ahmed M. Abdelmoniem",
      "Felix Cuadrado",
      "Blesson Varghese",
      "Omer Rana",
      "Schahram Dustdar",
      "Steve Uhlig"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.04645"
  },
  {
    "id": "arXiv:2212.04646",
    "title": "DRIP: Domain Refinement Iteration with Polytopes for Backward  Reachability Analysis of Neural Feedback Loops",
    "abstract": "Safety certification of data-driven control techniques remains a major open\nproblem. This work investigates backward reachability as a framework for\nproviding collision avoidance guarantees for systems controlled by neural\nnetwork (NN) policies. Because NNs are typically not invertible, existing\nmethods conservatively assume a domain over which to relax the NN, which causes\nloose over-approximations of the set of states that could lead the system into\nthe obstacle (i.e., backprojection (BP) sets). To address this issue, we\nintroduce DRIP, an algorithm with a refinement loop on the relaxation domain,\nwhich substantially tightens the BP set bounds. Furthermore, we introduce a\nformulation that enables directly obtaining closed-form representations of\npolytopes to bound the BP sets tighter than prior work, which required solving\nlinear programs and using hyper-rectangles. Furthermore, this work extends the\nNN relaxation algorithm to handle polytope domains, which further tightens the\nbounds on BP sets. DRIP is demonstrated in numerical experiments on control\nsystems, including a ground robot controlled by a learned NN obstacle avoidance\npolicy.",
    "descriptor": "",
    "authors": [
      "Michael Everett",
      "Rudy Bunel",
      "Shayegan Omidshafiei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04646"
  },
  {
    "id": "arXiv:2212.04651",
    "title": "Automated Integration of Infrastructure Component Status for Real-Time  Restoration Progress Control: Case Study of Highway System in Hurricane  Harvey",
    "abstract": "Following extreme events, efficient restoration of infrastructure systems is\ncritical to sustaining community lifelines. During the process, effective\nmonitoring and control of the infrastructure restoration progress is critical.\nThis research proposes a systematic approach that automatically integrates\ncomponent-level restoration status to achieve real-time forecasting of overall\ninfrastructure restoration progress. In this research, the approach is mainly\ndesigned for transportation infrastructure restoration following Hurricane\nHarvey. In detail, the component-level restoration status is linked to the\nrestoration progress forecasting through network modeling and earned value\nmethod. Once the new component restoration status is collected, the information\nis automatically integrated to update the overall restoration progress\nforecasting. Academically, an approach is proposed to automatically transform\nthe component-level restoration information to overall restoration progress. In\npractice, the approach expects to ease the communication and coordination\nefforts between emergency managers, thereby facilitating timely identification\nand resolution of issues for rapid infrastructure restoration.",
    "descriptor": "",
    "authors": [
      "Yitong Li",
      "Fengxiu Zhang",
      "Wenying Ji"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2212.04651"
  },
  {
    "id": "arXiv:2212.04654",
    "title": "Discrete Event Simulation for Port Berth Maintenance Planning",
    "abstract": "Industrial and commercial ports, which are one of the three main hubs to the\ncountry, require 24/7 operations to maintain the goods export and import flow.\nDue to the aging and weather factors, berths require regular maintenance, such\nas replacing old piles, timber finders, marine ladders, rubber fenders, and\ndeck slabs. For efficient berth maintenance, strategies are highly desired to\nminimize or eliminate any delays in operations during the maintenance. This\npaper develops a discrete event simulation model using Simphony.NET for berth\nmaintenance processes in Doha Port, Kuwait. The model derives minimum\nmaintenance duration under limited resources and associated uncertainties. The\nmodel can be used as a decision support tool to minimize interruption or delays\nin the port maintenance operations.",
    "descriptor": "",
    "authors": [
      "Ruqayah Alsayed Ebrahim",
      "Shivanan Singh",
      "Yitong Li",
      "Wenying Ji"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2212.04654"
  },
  {
    "id": "arXiv:2212.04655",
    "title": "MIMO Is All You Need : A Strong Multi-In-Multi-Out Baseline for Video  Prediction",
    "abstract": "The mainstream of the existing approaches for video prediction builds up\ntheir models based on a Single-In-Single-Out (SISO) architecture, which takes\nthe current frame as input to predict the next frame in a recursive manner.\nThis way often leads to severe performance degradation when they try to\nextrapolate a longer period of future, thus limiting the practical use of the\nprediction model. Alternatively, a Multi-In-Multi-Out (MIMO) architecture that\noutputs all the future frames at one shot naturally breaks the recursive manner\nand therefore prevents error accumulation. However, only a few MIMO models for\nvideo prediction are proposed and they only achieve inferior performance due to\nthe date. The real strength of the MIMO model in this area is not well noticed\nand is largely under-explored. Motivated by that, we conduct a comprehensive\ninvestigation in this paper to thoroughly exploit how far a simple MIMO\narchitecture can go. Surprisingly, our empirical studies reveal that a simple\nMIMO model can outperform the state-of-the-art work with a large margin much\nmore than expected, especially in dealing with longterm error accumulation.\nAfter exploring a number of ways and designs, we propose a new MIMO\narchitecture based on extending the pure Transformer with local spatio-temporal\nblocks and a new multi-output decoder, namely MIMO-VP, to establish a new\nstandard in video prediction. We evaluate our model in four highly competitive\nbenchmarks (Moving MNIST, Human3.6M, Weather, KITTI). Extensive experiments\nshow that our model wins 1st place on all the benchmarks with remarkable\nperformance gains and surpasses the best SISO model in all aspects including\nefficiency, quantity, and quality. We believe our model can serve as a new\nbaseline to facilitate the future research of video prediction tasks. The code\nwill be released.",
    "descriptor": "",
    "authors": [
      "Shuliang Ning",
      "Mengcheng Lan",
      "Yanran Li",
      "Chaofeng Chen",
      "Qian Chen",
      "Xunlai Chen",
      "Xiaoguang Han",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04655"
  },
  {
    "id": "arXiv:2212.04656",
    "title": "Robust Graph Representation Learning via Predictive Coding",
    "abstract": "Predictive coding is a message-passing framework initially developed to model\ninformation processing in the brain, and now also topic of research in machine\nlearning due to some interesting properties. One of such properties is the\nnatural ability of generative models to learn robust representations thanks to\ntheir peculiar credit assignment rule, that allows neural activities to\nconverge to a solution before updating the synaptic weights. Graph neural\nnetworks are also message-passing models, which have recently shown outstanding\nresults in diverse types of tasks in machine learning, providing\ninterdisciplinary state-of-the-art performance on structured data. However,\nthey are vulnerable to imperceptible adversarial attacks, and unfit for\nout-of-distribution generalization. In this work, we address this by building\nmodels that have the same structure of popular graph neural network\narchitectures, but rely on the message-passing rule of predictive coding.\nThrough an extensive set of experiments, we show that the proposed models are\n(i) comparable to standard ones in terms of performance in both inductive and\ntransductive tasks, (ii) better calibrated, and (iii) robust against multiple\nkinds of adversarial attacks.",
    "descriptor": "\nComments: 27 Pages, 31 Figures\n",
    "authors": [
      "Billy Byiringiro",
      "Tommaso Salvatori",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04656"
  },
  {
    "id": "arXiv:2212.04658",
    "title": "Trust and Reputation Management for Blockchain-enabled IoT",
    "abstract": "In recent years, there has been an increasing interest in incorporating\nblockchain for the Internet of Things (IoT) to address the inherent issues of\nIoT, such as single point of failure and data silos. However, blockchain alone\ncannot ascertain the authenticity and veracity of the data coming from IoT\ndevices. The append-only nature of blockchain exacerbates this issue, as it\nwould not be possible to alter the data once recorded on-chain. Trust and\nReputation Management (TRM) is an effective approach to overcome the\naforementioned trust issues. However, designing TRM frameworks for\nblockchain-enabled IoT applications is a non-trivial task, as each application\nhas its unique trust challenges with their unique features and requirements. In\nthis paper, we present our experiences in designing TRM framework for various\nblockchain-enabled IoT applications to provide insights and highlight open\nresearch challenges for future opportunities.",
    "descriptor": "\nComments: COMSNETS 2023 Invited Paper\n",
    "authors": [
      "Guntur Dharma Putra",
      "Sidra Malik",
      "Volkan Dedeoglu",
      "Salil S Kanhere",
      "Raja Jurdak"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.04658"
  },
  {
    "id": "arXiv:2212.04661",
    "title": "An Attention-based Multi-Scale Feature Learning Network for Multimodal  Medical Image Fusion",
    "abstract": "Medical images play an important role in clinical applications. Multimodal\nmedical images could provide rich information about patients for physicians to\ndiagnose. The image fusion technique is able to synthesize complementary\ninformation from multimodal images into a single image. This technique will\nprevent radiologists switch back and forth between different images and save\nlots of time in the diagnostic process. In this paper, we introduce a novel\nDilated Residual Attention Network for the medical image fusion task. Our\nnetwork is capable to extract multi-scale deep semantic features. Furthermore,\nwe propose a novel fixed fusion strategy termed Softmax-based weighted strategy\nbased on the Softmax weights and matrix nuclear norm. Extensive experiments\nshow our proposed network and fusion strategy exceed the state-of-the-art\nperformance compared with reference image fusion methods on four commonly used\nfusion metrics.",
    "descriptor": "\nComments: 8 pages, 8 figures, 3 tables\n",
    "authors": [
      "Meng Zhou",
      "Xiaolan Xu",
      "Yuxuan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04661"
  },
  {
    "id": "arXiv:2212.04663",
    "title": "Transfer Learning Enhanced DeepONet for Long-Time Prediction of  Evolution Equations",
    "abstract": "Deep operator network (DeepONet) has demonstrated great success in various\nlearning tasks, including learning solution operators of partial differential\nequations. In particular, it provides an efficient approach to predict the\nevolution equations in a finite time horizon. Nevertheless, the vanilla\nDeepONet suffers from the issue of stability degradation in the long-time\nprediction. This paper proposes a {\\em transfer-learning} aided DeepONet to\nenhance the stability. Our idea is to use transfer learning to sequentially\nupdate the DeepONets as the surrogates for propagators learned in different\ntime frames. The evolving DeepONets can better track the varying complexities\nof the evolution equations, while only need to be updated by efficient training\nof a tiny fraction of the operator networks. Through systematic experiments, we\nshow that the proposed method not only improves the long-time accuracy of\nDeepONet while maintaining similar computational cost but also substantially\nreduces the sample size of the training set.",
    "descriptor": "",
    "authors": [
      "Wuzhe Xu",
      "Yulong Lu",
      "Li Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.04663"
  },
  {
    "id": "arXiv:2212.04665",
    "title": "A Computer Vision Method for Estimating Velocity from Jumps",
    "abstract": "Athletes routinely undergo fitness evaluations to evaluate their training\nprogress. Typically, these evaluations require a trained professional who\nutilizes specialized equipment like force plates. For the assessment, athletes\nperform drop and squat jumps, and key variables are measured, e.g. velocity,\nflight time, and time to stabilization, to name a few. However, amateur\nathletes may not have access to professionals or equipment that can provide\nthese assessments. Here, we investigate the feasibility of estimating key\nvariables using video recordings. We focus on jump velocity as a starting point\nbecause it is highly correlated with other key variables and is important for\ndetermining posture and lower-limb capacity. We find that velocity can be\nestimated with a high degree of precision across a range of athletes, with an\naverage R-value of 0.71 (SD = 0.06).",
    "descriptor": "",
    "authors": [
      "Soumyadip Roy",
      "Chaitanya Roygaga",
      "Nathaniel Blanchard",
      "Aparna Bharati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04665"
  },
  {
    "id": "arXiv:2212.04666",
    "title": "Neural Volume Super-Resolution",
    "abstract": "Neural volumetric representations have become a widely adopted model for\nradiance fields in 3D scenes. These representations are fully implicit or\nhybrid function approximators of the instantaneous volumetric radiance in a\nscene, which are typically learned from multi-view captures of the scene. We\ninvestigate the new task of neural volume super-resolution - rendering\nhigh-resolution views corresponding to a scene captured at low resolution. To\nthis end, we propose a neural super-resolution network that operates directly\non the volumetric representation of the scene. This approach allows us to\nexploit an advantage of operating in the volumetric domain, namely the ability\nto guarantee consistent super-resolution across different viewing directions.\nTo realize our method, we devise a novel 3D representation that hinges on\nmultiple 2D feature planes. This allows us to super-resolve the 3D scene\nrepresentation by applying 2D convolutional networks on the 2D feature planes.\nWe validate the proposed method's capability of super-resolving multi-view\nconsistent views both quantitatively and qualitatively on a diverse set of\nunseen 3D scenes, demonstrating a significant advantage over existing\napproaches.",
    "descriptor": "",
    "authors": [
      "Yuval Bahat",
      "Yuxuan Zhang",
      "Hendrik Sommerhoff",
      "Andreas Kolb",
      "Felix Heide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04666"
  },
  {
    "id": "arXiv:2212.04668",
    "title": "Synthetic-to-Real Domain Generalized Semantic Segmentation for 3D Indoor  Point Clouds",
    "abstract": "Semantic segmentation in 3D indoor scenes has achieved remarkable performance\nunder the supervision of large-scale annotated data. However, previous works\nrely on the assumption that the training and testing data are of the same\ndistribution, which may suffer from performance degradation when evaluated on\nthe out-of-distribution scenes. To alleviate the annotation cost and the\nperformance degradation, this paper introduces the synthetic-to-real domain\ngeneralization setting to this task. Specifically, the domain gap between\nsynthetic and real-world point cloud data mainly lies in the different layouts\nand point patterns. To address these problems, we first propose a clustering\ninstance mix (CINMix) augmentation technique to diversify the layouts of the\nsource data. In addition, we augment the point patterns of the source data and\nintroduce non-parametric multi-prototypes to ameliorate the intra-class\nvariance enlarged by the augmented point patterns. The multi-prototypes can\nmodel the intra-class variance and rectify the global classifier in both\ntraining and inference stages. Experiments on the synthetic-to-real benchmark\ndemonstrate that both CINMix and multi-prototypes can narrow the distribution\ngap and thus improve the generalization ability on real-world datasets.",
    "descriptor": "",
    "authors": [
      "Yuyang Zhao",
      "Na Zhao",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04668"
  },
  {
    "id": "arXiv:2212.04673",
    "title": "MSI: Maximize Support-Set Information for Few-Shot Segmentation",
    "abstract": "FSS(Few-shot segmentation)~aims to segment a target class with a small number\nof labeled images (support Set). To extract information relevant to target\nclass, a dominant approach in best performing FSS baselines removes background\nfeatures using support mask. We observe that this support mask presents an\ninformation bottleneck in several challenging FSS cases e.g., for small targets\nand/or inaccurate target boundaries. To this end, we present a novel method\n(MSI), which maximizes the support-set information by exploiting two\ncomplementary source of features in generating super correlation maps. We\nvalidate the effectiveness of our approach by instantiating it into three\nrecent and strong FSS baselines. Experimental results on several publicly\navailable FSS benchmarks show that our proposed method consistently improves\nthe performance by visible margins and allows faster convergence. Our codes and\nmodels will be publicly released.",
    "descriptor": "",
    "authors": [
      "Seonghyeon Moon",
      "Samuel S. Sohn",
      "Honglu Zhou",
      "Sejong Yoon",
      "Vladimir Pavlovic",
      "Muhammad Haris Khan",
      "Mubbasir Kapadia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04673"
  },
  {
    "id": "arXiv:2212.04675",
    "title": "SemanticBEVFusion: Rethink LiDAR-Camera Fusion in Unified Bird's-Eye  View Representation for 3D Object Detection",
    "abstract": "LiDAR and camera are two essential sensors for 3D object detection in\nautonomous driving. LiDAR provides accurate and reliable 3D geometry\ninformation while the camera provides rich texture with color. Despite the\nincreasing popularity of fusing these two complementary sensors, the challenge\nremains in how to effectively fuse 3D LiDAR point cloud with 2D camera images.\nRecent methods focus on point-level fusion which paints the LiDAR point cloud\nwith camera features in the perspective view or bird's-eye view (BEV)-level\nfusion which unifies multi-modality features in the BEV representation. In this\npaper, we rethink these previous fusion strategies and analyze their\ninformation loss and influences on geometric and semantic features. We present\nSemanticBEVFusion to deeply fuse camera features with LiDAR features in a\nunified BEV representation while maintaining per-modality strengths for 3D\nobject detection. Our method achieves state-of-the-art performance on the\nlarge-scale nuScenes dataset, especially for challenging distant objects. The\ncode will be made publicly available.",
    "descriptor": "\nComments: The first two authors contributed equally to this work\n",
    "authors": [
      "Qi Jiang",
      "Hao Sun",
      "Xi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04675"
  },
  {
    "id": "arXiv:2212.04677",
    "title": "Reinforcement Learning for Predicting Traffic Accidents",
    "abstract": "As the demand for autonomous driving increases, it is paramount to ensure\nsafety. Early accident prediction using deep learning methods for driving\nsafety has recently gained much attention. In this task, early accident\nprediction and a point prediction of where the drivers should look are\ndetermined, with the dashcam video as input. We propose to exploit the double\nactors and regularized critics (DARC) method, for the first time, on this\naccident forecasting platform. We derive inspiration from DARC since it is\ncurrently a state-of-the-art reinforcement learning (RL) model on continuous\naction space suitable for accident anticipation. Results show that by utilizing\nDARC, we can make predictions 5\\% earlier on average while improving in\nmultiple metrics of precision compared to existing methods. The results imply\nthat using our RL-based problem formulation could significantly increase the\nsafety of autonomous driving.",
    "descriptor": "",
    "authors": [
      "Injoon Cho",
      "Praveen Kumar Rajendran",
      "Taeyoung Kim",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04677"
  },
  {
    "id": "arXiv:2212.04679",
    "title": "Motion and Context-Aware Audio-Visual Conditioned Video Prediction",
    "abstract": "Existing state-of-the-art method for audio-visual conditioned video\nprediction uses the latent codes of the audio-visual frames from a multimodal\nstochastic network and a frame encoder to predict the next visual frame.\nHowever, a direct inference of per-pixel intensity for the next visual frame\nfrom the latent codes is extremely challenging because of the high-dimensional\nimage space. To this end, we propose to decouple the audio-visual conditioned\nvideo prediction into motion and appearance modeling. The first part is the\nmultimodal motion estimation module that learns motion information as optical\nflow from the given audio-visual clip. The second part is the context-aware\nrefinement module that uses the predicted optical flow to warp the current\nvisual frame into the next visual frame and refines it base on the given\naudio-visual context. Experimental results show that our method achieves\ncompetitive results on existing benchmarks.",
    "descriptor": "\nComments: under consideration at Computer Vision and Image Understanding\n",
    "authors": [
      "Yating Xu",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04679"
  },
  {
    "id": "arXiv:2212.04680",
    "title": "Near-Optimal Differentially Private Reinforcement Learning",
    "abstract": "Motivated by personalized healthcare and other applications involving\nsensitive data, we study online exploration in reinforcement learning with\ndifferential privacy (DP) constraints. Existing work on this problem\nestablished that no-regret learning is possible under joint differential\nprivacy (JDP) and local differential privacy (LDP) but did not provide an\nalgorithm with optimal regret. We close this gap for the JDP case by designing\nan $\\epsilon$-JDP algorithm with a regret of\n$\\widetilde{O}(\\sqrt{SAH^2T}+S^2AH^3/\\epsilon)$ which matches the\ninformation-theoretic lower bound of non-private learning for all choices of\n$\\epsilon> S^{1.5}A^{0.5} H^2/\\sqrt{T}$. In the above, $S$, $A$ denote the\nnumber of states and actions, $H$ denotes the planning horizon, and $T$ is the\nnumber of steps. To the best of our knowledge, this is the first private RL\nalgorithm that achieves \\emph{privacy for free} asymptotically as $T\\rightarrow\n\\infty$. Our techniques -- which could be of independent interest -- include\nprivately releasing Bernstein-type exploration bonuses and an improved method\nfor releasing visitation statistics. The same techniques also imply a slightly\nimproved regret bound for the LDP case.",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Dan Qiao",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.04680"
  },
  {
    "id": "arXiv:2212.04681",
    "title": "AugNet: Dynamic Test-Time Augmentation via Differentiable Functions",
    "abstract": "Distribution shifts, which often occur in the real world, degrade the\naccuracy of deep learning systems, and thus improving robustness is essential\nfor practical applications. To improve robustness, we study an image\nenhancement method that generates recognition-friendly images without\nretraining the recognition model. We propose a novel image enhancement method,\nAugNet, which is based on differentiable data augmentation techniques and\ngenerates a blended image from many augmented images to improve the recognition\naccuracy under distribution shifts. In addition to standard data augmentations,\nAugNet can also incorporate deep neural network-based image transformation,\nwhich further improves the robustness. Because AugNet is composed of\ndifferentiable functions, AugNet can be directly trained with the\nclassification loss of the recognition model. AugNet is evaluated on widely\nused image recognition datasets using various classification models, including\nVision Transformer and MLP-Mixer. AugNet improves the robustness with almost no\nreduction in classification accuracy for clean images, which is a better result\nthan the existing methods. Furthermore, we show that interpretation of\ndistribution shifts using AugNet and retraining based on that interpretation\ncan greatly improve robustness.",
    "descriptor": "",
    "authors": [
      "Shohei Enomoto",
      "Monikka Roslianna Busto",
      "Takeharu Eda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04681"
  },
  {
    "id": "arXiv:2212.04684",
    "title": "Machine Learning-based Classification of Birds through Birdsong",
    "abstract": "Audio sound recognition and classification is used for many tasks and\napplications including human voice recognition, music recognition and audio\ntagging. In this paper we apply Mel Frequency Cepstral Coefficients (MFCC) in\ncombination with a range of machine learning models to identify (Australian)\nbirds from publicly available audio files of their birdsong. We present\napproaches used for data processing and augmentation and compare the results of\nvarious state of the art machine learning models. We achieve an overall\naccuracy of 91% for the top-5 birds from the 30 selected as the case study.\nApplying the models to more challenging and diverse audio files comprising 152\nbird species, we achieve an accuracy of 58%",
    "descriptor": "",
    "authors": [
      "Yueying Chang",
      "Richard O. Sinnott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.04684"
  },
  {
    "id": "arXiv:2212.04687",
    "title": "Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of  Backdoor Effects in Trojaned Machine Learning Models",
    "abstract": "In this paper, we present a simple yet surprisingly effective technique to\ninduce \"selective amnesia\" on a backdoored model. Our approach, called SEAM,\nhas been inspired by the problem of catastrophic forgetting (CF), a long\nstanding issue in continual learning. Our idea is to retrain a given DNN model\non randomly labeled clean data, to induce a CF on the model, leading to a\nsudden forget on both primary and backdoor tasks; then we recover the primary\ntask by retraining the randomized model on correctly labeled clean data. We\nanalyzed SEAM by modeling the unlearning process as continual learning and\nfurther approximating a DNN using Neural Tangent Kernel for measuring CF. Our\nanalysis shows that our random-labeling approach actually maximizes the CF on\nan unknown backdoor in the absence of triggered inputs, and also preserves some\nfeature extraction in the network to enable a fast revival of the primary task.\nWe further evaluated SEAM on both image processing and Natural Language\nProcessing tasks, under both data contamination and training manipulation\nattacks, over thousands of models either trained on popular image datasets or\nprovided by the TrojAI competition. Our experiments show that SEAM vastly\noutperforms the state-of-the-art unlearning techniques, achieving a high\nFidelity (measuring the gap between the accuracy of the primary task and that\nof the backdoor) within a few minutes (about 30 times faster than training a\nmodel from scratch using the MNIST dataset), with only a small amount of clean\ndata (0.1% of training data for TrojAI models).",
    "descriptor": "",
    "authors": [
      "Rui Zhu",
      "Di Tang",
      "Siyuan Tang",
      "XiaoFeng Wang",
      "Haixu Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04687"
  },
  {
    "id": "arXiv:2212.04688",
    "title": "Comparative Study of Sentiment Analysis for Multi-Sourced Social Media  Platforms",
    "abstract": "There is a vast amount of data generated every second due to the rapidly\ngrowing technology in the current world. This area of research attempts to\ndetermine the feelings or opinions of people on social media posts. The dataset\nwe used was a multi-source dataset from the comment section of various social\nnetworking sites like Twitter, Reddit, etc. Natural Language Processing\nTechniques were employed to perform sentiment analysis on the obtained dataset.\nIn this paper, we provide a comparative analysis using techniques of\nlexicon-based, machine learning and deep learning approaches. The Machine\nLearning algorithm used in this work is Naive Bayes, the Lexicon-based approach\nused in this work is TextBlob, and the deep-learning algorithm used in this\nwork is LSTM.",
    "descriptor": "",
    "authors": [
      "Keshav Kapur",
      "Rajitha Harikrishnan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04688"
  },
  {
    "id": "arXiv:2212.04689",
    "title": "Non-equispaced Fourier Neural Solvers for PDEs",
    "abstract": "Solving partial differential equations is difficult. Recently proposed neural\nresolution-invariant models, despite their effectiveness and efficiency,\nusually require equispaced spatial points of data. However, sampling in spatial\ndomain is sometimes inevitably non-equispaced in real-world systems, limiting\ntheir applicability. In this paper, we propose a Non-equispaced Fourier PDE\nSolver (\\textsc{NFS}) with adaptive interpolation on resampled equispaced\npoints and a variant of Fourier Neural Operators as its components.\nExperimental results on complex PDEs demonstrate its advantages in accuracy and\nefficiency. Compared with the spatially-equispaced benchmark methods, it\nachieves superior performance with $42.85\\%$ improvements on MAE, and is able\nto handle non-equispaced data with a tiny loss of accuracy. Besides, to our\nbest knowledge, \\textsc{NFS} is the first ML-based method with mesh invariant\ninference ability to successfully model turbulent flows in non-equispaced\nscenarios, with a minor deviation of the error on unseen spatial points.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Haitao Lin",
      "Lirong Wu",
      "Yongjie Xu",
      "Yufei Huang",
      "Siyuan Li",
      "Guojiang Zhao",
      "Stan Z",
      "Li Cari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04689"
  },
  {
    "id": "arXiv:2212.04690",
    "title": "Benchmarking Self-Supervised Learning on Diverse Pathology Datasets",
    "abstract": "Computational pathology can lead to saving human lives, but models are\nannotation hungry and pathology images are notoriously expensive to annotate.\nSelf-supervised learning has shown to be an effective method for utilizing\nunlabeled data, and its application to pathology could greatly benefit its\ndownstream tasks. Yet, there are no principled studies that compare SSL methods\nand discuss how to adapt them for pathology. To address this need, we execute\nthe largest-scale study of SSL pre-training on pathology image data, to date.\nOur study is conducted using 4 representative SSL methods on diverse downstream\ntasks. We establish that large-scale domain-aligned pre-training in pathology\nconsistently out-performs ImageNet pre-training in standard SSL settings such\nas linear and fine-tuning evaluations, as well as in low-label regimes.\nMoreover, we propose a set of domain-specific techniques that we experimentally\nshow leads to a performance boost. Lastly, for the first time, we apply SSL to\nthe challenging task of nuclei instance segmentation and show large and\nconsistent performance improvements under diverse settings.",
    "descriptor": "",
    "authors": [
      "Mingu Kang",
      "Heon Song",
      "Seonwook Park",
      "Donggeun Yoo",
      "S\u00e9rgio Pereira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04690"
  },
  {
    "id": "arXiv:2212.04692",
    "title": "Attention in a family of Boltzmann machines emerging from modern  Hopfield networks",
    "abstract": "Hopfield networks and Boltzmann machines (BMs) are fundamental energy-based\nneural network models. Recent studies on modern Hopfield networks have broaden\nthe class of energy functions and led to a unified perspective on general\nHopfield networks including an attention module. In this letter, we consider\nthe BM counterparts of modern Hopfield networks using the associated energy\nfunctions, and study their salient properties from a trainability perspective.\nIn particular, the energy function corresponding to the attention module\nnaturally introduces a novel BM, which we refer to as attentional BM (AttnBM).\nWe verify that AttnBM has a tractable likelihood function and gradient for a\nspecial case and is easy to train. Moreover, we reveal the hidden connections\nbetween AttnBM and some single-layer models, namely the Gaussian--Bernoulli\nrestricted BM and denoising autoencoder with softmax units. We also investigate\nBMs introduced by other energy functions, and in particular, observe that the\nenergy function of dense associative memory models gives BMs belonging to\nExponential Family Harmoniums.",
    "descriptor": "\nComments: 12 pages, 1 figure\n",
    "authors": [
      "Toshihiro Ota",
      "Ryo Karakida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.04692"
  },
  {
    "id": "arXiv:2212.04700",
    "title": "Tencent AVS: A Holistic Ads Video Dataset for Multi-modal Scene  Segmentation",
    "abstract": "Temporal video segmentation and classification have been advanced greatly by\npublic benchmarks in recent years. However, such research still mainly focuses\non human actions, failing to describe videos in a holistic view. In addition,\nprevious research tends to pay much attention to visual information yet ignores\nthe multi-modal nature of videos. To fill this gap, we construct the Tencent\n`Ads Video Segmentation'~(TAVS) dataset in the ads domain to escalate\nmulti-modal video analysis to a new level. TAVS describes videos from three\nindependent perspectives as `presentation form', `place', and `style', and\ncontains rich multi-modal information such as video, audio, and text. TAVS is\norganized hierarchically in semantic aspects for comprehensive temporal video\nsegmentation with three levels of categories for multi-label classification,\ne.g., `place' - `working place' - `office'. Therefore, TAVS is distinguished\nfrom previous temporal segmentation datasets due to its multi-modal\ninformation, holistic view of categories, and hierarchical granularities. It\nincludes 12,000 videos, 82 classes, 33,900 segments, 121,100 shots, and 168,500\nlabels. Accompanied with TAVS, we also present a strong multi-modal video\nsegmentation baseline coupled with multi-label class prediction. Extensive\nexperiments are conducted to evaluate our proposed method as well as existing\nrepresentative methods to reveal key challenges of our dataset TAVS.",
    "descriptor": "",
    "authors": [
      "Jie Jiang",
      "Zhimin Li",
      "Jiangfeng Xiong",
      "Rongwei Quan",
      "Qinglin Lu",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04700"
  },
  {
    "id": "arXiv:2212.04701",
    "title": "4K-NeRF: High Fidelity Neural Radiance Fields at Ultra High Resolutions",
    "abstract": "In this paper, we present a novel and effective framework, named 4K-NeRF, to\npursue high fidelity view synthesis on the challenging scenarios of ultra high\nresolutions, building on the methodology of neural radiance fields (NeRF). The\nrendering procedure of NeRF-based methods typically relies on a pixel wise\nmanner in which rays (or pixels) are treated independently on both training and\ninference phases, limiting its representational ability on describing subtle\ndetails especially when lifting to a extremely high resolution. We address the\nissue by better exploring ray correlation for enhancing high-frequency details\nbenefiting from the use of geometry-aware local context. Particularly, we use\nthe view-consistent encoder to model geometric information effectively in a\nlower resolution space and recover fine details through the view-consistent\ndecoder, conditioned on ray features and depths estimated by the encoder. Joint\ntraining with patch-based sampling further facilitates our method incorporating\nthe supervision from perception oriented regularization beyond pixel wise loss.\nQuantitative and qualitative comparisons with modern NeRF methods demonstrate\nthat our method can significantly boost rendering quality for retaining\nhigh-frequency details, achieving the state-of-the-art visual quality on 4K\nultra-high-resolution scenario. Code Available at\n\\url{https://github.com/frozoul/4K-NeRF}",
    "descriptor": "",
    "authors": [
      "Zhongshu Wang",
      "Lingzhi Li",
      "Zhen Shen",
      "Li Shen",
      "Liefeng Bo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04701"
  },
  {
    "id": "arXiv:2212.04705",
    "title": "DIP: Differentiable Interreflection-aware Physics-based Inverse  Rendering",
    "abstract": "We present a physics-based inverse rendering method that learns the\nillumination, geometry, and materials of a scene from posed multi-view RGB\nimages. To model the illumination of a scene, existing inverse rendering works\neither completely ignore the indirect illumination or model it by coarse\napproximations, leading to sub-optimal illumination, geometry, and material\nprediction of the scene. In this work, we propose a physics-based illumination\nmodel that explicitly traces the incoming indirect lights at each surface point\nbased on interreflection, followed by estimating each identified indirect light\nthrough an efficient neural network. Furthermore, we utilize the Leibniz's\nintegral rule to resolve non-differentiability in the proposed illumination\nmodel caused by one type of environment light -- the tangent lights. As a\nresult, the proposed interreflection-aware illumination model can be learned\nend-to-end together with geometry and materials estimation. As a side product,\nour physics-based inverse rendering model also facilitates flexible and\nrealistic material editing as well as relighting. Extensive experiments on both\nsynthetic and real-world datasets demonstrate that the proposed method performs\nfavorably against existing inverse rendering methods on novel view synthesis\nand inverse rendering.",
    "descriptor": "",
    "authors": [
      "Youming Deng",
      "Xueting Li",
      "Sifei Liu",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04705"
  },
  {
    "id": "arXiv:2212.04706",
    "title": "The Platform for non-metallic pipes defects recognition. Design and  Implementation",
    "abstract": "This paper describes a prototype software and hardware platform to provide\nsupport to field operators during the inspection of surface defects of\nnon-metallic pipes. Inspection is carried out by video filming defects created\non the same surface in real-time using a \"smart\" helmet device and other mobile\ndevices. The work focuses on the detection and recognition of the defects which\nappears as colored iridescence of reflected light caused by the diffraction\neffect arising from the presence of internal stresses in the inspected\nmaterial. The platform allows you to carry out preliminary analysis directly on\nthe device in offline mode, and, if a connection to the network is established,\nthe received data is transmitted to the server for post-processing to extract\ninformation about possible defects that were not detected at the previous\nstage. The paper presents a description of the stages of design, formal\ndescription, and implementation details of the platform. It also provides\ndescriptions of the models used to recognize defects and examples of the result\nof the work.",
    "descriptor": "",
    "authors": [
      "Fabio Cacciatori",
      "Sergei Nikolaev",
      "Dmitrii Grigorev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04706"
  },
  {
    "id": "arXiv:2212.04708",
    "title": "PATO: Policy Assisted TeleOperation for Scalable Robot Data Collection",
    "abstract": "Large-scale data is an essential component of machine learning as\ndemonstrated in recent advances in natural language processing and computer\nvision research. However, collecting large-scale robotic data is much more\nexpensive and slower as each operator can control only a single robot at a\ntime. To make this costly data collection process efficient and scalable, we\npropose Policy Assisted TeleOperation (PATO), a system which automates part of\nthe demonstration collection process using a learned assistive policy. PATO\nautonomously executes repetitive behaviors in data collection and asks for\nhuman input only when it is uncertain about which subtask or behavior to\nexecute. We conduct teleoperation user studies both with a real robot and a\nsimulated robot fleet and demonstrate that our assisted teleoperation system\nreduces human operators' mental load while improving data collection\nefficiency. Further, it enables a single operator to control multiple robots in\nparallel, which is a first step towards scalable robotic data collection. For\ncode and video results, see https://clvrai.com/pato",
    "descriptor": "\nComments: Website: this https URL\n",
    "authors": [
      "Shivin Dass",
      "Karl Pertsch",
      "Hejia Zhang",
      "Youngwoon Lee",
      "Joseph J. Lim",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04708"
  },
  {
    "id": "arXiv:2212.04711",
    "title": "ShadowDiffusion: When Degradation Prior Meets Diffusion Model for Shadow  Removal",
    "abstract": "Recent deep learning methods have achieved promising results in image shadow\nremoval. However, their restored images still suffer from unsatisfactory\nboundary artifacts, due to the lack of degradation prior embedding and the\ndeficiency in modeling capacity. Our work addresses these issues by proposing a\nunified diffusion framework that integrates both the image and degradation\npriors for highly effective shadow removal. In detail, we first propose a\nshadow degradation model, which inspires us to build a novel unrolling\ndiffusion model, dubbed ShandowDiffusion. It remarkably improves the model's\ncapacity in shadow removal via progressively refining the desired output with\nboth degradation prior and diffusive generative prior, which by nature can\nserve as a new strong baseline for image restoration. Furthermore,\nShadowDiffusion progressively refines the estimated shadow mask as an auxiliary\ntask of the diffusion generator, which leads to more accurate and robust\nshadow-free image generation. We conduct extensive experiments on three popular\npublic datasets, including ISTD, ISTD+, and SRD, to validate our method's\neffectiveness. Compared to the state-of-the-art methods, our model achieves a\nsignificant improvement in terms of PSNR, increasing from 31.69dB to 34.73dB\nover SRD dataset.",
    "descriptor": "\nComments: Submitted to CVPR 2023\n",
    "authors": [
      "Lanqing Guo",
      "Chong Wang",
      "Wenhan Yang",
      "Siyu Huang",
      "Yufei Wang",
      "Hanspeter Pfister",
      "Bihan Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04711"
  },
  {
    "id": "arXiv:2212.04712",
    "title": "Occluded Person Re-Identification via Relational Adaptive Feature  Correction Learning",
    "abstract": "Occluded person re-identification (Re-ID) in images captured by multiple\ncameras is challenging because the target person is occluded by pedestrians or\nobjects, especially in crowded scenes. In addition to the processes performed\nduring holistic person Re-ID, occluded person Re-ID involves the removal of\nobstacles and the detection of partially visible body parts. Most existing\nmethods utilize the off-the-shelf pose or parsing networks as pseudo labels,\nwhich are prone to error. To address these issues, we propose a novel Occlusion\nCorrection Network (OCNet) that corrects features through relational-weight\nlearning and obtains diverse and representative features without using external\nnetworks. In addition, we present a simple concept of a center feature in order\nto provide an intuitive solution to pedestrian occlusion scenarios.\nFurthermore, we suggest the idea of Separation Loss (SL) for focusing on\ndifferent parts between global features and part features. We conduct extensive\nexperiments on five challenging benchmark datasets for occluded and holistic\nRe-ID tasks to demonstrate that our method achieves superior performance to\nstate-of-the-art methods especially on occluded scene.",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Minjung Kim",
      "MyeongAh Cho",
      "Heansung Lee",
      "Suhwan Cho",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04712"
  },
  {
    "id": "arXiv:2212.04717",
    "title": "On the Sensitivity of Reward Inference to Misspecified Human Models",
    "abstract": "Inferring reward functions from human behavior is at the center of value\nalignment - aligning AI objectives with what we, humans, actually want. But\ndoing so relies on models of how humans behave given their objectives. After\ndecades of research in cognitive science, neuroscience, and behavioral\neconomics, obtaining accurate human models remains an open research topic. This\nbegs the question: how accurate do these models need to be in order for the\nreward inference to be accurate? On the one hand, if small errors in the model\ncan lead to catastrophic error in inference, the entire framework of reward\nlearning seems ill-fated, as we will never have perfect models of human\nbehavior. On the other hand, if as our models improve, we can have a guarantee\nthat reward accuracy also improves, this would show the benefit of more work on\nthe modeling side. We study this question both theoretically and empirically.\nWe do show that it is unfortunately possible to construct small adversarial\nbiases in behavior that lead to arbitrarily large errors in the inferred\nreward. However, and arguably more importantly, we are also able to identify\nreasonable assumptions under which the reward inference error can be bounded\nlinearly in the error in the human model. Finally, we verify our theoretical\ninsights in discrete and continuous control tasks with simulated and human\ndata.",
    "descriptor": "\nComments: 17 pages, 12 figures\n",
    "authors": [
      "Joey Hong",
      "Kush Bhatia",
      "Anca Dragan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04717"
  },
  {
    "id": "arXiv:2212.04718",
    "title": "Controllability of complex networks: input node placement restricting  the longest control chain",
    "abstract": "The minimum number of inputs needed to control a network is frequently used\nto quantify its controllability. Control of linear dynamics through a minimum\nset of inputs, however, often has prohibitively large energy requirements and\nthere is an inherent trade-off between minimizing the number of inputs and\ncontrol energy. To better understand this trade-off, we study the problem of\nidentifying a minimum set of input nodes such that controllabililty is ensured\nwhile restricting the length of the longest control chain. The longest control\nchain is the maximum distance from input nodes to any network node, and recent\nwork found that reducing its length significantly reduces control energy. We\nmap the longest control chain-constraint minimum input problem to finding a\njoint maximum matching and minimum dominating set. We show that this graph\ncombinatorial problem is NP-complete, and we introduce and validate a heuristic\napproximation. Applying this algorithm to a collection of real and model\nnetworks, we investigate how network structure affects the minimum number of\ninputs, revealing, for example, that for many real networks reducing the\nlongest control chain requires only few or no additional inputs, only the\nrearrangement of the input nodes.",
    "descriptor": "\nComments: 16 pages, 9 figures, supplementary\n",
    "authors": [
      "Samie Alizadeh",
      "M\u00e1rton P\u00f3sfai",
      "Abdorasoul Ghasemi"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2212.04718"
  },
  {
    "id": "arXiv:2212.04719",
    "title": "Several new infinite classes of 0-APN power functions over  $\\mathbb{F}_{2^n}$",
    "abstract": "The investigation of partially APN functions has attracted a lot of research\ninterest recently. In this paper, we present several new infinite classes of\n0-APN power functions over $\\mathbb{F}_{2^n}$ by using the multivariate method\nand resultant elimination, and show that these 0-APN power functions are\nCCZ-inequivalent to the known ones.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2210.02207, arXiv:2210.15103 by other authors\n",
    "authors": [
      "Yuying Man",
      "Shizhu Tian",
      "Nian Li",
      "Xiangyong Zeng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.04719"
  },
  {
    "id": "arXiv:2212.04720",
    "title": "Multi-Task Off-Policy Learning from Bandit Feedback",
    "abstract": "Many practical applications, such as recommender systems and learning to\nrank, involve solving multiple similar tasks. One example is learning of\nrecommendation policies for users with similar movie preferences, where the\nusers may still rank the individual movies slightly differently. Such tasks can\nbe organized in a hierarchy, where similar tasks are related through a shared\nstructure. In this work, we formulate this problem as a contextual off-policy\noptimization in a hierarchical graphical model from logged bandit feedback. To\nsolve the problem, we propose a hierarchical off-policy optimization algorithm\n(HierOPO), which estimates the parameters of the hierarchical model and then\nacts pessimistically with respect to them. We instantiate HierOPO in linear\nGaussian models, for which we also provide an efficient implementation and\nanalysis. We prove per-task bounds on the suboptimality of the learned\npolicies, which show a clear improvement over not using the hierarchical model.\nWe also evaluate the policies empirically. Our theoretical and empirical\nresults show a clear advantage of using the hierarchy over solving each task\nindependently.",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Joey Hong",
      "Branislav Kveton",
      "Sumeet Katariya",
      "Manzil Zaheer",
      "Mohammad Ghavamzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04720"
  },
  {
    "id": "arXiv:2212.04721",
    "title": "A Grid-based Sensor Floor Platform for Robot Localization using Machine  Learning",
    "abstract": "Wireless Sensor Network (WSN) applications reshape the trend of warehouse\nmonitoring systems allowing them to track and locate massive numbers of\nlogistic entities in real-time. To support the tasks, classic Radio Frequency\n(RF)-based localization approaches (e.g. triangulation and trilateration)\nconfront challenges due to multi-path fading and signal loss in noisy warehouse\nenvironment. In this paper, we investigate machine learning methods using a new\ngrid-based WSN platform called Sensor Floor that can overcome the issues.\nSensor Floor consists of 345 nodes installed across the floor of our logistic\nresearch hall with dual-band RF and Inertial Measurement Unit (IMU) sensors.\nOur goal is to localize all logistic entities, for this study we use a mobile\nrobot. We record distributed sensing measurements of Received Signal Strength\nIndicator (RSSI) and IMU values as the dataset and position tracking from Vicon\nsystem as the ground truth. The asynchronous collected data is pre-processed\nand trained using Random Forest and Convolutional Neural Network (CNN). The CNN\nmodel with regularization outperforms the Random Forest in terms of\nlocalization accuracy with aproximate 15 cm. Moreover, the CNN architecture can\nbe configured flexibly depending on the scenario in the warehouse. The\nhardware, software and the CNN architecture of the Sensor Floor are open-source\nunder https://github.com/FLW-TUDO/sensorfloor.",
    "descriptor": "\nComments: This is a preprint version for IEEE I2MTC 2023\n",
    "authors": [
      "Anas Gouda",
      "Danny Heinrich",
      "Mirco H\u00fcnnefeld",
      "Irfan Fachrudin Priyanta",
      "Christopher Reining",
      "Moritz Roidl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.04721"
  },
  {
    "id": "arXiv:2212.04725",
    "title": "Augmenting Knowledge Transfer across Graphs",
    "abstract": "Given a resource-rich source graph and a resource-scarce target graph, how\ncan we effectively transfer knowledge across graphs and ensure a good\ngeneralization performance? In many high-impact domains (e.g., brain networks\nand molecular graphs), collecting and annotating data is prohibitively\nexpensive and time-consuming, which makes domain adaptation an attractive\noption to alleviate the label scarcity issue. In light of this, the\nstate-of-the-art methods focus on deriving domain-invariant graph\nrepresentation that minimizes the domain discrepancy. However, it has recently\nbeen shown that a small domain discrepancy loss may not always guarantee a good\ngeneralization performance, especially in the presence of disparate graph\nstructures and label distribution shifts. In this paper, we present TRANSNET, a\ngeneric learning framework for augmenting knowledge transfer across graphs. In\nparticular, we introduce a novel notion named trinity signal that can naturally\nformulate various graph signals at different granularity (e.g., node\nattributes, edges, and subgraphs). With that, we further propose a domain\nunification module together with a trinity-signal mixup scheme to jointly\nminimize the domain discrepancy and augment the knowledge transfer across\ngraphs. Finally, comprehensive empirical results show that TRANSNET outperforms\nall existing approaches on seven benchmark datasets by a significant margin.",
    "descriptor": "",
    "authors": [
      "Yuzhen Mao",
      "Jianhui Sun",
      "Dawei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.04725"
  },
  {
    "id": "arXiv:2212.04726",
    "title": "Breaking the Barrier $2^k$ for Subset Feedback Vertex Set in Chordal  Graphs",
    "abstract": "The Subset Feedback Vertex Set problem (SFVS), to delete $k$ vertices from a\ngiven graph such that any vertex in a vertex subset (called a terminal set) is\nnot in a cycle in the remaining graph, generalizes the famous Feedback Vertex\nSet problem and Multiway Cut problem. SFVS remains $\\mathrm{NP}$-hard even in\nsplit and chordal graphs, and SFVS in Chordal Graphs can be considered as a\nspecial case of the 3-Hitting Set problem. However, it is not easy to solve\nSFVS in Chordal Graphs faster than 3-Hitting Set. In 2019, Philip, Rajan,\nSaurabh, and Tale (Algorithmica 2019) proved that SFVS in Chordal Graphs can be\nsolved in $2^k n^{\\mathcal{O}(1)}$, slightly improving the best result $2.076^k\nn^{\\mathcal{O}(1)}$ for 3-Hitting Set. In this paper, we break the\n\"$2^k$-barrier\" for SFVS in Chordal Graphs by giving a $1.619^k\nn^{\\mathcal{O}(1)}$-time algorithm. Our algorithm uses reduction and branching\nrules based on the Dulmage-Mendelsohn decomposition and a divide-and-conquer\nmethod.",
    "descriptor": "\nComments: 27 pages, 8 figures. Full version\n",
    "authors": [
      "Tian Bai",
      "Mingyu Xiao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.04726"
  },
  {
    "id": "arXiv:2212.04732",
    "title": "Fill in the Blank: Context-aware Automated Text Input Generation for  Mobile GUI Testing",
    "abstract": "Automated GUI testing is widely used to help ensure the quality of mobile\napps. However, many GUIs require appropriate text inputs to proceed to the next\npage which remains a prominent obstacle for testing coverage. Considering the\ndiversity and semantic requirement of valid inputs (e.g., flight departure,\nmovie name), it is challenging to automate the text input generation. Inspired\nby the fact that the pre-trained Large Language Model (LLM) has made\noutstanding progress in text generation, we propose an approach named QTypist\nbased on LLM for intelligently generating semantic input text according to the\nGUI context. To boost the performance of LLM in the mobile testing scenario, we\ndevelop a prompt-based data construction and tuning method which automatically\nextracts the prompts and answers for model tuning. We evaluate QTypist on 106\napps from Google Play and the result shows that the passing rate of QTypist is\n87%, which is 93% higher than the best baseline. We also integrate QTypist with\nthe automated GUI testing tools and it can cover 42% more app activities, 52%\nmore pages, and subsequently help reveal 122% more bugs compared with the raw\ntool.",
    "descriptor": "\nComments: Accepted by IEEE/ACM International Conference on Software Engineering 2023 (ICSE 2023)\n",
    "authors": [
      "Zhe Liu",
      "Chunyang Chen",
      "Junjie Wang",
      "Xing Che",
      "Yuekai Huang",
      "Jun Hu",
      "Qing Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.04732"
  },
  {
    "id": "arXiv:2212.04734",
    "title": "MED-SE: Medical Entity Definition-based Sentence Embedding",
    "abstract": "We propose Medical Entity Definition-based Sentence Embedding (MED-SE), a\nnovel unsupervised contrastive learning framework designed for clinical texts,\nwhich exploits the definitions of medical entities. To this end, we conduct an\nextensive analysis of multiple sentence embedding techniques in clinical\nsemantic textual similarity (STS) settings. In the entity-centric setting that\nwe have designed, MED-SE achieves significantly better performance, while the\nexisting unsupervised methods including SimCSE show degraded performance. Our\nexperiments elucidate the inherent discrepancies between the general- and\nclinical-domain texts, and suggest that entity-centric contrastive approaches\nmay help bridge this gap and lead to a better representation of clinical\nsentences.",
    "descriptor": "\nComments: 8 pages, 2 figures, 9 tables\n",
    "authors": [
      "Hyeonbin Hwang",
      "Haanju Yoo",
      "Yera Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.04734"
  },
  {
    "id": "arXiv:2212.04739",
    "title": "Lower Bounds for R\u00e9nyi Differential Privacy in a Black-Box Setting",
    "abstract": "We present new methods for assessing the privacy guarantees of an algorithm\nwith regard to R\\'enyi Differential Privacy. To the best of our knowledge, this\nwork is the first to address this problem in a black-box scenario, where only\nalgorithmic outputs are available. To quantify privacy leakage, we devise a new\nestimator for the R\\'enyi divergence of a pair of output distributions. This\nestimator is transformed into a statistical lower bound that is proven to hold\nfor large samples with high probability. Our method is applicable for a broad\nclass of algorithms, including many well-known examples from the privacy\nliterature. We demonstrate the effectiveness of our approach by experiments\nencompassing algorithms and privacy enhancing methods that have not been\nconsidered in related works.",
    "descriptor": "",
    "authors": [
      "Tim Kutta",
      "\u00d6nder Askin",
      "Martin Dunsche"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.04739"
  },
  {
    "id": "arXiv:2212.04740",
    "title": "Predicting Shape Development: a Riemannian Method",
    "abstract": "Predicting the future development of an anatomical shape from a single\nbaseline is an important but difficult problem to solve. Research has shown\nthat it should be tackled in curved shape spaces, as (e.g., disease-related)\nshape changes frequently expose nonlinear characteristics. We thus propose a\nnovel prediction method that encodes the whole shape in a Riemannian shape\nspace. It then learns a simple prediction technique that is founded on\nstatistical hierarchical modelling of longitudinal training data. It is fully\nautomatic, which makes it stand out in contrast to parameter-rich\nstate-of-the-art methods. When applied to predict the future development of the\nshape of right hippocampi under Alzheimer's disease, it outperforms deep\nlearning supported variants and achieves results on par with state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Do\u011fa T\u00fcrkseven",
      "Islem Rekik",
      "Christoph von Tycowicz",
      "Martin Hanik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Differential Geometry (math.DG)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2212.04740"
  },
  {
    "id": "arXiv:2212.04741",
    "title": "Physically Plausible Animation of Human Upper Body from a Single Image",
    "abstract": "We present a new method for generating controllable, dynamically responsive,\nand photorealistic human animations. Given an image of a person, our system\nallows the user to generate Physically plausible Upper Body Animation (PUBA)\nusing interaction in the image space, such as dragging their hand to various\nlocations. We formulate a reinforcement learning problem to train a dynamic\nmodel that predicts the person's next 2D state (i.e., keypoints on the image)\nconditioned on a 3D action (i.e., joint torque), and a policy that outputs\noptimal actions to control the person to achieve desired goals. The dynamic\nmodel leverages the expressiveness of 3D simulation and the visual realism of\n2D videos. PUBA generates 2D keypoint sequences that achieve task goals while\nbeing responsive to forceful perturbation. The sequences of keypoints are then\ntranslated by a pose-to-image generator to produce the final photorealistic\nvideo.",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Ziyuan Huang",
      "Zhengping Zhou",
      "Yung-Yu Chuang",
      "Jiajun Wu",
      "C. Karen Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.04741"
  },
  {
    "id": "arXiv:2212.04744",
    "title": "Weakly Supervised Semantic Segmentation for Large-Scale Point Cloud",
    "abstract": "Existing methods for large-scale point cloud semantic segmentation require\nexpensive, tedious and error-prone manual point-wise annotations. Intuitively,\nweakly supervised training is a direct solution to reduce the cost of labeling.\nHowever, for weakly supervised large-scale point cloud semantic segmentation,\ntoo few annotations will inevitably lead to ineffective learning of network. We\npropose an effective weakly supervised method containing two components to\nsolve the above problem. Firstly, we construct a pretext task, \\textit{i.e.,}\npoint cloud colorization, with a self-supervised learning to transfer the\nlearned prior knowledge from a large amount of unlabeled point cloud to a\nweakly supervised network. In this way, the representation capability of the\nweakly supervised network can be improved by the guidance from a heterogeneous\ntask. Besides, to generate pseudo label for unlabeled data, a sparse label\npropagation mechanism is proposed with the help of generated class prototypes,\nwhich is used to measure the classification confidence of unlabeled point. Our\nmethod is evaluated on large-scale point cloud datasets with different\nscenarios including indoor and outdoor. The experimental results show the large\ngain against existing weakly supervised and comparable results to fully\nsupervised methods\\footnote{Code based on mindspore:\nhttps://github.com/dmcv-ecnu/MindSpore\\_ModelZoo/tree/main/WS3\\_MindSpore}.",
    "descriptor": "",
    "authors": [
      "Yachao Zhang",
      "Zonghao Li",
      "Yuan Xie",
      "Yanyun Qu",
      "Cuihua Li",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04744"
  },
  {
    "id": "arXiv:2212.04745",
    "title": "SLAM for Visually Impaired People: A Survey",
    "abstract": "In recent decades, several assistive technologies for visually impaired and\nblind (VIB) people have been developed to improve their ability to navigate\nindependently and safely. At the same time, simultaneous localization and\nmapping (SLAM) techniques have become sufficiently robust and efficient to be\nadopted in the development of assistive technologies. In this paper, we first\nreport the results of an anonymous survey conducted with VIB people to\nunderstand their experience and needs; we focus on digital assistive\ntechnologies that help them with indoor and outdoor navigation. Then, we\npresent a literature review of assistive technologies based on SLAM. We discuss\nproposed approaches and indicate their pros and cons. We conclude by presenting\nfuture opportunities and challenges in this domain.",
    "descriptor": "\nComments: 26 pages, 5 tables, 3 figures\n",
    "authors": [
      "Marziyeh Bamdad",
      "Davide Scaramuzza",
      "Alireza Darvishy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04745"
  },
  {
    "id": "arXiv:2212.04747",
    "title": "Reminding Forgetful Organic Neuromorphic Device Networks",
    "abstract": "Organic neuromorphic device networks can accelerate neural network algorithms\nand directly integrate with microfluidic systems or living tissues. Proposed\ndevices based on the bio-compatible conductive polymer PEDOT:PSS have shown\nhigh switching speeds and low energy demand. However, as electrochemical\nsystems, they are prone to self-discharge through parasitic electrochemical\nreactions. Therefore, the network's synapses forget their trained conductance\nstates over time. This work integrates single-device high-resolution charge\ntransport models to simulate neuromorphic device networks and analyze the\nimpact of self-discharge on network performance. Simulation of a single-layer\nnine-pixel image classification network reveals no significant impact of\nself-discharge on training efficiency. And, even though the network's weights\ndrift significantly during self-discharge, its predictions remain 100\\%\naccurate for over ten hours. On the other hand, a multi-layer network for the\napproximation of the circle function is shown to degrade significantly over\ntwenty minutes with a final mean-squared-error loss of 0.4. We propose to\ncounter the effect by periodically reminding the network based on a map between\na synapse's current state, the time since the last reminder, and the weight\ndrift. We show that this method with a map obtained through validated\nsimulations can reduce the effective loss to below 0.1 even with worst-case\nassumptions. Finally, while the training of this network is affected by\nself-discharge, a good classification is still obtained. Electrochemical\norganic neuromorphic devices have not been integrated into larger device\nnetworks. This work predicts their behavior under nonideal conditions,\nmitigates the worst-case effects of parasitic self-discharge, and opens the\npath toward implementing fast and efficient neural networks on organic\nneuromorphic hardware.",
    "descriptor": "",
    "authors": [
      "Daniel Felder",
      "Katerina Muche",
      "John Linkhorst",
      "Matthias Wessling"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2212.04747"
  },
  {
    "id": "arXiv:2212.04748",
    "title": "Approximations of solution concepts of cooperative games",
    "abstract": "The computation of a solution concept of a cooperative game usually depends\non values of all coalitions. However, in some applications, values of some of\nthe coalitions might be unknown due to various reasons. We introduce a method\nto approximate standard solution concepts based only on partial information\ngiven by a so called incomplete game. We demonstrate the ideas on the class of\nminimal incomplete games. Approximations are derived for different solution\nconcepts including the Shapley value, the nucleolus, or the core. We show\nexplicit formulas for approximations of some of the solution concepts and show\nhow the approximability differs based on additional information about the game.",
    "descriptor": "",
    "authors": [
      "Martin \u010cern\u00fd"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2212.04748"
  },
  {
    "id": "arXiv:2212.04750",
    "title": "Fluctuations of Rare Event Simulation with Monte Carlo Splitting in the  Small Noise Asymptotics",
    "abstract": "Diffusion processes with small noise conditioned to reach a target set are\nconsidered. The AMS algorithm is a Monte Carlo method that is used to sample\nsuch rare events by iteratively simulating clones of the process and selecting\ntrajectories that have reached the highest value of a so-called importance\nfunction. In this paper, the large sample size relative variance of the AMS\nsmall probability estimator is considered. The main result is a large\ndeviations logarithmic equivalent of the latter in the small noise asymptotics,\nwhich is rigorously derived. It is given as a maximisation problem explicit in\nterms of the quasi-potential cost function associated with the underlying small\nnoise large deviations. Necessary and sufficient geometric conditions ensuring\nthe vanishing of the obtained quantity ('weak' asymptotic efficiency) are\nprovided. Interpretations and practical consequences are discussed.",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric C\u00e9rou",
      "Sofiane Martel",
      "Mathias Rousset"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2212.04750"
  },
  {
    "id": "arXiv:2212.04754",
    "title": "Optimal Sizing and Pricing of Renewable Power to Ammonia Systems  Considering the Limited Flexibility of Ammonia Synthesis",
    "abstract": "Converting renewable energy into ammonia has been recognized as a promising\nway to realize ``green hydrogen substitution\" in the chemical industry.\nHowever, renewable power to ammonia (RePtA) requires an essential investment in\nfacilities to provide a buffer against the strong volatility of renewable\nenergy and the limited flexibility of ammonia synthesis, which involves the\nthree main stakeholders, namely, power, hydrogen, and ammonia. Therefore, the\nsizing and pricing of RePtA play a core role in balancing the interest demands\nof investors. This paper proposes an optimal sizing and pricing method for\nRePtA system planning. First, power to ammonia (P2A) is modeled as a flexible\nload, especially considering the limited flexibility of ammonia synthesis,\nwhich has been verified using real dynamic regulation data. Second, the\nmulti-investor economic (MIE) model is established considering both external\nand internal trading modes. Then, a two-stage decomposed sizing and pricing\nmethod is proposed to solve the problem caused by the strong coupling of\nplanning, operation, and trading, and information gap decision theory (IGDT)\nmethod is utilized to handle the uncertainty of renewable generation. Finally,\nreal data from a real-life system in Inner Mongolia are utilized to verify the\nproposed approach. The results show that the system proposed has a yield of\n8.15%.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Zhipeng Yu",
      "Jin Lin",
      "Feng Liu",
      "Jiarong Li",
      "Yuxuan Zhao",
      "Yonghua Song",
      "Yanhua Song",
      "Xinzhen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.04754"
  },
  {
    "id": "arXiv:2212.04755",
    "title": "From Clozing to Comprehending: Retrofitting Pre-trained Language Model  to Pre-trained Machine Reader",
    "abstract": "We present Pre-trained Machine Reader (PMR), a novel method to retrofit\nPre-trained Language Models (PLMs) into Machine Reading Comprehension (MRC)\nmodels without acquiring labeled data. PMR is capable of resolving the\ndiscrepancy between model pre-training and downstream fine-tuning of existing\nPLMs, and provides a unified solver for tackling various extraction tasks. To\nachieve this, we construct a large volume of general-purpose and high-quality\nMRC-style training data with the help of Wikipedia hyperlinks and design a Wiki\nAnchor Extraction task to guide the MRC-style pre-training process. Although\nconceptually simple, PMR is particularly effective in solving extraction tasks\nincluding Extractive Question Answering and Named Entity Recognition, where it\nshows tremendous improvements over previous approaches especially under\nlow-resource settings. Moreover, viewing sequence classification task as a\nspecial case of extraction task in our MRC formulation, PMR is even capable to\nextract high-quality rationales to explain the classification process,\nproviding more explainability of the predictions.",
    "descriptor": "",
    "authors": [
      "Weiwen Xu",
      "Xin Li",
      "Wenxuan Zhang",
      "Meng Zhou",
      "Lidong Bing",
      "Wai Lam",
      "Luo Si"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.04755"
  },
  {
    "id": "arXiv:2212.04761",
    "title": "Leveraging Spatio-Temporal Dependency for Skeleton-Based Action  Recognition",
    "abstract": "Skeleton-based action recognition has attracted considerable attention due to\nits compact skeletal structure of the human body. Many recent methods have\nachieved remarkable performance using graph convolutional networks (GCNs) and\nconvolutional neural networks (CNNs), which extract spatial and temporal\nfeatures, respectively. Although spatial and temporal dependencies in the human\nskeleton have been explored, spatio-temporal dependency is rarely considered.\nIn this paper, we propose the Inter-Frame Curve Network (IFC-Net) to\neffectively leverage the spatio-temporal dependency of the human skeleton. Our\nproposed network consists of two novel elements: 1) The Inter-Frame Curve (IFC)\nmodule; and 2) Dilated Graph Convolution (D-GC). The IFC module increases the\nspatio-temporal receptive field by identifying meaningful node connections\nbetween every adjacent frame and generating spatio-temporal curves based on the\nidentified node connections. The D-GC allows the network to have a large\nspatial receptive field, which specifically focuses on the spatial domain. The\nkernels of D-GC are computed from the given adjacency matrices of the graph and\nreflect large receptive field in a way similar to the dilated CNNs. Our IFC-Net\ncombines these two modules and achieves state-of-the-art performance on three\nskeleton-based action recognition benchmarks: NTU-RGB+D 60, NTU-RGB+D 120, and\nNorthwestern-UCLA.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Jungho Lee",
      "Minhyeok Lee",
      "Suhwan Cho",
      "Sungmin Woo",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04761"
  },
  {
    "id": "arXiv:2212.04764",
    "title": "AuE-IPA: An AU Engagement Based Infant Pain Assessment Method",
    "abstract": "Recent studies have found that pain in infancy has a significant impact on\ninfant development, including psychological problems, possible brain injury,\nand pain sensitivity in adulthood. However, due to the lack of specialists and\nthe fact that infants are unable to express verbally their experience of pain,\nit is difficult to assess infant pain. Most existing infant pain assessment\nsystems directly apply adult methods to infants ignoring the differences\nbetween infant expressions and adult expressions. Meanwhile, as the study of\nfacial action coding system continues to advance, the use of action units (AUs)\nopens up new possibilities for expression recognition and pain assessment. In\nthis paper, a novel AuE-IPA method is proposed for assessing infant pain by\nleveraging different engagement levels of AUs. First, different engagement\nlevels of AUs in infant pain are revealed, by analyzing the class activation\nmap of an end-to-end pain assessment model. The intensities of top-engaged AUs\nare then used in a regression model for achieving automatic infant pain\nassessment. The model proposed is trained and experimented on YouTube\nImmunization dataset, YouTube Blood Test dataset, and iCOPEVid dataset. The\nexperimental results show that our AuE-IPA method is more applicable to infants\nand possesses stronger generalization ability than end-to-end assessment model\nand the classic PSPI metric.",
    "descriptor": "",
    "authors": [
      "Mingze Sun",
      "Haoxiang Wang",
      "Wei Yao",
      "Jiawang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04764"
  },
  {
    "id": "arXiv:2212.04765",
    "title": "Understanding Online Migration Decisions Following the Banning of  Radical Communities",
    "abstract": "The proliferation of radical online communities and their violent offshoots\nhas sparked great societal concern. However, the current practice of banning\nsuch communities from mainstream platforms has unintended consequences: (I) the\nfurther radicalization of their members in fringe platforms where they migrate;\nand (ii) the spillover of harmful content from fringe back onto mainstream\nplatforms. Here, in a large observational study on two banned subreddits,\nr/The\\_Donald and r/fatpeoplehate, we examine how factors associated with the\nRECRO radicalization framework relate to users' migration decisions.\nSpecifically, we quantify how these factors affect users' decisions to post on\nfringe platforms and, for those who do, whether they continue posting on the\nmainstream platform. Our results show that individual-level factors, those\nrelating to the behavior of users, are associated with the decision to post on\nthe fringe platform. Whereas social-level factors, users' connection with the\nradical community, only affect the propensity to be coactive on both platforms.\nOverall, our findings pave the way for evidence-based moderation policies, as\nthe decisions to migrate and remain coactive amplify unintended consequences of\ncommunity bans.",
    "descriptor": "\nComments: 19 pages, 3 figures, 3 tables\n",
    "authors": [
      "Giuseppe Russo",
      "Manoel Horta Ribeiro",
      "Giona Casiraghi",
      "Luca Verginer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.04765"
  },
  {
    "id": "arXiv:2212.04769",
    "title": "Machine Learning-based Test Selection for Simulation-based Testing of  Self-driving Cars Software",
    "abstract": "Simulation platforms facilitate the development of emerging Cyber-Physical\nSystems (CPS) like self-driving cars (SDC) because they are more efficient and\nless dangerous than field operational test cases. Despite this, thoroughly\ntesting SDCs in simulated environments remains challenging because SDCs must be\ntested in a sheer amount of long-running test cases. Past results on software\ntesting optimization have shown that not all the test cases contribute equally\nto establishing confidence in test subjects' quality and reliability, and the\nexecution of \"safe and uninformative\" test cases can be skipped to reduce\ntesting effort. However, this problem is only partially addressed in the\ncontext of SDC simulation platforms. In this paper, we investigate test\nselection strategies to increase the cost-effectiveness of simulation-based\ntesting in the context of SDCs. We propose an approach called SDC-Scissor (SDC\ncoSt-effeCtIve teSt SelectOR) that leverages Machine Learning (ML) strategies\nto identify and skip test cases that are unlikely to detect faults in SDCs\nbefore executing them.\nOur evaluation shows that SDC-Scissor outperforms the baselines. With the\nLogistic model, we achieve an accuracy of 70%, a precision of 65%, and a recall\nof 80% in selecting tests leading to a fault and improved testing\ncost-effectiveness. Specifically, SDC-Scissor avoided the execution of 50% of\nunnecessary tests as well as outperformed two baseline strategies.\nComplementary to existing work, we also integrated SDC-Scissor into the context\nof an industrial organization in the automotive domain to demonstrate how it\ncan be used in industrial settings.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2111.04666\n",
    "authors": [
      "Christian Birchler",
      "Sajad Khatiri",
      "Bill Bosshard",
      "Alessio Gambi",
      "Sebastiano Panichella"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.04769"
  },
  {
    "id": "arXiv:2212.04771",
    "title": "Taskgraph: A Low Contention OpenMP Tasking Framework",
    "abstract": "OpenMP is the de-facto standard for shared memory systems in High-Performance\nComputing (HPC). It includes a task-based model that offers a high-level of\nabstraction to effectively exploit highly dynamic structured and unstructured\nparallelism in an easy and flexible way. Unfortunately, the run-time overheads\nintroduced to manage tasks are (very) high in most common OpenMP frameworks\n(e.g., GCC, LLVM), which defeats the potential benefits of the tasking model,\nand makes it suitable for coarse-grained tasks only. This paper presents\ntaskgraph, a framework that uses a task dependency graph (TDG) to represent a\nregion of code implemented with OpenMP tasks in order to reduce the run-time\noverheads associated with the management of tasks, i.e., contention and\nparallel orchestration, including task creation and synchronization. The TDG\navoids the overheads related to the resolution of task dependencies and greatly\nreduces those deriving from the accesses to shared resources. Moreover, the\ntaskgraph framework introduces in OpenMP the record-and-replay execution model\nthat accelerates the taskgraph region from its second execution. Overall, the\nmultiple optimizations presented in this paper allow exploiting fine-grained\nOpenMP tasks to cope with the trend in current applications pointing to\nleverage massive on-node parallelism, fine-grained and dynamic scheduling\nparadigms. The framework is implemented on LLVM 15.0. Results show that the\ntaskgraph implementation outperforms the vanilla OpenMP system in terms of\nperformance and scalability, for all structured and unstructured parallelism,\nand considering coarse and fine grained tasks. Furthermore, the proposed\nframework considerably reduces the performance gap between the task and the\nthread models of OpenMP.",
    "descriptor": "",
    "authors": [
      "Chenle Yu",
      "Sara Royuela",
      "Eduardo Qui\u00f1ones"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.04771"
  },
  {
    "id": "arXiv:2212.04774",
    "title": "Model-based training of manual procedures in automated production  systems",
    "abstract": "Maintenance engineers deal with increasingly complex automated production\nsystems (aPSs). Such systems are characterized by an increasing computerization\nor the addition of robots that collaborate with human workers. The effects of\nchanging or replacing components of such systems are difficult to assess since\nthere are complex interdependencies between process parameters and the state of\nthe components. This paper proposes a model-based training system that\nvisualizes these interdependencies using domain-independent SysML models. The\ntraining system consists of a virtual training system for initial training and\nan online support system for assistance during maintenance or changeover\nprocedures. Both systems use structural SysML models to visualize the state of\nthe machine at a certain step of a procedure. An evaluation of the system in a\nchangeover procedure against a paper-based manual showed promising results\nregarding effectiveness, usability and attractiveness.",
    "descriptor": "\nComments: 25 pages, this https URL\n",
    "authors": [
      "Frieder Loch",
      "Gennadiy D. Koltun",
      "Victoria Karaseva",
      "Dorothea Pantfoerder",
      "Birgit Vogel-Heuser"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.04774"
  },
  {
    "id": "arXiv:2212.04780",
    "title": "Genie: Show Me the Data for Quantization",
    "abstract": "Zero-shot quantization is a promising approach for developing lightweight\ndeep neural networks when data is inaccessible owing to various reasons,\nincluding cost and issues related to privacy. By utilizing the learned\nparameters (statistics) of FP32-pre-trained models, zero-shot quantization\nschemes focus on generating synthetic data by minimizing the distance between\nthe learned parameters ($\\mu$ and $\\sigma$) and distributions of intermediate\nactivations. Subsequently, they distill knowledge from the pre-trained model\n(\\textit{teacher}) to the quantized model (\\textit{student}) such that the\nquantized model can be optimized with the synthetic dataset. In general,\nzero-shot quantization comprises two major elements: synthesizing datasets and\nquantizing models. However, thus far, zero-shot quantization has primarily been\ndiscussed in the context of quantization-aware training methods, which require\ntask-specific losses and long-term optimization as much as retraining. We thus\nintroduce a post-training quantization scheme for zero-shot quantization that\nproduces high-quality quantized networks within a few hours on even half an\nhour. Furthermore, we propose a framework called \\genie~that generates data\nsuited for post-training quantization. With the data synthesized by \\genie, we\ncan produce high-quality quantized models without real datasets, which is\ncomparable to few-shot quantization. We also propose a post-training\nquantization algorithm to enhance the performance of quantized models. By\ncombining them, we can bridge the gap between zero-shot and few-shot\nquantization while significantly improving the quantization performance\ncompared to that of existing approaches. In other words, we can obtain a unique\nstate-of-the-art zero-shot quantization approach.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Yongkweon Jeon",
      "Chungman Lee",
      "Ho-young Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04780"
  },
  {
    "id": "arXiv:2212.04781",
    "title": "A Bayesian Model Combination-based approach to Active Malware Analysis",
    "abstract": "Active Malware Analysis involves modeling malware behavior by executing\nactions to trigger responses and explore multiple execution paths. One of the\naims is making the action selection more efficient. This paper treats Active\nMalware Analysis as a Bayes-Active Markov Decision Process and uses a Bayesian\nModel Combination approach to train an analyzer agent. We show an improvement\nin performance against other Bayesian and stochastic approaches to Active\nMalware Analysis.",
    "descriptor": "",
    "authors": [
      "Abhilash Hota",
      "Jurgen Schonwalder"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.04781"
  },
  {
    "id": "arXiv:2212.04782",
    "title": "Music Recommendation System based on Emotion, Age and Ethnicity",
    "abstract": "A Music Recommendation System based on Emotion, Age, and Ethnicity is\ndeveloped in this study, using FER-2013 and ``Age, Gender, and Ethnicity (Face\nData) CSV'' datasets. The CNN architecture, which is extensively used for this\nkind of purpose has been applied to the training of the models. After adding\nseveral appropriate layers to the training end of the project, in total, 3\nseparate models are trained in the Deep Learning side of the project: Emotion,\nEthnicity, and Age. After the training step of these models, they are used as\nclassifiers on the web application side. The snapshot of the user taken through\nthe interface is sent to the models to predict their mood, age, and ethnic\norigin. According to these classifiers, various kinds of playlists pulled from\nSpotify API are proposed to the user in order to establish a functional and\nuser-friendly atmosphere for the music selection. Afterward, the user can\nchoose the playlist they want and listen to it by following the given link.",
    "descriptor": "\nComments: 14 Pages, 10 Figures and 3 Tables\n",
    "authors": [
      "Ramiz Mammadli",
      "Huma Bilgin",
      "Ali Can Karaca"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04782"
  },
  {
    "id": "arXiv:2212.04786",
    "title": "Image-Based Fire Detection in Industrial Environments with YOLOv4",
    "abstract": "Fires have destructive power when they break out and affect their\nsurroundings on a devastatingly large scale. The best way to minimize their\ndamage is to detect the fire as quickly as possible before it has a chance to\ngrow. Accordingly, this work looks into the potential of AI to detect and\nrecognize fires and reduce detection time using object detection on an image\nstream. Object detection has made giant leaps in speed and accuracy over the\nlast six years, making real-time detection feasible. To our end, we collected\nand labeled appropriate data from several public sources, which have been used\nto train and evaluate several models based on the popular YOLOv4 object\ndetector. Our focus, driven by a collaborating industrial partner, is to\nimplement our system in an industrial warehouse setting, which is characterized\nby high ceilings. A drawback of traditional smoke detectors in this setup is\nthat the smoke has to rise to a sufficient height. The AI models brought\nforward in this research managed to outperform these detectors by a significant\namount of time, providing precious anticipation that could help to minimize the\neffects of fires further.",
    "descriptor": "\nComments: Accepted for publication at ICPRAM\n",
    "authors": [
      "Otto Zell",
      "Joel P\u00e5lsson",
      "Kevin Hernandez-Diaz",
      "Fernando Alonso-Fernandez",
      "Felix Nilsson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04786"
  },
  {
    "id": "arXiv:2212.04789",
    "title": "On the Evolution of Boomerang Uniformity in Cryptographic S-boxes",
    "abstract": "S-boxes are an important primitive that help cryptographic algorithms to be\nresilient against various attacks. The resilience against specific attacks can\nbe connected with a certain property of an S-box, and the better the property\nvalue, the more secure the algorithm. One example of such a property is called\nboomerang uniformity, which helps to be resilient against boomerang attacks.\nHow to construct S-boxes with good boomerang uniformity is not always clear.\nThere are algebraic techniques that can result in good boomerang uniformity,\nbut the results are still rare. In this work, we explore the evolution of\nS-boxes with good values of boomerang uniformity. We consider three different\nencodings and five S-box sizes. For sizes $4\\times 4$ and $5\\times 5$, we\nmanage to obtain optimal solutions. For $6\\times 6$, we obtain optimal\nboomerang uniformity for the non-APN function. For larger sizes, the results\nindicate the problem to be very difficult (even more difficult than evolving\ndifferential uniformity, which can be considered a well-researched problem).",
    "descriptor": "\nComments: 15 pages, 3 figures, 4 tables\n",
    "authors": [
      "Marko Djurasevic",
      "Domagoj Jakobovic",
      "Luca Mariot",
      "Sihem Mesnager",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.04789"
  },
  {
    "id": "arXiv:2212.04790",
    "title": "Synthetic Data for Object Classification in Industrial Applications",
    "abstract": "One of the biggest challenges in machine learning is data collection.\nTraining data is an important part since it determines how the model will\nbehave. In object classification, capturing a large number of images per object\nand in different conditions is not always possible and can be very\ntime-consuming and tedious. Accordingly, this work explores the creation of\nartificial images using a game engine to cope with limited data in the training\ndataset. We combine real and synthetic data to train the object classification\nengine, a strategy that has shown to be beneficial to increase confidence in\nthe decisions made by the classifier, which is often critical in industrial\nsetups. To combine real and synthetic data, we first train the classifier on a\nmassive amount of synthetic data, and then we fine-tune it on real images.\nAnother important result is that the amount of real images needed for\nfine-tuning is not very high, reaching top accuracy with just 12 or 24 images\nper class. This substantially reduces the requirements of capturing a great\namount of real data.",
    "descriptor": "\nComments: Accepted for publication at ICPRAM\n",
    "authors": [
      "August Baaz",
      "Yonan Yonan",
      "Kevin Hernandez-Diaz",
      "Fernando Alonso-Fernandez",
      "Felix Nilsson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04790"
  },
  {
    "id": "arXiv:2212.04794",
    "title": "Visual Detection of Personal Protective Equipment and Safety Gear on  Industry Workers",
    "abstract": "Workplace injuries are common in today's society due to a lack of adequately\nworn safety equipment. A system that only admits appropriately equipped\npersonnel can be created to improve working conditions. The goal is thus to\ndevelop a system that will improve workers' safety using a camera that will\ndetect the usage of Personal Protective Equipment (PPE). To this end, we\ncollected and labeled appropriate data from several public sources, which have\nbeen used to train and evaluate several models based on the popular YOLOv4\nobject detector. Our focus, driven by a collaborating industrial partner, is to\nimplement our system into an entry control point where workers must present\nthemselves to obtain access to a restricted area. Combined with facial identity\nrecognition, the system would ensure that only authorized people wearing\nappropriate equipment are granted access. A novelty of this work is that we\nincrease the number of classes to five objects (hardhat, safety vest, safety\ngloves, safety glasses, and hearing protection), whereas most existing works\nonly focus on one or two classes, usually hardhats or vests. The AI model\ndeveloped provides good detection accuracy at a distance of 3 and 5 meters in\nthe collaborative environment where we aim at operating (mAP of 99/89%,\nrespectively). The small size of some objects or the potential occlusion by\nbody parts have been identified as potential factors that are detrimental to\naccuracy, which we have counteracted via data augmentation and cropping of the\nbody before applying PPE detection.",
    "descriptor": "\nComments: Accepted for publication at ICPRAM\n",
    "authors": [
      "Jonathan Karlsson",
      "Fredrik Strand",
      "Josef Bigun",
      "Fernando Alonso-Fernandez",
      "Kevin Hernandez-Diaz",
      "Felix Nilsson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04794"
  },
  {
    "id": "arXiv:2212.04798",
    "title": "Model-based control algorithms for the quadruple tank system: An  experimental comparison",
    "abstract": "We compare the performance of proportional-integral-derivative (PID) control,\nlinear model predictive control (LMPC), and nonlinear model predictive control\n(NMPC) for a physical setup of the quadruple tank system (QTS). We estimate the\nparameters in a continuous-discrete time stochastic nonlinear model for the QTS\nusing a prediction-error-method based on the measured process data and a\nmaximum likelihood (ML) criterion. In the NMPC algorithm, we use this\nidentified continuous-discrete time stochastic nonlinear model. The LMPC\nalgorithm is based on a linearization of this nonlinear model. We tune the PID\ncontroller using Skogestad's IMC tuning rules using a transfer function\nrepresentation of the linearized model. Norms of the observed tracking errors\nand the rate of change of the manipulated variables are used to compare the\nperformance of the control algorithms. The LMPC and NMPC perform better than\nthe PID controller for a predefined time-varying setpoint trajectory. The LMPC\nand NMPC algorithms have similar performance.",
    "descriptor": "\nComments: 6 pages, 5 figures, 3 tables, to be published in Foundations of Computer Aided Process Operations / Chemical Process Control (FOCAPO/CPC 2023). Hilton San Antonio Hill Country, San Antonio, Texas\n",
    "authors": [
      "Anders H. D. Andersen",
      "Tobias K. S. Ritschel",
      "Steen H\u00f8rsholt",
      "Jakob Kj\u00f8bsted Huusom",
      "John Bagterp J\u00f8rgensen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.04798"
  },
  {
    "id": "arXiv:2212.04799",
    "title": "The Subfield Codes of Some Few-Weight Linear Codes",
    "abstract": "Subfield codes of linear codes over finite fields have recently received a\nlot of attention, as some of these codes are optimal and have applications in\nsecrete sharing, authentication codes and association schemes. In this paper,\nthe $q$-ary subfield codes $\\bar{C}_{f,g}^{(q)}$ of six different families of\nlinear codes $\\bar{C}_{f,g}$ are presented, respectively. The parameters and\nweight distribution of the subfield codes and their punctured codes\n$\\bar{C}_{f,g}^{(q)}$ are explicitly determined. The parameters of the duals of\nthese codes are also studied. Some of the resultant $q$-ary codes\n$\\bar{C}_{f,g}^{(q)},$ $\\bar{C}_{f,g}^{(q)}$ and their dual codes are optimal\nand some have the best known parameters. The parameters and weight enumerators\nof the first two families of linear codes $\\bar{C}_{f,g}$ are also settled,\namong which the first family is an optimal two-weight linear code meeting the\nGriesmer bound, and the dual codes of these two families are almost MDS codes.\nAs a byproduct of this paper, a family of $[2^{4m-2},2m+1,2^{4m-3}]$ quaternary\nHermitian self-dual code are obtained with $m \\geq 2$. As an application,\nseveral infinite families of 2-designs and 3-designs are also constructed with\nthree families of linear codes of this paper.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1804.06003, arXiv:2207.07262 by other authors\n",
    "authors": [
      "Li Xu",
      "Cuiling Fan",
      "Sihem Mesnager",
      "Rong Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.04799"
  },
  {
    "id": "arXiv:2212.04800",
    "title": "AUC Maximization for Low-Resource Named Entity Recognition",
    "abstract": "Current work in named entity recognition (NER) uses either cross entropy (CE)\nor conditional random fields (CRF) as the objective/loss functions to optimize\nthe underlying NER model. Both of these traditional objective functions for the\nNER problem generally produce adequate performance when the data distribution\nis balanced and there are sufficient annotated training examples. But since NER\nis inherently an imbalanced tagging problem, the model performance under the\nlow-resource settings could suffer using these standard objective functions.\nBased on recent advances in area under the ROC curve (AUC) maximization, we\npropose to optimize the NER model by maximizing the AUC score. We give evidence\nthat by simply combining two binary-classifiers that maximize the AUC score,\nsignificant performance improvement over traditional loss functions is achieved\nunder low-resource NER settings. We also conduct extensive experiments to\ndemonstrate the advantages of our method under the low-resource and\nhighly-imbalanced data distribution settings. To the best of our knowledge,\nthis is the first work that brings AUC maximization to the NER setting.\nFurthermore, we show that our method is agnostic to different types of NER\nembeddings, models and domains. The code to replicate this work will be\nprovided upon request.",
    "descriptor": "\nComments: 10 pages, 4 figures, AAAI 2023 accepted paper\n",
    "authors": [
      "Ngoc Dang Nguyen",
      "Wei Tan",
      "Wray Buntine",
      "Richard Beare",
      "Changyou Chen",
      "Lan Du"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04800"
  },
  {
    "id": "arXiv:2212.04802",
    "title": "Efficient Convex Zone Merging in Parametric Timed Automata",
    "abstract": "Parametric timed automata are a powerful formalism for reasoning on\nconcurrent real-time systems with unknown or uncertain timing constants.\nReducing their state space is a significant way to reduce the inherently large\nanalysis times. We present here different merging reduction techniques based on\nconvex union of constraints (parametric zones), allowing to decrease the number\nof states while preserving the correctness of verification and synthesis\nresults. We perform extensive experiments, and identify the best heuristics in\npractice, bringing a significant decrease in the computation time on a\nbenchmarks library.",
    "descriptor": "\nComments: This is the author version of the manuscript of the same name published in the proceedings of the 20th International Conference on Formal Modeling and Analysis of Timed Systems (FORMATS 2022)\n",
    "authors": [
      "\u00c9tienne Andr\u00e9",
      "Dylan Marinho",
      "Laure Petrucci",
      "Jaco van de Pol"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.04802"
  },
  {
    "id": "arXiv:2212.04805",
    "title": "Understanding electricity prices beyond the merit order principle using  explainable AI",
    "abstract": "Electricity prices in liberalized markets are determined by the supply and\ndemand for electric power, which are in turn driven by various external\ninfluences that vary strongly in time. In perfect competition, the merit order\nprinciple describes that dispatchable power plants enter the market in the\norder of their marginal costs to meet the residual load, i.e. the difference of\nload and renewable generation. Many market models implement this principle to\npredict electricity prices but typically require certain assumptions and\nsimplifications. In this article, we present an explainable machine learning\nmodel for the prices on the German day-ahead market, which substantially\noutperforms a benchmark model based on the merit order principle. Our model is\ndesigned for the ex-post analysis of prices and thus builds on various external\nfeatures. Using Shapley Additive exPlanation (SHAP) values, we can disentangle\nthe role of the different features and quantify their importance from empiric\ndata. Load, wind and solar generation are most important, as expected, but wind\npower appears to affect prices stronger than solar power does. Fuel prices also\nrank highly and show nontrivial dependencies, including strong interactions\nwith other features revealed by a SHAP interaction analysis. Large generation\nramps are correlated with high prices, again with strong feature interactions,\ndue to the limited flexibility of nuclear and lignite plants. Our results\nfurther contribute to model development by providing quantitative insights\ndirectly from data.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Julius Trebbien",
      "Leonardo Rydin Gorj\u00e3o",
      "Aaron Praktiknjo",
      "Benjamin Sch\u00e4fer",
      "Dirk Witthaut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04805"
  },
  {
    "id": "arXiv:2212.04806",
    "title": "Direct sampling method to inverse wave-number-dependent source problems  (part I): determination of the support of a stationary source",
    "abstract": "This paper is concerned with a direct sampling method for imaging the support\nof a frequency-dependent source term embedded in a homogeneous and isotropic\nmedium. The source term is given by the Fourier transform of a time-dependent\nsource whose radiating period in the time domain is known.\nThe time-dependent source is supposed to be stationary in the sense that its\ncompact support does not vary along the time variable.\nVia a multi-frequency direct sampling method, we show that the smallest strip\ncontaining the source support and perpendicular to the observation direction\ncan be recovered from far-field patterns at a fixed observation angle. With\nmultiple but sparse observation directions, the shape of the convex hull of the\nsource support can be recovered. The frequency-domain analysis performed here\ncan be used to handle inverse time-dependent source problems.\nOur algorithm has low computational overhead and is robust against noise.\nNumerical experiments in both two and three dimensions have proved our\ntheoretical findings.",
    "descriptor": "",
    "authors": [
      "Hongxia Guo",
      "Guanghui Hu",
      "Mengjie Zhao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.04806"
  },
  {
    "id": "arXiv:2212.04808",
    "title": "CEPHA29: Automatic Cephalometric Landmark Detection Challenge 2023",
    "abstract": "Quantitative cephalometric analysis is the most widely used clinical and\nresearch tool in modern orthodontics. Accurate localization of cephalometric\nlandmarks enables the quantification and classification of anatomical\nabnormalities, however, the traditional manual way of marking these landmarks\nis a very tedious job. Endeavours have constantly been made to develop\nautomated cephalometric landmark detection systems but they are inadequate for\northodontic applications. The fundamental reason for this is that the amount of\npublicly available datasets as well as the images provided for training in\nthese datasets are insufficient for an AI model to perform well. To facilitate\nthe development of robust AI solutions for morphometric analysis, we organise\nthe CEPHA29 Automatic Cephalometric Landmark Detection Challenge in conjunction\nwith IEEE International Symposium on Biomedical Imaging (ISBI 2023). In this\ncontext, we provide the largest known publicly available dataset, consisting of\n1000 cephalometric X-ray images. We hope that our challenge will not only\nderive forward research and innovation in automatic cephalometric landmark\nidentification but will also signal the beginning of a new era in the\ndiscipline.",
    "descriptor": "",
    "authors": [
      "Muhammad Anwaar Khalid",
      "Kanwal Zulfiqar",
      "Ulfat Bashir",
      "Areeba Shaheen",
      "Rida Iqbal",
      "Zarnab Rizwan",
      "Ghina Rizwan",
      "Muhammad Moazam Fraz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04808"
  },
  {
    "id": "arXiv:2212.04810",
    "title": "Machine Learning Framework: Competitive Intelligence and Key Drivers  Identification of Market Share Trends Among Healthcare Facilities",
    "abstract": "The necessity of data driven decisions in healthcare strategy formulation is\nrapidly increasing. A reliable framework which helps identify factors impacting\na Healthcare Provider Facility or a Hospital (from here on termed as Facility)\nMarket Share is of key importance. This pilot study aims at developing a data\ndriven Machine Learning - Regression framework which aids strategists in\nformulating key decisions to improve the Facilitys Market Share which in turn\nimpacts in improving the quality of healthcare services. The US (United States)\nhealthcare business is chosen for the study; and the data spanning across 60\nkey Facilities in Washington State and about 3 years of historical data is\nconsidered. In the current analysis Market Share is termed as the ratio of\nfacility encounters to the total encounters among the group of potential\ncompetitor facilities. The current study proposes a novel two-pronged approach\nof competitor identification and regression approach to evaluate and predict\nmarket share, respectively. Leveraged model agnostic technique, SHAP, to\nquantify the relative importance of features impacting the market share. The\nproposed method to identify pool of competitors in current analysis, develops\nDirected Acyclic Graphs (DAGs), feature level word vectors and evaluates the\nkey connected components at facility level. This technique is robust since its\ndata driven which minimizes the bias from empirical techniques. Post\nidentifying the set of competitors among facilities, developed Regression model\nto predict the Market share. For relative quantification of features at a\nfacility level, incorporated SHAP a model agnostic explainer. This helped to\nidentify and rank the attributes at each facility which impacts the market\nshare.",
    "descriptor": "\nComments: 7 Pages 5 figures 6 tables To appear in ICHA 2022\n",
    "authors": [
      "Anudeep Appe",
      "Bhanu Poluparthi",
      "Lakshmi Kasivajjula",
      "Udai Mv",
      "Sobha Bagadi",
      "Punya Modi",
      "Aditya Singh",
      "Hemanth Gunupudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.04810"
  },
  {
    "id": "arXiv:2212.04812",
    "title": "Reliable Multimodal Trajectory Prediction via Error Aligned Uncertainty  Optimization",
    "abstract": "Reliable uncertainty quantification in deep neural networks is very crucial\nin safety-critical applications such as automated driving for trustworthy and\ninformed decision-making. Assessing the quality of uncertainty estimates is\nchallenging as ground truth for uncertainty estimates is not available.\nIdeally, in a well-calibrated model, uncertainty estimates should perfectly\ncorrelate with model error. We propose a novel error aligned uncertainty\noptimization method and introduce a trainable loss function to guide the models\nto yield good quality uncertainty estimates aligning with the model error. Our\napproach targets continuous structured prediction and regression tasks, and is\nevaluated on multiple datasets including a large-scale vehicle motion\nprediction task involving real-world distributional shifts. We demonstrate that\nour method improves average displacement error by 1.69% and 4.69%, and the\nuncertainty correlation with model error by 17.22% and 19.13% as quantified by\nPearson correlation coefficient on two state-of-the-art baselines.",
    "descriptor": "\nComments: Accepted to ECCV 2022 workshop - Safe Artificial Intelligence for Automated Driving\n",
    "authors": [
      "Neslihan Kose",
      "Ranganath Krishnan",
      "Akash Dhamasia",
      "Omesh Tickoo",
      "Michael Paulitsch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04812"
  },
  {
    "id": "arXiv:2212.04816",
    "title": "DUNE: Improving Accuracy for Sketch-INT Network Measurement Systems",
    "abstract": "In-band Network Telemetry (INT) and sketching algorithms are two promising\ndirections for measuring network traffics in real time. To combine sketch with\nINT and preserve their advantages, a representative approach is to use INT to\nsend a switch sketch in small pieces (called sketchlets) to end-host for\nreconstructing an identical sketch. However, in this paper, we reveal that when\nnaively selecting buckets to sketchlets, the end-host reconstructed sketch is\ninaccurate. To overcome this problem, we present DUNE, an innovative sketch-INT\nnetwork measurement system. DUNE incorporates two key innovations: First, we\ndesign a novel scatter sketchlet that is more efficient in transferring\nmeasurement data by allowing a switch to select individual buckets to add to\nsketchlets; Second, we propose lightweight data structures for tracing\n\"freshness\" of the sketch buckets, and present algorithms for smartly selecting\nbuckets that contain valuable measurement data to send to end-host. We\ntheoretically prove the effectiveness of our proposed methods, and implement a\nprototype on commodity programmable switch. The results of extensive\nexperiments driven by real-world traffics on DUNE suggest that our proposed\nsystem can substantially improve the measurement accuracy at a trivial cost.",
    "descriptor": "\nComments: Technical report for the paper published in IEEE INFOCOM 2023\n",
    "authors": [
      "Zhongxiang Wei",
      "Ye Tian",
      "Wei Chen",
      "Liyuan Gu",
      "Xinming Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.04816"
  },
  {
    "id": "arXiv:2212.04818",
    "title": "Parallelism detection using graph labelling",
    "abstract": "Usage of multiprocessor and multicore computers implies parallel programming.\nTools for preparing parallel programs include parallel languages and libraries\nas well as parallelizing compilers and convertors that can perform automatic\nparallelization. The basic approach for parallelism detection is analysis of\ndata dependencies and properties of program components, including data use and\npredicates. In this article a suite of used data and predicates sets for\nprogram components is proposed and an algorithm for computing these sets is\nsuggested. The algorithm is based on wave propagation on graphs with cycles and\nlabelling. This method allows analyzing complex program components, improving\ndata localization and thus providing enhanced data parallelism detection.",
    "descriptor": "",
    "authors": [
      "Pavel Telegin",
      "Anton Baranov",
      "Boris Shabanov",
      "Artem Tikhomirov"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2212.04818"
  },
  {
    "id": "arXiv:2212.04819",
    "title": "Phone2Proc: Bringing Robust Robots Into Our Chaotic World",
    "abstract": "Training embodied agents in simulation has become mainstream for the embodied\nAI community. However, these agents often struggle when deployed in the\nphysical world due to their inability to generalize to real-world environments.\nIn this paper, we present Phone2Proc, a method that uses a 10-minute phone scan\nand conditional procedural generation to create a distribution of training\nscenes that are semantically similar to the target environment. The generated\nscenes are conditioned on the wall layout and arrangement of large objects from\nthe scan, while also sampling lighting, clutter, surface textures, and\ninstances of smaller objects with randomized placement and materials.\nLeveraging just a simple RGB camera, training with Phone2Proc shows massive\nimprovements from 34.7% to 70.7% success rate in sim-to-real ObjectNav\nperformance across a test suite of over 200 trials in diverse real-world\nenvironments, including homes, offices, and RoboTHOR. Furthermore, Phone2Proc's\ndiverse distribution of generated scenes makes agents remarkably robust to\nchanges in the real world, such as human movement, object rearrangement,\nlighting changes, or clutter.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Matt Deitke",
      "Rose Hendrix",
      "Luca Weihs",
      "Ali Farhadi",
      "Kiana Ehsani",
      "Aniruddha Kembhavi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04819"
  },
  {
    "id": "arXiv:2212.04820",
    "title": "Pose Estimation for Human Wearing Loose-Fitting Clothes: Obtaining  Ground Truth Posture Using HFR Camera and Blinking LEDs",
    "abstract": "Human pose estimation, particularly in athletes, can help improve their\nperformance. However, this estimation is difficult using existing methods, such\nas human annotation, if the subjects wear loose-fitting clothes such as\nski/snowboard wears. This study developed a method for obtaining the ground\ntruth data on two-dimensional (2D) poses of a human wearing loose-fitting\nclothes. This method uses fast-flushing light-emitting diodes (LEDs). The\nsubjects were required to wear loose-fitting clothes and place the LED on the\ntarget joints. The LEDs were observed directly using a camera by selecting thin\nfilmy loose-fitting clothes. The proposed method captures the scene at 240 fps\nby using a high-frame-rate camera and renders two 30 fps image sequences by\nextracting LED-on and -off frames. The temporal differences between the two\nvideo sequences can be ignored, considering the speed of human motion. The\nLED-on video was used to manually annotate the joints and thus obtain the\nground truth data. Additionally, the LED-off video, equivalent to a standard\nvideo at 30 fps, confirmed the accuracy of existing machine learning-based\nmethods and manual annotations. Experiments demonstrated that the proposed\nmethod can obtain ground truth data for standard RGB videos. Further, it was\nrevealed that neither manual annotation nor the state-of-the-art pose estimator\nobtains the correct position of target joints.",
    "descriptor": "\nComments: Extended abstract of WACV2023 workshop on Computer Vision 4 Winter Sports\n",
    "authors": [
      "Takayoshi Yamaguchi",
      "Dan Mikami",
      "Seiji Matsumura",
      "Naoki Saijo",
      "Makio Kashino"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04820"
  },
  {
    "id": "arXiv:2212.04821",
    "title": "PromptonomyViT: Multi-Task Prompt Learning Improves Video Transformers  using Synthetic Scene Data",
    "abstract": "Action recognition models have achieved impressive results by incorporating\nscene-level annotations, such as objects, their relations, 3D structure, and\nmore. However, obtaining annotations of scene structure for videos requires a\nsignificant amount of effort to gather and annotate, making these methods\nexpensive to train. In contrast, synthetic datasets generated by graphics\nengines provide powerful alternatives for generating scene-level annotations\nacross multiple tasks. In this work, we propose an approach to leverage\nsynthetic scene data for improving video understanding. We present a multi-task\nprompt learning approach for video transformers, where a shared video\ntransformer backbone is enhanced by a small set of specialized parameters for\neach task. Specifically, we add a set of ``task prompts'', each corresponding\nto a different task, and let each prompt predict task-related annotations. This\ndesign allows the model to capture information shared among synthetic scene\ntasks as well as information shared between synthetic scene tasks and a real\nvideo downstream task throughout the entire network. We refer to this approach\nas ``Promptonomy'', since the prompts model a task-related structure. We\npropose the PromptonomyViT model (PViT), a video transformer that incorporates\nvarious types of scene-level information from synthetic data using the\n``Promptonomy'' approach. PViT shows strong performance improvements on\nmultiple video understanding tasks and datasets.",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Roei Herzig",
      "Ofir Abramovich",
      "Elad Ben-Avraham",
      "Assaf Arbelle",
      "Leonid Karlinsky",
      "Ariel Shamir",
      "Trevor Darrell",
      "Amir Globerson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04821"
  },
  {
    "id": "arXiv:2212.04823",
    "title": "GazeNeRF: 3D-Aware Gaze Redirection with Neural Radiance Fields",
    "abstract": "We propose GazeNeRF, a 3D-aware method for the task of gaze redirection.\nExisting gaze redirection methods operate on 2D images and struggle to generate\n3D consistent results. Instead, we build on the intuition that the face region\nand eyeballs are separate 3D structures that move in a coordinated yet\nindependent fashion. Our method leverages recent advancements in conditional\nimage-based neural radiance fields and proposes a two-stream architecture that\npredicts volumetric features for the face and eye regions separately. Rigidly\ntransforming the eye features via a 3D rotation matrix provides fine-grained\ncontrol over the desired gaze angle. The final, redirected image is then\nattained via differentiable volume compositing. Our experiments show that this\narchitecture outperforms naively conditioned NeRF baselines as well as previous\nstate-of-the-art 2D gaze redirection methods in terms of redirection accuracy\nand identity preservation.",
    "descriptor": "",
    "authors": [
      "Alessandro Ruzzi",
      "Xiangwei Shi",
      "Xi Wang",
      "Gengyan Li",
      "Shalini De Mello",
      "Hyung Jin Chang",
      "Xucong Zhang",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04823"
  },
  {
    "id": "arXiv:2212.04824",
    "title": "Reinforcement Learning and Mixed-Integer Programming for Power Plant  Scheduling in Low Carbon Systems: Comparison and Hybridisation",
    "abstract": "Decarbonisation is driving dramatic growth in renewable power generation.\nThis increases uncertainty in the load to be served by power plants and makes\ntheir efficient scheduling, known as the unit commitment (UC) problem, more\ndifficult. UC is solved in practice by mixed-integer programming (MIP) methods;\nhowever, there is growing interest in emerging data-driven methods including\nreinforcement learning (RL). In this paper, we extensively test two MIP\n(deterministic and stochastic) and two RL (model-free and with lookahead)\nscheduling methods over a large set of test days and problem sizes, for the\nfirst time comparing the state-of-the-art of these two approaches on a level\nplaying field. We find that deterministic and stochastic MIP consistently\nproduce lower-cost UC schedules than RL, exhibiting better reliability and\nscalability with problem size. Average operating costs of RL are more than 2\ntimes larger than stochastic MIP for a 50-generator test case, while the cost\nis 13 times larger in the worst instance. However, the key strength of RL is\nthe ability to produce solutions practically instantly, irrespective of problem\nsize. We leverage this advantage to produce various initial solutions for warm\nstarting concurrent stochastic MIP solves. By producing several near-optimal\nsolutions simultaneously and then evaluating them using Monte Carlo methods,\nthe differences between the true cost function and the discrete approximation\nrequired to formulate the MIP are exploited. The resulting hybrid technique\noutperforms both the RL and MIP methods individually, reducing total operating\ncosts by 0.3% on average.",
    "descriptor": "\nComments: Submitted to Applied Energy, Dec 2022\n",
    "authors": [
      "Cormac O'Malley",
      "Patrick de Mars",
      "Luis Badesa",
      "Goran Strbac"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.04824"
  },
  {
    "id": "arXiv:2212.04825",
    "title": "A Whac-A-Mole Dilemma: Shortcuts Come in Multiples Where Mitigating One  Amplifies Others",
    "abstract": "Machine learning models have been found to learn shortcuts -- unintended\ndecision rules that are unable to generalize -- undermining models'\nreliability. Previous works address this problem under the tenuous assumption\nthat only a single shortcut exists in the training data. Real-world images are\nrife with multiple visual cues from background to texture. Key to advancing the\nreliability of vision systems is understanding whether existing methods can\novercome multiple shortcuts or struggle in a Whac-A-Mole game, i.e., where\nmitigating one shortcut amplifies reliance on others. To address this\nshortcoming, we propose two benchmarks: 1) UrbanCars, a dataset with precisely\ncontrolled spurious cues, and 2) ImageNet-W, an evaluation set based on\nImageNet for watermark, a shortcut we discovered affects nearly every modern\nvision model. Along with texture and background, ImageNet-W allows us to study\nmultiple shortcuts emerging from training on natural images. We find computer\nvision models, including large foundation models -- regardless of training set,\narchitecture, and supervision -- struggle when multiple shortcuts are present.\nEven methods explicitly designed to combat shortcuts struggle in a Whac-A-Mole\ndilemma. To tackle this challenge, we propose Last Layer Ensemble, a\nsimple-yet-effective method to mitigate multiple shortcuts without Whac-A-Mole\nbehavior. Our results surface multi-shortcut mitigation as an overlooked\nchallenge critical to advancing the reliability of vision systems. The datasets\nand code are released: https://github.com/facebookresearch/Whac-A-Mole.git.",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Zhiheng Li",
      "Ivan Evtimov",
      "Albert Gordo",
      "Caner Hazirbas",
      "Tal Hassner",
      "Cristian Canton Ferrer",
      "Chenliang Xu",
      "Mark Ibrahim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04825"
  },
  {
    "id": "arXiv:2212.04830",
    "title": "Introduction of an Assistance System to Support Domain Experts in  Programming Low-code to Leverage Industry 5.0",
    "abstract": "The rapid technological leaps of Industry 4.0 increase the pressure and\ndemands on humans working in automation, which is one of the main motivators of\nIndustry 5.0. In particular, automation software development for mechatronic\nsystems becomes increasingly challenging, as both domain knowledge and\nprogramming skills are required for high-quality, maintainable software.\nEspecially for small companies from automation and robotics without dedicated\nsoftware engineering departments, domain-specific low-code platforms become\nindispensable that enable domain experts to develop code intuitively using\nvisual programming languages, e.g., for tasks such as retrofitting mobile\nmachines. However, for extensive functionalities, visual programs may become\noverwhelming due to the scaling-up problem. In addition, the ever-shortening\ntime-to-market increases the time pressure on programmers. Thus, an assistance\nsystem concept is introduced that can be implemented by low-code platform\nsuppliers based on combining data mining and static code analysis. Domain\nexperts are supported in developing low-code by targeted recommendations,\nmetric-based complexity measurement, and reducing complexity by encapsulating\nfunctionalities. The concept is implemented for the industrial low-code\nplatform HAWE eDesign to program hydraulic components in mobile machines, and\nits benefits are confirmed in a user study and an industrial expert workshop.",
    "descriptor": "\nComments: 8 pages, this https URL\n",
    "authors": [
      "Eva-Maria Neumann",
      "Birgit Vogel-Heuser",
      "Fabian Haben",
      "Marius Krueger",
      "Timotheus Wieringa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.04830"
  },
  {
    "id": "arXiv:2212.04842",
    "title": "PIVOT: Prompting for Video Continual Learning",
    "abstract": "Modern machine learning pipelines are limited due to data availability,\nstorage quotas, privacy regulations, and expensive annotation processes. These\nconstraints make it difficult or impossible to maintain a large-scale model\ntrained on growing annotation sets. Continual learning directly approaches this\nproblem, with the ultimate goal of devising methods where a neural network\neffectively learns relevant patterns for new (unseen) classes without\nsignificantly altering its performance on previously learned ones. In this\npaper, we address the problem of continual learning for video data. We\nintroduce PIVOT, a novel method that leverages the extensive knowledge in\npre-trained models from the image domain, thereby reducing the number of\ntrainable parameters and the associated forgetting. Unlike previous methods,\nours is the first approach that effectively uses prompting mechanisms for\ncontinual learning without any in-domain pre-training. Our experiments show\nthat PIVOT improves state-of-the-art methods by a significant 27% on the\n20-task ActivityNet setup.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Andr\u00e9s Villa",
      "Juan Le\u00f3n Alc\u00e1zar",
      "Motasem Alfarra",
      "Kumail Alhamoud",
      "Julio Hurtado",
      "Fabian Caba Heilbron",
      "Alvaro Soto",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04842"
  },
  {
    "id": "arXiv:2212.04843",
    "title": "CopAS: A Big Data Forensic Analytics System",
    "abstract": "With the advancing digitization of our society, network security has become\none of the critical concerns for most organizations. In this paper, we present\nCopAS, a system targeted at Big Data forensics analysis, allowing network\noperators to comfortably analyze and correlate large amounts of network data to\nget insights about potentially malicious and suspicious events. We demonstrate\nthe practical usage of CopAS for insider threat detection on a publicly\navailable PCAP dataset and show how the system can be used to detect insiders\nhiding their malicious activity in the large amounts of networking data streams\ngenerated during the daily activities of an organization.",
    "descriptor": "",
    "authors": [
      "Martin Macak",
      "Matus Stovcik",
      "Tomas Rebok",
      "Mouzhi Ge",
      "Bruno Rossi",
      "Barbora Buhnova"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.04843"
  },
  {
    "id": "arXiv:2212.04844",
    "title": "Album cover art image generation with Generative Adversarial Networks",
    "abstract": "Generative Adversarial Networks (GANs) were introduced by Goodfellow in 2014,\nand since then have become popular for constructing generative artificial\nintelligence models. However, the drawbacks of such networks are numerous, like\ntheir longer training times, their sensitivity to hyperparameter tuning,\nseveral types of loss and optimization functions and other difficulties like\nmode collapse. Current applications of GANs include generating photo-realistic\nhuman faces, animals and objects. However, I wanted to explore the artistic\nability of GANs in more detail, by using existing models and learning from\nthem. This dissertation covers the basics of neural networks and works its way\nup to the particular aspects of GANs, together with experimentation and\nmodification of existing available models, from least complex to most. The\nintention is to see if state of the art GANs (specifically StyleGAN2) can\ngenerate album art covers and if it is possible to tailor them by genre. This\nwas attempted by first familiarizing myself with 3 existing GANs architectures,\nincluding the state of the art StyleGAN2. The StyleGAN2 code was used to train\na model with a dataset containing 80K album cover images, then used to style\nimages by picking curated images and mixing their styles.",
    "descriptor": "",
    "authors": [
      "Felipe Perez Stoppa",
      "Ester Vida\u00f1a-Vila",
      "Joan Navarro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.04844"
  },
  {
    "id": "arXiv:2212.04849",
    "title": "Closed pattern mining of interval data and distributional data",
    "abstract": "We discuss pattern languages for closed pattern mining and learning of\ninterval data and distributional data. We first introduce pattern languages\nrelying on pairs of intersection-based constraints or pairs of inclusion based\nconstraints, or both, applied to intervals. We discuss the encoding of such\ninterval patterns as itemsets thus allowing to use closed itemsets mining and\nformal concept analysis programs. We experiment these languages on clustering\nand supervised learning tasks. Then we show how to extend the approach to\naddress distributional data.",
    "descriptor": "\nComments: 15p\n",
    "authors": [
      "Henry Soldano",
      "Guillaume Santini",
      "Stella Zevio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04849"
  },
  {
    "id": "arXiv:2212.04851",
    "title": "A perspective on physical reservoir computing with nanomagnetic devices",
    "abstract": "Neural networks have revolutionized the area of artificial intelligence and\nintroduced transformative applications to almost every scientific field and\nindustry. However, this success comes at a great price; the energy requirements\nfor training advanced models are unsustainable. One promising way to address\nthis pressing issue is by developing low-energy neuromorphic hardware that\ndirectly supports the algorithm's requirements. The intrinsic non-volatility,\nnon-linearity, and memory of spintronic devices make them appealing candidates\nfor neuromorphic devices. Here we focus on the reservoir computing paradigm, a\nrecurrent network with a simple training algorithm suitable for computation\nwith spintronic devices since they can provide the properties of non-linearity\nand memory. We review technologies and methods for developing neuromorphic\nspintronic devices and conclude with critical open issues to address before\nsuch devices become widely used.",
    "descriptor": "",
    "authors": [
      "Dan A Allwood",
      "Matthew O A Ellis",
      "David Griffin",
      "Thomas J Hayward",
      "Luca Manneschi",
      "Mohammad F KH Musameh",
      "Simon O'Keefe",
      "Susan Stepney",
      "Charles Swindells",
      "Martin A Trefzer",
      "Eleni Vasilaki",
      "Guru Venkat",
      "Ian Vidamour",
      "Chester Wringe"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.04851"
  },
  {
    "id": "arXiv:2212.04854",
    "title": "Improving transferability between different engineering stages in the  development of automated material flow modules",
    "abstract": "For improving flexibility and robustness of the engineering of automated\nproduction systems (aPS) in case of extending, reducing or modifying parts,\nseveral approaches propose an encapsulation and clustering of related\nfunctions, e.g. from the electrical, mechanical or software engineering, based\non a modular architecture. Considering the development of these modules, there\nare different stages, e.g. module planning or functional engineering, which\nhave to be completed. A reference model that addresses the different stages for\nthe engineering of aPS is proposed by AutomationML. Due to these different\nstages and the integration of several engineering disciplines, e.g. mechanical,\nelectrical/electronic or software engineering, information not limited to one\ndiscipline are stored redundantly increasing the effort to transfer information\nand the risk of inconsistency. Although, data formats for the storage and\nexchange of plant engineering information exist, e.g. AutomationML, fixed\ndomain specific structures and relations of the information, e.g. for automated\nmaterial flow systems (aMFS), are missing. This paper presents the integration\nof a meta model into the development of modules for aMFS to improve the\ntransferability and consistency of information between the different\nengineering stages and the increasing level of detail from the coarse-grained\nplant planning to the fine-grained functional engineering.",
    "descriptor": "\nComments: 11 pages, this https URL\n",
    "authors": [
      "Daniel Regulin",
      "Thomas Aicher",
      "Birgit Vogel-Heuser"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.04854"
  },
  {
    "id": "arXiv:2212.04858",
    "title": "Predictor networks and stop-grads provide implicit variance  regularization in BYOL/SimSiam",
    "abstract": "Self-supervised learning (SSL) learns useful representations from unlabelled\ndata by training networks to be invariant to pairs of augmented versions of the\nsame input. Non-contrastive methods avoid collapse either by directly\nregularizing the covariance matrix of network outputs or through asymmetric\nloss architectures, two seemingly unrelated approaches. Here, by building on\nDirectPred, we lay out a theoretical framework that reconciles these two views.\nWe derive analytical expressions for the representational learning dynamics in\nlinear networks. By expressing them in the eigenspace of the embedding\ncovariance matrix, where the solutions decouple, we reveal the mechanism and\nconditions that provide implicit variance regularization. These insights allow\nus to formulate a new isotropic loss function that equalizes eigenvalue\ncontribution and renders learning more robust. Finally, we show empirically\nthat our findings translate to nonlinear networks trained on CIFAR-10 and\nSTL-10.",
    "descriptor": "",
    "authors": [
      "Manu Srinath Halvagal",
      "Axel Laborieux",
      "Friedemann Zenke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2212.04858"
  },
  {
    "id": "arXiv:2212.04864",
    "title": "A Comparative Performance Analysis of Explainable Machine Learning  Models With And Without RFECV Feature Selection Technique Towards Ransomware  Classification",
    "abstract": "Ransomware has emerged as one of the major global threats in recent days. The\nalarming increasing rate of ransomware attacks and new ransomware variants\nintrigue the researchers in this domain to constantly examine the\ndistinguishing traits of ransomware and refine their detection or\nclassification strategies. Among the broad range of different behavioral\ncharacteristics, the trait of Application Programming Interface (API) calls and\nnetwork behaviors have been widely utilized as differentiating factors for\nransomware detection, or classification. Although many of the prior approaches\nhave shown promising results in detecting and classifying ransomware families\nutilizing these features without applying any feature selection techniques,\nfeature selection, however, is one of the potential steps toward an efficient\ndetection or classification Machine Learning model because it reduces the\nprobability of overfitting by removing redundant data, improves the model's\naccuracy by eliminating irrelevant features, and therefore reduces training\ntime. There have been a good number of feature selection techniques to date\nthat are being used in different security scenarios to optimize the performance\nof the Machine Learning models. Hence, the aim of this study is to present the\ncomparative performance analysis of widely utilized Supervised Machine Learning\nmodels with and without RFECV feature selection technique towards ransomware\nclassification utilizing the API call and network traffic features. Thereby,\nthis study provides insight into the efficiency of the RFECV feature selection\ntechnique in the case of ransomware classification which can be used by peers\nas a reference for future work in choosing the feature selection technique in\nthis domain.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2210.11235\n",
    "authors": [
      "Rawshan Ara Mowri",
      "Madhuri Siddula",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.04864"
  },
  {
    "id": "arXiv:2212.04865",
    "title": "Polynomial Distributions and Transformations",
    "abstract": "Polynomials are common algebraic structures, which are often used to\napproximate functions including probability distributions. This paper proposes\nto directly define polynomial distributions in order to describe stochastic\nproperties of systems rather than to assume polynomials for only approximating\nknown or empirically estimated distributions. Polynomial distributions offer a\ngreat modeling flexibility, and often, also mathematical tractability. However,\nunlike canonical distributions, polynomial functions may have non-negative\nvalues in the interval of support for some parameter values, the number of\ntheir parameters is usually much larger than for canonical distributions, and\nthe interval of support must be finite. In particular, polynomial distributions\nare defined here assuming three forms of polynomial function. The\ntransformation of polynomial distributions and fitting a histogram to a\npolynomial distribution are considered. The key properties of polynomial\ndistributions are derived in closed-form. A piecewise polynomial distribution\nconstruction is devised to ensure that it is non-negative over the support\ninterval. Finally, the problems of estimating parameters of polynomial\ndistributions and generating polynomially distributed samples are also studied.",
    "descriptor": "\nComments: 21 pages, no figures\n",
    "authors": [
      "Yue Yu",
      "Pavel Loskot"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2212.04865"
  },
  {
    "id": "arXiv:2212.04866",
    "title": "Deep Learning of Causal Structures in High Dimensions",
    "abstract": "Recent years have seen rapid progress at the intersection between causality\nand machine learning. Motivated by scientific applications involving\nhigh-dimensional data, in particular in biomedicine, we propose a deep neural\narchitecture for learning causal relationships between variables from a\ncombination of empirical data and prior causal knowledge. We combine\nconvolutional and graph neural networks within a causal risk framework to\nprovide a flexible and scalable approach. Empirical results include linear and\nnonlinear simulations (where the underlying causal structures are known and can\nbe directly compared against), as well as a real biological example where the\nmodels are applied to high-dimensional molecular data and their output compared\nagainst entirely unseen validation experiments. These results demonstrate the\nfeasibility of using deep learning approaches to learn causal networks in\nlarge-scale problems spanning thousands of variables.",
    "descriptor": "",
    "authors": [
      "Kai Lagemann",
      "Christian Lagemann",
      "Bernd Taschler",
      "Sach Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04866"
  },
  {
    "id": "arXiv:2212.04868",
    "title": "Frugal Reinforcement-based Active Learning",
    "abstract": "Most of the existing learning models, particularly deep neural networks, are\nreliant on large datasets whose hand-labeling is expensive and time demanding.\nA current trend is to make the learning of these models frugal and less\ndependent on large collections of labeled data. Among the existing solutions,\ndeep active learning is currently witnessing a major interest and its purpose\nis to train deep networks using as few labeled samples as possible. However,\nthe success of active learning is highly dependent on how critical are these\nsamples when training models. In this paper, we devise a novel active learning\napproach for label-efficient training. The proposed method is iterative and\naims at minimizing a constrained objective function that mixes diversity,\nrepresentativity and uncertainty criteria. The proposed approach is\nprobabilistic and unifies all these criteria in a single objective function\nwhose solution models the probability of relevance of samples (i.e., how\ncritical) when learning a decision function. We also introduce a novel\nweighting mechanism based on reinforcement learning, which adaptively balances\nthese criteria at each training iteration, using a particular stateless\nQ-learning model. Extensive experiments conducted on staple image\nclassification data, including Object-DOTA, show the effectiveness of our\nproposed model w.r.t. several baselines including random, uncertainty and flat\nas well as other work.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.11564\n",
    "authors": [
      "Sebastien Deschamps",
      "Hichem Sahbi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04868"
  },
  {
    "id": "arXiv:2212.04869",
    "title": "RCDT: Relational Remote Sensing Change Detection with Transformer",
    "abstract": "Deep learning based change detection methods have received wide attentoion,\nthanks to their strong capability in obtaining rich features from images.\nHowever, existing AI-based CD methods largely rely on three\nfunctionality-enhancing modules, i.e., semantic enhancement, attention\nmechanisms, and correspondence enhancement. The stacking of these modules leads\nto great model complexity. To unify these three modules into a simple pipeline,\nwe introduce Relational Change Detection Transformer (RCDT), a novel and simple\nframework for remote sensing change detection tasks. The proposed RCDT consists\nof three major components, a weight-sharing Siamese Backbone to obtain\nbi-temporal features, a Relational Cross Attention Module (RCAM) that\nimplements offset cross attention to obtain bi-temporal relation-aware\nfeatures, and a Features Constrain Module (FCM) to achieve the final refined\npredictions with high-resolution constraints. Extensive experiments on four\ndifferent publically available datasets suggest that our proposed RCDT exhibits\nsuperior change detection performance compared with other competing methods.\nThe therotical, methodogical, and experimental knowledge of this study is\nexpected to benefit future change detection efforts that involve the cross\nattention mechanism.",
    "descriptor": "\nComments: 18 pages, 11 figures,\n",
    "authors": [
      "Kaixuan Lu",
      "Xiao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04869"
  },
  {
    "id": "arXiv:2212.04871",
    "title": "Spurious Features Everywhere -- Large-Scale Detection of Harmful  Spurious Features in ImageNet",
    "abstract": "Benchmark performance of deep learning classifiers alone is not a reliable\npredictor for the performance of a deployed model. In particular, if the image\nclassifier has picked up spurious features in the training data, its\npredictions can fail in unexpected ways. In this paper, we develop a framework\nthat allows us to systematically identify spurious features in large datasets\nlike ImageNet. It is based on our neural PCA components and their\nvisualization. Previous work on spurious features of image classifiers often\noperates in toy settings or requires costly pixel-wise annotations. In\ncontrast, we validate our results by checking that presence of the harmful\nspurious feature of a class is sufficient to trigger the prediction of that\nclass. We introduce a novel dataset \"Spurious ImageNet\" and check how much\nexisting classifiers rely on spurious features.",
    "descriptor": "",
    "authors": [
      "Yannic Neuhaus",
      "Maximilian Augustin",
      "Valentyn Boreiko",
      "Matthias Hein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04871"
  },
  {
    "id": "arXiv:2212.04873",
    "title": "Multimodal Prototype-Enhanced Network for Few-Shot Action Recognition",
    "abstract": "Current methods for few-shot action recognition mainly fall into the metric\nlearning framework following ProtoNet. However, they either ignore the effect\nof representative prototypes or fail to enhance the prototypes with multimodal\ninformation adequately. In this work, we propose a novel Multimodal\nPrototype-Enhanced Network (MORN) to use the semantic information of label\ntexts as multimodal information to enhance prototypes, including two modality\nflows. A CLIP visual encoder is introduced in the visual flow, and visual\nprototypes are computed by the Temporal-Relational CrossTransformer (TRX)\nmodule. A frozen CLIP text encoder is introduced in the text flow, and a\nsemantic-enhanced module is used to enhance text features. After inflating,\ntext prototypes are obtained. The final multimodal prototypes are then computed\nby a multimodal prototype-enhanced module. Besides, there exist no evaluation\nmetrics to evaluate the quality of prototypes. To the best of our knowledge, we\nare the first to propose a prototype evaluation metric called Prototype\nSimilarity Difference (PRIDE), which is used to evaluate the performance of\nprototypes in discriminating different categories. We conduct extensive\nexperiments on four popular datasets. MORN achieves state-of-the-art results on\nHMDB51, UCF101, Kinetics and SSv2. MORN also performs well on PRIDE, and we\nexplore the correlation between PRIDE and accuracy.",
    "descriptor": "",
    "authors": [
      "Xinzhe Ni",
      "Hao Wen",
      "Yong Liu",
      "Yatai Ji",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04873"
  },
  {
    "id": "arXiv:2212.04875",
    "title": "Expeditious Saliency-guided Mix-up through Random Gradient Thresholding",
    "abstract": "Mix-up training approaches have proven to be effective in improving the\ngeneralization ability of Deep Neural Networks. Over the years, the research\ncommunity expands mix-up methods into two directions, with extensive efforts to\nimprove saliency-guided procedures but minimal focus on the arbitrary path,\nleaving the randomization domain unexplored. In this paper, inspired by the\nsuperior qualities of each direction over one another, we introduce a novel\nmethod that lies at the junction of the two routes. By combining the best\nelements of randomness and saliency utilization, our method balances speed,\nsimplicity, and accuracy. We name our method R-Mix following the concept of\n\"Random Mix-up\". We demonstrate its effectiveness in generalization, weakly\nsupervised object localization, calibration, and robustness to adversarial\nattacks. Finally, in order to address the question of whether there exists a\nbetter decision protocol, we train a Reinforcement Learning agent that decides\nthe mix-up policies based on the classifier's performance, reducing dependency\non human-designed objectives and hyperparameter tuning. Extensive experiments\nfurther show that the agent is capable of performing at the cutting-edge level,\nlaying the foundation for a fully automatic mix-up. Our code is released at\n[https://github.com/minhlong94/Random-Mixup].",
    "descriptor": "\nComments: Accepted Long paper at 2nd Practical-DL Workshop at AAAI 2023\n",
    "authors": [
      "Minh-Long Luu",
      "Zeyi Huang",
      "Eric P. Xing",
      "Yong Jae Lee",
      "Haohan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04875"
  },
  {
    "id": "arXiv:2212.04877",
    "title": "Industry Best Practices in Robotics Software Engineering",
    "abstract": "Robotics software is pushing the limits of software engineering practice. The\n3rd International Workshop on Robotics Software Engineering held a panel on\n\"the best practices for robotic software engineering\". This article shares the\nkey takeaways that emerged from the discussion among the panelists and the\nworkshop, ranging from architecting practices at the NASA/Caltech Jet\nPropulsion Laboratory, model-driven development at Bosch, development and\ntesting of autonomous driving systems at Waymo, and testing of robotics\nsoftware at XITASO. Researchers and practitioners can build on the contents of\nthis paper to gain a fresh perspective on their activities and focus on the\nmost pressing practices and challenges in developing robotics software today.",
    "descriptor": "\nComments: 10 pages, 0 figures\n",
    "authors": [
      "Robert Bocchino",
      "Arne Nordmann",
      "Allison Thackston",
      "Andreas Angerer",
      "Federico Ciccozzi",
      "Ivano Malavolta",
      "Andreas Wortmann"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.04877"
  },
  {
    "id": "arXiv:2212.04878",
    "title": "Towards a Formal Specification Framework for Manufacturing Execution  Systems",
    "abstract": "Manufacturing Execution Systems (MES) optimize production and business\nprocesses at the same time. However, the engineering and specification of MES\nis a challenging, interdisciplinary process. Especially IT and production\nexperts with different views and background have to cooperate. For successful\nand efficient MES software projects, misunderstandings in the specification\nprocess have to be avoided. Therefore, textual specifications need to be\ncomplemented by unambiguous graphical models, reducing the complexity by\nintegrating interdisciplinary views and domain specific terms based on\ndifferent background knowledge. Today's modeling notations focus on the\ndetailed modeling of a certain domain specific problem area. They do not\nsupport interdisciplinary discussion adequately. To bridge this gap a novel MES\nModeling Language (MES-ML) integrating all necessary views important for MES\nand pointing out their interdependencies has been developed. Due to its formal\nbasis, comparable and consistent MES-models can be created for specification,\nstandardization, testing, and documentation of MES software. In this paper, the\nauthors present the formal basis of the modeling language and its core\nnotation. The application of MES-ML is demonstrated taking a yogurt production\nas an example. Finally, the authors give some evaluation results that underline\nthe effectiveness and efficiency of this new modeling approach with reference\nto four applications in industrial MES-projects in the domain of discrete and\nhybrid manufacturing.",
    "descriptor": "\nComments: 10 pages, this https URL\n",
    "authors": [
      "Maria Witsch",
      "Birgit Vogel-Heuser"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.04878"
  },
  {
    "id": "arXiv:2212.04880",
    "title": "A Polynomial-Time Algorithm for MCS Partial Search Order on Chordal  Graphs",
    "abstract": "We study the partial search order problem (PSOP) proposed recently by\nScheffler [WG 2022]. Given a graph $G$ together with a partial order over the\nvertices of $G$, this problem determines if there is an $\\mathcal{S}$-ordering\nthat is consistent with the given partial order, where $\\mathcal{S}$ is a graph\nsearch paradigm like BFS, DFS, etc. This problem naturally generalizes the\nend-vertex problem which has received much attention over the past few years.\nIt also generalizes the so-called ${\\mathcal{F}}$-tree recognition problem\nwhich has just been studied in the literature recently. Our main contribution\nis a polynomial-time dynamic programming algorithm for the PSOP on chordal\ngraphs with respect to the maximum cardinality search (MCS). This resolves one\nof the most intriguing open questions left in the work of Sheffler [WG 2022].\nTo obtain our result, we propose the notion of layer structure and study\nnumerous related structural properties which might be of independent interest.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Guozhen Rong",
      "Yongjie Yang",
      "Wenjun Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2212.04880"
  },
  {
    "id": "arXiv:2212.04882",
    "title": "Revisiting Decidable Bounded Quantification, via Dinaturality",
    "abstract": "We use a semantic interpretation to investigate the problem of defining an\nexpressive but decidable type system with bounded quantification. Typechecking\nin the widely studied System \\fsub is undecidable thanks to an undecidable\nsubtyping relation, for which the culprit is the rule for subtyping bounded\nquantification. Weaker versions of this rule, allowing decidable subtyping,\nhave been proposed. One of the resulting type systems (Kernel Fsub) lacks\nexpressiveness, another (System Fsubtop) lacks the minimal typing property and\nthus has no evident typechecking algorithm.\nWe consider these rules as defining distinct forms of bounded quantification,\none for interpreting type variable abstraction, and the other for type\ninstantiation. By giving a semantic interpretation for both in terms of\nunbounded quantification, using the dinaturality of type instantiation with\nrespect to subsumption, we show that they can coexist within a single type\nsystem. This does have the minimal typing property and thus a simple\ntypechecking procedure.\nWe consider the fragments of this unified type system over types which\ncontain only one form of bounded quantifier. One of these is equivalent to\nKernel Fsub, while the other can type strictly more terms than System Fsubtop\nbut the same set of beta-normal terms. We show decidability of typechecking for\nthis fragment, and thus for System Fsubtop typechecking of beta-normal terms.",
    "descriptor": "\nComments: In Mathematical Semantics of Programming Languages (MFPS) '22\n",
    "authors": [
      "James Laird"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.04882"
  },
  {
    "id": "arXiv:2212.04884",
    "title": "Co-training $2^L$ Submodels for Visual Recognition",
    "abstract": "We introduce submodel co-training, a regularization method related to\nco-training, self-distillation and stochastic depth. Given a neural network to\nbe trained, for each sample we implicitly instantiate two altered networks,\n``submodels'', with stochastic depth: we activate only a subset of the layers.\nEach network serves as a soft teacher to the other, by providing a loss that\ncomplements the regular loss provided by the one-hot label. Our approach,\ndubbed cosub, uses a single set of weights, and does not involve a pre-trained\nexternal model or temporal averaging.\nExperimentally, we show that submodel co-training is effective to train\nbackbones for recognition tasks such as image classification and semantic\nsegmentation. Our approach is compatible with multiple architectures, including\nRegNet, ViT, PiT, XCiT, Swin and ConvNext. Our training strategy improves their\nresults in comparable settings. For instance, a ViT-B pretrained with cosub on\nImageNet-21k obtains 87.4% top-1 acc. @448 on ImageNet-val.",
    "descriptor": "",
    "authors": [
      "Hugo Touvron",
      "Matthieu Cord",
      "Maxime Oquab",
      "Piotr Bojanowski",
      "Jakob Verbeek",
      "Herv\u00e9 J\u00e9gou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04884"
  },
  {
    "id": "arXiv:2212.04886",
    "title": "A Modified Sequence-to-point HVAC Load Disaggregation Algorithm",
    "abstract": "This paper presents a modified sequence-to-point (S2P) algorithm for\ndisaggregating the heat, ventilation, and air conditioning (HVAC) load from the\ntotal building electricity consumption. The original S2P model is convolutional\nneural network (CNN) based, which uses load profiles as inputs. We propose\nthree modifications. First, the input convolution layer is changed from 1D to\n2D so that normalized temperature profiles are also used as inputs to the S2P\nmodel. Second, a drop-out layer is added to improve adaptability and\ngeneralizability so that the model trained in one area can be transferred to\nother geographical areas without labelled HVAC data. Third, a fine-tuning\nprocess is proposed for areas with a small amount of labelled HVAC data so that\nthe pre-trained S2P model can be fine-tuned to achieve higher disaggregation\naccuracy (i.e., better transferability) in other areas. The model is first\ntrained and tested using smart meter and sub-metered HVAC data collected in\nAustin, Texas. Then, the trained model is tested on two other areas: Boulder,\nColorado and San Diego, California. Simulation results show that the proposed\nmodified S2P algorithm outperforms the original S2P model and the\nsupport-vector machine based approach in accuracy, adaptability, and\ntransferability.",
    "descriptor": "",
    "authors": [
      "Kai Ye",
      "Hyeonjin Kim",
      "Yi Hu",
      "Ning Lu",
      "Di Wu",
      "PJ Rehm"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.04886"
  },
  {
    "id": "arXiv:2212.04891",
    "title": "HieNet: Bidirectional Hierarchy Framework for Automated ICD Coding",
    "abstract": "International Classification of Diseases (ICD) is a set of classification\ncodes for medical records. Automated ICD coding, which assigns unique\nInternational Classification of Diseases codes with each medical record, is\nwidely used recently for its efficiency and error-prone avoidance. However,\nthere are challenges that remain such as heterogeneity, label unbalance, and\ncomplex relationships between ICD codes. In this work, we proposed a novel\nBidirectional Hierarchy Framework(HieNet) to address the challenges.\nSpecifically, a personalized PageRank routine is developed to capture the\nco-relation of codes, a bidirectional hierarchy passage encoder to capture the\ncodes' hierarchical representations, and a progressive predicting method is\nthen proposed to narrow down the semantic searching space of prediction. We\nvalidate our method on two widely used datasets. Experimental results on two\nauthoritative public datasets demonstrate that our proposed method boosts\nstate-of-the-art performance by a large margin.",
    "descriptor": "",
    "authors": [
      "Shi Wang",
      "Daniel Tang",
      "Luchen Zhang",
      "Huilin Li",
      "Ding Han"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04891"
  },
  {
    "id": "arXiv:2212.04895",
    "title": "CryptoConcurrency: (Almost) Consensusless Asset Transfer with Shared  Accounts",
    "abstract": "A typical blockchain protocol uses consensus to make sure that mutually\nmistrusting users agree on the order in which their operations on shared data\nare executed. It is known, however, that asset transfer systems, by far the\nmost popular application of blockchains, can be implemented without consensus.\nAssuming that no account can be accessed concurrently, i.e., that every account\nbelongs to a single owner, one can efficiently implement an asset transfer\nsystem in a purely asynchronous, consensus-free manner. It has been also shown\nthat asset transfer with shared accounts is impossible to implement without\nconsensus.\nIn this paper, we propose CryptoConcurrency, an asset transfer protocol that\nallows concurrent accesses to be processed in parallel, without involving\nconsensus, whenever possible. More precisely, if concurrent transfer operations\non a given account do not lead to overspending, i.e., can all be applied\nwithout the account balance going below zero, they proceed in parallel.\nOtherwise, the account's owners may have to access an external consensus\nobject. We allow each account to use its own consensus implementation, which\nonly the owners of this account trust.",
    "descriptor": "",
    "authors": [
      "Petr Kuznetsov",
      "Yvonne-Anne Pignolet",
      "Pavel Ponomarev",
      "Andrei Tonkikh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.04895"
  },
  {
    "id": "arXiv:2212.04896",
    "title": "Self-sustaining Ultra-wideband Positioning System for Event-driven  Indoor Localization",
    "abstract": "Smart and unobtrusive mobile sensor nodes that accurately track their own\nposition have the potential to augment data collection with location-based\nfunctions. To attain this vision of unobtrusiveness, the sensor nodes must have\na compact form factor and operate over long periods without battery recharging\nor replacement. This paper presents a self-sustaining and accurate\nultra-wideband-based indoor location system with conservative infrastructure\noverhead. An event-driven sensing approach allows for balancing the limited\nenergy harvested in indoor conditions with the power consumption of\nultra-wideband transceivers. The presented tag-centralized concept, which\ncombines heterogeneous system design with embedded processing, minimizes idle\nconsumption without sacrificing functionality. Despite modest infrastructure\nrequirements, high localization accuracy is achieved with error-correcting\ndouble-sided two-way ranging and embedded optimal multilateration. Experimental\nresults demonstrate the benefits of the proposed system: the node achieves a\nquiescent current of $47~nA$ and operates at $1.2~\\mu A$ while performing\nenergy harvesting and motion detection. The energy consumption for position\nupdates, with an accuracy of $40~cm$ (2D) in realistic non-line-of-sight\nconditions, is $10.84~mJ$. In an asset tracking case study within a $200~m^2$\nmulti-room office space, the achieved accuracy level allows for identifying 36\ndifferent desk and storage locations with an accuracy of over $95~{\\%}$. The\nsystem`s long-time self-sustainability has been analyzed over $700~days$ in\nmultiple indoor lighting situations.",
    "descriptor": "",
    "authors": [
      "Philipp Mayer",
      "Michele Magno",
      "Luca Benini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.04896"
  },
  {
    "id": "arXiv:2212.04909",
    "title": "CKG: Dynamic Representation Based on Context and Knowledge Graph",
    "abstract": "Recently, neural language representation models pre-trained on large corpus\ncan capture rich co-occurrence information and be fine-tuned in downstream\ntasks to improve the performance. As a result, they have achieved\nstate-of-the-art results in a large range of language tasks. However, there\nexists other valuable semantic information such as similar, opposite, or other\npossible meanings in external knowledge graphs (KGs). We argue that entities in\nKGs could be used to enhance the correct semantic meaning of language\nsentences. In this paper, we propose a new method CKG: Dynamic Representation\nBased on \\textbf{C}ontext and \\textbf{K}nowledge \\textbf{G}raph. On the one\nside, CKG can extract rich semantic information of large corpus. On the other\nside, it can make full use of inside information such as co-occurrence in large\ncorpus and outside information such as similar entities in KGs. We conduct\nextensive experiments on a wide range of tasks, including QQP, MRPC, SST-5,\nSQuAD, CoNLL 2003, and SNLI. The experiment results show that CKG achieves SOTA\n89.2 on SQuAD compared with SAN (84.4), ELMo (85.8), and BERT$_{Base}$ (88.5).",
    "descriptor": "",
    "authors": [
      "Xunzhu Tang",
      "Tiezhu Sun",
      "Rujie Zhu",
      "Shi Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.04909"
  },
  {
    "id": "arXiv:2212.04914",
    "title": "Information-Theoretic Safe Exploration with Gaussian Processes",
    "abstract": "We consider a sequential decision making task where we are not allowed to\nevaluate parameters that violate an a priori unknown (safety) constraint. A\ncommon approach is to place a Gaussian process prior on the unknown constraint\nand allow evaluations only in regions that are safe with high probability. Most\ncurrent methods rely on a discretization of the domain and cannot be directly\nextended to the continuous case. Moreover, the way in which they exploit\nregularity assumptions about the constraint introduces an additional critical\nhyperparameter. In this paper, we propose an information-theoretic safe\nexploration criterion that directly exploits the GP posterior to identify the\nmost informative safe parameters to evaluate. Our approach is naturally\napplicable to continuous domains and does not require additional\nhyperparameters. We theoretically analyze the method and show that we do not\nviolate the safety constraint with high probability and that we explore by\nlearning about the constraint up to arbitrary precision. Empirical evaluations\ndemonstrate improved data-efficiency and scalability.",
    "descriptor": "\nComments: Submitted to NeurIPS 2022\n",
    "authors": [
      "Alessandro G. Bottero",
      "Carlos E. Luis",
      "Julia Vinogradska",
      "Felix Berkenkamp",
      "Jan Peters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04914"
  },
  {
    "id": "arXiv:2212.04916",
    "title": "Stochastic Amplitude Flow for phase retrieval, its convergence and  doppelg\u00e4ngers",
    "abstract": "In this paper, we focus on Stochastic Amplitude Flow (SAF) for phase\nretrieval, a stochastic gradient descent for the amplitude-based squared loss.\nWhile the convergence to a critical point of (nonstochastic) Amplitude Flow is\nwell-understood, SAF is a much less studied algorithm. We close this gap by\nderiving the convergence guarantees for SAF based on the contributions for\nAmplitude Flow and analysis for stochastic gradient descent. These results are\nthen applied to two more algorithms, which can be seen as instances of SAF. The\nfirst is an extension of the Kaczmarz method for phase retrieval. The second is\nPtychographic Iterative Engine, which is a popular algorithm for ptychography,\na special case of phase retrieval with the short-time Fourier transform.\nKeywords: phase retrieval, Amplitude Flow, stochastic gradient descent,\nptychography, Ptychographic Iterative Engine, Kaczmarz method.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Oleh Melnyk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.04916"
  },
  {
    "id": "arXiv:2212.04917",
    "title": "TRBLLmaker -- Transformer Reads Between Lyrics Lines maker",
    "abstract": "Even for us, it can be challenging to comprehend the meaning of songs. As\npart of this project, we explore the process of generating the meaning of\nsongs. Despite the widespread use of text-to-text models, few attempts have\nbeen made to achieve a similar objective. Songs are primarily studied in the\ncontext of sentiment analysis. This involves identifying opinions and emotions\nin texts, evaluating them as positive or negative, and utilizing these\nevaluations to make music recommendations. In this paper, we present a\ngenerative model that offers implicit meanings for several lines of a song. Our\nmodel uses a decoder Transformer architecture GPT-2, where the input is the\nlyrics of a song. Furthermore, we compared the performance of this architecture\nwith that of the encoder-decoder Transformer architecture of the T5 model. We\nalso examined the effect of different prompt types with the option of appending\nadditional information, such as the name of the artist and the title of the\nsong. Moreover, we tested different decoding methods with different training\nparameters and evaluated our results using ROUGE. In order to build our\ndataset, we utilized the 'Genious' API, which allowed us to acquire the lyrics\nof songs and their explanations, as well as their rich metadata.",
    "descriptor": "",
    "authors": [
      "Mor Ventura",
      "Michael Toker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04917"
  },
  {
    "id": "arXiv:2212.04934",
    "title": "Learning Graph Algorithms With Recurrent Graph Neural Networks",
    "abstract": "Classical graph algorithms work well for combinatorial problems that can be\nthoroughly formalized and abstracted. Once the algorithm is derived, it\ngeneralizes to instances of any size. However, developing an algorithm that\nhandles complex structures and interactions in the real world can be\nchallenging. Rather than specifying the algorithm, we can try to learn it from\nthe graph-structured data. Graph Neural Networks (GNNs) are inherently capable\nof working on graph structures; however, they struggle to generalize well, and\nlearning on larger instances is challenging. In order to scale, we focus on a\nrecurrent architecture design that can learn simple graph problems end to end\non smaller graphs and then extrapolate to larger instances. As our main\ncontribution, we identify three essential techniques for recurrent GNNs to\nscale. By using (i) skip connections, (ii) state regularization, and (iii) edge\nconvolutions, we can guide GNNs toward extrapolation. This allows us to train\non small graphs and apply the same model to much larger graphs during\ninference. Moreover, we empirically validate the extrapolation capabilities of\nour GNNs on algorithmic datasets.",
    "descriptor": "\nComments: Accepted at GCLR@AAAI23, workshop on Graphs and more Complex structures for Learning and Reasoning\n",
    "authors": [
      "Florian Gr\u00f6tschla",
      "Jo\u00ebl Mathys",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04934"
  },
  {
    "id": "arXiv:2212.04943",
    "title": "On Median Filters for Motion by Mean Curvature",
    "abstract": "The median filter scheme is an elegant, monotone discretization of the level\nset formulation of motion by mean curvature. It turns out to evolve every level\nset of the initial condition precisely by another class of methods known as\nthreshold dynamics. Median filters are, in other words, the natural level set\nversions of threshold dynamics algorithms. Exploiting this connection, we\nrevisit median filters in light of recent progress on the threshold dynamics\nmethod. In particular, we give a variational formulation of, and exhibit a\nLyapunov function for, median filters, resulting in energy based unconditional\nstability properties. The connection also yields analogues of median filters in\nthe multiphase setting of mean curvature flow of networks. These new multiphase\nlevel set methods do not require frequent redistancing, and can accommodate a\nwide range of surface tensions.",
    "descriptor": "\nComments: 41 pages, 8 figures\n",
    "authors": [
      "Selim Esedoglu",
      "Jiajia Guo",
      "David Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.04943"
  },
  {
    "id": "arXiv:2212.04960",
    "title": "BigScience: A Case Study in the Social Construction of a Multilingual  Large Language Model",
    "abstract": "The BigScience Workshop was a value-driven initiative that spanned one and\nhalf years of interdisciplinary research and culminated in the creation of\nROOTS, a 1.6TB multilingual dataset that was used to train BLOOM, one of the\nlargest multilingual language models to date. In addition to the technical\noutcomes and artifacts, the workshop fostered multidisciplinary collaborations\naround large models, datasets, and their analysis. This in turn led to a wide\nrange of research publications spanning topics from ethics to law, data\ngovernance, modeling choices and distributed training. This paper focuses on\nthe collaborative research aspects of BigScience and takes a step back to look\nat the challenges of large-scale participatory research, with respect to\nparticipant diversity and the tasks required to successfully carry out such a\nproject. Our main goal is to share the lessons we learned from this experience,\nwhat we could have done better and what we did well. We show how the impact of\nsuch a social approach to scientific research goes well beyond the technical\nartifacts that were the basis of its inception.",
    "descriptor": "\nComments: Presented at the 2022 NeurIPS Workshop on Broadening Research Collaborations in ML\n",
    "authors": [
      "Christopher Akiki",
      "Giada Pistilli",
      "Margot Mieskes",
      "Matthias Gall\u00e9",
      "Thomas Wolf",
      "Suzana Ili\u0107",
      "Yacine Jernite"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.04960"
  },
  {
    "id": "arXiv:2212.04964",
    "title": "PACMAN: a framework for pulse oximeter digit detection and reading in a  low-resource setting",
    "abstract": "In light of the COVID-19 pandemic, patients were required to manually input\ntheir daily oxygen saturation (SpO2) and pulse rate (PR) values into a health\nmonitoring system-unfortunately, such a process trend to be an error in typing.\nSeveral studies attempted to detect the physiological value from the captured\nimage using optical character recognition (OCR). However, the technology has\nlimited availability with high cost. Thus, this study aimed to propose a novel\nframework called PACMAN (Pandemic Accelerated Human-Machine Collaboration) with\na low-resource deep learning-based computer vision. We compared\nstate-of-the-art object detection algorithms (scaled YOLOv4, YOLOv5, and\nYOLOR), including the commercial OCR tools for digit recognition on the\ncaptured images from pulse oximeter display. All images were derived from\ncrowdsourced data collection with varying quality and alignment. YOLOv5 was the\nbest-performing model against the given model comparison across all datasets,\nnotably the correctly orientated image dataset. We further improved the model\nperformance with the digits auto-orientation algorithm and applied a clustering\nalgorithm to extract SpO2 and PR values. The accuracy performance of YOLOv5\nwith the implementations was approximately 81.0-89.5%, which was enhanced\ncompared to without any additional implementation. Accordingly, this study\nhighlighted the completion of PACMAN framework to detect and read digits in\nreal-world datasets. The proposed framework has been currently integrated into\nthe patient monitoring system utilized by hospitals nationwide.",
    "descriptor": "",
    "authors": [
      "Chiraphat Boonnag",
      "Wanumaidah Saengmolee",
      "Narongrid Seesawad",
      "Amrest Chinkamol",
      "Saendee Rattanasomrerk",
      "Kanyakorn Veerakanjana",
      "Kamonwan Thanontip",
      "Warissara Limpornchitwilai",
      "Piyalitt Ittichaiwong",
      "Theerawit Wilaiprasitporn"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04964"
  },
  {
    "id": "arXiv:2212.04965",
    "title": "Seeing a Rose in Five Thousand Ways",
    "abstract": "What is a rose, visually? A rose comprises its intrinsics, including the\ndistribution of geometry, texture, and material specific to its object\ncategory. With knowledge of these intrinsic properties, we may render roses of\ndifferent sizes and shapes, in different poses, and under different lighting\nconditions. In this work, we build a generative model that learns to capture\nsuch object intrinsics from a single image, such as a photo of a bouquet. Such\nan image includes multiple instances of an object type. These instances all\nshare the same intrinsics, but appear different due to a combination of\nvariance within these intrinsics and differences in extrinsic factors, such as\npose and illumination. Experiments show that our model successfully learns\nobject intrinsics (distribution of geometry, texture, and material) for a wide\nrange of objects, each from a single Internet image. Our method achieves\nsuperior results on multiple downstream tasks, including intrinsic image\ndecomposition, shape and image generation, view synthesis, and relighting.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yunzhi Zhang",
      "Shangzhe Wu",
      "Noah Snavely",
      "Jiajun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04965"
  },
  {
    "id": "arXiv:2212.04966",
    "title": "Towards High-Order Complementary Recommendation via Logical Reasoning  Network",
    "abstract": "Complementary recommendation gains increasing attention in e-commerce since\nit expedites the process of finding frequently-bought-with products for users\nin their shopping journey. Therefore, learning the product representation that\ncan reflect this complementary relationship plays a central role in modern\nrecommender systems. In this work, we propose a logical reasoning network,\nLOGIREC, to effectively learn embeddings of products as well as various\ntransformations (projection, intersection, negation) between them. LOGIREC is\ncapable of capturing the asymmetric complementary relationship between products\nand seamlessly extending to high-order recommendations where more comprehensive\nand meaningful complementary relationship is learned for a query set of\nproducts. Finally, we further propose a hybrid network that is jointly\noptimized for learning a more generic product representation. We demonstrate\nthe effectiveness of our LOGIREC on multiple public real-world datasets in\nterms of various ranking-based metrics under both low-order and high-order\nrecommendation scenarios.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Longfeng Wu",
      "Yao Zhou",
      "Dawei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04966"
  },
  {
    "id": "arXiv:2212.04968",
    "title": "SupeRVol: Super-Resolution Shape and Reflectance Estimation in Inverse  Volume Rendering",
    "abstract": "We propose an end-to-end inverse rendering pipeline called SupeRVol that\nallows us to recover 3D shape and material parameters from a set of color\nimages in a super-resolution manner. To this end, we represent both the\nbidirectional reflectance distribution function (BRDF) and the signed distance\nfunction (SDF) by multi-layer perceptrons. In order to obtain both the surface\nshape and its reflectance properties, we revert to a differentiable volume\nrenderer with a physically based illumination model that allows us to decouple\nreflectance and lighting. This physical model takes into account the effect of\nthe camera's point spread function thereby enabling a reconstruction of shape\nand material in a super-resolution quality. Experimental validation confirms\nthat SupeRVol achieves state of the art performance in terms of inverse\nrendering quality. It generates reconstructions that are sharper than the\nindividual input images, making this method ideally suited for 3D modeling from\nlow-resolution imagery.",
    "descriptor": "",
    "authors": [
      "Mohammed Brahimi",
      "Bjoern Haefner",
      "Tarun Yenamandra",
      "Bastian Goldluecke",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04968"
  },
  {
    "id": "arXiv:2212.04970",
    "title": "Masked Lip-Sync Prediction by Audio-Visual Contextual Exploitation in  Transformers",
    "abstract": "Previous studies have explored generating accurately lip-synced talking faces\nfor arbitrary targets given audio conditions. However, most of them deform or\ngenerate the whole facial area, leading to non-realistic results. In this work,\nwe delve into the formulation of altering only the mouth shapes of the target\nperson. This requires masking a large percentage of the original image and\nseamlessly inpainting it with the aid of audio and reference frames. To this\nend, we propose the Audio-Visual Context-Aware Transformer (AV-CAT) framework,\nwhich produces accurate lip-sync with photo-realistic quality by predicting the\nmasked mouth shapes. Our key insight is to exploit desired contextual\ninformation provided in audio and visual modalities thoroughly with delicately\ndesigned Transformers. Specifically, we propose a convolution-Transformer\nhybrid backbone and design an attention-based fusion strategy for filling the\nmasked parts. It uniformly attends to the textural information on the unmasked\nregions and the reference frame. Then the semantic audio information is\ninvolved in enhancing the self-attention computation. Additionally, a\nrefinement network with audio injection improves both image and lip-sync\nquality. Extensive experiments validate that our model can generate\nhigh-fidelity lip-synced results for arbitrary subjects.",
    "descriptor": "\nComments: Accepted to SIGGRAPH Asia 2022 (Conference Proceedings). Project page: this https URL\n",
    "authors": [
      "Yasheng Sun",
      "Hang Zhou",
      "Kaisiyuan Wang",
      "Qianyi Wu",
      "Zhibin Hong",
      "Jingtuo Liu",
      "Errui Ding",
      "Jingdong Wang",
      "Ziwei Liu",
      "Hideki Koike"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2212.04970"
  },
  {
    "id": "arXiv:2212.04971",
    "title": "PDE-LEARN: Using Deep Learning to Discover Partial Differential  Equations from Noisy, Limited Data",
    "abstract": "In this paper, we introduce PDE-LEARN, a novel PDE discovery algorithm that\ncan identify governing partial differential equations (PDEs) directly from\nnoisy, limited measurements of a physical system of interest. PDE-LEARN uses a\nRational Neural Network, $U$, to approximate the system response function and a\nsparse, trainable vector, $\\xi$, to characterize the hidden PDE that the system\nresponse function satisfies. Our approach couples the training of $U$ and $\\xi$\nusing a loss function that (1) makes $U$ approximate the system response\nfunction, (2) encapsulates the fact that $U$ satisfies a hidden PDE that $\\xi$\ncharacterizes, and (3) promotes sparsity in $\\xi$ using ideas from iteratively\nreweighted least-squares. Further, PDE-LEARN can simultaneously learn from\nseveral data sets, allowing it to incorporate results from multiple\nexperiments. This approach yields a robust algorithm to discover PDEs directly\nfrom realistic scientific data. We demonstrate the efficacy of PDE-LEARN by\nidentifying several PDEs from noisy and limited measurements.",
    "descriptor": "\nComments: 25 pages, 7 figures, 9 tables\n",
    "authors": [
      "Robert Stephany",
      "Christopher Earls"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04971"
  },
  {
    "id": "arXiv:2212.04972",
    "title": "MOPRD: A multidisciplinary open peer review dataset",
    "abstract": "Open peer review is a growing trend in academic publications. Public access\nto peer review data can benefit both the academic and publishing communities.\nIt also serves as a great support to studies on review comment generation and\nfurther to the realization of automated scholarly paper review. However, most\nof the existing peer review datasets do not provide data that cover the whole\npeer review process. Apart from this, their data are not diversified enough as\nthey are mainly collected from the field of computer science. These two\ndrawbacks of the currently available peer review datasets need to be addressed\nto unlock more opportunities for related studies. In response to this problem,\nwe construct MOPRD, a multidisciplinary open peer review dataset. This dataset\nconsists of paper metadata, multiple version manuscripts, review comments,\nmeta-reviews, author's rebuttal letters, and editorial decisions. Moreover, we\ndesign a modular guided review comment generation method based on MOPRD.\nExperiments show that our method delivers better performance indicated by both\nautomatic metrics and human evaluation. We also explore other potential\napplications of MOPRD, including meta-review generation, editorial decision\nprediction, author rebuttal generation, and scientometric analysis. MOPRD is a\nstrong endorsement for further studies in peer review-related research and\nother applications.",
    "descriptor": "",
    "authors": [
      "Jialiang Lin",
      "Jiaxin Song",
      "Zhangping Zhou",
      "Yidong Chen",
      "Xiaodong Shi"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04972"
  },
  {
    "id": "arXiv:2212.04973",
    "title": "Towards Leakage-Free Volatile Static Memory with Antiferroelectric  Transistors",
    "abstract": "Cache serves as a temporary data memory module in many general-purpose\nprocessors and domain-specific accelerators. Its density, power, speed, and\nreliability play a critical role in enhancing the overall system performance\nand quality of service. Conventional volatile memories, including static\nrandom-access memory (SRAM) and embedded dynamic random-access memory (eDRAM)\nin the complementary metal-oxide-semiconductor technology, have high\nperformance and reliability. However, the inherent growing leakage in both SRAM\nand eDRAM hinders further improvement towards smaller feature sizes and higher\nenergy efficiency. Although the emerging nonvolatile memories can eliminate the\nleakage efficiently, the penalties of lower speed and reliability are\nsignificant. This article reveals the new opportunity towards leakage-free\nvolatile static memory beyond the known paradigms of existing volatile and\nnonvolatile memories. By engineering a double-well energy landscape with the\nassistance of a clamping voltage bias, leakage-free and refresh-free state\nretention of a volatile memory is achieved for the first time. This new memory\nis highlighted with both the ultra-low leakage of nonvolatile memories and the\nspeed and energy advantages of volatile memories. A proof-of-concept memory is\ndemonstrated using antiferroelectric field-effect transistors (AFeFETs),\ndelivering an extrapolated endurance of about 1012 cycles, retention time of\nover 10 years, and ultra-low leakage below 10 pA/size. Such a new concept of\nAFeFET-based memory enables improved balance between density, power, and\nreliability beyond all existing memory solutions.",
    "descriptor": "",
    "authors": [
      "Hongtao Zhong",
      "Zijie Zheng",
      "Kai Ni",
      "Xiao Gong",
      "Huazhong Yang",
      "Xueqing Li"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2212.04973"
  },
  {
    "id": "arXiv:2212.04974",
    "title": "Understanding stock market instability via graph auto-encoders",
    "abstract": "Understanding stock market instability is a key question in financial\nmanagement as practitioners seek to forecast breakdowns in asset co-movements\nwhich expose portfolios to rapid and devastating collapses in value. The\nstructure of these co-movements can be described as a graph where companies are\nrepresented by nodes and edges capture correlations between their price\nmovements. Learning a timely indicator of co-movement breakdowns (manifested as\nmodifications in the graph structure) is central in understanding both\nfinancial stability and volatility forecasting. We propose to use the edge\nreconstruction accuracy of a graph auto-encoder (GAE) as an indicator for how\nspatially homogeneous connections between assets are, which, based on financial\nnetwork literature, we use as a proxy to infer market volatility. Our\nexperiments on the S&P 500 over the 2015-2022 period show that higher GAE\nreconstruction error values are correlated with higher volatility. We also show\nthat out-of-sample autoregressive modeling of volatility is improved by the\naddition of the proposed measure. Our paper contributes to the literature of\nmachine learning in finance particularly in the context of understanding stock\nmarket instability.",
    "descriptor": "\nComments: Submitted to Glinda workshop of the Neurips 2022 conference Keywords : Graph Based Learning, Graph Neural Networks, Graph Autoencoder, Stock Market Information, Volatility Forecasting\n",
    "authors": [
      "Dragos Gorduza",
      "Xiaowen Dong",
      "Stefan Zohren"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2212.04974"
  },
  {
    "id": "arXiv:2212.04976",
    "title": "Augmentation Matters: A Simple-yet-Effective Approach to Semi-supervised  Semantic Segmentation",
    "abstract": "Recent studies on semi-supervised semantic segmentation (SSS) have seen fast\nprogress. Despite their promising performance, current state-of-the-art methods\ntend to increasingly complex designs at the cost of introducing more network\ncomponents and additional training procedures. Differently, in this work, we\nfollow a standard teacher-student framework and propose AugSeg, a simple and\nclean approach that focuses mainly on data perturbations to boost the SSS\nperformance. We argue that various data augmentations should be adjusted to\nbetter adapt to the semi-supervised scenarios instead of directly applying\nthese techniques from supervised learning. Specifically, we adopt a simplified\nintensity-based augmentation that selects a random number of data\ntransformations with uniformly sampling distortion strengths from a continuous\nspace. Based on the estimated confidence of the model on different unlabeled\nsamples, we also randomly inject labelled information to augment the unlabeled\nsamples in an adaptive manner. Without bells and whistles, our simple AugSeg\ncan readily achieve new state-of-the-art performance on SSS benchmarks under\ndifferent partition protocols.",
    "descriptor": "\nComments: 10 pages, 8 tables\n",
    "authors": [
      "Zhen Zhao",
      "Lihe Yang",
      "Sifan Long",
      "Jimin Pi",
      "Luping Zhou",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04976"
  },
  {
    "id": "arXiv:2212.04979",
    "title": "Video-Text Modeling with Zero-Shot Transfer from Contrastive Captioners",
    "abstract": "This work explores an efficient approach to establish a foundational\nvideo-text model for tasks including open-vocabulary video classification,\ntext-to-video retrieval, video captioning and video question-answering. We\npresent VideoCoCa that reuses a pretrained image-text contrastive captioner\n(CoCa) model and adapt it to video-text tasks with minimal extra training.\nWhile previous works adapt image-text models with various cross-frame fusion\nmodules (for example, cross-frame attention layer or perceiver resampler) and\nfinetune the modified architecture on video-text data, we surprisingly find\nthat the generative attentional pooling and contrastive attentional pooling\nlayers in the image-text CoCa design are instantly adaptable to ``flattened\nframe embeddings'', yielding a strong zero-shot transfer baseline for many\nvideo-text tasks. Specifically, the frozen image encoder of a pretrained\nimage-text CoCa takes each video frame as inputs and generates \\(N\\) token\nembeddings per frame for totally \\(T\\) video frames. We flatten \\(N \\times T\\)\ntoken embeddings as a long sequence of frozen video representation and apply\nCoCa's generative attentional pooling and contrastive attentional pooling on\ntop. All model weights including pooling layers are directly loaded from an\nimage-text CoCa pretrained model. Without any video or video-text data,\nVideoCoCa's zero-shot transfer baseline already achieves state-of-the-art\nresults on zero-shot video classification on Kinetics 400/600/700, UCF101,\nHMDB51, and Charades, as well as zero-shot text-to-video retrieval on MSR-VTT\nand ActivityNet Captions. We also explore lightweight finetuning on top of\nVideoCoCa, and achieve strong results on video question-answering (iVQA,\nMSRVTT-QA, MSVD-QA) and video captioning (MSR-VTT, ActivityNet, Youcook2). Our\napproach establishes a simple and effective video-text baseline for future\nresearch.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Shen Yan",
      "Tao Zhu",
      "Zirui Wang",
      "Yuan Cao",
      "Mi Zhang",
      "Soham Ghosh",
      "Yonghui Wu",
      "Jiahui Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2212.04979"
  },
  {
    "id": "arXiv:2212.04981",
    "title": "LoopDraw: a Loop-Based Autoregressive Model for Shape Synthesis and  Editing",
    "abstract": "There is no settled universal 3D representation for geometry with many\nalternatives such as point clouds, meshes, implicit functions, and voxels to\nname a few. In this work, we present a new, compelling alternative for\nrepresenting shapes using a sequence of cross-sectional closed loops. The loops\nacross all planes form an organizational hierarchy which we leverage for\nautoregressive shape synthesis and editing. Loops are a non-local description\nof the underlying shape, as simple loop manipulations (such as shifts) result\nin significant structural changes to the geometry. This is in contrast to\nmanipulating local primitives such as points in a point cloud or a triangle in\na triangle mesh. We further demonstrate that loops are intuitive and natural\nprimitive for analyzing and editing shapes, both computationally and for users.",
    "descriptor": "",
    "authors": [
      "Nam Anh Dinh",
      "Haochen Wang",
      "Greg Shakhnarovich",
      "Rana Hanocka"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04981"
  },
  {
    "id": "arXiv:2212.04983",
    "title": "Adversarial Weight Perturbation Improves Generalization in Graph Neural  Network",
    "abstract": "A lot of theoretical and empirical evidence shows that the flatter local\nminima tend to improve generalization. Adversarial Weight Perturbation (AWP) is\nan emerging technique to efficiently and effectively find such minima. In AWP\nwe minimize the loss w.r.t. a bounded worst-case perturbation of the model\nparameters thereby favoring local minima with a small loss in a neighborhood\naround them. The benefits of AWP, and more generally the connections between\nflatness and generalization, have been extensively studied for i.i.d. data such\nas images. In this paper, we extensively study this phenomenon for graph data.\nAlong the way, we first derive a generalization bound for non-i.i.d. node\nclassification tasks. Then we identify a vanishing-gradient issue with all\nexisting formulations of AWP and we propose a new Weighted Truncated AWP\n(WT-AWP) to alleviate this issue. We show that regularizing graph neural\nnetworks with WT-AWP consistently improves both natural and robust\ngeneralization across many different graph learning tasks and models.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Yihan Wu",
      "Aleksandar Bojchevski",
      "Heng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04983"
  },
  {
    "id": "arXiv:2212.04984",
    "title": "Transformer-based normative modelling for anomaly detection of early  schizophrenia",
    "abstract": "Despite the impact of psychiatric disorders on clinical health, early-stage\ndiagnosis remains a challenge. Machine learning studies have shown that\nclassifiers tend to be overly narrow in the diagnosis prediction task. The\noverlap between conditions leads to high heterogeneity among participants that\nis not adequately captured by classification models. To address this issue,\nnormative approaches have surged as an alternative method. By using a\ngenerative model to learn the distribution of healthy brain data patterns, we\ncan identify the presence of pathologies as deviations or outliers from the\ndistribution learned by the model. In particular, deep generative models showed\ngreat results as normative models to identify neurological lesions in the\nbrain. However, unlike most neurological lesions, psychiatric disorders present\nsubtle changes widespread in several brain regions, making these alterations\nchallenging to identify. In this work, we evaluate the performance of\ntransformer-based normative models to detect subtle brain changes expressed in\nadolescents and young adults. We trained our model on 3D MRI scans of\nneurotypical individuals (N=1,765). Then, we obtained the likelihood of\nneurotypical controls and psychiatric patients with early-stage schizophrenia\nfrom an independent dataset (N=93) from the Human Connectome Project. Using the\npredicted likelihood of the scans as a proxy for a normative score, we obtained\nan AUROC of 0.82 when assessing the difference between controls and individuals\nwith early-stage schizophrenia. Our approach surpassed recent normative methods\nbased on brain age and Gaussian Process, showing the promising use of deep\ngenerative models to help in individualised analyses.",
    "descriptor": "\nComments: 10 pages, 2 figures, 2 tables, presented at NeurIPS22@PAI4MH\n",
    "authors": [
      "Pedro F Da Costa",
      "Jessica Dafflon",
      "Sergio Leonardo Mendes",
      "Jo\u00e3o Ricardo Sato",
      "M. Jorge Cardoso",
      "Robert Leech",
      "Emily JH Jones",
      "Walter H.L. Pinaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04984"
  },
  {
    "id": "arXiv:2212.04985",
    "title": "Understanding and Combating Robust Overfitting via Input Loss Landscape  Analysis and Regularization",
    "abstract": "Adversarial training is widely used to improve the robustness of deep neural\nnetworks to adversarial attack. However, adversarial training is prone to\noverfitting, and the cause is far from clear. This work sheds light on the\nmechanisms underlying overfitting through analyzing the loss landscape w.r.t.\nthe input. We find that robust overfitting results from standard training,\nspecifically the minimization of the clean loss, and can be mitigated by\nregularization of the loss gradients. Moreover, we find that robust overfitting\nturns severer during adversarial training partially because the gradient\nregularization effect of adversarial training becomes weaker due to the\nincrease in the loss landscapes curvature. To improve robust generalization, we\npropose a new regularizer to smooth the loss landscape by penalizing the\nweighted logits variation along the adversarial direction. Our method\nsignificantly mitigates robust overfitting and achieves the highest robustness\nand efficiency compared to similar previous methods. Code is available at\nhttps://github.com/TreeLLi/Combating-RO-AdvLC.",
    "descriptor": "\nComments: published in journal Pattern Recognition: this https URL\n",
    "authors": [
      "Lin Li",
      "Michael Spratling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04985"
  },
  {
    "id": "arXiv:2212.04994",
    "title": "Open Vocabulary Semantic Segmentation with Patch Aligned Contrastive  Learning",
    "abstract": "We introduce Patch Aligned Contrastive Learning (PACL), a modified\ncompatibility function for CLIP's contrastive loss, intending to train an\nalignment between the patch tokens of the vision encoder and the CLS token of\nthe text encoder. With such an alignment, a model can identify regions of an\nimage corresponding to a given text input, and therefore transfer seamlessly to\nthe task of open vocabulary semantic segmentation without requiring any\nsegmentation annotations during training. Using pre-trained CLIP encoders with\nPACL, we are able to set the state-of-the-art on the task of open vocabulary\nzero-shot segmentation on 4 different segmentation benchmarks: Pascal VOC,\nPascal Context, COCO Stuff and ADE20K. Furthermore, we show that PACL is also\napplicable to image-level predictions and when used with a CLIP backbone,\nprovides a general improvement in zero-shot classification accuracy compared to\nCLIP, across a suite of 12 image classification datasets.",
    "descriptor": "",
    "authors": [
      "Jishnu Mukhoti",
      "Tsung-Yu Lin",
      "Omid Poursaeed",
      "Rui Wang",
      "Ashish Shah",
      "Philip H.S. Torr",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04994"
  },
  {
    "id": "arXiv:2212.04997",
    "title": "Regulating Gatekeeper AI and Data: Transparency, Access, and Fairness  under the DMA, the GDPR, and beyond",
    "abstract": "Artificial intelligence is not only increasingly used in business and\nadministration contexts, but a race for its regulation is also underway, with\nthe EU spearheading the efforts. Contrary to existing literature, this article\nsuggests, however, that the most far-reaching and effective EU rules for AI\napplications in the digital economy will not be contained in the proposed AI\nAct - but have just been enacted in the Digital Markets Act. We analyze the\nimpact of the DMA and related EU acts on AI models and their underlying data\nacross four key areas: disclosure requirements; the regulation of AI training\ndata; access rules; and the regime for fair rankings. The paper demonstrates\nthat fairness, in the sense of the DMA, goes beyond traditionally protected\ncategories of non-discrimination law on which scholarship at the intersection\nof AI and law has so far largely focused on. Rather, we draw on competition law\nand the FRAND criteria known from intellectual property law to interpret and\nrefine the DMA provisions on fair rankings. Moreover, we show how, based on\nCJEU jurisprudence, a coherent interpretation of the concept of\nnon-discrimination in both traditional non-discrimination and competition law\nmay be found. The final part sketches specific proposals for a comprehensive\nframework of transparency, access, and fairness under the DMA and beyond.",
    "descriptor": "\nComments: under peer-review\n",
    "authors": [
      "Philipp Hacker",
      "Johann Cordes",
      "Janina Rochon"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04997"
  },
  {
    "id": "arXiv:2212.04999",
    "title": "An Implementation of the Extended Tower Number Field Sieve using 4d  Sieving in a Box and a Record Computation in Fp4",
    "abstract": "We report on an implementation of the Extended Tower Number Field Sieve\n(ExTNFS) and record computation in a medium characteristic finite field Fp4 of\n512 bits size. We show that sieving in a box (orthotope) for collecting\nrelations for ExTNFS is still fast in 4 dimensions.",
    "descriptor": "",
    "authors": [
      "Oisin Robinson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.04999"
  },
  {
    "id": "arXiv:2212.05005",
    "title": "Memories are One-to-Many Mapping Alleviators in Talking Face Generation",
    "abstract": "Talking face generation aims at generating photo-realistic video portraits of\na target person driven by input audio. Due to its nature of one-to-many mapping\nfrom the input audio to the output video (e.g., one speech content may have\nmultiple feasible visual appearances), learning a deterministic mapping like\nprevious works brings ambiguity during training, and thus causes inferior\nvisual results. Although this one-to-many mapping could be alleviated in part\nby a two-stage framework (i.e., an audio-to-expression model followed by a\nneural-rendering model), it is still insufficient since the prediction is\nproduced without enough information (e.g., emotions, wrinkles, etc.). In this\npaper, we propose MemFace to complement the missing information with an\nimplicit memory and an explicit memory that follow the sense of the two stages\nrespectively. More specifically, the implicit memory is employed in the\naudio-to-expression model to capture high-level semantics in the\naudio-expression shared space, while the explicit memory is employed in the\nneural-rendering model to help synthesize pixel-level details. Our experimental\nresults show that our proposed MemFace surpasses all the state-of-the-art\nresults across multiple scenarios consistently and significantly.",
    "descriptor": "\nComments: Project page: see this https URL\n",
    "authors": [
      "Anni Tang",
      "Tianyu He",
      "Xu Tan",
      "Jun Ling",
      "Runnan Li",
      "Sheng Zhao",
      "Li Song",
      "Jiang Bian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2212.05005"
  },
  {
    "id": "arXiv:2212.05009",
    "title": "Scalable Graph Convolutional Network Training on Distributed-Memory  Systems",
    "abstract": "Graph Convolutional Networks (GCNs) are extensively utilized for deep\nlearning on graphs. The large data sizes of graphs and their vertex features\nmake scalable training algorithms and distributed memory systems necessary.\nSince the convolution operation on graphs induces irregular memory access\npatterns, designing a memory- and communication-efficient parallel algorithm\nfor GCN training poses unique challenges. We propose a highly parallel training\nalgorithm that scales to large processor counts. In our solution, the large\nadjacency and vertex-feature matrices are partitioned among processors. We\nexploit the vertex-partitioning of the graph to use non-blocking point-to-point\ncommunication operations between processors for better scalability. To further\nminimize the parallelization overheads, we introduce a sparse matrix\npartitioning scheme based on a hypergraph partitioning model for full-batch\ntraining. We also propose a novel stochastic hypergraph model to encode the\nexpected communication volume in mini-batch training. We show the merits of the\nhypergraph model, previously unexplored for GCN training, over the standard\ngraph partitioning model which does not accurately encode the communication\ncosts. Experiments performed on real-world graph datasets demonstrate that the\nproposed algorithms achieve considerable speedups over alternative solutions.\nThe optimizations achieved on communication costs become even more pronounced\nat high scalability with many processors. The performance benefits are\npreserved in deeper GCNs having more layers as well as on billion-scale graphs.",
    "descriptor": "\nComments: To appear in PVLDB'22\n",
    "authors": [
      "Gunduz Vehbi Demirci",
      "Aparajita Haldar",
      "Hakan Ferhatosmanoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.05009"
  },
  {
    "id": "arXiv:2212.05011",
    "title": "LADIS: Language Disentanglement for 3D Shape Editing",
    "abstract": "Natural language interaction is a promising direction for democratizing 3D\nshape design. However, existing methods for text-driven 3D shape editing face\nchallenges in producing decoupled, local edits to 3D shapes. We address this\nproblem by learning disentangled latent representations that ground language in\n3D geometry. To this end, we propose a complementary tool set including a novel\nnetwork architecture, a disentanglement loss, and a new editing procedure.\nAdditionally, to measure edit locality, we define a new metric that we call\npart-wise edit precision. We show that our method outperforms existing SOTA\nmethods by 20% in terms of edit locality, and up to 6.6% in terms of language\nreference resolution accuracy. Our work suggests that by solely disentangling\nlanguage representations, downstream 3D shape editing can become more local to\nrelevant parts, even if the model was never given explicit part-based\nsupervision.",
    "descriptor": "",
    "authors": [
      "Ian Huang",
      "Panos Achlioptas",
      "Tianyi Zhang",
      "Sergey Tulyakov",
      "Minhyuk Sung",
      "Leonidas Guibas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.05011"
  },
  {
    "id": "arXiv:2212.05015",
    "title": "Robustness Implies Privacy in Statistical Estimation",
    "abstract": "We study the relationship between adversarial robustness and differential\nprivacy in high-dimensional algorithmic statistics. We give the first black-box\nreduction from privacy to robustness which can produce private estimators with\noptimal tradeoffs among sample complexity, accuracy, and privacy for a wide\nrange of fundamental high-dimensional parameter estimation problems, including\nmean and covariance estimation. We show that this reduction can be implemented\nin polynomial time in some important special cases. In particular, using\nnearly-optimal polynomial-time robust estimators for the mean and covariance of\nhigh-dimensional Gaussians which are based on the Sum-of-Squares method, we\ndesign the first polynomial-time private estimators for these problems with\nnearly-optimal samples-accuracy-privacy tradeoffs. Our algorithms are also\nrobust to a constant fraction of adversarially-corrupted samples.",
    "descriptor": "\nComments: 87 pages, 2 tables\n",
    "authors": [
      "Samuel B. Hopkins",
      "Gautam Kamath",
      "Mahbod Majid",
      "Shyam Narayanan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.05015"
  },
  {
    "id": "arXiv:2212.05019",
    "title": "Understanding User Perception and Intention to Use Smart Homes for  Energy Efficiency: A Survey",
    "abstract": "The positive impact of Smart Homes on energy efficiency is heavily dependent\non how consumers use the system after adoption. While the technical aspects of\nSmart Home systems and their potential to reduce energy usage is a focus of\nvarious studies, there is a limited consideration of behavioral psychology\nwhile designing systems for energy management. To investigate users' perception\nand intention to use Smart Homes to support energy efficiency, we design a\nresearch model by combining a theory of planned behavior and the norm\nactivation model. We design a questionnaire and conduct a survey targeting\ncurrent smart home users (over 350 responses). To analyze the survey results,\nwe extend the partial least squares structural equation modeling (PLS-SEM) by a\nrandom forest algorithm. The findings suggest that personal norms have the\nstrongest influence on behavioral intention to use Smart Homes for energy\nefficiency, followed by the ascription of responsibility. Furthermore, the\nresults support the effects of attitudes, subjective norms, awareness of\nconsequences, as well as the moderating effect of past behavior on the\nrelationship between personal norms and behavioral intentions.",
    "descriptor": "",
    "authors": [
      "Alona Zharova",
      "Hee-Eun Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.05019"
  },
  {
    "id": "arXiv:2212.05023",
    "title": "Mesh Neural Networks for SE(3)-Equivariant Hemodynamics Estimation on  the Artery Wall",
    "abstract": "Computational fluid dynamics (CFD) is a valuable asset for patient-specific\ncardiovascular-disease diagnosis and prognosis, but its high computational\ndemands hamper its adoption in practice. Machine-learning methods that estimate\nblood flow in individual patients could accelerate or replace CFD simulation to\novercome these limitations. In this work, we consider the estimation of\nvector-valued quantities on the wall of three-dimensional geometric artery\nmodels. We employ group-equivariant graph convolution in an end-to-end\nSE(3)-equivariant neural network that operates directly on triangular surface\nmeshes and makes efficient use of training data. We run experiments on a large\ndataset of synthetic coronary arteries and find that our method estimates\ndirectional wall shear stress (WSS) with an approximation error of 7.6% and\nnormalised mean absolute error (NMAE) of 0.4% while up to two orders of\nmagnitude faster than CFD. Furthermore, we show that our method is powerful\nenough to accurately predict transient, vector-valued WSS over the cardiac\ncycle while conditioned on a range of different inflow boundary conditions.\nThese results demonstrate the potential of our proposed method as a plugin\nreplacement for CFD in the personalised prediction of hemodynamic vector and\nscalar fields.",
    "descriptor": "\nComments: Preprint. Under Review\n",
    "authors": [
      "Julian Suk",
      "Pim de Haan",
      "Phillip Lippe",
      "Christoph Brune",
      "Jelmer M. Wolterink"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Group Theory (math.GR)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2212.05023"
  },
  {
    "id": "arXiv:2212.05024",
    "title": "Decomposable Sparse Tensor on Tensor Regression",
    "abstract": "Most regularized tensor regression research focuses on tensors predictors\nwith scalars responses or vectors predictors to tensors responses. We consider\nthe sparse low rank tensor on tensor regression where predictors $\\mathcal{X}$\nand responses $\\mathcal{Y}$ are both high-dimensional tensors. By demonstrating\nthat the general inner product or the contracted product on a unit rank tensor\ncan be decomposed into standard inner products and outer products, the problem\ncan be simply transformed into a tensor to scalar regression followed by a\ntensor decomposition. So we propose a fast solution based on stagewise search\ncomposed by contraction part and generation part which are optimized\nalternatively. We successfully demonstrate our method can out perform current\nmethods in terms of accuracy, predictors selection by effectively incorporating\nthe structural information.",
    "descriptor": "",
    "authors": [
      "Haiyi Mao",
      "Jason Xiaotian Dou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.05024"
  },
  {
    "id": "arXiv:2212.05028",
    "title": "A systematic literature review on Security of Unmanned Aerial Vehicle  Systems",
    "abstract": "Unmanned aerial vehicles (UAVs) are becoming more common, and their\noperational range is expanding tremendously, making the security aspect of the\ninquiry essential. This study does a thorough assessment of the literature to\ndetermine the most common cyberattacks and the effects they have on UAV\nassaults on civilian targets. The STRIDE assault paradigm, the challenge they\npresent, and the proper tools for the attack are used to categorize the cyber\ndangers discussed in this paper. Spoofing and denial of service assaults are\nthe most prevalent types of UAV cyberattacks and have the best results. No\nattack style demands the employment of a hard-to-reach gadget, indicating that\nthe security environment currently necessitates improvements to UAV use in\ncivilian applications.",
    "descriptor": "\nComments: 10 Pages, 4 Figures\n",
    "authors": [
      "Tirth Patel",
      "Niyatiben Salot",
      "Vrusha Parikh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.05028"
  },
  {
    "id": "arXiv:2212.05030",
    "title": "ICT4S2022 -- Demonstrations and Posters Track Proceedings",
    "abstract": "Submissions accepted for The 8th International Conference on ICT for\nSustainability (ICT4S 2022), Demonstrations and Posters Track Proceedings,\nPlovdiv, Bulgaria, Mon 13 - Fri 17 June 2022. Most of the submissions are\nincluded in the arXiv proceedings while some demonstrations and posters are out\nof arXiv publication scope as the ICT4S scope is broad and multidisciplinary.\nCorresponding posters are available on the ICT4S2022 - Demonstrations and\nPosters page.",
    "descriptor": "",
    "authors": [
      "Rui Pereira",
      "Gordana Raki\u0107"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.05030"
  },
  {
    "id": "arXiv:2212.05031",
    "title": "Towards a learning-based performance modeling for accelerating Deep  Neural Networks",
    "abstract": "Emerging applications such as Deep Learning are often data-driven, thus\ntraditional approaches based on auto-tuners are not performance effective\nacross the wide range of inputs used in practice. In the present paper, we\nstart an investigation of predictive models based on machine learning\ntechniques in order to optimize Convolution Neural Networks (CNNs). As a\nuse-case, we focus on the ARM Compute Library which provides three different\nimplementations of the convolution operator at different numeric precision.\nStarting from a collation of benchmarks, we build and validate models learned\nby Decision Tree and naive Bayesian classifier. Preliminary experiments on\nMidgard-based ARM Mali GPU show that our predictive model outperforms all the\nconvolution operators manually selected by the library.",
    "descriptor": "",
    "authors": [
      "Damiano Perri",
      "Paolo Sylos Labini",
      "Osvaldo Gervasi",
      "Sergio Tasso",
      "Flavio Vella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.05031"
  },
  {
    "id": "arXiv:2212.05032",
    "title": "Training-Free Structured Diffusion Guidance for Compositional  Text-to-Image Synthesis",
    "abstract": "Large-scale diffusion models have achieved state-of-the-art results on\ntext-to-image synthesis (T2I) tasks. Despite their ability to generate\nhigh-quality yet creative images, we observe that attribution-binding and\ncompositional capabilities are still considered major challenging issues,\nespecially when involving multiple objects. In this work, we improve the\ncompositional skills of T2I models, specifically more accurate attribute\nbinding and better image compositions. To do this, we incorporate linguistic\nstructures with the diffusion guidance process based on the controllable\nproperties of manipulating cross-attention layers in diffusion-based T2I\nmodels. We observe that keys and values in cross-attention layers have strong\nsemantic meanings associated with object layouts and content. Therefore, we can\nbetter preserve the compositional semantics in the generated image by\nmanipulating the cross-attention representations based on linguistic insights.\nBuilt upon Stable Diffusion, a SOTA T2I model, our structured cross-attention\ndesign is efficient that requires no additional training samples. We achieve\nbetter compositional skills in qualitative and quantitative results, leading to\na 5-8% advantage in head-to-head user comparison studies. Lastly, we conduct an\nin-depth analysis to reveal potential causes of incorrect image compositions\nand justify the properties of cross-attention layers in the generation process.",
    "descriptor": "",
    "authors": [
      "Weixi Feng",
      "Xuehai He",
      "Tsu-Jui Fu",
      "Varun Jampani",
      "Arjun Akula",
      "Pradyumna Narayana",
      "Sugato Basu",
      "Xin Eric Wang",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.05032"
  },
  {
    "id": "arXiv:2212.05033",
    "title": "Mining CryptoNight-Haven on the Varium C1100 Blockchain Accelerator Card",
    "abstract": "Cryptocurrency mining is an energy-intensive process that presents a prime\ncandidate for hardware acceleration. This work-in-progress presents the first\ncoprocessor design for the ASIC-resistant CryptoNight-Haven Proof of Work (PoW)\nalgorithm. We construct our hardware accelerator as a Xilinx Run Time (XRT) RTL\nkernel targeting the Xilinx Varium C1100 Blockchain Accelerator Card. The\ndesign employs deeply pipelined computation and High Bandwidth Memory (HBM) for\nthe underlying scratchpad data. We aim to compare our accelerator to existing\nCPU and GPU miners to show increased throughput and energy efficiency of its\nhash computations",
    "descriptor": "",
    "authors": [
      "Lucas Bex",
      "Furkan Turan",
      "Michiel Van Beirendonck",
      "Ingrid Verbauwhede"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2212.05033"
  },
  {
    "id": "arXiv:2212.05034",
    "title": "SmartBrush: Text and Shape Guided Object Inpainting with Diffusion Model",
    "abstract": "Generic image inpainting aims to complete a corrupted image by borrowing\nsurrounding information, which barely generates novel content. By contrast,\nmulti-modal inpainting provides more flexible and useful controls on the\ninpainted content, \\eg, a text prompt can be used to describe an object with\nricher attributes, and a mask can be used to constrain the shape of the\ninpainted object rather than being only considered as a missing area. We\npropose a new diffusion-based model named SmartBrush for completing a missing\nregion with an object using both text and shape-guidance. While previous work\nsuch as DALLE-2 and Stable Diffusion can do text-guided inapinting they do not\nsupport shape guidance and tend to modify background texture surrounding the\ngenerated object. Our model incorporates both text and shape guidance with\nprecision control. To preserve the background better, we propose a novel\ntraining and sampling strategy by augmenting the diffusion U-net with\nobject-mask prediction. Lastly, we introduce a multi-task training strategy by\njointly training inpainting with text-to-image generation to leverage more\ntraining data. We conduct extensive experiments showing that our model\noutperforms all baselines in terms of visual quality, mask controllability, and\nbackground preservation.",
    "descriptor": "",
    "authors": [
      "Shaoan Xie",
      "Zhifei Zhang",
      "Zhe Lin",
      "Tobias Hinz",
      "Kun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.05034"
  },
  {
    "id": "arXiv:2212.05035",
    "title": "COVID-19 Activity Risk Calculator as a Gamified Public Health  Intervention Tool",
    "abstract": "Public health intervention techniques have been highly significant in\nreducing the negative impact of several epidemics and pandemics. Among all of\nthe wide-spread diseases, one of the most dangerous one has been severe acute\nrespiratory syndrome coronavirus 2 (SARS-CoV-2) or Coronavirus disease 2019\n(COVID-19). The impact of the virus has been observed in over 200 countries\nleading to hospitalizations and deaths of millions of people. Currently\nexisting COVID-19 risk estimation tools provided to the general public have\nbeen highly variable during the pandemic due to its dependency on rapidly\nevolving factors such as community transmission levels and variants. There has\nalso been confusion surrounding certain personal protective strategies such as\nrisk reduction by mask-wearing and vaccination. In order to create a simplified\neasy-to-use tool for estimating different individual risks associated with\ncarrying out daily-life activity, we developed COVID-19 Activity Risk\nCalculator (CovARC). CovARC serves as a gamified public health intervention as\nusers can \"play with\" how different risks associated with COVID-19 would change\ndepending on several different factors when carrying out a daily routine\nactivity. Empowering the public to make informed, data-driven decisions about\nsafely engaging in activities may help to reduce COVID- 19 levels in the\ncommunity. In this study, we demonstrate a streamlined, scalable and accurate\nCOVID-19 risk calculation system. Our study also showcases quantitatively, the\nincreased impact of interventions such as vaccination and mask-wearing when\ncases are higher, which could prove as a validity to inform and support policy\ndecisions around mask mandate case thresholds and other non-pharmaceutical\ninterventions.",
    "descriptor": "\nComments: 11 pages, 6 figures (main paper + 1 figure supplementary section.)\n",
    "authors": [
      "Shreyasvi Natraj",
      "Malhar Bhide",
      "Nathan Yap",
      "Meng Liu",
      "Agrima Seth",
      "Christin Glorioso"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.05035"
  },
  {
    "id": "arXiv:2212.05037",
    "title": "A Topological Deep Learning Framework for Neural Spike Decoding",
    "abstract": "The brain's spatial orientation system uses different neuron ensembles to aid\nin environment-based navigation. One of the ways brains encode spatial\ninformation is through grid cells, layers of decked neurons that overlay to\nprovide environment-based navigation. These neurons fire in ensembles where\nseveral neurons fire at once to activate a single grid. We want to capture this\nfiring structure and use it to decode grid cell data. Understanding,\nrepresenting, and decoding these neural structures require models that\nencompass higher order connectivity than traditional graph-based models may\nprovide. To that end, in this work, we develop a topological deep learning\nframework for neural spike train decoding. Our framework combines unsupervised\nsimplicial complex discovery with the power of deep learning via a new\narchitecture we develop herein called a simplicial convolutional recurrent\nneural network (SCRNN). Simplicial complexes, topological spaces that use not\nonly vertices and edges but also higher-dimensional objects, naturally\ngeneralize graphs and capture more than just pairwise relationships.\nAdditionally, this approach does not require prior knowledge of the neural\nactivity beyond spike counts, which removes the need for similarity\nmeasurements. The effectiveness and versatility of the SCRNN is demonstrated on\nhead direction data to test its performance and then applied to grid cell\ndatasets with the task to automatically predict trajectories.",
    "descriptor": "",
    "authors": [
      "Edward C. Mitchell",
      "Brittany Story",
      "David Boothe",
      "Piotr J. Franaszczuk",
      "Vasileios Maroulas"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.05037"
  },
  {
    "id": "arXiv:2212.05039",
    "title": "Incorporating Emotions into Health Mention Classification Task on Social  Media",
    "abstract": "The health mention classification (HMC) task is the process of identifying\nand classifying mentions of health-related concepts in text. This can be useful\nfor identifying and tracking the spread of diseases through social media posts.\nHowever, this is a non-trivial task. Here we build on recent studies suggesting\nthat using emotional information may improve upon this task. Our study results\nin a framework for health mention classification that incorporates affective\nfeatures. We present two methods, an intermediate task fine-tuning approach\n(implicit) and a multi-feature fusion approach (explicit) to incorporate\nemotions into our target task of HMC. We evaluated our approach on 5\nHMC-related datasets from different social media platforms including three from\nTwitter, one from Reddit and another from a combination of social media\nsources. Extensive experiments demonstrate that our approach results in\nstatistically significant performance gains on HMC tasks. By using the\nmulti-feature fusion approach, we achieve at least a 3% improvement in F1 score\nover BERT baselines across all datasets. We also show that considering only\nnegative emotions does not significantly affect performance on the HMC task.\nAdditionally, our results indicate that HMC models infused with emotional\nknowledge are an effective alternative, especially when other HMC datasets are\nunavailable for domain-specific fine-tuning. The source code for our models is\nfreely available at https://github.com/tahirlanre/Emotion_PHM.",
    "descriptor": "",
    "authors": [
      "Olanrewaju Tahir Aduragba",
      "Jialin Yu",
      "Alexandra I. Cristea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.05039"
  },
  {
    "id": "arXiv:2212.05040",
    "title": "OmniHorizon: In-the-Wild Outdoors Depth and Normal Estimation from  Synthetic Omnidirectional Dataset",
    "abstract": "Understanding the ambient scene is imperative for several applications such\nas autonomous driving and navigation. While obtaining real-world image data\nwith per-pixel labels is challenging, existing accurate synthetic image\ndatasets primarily focus on indoor spaces with fixed lighting and scene\nparticipants, thereby severely limiting their application to outdoor scenarios.\nIn this work we introduce OmniHorizon, a synthetic dataset with 24,335\nomnidirectional views comprising of a broad range of indoor and outdoor spaces\nconsisting of buildings, streets, and diverse vegetation. Our dataset also\naccounts for dynamic scene components including lighting, different times of a\nday settings, pedestrians, and vehicles. Furthermore, we also demonstrate a\nlearned synthetic-to-real cross-domain inference method for in-the-wild 3D\nscene depth and normal estimation method using our dataset. To this end, we\npropose UBotNet, an architecture based on a UNet and a Bottleneck Transformer,\nto estimate scene-consistent normals. We show that UBotNet achieves\nsignificantly improved depth accuracy (4.6%) and normal estimation (5.75%)\ncompared to several existing networks such as U-Net with skip-connections.\nFinally, we demonstrate in-the-wild depth and normal estimation on real-world\nimages with UBotNet trained purely on our OmniHorizon dataset, showing the\npromise of proposed dataset and network for scene understanding.",
    "descriptor": "\nComments: 16 pages and 18 figures\n",
    "authors": [
      "Jay Bhanushali",
      "Praneeth Chakravarthula",
      "Manivannan Muniyandi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.05040"
  },
  {
    "id": "arXiv:2212.05044",
    "title": "Simulating the Power Electronics-Dominated Grid using Schwarz-Schur  Complement based Hybrid Domain Decomposition Algorithm",
    "abstract": "This paper proposes a novel two-stage hybrid domain decomposition algorithm\nto speed up the dynamic simulations and the analysis of power systems that can\nbe computationally demanding due to the high penetration of renewables. On the\nfirst level of the decomposition, a Schwarz-based strategy is used to decouple\nthe original problem into various subsystems through boundary variable\nrelaxation, while on the second level, each decoupled subsystem is further\ndecomposed into subdomains that are solved independently using the\nSchur-complement approach. Convergence is checked in both stages to ensure that\nthe parallelized implementation of the subsystems can produce identical results\nto the original problem. The proposed approach is tested on an IEEE 9 bus\nsystem in which one synchronous generator is replaced with a solar PV farm\nthrough a grid-forming inverter (GFM) with an admittance control method to\nevaluate its effectiveness and applicability for large-scale and\nvery-large-scale implementations. Since conventional dual-loop GFMs are not\nstable when connecting to a stronger grid with a small grid inductance, a\nvirtual inductance method is adopted to increase the equivalent inductance\nconnecting the grid to enhance stability.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Fatemeh Kalantari",
      "Jian Shi",
      "Harish Krishnamoorthy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.05044"
  },
  {
    "id": "arXiv:2212.05045",
    "title": "On Optimal Cell Average Decomposition for High-Order Bound-Preserving  Schemes of Hyperbolic Conservation Laws",
    "abstract": "This paper presents the first systematic study on the fundamental problem of\nseeking optimal cell average decomposition (OCAD), which arises from\nconstructing efficient high-order bound-preserving (BP) numerical methods\nwithin Zhang--Shu framework. Since proposed in 2010, Zhang--Shu framework has\nattracted extensive attention and been applied to developing many high-order BP\ndiscontinuous Galerkin and finite volume schemes for various hyperbolic\nequations. An essential ingredient in the framework is the decomposition of the\ncell averages of the numerical solution into a convex combination of the\nsolution values at certain quadrature points. The classic CAD originally\nproposed by Zhang and Shu has been widely used in the past decade. However, the\nfeasible CADs are not unique, and different CAD would affect the theoretical BP\nCFL condition and thus the computational costs. Zhang and Shu only checked, for\nthe 1D $\\mathbb P^2$ and $\\mathbb P^3$ spaces, that their classic CAD based on\nthe Gauss--Lobatto quadrature is optimal in the sense of achieving the mildest\nBP CFL conditions.\nIn this paper, we establish the general theory for studying the OCAD problem\non Cartesian meshes in 1D and 2D. We rigorously prove that the classic CAD is\noptimal for general 1D $\\mathbb P^k$ spaces and general 2D $\\mathbb Q^k$ spaces\nof arbitrary $k$. For the widely used 2D $\\mathbb P^k$ spaces, the classic CAD\nis not optimal, and we establish the general approach to find out the genuine\nOCAD and propose a more practical quasi-optimal CAD, both of which provide much\nmilder BP CFL conditions than the classic CAD. As a result, our OCAD and\nquasi-optimal CAD notably improve the efficiency of high-order BP schemes for a\nlarge class of hyperbolic or convection-dominated equations, at little cost of\nonly a slight and local modification to the implementation code.",
    "descriptor": "",
    "authors": [
      "Shumo Cui",
      "Shengrong Ding",
      "Kailiang Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.05045"
  },
  {
    "id": "arXiv:2212.05051",
    "title": "VindLU: A Recipe for Effective Video-and-Language Pretraining",
    "abstract": "The last several years have witnessed remarkable progress in\nvideo-and-language (VidL) understanding. However, most modern VidL approaches\nuse complex and specialized model architectures and sophisticated pretraining\nprotocols, making the reproducibility, analysis and comparisons of these\nframeworks difficult. Hence, instead of proposing yet another new VidL model,\nthis paper conducts a thorough empirical study demystifying the most important\nfactors in the VidL model design. Among the factors that we investigate are (i)\nthe spatiotemporal architecture design, (ii) the multimodal fusion schemes,\n(iii) the pretraining objectives, (iv) the choice of pretraining data, (v)\npretraining and finetuning protocols, and (vi) dataset and model scaling. Our\nempirical study reveals that the most important design factors include:\ntemporal modeling, video-to-text multimodal fusion, masked modeling objectives,\nand joint training on images and videos. Using these empirical insights, we\nthen develop a step-by-step recipe, dubbed VindLU, for effective VidL\npretraining. Our final model trained using our recipe achieves comparable or\nbetter than state-of-the-art results on several VidL tasks without relying on\nexternal CLIP pretraining. In particular, on the text-to-video retrieval task,\nour approach obtains 61.2% on DiDeMo, and 55.0% on ActivityNet, outperforming\ncurrent SOTA by 7.8% and 6.1% respectively. Furthermore, our model also obtains\nstate-of-the-art video question-answering results on ActivityNet-QA, MSRVTT-QA,\nMSRVTT-MC and TVQA. Our code and pretrained models are publicly available at:\nhttps://github.com/klauscc/VindLU.",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Feng Cheng",
      "Xizi Wang",
      "Jie Lei",
      "David Crandall",
      "Mohit Bansal",
      "Gedas Bertasius"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.05051"
  },
  {
    "id": "arXiv:2212.05055",
    "title": "Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints",
    "abstract": "Training large, deep neural networks to convergence can be prohibitively\nexpensive. As a result, often only a small selection of popular, dense models\nare reused across different contexts and tasks. Increasingly, sparsely\nactivated models, which seek to decouple model size from computation costs, are\nbecoming an attractive alternative to dense models. Although more efficient in\nterms of quality and computation cost, sparse models remain data-hungry and\ncostly to train from scratch in the large scale regime. In this work, we\npropose sparse upcycling -- a simple way to reuse sunk training costs by\ninitializing a sparsely activated Mixture-of-Experts model from a dense\ncheckpoint. We show that sparsely upcycled T5 Base, Large, and XL language\nmodels and Vision Transformer Base and Large models, respectively,\nsignificantly outperform their dense counterparts on SuperGLUE and ImageNet,\nusing only ~50% of the initial dense pretraining sunk cost. The upcycled models\nalso outperform sparse models trained from scratch on 100% of the initial dense\npretraining computation budget.",
    "descriptor": "",
    "authors": [
      "Aran Komatsuzaki",
      "Joan Puigcerver",
      "James Lee-Thorp",
      "Carlos Riquelme Ruiz",
      "Basil Mustafa",
      "Joshua Ainslie",
      "Yi Tay",
      "Mostafa Dehghani",
      "Neil Houlsby"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.05055"
  },
  {
    "id": "arXiv:2212.04508",
    "title": "Compiler Optimization for Quantum Computing Using Reinforcement Learning",
    "abstract": "Any quantum computing application, once encoded as a quantum circuit, must be\ncompiled before being executable on a quantum computer. Similar to classical\ncompilation, quantum compilation is a sequential process with many compilation\nsteps and numerous possible optimization passes. Despite the similarities, the\ndevelopment of compilers for quantum computing is still in its infancy-lacking\nmutual consolidation on the best sequence of passes, compatibility,\nadaptability, and flexibility. In this work, we take advantage of decades of\nclassical compiler optimization and propose a reinforcement learning framework\nfor developing optimized quantum circuit compilation flows. Through distinct\nconstraints and a unifying interface, the framework supports the combination of\ntechniques from different compilers and optimization tools in a single\ncompilation flow. Experimental evaluations show that the proposed framework-set\nup with a selection of compilation passes from IBM's Qiskit and Quantinuum's\nTKET-significantly outperforms both individual compilers in over 70% of cases\nregarding the expected fidelity. The framework is available on GitHub\n(https://github.com/cda-tum/MQTPredictor).",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Nils Quetschlich",
      "Lukas Burgholzer",
      "Robert Wille"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04508"
  },
  {
    "id": "arXiv:2212.04532",
    "title": "Framewise WaveGAN: High Speed Adversarial Vocoder in Time Domain with  Very Low Computational Complexity",
    "abstract": "GAN vocoders are currently one of the state-of-the-art methods for building\nhigh-quality neural waveform generative models. However, most of their\narchitectures require dozens of billion floating-point operations per second\n(GFLOPS) to generate speech waveforms in samplewise manner. This makes GAN\nvocoders still challenging to run on normal CPUs without accelerators or\nparallel computers. In this work, we propose a new architecture for GAN\nvocoders that mainly depends on recurrent and fully-connected networks to\ndirectly generate the time domain signal in framewise manner. This results in\nconsiderable reduction of the computational cost and enables very fast\ngeneration on both GPUs and low-complexity CPUs. Experimental results show that\nour Framewise WaveGAN vocoder achieves significantly higher quality than\nauto-regressive maximum-likelihood vocoders such as LPCNet at a very low\ncomplexity of 1.2 GFLOPS. This makes GAN vocoders more practical on edge and\nlow-power devices.",
    "descriptor": "\nComments: Submitted to ICASSP 2023, demo: this https URL\n",
    "authors": [
      "Ahmed Mustafa",
      "Jean-Marc Valin",
      "Jan B\u00fcthe",
      "Paris Smaragdis",
      "Mike Goodwin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.04532"
  },
  {
    "id": "arXiv:2212.04559",
    "title": "SpeechLMScore: Evaluating speech generation using speech language model",
    "abstract": "While human evaluation is the most reliable metric for evaluating speech\ngeneration systems, it is generally costly and time-consuming. Previous studies\non automatic speech quality assessment address the problem by predicting human\nevaluation scores with machine learning models. However, they rely on\nsupervised learning and thus suffer from high annotation costs and domain-shift\nproblems. We propose SpeechLMScore, an unsupervised metric to evaluate\ngenerated speech using a speech-language model. SpeechLMScore computes the\naverage log-probability of a speech signal by mapping it into discrete tokens\nand measures the average probability of generating the sequence of tokens.\nTherefore, it does not require human annotation and is a highly scalable\nframework. Evaluation results demonstrate that the proposed metric shows a\npromising correlation with human evaluation scores on different speech\ngeneration tasks including voice conversion, text-to-speech, and speech\nenhancement.",
    "descriptor": "",
    "authors": [
      "Soumi Maiti",
      "Yifan Peng",
      "Takaaki Saeki",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2212.04559"
  },
  {
    "id": "arXiv:2212.04567",
    "title": "Enhanced prediction accuracy with uncertainty quantification in  monitoring CO2 sequestration using convolutional neural networks",
    "abstract": "Monitoring changes inside a reservoir in real time is crucial for the success\nof CO2 injection and long-term storage. Machine learning (ML) is well-suited\nfor real-time CO2 monitoring because of its computational efficiency. However,\nmost existing applications of ML yield only one prediction (i.e., the\nexpectation) for a given input, which may not properly reflect the distribution\nof the testing data, if it has a shift with respect to that of the training\ndata. The Simultaneous Quantile Regression (SQR) method can estimate the entire\nconditional distribution of the target variable of a neural network via pinball\nloss. Here, we incorporate this technique into seismic inversion for purposes\nof CO2 monitoring. The uncertainty map is then calculated pixel by pixel from a\nparticular prediction interval around the median. We also propose a novel\ndata-augmentation method by sampling the uncertainty to further improve\nprediction accuracy. The developed methodology is tested on synthetic\nKimberlina data, which are created by the Department of Energy and based on a\nCO2 capture and sequestration (CCS) project in California. The results prove\nthat the proposed network can estimate the subsurface velocity rapidly and with\nsufficient resolution. Furthermore, the computed uncertainty quantifies the\nprediction accuracy. The method remains robust even if the testing data are\ndistorted due to problems in the field data acquisition. Another test\ndemonstrates the effectiveness of the developed data-augmentation method in\nincreasing the spatial resolution of the estimated velocity field and in\nreducing the prediction error.",
    "descriptor": "\nComments: 42 pages (double-space), 14 figures, 1 table\n",
    "authors": [
      "Yanhua Liu",
      "Xitong Zhang",
      "Ilya Tsvankin",
      "Youzuo Lin"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04567"
  },
  {
    "id": "arXiv:2212.04569",
    "title": "Knowledge Distillation Applied to Optical Channel Equalization: Solving  the Parallelization Problem of Recurrent Connection",
    "abstract": "To circumvent the non-parallelizability of recurrent neural network-based\nequalizers, we propose knowledge distillation to recast the RNN into a\nparallelizable feedforward structure. The latter shows 38\\% latency decrease,\nwhile impacting the Q-factor by only 0.5dB.",
    "descriptor": "\nComments: Paper Accepted for Oral presentation - OFC 2023 (Optical Fiber Communication Conference)\n",
    "authors": [
      "Sasipim Srivallapanondh",
      "Pedro J. Freire",
      "Bernhard Spinnler",
      "Nelson Costa",
      "Antonio Napoli",
      "Sergei K. Turitsyn",
      "Jaroslaw E. Prilepsky"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04569"
  },
  {
    "id": "arXiv:2212.04572",
    "title": "A Data-driven Cognitive Salience Model for Objective Perceptual Audio  Quality Assessment",
    "abstract": "Objective audio quality measurement systems often use perceptual models to\npredict the subjective quality scores of processed signals, as reported in\nlistening tests. Most systems map different metrics of perceived degradation\ninto a single quality score predicting subjective quality. This requires a\nquality mapping stage that is informed by real listening test data using\nstatistical learning (i.e., a data-driven approach) with distortion metrics as\ninput features. However, the amount of reliable training data is limited in\npractice, and usually not sufficient for a comprehensive training of large\nlearning models. Models of cognitive effects in objective systems can, however,\nimprove the learning model. Specifically, considering the salience of certain\ndistortion types, they provide additional features to the mapping stage that\nimprove the learning process, especially for limited amounts of training data.\nWe propose a novel data-driven salience model that informs the quality mapping\nstage by explicitly estimating the cognitive/degradation metric interactions\nusing a salience measure. Systems incorporating the novel salience model are\nshown to outperform equivalent systems that only use statistical learning to\ncombine cognitive and degradation metrics, as well as other well-known\nmeasurement systems, for a representative validation dataset.",
    "descriptor": "\nComments: Accepted version of the paper submitted to ICASSP 2020\n",
    "authors": [
      "Pablo M. Delgado",
      "J\u00fcrgen Herre"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.04572"
  },
  {
    "id": "arXiv:2212.04579",
    "title": "3D Inception-Based TransMorph: Pre- and Post-operative Multi-contrast  MRI Registration in Brain Tumors",
    "abstract": "Deformable image registration is a key task in medical image analysis. The\nBrain Tumor Sequence Registration challenge (BraTS-Reg) aims at establishing\ncorrespondences between pre-operative and follow-up scans of the same patient\ndiagnosed with an adult brain diffuse high-grade glioma and intends to address\nthe challenging task of registering longitudinal data with major tissue\nappearance changes. In this work, we proposed a two-stage cascaded network\nbased on the Inception and TransMorph models. The dataset for each patient was\ncomprised of a native pre-contrast (T1), a contrast-enhanced T1-weighted\n(T1-CE), a T2-weighted (T2), and a Fluid Attenuated Inversion Recovery (FLAIR).\nThe Inception model was used to fuse the 4 image modalities together and\nextract the most relevant information. Then, a variant of the TransMorph\narchitecture was adapted to generate the displacement fields. The Loss function\nwas composed of a standard image similarity measure, a diffusion regularizer,\nand an edge-map similarity measure added to overcome intensity dependence and\nreinforce correct boundary deformation. We observed that the addition of the\nInception module substantially increased the performance of the network.\nAdditionally, performing an initial affine registration before training the\nmodel showed improved accuracy in the landmark error measurements between pre\nand post-operative MRIs. We observed that our best model composed of the\nInception and TransMorph architectures while using an initially affine\nregistered dataset had the best performance with a median absolute error of\n2.91 (initial error = 7.8). We achieved 6th place at the time of model\nsubmission in the final testing phase of the BraTS-Reg challenge.",
    "descriptor": "\nComments: Contribution to the BraTS-Reg Challenge at MICCAI conference\n",
    "authors": [
      "Javid Abderezaei",
      "Aymeric Pionteck",
      "Agamdeep Chopra",
      "Mehmet Kurt"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04579"
  },
  {
    "id": "arXiv:2212.04580",
    "title": "Effective Dynamics of Generative Adversarial Networks",
    "abstract": "Generative adversarial networks (GANs) are a class of machine-learning models\nthat use adversarial training to generate new samples with the same\n(potentially very complex) statistics as the training samples. One major form\nof training failure, known as mode collapse, involves the generator failing to\nreproduce the full diversity of modes in the target probability distribution.\nHere, we present an effective model of GAN training, which captures the\nlearning dynamics by replacing the generator neural network with a collection\nof particles in the output space; particles are coupled by a universal kernel\nvalid for certain wide neural networks and high-dimensional inputs. The\ngenerality of our simplified model allows us to study the conditions under\nwhich mode collapse occurs. Indeed, experiments which vary the effective kernel\nof the generator reveal a mode collapse transition, the shape of which can be\nrelated to the type of discriminator through the frequency principle. Further,\nwe find that gradient regularizers of intermediate strengths can optimally\nyield convergence through critical damping of the generator dynamics. Our\neffective GAN model thus provides an interpretable physical framework for\nunderstanding and improving adversarial training.",
    "descriptor": "\nComments: 19 pages, 21 figures\n",
    "authors": [
      "Steven Durr",
      "Youssef Mroueh",
      "Yuhai Tu",
      "Shenshen Wang"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.04580"
  },
  {
    "id": "arXiv:2212.04583",
    "title": "High Quality Audio Coding with MDCTNet",
    "abstract": "We propose a neural audio generative model, MDCTNet, operating in the\nperceptually weighted domain of an adaptive modified discrete cosine transform\n(MDCT). The architecture of the model captures correlations in both time and\nfrequency directions with recurrent layers (RNNs). An audio coding system is\nobtained by training MDCTNet on a diverse set of fullband monophonic audio\nsignals at 48 kHz sampling, conditioned by a perceptual audio encoder. In a\nsubjective listening test with ten excerpts chosen to be balanced across\ncontent types, yet stressful for both codecs, the mean performance of the\nproposed system for 24 kb/s variable bitrate (VBR) is similar to that of Opus\nat twice the bitrate.",
    "descriptor": "\nComments: Five pages, five figures\n",
    "authors": [
      "Grant Davidson",
      "Mark Vinton",
      "Per Ekstrand",
      "Cong Zhou",
      "Lars Villemoes",
      "Lie Lu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2212.04583"
  },
  {
    "id": "arXiv:2212.04606",
    "title": "The R-algebra of Quasiknowledge and Convex Optimization",
    "abstract": "This article develops a convex description of a classical or quantum\nlearner's or agent's state of knowledge about its environment, presented as a\nconvex subset of a commutative R-algebra. With caveats, this leads to a\ngeneralization of certain semidefinite programs in quantum information (such as\nthose describing the universal query algorithm dual to the quantum adversary\nbound, related to optimal learning or control of the environment) to the\nclassical and faulty-quantum setting, which would not be possible with a naive\ndescription via joint probability distributions over environment and internal\nmemory. More philosophically, it also makes an interpretation of the set of\nreduced density matrices as \"states of knowledge\" of an observer of its\nenvironment, related to these techniques, more explicit. As another example, I\ndescribe and solve a formal differential equation of states of knowledge in\nthat algebra, where an agent obtains experimental data in a Poissonian process,\nand its state of knowledge evolves as an exponential power series. However,\nthis framework currently lacks impressive applications, and I post it in part\nto solicit feedback and collaboration on those. In particular, it may be\npossible to develop it into a new framework for the design of experiments, e.g.\nthe problem of finding maximally informative questions to ask human labelers or\nthe environment in machine-learning problems. The parts of the article not\nrelated to quantum information don't assume knowledge of it.",
    "descriptor": "\nComments: 40 pages\n",
    "authors": [
      "Duyal Yolcu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04606"
  },
  {
    "id": "arXiv:2212.04617",
    "title": "UNet Based Pipeline for Lung Segmentation from Chest X-Ray Images",
    "abstract": "Biomedical image segmentation is one of the fastest growing fields which has\nseen extensive automation through the use of Artificial Intelligence. This has\nenabled widespread adoption of accurate techniques to expedite the screening\nand diagnostic processes which would otherwise take several days to finalize.\nIn this paper, we present an end-to-end pipeline to segment lungs from chest\nX-ray images, training the neural network model on the Japanese Society of\nRadiological Technology (JSRT) dataset, using UNet to enable faster processing\nof initial screening for various lung disorders. The pipeline developed can be\nreadily used by medical centers with just the provision of X-Ray images as\ninput. The model will perform the preprocessing, and provide a segmented image\nas the final output. It is expected that this will drastically reduce the\nmanual effort involved and lead to greater accessibility in\nresource-constrained locations.",
    "descriptor": "\nComments: 6 Pages\n",
    "authors": [
      "Shashank Shekhar",
      "Ritika Nandi",
      "H Srikanth Kamath"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04617"
  },
  {
    "id": "arXiv:2212.04624",
    "title": "The Hybridization of Branch and Bound with Metaheuristics for Nonconvex  Multiobjective Optimization",
    "abstract": "A hybrid framework combining the branch and bound method with multiobjective\nevolutionary algorithms is proposed for nonconvex multiobjective optimization.\nThe hybridization exploits the complementary character of the two optimization\nstrategies. A multiobjective evolutionary algorithm is intended for inducing\ntight lower and upper bounds during the branch and bound procedure. Tight\nbounds such as the ones derived in this way can reduce the number of\nsubproblems that have to be solved. The branch and bound method guarantees the\nglobal convergence of the framework and improves the search capability of the\nmultiobjective evolutionary algorithm. An implementation of the hybrid\nframework considering NSGA-II and MOEA/D-DE as multiobjective evolutionary\nalgorithms is presented. Numerical experiments verify the hybrid algorithms\nbenefit from synergy of the branch and bound method and multiobjective\nevolutionary algorithms.",
    "descriptor": "",
    "authors": [
      "Wei-tian Wu",
      "Xin-min Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2212.04624"
  },
  {
    "id": "arXiv:2212.04659",
    "title": "A refinement on the structure of vertex-critical ($P_5$, gem)-free  graphs",
    "abstract": "We give a new, stronger proof that there are only finitely many\n$k$-vertex-critical ($P_5$,~gem)-free graphs for all $k$. Our proof further\nrefines the structure of these graphs and allows for the implementation of a\nsimple exhaustive computer search to completely list all $6$- and\n$7$-vertex-critical $(P_5$, gem)-free graphs. Our results imply the existence\nof polynomial-time certifying algorithms to decide the $k$-colourability of\n$(P_5$, gem)-free graphs for all $k$ where the certificate is either a\n$k$-colouring or a $(k+1)$-vertex-critical induced subgraph. Our complete lists\nfor $k\\le 7$ allow for the implementation of these algorithms for all $k\\le 6$.",
    "descriptor": "",
    "authors": [
      "Ben Cameron",
      "Ch\u00ednh T. Ho\u00e0ng"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.04659"
  },
  {
    "id": "arXiv:2212.04672",
    "title": "Primal Dual Alternating Proximal Gradient Algorithms for Nonsmooth  Nonconvex Minimax Problems with Coupled Linear Constraints",
    "abstract": "Nonconvex minimax problems have attracted wide attention in machine learning,\nsignal processing and many other fields in recent years. In this paper, we\npropose a primal dual alternating proximal gradient (PDAPG) algorithm and a\nprimal dual proximal gradient (PDPG-L) algorithm for solving nonsmooth\nnonconvex-strongly concave and nonconvex-linear minimax problems with coupled\nlinear constraints, respectively. The corresponding iteration complexity of the\ntwo algorithms are proved to be $\\mathcal{O}\\left( \\varepsilon ^{-2} \\right)$\nand $\\mathcal{O}\\left( \\varepsilon ^{-3} \\right)$ to reach an\n$\\varepsilon$-stationary point, respectively. To our knowledge, they are the\nfirst two algorithms with iteration complexity guarantee for solving the two\nclasses of minimax problems.",
    "descriptor": "",
    "authors": [
      "Huiling Zhang",
      "Junlin Wang",
      "Zi Xu",
      "Yu-Hong Dai"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.04672"
  },
  {
    "id": "arXiv:2212.04703",
    "title": "Implementing Neural Network-Based Equalizers in a Coherent Optical  Transmission System Using Field-Programmable Gate Arrays",
    "abstract": "In this work, we demonstrate the offline FPGA realization of both recurrent\nand feedforward neural network (NN)-based equalizers for nonlinearity\ncompensation in coherent optical transmission systems. First, we present a\nrealization pipeline showing the conversion of the models from Python libraries\nto the FPGA chip synthesis and implementation. Then, we review the main\nalternatives for the hardware implementation of nonlinear activation functions.\nThe main results are divided into three parts: a performance comparison, an\nanalysis of how activation functions are implemented, and a report on the\ncomplexity of the hardware. The performance in Q-factor is presented for the\ncases of bidirectional long-short-term memory coupled with convolutional NN\n(biLSTM + CNN) equalizer, CNN equalizer, and standard 1-StpS digital\nback-propagation (DBP) for the simulation and experiment propagation of a\nsingle channel dual-polarization (SC-DP) 16QAM at 34 GBd along 17x70km of LEAF.\nThe biLSTM+CNN equalizer provides a similar result to DBP and a 1.7 dB Q-factor\ngain compared with the chromatic dispersion compensation baseline in the\nexperimental dataset. After that, we assess the Q-factor and the impact of\nhardware utilization when approximating the activation functions of NN using\nTaylor series, piecewise linear, and look-up table (LUT) approximations. We\nalso show how to mitigate the approximation errors with extra training and\nprovide some insights into possible gradient problems in the LUT approximation.\nFinally, to evaluate the complexity of hardware implementation to achieve 400G\nthroughput, fixed-point NN-based equalizers with approximated activation\nfunctions are developed and implemented in an FPGA.",
    "descriptor": "\nComments: Invited paper at Journal of Lightwave Technology - IEEE\n",
    "authors": [
      "Pedro J. Freire",
      "Sasipim Srivallapanondh",
      "Michael Anderson",
      "Bernhard Spinnler",
      "Thomas Bex",
      "Tobias A. Eriksson",
      "Antonio Napoli",
      "Wolfgang Schairer",
      "Nelson Costa",
      "Michaela Blott",
      "Sergei K. Turitsyn",
      "Jaroslaw E. Prilepsky"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Hardware Architecture (cs.AR)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04703"
  },
  {
    "id": "arXiv:2212.04749",
    "title": "Validating quantum-supremacy experiments with exact and fast tensor  network contraction",
    "abstract": "The quantum circuits that declare quantum supremacy, such as Google Sycamore\n[Nature \\textbf{574}, 505 (2019)], raises a paradox in building reliable result\nreferences. While simulation on traditional computers seems the sole way to\nprovide reliable verification, the required run time is doomed with an\nexponentially-increasing compute complexity. To find a way to validate current\n``quantum-supremacy\" circuits with more than $50$ qubits, we propose a\nsimulation method that exploits the ``classical advantage\" (the inherent\n``store-and-compute\" operation mode of von Neumann machines) of current\nsupercomputers, and computes uncorrelated amplitudes of a random quantum\ncircuit with an optimal reuse of the intermediate results and a minimal memory\noverhead throughout the process. Such a reuse strategy reduces the original\nlinear scaling of the total compute cost against the number of amplitudes to a\nsublinear pattern, with greater reduction for more amplitudes. Based on a\nwell-optimized implementation of this method on a new-generation Sunway\nsupercomputer, we directly verify Sycamore by computing three million exact\namplitudes for the experimentally generated bitstrings, obtaining an XEB\nfidelity of $0.191\\%$ which closely matches the estimated value of $0.224\\%$.\nOur computation scales up to $41,932,800$ cores with a sustained\nsingle-precision performance of $84.8$ Pflops, which is accomplished within\n$8.5$ days. Our method has a far-reaching impact in solving quantum many-body\nproblems, statistical problems as well as combinatorial optimization problems\nwhere one often needs to contract many tensor networks which share a\nsignificant portion of tensors in common.",
    "descriptor": "\nComments: 7 pages, 4 figures, comments are welcome!\n",
    "authors": [
      "Yong Liu",
      "Yaojian Chen",
      "Chu Guo",
      "Jiawei Song",
      "Xinmin Shi",
      "Lin Gan",
      "Wenzhao Wu",
      "Wei Wu",
      "Haohuan Fu",
      "Xin Liu",
      "Dexun Chen",
      "Guangwen Yang",
      "Jiangang Gao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.04749"
  },
  {
    "id": "arXiv:2212.04813",
    "title": "Remote estimation of geologic composition using interferometric  synthetic-aperture radar in California's Central Valley",
    "abstract": "California's Central Valley is the national agricultural center, producing\n1/4 of the nation's food. However, land in the Central Valley is sinking at a\nrapid rate (as much as 20 cm per year) due to continued groundwater pumping.\nLand subsidence has a significant impact on infrastructure resilience and\ngroundwater sustainability. In this study, we aim to identify specific regions\nwith different temporal dynamics of land displacement and find relationships\nwith underlying geological composition. Then, we aim to remotely estimate\ngeologic composition using interferometric synthetic aperture radar\n(InSAR)-based land deformation temporal changes using machine learning\ntechniques. We identified regions with different temporal characteristics of\nland displacement in that some areas (e.g., Helm) with coarser grain geologic\ncompositions exhibited potentially reversible land deformation (elastic land\ncompaction). We found a significant correlation between InSAR-based land\ndeformation and geologic composition using random forest and deep neural\nnetwork regression models. We also achieved significant accuracy with 1/4\nsparse sampling to reduce any spatial correlations among data, suggesting that\nthe model has the potential to be generalized to other regions for indirect\nestimation of geologic composition. Our results indicate that geologic\ncomposition can be estimated using InSAR-based land deformation data. In-situ\nmeasurements of geologic composition can be expensive and time consuming and\nmay be impractical in some areas. The generalizability of the model sheds light\non high spatial resolution geologic composition estimation utilizing existing\nmeasurements.",
    "descriptor": "\nComments: 10 pages, 7 figures, NeurIPS 2022\n",
    "authors": [
      "Kyongsik Yun",
      "Kyra Adams",
      "John Reager",
      "Zhen Liu",
      "Caitlyn Chavez",
      "Michael Turmon",
      "Thomas Lu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.04813"
  },
  {
    "id": "arXiv:2212.04817",
    "title": "A New OFDM System for IIR Channels",
    "abstract": "In this paper, we propose a new OFDM system for an IIR channel with the form\nof $B(z)/A(z)$ for two polynomials $A(z)$ and $B(z)$. Different from the\nconventional OFDM transmission over an FIR channel, a guard interval of an OFDM\nsymbol is added such that the corresponding part at receiver is the cyclic\nprefix (CP) of the received OFDM symbol. The guard interval and CP lengths are\nthe same and not smaller than the orders of polynomials $A(z)$ and $B(z)$. The\nOFDM symbol without the guard interval is the same as the conventional OFDM\nsymbol without the CP. At the receiver, the IIR channel is then converted to\n$N$ intersymbol interference (ISI) free subchannels, where $N$ is the number of\nsubcarriers of an OFDM symbol.",
    "descriptor": "",
    "authors": [
      "Xiang-Gen Xia"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.04817"
  },
  {
    "id": "arXiv:2212.04827",
    "title": "Cortical origins of MacKay-type visual illusions. A case for the  non-linearity",
    "abstract": "To study the interaction between retinal stimulation by redundant geometrical\npatterns and the cortical response in the primary visual cortex (V1), we focus\non the MacKay effect (Nature, 1957) and Billock and Tsou's experiments (PNAS,\n2007). Starting from a classical biological model of neuronal fields equations\nwith a non-linear response function, we use a controllability approach to\ndescribe these phenomena. The external input containing a localised control\nfunction is interpreted as a cortical representation of the static visual\nstimuli used in these experiments. We prove that while the MacKay effect is\nessentially a linear phenomenon (i.e., the nonlinear nature of the activation\ndoes not play any role in its reproduction), the phenomena reported by Billock\nand Tsou are wholly nonlinear and depend strongly on the shape of the\nnonlinearity used to model the response function.",
    "descriptor": "",
    "authors": [
      "Cyprien Tamekue",
      "Dario Prandi",
      "Yacine Chitour"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Pattern Formation and Solitons (nlin.PS)"
    ],
    "url": "https://arxiv.org/abs/2212.04827"
  },
  {
    "id": "arXiv:2212.04831",
    "title": "Uncertainty Estimation in Deep Speech Enhancement Using Complex Gaussian  Mixture Models",
    "abstract": "Single-channel deep speech enhancement approaches often estimate a single\nmultiplicative mask to extract clean speech without a measure of its accuracy.\nInstead, in this work, we propose to quantify the uncertainty associated with\nclean speech estimates in neural network-based speech enhancement. Predictive\nuncertainty is typically categorized into aleatoric uncertainty and epistemic\nuncertainty. The former accounts for the inherent uncertainty in data and the\nlatter corresponds to the model uncertainty. Aiming for robust clean speech\nestimation and efficient predictive uncertainty quantification, we propose to\nintegrate statistical complex Gaussian mixture models (CGMMs) into a deep\nspeech enhancement framework. More specifically, we model the dependency\nbetween input and output stochastically by means of a conditional probability\ndensity and train a neural network to map the noisy input to the full posterior\ndistribution of clean speech, modeled as a mixture of multiple complex Gaussian\ncomponents. Experimental results on different datasets show that the proposed\nalgorithm effectively captures predictive uncertainty and that combining\npowerful statistical models and deep learning also delivers a superior speech\nenhancement performance.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Huajian Fang",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2212.04831"
  },
  {
    "id": "arXiv:2212.04832",
    "title": "Noise2Contrast: Multi-Contrast Fusion Enables Self-Supervised  Tomographic Image Denoising",
    "abstract": "Self-supervised image denoising techniques emerged as convenient methods that\nallow training denoising models without requiring ground-truth noise-free data.\nExisting methods usually optimize loss metrics that are calculated from\nmultiple noisy realizations of similar images, e.g., from neighboring\ntomographic slices. However, those approaches fail to utilize the multiple\ncontrasts that are routinely acquired in medical imaging modalities like MRI or\ndual-energy CT. In this work, we propose the new self-supervised training\nscheme Noise2Contrast that combines information from multiple measured image\ncontrasts to train a denoising model. We stack denoising with domain-transfer\noperators to utilize the independent noise realizations of different image\ncontrasts to derive a self-supervised loss. The trained denoising operator\nachieves convincing quantitative and qualitative results, outperforming\nstate-of-the-art self-supervised methods by 4.7-11.0%/4.8-7.3% (PSNR/SSIM) on\nbrain MRI data and by 43.6-50.5%/57.1-77.1% (PSNR/SSIM) on dual-energy CT X-ray\nmicroscopy data with respect to the noisy baseline. Our experiments on\ndifferent real measured data sets indicate that Noise2Contrast training\ngeneralizes to other multi-contrast imaging modalities.",
    "descriptor": "",
    "authors": [
      "Fabian Wagner",
      "Mareike Thies",
      "Laura Pfaff",
      "Noah Maul",
      "Sabrina Pechmann",
      "Mingxuan Gu",
      "Jonas Utz",
      "Oliver Aust",
      "Daniela Weidner",
      "Georgiana Neag",
      "Stefan Uderhardt",
      "Jang-Hwan Choi",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04832"
  },
  {
    "id": "arXiv:2212.04881",
    "title": "ProductGraphSleepNet: Sleep Staging using Product Spatio-Temporal Graph  Learning with Attentive Temporal Aggregation",
    "abstract": "The classification of sleep stages plays a crucial role in understanding and\ndiagnosing sleep pathophysiology. Sleep stage scoring relies heavily on visual\ninspection by an expert that is time consuming and subjective procedure.\nRecently, deep learning neural network approaches have been leveraged to\ndevelop a generalized automated sleep staging and account for shifts in\ndistributions that may be caused by inherent inter/intra-subject variability,\nheterogeneity across datasets, and different recording environments. However,\nthese networks ignore the connections among brain regions, and disregard the\nsequential connections between temporally adjacent sleep epochs. To address\nthese issues, this work proposes an adaptive product graph learning-based graph\nconvolutional network, named ProductGraphSleepNet, for learning joint\nspatio-temporal graphs along with a bidirectional gated recurrent unit and a\nmodified graph attention network to capture the attentive dynamics of sleep\nstage transitions. Evaluation on two public databases: the Montreal Archive of\nSleep Studies (MASS) SS3; and the SleepEDF, which contain full night\npolysomnography recordings of 62 and 20 healthy subjects, respectively,\ndemonstrates performance comparable to the state-of-the-art (Accuracy:\n0.867;0.838, F1-score: 0.818;0.774 and Kappa: 0.802;0.775, on each database\nrespectively). More importantly, the proposed network makes it possible for\nclinicians to comprehend and interpret the learned connectivity graphs for\nsleep stages.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Aref Einizade",
      "Samaneh Nasiri",
      "Sepideh Hajipour Sardouie",
      "Gari Clifford"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04881"
  },
  {
    "id": "arXiv:2212.04902",
    "title": "Self-Supervised PPG Representation Learning Shows High Inter-Subject  Variability",
    "abstract": "With the progress of sensor technology in wearables, the collection and\nanalysis of PPG signals are gaining more interest. Using Machine Learning, the\ncardiac rhythm corresponding to PPG signals can be used to predict different\ntasks such as activity recognition, sleep stage detection, or more general\nhealth status. However, supervised learning is often limited by the amount of\navailable labeled data, which is typically expensive to obtain. To address this\nproblem, we propose a Self-Supervised Learning (SSL) method with a pretext task\nof signal reconstruction to learn an informative generalized PPG\nrepresentation. The performance of the proposed SSL framework is compared with\ntwo fully supervised baselines. The results show that in a very limited label\ndata setting (10 samples per class or less), using SSL is beneficial, and a\nsimple classifier trained on SSL-learned representations outperforms fully\nsupervised deep neural networks. However, the results reveal that the\nSSL-learned representations are too focused on encoding the subjects.\nUnfortunately, there is high inter-subject variability in the SSL-learned\nrepresentations, which makes working with this data more challenging when\nlabeled data is scarce. The high inter-subject variability suggests that there\nis still room for improvements in learning representations. In general, the\nresults suggest that SSL may pave the way for the broader use of machine\nlearning models on PPG data in label-scarce regimes.",
    "descriptor": "",
    "authors": [
      "Ramin Ghorbani",
      "Marcel T.J. Reinders",
      "David M.J. Tax"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04902"
  },
  {
    "id": "arXiv:2212.04905",
    "title": "Robust detection and attribution of climate change under interventions",
    "abstract": "Fingerprints are key tools in climate change detection and attribution (D&A)\nthat are used to determine whether changes in observations are different from\ninternal climate variability (detection), and whether observed changes can be\nassigned to specific external drivers (attribution). We propose a direct D&A\napproach based on supervised learning to extract fingerprints that lead to\nrobust predictions under relevant interventions on exogenous variables, i.e.,\nclimate drivers other than the target. We employ anchor regression, a\ndistributionally-robust statistical learning method inspired by causal\ninference that extrapolates well to perturbed data under the interventions\nconsidered. The residuals from the prediction achieve either uncorrelatedness\nor mean independence with the exogenous variables, thus guaranteeing\nrobustness. We define D&A as a unified hypothesis testing framework that relies\non the same statistical model but uses different targets and test statistics.\nIn the experiments, we first show that the CO2 forcing can be robustly\npredicted from temperature spatial patterns under strong interventions on the\nsolar forcing. Second, we illustrate attribution to the greenhouse gases and\naerosols while protecting against interventions on the aerosols and CO2\nforcing, respectively. Our study shows that incorporating robustness\nconstraints against relevant interventions may significantly benefit detection\nand attribution of climate change.",
    "descriptor": "",
    "authors": [
      "Enik\u0151 Sz\u00e9kely",
      "Sebastian Sippel",
      "Nicolai Meinshausen",
      "Guillaume Obozinski",
      "Reto Knutti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.04905"
  },
  {
    "id": "arXiv:2212.04908",
    "title": "Reconfigurable Intelligent Surfaces for 6G -- Applications, Challenges  and Solutions",
    "abstract": "It is expected that scholars will continuously strengthen the depth and\nbreadth of theoretical research on RIS, and provide a higher theoretical upper\nbound for the engineering application of RIS. While making breakthroughs in\nacademic research, it has also made rapid progress in engineering application\nresearch and industrialization promotion. This paper will provide an overview\nof RIS engineering applications, and make a systematic and in-depth analysis of\nthe challenges and candidate solutions of RIS engineering applications. Future\ntrends and challenges are also provided.",
    "descriptor": "\nComments: 22\n",
    "authors": [
      "Yajun Zhao",
      "Xin Lv"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.04908"
  },
  {
    "id": "arXiv:2212.04913",
    "title": "Review of Ansatz Designing Techniques for Variational Quantum Algorithms",
    "abstract": "For a large number of tasks, quantum computing demonstrates the potential for\nexponential acceleration over classical computing. In the NISQ era,\nvariable-component subcircuits enable applications of quantum computing. To\nreduce the inherent noise and qubit size limitations of quantum computers,\nexisting research has improved the accuracy and efficiency of Variational\nQuantum Algorithm (VQA). In this paper, we explore the various ansatz\nimprovement methods for VQAs at the gate level and pulse level, and classify,\nevaluate and summarize them.",
    "descriptor": "\nComments: 8 pages, 5 figure\n",
    "authors": [
      "Junhan Qin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04913"
  },
  {
    "id": "arXiv:2212.04921",
    "title": "Do we live in a [quantum] simulation? Constraints, observations, and  experiments on the simulation hypothesis",
    "abstract": "The question \"What is real?\" can be traced back to the shadows in Plato's\ncave. Two thousand years later, Rene Descartes lacked knowledge about arguing\nagainst an evil deceiver feeding us the illusion of sensation. Descartes'\nepistemological concept later led to various theories of sensory experiences.\nThe concept of \"illusionism\", proposing that even the very conscious experience\nwe have is an illusion, is not only a red-pill scenario found in the 1999\nscience fiction movie \"The Matrix\" but is also a philosophical concept promoted\nby modern tinkers, most prominently by Daniel Dennett. Reflection upon a\npossible simulation and our perceived reality was beautifully visualized in\n\"The Matrix\", bringing the old ideas of Descartes to coffee houses around the\nworld. Irish philosopher Bishop Berkeley was the father of what was later\ncoined as \"subjective idealism\", basically stating that \"what you perceive is\nreal\". With the advent of quantum technologies based on the control of\nindividual fundamental particles, the question of whether our universe is a\nsimulation isn't just intriguing. Our ever-advancing understanding of\nfundamental physical processes will likely lead us to build quantum computers\nutilizing quantum effects for simulating nature quantum-mechanically in all\ncomplexity, as famously envisioned by Richard Feynman. In this article, we\noutline constraints on the limits of computability and predictability in/of the\nuniverse, which we then use to design experiments allowing for first\nconclusions as to whether we participate in a simulation chain. Eventually, in\na simulation in which the computer simulating a universe is governed by the\nsame physical laws as the simulation, the exhaustion of computational resources\nwill halt all simulations down the simulation chain unless an external\nprogrammer intervenes, which we may be able to observe.",
    "descriptor": "\nComments: 27 pages, 5 figures\n",
    "authors": [
      "Florian Neukart",
      "Anders Indset",
      "Markus Pflitsch",
      "Michael Perelshtein"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computers and Society (cs.CY)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.04921"
  },
  {
    "id": "arXiv:2212.04922",
    "title": "Doubly Robust Kernel Statistics for Testing Distributional Treatment  Effects Even Under One Sided Overlap",
    "abstract": "As causal inference becomes more widespread the importance of having good\ntools to test for causal effects increases. In this work we focus on the\nproblem of testing for causal effects that manifest in a difference in\ndistribution for treatment and control. We build on work applying kernel\nmethods to causality, considering the previously introduced Counterfactual Mean\nEmbedding framework (\\textsc{CfME}). We improve on this by proposing the\n\\emph{Doubly Robust Counterfactual Mean Embedding} (\\textsc{DR-CfME}), which\nhas better theoretical properties than its predecessor by leveraging\nsemiparametric theory. This leads us to propose new kernel based test\nstatistics for distributional effects which are based upon doubly robust\nestimators of treatment effects. We propose two test statistics, one which is a\ndirect improvement on previous work and one which can be applied even when the\nsupport of the treatment arm is a subset of that of the control arm. We\ndemonstrate the validity of our methods on simulated and real-world data, as\nwell as giving an application in off-policy evaluation.",
    "descriptor": "\nComments: 9 pages, Preprint\n",
    "authors": [
      "Jake Fawkes",
      "Robert Hu",
      "Robin J. Evans",
      "Dino Sejdinovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04922"
  },
  {
    "id": "arXiv:2212.04923",
    "title": "Eulerian Phase-based Motion Magnification for High-Fidelity Vital Sign  Estimation with Radar in Clinical Settings",
    "abstract": "Efficient and accurate detection of subtle motion generated from small\nobjects in noisy environments, as needed for vital sign monitoring, is\nchallenging, but can be substantially improved with magnification. We developed\na complex Gabor filter-based decomposition method to amplify phases at\ndifferent spatial wavelength levels to magnify motion and extract 1D motion\nsignals for fundamental frequency estimation. The phase-based complex Gabor\nfilter outputs are processed and then used to train machine learning models\nthat predict respiration and heart rate with greater accuracy. We show that our\nproposed technique performs better than the conventional temporal FFT-based\nmethod in clinical settings, such as sleep laboratories and emergency\ndepartments, as well for a variety of human postures.",
    "descriptor": "\nComments: Accepted in IEEE Sensors 2022\n",
    "authors": [
      "Md Farhan Tasnim Oshim",
      "Toral Surti",
      "Stephanie Carreiro",
      "Deepak Ganesan",
      "Suren Jayasuriya",
      "Tauhidur Rahman"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04923"
  },
  {
    "id": "arXiv:2212.04928",
    "title": "P2T2: a Physically-primed deep-neural-network approach for robust  $T_{2}$ distribution estimation from quantitative $T_{2}$-weighted MRI",
    "abstract": "Estimation of the T2 distribution from multi-echo T2-Weighted MRI (T2W) data\ncan provide insight into the microscopic content of tissue using macroscopic\nimaging. This information can be used as a biomarker for several pathologies,\nsuch as tumor characterization, osteoarthritis, and neurodegenerative diseases.\nRecently, deep neural network (DNN) based methods were proposed for T2\ndistribution estimation from MRI data. However, these methods are highly\nsensitive to distribution shifts such as variations in the echo-times (TE) used\nduring acquisition. Therefore, DNN-based methods cannot be utilized in\nlarge-scale multi-institutional trials with heterogeneous acquisition\nprotocols. We present P2T2, a new physically-primed DNN approach for T2\ndistribution estimation that is robust to different acquisition parameters\nwhile maintaining state-of-the-art estimation accuracy. Our P2T2 model encodes\nthe forward model of the signal decay by taking as input the TE acquisition\narray, in addition to the MRI signal, and provides an estimate of the\ncorresponding T2 distribution as its output. Our P2T2 model has improved the\nrobustness against distribution shifts in the acquisition process by more than\n50% compared to the previously proposed DNN model. When tested without any\ndistribution shifts, our model achieved about the same accuracy. Finally, when\napplied to real human MRI data, our P2T2 model produced the most detailed\nMyelin-Water fraction maps compared to both the MIML model and classical\napproaches. Our proposed physically-primed approach improved the generalization\ncapacity of DNN models for T2 distribution estimation and their robustness\nagainst distribution shifts compared to previous approaches without\ncompromising the accuracy.",
    "descriptor": "",
    "authors": [
      "Hadas Ben-Atya",
      "Moti Freiman"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04928"
  },
  {
    "id": "arXiv:2212.04930",
    "title": "DDSupport: Language Learning Support System that Displays Differences  and Distances from Model Speech",
    "abstract": "When beginners learn to speak a non-native language, it is difficult for them\nto judge for themselves whether they are speaking well. Therefore,\ncomputer-assisted pronunciation training systems are used to detect learner\nmispronunciations. These systems typically compare the user's speech with that\nof a specific native speaker as a model in units of rhythm, phonemes, or words\nand calculate the differences. However, they require extensive speech data with\ndetailed annotations or can only compare with one specific native speaker. To\novercome these problems, we propose a new language learning support system that\ncalculates speech scores and detects mispronunciations by beginners based on a\nsmall amount of unannotated speech data without comparison to a specific\nperson. The proposed system uses deep learning--based speech processing to\ndisplay the pronunciation score of the learner's speech and the\ndifference/distance between the learner's and a group of models' pronunciation\nin an intuitively visual manner. Learners can gradually improve their\npronunciation by eliminating differences and shortening the distance from the\nmodel until they become sufficiently proficient. Furthermore, since the\npronunciation score and difference/distance are not calculated compared to\nspecific sentences of a particular model, users are free to study the sentences\nthey wish to study. We also built an application to help non-native speakers\nlearn English and confirmed that it can improve users' speech intelligibility.",
    "descriptor": "",
    "authors": [
      "Kazuki Kawamura",
      "Jun Rekimoto"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2212.04930"
  },
  {
    "id": "arXiv:2212.04936",
    "title": "Deep conv-attention model for diagnosing left bundle branch block from  12-lead electrocardiograms",
    "abstract": "Cardiac resynchronization therapy (CRT) is a treatment that is used to\ncompensate for irregularities in the heartbeat. Studies have shown that this\ntreatment is more effective in heart patients with left bundle branch block\n(LBBB) arrhythmia. Therefore, identifying this arrhythmia is an important\ninitial step in determining whether or not to use CRT. On the other hand,\ntraditional methods for detecting LBBB on electrocardiograms (ECG) are often\nassociated with errors. Thus, there is a need for an accurate method to\ndiagnose this arrhythmia from ECG data. Machine learning, as a new field of\nstudy, has helped to increase human systems' performance. Deep learning, as a\nnewer subfield of machine learning, has more power to analyze data and increase\nsystems accuracy. This study presents a deep learning model for the detection\nof LBBB arrhythmia from 12-lead ECG data. This model consists of 1D dilated\nconvolutional layers. Attention mechanism has also been used to identify\nimportant input data features and classify inputs more accurately. The proposed\nmodel is trained and validated on a database containing 10344 12-lead ECG\nsamples using the 10-fold cross-validation method. The final results obtained\nby the model on the 12-lead ECG data are as follows. Accuracy: 98.80+-0.08%,\nspecificity: 99.33+-0.11 %, F1 score: 73.97+-1.8%, and area under the receiver\noperating characteristics curve (AUC): 0.875+-0.0192. These results indicate\nthat the proposed model in this study can effectively diagnose LBBB with good\nefficiency and, if used in medical centers, will greatly help diagnose this\narrhythmia and early treatment.",
    "descriptor": "",
    "authors": [
      "Alireza Sadeghi",
      "Alireza Rezaee",
      "Farshid Hajati"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04936"
  },
  {
    "id": "arXiv:2212.04938",
    "title": "Emergent Computations in Trained Artificial Neural Networks and Real  Brains",
    "abstract": "Synaptic plasticity allows cortical circuits to learn new tasks and to adapt\nto changing environments. How do cortical circuits use plasticity to acquire\nfunctions such as decision-making or working memory? Neurons are connected in\ncomplex ways, forming recurrent neural networks, and learning modifies the\nstrength of their connections. Moreover, neurons communicate emitting brief\ndiscrete electric signals. Here we describe how to train recurrent neural\nnetworks in tasks like those used to train animals in neuroscience\nlaboratories, and how computations emerge in the trained networks.\nSurprisingly, artificial networks and real brains can use similar computational\nstrategies.",
    "descriptor": "",
    "authors": [
      "Nestor Parga",
      "Luis Serrano-Fernandez",
      "Joan Falco-Roget"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2212.04938"
  },
  {
    "id": "arXiv:2212.04942",
    "title": "Digital quantum simulation of Schr\u00f6dinger dynamics using adaptive  approximations of potential functions",
    "abstract": "Digital quantum simulation (DQS) of continuous-variable quantum systems in\nthe position basis requires efficient implementation of diagonal unitaries\napproximating the time evolution operator generated by the potential energy\nfunction. In this work, we provide efficient implementations suitable for\npotential functions approximable by piecewise polynomials, with either uniform\nor adaptively chosen subdomains. For a fixed precision of approximation, we\nshow how adaptive grids can significantly reduce the total gate count at the\ncost of introducing a small number of ancillary qubits. We demonstrate the\ncircuit construction with both physically motivated and artificially designed\npotential functions, and discuss their generalizations to higher dimensions.",
    "descriptor": "",
    "authors": [
      "Tenzan Araki",
      "James Stokes",
      "Shravan Veerapaneni"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.04942"
  },
  {
    "id": "arXiv:2212.04948",
    "title": "A Learned Born Series for Highly-Scattering Media",
    "abstract": "A new method for solving the wave equation is presented, called the learned\nBorn series (LBS), which is derived from a convergent Born Series but its\ncomponents are found through training. The LBS is shown to be significantly\nmore accurate than the convergent Born series for the same number of\niterations, in the presence of high contrast scatterers, while maintaining a\ncomparable computational complexity. The LBS is able to generate a reasonable\nprediction of the global pressure field with a small number of iterations, and\nthe errors decrease with the number of learned iterations.",
    "descriptor": "\nComments: 6 pages, 1 figure\n",
    "authors": [
      "Antonio Stanziola",
      "Simon Arridge",
      "Ben T. Cox",
      "Bradley E. Treeby"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.04948"
  },
  {
    "id": "arXiv:2212.04951",
    "title": "EEG-NeXt: A Modernized ConvNet for The Classification of Cognitive  Activity from EEG",
    "abstract": "One of the main challenges in electroencephalogram (EEG) based brain-computer\ninterface (BCI) systems is learning the subject/session invariant features to\nclassify cognitive activities within an end-to-end discriminative setting. We\npropose a novel end-to-end machine learning pipeline, EEG-NeXt, which\nfacilitates transfer learning by: i) aligning the EEG trials from different\nsubjects in the Euclidean-space, ii) tailoring the techniques of deep learning\nfor the scalograms of EEG signals to capture better frequency localization for\nlow-frequency, longer-duration events, and iii) utilizing pretrained ConvNeXt\n(a modernized ResNet architecture which supersedes state-of-the-art (SOTA)\nimage classification models) as the backbone network via adaptive finetuning.\nOn publicly available datasets (Physionet Sleep Cassette and BNCI2014001) we\nbenchmark our method against SOTA via cross-subject validation and demonstrate\nimproved accuracy in cognitive activity classification along with better\ngeneralizability across cohorts.",
    "descriptor": "",
    "authors": [
      "Andac Demir",
      "Iya Khalil",
      "Bulent Kiziltan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2212.04951"
  },
  {
    "id": "arXiv:2212.04953",
    "title": "TargetCall: Eliminating the Wasted Computation in Basecalling via  Pre-Basecalling Filtering",
    "abstract": "Basecalling is an essential step in nanopore sequencing analysis where the\nraw signals of nanopore sequencers are converted into nucleotide sequences,\ni.e., reads. State-of-the-art basecallers employ complex deep learning models\nto achieve high basecalling accuracy. This makes basecalling\ncomputationally-inefficient and memory-hungry; bottlenecking the entire genome\nanalysis pipeline. However, for many applications, the majority of reads do no\nmatch the reference genome of interest (i.e., target reference) and thus are\ndiscarded in later steps in the genomics pipeline, wasting the basecalling\ncomputation. To overcome this issue, we propose TargetCall, the first fast and\nwidely-applicable pre-basecalling filter to eliminate the wasted computation in\nbasecalling. TargetCall's key idea is to discard reads that will not match the\ntarget reference (i.e., off-target reads) prior to basecalling. TargetCall\nconsists of two main components: (1) LightCall, a lightweight neural network\nbasecaller that produces noisy reads; and (2) Similarity Check, which labels\neach of these noisy reads as on-target or off-target by matching them to the\ntarget reference. TargetCall filters out all off-target reads before\nbasecalling; and the highly-accurate but slow basecalling is performed only on\nthe raw signals whose noisy reads are labeled as on-target. Our thorough\nexperimental evaluations using both real and simulated data show that\nTargetCall 1) improves the end-to-end basecalling performance of the\nstate-of-the-art basecaller by 3.31x while maintaining high (98.88%)\nsensitivity in keeping on-target reads, 2) maintains high accuracy in\ndownstream analysis, 3) precisely filters out up to 94.71% of off-target reads,\nand 4) achieves better performance, sensitivity, and generality compared to\nprior works. We freely open-source TargetCall at\nhttps://github.com/CMU-SAFARI/TargetCall.",
    "descriptor": "",
    "authors": [
      "Meryem Banu Cavlak",
      "Gagandeep Singh",
      "Mohammed Alser",
      "Can Firtina",
      "Jo\u00ebl Lindegger",
      "Mohammad Sadrosadati",
      "Nika Mansouri Ghiasi",
      "Can Alkan",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04953"
  },
  {
    "id": "arXiv:2212.05008",
    "title": "Hyperbolic Audio Source Separation",
    "abstract": "We introduce a framework for audio source separation using embeddings on a\nhyperbolic manifold that compactly represent the hierarchical relationship\nbetween sound sources and time-frequency features. Inspired by recent successes\nmodeling hierarchical relationships in text and images with hyperbolic\nembeddings, our algorithm obtains a hyperbolic embedding for each\ntime-frequency bin of a mixture signal and estimates masks using hyperbolic\nsoftmax layers. On a synthetic dataset containing mixtures of multiple people\ntalking and musical instruments playing, our hyperbolic model performed\ncomparably to a Euclidean baseline in terms of source to distortion ratio, with\nstronger performance at low embedding dimensions. Furthermore, we find that\ntime-frequency regions containing multiple overlapping sources are embedded\ntowards the center (i.e., the most uncertain region) of the hyperbolic space,\nand we can use this certainty estimate to efficiently trade-off between\nartifact introduction and interference reduction when isolating individual\nsounds.",
    "descriptor": "\nComments: Submitted to ICASSP 2023, Demo page: this https URL\n",
    "authors": [
      "Darius Petermann",
      "Gordon Wichern",
      "Aswin Subramanian",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2212.05008"
  },
  {
    "id": "arXiv:2212.05014",
    "title": "A reversed form of public goods game: equivalence and difference",
    "abstract": "According to the public goods game (PGG) protocol, participants decide freely\nwhether they want to contribute to a common pool or not, but the resulting\nbenefit is distributed equally. A conceptually similar dilemma situation may\nemerge when participants consider if they claim a common resource but the\nrelated cost is covered equally by all group members. The latter establishes a\nreversed form of the original public goods game (R-PGG). In this work, we show\nthat R-PGG is equivalent to PGG in several circumstances, starting from the\ntraditional analysis, via the evolutionary approach in unstructured\npopulations, to Monte Carlo simulations in structured populations. However,\nthere are also cases when the behavior of R-PGG could be surprisingly different\nfrom the outcome of PGG. When the key parameters are heterogeneous, for\ninstance, the results of PGG and R-PGG could be diverse even if we apply the\nsame amplitudes of heterogeneity. We find that the heterogeneity in R-PGG\ngenerally impedes cooperation, while the opposite is observed for PGG. These\ndiverse system reactions can be understood if we follow how payoff functions\nchange when introducing heterogeneity in the parameter space. This analysis\nalso reveals the distinct roles of cooperator and defector strategies in the\nmentioned games. Our observations may hopefully stimulate further research to\ncheck the potential differences between PGG and R-PGG due to the alternative\ncomplexity of conditions.",
    "descriptor": "\nComments: 30 pages, 11 figures, accepted for publication in New Journal of Physics\n",
    "authors": [
      "Chaoqian Wang",
      "Attila Szolnoki"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computer Science and Game Theory (cs.GT)",
      "Pattern Formation and Solitons (nlin.PS)"
    ],
    "url": "https://arxiv.org/abs/2212.05014"
  },
  {
    "id": "arXiv:2212.05017",
    "title": "A general framework for the rigorous computation of invariant densities  and the coarse-fine strategy",
    "abstract": "In this paper we present a general, axiomatical framework for the rigorous\napproximation of invariant densities and other important statistical features\nof dynamics. We approximate the system trough a finite element reduction, by\ncomposing the associated transfer operator with a suitable finite dimensional\nprojection (a discretization scheme) as in the well-known Ulam method.\nWe introduce a general framework based on a list of properties (of the system\nand of the projection) that need to be verified so that we can take advantage\nof a so-called ``coarse-fine'' strategy. This strategy is a novel method in\nwhich we exploit information coming from a coarser approximation of the system\nto get useful information on a finer approximation, speeding up the\ncomputation. This coarse-fine strategy allows a precise estimation of invariant\ndensities and also allows to estimate rigorously the speed of mixing of the\nsystem by the speed of mixing of a coarse approximation of it, which can easily\nbe estimated by the computer.\nThe estimates obtained here are rigourous, i.e., they come with exact error\nbounds that are guaranteed to hold and take into account both the\ndiscretiazation and the approximations induced by finite-precision arithmetic.\nWe apply this framework to several discretization schemes and examples of\ninvariant density computation from previous works, obtaining a remarkable\nreduction in computation time.\nWe have implemented the numerical methods described here in the Julia\nprogramming language, and released our implementation publicly as a Julia\npackage.",
    "descriptor": "",
    "authors": [
      "Stefano Galatolo",
      "Maurizio Monge",
      "Isaia Nisoli",
      "Federico Poloni"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2212.05017"
  },
  {
    "id": "arXiv:2212.05050",
    "title": "The unstable formula theorem revisited",
    "abstract": "We first prove that Littlestone classes, those which model theorists call\nstable, characterize learnability in a new statistical model: a learner in this\nnew setting outputs the same hypothesis, up to measure zero, with probability\none, after a uniformly bounded number of revisions. This fills a certain gap in\nthe literature, and sets the stage for an approximation theorem characterizing\nLittlestone classes in terms of a range of learning models, by analogy to\ndefinability of types in model theory. We then give a complete analogue of\nShelah's celebrated (and perhaps a priori untranslatable) Unstable Formula\nTheorem in the learning setting, with algorithmic arguments taking the place of\nthe infinite.",
    "descriptor": "",
    "authors": [
      "Maryanthe Malliaris",
      "Shay Moran"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2212.05050"
  },
  {
    "id": "arXiv:1805.02351",
    "title": "Fine-grained Complexity Meets IP = PSPACE",
    "abstract": "Comments: Fixed a mistake in Theorem 11.2 (we thank Ray Li for pointing it out to us); all main results are unaffected",
    "descriptor": "\nComments: Fixed a mistake in Theorem 11.2 (we thank Ray Li for pointing it out to us); all main results are unaffected\n",
    "authors": [
      "Lijie Chen",
      "Shafi Goldwasser",
      "Kaifeng Lyu",
      "Guy N. Rothblum",
      "Aviad Rubinstein"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1805.02351"
  },
  {
    "id": "arXiv:1805.08102",
    "title": "PiPs: a Kernel-based Optimization Scheme for Analyzing Non-Stationary 1D  Signals",
    "abstract": "PiPs: a Kernel-based Optimization Scheme for Analyzing Non-Stationary 1D  Signals",
    "descriptor": "",
    "authors": [
      "Jieren Xu",
      "Yitong Li",
      "Haizhao Yang",
      "David Dunson",
      "Ingrid Daubechies"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1805.08102"
  },
  {
    "id": "arXiv:1904.12060",
    "title": "Every planar graph with $\u0394\\geqslant 8$ is totally  $(\u0394+2)$-choosable",
    "abstract": "Comments: 64 pages, 77 figures",
    "descriptor": "\nComments: 64 pages, 77 figures\n",
    "authors": [
      "Marthe Bonamy",
      "Th\u00e9o Pierron",
      "\u00c9ric Sopena"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1904.12060"
  },
  {
    "id": "arXiv:1910.04193",
    "title": "Observer-based boundary control of distributed port-Hamiltonian systems",
    "abstract": "Observer-based boundary control of distributed port-Hamiltonian systems",
    "descriptor": "",
    "authors": [
      "Jesus Toledo",
      "Yongxin Wu",
      "Hector Ramirez",
      "Yann Le Gorrec"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1910.04193"
  },
  {
    "id": "arXiv:2001.08025",
    "title": "Optimal binning: mathematical programming formulation",
    "abstract": "Optimal binning: mathematical programming formulation",
    "descriptor": "",
    "authors": [
      "Guillermo Navas-Palencia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.08025"
  },
  {
    "id": "arXiv:2006.01893",
    "title": "Unsupervised Discretization by Two-dimensional MDL-based Histogram",
    "abstract": "Comments: Accepted version at Machine Learning",
    "descriptor": "\nComments: Accepted version at Machine Learning\n",
    "authors": [
      "Lincen Yang",
      "Mitra Baratchi",
      "Matthijs van Leeuwen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.01893"
  },
  {
    "id": "arXiv:2007.02330",
    "title": "Universal codes in the shared-randomness model for channels with general  distortion capabilities",
    "abstract": "Comments: Removed the mentioning of online matching, which is not used here",
    "descriptor": "\nComments: Removed the mentioning of online matching, which is not used here\n",
    "authors": [
      "Bruno Bauwens",
      "Marius Zimand"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2007.02330"
  },
  {
    "id": "arXiv:2009.10353",
    "title": "Complexity and Approximation for Discriminating and Identifying Code  Problems in Geometric Setups",
    "abstract": "Complexity and Approximation for Discriminating and Identifying Code  Problems in Geometric Setups",
    "descriptor": "",
    "authors": [
      "Sanjana Dey",
      "Florent Foucaud",
      "Subhas C Nandy",
      "Arunabha Sen"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2009.10353"
  },
  {
    "id": "arXiv:2010.06314",
    "title": "Linear Matrix Inequality Design of Exponentially Stabilizing  Observer-Based State Feedback Port-Hamiltonian Controllers",
    "abstract": "Linear Matrix Inequality Design of Exponentially Stabilizing  Observer-Based State Feedback Port-Hamiltonian Controllers",
    "descriptor": "",
    "authors": [
      "Jesus Toledo",
      "Hector Ramirez",
      "Yongxin Wu",
      "Yann Le Gorrec"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.06314"
  },
  {
    "id": "arXiv:2010.09471",
    "title": "Finding Cut-Offs in Leaderless Rendez-Vous Protocols is Easy",
    "abstract": "Finding Cut-Offs in Leaderless Rendez-Vous Protocols is Easy",
    "descriptor": "",
    "authors": [
      "A. R. Balasubramanian",
      "Javier Esparza",
      "Mikhail Raskin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2010.09471"
  },
  {
    "id": "arXiv:2102.06197",
    "title": "Estimating a Directed Tree for Extremes",
    "abstract": "Comments: Extensive Revision. 55 pages, 25 Figures",
    "descriptor": "\nComments: Extensive Revision. 55 pages, 25 Figures\n",
    "authors": [
      "Ngoc Mai Tran",
      "Johannes Buck",
      "Claudia Kl\u00fcppelberg"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2102.06197"
  },
  {
    "id": "arXiv:2105.07743",
    "title": "Universal Regular Conditional Distributions",
    "abstract": "Comments: Regular Conditional Distributions, Geometric Deep Learning, Computational Optimal Transport, Measure-Valued Neural Networks, Universal Approximation, Transformers",
    "descriptor": "\nComments: Regular Conditional Distributions, Geometric Deep Learning, Computational Optimal Transport, Measure-Valued Neural Networks, Universal Approximation, Transformers\n",
    "authors": [
      "Anastasis Kratsios"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Metric Geometry (math.MG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.07743"
  },
  {
    "id": "arXiv:2105.12125",
    "title": "An explicit algorithm for normal forms in small overlap monoids",
    "abstract": "Comments: 31 pages, 6 figures (some further detail was added to the proof of correctness of the normal form algorithm, some further errors and omissions were corrected, and an appendix with information about the performance of the implementation of the algorithms in the paper was added)",
    "descriptor": "\nComments: 31 pages, 6 figures (some further detail was added to the proof of correctness of the normal form algorithm, some further errors and omissions were corrected, and an appendix with information about the performance of the implementation of the algorithms in the paper was added)\n",
    "authors": [
      "James D. Mitchell",
      "Maria Tsalakou"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Data Structures and Algorithms (cs.DS)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2105.12125"
  },
  {
    "id": "arXiv:2106.05473",
    "title": "Stream processors and comodels",
    "abstract": "Comments: 24 pages; v4: final accepted version",
    "descriptor": "\nComments: 24 pages; v4: final accepted version\n",
    "authors": [
      "Richard Garner"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2106.05473"
  },
  {
    "id": "arXiv:2107.00630",
    "title": "Variational Diffusion Models",
    "abstract": "Comments: Published at NeurIPS'21. Camera-ready version, with code URL. v4: fixes typo in Appendix A.2",
    "descriptor": "\nComments: Published at NeurIPS'21. Camera-ready version, with code URL. v4: fixes typo in Appendix A.2\n",
    "authors": [
      "Diederik P. Kingma",
      "Tim Salimans",
      "Ben Poole",
      "Jonathan Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00630"
  },
  {
    "id": "arXiv:2109.01517",
    "title": "A brief history of AI: how to prevent another winter (a critical review)",
    "abstract": "Comments: 21 pages, 12 figures, 106 references, a Glossary section comes at the end of the paper, right after References. The article is accepted and going to be published by Elsevier, journal of PET - Clinics. Typos in the main text and in figure 3 fixed",
    "descriptor": "\nComments: 21 pages, 12 figures, 106 references, a Glossary section comes at the end of the paper, right after References. The article is accepted and going to be published by Elsevier, journal of PET - Clinics. Typos in the main text and in figure 3 fixed\n",
    "authors": [
      "Amirhosein Toosi",
      "Andrea Bottino",
      "Babak Saboury",
      "Eliot Siegel",
      "Arman Rahmim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.01517"
  },
  {
    "id": "arXiv:2109.03025",
    "title": "Linear equations for unordered data vectors in $[D]^k\\to{}Z^d$",
    "abstract": "Linear equations for unordered data vectors in $[D]^k\\to{}Z^d$",
    "descriptor": "",
    "authors": [
      "Piotr Hofman",
      "Jakub R\u00f3\u017cycki"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2109.03025"
  },
  {
    "id": "arXiv:2109.06095",
    "title": "Nonlinear matrix recovery using optimization on the Grassmann manifold",
    "abstract": "Comments: Fixed some typos in version 2",
    "descriptor": "\nComments: Fixed some typos in version 2\n",
    "authors": [
      "Florentin Goyens",
      "Coralia Cartis",
      "Armin Eftekhari"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.06095"
  },
  {
    "id": "arXiv:2110.00734",
    "title": "Capacity Planning in Stable Matching: An Application to School Choice",
    "abstract": "Comments: 46 pages, 6 figures and 2 tables",
    "descriptor": "\nComments: 46 pages, 6 figures and 2 tables\n",
    "authors": [
      "Federico Bobbio",
      "Margarida Carvalho",
      "Andrea Lodi",
      "Ignacio Rios",
      "Alfredo Torrico"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.00734"
  },
  {
    "id": "arXiv:2111.01528",
    "title": "Effective and Imperceptible Adversarial Textual Attack via  Multi-objectivization",
    "abstract": "Effective and Imperceptible Adversarial Textual Attack via  Multi-objectivization",
    "descriptor": "",
    "authors": [
      "Shengcai Liu",
      "Ning Lu",
      "Wenjing Hong",
      "Chao Qian",
      "Ke Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.01528"
  },
  {
    "id": "arXiv:2111.09337",
    "title": "Temporally Consistent Online Depth Estimation in Dynamic Scenes",
    "abstract": "Comments: WACV 2023, project page: this https URL",
    "descriptor": "\nComments: WACV 2023, project page: this https URL\n",
    "authors": [
      "Zhaoshuo Li",
      "Wei Ye",
      "Dilin Wang",
      "Francis X. Creighton",
      "Russell H. Taylor",
      "Ganesh Venkatesh",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09337"
  },
  {
    "id": "arXiv:2111.10349",
    "title": "Understanding Developers Well-Being and Productivity: A Longitudinal  Analysis of the COVID-19 Pandemic",
    "abstract": "Understanding Developers Well-Being and Productivity: A Longitudinal  Analysis of the COVID-19 Pandemic",
    "descriptor": "",
    "authors": [
      "Daniel Russo",
      "Paul H.P. Hanel",
      "Niels van Berkel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.10349"
  },
  {
    "id": "arXiv:2111.12379",
    "title": "Efficient Anomaly Detection Using Self-Supervised Multi-Cue Tasks",
    "abstract": "Efficient Anomaly Detection Using Self-Supervised Multi-Cue Tasks",
    "descriptor": "",
    "authors": [
      "Loic Jezequel",
      "Ngoc-Son Vu",
      "Jean Beaudet",
      "Aymeric Histace"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12379"
  },
  {
    "id": "arXiv:2111.14020",
    "title": "Local Edge Dynamics and Opinion Polarization",
    "abstract": "Comments: Accepted to WSDM 2023. 14 pages, 30 figures",
    "descriptor": "\nComments: Accepted to WSDM 2023. 14 pages, 30 figures\n",
    "authors": [
      "Nikita Bhalla",
      "Adam Lechowicz",
      "Cameron Musco"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.14020"
  },
  {
    "id": "arXiv:2112.04571",
    "title": "Ambiguous Dynamic Treatment Regimes: A Reinforcement Learning Approach",
    "abstract": "Ambiguous Dynamic Treatment Regimes: A Reinforcement Learning Approach",
    "descriptor": "",
    "authors": [
      "Soroush Saghafian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04571"
  },
  {
    "id": "arXiv:2112.07877",
    "title": "Learning to Transpile AMR into SPARQL",
    "abstract": "Learning to Transpile AMR into SPARQL",
    "descriptor": "",
    "authors": [
      "Mihaela Bornea",
      "Ramon Fernandez Astudillo",
      "Tahira Naseem",
      "Nandana Mihindukulasooriya",
      "Ibrahim Abdelaziz",
      "Pavan Kapanipathi",
      "Radu Florian",
      "Salim Roukos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07877"
  },
  {
    "id": "arXiv:2201.05395",
    "title": "De Rham compatible Deep Neural Network FEM",
    "abstract": "De Rham compatible Deep Neural Network FEM",
    "descriptor": "",
    "authors": [
      "Marcello Longo",
      "Joost A. A. Opschoor",
      "Nico Disch",
      "Christoph Schwab",
      "Jakob Zech"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.05395"
  },
  {
    "id": "arXiv:2201.05991",
    "title": "Video Transformers: A Survey",
    "abstract": "Video Transformers: A Survey",
    "descriptor": "",
    "authors": [
      "Javier Selva",
      "Anders S. Johansen",
      "Sergio Escalera",
      "Kamal Nasrollahi",
      "Thomas B. Moeslund",
      "Albert Clap\u00e9s"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05991"
  },
  {
    "id": "arXiv:2202.03949",
    "title": "Systematically and efficiently improving $k$-means initialization by  pairwise-nearest-neighbor smoothing",
    "abstract": "Comments: this https URL 16 pages (+8 appendix), 2 figures, 4 tables (+14 appendix). Transactions on Machine Learning Research, Dec 2022",
    "descriptor": "\nComments: this https URL 16 pages (+8 appendix), 2 figures, 4 tables (+14 appendix). Transactions on Machine Learning Research, Dec 2022\n",
    "authors": [
      "Carlo Baldassi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03949"
  },
  {
    "id": "arXiv:2203.00552",
    "title": "Linear scaling computation of forces for the domain-decomposition linear  Poisson--Boltzmann method",
    "abstract": "Linear scaling computation of forces for the domain-decomposition linear  Poisson--Boltzmann method",
    "descriptor": "",
    "authors": [
      "Abhinav Jha",
      "Michele Nottoli",
      "Aleksandr Mikhalev",
      "Chaoyu Quan",
      "Benjamin Stamm"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.00552"
  },
  {
    "id": "arXiv:2203.04166",
    "title": "Curriculum-based Reinforcement Learning for Distribution System Critical  Load Restoration",
    "abstract": "Comments: IEEE Transactions on Power Systems",
    "descriptor": "\nComments: IEEE Transactions on Power Systems\n",
    "authors": [
      "Xiangyu Zhang",
      "Abinet Tesfaye Eseye",
      "Bernard Knueven",
      "Weijia Liu",
      "Matthew Reynolds",
      "Wesley Jones"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.04166"
  },
  {
    "id": "arXiv:2203.07601",
    "title": "Automatic HFL(Z) Validity Checking for Program Verification",
    "abstract": "Comments: A long version of the paper published in Proceedings of POPL 2023",
    "descriptor": "\nComments: A long version of the paper published in Proceedings of POPL 2023\n",
    "authors": [
      "Naoki Kobayashi",
      "Kento Tanahashi",
      "Ryosuke Sato",
      "Takeshi Tsukada"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.07601"
  },
  {
    "id": "arXiv:2203.15720",
    "title": "Transformer Inertial Poser: Real-time Human Motion Reconstruction from  Sparse IMUs with Simultaneous Terrain Generation",
    "abstract": "Comments: SIGGRAPH Asia 2022. Video: this https URL Code: this https URL",
    "descriptor": "\nComments: SIGGRAPH Asia 2022. Video: this https URL Code: this https URL\n",
    "authors": [
      "Yifeng Jiang",
      "Yuting Ye",
      "Deepak Gopinath",
      "Jungdam Won",
      "Alexander W. Winkler",
      "C. Karen Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.15720"
  },
  {
    "id": "arXiv:2204.03133",
    "title": "Bi-fidelity conditional-value-at-risk estimation by dimensionally  decomposed generalized polynomial chaos expansion",
    "abstract": "Bi-fidelity conditional-value-at-risk estimation by dimensionally  decomposed generalized polynomial chaos expansion",
    "descriptor": "",
    "authors": [
      "Dongjin Lee",
      "Boris Kramer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03133"
  },
  {
    "id": "arXiv:2204.06502",
    "title": "Study of Indian English Pronunciation Variabilities relative to Received  Pronunciation",
    "abstract": "Study of Indian English Pronunciation Variabilities relative to Received  Pronunciation",
    "descriptor": "",
    "authors": [
      "Priyanshi Pal",
      "Shelly Jain",
      "Anil Vuppala",
      "Chiranjeevi Yarra",
      "Prasanta Ghosh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.06502"
  },
  {
    "id": "arXiv:2204.06552",
    "title": "Neural Vector Fields for Implicit Surface Representation and Inference",
    "abstract": "Neural Vector Fields for Implicit Surface Representation and Inference",
    "descriptor": "",
    "authors": [
      "Edoardo Mello Rella",
      "Ajad Chhatkuli",
      "Ender Konukoglu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.06552"
  },
  {
    "id": "arXiv:2204.11743",
    "title": "Structure-preserving numerical method for Maxwell-Amp\u00e8re  Nernst-Planck model",
    "abstract": "Structure-preserving numerical method for Maxwell-Amp\u00e8re  Nernst-Planck model",
    "descriptor": "",
    "authors": [
      "Zhonghua Qiao",
      "Zhenli Xu",
      "Qian Yin",
      "Shenggao Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.11743"
  },
  {
    "id": "arXiv:2204.12621",
    "title": "A sharp upper bound for sampling numbers in $L_{2}$",
    "abstract": "A sharp upper bound for sampling numbers in $L_{2}$",
    "descriptor": "",
    "authors": [
      "Matthieu Dolbeault",
      "David Krieg",
      "Mario Ullrich"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2204.12621"
  },
  {
    "id": "arXiv:2205.01749",
    "title": "Mixed-effects transformers for hierarchical adaptation",
    "abstract": "Mixed-effects transformers for hierarchical adaptation",
    "descriptor": "",
    "authors": [
      "Julia White",
      "Noah Goodman",
      "Robert Hawkins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01749"
  },
  {
    "id": "arXiv:2205.04040",
    "title": "ProQA: Structural Prompt-based Pre-training for Unified Question  Answering",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Wanjun Zhong",
      "Yifan Gao",
      "Ning Ding",
      "Yujia Qin",
      "Zhiyuan Liu",
      "Ming Zhou",
      "Jiahai Wang",
      "Jian Yin",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.04040"
  },
  {
    "id": "arXiv:2205.04099",
    "title": "Robustness of double-layer group-dependent combat network with cascading  failure",
    "abstract": "Robustness of double-layer group-dependent combat network with cascading  failure",
    "descriptor": "",
    "authors": [
      "Jintao Yu",
      "Bing Xiao",
      "Yuzhu Cui"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.04099"
  },
  {
    "id": "arXiv:2205.05419",
    "title": "Multi-Label Logo Recognition and Retrieval based on Weighted Fusion of  Neural Features",
    "abstract": "Multi-Label Logo Recognition and Retrieval based on Weighted Fusion of  Neural Features",
    "descriptor": "",
    "authors": [
      "Marisa Bernabeu",
      "Antonio Javier Gallego",
      "Antonio Pertusa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05419"
  },
  {
    "id": "arXiv:2205.08794",
    "title": "LogiGAN: Learning Logical Reasoning via Adversarial Pre-training",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Xinyu Pi",
      "Wanjun Zhong",
      "Yan Gao",
      "Nan Duan",
      "Jian-Guang Lou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.08794"
  },
  {
    "id": "arXiv:2205.10583",
    "title": "Automated Repair of Code from Language Models",
    "abstract": "Comments: 12 pages, To appear in ICSE 2023",
    "descriptor": "\nComments: 12 pages, To appear in ICSE 2023\n",
    "authors": [
      "Zhiyu Fan",
      "Xiang Gao",
      "Martin Mirchev",
      "Abhik Roychoudhury",
      "Shin Hwei Tan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.10583"
  },
  {
    "id": "arXiv:2205.11838",
    "title": "Model-Based and Graph-Based Priors for Group Testing",
    "abstract": "Comments: IEEE Transactions on Signal Processing",
    "descriptor": "\nComments: IEEE Transactions on Signal Processing\n",
    "authors": [
      "Ivan Lau",
      "Jonathan Scarlett",
      "Yang Sun"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.11838"
  },
  {
    "id": "arXiv:2205.13355",
    "title": "Single-pass Nystr\u00f6m approximation in mixed precision",
    "abstract": "Single-pass Nystr\u00f6m approximation in mixed precision",
    "descriptor": "",
    "authors": [
      "Erin Carson",
      "Ieva Dau\u017eickait\u0117"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.13355"
  },
  {
    "id": "arXiv:2205.14772",
    "title": "Unfooling Perturbation-Based Post Hoc Explainers",
    "abstract": "Comments: Accepted to AAAI-23. 9 pages (not including references and supplemental)",
    "descriptor": "\nComments: Accepted to AAAI-23. 9 pages (not including references and supplemental)\n",
    "authors": [
      "Zachariah Carmichael",
      "Walter J Scheirer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14772"
  },
  {
    "id": "arXiv:2206.00798",
    "title": "Multi-scale frequency separation network for image deblurring",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yanni Zhang",
      "Qiang Li",
      "Miao Qi",
      "Di Liu",
      "Jun Kong",
      "Jianzhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00798"
  },
  {
    "id": "arXiv:2206.04988",
    "title": "Conjunctive Queries With Self-Joins, Towards a Fine-Grained Complexity  Analysis",
    "abstract": "Conjunctive Queries With Self-Joins, Towards a Fine-Grained Complexity  Analysis",
    "descriptor": "",
    "authors": [
      "Nofar Carmeli",
      "Luc Segoufin"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.04988"
  },
  {
    "id": "arXiv:2206.07785",
    "title": "Strategic Coalition for Data Pricing in IoT Data Markets",
    "abstract": "Comments: 14 pages. Submitted for possible publication",
    "descriptor": "\nComments: 14 pages. Submitted for possible publication\n",
    "authors": [
      "Shashi Raj Pandey",
      "Pierre Pinson",
      "Petar Popovski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.07785"
  },
  {
    "id": "arXiv:2206.10210",
    "title": "The Integration of Machine Learning into Automated Test Generation: A  Systematic Mapping Study",
    "abstract": "Comments: Under submission to Software Testing, Verification, and Reliability journal. (arXiv admin note: text overlap with arXiv:2107.00906 - This is an earlier study that this study extends)",
    "descriptor": "\nComments: Under submission to Software Testing, Verification, and Reliability journal. (arXiv admin note: text overlap with arXiv:2107.00906 - This is an earlier study that this study extends)\n",
    "authors": [
      "Afonso Fontes",
      "Gregory Gay"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10210"
  },
  {
    "id": "arXiv:2207.07759",
    "title": "ESFPNet: efficient deep learning architecture for real-time lesion  segmentation in autofluorescence bronchoscopic video",
    "abstract": "Comments: SPIE 2023 drafts update",
    "descriptor": "\nComments: SPIE 2023 drafts update\n",
    "authors": [
      "Qi Chang",
      "Danish Ahmad",
      "Jennifer Toth",
      "Rebecca Bascom",
      "William E. Higgins"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.07759"
  },
  {
    "id": "arXiv:2207.07782",
    "title": "Rate-Splitting Multiple Access for Short-Packet Uplink Communications: A  Finite Blocklength Error Probability Analysis",
    "abstract": "Comments: 5 pages, 4 figures",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Jiawei Xu",
      "Onur Dizdar",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.07782"
  },
  {
    "id": "arXiv:2207.09031",
    "title": "Decorrelative Network Architecture for Robust Electrocardiogram  Classification",
    "abstract": "Comments: 16 pages, 6 figures",
    "descriptor": "\nComments: 16 pages, 6 figures\n",
    "authors": [
      "Christopher Wiedeman",
      "Ge Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09031"
  },
  {
    "id": "arXiv:2207.10241",
    "title": "Unsupervised Legendre-Galerkin Neural Network for Singularly Perturbed  Partial Differential Equations",
    "abstract": "Comments: 16 pages, 8 figures",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Junho Choi",
      "Namjung Kim",
      "Youngjoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10241"
  },
  {
    "id": "arXiv:2207.14636",
    "title": "Detecting Spam Reviews on Vietnamese E-commerce Websites",
    "abstract": "Comments: Published at The 14th Asian Conference on Intelligent Information and Database Systems (ACIIDS 2022). The dataset is available at this https URL",
    "descriptor": "\nComments: Published at The 14th Asian Conference on Intelligent Information and Database Systems (ACIIDS 2022). The dataset is available at this https URL\n",
    "authors": [
      "Co Van Dinh",
      "Son T. Luu",
      "Anh Gia-Tuan Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.14636"
  },
  {
    "id": "arXiv:2208.03082",
    "title": "Conflict-free joint sampling for preference satisfaction through quantum  interference",
    "abstract": "Comments: 14 pages, 6 figures",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Hiroaki Shinkawa",
      "Nicolas Chauvet",
      "Andr\u00e9 R\u00f6hm",
      "Takatomo Mihana",
      "Ryoichi Horisaki",
      "Guillaume Bachelier",
      "Makoto Naruse"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Applied Physics (physics.app-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2208.03082"
  },
  {
    "id": "arXiv:2208.04884",
    "title": "Localizing the conceptual difference of two scenes using deep learning  for house keeping usages",
    "abstract": "Localizing the conceptual difference of two scenes using deep learning  for house keeping usages",
    "descriptor": "",
    "authors": [
      "Ali Atghaei",
      "Ehsan Rahnama",
      "Kiavash Azimi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.04884"
  },
  {
    "id": "arXiv:2208.07009",
    "title": "Copula-based analysis of the generalized friendship paradox in clustered  networks",
    "abstract": "Comments: 9 pages, 3 figures. arXiv admin note: text overlap with arXiv:2107.05838",
    "descriptor": "\nComments: 9 pages, 3 figures. arXiv admin note: text overlap with arXiv:2107.05838\n",
    "authors": [
      "Hang-Hyun Jo",
      "Eun Lee",
      "Young-Ho Eom"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2208.07009"
  },
  {
    "id": "arXiv:2208.09047",
    "title": "Machine learning algorithms for three-dimensional mean-curvature  computation in the level-set method",
    "abstract": "Machine learning algorithms for three-dimensional mean-curvature  computation in the level-set method",
    "descriptor": "",
    "authors": [
      "Luis \u00c1ngel Larios-C\u00e1rdenas",
      "Fr\u00e9d\u00e9ric Gibou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.09047"
  },
  {
    "id": "arXiv:2208.09683",
    "title": "Machine learning based surrogate models for microchannel heat sink  optimization",
    "abstract": "Comments: 33 pages, brief appendix",
    "descriptor": "\nComments: 33 pages, brief appendix\n",
    "authors": [
      "Ante Sikirica",
      "Luka Grb\u010di\u0107",
      "Lado Kranj\u010devi\u0107"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09683"
  },
  {
    "id": "arXiv:2208.12055",
    "title": "Combating Mode Collapse in GANs via Manifold Entropy Estimation",
    "abstract": "Comments: Accepted by AAAI'2023; Code will be released soon",
    "descriptor": "\nComments: Accepted by AAAI'2023; Code will be released soon\n",
    "authors": [
      "Haozhe Liu",
      "Bing Li",
      "Haoqian Wu",
      "Hanbang Liang",
      "Yawen Huang",
      "Yuexiang Li",
      "Bernard Ghanem",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.12055"
  },
  {
    "id": "arXiv:2208.12681",
    "title": "Disentangle and Remerge: Interventional Knowledge Distillation for  Few-Shot Object Detection from A Conditional Causal Perspective",
    "abstract": "Comments: Accepted by AAAI 2023",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Jiangmeng Li",
      "Yanan Zhang",
      "Wenwen Qiang",
      "Lingyu Si",
      "Chengbo Jiao",
      "Xiaohui Hu",
      "Changwen Zheng",
      "Fuchun Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.12681"
  },
  {
    "id": "arXiv:2209.00283",
    "title": "Conditional graph entropy as an alternating minimization problem",
    "abstract": "Conditional graph entropy as an alternating minimization problem",
    "descriptor": "",
    "authors": [
      "Viktor Harangi",
      "Xueyan Niu",
      "Bo Bai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2209.00283"
  },
  {
    "id": "arXiv:2209.01816",
    "title": "ADTR: Anomaly Detection Transformer with Feature Reconstruction",
    "abstract": "Comments: Accepted by ICONIP 2022",
    "descriptor": "\nComments: Accepted by ICONIP 2022\n",
    "authors": [
      "Zhiyuan You",
      "Kai Yang",
      "Wenhan Luo",
      "Lei Cui",
      "Yu Zheng",
      "Xinyi Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.01816"
  },
  {
    "id": "arXiv:2209.05899",
    "title": "A Meta-level Analysis of Online Anomaly Detectors",
    "abstract": "A Meta-level Analysis of Online Anomaly Detectors",
    "descriptor": "",
    "authors": [
      "Antonios Ntroumpogiannis",
      "Michail Giannoulis",
      "Nikolaos Myrtakis",
      "Vassilis Christophides",
      "Eric Simon",
      "Ioannis Tsamardinos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.05899"
  },
  {
    "id": "arXiv:2209.06950",
    "title": "Lossy Image Compression with Conditional Diffusion Models",
    "abstract": "Lossy Image Compression with Conditional Diffusion Models",
    "descriptor": "",
    "authors": [
      "Ruihan Yang",
      "Stephan Mandt"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.06950"
  },
  {
    "id": "arXiv:2209.07902",
    "title": "MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning",
    "abstract": "Comments: Accepted by NeurIPS 2022 as Spotlight",
    "descriptor": "\nComments: Accepted by NeurIPS 2022 as Spotlight\n",
    "authors": [
      "Jiangmeng Li",
      "Wenwen Qiang",
      "Yanan Zhang",
      "Wenyi Mo",
      "Changwen Zheng",
      "Bing Su",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07902"
  },
  {
    "id": "arXiv:2209.09051",
    "title": "Derivative Descendants and Ascendants of Binary Cyclic Codes, and  Derivative Decoding",
    "abstract": "Derivative Descendants and Ascendants of Binary Cyclic Codes, and  Derivative Decoding",
    "descriptor": "",
    "authors": [
      "Bin Zhang",
      "Qin Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.09051"
  },
  {
    "id": "arXiv:2209.11672",
    "title": "MiCellAnnGELo: Annotate microscopy time series of complex cell surfaces  with 3D Virtual Reality",
    "abstract": "Comments: For associated code and sample data, see this https URL",
    "descriptor": "\nComments: For associated code and sample data, see this https URL\n",
    "authors": [
      "Adam Platt",
      "E. Josiah Lutton",
      "Edward Offord",
      "Till Bretschneider"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.11672"
  },
  {
    "id": "arXiv:2210.01703",
    "title": "Improving Label-Deficient Keyword Spotting Using Self-Supervised  Pretraining",
    "abstract": "Comments: 8 pages, 3 figures, 4 tables",
    "descriptor": "\nComments: 8 pages, 3 figures, 4 tables\n",
    "authors": [
      "Holger Severin Bovbjerg",
      "Zheng-Hua Tan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.01703"
  },
  {
    "id": "arXiv:2210.05318",
    "title": "CASAPose: Class-Adaptive and Semantic-Aware Multi-Object Pose Estimation",
    "abstract": "Comments: BMVC 2022, camera-ready version (this submission includes the paper and supplementary material)",
    "descriptor": "\nComments: BMVC 2022, camera-ready version (this submission includes the paper and supplementary material)\n",
    "authors": [
      "Niklas Gard",
      "Anna Hilsmann",
      "Peter Eisert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05318"
  },
  {
    "id": "arXiv:2210.05634",
    "title": "The IID Prophet Inequality with Limited Flexibility",
    "abstract": "The IID Prophet Inequality with Limited Flexibility",
    "descriptor": "",
    "authors": [
      "Sebastian Perez-Salazar",
      "Mohit Singh",
      "Alejandro Toriello"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.05634"
  },
  {
    "id": "arXiv:2210.05885",
    "title": "Unitary property testing lower bounds by polynomials",
    "abstract": "Comments: 58 pages, v2: typos corrected, Section 6.1-6.3 revised, added some new results",
    "descriptor": "\nComments: 58 pages, v2: typos corrected, Section 6.1-6.3 revised, added some new results\n",
    "authors": [
      "Adrian She",
      "Henry Yuen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.05885"
  },
  {
    "id": "arXiv:2210.06384",
    "title": "GMP*: Well-Tuned Gradual Magnitude Pruning Can Outperform Most  BERT-Pruning Methods",
    "abstract": "GMP*: Well-Tuned Gradual Magnitude Pruning Can Outperform Most  BERT-Pruning Methods",
    "descriptor": "",
    "authors": [
      "Eldar Kurtic",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.06384"
  },
  {
    "id": "arXiv:2210.07182",
    "title": "PDEBENCH: An Extensive Benchmark for Scientific Machine Learning",
    "abstract": "Comments: 16 pages (main body) + 34 pages (supplemental material), accepted for publication in NeurIPS 2022 Track Datasets and Benchmarks",
    "descriptor": "\nComments: 16 pages (main body) + 34 pages (supplemental material), accepted for publication in NeurIPS 2022 Track Datasets and Benchmarks\n",
    "authors": [
      "Makoto Takamoto",
      "Timothy Praditia",
      "Raphael Leiteritz",
      "Dan MacKinlay",
      "Francesco Alesiani",
      "Dirk Pfl\u00fcger",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.07182"
  },
  {
    "id": "arXiv:2210.14869",
    "title": "An Efficient Dynamic Multi-Sources To Single-Destination (DMS-SD)  Algorithm In Smart City Navigation Using Adjacent Matrix",
    "abstract": "Comments: International Conference On Human-Centered Cognitive Systems (HCCS) 2022",
    "descriptor": "\nComments: International Conference On Human-Centered Cognitive Systems (HCCS) 2022\n",
    "authors": [
      "Ziren Xiao",
      "Ruxin Xiao",
      "Chang Liu",
      "Honghao Gao",
      "Xiaolong Xu",
      "Shan Luo",
      "Xinheng Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.14869"
  },
  {
    "id": "arXiv:2210.15996",
    "title": "Towards Few-Shot Open-Set Object Detection",
    "abstract": "Towards Few-Shot Open-Set Object Detection",
    "descriptor": "",
    "authors": [
      "Binyi Su",
      "Hua Zhang",
      "Jingzhi Li",
      "Zhong Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15996"
  },
  {
    "id": "arXiv:2211.01451",
    "title": "Privacy-preserving Non-negative Matrix Factorization with Outliers",
    "abstract": "Comments: 15 pages, 11 figures; additional explanations (in blue colours)",
    "descriptor": "\nComments: 15 pages, 11 figures; additional explanations (in blue colours)\n",
    "authors": [
      "Swapnil Saha",
      "Hafiz Imtiaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01451"
  },
  {
    "id": "arXiv:2211.04119",
    "title": "Simulation-Based Parallel Training",
    "abstract": "Simulation-Based Parallel Training",
    "descriptor": "",
    "authors": [
      "Lucas Meyer",
      "Alejandro Rib\u00e9s",
      "Bruno Raffin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04119"
  },
  {
    "id": "arXiv:2211.05627",
    "title": "Representing LLVM-IR in a Code Property Graph",
    "abstract": "Representing LLVM-IR in a Code Property Graph",
    "descriptor": "",
    "authors": [
      "Alexander K\u00fcchler",
      "Christian Banse"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.05627"
  },
  {
    "id": "arXiv:2211.05656",
    "title": "Probabilistically Robust PAC Learning",
    "abstract": "Comments: Organized sections + added new content",
    "descriptor": "\nComments: Organized sections + added new content\n",
    "authors": [
      "Vinod Raman",
      "Unique Subedi",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.05656"
  },
  {
    "id": "arXiv:2211.05979",
    "title": "Semi-supervised Variational Autoencoder for Regression: Application on  Soft Sensors",
    "abstract": "Semi-supervised Variational Autoencoder for Regression: Application on  Soft Sensors",
    "descriptor": "",
    "authors": [
      "Yilin Zhuang",
      "Zhuobin Zhou",
      "Burak Alakent",
      "Mehmet Mercang\u00f6z"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05979"
  },
  {
    "id": "arXiv:2211.07208",
    "title": "A Lego-Brick Approach to Coding for Network Communication",
    "abstract": "A Lego-Brick Approach to Coding for Network Communication",
    "descriptor": "",
    "authors": [
      "Nadim Ghaddar",
      "Shouvik Ganguly",
      "Lele Wang",
      "Young-Han Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.07208"
  },
  {
    "id": "arXiv:2211.08682",
    "title": "Parameter-Efficient Tuning on Layer Normalization for Pre-trained  Language Models",
    "abstract": "Parameter-Efficient Tuning on Layer Normalization for Pre-trained  Language Models",
    "descriptor": "",
    "authors": [
      "Wang Qi",
      "Yu-Ping Ruan",
      "Yuan Zuo",
      "Taihao Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08682"
  },
  {
    "id": "arXiv:2211.10011",
    "title": "Structural Quality Metrics to Evaluate Knowledge Graphs",
    "abstract": "Structural Quality Metrics to Evaluate Knowledge Graphs",
    "descriptor": "",
    "authors": [
      "Sumin Seo",
      "Heeseon Cheon",
      "Hyunho Kim",
      "Dongseok Hyun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10011"
  },
  {
    "id": "arXiv:2211.10556",
    "title": "A Distanced Matching Game, Decremental APSP in Expanders, and Faster  Deterministic Algorithms for Graph Cut Problems",
    "abstract": "A Distanced Matching Game, Decremental APSP in Expanders, and Faster  Deterministic Algorithms for Graph Cut Problems",
    "descriptor": "",
    "authors": [
      "Julia Chuzhoy"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.10556"
  },
  {
    "id": "arXiv:2211.11368",
    "title": "Precise Asymptotics for Spectral Methods in Mixed Generalized Linear  Models",
    "abstract": "Precise Asymptotics for Spectral Methods in Mixed Generalized Linear  Models",
    "descriptor": "",
    "authors": [
      "Yihan Zhang",
      "Marco Mondelli",
      "Ramji Venkataramanan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11368"
  },
  {
    "id": "arXiv:2211.11694",
    "title": "Exploring Discrete Diffusion Models for Image Captioning",
    "abstract": "Exploring Discrete Diffusion Models for Image Captioning",
    "descriptor": "",
    "authors": [
      "Zixin Zhu",
      "Yixuan Wei",
      "Jianfeng Wang",
      "Zhe Gan",
      "Zheng Zhang",
      "Le Wang",
      "Gang Hua",
      "Lijuan Wang",
      "Zicheng Liu",
      "Han Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11694"
  },
  {
    "id": "arXiv:2211.13696",
    "title": "FPT: a Fixed-Point Accelerator for Torus Fully Homomorphic Encryption",
    "abstract": "FPT: a Fixed-Point Accelerator for Torus Fully Homomorphic Encryption",
    "descriptor": "",
    "authors": [
      "Michiel Van Beirendonck",
      "Jan-Pieter D'Anvers",
      "Ingrid Verbauwhede"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.13696"
  },
  {
    "id": "arXiv:2211.13737",
    "title": "CycleGANWM: A CycleGAN watermarking method for ownership verification",
    "abstract": "Comments: There is an crucial error in Figure 1, where the \"watermark\" should be modified",
    "descriptor": "\nComments: There is an crucial error in Figure 1, where the \"watermark\" should be modified\n",
    "authors": [
      "Dongdong Lin",
      "Benedetta Tondi",
      "Bin Li",
      "Mauro Barni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13737"
  },
  {
    "id": "arXiv:2211.14794",
    "title": "Traditional Classification Neural Networks are Good Generators: They are  Competitive with DDPMs and GANs",
    "abstract": "Comments: This paper has 29 pages with 22 figures, including rich supplementary information. Project page is at \\url{this https URL}",
    "descriptor": "\nComments: This paper has 29 pages with 22 figures, including rich supplementary information. Project page is at \\url{this https URL}\n",
    "authors": [
      "Guangrun Wang",
      "Philip H.S. Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14794"
  },
  {
    "id": "arXiv:2211.14939",
    "title": "Applying Deep Reinforcement Learning to the HP Model for Protein  Structure Prediction",
    "abstract": "Comments: Published at Physica A: Statistical Mechanics and its Applications, available online 7 December 2022. Extended abstract accepted by the Machine Learning and the Physical Sciences workshop, NeurIPS 2022",
    "descriptor": "\nComments: Published at Physica A: Statistical Mechanics and its Applications, available online 7 December 2022. Extended abstract accepted by the Machine Learning and the Physical Sciences workshop, NeurIPS 2022\n",
    "authors": [
      "Kaiyuan Yang",
      "Houjing Huang",
      "Olafs Vandans",
      "Adithya Murali",
      "Fujia Tian",
      "Roland H.C. Yap",
      "Liang Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2211.14939"
  },
  {
    "id": "arXiv:2211.15046",
    "title": "Regional Precipitation Nowcasting Based on CycleGAN Extension",
    "abstract": "Regional Precipitation Nowcasting Based on CycleGAN Extension",
    "descriptor": "",
    "authors": [
      "Jaeho Choi",
      "Yura Kim",
      "Kwang-Ho Kim",
      "Sung-Hwa Jung",
      "Ikhyun Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15046"
  },
  {
    "id": "arXiv:2211.16028",
    "title": "jaCappella Corpus: A Japanese a Cappella Vocal Ensemble Corpus",
    "abstract": "Comments: Submitted to ICASSP2023",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Tomohiko Nakamura",
      "Shinnosuke Takamichi",
      "Naoko Tanji",
      "Satoru Fukayama",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.16028"
  },
  {
    "id": "arXiv:2211.16494",
    "title": "On the Ability of Graph Neural Networks to Model Interactions Between  Vertices",
    "abstract": "On the Ability of Graph Neural Networks to Model Interactions Between  Vertices",
    "descriptor": "",
    "authors": [
      "Noam Razin",
      "Tom Verbin",
      "Nadav Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16494"
  },
  {
    "id": "arXiv:2211.16676",
    "title": "Robust Learning of Nonlinear Dynamical Systems with Safety and Stability  Properties",
    "abstract": "Robust Learning of Nonlinear Dynamical Systems with Safety and Stability  Properties",
    "descriptor": "",
    "authors": [
      "Iman Salehi",
      "Ghananeel Rotithor",
      "Ashwin P. Dani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16676"
  },
  {
    "id": "arXiv:2211.17239",
    "title": "Multi-level Parareal algorithm with Averaging",
    "abstract": "Comments: 33 pages",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Juliane Rosemeier",
      "Terry Haut",
      "Beth Wingate"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.17239"
  },
  {
    "id": "arXiv:2212.00921",
    "title": "AGRO: Adversarial Discovery of Error-prone groups for Robust  Optimization",
    "abstract": "AGRO: Adversarial Discovery of Error-prone groups for Robust  Optimization",
    "descriptor": "",
    "authors": [
      "Bhargavi Paranjape",
      "Pradeep Dasigi",
      "Vivek Srikumar",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.00921"
  },
  {
    "id": "arXiv:2212.00923",
    "title": "A Tractable Probability Distribution with Applications in  Three-Dimensional Statistics",
    "abstract": "A Tractable Probability Distribution with Applications in  Three-Dimensional Statistics",
    "descriptor": "",
    "authors": [
      "Seyed Mohammad Azimi-Abarghouyi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2212.00923"
  },
  {
    "id": "arXiv:2212.00937",
    "title": "StructVPR: Distill Structural Knowledge with Weighting Samples for  Visual Place Recognition",
    "abstract": "StructVPR: Distill Structural Knowledge with Weighting Samples for  Visual Place Recognition",
    "descriptor": "",
    "authors": [
      "Yanqing Shen",
      "Sanping Zhou",
      "Jingwen Fu",
      "Ruotong Wang",
      "Shitao Chen",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00937"
  },
  {
    "id": "arXiv:2212.01098",
    "title": "RGB-D-based Stair Detection using Deep Learning for Autonomous Stair  Climbing",
    "abstract": "RGB-D-based Stair Detection using Deep Learning for Autonomous Stair  Climbing",
    "descriptor": "",
    "authors": [
      "Chen Wang",
      "Zhongcai Pei",
      "Shuang Qiu",
      "Zhiyong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.01098"
  },
  {
    "id": "arXiv:2212.01241",
    "title": "Analyzing the Hardware-Software Implications of Multi-modal DNN  Workloads using MMBench",
    "abstract": "Analyzing the Hardware-Software Implications of Multi-modal DNN  Workloads using MMBench",
    "descriptor": "",
    "authors": [
      "Xiaofeng Hou",
      "Cheng Xu",
      "Jiacheng Liu",
      "Xuehan Tang",
      "Linyu Sun",
      "Chao Li",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2212.01241"
  },
  {
    "id": "arXiv:2212.01326",
    "title": "Legal Prompting: Teaching a Language Model to Think Like a Lawyer",
    "abstract": "Comments: 12 pages, 6 figures, 4 tables. Accepted by NLLP 2022 (EMNLP workshop)",
    "descriptor": "\nComments: 12 pages, 6 figures, 4 tables. Accepted by NLLP 2022 (EMNLP workshop)\n",
    "authors": [
      "Fangyi Yu",
      "Lee Quartey",
      "Frank Schilder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01326"
  },
  {
    "id": "arXiv:2212.01382",
    "title": "Welfare and Fairness in Multi-objective Reinforcement Learning",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Zimeng Fan",
      "Nianli Peng",
      "Muhang Tian",
      "Brandon Fain"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2212.01382"
  },
  {
    "id": "arXiv:2212.02500",
    "title": "PhysDiff: Physics-Guided Human Motion Diffusion Model",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Ye Yuan",
      "Jiaming Song",
      "Umar Iqbal",
      "Arash Vahdat",
      "Jan Kautz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02500"
  },
  {
    "id": "arXiv:2212.02796",
    "title": "DiffuPose: Monocular 3D Human Pose Estimation via Denoising Diffusion  Probabilistic Model",
    "abstract": "DiffuPose: Monocular 3D Human Pose Estimation via Denoising Diffusion  Probabilistic Model",
    "descriptor": "",
    "authors": [
      "Jeongjun Choi",
      "Dongseok Shim",
      "H. Jin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02796"
  },
  {
    "id": "arXiv:2212.03177",
    "title": "Privacy-Preserving Visual Localization with Event Cameras",
    "abstract": "Privacy-Preserving Visual Localization with Event Cameras",
    "descriptor": "",
    "authors": [
      "Junho Kim",
      "Young Min Kim",
      "Yicheng Wu",
      "Ramzi Zahreddine",
      "Weston A. Welge",
      "Gurunandan Krishnan",
      "Sizhuo Ma",
      "Jian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03177"
  },
  {
    "id": "arXiv:2212.03454",
    "title": "Fallen Angel Bonds Investment and Bankruptcy Predictions Using Manual  Models and Automated Machine Learning",
    "abstract": "Comments: 8 pages, 3 figures",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Harrison Mateika",
      "Juannan Jia",
      "Linda Lillard",
      "Noah Cronbaugh",
      "Will Shin"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03454"
  },
  {
    "id": "arXiv:2212.03496",
    "title": "A Generative Approach for Script Event Prediction via Contrastive  Fine-tuning",
    "abstract": "A Generative Approach for Script Event Prediction via Contrastive  Fine-tuning",
    "descriptor": "",
    "authors": [
      "Fangqi Zhu",
      "Jun Gao",
      "Changlong Yu",
      "Wei Wang",
      "Chen Xu",
      "Xin Mu",
      "Min Yang",
      "Ruifeng Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.03496"
  },
  {
    "id": "arXiv:2212.03507",
    "title": "Judge, Localize, and Edit: Ensuring Visual Commonsense Morality for  Text-to-Image Generation",
    "abstract": "Judge, Localize, and Edit: Ensuring Visual Commonsense Morality for  Text-to-Image Generation",
    "descriptor": "",
    "authors": [
      "Seongbeom Park",
      "Suhong Moon",
      "Jinkyu Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.03507"
  },
  {
    "id": "arXiv:2212.03946",
    "title": "Bio-Heat Transfer and Monte Carlo Measurement of Near-Infrared  Transcranial Stimulation of Human Brain",
    "abstract": "Comments: The complete geometry proposed in this work is available for download. The proposed geometry is in STL and MPHBIN formats, and the model is surrounded by air. All the tissues are available and assembled, and it is recommended to use the transparency tool to acquire a better observation. Please cite this publication when referencing this material",
    "descriptor": "\nComments: The complete geometry proposed in this work is available for download. The proposed geometry is in STL and MPHBIN formats, and the model is surrounded by air. All the tissues are available and assembled, and it is recommended to use the transparency tool to acquire a better observation. Please cite this publication when referencing this material\n",
    "authors": [
      "Faezeh Ibrahimi",
      "Mehdi Delrobaei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.03946"
  },
  {
    "id": "arXiv:2212.04098",
    "title": "Frozen CLIP Model is An Efficient Point Cloud Backbone",
    "abstract": "Comments: Technical report",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Xiaoshui Huang",
      "Sheng Li",
      "Wentao Qu",
      "Tong He",
      "Yifan Zuo",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04098"
  },
  {
    "id": "arXiv:2212.04309",
    "title": "Deep Variational Inverse Scattering",
    "abstract": "Comments: 5 pages, 5 figures",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "AmirEhsan Khorashadizadeh",
      "Ali Aghababaei",
      "Tin Vla\u0161i\u0107",
      "Hieu Nguyen",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04309"
  },
  {
    "id": "arXiv:2212.04419",
    "title": "Mining Explainable Predictive Features for Water Quality Management",
    "abstract": "Mining Explainable Predictive Features for Water Quality Management",
    "descriptor": "",
    "authors": [
      "Conor Muldoon",
      "Levent G\u00f6rg\u00fc",
      "John J. O'Sullivan",
      "Wim G. Meijer",
      "Gregory M. P. O'Hare"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.04419"
  },
  {
    "id": "arXiv:2212.04466",
    "title": "On inclusion of source in the system of first-order linear acoustic wave  equations",
    "abstract": "Comments: List of changes: 1) In version 1, there was a mistake in displaying figures 3(d), 3(e), 3(f), 6(d), 6(e) and 6(f). Those figures are corrected. 2) The word \"acoustic\" was added to the title",
    "descriptor": "\nComments: List of changes: 1) In version 1, there was a mistake in displaying figures 3(d), 3(e), 3(f), 6(d), 6(e) and 6(f). Those figures are corrected. 2) The word \"acoustic\" was added to the title\n",
    "authors": [
      "Ashkan Javaherian"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.04466"
  },
  {
    "id": "arXiv:2212.04473",
    "title": "Diffusion Guided Domain Adaptation of Image Generators",
    "abstract": "Comments: Project website: this https URL",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Kunpeng Song",
      "Ligong Han",
      "Bingchen Liu",
      "Dimitris Metaxas",
      "Ahmed Elgammal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.04473"
  }
]
[
  {
    "id": "arXiv:2211.16506",
    "title": "Where did you tweet from? Inferring the origin locations of tweets based  on contextual information",
    "abstract": "Public conversations on Twitter comprise many pertinent topics including\ndisasters, protests, politics, propaganda, sports, climate change,\nepidemics/pandemic outbreaks, etc., that can have both regional and global\naspects. Spatial discourse analysis rely on geographical data. However, today\nless than 1% of tweets are geotagged; in both cases--point location or bounding\nplace information. A major issue with tweets is that Twitter users can be at\nlocation A and exchange conversations specific to location B, which we call the\nLocation A/B problem. The problem is considered solved if location entities can\nbe classified as either origin locations (Location As) or non-origin locations\n(Location Bs). In this work, we propose a simple yet effective framework--the\nTrue Origin Model--to address the problem that uses machine-level natural\nlanguage understanding to identify tweets that conceivably contain their origin\nlocation information. The model achieves promising accuracy at country (80%),\nstate (67%), city (58%), county (56%) and district (64%) levels with support\nfrom a Location Extraction Model as basic as the CoNLL-2003-based RoBERTa. We\nemploy a tweet contexualizer (locBERT) which is one of the core components of\nthe proposed model, to investigate multiple tweets' distributions for\nunderstanding Twitter users' tweeting behavior in terms of mentioning origin\nand non-origin locations. We also highlight a major concern with the currently\nregarded gold standard test set (ground truth) methodology, introduce a new\ndata set, and identify further research avenues for advancing the area.",
    "descriptor": "\nComments: To appear in Proceedings of the IEEE Big Data Conference 2022\n",
    "authors": [
      "Rabindra Lamsal",
      "Aaron Harwood",
      "Maria Rodriguez Read"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.16506"
  },
  {
    "id": "arXiv:2211.16507",
    "title": "Structure-Preserving Invariant Interpolation Schemes for Invertible  Second-Order Tensors",
    "abstract": "Tensor interpolation is an essential step for tensor data analysis in various\nfields of application and scientific disciplines. In the present work, novel\ninterpolation schemes for general, i.e., symmetric or non-symmetric, invertible\nsquare tensors are proposed. Critically, the proposed schemes rely on a\ncombined polar and spectral decomposition of the tensor data\n$\\boldsymbol{T}\\!\\!=\\!\\!\\boldsymbol{R}\\boldsymbol{Q}^T \\!\\!\n\\boldsymbol{\\Lambda} \\boldsymbol{Q}$, followed by an individual interpolation\nof the two rotation tensors $\\boldsymbol{R}$ and $\\boldsymbol{Q}$ and the\npositive definite diagonal eigenvalue tensor $\\boldsymbol{\\Lambda}$ resulting\nfrom this decomposition. Two different schemes are considered for a consistent\nrotation interpolation within the special orthogonal group $\\mathbb{SO}(3)$,\neither based on relative rotation vectors or quaternions. For eigenvalue\ninterpolation, three different schemes, either based on the logarithmic\nweighted average, moving least squares or logarithmic moving least squares, are\nconsidered. It is demonstrated that the proposed interpolation procedure\npreserves the structure of a tensor, i.e., $\\boldsymbol{R}$ and\n$\\boldsymbol{Q}$ remain orthogonal tensors and $\\boldsymbol{\\Lambda}$ remains a\npositive definite diagonal tensor during interpolation, as well as scaling and\nrotational invariance (objectivity). Based on selected numerical examples\nconsidering the interpolation of either symmetric or non-symmetric tensors, the\nproposed schemes are compared to existing approaches such as Euclidean,\nLog-Euclidean, Cholesky and Log-Cholesky interpolation. In contrast to these\nexisting methods, the proposed interpolation schemes result in smooth and\nmonotonic evolutions of tensor invariants such as determinant, trace,\nfractional anisotropy (FA), and Hilbert's anisotropy (HA)...{continued see pdf}",
    "descriptor": "",
    "authors": [
      "Abhiroop Satheesh",
      "Christoph P. Schmidt",
      "Wolfgang A. Wall",
      "Christoph Meier"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.16507"
  },
  {
    "id": "arXiv:2211.16525",
    "title": "Proactive Moderation of Online Discussions: Existing Practices and the  Potential for Algorithmic Support",
    "abstract": "To address the widespread problem of uncivil behavior, many online discussion\nplatforms employ human moderators to take action against objectionable content,\nsuch as removing it or placing sanctions on its authors. This reactive paradigm\nof taking action against already-posted antisocial content is currently the\nmost common form of moderation, and has accordingly underpinned many recent\nefforts at introducing automation into the moderation process. Comparatively\nless work has been done to understand other moderation paradigms -- such as\nproactively discouraging the emergence of antisocial behavior rather than\nreacting to it -- and the role algorithmic support can play in these paradigms.\nIn this work, we investigate such a proactive framework for moderation in a\ncase study of a collaborative setting: Wikipedia Talk Pages. We employ a mixed\nmethods approach, combining qualitative and design components for a holistic\nanalysis. Through interviews with moderators, we find that despite a lack of\ntechnical and social support, moderators already engage in a number of\nproactive moderation behaviors, such as preemptively intervening in\nconversations to keep them on track. Further, we explore how automation could\nassist with this existing proactive moderation workflow by building a prototype\ntool, presenting it to moderators, and examining how the assistance it provides\nmight fit into their workflow. The resulting feedback uncovers both strengths\nand drawbacks of the prototype tool and suggests concrete steps towards further\ndeveloping such assisting technology so it can most effectively support\nmoderators in their existing proactive moderation workflow.",
    "descriptor": "\nComments: 27 pages, 3 figures. More info at this https URL\n",
    "authors": [
      "Charlotte Schluger",
      "Jonathan P. Chang",
      "Cristian Danescu-Niculescu-Mizil",
      "Karen Levy"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.16525"
  },
  {
    "id": "arXiv:2211.16544",
    "title": "Transcervical Ultrasound Image Guidance System for Transoral Robotic  Surgery",
    "abstract": "Purpose: Trans-oral robotic surgery (TORS) using the da Vinci surgical robot\nis a new minimally-invasive surgery method to treat oropharyngeal tumors, but\nit is a challenging operation. Augmented reality (AR) based on intra-operative\nultrasound (US) has the potential to enhance the visualization of the anatomy\nand cancerous tumors to provide additional tools for decision-making in\nsurgery. Methods: We propose and carry out preliminary evaluations of a\nUS-guided AR system for TORS, with the transducer placed on the neck for a\ntranscervical view. Firstly, we perform a novel MRI-transcervical 3D US\nregistration study. Secondly, we develop a US-robot calibration method with an\noptical tracker and an AR system to display the anatomy mesh model in the\nreal-time endoscope images inside the surgeon console. Results: Our AR system\nreaches a mean projection error of 26.81 and 27.85 pixels for the projection\nfrom the US to stereo cameras in a water bath experiment. The average target\nregistration error for MRI to 3D US is 8.90 mm for the 3D US transducer and\n5.85 mm for freehand 3D US, and the average distance between the vessel\ncenterlines is 2.32 mm. Conclusion: We demonstrate the first proof-of-concept\ntranscervical US-guided AR system for TORS and the feasibility of\ntrans-cervical 3D US-MRI registration. Our results show that trans-cervical 3D\nUS is a promising technique for TORS image guidance.",
    "descriptor": "\nComments: 12 pages, 7 figures. Submitted to Information Processing for Computer Assisted Interventions (IPCAI 2023)\n",
    "authors": [
      "Wanwen Chen",
      "Megha Kalia",
      "Qi Zeng",
      "Emily H.T. Pang",
      "Razeyeh Bagherinasab",
      "Thomas D. Milner",
      "Farahna Sabiq",
      "Eitan Prisman",
      "Septimiu E. Salcudean"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.16544"
  },
  {
    "id": "arXiv:2211.16548",
    "title": "Solving High Dimensional Partial Differential Equations Using Tensor  Type Discretization and Optimization Process",
    "abstract": "In this paper, we propose a tensor type of discretization and optimization\nprocess for solving high dimensional partial differential equations. First, we\ndesign the tensor type of trial function for the high dimensional partial\ndifferential equations. Based on the tensor structure of the trial functions,\nwe can do the direct numerical integration of the approximate solution without\nthe help of Monte-Carlo method. Then combined with the Ritz or Galerkin method,\nsolving the high dimensional partial differential equation can be transformed\nto solve a concerned optimization problem. Some numerical tests are provided to\nvalidate the proposed numerical methods.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Yangfei Liao",
      "Yifan Wang",
      "Hehu Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16548"
  },
  {
    "id": "arXiv:2211.16550",
    "title": "Soft Alignment Objectives for Robust Adaptation in Machine Translation",
    "abstract": "Domain adaptation allows generative language models to address specific flaws\ncaused by the domain shift of their application. However, the traditional\nadaptation by further training on in-domain data rapidly weakens the model's\nability to generalize to other domains, making the open-ended deployments of\nthe adapted models prone to errors. This work introduces novel training\nobjectives built upon a semantic similarity of the predicted tokens to the\nreference.\nOur results show that (1) avoiding the common assumption of a single correct\nprediction by constructing the training target from tokens' semantic similarity\ncan mitigate catastrophic forgetting during domain adaptation, while (2)\npreserving the quality of the adaptation, (3) with negligible additions to\ncompute costs. In the broader perspective, the objectives grounded in a soft\ntoken alignment pioneer the exploration of the middle ground between the\nefficient but naive exact-match token-level objectives and expressive but\ncomputationally- and resource-intensive sequential objectives.",
    "descriptor": "",
    "authors": [
      "Michal \u0160tef\u00e1nik",
      "Marek Kadl\u010d\u00edk",
      "Petr Sojka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.16550"
  },
  {
    "id": "arXiv:2211.16553",
    "title": "Hierarchically Clustered PCA and CCA via a Convex Clustering Penalty",
    "abstract": "We introduce an unsupervised learning approach that combines the truncated\nsingular value decomposition with convex clustering to estimate within-cluster\ndirections of maximum variance/covariance (in the variables) while\nsimultaneously hierarchically clustering (on observations). In contrast to\nprevious work on joint clustering and embedding, our approach has a\nstraightforward formulation, is readily scalable via distributed optimization,\nand admits a direct interpretation as hierarchically clustered principal\ncomponent analysis (PCA) or hierarchically clustered canonical correlation\nanalysis (CCA). Through numerical experiments and real-world examples relevant\nto precision medicine, we show that our approach outperforms traditional and\ncontemporary clustering methods on underdetermined problems ($p \\gg N$ with\ntens of observations) and scales to large datasets (e.g., $N=100,000$;\n$p=1,000$) while yielding interpretable dendrograms of hierarchical per-cluster\nprincipal components or canonical variates.",
    "descriptor": "\nComments: 13 pages, 4 figures, 2 tables\n",
    "authors": [
      "Amanda M. Buch",
      "Conor Liston",
      "Logan Grosenick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16553"
  },
  {
    "id": "arXiv:2211.16563",
    "title": "Towards a Taxonomy of Industrial Challenges and Enabling Technologies in  Industry 4.0",
    "abstract": "Today, one of the biggest challenges for digital transformation in the\nIndustry 4.0 paradigm is the lack of mutual understanding between the academic\nand the industrial world. On the one hand, the industry fails to apply new\ntechnologies and innovations from scientific research. At the same time,\nacademics struggle to find and focus on real-world applications for their\ndeveloping technological solutions. Moreover, the increasing complexity of\nindustrial challenges and technologies is widening this hiatus. To reduce this\nknowledge and communication gap, this article proposes a mixed approach of\nhumanistic and engineering techniques applied to the technological and\nenterprise fields. The study's results are represented by a taxonomy in which\nindustrial challenges and I4.0-focused technologies are categorized and\nconnected through academic and grey literature analysis. This taxonomy also\nformed the basis for creating a public web platform where industrial\npractitioners can identify candidate solutions for an industrial challenge. At\nthe same time, from the educational perspective, the learning procedure can be\nsupported since, through this tool, academics can identify real-world scenarios\nto integrate digital technologies' teaching process.",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Roberto Figli\u00e8",
      "Riccardo Amadio",
      "Marios Tyrovolas",
      "Chrysostomos Stylios",
      "\u0141ukasz Pa\u015bko",
      "Dorota Stadnicka",
      "Anna Carreras-Coch",
      "Agust\u00edn Zaballos",
      "Joan Navarro",
      "Daniele Mazzei"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.16563"
  },
  {
    "id": "arXiv:2211.16564",
    "title": "Testing GLOM's ability to infer wholes from ambiguous parts",
    "abstract": "The GLOM architecture proposed by Hinton [2021] is a recurrent neural network\nfor parsing an image into a hierarchy of wholes and parts. When a part is\nambiguous, GLOM assumes that the ambiguity can be resolved by allowing the part\nto make multi-modal predictions for the pose and identity of the whole to which\nit belongs and then using attention to similar predictions coming from other\npossibly ambiguous parts to settle on a common mode that is predicted by\nseveral different parts. In this study, we describe a highly simplified version\nof GLOM that allows us to assess the effectiveness of this way of dealing with\nambiguity. Our results show that, with supervised training, GLOM is able to\nsuccessfully form islands of very similar embedding vectors for all of the\nlocations occupied by the same object and it is also robust to strong noise\ninjections in the input and to out-of-distribution input transformations.",
    "descriptor": "",
    "authors": [
      "Laura Culp",
      "Sara Sabour",
      "Geoffrey E. Hinton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16564"
  },
  {
    "id": "arXiv:2211.16570",
    "title": "Performance Evaluation of Vanilla, Residual, and Dense 2D U-Net  Architectures for Skull Stripping of Augmented 3D T1-weighted MRI Head Scans",
    "abstract": "Skull Stripping is a requisite preliminary step in most diagnostic\nneuroimaging applications. Manual Skull Stripping methods define the gold\nstandard for the domain but are time-consuming and challenging to integrate\ninto pro-cessing pipelines with a high number of data samples. Automated\nmethods are an active area of research for head MRI segmentation, especially\ndeep learning methods such as U-Net architecture implementations. This study\ncompares Vanilla, Residual, and Dense 2D U-Net architectures for Skull\nStripping. The Dense 2D U-Net architecture outperforms the Vanilla and Residual\ncounterparts by achieving an accuracy of 99.75% on a test dataset. It is\nobserved that dense interconnections in a U-Net encourage feature reuse across\nlayers of the architecture and allow for shallower models with the strengths of\na deeper network.",
    "descriptor": "",
    "authors": [
      "Anway S. Pimpalkar",
      "Rashmika K. Patole",
      "Ketaki D. Kamble",
      "Mahesh H. Shindikar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16570"
  },
  {
    "id": "arXiv:2211.16574",
    "title": "Adaptive Scenario Subset Selection for Worst-Case Optimization and its  Application to Well Placement Optimization",
    "abstract": "In this study, we consider simulation-based worst-case optimization problems\nwith continuous design variables and a finite scenario set. To reduce the\nnumber of simulations required and increase the number of restarts for better\nlocal optimum solutions, we propose a new approach referred to as adaptive\nscenario subset selection (AS3). The proposed approach subsamples a scenario\nsubset as a support to construct the worst-case function in a given\nneighborhood, and we introduce such a scenario subset. Moreover, we develop a\nnew optimization algorithm by combining AS3 and the covariance matrix\nadaptation evolution strategy (CMA-ES), denoted AS3-CMA-ES. At each algorithmic\niteration, a subset of support scenarios is selected, and CMA-ES attempts to\noptimize the worst-case objective computed only through a subset of the\nscenarios. The proposed algorithm reduces the number of simulations required by\nexecuting simulations on only a scenario subset, rather than on all scenarios.\nIn numerical experiments, we verified that AS3-CMA-ES is more efficient in\nterms of the number of simulations than the brute-force approach and a\nsurrogate-assisted approach lq-CMA-ES when the ratio of the number of support\nscenarios to the total number of scenarios is relatively small. In addition,\nthe usefulness of AS3-CMA-ES was evaluated for well placement optimization for\ncarbon dioxide capture and storage (CCS). In comparison with the brute-force\napproach and lq-CMA-ES, AS3-CMA-ES was able to find better solutions because of\nmore frequent restarts.",
    "descriptor": "",
    "authors": [
      "Atsuhiro Miyagi",
      "Kazuto Fukuchi",
      "Jun Sakuma",
      "Youhei Akimoto"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.16574"
  },
  {
    "id": "arXiv:2211.16578",
    "title": "ButterflyNet2D: Bridging Classical Methods and Neural Network Methods in  Image Processing",
    "abstract": "Both classical Fourier transform-based methods and neural network methods are\nwidely used in image processing tasks. The former has better interpretability,\nwhereas the latter often achieves better performance in practice. This paper\nintroduces ButterflyNet2D, a regular CNN with sparse cross-channel connections.\nA Fourier initialization strategy for ButterflyNet2D is proposed to approximate\nFourier transforms. Numerical experiments validate the accuracy of\nButterflyNet2D approximating both the Fourier and the inverse Fourier\ntransforms. Moreover, through four image processing tasks and image datasets,\nwe show that training ButterflyNet2D from Fourier initialization does achieve\nbetter performance than random initialized neural networks.",
    "descriptor": "",
    "authors": [
      "Gengzhi Yang",
      "Yingzhou Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16578"
  },
  {
    "id": "arXiv:2211.16581",
    "title": "Batching and Optimal Multi-stage Bipartite Allocations",
    "abstract": "In several applications of real-time matching of demand to supply in online\nmarketplaces, the platform allows for some latency to batch the demand and\nimprove the efficiency. Motivated by these applications, we study the optimal\ntrade-off between batching and inefficiency under adversarial arrival. As our\nbase model, we consider K-stage variants of the vertex weighted b-matching in\nthe adversarial setting, where online vertices arrive stage-wise and in K\nbatches -- in contrast to online arrival. Our main result for this problem is\nan optimal (1-(1-1/K)^K)- competitive (fractional) matching algorithm,\nimproving the classic (1-1/e) competitive ratio bound known for its online\nvariant (Mehta et al., 2007; Aggarwal et al., 2011). We also extend this result\nto the rich model of multi-stage configuration allocation with free-disposals\n(Devanur et al., 2016), which is motivated by the display advertising in video\nstreaming platforms.\nOur main technique is developing tools to vary the trade-off between\n\"greedy-ness\" and \"hedging\" of the algorithm across stages. We rely on a\nparticular family of convex-programming based matchings that distribute the\ndemand in a specifically balanced way among supply in different stages, while\ncarefully modifying the balancedness of the resulting matching across stages.\nMore precisely, we identify a sequence of polynomials with decreasing degrees\nto be used as strictly concave regularizers of the maximum weight matching\nlinear program to form these convex programs. At each stage, our algorithm\nreturns the corresponding regularized optimal solution as the matching of this\nstage (by solving the convex program). Using structural properties of these\nconvex programs and recursively connecting the regularizers together, we\ndevelop a new multi-stage primal-dual framework to analyze the competitive\nratio. We further show this algorithm is optimally competitive.",
    "descriptor": "",
    "authors": [
      "Yiding Feng",
      "Rad Niazadeh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.16581"
  },
  {
    "id": "arXiv:2211.16582",
    "title": "SinDDM: A Single Image Denoising Diffusion Model",
    "abstract": "Denoising diffusion models (DDMs) have led to staggering performance leaps in\nimage generation, editing and restoration. However, existing DDMs use very\nlarge datasets for training. Here, we introduce a framework for training a DDM\non a single image. Our method, which we coin SinDDM, learns the internal\nstatistics of the training image by using a multi-scale diffusion process. To\ndrive the reverse diffusion process, we use a fully-convolutional light-weight\ndenoiser, which is conditioned on both the noise level and the scale. This\narchitecture allows generating samples of arbitrary dimensions, in a\ncoarse-to-fine manner. As we illustrate, SinDDM generates diverse high-quality\nsamples, and is applicable in a wide array of tasks, including style transfer\nand harmonization. Furthermore, it can be easily guided by external\nsupervision. Particularly, we demonstrate text-guided generation from a single\nimage using a pre-trained CLIP model.",
    "descriptor": "",
    "authors": [
      "Vladimir Kulikov",
      "Shahar Yadin",
      "Matan Kleiner",
      "Tomer Michaeli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.16582"
  },
  {
    "id": "arXiv:2211.16585",
    "title": "DSO-DERA Coordination for the Wholesale Market Participation of  Distributed Energy Resources",
    "abstract": "We design a coordination mechanism between a distribution system operator\n(DSO) and distributed energy resource aggregators (DERAs) participating\ndirectly in the wholesale electricity market. Aimed at ensuring system\nreliability while providing open access to DERAs, the coordination mechanism\nincludes a forward auction that allocates access limits to aggregators based on\naggregators' bids that represent their benefits of aggregation. The proposed\ncoordination mechanism results in decoupled DSO and DERAs operations that\nsatisfy the network constraints, independent of the stochasticity of the\nrenewables, wholesale real-time locational marginal prices, and individual\nDERA's aggregation policy. Optimal bidding strategies by competitive\naggregators are also derived. The efficiency of the coordination mechanism and\nthe locational price distribution at buses of a radial distribution grid are\ndemonstrated for a 141-bus radial network.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Cong Chen",
      "Subhonmesh Bose",
      "Lang Tong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16585"
  },
  {
    "id": "arXiv:2211.16587",
    "title": "Rigorous Assessment of Model Inference Accuracy using Language  Cardinality",
    "abstract": "Models such as finite state automata are widely used to abstract the behavior\nof software systems by capturing the sequences of events observable during\ntheir execution. Nevertheless, models rarely exist in practice and, when they\ndo, get easily outdated; moreover, manually building and maintaining models is\ncostly and error-prone. As a result, a variety of model inference methods that\nautomatically construct models from execution traces have been proposed to\naddress these issues.\nHowever, performing a systematic and reliable accuracy assessment of inferred\nmodels remains an open problem. Even when a reference model is given, most\nexisting model accuracy assessment methods may return misleading and biased\nresults. This is mainly due to their reliance on statistical estimators over a\nfinite number of randomly generated traces, introducing avoidable uncertainty\nabout the estimation and being sensitive to the parameters of the random trace\ngenerative process.\nThis paper addresses this problem by developing a systematic approach based\non analytic combinatorics that minimizes bias and uncertainty in model accuracy\nassessment by replacing statistical estimation with deterministic accuracy\nmeasures. We experimentally demonstrate the consistency and applicability of\nour approach by assessing the accuracy of models inferred by state-of-the-art\ninference tools against reference models from established specification mining\nbenchmarks.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Donato Clun",
      "Donghwan Shin",
      "Antonio Filieri",
      "Domenico Bianculli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.16587"
  },
  {
    "id": "arXiv:2211.16590",
    "title": "Artificial prediction markets present a novel opportunity for human-AI  collaboration",
    "abstract": "Despite high-profile successes in the field of Artificial Intelligence,\nmachine-driven technologies still suffer important limitations, particularly\nfor complex tasks where creativity, planning, common sense, intuition, or\nlearning from limited data is required. These limitations motivate effective\nmethods for human-machine collaboration. Our work makes two primary\ncontributions. We thoroughly experiment with an artificial prediction market\nmodel to understand the effects of market parameters on model performance for\nbenchmark classification tasks. We then demonstrate, through simulation, the\nimpact of exogenous agents in the market, where these exogenous agents\nrepresent primitive human behaviors. This work lays the foundation for a novel\nset of hybrid human-AI machine learning algorithms.",
    "descriptor": "",
    "authors": [
      "Tatiana Chakravorti",
      "Vaibhav Singh",
      "Sarah Rajmajer",
      "Michael McLaughlin",
      "Robert Fraleigh",
      "Christopher Griffin",
      "Anthony Kwasnica",
      "David Pennock",
      "C. Lee Giles"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.16590"
  },
  {
    "id": "arXiv:2211.16592",
    "title": "Sequence learning in a spiking neuronal network with memristive synapses",
    "abstract": "Brain-inspired computing proposes a set of algorithmic principles that hold\npromise for advancing artificial intelligence. They endow systems with self\nlearning capabilities, efficient energy usage, and high storage capacity. A\ncore concept that lies at the heart of brain computation is sequence learning\nand prediction. This form of computation is essential for almost all our daily\ntasks such as movement generation, perception, and language. Understanding how\nthe brain performs such a computation is not only important to advance\nneuroscience but also to pave the way to new technological brain-inspired\napplications. A previously developed spiking neural network implementation of\nsequence prediction and recall learns complex, high-order sequences in an\nunsupervised manner by local, biologically inspired plasticity rules. An\nemerging type of hardware that holds promise for efficiently running this type\nof algorithm is neuromorphic hardware. It emulates the way the brain processes\ninformation and maps neurons and synapses directly into a physical substrate.\nMemristive devices have been identified as potential synaptic elements in\nneuromorphic hardware. In particular, redox-induced resistive random access\nmemories (ReRAM) devices stand out at many aspects. They permit scalability,\nare energy efficient and fast, and can implement biological plasticity rules.\nIn this work, we study the feasibility of using ReRAM devices as a replacement\nof the biological synapses in the sequence learning model. We implement and\nsimulate the model including the ReRAM plasticity using the neural simulator\nNEST. We investigate the effect of different device properties on the\nperformance characteristics of the sequence learning model, and demonstrate\nresilience with respect to different on-off ratios, conductance resolutions,\ndevice variability, and synaptic failure.",
    "descriptor": "\nComments: 23 pages, 13 Figures\n",
    "authors": [
      "Younes Bouhadjar",
      "Sebastian Siegel",
      "Tom Tetzlaff",
      "Markus Diesmann",
      "Rainer Waser",
      "Dirk J. Wouters"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.16592"
  },
  {
    "id": "arXiv:2211.16594",
    "title": "Exploiting Category Names for Few-Shot Classification with  Vision-Language Models",
    "abstract": "Vision-language foundation models pretrained on large-scale data provide a\npowerful tool for many visual understanding tasks. Notably, many\nvision-language models build two encoders (visual and textual) that can map two\nmodalities into the same embedding space. As a result, the learned\nrepresentations achieve good zero-shot performance on tasks like image\nclassification. However, when there are only a few examples per category, the\npotential of large vision-language models is often underperformed, mainly due\nto the gap between a large number of parameters and a relatively small amount\nof training data. This paper shows that we can significantly improve the\nperformance of few-shot classification by using the category names to\ninitialize the classification head. More interestingly, we can borrow the\nnon-perfect category names, or even names from a foreign language, to improve\nthe few-shot classification performance compared with random initialization.\nWith the proposed category name initialization method, our model obtains the\nstate-of-the-art performance on a number of few-shot image classification\nbenchmarks (e.g., 87.37\\% on ImageNet and 96.08\\% on Stanford Cars, both using\nfive-shot learning). We also investigate and analyze when the benefit of\ncategory names diminishes and how to use distillation to improve the\nperformance of smaller models, providing guidance for future research.",
    "descriptor": "",
    "authors": [
      "Taihong Xiao",
      "Zirui Wang",
      "Liangliang Cao",
      "Jiahui Yu",
      "Shengyang Dai",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16594"
  },
  {
    "id": "arXiv:2211.16597",
    "title": "Right and wrong: ten choices in language design",
    "abstract": "A description of language design choices that have profound effects on\nsoftware quality, criticism of how ordinary OO languages address them, and\nexplanation of the thinking behind Eiffel's corresponding mechanisms.",
    "descriptor": "",
    "authors": [
      "Bertrand Meyer"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.16597"
  },
  {
    "id": "arXiv:2211.16605",
    "title": "Top-Down Synthesis for Library Learning",
    "abstract": "This paper introduces corpus-guided top-down synthesis as a mechanism for\nsynthesizing library functions that capture common functionality from a corpus\nof programs in a domain specific language (DSL). The algorithm builds\nabstractions directly from initial DSL primitives, using syntactic pattern\nmatching of intermediate abstractions to intelligently prune the search space\nand guide the algorithm towards abstractions that maximally capture shared\nstructures in the corpus. We present an implementation of the approach in a\ntool called Stitch and evaluate it against the state-of-the-art deductive\nlibrary learning algorithm from DreamCoder. Our evaluation shows that Stitch is\n3-4 orders of magnitude faster and uses 2 orders of magnitude less memory while\nmaintaining comparable or better library quality (as measured by\ncompressivity). We also demonstrate Stitch's scalability on corpora containing\nhundreds of complex programs that are intractable with prior deductive\napproaches and show empirically that it is robust to terminating the search\nprocedure early -- further allowing it to scale to challenging datasets by\nmeans of early stopping.",
    "descriptor": "\nComments: Accepted at POPL 2023\n",
    "authors": [
      "Matthew Bowers",
      "Theo X. Olausson",
      "Catherine Wong",
      "Gabriel Grand",
      "Joshua B. Tenenbaum",
      "Kevin Ellis",
      "Armando Solar-Lezama"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16605"
  },
  {
    "id": "arXiv:2211.16607",
    "title": "Transfer Entropy Bottleneck: Learning Sequence to Sequence Information  Transfer",
    "abstract": "When presented with a data stream of two statistically dependent variables,\npredicting the future of one of the variables (the target stream) can benefit\nfrom information about both its history and the history of the other variable\n(the source stream). For example, fluctuations in temperature at a weather\nstation can be predicted using both temperatures and barometric readings.\nHowever, a challenge when modelling such data is that it is easy for a neural\nnetwork to rely on the greatest joint correlations within the target stream,\nwhich may ignore a crucial but small information transfer from the source to\nthe target stream. As well, there are often situations where the target stream\nmay have previously been modelled independently and it would be useful to use\nthat model to inform a new joint model. Here, we develop an information\nbottleneck approach for conditional learning on two dependent streams of data.\nOur method, which we call Transfer Entropy Bottleneck (TEB), allows one to\nlearn a model that bottlenecks the directed information transferred from the\nsource variable to the target variable, while quantifying this information\ntransfer within the model. As such, TEB provides a useful new information\nbottleneck approach for modelling two statistically dependent streams of data\nin order to make predictions about one of them.",
    "descriptor": "\nComments: 39 pages, 28 figures\n",
    "authors": [
      "Damjan Kalajdzievski",
      "Ximeng Mao",
      "Pascal Fortier-Poisson",
      "Guillaume Lajoie",
      "Blake Richards"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.16607"
  },
  {
    "id": "arXiv:2211.16610",
    "title": "Deep Learning Discrete Calculus (DLDC): A Family of Discrete Numerical  Methods by Universal Approximation for STEM Education to Frontier Research",
    "abstract": "The article proposes formulating and codifying a set of applied numerical\nmethods, coined as Deep Learning Discrete Calculus (DLDC), that uses the\nknowledge from discrete numerical methods to interpret the deep learning\nalgorithms through the lens of applied mathematics. The DLDC methods aim to\nleverage the flexibility and ever increasing resources of deep learning and\nrich literature of numerical analysis to formulate a general class of numerical\nmethod that can directly use data with uncertainty to predict the behavior of\nan unknown system as well as elevate the speed and accuracy of numerical\nsolution of the governing equations for known systems. The article is\nstructured in two major sections. In the first section, the building blocks of\nthe DLDC methods are presented and deep learning structures analogous to\ntraditional numerical methods such as finite difference and finite element\nmethods are constructed with a view to incorporate these techniques in Science,\nTechnology, Engineering, Mathematics (STEM) syllabus for K-12 students. The\nsecond section builds upon the building blocks of the previous discussion,and\nproposes new solution schemes for differential and integral equations pertinent\nto multiscale mechanics. Each section is accompanied with mathematical\nformulation of the numerical methods, analogous DLDC formulation, and suitable\nexamples.",
    "descriptor": "",
    "authors": [
      "Sourav Saha",
      "Chanwook Park",
      "Stefan Knapik",
      "Jiachen Guo",
      "Owen Huang",
      "Wing Kam Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16610"
  },
  {
    "id": "arXiv:2211.16611",
    "title": "Holonomic Control of Arbitrary Configurations of Docked Modboats",
    "abstract": "The Modboat is a low-cost, underactuated, modular robot capable of surface\nswimming, docking to other modules, and undocking from them using only a single\nmotor and two passive flippers. Undocking is achieved by causing intentional\nself-collision between the tails of neighboring modules in certain\nconfigurations; this becomes a challenge, however, when collective swimming as\none connected component is desirable. Prior work has developed controllers that\nturn arbitrary configurations of docked Modboats into steerable vehicles, but\nthey cannot counteract lateral forces and disturbances. In this work we present\na centralized control strategy to create holonomic vehicles out of arbitrary\nconfigurations of docked Modboats using an iterative potential-field based\nsearch. We experimentally demonstrate that our controller performs well and can\ncontrol surge and sway velocities and yaw angle simultaneously.",
    "descriptor": "",
    "authors": [
      "Zhijie Qiao",
      "Gedaliah Knizhnik",
      "Mark Yim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.16611"
  },
  {
    "id": "arXiv:2211.16612",
    "title": "Numerical approximation of partial differential equations with MFEM  library",
    "abstract": "We revise the finite element formulation for Lagrange, Raviart- Thomas, and\nTaylor-Hood finite element spaces. We solve Laplace equation in first and\nsecond order formulation, and compare the solutions obtained with Lagrange and\nRaviart-Thomas finite element spaces by changing the order of the shape\nfunctions and the refinement level of the mesh. Finally, we solve Navier-Stokes\nequations in a two dimensional domain, where the solution is a steady state,\nand in a three dimensional domain, where the system presents a turbulent\nbehaviour. All numerical experiments are computed using MFEM library, which is\nalso studied.",
    "descriptor": "\nComments: Undergrad degree work. 65 pages. arXiv admin note: text overlap with arXiv:2105.03002\n",
    "authors": [
      "Felipe Cruz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16612"
  },
  {
    "id": "arXiv:2211.16617",
    "title": "Identification of the Breach of Short-term Rental Regulations in Irish  Rent Pressure Zones",
    "abstract": "The housing crisis in Ireland has rapidly grown in recent years. To make a\nmore significant profit, many landlords are no longer renting out their houses\nunder long-term tenancies but under short-term tenancies. The shift from\nlong-term to short-term rentals has harmed the supply of private housing\nrentals. Regulating rentals in Rent Pressure Zones with the highest and rising\nrents is becoming a tricky issue.\nIn this paper, we develop a breach identifier to check short-term rentals\nlocated in Rent Pressure Zones with potential breaches only using publicly\navailable data from Airbnb (an online marketplace focused on short-term\nhome-stays). First, we use a Residual Neural Network to filter out outdoor\nlandscape photos that negatively impact identifying whether an owner has\nmultiple rentals in a Rent Pressure Zone. Second, a Siamese Neural Network is\nused to compare the similarity of indoor photos to determine if multiple rental\nposts correspond to the same residence. Next, we use the Haversine algorithm to\nlocate short-term rentals within a circle centered on the coordinate of a\npermit. Short-term rentals with a permit will not be restricted. Finally, we\nimprove the occupancy estimation model combined with sentiment analysis, which\nmay provide higher accuracy.\nBecause Airbnb does not disclose accurate house coordinates and occupancy\ndata, it is impossible to verify the accuracy of our breach identifier. The\naccuracy of the occupancy estimator cannot be verified either. It only provides\nan estimate within a reasonable range. Users should be skeptical of short-term\nrentals that are flagged as possible breaches.",
    "descriptor": "",
    "authors": [
      "Guowen Liu",
      "Inmaculada Arnedillo-Sanchez",
      "Zhenshuo Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16617"
  },
  {
    "id": "arXiv:2211.16620",
    "title": "TetraFreeQ: tetrahedra-free quadrature on polyhedral elements",
    "abstract": "In this paper we provide a tetrahedra-free algorithm to compute\nlow-cardinality quadrature rules with a given degree of polynomial exactness,\npositive weights and interior nodes on a polyhedral element with arbitrary\nshape. The key tools are the notion of Tchakaloff discretization set and the\nsolution of moment-matching equations by Lawson-Hanson iterations for\nNonNegative Least-Squares. Several numerical tests are presented. The method is\nimplemented in Matlab as open-source software.",
    "descriptor": "",
    "authors": [
      "Alvise Sommariva",
      "Marco Vianello"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16620"
  },
  {
    "id": "arXiv:2211.16626",
    "title": "Sludge for Good: Slowing and Imposing Costs on Cyber Attackers",
    "abstract": "Choice architecture describes the design by which choices are presented to\npeople. Nudges are an aspect intended to make \"good\" outcomes easy, such as\nusing password meters to encourage strong passwords. Sludge, on the contrary,\nis friction that raises the transaction cost and is often seen as a negative to\nusers. Turning this concept around, we propose applying sludge for positive\ncybersecurity outcomes by using it offensively to consume attackers' time and\nother resources.\nTo date, most cyber defenses have been designed to be optimally strong and\neffective and prohibit or eliminate attackers as quickly as possible. Our\ncomplimentary approach is to also deploy defenses that seek to maximize the\nconsumption of the attackers' time and other resources while causing as little\ndamage as possible to the victim. This is consistent with zero trust and\nsimilar mindsets which assume breach. The Sludge Strategy introduces\ncost-imposing cyber defense by strategically deploying friction for attackers\nbefore, during, and after an attack using deception and authentic design\nfeatures. We present the characteristics of effective sludge, and show a\ncontinuum from light to heavy sludge. We describe the quantitative and\nqualitative costs to attackers and offer practical considerations for deploying\nsludge in practice. Finally, we examine real-world examples of U.S. government\noperations to frustrate and impose cost on cyber adversaries.",
    "descriptor": "",
    "authors": [
      "Josiah Dykstra",
      "Kelly Shortridge",
      "Jamie Met",
      "Douglas Hough"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.16626"
  },
  {
    "id": "arXiv:2211.16630",
    "title": "DINER: Depth-aware Image-based NEural Radiance fields",
    "abstract": "We present Depth-aware Image-based NEural Radiance fields (DINER). Given a\nsparse set of RGB input views, we predict depth and feature maps to guide the\nreconstruction of a volumetric scene representation that allows us to render 3D\nobjects under novel views. Specifically, we propose novel techniques to\nincorporate depth information into feature fusion and efficient scene sampling.\nIn comparison to the previous state of the art, DINER achieves higher synthesis\nquality and can process input views with greater disparity. This allows us to\ncapture scenes more completely without changing capturing hardware requirements\nand ultimately enables larger viewpoint changes during novel view synthesis. We\nevaluate our method by synthesizing novel views, both for human heads and for\ngeneral objects, and observe significantly improved qualitative results and\nincreased perceptual metrics compared to the previous state of the art. The\ncode will be made publicly available for research purposes.",
    "descriptor": "\nComments: Website: this https URL ; Video: this https URL\n",
    "authors": [
      "Malte Prinzler",
      "Otmar Hilliges",
      "Justus Thies"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16630"
  },
  {
    "id": "arXiv:2211.16631",
    "title": "Every Node Counts: Improving the Training of Graph Neural Networks on  Node Classification",
    "abstract": "Graph Neural Networks (GNNs) are prominent in handling sparse and\nunstructured data efficiently and effectively. Specifically, GNNs were shown to\nbe highly effective for node classification tasks, where labelled information\nis available for only a fraction of the nodes. Typically, the optimization\nprocess, through the objective function, considers only labelled nodes while\nignoring the rest. In this paper, we propose novel objective terms for the\ntraining of GNNs for node classification, aiming to exploit all the available\ndata and improve accuracy. Our first term seeks to maximize the mutual\ninformation between node and label features, considering both labelled and\nunlabelled nodes in the optimization process. Our second term promotes\nanisotropic smoothness in the prediction maps. Lastly, we propose a\ncross-validating gradients approach to enhance the learning from labelled data.\nOur proposed objectives are general and can be applied to various GNNs and\nrequire no architectural modifications. Extensive experiments demonstrate our\napproach using popular GNNs like GCN, GAT and GCNII, reading a consistent and\nsignificant accuracy improvement on 10 real-world node classification datasets.",
    "descriptor": "",
    "authors": [
      "Moshe Eliasof",
      "Eldad Haber",
      "Eran Treister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.16631"
  },
  {
    "id": "arXiv:2211.16632",
    "title": "Hierarchical Transformer for Survival Prediction Using Multimodality  Whole Slide Images and Genomics",
    "abstract": "Learning good representation of giga-pixel level whole slide pathology images\n(WSI) for downstream tasks is critical. Previous studies employ multiple\ninstance learning (MIL) to represent WSIs as bags of sampled patches because,\nfor most occasions, only slide-level labels are available, and only a tiny\nregion of the WSI is disease-positive area. However, WSI representation\nlearning still remains an open problem due to: (1) patch sampling on a higher\nresolution may be incapable of depicting microenvironment information such as\nthe relative position between the tumor cells and surrounding tissues, while\npatches at lower resolution lose the fine-grained detail; (2) extracting\npatches from giant WSI results in large bag size, which tremendously increases\nthe computational cost. To solve the problems, this paper proposes a\nhierarchical-based multimodal transformer framework that learns a hierarchical\nmapping between pathology images and corresponding genes. Precisely, we\nrandomly extract instant-level patch features from WSIs with different\nmagnification. Then a co-attention mapping between imaging and genomics is\nlearned to uncover the pairwise interaction and reduce the space complexity of\nimaging features. Such early fusion makes it computationally feasible to use\nMIL Transformer for the survival prediction task. Our architecture requires\nfewer GPU resources compared with benchmark methods while maintaining better\nWSI representation ability. We evaluate our approach on five cancer types from\nthe Cancer Genome Atlas database and achieved an average c-index of $0.673$,\noutperforming the state-of-the-art multimodality methods.",
    "descriptor": "\nComments: accepted by ICPR 2022\n",
    "authors": [
      "Chunyuan Li",
      "Xinliang Zhu",
      "Jiawen Yao",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16632"
  },
  {
    "id": "arXiv:2211.16633",
    "title": "Collaborative learning model predictive control for repetitive tasks",
    "abstract": "This paper presents a cloud-based learning model predictive controller that\nintegrates three interacting components: a set of agents, which must learn to\nperform a finite set of tasks with the minimum possible local cost; a\ncoordinator, which assigns the tasks to the agents; and the cloud, which stores\ndata to facilitate the agents' learning. The tasks consist in traveling\nrepeatedly between a set of target states while satisfying input and state\nconstraints. In turn, the state constraints may change in time for each of the\npossible tasks. To deal with it, different modes of operation, which establish\ndifferent restrictions, are defined. The agents' inputs are found by solving\nlocal model predictive control (MPC) problems where the terminal set and cost\nare defined from previous trajectories. The data collected by each agent is\nuploaded to the cloud and made accessible to all their peers. Likewise,\nsimilarity between tasks is exploited to accelerate the learning process. The\napplicability of the proposed approach is illustrated by simulation results.",
    "descriptor": "\nComments: Conference on Decision and Control 2022\n",
    "authors": [
      "Paula Chanfreut",
      "Jos\u00e9 Mar\u00eda Maestre",
      "Eduardo F. Camacho",
      "Francesco Borrelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16633"
  },
  {
    "id": "arXiv:2211.16634",
    "title": "SPARTAN: Sparse Hierarchical Memory for Parameter-Efficient Transformers",
    "abstract": "Fine-tuning pre-trained language models (PLMs) achieves impressive\nperformance on a range of downstream tasks, and their sizes have consequently\nbeen getting bigger. Since a different copy of the model is required for each\ntask, this paradigm is infeasible for storage-constrained edge devices like\nmobile phones. In this paper, we propose SPARTAN, a parameter efficient (PE)\nand computationally fast architecture for edge devices that adds hierarchically\norganized sparse memory after each Transformer layer. SPARTAN freezes the PLM\nparameters and fine-tunes only its memory, thus significantly reducing storage\ncosts by re-using the PLM backbone for different tasks. SPARTAN contains two\nlevels of memory, with only a sparse subset of parents being chosen in the\nfirst level for each input, and children cells corresponding to those parents\nbeing used to compute an output representation. This sparsity combined with\nother architecture optimizations improves SPARTAN's throughput by over 90%\nduring inference on a Raspberry Pi 4 when compared to PE baselines (adapters)\nwhile also outperforming the latter by 0.1 points on the GLUE benchmark.\nFurther, it can be trained 34% faster in a few-shot setting, while performing\nwithin 0.9 points of adapters. Qualitative analysis shows that different parent\ncells in SPARTAN specialize in different topics, thus dividing responsibility\nefficiently.",
    "descriptor": "",
    "authors": [
      "Ameet Deshpande",
      "Md Arafat Sultan",
      "Anthony Ferritto",
      "Ashwin Kalyan",
      "Karthik Narasimhan",
      "Avirup Sil"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16634"
  },
  {
    "id": "arXiv:2211.16636",
    "title": "Iterative Scene Graph Generation with Generative Transformers",
    "abstract": "Scene graphs provide a rich, structured representation of a scene by encoding\nthe entities (objects) and their spatial relationships in a graphical format.\nThis representation has proven useful in several tasks, such as question\nanswering, captioning, and even object detection, to name a few. Current\napproaches take a generation-by-classification approach where the scene graph\nis generated through labeling of all possible edges between objects in a scene,\nwhich adds computational overhead to the approach. This work introduces a\ngenerative transformer-based approach to generating scene graphs beyond link\nprediction. Using two transformer-based components, we first sample a possible\nscene graph structure from detected objects and their visual features. We then\nperform predicate classification on the sampled edges to generate the final\nscene graph. This approach allows us to efficiently generate scene graphs from\nimages with minimal inference overhead. Extensive experiments on the Visual\nGenome dataset demonstrate the efficiency of the proposed approach. Without\nbells and whistles, we obtain, on average, 20.7% mean recall (mR@100) across\ndifferent settings for scene graph generation (SGG), outperforming\nstate-of-the-art SGG approaches while offering competitive performance to\nunbiased SGG approaches.",
    "descriptor": "\nComments: 10 pages, 4 figures, 4 tables\n",
    "authors": [
      "Sanjoy Kundu",
      "Sathyanarayanan N. Aakur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16636"
  },
  {
    "id": "arXiv:2211.16646",
    "title": "Progressive Knowledge Transfer Based on Human Visual Perception  Mechanism for Perceptual Quality Assessment of Point Clouds",
    "abstract": "With the wide applications of colored point cloud in many fields, point cloud\nperceptual quality assessment plays a vital role in the visual communication\nsystems owing to the existence of quality degradations introduced in various\nstages. However, the existing point cloud quality assessments ignore the\nmechanism of human visual system (HVS) which has an important impact on the\naccuracy of the perceptual quality assessment. In this paper, a progressive\nknowledge transfer based on human visual perception mechanism for perceptual\nquality assessment of point clouds (PKT-PCQA) is proposed. The PKT-PCQA merges\nlocal features from neighboring regions and global features extracted from\ngraph spectrum. Taking into account the HVS properties, the spatial and channel\nattention mechanism is also considered in PKT-PCQA. Besides, inspired by the\nhierarchical perception system of human brains, PKT-PCQA adopts a progressive\nknowledge transfer to convert the coarse-grained quality classification\nknowledge to the fine-grained quality prediction task. Experiments on three\nlarge and independent point cloud assessment datasets show that the proposed no\nreference PKT-PCQA network achieves better of equivalent performance comparing\nwith the state-of-the-art full reference quality assessment methods,\noutperforming the existed no reference quality assessment network.",
    "descriptor": "",
    "authors": [
      "Qi Liu",
      "Yiyun Liu",
      "Honglei Su",
      "Hui Yuan",
      "Raouf Hamzaoui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.16646"
  },
  {
    "id": "arXiv:2211.16648",
    "title": "COMET: A Comprehensive Cluster Design Methodology for Distributed Deep  Learning Training",
    "abstract": "Modern Deep Learning (DL) models have grown to sizes requiring massive\nclusters of specialized, high-end nodes to train. Designing such clusters to\nmaximize both performance and utilization to amortize their steep cost is a\nchallenging task requiring careful balance of compute, memory, and network\nresources. Moreover, a plethora of each model's tuning knobs drastically affect\nthe performance, with optimal values often depending on the underlying\ncluster's characteristics, which necessitates a complex cluster-workload\nco-design process. To facilitate the design space exploration of such massive\nDL training clusters, we introduce COMET a holistic cluster design methodology\nand workflow to jointly study the impact of parallelization strategies and key\ncluster resource provisioning on the performance of distributed DL training. We\ndevelop a step-by-step process to establish a reusable and flexible\nmethodology, and demonstrate its application with a case study of training a\nTransformer-1T model on a cluster of variable compute, memory, and network\nresources. Our case study demonstrates COMET's utility in identifying promising\narchitectural optimization directions and guiding system designers in\nconfiguring key model and cluster parameters.",
    "descriptor": "",
    "authors": [
      "Divya Kiran Kadiyala",
      "Saeed Rashidi",
      "Taekyung Heo",
      "Abhimanyu Rajeshkumar Bambhaniya",
      "Tushar Krishna",
      "Alexandros Daglis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16648"
  },
  {
    "id": "arXiv:2211.16649",
    "title": "CLIP-Nav: Using CLIP for Zero-Shot Vision-and-Language Navigation",
    "abstract": "Household environments are visually diverse. Embodied agents performing\nVision-and-Language Navigation (VLN) in the wild must be able to handle this\ndiversity, while also following arbitrary language instructions. Recently,\nVision-Language models like CLIP have shown great performance on the task of\nzero-shot object recognition. In this work, we ask if these models are also\ncapable of zero-shot language grounding. In particular, we utilize CLIP to\ntackle the novel problem of zero-shot VLN using natural language referring\nexpressions that describe target objects, in contrast to past work that used\nsimple language templates describing object classes. We examine CLIP's\ncapability in making sequential navigational decisions without any\ndataset-specific finetuning, and study how it influences the path that an agent\ntakes. Our results on the coarse-grained instruction following task of REVERIE\ndemonstrate the navigational capability of CLIP, surpassing the supervised\nbaseline in terms of both success rate (SR) and success weighted by path length\n(SPL). More importantly, we quantitatively show that our CLIP-based zero-shot\napproach generalizes better to show consistent performance across environments\nwhen compared to SOTA, fully supervised learning approaches when evaluated via\nRelative Change in Success (RCS).",
    "descriptor": "\nComments: 8 pages, Accepted at LangRob Workshop at Conference on Robot Learning (CoRL), 2022\n",
    "authors": [
      "Vishnu Sashank Dorbala",
      "Gunnar Sigurdsson",
      "Robinson Piramuthu",
      "Jesse Thomason",
      "Gaurav S. Sukhatme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.16649"
  },
  {
    "id": "arXiv:2211.16653",
    "title": "CRU: A Novel Neural Architecture for Improving the Predictive  Performance of Time-Series Data",
    "abstract": "The time-series forecasting (TSF) problem is a traditional problem in the\nfield of artificial intelligence. Models such as Recurrent Neural Network\n(RNN), Long Short Term Memory (LSTM), and GRU (Gate Recurrent Units) have\ncontributed to improving the predictive accuracy of TSF. Furthermore, model\nstructures have been proposed to combine time-series decomposition methods,\nsuch as seasonal-trend decomposition using Loess (STL) to ensure improved\npredictive accuracy. However, because this approach is learned in an\nindependent model for each component, it cannot learn the relationships between\ntime-series components. In this study, we propose a new neural architecture\ncalled a correlation recurrent unit (CRU) that can perform time series\ndecomposition within a neural cell and learn correlations (autocorrelation and\ncorrelation) between each decomposition component. The proposed neural\narchitecture was evaluated through comparative experiments with previous\nstudies using five univariate time-series datasets and four multivariate\ntime-series data. The results showed that long- and short-term predictive\nperformance was improved by more than 10%. The experimental results show that\nthe proposed CRU is an excellent method for TSF problems compared to other\nneural architectures.",
    "descriptor": "",
    "authors": [
      "Sunghyun Sim",
      "Dohee Kim",
      "Hyerim Bae"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.16653"
  },
  {
    "id": "arXiv:2211.16655",
    "title": "High order asymptotic preserving finite difference WENO schemes with  constrained transport for MHD equations in all sonic Mach numbers",
    "abstract": "In this paper, a high-order semi-implicit (SI) asymptotic preserving (AP) and\ndivergence-free finite difference weighted essentially nonoscillatory (WENO)\nscheme is proposed for magnetohydrodynamic (MHD) equations. We consider the\nsonic Mach number $\\varepsilon$ ranging from $0$ to $\\mathcal{O}(1)$.\nHigh-order accuracy in time is obtained by SI implicit-explicit Runge-Kutta\n(IMEX-RK) time discretization. High-order accuracy in space is achieved by\nfinite difference WENO schemes with characteristic-wise reconstructions. A\nconstrained transport method is applied to maintain a discrete divergence-free\ncondition. We formally prove that the scheme is AP. Asymptotic accuracy (AA) in\nthe incompressible MHD limit is obtained if the implicit part of the SI IMEX-RK\nscheme is stiffly accurate. Numerical experiments are provided to validate the\nAP, AA, and divergence-free properties of our proposed approach. Besides, the\nscheme can well capture discontinuities such as shocks in an essentially\nnon-oscillatory fashion in the compressible regime, while it is also a good\nincompressible solver with uniform large-time step conditions in the low sonic\nMach limit.",
    "descriptor": "",
    "authors": [
      "Wei Chen",
      "Kailiang Wu",
      "Tao Xiong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16655"
  },
  {
    "id": "arXiv:2211.16656",
    "title": "An Integrated Ride-Matching Model for Shared Mobility on Demand Services",
    "abstract": "Shared mobility on demand (MoD) services are receiving increased attention as\nmany high volume ride-hailing companies are offering shared services (e.g.\nUberPool, LyftLine) at an increasing rate. Also, the advent of autonomous\nvehicles (AVs) promises further operational opportunities to benefit from these\ndevelopments as AVs enable a centrally operated and fully connected fleet.\nThere are two fundamental tasks for a shared MoD service: ride-matching and\nvehicle rebalancing. Traditionally, these two functions are performed\nsequentially and independently. In this paper, we propose and formulate an\nintegrated ride-matching problem which aims to integrate ride-matching and\nrebalancing into a single formulation. The integrated problem benefits from\ninteractions between these two tasks. We also propose a methodology to solve\nthe integrated shared ride-matching problem by using supply level information\nbased on a grid representation of the city network. We demonstrate the\neffectiveness of the proposed methodology through a comparative case study\nusing a benchmark sequential approach and an open source data set. Our results\nshow that the integrated model is able to serve at least the same amount of\npassengers with significant gains in terms of level of service and\nsustainability metrics.",
    "descriptor": "",
    "authors": [
      "Kerem Tuncel",
      "Haris N. Koutsopoulos",
      "Zhenliang Ma"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16656"
  },
  {
    "id": "arXiv:2211.16657",
    "title": "Task-Driven Hybrid Model Reduction for Dexterous Manipulation",
    "abstract": "In contact-rich tasks, like dexterous manipulation, the hybrid nature of\nmaking and breaking contact creates challenges for model representation and\ncontrol. For example, choosing and sequencing contact locations for in-hand\nmanipulation, where there are thousands of potential hybrid modes, is not\ngenerally tractable. In this paper, we are inspired by the observation that far\nfewer modes are actually necessary to accomplish many tasks. Building on our\nprior work learning hybrid models, represented as linear complementarity\nsystems, we find a reduced-order hybrid model requiring only a limited number\nof task-relevant modes. This simplified representation, in combination with\nmodel predictive control, enables real-time control yet is sufficient for\nachieving high performance. We demonstrate the proposed method first on\nsynthetic hybrid systems, reducing the mode count by multiple orders of\nmagnitude while achieving task performance loss of less than 5%. We also apply\nthe proposed method to a three-fingered robotic hand manipulating a previously\nunknown object. With no prior knowledge, we achieve state-of-the-art\nclosed-loop performance in less than five minutes of online learning.",
    "descriptor": "\nComments: Reproducing code: this https URL\n",
    "authors": [
      "Wanxin Jin",
      "Michael Posa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16657"
  },
  {
    "id": "arXiv:2211.16660",
    "title": "Approximating binary longest common subsequence in near-linear time",
    "abstract": "The Longest Common Subsequence (LCS) is a fundamental string similarity\nmeasure, and computing the LCS of two strings is a classic algorithms question.\nA textbook dynamic programming algorithm gives an exact algorithm in quadratic\ntime, and this is essentially best possible under plausible fine-grained\ncomplexity assumptions, so a natural problem is to find faster approximation\nalgorithms. When the inputs are two binary strings, there is a simple\n$\\frac{1}{2}$-approximation in linear time: compute the longest common all-0s\nor all-1s subsequence. It has been open whether a better approximation is\npossible even in truly subquadratic time. Rubinstein and Song showed that the\nanswer is yes under the assumption that the two input strings have equal\nlengths. We settle the question, generalizing their result to unequal length\nstrings, proving that, for any $\\varepsilon>0$, there exists $\\delta>0$ and a\n$(\\frac{1}{2}+\\delta)$-approximation algorithm for binary LCS that runs in\n$n^{1+\\varepsilon}$ time. As a consequence of our result and a result of Akmal\nand Vassilevska-Williams, for any $\\varepsilon>0$, there exists a\n$(\\frac{1}{q}+\\delta)$-approximation for LCS over $q$-ary strings in\n$n^{1+\\varepsilon}$ time.\nOur techniques build on the recent work of Guruswami, He, and Li who proved\nnew bounds for error-correcting codes tolerating deletion errors. They prove a\ncombinatorial \"structure lemma\" for strings which classifies them according to\ntheir oscillation patterns. We prove and use an algorithmic generalization of\nthis structure lemma, which may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Xiaoyu He",
      "Ray Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.16660"
  },
  {
    "id": "arXiv:2211.16662",
    "title": "A Blockchain-based Semantic Exchange Framework for Web 3.0 toward  Participatory Economy",
    "abstract": "Web 3.0 is the next-generation Internet that enables participants to read,\nwrite, and own contents in a decentralized manner. It is mainly driven by\nblockchain, semantic communication, edge computing, and artificial\nintelligence, which can construct value networks to achieve participatory\neconomics based on participatory decision making. Web 3.0 can capture the\ncharacteristics of blockchain, semantic extraction, and communication to\nachieve decentralized semantic sharing and transfer information precisely.\nHowever, current Web 3.0 solutions focus on the blockchain while overlooking\nother new technologies' roles in Web 3.0. To further unleash the advantages of\nsemantic extraction and communication in Web 3.0, in this paper, we propose a\nblockchain-based semantic exchange framework to realize fair and efficient\ninteractions. In this framework, we first attempt to tokenize semantic\ninformation into Non-Fungible Token (NFT) for semantic exchange. Then we\nutilize a Stackelberg game to maximize buying and pricing strategies for\nsemantic trading. We also leverage Zero-Knowledge Proof to share authentic\nsemantic information without publishing it before receiving payments, which can\nachieve a fair and privacy-preserving trading compared with current NFT\nmarketplaces. A case study about urban planning is given to show clearly the\nproposed mechanisms. Finally, several challenges and opportunities are\nidentified.",
    "descriptor": "\nComments: 7 pages, 5 figures and tables\n",
    "authors": [
      "Yijing Lin",
      "Zhipeng Gao",
      "Yaofeng Tu",
      "Hongyang Du",
      "Dusit Niyato",
      "Jiawen Kang",
      "Hui Yang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.16662"
  },
  {
    "id": "arXiv:2211.16663",
    "title": "Geoclidean: Few-Shot Generalization in Euclidean Geometry",
    "abstract": "Euclidean geometry is among the earliest forms of mathematical thinking.\nWhile the geometric primitives underlying its constructions, such as perfect\nlines and circles, do not often occur in the natural world, humans rarely\nstruggle to perceive and reason with them. Will computer vision models trained\non natural images show the same sensitivity to Euclidean geometry? Here we\nexplore these questions by studying few-shot generalization in the universe of\nEuclidean geometry constructions. We introduce Geoclidean, a domain-specific\nlanguage for Euclidean geometry, and use it to generate two datasets of\ngeometric concept learning tasks for benchmarking generalization judgements of\nhumans and machines. We find that humans are indeed sensitive to Euclidean\ngeometry and generalize strongly from a few visual examples of a geometric\nconcept. In contrast, low-level and high-level visual features from standard\ncomputer vision models pretrained on natural images do not support correct\ngeneralization. Thus Geoclidean represents a novel few-shot generalization\nbenchmark for geometric concept learning, where the performance of humans and\nof AI models diverge. The Geoclidean framework and dataset are publicly\navailable for download.",
    "descriptor": "\nComments: To appear at NeurIPS 2022\n",
    "authors": [
      "Joy Hsu",
      "Jiajun Wu",
      "Noah D. Goodman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16663"
  },
  {
    "id": "arXiv:2211.16665",
    "title": "3D fictitious wave domain CSEM inversion by adjoint source estimation",
    "abstract": "Marine controlled-source electromagnetic (CSEM) method has proved its\npotential in detecting highly resistive hydrocarbon bearing formations. A novel\nfrequency domain CSEM inversion approach using fictitious wave domain time\nstepping modelling is presented. Using Lagrangian-based adjoint state method,\nthe inversion gradient with respect to resistivity can be computed by the\nproduct between the forward and adjoint fields. Simulation of the adjoint field\nusing the same modelling engine is challenging as it requires time domain\nadjoint source time functions while only a few discrete frequencies of the data\nresidual are available for the inversion. A regularized linear inverse problem\nis formulated in order to estimate a long time series from very few frequency\nsamples. It can then be solved using linear optimization technique, yielding a\nmatrix-free implementation. Instead of computing adjoint source time function\none by one at each receiver location, a basis function implementation has been\ndeveloped such that the inverse problem can be solved only once and reused\nevery time to construct all time-domain adjoint sources. The method allows\ncomputing all frequencies of the EM fields in one go without heavy memory and\ncomputational overhead, making efficient 3D CSEM inversion feasible. Numerical\nexamples are employed to demonstrate the application of our method.",
    "descriptor": "",
    "authors": [
      "Pengliang Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16665"
  },
  {
    "id": "arXiv:2211.16666",
    "title": "Secrecy Rate Maximization of RIS-assisted SWIPT Systems: A Two-Timescale  Beamforming Design Approach",
    "abstract": "Reconfigurable intelligent surfaces (RISs) achieve high passive beamforming\ngains for signal enhancement or interference nulling by dynamically adjusting\ntheir reflection coefficients. Their employment is particularly appealing for\nimproving both the wireless security and the efficiency of radio frequency\n(RF)-based wireless power transfer. Motivated by this, we conceive and\ninvestigate a RIS-assisted secure simultaneous wireless information and power\ntransfer (SWIPT) system designed for information and power transfer from a base\nstation (BS) to an information user (IU) and to multiple energy users (EUs),\nrespectively. Moreover, the EUs are also potential eavesdroppers that may\noverhear the communication between the BS and IU. We adopt two-timescale\ntransmission for reducing the signal processing complexity as well as channel\ntraining overhead, and aim for maximizing the average worst-case secrecy rate\nachieved by the IU. This is achieved by jointly optimizing the short-term\ntransmit beamforming vectors at the BS as well as the long-term phase shifts at\nthe RIS, under the energy harvesting constraints considered at the EUs and the\npower constraint at the BS. The stochastic optimization problem formulated is\nnon-convex with intricately coupled variables, and is non-smooth due to the\nexistence of multiple EUs/eavesdroppers. No standard optimization approach is\navailable for this challenging scenario. To tackle this challenge, we propose a\nsmooth approximation aided stochastic successive convex approximation (SA-SSCA)\nalgorithm. Furthermore, a low-complexity heuristic algorithm is proposed for\nreducing the computational complexity without unduly eroding the performance.\nSimulation results show the efficiency of the RIS in securing SWIPT systems.\nThe significant performance gains achieved by our proposed algorithms over the\nrelevant benchmark schemes are also demonstrated.",
    "descriptor": "\nComments: 16 pages, 12 figures, accepted for publication in IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Ming-Min Zhao",
      "Kaidi Xu",
      "Yunlong Cai",
      "Yong Niu",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.16666"
  },
  {
    "id": "arXiv:2211.16667",
    "title": "Dynamic Sparse Training via Balancing the Exploration-Exploitation  Trade-off",
    "abstract": "Over-parameterization of deep neural networks (DNNs) has shown high\nprediction accuracy for many applications. Although effective, the large number\nof parameters hinders its popularity on resource-limited devices and has an\noutsize environmental impact. Sparse training (using a fixed number of nonzero\nweights in each iteration) could significantly mitigate the training costs by\nreducing the model size. However, existing sparse training methods mainly use\neither random-based or greedy-based drop-and-grow strategies, resulting in\nlocal minimal and low accuracy. In this work, to assist explainable sparse\ntraining, we propose important weights Exploitation and coverage Exploration to\ncharacterize Dynamic Sparse Training (DST-EE), and provide quantitative\nanalysis of these two metrics. We further design an acquisition function and\nprovide the theoretical guarantees for the proposed method and clarify its\nconvergence property. Experimental results show that sparse models (up to 98\\%\nsparsity) obtained by our proposed method outperform the SOTA sparse training\nmethods on a wide variety of deep learning tasks. On VGG-19 / CIFAR-100,\nResNet-50 / CIFAR-10, ResNet-50 / CIFAR-100, our method has even higher\naccuracy than dense models. On ResNet-50 / ImageNet, the proposed method has up\nto 8.2\\% accuracy improvement compared to SOTA sparse training methods.",
    "descriptor": "",
    "authors": [
      "Shaoyi Huang",
      "Bowen Lei",
      "Dongkuan Xu",
      "Hongwu Peng",
      "Yue Sun",
      "Mimi Xie",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16667"
  },
  {
    "id": "arXiv:2211.16669",
    "title": "FedGPO: Heterogeneity-Aware Global Parameter Optimization for Efficient  Federated Learning",
    "abstract": "Federated learning (FL) has emerged as a solution to deal with the risk of\nprivacy leaks in machine learning training. This approach allows a variety of\nmobile devices to collaboratively train a machine learning model without\nsharing the raw on-device training data with the cloud. However, efficient edge\ndeployment of FL is challenging because of the system/data heterogeneity and\nruntime variance. This paper optimizes the energy-efficiency of FL use cases\nwhile guaranteeing model convergence, by accounting for the aforementioned\nchallenges. We propose FedGPO based on a reinforcement learning, which learns\nhow to identify optimal global parameters (B, E, K) for each FL aggregation\nround adapting to the system/data heterogeneity and stochastic runtime\nvariance. In our experiments, FedGPO improves the model convergence time by 2.4\ntimes, and achieves 3.6 times higher energy efficiency over the baseline\nsettings, respectively.",
    "descriptor": "\nComments: 12 pages, 12 figures, IEEE International Symposium on Workload Characterization (IISWC)\n",
    "authors": [
      "Young Geun Kim",
      "Carole-Jean Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.16669"
  },
  {
    "id": "arXiv:2211.16670",
    "title": "Regret Pruning for Learning Equilibria in Simulation-Based Games",
    "abstract": "In recent years, empirical game-theoretic analysis (EGTA) has emerged as a\npowerful tool for analyzing games in which an exact specification of the\nutilities is unavailable. Instead, EGTA assumes access to an oracle, i.e., a\nsimulator, which can generate unbiased noisy samples of players' unknown\nutilities, given a strategy profile. Utilities can thus be empirically\nestimated by repeatedly querying the simulator. Recently, various progressive\nsampling (PS) algorithms have been proposed, which aim to produce PAC-style\nlearning guarantees (e.g., approximate Nash equilibria with high probability)\nusing as few simulator queries as possible. One recent work introduces a\npruning technique called regret-pruning which further minimizes the number of\nsimulator queries placed in PS algorithms which aim to learn pure Nash\nequilibria. In this paper, we address a serious limitation of this original\nregret pruning approach -- it is only able to guarantee that true pure Nash\nequilibria of the empirical game are approximate equilibria of the true game,\nand is unable to provide any strong guarantees regarding the efficacy of\napproximate pure Nash equilibria. This is a significant limitation since in\nmany games, pure Nash equilibria are computationally intractable to find, or\neven non-existent. We introduce three novel regret pruning variations. The\nfirst two variations generalize the original regret pruning approach to yield\nguarantees for approximate pure Nash equilibria of the empirical game. The\nthird variation goes further to even yield strong guarantees for all\napproximate mixed Nash equilibria of the empirical game. We use these regret\npruning variations to design two novel progressive sampling algorithms, PS-REG+\nand PS-REG-M, which experimentally outperform the previous state-of-the-art\nalgorithms for learning pure and mixed equilibria, respectively, of\nsimulation-based games.",
    "descriptor": "",
    "authors": [
      "Bhaskar Mishra",
      "Cyrus Cousins",
      "Amy Greenwald"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.16670"
  },
  {
    "id": "arXiv:2211.16671",
    "title": "Domain Mismatch Doesn't Always Prevent Cross-Lingual Transfer Learning",
    "abstract": "Cross-lingual transfer learning without labeled target language data or\nparallel text has been surprisingly effective in zero-shot cross-lingual\nclassification, question answering, unsupervised machine translation, etc.\nHowever, some recent publications have claimed that domain mismatch prevents\ncross-lingual transfer, and their results show that unsupervised bilingual\nlexicon induction (UBLI) and unsupervised neural machine translation (UNMT) do\nnot work well when the underlying monolingual corpora come from different\ndomains (e.g., French text from Wikipedia but English text from UN\nproceedings). In this work, we show that a simple initialization regimen can\novercome much of the effect of domain mismatch in cross-lingual transfer. We\npre-train word and contextual embeddings on the concatenated domain-mismatched\ncorpora, and use these as initializations for three tasks: MUSE UBLI, UN\nParallel UNMT, and the SemEval 2017 cross-lingual word similarity task. In all\ncases, our results challenge the conclusions of prior work by showing that\nproper initialization can recover a large portion of the losses incurred by\ndomain mismatch.",
    "descriptor": "\nComments: 8 pages, 1 figure. Published/presented at LREC (2022)\n",
    "authors": [
      "Daniel Edmiston",
      "Phillip Keung",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16671"
  },
  {
    "id": "arXiv:2211.16673",
    "title": "High order asymptotic preserving well-balanced finite difference WENO  schemes for all Mach full Euler equations with gravity",
    "abstract": "In this paper, we propose a high order semi-implicit well-balanced finite\ndifference scheme for all Mach Euler equations with a gravitational source\nterm. To obtain the asymptotic preserving property, we start from the\nconservative form of full compressible Euler equations and add the evolution\nequation of the perturbation of potential temperature. The resulting system is\nthen split into a (non-stiff) nonlinear low dynamic material wave to be treated\nexplicitly, and (stiff) fast acoustic and gravity waves to be treated\nimplicitly. With the aid of explicit time evolution for the perturbation of\npotential temperature, we design a novel well-balanced finite difference WENO\nscheme for the conservative variables, which can be proven to be both\nasymptotic preserving and asymptotically accurate in the incompressible limit.\nExtensive numerical experiments were provided to validate these properties.",
    "descriptor": "",
    "authors": [
      "Guanlan Huang",
      "Yulong Xing",
      "Tao Xiong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16673"
  },
  {
    "id": "arXiv:2211.16675",
    "title": "ShaDocNet: Learning Spatial-Aware Tokens in Transformer for Document  Shadow Removal",
    "abstract": "Shadow removal improves the visual quality and legibility of digital copies\nof documents. However, document shadow removal remains an unresolved subject.\nTraditional techniques rely on heuristics that vary from situation to\nsituation. Given the quality and quantity of current public datasets, the\nmajority of neural network models are ill-equipped for this task. In this\npaper, we propose a Transformer-based model for document shadow removal that\nutilizes shadow context encoding and decoding in both shadow and shadow-free\nregions. Additionally, shadow detection and pixel-level enhancement are\nincluded in the whole coarse-to-fine process. On the basis of comprehensive\nbenchmark evaluations, it is competitive with state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Xuhang Chen",
      "Xiaodong Cun",
      "Chi-Man Pun",
      "Shuqiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16675"
  },
  {
    "id": "arXiv:2211.16676",
    "title": "Robust Learning of Nonlinear Dynamical Systems with Safety and Stability  Properties",
    "abstract": "The paper presents a robust parameter learning methodology for identification\nof nonlinear dynamical system from data while satisfying safety and stability\nconstraints in the context of learning from demonstration (LfD) methods.\nExtreme Learning Machines (ELM) is used to approximate the system model, whose\nparameters are learned subject to the safety and stability constraints obtained\nusing zeroing barrier and Lyapunov-based stability analysis in the presence of\nmodel uncertainties and external disturbances. A constrained Quadratic Program\n(QP) is developed, which accounts for the ELM function reconstruction error, to\nestimate the ELM parameters. Furthermore, a robustness lemma is presented,\nwhich proves that the learned system model guarantees safety and stability in\nthe presence of disturbances. The method is tested in simulations. Trajectory\nreconstruction accuracy of the method is compared against state-of-the-art LfD\nmethods using swept error area (SEA) metric. Robustness of the learned model is\ntested by conducting Monte Carlo tests. The proposed method is implemented on a\nBaxter robot for a pick-and-place task where the robot is constrained to an\nellipsoidal safety region.",
    "descriptor": "",
    "authors": [
      "Iman Salehi",
      "Ghananeel Rotithor",
      "Ashwin P. Dani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16676"
  },
  {
    "id": "arXiv:2211.16677",
    "title": "3D Neural Field Generation using Triplane Diffusion",
    "abstract": "Diffusion models have emerged as the state-of-the-art for image generation,\namong other tasks. Here, we present an efficient diffusion-based model for\n3D-aware generation of neural fields. Our approach pre-processes training data,\nsuch as ShapeNet meshes, by converting them to continuous occupancy fields and\nfactoring them into a set of axis-aligned triplane feature representations.\nThus, our 3D training scenes are all represented by 2D feature planes, and we\ncan directly train existing 2D diffusion models on these representations to\ngenerate 3D neural fields with high quality and diversity, outperforming\nalternative approaches to 3D-aware generation. Our approach requires essential\nmodifications to existing triplane factorization pipelines to make the\nresulting features easy to learn for the diffusion model. We demonstrate\nstate-of-the-art results on 3D generation on several object classes from\nShapeNet.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "J. Ryan Shue",
      "Eric Ryan Chan",
      "Ryan Po",
      "Zachary Ankner",
      "Jiajun Wu",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.16677"
  },
  {
    "id": "arXiv:2211.16678",
    "title": "FREDSR: Fourier Residual Efficient Diffusive GAN for Single Image Super  Resolution",
    "abstract": "FREDSR is a GAN variant that aims to outperform traditional GAN models in\nspecific tasks such as Single Image Super Resolution with extreme parameter\nefficiency at the cost of per-dataset generalizeability. FREDSR integrates fast\nFourier transformation, residual prediction, diffusive discriminators, etc to\nachieve strong performance in comparisons to other models on the UHDSR4K\ndataset for Single Image 3x Super Resolution from 360p and 720p with only 37000\nparameters. The model follows the characteristics of the given dataset,\nresulting in lower generalizeability but higher performance on tasks such as\nreal time up-scaling.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Kyoungwan Woo",
      "Achyuta Rajaram"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.16678"
  },
  {
    "id": "arXiv:2211.16682",
    "title": "Randomized block subsampling Kaczmarz-Motzkin method",
    "abstract": "By introducing a subsampling strategy, we propose a randomized block\nKaczmarz-Motzkin method for solving linear systems. Such strategy not only\ndetermines the block size, but also combines and extends two famous strategies,\ni.e., randomness and greed, and hence can inherit their advantages. Theoretical\nanalysis shows that the proposed method converges linearly in expectation to\nthe least-Euclidean-norm solution. Several numerical examples are reported to\nverify the efficiency and feasibility of the new method.",
    "descriptor": "",
    "authors": [
      "Yanjun Zhang",
      "Hanyu Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16682"
  },
  {
    "id": "arXiv:2211.16683",
    "title": "Subsampling for tensor least squares: Optimization and statistical  perspectives",
    "abstract": "In this paper, we investigate the random subsampling method for tensor least\nsquares problem with respect to the popular t-product. From the optimization\nperspective, we present the error bounds in the sense of probability for the\nresidual and solution obtained by the proposed method. From the statistical\nperspective, we derive the expressions of the conditional and unconditional\nexpectations and variances for the solution, where the unconditional ones\ncombine the model noises. Moreover, based on the unconditional variance, an\noptimal subsampling probability distribution is also found. Finally, the\nfeasibility and effectiveness of the proposed method and the correctness of the\ntheoretical results are verified by numerical experiments.",
    "descriptor": "",
    "authors": [
      "Ling Tang",
      "Hanyu Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16683"
  },
  {
    "id": "arXiv:2211.16687",
    "title": "Automatic Discovery of Multi-perspective Process Model using  Reinforcement Learning",
    "abstract": "Process mining is a methodology for the derivation and analysis of process\nmodels based on the event log. When process mining is employed to analyze\nbusiness processes, the process discovery step, the conformance checking step,\nand the enhancements step are repeated. If a user wants to analyze a process\nfrom multiple perspectives (such as activity perspectives, originator\nperspectives, and time perspectives), the above procedure, inconveniently, has\nto be repeated over and over again. Although past studies involving process\nmining have applied detailed stepwise methodologies, no attempt has been made\nto incorporate and optimize multi-perspective process mining procedures. This\npaper contributes to developing a solution approach to this problem. First, we\npropose an automatic discovery framework of a multi-perspective process model\nbased on deep Q-Learning. Our Dual Experience Replay with Experience\nDistribution (DERED) approach can automatically perform process model discovery\nsteps, conformance check steps, and enhancements steps. Second, we propose a\nnew method that further optimizes the experience replay (ER) method, one of the\nkey algorithms of deep Q-learning, to improve the learning performance of\nreinforcement learning agents. Finally, we validate our approach using six\nreal-world event datasets collected in port logistics, steel manufacturing,\nfinance, IT, and government administration. We show that our DERED approach can\nprovide users with multi-perspective, high-quality process models that can be\nemployed more conveniently for multi-perspective process mining.",
    "descriptor": "",
    "authors": [
      "Sunghyun Sim",
      "Ling Liu",
      "Hyerim Bae"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16687"
  },
  {
    "id": "arXiv:2211.16689",
    "title": "A Node-collaboration-informed Graph Convolutional Network for Precise  Representation to Undirected Weighted Graphs",
    "abstract": "An undirected weighted graph (UWG) is frequently adopted to describe the\ninteractions among a solo set of nodes from real applications, such as the user\ncontact frequency from a social network services system. A graph convolutional\nnetwork (GCN) is widely adopted to perform representation learning to a UWG for\nsubsequent pattern analysis tasks such as clustering or missing data\nestimation. However, existing GCNs mostly neglects the latent collaborative\ninformation hidden in its connected node pairs. To address this issue, this\nstudy proposes to model the node collaborations via a symmetric latent factor\nanalysis model, and then regards it as a node-collaboration module for\nsupplementing the collaboration loss in a GCN. Based on this idea, a\nNode-collaboration-informed Graph Convolutional Network (NGCN) is proposed with\nthree-fold ideas: a) Learning latent collaborative information from the\ninteraction of node pairs via a node-collaboration module; b) Building the\nresidual connection and weighted representation propagation to obtain high\nrepresentation capacity; and c) Implementing the model optimization in an\nend-to-end fashion to achieve precise representation to the target UWG.\nEmpirical studies on UWGs emerging from real applications demonstrate that\nowing to its efficient incorporation of node-collaborations, the proposed NGCN\nsignificantly outperforms state-of-the-art GCNs in addressing the task of\nmissing weight estimation. Meanwhile, its good scalability ensures its\ncompatibility with more advanced GCN extensions, which will be further\ninvestigated in our future studies.",
    "descriptor": "",
    "authors": [
      "Ying Wang",
      "Ye Yuan",
      "Xin Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.16689"
  },
  {
    "id": "arXiv:2211.16691",
    "title": "Efficient Reinforcement Learning (ERL): Targeted Exploration Through  Action Saturation",
    "abstract": "Reinforcement Learning (RL) generally suffers from poor sample complexity,\nmostly due to the need to exhaustively explore the state space to find good\npolicies. On the other hand, we postulate that expert knowledge of the system\nto control often allows us to design simple rules we expect good policies to\nfollow at all times. In this work, we hence propose a simple yet effective\nmodification of continuous actor-critic RL frameworks to incorporate such prior\nknowledge in the learned policies and constrain them to regions of the state\nspace that are deemed interesting, thereby significantly accelerating their\nconvergence. Concretely, we saturate the actions chosen by the agent if they do\nnot comply with our intuition and, critically, modify the gradient update step\nof the policy to ensure the learning process does not suffer from the\nsaturation step. On a room temperature control simulation case study, these\nmodifications allow agents to converge to well-performing policies up to one\norder of magnitude faster than classical RL agents while retaining good final\nperformance.",
    "descriptor": "\nComments: Submitted to L4DC 2023\n",
    "authors": [
      "Loris Di Natale",
      "Bratislav Svetozarevic",
      "Philipp Heer",
      "Colin N. Jones"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16691"
  },
  {
    "id": "arXiv:2211.16693",
    "title": "Visual-tactile Fusion for Transparent Object Grasping in Complex  Backgrounds",
    "abstract": "The accurate detection and grasping of transparent objects are challenging\nbut of significance to robots. Here, a visual-tactile fusion framework for\ntransparent object grasping under complex backgrounds and variant light\nconditions is proposed, including the grasping position detection, tactile\ncalibration, and visual-tactile fusion based classification. First, a\nmulti-scene synthetic grasping dataset generation method with a Gaussian\ndistribution based data annotation is proposed. Besides, a novel grasping\nnetwork named TGCNN is proposed for grasping position detection, showing good\nresults in both synthetic and real scenes. In tactile calibration, inspired by\nhuman grasping, a fully convolutional network based tactile feature extraction\nmethod and a central location based adaptive grasping strategy are designed,\nimproving the success rate by 36.7% compared to direct grasping. Furthermore, a\nvisual-tactile fusion method is proposed for transparent objects\nclassification, which improves the classification accuracy by 34%. The proposed\nframework synergizes the advantages of vision and touch, and greatly improves\nthe grasping efficiency of transparent objects.",
    "descriptor": "",
    "authors": [
      "Shoujie Li",
      "Haixin Yu",
      "Wenbo Ding",
      "Houde Liu",
      "Linqi Ye",
      "Chongkun Xia",
      "Xueqian Wang",
      "Xiao-Ping Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16693"
  },
  {
    "id": "arXiv:2211.16695",
    "title": "A fully asymptotic preserving decomposed multi-group method for the  frequency-dependent radiative transfer equations",
    "abstract": "The opacity of FRTE depends on not only the material temperature but also the\nfrequency, whose values may vary several orders of magnitude for different\nfrequencies. The gray radiation diffusion and frequency-dependent diffusion\nequations are two simplified models that can approximate the solution to FRTE\nin the thick opacity regime. The frequency discretization for the two limit\nmodels highly affects the numerical accuracy. However, classical frequency\ndiscretization for FRTE considers only the absorbing coefficient. In this\npaper, we propose a new decomposed multi-group method for frequency\ndiscretization that is not only AP in both gray radiation diffusion and\nfrequency-dependent diffusion limits, but also the frequency discretization of\nthe limiting models can be tuned. Based on the decomposed multi-group method, a\nfull AP scheme in frequency, time, and space is proposed. Several numerical\nexamples are used to verify the performance of the proposed scheme.",
    "descriptor": "\nComments: 36 pages, 14 figures\n",
    "authors": [
      "Xiaojiang Zhang",
      "Peng Song",
      "Yi Shi",
      "Min Tang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16695"
  },
  {
    "id": "arXiv:2211.16697",
    "title": "SGDraw: Scene Graph Drawing Interface Using Object-Oriented  Representation",
    "abstract": "Scene understanding is an essential and challenging task in computer vision.\nTo provide the visually fundamental graphical structure of an image, the scene\ngraph has received increased attention due to its powerful semantic\nrepresentation. However, it is difficult to draw a proper scene graph for image\nretrieval, image generation, and multi-modal applications. The conventional\nscene graph annotation interface is not easy to use in image annotations, and\nthe automatic scene graph generation approaches using deep neural networks are\nprone to generate redundant content while disregarding details. In this work,\nwe propose SGDraw, a scene graph drawing interface using object-oriented scene\ngraph representation to help users draw and edit scene graphs interactively.\nFor the proposed object-oriented representation, we consider the objects,\nattributes, and relationships of objects as a structural unit. SGDraw provides\na web-based scene graph annotation and generation tool for scene understanding\napplications. To verify the effectiveness of the proposed interface, we\nconducted a comparison study with the conventional tool and the user experience\nstudy. The results show that SGDraw can help generate scene graphs with richer\ndetails and describe the images more accurately than traditional bounding box\nannotations. We believe the proposed SGDraw can be useful in various vision\ntasks, such as image retrieval and generation.",
    "descriptor": "\nComments: 9 pages, 10 figures, video is this https URL\n",
    "authors": [
      "Tianyu Zhang",
      "Xusheng Du",
      "Chia-Ming Chang",
      "Xi Yang",
      "Haoran Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.16697"
  },
  {
    "id": "arXiv:2211.16699",
    "title": "Interpretability and accessibility of machine learning in selected food  processing, agriculture and health applications",
    "abstract": "Artificial Intelligence (AI) and its data-centric branch of machine learning\n(ML) have greatly evolved over the last few decades. However, as AI is used\nincreasingly in real world use cases, the importance of the interpretability of\nand accessibility to AI systems have become major research areas. The lack of\ninterpretability of ML based systems is a major hindrance to widespread\nadoption of these powerful algorithms. This is due to many reasons including\nethical and regulatory concerns, which have resulted in poorer adoption of ML\nin some areas. The recent past has seen a surge in research on interpretable\nML. Generally, designing a ML system requires good domain understanding\ncombined with expert knowledge. New techniques are emerging to improve ML\naccessibility through automated model design. This paper provides a review of\nthe work done to improve interpretability and accessibility of machine learning\nin the context of global problems while also being relevant to developing\ncountries. We review work under multiple levels of interpretability including\nscientific and mathematical interpretation, statistical interpretation and\npartial semantic interpretation. This review includes applications in three\nareas, namely food processing, agriculture and health.",
    "descriptor": "\nComments: published in the \"Journal of the National Science Foundation of Sri Lanka, Volume 50\"\n",
    "authors": [
      "N. Ranasinghe",
      "A. Ramanan",
      "S. Fernando",
      "P. N. Hameed",
      "D. Herath",
      "T. Malepathirana",
      "P. Suganthan",
      "M. Niranjan",
      "S. Halgamuge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16699"
  },
  {
    "id": "arXiv:2211.16701",
    "title": "Conservative-Progressive Collaborative Learning for Semi-supervised  Semantic Segmentation",
    "abstract": "Pseudo supervision is regarded as the core idea in semi-supervised learning\nfor semantic segmentation, and there is always a tradeoff between utilizing\nonly the high-quality pseudo labels and leveraging all the pseudo labels.\nAddressing that, we propose a novel learning approach, called\nConservative-Progressive Collaborative Learning (CPCL), among which two\npredictive networks are trained in parallel, and the pseudo supervision is\nimplemented based on both the agreement and disagreement of the two\npredictions. One network seeks common ground via intersection supervision and\nis supervised by the high-quality labels to ensure a more reliable supervision,\nwhile the other network reserves differences via union supervision and is\nsupervised by all the pseudo labels to keep exploring with curiosity. Thus, the\ncollaboration of conservative evolution and progressive exploration can be\nachieved. To reduce the influences of the suspicious pseudo labels, the loss is\ndynamic re-weighted according to the prediction confidence. Extensive\nexperiments demonstrate that CPCL achieves state-of-the-art performance for\nsemi-supervised semantic segmentation.",
    "descriptor": "",
    "authors": [
      "Siqi Fan",
      "Fenghua Zhu",
      "Zunlei Feng",
      "Yisheng Lv",
      "Mingli Song",
      "Fei-Yue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16701"
  },
  {
    "id": "arXiv:2211.16702",
    "title": "I Will Survive: An Online Conformance Checking Algorithm Using Decay  Time",
    "abstract": "Process executions in organizations generate a large variety of data. Process\nmining is a data-driven analytical approach for analyzing this data from a\nbusiness process point of view. Online conformance checking deals with finding\ndiscrepancies between real-life and modeled process behavior on data streams.\nThe current state-of-the-art output of online conformance checking is a\nprefix-alignment, which is used for pinpointing the exact deviations in terms\nof the trace and the model while accommodating a trace's unknown termination in\na streaming setting. However, producing prefix-alignments entails a state space\nsearch to find the shortest path from a common start state to a common end\nstate between the trace and the model. This is computationally expensive and\nmakes the method infeasible in an online setting. Previously, the trie data\nstructure has been shown to be efficient for constructing alignments, utilizing\na proxy log representing the process model in a finite way. This paper\nintroduces a new approximate algorithm (IWS) on top of the trie for online\nconformance checking. The algorithm is shown to be fast, memory-efficient, and\nable to output both a prefix and a complete alignment event-by-event while\nkeeping track of previously seen cases and their state. Comparative analysis\nagainst the current state-of-the-art algorithm for finding prefix-alignments\nshows that the IWS algorithm achieves, in some cases, an order of magnitude\nfaster execution time while having a smaller error cost. In extreme cases, the\nIWS finds prefix-alignments roughly three orders of magnitude faster than the\ncurrent state of the art. The IWS algorithm includes a discounted decay time\nsetting for efficient memory usage and a look-ahead limit for improving\ncomputation time. Finally, the algorithm is stress tested for performance using\na simulation of high-traffic event streams.",
    "descriptor": "",
    "authors": [
      "Kristo Raun",
      "Ahmed Awad"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.16702"
  },
  {
    "id": "arXiv:2211.16703",
    "title": "An Efficient Split Fine-tuning Framework for Edge and Cloud  Collaborative Learning",
    "abstract": "To enable the pre-trained models to be fine-tuned with local data on edge\ndevices without sharing data with the cloud, we design an efficient split\nfine-tuning (SFT) framework for edge and cloud collaborative learning. We\npropose three novel techniques in this framework. First, we propose a matrix\ndecomposition-based method to compress the intermediate output of a neural\nnetwork to reduce the communication volume between the edge device and the\ncloud server. Second, we eliminate particular links in the model without\naffecting the convergence performance in fine-tuning. Third, we implement our\nsystem atop PyTorch to allow users to easily extend their existing training\nscripts to enjoy the efficient edge and cloud collaborative learning.\nExperiments results on 9 NLP datasets show that our framework can reduce the\ncommunication traffic by 96 times with little impact on the model accuracy.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Shaohuai Shi",
      "Qing Yang",
      "Yang Xiang",
      "Shuhan Qi",
      "Xuan Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16703"
  },
  {
    "id": "arXiv:2211.16710",
    "title": "Extracting Semantic Knowledge from GANs with Unsupervised Learning",
    "abstract": "Recently, unsupervised learning has made impressive progress on various\ntasks. Despite the dominance of discriminative models, increasing attention is\ndrawn to representations learned by generative models and in particular,\nGenerative Adversarial Networks (GANs). Previous works on the interpretation of\nGANs reveal that GANs encode semantics in feature maps in a linearly separable\nform. In this work, we further find that GAN's features can be well clustered\nwith the linear separability assumption. We propose a novel clustering\nalgorithm, named KLiSH, which leverages the linear separability to cluster\nGAN's features. KLiSH succeeds in extracting fine-grained semantics of GANs\ntrained on datasets of various objects, e.g., car, portrait, animals, and so\non. With KLiSH, we can sample images from GANs along with their segmentation\nmasks and synthesize paired image-segmentation datasets. Using the synthesized\ndatasets, we enable two downstream applications. First, we train semantic\nsegmentation networks on these datasets and test them on real images, realizing\nunsupervised semantic segmentation. Second, we train image-to-image translation\nnetworks on the synthesized datasets, enabling semantic-conditional image\nsynthesis without human annotations.",
    "descriptor": "",
    "authors": [
      "Jianjin Xu",
      "Zhaoxiang Zhang",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16710"
  },
  {
    "id": "arXiv:2211.16712",
    "title": "Coordinating Cross-modal Distillation for Molecular Property Prediction",
    "abstract": "In recent years, molecular graph representation learning (GRL) has drawn much\nmore attention in molecular property prediction (MPP) problems. The existing\ngraph methods have demonstrated that 3D geometric information is significant\nfor better performance in MPP. However, accurate 3D structures are often costly\nand time-consuming to obtain, limiting the large-scale application of GRL. It\nis an intuitive solution to train with 3D to 2D knowledge distillation and\npredict with only 2D inputs. But some challenging problems remain open for 3D\nto 2D distillation. One is that the 3D view is quite distinct from the 2D view,\nand the other is that the gradient magnitudes of atoms in distillation are\ndiscrepant and unstable due to the variable molecular size. To address these\nchallenging problems, we exclusively propose a distillation framework that\ncontains global molecular distillation and local atom distillation. We also\nprovide a theoretical insight to justify how to coordinate atom and molecular\ninformation, which tackles the drawback of variable molecular size for atom\ninformation distillation. Experimental results on two popular molecular\ndatasets demonstrate that our proposed model achieves superior performance over\nother methods. Specifically, on the largest MPP dataset PCQM4Mv2 served as an\n\"ImageNet Large Scale Visual Recognition Challenge\" in the field of graph ML,\nthe proposed method achieved a 6.9% improvement compared with the best works.\nAnd we obtained fourth place with the MAE of 0.0734 on the test-challenge set\nfor OGB-LSC 2022 Graph Regression Task. We will release the code soon.",
    "descriptor": "",
    "authors": [
      "Hao Zhang",
      "Nan Zhang",
      "Ruixin Zhang",
      "Lei Shen",
      "Yingyi Zhang",
      "Meng Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.16712"
  },
  {
    "id": "arXiv:2211.16715",
    "title": "Policy Optimization over General State and Action Spaces",
    "abstract": "Reinforcement learning (RL) problems over general state and action spaces are\nnotoriously challenging. In contrast to the tableau setting, one can not\nenumerate all the states and then iteratively update the policies for each\nstate. This prevents the application of many well-studied RL methods especially\nthose with provable convergence guarantees. In this paper, we first present a\nsubstantial generalization of the recently developed policy mirror descent\nmethod to deal with general state and action spaces. We introduce new\napproaches to incorporate function approximation into this method, so that we\ndo not need to use explicit policy parameterization at all. Moreover, we\npresent a novel policy dual averaging method for which possibly simpler\nfunction approximation techniques can be applied. We establish linear\nconvergence rate to global optimality or sublinear convergence to stationarity\nfor these methods applied to solve different classes of RL problems under exact\npolicy evaluation. We then define proper notions of the approximation errors\nfor policy evaluation and investigate their impact on the convergence of these\nmethods applied to general-state RL problems with either finite-action or\ncontinuous-action spaces. To the best of our knowledge, the development of\nthese algorithmic frameworks as well as their convergence analysis appear to be\nnew in the literature.",
    "descriptor": "",
    "authors": [
      "Guanghui Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.16715"
  },
  {
    "id": "arXiv:2211.16716",
    "title": "Automated Generating Natural Language Requirements based on Domain  Ontology",
    "abstract": "Software requirements specification is undoubtedly critical for the whole\nsoftware life-cycle. Nowadays, writing software requirements specifications\nprimarily depends on human work. Although massive studies have been proposed to\nfasten the process via proposing advanced elicitation and analysis techniques,\nit is still a time-consuming and error-prone task that needs to take domain\nknowledge and business information into consideration. In this paper, we\npropose an approach, named ReqGen, which can provide recommendations by\nautomatically generating natural language requirements specifications based on\ncertain given keywords. Specifically, ReqGen consists of three critical steps.\nFirst, keywords-oriented knowledge is selected from domain ontology and is\ninjected to the basic Unified pre-trained Language Model (UniLM) for domain\nfine-tuning. Second, a copy mechanism is integrated to ensure the occurrence of\nkeywords in the generated statements. Finally, a requirement syntax constrained\ndecoding is designed to close the semantic and syntax distance between the\ncandidate and reference specifications. Experiments on two public datasets from\ndifferent groups and domains show that ReqGen outperforms six popular natural\nlanguage generation approaches with respect to the hard constraint of\nkeywords(phrases) inclusion, BLEU, ROUGE and syntax compliance. We believe that\nReqGen can promote the efficiency and intelligence of specifying software\nrequirements.",
    "descriptor": "",
    "authors": [
      "Ziyan Zhao",
      "Li Zhang",
      "Xiaoyun Gao",
      "Xiaoli Lian",
      "Heyang Lv",
      "Lin Shi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.16716"
  },
  {
    "id": "arXiv:2211.16717",
    "title": "Findings of the WMT 2022 Shared Task on Translation Suggestion",
    "abstract": "We report the result of the first edition of the WMT shared task on\nTranslation Suggestion (TS). The task aims to provide alternatives for specific\nwords or phrases given the entire documents generated by machine translation\n(MT). It consists two sub-tasks, namely, the naive translation suggestion and\ntranslation suggestion with hints. The main difference is that some hints are\nprovided in sub-task two, therefore, it is easier for the model to generate\nmore accurate suggestions. For sub-task one, we provide the corpus for the\nlanguage pairs English-German and English-Chinese. And only English-Chinese\ncorpus is provided for the sub-task two.\nWe received 92 submissions from 5 participating teams in sub-task one and 6\nsubmissions for the sub-task 2, most of them covering all of the translation\ndirections. We used the automatic metric BLEU for evaluating the performance of\neach submission.",
    "descriptor": "\nComments: 8 pages, EMNLP2022, WMT2022, Translatio Suggestion Shared Task\n",
    "authors": [
      "Zhen Yang",
      "Fandong Meng",
      "Yingxue Zhang",
      "Ernan Li",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16717"
  },
  {
    "id": "arXiv:2211.16718",
    "title": "GPU-Accelerated WENO Schemes for DNS of Compressible Turbulent Flows",
    "abstract": "This paper explores strategies to transform an existing CPU-based\nhigh-performance computational fluid dynamics (CFD) solver, HyPar, for\ncompressible flow simulations on emerging exascale heterogeneous, CPU+GPU,\ncomputing platforms. The scientific motivation for developing a GPU enhanced\nversion of HyPar is to simulate canonical flows, such as homogeneous isotropic\nturbulence (HIT) of compressible flow in a triply periodic box. We show that\noptimizing memory operations and thread blocks results in a code that is more\nthan 200x faster on GPUs than on CPUs. Using multiple GPUs and MPI\ncommunication, we demonstrate both strong and weak scaling of our GPU-based\nHyPar implementation on the Summit supercomputer at Oak Ridge National\nLaboratory.",
    "descriptor": "",
    "authors": [
      "Youngdae Kim",
      "Debojyoti Ghosh",
      "Emil M. Constantinescu",
      "Ramesh Balakrishnan"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.16718"
  },
  {
    "id": "arXiv:2211.16720",
    "title": "Quadratic Programming for Continuous Control of Safety-Critical  Multi-Agent Systems Under Uncertainty",
    "abstract": "This paper studies the control problem for safety-critical multi-agent\nsystems based on quadratic programming (QP). Each controlled agent is modeled\nas a cascade connection of an integrator and an uncertain nonlinear actuation\nsystem. In particular, the integrator represents the position-velocity\nrelation, and the actuation system describes the dynamic response of the actual\nvelocity to the velocity reference signal. The notion of input-to-output\nstability (IOS) is employed to characterize the essential velocity-tracking\ncapability of the actuation system. The uncertain actuation dynamics may cause\ninfeasibility or discontinuous solutions of QP algorithms for collision\navoidance. Also, the interaction between the controlled integrator and the\nuncertain actuation dynamics may lead to significant robustness issues. By\nusing nonlinear control methods and numerical optimization methods, this paper\nfirst contributes a new feasible-set reshaping technique and a refined QP\nalgorithm for feasibility, robustness, and local Lipschitz continuity. Then, we\npresent a nonlinear small-gain analysis to handle the inherent interaction for\nguaranteed safety of the closed-loop multi-agent system. The proposed methods\nare illustrated by numerical simulations and a physical experiment.",
    "descriptor": "",
    "authors": [
      "Si Wu",
      "Tengfei Liu",
      "Magnus Egerstedt",
      "Zhong-Ping Jiang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16720"
  },
  {
    "id": "arXiv:2211.16721",
    "title": "Dynamically Finding Optimal Observer States to Minimize Localization  Error with Complex State-Dependent Noise",
    "abstract": "We present DyFOS, an active perception method that Dynamically Finds Optimal\nStates to minimize localization error while avoiding obstacles and occlusions.\nWe consider the scenario where a ground target without any exteroceptive\nsensors must rely on an aerial observer for pose and uncertainty estimates to\nlocalize itself along an obstacle-filled path. The observer uses a\ndownward-facing camera to estimate the target's pose and uncertainty. However,\nthe pose uncertainty is a function of the states of the observer, target, and\nsurrounding environment. To find an optimal state that minimizes the target's\nlocalization uncertainty, DyFOS uses a localization error prediction pipeline\nin an optimization search. Given the states mentioned above, the pipeline\npredicts the target's localization uncertainty with the help of a trained,\ncomplex state-dependent sensor measurement model (which is a probabilistic\nneural network in our case). Our pipeline also predicts target occlusion and\nobstacle collision to remove undesirable observer states. The output of the\noptimization search is an optimal observer state that minimizes target\nlocalization uncertainty while avoiding occlusion and collision. We evaluate\nthe proposed method using numerical and simulated (Gazebo) experiments. Our\nresults show that DyFOS is almost 100x faster than yet as good as brute force.\nFurthermore, DyFOS yielded lower localization errors than random and heuristic\nsearches.",
    "descriptor": "\nComments: 7 pages, 7 figures, Submitted to IEEE ICRA 2023\n",
    "authors": [
      "Troi Williams",
      "Po-Lun Chen",
      "Sparsh Bhogavilli",
      "Vaibhav Sanjay",
      "Pratap Tokekar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16721"
  },
  {
    "id": "arXiv:2211.16726",
    "title": "Boosted Dynamic Neural Networks",
    "abstract": "Early-exiting dynamic neural networks (EDNN), as one type of dynamic neural\nnetworks, has been widely studied recently. A typical EDNN has multiple\nprediction heads at different layers of the network backbone. During inference,\nthe model will exit at either the last prediction head or an intermediate\nprediction head where the prediction confidence is higher than a predefined\nthreshold. To optimize the model, these prediction heads together with the\nnetwork backbone are trained on every batch of training data. This brings a\ntrain-test mismatch problem that all the prediction heads are optimized on all\ntypes of data in training phase while the deeper heads will only see difficult\ninputs in testing phase. Treating training and testing inputs differently at\nthe two phases will cause the mismatch between training and testing data\ndistributions. To mitigate this problem, we formulate an EDNN as an additive\nmodel inspired by gradient boosting, and propose multiple training techniques\nto optimize the model effectively. We name our method BoostNet. Our experiments\nshow it achieves the state-of-the-art performance on CIFAR100 and ImageNet\ndatasets in both anytime and budgeted-batch prediction modes. Our code is\nreleased at https://github.com/SHI-Labs/Boosted-Dynamic-Networks.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Haichao Yu",
      "Haoxiang Li",
      "Gang Hua",
      "Gao Huang",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16726"
  },
  {
    "id": "arXiv:2211.16731",
    "title": "Towards Training GNNs using Explanation Directed Message Passing",
    "abstract": "With the increasing use of Graph Neural Networks (GNNs) in critical\nreal-world applications, several post hoc explanation methods have been\nproposed to understand their predictions. However, there has been no work in\ngenerating explanations on the fly during model training and utilizing them to\nimprove the expressive power of the underlying GNN models. In this work, we\nintroduce a novel explanation-directed neural message passing framework for\nGNNs, EXPASS (EXplainable message PASSing), which aggregates only embeddings\nfrom nodes and edges identified as important by a GNN explanation method.\nEXPASS can be used with any existing GNN architecture and subgraph-optimizing\nexplainer to learn accurate graph embeddings. We theoretically show that EXPASS\nalleviates the oversmoothing problem in GNNs by slowing the layer wise loss of\nDirichlet energy and that the embedding difference between the vanilla message\npassing and EXPASS framework can be upper bounded by the difference of their\nrespective model weights. Our empirical results show that graph embeddings\nlearned using EXPASS improve the predictive performance and alleviate the\noversmoothing problems of GNNs, opening up new frontiers in graph machine\nlearning to develop explanation-based training frameworks.",
    "descriptor": "\nComments: Accepted to the proceedings of the First Learning on Graphs Conference (LoG 2022)\n",
    "authors": [
      "Valentina Giunchiglia",
      "Chirag Varun Shukla",
      "Guadalupe Gonzalez",
      "Chirag Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16731"
  },
  {
    "id": "arXiv:2211.16735",
    "title": "Unsafe at Any Copy: Name Collisions from Mixing Case Sensitivities",
    "abstract": "File name confusion attacks, such as malicious symbolic links and file\nsquatting, have long been studied as sources of security vulnerabilities.\nHowever, a recently emerged type, i.e., case-sensitivity-induced name\ncollisions, has not been scrutinized. These collisions are introduced by\ndifferences in name resolution under case-sensitive and case-insensitive file\nsystems or directories. A prominent example is the recent Git vulnerability\n(CVE-2021-21300) which can lead to code execution on a victim client when it\nclones a maliciously crafted repository onto a case-insensitive file system.\nWith trends including ext4 adding support for per-directory case-insensitivity\nand the broad deployment of the Windows Subsystem for Linux, the prerequisites\nfor such vulnerabilities are increasingly likely to exist even in a single\nsystem.\nIn this paper, we make a first effort to investigate how and where the lack\nof any uniform approach to handling name collisions leads to a diffusion of\nresponsibility and resultant vulnerabilities. Interestingly, we demonstrate the\nexistence of a range of novel security challenges arising from name collisions\nand their inconsistent handling by low-level utilities and applications.\nSpecifically, our experiments show that utilities handle many name collision\nscenarios unsafely, leaving the responsibility to applications whose developers\nare unfortunately not yet aware of the threats. We examine three case studies\nas a first step towards systematically understanding the emerging type of name\ncollision vulnerability.",
    "descriptor": "\nComments: 15 pages, 1 appendix, 2 tables, 12 figures\n",
    "authors": [
      "Aditya Basu",
      "John Sampson",
      "Zhiyun Qian",
      "Trent Jaeger"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2211.16735"
  },
  {
    "id": "arXiv:2211.16736",
    "title": "Understanding transit ridership in an equity context through a  comparison of statistical and machine learning algorithms",
    "abstract": "Building an accurate model of travel behaviour based on individuals'\ncharacteristics and built environment attributes is of importance for\npolicy-making and transportation planning. Recent experiments with big data and\nMachine Learning (ML) algorithms toward a better travel behaviour analysis have\nmainly overlooked socially disadvantaged groups. Accordingly, in this study, we\nexplore the travel behaviour responses of low-income individuals to transit\ninvestments in the Greater Toronto and Hamilton Area, Canada, using statistical\nand ML models. We first investigate how the model choice affects the prediction\nof transit use by the low-income group. This step includes comparing the\npredictive performance of traditional and ML algorithms and then evaluating a\ntransit investment policy by contrasting the predicted activities and the\nspatial distribution of transit trips generated by vulnerable households after\nimproving accessibility. We also empirically investigate the proposed transit\ninvestment by each algorithm and compare it with the city of Brampton's future\ntransportation plan. While, unsurprisingly, the ML algorithms outperform\nclassical models, there are still doubts about using them due to\ninterpretability concerns. Hence, we adopt recent local and global\nmodel-agnostic interpretation tools to interpret how the model arrives at its\npredictions. Our findings reveal the great potential of ML algorithms for\nenhanced travel behaviour predictions for low-income strata without\nconsiderably sacrificing interpretability.",
    "descriptor": "\nComments: This is the preprint of the accepted paper in the journal of Transport Geography. Please refer to its DOI\n",
    "authors": [
      "Elnaz Yousefzadeh Barri",
      "Steven Farber",
      "Hadi Jahanshahi",
      "Eda Beyazit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.16736"
  },
  {
    "id": "arXiv:2211.16738",
    "title": "Growing Instance Mask on Leaf",
    "abstract": "Contour-based instance segmentation methods include one-stage and multi-stage\nschemes. These approaches achieve remarkable performance. However, they have to\ndefine plenty of points to segment precise masks, which leads to high\ncomplexity. We follow this issue and present a single-shot method, called\n\\textbf{VeinMask}, for achieving competitive performance in low design\ncomplexity. Concretely, we observe that the leaf locates coarse margins via\nmajor veins and grows minor veins to refine twisty parts, which makes it\npossible to cover any objects accurately. Meanwhile, major and minor veins\nshare the same growth mode, which avoids modeling them separately and ensures\nmodel simplicity. Considering the superiorities above, we propose VeinMask to\nformulate the instance segmentation problem as the simulation of the vein\ngrowth process and to predict the major and minor veins in polar coordinates.\nBesides, centroidness is introduced for instance segmentation tasks to help\nsuppress low-quality instances. Furthermore, a surroundings cross-correlation\nsensitive (SCCS) module is designed to enhance the feature expression by\nutilizing the surroundings of each pixel. Additionally, a Residual IoU (R-IoU)\nloss is formulated to supervise the regression tasks of major and minor veins\neffectively. Experiments demonstrate that VeinMask performs much better than\nother contour-based methods in low design complexity. Particularly, our method\noutperforms existing one-stage contour-based methods on the COCO dataset with\nalmost half the design complexity.",
    "descriptor": "",
    "authors": [
      "Chuang Yang",
      "Haozhao Ma",
      "Qi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16738"
  },
  {
    "id": "arXiv:2211.16739",
    "title": "Quasi Non-Negative Quaternion Matrix Factorization with Application to  Color Face Recognition",
    "abstract": "To address the non-negativity dropout problem of quaternion models, a novel\nquasi non-negative quaternion matrix factorization (QNQMF) model is presented\nfor color image processing. To implement QNQMF, the quaternion projected\ngradient algorithm and the quaternion alternating direction method of\nmultipliers are proposed via formulating QNQMF as the non-convex constraint\nquaternion optimization problems. Some properties of the proposed algorithms\nare studied. The numerical experiments on the color image reconstruction show\nthat these algorithms encoded on the quaternion perform better than these\nalgorithms encoded on the red, green and blue channels. Furthermore, we apply\nthe proposed algorithms to the color face recognition. Numerical results\nindicate that the accuracy rate of face recognition on the quaternion model is\nbetter than on the red, green and blue channels of color image as well as\nsingle channel of gray level images for the same data, when large facial\nexpressions and shooting angle variations are presented.",
    "descriptor": "\nComments: 35 pages, 8 figures\n",
    "authors": [
      "Yifen Ke",
      "Changfeng Ma",
      "Zhigang Jia",
      "Yajun Xie",
      "Riwei Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.16739"
  },
  {
    "id": "arXiv:2211.16740",
    "title": "Explicit Knowledge Transfer for Weakly-Supervised Code Generation",
    "abstract": "Large language models (LLMs) can acquire strong code-generation capabilities\nthrough few-shot learning. In contrast, supervised fine-tuning is still needed\nfor smaller models to achieve good performance. Such fine-tuning demands a\nlarge number of task-specific NL-code pairs, which are expensive to obtain. In\nthis paper, we attempt to transfer the code generation ability of an LLM to a\nsmaller model with the aid of weakly-supervised data. More specifically, we\npropose explicit knowledge transfer (EKT), which uses the few-shot capabilities\nof a teacher LLM to create NL-code pairs that we then filter for correctness\nand fine-tune the student on. We evaluate EKT on the task of generating code\nsolutions to math word problems from the GSM8k dataset. We find that EKT not\nonly yields better performance than training with expert iteration, but also\noutperforms knowledge distillation, another form of knowledge transfer. A\nGPT-Neo 1.3B model trained using EKT with a GPT-J teacher achieves a 12.4%\npass@100 on GSM8k, while the same student and teacher trained with knowledge\ndistillation yield only a 3.7% pass@100. We also show that it is possible for a\nstudent model to outperform the teacher using EKT.",
    "descriptor": "",
    "authors": [
      "Zhangir Azerbayev",
      "Ansong Ni",
      "Hailey Schoelkopf",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16740"
  },
  {
    "id": "arXiv:2211.16746",
    "title": "ClaRet -- A CNN Architecture for Optical Coherence Tomography",
    "abstract": "Optical Coherence Tomography is a technique used to scan the Retina of the\neye and check for tears. In this paper, we develop a Convolutional Neural\nNetwork Architecture for OCT scan classification. The model is trained to\ndetect Retinal tears from an OCT scan and classify the type of tear. We\ndesigned a block-based approach to accompany a pre-trained VGG-19 using\nTransfer Learning by writing customised layers in blocks for better feature\nextraction. The approach achieved substantially better results than the\nbaseline we initially started out with.",
    "descriptor": "\nComments: Denotes equal contribution\n",
    "authors": [
      "Adit Magotra",
      "Aagat Gedam",
      "Tanush Savadi",
      "Emily Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16746"
  },
  {
    "id": "arXiv:2211.16747",
    "title": "Approximate minimum cuts and their enumeration",
    "abstract": "We show that every $\\alpha$-approximate minimum cut in a connected graph is\nthe unique minimum $(S,T)$-terminal cut for some subsets $S$ and $T$ of\nvertices each of size at most $\\lfloor2\\alpha\\rfloor+1$. This leads to an\nalternative proof that the number of $\\alpha$-approximate minimum cuts in a\n$n$-vertex connected graph is $n^{O(\\alpha)}$ and they can all be enumerated in\ndeterministic polynomial time for constant $\\alpha$.",
    "descriptor": "\nComments: Accepted to SOSA'23\n",
    "authors": [
      "Calvin Beideman",
      "Karthekeyan Chandrasekaran",
      "Weihang Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.16747"
  },
  {
    "id": "arXiv:2211.16749",
    "title": "HEAT: Hardware-Efficient Automatic Tensor Decomposition for Transformer  Compression",
    "abstract": "Transformers have attained superior performance in natural language\nprocessing and computer vision. Their self-attention and feedforward layers are\noverparameterized, limiting inference speed and energy efficiency. Tensor\ndecomposition is a promising technique to reduce parameter redundancy by\nleveraging tensor algebraic properties to express the parameters in a\nfactorized form. Prior efforts used manual or heuristic factorization settings\nwithout hardware-aware customization, resulting in poor hardware efficiencies\nand large performance degradation.\nIn this work, we propose a hardware-aware tensor decomposition framework,\ndubbed HEAT, that enables efficient exploration of the exponential space of\npossible decompositions and automates the choice of tensorization shape and\ndecomposition rank with hardware-aware co-optimization. We jointly investigate\ntensor contraction path optimizations and a fused Einsum mapping strategy to\nbridge the gap between theoretical benefits and real hardware efficiency\nimprovement. Our two-stage knowledge distillation flow resolves the\ntrainability bottleneck and thus significantly boosts the final accuracy of\nfactorized Transformers. Overall, we experimentally show that our\nhardware-aware factorized BERT variants reduce the energy-delay product by 5.7x\nwith less than 1.1% accuracy loss and achieve a better efficiency-accuracy\nPareto frontier than hand-tuned and heuristic baselines.",
    "descriptor": "\nComments: 9 pages. Accepted to NeurIPS ML for System Workshop 2022 (Spotlight)\n",
    "authors": [
      "Jiaqi Gu",
      "Ben Keller",
      "Jean Kossaifi",
      "Anima Anandkumar",
      "Brucek Khailany",
      "David Z. Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.16749"
  },
  {
    "id": "arXiv:2211.16750",
    "title": "Score-based Continuous-time Discrete Diffusion Models",
    "abstract": "Score-based modeling through stochastic differential equations (SDEs) has\nprovided a new perspective on diffusion models, and demonstrated superior\nperformance on continuous data. However, the gradient of the log-likelihood\nfunction, i.e., the score function, is not properly defined for discrete\nspaces. This makes it non-trivial to adapt \\textcolor{\\cdiff}{the score-based\nmodeling} to categorical data. In this paper, we extend diffusion models to\ndiscrete variables by introducing a stochastic jump process where the reverse\nprocess denoises via a continuous-time Markov chain. This formulation admits an\nanalytical simulation during backward sampling. To learn the reverse process,\nwe extend score matching to general categorical data and show that an unbiased\nestimator can be obtained via simple matching of the conditional marginal\ndistributions. We demonstrate the effectiveness of the proposed method on a set\nof synthetic and real-world music and image benchmarks.",
    "descriptor": "",
    "authors": [
      "Haoran Sun",
      "Lijun Yu",
      "Bo Dai",
      "Dale Schuurmans",
      "Hanjun Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16750"
  },
  {
    "id": "arXiv:2211.16751",
    "title": "DiProber: Using Dual Probing to Estimate Tor Relay Capacities in  Underloaded Networks",
    "abstract": "Tor is the most popular anonymous communication network. It has millions of\ndaily users seeking privacy while browsing the internet. It has thousands of\nrelays to route and anonymize the source and destinations of the users packets.\nTo create a path, Tor authorities generate a probability distribution over\nrelays based on the estimates of the capacities of the relays. An incoming user\nwill then sample this probability distribution and choose three relays for\ntheir paths. The estimates are based on the bandwidths of observation probes\nthe authority assigns to each relay in the network. Thus, in order to achieve\nbetter load balancing between users, accurate estimates are necessary.\nUnfortunately, the currently implemented estimation algorithm generate\ninaccurate estimates causing the network to be under utilized and its\ncapacities unfairly distributed between the users paths. We propose DiProber, a\nnew relay capacity estimation algorithm. The algorithm proposes a new\nmeasurement scheme in Tor consisting of two probes per relay and uses maximum\nlikelihood to estimate their capacities. We show that the new technique works\nbetter in the case of under-utilized networks where users tend to have very low\ndemand on the Tor network.",
    "descriptor": "",
    "authors": [
      "Hussein Darir",
      "Nikita Borisov",
      "Geir Dullerud"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.16751"
  },
  {
    "id": "arXiv:2211.16752",
    "title": "DimenFix: A novel meta-dimensionality reduction method for feature  preservation",
    "abstract": "Dimensionality reduction has become an important research topic as demand for\ninterpreting high-dimensional datasets has been increasing rapidly in recent\nyears. There have been many dimensionality reduction methods with good\nperformance in preserving the overall relationship among data points when\nmapping them to a lower-dimensional space. However, these existing methods fail\nto incorporate the difference in importance among features.\nTo address this problem, we propose a novel meta-method, DimenFix, which can\nbe operated upon any base dimensionality reduction method that involves a\ngradient-descent-like process. By allowing users to define the importance of\ndifferent features, which is considered in dimensionality reduction, DimenFix\ncreates new possibilities to visualize and understand a given dataset.\nMeanwhile, DimenFix does not increase the time cost or reduce the quality of\ndimensionality reduction with respect to the base dimensionality reduction\nused.",
    "descriptor": "",
    "authors": [
      "Qiaodan Luo",
      "Leonardo Christino",
      "Fernando V Paulovich",
      "Evangelos Milios"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16752"
  },
  {
    "id": "arXiv:2211.16753",
    "title": "VI-PINNs: Variance-involved Physics-informed Neural Networks for Fast  and Accurate Prediction of Partial Differential Equations",
    "abstract": "Although physics-informed neural networks(PINNs) have progressed a lot in\nmany real applications recently, there remains problems to be further studied,\nsuch as achieving more accurate results, taking less training time, and\nquantifying the uncertainty of the predicted results. Recent advances in PINNs\nhave indeed significantly improved the performance of PINNs in many aspects,\nbut few have considered the effect of variance in the training process. In this\nwork, we take into consideration the effect of variance and propose our\nVI-PINNs to give better predictions. We output two values in the final layer of\nthe network to represent the predicted mean and variance respectively, and the\nlatter is used to represent the uncertainty of the output. A modified negative\nlog-likelihood loss and an auxiliary task are introduced for fast and accurate\ntraining. We perform several experiments on a wide range of different problems\nto highlight the advantages of our approach. The results convey that our method\nnot only gives more accurate predictions but also converges faster.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Bin Shan",
      "Ye Li",
      "Shengjun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16753"
  },
  {
    "id": "arXiv:2211.16756",
    "title": "Split-PU: Hardness-aware Training Strategy for Positive-Unlabeled  Learning",
    "abstract": "Positive-Unlabeled (PU) learning aims to learn a model with rare positive\nsamples and abundant unlabeled samples. Compared with classical binary\nclassification, the task of PU learning is much more challenging due to the\nexistence of many incompletely-annotated data instances. Since only part of the\nmost confident positive samples are available and evidence is not enough to\ncategorize the rest samples, many of these unlabeled data may also be the\npositive samples. Research on this topic is particularly useful and essential\nto many real-world tasks which demand very expensive labelling cost. For\nexample, the recognition tasks in disease diagnosis, recommendation system and\nsatellite image recognition may only have few positive samples that can be\nannotated by the experts. These methods mainly omit the intrinsic hardness of\nsome unlabeled data, which can result in sub-optimal performance as a\nconsequence of fitting the easy noisy data and not sufficiently utilizing the\nhard data. In this paper, we focus on improving the commonly-used nnPU with a\nnovel training pipeline. We highlight the intrinsic difference of hardness of\nsamples in the dataset and the proper learning strategies for easy and hard\ndata. By considering this fact, we propose first splitting the unlabeled\ndataset with an early-stop strategy. The samples that have inconsistent\npredictions between the temporary and base model are considered as hard\nsamples. Then the model utilizes a noise-tolerant Jensen-Shannon divergence\nloss for easy data; and a dual-source consistency regularization for hard data\nwhich includes a cross-consistency between student and base model for low-level\nfeatures and self-consistency for high-level features and predictions,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Chengming Xu",
      "Chen Liu",
      "Siqian Yang",
      "Yabiao Wang",
      "Shijie Zhang",
      "Lijie Jia",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16756"
  },
  {
    "id": "arXiv:2211.16759",
    "title": "General policy mapping: online continual reinforcement learning inspired  on the insect brain",
    "abstract": "We have developed a model for online continual or lifelong reinforcement\nlearning (RL) inspired on the insect brain. Our model leverages the offline\ntraining of a feature extraction and a common general policy layer to enable\nthe convergence of RL algorithms in online settings. Sharing a common policy\nlayer across tasks leads to positive backward transfer, where the agent\ncontinuously improved in older tasks sharing the same underlying general\npolicy. Biologically inspired restrictions to the agent's network are key for\nthe convergence of RL algorithms. This provides a pathway towards efficient\nonline RL in resource-constrained scenarios.",
    "descriptor": "",
    "authors": [
      "Angel Yanguas-Gil",
      "Sandeep Madireddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16759"
  },
  {
    "id": "arXiv:2211.16761",
    "title": "Improving Cross-Modal Retrieval with Set of Diverse Embeddings",
    "abstract": "Cross-modal retrieval across image and text modalities is a challenging task\ndue to its inherent ambiguity: An image often exhibits various situations, and\na caption can be coupled with diverse images. Set-based embedding has been\nstudied as a solution to this problem. It seeks to encode a sample into a set\nof different embedding vectors that capture different semantics of the sample.\nIn this paper, we present a novel set-based embedding method, which is distinct\nfrom previous work in two aspects. First, we present a new similarity function\ncalled smooth-Chamfer similarity, which is designed to alleviate the side\neffects of existing similarity functions for set-based embedding. Second, we\npropose a novel set prediction module to produce a set of embedding vectors\nthat effectively captures diverse semantics of input by the slot attention\nmechanism. Our method is evaluated on the COCO and Flickr30K datasets across\ndifferent visual backbones, where it outperforms existing methods including\nones that demand substantially larger computation at inference.",
    "descriptor": "",
    "authors": [
      "Dongwon Kim",
      "Namyup Kim",
      "Suha Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16761"
  },
  {
    "id": "arXiv:2211.16762",
    "title": "GeoUDF: Surface Reconstruction from 3D Point Clouds via Geometry-guided  Distance Representation",
    "abstract": "The recent neural implicit representation-based methods have greatly advanced\nthe state of the art for solving the long-standing and challenging problem of\nreconstructing a discrete surface from a sparse point cloud. These methods\ngenerally learn either a binary occupancy or signed/unsigned distance field\n(SDF/UDF) as surface representation. However, all the existing SDF/UDF-based\nmethods use neural networks to implicitly regress the distance in a purely\ndata-driven manner, thus limiting the accuracy and generalizability to some\nextent. In contrast, we propose the first geometry-guided method for UDF and\nits gradient estimation that explicitly formulates the unsigned distance of a\nquery point as the learnable affine averaging of its distances to the tangent\nplanes of neighbouring points. Besides, we model the local geometric structure\nof the input point clouds by explicitly learning a quadratic polynomial for\neach point. This not only facilitates upsampling the input sparse point cloud\nbut also naturally induces unoriented normal, which further augments UDF\nestimation. Finally, to extract triangle meshes from the predicted UDF we\npropose a customized edge-based marching cube module. We conduct extensive\nexperiments and ablation studies to demonstrate the significant advantages of\nour method over state-of-the-art methods in terms of reconstruction accuracy,\nefficiency, and generalizability. The source code is publicly available at\nhttps://github.com/rsy6318/GeoUDF.",
    "descriptor": "",
    "authors": [
      "Siyu Ren",
      "Junhui Hou",
      "Xiaodong Chen",
      "Ying He",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16762"
  },
  {
    "id": "arXiv:2211.16764",
    "title": "A General Deep Learning Speech Enhancement Framework Motivated by  Taylor's Theorem",
    "abstract": "While deep neural networks greatly facilitate the proliferation of the speech\nenhancement field, most of the existing methods are developed following either\nheuristic or blind optimization criteria, which severely hampers\ninterpretability and transparency. Inspired by Taylor's theorem, we propose a\ngeneral unfolding framework for both single- and multi-channel speech\nenhancement tasks. Concretely, we formulate the complex spectrum recovery into\nthe spectral magnitude mapping in the neighboring space of the noisy mixture,\nin which the sparse prior is introduced for phase modification in advance.\nBased on that, the mapping function is decomposed into the superimposition of\nthe 0th-order and high-order polynomials in Taylor's series, where the former\ncoarsely removes the interference in the magnitude domain and the latter\nprogressively complements the remaining spectral detail in the complex spectrum\ndomain. In addition, we study the relation between adjacent order term and\nreveal that each high-order term can be recursively estimated with its\nlower-order term, and each high-order term is then proposed to evaluate using a\nsurrogate function with trainable weights, so that the whole system can be\ntrained in an end-to-end manner. Extensive experiments are conducted on\nWSJ0-SI84, DNS-Challenge, Voicebank+Demand, and spatialized Librispeech\ndatasets. Quantitative results show that the proposed approach not only yields\ncompetitive performance over existing top-performed approaches, but also enjoys\ndecent internal transparency and flexibility.",
    "descriptor": "\nComments: Submitted to TASLP, 13 pages\n",
    "authors": [
      "Andong Li",
      "Guochen Yu",
      "Chengshi Zheng",
      "Wenzhe Liu",
      "Xiaodong Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.16764"
  },
  {
    "id": "arXiv:2211.16766",
    "title": "Arithmetic autocorrelation distribution of binary $m$-sequences",
    "abstract": "Binary $m$-sequences are ones with the largest period $n=2^m-1$ among the\nbinary sequences produced by linear shift registers with length $m$. They have\na wide range of applications in communication since they have several desirable\npseudorandomness such as balance, uniform pattern distribution and ideal\n(classical) autocorrelation. In his reseach on arithmetic codes, Mandelbaum\n\\cite{9Mand} introduces a 2-adic version of classical autocorrelation of binary\nsequences, called arithmetic autocorrelation. Later, Goresky and Klapper\n\\cite{3G1,4G2,5G3,6G4} generalize this notion to nonbinary case and develop\nseveral properties of arithmetic autocorrelation related to linear shift\nregisters with carry. Recently, Z. Chen et al. \\cite{1C1} show an upper bound\non arithmetic autocorrelation of binary $m$-sequences and raise a conjecture on\nabsolute value distribution on arithmetic autocorrelation of binary\n$m$-sequences.",
    "descriptor": "",
    "authors": [
      "Xiaoyan Jing",
      "Aixian Zhang",
      "Keqin Feng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.16766"
  },
  {
    "id": "arXiv:2211.16769",
    "title": "Uncertainty-Aware Image Captioning",
    "abstract": "It is well believed that the higher uncertainty in a word of the caption, the\nmore inter-correlated context information is required to determine it. However,\ncurrent image captioning methods usually consider the generation of all words\nin a sentence sequentially and equally. In this paper, we propose an\nuncertainty-aware image captioning framework, which parallelly and iteratively\noperates insertion of discontinuous candidate words between existing words from\neasy to difficult until converged. We hypothesize that high-uncertainty words\nin a sentence need more prior information to make a correct decision and should\nbe produced at a later stage. The resulting non-autoregressive hierarchy makes\nthe caption generation explainable and intuitive. Specifically, we utilize an\nimage-conditioned bag-of-word model to measure the word uncertainty and apply a\ndynamic programming algorithm to construct the training pairs. During\ninference, we devise an uncertainty-adaptive parallel beam search technique\nthat yields an empirically logarithmic time complexity. Extensive experiments\non the MS COCO benchmark reveal that our approach outperforms the strong\nbaseline and related methods on both captioning quality as well as decoding\nspeed.",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Zhengcong Fei",
      "Mingyuan Fan",
      "Li Zhu",
      "Junshi Huang",
      "Xiaoming Wei",
      "Xiaolin Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16769"
  },
  {
    "id": "arXiv:2211.16771",
    "title": "Handling Missing Data via Max-Entropy Regularized Graph Autoencoder",
    "abstract": "Graph neural networks (GNNs) are popular weapons for modeling relational\ndata. Existing GNNs are not specified for attribute-incomplete graphs, making\nmissing attribute imputation a burning issue. Until recently, many works notice\nthat GNNs are coupled with spectral concentration, which means the spectrum\nobtained by GNNs concentrates on a local part in spectral domain, e.g.,\nlow-frequency due to oversmoothing issue. As a consequence, GNNs may be\nseriously flawed for reconstructing graph attributes as graph spectral\nconcentration tends to cause a low imputation precision. In this work, we\npresent a regularized graph autoencoder for graph attribute imputation, named\nMEGAE, which aims at mitigating spectral concentration problem by maximizing\nthe graph spectral entropy. Notably, we first present the method for estimating\ngraph spectral entropy without the eigen-decomposition of Laplacian matrix and\nprovide the theoretical upper error bound. A maximum entropy regularization\nthen acts in the latent space, which directly increases the graph spectral\nentropy. Extensive experiments show that MEGAE outperforms all the other\nstate-of-the-art imputation methods on a variety of benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Ziqi Gao",
      "Yifan Niu",
      "Jiashun Cheng",
      "Jianheng Tang",
      "Tingyang Xu",
      "Peilin Zhao",
      "Lanqing Li",
      "Fugee Tsung",
      "Jia Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16771"
  },
  {
    "id": "arXiv:2211.16773",
    "title": "Reinforced Language Modeling for End-to-End Task Oriented Dialog",
    "abstract": "In task-oriented dialogs such as MultiWoZ (Budzianowski et al., 2018), an\ninformative and/or successful system response needs to include necessary key\ninformation such as the phone number of a hotel. Therefore, we hypothesize that\nby helping the model to focus more on learning key quantities in the dialog,\nthe model can generative more informative and helpful responses. In this paper,\nwe propose a new training algorithm, Reinforced Language Modeling (RLM), that\naims to use a fine-grained reward function and reinforcement learning to help\nthe model focus more on generating key quantities correctly during test time.\nEmpirical results show our proposed RLM achieves state-of-the-art performance\non the inform rate, success rate, and combined score in MultiWoZ.",
    "descriptor": "",
    "authors": [
      "Xiao Yu",
      "Qingyang Wu",
      "Kun Qian",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16773"
  },
  {
    "id": "arXiv:2211.16776",
    "title": "From Coarse to Fine: Hierarchical Pixel Integration for Lightweight  Image Super-Resolution",
    "abstract": "Image super-resolution (SR) serves as a fundamental tool for the processing\nand transmission of multimedia data. Recently, Transformer-based models have\nachieved competitive performances in image SR. They divide images into\nfixed-size patches and apply self-attention on these patches to model\nlong-range dependencies among pixels. However, this architecture design is\noriginated for high-level vision tasks, which lacks design guideline from SR\nknowledge. In this paper, we aim to design a new attention block whose insights\nare from the interpretation of Local Attribution Map (LAM) for SR networks.\nSpecifically, LAM presents a hierarchical importance map where the most\nimportant pixels are located in a fine area of a patch and some less important\npixels are spread in a coarse area of the whole image. To access pixels in the\ncoarse area, instead of using a very large patch size, we propose a lightweight\nGlobal Pixel Access (GPA) module that applies cross-attention with the most\nsimilar patch in an image. In the fine area, we use an Intra-Patch\nSelf-Attention (IPSA) module to model long-range pixel dependencies in a local\npatch, and then a $3\\times3$ convolution is applied to process the finest\ndetails. In addition, a Cascaded Patch Division (CPD) strategy is proposed to\nenhance perceptual quality of recovered images. Extensive experiments suggest\nthat our method outperforms state-of-the-art lightweight SR methods by a large\nmargin. Code is available at https://github.com/passerer/HPINet.",
    "descriptor": "\nComments: SOTA lightweight image super-resolution. To be appear at AAAI 2023\n",
    "authors": [
      "Jie Liu",
      "Chao Chen",
      "Jie Tang",
      "Gangshan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16776"
  },
  {
    "id": "arXiv:2211.16778",
    "title": "Rethinking Out-of-Distribution Detection From a Human-Centric  Perspective",
    "abstract": "Out-Of-Distribution (OOD) detection has received broad attention over the\nyears, aiming to ensure the reliability and safety of deep neural networks\n(DNNs) in real-world scenarios by rejecting incorrect predictions. However, we\nnotice a discrepancy between the conventional evaluation vs. the essential\npurpose of OOD detection. On the one hand, the conventional evaluation\nexclusively considers risks caused by label-space distribution shifts while\nignoring the risks from input-space distribution shifts. On the other hand, the\nconventional evaluation reward detection methods for not rejecting the\nmisclassified image in the validation dataset. However, the misclassified image\ncan also cause risks and should be rejected. We appeal to rethink OOD detection\nfrom a human-centric perspective, that a proper detection method should reject\nthe case that the deep model's prediction mismatches the human expectations and\nadopt the case that the deep model's prediction meets the human expectations.\nWe propose a human-centric evaluation and conduct extensive experiments on 45\nclassifiers and 8 test datasets. We find that the simple baseline OOD detection\nmethod can achieve comparable and even better performance than the recently\nproposed methods, which means that the development in OOD detection in the past\nyears may be overestimated. Additionally, our experiments demonstrate that\nmodel selection is non-trivial for OOD detection and should be considered as an\nintegral of the proposed method, which differs from the claim in existing works\nthat proposed methods are universal across different models.",
    "descriptor": "\nComments: Preprint version. Submitted to International Journal of Computer Vision\n",
    "authors": [
      "Yao Zhu",
      "Yuefeng Chen",
      "Xiaodan Li",
      "Rong Zhang",
      "Hui Xue",
      "Xiang Tian",
      "Rongxin Jiang",
      "Bolun Zheng",
      "Yaowu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16778"
  },
  {
    "id": "arXiv:2211.16779",
    "title": "Attention-based Depth Distillation with 3D-Aware Positional Encoding for  Monocular 3D Object Detection",
    "abstract": "Monocular 3D object detection is a low-cost but challenging task, as it\nrequires generating accurate 3D localization solely from a single image input.\nRecent developed depth-assisted methods show promising results by using\nexplicit depth maps as intermediate features, which are either precomputed by\nmonocular depth estimation networks or jointly evaluated with 3D object\ndetection. However, inevitable errors from estimated depth priors may lead to\nmisaligned semantic information and 3D localization, hence resulting in feature\nsmearing and suboptimal predictions. To mitigate this issue, we propose ADD, an\nAttention-based Depth knowledge Distillation framework with 3D-aware positional\nencoding. Unlike previous knowledge distillation frameworks that adopt stereo-\nor LiDAR-based teachers, we build up our teacher with identical architecture as\nthe student but with extra ground-truth depth as input. Credit to our teacher\ndesign, our framework is seamless, domain-gap free, easily implementable, and\nis compatible with object-wise ground-truth depth. Specifically, we leverage\nintermediate features and responses for knowledge distillation. Considering\nlong-range 3D dependencies, we propose \\emph{3D-aware self-attention} and\n\\emph{target-aware cross-attention} modules for student adaptation. Extensive\nexperiments are performed to verify the effectiveness of our framework on the\nchallenging KITTI 3D object detection benchmark. We implement our framework on\nthree representative monocular detectors, and we achieve state-of-the-art\nperformance with no additional inference computational cost relative to\nbaseline models. Our code is available at https://github.com/rockywind/ADD.",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Zizhang Wu",
      "Yunzhe Wu",
      "Jian Pu",
      "Xianzhi Li",
      "Xiaoquan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16779"
  },
  {
    "id": "arXiv:2211.16780",
    "title": "Continual Learning with Optimal Transport based Mixture Model",
    "abstract": "Online Class Incremental learning (CIL) is a challenging setting in Continual\nLearning (CL), wherein data of new tasks arrive in incoming streams and online\nlearning models need to handle incoming data streams without revisiting\nprevious ones. Existing works used a single centroid adapted with incoming data\nstreams to characterize a class. This approach possibly exposes limitations\nwhen the incoming data stream of a class is naturally multimodal. To address\nthis issue, in this work, we first propose an online mixture model learning\napproach based on nice properties of the mature optimal transport theory\n(OT-MM). Specifically, the centroids and covariance matrices of the mixture\nmodel are adapted incrementally according to incoming data streams. The\nadvantages are two-fold: (i) we can characterize more accurately complex data\nstreams and (ii) by using centroids for each class produced by OT-MM, we can\nestimate the similarity of an unseen example to each class more reasonably when\ndoing inference. Moreover, to combat the catastrophic forgetting in the CIL\nscenario, we further propose Dynamic Preservation. Particularly, after\nperforming the dynamic preservation technique across data streams, the latent\nrepresentations of the classes in the old and new tasks become more condensed\nthemselves and more separate from each other. Together with a contraction\nfeature extractor, this technique facilitates the model in mitigating the\ncatastrophic forgetting. The experimental results on real-world datasets show\nthat our proposed method can significantly outperform the current\nstate-of-the-art baselines.",
    "descriptor": "",
    "authors": [
      "Quyen Tran",
      "Hoang Phan",
      "Khoat Than",
      "Dinh Phung",
      "Trung Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16780"
  },
  {
    "id": "arXiv:2211.16784",
    "title": "Robust and Fast Measure of Information via Low-rank Representation",
    "abstract": "The matrix-based R\\'enyi's entropy allows us to directly quantify information\nmeasures from given data, without explicit estimation of the underlying\nprobability distribution. This intriguing property makes it widely applied in\nstatistical inference and machine learning tasks. However, this information\ntheoretical quantity is not robust against noise in the data, and is\ncomputationally prohibitive in large-scale applications. To address these\nissues, we propose a novel measure of information, termed low-rank matrix-based\nR\\'enyi's entropy, based on low-rank representations of infinitely divisible\nkernel matrices. The proposed entropy functional inherits the specialty of of\nthe original definition to directly quantify information from data, but enjoys\nadditional advantages including robustness and effective calculation.\nSpecifically, our low-rank variant is more sensitive to informative\nperturbations induced by changes in underlying distributions, while being\ninsensitive to uninformative ones caused by noises. Moreover, low-rank\nR\\'enyi's entropy can be efficiently approximated by random projection and\nLanczos iteration techniques, reducing the overall complexity from\n$\\mathcal{O}(n^3)$ to $\\mathcal{O}(n^2 s)$ or even $\\mathcal{O}(ns^2)$, where\n$n$ is the number of data samples and $s \\ll n$. We conduct large-scale\nexperiments to evaluate the effectiveness of this new information measure,\ndemonstrating superior results compared to matrix-based R\\'enyi's entropy in\nterms of both performance and computational efficiency.",
    "descriptor": "",
    "authors": [
      "Yuxin Dong",
      "Tieliang Gong",
      "Shujian Yu",
      "Hong Chen",
      "Chen Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.16784"
  },
  {
    "id": "arXiv:2211.16785",
    "title": "SafeSpace MFNet: Precise and Efficient MultiFeature Drone Detection  Network",
    "abstract": "Unmanned air vehicles (UAVs) popularity is on the rise as it enables the\nservices like traffic monitoring, emergency communications, deliveries, and\nsurveillance. However, the unauthorized usage of UAVs (a.k.a drone) may violate\nsecurity and privacy protocols for security-sensitive national and\ninternational institutions. The presented challenges require fast, efficient,\nand precise detection of UAVs irrespective of harsh weather conditions, the\npresence of different objects, and their size to enable SafeSpace. Recently,\nthere has been significant progress in using the latest deep learning models,\nbut those models have shortcomings in terms of computational complexity,\nprecision, and non-scalability. To overcome these limitations, we propose a\nprecise and efficient multiscale and multifeature UAV detection network for\nSafeSpace, i.e., \\textit{MultiFeatureNet} (\\textit{MFNet}), an improved version\nof the popular object detection algorithm YOLOv5s. In \\textit{MFNet}, we\nperform multiple changes in the backbone and neck of the YOLOv5s network to\nfocus on the various small and ignored features required for accurate and fast\nUAV detection. To further improve the accuracy and focus on the specific\nsituation and multiscale UAVs, we classify the \\textit{MFNet} into small (S),\nmedium (M), and large (L): these are the combinations of various size filters\nin the convolution and the bottleneckCSP layers, reside in the backbone and\nneck of the architecture. This classification helps to overcome the\ncomputational cost by training the model on a specific feature map rather than\nall the features. The dataset and code are available as an open source:\ngithub.com/ZeeshanKaleem/MultiFeatureNet.",
    "descriptor": "\nComments: Paper under review in IEEE TVT\n",
    "authors": [
      "Mahnoor Dil",
      "Misha Urooj Khan",
      "Muhammad Zeshan Alam",
      "Farooq Alam Orakazi",
      "Zeeshan Kaleem",
      "Chau Yuen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16785"
  },
  {
    "id": "arXiv:2211.16786",
    "title": "Two-branch Multi-scale Deep Neural Network for Generalized Document  Recapture Attack Detection",
    "abstract": "The image recapture attack is an effective image manipulation method to erase\ncertain forensic traces, and when targeting on personal document images, it\nposes a great threat to the security of e-commerce and other web applications.\nConsidering the current learning-based methods suffer from serious overfitting\nproblem, in this paper, we propose a novel two-branch deep neural network by\nmining better generalized recapture artifacts with a designed frequency filter\nbank and multi-scale cross-attention fusion module. In the extensive\nexperiment, we show that our method can achieve better generalization\ncapability compared with state-of-the-art techniques on different scenarios.",
    "descriptor": "\nComments: 5 pages, 4 figures, 2023 IEEE International Conference on Acoustics, Speech and Signal Processing, under review\n",
    "authors": [
      "Jiaxing Li",
      "Chenqi Kong",
      "Shiqi Wang",
      "Haoliang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16786"
  },
  {
    "id": "arXiv:2211.16791",
    "title": "Adaptive adversarial training method for improving multi-scale GAN based  on generalization bound theory",
    "abstract": "In recent years, multi-scale generative adversarial networks (GANs) have been\nproposed to build generalized image processing models based on single sample.\nConstraining on the sample size, multi-scale GANs have much difficulty\nconverging to the global optimum, which ultimately leads to limitations in\ntheir capabilities. In this paper, we pioneered the introduction of PAC-Bayes\ngeneralized bound theory into the training analysis of specific models under\ndifferent adversarial training methods, which can obtain a non-vacuous upper\nbound on the generalization error for the specified multi-scale GAN structure.\nBased on the drastic changes we found of the generalization error bound under\ndifferent adversarial attacks and different training states, we proposed an\nadaptive training method which can greatly improve the image manipulation\nability of multi-scale GANs. The final experimental results show that our\nadaptive training method in this paper has greatly contributed to the\nimprovement of the quality of the images generated by multi-scale GANs on\nseveral image manipulation tasks. In particular, for the image super-resolution\nrestoration task, the multi-scale GAN model trained by the proposed method\nachieves a 100% reduction in natural image quality evaluator (NIQE) and a 60%\nreduction in root mean squared error (RMSE), which is better than many models\ntrained on large-scale datasets.",
    "descriptor": "",
    "authors": [
      "Jing Tang",
      "Bo Tao",
      "Zeyu Gong",
      "Zhouping Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.16791"
  },
  {
    "id": "arXiv:2211.16796",
    "title": "Gradient Domain Weighted Guided Image Filtering",
    "abstract": "As an excellent local filter, guided image filters are subject to halo\nartifacts. In this paper, the algorithm uses gradient information to accurately\ndetermine the edge of the image, and uses the weighted information to further\naccurately distinguish the flat area and edge area of the image. As a result,\nthe edges of the image are sharper and the level of blur in flat areas is\nreduced, avoiding halo artifacts caused by excessive blurring near edges.\nExperiments show that the proposed algorithm can better suppress halo artifacts\nat the edges. The proposed algorithm has good performance in both image\ndenoising and image detail enhancement.",
    "descriptor": "",
    "authors": [
      "Bo Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.16796"
  },
  {
    "id": "arXiv:2211.16798",
    "title": "Dr.3D: Adapting 3D GANs to Artistic Drawings",
    "abstract": "While 3D GANs have recently demonstrated the high-quality synthesis of\nmulti-view consistent images and 3D shapes, they are mainly restricted to\nphoto-realistic human portraits. This paper aims to extend 3D GANs to a\ndifferent, but meaningful visual form: artistic portrait drawings. However,\nextending existing 3D GANs to drawings is challenging due to the inevitable\ngeometric ambiguity present in drawings. To tackle this, we present Dr.3D, a\nnovel adaptation approach that adapts an existing 3D GAN to artistic drawings.\nDr.3D is equipped with three novel components to handle the geometric\nambiguity: a deformation-aware 3D synthesis network, an alternating adaptation\nof pose estimation and image synthesis, and geometric priors. Experiments show\nthat our approach can successfully adapt 3D GANs to drawings and enable\nmulti-view consistent semantic editing of drawings.",
    "descriptor": "\nComments: Accepted to SIGGRAPH Asia 2022 (Conference Track). For project page, see this https URL\n",
    "authors": [
      "Wonjoon Jin",
      "Nuri Ryu",
      "Geonung Kim",
      "Seung-Hwan Baek",
      "Sunghyun Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16798"
  },
  {
    "id": "arXiv:2211.16799",
    "title": "NOPE-SAC: Neural One-Plane RANSAC for Sparse-View Planar 3D  Reconstruction",
    "abstract": "This paper studies the challenging two-view 3D reconstruction in a rigorous\nsparse-view configuration, which is suffering from insufficient correspondences\nin the input image pairs for camera pose estimation. We present a novel Neural\nOne-PlanE RANSAC framework (termed NOPE-SAC in short) that exerts excellent\ncapability to learn one-plane pose hypotheses from 3D plane correspondences.\nBuilding on the top of a siamese plane detection network, our NOPE-SAC first\ngenerates putative plane correspondences with a coarse initial pose. It then\nfeeds the learned 3D plane parameters of correspondences into shared MLPs to\nestimate the one-plane camera pose hypotheses, which are subsequently reweighed\nin a RANSAC manner to obtain the final camera pose. Because the neural\none-plane pose minimizes the number of plane correspondences for adaptive pose\nhypotheses generation, it enables stable pose voting and reliable pose\nrefinement in a few plane correspondences for the sparse-view inputs. In the\nexperiments, we demonstrate that our NOPE-SAC significantly improves the camera\npose estimation for the two-view inputs with severe viewpoint changes, setting\nseveral new state-of-the-art performances on two challenging benchmarks, i.e.,\nMatterPort3D and ScanNet, for sparse-view 3D reconstruction. The source code is\nreleased at https://github.com/IceTTTb/NopeSAC for reproducible research.",
    "descriptor": "\nComments: Code: see this https URL\n",
    "authors": [
      "Bin Tan",
      "Nan Xue",
      "Tianfu Wu",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16799"
  },
  {
    "id": "arXiv:2211.16801",
    "title": "Generalised Spherical Text Embedding",
    "abstract": "This paper aims to provide an unsupervised modelling approach that allows for\na more flexible representation of text embeddings. It jointly encodes the words\nand the paragraphs as individual matrices of arbitrary column dimension with\nunit Frobenius norm. The representation is also linguistically motivated with\nthe introduction of a novel similarity metric. The proposed modelling and the\nnovel similarity metric exploits the matrix structure of embeddings. We then go\non to show that the same matrices can be reshaped into vectors of unit norm and\ntransform our problem into an optimization problem over the spherical manifold.\nWe exploit manifold optimization to efficiently train the matrix embeddings. We\nalso quantitatively verify the quality of our text embeddings by showing that\nthey demonstrate improved results in document classification, document\nclustering, and semantic textual similarity benchmark tests.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Souvik Banerjee",
      "Bamdev Mishra",
      "Pratik Jawanpuria",
      "Manish Shrivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16801"
  },
  {
    "id": "arXiv:2211.16807",
    "title": "Camelira: An Arabic Multi-Dialect Morphological Disambiguator",
    "abstract": "We present Camelira, a web-based Arabic multi-dialect morphological\ndisambiguation tool that covers four major variants of Arabic: Modern Standard\nArabic, Egyptian, Gulf, and Levantine. Camelira offers a user-friendly web\ninterface that allows researchers and language learners to explore various\nlinguistic information, such as part-of-speech, morphological features, and\nlemmas. Our system also provides an option to automatically choose an\nappropriate dialect-specific disambiguator based on the prediction of a dialect\nidentification component. Camelira is publicly accessible at\nthis http URL",
    "descriptor": "",
    "authors": [
      "Ossama Obeid",
      "Go Inoue",
      "Nizar Habash"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16807"
  },
  {
    "id": "arXiv:2211.16808",
    "title": "Efficient Adversarial Input Generation via Neural Net Patching",
    "abstract": "The adversarial input generation problem has become central in establishing\nthe robustness and trustworthiness of deep neural nets, especially when they\nare used in safety-critical application domains such as autonomous vehicles and\nprecision medicine. This is also practically challenging for multiple\nreasons-scalability is a common issue owing to large-sized networks, and the\ngenerated adversarial inputs often lack important qualities such as naturalness\nand output-impartiality. We relate this problem to the task of patching neural\nnets, i.e. applying small changes in some of the network$'$s weights so that\nthe modified net satisfies a given property. Intuitively, a patch can be used\nto produce an adversarial input because the effect of changing the weights can\nalso be brought about by changing the inputs instead. This work presents a\nnovel technique to patch neural networks and an innovative approach of using it\nto produce perturbations of inputs which are adversarial for the original net.\nWe note that the proposed solution is significantly more effective than the\nprior state-of-the-art techniques.",
    "descriptor": "",
    "authors": [
      "Tooba Khan",
      "Kumar Madhukar",
      "Subodh Vishnu Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.16808"
  },
  {
    "id": "arXiv:2211.16820",
    "title": "Trajectory-based Traveling Salesman Problem for Multirotor UAVs",
    "abstract": "This paper presents a new method for integrated time-optimal routing and\ntrajectory optimization of multirotor unmanned aerial vehicles (UAVs). Our\napproach extends the well-known Traveling Salesman Problem by accounting for\nthe limited maneuverability of the UAVs due to their kinematic properties. To\nthis end, we allow each waypoint to be traversed with a discretized velocity as\nwell as a discretized flight direction and compute time-optimal trajectories to\ndetermine the travel time costs for each edge. We refer to this novel\noptimization problem as the Trajectory-based Traveling Salesman Problem\n(TBTSP). The results show that compared to a state-of-the-art approach for\nTraveling Salesman Problems with kinematic restrictions of UAVs, we can\ndecrease mission duration by up to 15\\%.",
    "descriptor": "\nComments: This work was published at 2021 17th International Conference on Distributed Computing in Sensor Systems (DCOSS)\n",
    "authors": [
      "Fabian Meyer",
      "Katharina Glock"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.16820"
  },
  {
    "id": "arXiv:2211.16822",
    "title": "A Probabilistic-Logic based Commonsense Representation Framework for  Modelling Inferences with Multiple Antecedents and Varying Likelihoods",
    "abstract": "Commonsense knowledge-graphs (CKGs) are important resources towards building\nmachines that can 'reason' on text or environmental inputs and make inferences\nbeyond perception. While current CKGs encode world knowledge for a large number\nof concepts and have been effectively utilized for incorporating commonsense in\nneural models, they primarily encode declarative or single-condition\ninferential knowledge and assume all conceptual beliefs to have the same\nlikelihood. Further, these CKGs utilize a limited set of relations shared\nacross concepts and lack a coherent knowledge organization structure resulting\nin redundancies as well as sparsity across the larger knowledge graph.\nConsequently, today's CKGs, while useful for a first level of reasoning, do not\nadequately capture deeper human-level commonsense inferences which can be more\nnuanced and influenced by multiple contextual or situational factors.\nAccordingly, in this work, we study how commonsense knowledge can be better\nrepresented by -- (i) utilizing a probabilistic logic representation scheme to\nmodel composite inferential knowledge and represent conceptual beliefs with\nvarying likelihoods, and (ii) incorporating a hierarchical conceptual ontology\nto identify salient concept-relevant relations and organize beliefs at\ndifferent conceptual levels. Our resulting knowledge representation framework\ncan encode a wider variety of world knowledge and represent beliefs flexibly\nusing grounded concepts as well as free-text phrases. As a result, the\nframework can be utilized as both a traditional free-text knowledge graph and a\ngrounded logic-based inference system more suitable for neuro-symbolic\napplications. We describe how we extend the PrimeNet knowledge base with our\nframework through crowd-sourcing and expert-annotation, and demonstrate its\napplication for more interpretable passage-based semantic parsing and question\nanswering.",
    "descriptor": "\nComments: Preprint (work in progress)\n",
    "authors": [
      "Shantanu Jaiswal",
      "Liu Yan",
      "Dongkyu Choi",
      "Kenneth Kwok"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16822"
  },
  {
    "id": "arXiv:2211.16824",
    "title": "WeatherFusionNet: Predicting Precipitation from Satellite Data",
    "abstract": "The short-term prediction of precipitation is critical in many areas of life.\nRecently, a large body of work was devoted to forecasting radar reflectivity\nimages. The radar images are available only in areas with ground weather\nradars. Thus, we aim to predict high-resolution precipitation from\nlower-resolution satellite radiance images. A neural network called\nWeatherFusionNet is employed to predict severe rain up to eight hours in\nadvance. WeatherFusionNet is a U-Net architecture that fuses three different\nways to process the satellite data; predicting future satellite frames,\nextracting rain information from the current frames, and using the input\nsequence directly. Using the presented method, we achieved 1st place in the\nNeurIPS 2022 Weather4Cast Core challenge. The code and trained parameters are\navailable at \\url{https://github.com/Datalab-FIT-CTU/weather4cast-2022}.",
    "descriptor": "\nComments: NeurIPS 2022, Weather4Cast core challenge\n",
    "authors": [
      "Ji\u0159\u00ed Pihrt",
      "Rudolf Raevskiy",
      "Petr \u0160im\u00e1nek",
      "Matej Choma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16824"
  },
  {
    "id": "arXiv:2211.16827",
    "title": "Immersed isogeometric Boundary Elements: A user friendly method for the  3-D elasto-plastic simulation of underground excavations",
    "abstract": "The immersed isogeometric Boundary Element Method is presented and applied to\nthe simulation of underground excavations. Nonuniform rational B-splines\n(NURBS) are used for the accurate definition of complex geometries with few\nparameters. Immersed technology is applied to automatically generate cell\nmeshes. This allows heterogeneous and anisotropic ground conditions as well as\nnonlinear material behaviour to be considered. On a practical example the user\nfriendliness and accuracy is demonstrated.",
    "descriptor": "\nComments: Novel approach to the simulation of underground excavations\n",
    "authors": [
      "Gernot Beer",
      "Christian Duenser"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16827"
  },
  {
    "id": "arXiv:2211.16835",
    "title": "Reconstructing Hand-Held Objects from Monocular Video",
    "abstract": "This paper presents an approach that reconstructs a hand-held object from a\nmonocular video. In contrast to many recent methods that directly predict\nobject geometry by a trained network, the proposed approach does not require\nany learned prior about the object and is able to recover more accurate and\ndetailed object geometry. The key idea is that the hand motion naturally\nprovides multiple views of the object and the motion can be reliably estimated\nby a hand pose tracker. Then, the object geometry can be recovered by solving a\nmulti-view reconstruction problem. We devise an implicit neural\nrepresentation-based method to solve the reconstruction problem and address the\nissues of imprecise hand pose estimation, relative hand-object motion, and\ninsufficient geometry optimization for small objects. We also provide a newly\ncollected dataset with 3D ground truth to validate the proposed approach.",
    "descriptor": "\nComments: SIGGRAPH Asia 2022 Conference Papers. Project page: this https URL\n",
    "authors": [
      "Di Huang",
      "Xiaopeng Ji",
      "Xingyi He",
      "Jiaming Sun",
      "Tong He",
      "Qing Shuai",
      "Wanli Ouyang",
      "Xiaowei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16835"
  },
  {
    "id": "arXiv:2211.16837",
    "title": "Kinematic Orienteering Problem With Time-Optimal Trajectories for  Multirotor UAVs",
    "abstract": "In many unmanned aerial vehicle (UAV) applications for surveillance and data\ncollection, it is not possible to reach all requested locations due to the\ngiven maximum flight time. Hence, the requested locations must be prioritized\nand the problem of selecting the most important locations is modeled as an\nOrienteering Problem (OP). To fully exploit the kinematic properties of the UAV\nin such scenarios, we combine the OP with the generation of time-optimal\ntrajectories with bounds on velocity and acceleration. We define the resulting\nproblem as the Kinematic Orienteering Problem (KOP) and propose an exact\nmixed-integer formulation together with a Large Neighborhood Search (LNS) as a\nheuristic solution method. We demonstrate the effectiveness of our approach\nbased on Orienteering instances from the literature and benchmark against\noptimal solutions of the Dubins Orienteering Problem (DOP) as the\nstate-of-the-art. Additionally, we show by simulation \\color{black} that the\nresulting solutions can be tracked precisely by a modern MPC-based flight\ncontroller. Since we demonstrate that the state-of-the-art in generating\ntime-optimal trajectories in multiple dimensions is not generally correct, we\nfurther present an improved analytical method for time-optimal trajectory\ngeneration.",
    "descriptor": "\nComments: This work was published in IEEE Robotics and Automation Letteres, VOL. 7, NO. 4, OCTOBER 2022\n",
    "authors": [
      "Fabian Meyer",
      "Katharina Glock"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.16837"
  },
  {
    "id": "arXiv:2211.16838",
    "title": "Towards Improving Exploration in Self-Imitation Learning using Intrinsic  Motivation",
    "abstract": "Reinforcement Learning has emerged as a strong alternative to solve\noptimization tasks efficiently. The use of these algorithms highly depends on\nthe feedback signals provided by the environment in charge of informing about\nhow good (or bad) the decisions made by the learned agent are. Unfortunately,\nin a broad range of problems the design of a good reward function is not\ntrivial, so in such cases sparse reward signals are instead adopted. The lack\nof a dense reward function poses new challenges, mostly related to exploration.\nImitation Learning has addressed those problems by leveraging demonstrations\nfrom experts. In the absence of an expert (and its subsequent demonstrations),\nan option is to prioritize well-suited exploration experiences collected by the\nagent in order to bootstrap its learning process with good exploration\nbehaviors. However, this solution highly depends on the ability of the agent to\ndiscover such trajectories in the early stages of its learning process. To\ntackle this issue, we propose to combine imitation learning with intrinsic\nmotivation, two of the most widely adopted techniques to address problems with\nsparse reward. In this work intrinsic motivation is used to encourage the agent\nto explore the environment based on its curiosity, whereas imitation learning\nallows repeating the most promising experiences to accelerate the learning\nprocess. This combination is shown to yield an improved performance and better\ngeneralization in procedurally-generated environments, outperforming previously\nreported self-imitation learning methods and achieving equal or better sample\nefficiency with respect to intrinsic motivation in isolation.",
    "descriptor": "\nComments: 10 pages, 7 figures, 1 tables\n",
    "authors": [
      "Alain Andres",
      "Esther Villar-Rodriguez",
      "Javier Del Ser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16838"
  },
  {
    "id": "arXiv:2211.16841",
    "title": "Linking Sketch Patches by Learning Synonymous Proximity for Graphic  Sketch Representation",
    "abstract": "Graphic sketch representations are effective for representing sketches.\nExisting methods take the patches cropped from sketches as the graph nodes, and\nconstruct the edges based on sketch's drawing order or Euclidean distances on\nthe canvas. However, the drawing order of a sketch may not be unique, while the\npatches from semantically related parts of a sketch may be far away from each\nother on the canvas. In this paper, we propose an order-invariant,\nsemantics-aware method for graphic sketch representations. The cropped sketch\npatches are linked according to their global semantics or local geometric\nshapes, namely the synonymous proximity, by computing the cosine similarity\nbetween the captured patch embeddings. Such constructed edges are learnable to\nadapt to the variation of sketch drawings, which enable the message passing\namong synonymous patches. Aggregating the messages from synonymous patches by\ngraph convolutional networks plays a role of denoising, which is beneficial to\nproduce robust patch embeddings and accurate sketch representations.\nFurthermore, we enforce a clustering constraint over the embeddings jointly\nwith the network learning. The synonymous patches are self-organized as compact\nclusters, and their embeddings are guided to move towards their assigned\ncluster centroids. It raises the accuracy of the computed synonymous proximity.\nExperimental results show that our method significantly improves the\nperformance on both controllable sketch synthesis and sketch healing.",
    "descriptor": "\nComments: This paper was accepted by AAAI 2023, and the source codes are available at this https URL\n",
    "authors": [
      "Sicong Zang",
      "Shikui Tu",
      "Lei Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16841"
  },
  {
    "id": "arXiv:2211.16843",
    "title": "Optimal Allocation of Virtual Inertia and Droop Control for Renewable  Energy in Stochastic Look-Ahead Power Dispatch",
    "abstract": "To stabilize the frequency of the renewable energy sources (RESs) dominated\npower system, frequency supports are required by RESs through virtual inertia\nemulation or droop control in the newly published grid codes. Since the\nlong-term RES prediction involves significant errors, we need online configure\nthe frequency control parameters of RESs in a rolling manner to improve the\noperation economics under the premise of stabilizing system frequency. To\naddress this concern, this paper proposes a frequency constrained stochastic\nlook-ahead power dispatch (FCS-LAPD) model to formulate the frequency control\nparameters of RESs and Energy Storage Systems (ESSs) as scheduling variables,\nwhich can optimally allocate the virtual inertia and droop coefficient of RESs\nand ESSs. In this FCS-LAPD model, the uncertainties of RESs are characterized\nusing Gaussian Mixture Model (GMM). The required reserves are determined by\nfrequency control parameters, and the reserve cost coefficients are adjusted\nproperly to allocate the reserves according to the predicted power generation.\nDue to the nonlinearity of the frequency nadir constraint, a convex hull\napproximation method is proposed to linearize it with guaranteed feasibility.\nThe proposed FCS-LAPD is ultimately cast as an instance of quadratic\nprogramming and can be efficiently solved. Case studies on modified IEEE 24-bus\nsystem and a provincial power system in China are conducted to show the\neffectiveness of the proposed model.",
    "descriptor": "",
    "authors": [
      "Yukang Shen",
      "Wenchuan Wu",
      "Shumin Sun",
      "Bin Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16843"
  },
  {
    "id": "arXiv:2211.16846",
    "title": "Universal Feature Selection Tool (UniFeat): An Open-Source Tool for  Dimensionality Reduction",
    "abstract": "The Universal Feature Selection Tool (UniFeat) is an open-source tool\ndeveloped entirely in Java for performing feature selection processes in\nvarious research areas. It provides a set of well-known and advanced feature\nselection methods within its significant auxiliary tools. This allows users to\ncompare the performance of feature selection methods. Moreover, due to the\nopen-source nature of UniFeat, researchers can use and modify it in their\nresearch, which facilitates the rapid development of new feature selection\nalgorithms.",
    "descriptor": "\nComments: 9 pages, 6 figures, This tool is available at this https URL\n",
    "authors": [
      "Sina Tabakhi",
      "Parham Moradi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16846"
  },
  {
    "id": "arXiv:2211.16847",
    "title": "Neighbour Consistency Guided Pseudo-Label Refinement for Unsupervised  Person Re-Identification",
    "abstract": "Unsupervised person re-identification (ReID) aims at learning discriminative\nidentity features for person retrieval without any annotations. Recent advances\naccomplish this task by leveraging clustering-based pseudo labels, but these\npseudo labels are inevitably noisy which deteriorate model performance. In this\npaper, we propose a Neighbour Consistency guided Pseudo Label Refinement\n(NCPLR) framework, which can be regarded as a transductive form of label\npropagation under the assumption that the prediction of each example should be\nsimilar to its nearest neighbours'. Specifically, the refined label for each\ntraining instance can be obtained by the original clustering result and a\nweighted ensemble of its neighbours' predictions, with weights determined\naccording to their similarities in the feature space. In addition, we consider\nthe clustering-based unsupervised person ReID as a label-noise learning\nproblem. Then, we proposed an explicit neighbour consistency regularization to\nreduce model susceptibility to over-fitting while improving the training\nstability. The NCPLR method is simple yet effective, and can be seamlessly\nintegrated into existing clustering-based unsupervised algorithms. Extensive\nexperimental results on five ReID datasets demonstrate the effectiveness of the\nproposed method, and showing superior performance to state-of-the-art methods\nby a large margin.",
    "descriptor": "\nComments: 8pages, 3figures\n",
    "authors": [
      "De Cheng",
      "Haichun Tai",
      "Nannan Wang",
      "Zhen Wang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16847"
  },
  {
    "id": "arXiv:2211.16851",
    "title": "A linear filter regularization for POD-based reduced order models of the  quasi-geostrophic equations",
    "abstract": "We propose a regularization for Reduced Order Models (ROMs) of the\nquasi-geostrophic equations (QGE) to increase accuracy when the Proper\nOrthogonal Decomposition (POD) modes retained to construct the reduced basis\nare insufficient to describe the system dynamics. Our regularization is based\non the so-called BV-alpha model, which modifies the nonlinear term in the QGE\nand adds a linear differential filter for the vorticity. To show the\neffectiveness of the BV-alpha model for ROM closure, we compare the results\ncomputed by a POD-Galerkin ROM with and without regularization for the\nclassical double-gyre wind forcing benchmark. Our numerical results show that\nthe solution computed by the regularized ROM is more accurate, even when the\nretained POD modes account for a small percentage of the eigenvalue energy.\nAdditionally, we show that, although computationally more expensive that the\nROM with no regularization, the regularized ROM is still a competitive\nalternative to full order simulations of the QGE.",
    "descriptor": "\nComments: 19 pages, 4 tables, 9 figures\n",
    "authors": [
      "Michele Girfoglio",
      "Annalisa Quaini",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16851"
  },
  {
    "id": "arXiv:2211.16853",
    "title": "Revisiting text decomposition methods for NLI-based factuality scoring  of summaries",
    "abstract": "Scoring the factuality of a generated summary involves measuring the degree\nto which a target text contains factual information using the input document as\nsupport. Given the similarities in the problem formulation, previous work has\nshown that Natural Language Inference models can be effectively repurposed to\nperform this task. As these models are trained to score entailment at a\nsentence level, several recent studies have shown that decomposing either the\ninput document or the summary into sentences helps with factuality scoring. But\nis fine-grained decomposition always a winning strategy? In this paper we\nsystematically compare different granularities of decomposition -- from\ndocument to sub-sentence level, and we show that the answer is no. Our results\nshow that incorporating additional context can yield improvement, but that this\ndoes not necessarily apply to all datasets. We also show that small changes to\npreviously proposed entailment-based scoring methods can result in better\nperformance, highlighting the need for caution in model and methodology\nselection for downstream tasks.",
    "descriptor": "\nComments: Generation, Evaluation & Metrics (GEM) Workshop 2022\n",
    "authors": [
      "John Glover",
      "Federico Fancellu",
      "Vasudevan Jagannathan",
      "Matthew R. Gormley",
      "Thomas Schaaf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16853"
  },
  {
    "id": "arXiv:2211.16858",
    "title": "A Major Obstacle for NLP Research: Let's Talk about Time Allocation!",
    "abstract": "The field of natural language processing (NLP) has grown over the last few\nyears: conferences have become larger, we have published an incredible amount\nof papers, and state-of-the-art research has been implemented in a large\nvariety of customer-facing products. However, this paper argues that we have\nbeen less successful than we should have been and reflects on where and how the\nfield fails to tap its full potential. Specifically, we demonstrate that, in\nrecent years, subpar time allocation has been a major obstacle for NLP\nresearch. We outline multiple concrete problems together with their negative\nconsequences and, importantly, suggest remedies to improve the status quo. We\nhope that this paper will be a starting point for discussions around which\ncommon practices are -- or are not -- beneficial for NLP research.",
    "descriptor": "\nComments: To appear at EMNLP 2022\n",
    "authors": [
      "Katharina Kann",
      "Shiran Dudy",
      "Arya D. McCarthy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16858"
  },
  {
    "id": "arXiv:2211.16860",
    "title": "Gapped String Indexing in Subquadratic Space and Sublinear Query Time",
    "abstract": "In Gapped String Indexing, the goal is to compactly represent a string $S$ of\nlength $n$ such that given queries consisting of two strings $P_1$ and $P_2$,\ncalled patterns, and an integer interval $[\\alpha, \\beta]$, called gap range,\nwe can quickly find occurrences of $P_1$ and $P_2$ in $S$ with distance in\n$[\\alpha, \\beta]$. Due to the many applications of this fundamental problem in\ncomputational biology and elsewhere, there is a great body of work for\nrestricted or parameterised variants of the problem. However, for the general\nproblem statement, no improvements upon the trivial $\\mathcal{O}(n)$-space\n$\\mathcal{O}(n)$-query time or $\\Omega(n^2)$-space $\\mathcal{\\tilde{O}}(|P_1| +\n|P_2| + \\mathrm{occ})$-query time solutions were known so far. We break this\nbarrier obtaining interesting trade-offs with polynomially subquadratic space\nand polynomially sublinear query time. In particular, we show that, for every\n$0\\leq \\delta \\leq 1$, there is a data structure for Gapped String Indexing\nwith either $\\mathcal{\\tilde{O}}(n^{2-\\delta/3})$ or\n$\\mathcal{\\tilde{O}}(n^{3-2\\delta})$ space and $\\mathcal{\\tilde{O}}(|P_1| +\n|P_2| + n^{\\delta}\\cdot (\\mathrm{occ}+1))$ query time, where $\\mathrm{occ}$ is\nthe number of reported occurrences. As a new fundamental tool towards obtaining\nour main result, we introduce the Shifted Set Intersection problem: preprocess\na collection of sets $S_1, \\ldots, S_k$ of integers such that given queries\nconsisting of three integers $i,j,s$, we can quickly output YES if and only if\nthere exist $a \\in S_i$ and $b \\in S_j$ with $a+s = b$. We start by showing\nthat the Shifted Set Intersection problem is equivalent to the indexing variant\nof 3SUM (3SUM Indexing) [Golovnev et al., STOC 2020]. Via several steps of\nreduction we then show that the Gapped String Indexing problem reduces to\npolylogarithmically many instances of the Shifted Set Intersection problem.",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Philip Bille",
      "Inge Li G\u00f8rtz",
      "Moshe Lewenstein",
      "Solon P. Pissis",
      "Eva Rotenberg",
      "Teresa Anna Steiner"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.16860"
  },
  {
    "id": "arXiv:2211.16863",
    "title": "Rephrasing the Reference for Non-Autoregressive Machine Translation",
    "abstract": "Non-autoregressive neural machine translation (NAT) models suffer from the\nmulti-modality problem that there may exist multiple possible translations of a\nsource sentence, so the reference sentence may be inappropriate for the\ntraining when the NAT output is closer to other translations. In response to\nthis problem, we introduce a rephraser to provide a better training target for\nNAT by rephrasing the reference sentence according to the NAT output. As we\ntrain NAT based on the rephraser output rather than the reference sentence, the\nrephraser output should fit well with the NAT output and not deviate too far\nfrom the reference, which can be quantified as reward functions and optimized\nby reinforcement learning. Experiments on major WMT benchmarks and NAT\nbaselines show that our approach consistently improves the translation quality\nof NAT. Specifically, our best variant achieves comparable performance to the\nautoregressive Transformer, while being 14.7 times more efficient in inference.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Chenze Shao",
      "Jinchao Zhang",
      "Jie Zhou",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16863"
  },
  {
    "id": "arXiv:2211.16865",
    "title": "Logic and Commonsense-Guided Temporal Knowledge Graph Completion",
    "abstract": "A temporal knowledge graph (TKG) stores the events derived from the data\ninvolving time. Predicting events is extremely challenging due to the\ntime-sensitive property of events. Besides, the previous TKG completion (TKGC)\napproaches cannot represent both the timeliness and the causality properties of\nevents, simultaneously. To address these challenges, we propose a Logic and\nCommonsense-Guided Embedding model (LCGE) to jointly learn the time-sensitive\nrepresentation involving timeliness and causality of events, together with the\ntime-independent representation of events from the perspective of commonsense.\nSpecifically, we design a temporal rule learning algorithm to construct a\nrule-guided predicate embedding regularization strategy for learning the\ncausality among events. Furthermore, we could accurately evaluate the\nplausibility of events via auxiliary commonsense knowledge. The experimental\nresults of TKGC task illustrate the significant performance improvements of our\nmodel compared with the existing approaches. More interestingly, our model is\nable to provide the explainability of the predicted results in the view of\ncausal inference. The source code and datasets of this paper are available at\nhttps://github.com/ngl567/LCGE.",
    "descriptor": "\nComments: The full version of a long paper accepted to AAAI 2023\n",
    "authors": [
      "Guanglin Niu",
      "Bo Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16865"
  },
  {
    "id": "arXiv:2211.16869",
    "title": "NeAF: Learning Neural Angle Fields for Point Normal Estimation",
    "abstract": "Normal estimation for unstructured point clouds is an important task in 3D\ncomputer vision. Current methods achieve encouraging results by mapping local\npatches to normal vectors or learning local surface fitting using neural\nnetworks. However, these methods are not generalized well to unseen scenarios\nand are sensitive to parameter settings. To resolve these issues, we propose an\nimplicit function to learn an angle field around the normal of each point in\nthe spherical coordinate system, which is dubbed as Neural Angle Fields (NeAF).\nInstead of directly predicting the normal of an input point, we predict the\nangle offset between the ground truth normal and a randomly sampled query\nnormal. This strategy pushes the network to observe more diverse samples, which\nleads to higher prediction accuracy in a more robust manner. To predict normals\nfrom the learned angle fields at inference time, we randomly sample query\nvectors in a unit spherical space and take the vectors with minimal angle\nvalues as the predicted normals. To further leverage the prior learned by NeAF,\nwe propose to refine the predicted normal vectors by minimizing the angle\noffsets. The experimental results with synthetic data and real scans show\nsignificant improvements over the state-of-the-art under widely used\nbenchmarks.",
    "descriptor": "\nComments: Accepted by AAAI 2023. Project page: this https URL Code:this https URL\n",
    "authors": [
      "Shujuan Li",
      "Junsheng Zhou",
      "Baorui Ma",
      "Yu-Shen Liu",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16869"
  },
  {
    "id": "arXiv:2211.16878",
    "title": "Transformers are Short Text Classifiers: A Study of Inductive Short Text  Classifiers on Benchmarks and Real-world Datasets",
    "abstract": "Short text classification is a crucial and challenging aspect of Natural\nLanguage Processing. For this reason, there are numerous highly specialized\nshort text classifiers. However, in recent short text research, State of the\nArt (SOTA) methods for traditional text classification, particularly the pure\nuse of Transformers, have been unexploited. In this work, we examine the\nperformance of a variety of short text classifiers as well as the top\nperforming traditional text classifier. We further investigate the effects on\ntwo new real-world short text datasets in an effort to address the issue of\nbecoming overly dependent on benchmark datasets with a limited number of\ncharacteristics. Our experiments unambiguously demonstrate that Transformers\nachieve SOTA accuracy on short text classification tasks, raising the question\nof whether specialized short text techniques are necessary.",
    "descriptor": "",
    "authors": [
      "Fabian Karl",
      "Ansgar Scherp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16878"
  },
  {
    "id": "arXiv:2211.16882",
    "title": "MVRackLay: Monocular Multi-View Layout Estimation for Warehouse Racks  and Shelves",
    "abstract": "In this paper, we propose and showcase, for the first time, monocular\nmulti-view layout estimation for warehouse racks and shelves. Unlike typical\nlayout estimation methods, MVRackLay estimates multi-layered layouts, wherein\neach layer corresponds to the layout of a shelf within a rack. Given a sequence\nof images of a warehouse scene, a dual-headed Convolutional-LSTM architecture\noutputs segmented racks, the front and the top view layout of each shelf within\na rack. With minimal effort, such an output is transformed into a 3D rendering\nof all racks, shelves and objects on the shelves, giving an accurate 3D\ndepiction of the entire warehouse scene in terms of racks, shelves and the\nnumber of objects on each shelf. MVRackLay generalizes to a diverse set of\nwarehouse scenes with varying number of objects on each shelf, number of\nshelves and in the presence of other such racks in the background. Further,\nMVRackLay shows superior performance vis-a-vis its single view counterpart,\nRackLay, in layout accuracy, quantized in terms of the mean IoU and mAP\nmetrics. We also showcase a multi-view stitching of the 3D layouts resulting in\na representation of the warehouse scene with respect to a global reference\nframe akin to a rendering of the scene from a SLAM pipeline. To the best of our\nknowledge, this is the first such work to portray a 3D rendering of a warehouse\nscene in terms of its semantic components - Racks, Shelves and Objects - all\nfrom a single monocular camera.",
    "descriptor": "",
    "authors": [
      "Pranjali Pathre",
      "Anurag Sahu",
      "Ashwin Rao",
      "Avinash Prabhu",
      "Meher Shashwat Nigam",
      "Tanvi Karandikar",
      "Harit Pandya",
      "K. Madhava Krishna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.16882"
  },
  {
    "id": "arXiv:2211.16883",
    "title": "X-PuDu at SemEval-2022 Task 6: Multilingual Learning for English and  Arabic Sarcasm Detection",
    "abstract": "Detecting sarcasm and verbal irony from people's subjective statements is\ncrucial to understanding their intended meanings and real sentiments and\npositions in social scenarios. This paper describes the X-PuDu system that\nparticipated in SemEval-2022 Task 6, iSarcasmEval - Intended Sarcasm Detection\nin English and Arabic, which aims at detecting intended sarcasm in various\nsettings of natural language understanding. Our solution finetunes pre-trained\nlanguage models, such as ERNIE-M and DeBERTa, under the multilingual settings\nto recognize the irony from Arabic and English texts. Our system ranked second\nout of 43, and ninth out of 32 in Task A: one-sentence detection in English and\nArabic; fifth out of 22 in Task B: binary multi-label classification in\nEnglish; first out of 16, and fifth out of 13 in Task C: sentence-pair\ndetection in English and Arabic.",
    "descriptor": "\nComments: SemEval-2022 Task 6\n",
    "authors": [
      "Yaqian Han",
      "Yekun Chai",
      "Shuohuan Wang",
      "Yu Sun",
      "Hongyi Huang",
      "Guanghao Chen",
      "Yitong Xu",
      "Yang Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16883"
  },
  {
    "id": "arXiv:2211.16884",
    "title": "Context-Aware Ensemble Learning for Time Series",
    "abstract": "We investigate ensemble methods for prediction in an online setting. Unlike\nall the literature in ensembling, for the first time, we introduce a new\napproach using a meta learner that effectively combines the base model\npredictions via using a superset of the features that is the union of the base\nmodels' feature vectors instead of the predictions themselves. Here, our model\ndoes not use the predictions of the base models as inputs to a machine learning\nalgorithm, but choose the best possible combination at each time step based on\nthe state of the problem. We explore three different constraint spaces for the\nensembling of the base learners that linearly combines the base predictions,\nwhich are convex combinations where the components of the ensembling vector are\nall nonnegative and sum up to 1; affine combinations where the weight vector\ncomponents are required to sum up to 1; and the unconstrained combinations\nwhere the components are free to take any real value. The constraints are both\ntheoretically analyzed under known statistics and integrated into the learning\nprocedure of the meta learner as a part of the optimization in an automated\nmanner. To show the practical efficiency of the proposed method, we employ a\ngradient-boosted decision tree and a multi-layer perceptron separately as the\nmeta learners. Our framework is generic so that one can use other machine\nlearning architectures as the ensembler as long as they allow for a custom\ndifferentiable loss for minimization. We demonstrate the learning behavior of\nour algorithm on synthetic data and the significant performance improvements\nover the conventional methods over various real life datasets, extensively used\nin the well-known data competitions. Furthermore, we openly share the source\ncode of the proposed method to facilitate further research and comparison.",
    "descriptor": "",
    "authors": [
      "Arda Fazla",
      "Mustafa Enes Aydin",
      "Orhun Tamyigit",
      "Suleyman Serdar Kozat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16884"
  },
  {
    "id": "arXiv:2211.16886",
    "title": "A Unifying Theory of Distance from Calibration",
    "abstract": "We study the fundamental question of how to define and measure the distance\nfrom calibration for probabilistic predictors. While the notion of perfect\ncalibration is well-understood, there is no consensus on how to quantify the\ndistance from perfect calibration. Numerous calibration measures have been\nproposed in the literature, but it is unclear how they compare to each other,\nand many popular measures such as Expected Calibration Error (ECE) fail to\nsatisfy basic properties like continuity.\nWe present a rigorous framework for analyzing calibration measures, inspired\nby the literature on property testing. We propose a ground-truth notion of\ndistance from calibration: the $\\ell_1$ distance to the nearest perfectly\ncalibrated predictor. We define a consistent calibration measure as one that is\na polynomial factor approximation to the this distance. Applying our framework,\nwe identify three calibration measures that are consistent and can be estimated\nefficiently: smooth calibration, interval calibration, and Laplace kernel\ncalibration. The former two give quadratic approximations to the ground truth\ndistance, which we show is information-theoretically optimal. Our work thus\nestablishes fundamental lower and upper bounds on measuring distance to\ncalibration, and also provides theoretical justification for preferring certain\nmetrics (like Laplace kernel calibration) in practice.",
    "descriptor": "",
    "authors": [
      "Jaros\u0142aw B\u0142asiok",
      "Parikshit Gopalan",
      "Lunjia Hu",
      "Preetum Nakkiran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16886"
  },
  {
    "id": "arXiv:2211.16887",
    "title": "T2G-Former: Organizing Tabular Features into Relation Graphs Promotes  Heterogeneous Feature Interaction",
    "abstract": "Recent development of deep neural networks (DNNs) for tabular learning has\nlargely benefited from the capability of DNNs for automatic feature\ninteraction. However, the heterogeneity nature of tabular features makes such\nfeatures relatively independent, and developing effective methods to promote\ntabular feature interaction still remains an open problem. In this paper, we\npropose a novel Graph Estimator, which automatically estimates the relations\namong tabular features and builds graphs by assigning edges between related\nfeatures. Such relation graphs organize independent tabular features into a\nkind of graph data such that interaction of nodes (tabular features) can be\nconducted in an orderly fashion. Based on our proposed Graph Estimator, we\npresent a bespoke Transformer network tailored for tabular learning, called\nT2G-Former, which processes tabular data by performing tabular feature\ninteraction guided by the relation graphs. A specific Cross-level Readout\ncollects salient features predicted by the layers in T2G-Former across\ndifferent levels, and attains global semantics for final prediction.\nComprehensive experiments show that our T2G-Former achieves superior\nperformance among DNNs and is competitive with non-deep Gradient Boosted\nDecision Tree models.",
    "descriptor": "\nComments: 13 pages, 3 figures\n",
    "authors": [
      "Jiahuan Yan",
      "Jintai Chen",
      "Yixuan Wu",
      "Danny Z. Chen",
      "Jian Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16887"
  },
  {
    "id": "arXiv:2211.16889",
    "title": "Generating Realistic Synthetic Relational Data through Graph Variational  Autoencoders",
    "abstract": "Synthetic data generation has recently gained widespread attention as a more\nreliable alternative to traditional data anonymization. The involved methods\nare originally developed for image synthesis. Hence, their application to the\ntypically tabular and relational datasets from healthcare, finance and other\nindustries is non-trivial. While substantial research has been devoted to the\ngeneration of realistic tabular datasets, the study of synthetic relational\ndatabases is still in its infancy. In this paper, we combine the variational\nautoencoder framework with graph neural networks to generate realistic\nsynthetic relational databases. We then apply the obtained method to two\npublicly available databases in computational experiments. The results indicate\nthat real databases' structures are accurately preserved in the resulting\nsynthetic datasets, even for large datasets with advanced data types.",
    "descriptor": "\nComments: 8 pages, 2 figures, 2 tables, Synthetic Data 4 ML workshop of the Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Ciro Antonio Mami",
      "Andrea Coser",
      "Eric Medvet",
      "Alexander T.P. Boudewijn",
      "Marco Volpe",
      "Michael Whitworth",
      "Borut Svara",
      "Gabriele Sgroi",
      "Daniele Panfilo",
      "Sebastiano Saccani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16889"
  },
  {
    "id": "arXiv:2211.16891",
    "title": "Quantitative Information Flow for Hardware: Advancing the Attack  Landscape",
    "abstract": "Security still remains an afterthought in modern Electronic Design Automation\n(EDA) tools, which solely focus on enhancing performance and reducing the chip\nsize. Typically, the security analysis is conducted by hand, leading to\nvulnerabilities in the design remaining unnoticed. Security-aware EDA tools\nassist the designer in the identification and removal of security threats while\nkeeping performance and area in mind. State-of-the-art approaches utilize\ninformation flow analysis to spot unintended information leakages in design\nstructures. However, the classification of such threats is binary, resulting in\nnegligible leakages being listed as well. A novel quantitative analysis allows\nthe application of a metric to determine a numeric value for a leakage.\nNonetheless, current approximations to quantify the leakage are still prone to\noverlooking leakages. The mathematical model 2D-QModel introduced in this work\naims to overcome this shortcoming. Additionally, as previous work only includes\na limited threat model, multiple threat models can be applied using the\nprovided approach. Open-source benchmarks are used to show the capabilities of\n2D-QModel to identify hardware Trojans in the design while ignoring\ninsignificant leakages.",
    "descriptor": "\nComments: 4 pages, accepted at IEEE Latin American Symposium on Circuits and Systems (LASCAS), 2023\n",
    "authors": [
      "Lennart M. Reimann",
      "Sarp Erd\u00f6nmez",
      "Dominik Sisejkovic",
      "Rainer Leupers"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.16891"
  },
  {
    "id": "arXiv:2211.16895",
    "title": "Self-Adaptive Digital Assistance Systems for Work 4.0",
    "abstract": "In the era of digital transformation, new technological foundations and\npossibilities for collaboration, production as well as organization open up\nmany opportunities to work differently in the future. The digitization of\nworkflows results in new forms of working which is denoted by the term Work\n4.0. In the context of Work 4.0, digital assistance systems play an important\nrole as they give users additional situation-specific information about a\nworkflow or a product via displays, mobile devices such as tablets and\nsmartphones, or data glasses. Furthermore, such digital assistance systems can\nbe used to provide instructions and technical support in the working process as\nwell as for training purposes. However, existing digital assistance systems are\nmostly created focusing on the \"design for all\" paradigm neglecting the\nsituation-specific tasks, skills, preferences, or environments of an individual\nhuman worker. To overcome this issue, we present a monitoring and adaptation\nframework for supporting self-adaptive digital assistance systems for Work 4.0.\nOur framework supports context monitoring as well as UI adaptation for\naugmented (AR) and virtual reality (VR)-based digital assistance systems. The\nbenefit of our framework is shown based on exemplary case studies from\ndifferent domains, e.g. context-aware maintenance application in AR or\nwarehouse management training in VR.",
    "descriptor": "\nComments: Preprint of our book chapter in: Digital Transformation: Core Technologies and Emerging Topics from a Computer Science Perspective, Springer-Vieweg, 2022\n",
    "authors": [
      "Enes Yigitbas",
      "Stefan Sauer",
      "Gregor Engels"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.16895"
  },
  {
    "id": "arXiv:2211.16897",
    "title": "Flux-mortar mixed finite element methods with multipoint flux  approximation",
    "abstract": "The flux-mortar mixed finite element method was recently developed for a\ngeneral class of domain decomposition saddle point problems on non-matching\ngrids. In this work we develop the method for Darcy flow using the multipoint\nflux approximation as the subdomain discretization. The subdomain problems\ninvolve solving positive definite cell-centered pressure systems. The normal\nflux on the subdomain interfaces is the mortar coupling variable, which plays\nthe role of a Lagrange multiplier to impose weakly continuity of pressure. We\npresent well-posedness and error analysis based on reformulating the method as\na mixed finite element method with a quadrature rule. We develop a\nnon-overlapping domain decomposition algorithm for the solution of the\nresulting algebraic system that reduces it to an interface problem for the\nflux-mortar, as well as an efficient interface preconditioner. A series of\nnumerical experiments is presented illustrating the performance of the method\non general grids, including applications to flow in complex porous media.",
    "descriptor": "",
    "authors": [
      "Wietse M. Boon",
      "Dennis Gl\u00e4ser",
      "Rainer Helmig",
      "Ivan Yotov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16897"
  },
  {
    "id": "arXiv:2211.16905",
    "title": "Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on  Disparity",
    "abstract": "Existing learning-based multi-view stereo (MVS) methods rely on the depth\nrange to build the 3D cost volume and may fail when the range is too large or\nunreliable. To address this problem, we propose a disparity-based MVS method\nbased on the epipolar disparity flow (E-flow), called DispMVS, which infers the\ndepth information from the pixel movement between two views. The core of\nDispMVS is to construct a 2D cost volume on the image plane along the epipolar\nline between each pair (between the reference image and several source images)\nfor pixel matching and fuse uncountable depths triangulated from each pair by\nmulti-view geometry to ensure multi-view consistency. To be robust, DispMVS\nstarts from a randomly initialized depth map and iteratively refines the depth\nmap with the help of the coarse-to-fine strategy. Experiments on DTUMVS and\nTanks\\&Temple datasets show that DispMVS is not sensitive to the depth range\nand achieves state-of-the-art results with lower GPU memory.",
    "descriptor": "\nComments: Accepted at the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI23)\n",
    "authors": [
      "Qingsong Yan",
      "Qiang Wang",
      "Kaiyong Zhao",
      "Bo Li",
      "Xiaowen Chu",
      "Fei Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16905"
  },
  {
    "id": "arXiv:2211.16908",
    "title": "Improved Smoothed Analysis of 2-Opt for the Euclidean TSP",
    "abstract": "The 2-opt heuristic is a simple local search heuristic for the Travelling\nSalesperson Problem (TSP). Although it usually performs well in practice, its\nworst-case running time is poor. Attempts to reconcile this difference have\nused smoothed analysis, in which adversarial instances are perturbed\nprobabilistically.\nWe are interested in the classical model of smoothed analysis for the\nEuclidean TSP, in which the perturbations are Gaussian. This model was\npreviously used by Manthey \\& Veenstra, who obtained smoothed complexity bounds\npolynomial in $n$, the dimension $d$, and the perturbation strength\n$\\sigma^{-1}$. However, their analysis only works for $d \\geq 4$. The only\nprevious analysis for $d \\leq 3$ was performed by Englert, R\\\"oglin \\&\nV\\\"ocking, who used a different perturbation model which can be translated to\nGaussian perturbations. Their model yields bounds polynomial in $n$ and\n$\\sigma^{-d}$, and super-exponential in $d$.\nAs no direct analysis existed for Gaussian perturbations that yields\npolynomial bounds for all $d$, we perform this missing analysis. Along the way,\nwe improve all existing smoothed complexity bounds for Euclidean 2-opt.",
    "descriptor": "\nComments: 32 pages, 5 figures\n",
    "authors": [
      "Bodo Manthey",
      "Jesse van Rhijn"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.16908"
  },
  {
    "id": "arXiv:2211.16912",
    "title": "Quadapter: Adapter for GPT-2 Quantization",
    "abstract": "Transformer language models such as GPT-2 are difficult to quantize because\nof outliers in activations leading to a large quantization error. To adapt to\nthe error, one must use quantization-aware training, which entails a\nfine-tuning process based on the dataset and the training pipeline identical to\nthose for the original model. Pretrained language models, however, often do not\ngrant access to their datasets and training pipelines, forcing us to rely on\narbitrary ones for fine-tuning. In that case, it is observed that\nquantization-aware training overfits the model to the fine-tuning data. For\nquantization without overfitting, we introduce a quantization adapter\n(Quadapter), a small set of parameters that are learned to make activations\nquantization-friendly by scaling them channel-wise. It keeps the model\nparameters unchanged. By applying our method to the challenging task of\nquantizing GPT-2, we demonstrate that it effectively prevents the overfitting\nand improves the quantization performance.",
    "descriptor": "",
    "authors": [
      "Minseop Park",
      "Jaeseong You",
      "Markus Nagel",
      "Simyung Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16912"
  },
  {
    "id": "arXiv:2211.16914",
    "title": "A Design Philosophy for Agents in the Smart Home",
    "abstract": "The home is often the most private space in people's lives, and not one in\nwhich they expect to be surveilled. However, today's market for smart home\ndevices has quickly evolved to include products that monitor, automate, and\npresent themselves as human. After documenting some of the more unusual\nemergent problems with contemporary devices, this body of work seeks to develop\na design philosophy for intelligent agents in the smart home that can act as an\nalternative to the ways that these devices are currently built. This is then\napplied to the design of privacy empowering technologies, representing the\nfirst steps from the devices of the present towards a more respectful future.",
    "descriptor": "",
    "authors": [
      "William Seymour"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.16914"
  },
  {
    "id": "arXiv:2211.16915",
    "title": "The Cost of Learning: Efficiency vs. Efficacy of Learning-Based RRM for  6G",
    "abstract": "In the past few years, Deep Reinforcement Learning (DRL) has become a\nvaluable solution to automatically learn efficient resource management\nstrategies in complex networks. In many scenarios, the learning task is\nperformed in the Cloud, while experience samples are generated directly by edge\nnodes or users. Therefore, the learning task involves some data exchange which,\nin turn, subtracts a certain amount of transmission resources from the system.\nThis creates a friction between the need to speed up convergence towards an\neffective strategy, which requires the allocation of resources to transmit\nlearning samples, and the need to maximize the amount of resources used for\ndata plane communication, maximizing users' Quality of Service (QoS), which\nrequires the learning process to be efficient, i.e., minimize its overhead. In\nthis paper, we investigate this trade-off and propose a dynamic balancing\nstrategy between the learning and data planes, which allows the centralized\nlearning agent to quickly converge to an efficient resource allocation strategy\nwhile minimizing the impact on QoS. Simulation results show that the proposed\nmethod outperforms static allocation methods, converging to the optimal policy\n(i.e., maximum efficacy and minimum overhead of the learning plane) in the long\nrun.",
    "descriptor": "",
    "authors": [
      "Seyyidahmed Lahmer",
      "Federico Chiariotti",
      "Andrea Zanella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.16915"
  },
  {
    "id": "arXiv:2211.16919",
    "title": "The Mood of the Sunlight: Visualization of the Sunlight Data for Public  Art",
    "abstract": "The application of data visualization in public art attracts increasing\nattention. In this paper, we present the design and implementation of a\nvisualization method for sunlight data collected over a long period of time.\nThe proposed method makes use of the Saturation and Value information of\ncollected sunlight data in Hue Saturation Value color space to show the\nvariation of the mood of the sunlight. Specifically, we create visual patterns\nwith two rotating gears, which has an intuitively consistent geometric meaning\nwith HSV color space and the planetary motion. Due to the variation of the\nsunlight data over time, the generated visual patter presents a periodic\nvariation that corresponds to the changing mood of the sunlight. Furthermore,\nwe also use the sunlight data to generate music as another form of data\nrepresentation. Two public art works have been created with the above\nvisualization and auralization methods and displayed on an exhibition.",
    "descriptor": "",
    "authors": [
      "Yifan Wang",
      "Nan Li",
      "Suxuan Jiang",
      "Jinlong Xu",
      "Qi Wang",
      "Shaomin Shen",
      "Ning Ding"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.16919"
  },
  {
    "id": "arXiv:2211.16922",
    "title": "Learning Motion-Robust Remote Photoplethysmography through Arbitrary  Resolution Videos",
    "abstract": "Remote photoplethysmography (rPPG) enables non-contact heart rate (HR)\nestimation from facial videos which gives significant convenience compared with\ntraditional contact-based measurements. In the real-world long-term health\nmonitoring scenario, the distance of the participants and their head movements\nusually vary by time, resulting in the inaccurate rPPG measurement due to the\nvarying face resolution and complex motion artifacts. Different from the\nprevious rPPG models designed for a constant distance between camera and\nparticipants, in this paper, we propose two plug-and-play blocks (i.e.,\nphysiological signal feature extraction block (PFE) and temporal face alignment\nblock (TFA)) to alleviate the degradation of changing distance and head motion.\nOn one side, guided with representative-area information, PFE adaptively\nencodes the arbitrary resolution facial frames to the fixed-resolution facial\nstructure features. On the other side, leveraging the estimated optical flow,\nTFA is able to counteract the rPPG signal confusion caused by the head movement\nthus benefit the motion-robust rPPG signal recovery. Besides, we also train the\nmodel with a cross-resolution constraint using a two-stream dual-resolution\nframework, which further helps PFE learn resolution-robust facial rPPG\nfeatures. Extensive experiments on three benchmark datasets (UBFC-rPPG, COHFACE\nand PURE) demonstrate the superior performance of the proposed method. One\nhighlight is that with PFE and TFA, the off-the-shelf spatio-temporal rPPG\nmodels can predict more robust rPPG signals under both varying face resolution\nand severe head movement scenarios. The codes are available at\nhttps://github.com/LJW-GIT/Arbitrary_Resolution_rPPG.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Jianwei Li",
      "Zitong Yu",
      "Jingang Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16922"
  },
  {
    "id": "arXiv:2211.16927",
    "title": "3D GAN Inversion with Facial Symmetry Prior",
    "abstract": "Recently, a surge of high-quality 3D-aware GANs have been proposed, which\nleverage the generative power of neural rendering. It is natural to associate\n3D GANs with GAN inversion methods to project a real image into the generator's\nlatent space, allowing free-view consistent synthesis and editing, referred as\n3D GAN inversion. Although with the facial prior preserved in pre-trained 3D\nGANs, reconstructing a 3D portrait with only one monocular image is still an\nill-pose problem. The straightforward application of 2D GAN inversion methods\nfocuses on texture similarity only while ignoring the correctness of 3D\ngeometry shapes. It may raise geometry collapse effects, especially when\nreconstructing a side face under an extreme pose. Besides, the synthetic\nresults in novel views are prone to be blurry. In this work, we propose a novel\nmethod to promote 3D GAN inversion by introducing facial symmetry prior. We\ndesign a pipeline and constraints to make full use of the pseudo auxiliary view\nobtained via image flipping, which helps obtain a robust and reasonable\ngeometry shape during the inversion process. To enhance texture fidelity in\nunobserved viewpoints, pseudo labels from depth-guided 3D warping can provide\nextra supervision. We design constraints aimed at filtering out conflict areas\nfor optimization in asymmetric situations. Comprehensive quantitative and\nqualitative evaluations on image reconstruction and editing demonstrate the\nsuperiority of our method.",
    "descriptor": "\nComments: Project Page is at this https URL\n",
    "authors": [
      "Fei Yin",
      "Yong Zhang",
      "Xuan Wang",
      "Tengfei Wang",
      "Xiaoyu Li",
      "Yuan Gong",
      "Yanbo Fan",
      "Xiaodong Cun",
      "Ying Shan",
      "Cengiz Oztireli",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16927"
  },
  {
    "id": "arXiv:2211.16934",
    "title": "VideoDubber: Machine Translation with Speech-Aware Length Control for  Video Dubbing",
    "abstract": "Video dubbing aims to translate the original speech in a film or television\nprogram into the speech in a target language, which can be achieved with a\ncascaded system consisting of speech recognition, machine translation and\nspeech synthesis. To ensure the translated speech to be well aligned with the\ncorresponding video, the length/duration of the translated speech should be as\nclose as possible to that of the original speech, which requires strict length\ncontrol. Previous works usually control the number of words or characters\ngenerated by the machine translation model to be similar to the source\nsentence, without considering the isochronicity of speech as the speech\nduration of words/characters in different languages varies. In this paper, we\npropose a machine translation system tailored for the task of video dubbing,\nwhich directly considers the speech duration of each token in translation, to\nmatch the length of source and target speech. Specifically, we control the\nspeech length of generated sentence by guiding the prediction of each word with\nthe duration information, including the speech duration of itself as well as\nhow much duration is left for the remaining words. We design experiments on\nfour language directions (German -> English, Spanish -> English, Chinese <->\nEnglish), and the results show that the proposed method achieves better length\ncontrol ability on the generated speech than baseline methods. To make up the\nlack of real-world datasets, we also construct a real-world test set collected\nfrom films to provide comprehensive evaluations on the video dubbing task.",
    "descriptor": "\nComments: AAAI 2023 camera version\n",
    "authors": [
      "Yihan Wu",
      "Junliang Guo",
      "Xu Tan",
      "Chen Zhang",
      "Bohan Li",
      "Ruihua Song",
      "Lei He",
      "Sheng Zhao",
      "Arul Menezes",
      "Jiang Bian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.16934"
  },
  {
    "id": "arXiv:2211.16938",
    "title": "Evaluating Digital Agriculture Recommendations with Causal Inference",
    "abstract": "In contrast to the rapid digitalization of several industries, agriculture\nsuffers from low adoption of smart farming tools. While AI-driven digital\nagriculture tools can offer high-performing predictive functionalities, they\nlack tangible quantitative evidence on their benefits to the farmers. Field\nexperiments can derive such evidence, but are often costly, time consuming and\nhence limited in scope and scale of application. To this end, we propose an\nobservational causal inference framework for the empirical evaluation of the\nimpact of digital tools on target farm performance indicators (e.g., yield in\nthis case). This way, we can increase farmers' trust via enhancing the\ntransparency of the digital agriculture market and accelerate the adoption of\ntechnologies that aim to secure farmer income resilience and global\nagricultural sustainability. As a case study, we designed and implemented a\nrecommendation system for the optimal sowing time of cotton based on numerical\nweather predictions, which was used by a farmers' cooperative during the\ngrowing season of 2021. We then leverage agricultural knowledge, collected\nyield data, and environmental information to develop a causal graph of the farm\nsystem. Using the back-door criterion, we identify the impact of sowing\nrecommendations on the yield and subsequently estimate it using linear\nregression, matching, inverse propensity score weighting and meta-learners. The\nresults reveal that a field sown according to our recommendations exhibited a\nstatistically significant yield increase that ranged from 12% to 17%, depending\non the method. The effect estimates were robust, as indicated by the agreement\namong the estimation methods and four successful refutation tests. We argue\nthat this approach can be implemented for decision support systems of other\nfields, extending their evaluation beyond a performance assessment of internal\nfunctionalities.",
    "descriptor": "\nComments: Accepted at AAAI'23, AI for Social Impact Track. arXiv admin note: substantial text overlap with arXiv:2211.03195\n",
    "authors": [
      "Ilias Tsoumas",
      "Georgios Giannarakis",
      "Vasileios Sitokonstantinou",
      "Alkiviadis Koukos",
      "Dimitra Loka",
      "Nikolaos Bartsotas",
      "Charalampos Kontoes",
      "Ioannis Athanasiadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16938"
  },
  {
    "id": "arXiv:2211.16940",
    "title": "DiffPose: Toward More Reliable 3D Pose Estimation",
    "abstract": "Monocular 3D human pose estimation is quite challenging due to the inherent\nambiguity and occlusion, which often lead to high uncertainty and\nindeterminacy. On the other hand, diffusion models have recently emerged as an\neffective tool for generating high-quality images from noise. Inspired by their\ncapability, we explore a novel pose estimation framework (DiffPose) that\nformulates 3D pose estimation as a reverse diffusion process. We incorporate\nnovel designs into our DiffPose that facilitate the diffusion process for 3D\npose estimation: a pose-specific initialization of pose uncertainty\ndistributions, a Gaussian Mixture Model-based forward diffusion process, and a\ncontext-conditioned reverse diffusion process. Our proposed DiffPose\nsignificantly outperforms existing methods on the widely used pose estimation\nbenchmarks Human3.6M and MPI-INF-3DHP.",
    "descriptor": "",
    "authors": [
      "Jia Gong",
      "Lin Geng Foo",
      "Zhipeng Fan",
      "Qiuhong Ke",
      "Hossein Rahmani",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16940"
  },
  {
    "id": "arXiv:2211.16942",
    "title": "ALARM: Active LeArning of Rowhammer Mitigations",
    "abstract": "Rowhammer is a serious security problem of contemporary dynamic random-access\nmemory (DRAM) where reads or writes of bits can flip other bits. DRAM\nmanufacturers add mitigations, but don't disclose details, making it difficult\nfor customers to evaluate their efficacy. We present a tool, based on active\nlearning, that automatically infers parameter of Rowhammer mitigations against\nsynthetic models of modern DRAM.",
    "descriptor": "",
    "authors": [
      "Amir Naseredini",
      "Martin Berger",
      "Matteo Sammartino",
      "Shale Xiong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16942"
  },
  {
    "id": "arXiv:2211.16944",
    "title": "AIONER: All-in-one scheme-based biomedical named entity recognition  using deep learning",
    "abstract": "Biomedical named entity recognition (BioNER) seeks to automatically recognize\nbiomedical entities in natural language text, serving as a necessary foundation\nfor downstream text mining tasks and applications such as information\nextraction and question answering. Manually labeling training data for the\nBioNER task is costly, however, due to the significant domain expertise\nrequired for accurate annotation. The resulting data scarcity causes current\nBioNER approaches to be prone to overfitting, to suffer from limited\ngeneralizability, and to address a single entity type at a time (e.g., gene or\ndisease). We therefore propose a novel all-in-one (AIO) scheme that uses\nexternal data from existing annotated resources to improve generalization. We\nfurther present AIONER, a general-purpose BioNER tool based on cutting-edge\ndeep learning and our AIO schema. We evaluate AIONER on 14 BioNER benchmark\ntasks and show that AIONER is effective, robust, and compares favorably to\nother state-of-the-art approaches such as multi-task learning. We further\ndemonstrate the practical utility of AIONER in three independent tasks to\nrecognize entity types not previously seen in training data, as well as the\nadvantages of AIONER over existing methods for processing biomedical text at a\nlarge scale (e.g., the entire PubMed data).",
    "descriptor": "",
    "authors": [
      "Ling Luo",
      "Chih-Hsuan Wei",
      "Po-Ting Lai",
      "Robert Leaman",
      "Qingyu Chen",
      "Zhiyong Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16944"
  },
  {
    "id": "arXiv:2211.16945",
    "title": "Federated Learning-Based Cell-Free Massive MIMO System for  Privacy-Preserving",
    "abstract": "Cell-free massive MIMO (CF mMIMO) is a promising next generation wireless\narchitecture to realize federated learning (FL). However, sensitive information\nof user equipments (UEs) may be exposed to the involved access points or the\ncentral processing unit in practice. To guarantee data privacy, effective\nprivacy-preserving mechanisms are defined in this paper. In particular, we\ndemonstrate and characterize the possibility in exploiting the inherent\nquantization error, caused by low-resolution analog-to-digital converters\n(ADCs) and digital-to-analog converters (DACs), for privacy-preserving in a FL\nCF mMIMO system. Furthermore, to reduce the required uplink training time in\nsuch a system, a stochastic non-convex design problem that jointly optimizing\nthe transmit power and the data rate is formulated. To address the problem at\nhand, we propose a novel power control method by utilizing the successive\nconvex approximation approach to obtain a suboptimal solution. Besides, an\nasynchronous protocol is established for mitigating the straggler effect to\nfacilitate FL. Numerical results show that compared with the conventional full\npower transmission, adopting the proposed power control method can effectively\nreduce the uplink training time under various practical system settings. Also,\nour results unveil that our proposed asynchronous approach can reduce the\nwaiting time at the central processing unit for receiving all user information,\nas there are no stragglers that requires a long time to report their local\nupdates.",
    "descriptor": "\nComments: 27 pages, 7 figures, to appear in IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Jiayi Zhang",
      "Jing Zhang",
      "Derrick Wing Kwan Ng",
      "Bo Ai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.16945"
  },
  {
    "id": "arXiv:2211.16947",
    "title": "Using Text Classification with a Bayesian Correction for Estimating  Overreporting in the Creditor Reporting System on Climate Adaptation Finance",
    "abstract": "Development funds are essential to finance climate change adaptation and are\nthus an important part of international climate policy. % However, the absence\nof a common reporting practice makes it difficult to assess the amount and\ndistribution of such funds. Research has questioned the credibility of reported\nfigures, indicating that adaptation financing is in fact lower than published\nfigures suggest. Projects claiming a greater relevance to climate change\nadaptation than they target are referred to as \"overreported\". To estimate\nrealistic rates of overreporting in large data sets over times, we propose an\napproach based on state-of-the-art text classification. To date, assessments of\ncredibility have relied on small, manually evaluated samples. We use such a\nsample data set to train a classifier with an accuracy of $89.81\\% \\pm 0.83\\%$\n(tenfold cross-validation) and extrapolate to larger data sets to identify\noverreporting. Additionally, we propose a method that incorporates evidence of\nsmaller, higher-quality data to correct predicted rates using Bayes' theorem.\nThis enables a comparison of different annotation schemes to estimate the\ndegree of overreporting in climate change adaptation. Our results support\nfindings that indicate extensive overreporting of $32.03\\%$ with a credible\ninterval of $[19.81\\%;48.34\\%]$.",
    "descriptor": "\nComments: 9+4 Pages, 3 figures, 4 tables\n",
    "authors": [
      "Janos Borst",
      "Thomas Wencker",
      "Andreas Niekler"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16947"
  },
  {
    "id": "arXiv:2211.16951",
    "title": "Weakly Supervised 3D Multi-person Pose Estimation for Large-scale Scenes  based on Monocular Camera and Single LiDAR",
    "abstract": "Depth estimation is usually ill-posed and ambiguous for monocular\ncamera-based 3D multi-person pose estimation. Since LiDAR can capture accurate\ndepth information in long-range scenes, it can benefit both the global\nlocalization of individuals and the 3D pose estimation by providing rich\ngeometry features. Motivated by this, we propose a monocular camera and single\nLiDAR-based method for 3D multi-person pose estimation in large-scale scenes,\nwhich is easy to deploy and insensitive to light. Specifically, we design an\neffective fusion strategy to take advantage of multi-modal input data,\nincluding images and point cloud, and make full use of temporal information to\nguide the network to learn natural and coherent human motions. Without relying\non any 3D pose annotations, our method exploits the inherent geometry\nconstraints of point cloud for self-supervision and utilizes 2D keypoints on\nimages for weak supervision. Extensive experiments on public datasets and our\nnewly collected dataset demonstrate the superiority and generalization\ncapability of our proposed method.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Peishan Cong",
      "Yiteng Xu",
      "Yiming Ren",
      "Juze Zhang",
      "Lan Xu",
      "Jingya Wang",
      "Jingyi Yu",
      "Yuexin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16951"
  },
  {
    "id": "arXiv:2211.16952",
    "title": "On the Design of Communication-Efficient Federated Learning for Health  Monitoring",
    "abstract": "With the booming deployment of Internet of Things, health monitoring\napplications have gradually prospered. Within the recent COVID-19 pandemic\nsituation, interest in permanent remote health monitoring solutions has raised,\ntargeting to reduce contact and preserve the limited medical resources. Among\nthe technological methods to realize efficient remote health monitoring,\nfederated learning (FL) has drawn particular attention due to its robustness in\npreserving data privacy. However, FL can yield to high communication costs, due\nto frequent transmissions between the FL server and clients. To tackle this\nproblem, we propose in this paper a communication-efficient federated learning\n(CEFL) framework that involves clients clustering and transfer learning. First,\nwe propose to group clients through the calculation of similarity factors,\nbased on the neural networks characteristics. Then, a representative client in\neach cluster is selected to be the leader of the cluster. Differently from the\nconventional FL, our method performs FL training only among the cluster\nleaders. Subsequently, transfer learning is adopted by the leader to update its\ncluster members with the trained FL model. Finally, each member fine-tunes the\nreceived model with its own data. To further reduce the communication costs, we\nopt for a partial-layer FL aggregation approach. This method suggests partially\nupdating the neural network model rather than fully. Through experiments, we\nshow that CEFL can save up to to 98.45% in communication costs while conceding\nless than 3% in accuracy loss, when compared to the conventional FL. Finally,\nCEFL demonstrates a high accuracy for clients with small or unbalanced\ndatasets.",
    "descriptor": "",
    "authors": [
      "Dong Chu",
      "Wael Jaafar",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.16952"
  },
  {
    "id": "arXiv:2211.16958",
    "title": "How to (virtually) train your sound source localizer",
    "abstract": "Learning-based methods have become ubiquitous in sound source localization\n(SSL). Existing systems rely on simulated training sets for the lack of\nsufficiently large, diverse and annotated real datasets. Most room acoustic\nsimulators used for this purpose rely on the image source method (ISM) because\nof its computational efficiency. This paper argues that carefully extending the\nISM to incorporate more realistic surface, source and microphone responses into\ntraining sets can significantly boost the real-world performance of SSL\nsystems. It is shown that increasing the training-set realism of a\nstate-of-the-art direction-of-arrival estimator yields consistent improvements\nacross three different real test sets featuring human speakers in a variety of\nrooms and various microphone arrays. An ablation study further reveals that\nevery added layer of realism contributes positively to these improvements.",
    "descriptor": "\nComments: Pre-Print\n",
    "authors": [
      "Prerak Srivastava",
      "Antoine Deleforge",
      "Archontis Politis",
      "Emmanuel Vincent"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.16958"
  },
  {
    "id": "arXiv:2211.16960",
    "title": "BASiS: Batch Aligned Spectral Embedding Space",
    "abstract": "Graph is a highly generic and diverse representation, suitable for almost any\ndata processing problem. Spectral graph theory has been shown to provide\npowerful algorithms, backed by solid linear algebra theory. It thus can be\nextremely instrumental to design deep network building blocks with spectral\ngraph characteristics. For instance, such a network allows the design of\noptimal graphs for certain tasks or obtaining a canonical orthogonal\nlow-dimensional embedding of the data. Recent attempts to solve this problem\nwere based on minimizing Rayleigh-quotient type losses. We propose a different\napproach of directly learning the eigensapce. A severe problem of the direct\napproach, applied in batch-learning, is the inconsistent mapping of features to\neigenspace coordinates in different batches. We analyze the degrees of freedom\nof learning this task using batches and propose a stable alignment mechanism\nthat can work both with batch changes and with graph-metric changes. We show\nthat our learnt spectral embedding is better in terms of NMI, ACC, Grassman\ndistance, orthogonality and classification accuracy, compared to SOTA. In\naddition, the learning is more stable.",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Or Streicher",
      "Ido Cohen",
      "Guy Gilboa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.16960"
  },
  {
    "id": "arXiv:2211.16961",
    "title": "Pattern Attention Transformer with Doughnut Kernel",
    "abstract": "We present in this paper a new architecture, the Pattern Attention\nTransformer (PAT), that is composed of the new doughnut kernel. Compared with\ntokens in the NLP field, Transformer in computer vision has the problem of\nhandling the high resolution of pixels in images. Inheriting the patch/window\nidea from ViT and its follow-ups, the doughnut kernel enhances the design of\npatches. It replaces the line-cut boundaries with two types of areas: sensor\nand updating, which is based on the comprehension of self-attention (named QKVA\ngrid). The doughnut kernel also brings a new topic about the shape of kernels.\nTo verify its performance on image classification, PAT is designed with\nTransformer blocks of regular octagon shape doughnut kernels. Its performance\non ImageNet 1K surpasses the Swin Transformer (+0.7 acc1).",
    "descriptor": "",
    "authors": [
      "WenYuan Sheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16961"
  },
  {
    "id": "arXiv:2211.16963",
    "title": "Rendezvous in Time: An Attention-based Temporal Fusion approach for  Surgical Triplet Recognition",
    "abstract": "One of the recent advances in surgical AI is the recognition of surgical\nactivities as triplets of (instrument, verb, target). Albeit providing detailed\ninformation for computer-assisted intervention, current triplet recognition\napproaches rely only on single frame features. Exploiting the temporal cues\nfrom earlier frames would improve the recognition of surgical action triplets\nfrom videos. In this paper, we propose Rendezvous in Time (RiT) - a deep\nlearning model that extends the state-of-the-art model, Rendezvous, with\ntemporal modeling. Focusing more on the verbs, our RiT explores the\nconnectedness of current and past frames to learn temporal attention-based\nfeatures for enhanced triplet recognition. We validate our proposal on the\nchallenging surgical triplet dataset, CholecT45, demonstrating an improved\nrecognition of the verb and triplet along with other interactions involving the\nverb such as (instrument, verb). Qualitative results show that the RiT produces\nsmoother predictions for most triplet instances than the state-of-the-arts. We\npresent a novel attention-based approach that leverages the temporal fusion of\nvideo frames to model the evolution of surgical actions and exploit their\nbenefits for surgical triplet recognition.",
    "descriptor": "\nComments: 9 pages, 2 figures, 7 tables\n",
    "authors": [
      "Saurav Sharma",
      "Chinedu Innocent Nwoye",
      "Didier Mutter",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16963"
  },
  {
    "id": "arXiv:2211.16965",
    "title": "Federated deep clustering with GAN-based data synthesis",
    "abstract": "Clustering has been extensively studied in centralized settings, but\nrelatively unexplored in federated ones that data are distributed among\nmultiple clients and can only be kept local at the clients. The necessity to\ninvest more resources in improving federated clustering methods is twofold: 1)\nThe performance of supervised federated learning models can benefit from\nclustering. 2) It is non-trivial to extend centralized ones to perform\nfederated clustering tasks. In centralized settings, various deep clustering\nmethods that perform dimensionality reduction and clustering jointly have\nachieved great success. To obtain high-quality cluster information, it is\nnatural but non-trivial to extend these methods to federated settings. For this\npurpose, we propose a simple but effective federated deep clustering method. It\nrequires only one communication round between the central server and clients,\ncan run asynchronously, and can handle device failures. Moreover, although most\nstudies have highlighted adverse effects of the non-independent and identically\ndistributed (non-IID) data across clients, experimental results indicate that\nthe proposed method can significantly benefit from this scenario.",
    "descriptor": "",
    "authors": [
      "Jie Yan",
      "Jing Liu",
      "Ji Qi",
      "Zhong-Yuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16965"
  },
  {
    "id": "arXiv:2211.16971",
    "title": "A Pipeline for Generating, Annotating and Employing Synthetic Data for  Real World Question Answering",
    "abstract": "Question Answering (QA) is a growing area of research, often used to\nfacilitate the extraction of information from within documents.\nState-of-the-art QA models are usually pre-trained on domain-general corpora\nlike Wikipedia and thus tend to struggle on out-of-domain documents without\nfine-tuning. We demonstrate that synthetic domain-specific datasets can be\ngenerated easily using domain-general models, while still providing significant\nimprovements to QA performance. We present two new tools for this task: A\nflexible pipeline for validating the synthetic QA data and training downstream\nmodels on it, and an online interface to facilitate human annotation of this\ngenerated data. Using this interface, crowdworkers labelled 1117 synthetic QA\npairs, which we then used to fine-tune downstream models and improve\ndomain-specific QA performance by 8.75 F1.",
    "descriptor": "\nComments: To be published in the companion proceedings of EMNLP 2022. 17 pages (11 of which are in the appendix), 7 figures (3 of which are in the appendix)\n",
    "authors": [
      "Matthew Maufe",
      "James Ravenscroft",
      "Rob Procter",
      "Maria Liakata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16971"
  },
  {
    "id": "arXiv:2211.16978",
    "title": "Combining Neuro-Evolution of Augmenting Topologies with Convolutional  Neural Networks",
    "abstract": "Current deep convolutional networks are fixed in their topology. We explore\nthe possibilites of making the convolutional topology a parameter itself by\ncombining NeuroEvolution of Augmenting Topologies (NEAT) with Convolutional\nNeural Networks (CNNs) and propose such a system using blocks of Residual\nNetworks (ResNets). We then explain how our suggested system can only be built\nonce additional optimizations have been made, as genetic algorithms are way\nmore demanding than training per backpropagation. On the way there we explain\nmost of those buzzwords and offer a gentle and brief introduction to the most\nimportant modern areas of machine learning",
    "descriptor": "\nComments: Unpublished\n",
    "authors": [
      "Jan Hohenheim",
      "Mathias Fischler",
      "Sara Zarubica",
      "Jeremy Stucki"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16978"
  },
  {
    "id": "arXiv:2211.16980",
    "title": "Infinite-width limit of deep linear neural networks",
    "abstract": "This paper studies the infinite-width limit of deep linear neural networks\ninitialized with random parameters. We obtain that, when the number of neurons\ndiverges, the training dynamics converge (in a precise sense) to the dynamics\nobtained from a gradient descent on an infinitely wide deterministic linear\nneural network. Moreover, even if the weights remain random, we get their\nprecise law along the training dynamics, and prove a quantitative convergence\nresult of the linear predictor in terms of the number of neurons.\nWe finally study the continuous-time limit obtained for infinitely wide\nlinear neural networks and show that the linear predictors of the neural\nnetwork converge at an exponential rate to the minimal $\\ell_2$-norm minimizer\nof the risk.",
    "descriptor": "",
    "authors": [
      "L\u00e9na\u00efc Chizat",
      "Maria Colombo",
      "Xavier Fern\u00e1ndez-Real",
      "Alessio Figalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16980"
  },
  {
    "id": "arXiv:2211.16986",
    "title": "A Geometric Model for Polarization Imaging on Projective Cameras",
    "abstract": "The vast majority of Shape-from-Polarization (SfP) methods work under the\noversimplified assumption of using orthographic cameras. Indeed, it is still\nnot well understood how to project the Stokes vectors when the incoming rays\nare not orthogonal to the image plane. We try to answer this question\npresenting a geometric model describing how a general projective camera\ncaptures the light polarization state. Based on the optical properties of a\ntilted polarizer, our model is implemented as a pre-processing operation acting\non raw images, followed by a per-pixel rotation of the reconstructed normal\nfield. In this way, all the existing SfP methods assuming orthographic cameras\ncan behave like they were designed for projective ones. Moreover, our model is\nconsistent with state-of-the-art forward and inverse renderers (like Mitsuba3\nand ART), intrinsically enforces physical constraints among the captured\nchannels, and handles demosaicing of DoFP sensors. Experiments on existing and\nnew datasets demonstrate the accuracy of the model when applied to commercially\navailable polarimetric cameras.",
    "descriptor": "",
    "authors": [
      "Mara Pistellato",
      "Filippo Bergamasco"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16986"
  },
  {
    "id": "arXiv:2211.16987",
    "title": "Secure Software Development Methodologies: A Multivocal Literature  Review",
    "abstract": "In recent years, the number of cyber attacks has grown rapidly. An effective\nway to reduce the attack surface and protect software is adoption of\nmethodologies that apply security at each step of the software development\nlifecycle. While different methodologies have been proposed to address software\nsecurity, recent research shows an increase in the number of vulnerabilities in\nsoftware and data breaches. Therefore, the security practices incorporated in\nsecure software development methodologies require investigation. This paper\nprovides an overview of security practices involved in 28 secure software\ndevelopment methodologies from industry, government, and academia. To achieve\nthis goal, we distributed the security practices among the software development\nlifecycle stages. We also investigated auxiliary (non-technical) practices,\nsuch as organizational, behavioral, legal, policy, and governance aspects that\nare incorporated in the secure software development methodologies. Furthermore,\nwe explored methods used to provide evidence of the effectiveness of the\nmethodologies. Finally, we present the gaps that require attention in the\nscientific community. The results of our survey may assist researchers and\norganizations to better understand the existing security practices integrated\ninto the secure software development methodologies. In addition, our bridge\nbetween \"technical\" and \"non-technical\" worlds may be useful for non-technical\nspecialists who investigate software security. Moreover, exploring the gaps\nthat we found in current research may help improve security in software\ndevelopment and produce software with fewer number of vulnerabilities.",
    "descriptor": "\nComments: 27 pages, 2 figures\n",
    "authors": [
      "Arina Kudriavtseva",
      "Olga Gadyatskaya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.16987"
  },
  {
    "id": "arXiv:2211.16988",
    "title": "QuadFormer: Quadruple Transformer for Unsupervised Domain Adaptation in  Power Line Segmentation of Aerial Images",
    "abstract": "Accurate segmentation of power lines in aerial images is essential to ensure\nthe flight safety of aerial vehicles. Acquiring high-quality ground truth\nannotations for training a deep learning model is a laborious process.\nTherefore, developing algorithms that can leverage knowledge from labelled\nsynthetic data to unlabelled real images is highly demanded. This process is\nstudied in Unsupervised domain adaptation (UDA). Recent approaches to\nself-training have achieved remarkable performance in UDA for semantic\nsegmentation, which trains a model with pseudo labels on the target domain.\nHowever, the pseudo labels are noisy due to a discrepancy in the two data\ndistributions. We identify that context dependency is important for bridging\nthis domain gap. Motivated by this, we propose QuadFormer, a novel framework\ndesigned for domain adaptive semantic segmentation. The hierarchical quadruple\ntransformer combines cross-attention and self-attention mechanisms to adapt\ntransferable context. Based on cross-attentive and self-attentive feature\nrepresentations, we introduce a pseudo label correction scheme to online\ndenoise the pseudo labels and reduce the domain gap. Additionally, we present\ntwo datasets - ARPLSyn and ARPLReal to further advance research in unsupervised\ndomain adaptive powerline segmentation. Finally, experimental results indicate\nthat our method achieves state-of-the-art performance for the domain adaptive\npower line segmentation on ARPLSyn$\\rightarrow$TTTPLA and\nARPLSyn$\\rightarrow$ARPLReal.",
    "descriptor": "",
    "authors": [
      "Pratyaksh Prabhav Rao",
      "Feng Qiao",
      "Weide Zhang",
      "Yiliang Xu",
      "Yong Deng",
      "Guangbin Wu",
      "Qiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16988"
  },
  {
    "id": "arXiv:2211.16989",
    "title": "Wearing the Same Outfit in Different Ways -- A Controllable Virtual  Try-on Method",
    "abstract": "An outfit visualization method generates an image of a person wearing real\ngarments from images of those garments. Current methods can produce images that\nlook realistic and preserve garment identity, captured in details such as\ncollar, cuffs, texture, hem, and sleeve length. However, no current method can\nboth control how the garment is worn -- including tuck or untuck, opened or\nclosed, high or low on the waist, etc.. -- and generate realistic images that\naccurately preserve the properties of the original garment. We describe an\noutfit visualization method that controls drape while preserving garment\nidentity. Our system allows instance independent editing of garment drape,\nwhich means a user can construct an edit (e.g. tucking a shirt in a specific\nway) that can be applied to all shirts in a garment collection. Garment detail\nis preserved by relying on a warping procedure to place the garment on the body\nand a generator then supplies fine shading detail. To achieve instance\nindependent control, we use control points with garment category-level\nsemantics to guide the warp. The method produces state-of-the-art quality\nimages, while allowing creative ways to style garments, including allowing tops\nto be tucked or untucked; jackets to be worn open or closed; skirts to be worn\nhigher or lower on the waist; and so on. The method allows interactive control\nto correct errors in individual renderings too. Because the edits are instance\nindependent, they can be applied to large pools of garments automatically and\ncan be conditioned on garment metadata (e.g. all cropped jackets are worn\nclosed or all bomber jackets are worn closed).",
    "descriptor": "",
    "authors": [
      "Kedan Li",
      "Jeffrey Zhang",
      "Shao-Yu Chang",
      "David Forsyth"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16989"
  },
  {
    "id": "arXiv:2211.16991",
    "title": "SparsePose: Sparse-View Camera Pose Regression and Refinement",
    "abstract": "Camera pose estimation is a key step in standard 3D reconstruction pipelines\nthat operate on a dense set of images of a single object or scene. However,\nmethods for pose estimation often fail when only a few images are available\nbecause they rely on the ability to robustly identify and match visual features\nbetween image pairs. While these methods can work robustly with dense camera\nviews, capturing a large set of images can be time-consuming or impractical. We\npropose SparsePose for recovering accurate camera poses given a sparse set of\nwide-baseline images (fewer than 10). The method learns to regress initial\ncamera poses and then iteratively refine them after training on a large-scale\ndataset of objects (Co3D: Common Objects in 3D). SparsePose significantly\noutperforms conventional and learning-based baselines in recovering accurate\ncamera rotations and translations. We also demonstrate our pipeline for\nhigh-fidelity 3D reconstruction using only 5-9 images of an object.",
    "descriptor": "",
    "authors": [
      "Samarth Sinha",
      "Jason Y. Zhang",
      "Andrea Tagliasacchi",
      "Igor Gilitschenski",
      "David B. Lindell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16991"
  },
  {
    "id": "arXiv:2211.16993",
    "title": "Post-Quantum $\u03ba$-to-1 Trapdoor Claw-free Functions from  Extrapolated Dihedral Cosets",
    "abstract": "Noisy Trapdoor Claw-free functions (NTCF) as powerful post-quantum\ncryptographic tools can efficiently constrain actions of untrusted quantum\ndevices. Recently, Brakerski et al. at FOCS 2018 showed a remarkable use of\nNTCF for a classically verifiable proof of quantumness and also derived a\nprotocol for cryptographically certifiable quantum randomness generation.\nHowever, the original NTCF used in their work is essentially 2-to-1 one-way\nfunction, namely NTCF$^1_2$, which greatly limits the rate of randomness\ngeneration.\nIn this work, we attempt to further extend the NTCF$^1_2$ to achieve a\n$\\kappa$-to-1 function with poly-bounded preimage size. Specifically, we focus\non a significant extrapolation of NTCF$^1_2$ by drawing on extrapolated\ndihedral cosets, giving a model of NTCF$^1_{\\kappa}$ with $\\kappa = poly(n)$.\nThen, we present an efficient construction of NTCF$^1_{\\kappa}$ under the\nwell-known quantum hardness of the Learning with Errors (QLWE) assumption. As a\nbyproduct, our work manifests an interesting connection between the NTCF$^1_2$\n(resp. NTCF$^1_{\\kappa}$) and the Dihedral Coset States (resp. Extrapolated\nDihedral Coset States). Finally, we give a similar interactive protocol for\nproving quantumness from the NTCF$^1_{\\kappa}$.",
    "descriptor": "",
    "authors": [
      "Xingyu Yan",
      "Licheng Wang",
      "Weiqiang Wen",
      "Ziyi Li",
      "Jingwen Suo",
      "Lize Gu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Complexity (cs.CC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.16993"
  },
  {
    "id": "arXiv:2211.16999",
    "title": "Continuous Methods : Adaptively intrusive reduced order model closure",
    "abstract": "Reduced order modeling methods are often used as a mean to reduce simulation\ncosts in industrial applications. Despite their computational advantages,\nreduced order models (ROMs) often fail to accurately reproduce complex dynamics\nencountered in real life applications. To address this challenge, we leverage\nNeuralODEs to propose a novel ROM correction approach based on a\ntime-continuous memory formulation. Finally, experimental results show that our\nproposed method provides a high level of accuracy while retaining the low\ncomputational costs inherent to reduced models.",
    "descriptor": "",
    "authors": [
      "Emmanuel Menier",
      "Michele Alessandro Bucci",
      "Mouadh Yagoubi",
      "Lionel Mathelin",
      "Thibault Dairay",
      "Raphael Meunier",
      "Marc Schoenauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Classical Physics (physics.class-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.16999"
  },
  {
    "id": "arXiv:2211.17010",
    "title": "Carbon Emission Prediction on the World Bank Dataset for Canada",
    "abstract": "The continuous rise in CO2 emission into the environment is one of the most\ncrucial issues facing the whole world. Many countries are making crucial\ndecisions to control their carbon footprints to escape some of their\ncatastrophic outcomes. There has been a lot of research going on to project the\namount of carbon emissions in the future, which can help us to develop\ninnovative techniques to deal with it in advance. Machine learning is one of\nthe most advanced and efficient techniques for predicting the amount of carbon\nemissions from current data. This paper provides the methods for predicting\ncarbon emissions (CO2 emissions) for the next few years. The predictions are\nbased on data from the past 50 years. The dataset, which is used for making the\nprediction, is collected from World Bank datasets. This dataset contains CO2\nemissions (metric tons per capita) of all the countries from 1960 to 2018. Our\nmethod consists of using machine learning techniques to take the idea of what\ncarbon emission measures will look like in the next ten years and project them\nonto the dataset taken from the World Bank's data repository. The purpose of\nthis research is to compare how different machine learning models (Decision\nTree, Linear Regression, Random Forest, and Support Vector Machine) perform on\na similar dataset and measure the difference between their predictions.",
    "descriptor": "\nComments: Submitted to Annals of Data Science, 2022 - Springer\n",
    "authors": [
      "Aman Desai",
      "Shyamal Gandhi",
      "Sachin Gupta",
      "Manan Shah",
      "Samir Patel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.17010"
  },
  {
    "id": "arXiv:2211.17011",
    "title": "Space-time approximation of local strong solutions to the 3D stochastic  Navier-Stokes equations",
    "abstract": "We consider the 3D stochastic Navier-Stokes equation on the torus. Our main\nresult concerns the temporal and spatio-temporal discretisation of a local\nstrong pathwise solution. We prove optimal convergence rates in for the energy\nerror with respect to convergence in probability, that is convergence of order\n1 in space and of order (up to) 1/2 in time. The result holds up to the\npossible blow-up of the (time-discrete) solution. Our approach is based on\ndiscrete stopping times for the (time-discrete) solution.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2109.06495\n",
    "authors": [
      "Dominic Breit",
      "Alan Dodgson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.17011"
  },
  {
    "id": "arXiv:2211.17012",
    "title": "Correlation of the importances of neural network weights calculated by  modern methods of overcoming catastrophic forgetting",
    "abstract": "Following the invention in 2017 of the EWC method, several methods have been\nproposed to calculate the importance of neural network weights for use in the\nEWC method. Despite the significant difference in calculating the importance of\nweights, they all proved to be effective. Accordingly, a reasonable question\narises as to how similar the importances of the weights calculated by different\nmethods. To answer this question, we calculated layer-by-layer correlations of\nthe importance of weights calculated by all those methods. As a result, it\nturned out that the importances of several of the methods correlated with each\nother quite strongly and we were able to present an explanation for such a\ncorrelation. At the same time, for other methods, the correlation can vary from\nstrong on some layers of the network to negative on other layers. Which raises\na reasonable question: why, despite the very different calculation methods, all\nthose importances allow EWC method to overcome the catastrophic forgetting of\nneural networks perfectly?",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Alexey Kutalev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17012"
  },
  {
    "id": "arXiv:2211.17013",
    "title": "Climate Change Policy Exploration using Reinforcement Learning",
    "abstract": "Climate Change is an incredibly complicated problem that humanity faces. When\nmany variables interact with each other, it can be difficult for humans to\ngrasp the causes and effects of the very large-scale problem of climate change.\nThe climate is a dynamical system, where small changes can have considerable\nand unpredictable repercussions in the long term. Understanding how to nudge\nthis system in the right ways could help us find creative solutions to climate\nchange.\nIn this research, we combine Deep Reinforcement Learning and a World-Earth\nsystem model to find, and explain, creative strategies to a sustainable future.\nThis is an extension of the work from Strnad et al. where we extend on the\nmethod and analysis, by taking multiple directions. We use four different\nReinforcement Learning agents varying in complexity to probe the environment in\ndifferent ways and to find various strategies. The environment is a\nlow-complexity World Earth system model where the goal is to reach a future\nwhere all the energy for the economy is produced by renewables by enacting\ndifferent policies. We use a reward function based on planetary boundaries that\nwe modify to force the agents to find a wider range of strategies. To favour\napplicability, we slightly modify the environment, by injecting noise and\nmaking it fully observable, to understand the impacts of these factors on the\nlearning of the agents.",
    "descriptor": "\nComments: 76 pages\n",
    "authors": [
      "Theodore Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17013"
  },
  {
    "id": "arXiv:2211.17014",
    "title": "An Interpretable Hybrid Predictive Model of COVID-19 Cases using  Autoregressive Model and LSTM",
    "abstract": "The Coronavirus Disease 2019 (COVID-19) has posed a severe threat to global\nhuman health and economic. It is an urgent task to build reliable data-driven\nprediction models for Covid 19 cases to improve public policy making. However,\nCOVID-19 data shows special transmission characteristics such as significant\nfluctuations and non-stationarity, which may be difficult to be captured by a\nsingle predictive model and poses grand challenges in effective forecasting. In\nthis paper, we proposed a novel Hybrid data-driven model combining\nAutoregressive model (AR) and long short-term memory neural networks (LSTM). It\ncan be viewed as a new neural network model and the contribution of AR and LSTM\nis auto tuned in the training procedure. We conduct extensive numerical\nexperiments on data collected from 8 counties of California that display\nvarious trends. The numerical results show the Hybrid model' advantages over AR\nand LSTM by its predictive powers. We show that the Hybrid model achieved\n4.195\\% MAPE, outperformed the AR 5.629\\% and LSTM 5.070\\% on average, and\nprovide a discussion on interpretability.",
    "descriptor": "",
    "authors": [
      "Yangyi Zhang",
      "Sui Tang",
      "Guo Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.17014"
  },
  {
    "id": "arXiv:2211.17015",
    "title": "Explaining automated gender classification of human gait",
    "abstract": "State-of-the-art machine learning (ML) models are highly effective in\nclassifying gait analysis data, however, they lack in providing explanations\nfor their predictions. This \"black-box\" characteristic makes it impossible to\nunderstand on which input patterns, ML models base their predictions. The\npresent study investigates whether Explainable Artificial Intelligence methods,\ni.e., Layer-wise Relevance Propagation (LRP), can be useful to enhance the\nexplainability of ML predictions in gait classification. The research question\nwas: Which input patterns are most relevant for an automated gender\nclassification model and do they correspond to characteristics identified in\nthe literature? We utilized a subset of the GAITREC dataset containing five\nbilateral ground reaction force (GRF) recordings per person during barefoot\nwalking of 62 healthy participants: 34 females and 28 males. Each input signal\n(right and left side) was min-max normalized before concatenation and fed into\na multi-layer Convolutional Neural Network (CNN). The classification accuracy\nwas obtained over a stratified ten-fold cross-validation. To identify\ngender-specific patterns, the input relevance scores were derived using LRP.\nThe mean classification accuracy of the CNN with 83.3% showed a clear\nsuperiority over the zero-rule baseline of 54.8%.",
    "descriptor": "\nComments: 3 pages, 1 figure\n",
    "authors": [
      "Fabian Horst",
      "Djordje Slijepcevic",
      "Matthias Zeppelzauer",
      "Anna-Maria Raberger",
      "Sebastian Lapuschkin",
      "Wojciech Samek",
      "Wolfgang I. Sch\u00f6llhorn",
      "Christian Breiteneder",
      "Brian Horsak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17015"
  },
  {
    "id": "arXiv:2211.17016",
    "title": "Explaining machine learning models for age classification in human gait  analysis",
    "abstract": "Machine learning (ML) models have proven effective in classifying gait\nanalysis data, e.g., binary classification of young vs. older adults. ML\nmodels, however, lack in providing human understandable explanations for their\npredictions. This \"black-box\" behavior impedes the understanding of which input\nfeatures the model predictions are based on. We investigated an Explainable\nArtificial Intelligence method, i.e., Layer-wise Relevance Propagation (LRP),\nfor gait analysis data. The research question was: Which input features are\nused by ML models to classify age-related differences in walking patterns? We\nutilized a subset of the AIST Gait Database 2019 containing five bilateral\nground reaction force (GRF) recordings per person during barefoot walking of\nhealthy participants. Each input signal was min-max normalized before\nconcatenation and fed into a Convolutional Neural Network (CNN). Participants\nwere divided into three age groups: young (20-39 years), middle-aged (40-64\nyears), and older (65-79 years) adults. The classification accuracy and\nrelevance scores (derived using LRP) were averaged over a stratified ten-fold\ncross-validation. The mean classification accuracy of 60.1% was clearly higher\nthan the zero-rule baseline of 37.3%. The confusion matrix shows that the CNN\ndistinguished younger and older adults well, but had difficulty modeling the\nmiddle-aged adults.",
    "descriptor": "\nComments: 3 pages, 1 figure\n",
    "authors": [
      "Djordje Slijepcevic",
      "Fabian Horst",
      "Marvin Simak",
      "Sebastian Lapuschkin",
      "Anna-Maria Raberger",
      "Wojciech Samek",
      "Christian Breiteneder",
      "Wolfgang I. Sch\u00f6llhorn",
      "Matthias Zeppelzauer",
      "Brian Horsak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17016"
  },
  {
    "id": "arXiv:2211.17017",
    "title": "Integrating wind variability to modelling wind-ramp events using a  non-binary ramp function and deep learning models",
    "abstract": "The forecasting of large ramps in wind power output known as ramp events is\ncrucial for the incorporation of large volumes of wind energy into national\nelectricity grids. Large variations in wind power supply must be compensated by\nancillary energy sources which can include the use of fossil fuels. Improved\nprediction of wind power will help to reduce dependency on supplemental energy\nsources along with their associated costs and emissions. In this paper, we\ndiscuss limitations of current predictive practices and explore the use of\nMachine Learning methods to enhance wind ramp event classification and\nprediction. We additionally outline a design for a novel approach to wind ramp\nprediction, in which high-resolution wind fields are incorporated to the\nmodelling of wind power.",
    "descriptor": "\nComments: International Conference for Sustainable Ecological Engineering Design for Society (SEEDS 2022)\n",
    "authors": [
      "Russell Sharp",
      "Hisham Ihshaish",
      "J. Ignacio Deza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17017"
  },
  {
    "id": "arXiv:2211.17019",
    "title": "Real time QKD Post Processing based on Reconfigurable Hardware  Acceleration",
    "abstract": "Key Distillation is an essential component of every Quantum Key Distribution\nsystem because it compensates the inherent transmission errors of quantum\nchannel. However, throughput and interoperability aspects of post-processing\nengine design often neglected, and exiting solutions are not providing any\nguarantee. In this paper, we propose multiple protocol support high throughput\nkey distillation framework implemented in a Field Programmable Gate Array\n(FPGA) using High-Level Synthesis (HLS). The proposed design uses a Hadoop\nframework with a map-reduce programming model to efficiently process large\nchunks of raw data across the limited computing resources of an FPGA. We\npresent a novel hardware-efficient integrated post-processing architecture that\noffer dynamic error correction, a side-channel resistant authentication scheme,\nand an inbuilt high-speed encryption application, which uses the key for secure\ncommunication. We develop a semi automated High level synthesis framework\ncapable of handling different QKD protocols with promising speedup. Overall,\nthe experimental results shows that there is a significant improvement in\nperformance and compatible with any discrete variable QKD systems.",
    "descriptor": "",
    "authors": [
      "Foram P Shingala",
      "Natarajan Venkatachalam",
      "Selvagangai C",
      "Hema Priya S",
      "Dillibabu S",
      "Pooja Chandravanshi",
      "Ravindra P. Singh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.17019"
  },
  {
    "id": "arXiv:2211.17022",
    "title": "Design and Verification of a Novel Triphibian Platform",
    "abstract": "Multi-modal robots expand their operations from one working media to another,\nland to air for example. The majorities multi-modal robots mainly refer to\nplatforms that operate in two different media. However, for all-terrain tasks,\nthere is seldom research to date in the literature. In this paper, we proposed\na triphibian robotic platform aiming at solving the challenges of different\npropulsion systems and immensely varied working media. In our design, three\nducted fans are adopted to unify the propulsion system and provide the robot\nwith driving forces to perform all-terrain operations. A morphable mechanism is\ndesigned to enable the transition between different motion modes, and\nspecifically, a cylindrical body is implemented as the rolling mechanism in\nland mode. Detailed design principles of different mechanisms and the\ntransition between various locomotion modes are analyzed in detail. Finally, a\ntriphibian robot prototype is fabricated and tested in various working media\nwith mono-modal and multi-modal functionalities. Experiments have verified our\nplatform, and the results show promising adaptions for future exploration tasks\nin different working scenarios.",
    "descriptor": "",
    "authors": [
      "Kaiwen Xue",
      "Shiqi Yang",
      "Minen Lv",
      "Yiying Lu",
      "Huihuan Qian"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.17022"
  },
  {
    "id": "arXiv:2211.17024",
    "title": "Non-intrusive implementation of a wide variety of Multiscale Finite  Element Methods",
    "abstract": "Multiscale Finite Element Methods (MsFEMs) are now well-established finite\nelement type approaches dedicated to multiscale problems. They first compute\nlocal, oscillatory, problem-dependent basis functions that generate a suitable\ndiscretization space, and next perform a Galerkin approximation of the problem\non that space. We investigate here how these approaches can be implemented in a\nnon-intrusive way, in order to facilitate their dissemination within industrial\ncodes or non-academic environments. We develop an abstract framework that\ncovers a wide variety of MsFEMs for linear second-order partial differential\nequations. Non-intrusive MsFEM approaches are developed within the full\ngenerality of this framework, which may moreover be beneficial to steering\nsoftware development and improving the theoretical understanding and analysis\nof MsFEMs.",
    "descriptor": "\nComments: 46 pages, 4 figures\n",
    "authors": [
      "Rutger A. Biezemans",
      "Claude Le Bris",
      "Fr\u00e9d\u00e9ric Legoll",
      "Alexei Lozinski"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.17024"
  },
  {
    "id": "arXiv:2211.17029",
    "title": "Directed Acyclic Graph Structure Learning from Dynamic Graphs",
    "abstract": "Estimating the structure of directed acyclic graphs (DAGs) of features\n(variables) plays a vital role in revealing the latent data generation process\nand providing causal insights in various applications. Although there have been\nmany studies on structure learning with various types of data, the structure\nlearning on the dynamic graph has not been explored yet, and thus we study the\nlearning problem of node feature generation mechanism on such ubiquitous\ndynamic graph data. In a dynamic graph, we propose to simultaneously estimate\ncontemporaneous relationships and time-lagged interaction relationships between\nthe node features. These two kinds of relationships form a DAG, which could\neffectively characterize the feature generation process in a concise way. To\nlearn such a DAG, we cast the learning problem as a continuous score-based\noptimization problem, which consists of a differentiable score function to\nmeasure the validity of the learned DAGs and a smooth acyclicity constraint to\nensure the acyclicity of the learned DAGs. These two components are translated\ninto an unconstraint augmented Lagrangian objective which could be minimized by\nmature continuous optimization techniques. The resulting algorithm, named\nGraphNOTEARS, outperforms baselines on simulated data across a wide range of\nsettings that may encounter in real-world applications. We also apply the\nproposed approach on two dynamic graphs constructed from the real-world Yelp\ndataset, demonstrating our method could learn the connections between node\nfeatures, which conforms with the domain knowledge.",
    "descriptor": "\nComments: Accepted by AAAI23\n",
    "authors": [
      "Shaohua Fan",
      "Shuyang Zhang",
      "Xiao Wang",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.17029"
  },
  {
    "id": "arXiv:2211.17033",
    "title": "On the use of energy tanks for robotic systems",
    "abstract": "In this document we describe and discuss energy tanks, a control algorithm\nwhich has gained popularity inside the robotics and control community over the\nlast years. This article has the threefold scope of i) introducing to the\nreader the topic in a simple yet precise way, starting with a throughout\ndescription of the energy-aware framework, where energy tanks find their\ngenesis; ii) summarising the range of applications of energy tanks, including\nan original reflection about different formulations of those; iii) discussing\nlimits and future challenges involving energy tanks and energy-aware control in\ngeneral.",
    "descriptor": "\nComments: In press in a volume of Springer Proceedings in Advanced Robotics (SPAR)\n",
    "authors": [
      "Federico Califano",
      "Ramy Rashad",
      "Cristian Secchi",
      "Stefano Stramigioli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.17033"
  },
  {
    "id": "arXiv:2211.17036",
    "title": "High-Dimensional Wide Gap $k$-Means Versus Clustering Axioms",
    "abstract": "Kleinberg's axioms for distance based clustering proved to be contradictory.\nVarious efforts have been made to overcome this problem.\nHere we make an attempt to handle the issue by embedding in high-dimensional\nspace and granting wide gaps between clusters.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Mieczys\u0142aw A. K\u0142opotek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.17036"
  },
  {
    "id": "arXiv:2211.17039",
    "title": "Neural Network Representation of Time Integrators",
    "abstract": "Deep neural network (DNN) architectures are constructed that are the exact\nequivalent of explicit Runge-Kutta schemes for numerical time integration. The\nnetwork weights and biases are given, i.e., no training is needed. In this way,\nthe only task left for physics-based integrators is the DNN approximation of\nthe right-hand side. This allows to clearly delineate the approximation\nestimates for right-hand side errors and time integration errors. The\narchitecture required for the integration of a simple mass-damper-stiffness\ncase is included as an example.",
    "descriptor": "",
    "authors": [
      "Rainald L\u00f6hner",
      "Harbir Antil"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17039"
  },
  {
    "id": "arXiv:2211.17042",
    "title": "Spatio-Temporal Crop Aggregation for Video Representation Learning",
    "abstract": "We propose Spatio-temporal Crop Aggregation for video representation LEarning\n(SCALE), a novel method that enjoys high scalability at both training and\ninference time. Our model builds long-range video features by learning from\nsets of video clip-level features extracted with a pre-trained backbone. To\ntrain the model, we propose a self-supervised objective consisting of masked\nclip feature prediction. We apply sparsity to both the input, by extracting a\nrandom set of video clips, and to the loss function, by only reconstructing the\nsparse inputs. Moreover, we use dimensionality reduction by working in the\nlatent space of a pre-trained backbone applied to single video clips. The video\nrepresentation is then obtained by taking the ensemble of the concatenation of\nembeddings of separate video clips with a video clip set summarization token.\nThese techniques make our method not only extremely efficient to train, but\nalso highly effective in transfer learning. We demonstrate that our video\nrepresentation yields state-of-the-art performance with linear, non-linear, and\n$k$-NN probing on common action classification datasets.",
    "descriptor": "",
    "authors": [
      "Sepehr Sameni",
      "Simon Jenni",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.17042"
  },
  {
    "id": "arXiv:2211.17045",
    "title": "From Actions to Events: A Transfer Learning Approach Using Improved Deep  Belief Networks",
    "abstract": "In the last decade, exponential data growth supplied machine learning-based\nalgorithms' capacity and enabled their usage in daily-life activities.\nAdditionally, such an improvement is partially explained due to the advent of\ndeep learning techniques, i.e., stacks of simple architectures that end up in\nmore complex models. Although both factors produce outstanding results, they\nalso pose drawbacks regarding the learning process as training complex models\nover large datasets are expensive and time-consuming. Such a problem is even\nmore evident when dealing with video analysis. Some works have considered\ntransfer learning or domain adaptation, i.e., approaches that map the knowledge\nfrom one domain to another, to ease the training burden, yet most of them\noperate over individual or small blocks of frames. This paper proposes a novel\napproach to map the knowledge from action recognition to event recognition\nusing an energy-based model, denoted as Spectral Deep Belief Network. Such a\nmodel can process all frames simultaneously, carrying spatial and temporal\ninformation through the learning process. The experimental results conducted\nover two public video dataset, the HMDB-51 and the UCF-101, depict the\neffectiveness of the proposed model and its reduced computational burden when\ncompared to traditional energy-based models, such as Restricted Boltzmann\nMachines and Deep Belief Networks.",
    "descriptor": "",
    "authors": [
      "Mateus Roder",
      "Jurandy Almeida",
      "Gustavo H. de Rosa",
      "Leandro A. Passos",
      "Andr\u00e9 L. D. Rossi",
      "Jo\u00e3o P. Papa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.17045"
  },
  {
    "id": "arXiv:2211.17046",
    "title": "RAFT: Rationale adaptor for few-shot abusive language detection",
    "abstract": "Abusive language is a concerning problem in online social media. Past\nresearch on detecting abusive language covers different platforms, languages,\ndemographies, etc. However, models trained using these datasets do not perform\nwell in cross-domain evaluation settings. To overcome this, a common strategy\nis to use a few samples from the target domain to train models to get better\nperformance in that domain (cross-domain few-shot training). However, this\nmight cause the models to overfit the artefacts of those samples. A compelling\nsolution could be to guide the models toward rationales, i.e., spans of text\nthat justify the text's label. This method has been found to improve model\nperformance in the in-domain setting across various NLP tasks. In this paper,\nwe propose RAFT (Rationale Adaptor for Few-shoT classification) for abusive\nlanguage detection. We first build a multitask learning setup to jointly learn\nrationales, targets, and labels, and find a significant improvement of 6% macro\nF1 on the rationale detection task over training solely rationale classifiers.\nWe introduce two rationale-integrated BERT-based architectures (the RAFT\nmodels) and evaluate our systems over five different abusive language datasets,\nfinding that in the few-shot classification setting, RAFT-based models\noutperform baseline models by about 7% in macro F1 scores and perform\ncompetitively to models finetuned on other source domains. Furthermore,\nRAFT-based models outperform LIME/SHAP-based approaches in terms of\nplausibility and are close in performance in terms of faithfulness.",
    "descriptor": "\nComments: 9 pages, 6 tables, 2 figures\n",
    "authors": [
      "Punyajoy Saha",
      "Divyanshu Sheth",
      "Kushal Kedia",
      "Binny Mathew",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.17046"
  },
  {
    "id": "arXiv:2211.17054",
    "title": "Approximating robot reachable space using convex polytopes",
    "abstract": "This paper presents an approach for approximating the reachable space of\nrobotic manipulators based on convex polytopes. The proposed approach predicts\nthe reachable space over a given time horizon based on the robot's actuation\nlimits and kinematic constraints. The approach is furthermore extended to\nintegrate the robot's environment, assuming it can be expressed in a form of\nlinear constraints, and to account for the robot's link geometry.The accuracy\nof the proposed method is evaluated using simulations of robot's nonlinear\ndynamics and it is compared against the cartesian space limits, usually\nprovided by manufacturers in standard datasheets.The accuracy analysis results\nshow that the proposed method has good performance for the time horizons up to\n250ms, encapsulating most of the simulated robot's reachable space while\nmaintaining comparable volume. For a 7 dof robot, the method has an average\nexecution time of 50ms, independent of the horizon time, potentially enabling\nreal-time applications.",
    "descriptor": "",
    "authors": [
      "Antun Skuric",
      "Vincent Padois",
      "David Daney"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.17054"
  },
  {
    "id": "arXiv:2211.17056",
    "title": "Improving the Thresholds of Generalized LDPC Codes with Convolutional  Code Constraints",
    "abstract": "CC-GLPDC codes are a class of generalized low-density parity-check (GLDPC)\ncodes where the constraint nodes (CNs) represent convolutional codes. This\nallows for efficient decoding in the trellis with the forward-backward\nalgorithm, and the strength of the component codes easily can be controlled by\nthe encoder memory without changing the graph structure. In this letter, we\nextend the class of CC-GLDPC codes by introducing different types of\nirregularity at the CNs and investigating their effect on the BP and MAP\ndecoding thresholds for the binary erasure channel (BEC). For the considered\nclass of codes, an exhaustive grid search is performed to find the BP-optimized\nand MAP-optimized ensembles and compare their thresholds with the regular\nensemble of the same design rate. The results show that irregularity can\nsignificantly improve the BP thresholds, whereas the thresholds of the\nMAP-optimized ensembles are only slightly different from the regular ensembles.\nSimulation results for the AWGN channel are presented as well and compared to\nthe corresponding thresholds.",
    "descriptor": "\nComments: Submitted to IEEE communication letters\n",
    "authors": [
      "Muhammad Umar Farooq",
      "Michael Lentmaier",
      "Alexandre Graell i Amat"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.17056"
  },
  {
    "id": "arXiv:2211.17059",
    "title": "Hint-dynamic Knowledge Distillation",
    "abstract": "Knowledge Distillation (KD) transfers the knowledge from a high-capacity\nteacher model to promote a smaller student model. Existing efforts guide the\ndistillation by matching their prediction logits, feature embedding, etc.,\nwhile leaving how to efficiently utilize them in junction less explored. In\nthis paper, we propose Hint-dynamic Knowledge Distillation, dubbed HKD, which\nexcavates the knowledge from the teacher' s hints in a dynamic scheme. The\nguidance effect from the knowledge hints usually varies in different instances\nand learning stages, which motivates us to customize a specific hint-learning\nmanner for each instance adaptively. Specifically, a meta-weight network is\nintroduced to generate the instance-wise weight coefficients about knowledge\nhints in the perception of the dynamical learning progress of the student\nmodel. We further present a weight ensembling strategy to eliminate the\npotential bias of coefficient estimation by exploiting the historical statics.\nExperiments on standard benchmarks of CIFAR-100 and Tiny-ImageNet manifest that\nthe proposed HKD well boost the effect of knowledge distillation tasks.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Yiyang Liu",
      "Chenxin Li",
      "Xiaotong Tu",
      "Xinghao Ding",
      "Yue Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17059"
  },
  {
    "id": "arXiv:2211.17067",
    "title": "Fair Ranking with Noisy Protected Attributes",
    "abstract": "The fair-ranking problem, which asks to rank a given set of items to maximize\nutility subject to group fairness constraints, has received attention in the\nfairness, information retrieval, and machine learning literature. Recent works,\nhowever, observe that errors in socially-salient (including protected)\nattributes of items can significantly undermine fairness guarantees of existing\nfair-ranking algorithms and raise the problem of mitigating the effect of such\nerrors. We study the fair-ranking problem under a model where socially-salient\nattributes of items are randomly and independently perturbed. We present a\nfair-ranking framework that incorporates group fairness requirements along with\nprobabilistic information about perturbations in socially-salient attributes.\nWe provide provable guarantees on the fairness and utility attainable by our\nframework and show that it is information-theoretically impossible to\nsignificantly beat these guarantees. Our framework works for multiple\nnon-disjoint attributes and a general class of fairness constraints that\nincludes proportional and equal representation. Empirically, we observe that,\ncompared to baselines, our algorithm outputs rankings with higher fairness, and\nhas a similar or better fairness-utility trade-off compared to baselines.",
    "descriptor": "\nComments: Full version of a paper accepted for presentation in NeurIPS 2022\n",
    "authors": [
      "Anay Mehrotra",
      "Nisheeth K. Vishnoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.17067"
  },
  {
    "id": "arXiv:2211.17068",
    "title": "Self-Supervised Continual Graph Learning in Adaptive Riemannian Spaces",
    "abstract": "Continual graph learning routinely finds its role in a variety of real-world\napplications where the graph data with different tasks come sequentially.\nDespite the success of prior works, it still faces great challenges. On the one\nhand, existing methods work with the zero-curvature Euclidean space, and\nlargely ignore the fact that curvature varies over the coming graph sequence.\nOn the other hand, continual learners in the literature rely on abundant\nlabels, but labeling graph in practice is particularly hard especially for the\ncontinuously emerging graphs on-the-fly. To address the aforementioned\nchallenges, we propose to explore a challenging yet practical problem, the\nself-supervised continual graph learning in adaptive Riemannian spaces. In this\npaper, we propose a novel self-supervised Riemannian Graph Continual Learner\n(RieGrace). In RieGrace, we first design an Adaptive Riemannian GCN (AdaRGCN),\na unified GCN coupled with a neural curvature adapter, so that Riemannian space\nis shaped by the learnt curvature adaptive to each graph. Then, we present a\nLabel-free Lorentz Distillation approach, in which we create teacher-student\nAdaRGCN for the graph sequence. The student successively performs\nintra-distillation from itself and inter-distillation from the teacher so as to\nconsolidate knowledge without catastrophic forgetting. In particular, we\npropose a theoretically grounded Generalized Lorentz Projection for the\ncontrastive distillation in Riemannian space. Extensive experiments on the\nbenchmark datasets show the superiority of RieGrace, and additionally, we\ninvestigate on how curvature changes over the graph sequence.",
    "descriptor": "\nComments: Accepted by AAAI 2023 (Main Track), 9 pages, 4 figures\n",
    "authors": [
      "Li Sun",
      "Junda Ye",
      "Hao Peng",
      "Feiyang Wang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17068"
  },
  {
    "id": "arXiv:2211.17070",
    "title": "Differentially Private ADMM-Based Distributed Discrete Optimal Transport  for Resource Allocation",
    "abstract": "Optimal transport (OT) is a framework that can guide the design of efficient\nresource allocation strategies in a network of multiple sources and targets. To\nease the computational complexity of large-scale transport design, we first\ndevelop a distributed algorithm based on the alternating direction method of\nmultipliers (ADMM). However, such a distributed algorithm is vulnerable to\nsensitive information leakage when an attacker intercepts the transport\ndecisions communicated between nodes during the distributed ADMM updates. To\nthis end, we propose a privacy-preserving distributed mechanism based on output\nvariable perturbation by adding appropriate randomness to each node's decision\nbefore it is shared with other corresponding nodes at each update instance. We\nshow that the developed scheme is differentially private, which prevents the\nadversary from inferring the node's confidential information even knowing the\ntransport decisions. Finally, we corroborate the effectiveness of the devised\nalgorithm through case studies.",
    "descriptor": "\nComments: 6 pages, 4 images, 1 algorithm, IEEE GLOBECOMM 2022\n",
    "authors": [
      "Jason Hughes",
      "Juntao Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.17070"
  },
  {
    "id": "arXiv:2211.17071",
    "title": "Towards Interpreting Vulnerability of Multi-Instance Learning via  Customized and Universal Adversarial Perturbations",
    "abstract": "Multi-instance learning (MIL) is a great paradigm for dealing with complex\ndata and has achieved impressive achievements in a number of fields, including\nimage classification, video anomaly detection, and far more. Each data sample\nis referred to as a bag containing several unlabeled instances, and the\nsupervised information is only provided at the bag-level. The safety of MIL\nlearners is concerning, though, as we can greatly fool them by introducing a\nfew adversarial perturbations. This can be fatal in some cases, such as when\nusers are unable to access desired images and criminals are attempting to trick\nsurveillance cameras. In this paper, we design two adversarial perturbations to\ninterpret the vulnerability of MIL methods. The first method can efficiently\ngenerate the bag-specific perturbation (called customized) with the aim of\noutsiding it from its original classification region. The second method builds\non the first one by investigating the image-agnostic perturbation (called\nuniversal) that aims to affect all bags in a given data set and obtains some\ngeneralizability. We conduct various experiments to verify the performance of\nthese two perturbations, and the results show that both of them can effectively\nfool MIL learners. We additionally propose a simple strategy to lessen the\neffects of adversarial perturbations. Source codes are available at\nhttps://github.com/InkiInki/MI-UAP.",
    "descriptor": "",
    "authors": [
      "Yu-Xuan Zhang",
      "Hua Meng",
      "Xuemei Cao",
      "Zhengchun Zhou",
      "Mei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17071"
  },
  {
    "id": "arXiv:2211.17072",
    "title": "Security Investment Over Networks with Bounded Rational Agents: Analysis  and Distributed Algorithm",
    "abstract": "This paper considers the security investment problem over a network in which\nthe resource owners aim to allocate their constrained security resources to\nheterogeneous targets strategically. Investing in each target makes it less\nvulnerable, and thus lowering its probability of a successful attack. However,\nhumans tend to perceive such probabilities inaccurately yielding bounded\nrational behaviors; a phenomenon frequently observed in their decision-making\nwhen facing uncertainties. We capture this human nature through the lens of\ncumulative prospect theory and establish a behavioral resource allocation\nframework to account for the human's misperception in security investment. We\nanalyze how this misperception behavior affects the resource allocation plan by\ncomparing it with the accurate perception counterpart. The network can become\nhighly complex with a large number of participating agents. To this end, we\nfurther develop a fully distributed algorithm to compute the behavioral\nsecurity investment strategy efficiently. Finally, we corroborate our results\nand illustrate the impacts of human's bounded rationality on the resource\nallocation scheme using cases studies.",
    "descriptor": "\nComments: 8 pages, 4 images, 1 algorithm, under review: ACC 2023\n",
    "authors": [
      "Jason Hughes",
      "Juntao Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.17072"
  },
  {
    "id": "arXiv:2211.17073",
    "title": "Risks to Zero Trust in a Federated Mission Partner Environment",
    "abstract": "Recent cybersecurity events have prompted the federal government to begin\ninvestigating strategies to transition to Zero Trust Architectures (ZTA) for\nfederal information systems. Within federated mission networks, ZTA provides\nmeasures to minimize the potential for unauthorized release and disclosure of\ninformation outside bilateral and multilateral agreements. When federating with\nmission partners, there are potential risks that may undermine the benefits of\nZero Trust. This paper explores risks associated with integrating multiple\nidentity models and proposes two potential avenues to investigate in order to\nmitigate these risks.",
    "descriptor": "",
    "authors": [
      "Keith Strandell",
      "Sudip Mittal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.17073"
  },
  {
    "id": "arXiv:2211.17074",
    "title": "On Data-Driven Stochastic Output-Feedback Predictive Control",
    "abstract": "Recently, the fundamental lemma by Willems et al. has seen frequent use for\nthe design of data-driven output-feedback predictive control. However, the\nmajority of existing results considers deterministic Linear Time-Invariant\n(LTI) systems with or without measurement noise. In this paper, we analyze\ndata-driven output-feedback predictive control of stochastic LTI systems with\nrespect to closed-loop guarantees on recursive feasibility, performance, and\nstability. Based on a stochastic variant of the fundamental lemma and\nleveraging polynomial chaos expansions, we construct a data-driven Optimal\nControl Problem (OCP) that allows the propagation of uncertainties over finite\nprediction horizons. The OCP includes a terminal cost and terminal constraints\nexpressed in predicted inputs and outputs. Combined with a selection strategy\nof initial conditions, we prove sufficient conditions for recursive feasibility\nand for the practical stability of the proposed scheme. A numerical example\nillustrates the efficacy of the proposed scheme.",
    "descriptor": "",
    "authors": [
      "Guanru Pan",
      "Ruchuan Ou",
      "Timm Faulwasser"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.17074"
  },
  {
    "id": "arXiv:2211.17077",
    "title": "Dynamic and Distributed Optimization for the Allocation of Aerial Swarm  Vehicles",
    "abstract": "Optimal transport (OT) is a framework that can guide the design of efficient\nresource allocation strategies in a network of multiple sources and targets.\nThis paper applies discrete OT to a swarm of UAVs in a novel way to achieve\nappropriate task allocation and execution. Drone swarm deployments already\noperate in multiple domains where sensors are used to gain knowledge of an\nenvironment [1]. Use cases such as, chemical and radiation detection, and\nthermal and RGB imaging create a specific need for an algorithm that considers\nparameters on both the UAV and waypoint side and allows for updating the\nmatching scheme as the swarm gains information from the environment.\nAdditionally, the need for a centralized planner can be removed by using a\ndistributed algorithm that can dynamically update based on changes in the swarm\nnetwork or parameters. To this end, we develop a dynamic and distributed OT\nalgorithm that matches a UAV to the optimal waypoint based on one parameter at\nthe UAV and another parameter at the waypoint. We show the convergence and\nallocation of the algorithm through a case study and test the algorithm's\neffectiveness against a greedy assignment algorithm in simulation.",
    "descriptor": "\nComments: 6 Pages, 6 images, 1 algorithm, International Conference on Unmanned Aerial Systems 2022\n",
    "authors": [
      "Jason Hughes",
      "Dominic Larkin",
      "Charles O'Donnell",
      "Christopher Korpela"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.17077"
  },
  {
    "id": "arXiv:2211.17078",
    "title": "Reinforcement Learning for Multi-Truck Vehicle Routing Problems",
    "abstract": "Vehicle routing problems and other combinatorial optimization problems have\nbeen approximately solved by reinforcement learning agents with policies based\non encoder-decoder models with attention mechanisms. These techniques are of\nsubstantial interest but still cannot solve the complex routing problems that\narise in a realistic setting which can have many trucks and complex\nrequirements. With the aim of making reinforcement learning a viable technique\nfor supply chain optimization, we develop new extensions to encoder-decoder\nmodels for vehicle routing that allow for complex supply chains using classical\ncomputing today and quantum computing in the future. We make two major\ngeneralizations. First, our model allows for routing problems with multiple\ntrucks. Second, we move away from the simple requirement of having a truck\ndeliver items from nodes to one special depot node, and instead allow for a\ncomplex tensor demand structure. We show how our model, even if trained only\nfor a small number of trucks, can be embedded into a large supply chain to\nyield viable solutions.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Randall Correll",
      "Sean J. Weinberg",
      "Fabio Sanches",
      "Takanori Ide",
      "Takafumi Suzuki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.17078"
  },
  {
    "id": "arXiv:2211.17081",
    "title": "Self-Emphasizing Network for Continuous Sign Language Recognition",
    "abstract": "Hand and face play an important role in expressing sign language. Their\nfeatures are usually especially leveraged to improve system performance.\nHowever, to effectively extract visual representations and capture trajectories\nfor hands and face, previous methods always come at high computations with\nincreased training complexity. They usually employ extra heavy pose-estimation\nnetworks to locate human body keypoints or rely on additional pre-extracted\nheatmaps for supervision. To relieve this problem, we propose a\nself-emphasizing network (SEN) to emphasize informative spatial regions in a\nself-motivated way, with few extra computations and without additional\nexpensive supervision. Specifically, SEN first employs a lightweight subnetwork\nto incorporate local spatial-temporal features to identify informative regions,\nand then dynamically augment original features via attention maps. It's also\nobserved that not all frames contribute equally to recognition. We present a\ntemporal self-emphasizing module to adaptively emphasize those discriminative\nframes and suppress redundant ones. A comprehensive comparison with previous\nmethods equipped with hand and face features demonstrates the superiority of\nour method, even though they always require huge computations and rely on\nexpensive extra supervision. Remarkably, with few extra computations, SEN\nachieves new state-of-the-art accuracy on four large-scale datasets, PHOENIX14,\nPHOENIX14-T, CSL-Daily, and CSL. Visualizations verify the effects of SEN on\nemphasizing informative spatial and temporal features. Code is available at\nhttps://github.com/hulianyuyy/SEN_CSLR",
    "descriptor": "\nComments: AAAI2023,Code is available at this https URL\n",
    "authors": [
      "Lianyu Hu",
      "Liqing Gao",
      "Zekang liu",
      "Wei Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.17081"
  },
  {
    "id": "arXiv:2211.17084",
    "title": "High-Fidelity Guided Image Synthesis with Latent Diffusion Models",
    "abstract": "Controllable image synthesis with user scribbles has gained huge public\ninterest with the recent advent of text-conditioned latent diffusion models.\nThe user scribbles control the color composition while the text prompt provides\ncontrol over the overall image semantics. However, we note that prior works in\nthis direction suffer from an intrinsic domain shift problem, wherein the\ngenerated outputs often lack details and resemble simplistic representations of\nthe target domain. In this paper, we propose a novel guided image synthesis\nframework, which addresses this problem by modeling the output image as the\nsolution of a constrained optimization problem. We show that while computing an\nexact solution to the optimization is infeasible, an approximation of the same\ncan be achieved while just requiring a single pass of the reverse diffusion\nprocess. Additionally, we show that by simply defining a cross-attention based\ncorrespondence between the input text tokens and the user stroke-painting, the\nuser is also able to control the semantics of different painted regions without\nrequiring any conditional training or finetuning. Human user study results show\nthat the proposed approach outperforms the previous state-of-the-art by over\n85.32% on the overall user satisfaction scores. Project page for our paper is\navailable at https://1jsingh.github.io/gradop.",
    "descriptor": "",
    "authors": [
      "Jaskirat Singh",
      "Stephen Gould",
      "Liang Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.17084"
  },
  {
    "id": "arXiv:2211.17091",
    "title": "Refining Generative Process with Discriminator Guidance in Score-based  Diffusion Models",
    "abstract": "While the success of diffusion models has been witnessed in various domains,\nonly a few works have investigated the variation of the generative process. In\nthis paper, we introduce a new generative process that is closer to the reverse\nprocess than the original generative process, given the identical score\ncheckpoint. Specifically, we adjust the generative process with the auxiliary\ndiscriminator between the real data and the generated data. Consequently, the\nadjusted generative process with the discriminator generates more realistic\nsamples than the original process. In experiments, we achieve new SOTA FIDs of\n1.74 on CIFAR-10, 1.33 on CelebA, and 1.88 on FFHQ in the unconditional\ngeneration.",
    "descriptor": "\nComments: 6 pages, 4 figures, 1 table\n",
    "authors": [
      "Dongjun Kim",
      "Yeongmin Kim",
      "Wanmo Kang",
      "Il-Chul Moon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17091"
  },
  {
    "id": "arXiv:2211.17093",
    "title": "CutFEM forward modeling for EEG source analysis",
    "abstract": "Source analysis of Electroencephalography (EEG) data requires the computation\nof the scalp potential induced by current sources in the brain. This so-called\nEEG forward problem is based on an accurate estimation of the volume conduction\neffects in the human head, represented by a partial differential equation which\ncan be solved using the finite element method (FEM). FEM offers flexibility\nwhen modeling anisotropic tissue conductivities but requires a volumetric\ndiscretization, a mesh, of the head domain. Structured hexahedral meshes are\neasy to create in an automatic fashion, while tetrahedral meshes are better\nsuited to model curved geometries. Tetrahedral meshes thus offer better\naccuracy, but are more difficult to create. Methods: We introduce CutFEM for\nEEG forward simulations to integrate the strengths of hexahedra and tetrahedra.\nIt belongs to the family of unfitted finite element methods, decoupling mesh\nand geometry representation. Following a description of the method, we will\nemploy CutFEM in both controlled spherical scenarios and the reconstruction of\nsomatosensory evoked potentials. Results: CutFEM outperforms competing FEM\napproaches with regard to numerical accuracy, memory consumption and\ncomputational speed while being able to mesh arbitrarily touching compartments.\nConclusion: CutFEM balances numerical accuracy, computational efficiency and a\nsmooth approximation of complex geometries that has previously not been\navailable in FEM-based EEG forward modeling.",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Tim Erdbr\u00fcgger",
      "Andreas Westhoff",
      "Malte Hoeltershinken",
      "Jan-Ole Radecke",
      "Yvonne Buschermoehle",
      "Alena Buyx",
      "Fabrice Wallois",
      "Sampsa Pursiainen",
      "Joachim Gross",
      "Rebekka Lencer",
      "Christian Engwer",
      "Carsten Wolters"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.17093"
  },
  {
    "id": "arXiv:2211.17095",
    "title": "Optimizing time-shifts for reservoir computing using a rank-revealing QR  algorithm",
    "abstract": "Reservoir computing is a recurrent neural network paradigm in which only the\noutput layer is trained. Recently, it was demonstrated that adding time-shifts\nto the signals generated by a reservoir can provide large improvements in\nperformance accuracy. In this work, we present a technique to choose the\noptimal time shifts. Our technique maximizes the rank of the reservoir matrix\nusing a rank-revealing QR algorithm and is not task dependent. Further, our\ntechnique does not require a model of the system, and therefore is directly\napplicable to analog hardware reservoir computers. We demonstrate our\ntime-shift optimization technique on two types of reservoir computer: one based\non an opto-electronic oscillator and the traditional recurrent network with a\n$tanh$ activation function. We find that our technique provides improved\naccuracy over random time-shift selection in essentially all cases.",
    "descriptor": "",
    "authors": [
      "Joseph D. Hart",
      "Francesco Sorrentino",
      "Thomas L. Carroll"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ],
    "url": "https://arxiv.org/abs/2211.17095"
  },
  {
    "id": "arXiv:2211.17100",
    "title": "Holistic Outpost Design for Lunar Lava Tubes",
    "abstract": "As the space industry continues its rapid development, humanity is poised to\nexpand beyond Low Earth Orbit (LEO), seeking to establish permanent presence on\nthe Moon and beyond. While space travel has traditionally been the domain of a\nsmall number of highly specialized professionals, a new era of human\nexploration, involving non-space actors and stakeholders, is now becoming a\nreality. In spite of this development, most space habitats are still designed\nfor a narrow target group. This paper seeks to address this deficit by\nrethinking the established design approaches, typically limited to tackling\nengineering and challenges of human space exploration (such as radiation or\nhypogravity), by instead adopting an interdisciplinary \"big picture\"\nperspective encompassing social, psychological and cultural aspects of future\nspace habitats. By elaborating and reflecting on our concept, this paper seeks\nto demonstrate the importance of a trans-disciplinary approach to designing\nthriving sustainable colonies beyond LEO. We demonstrate the potentially key\nrole of design as mediator in advancing macro-strategies promoting thriving\nexistence and sustainable growth. With this approach we tackle big-picture\nquestions about humanity's future and prospects amongst the stars.",
    "descriptor": "\nComments: 73rd International Astronautical Congress (IAC)\n",
    "authors": [
      "Anna Vock",
      "Tommy Nilsson"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.17100"
  },
  {
    "id": "arXiv:2211.17104",
    "title": "Agent-Cells with $DNA$ Programming: A Dynamic Decentralized System",
    "abstract": "We intend to give life to a software agent. A software agent is a computer\nprogram that acts on a user's behalf. We create a reproductive part for an\n$agent$ that make the agent act and decide independently. Denote this part by\n$DNA$. We look at an agent as a cell in the body of an alive creature.\nThe operations and behavior of an agent will be determined by $DNA$. There\ncould be several types of agents. The $DNA$ illustrates the agent's duties and\ncommunication protocols. By defining different $DNA$ structures, one can\nestablish new agents and, consequently, different nets for different usage. We\ninitiate such thinking as \"$DNA$ programming\". This strategy could lead to a\nnew field of programming. This type of programming can help us manage and\nmonitor large systems with various elements with an incredibly more organized\ncustomizable structure. An agent can fork another agent. We put one or a few\nagents around a given network, and the agents will reproduce themselves till\nthey can reach others and pervade the whole network. An agent's environmental\nor geographical characteristics make it possible for an agent to know its\nduties based on its $DNA$. There is a database that includes a list of\nfunctions. Each function is an implementation of a $gene$ already exist in the\n$DNA$. The genome (the set of all the genes) is the same for all the agents,\nbut the environmental or geographical conditions make only a subset of genes\nactive for a specific agent.\nThis design can adapt itself to a system that deals with managing many static\nand dynamic networks. This network could be a distributed system, a\ndecentralized system, a telecommunication network such as a 5G monitoring\nsystem, an IoT management system, or an energy management system.",
    "descriptor": "",
    "authors": [
      "Arash Vaezi"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.17104"
  },
  {
    "id": "arXiv:2211.17106",
    "title": "Diffusion Probabilistic Model Made Slim",
    "abstract": "Despite the recent visually-pleasing results achieved, the massive\ncomputational cost has been a long-standing flaw for diffusion probabilistic\nmodels (DPMs), which, in turn, greatly limits their applications on\nresource-limited platforms. Prior methods towards efficient DPM, however, have\nlargely focused on accelerating the testing yet overlooked their huge\ncomplexity and sizes. In this paper, we make a dedicated attempt to lighten DPM\nwhile striving to preserve its favourable performance. We start by training a\nsmall-sized latent diffusion model (LDM) from scratch, but observe a\nsignificant fidelity drop in the synthetic images. Through a thorough\nassessment, we find that DPM is intrinsically biased against high-frequency\ngeneration, and learns to recover different frequency components at different\ntime-steps. These properties make compact networks unable to represent\nfrequency dynamics with accurate high-frequency estimation. Towards this end,\nwe introduce a customized design for slim DPM, which we term as Spectral\nDiffusion (SD), for light-weight image synthesis. SD incorporates wavelet\ngating in its architecture to enable frequency dynamic feature extraction at\nevery reverse steps, and conducts spectrum-aware distillation to promote\nhigh-frequency recovery by inverse weighting the objective based on spectrum\nmagni tudes. Experimental results demonstrate that, SD achieves 8-18x\ncomputational complexity reduction as compared to the latent diffusion models\non a series of conditional and unconditional image generation tasks while\nretaining competitive image fidelity.",
    "descriptor": "",
    "authors": [
      "Xingyi Yang",
      "Daquan Zhou",
      "Jiashi Feng",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.17106"
  },
  {
    "id": "arXiv:2211.17107",
    "title": "Handling and extracting key entities from customer conversations using  Speech recognition and Named Entity recognition",
    "abstract": "In this modern era of technology with e-commerce developing at a rapid pace,\nit is very important to understand customer requirements and details from a\nbusiness conversation. It is very crucial for customer retention and\nsatisfaction. Extracting key insights from these conversations is very\nimportant when it comes to developing their product or solving their issue.\nUnderstanding customer feedback, responses, and important details of the\nproduct are essential and it would be done using Named entity recognition\n(NER). For extracting the entities we would be converting the conversations to\ntext using the optimal speech-to-text model. The model would be a two-stage\nnetwork in which the conversation is converted to text. Then, suitable entities\nare extracted using robust techniques using a NER BERT transformer model. This\nwill aid in the enrichment of customer experience when there is an issue which\nis faced by them. If a customer faces a problem he will call and register his\ncomplaint. The model will then extract the key features from this conversation\nwhich will be necessary to look into the problem. These features would include\ndetails like the order number, and the exact problem. All these would be\nextracted directly from the conversation and this would reduce the effort of\ngoing through the conversation again.",
    "descriptor": "",
    "authors": [
      "Sharvi Endait",
      "Ruturaj Ghatage",
      "Prof. DD Kadam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17107"
  },
  {
    "id": "arXiv:2211.17108",
    "title": "An Emotion-guided Approach to Domain Adaptive Fake News Detection using  Adversarial Learning",
    "abstract": "Recent works on fake news detection have shown the efficacy of using emotions\nas a feature for improved performance. However, the cross-domain impact of\nemotion-guided features for fake news detection still remains an open problem.\nIn this work, we propose an emotion-guided, domain-adaptive, multi-task\napproach for cross-domain fake news detection, proving the efficacy of\nemotion-guided models in cross-domain settings for various datasets.",
    "descriptor": "\nComments: Accepted in the Student Abstract & Poster Presentation track at AAAI 2023. arXiv admin note: substantial text overlap with arXiv:2211.13718\n",
    "authors": [
      "Arkajyoti Chakraborty",
      "Inder Khatri",
      "Arjun Choudhry",
      "Pankaj Gupta",
      "Dinesh Kumar Vishwakarma",
      "Mukesh Prasad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.17108"
  },
  {
    "id": "arXiv:2211.17111",
    "title": "BEVPoolv2: A Cutting-edge Implementation of BEVDet Toward Deployment",
    "abstract": "We release a new codebase version of the BEVDet, dubbed branch dev2.0. With\ndev2.0, we propose BEVPoolv2 upgrade the view transformation process from the\nperspective of engineering optimization, making it free from a huge burden in\nboth calculation and storage aspects. It achieves this by omitting the\ncalculation and preprocessing of the large frustum feature. As a result, it can\nbe processed within 0.82 ms even with a large input resolution of 640x1600,\nwhich is 15.1 times the previous fastest implementation. Besides, it is also\nless cache consumptive when compared with the previous implementation,\nnaturally as it no longer needs to store the large frustum feature. Last but\nnot least, this also makes the deployment to the other backend handy. We offer\nan example of deployment to the TensorRT backend in branch dev2.0 and show how\nfast the BEVDet paradigm can be processed on it. Other than BEVPoolv2, we also\nselect and integrate some substantial progress that was proposed in the past\nyear. As an example configuration, BEVDet4D-R50-Depth-CBGS scores 52.3 NDS on\nthe NuScenes validation set and can be processed at a speed of 16.4 FPS with\nthe PyTorch backend. The code has been released to facilitate the study on\nhttps://github.com/HuangJunJie2017/BEVDet/tree/dev2.0.",
    "descriptor": "\nComments: Technique report\n",
    "authors": [
      "Junjie Huang",
      "Guan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.17111"
  },
  {
    "id": "arXiv:2211.17113",
    "title": "Weisfeiler and Leman Go Relational",
    "abstract": "Knowledge graphs, modeling multi-relational data, improve numerous\napplications such as question answering or graph logical reasoning. Many graph\nneural networks for such data emerged recently, often outperforming shallow\narchitectures. However, the design of such multi-relational graph neural\nnetworks is ad-hoc, driven mainly by intuition and empirical insights. Up to\nnow, their expressivity, their relation to each other, and their (practical)\nlearning performance is poorly understood. Here, we initiate the study of\nderiving a more principled understanding of multi-relational graph neural\nnetworks. Namely, we investigate the limitations in the expressive power of the\nwell-known Relational GCN and Compositional GCN architectures and shed some\nlight on their practical learning performance. By aligning both architectures\nwith a suitable version of the Weisfeiler-Leman test, we establish under which\nconditions both models have the same expressive power in distinguishing\nnon-isomorphic (multi-relational) graphs or vertices with different structural\nroles. Further, by leveraging recent progress in designing expressive graph\nneural networks, we introduce the $k$-RN architecture that provably overcomes\nthe expressiveness limitations of the above two architectures. Empirically, we\nconfirm our theoretical findings in a vertex classification setting over small\nand large multi-relational graphs.",
    "descriptor": "\nComments: Learning on Graphs Conference 2022. arXiv admin note: text overlap with arXiv:2206.11168\n",
    "authors": [
      "Pablo Barcelo",
      "Mikhail Galkin",
      "Christopher Morris",
      "Miguel Romero Orth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.17113"
  },
  {
    "id": "arXiv:2211.17115",
    "title": "Multiresolution Textual Inversion",
    "abstract": "We extend Textual Inversion to learn pseudo-words that represent a concept at\ndifferent resolutions. This allows us to generate images that use the concept\nwith different levels of detail and also to manipulate different resolutions\nusing language. Once learned, the user can generate images at different levels\nof agreement to the original concept; \"A photo of $S^*(0)$\" produces the exact\nobject while the prompt \"A photo of $S^*(0.8)$\" only matches the rough outlines\nand colors. Our framework allows us to generate images that use different\nresolutions of an image (e.g. details, textures, styles) as separate\npseudo-words that can be composed in various ways. We open-soure our code in\nthe following URL: https://github.com/giannisdaras/multires_textual_inversion",
    "descriptor": "\nComments: Accepted at NeurIPS 2022 Workshop on Score-Based Methods. 5 pages, 4 Figures, work in progress\n",
    "authors": [
      "Giannis Daras",
      "Alexandros G. Dimakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17115"
  },
  {
    "id": "arXiv:2211.17116",
    "title": "Global Convergence of Localized Policy Iteration in Networked  Multi-Agent Reinforcement Learning",
    "abstract": "We study a multi-agent reinforcement learning (MARL) problem where the agents\ninteract over a given network. The goal of the agents is to cooperatively\nmaximize the average of their entropy-regularized long-term rewards. To\novercome the curse of dimensionality and to reduce communication, we propose a\nLocalized Policy Iteration (LPI) algorithm that provably learns a\nnear-globally-optimal policy using only local information. In particular, we\nshow that, despite restricting each agent's attention to only its $\\kappa$-hop\nneighborhood, the agents are able to learn a policy with an optimality gap that\ndecays polynomially in $\\kappa$. In addition, we show the finite-sample\nconvergence of LPI to the global optimal policy, which explicitly captures the\ntrade-off between optimality and computational complexity in choosing $\\kappa$.\nNumerical simulations demonstrate the effectiveness of LPI.",
    "descriptor": "",
    "authors": [
      "Yizhou Zhang",
      "Guannan Qu",
      "Pan Xu",
      "Yiheng Lin",
      "Zaiwei Chen",
      "Adam Wierman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.17116"
  },
  {
    "id": "arXiv:2211.17121",
    "title": "sEHR-CE: Language modelling of structured EHR data for efficient and  generalizable patient cohort expansion",
    "abstract": "Electronic health records (EHR) offer unprecedented opportunities for\nin-depth clinical phenotyping and prediction of clinical outcomes. Combining\nmultiple data sources is crucial to generate a complete picture of disease\nprevalence, incidence and trajectories. The standard approach to combining\nclinical data involves collating clinical terms across different terminology\nsystems using curated maps, which are often inaccurate and/or incomplete. Here,\nwe propose sEHR-CE, a novel framework based on transformers to enable\nintegrated phenotyping and analyses of heterogeneous clinical datasets without\nrelying on these mappings. We unify clinical terminologies using textual\ndescriptors of concepts, and represent individuals' EHR as sections of text. We\nthen fine-tune pre-trained language models to predict disease phenotypes more\naccurately than non-text and single terminology approaches. We validate our\napproach using primary and secondary care data from the UK Biobank, a\nlarge-scale research study. Finally, we illustrate in a type 2 diabetes use\ncase how sEHR-CE identifies individuals without diagnosis that share clinical\ncharacteristics with patients.",
    "descriptor": "\nComments: Workshop on Learning from Time Series for Health, 36th Conference on Neural Information Processing Systems (NeurIPS 2022). arXiv admin note: text overlap with arXiv:2202.09318\n",
    "authors": [
      "Anna Munoz-Farre",
      "Harry Rose",
      "Sera Aylin Cakiroglu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.17121"
  },
  {
    "id": "arXiv:2211.17126",
    "title": "Multi-latent Space Alignments for Unsupervised Domain Adaptation in  Multi-view 3D Object Detection",
    "abstract": "Vision-Centric Bird-Eye-View (BEV) perception has shown promising potential\nand attracted increasing attention in autonomous driving. Recent works mainly\nfocus on improving efficiency or accuracy but neglect the domain shift problem,\nresulting in severe degradation of transfer performance. With extensive\nobservations, we figure out the significant domain gaps existing in the scene,\nweather, and day-night changing scenarios and make the first attempt to solve\nthe domain adaption problem for multi-view 3D object detection. Since BEV\nperception approaches are usually complicated and contain several components,\nthe domain shift accumulation on multi-latent spaces makes BEV domain\nadaptation challenging. In this paper, we propose a novel Multi-level\nMulti-space Alignment Teacher-Student ($M^{2}ATS$) framework to ease the domain\nshift accumulation, which consists of a Depth-Aware Teacher (DAT) and a\nMulti-space Feature Aligned (MFA) student model. Specifically, DAT model adopts\nuncertainty guidance to sample reliable depth information in target domain.\nAfter constructing domain-invariant BEV perception, it then transfers pixel and\ninstance-level knowledge to student model. To further alleviate the domain\nshift at the global level, MFA student model is introduced to align\ntask-relevant multi-space features of two domains. To verify the effectiveness\nof $M^{2}ATS$, we conduct BEV 3D object detection experiments on four cross\ndomain scenarios and achieve state-of-the-art performance (e.g., +12.6% NDS and\n+9.1% mAP on Day-Night). Code and dataset will be released.",
    "descriptor": "",
    "authors": [
      "Jiaming Liu",
      "Rongyu Zhang",
      "Xiaowei Chi",
      "Xiaoqi Li",
      "Ming Lu",
      "Yandong Guo",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.17126"
  },
  {
    "id": "arXiv:2211.17131",
    "title": "Nonmonontone submodular maximization under routing constraints",
    "abstract": "In machine learning and big data, the optimization objectives based on\nset-cover, entropy, diversity, influence, feature selection, etc. are commonly\nmodeled as submodular functions. Submodular (function) maximization is\ngenerally NP-hard, even in the absence of constraints. Recently, submodular\nmaximization has been successfully investigated for the settings where the\nobjective function is monotone or the constraint is computation-tractable.\nHowever, maximizing nonmonotone submodular function with complex constraints is\nnot yet well-understood. In this paper, we consider the nonmonotone submodular\nmaximization with a cost budget or feasibility constraint (especially from\nroute planning) that is generally NP-hard to evaluate. Such a problem is common\nfor machine learning, big data, and robotics. This problem is NP-hard, and on\ntop of that, its constraint evaluation is also NP-hard, which adds an\nadditional layer of complexity. So far, few studies have been devoted to\nproposing effective solutions, making this problem currently unclear. In this\npaper, we first propose an iterated greedy algorithm, which yields an\napproximation solution. Then we develop the proof machinery that shows our\nalgorithm is a bi-criterion approximation algorithm: it can achieve a\nconstant-factor approximation to the optimal algorithm, while keeping the\nover-budget tightly bounded. We also explore practical considerations of\nachieving a trade-off between time complexity and over-budget. Finally, we\nconduct numeric experiments on two concrete examples, and show our design's\nefficacy in practical settings.",
    "descriptor": "",
    "authors": [
      "Haotian Zhang",
      "Rao Li",
      "Zewei Wu",
      "Guodong Sun"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.17131"
  },
  {
    "id": "arXiv:2211.17132",
    "title": "Targets in Reinforcement Learning to solve Stackelberg Security Games",
    "abstract": "Reinforcement Learning (RL) algorithms have been successfully applied to real\nworld situations like illegal smuggling, poaching, deforestation, climate\nchange, airport security, etc. These scenarios can be framed as Stackelberg\nsecurity games (SSGs) where defenders and attackers compete to control target\nresources. The algorithm's competency is assessed by which agent is controlling\nthe targets. This review investigates modeling of SSGs in RL with a focus on\npossible improvements of target representations in RL algorithms.",
    "descriptor": "\nComments: Appears in Proceedings of AAAI FSS-22 Symposium \"Lessons Learned for Autonomous Assessment of Machine Abilities (LLAAMA)\"\n",
    "authors": [
      "Saptarashmi Bandyopadhyay",
      "Chenqi Zhu",
      "Philip Daniel",
      "Joshua Morrison",
      "Ethan Shay",
      "John Dickerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.17132"
  },
  {
    "id": "arXiv:2211.17135",
    "title": "BudgetLongformer: Can we Cheaply Pretrain a SotA Legal Language Model  From Scratch?",
    "abstract": "Pretrained transformer models have achieved state-of-the-art results in many\ntasks and benchmarks recently. Many state-of-the-art Language Models (LMs),\nhowever, do not scale well above the threshold of 512 input tokens. In\nspecialized domains though (such as legal, scientific or biomedical), models\noften need to process very long text (sometimes well above 10000 tokens). Even\nthough many efficient transformers have been proposed (such as Longformer,\nBigBird or FNet), so far, only very few such efficient models are available for\nspecialized domains. Additionally, since the pretraining process is extremely\ncostly in general - but even more so as the sequence length increases - it is\noften only in reach of large research labs. One way of making pretraining\ncheaper is the Replaced Token Detection (RTD) task, by providing more signal\nduring training, since the loss can be computed over all tokens. In this work,\nwe train Longformer models with the efficient RTD task on legal data to\nshowcase that pretraining efficient LMs is possible using much less compute. We\nevaluate the trained models on challenging summarization tasks requiring the\nmodel to summarize long texts to show to what extent the models can achieve\ngood performance on downstream tasks. We find that both the small and base\nmodels outperform their baselines on the in-domain BillSum and out-of-domain\nPubMed tasks in their respective parameter range. We publish our code and\nmodels for research purposes.",
    "descriptor": "\nComments: Accepted at ENLSP @ NeurIPS 2022\n",
    "authors": [
      "Joel Niklaus",
      "Daniele Giofr\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17135"
  },
  {
    "id": "arXiv:2211.17139",
    "title": "Multidimensional analysis using sensor arrays with deep learning for  high-precision and high-accuracy diagnosis",
    "abstract": "In the upcoming years, artificial intelligence (AI) is going to transform the\npractice of medicine in most of its specialties. Deep learning can help achieve\nbetter and earlier problem detection, while reducing errors on diagnosis. By\nfeeding a deep neural network (DNN) with the data from a low-cost and\nlow-accuracy sensor array, we demonstrate that it becomes possible to\nsignificantly improve the measurements' precision and accuracy. The data\ncollection is done with an array composed of 32 temperature sensors, including\n16 analog and 16 digital sensors. All sensors have accuracies between\n0.5-2.0$^\\circ$C. 800 vectors are extracted, covering a range from to 30 to\n45$^\\circ$C. In order to improve the temperature readings, we use machine\nlearning to perform a linear regression analysis through a DNN. In an attempt\nto minimize the model's complexity in order to eventually run inferences\nlocally, the network with the best results involves only three layers using the\nhyperbolic tangent activation function and the Adam Stochastic Gradient Descent\n(SGD) optimizer. The model is trained with a randomly-selected dataset using\n640 vectors (80% of the data) and tested with 160 vectors (20%). Using the mean\nsquared error as a loss function between the data and the model's prediction,\nwe achieve a loss of only 1.47x10$^{-4}$ on the training set and 1.22x10$^{-4}$\non the test set. As such, we believe this appealing approach offers a new\npathway towards significantly better datasets using readily-available ultra\nlow-cost sensors.",
    "descriptor": "",
    "authors": [
      "Julie Payette",
      "Sylvain G.Cloutier",
      "Fabrice Vaussenat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17139"
  },
  {
    "id": "arXiv:2211.17142",
    "title": "Learning Label Modular Prompts for Text Classification in the Wild",
    "abstract": "Machine learning models usually assume i.i.d data during training and\ntesting, but data and tasks in real world often change over time. To emulate\nthe transient nature of real world, we propose a challenging but practical\ntask: text classification in-the-wild, which introduces different\nnon-stationary training/testing stages. Decomposing a complex task into modular\ncomponents can enable robust generalisation under such non-stationary\nenvironment. However, current modular approaches in NLP do not take advantage\nof recent advances in parameter efficient tuning of pretrained language models.\nTo close this gap, we propose MODULARPROMPT, a label-modular prompt tuning\nframework for text classification tasks. In MODULARPROMPT, the input prompt\nconsists of a sequence of soft label prompts, each encoding modular knowledge\nrelated to the corresponding class label. In two of most formidable settings,\nMODULARPROMPT outperforms relevant baselines by a large margin demonstrating\nstrong generalisation ability. We also conduct comprehensive analysis to\nvalidate whether the learned prompts satisfy properties of a modular\nrepresentation.",
    "descriptor": "\nComments: accepted to EMNLP 2022\n",
    "authors": [
      "Hailin Chen",
      "Amrita Saha",
      "Shafiq Joty",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.17142"
  },
  {
    "id": "arXiv:2211.17148",
    "title": "ConvLab-3: A Flexible Dialogue System Toolkit Based on a Unified Data  Format",
    "abstract": "Diverse data formats and ontologies of task-oriented dialogue (TOD) datasets\nhinder us from developing general dialogue models that perform well on many\ndatasets and studying knowledge transfer between datasets. To address this\nissue, we present ConvLab-3, a flexible dialogue system toolkit based on a\nunified TOD data format. In ConvLab-3, different datasets are transformed into\none unified format and loaded by models in the same way. As a result, the cost\nof adapting a new model or dataset is significantly reduced. Compared to the\nprevious releases of ConvLab (Lee et al., 2019b; Zhu et al., 2020b), ConvLab-3\nallows developing dialogue systems with much more datasets and enhances the\nutility of the reinforcement learning (RL) toolkit for dialogue policies. To\nshowcase the use of ConvLab-3 and inspire future work, we present a\ncomprehensive study with various settings. We show the benefit of pre-training\non other datasets for few-shot fine-tuning and RL, and encourage evaluating\npolicy with diverse user simulators.",
    "descriptor": "",
    "authors": [
      "Qi Zhu",
      "Christian Geishauser",
      "Hsien-chin Lin",
      "Carel van Niekerk",
      "Baolin Peng",
      "Zheng Zhang",
      "Michael Heck",
      "Nurul Lubis",
      "Dazhen Wan",
      "Xiaochen Zhu",
      "Jianfeng Gao",
      "Milica Ga\u0161i\u0107",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.17148"
  },
  {
    "id": "arXiv:2211.17157",
    "title": "Swarm-Based Gradient Descent Method for Non-Convex Optimization",
    "abstract": "We introduce a new Swarm-Based Gradient Descent (SBGD) method for non-convex\noptimization. The swarm consists of agents, each is identified with a position,\n$\\boldsymbol{x}$, and mass, $m$. The key to their dynamics is communication:\nmasses are being transferred from agents at high ground to low(-est) ground. At\nthe same time, agents change positions with step size, $h=h(\\boldsymbol{x},m)$,\nadjusted to their relative mass: heavier agents proceed with small time-steps\nin the direction of local gradient, while lighter agents take larger time-steps\nbased on a backtracking protocol. Accordingly, the crowd of agents is\ndynamically divided between `heavier' leaders, expected to approach local\nminima, and `lighter' explorers. With their large-step protocol, explorers are\nexpected to encounter improved position for the swarm; if they do, then they\nassume the role of `heavy' swarm leaders and so on. Convergence analysis and\nnumerical simulations in one-, two-, and 20-dimensional benchmarks demonstrate\nthe effectiveness of SBGD as a global optimizer.",
    "descriptor": "",
    "authors": [
      "Jingcheng Lu",
      "Eitan Tadmor",
      "Anil Zenginoglu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.17157"
  },
  {
    "id": "arXiv:2211.17158",
    "title": "Proximal Residual Flows for Bayesian Inverse Problems",
    "abstract": "Normalizing flows are a powerful tool for generative modelling, density\nestimation and posterior reconstruction in Bayesian inverse problems. In this\npaper, we introduce proximal residual flows, a new architecture of normalizing\nflows. Based on the fact, that proximal neural networks are by definition\naveraged operators, we ensure invertibility of certain residual blocks.\nMoreover, we extend the architecture to conditional proximal residual flows for\nposterior reconstruction within Bayesian inverse problems. We demonstrate the\nperformance of proximal residual flows on numerical examples.",
    "descriptor": "",
    "authors": [
      "Johannes Hertrich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17158"
  },
  {
    "id": "arXiv:2211.17159",
    "title": "Opinion Evolution among friends and foes: the deterministic Majority  Rule - extended abstract",
    "abstract": "The influence of the social relationships of an individual on the\nindividual's opinions (about a topic, a product, or whatever else) is a well\nknown phenomenon and it has been widely studied. This paper considers a network\nof positive (i.e. trusting) or negative (distrusting) social relationships\nwhere every individual has an initial positive or negative opinion (about a\ntopic, a product, or whatever else) that changes over time, at discrete\ntime-steps, due to the influences each individual gets from its neighbors.\nHere, the influence of a trusted neighbor is consistent with the neighbor's\nopinion, while the influence of an untrusted neighbor is opposite to the\nneighbor's opinion. This extended abstract introduces the local threshold-based\nopinion dynamics and, after stating the computational complexity of some\nnatural reachability problems arising in this setting when individuals change\ntheir opinions according to the opinions of the majority of their neighbors,\nproves an upper bound on the number of opinion configurations met by a\nsymmetric positive-only relationships network evolving according to any of such\nmodels, which is polynomial in the size of the network. This generalizes a\nresult in [Krishnendu Chatterjee, Rasmus Ibsen-Jensen, Isma\\\"el Jecker, and\nJakub Svoboda, \"Simplified Game of Life: Algorithms and Complexity\", 45th\nInternational Symposium on Mathematical Foundations of Computer Science (MFCS\n2020)]",
    "descriptor": "\nComments: 12 pages, no figures\n",
    "authors": [
      "Miriam Di Ianni"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.17159"
  },
  {
    "id": "arXiv:2211.17161",
    "title": "Bi-directional Feature Reconstruction Network for Fine-Grained Few-Shot  Image Classification",
    "abstract": "The main challenge for fine-grained few-shot image classification is to learn\nfeature representations with higher inter-class and lower intra-class\nvariations, with a mere few labelled samples. Conventional few-shot learning\nmethods however cannot be naively adopted for this fine-grained setting -- a\nquick pilot study reveals that they in fact push for the opposite (i.e., lower\ninter-class variations and higher intra-class variations). To alleviate this\nproblem, prior works predominately use a support set to reconstruct the query\nimage and then utilize metric learning to determine its category. Upon careful\ninspection, we further reveal that such unidirectional reconstruction methods\nonly help to increase inter-class variations and are not effective in tackling\nintra-class variations. In this paper, we for the first time introduce a\nbi-reconstruction mechanism that can simultaneously accommodate for inter-class\nand intra-class variations. In addition to using the support set to reconstruct\nthe query set for increasing inter-class variations, we further use the query\nset to reconstruct the support set for reducing intra-class variations. This\ndesign effectively helps the model to explore more subtle and discriminative\nfeatures which is key for the fine-grained problem in hand. Furthermore, we\nalso construct a self-reconstruction module to work alongside the\nbi-directional module to make the features even more discriminative.\nExperimental results on three widely used fine-grained image classification\ndatasets consistently show considerable improvements compared with other\nmethods. Codes are available at: https://github.com/PRIS-CV/Bi-FRN.",
    "descriptor": "\nComments: Accepted in AAAI-23\n",
    "authors": [
      "Jijie Wu",
      "Dongliang Chang",
      "Aneeshan Sain",
      "Xiaoxu Li",
      "Zhanyu Ma",
      "Jie Cao",
      "Jun Guo",
      "Yi-Zhe Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.17161"
  },
  {
    "id": "arXiv:2211.17163",
    "title": "Misogyny classification of German newspaper forum comments",
    "abstract": "This paper presents work on detecting misogyny in the comments of a large\nAustrian German language newspaper forum. We describe the creation of a corpus\nof 6600 comments which were annotated with 5 levels of misogyny. The forum\nmoderators were involved as experts in the creation of the annotation\nguidelines and the annotation of the comments. We also describe the results of\ntraining transformer-based classification models for both binarized and\noriginal label classification of that corpus.",
    "descriptor": "",
    "authors": [
      "Johann Petrak",
      "Brigitte Krenn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.17163"
  },
  {
    "id": "arXiv:2211.17164",
    "title": "Measuring the Competitive Pressure of Academic Journals and the  Competitive Intensity within Subjects",
    "abstract": "A journal's impact and similarity with rivals is closely related to its\ncompetitive intensity. A subject area can be considered as an ecological system\nof journals, and can then be measured using the competitive intensity concept\nfrom plant systems. Based on Journal Citation Reports data from 1997, 2000,\n2005, 2010, and 2013, we calculated the mutual citation, cosine similarity, and\ncompetitive relationship matrices for mycology journals. We derived the mutual\ncitation network for mycology according to Journal Citation Reports data from\n2013. We calculated each journal's competitive pressure, and the competitive\nintensity for the subject. We found that competitive pressures are very\nvariable among journals. Differences between a journal's absolute and relative\ninfluence are related to the competitive pressure. A more powerful journal has\nlower competitive pressure. New journals have more competitive pressure. If\nthere are no other influences, the competition intensity of a subject will\ncontinue to increase. Furthermore, we found that if a subject has more\njournals, its competitive intensity decreases.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Zheng Ma",
      "Zhenglu Yu",
      "Yuntao Pan",
      "Yishan Wu"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.17164"
  },
  {
    "id": "arXiv:2211.17166",
    "title": "Monitoring Arithmetic Temporal Properties on Finite Traces",
    "abstract": "We study monitoring of linear-time arithmetic properties against finite\ntraces generated by an unknown dynamic system. The monitoring state is\ndetermined by considering at once the trace prefix seen so far, and all its\npossible finite-length, future continuations. This makes monitoring at least as\nhard as satisfiability and validity. Traces consist of finite sequences of\nassignments of a fixed set of variables to numerical values. Properties are\nspecified in a logic we call ALTLf, combining LTLf (LTL on finite traces) with\nlinear arithmetic constraints that may carry lookahead, i.e., variables may be\ncompared over multiple instants of the trace. While the monitoring problem for\nthis setting is undecidable in general, we show decidability for (a) properties\nwithout lookahead, and (b) properties with lookahead that satisfy the abstract,\nsemantic condition of finite summary, studied before in the context of model\nchecking. We then single out concrete, practically relevant classes of\nconstraints guaranteeing finite summary. Feasibility is witnessed by a\nprototype implementation.",
    "descriptor": "",
    "authors": [
      "Paolo Felli",
      "Marco Montali",
      "Fabio Patrizi",
      "Sarah Winkler"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.17166"
  },
  {
    "id": "arXiv:2211.17169",
    "title": "Causes of Stability in Dynamic Coalition Formation",
    "abstract": "We study the formation of stable outcomes via simple dynamics in cardinal\nhedonic games, where the utilities of agents change over time depending on the\nhistory of the coalition formation process. Specifically, we analyze situations\nwhere members of a coalition decrease their utility for a leaving agent\n(resent) or increase their utility for a joining agent (appreciation). We show\nthat in contrast to classical dynamics, for resentful or appreciative agents,\ndynamics are guaranteed to converge under mild conditions for various stability\nconcepts. Thereby, we establish that both resent and appreciation are strong\nstability-driving forces.",
    "descriptor": "\nComments: Appears in the 37th AAAI Conference on Artificial Intelligence (AAAI), 2023\n",
    "authors": [
      "Niclas Boehmer",
      "Martin Bullinger",
      "Anna Maria Kerkmann"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.17169"
  },
  {
    "id": "arXiv:2211.17170",
    "title": "How to Train an Accurate and Efficient Object Detection Model on Any  Dataset",
    "abstract": "The rapidly evolving industry demands high accuracy of the models without the\nneed for time-consuming and computationally expensive experiments required for\nfine-tuning. Moreover, a model and training pipeline, which was once carefully\noptimized for a specific dataset, rarely generalizes well to training on a\ndifferent dataset. This makes it unrealistic to have carefully fine-tuned\nmodels for each use case. To solve this, we propose an alternative approach\nthat also forms a backbone of Intel Geti platform: a dataset-agnostic template\nfor object detection trainings, consisting of carefully chosen and pre-trained\nmodels together with a robust training pipeline for further training. Our\nsolution works out-of-the-box and provides a strong baseline on a wide range of\ndatasets. It can be used on its own or as a starting point for further\nfine-tuning for specific use cases when needed. We obtained dataset-agnostic\ntemplates by performing parallel training on a corpus of datasets and\noptimizing the choice of architectures and training tricks with respect to the\naverage results on the whole corpora. We examined a number of architectures,\ntaking into account the performance-accuracy trade-off. Consequently, we\npropose 3 finalists, VFNet, ATSS, and SSD, that can be deployed on CPU using\nthe OpenVINO toolkit. The source code is available as a part of the OpenVINO\nTraining Extensions (https://github.com/openvinotoolkit/training_extensions}",
    "descriptor": "\nComments: submitted to VISAPP 2023\n",
    "authors": [
      "Galina Zalesskaya",
      "Bogna Bylicka",
      "Eugene Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.17170"
  },
  {
    "id": "arXiv:2211.17171",
    "title": "CDSM: Cascaded Deep Semantic Matching on Textual Graphs Leveraging  Ad-hoc Neighbor Selection",
    "abstract": "Deep semantic matching aims to discriminate the relationship between\ndocuments based on deep neural networks. In recent years, it becomes\nincreasingly popular to organize documents with a graph structure, then\nleverage both the intrinsic document features and the extrinsic neighbor\nfeatures to derive discrimination. Most of the existing works mainly care about\nhow to utilize the presented neighbors, whereas limited effort is made to\nfilter appropriate neighbors. We argue that the neighbor features could be\nhighly noisy and partially useful. Thus, a lack of effective neighbor selection\nwill not only incur a great deal of unnecessary computation cost, but also\nrestrict the matching accuracy severely.\nIn this work, we propose a novel framework, Cascaded Deep Semantic Matching\n(CDSM), for accurate and efficient semantic matching on textual graphs. CDSM is\nhighlighted for its two-stage workflow. In the first stage, a lightweight\nCNN-based ad-hod neighbor selector is deployed to filter useful neighbors for\nthe matching task with a small computation cost. We design both one-step and\nmulti-step selection methods. In the second stage, a high-capacity graph-based\nmatching network is employed to compute fine-grained relevance scores based on\nthe well-selected neighbors. It is worth noting that CDSM is a generic\nframework which accommodates most of the mainstream graph-based semantic\nmatching networks. The major challenge is how the selector can learn to\ndiscriminate the neighbors usefulness which has no explicit labels. To cope\nwith this problem, we design a weak-supervision strategy for optimization,\nwhere we train the graph-based matching network at first and then the ad-hoc\nneighbor selector is learned on top of the annotations from the matching\nnetwork.",
    "descriptor": "",
    "authors": [
      "Jing Yao",
      "Zheng Liu",
      "Junhan Yang",
      "Zhicheng Dou",
      "Xing Xie",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.17171"
  },
  {
    "id": "arXiv:2211.17174",
    "title": "Optimizing Explanations by Network Canonization and Hyperparameter  Search",
    "abstract": "Explainable AI (XAI) is slowly becoming a key component for many AI\napplications. Rule-based and modified backpropagation XAI approaches however\noften face challenges when being applied to modern model architectures\nincluding innovative layer building blocks, which is caused by two reasons.\nFirstly, the high flexibility of rule-based XAI methods leads to numerous\npotential parameterizations. Secondly, many XAI methods break the\nimplementation-invariance axiom because they struggle with certain model\ncomponents, e.g., BatchNorm layers. The latter can be addressed with model\ncanonization, which is the process of re-structuring the model to disregard\nproblematic components without changing the underlying function. While model\ncanonization is straightforward for simple architectures (e.g., VGG, ResNet),\nit can be challenging for more complex and highly interconnected models (e.g.,\nDenseNet). Moreover, there is only little quantifiable evidence that model\ncanonization is beneficial for XAI. In this work, we propose canonizations for\ncurrently relevant model blocks applicable to popular deep neural network\narchitectures,including VGG, ResNet, EfficientNet, DenseNets, as well as\nRelation Networks. We further suggest a XAI evaluation framework with which we\nquantify and compare the effect sof model canonization for various XAI methods\nin image classification tasks on the Pascal-VOC and ILSVRC2017 datasets, as\nwell as for Visual Question Answering using CLEVR-XAI. Moreover, addressing the\nformer issue outlined above, we demonstrate how our evaluation framework can be\napplied to perform hyperparameter search for XAI methods to optimize the\nquality of explanations.",
    "descriptor": "",
    "authors": [
      "Frederik Pahde",
      "Galip \u00dcmit Yolcu",
      "Alexander Binder",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17174"
  },
  {
    "id": "arXiv:2211.17179",
    "title": "Investigation of Proper Orthogonal Decomposition for Echo State Networks",
    "abstract": "Echo State Networks (ESN) are a type of Recurrent Neural Networks that yields\npromising results in representing time series and nonlinear dynamic systems.\nAlthough they are equipped with a very efficient training procedure, Reservoir\nComputing strategies, such as the ESN, require the use of high order networks,\ni.e. large number of layers, resulting in number of states that is magnitudes\nhigher than the number of model inputs and outputs. This not only makes the\ncomputation of a time step more costly, but also may pose robustness issues\nwhen applying ESNs to problems such as Model Predictive Control (MPC) and other\noptimal control problems. One such way to circumvent this is through Model\nOrder Reduction strategies such as the Proper Orthogonal Decomposition (POD)\nand its variants (POD-DEIM), whereby we find an equivalent lower order\nrepresentation to an already trained high dimension ESN. The objective of this\nwork is to investigate and analyze the performance of POD methods in Echo State\nNetworks, evaluating their effectiveness. To this end, we evaluate the Memory\nCapacity (MC) of the POD-reduced network in comparison to the original (full\norder) ENS. We also perform experiments on two different numerical case\nstudies: a NARMA10 difference equation and an oil platform containing two wells\nand one riser. The results show that there is little loss of performance\ncomparing the original ESN to a POD-reduced counterpart, and also that the\nperformance of a POD-reduced ESN tend to be superior to a normal ESN of the\nsame size. Also we attain speedups of around $80\\%$ in comparison to the\noriginal ESN.",
    "descriptor": "\nComments: Submitted to Neurocomputing\n",
    "authors": [
      "Jean Panaioti Jordanou",
      "Eric Aislan Antonelo",
      "Eduardo Camponogara",
      "Eduardo Gildin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.17179"
  },
  {
    "id": "arXiv:2211.17180",
    "title": "Average Path Length: Sparsification of Nonlinearties Creates  Surprisingly Shallow Networks",
    "abstract": "We perform an empirical study of the behaviour of deep networks when pushing\nits activation functions to become fully linear in some of its feature channels\nthrough a sparsity prior on the overall number of nonlinear units in the\nnetwork. To measure the depth of the resulting partially linearized network, we\ncompute the average number of active nonlinearities encountered along a path in\nthe network graph. In experiments on CNNs with sparsified PReLUs on typical\nimage classification tasks, we make several observations: Under sparsity\npressure, the remaining nonlinear units organize into distinct structures,\nforming core-networks of near constant effective depth and width, which in turn\ndepend on task difficulty. We consistently observe a slow decay of performance\nwith depth until the onset of a rapid collapse in accuracy, allowing for\nsurprisingly shallow networks at moderate losses in accuracy that outperform\nbase-line networks of similar depth, even after increasing width to a\ncomparable number of parameters. In terms of training, we observe a nonlinear\nadvantage: Reducing nonlinearity after training leads to a better performance\nthan before, in line with previous findings in linearized training, but with a\ngap depending on task difficulty that vanishes for easy problems.",
    "descriptor": "",
    "authors": [
      "Christian H.X. Ali Mehmeti-G\u00f6pel",
      "Jan Disselhoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.17180"
  },
  {
    "id": "arXiv:2211.17182",
    "title": "Direct Data-Driven State-Feedback Control of Linear Parameter-Varying  Systems",
    "abstract": "We derive novel methods that allow to synthesize LPV state-feedback\ncontrollers directly from a single sequence of data and guarantee stability and\nperformance of the closed-loop system, without knowing the model of the plant.\nWe show that if the measured open-loop data from the system satisfies a\npersistency of excitation condition, then the full open-loop and closed-loop\ninput-scheduling-state behavior can be represented using the data. With this\nrepresentation, we formulate synthesis problems that yield controllers that\nguarantee stability and performance in terms of infinite horizon quadratic\ncost, generalized $\\mathcal{H}_2$-norm and $\\mathcal{L}_2$-gain of the\nclosed-loop system. The controllers are synthesized by solving an SDP with a\nfinite set of LMI constraints. Multiple illustrative examples, including\napplication on a nonlinear unbalanced disk system, demonstrate the\napplicability of the results.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Automatic Control, 15 pages\n",
    "authors": [
      "Chris Verhoek",
      "Roland T\u00f3th",
      "Hossam S. Abbas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.17182"
  },
  {
    "id": "arXiv:2211.17186",
    "title": "Linear Rank Intersection Types",
    "abstract": "Non-idempotent intersection types provide quantitative information about\ntyped programs, and have been used to obtain time and space complexity\nmeasures. Intersection type systems characterize termination, so restrictions\nneed to be made in order to make typability decidable. One such restriction\nconsists in using a notion of finite rank for the idempotent intersection\ntypes. In this work, we define a new notion of rank for the non-idempotent\nintersection types. We then define a novel type system and a type inference\nalgorithm for the lambda-calculus, using the new notion of rank 2. In the\nsecond part of this work, we extend the type system and the type inference\nalgorithm to use the quantitative properties of the non-idempotent intersection\ntypes to infer quantitative information related to resource usage.",
    "descriptor": "",
    "authors": [
      "F\u00e1bio Reis",
      "Sandra Alves",
      "M\u00e1rio Florido"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.17186"
  },
  {
    "id": "arXiv:2211.17188",
    "title": "Automated Play-Testing Through RL Based Human-Like Play-Styles  Generation",
    "abstract": "The increasing complexity of gameplay mechanisms in modern video games is\nleading to the emergence of a wider range of ways to play games. The variety of\npossible play-styles needs to be anticipated by designers, through automated\ntests. Reinforcement Learning is a promising answer to the need of automating\nvideo game testing. To that effect one needs to train an agent to play the\ngame, while ensuring this agent will generate the same play-styles as the\nplayers in order to give meaningful feedback to the designers. We present\nCARMI: a Configurable Agent with Relative Metrics as Input. An agent able to\nemulate the players play-styles, even on previously unseen levels. Unlike\ncurrent methods it does not rely on having full trajectories, but only summary\ndata. Moreover it only requires little human data, thus compatible with the\nconstraints of modern video game production. This novel agent could be used to\ninvestigate behaviors and balancing during the production of a video game with\na realistic amount of training time.",
    "descriptor": "\nComments: Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, 18(1)\n",
    "authors": [
      "Pierre Le Pelletier de Woillemont",
      "R\u00e9mi Labory",
      "Vincent Corruble"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.17188"
  },
  {
    "id": "arXiv:2211.17189",
    "title": "Airfoil Shape Optimization using Deep Q-Network",
    "abstract": "The feasibility of using reinforcement learning for airfoil shape\noptimization is explored. Deep Q-Network (DQN) is used over Markov's decision\nprocess to find the optimal shape by learning the best changes to the initial\nshape for achieving the required goal. The airfoil profile is generated using\nBezier control points to reduce the number of control variables. The changes in\nthe position of control points are restricted to the direction normal to the\nchordline so as to reduce the complexity of optimization. The process is\ndesigned as a search for an episode of change done to each control point of a\nprofile. The DQN essentially learns the episode of best changes by updating the\ntemporal difference of the Bellman Optimality Equation. The drag and lift\ncoefficients are calculated from the distribution of pressure coefficient along\nthe profile computed using XFoil potential flow solver. These coefficients are\nused to give a reward to every change during the learning process where the\nultimate aim stands to maximize the cumulate reward of an episode.",
    "descriptor": "\nComments: Conference: 72nd Annual Meeting of the APS Division of Fluid Dynamics,Seattle, WA, USA Volume: Volume 64, Number 13\n",
    "authors": [
      "Siddharth Rout",
      "Chao-An Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.17189"
  },
  {
    "id": "arXiv:2211.17191",
    "title": "Direct data-driven LPV control of nonlinear systems: An experimental  result",
    "abstract": "We demonstrate that direct data-driven control of nonlinear systems can be\nsuccessfully accomplished via a data-driven behavioral approach that builds on\na Linear Parameter-Varying (LPV) system concept. The underlying LPV data-driven\nrepresentation is used as a surrogate LPV form of the original nonlinear\nsystem's data-driven representation. The resulting LPV control design uses only\nmeasurement data from the nonlinear system, and a priori information on a\nscheduling map that can lead to an LPV embedding of the nonlinear system\nbehavior. Efficiency of the proposed approach is demonstrated experimentally on\na nonlinear unbalanced disc system showing for the first time in the literature\nthat behavioral data-driven methods are capable to stabilize arbitrary forced\nequilibria of a real-world nonlinear system by the use of only 7 data points.",
    "descriptor": "\nComments: Submitted to the 22nd IFAC World Congress 2023 (IFAC2023)\n",
    "authors": [
      "Chris Verhoek",
      "Hossam S. Abbas",
      "Roland T\u00f3th"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.17191"
  },
  {
    "id": "arXiv:2211.17192",
    "title": "Fast Inference from Transformers via Speculative Decoding",
    "abstract": "Inference from large autoregressive models like Transformers is slow -\ndecoding K tokens takes K serial runs of the model. In this work we introduce\nspeculative decoding - an algorithm to sample from autoregressive models faster\nwithout any changes to the outputs, by computing several tokens in parallel. At\nthe heart of our approach lie the observations that (1) hard language-modeling\ntasks often include easier subtasks that can be approximated well by more\nefficient models, and (2) using speculative execution and a novel sampling\nmethod, we can make exact decoding from the large models faster, by running\nthem in parallel on the outputs of the approximation models, potentially\ngenerating several tokens concurrently, and without changing the distribution.\nOur method supports existing off-the-shelf models without retraining or\narchitecture changes. We demonstrate it on T5-XXL and show a 2X-3X acceleration\ncompared to the standard T5X implementation, with identical outputs.",
    "descriptor": "",
    "authors": [
      "Yaniv Leviathan",
      "Matan Kalman",
      "Yossi Matias"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.17192"
  },
  {
    "id": "arXiv:2211.17196",
    "title": "EURO: ESPnet Unsupervised ASR Open-source Toolkit",
    "abstract": "This paper describes the ESPnet Unsupervised ASR Open-source Toolkit (EURO),\nan end-to-end open-source toolkit for unsupervised automatic speech recognition\n(UASR). EURO adopts the state-of-the-art UASR learning method introduced by the\nWav2vec-U, originally implemented at FAIRSEQ, which leverages self-supervised\nspeech representations and adversarial training. In addition to wav2vec2, EURO\nextends the functionality and promotes reproducibility for UASR tasks by\nintegrating S3PRL and k2, resulting in flexible frontends from 27\nself-supervised models and various graph-based decoding strategies. EURO is\nimplemented in ESPnet and follows its unified pipeline to provide UASR recipes\nwith a complete setup. This improves the pipeline's efficiency and allows EURO\nto be easily applied to existing datasets in ESPnet. Extensive experiments on\nthree mainstream self-supervised models demonstrate the toolkit's effectiveness\nand achieve state-of-the-art UASR performance on TIMIT and LibriSpeech\ndatasets. EURO will be publicly available at https://github.com/espnet/espnet,\naiming to promote this exciting and emerging research area based on UASR\nthrough open-source activity.",
    "descriptor": "",
    "authors": [
      "Dongji Gao",
      "Jiatong Shi",
      "Shun-Po Chuang",
      "Leibny Paola Garcia",
      "Hung-yi Lee",
      "Shinji Watanabe",
      "Sanjeev Khudanpur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.17196"
  },
  {
    "id": "arXiv:2211.17199",
    "title": "Resource Sharing Through Multi-Round Matchings",
    "abstract": "Applications such as employees sharing office spaces over a workweek can be\nmodeled as problems where agents are matched to resources over multiple rounds.\nAgents' requirements limit the set of compatible resources and the rounds in\nwhich they want to be matched. Viewing such an application as a multi-round\nmatching problem on a bipartite compatibility graph between agents and\nresources, we show that a solution (i.e., a set of matchings, with one matching\nper round) can be found efficiently if one exists. To cope with situations\nwhere a solution does not exist, we consider two extensions. In the first\nextension, a benefit function is defined for each agent and the objective is to\nfind a multi-round matching to maximize the total benefit. For a general class\nof benefit functions satisfying certain properties (including diminishing\nreturns), we show that this multi-round matching problem is efficiently\nsolvable. This class includes utilitarian and Rawlsian welfare functions. For\nanother benefit function, we show that the maximization problem is NP-hard. In\nthe second extension, the objective is to generate advice to each agent (i.e.,\na subset of requirements to be relaxed) subject to a budget constraint so that\nthe agent can be matched. We show that this budget-constrained advice\ngeneration problem is NP-hard. For this problem, we develop an integer linear\nprogramming formulation as well as a heuristic based on local search. We\nexperimentally evaluate our algorithms on synthetic networks and apply them to\ntwo real-world situations: shared office spaces and matching courses to\nclassrooms.",
    "descriptor": "",
    "authors": [
      "Yohai Trabelsi",
      "Abhijin Adiga",
      "Sarit Kraus",
      "S.S. Ravi",
      "Daniel J. Rosenkrantz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.17199"
  },
  {
    "id": "arXiv:2211.17200",
    "title": "CKS: A Community-based K-shell Decomposition Approach using Community  Bridge Nodes for Influence Maximization",
    "abstract": "Social networks have enabled user-specific advertisements and recommendations\non their platforms, which puts a significant focus on Influence Maximisation\n(IM) for target advertising and related tasks. The aim is to identify nodes in\nthe network which can maximize the spread of information through a diffusion\ncascade. We propose a community structures-based approach that employs K-Shell\nalgorithm with community structures to generate a score for the connections\nbetween seed nodes and communities. Further, our approach employs entropy\nwithin communities to ensure the proper spread of information within the\ncommunities. We validate our approach on four publicly available networks and\nshow its superiority to four state-of-the-art approaches while still being\nrelatively efficient.",
    "descriptor": "\nComments: Accepted in the Student Abstract & Poster Presentation Track at AAAI 2023\n",
    "authors": [
      "Inder Khatri",
      "Aaryan Gupta",
      "Arjun Choudhry",
      "Aryan Tyagi",
      "Dinesh Kumar Vishwakarma",
      "Mukesh Prasad"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.17200"
  },
  {
    "id": "arXiv:2211.17201",
    "title": "ExtremeBERT: A Toolkit for Accelerating Pretraining of Customized BERT",
    "abstract": "In this paper, we present ExtremeBERT, a toolkit for accelerating and\ncustomizing BERT pretraining. Our goal is to provide an easy-to-use BERT\npretraining toolkit for the research community and industry. Thus, the\npretraining of popular language models on customized datasets is affordable\nwith limited resources. Experiments show that, to achieve the same or better\nGLUE scores, the time cost of our toolkit is over $6\\times$ times less for BERT\nBase and $9\\times$ times less for BERT Large when compared with the original\nBERT paper. The documentation and code are released at\nhttps://github.com/extreme-bert/extreme-bert under the Apache-2.0 license.",
    "descriptor": "",
    "authors": [
      "Rui Pan",
      "Shizhe Diao",
      "Jianlin Chen",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.17201"
  },
  {
    "id": "arXiv:2211.17204",
    "title": "Semisoft Task Clustering for Multi-Task Learning",
    "abstract": "Multi-task learning (MTL) aims to improve the performance of multiple related\nprediction tasks by leveraging useful information from them. Due to their\nflexibility and ability to reduce unknown coefficients substantially, the\ntask-clustering-based MTL approaches have attracted considerable attention.\nMotivated by the idea of semisoft clustering of data, we propose a semisoft\ntask clustering approach, which can simultaneously reveal the task cluster\nstructure for both pure and mixed tasks as well as select the relevant\nfeatures. The main assumption behind our approach is that each cluster has some\npure tasks, and each mixed task can be represented by a linear combination of\npure tasks in different clusters. To solve the resulting non-convex constrained\noptimization problem, we design an efficient three-step algorithm. The\nexperimental results based on synthetic and real-world datasets validate the\neffectiveness and efficiency of the proposed approach. Finally, we extend the\nproposed approach to a robust task clustering problem.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Yuzhao Zhang",
      "Yifan Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.17204"
  },
  {
    "id": "arXiv:2211.17207",
    "title": "Canal: A Flexible Interconnect Generator for Coarse-Grained  Reconfigurable Arrays",
    "abstract": "The architecture of a coarse-grained reconfigurable array (CGRA) interconnect\nhas a significant effect on not only the flexibility of the resulting\naccelerator, but also its power, performance, and area. Design decisions that\nhave complex trade-offs need to be explored to maintain efficiency and\nperformance across a variety of evolving applications. This paper presents\nCanal, a Python-embedded domain-specific language (eDSL) and compiler for\nspecifying and generating reconfigurable interconnects for CGRAs. Canal uses a\ngraph-based intermediate representation (IR) that allows for easy hardware\ngeneration and tight integration with place and route tools. We evaluate Canal\nby constructing both a fully static interconnect and a hybrid interconnect with\nready-valid signaling, and by conducting design space exploration of the\ninterconnect architecture by modifying the switch box topology, the number of\nrouting tracks, and the interconnect tile connections. Through the use of a\ngraph-based IR for CGRA interconnects, the eDSL, and the interconnect\ngeneration system, Canal enables fast design space exploration and creation of\nCGRA interconnects.",
    "descriptor": "\nComments: Preprint version\n",
    "authors": [
      "Jackson Melchert",
      "Keyi Zhang",
      "Yuchen Mei",
      "Mark Horowitz",
      "Christopher Torng",
      "Priyanka Raina"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.17207"
  },
  {
    "id": "arXiv:2211.17211",
    "title": "On Disperser/Lifting Properties of the Index and Inner-Product Functions",
    "abstract": "Query-to-communication lifting theorems, which connect the query complexity\nof a Boolean function to the communication complexity of an associated `lifted'\nfunction obtained by composing the function with many copies of another\nfunction known as a gadget, have been instrumental in resolving many open\nquestions in computational complexity. Several important complexity questions\ncould be resolved if we could make substantial improvements in the input size\nrequired for lifting with the Index function, from its current near-linear size\ndown to polylogarithmic in the number of inputs $N$ of the original function\nor, ideally, constant. The near-linear size bound was shown by Lovett, Meka,\nMertz, Pitassi and Zhang using a recent breakthrough improvement on the\nSunflower Lemma to show that a certain graph associated with the Index function\nof near-linear size is a disperser. They also stated a conjecture about the\nIndex function that is essential for further improvements in the size required\nfor lifting with Index using current techniques. In this paper we prove the\nfollowing;\n1) The conjecture of Lovett et al. is false when the size of the Index gadget\nis $\\log N-\\omega(1)$.\n2) Also, the Inner-Product function, which satisfies the disperser property\nat size $O(\\log N)$, does not have this property when its size is $\\log\nN-\\omega(1)$.\n3) Nonetheless, using Index gadgets of size at least 4, we prove a lifting\ntheorem for a restricted class of communication protocols in which one of the\nplayers is limited to sending parities of its inputs.\n4) Using the ideas from this lifting theorem, we derive a strong lifting\ntheorem from decision tree size to parity decision tree size. We use this to\nderive a general lifting theorem in proof complexity from tree-resolution size\nto tree-like $Res(\\oplus)$ refutation size, which yields many new exponential\nlower bounds on such proofs.",
    "descriptor": "",
    "authors": [
      "Paul Beame",
      "Sajin Koroth"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.17211"
  },
  {
    "id": "arXiv:2211.17214",
    "title": "Lifting to Parity Decision Trees Via Stifling",
    "abstract": "We show that the deterministic decision tree complexity of a (partial)\nfunction or relation $f$ lifts to the deterministic parity decision tree (PDT)\nsize complexity of the composed function/relation $f \\circ g$ as long as the\ngadget $g$ satisfies a property that we call stifling. We observe that several\nsimple gadgets of constant size, like Indexing on 3 input bits, Inner Product\non 4 input bits, Majority on 3 input bits and random functions, satisfy this\nproperty. It can be shown that existing randomized communication lifting\ntheorems ([G\\\"{o}\\\"{o}s, Pitassi, Watson. SICOMP'20], [Chattopadhyay et al.\nSICOMP'21]) imply PDT-size lifting. However there are two shortcomings of this\napproach: first they lift randomized decision tree complexity of $f$, which\ncould be exponentially smaller than its deterministic counterpart when either\n$f$ is a partial function or even a total search problem. Second, the size of\nthe gadgets in such lifting theorems are as large as logarithmic in the size of\nthe input to $f$. Reducing the gadget size to a constant is an important open\nproblem at the frontier of current research.\nOur result shows that even a random constant-size gadget does enable lifting\nto PDT size. Further, it also yields the first systematic way of turning lower\nbounds on the width of tree-like resolution proofs of the unsatisfiability of\nconstant-width CNF formulas to lower bounds on the size of tree-like proofs in\nthe resolution with parity system, i.e., $\\textit{Res}$($\\oplus$), of the\nunsatisfiability of closely related constant-width CNF formulas.",
    "descriptor": "",
    "authors": [
      "Arkadev Chattopadhyay",
      "Nikhil S. Mande",
      "Swagato Sanyal",
      "Suhail Sherif"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.17214"
  },
  {
    "id": "arXiv:2211.17215",
    "title": "An MPI-based parallel genetic algorithm for multiple geographical  feature label placement based on the hybrid of fixed-sliding models",
    "abstract": "Multiple geographical feature label placement (MGFLP) has been a fundamental\nproblem in geographic information visualization for decades. The nature of\nlabel positioning is proven an NP-hard problem, where the complexity of such a\nproblem is directly influenced by the volume of input datasets. Advances in\ncomputer technology and robust approaches have addressed the problem of\nlabeling. However, what is less considered in recent studies is the\ncomputational complexity of MGFLP, which significantly decreases the\nadoptability of those recently introduced approaches. In this study, an MPI\nparallel genetic algorithm is proposed for MGFLP based on a hybrid of fixed\nposition model and sliding model to label fixed-types of geographical features.\nTo evaluate the quality of label placement, a quality function is defined based\non four quality metrics, label-feature conflict, label-label conflict, label\nambiguity factor, and label position priority for points and polygons.\nExperimental results reveal that the proposed algorithm significantly reduced\nthe overall score of the quality function and the computational time of label\nplacement compared to the previous studies. The algorithm achieves a result in\nless than one minute with 6 label-feature conflicts, while Parallel-MS (Lessani\net al., 2021) obtains the result in more than 20 minutes with 12 label-feature\nconflicts for the same dataset.",
    "descriptor": "\nComments: 35 Pages, 11 Figures\n",
    "authors": [
      "Mohammad Naser Lessani",
      "Zhenlong Li",
      "Jiqiu Deng",
      "Zhiyong Guo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.17215"
  },
  {
    "id": "arXiv:2211.17217",
    "title": "A Tutorial on Neural Networks and Gradient-free Training",
    "abstract": "This paper presents a compact, matrix-based representation of neural networks\nin a self-contained tutorial fashion. Specifically, we develop neural networks\nas a composition of several vector-valued functions. Although neural networks\nare well-understood pictorially in terms of interconnected neurons, neural\nnetworks are mathematical nonlinear functions constructed by composing several\nvector-valued functions. Using basic results from linear algebra, we represent\na neural network as an alternating sequence of linear maps and scalar nonlinear\nfunctions, also known as activation functions. The training of neural networks\nrequires the minimization of a cost function, which in turn requires the\ncomputation of a gradient. Using basic multivariable calculus results, the cost\ngradient is also shown to be a function composed of a sequence of linear maps\nand nonlinear functions. In addition to the analytical gradient computation, we\nconsider two gradient-free training methods and compare the three training\nmethods in terms of convergence rate and prediction accuracy.",
    "descriptor": "\nComments: Submitted to 2023 American Control Conference. Contains 8 pages, 10 figures, and 3 tables\n",
    "authors": [
      "Turibius Rozario",
      "Arjun Trivedi",
      "Ankit Goel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17217"
  },
  {
    "id": "arXiv:2211.17218",
    "title": "Specification Architectural Viewpoint for Benefit-Cost-Risk-Aware  Decision-Making in Self-Adaptive Systems",
    "abstract": "Over the past two decades, researchers and engineers have extensively studied\nthe problem of how to enable a software system to deal with uncertain operating\nconditions. One prominent solution to this problem is self-adaptation, which\nequips a software system with a feedback loop that resolves uncertainties\nduring operation and adapts the system to deal with them when necessary. Most\nself-adaptation approaches developed so far use decision-making mechanisms that\nfocus on achieving a set of goals, i.e., that select for execution the\nadaptation option with the best estimated benefit. A few approaches have also\nconsidered the estimated (one-off) cost of executing the candidate adaptation\noptions. We argue that besides benefit and cost, decision-making in\nself-adaptive systems should also consider the estimated risk the system or its\nusers would be exposed to if an adaptation option were selected for execution.\nBalancing all three factors when evaluating the options for adaptation when\nmitigating uncertainty is essential, not only for satisfying the concerns of\nthe stakeholders, but also to ensure safety and public acceptance of\nself-adaptive systems. In this paper, we present an ISO/IEC/IEEE 42010\ncompatible architectural viewpoint that considers the estimated benefit, cost,\nand risk as core factors of each adaptation option considered in\nself-adaptation. The viewpoint aims to support software architects responsible\nfor designing robust decision-making mechanisms for self-adaptive systems.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Danny Weyns",
      "Paris Avegriou",
      "Radu Calinescu",
      "Sara M. Hezavehi",
      "Raffaela Mirandola",
      "Diego Perez-Palacin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.17218"
  },
  {
    "id": "arXiv:2211.17221",
    "title": "Interval Value Fuzzy Modeling and Indirect Adaptive Control of Quadrotor",
    "abstract": "In this paper, a combination of fuzzy clustering estimation and sliding mode\ncontrol is used to control a quadrotor system, whose mathematical model is\ncomplex and has unknown elements, including structure, parameters, and so on.\nIn addition, they may be affected by external environmental disturbances. At\nfirst, the nonlinear unknown part of the system is estimated by a fuzzy model,\nA new method is presented for constructing a Takagi-Sugeno (TS) interval-valued\nfuzzy model (IVFM) based on inputoutput data of the identified system.\nFollowing the construction of the fuzzy model that estimates the unknown part\nof the quadrotor system, a control and on-line adjusting of the fuzzy modeled\npart of dynamics is used. In this step, the system model will be estimated in\nadaptive form so that the dynamic equations can be used in sliding mode\ncontrol. Finally, the proposed technique is applied, and the simulation results\nare presented to show the effectiveness of this approach in controlling the\nquadrotor with unknown nonlinear dynamics.",
    "descriptor": "\nComments: 44 pages, 23 figures\n",
    "authors": [
      "Bouhentala Moufid",
      "Ghanai Mouna",
      "Chafaa Khiereddine"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.17221"
  },
  {
    "id": "arXiv:2211.17222",
    "title": "QMKPy: A Python Testbed for the Quadratic Multiple Knapsack Problem",
    "abstract": "QMKPy provides a Python framework for modeling and solving the quadratic\nmultiple knapsack problem (QMKP). It is primarily aimed at researchers who\ndevelop new solution algorithms for the QMKP. QMKPy therefore mostly functions\nas a testbed to quickly implement novel algorithms and compare their results\nwith existing ones. However, the package also already includes implementations\nof established algorithms for those who only need to solve a QMKP as part of\ntheir research.",
    "descriptor": "\nComments: 3 pages\n",
    "authors": [
      "Karl-Ludwig Besser",
      "Eduard A. Jorswieck"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.17222"
  },
  {
    "id": "arXiv:2211.17223",
    "title": "Topological Data Analysis for Speech Processing",
    "abstract": "We apply topological data analysis (TDA) to speech classification problems\nand to the introspection of a pretrained speech model, HuBERT. To this end, we\nintroduce a number of topological and algebraic features derived from\nTransformer attention maps and embeddings. We show that a simple linear\nclassifier built on top of such features outperforms a fine-tuned\nclassification head. In particular, we achieve an improvement of about $9\\%$\naccuracy and $5\\%$ ERR on four common datasets; on CREMA-D, the proposed\nfeature set reaches a new state of the art performance with accuracy $80.155$.\nWe also show that topological features are able to reveal functional roles of\nspeech Transformer heads; e.g., we find the heads capable to distinguish\nbetween pairs of sample sources (natural/synthetic) or voices without any\ndownstream fine-tuning. Our results demonstrate that TDA is a promising new\napproach for speech analysis, especially for tasks that require structural\nprediction.",
    "descriptor": "\nComments: Submitted to ICASSP 2023 conference, awaiting review\n",
    "authors": [
      "Eduard Tulchinskii",
      "Kristian Kuznetsov",
      "Laida Kushnareva",
      "Daniil Cherniavskii",
      "Serguei Barannikov",
      "Irina Piontkovskaya",
      "Sergey Nikolenko",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2211.17223"
  },
  {
    "id": "arXiv:2211.17226",
    "title": "GENNAPE: Towards Generalized Neural Architecture Performance Estimators",
    "abstract": "Predicting neural architecture performance is a challenging task and is\ncrucial to neural architecture design and search. Existing approaches either\nrely on neural performance predictors which are limited to modeling\narchitectures in a predefined design space involving specific sets of operators\nand connection rules, and cannot generalize to unseen architectures, or resort\nto zero-cost proxies which are not always accurate. In this paper, we propose\nGENNAPE, a Generalized Neural Architecture Performance Estimator, which is\npretrained on open neural architecture benchmarks, and aims to generalize to\ncompletely unseen architectures through combined innovations in network\nrepresentation, contrastive pretraining, and fuzzy clustering-based predictor\nensemble. Specifically, GENNAPE represents a given neural network as a\nComputation Graph (CG) of atomic operations which can model an arbitrary\narchitecture. It first learns a graph encoder via Contrastive Learning to\nencourage network separation by topological features, and then trains multiple\npredictor heads, which are soft-aggregated according to the fuzzy membership of\na neural network. Experiments show that GENNAPE pretrained on NAS-Bench-101 can\nachieve superior transferability to 5 different public neural network\nbenchmarks, including NAS-Bench-201, NAS-Bench-301, MobileNet and ResNet\nfamilies under no or minimum fine-tuning. We further introduce 3 challenging\nnewly labelled neural network benchmarks: HiAML, Inception and Two-Path, which\ncan concentrate in narrow accuracy ranges. Extensive experiments show that\nGENNAPE can correctly discern high-performance architectures in these families.\nFinally, when paired with a search algorithm, GENNAPE can find architectures\nthat improve accuracy while reducing FLOPs on three families.",
    "descriptor": "\nComments: Accepted at AAAI 2023; version includes supplementary materials with more details on introduced benchmarks; 14 Pages, 6 Figures, 10 Tables\n",
    "authors": [
      "Keith G. Mills",
      "Fred X. Han",
      "Jialin Zhang",
      "Fabian Chudak",
      "Ali Safari Mamaghani",
      "Mohammad Salameh",
      "Wei Lu",
      "Shangling Jui",
      "Di Niu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.17226"
  },
  {
    "id": "arXiv:2211.17228",
    "title": "AIO-P: Expanding Neural Performance Predictors Beyond Image  Classification",
    "abstract": "Evaluating neural network performance is critical to deep neural network\ndesign but a costly procedure. Neural predictors provide an efficient solution\nby treating architectures as samples and learning to estimate their performance\non a given task. However, existing predictors are task-dependent, predominantly\nestimating neural network performance on image classification benchmarks. They\nare also search-space dependent; each predictor is designed to make predictions\nfor a specific architecture search space with predefined topologies and set of\noperations. In this paper, we propose a novel All-in-One Predictor (AIO-P),\nwhich aims to pretrain neural predictors on architecture examples from\nmultiple, separate computer vision (CV) task domains and multiple architecture\nspaces, and then transfer to unseen downstream CV tasks or neural\narchitectures. We describe our proposed techniques for general graph\nrepresentation, efficient predictor pretraining and knowledge infusion\ntechniques, as well as methods to transfer to downstream tasks/spaces.\nExtensive experimental results show that AIO-P can achieve Mean Absolute Error\n(MAE) and Spearman's Rank Correlation (SRCC) below 1% and above 0.5,\nrespectively, on a breadth of target downstream CV tasks with or without\nfine-tuning, outperforming a number of baselines. Moreover, AIO-P can directly\ntransfer to new architectures not seen during training, accurately rank them\nand serve as an effective performance estimator when paired with an algorithm\ndesigned to preserve performance while reducing FLOPs.",
    "descriptor": "\nComments: Accepted at AAAI 2023; version includes supplementary material; 16 Pages, 4 Figures, 22 Tables\n",
    "authors": [
      "Keith G. Mills",
      "Di Niu",
      "Mohammad Salameh",
      "Weichen Qiu",
      "Fred X. Han",
      "Puyuan Liu",
      "Jialin Zhang",
      "Wei Lu",
      "Shangling Jui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17228"
  },
  {
    "id": "arXiv:2211.17230",
    "title": "The Bounded Gaussian Mechanism for Differential Privacy",
    "abstract": "The Gaussian mechanism is one differential privacy mechanism commonly used to\nprotect numerical data. However, it may be ill-suited to some applications\nbecause it has unbounded support and thus can produce invalid numerical answers\nto queries, such as negative ages or human heights in the tens of meters. One\ncan project such private values onto valid ranges of data, though such\nprojections lead to the accumulation of private query responses at the\nboundaries of such ranges, thereby harming accuracy. Motivated by the need for\nboth privacy and accuracy over bounded domains, we present a bounded Gaussian\nmechanism for differential privacy, which has support only on a given region.\nWe present both univariate and multivariate versions of this mechanism and\nillustrate a significant reduction in variance relative to comparable existing\nwork.",
    "descriptor": "\nComments: 27 pages, submitted to Journal of Privacy and Confidentiality\n",
    "authors": [
      "Bo Chen",
      "Matthew Hale"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.17230"
  },
  {
    "id": "arXiv:2211.17232",
    "title": "ObjCAViT: Improving Monocular Depth Estimation Using Natural Language  Models And Image-Object Cross-Attention",
    "abstract": "While monocular depth estimation (MDE) is an important problem in computer\nvision, it is difficult due to the ambiguity that results from the compression\nof a 3D scene into only 2 dimensions. It is common practice in the field to\ntreat it as simple image-to-image translation, without consideration for the\nsemantics of the scene and the objects within it. In contrast, humans and\nanimals have been shown to use higher-level information to solve MDE: prior\nknowledge of the nature of the objects in the scene, their positions and likely\nconfigurations relative to one another, and their apparent sizes have all been\nshown to help resolve this ambiguity.\nIn this paper, we present a novel method to enhance MDE performance by\nencouraging use of known-useful information about the semantics of objects and\ninter-object relationships within a scene. Our novel ObjCAViT module sources\nworld-knowledge from language models and learns inter-object relationships in\nthe context of the MDE problem using transformer attention, incorporating\napparent size information. Our method produces highly accurate depth maps, and\nwe obtain competitive results on the NYUv2 and KITTI datasets. Our ablation\nexperiments show that the use of language and cross-attention within the\nObjCAViT module increases performance. Code is released at\nhttps://github.com/DylanAuty/ObjCAViT.",
    "descriptor": "\nComments: 9 pages, 4 figures. Code is released at this https URL\n",
    "authors": [
      "Dylan Auty",
      "Krystian Mikolajczyk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17232"
  },
  {
    "id": "arXiv:2211.17234",
    "title": "Genetic Programming with Local Scoring",
    "abstract": "We present several new techniques for evolving code through sequences of\nmutations. Among these are (1) a method of local scoring assigning a score to\neach expression in a program, allowing us to more precisely identify buggy\ncode, (2) suppose-expressions which act as an intermediate step to evolving\nif-conditionals, and (3) cyclic evolution in which we evolve programs through\nphases of expansion and reduction. To demonstrate their merits, we provide a\nbasic proof-of-concept implementation which we show evolves correct code for\nseveral functions manipulating integers and lists, including some that are\nintractable by means of existing Genetic Programming techniques.",
    "descriptor": "",
    "authors": [
      "Max Vistrup"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.17234"
  },
  {
    "id": "arXiv:2211.17235",
    "title": "NeRFInvertor: High Fidelity NeRF-GAN Inversion for Single-shot Real  Image Animation",
    "abstract": "Nerf-based Generative models have shown impressive capacity in generating\nhigh-quality images with consistent 3D geometry. Despite successful synthesis\nof fake identity images randomly sampled from latent space, adopting these\nmodels for generating face images of real subjects is still a challenging task\ndue to its so-called inversion issue. In this paper, we propose a universal\nmethod to surgically fine-tune these NeRF-GAN models in order to achieve\nhigh-fidelity animation of real subjects only by a single image. Given the\noptimized latent code for an out-of-domain real image, we employ 2D loss\nfunctions on the rendered image to reduce the identity gap. Furthermore, our\nmethod leverages explicit and implicit 3D regularizations using the in-domain\nneighborhood samples around the optimized latent code to remove geometrical and\nvisual artifacts. Our experiments confirm the effectiveness of our method in\nrealistic, high-fidelity, and 3D consistent animation of real faces on multiple\nNeRF-GAN models across different datasets.",
    "descriptor": "",
    "authors": [
      "Yu Yin",
      "Kamran Ghasedi",
      "HsiangTao Wu",
      "Jiaolong Yang",
      "Xin Tong",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.17235"
  },
  {
    "id": "arXiv:2211.17239",
    "title": "Multi-level Parareal algorithm with Averaging",
    "abstract": "The present study is an extension of the work done in [16] and [10], where a\ntwo-level Parareal method with averaging was examined. The method proposed in\nthis paper is a multi-level Parareal method with arbitrarily many levels, which\nis not restricted to the two-level case. We give an asymptotic error estimate\nwhich reduces to the two-level estimate for the case when only two levels are\nconsidered. Introducing more than two levels has important consequences for the\naveraging procedure, as we choose separate averaging windows for each of the\ndifferent levels, which is an additional new feature of the present study. The\ndifferent averaging windows make the proposed method especially appropriate for\nmulti-scale problems, because we can introduce a level for each intrinsic scale\nof the problem and adapt the averaging procedure such that we reproduce the\nbehavior of the model on the particular scale resolved by the level.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Juliane Rosemeier",
      "Terry Haut",
      "Beth Wingate"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.17239"
  },
  {
    "id": "arXiv:2211.17244",
    "title": "Overcoming the Convex Relaxation Barrier for Neural Network Verification  via Nonconvex Low-Rank Semidefinite Relaxations",
    "abstract": "To rigorously certify the robustness of neural networks to adversarial\nperturbations, most state-of-the-art techniques rely on a triangle-shaped\nlinear programming (LP) relaxation of the ReLU activation. While the LP\nrelaxation is exact for a single neuron, recent results suggest that it faces\nan inherent \"convex relaxation barrier\" as additional activations are added,\nand as the attack budget is increased. In this paper, we propose a nonconvex\nrelaxation for the ReLU relaxation, based on a low-rank restriction of a\nsemidefinite programming (SDP) relaxation. We show that the nonconvex\nrelaxation has a similar complexity to the LP relaxation, but enjoys improved\ntightness that is comparable to the much more expensive SDP relaxation. Despite\nnonconvexity, we prove that the verification problem satisfies constraint\nqualification, and therefore a Riemannian staircase approach is guaranteed to\ncompute a near-globally optimal solution in polynomial time. Our experiments\nprovide evidence that our nonconvex relaxation almost completely overcome the\n\"convex relaxation barrier\" faced by the LP relaxation.",
    "descriptor": "",
    "authors": [
      "Hong-Ming Chiu",
      "Richard Y. Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.17244"
  },
  {
    "id": "arXiv:2211.17246",
    "title": "Pex: Memory-efficient Microcontroller Deep Learning through Partial  Execution",
    "abstract": "Embedded and IoT devices, largely powered by microcontroller units (MCUs),\ncould be made more intelligent by leveraging on-device deep learning. One of\nthe main challenges of neural network inference on an MCU is the extremely\nlimited amount of read-write on-chip memory (SRAM, < 512 kB). SRAM is consumed\nby the neural network layer (operator) input and output buffers, which,\ntraditionally, must be in memory (materialised) for an operator to execute. We\ndiscuss a novel execution paradigm for microcontroller deep learning, which\nmodifies the execution of neural networks to avoid materialising full buffers\nin memory, drastically reducing SRAM usage with no computation overhead. This\nis achieved by exploiting the properties of operators, which can\nconsume/produce a fraction of their input/output at a time. We describe a\npartial execution compiler, Pex, which produces memory-efficient execution\nschedules automatically by identifying subgraphs of operators whose execution\ncan be split along the feature (\"channel\") dimension. Memory usage is reduced\nfurther by targeting memory bottlenecks with structured pruning, leading to the\nco-design of the network architecture and its execution schedule. Our\nevaluation of image and audio classification models: (a) establishes\nstate-of-the-art performance in low SRAM usage regimes for considered tasks\nwith up to +2.9% accuracy increase; (b) finds that a 4x memory reduction is\npossible by applying partial execution alone, or up to 10.5x when using the\ncompiler-pruning co-design, while maintaining the classification accuracy\ncompared to prior work; (c) uses the recovered SRAM to process higher\nresolution inputs instead, increasing accuracy by up to +3.9% on Visual Wake\nWords.",
    "descriptor": "",
    "authors": [
      "Edgar Liberis",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17246"
  },
  {
    "id": "arXiv:2211.17249",
    "title": "Efficient Reinforcement Learning Through Trajectory Generation",
    "abstract": "A key barrier to using reinforcement learning (RL) in many real-world\napplications is the requirement of a large number of system interactions to\nlearn a good control policy. Off-policy and Offline RL methods have been\nproposed to reduce the number of interactions with the physical environment by\nlearning control policies from historical data. However, their performances\nsuffer from the lack of exploration and the distributional shifts in\ntrajectories once controllers are updated. Moreover, most RL methods require\nthat all states are directly observed, which is difficult to be attained in\nmany settings.\nTo overcome these challenges, we propose a trajectory generation algorithm,\nwhich adaptively generates new trajectories as if the system is being operated\nand explored under the updated control policies. Motivated by the fundamental\nlemma for linear systems, assuming sufficient excitation, we generate\ntrajectories from linear combinations of historical trajectories. For linear\nfeedback control, we prove that the algorithm generates trajectories with the\nexact distribution as if they are sampled from the real system using the\nupdated control policy. In particular, the algorithm extends to systems where\nthe states are not directly observed. Experiments show that the proposed method\nsignificantly reduces the number of sampled data needed for RL algorithms.",
    "descriptor": "",
    "authors": [
      "Wenqi Cui",
      "Linbin Huang",
      "Weiwei Yang",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.17249"
  },
  {
    "id": "arXiv:2211.17250",
    "title": "Safe Model-Free Reinforcement Learning using Disturbance-Observer-Based  Control Barrier Functions",
    "abstract": "Safe reinforcement learning (RL) with assured satisfaction of hard state\nconstraints during training has recently received a lot of attention. Safety\nfilters, e.g., based on control barrier functions (CBFs), provide a promising\nway for safe RL via modifying the unsafe actions of an RL agent on the fly.\nExisting safety filter-based approaches typically involve learning of uncertain\ndynamics and quantifying the learned model error, which leads to conservative\nfilters before a large amount of data is collected to learn a good model,\nthereby preventing efficient exploration. This paper presents a method for safe\nand efficient model-free RL using disturbance observers (DOBs) and control\nbarrier functions (CBFs). Unlike most existing safe RL methods that deal with\nhard state constraints, our method does not involve model learning, and\nleverages DOBs to accurately estimate the pointwise value of the uncertainty,\nwhich is then incorporated into a robust CBF condition to generate safe\nactions. The DOB-based CBF can be used as a safety filter with any model-free\nRL algorithms by minimally modifying the actions of an RL agent whenever\nnecessary to ensure safety throughout the learning process. Simulation results\non a unicycle and a 2D quadrotor demonstrate that the proposed method\noutperforms a state-of-the-art safe RL algorithm using CBFs and Gaussian\nprocesses-based model learning, in terms of safety violation rate, and sample\nand computational efficiency.",
    "descriptor": "",
    "authors": [
      "Yikun Cheng",
      "Pan Zhao",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.17250"
  },
  {
    "id": "arXiv:2211.17256",
    "title": "CLIPascene: Scene Sketching with Different Types and Levels of  Abstraction",
    "abstract": "In this paper, we present a method for converting a given scene image into a\nsketch using different types and multiple levels of abstraction. We distinguish\nbetween two types of abstraction. The first considers the fidelity of the\nsketch, varying its representation from a more precise portrayal of the input\nto a looser depiction. The second is defined by the visual simplicity of the\nsketch, moving from a detailed depiction to a sparse sketch. Using an explicit\ndisentanglement into two abstraction axes -- and multiple levels for each one\n-- provides users additional control over selecting the desired sketch based on\ntheir personal goals and preferences. To form a sketch at a given level of\nfidelity and simplification, we train two MLP networks. The first network\nlearns the desired placement of strokes, while the second network learns to\ngradually remove strokes from the sketch without harming its recognizability\nand semantics. Our approach is able to generate sketches of complex scenes\nincluding those with complex backgrounds (e.g., natural and urban settings) and\nsubjects (e.g., animals and people) while depicting gradual abstractions of the\ninput scene in terms of fidelity and simplicity.",
    "descriptor": "\nComments: Project page available at this https URL\n",
    "authors": [
      "Yael Vinker",
      "Yuval Alaluf",
      "Daniel Cohen-Or",
      "Ariel Shamir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.17256"
  },
  {
    "id": "arXiv:2211.17257",
    "title": "CREPE: Open-Domain Question Answering with False Presuppositions",
    "abstract": "Information seeking users often pose questions with false presuppositions,\nespecially when asking about unfamiliar topics. Most existing question\nanswering (QA) datasets, in contrast, assume all questions have well defined\nanswers. We introduce CREPE, a QA dataset containing a natural distribution of\npresupposition failures from online information-seeking forums. We find that\n25% of questions contain false presuppositions, and provide annotations for\nthese presuppositions and their corrections. Through extensive baseline\nexperiments, we show that adaptations of existing open-domain QA models can\nfind presuppositions moderately well, but struggle when predicting whether a\npresupposition is factually correct. This is in large part due to difficulty in\nretrieving relevant evidence passages from a large text corpus. CREPE provides\na benchmark to study question answering in the wild, and our analyses provide\navenues for future work in better modeling and further studying the task.",
    "descriptor": "",
    "authors": [
      "Xinyan Velocity Yu",
      "Sewon Min",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.17257"
  },
  {
    "id": "arXiv:2211.17259",
    "title": "Corner Cases of the Generalized Tau Method",
    "abstract": "Polynomial spectral methods provide fast, accurate, and flexible solvers for\nbroad ranges of PDEs with one bounded dimension, where the incorporation of\ngeneral boundary conditions is well understood. However, automating extensions\nto domains with multiple bounded dimensions is challenging because of\ndifficulties in implementing boundary conditions and imposing compatibility\nconditions at shared edges and corners. Past work has included various\nworkarounds, such as the anisotropic inclusion of partial boundary data at\nshared edges or approaches that only work for specific boundary conditions.\nHere we present a general system for imposing boundary and compatibility\nconditions for elliptic equations on hypercubes. We take an approach based on\nthe generalized tau method, which allows for a wide range of boundary\nconditions for many types of spectral methods. The generalized tau method has\nthe distinct advantage that the specified polynomial residual determines the\nexact algebraic solution; afterwards, any stable numerical scheme will find the\nsame result. We can, therefore, provide one-to-one comparisons to traditional\ncollocation and Galerkin methods within the tau framework. As an essential\nrequirement, we add specific tau corrections to the boundary conditions in\naddition to the bulk PDE. We then impose additional mutual compatibility\nconditions to ensure boundary conditions match at shared subsurfaces. Our\napproach works with general boundary conditions that commute on intersecting\nsubsurfaces, including Dirichlet, Neumann, Robin, and any combination of these\non all boundaries. The tau corrections and compatibility conditions can be\nfully isotropic and easily incorporated into existing solvers. We present the\nmethod explicitly for the Poisson equation in two and three dimensions and\ndescribe its extension to arbitrary elliptic equations (e.g. biharmonic) in any\ndimension.",
    "descriptor": "",
    "authors": [
      "Keaton J. Burns",
      "Daniel Fortunato",
      "Keith Julien",
      "Geoffrey M. Vasil"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.17259"
  },
  {
    "id": "arXiv:2211.17260",
    "title": "SinGRAF: Learning a 3D Generative Radiance Field for a Single Scene",
    "abstract": "Generative models have shown great promise in synthesizing photorealistic 3D\nobjects, but they require large amounts of training data. We introduce SinGRAF,\na 3D-aware generative model that is trained with a few input images of a single\nscene. Once trained, SinGRAF generates different realizations of this 3D scene\nthat preserve the appearance of the input while varying scene layout. For this\npurpose, we build on recent progress in 3D GAN architectures and introduce a\nnovel progressive-scale patch discrimination approach during training. With\nseveral experiments, we demonstrate that the results produced by SinGRAF\noutperform the closest related works in both quality and diversity by a large\nmargin.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Minjung Son",
      "Jeong Joon Park",
      "Leonidas Guibas",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17260"
  },
  {
    "id": "arXiv:2211.17262",
    "title": "Non-Deterministic Approximation Fixpoint Theory and Its Application in  Disjunctive Logic Programming",
    "abstract": "Approximation fixpoint theory (AFT) is an abstract and general algebraic\nframework for studying the semantics of nonmonotonic logics. It provides a\nunifying study of the semantics of different formalisms for nonmonotonic\nreasoning, such as logic programming, default logic and autoepistemic logic. In\nthis paper, we extend AFT to dealing with non-deterministic constructs that\nallow to handle indefinite information, represented e.g. by disjunctive\nformulas. This is done by generalizing the main constructions and corresponding\nresults of AFT to non-deterministic operators, whose ranges are sets of\nelements rather than single elements. The applicability and usefulness of this\ngeneralization is illustrated in the context of disjunctive logic programming.",
    "descriptor": "",
    "authors": [
      "Jesse Heyninck",
      "Ofer Arieli",
      "Bart Bogaerts"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.17262"
  },
  {
    "id": "arXiv:2211.17263",
    "title": "Plateau-free Differentiable Path Tracing",
    "abstract": "Current differentiable renderers provide light transport gradients with\nrespect to arbitrary scene parameters. However, the mere existence of these\ngradients does not guarantee useful update steps in an optimization. Instead,\ninverse rendering might not converge due to inherent plateaus, i.e., regions of\nzero gradient, in the objective function. We propose to alleviate this by\nconvolving the high-dimensional rendering function that maps scene parameters\nto images with an additional kernel that blurs the parameter space. We describe\ntwo Monte Carlo estimators to compute plateau-free gradients efficiently, i.e.,\nwith low variance, and show that these translate into net-gains in optimization\nerror and runtime performance. Our approach is a straightforward extension to\nboth black-box and differentiable renderers and enables optimization of\nproblems with intricate light transport, such as caustics or global\nillumination, that existing differentiable renderers do not converge on.",
    "descriptor": "",
    "authors": [
      "Michael Fischer",
      "Tobias Ritschel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.17263"
  },
  {
    "id": "arXiv:2211.17264",
    "title": "Interpretability with full complexity by constraining feature  information",
    "abstract": "Interpretability is a pressing issue for machine learning. Common approaches\nto interpretable machine learning constrain interactions between features of\nthe input, rendering the effects of those features on a model's output\ncomprehensible but at the expense of model complexity. We approach\ninterpretability from a new angle: constrain the information about the features\nwithout restricting the complexity of the model. Borrowing from information\ntheory, we use the Distributed Information Bottleneck to find optimal\ncompressions of each feature that maximally preserve information about the\noutput. The learned information allocation, by feature and by feature value,\nprovides rich opportunities for interpretation, particularly in problems with\nmany features and complex feature interactions. The central object of analysis\nis not a single trained model, but rather a spectrum of models serving as\napproximations that leverage variable amounts of information about the inputs.\nInformation is allocated to features by their relevance to the output, thereby\nsolving the problem of feature selection by constructing a learned continuum of\nfeature inclusion-to-exclusion. The optimal compression of each feature -- at\nevery stage of approximation -- allows fine-grained inspection of the\ndistinctions among feature values that are most impactful for prediction. We\ndevelop a framework for extracting insight from the spectrum of approximate\nmodels and demonstrate its utility on a range of tabular datasets.",
    "descriptor": "\nComments: project page: this https URL\n",
    "authors": [
      "Kieran A. Murphy",
      "Dani S. Bassett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17264"
  },
  {
    "id": "arXiv:2211.17267",
    "title": "Variational Laplace Autoencoders",
    "abstract": "Variational autoencoders employ an amortized inference model to approximate\nthe posterior of latent variables. However, such amortized variational\ninference faces two challenges: (1) the limited posterior expressiveness of\nfully-factorized Gaussian assumption and (2) the amortization error of the\ninference model. We present a novel approach that addresses both challenges.\nFirst, we focus on ReLU networks with Gaussian output and illustrate their\nconnection to probabilistic PCA. Building on this observation, we derive an\niterative algorithm that finds the mode of the posterior and apply\nfull-covariance Gaussian posterior approximation centered on the mode.\nSubsequently, we present a general framework named Variational Laplace\nAutoencoders (VLAEs) for training deep generative models. Based on the Laplace\napproximation of the latent variable posterior, VLAEs enhance the\nexpressiveness of the posterior while reducing the amortization error.\nEmpirical results on MNIST, Omniglot, Fashion-MNIST, SVHN and CIFAR10 show that\nthe proposed approach significantly outperforms other recent amortized or\niterative methods on the ReLU networks.",
    "descriptor": "\nComments: Published in ICML 2019\n",
    "authors": [
      "Yookoon Park",
      "Chris Dongjoo Kim",
      "Gunhee Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17267"
  },
  {
    "id": "arXiv:2211.06369",
    "title": "Enhancing and Adversarial: Improve ASR with Speaker Labels",
    "abstract": "ASR can be improved by multi-task learning (MTL) with domain enhancing or\ndomain adversarial training, which are two opposite objectives with the aim to\nincrease/decrease domain variance towards domain-aware/agnostic ASR,\nrespectively. In this work, we study how to best apply these two opposite\nobjectives with speaker labels to improve conformer-based ASR. We also propose\na novel adaptive gradient reversal layer for stable and effective adversarial\ntraining without tuning effort. Detailed analysis and experimental verification\nare conducted to show the optimal positions in the ASR neural network (NN) to\napply speaker enhancing and adversarial training. We also explore their\ncombination for further improvement, achieving the same performance as\ni-vectors plus adversarial training. Our best speaker-based MTL achieves 7\\%\nrelative improvement on the Switchboard Hub5'00 set. We also investigate the\neffect of such speaker-based MTL w.r.t. cleaner dataset and weaker ASR NN.",
    "descriptor": "\nComments: submitted to ICASSP 2023\n",
    "authors": [
      "Wei Zhou",
      "Haotian Wu",
      "Jingjing Xu",
      "Mohammad Zeineldeen",
      "Christoph L\u00fcscher",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.06369"
  },
  {
    "id": "arXiv:2211.16416",
    "title": "Exploiting Data Locality to Improve Performance of Heterogeneous Server  Clusters",
    "abstract": "We consider load balancing in large-scale heterogeneous server systems in the\npresence of data locality that imposes constraints on which tasks can be\nassigned to which servers. The constraints are naturally captured by a\nbipartite graph between the servers and the dispatchers handling assignments of\nvarious arrival flows. When a task arrives, the corresponding dispatcher\nassigns it to a server with the shortest queue among $d\\geq 2$ randomly\nselected servers obeying the above constraints. Server processing speeds are\nheterogeneous and they depend on the server-type. For a broad class of\nbipartite graphs, we characterize the limit of the appropriately scaled\noccupancy process, both on the process-level and in steady state, as the system\nsize becomes large. Using such a characterization, we show that data locality\nconstraints can be used to significantly improve the performance of\nheterogeneous systems. This is in stark contrast to either heterogeneous\nservers in a full flexible system or data locality constraints in systems with\nhomogeneous servers, both of which have been observed to degrade the system\nperformance. Extensive numerical experiments corroborate the theoretical\nresults.",
    "descriptor": "\nComments: 52 pages, 10 figures\n",
    "authors": [
      "Zhisheng Zhao",
      "Debankur Mukherjee",
      "Ruoyu Wu"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.16416"
  },
  {
    "id": "arXiv:2211.16508",
    "title": "Reinforced Genetic Algorithm for Structure-based Drug Design",
    "abstract": "Structure-based drug design (SBDD) aims to discover drug candidates by\nfinding molecules (ligands) that bind tightly to a disease-related protein\n(targets), which is the primary approach to computer-aided drug discovery.\nRecently, applying deep generative models for three-dimensional (3D) molecular\ndesign conditioned on protein pockets to solve SBDD has attracted much\nattention, but their formulation as probabilistic modeling often leads to\nunsatisfactory optimization performance. On the other hand, traditional\ncombinatorial optimization methods such as genetic algorithms (GA) have\ndemonstrated state-of-the-art performance in various molecular optimization\ntasks. However, they do not utilize protein target structure to inform design\nsteps but rely on a random-walk-like exploration, which leads to unstable\nperformance and no knowledge transfer between different tasks despite the\nsimilar binding physics. To achieve a more stable and efficient SBDD, we\npropose Reinforced Genetic Algorithm (RGA) that uses neural models to\nprioritize the profitable design steps and suppress random-walk behavior. The\nneural models take the 3D structure of the targets and ligands as inputs and\nare pre-trained using native complex structures to utilize the knowledge of the\nshared binding physics from different targets and then fine-tuned during\noptimization. We conduct thorough empirical studies on optimizing binding\naffinity to various disease targets and show that RGA outperforms the baselines\nin terms of docking scores and is more robust to random initializations. The\nablation study also indicates that the training on different targets helps\nimprove performance by leveraging the shared underlying physics of the binding\nprocesses. The code is available at\nhttps://github.com/futianfan/reinforced-genetic-algorithm.",
    "descriptor": "",
    "authors": [
      "Tianfan Fu",
      "Wenhao Gao",
      "Connor W. Coley",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16508"
  },
  {
    "id": "arXiv:2211.16509",
    "title": "Multimodal Learning for Multi-Omics: A Survey",
    "abstract": "With advanced imaging, sequencing, and profiling technologies, multiple omics\ndata become increasingly available and hold promises for many healthcare\napplications such as cancer diagnosis and treatment. Multimodal learning for\nintegrative multi-omics analysis can help researchers and practitioners gain\ndeep insights into human diseases and improve clinical decisions. However,\nseveral challenges are hindering the development in this area, including the\navailability of easily accessible open-source tools. This survey aims to\nprovide an up-to-date overview of the data challenges, fusion approaches,\ndatasets, and software tools from several new perspectives. We identify and\ninvestigate various omics data challenges that can help us understand the field\nbetter. We categorize fusion approaches comprehensively to cover existing\nmethods in this area. We collect existing open-source tools to facilitate their\nbroader utilization and development. We explore a broad range of omics data\nmodalities and a list of accessible datasets. Finally, we summarize future\ndirections that can potentially address existing gaps and answer the pressing\nneed to advance multimodal learning for multi-omics data analysis.",
    "descriptor": "\nComments: 52 pages, 3 figures\n",
    "authors": [
      "Sina Tabakhi",
      "Mohammod Naimul Islam Suvon",
      "Pegah Ahadian",
      "Haiping Lu"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16509"
  },
  {
    "id": "arXiv:2211.16518",
    "title": "Optimizing sparse fermionic Hamiltonians",
    "abstract": "We consider the problem of approximating the ground state energy of a\nfermionic Hamiltonian using a Gaussian state. In sharp contrast to the dense\ncase (Hastings & O'Donnell, 2022), we prove that strictly $q$-local\n$\\rm{\\textit{sparse}}$ fermionic Hamiltonians have a constant Gaussian\napproximation ratio; the result holds for any connectivity and interaction\nstrengths. Sparsity means that each fermion participates in a bounded number of\ninteractions, and strictly $q$-local means that each term involves exactly $q$\nfermionic (Majorana) operators. We extend our proof to give a constant Gaussian\napproximation ratio for sparse fermionic Hamiltonians with both quartic and\nquadratic terms. With additional work, we also prove a constant Gaussian\napproximation ratio for the so-called sparse SYK model with strictly $4$-local\ninteractions (sparse SYK-4 model). In each setting we show that the Gaussian\nstate can be efficiently determined. Finally, we prove that the $O(n^{-1/2})$\nGaussian approximation ratio for the normal (dense) SYK-$4$ model extends to\nSYK-$q$ for even $q>4$, with an approximation ratio of $O(n^{1/2 - q/4})$. Our\nresults identify non-sparseness as the prime reason that the SYK-4 model can\nfail to have a constant approximation ratio.",
    "descriptor": "\nComments: 34 pages, 4 figures\n",
    "authors": [
      "Yaroslav Herasymenko",
      "Maarten Stroeks",
      "Jonas Helsen",
      "Barbara Terhal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Computational Complexity (cs.CC)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2211.16518"
  },
  {
    "id": "arXiv:2211.16551",
    "title": "Numerical evidence against advantage with quantum fidelity kernels on  classical data",
    "abstract": "Quantum machine learning techniques are commonly considered one of the most\npromising candidates for demonstrating practical quantum advantage. In\nparticular, quantum kernel methods have been demonstrated to be able to learn\ncertain classically intractable functions efficiently if the kernel is\nwell-aligned with the target function. In the more general case, quantum\nkernels are known to suffer from exponential \"flattening\" of the spectrum as\nthe number of qubits grows, preventing generalization and necessitating the\ncontrol of the inductive bias by hyperparameters. We show that the\ngeneral-purpose hyperparameter tuning techniques proposed to improve the\ngeneralization of quantum kernels lead to the kernel becoming well-approximated\nby a classical kernel, removing the possibility of quantum advantage. We\nprovide extensive numerical evidence for this phenomenon utilizing multiple\npreviously studied quantum feature maps and both synthetic and real data. Our\nresults show that unless novel techniques are developed to control the\ninductive bias of quantum kernels, they are unlikely to provide a quantum\nadvantage on classical data.",
    "descriptor": "",
    "authors": [
      "Lucas Slattery",
      "Ruslan Shaydulin",
      "Shouvanik Chakrabarti",
      "Marco Pistoia",
      "Sami Khairy",
      "Stefan M. Wild"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16551"
  },
  {
    "id": "arXiv:2211.16566",
    "title": "Relative Sparsity for Medical Decision Problems",
    "abstract": "Existing statistical methods can be used to estimate a policy, or a mapping\nfrom covariates to decisions, which can then instruct decision makers. There is\ngreat interest in using such data-driven policies in healthcare. In healthcare,\nhowever, it is often important to explain to the healthcare provider, and to\nthe patient, how a new policy differs from the current standard of care. This\nend is facilitated if one can pinpoint the aspects (i.e., parameters) of the\npolicy that change most when moving from the standard of care to the new,\nsuggested policy. To this end, we adapt ideas from Trust Region Policy\nOptimization. In our work, however, unlike in Trust Region Policy Optimization,\nthe difference between the suggested policy and standard of care is required to\nbe sparse, aiding with interpretability. In particular, we trade off between\nmaximizing expected reward and minimizing the $L_1$ norm divergence between the\nparameters of the two policies. This yields \"relative sparsity,\" where, as a\nfunction of a tuning parameter, $\\lambda$, we can approximately control the\nnumber of parameters in our suggested policy that differ from their\ncounterparts in the standard of care. We develop our methodology for the\nobservational data setting. We propose a problem-specific criterion for\nselecting $\\lambda$, perform simulations, and illustrate our method with a\nreal, observational healthcare dataset, deriving a policy that is easy to\nexplain in the context of the current standard of care. Our work promotes the\nadoption of data-driven decision aids, which have great potential to improve\nhealth outcomes.",
    "descriptor": "\nComments: 27 pages, 4 figures, 2 tables\n",
    "authors": [
      "Samuel J. Weisenthal",
      "Sally W. Thurston",
      "Ashkan Ertefaie"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16566"
  },
  {
    "id": "arXiv:2211.16571",
    "title": "Brain Tumor MRI Classification using a Novel Deep Residual and Regional  CNN",
    "abstract": "Brain tumor classification is crucial for clinical analysis and an effective\ntreatment plan to cure patients. Deep learning models help radiologists to\naccurately and efficiently analyze tumors without manual intervention. However,\nbrain tumor analysis is challenging because of its complex structure, texture,\nsize, location, and appearance. Therefore, a novel deep residual and\nregional-based Res-BRNet Convolutional Neural Network (CNN) is developed for\neffective brain tumor (Magnetic Resonance Imaging) MRI classification. The\ndeveloped Res-BRNet employed Regional and boundary-based operations in a\nsystematic order within the modified spatial and residual blocks. Moreover, the\nspatial block extract homogeneity and boundary-defined features at the abstract\nlevel. Furthermore, the residual blocks employed at the target level\nsignificantly learn local and global texture variations of different classes of\nbrain tumors. The efficiency of the developed Res-BRNet is evaluated on a\nstandard dataset; collected from Kaggle and Figshare containing various tumor\ncategories, including meningioma, glioma, pituitary, and healthy images.\nExperiments prove that the developed Res-BRNet outperforms the standard CNN\nmodels and attained excellent performances (accuracy: 98.22%, sensitivity:\n0.9811, F-score: 0.9841, and precision: 0.9822) on challenging datasets.\nAdditionally, the performance of the proposed Res-BRNet indicates a strong\npotential for medical image-based disease analyses.",
    "descriptor": "\nComments: 21 pages, 11 figures, 4 tables\n",
    "authors": [
      "Mirza Mumtaz Zahoor",
      "Saddam Hussain Khan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16571"
  },
  {
    "id": "arXiv:2211.16583",
    "title": "Offline Policy Evaluation and Optimization under Confounding",
    "abstract": "With a few exceptions, work in offline reinforcement learning (RL) has so far\nassumed that there is no confounding. In a classical regression setting,\nconfounders introduce omitted variable bias and inhibit the identification of\ncausal effects. In offline RL, they prevent the identification of a policy's\nvalue, and therefore make it impossible to perform policy improvement. Using\nconventional methods in offline RL in the presence of confounding can therefore\nnot only lead to poor decisions and poor policies, but can also have disastrous\neffects in applications such as healthcare and education. We provide approaches\nfor both off-policy evaluation (OPE) and local policy optimization in the\nsettings of i.i.d. and global confounders. Theoretical and empirical results\nconfirm the validity and viability of these methods.",
    "descriptor": "",
    "authors": [
      "Kevin Tan",
      "Yangyi Lu",
      "Chinmaya Kausik",
      "YIxin Wang",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16583"
  },
  {
    "id": "arXiv:2211.16596",
    "title": "A Novel Statistical Independence Test for Dynamic Causal Discovery with  Rare Events",
    "abstract": "Causal phenomena associated with rare events frequently occur across a wide\nrange of engineering and mathematical problems, such as risk-sensitive safety\nanalysis, accident analysis and prevention, and extreme value theory. However,\ncurrent methods for causal discovery are often unable to uncover causal links\nbetween random variables that manifest only when the variables first experience\nlow-probability realizations. To address this issue, we introduce a novel\nalgorithm that performs statistical independence tests on data collected from\ntime-invariant dynamical systems in which rare but consequential events occur.\nWe seek to understand if the state of the dynamical system causally affects the\nlikelihood of the rare event. In particular, we exploit the time-invariance of\nthe underlying data to superimpose the occurrences of rare events, thus\ncreating a new dataset, with rare events are better represented, on which\nconditional independence tests can be more efficiently performed. We provide\nnon-asymptotic bounds for the consistency of our algorithm, and validate the\nperformance of our algorithm across various simulated scenarios, with\napplications to traffic accidents.",
    "descriptor": "",
    "authors": [
      "Chih-Yuan Chiu",
      "Kshitij Kulkarni",
      "Shankar Sastry"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16596"
  },
  {
    "id": "arXiv:2211.16641",
    "title": "Predicting China's CPI by Scanner Big Data",
    "abstract": "Scanner big data has potential to construct Consumer Price Index (CPI). This\nwork utilizes the scanner data of supermarket retail sales, which are provided\nby China Ant Business Alliance (CAA), to construct the Scanner-data Food\nConsumer Price Index (S-FCPI) in China, and the index reliability is verified\nby other macro indicators, especially by China's CPI. And not only that, we\nbuild multiple machine learning models based on S-FCPI to quantitatively\npredict the CPI growth rate in months, and qualitatively predict those\ndirections and levels. The prediction models achieve much better performance\nthan the traditional time series models in existing research. This work paves\nthe way to construct and predict price indexes through using scanner big data\nin China. S-FCPI can not only reflect the changes of goods prices in higher\nfrequency and wider geographic dimension than CPI, but also provide a new\nperspective for monitoring macroeconomic operation, predicting inflation and\nunderstanding other economic issues, which is beneficial supplement to China's\nCPI.",
    "descriptor": "\nComments: 14 pages, 5 figures, 7 tables\n",
    "authors": [
      "Zhenkun Zhou",
      "Zikun Song",
      "Tao Ren"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.16641"
  },
  {
    "id": "arXiv:2211.16654",
    "title": "Stochastic Parameterization of Column Physics using Generative  Adversarial Networks",
    "abstract": "We demonstrate the use of a probabilistic machine learning technique to\ndevelop stochastic parameterizations of atmospheric column-physics. After\nsuitable preprocessing of NASA's Modern-Era Retrospective analysis for Research\nand Applications, version 2 (MERRA2) data to minimize the effects of\nhigh-frequency, high-wavenumber component of MERRA2 estimate of vertical\nvelocity, we use generative adversarial networks to learn the probability\ndistribution of vertical profiles of diabatic sources conditioned on vertical\nprofiles of temperature and humidity. This may be viewed as an improvement over\nprevious similar but deterministic approaches that seek to alleviate both,\nshortcomings of human-designed physics parameterizations, and the computational\ndemand of the \"physics\" step in climate models.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "B.T. Nadiga",
      "X. Sun",
      "C. Nash"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16654"
  },
  {
    "id": "arXiv:2211.16684",
    "title": "Capturing long-range interaction with reciprocal space neural network",
    "abstract": "Machine Learning (ML) interatomic models and potentials have been widely\nemployed in simulations of materials. Long-range interactions often dominate in\nsome ionic systems whose dynamics behavior is significantly influenced.\nHowever, the long-range effect such as Coulomb and Van der Wales potential is\nnot considered in most ML interatomic potentials. To address this issue, we put\nforward a method that can take long-range effects into account for most ML\nlocal interatomic models with the reciprocal space neural network. The\nstructure information in real space is firstly transformed into reciprocal\nspace and then encoded into a reciprocal space potential or a global descriptor\nwith full atomic interactions. The reciprocal space potential and descriptor\nkeep full invariance of Euclidean symmetry and choice of the cell. Benefiting\nfrom the reciprocal-space information, ML interatomic models can be extended to\ndescribe the long-range potential including not only Coulomb but any other\nlong-range interaction. A model NaCl system considering Coulomb interaction and\nthe GaxNy system with defects are applied to illustrate the advantage of our\napproach. At the same time, our approach helps to improve the prediction\naccuracy of some global properties such as the band gap where the full atomic\ninteraction beyond local atomic environments plays a very important role. In\nsummary, our work has expanded the ability of current ML interatomic models and\npotentials when dealing with the long-range effect, hence paving a new way for\naccurate prediction of global properties and large-scale dynamic simulations of\nsystems with defects.",
    "descriptor": "\nComments: 15 pages, 3 figures, 3 tables\n",
    "authors": [
      "Hongyu Yu",
      "Liangliang Hong",
      "Shiyou Chen",
      "Xingao Gong",
      "Hongjun Xiang"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.16684"
  },
  {
    "id": "arXiv:2211.16694",
    "title": "MSV Challenge 2022: NPU-HC Speaker Verification System for Low-resource  Indian Languages",
    "abstract": "This report describes the NPU-HC speaker verification system submitted to the\nO-COCOSDA Multi-lingual Speaker Verification (MSV) Challenge 2022, which\nfocuses on developing speaker verification systems for low-resource Asian\nlanguages. We participate in the I-MSV track, which aims to develop speaker\nverification systems for various Indian languages. In this challenge, we first\nexplore different neural network frameworks for low-resource speaker\nverification. Then we leverage vanilla fine-tuning and weight transfer\nfine-tuning to transfer the out-domain pre-trained models to the in-domain\nIndian dataset. Specifically, the weight transfer fine-tuning aims to constrain\nthe distance of the weights between the pre-trained model and the fine-tuned\nmodel, which takes advantage of the previously acquired discriminative ability\nfrom the large-scale out-domain datasets and avoids catastrophic forgetting and\noverfitting at the same time. Finally, score fusion is adopted to further\nimprove performance. Together with the above contributions, we obtain 0.223%\nEER on the public evaluation set, ranking 2nd place on the leaderboard. On the\nprivate evaluation set, the EER of our submitted system is 2.123% and 0.630%\nfor the constrained and unconstrained sub-tasks of the I-MSV track\nrespectively, leading to both the 2nd place in the ranking.",
    "descriptor": "\nComments: 6pages, submitted to the 9th International Workshop on Vietnamese Language and Speech Processing\n",
    "authors": [
      "Yue Li",
      "Li Zhang",
      "Namin Wang",
      "Jie Liu",
      "Lei Xie"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.16694"
  },
  {
    "id": "arXiv:2211.16696",
    "title": "Automated anomaly-aware 3D segmentation of bones and cartilages in knee  MR images from the Osteoarthritis Initiative",
    "abstract": "In medical image analysis, automated segmentation of multi-component\nanatomical structures, which often have a spectrum of potential anomalies and\npathologies, is a challenging task. In this work, we develop a multi-step\napproach using U-Net-based neural networks to initially detect anomalies (bone\nmarrow lesions, bone cysts) in the distal femur, proximal tibia and patella\nfrom 3D magnetic resonance (MR) images of the knee in individuals with varying\ngrades of osteoarthritis. Subsequently, the extracted data are used for\ndownstream tasks involving semantic segmentation of individual bone and\ncartilage volumes as well as bone anomalies. For anomaly detection, the\nU-Net-based models were developed to reconstruct the bone profiles of the femur\nand tibia in images via inpainting so anomalous bone regions could be replaced\nwith close to normal appearances. The reconstruction error was used to detect\nbone anomalies. A second anomaly-aware network, which was compared to\nanomaly-na\\\"ive segmentation networks, was used to provide a final automated\nsegmentation of the femoral, tibial and patellar bones and cartilages from the\nknee MR images containing a spectrum of bone anomalies. The anomaly-aware\nsegmentation approach provided up to 58% reduction in Hausdorff distances for\nbone segmentations compared to the results from the anomaly-na\\\"ive\nsegmentation networks. In addition, the anomaly-aware networks were able to\ndetect bone lesions in the MR images with greater sensitivity and specificity\n(area under the receiver operating characteristic curve [AUC] up to 0.896)\ncompared to the anomaly-na\\\"ive segmentation networks (AUC up to 0.874).",
    "descriptor": "",
    "authors": [
      "Boyeong Woo",
      "Craig Engstrom",
      "William Baresic",
      "Jurgen Fripp",
      "Stuart Crozier",
      "Shekhar S. Chandra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16696"
  },
  {
    "id": "arXiv:2211.16700",
    "title": "AirCon: Over-the-Air Consensus for Wireless Blockchain Networks",
    "abstract": "Blockchain has been deemed as a promising solution for providing security and\nprivacy protection in the next-generation wireless networks. Large-scale\nconcurrent access for massive wireless devices to accomplish the consensus\nprocedure may consume prohibitive communication and computing resources, and\nthus may limit the application of blockchain in wireless conditions. As most\nexisting consensus protocols are designed for wired networks, directly apply\nthem for wireless users may exhaust their scarce spectrum and computing\nresources. In this paper, we propose AirCon, a byzantine fault-tolerant (BFT)\nconsensus protocol for wireless users via the over-the-air computation. The\nnovelty of AirCon is to take advantage of the intrinsic characteristic of the\nwireless channel and automatically achieve the consensus in the physical layer\nwhile receiving from the end users, which greatly reduces the communication and\ncomputational cost that would be caused by traditional consensus protocols. We\nimplement the AirCon protocol integrated into an LTE system and provide\nsolutions to the critical issues for over-the-air consensus implementation.\nExperimental results are provided to show the feasibility of the proposed\nprotocol, and simulation results to show the performance of the AirCon protocol\nunder different wireless conditions.",
    "descriptor": "\nComments: 13 pages, 22 figures\n",
    "authors": [
      "Xin Xie",
      "Cunqing Hua",
      "Pengwenlong Gu",
      "Wenchao Xu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.16700"
  },
  {
    "id": "arXiv:2211.16708",
    "title": "Statistical treatment of convolutional neural network super-resolution  of inland surface wind for subgrid-scale variability quantification",
    "abstract": "Machine learning models are frequently employed to perform either purely\nphysics-free or hybrid downscaling of climate data. However, the majority of\nthese implementations operate over relatively small downscaling factors of\nabout 4--6x. This study examines the ability of convolutional neural networks\n(CNN) to downscale surface wind speed data from three different coarse\nresolutions (25km, 48km, and 100km side-length grid cells) to 3km and\nadditionally focuses on the ability to recover subgrid-scale variability.\nWithin each downscaling factor, namely 8x, 16x, and 32x, we consider models\nthat produce fine-scale wind speed predictions as functions of different input\nfeatures: coarse wind fields only; coarse wind and fine-scale topography; and\ncoarse wind, topography, and temporal information in the form of a timestamp.\nFurthermore, we train one model at 25km to 3km resolution whose fine-scale\noutputs are probability density function parameters through which sample wind\nspeeds can be generated. All CNN predictions performed on one out-of-sample\ndata outperform classical interpolation. Models with coarse wind and fine\ntopography are shown to exhibit the best performance compared to other models\noperating across the same downscaling factor. Our timestamp encoding results in\nlower out-of-sample generalizability compared to other input configurations.\nOverall, the downscaling factor plays the largest role in model performance.",
    "descriptor": "",
    "authors": [
      "Daniel Getter",
      "Julie Bessac",
      "Johann Rudi",
      "Yan Feng"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16708"
  },
  {
    "id": "arXiv:2211.16709",
    "title": "Entropy fluctuation formulas of fermionic Gaussian states",
    "abstract": "We study the statistical behaviour of quantum entanglement in bipartite\nsystems over fermionic Gaussian states as measured by von Neumann entropy. The\nformulas of average von Neumann entropy with and without particle number\nconstrains have been recently obtained, whereas the main results of this work\nare the exact yet explicit formulas of variances for both cases. For the latter\ncase of no particle number constrain, the results resolve a recent conjecture\non the corresponding variance. Different than existing methods in computing\nvariances over other generic state models, the key ingredient in proving the\nresults of this work relies on a new simplification framework. The framework\nconsists of a set of new tools in simplifying finite summations of what we\nrefer to as dummy summation and re-summation techniques. As a byproduct, the\nproposed framework leads to various new transformation formulas of\nhypergeometric functions.",
    "descriptor": "\nComments: 64 pages, 3 figures\n",
    "authors": [
      "Youyi Huang",
      "Lu Wei"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.16709"
  },
  {
    "id": "arXiv:2211.16733",
    "title": "A minor extension of the logistic equation for growth of word counts on  online media: Parametric description of diversity of growth phenomena in  society",
    "abstract": "To understand the growing phenomena of new vocabulary on nationwide online\nsocial media, we analyzed monthly word count time series extracted from\napproximately 1 billion Japanese blog articles from 2007 to 2019. In\nparticular, we first introduced the extended logistic equation by adding one\nparameter to the original equation and showed that the model can consistently\nreproduce various patterns of actual growth curves, such as the logistic\nfunction, linear growth, and finite-time divergence. Second, by analyzing the\nmodel parameters, we found that the typical growth pattern is not only a\nlogistic function, which often appears in various complex systems, but also a\nnontrivial growth curve that starts with an exponential function and\nasymptotically approaches a power function without a steady state. Furthermore,\nwe observed a connection between the functional form of growth and the\npeak-out. Finally, we showed that the proposed model and statistical properties\nare also valid for Google Trends data (English, French, Spanish, and Japanese),\nwhich is a time series of the nationwide popularity of search queries.",
    "descriptor": "",
    "authors": [
      "Hayafumi Watanabe"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.16733"
  },
  {
    "id": "arXiv:2211.16742",
    "title": "Protein Language Models and Structure Prediction: Connection and  Progression",
    "abstract": "The prediction of protein structures from sequences is an important task for\nfunction prediction, drug design, and related biological processes\nunderstanding. Recent advances have proved the power of language models (LMs)\nin processing the protein sequence databases, which inherit the advantages of\nattention networks and capture useful information in learning representations\nfor proteins. The past two years have witnessed remarkable success in tertiary\nprotein structure prediction (PSP), including evolution-based and\nsingle-sequence-based PSP. It seems that instead of using energy-based models\nand sampling procedures, protein language model (pLM)-based pipelines have\nemerged as mainstream paradigms in PSP. Despite the fruitful progress, the PSP\ncommunity needs a systematic and up-to-date survey to help bridge the gap\nbetween LMs in the natural language processing (NLP) and PSP domains and\nintroduce their methodologies, advancements and practical applications. To this\nend, in this paper, we first introduce the similarities between protein and\nhuman languages that allow LMs extended to pLMs, and applied to protein\ndatabases. Then, we systematically review recent advances in LMs and pLMs from\nthe perspectives of network architectures, pre-training strategies,\napplications, and commonly-used protein databases. Next, different types of\nmethods for PSP are discussed, particularly how the pLM-based architectures\nfunction in the process of protein folding. Finally, we identify challenges\nfaced by the PSP community and foresee promising research directions along with\nthe advances of pLMs. This survey aims to be a hands-on guide for researchers\nto understand PSP methods, develop pLMs and tackle challenging problems in this\nfield for practical purposes.",
    "descriptor": "",
    "authors": [
      "Bozhen Hu",
      "Jun Xia",
      "Jiangbin Zheng",
      "Cheng Tan",
      "Yufei Huang",
      "Yongjie Xu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16742"
  },
  {
    "id": "arXiv:2211.16757",
    "title": "Taming Hyperparameter Tuning in Continuous Normalizing Flows Using the  JKO Scheme",
    "abstract": "A normalizing flow (NF) is a mapping that transforms a chosen probability\ndistribution to a normal distribution. Such flows are a common technique used\nfor data generation and density estimation in machine learning and data\nscience. The density estimate obtained with a NF requires a change of variables\nformula that involves the computation of the Jacobian determinant of the NF\ntransformation. In order to tractably compute this determinant, continuous\nnormalizing flows (CNF) estimate the mapping and its Jacobian determinant using\na neural ODE. Optimal transport (OT) theory has been successfully used to\nassist in finding CNFs by formulating them as OT problems with a soft penalty\nfor enforcing the standard normal distribution as a target measure. A drawback\nof OT-based CNFs is the addition of a hyperparameter, $\\alpha$, that controls\nthe strength of the soft penalty and requires significant tuning. We present\nJKO-Flow, an algorithm to solve OT-based CNF without the need of tuning\n$\\alpha$. This is achieved by integrating the OT CNF framework into a\nWasserstein gradient flow framework, also known as the JKO scheme. Instead of\ntuning $\\alpha$, we repeatedly solve the optimization problem for a fixed\n$\\alpha$ effectively performing a JKO update with a time-step $\\alpha$. Hence\nwe obtain a \"divide and conquer\" algorithm by repeatedly solving simpler\nproblems instead of solving a potentially harder problem with large $\\alpha$.",
    "descriptor": "",
    "authors": [
      "Alexander Vidal",
      "Samy Wu Fung",
      "Luis Tenorio",
      "Stanley Osher",
      "Levon Nurbekyan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16757"
  },
  {
    "id": "arXiv:2211.16806",
    "title": "Toward Robust Diagnosis: A Contour Attention Preserving Adversarial  Defense for COVID-19 Detection",
    "abstract": "As the COVID-19 pandemic puts pressure on healthcare systems worldwide, the\ncomputed tomography image based AI diagnostic system has become a sustainable\nsolution for early diagnosis. However, the model-wise vulnerability under\nadversarial perturbation hinders its deployment in practical situation. The\nexisting adversarial training strategies are difficult to generalized into\nmedical imaging field challenged by complex medical texture features. To\novercome this challenge, we propose a Contour Attention Preserving (CAP) method\nbased on lung cavity edge extraction. The contour prior features are injected\nto attention layer via a parameter regularization and we optimize the robust\nempirical risk with hybrid distance metric. We then introduce a new\ncross-nation CT scan dataset to evaluate the generalization capability of the\nadversarial robustness under distribution shift. Experimental results indicate\nthat the proposed method achieves state-of-the-art performance in multiple\nadversarial defense and generalization tasks. The code and dataset are\navailable at https://github.com/Quinn777/CAP.",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Kun Xiang",
      "Xing Zhang",
      "Jinwen She",
      "Jinpeng Liu",
      "Haohan Wang",
      "Shiqi Deng",
      "Shancheng Jiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16806"
  },
  {
    "id": "arXiv:2211.16823",
    "title": "Algebraic-geometric codes with many automorphisms arising from Galois  points",
    "abstract": "A method of constructing algebraic-geometric codes with many automorphisms\narising from Galois points for algebraic curves is presented.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Satoru Fukasawa"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2211.16823"
  },
  {
    "id": "arXiv:2211.16834",
    "title": "MLC at HECKTOR 2022: The Effect and Importance of Training Data when  Analyzing Cases of Head and Neck Tumors using Machine Learning",
    "abstract": "Head and neck cancers are the fifth most common cancer worldwide, and\nrecently, analysis of Positron Emission Tomography (PET) and Computed\nTomography (CT) images has been proposed to identify patients with a prognosis.\nEven though the results look promising, more research is needed to further\nvalidate and improve the results. This paper presents the work done by team MLC\nfor the 2022 version of the HECKTOR grand challenge held at MICCAI 2022. For\nTask 1, the automatic segmentation task, our approach was, in contrast to\nearlier solutions using 3D segmentation, to keep it as simple as possible using\na 2D model, analyzing every slice as a standalone image. In addition, we were\ninterested in understanding how different modalities influence the results. We\nproposed two approaches; one using only the CT scans to make predictions and\nanother using a combination of the CT and PET scans. For Task 2, the prediction\nof recurrence-free survival, we first proposed two approaches, one where we\nonly use patient data and one where we combined the patient data with\nsegmentations from the image model. For the prediction of the first two\napproaches, we used Random Forest. In our third approach, we combined patient\ndata and image data using XGBoost. Low kidney function might worsen cancer\nprognosis. In this approach, we therefore estimated the kidney function of the\npatients and included it as a feature. Overall, we conclude that our simple\nmethods were not able to compete with the highest-ranking submissions, but we\nstill obtained reasonably good scores. We also got interesting insights into\nhow the combination of different modalities can influence the segmentation and\npredictions.",
    "descriptor": "\nComments: Submitted to this https URL\n",
    "authors": [
      "Vajira Thambawita",
      "Andrea M. Stor\u00e5s",
      "Steven A. Hicks",
      "P\u00e5l Halvorsen",
      "Michael A. Riegler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16834"
  },
  {
    "id": "arXiv:2211.16845",
    "title": "Non-volatile leaky integrate-and-fire neurons with domain walls in  antiferromagnetic insulators",
    "abstract": "Despite the rapid development of powerful supercomputers in recent years, the\nhuman brain still has some abilities that outperform modern computers which are\nbased on the von Neumann architecture. The human brain is much more energy\nefficient than state-of-the-art digital computers and can at the same time\nperform complex tasks such as pattern recognition. The brain-inspired\nneuromorphic computing paradigm is a promising path towards next generation\nanalogue computers with fundamentally different architecture. The building\nblocks of the human brain are neurons with leaky integrate-and-fire mechanisms.\nIn this work, using the advantage of antiferromagnetic insulators, we propose a\nnon-volatile spintronic-based neuron. In our proposal, an antiferromagnetic\ndomain wall in the presence of a magnetic anisotropy gradient mimics a\nbiological neuron with leaky and integrative properties. This single neuron is\ncontrolled by polarized antiferromagnetic magnons, activated by either a\nmagnetic field pulse or a spin transfer torque mechanism. We propose that this\nsingle neuron, based on antiferromagnetic insulators, is faster and more energy\nefficient than other metallic ferromagnetic-based neurons.",
    "descriptor": "",
    "authors": [
      "Johannes W. Austefjord",
      "Verena Brehm",
      "Serban Lepadatu",
      "Alireza Qaiumzadeh"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.16845"
  },
  {
    "id": "arXiv:2211.16852",
    "title": "Challenging mitosis detection algorithms: Global labels allow centroid  localization",
    "abstract": "Mitotic activity is a crucial proliferation biomarker for the diagnosis and\nprognosis of different types of cancers. Nevertheless, mitosis counting is a\ncumbersome process for pathologists, prone to low reproducibility, due to the\nlarge size of augmented biopsy slides, the low density of mitotic cells, and\npattern heterogeneity. To improve reproducibility, deep learning methods have\nbeen proposed in the last years using convolutional neural networks. However,\nthese methods have been hindered by the process of data labelling, which\nusually solely consist of the mitosis centroids. Therefore, current literature\nproposes complex algorithms with multiple stages to refine the labels at pixel\nlevel, and to reduce the number of false positives. In this work, we propose to\navoid complex scenarios, and we perform the localization task in a weakly\nsupervised manner, using only image-level labels on patches. The results\nobtained on the publicly available TUPAC16 dataset are competitive with\nstate-of-the-art methods, using only one training phase. Our method achieves an\nF1-score of 0.729 and challenges the efficiency of previous methods, which\nrequired multiple stages and strong mitosis location information.",
    "descriptor": "\nComments: Presented at IDEAL 2022\n",
    "authors": [
      "Claudio Fernandez-Mart\u00edn",
      "Umay Kiraz",
      "Julio Silva-Rodr\u00edguez",
      "Sandra Morales",
      "Emiel Janssen",
      "Valery Naranjo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16852"
  },
  {
    "id": "arXiv:2211.16854",
    "title": "Resolving Prime Modules: The Structure of Pseudo-cographs and  Galled-Tree Explainable Graphs",
    "abstract": "The modular decomposition of a graph $G$ is a natural construction to capture\nkey features of $G$ in terms of a labeled tree $(T,t)$ whose vertices are\nlabeled as \"series\" ($1$), \"parallel\" ($0$) or \"prime\". However, full\ninformation of $G$ is provided by its modular decomposition tree $(T,t)$ only,\nif $G$ is a cograph, i.e., $G$ does not contain prime modules. In this case,\n$(T,t)$ explains $G$, i.e., $\\{x,y\\}\\in E(G)$ if and only if the lowest common\nancestor $\\mathrm{lca}_T(x,y)$ of $x$ and $y$ has label \"$1$\". Pseudo-cographs,\nor, more general, GaTEx graphs $G$ are graphs that can be explained by labeled\ngalled-trees, i.e., labeled networks $(N,t)$ that are obtained from the modular\ndecomposition tree $(T,t)$ of $G$ by replacing the prime vertices in $T$ by\nsimple labeled cycles. GaTEx graphs can be recognized and labeled galled-trees\nthat explain these graphs can be constructed in linear time.\nIn this contribution, we provide a novel characterization of GaTEx graphs in\nterms of a set $\\mathfrak{F}_{\\mathrm{GT}}$ of 25 forbidden induced subgraphs.\nThis characterization, in turn, allows us to show that GaTEx graphs are closely\nrelated to many other well-known graph classes such as $P_4$-sparse and\n$P_4$-reducible graphs, weakly-chordal graphs, perfect graphs with perfect\norder, comparability and permutation graphs, murky graphs as well as interval\ngraphs, Meyniel graphs or very strongly-perfect and brittle graphs.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Marc Hellmuth",
      "Guillaume E. Scholz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.16854"
  },
  {
    "id": "arXiv:2211.16855",
    "title": "ATASI-Net: An Efficient Sparse Reconstruction Network for Tomographic  SAR Imaging with Adaptive Threshold",
    "abstract": "Tomographic SAR technique has attracted remarkable interest for its ability\nof three-dimensional resolving along the elevation direction via a stack of SAR\nimages collected from different cross-track angles. The emerged compressed\nsensing (CS)-based algorithms have been introduced into TomoSAR considering its\nsuper-resolution ability with limited samples. However, the conventional\nCS-based methods suffer from several drawbacks, including weak noise\nresistance, high computational complexity, and complex parameter fine-tuning.\nAiming at efficient TomoSAR imaging, this paper proposes a novel efficient\nsparse unfolding network based on the analytic learned iterative shrinkage\nthresholding algorithm (ALISTA) architecture with adaptive threshold, named\nAdaptive Threshold ALISTA-based Sparse Imaging Network (ATASI-Net). The weight\nmatrix in each layer of ATASI-Net is pre-computed as the solution of an\noff-line optimization problem, leaving only two scalar parameters to be learned\nfrom data, which significantly simplifies the training stage. In addition,\nadaptive threshold is introduced for each azimuth-range pixel, enabling the\nthreshold shrinkage to be not only layer-varied but also element-wise.\nMoreover, the final learned thresholds can be visualized and combined with the\nSAR image semantics for mutual feedback. Finally, extensive experiments on\nsimulated and real data are carried out to demonstrate the effectiveness and\nefficiency of the proposed method.",
    "descriptor": "",
    "authors": [
      "Muhan Wang",
      "Zhe Zhang",
      "Xiaolan Qiu",
      "Silin Gao",
      "Yue Wang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16855"
  },
  {
    "id": "arXiv:2211.16859",
    "title": "Unknown Input Observer Design for a class of Semilinear Hyperbolic  Systems with Dynamic Boundary Conditions",
    "abstract": "The problem of unknown input observer design is considered for coupled\nPDE/ODE systems subject to incremental sector bounded nonlinearities and\nunknown boundary inputs. Assuming available measurements at the boundary of the\ndistributed domain, the synthesis of the unknown input observer is based on\nLyapunov methods and convex optimization. Numerical simulations support and\nconfirm the theoretical findings, illustrating the robust estimation\nperformances of the proposed nonlinear unknown input observer.",
    "descriptor": "\nComments: Extended version of the paper to appear in the IEEE Transactions on Automatic Control\n",
    "authors": [
      "Andrea Cristofaro",
      "Francesco Ferrante"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.16859"
  },
  {
    "id": "arXiv:2211.16866",
    "title": "SNAC: Speaker-normalized affine coupling layer in flow-based  architecture for zero-shot multi-speaker text-to-speech",
    "abstract": "Zero-shot multi-speaker text-to-speech (ZSM-TTS) models aim to generate a\nspeech sample with the voice characteristic of an unseen speaker. The main\nchallenge of ZSM-TTS is to increase the overall speaker similarity for unseen\nspeakers. One of the most successful speaker conditioning methods for\nflow-based multi-speaker text-to-speech (TTS) models is to utilize the\nfunctions which predict the scale and bias parameters of the affine coupling\nlayers according to the given speaker embedding vector. In this letter, we\nimprove on the previous speaker conditioning method by introducing a\nspeaker-normalized affine coupling (SNAC) layer which allows for unseen speaker\nspeech synthesis in a zero-shot manner leveraging a normalization-based\nconditioning technique. The newly designed coupling layer explicitly normalizes\nthe input by the parameters predicted from a speaker embedding vector while\ntraining, enabling an inverse process of denormalizing for a new speaker\nembedding at inference. The proposed conditioning scheme yields the\nstate-of-the-art performance in terms of the speech quality and speaker\nsimilarity in a ZSM-TTS setting.",
    "descriptor": "\nComments: Accepted to IEEE Signal Processing Letters\n",
    "authors": [
      "Byoung Jin Choi",
      "Myeonghun Jeong",
      "Joun Yeop Lee",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.16866"
  },
  {
    "id": "arXiv:2211.16871",
    "title": "A Deep Learning Approach to the Prediction of Drug Side-Effects on  Molecular Graphs",
    "abstract": "Predicting drug side-effects before they occur is a key task in keeping the\nnumber of drug-related hospitalizations low and to improve drug discovery\nprocesses. Automatic predictors of side-effects generally are not able to\nprocess the structure of the drug, resulting in a loss of information. Graph\nneural networks have seen great success in recent years, thanks to their\nability of exploiting the information conveyed by the graph structure and\nlabels. These models have been used in a wide variety of biological\napplications, among which the prediction of drug side-effects on a large\nknowledge graph. Exploiting the molecular graph encoding the structure of the\ndrug represents a novel approach, in which the problem is formulated as a\nmulti-class multi-label graph-focused classification. We developed a\nmethodology to carry out this task, using recurrent Graph Neural Networks, and\nbuilding a dataset from freely accessible and well established data sources.\nThe results show that our method has an improved classification capability,\nunder many parameters and metrics, with respect to previously available\npredictors.",
    "descriptor": "\nComments: 16 pages, 2 figures, under review\n",
    "authors": [
      "Pietro Bongini",
      "Elisa Messori",
      "Niccol\u00f2 Pancino",
      "Monica Bianchini"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.16871"
  },
  {
    "id": "arXiv:2211.16881",
    "title": "Generalized Deep Learning-based Proximal Gradient Descent for MR  Reconstruction",
    "abstract": "The data consistency for the physical forward model is crucial in inverse\nproblems, especially in MR imaging reconstruction. The standard way is to\nunroll an iterative algorithm into a neural network with a forward model\nembedded. The forward model always changes in clinical practice, so the\nlearning component's entanglement with the forward model makes the\nreconstruction hard to generalize. The proposed method is more generalizable\nfor different MR acquisition settings by separating the forward model from the\ndeep learning component. The deep learning-based proximal gradient descent was\nproposed to create a learned regularization term independent of the forward\nmodel. We applied the one-time trained regularization term to different MR\nacquisition settings to validate the proposed method and compared the\nreconstruction with the commonly used $\\ell_1$ regularization. We showed ~3 dB\nimprovement in the peak signal to noise ratio, compared with conventional\n$\\ell_1$ regularized reconstruction. We demonstrated the flexibility of the\nproposed method in choosing different undersampling patterns. We also evaluated\nthe effect of parameter tuning for the deep learning regularization.",
    "descriptor": "\nComments: Keywords: MRI reconstruction, Deep Learning, Proximal gradient descent, Learned regularization term\n",
    "authors": [
      "Guanxiong Luo",
      "Mengmeng Kuang",
      "Peng Cao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16881"
  },
  {
    "id": "arXiv:2211.16909",
    "title": "Learning non-stationary and discontinuous functions using clustering,  classification and Gaussian process modelling",
    "abstract": "Surrogate models have shown to be an extremely efficient aid in solving\nengineering problems that require repeated evaluations of an expensive\ncomputational model. They are built by sparsely evaluating the costly original\nmodel and have provided a way to solve otherwise intractable problems. A\ncrucial aspect in surrogate modelling is the assumption of smoothness and\nregularity of the model to approximate. This assumption is however not always\nmet in reality. For instance in civil or mechanical engineering, some models\nmay present discontinuities or non-smoothness, e.g., in case of instability\npatterns such as buckling or snap-through. Building a single surrogate model\ncapable of accounting for these fundamentally different behaviors or\ndiscontinuities is not an easy task. In this paper, we propose a three-stage\napproach for the approximation of non-smooth functions which combines\nclustering, classification and regression. The idea is to split the space\nfollowing the localized behaviors or regimes of the system and build local\nsurrogates that are eventually assembled. A sequence of well-known machine\nlearning techniques are used: Dirichlet process mixtures models (DPMM), support\nvector machines and Gaussian process modelling. The approach is tested and\nvalidated on two analytical functions and a finite element model of a tensile\nmembrane structure.",
    "descriptor": "",
    "authors": [
      "M. Moustapha",
      "B. Sudret"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.16909"
  },
  {
    "id": "arXiv:2211.16928",
    "title": "Knowledge Distillation based Degradation Estimation for Blind  Super-Resolution",
    "abstract": "Blind image super-resolution (Blind-SR) aims to recover a high-resolution\n(HR) image from its corresponding low-resolution (LR) input image with unknown\ndegradations. Most of the existing works design an explicit degradation\nestimator for each degradation to guide SR. However, it is infeasible to\nprovide concrete labels of multiple degradation combinations (\\eg, blur, noise,\njpeg compression) to supervise the degradation estimator training. In addition,\nthese special designs for certain degradation, such as blur, impedes the models\nfrom being generalized to handle different degradations. To this end, it is\nnecessary to design an implicit degradation estimator that can extract\ndiscriminative degradation representation for all degradations without relying\non the supervision of degradation ground-truth. In this paper, we propose a\nKnowledge Distillation based Blind-SR network (KDSR). It consists of a\nknowledge distillation based implicit degradation estimator network (KD-IDE)\nand an efficient SR network. To learn the KDSR model, we first train a teacher\nnetwork: KD-IDE$_{T}$. It takes paired HR and LR patches as inputs and is\noptimized with the SR network jointly. Then, we further train a student network\nKD-IDE$_{S}$, which only takes LR images as input and learns to extract the\nsame implicit degradation representation (IDR) as KD-IDE$_{T}$. In addition, to\nfully use extracted IDR, we design a simple, strong, and efficient IDR based\ndynamic convolution residual block (IDR-DCRB) to build an SR network. We\nconduct extensive experiments under classic and real-world degradation\nsettings. The results show that KDSR achieves SOTA performance and can\ngeneralize to various degradation processes. The source codes and pre-trained\nmodels will be released.",
    "descriptor": "",
    "authors": [
      "Bin Xia",
      "Yulun Zhang",
      "Yitong Wang",
      "Yapeng Tian",
      "Wenming Yang",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16928"
  },
  {
    "id": "arXiv:2211.16930",
    "title": "Differentiable optimization of the Debye-Wolf integral for light shaping  and adaptive optics in two-photon microscopy",
    "abstract": "Control of light through a microscope objective with a high numerical\naperture is a common requirement in applications such as optogenetics, adaptive\noptics, or laser processing. Light propagation, including polarization effects,\ncan be described under these conditions using the Debye-Wolf diffraction\nintegral. Here, we take advantage of differentiable optimization and machine\nlearning for efficiently optimizing the Debye-Wolf integral for such\napplications. For light shaping we show that this optimization approach is\nsuitable for engineering arbitrary three-dimensional point spread functions in\na two-photon microscope. For differentiable model-based adaptive optics (DAO),\nthe developed method can find aberration corrections with intrinsic image\nfeatures, for example neurons labeled with genetically encoded calcium\nindicators, without requiring guide stars. Using computational modeling we\nfurther discuss the range of spatial frequencies and magnitudes of aberrations\nwhich can be corrected with this approach.",
    "descriptor": "",
    "authors": [
      "Ivan Vishniakou",
      "Johannes D. Seelig"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.16930"
  },
  {
    "id": "arXiv:2211.16943",
    "title": "Predicting Properties of Quantum Systems with Conditional Generative  Models",
    "abstract": "Machine learning has emerged recently as a powerful tool for predicting\nproperties of quantum many-body systems. For many ground states of gapped\nHamiltonians, generative models can learn from measurements of a single quantum\nstate to reconstruct the state accurately enough to predict local observables.\nAlternatively, kernel methods can predict local observables by learning from\nmeasurements on different but related states. In this work, we combine the\nbenefits of both approaches and propose the use of conditional generative\nmodels to simultaneously represent a family of states, by learning shared\nstructures of different quantum states from measurements. The trained model\nallows us to predict arbitrary local properties of ground states, even for\nstates not present in the training data, and without necessitating further\ntraining for new observables. We numerically validate our approach (with\nsimulations of up to 45 qubits) for two quantum many-body problems, 2D random\nHeisenberg models and Rydberg atom systems.",
    "descriptor": "\nComments: 12 pages, 14 figures, 5 pages appendix. Open-source code is available at this https URL\n",
    "authors": [
      "Haoxiang Wang",
      "Maurice Weber",
      "Josh Izaac",
      "Cedric Yen-Yu Lin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16943"
  },
  {
    "id": "arXiv:2211.16950",
    "title": "DSNet: a simple yet efficient network with dual-stream attention for  lesion segmentation",
    "abstract": "Lesion segmentation requires both speed and accuracy. In this paper, we\npropose a simple yet efficient network DSNet, which consists of a encoder based\non Transformer and a convolutional neural network(CNN)-based distinct pyramid\ndecoder containing three dual-stream attention (DSA) modules. Specifically, the\nDSA module fuses features from two adjacent levels through the false positive\nstream attention (FPSA) branch and the false negative stream attention (FNSA)\nbranch to obtain features with diversified contextual information. We compare\nour method with various state-of-the-art (SOTA) lesion segmentation methods\nwith several public datasets, including CVC-ClinicDB, Kvasir-SEG, and ISIC-2018\nTask 1. The experimental results show that our method achieves SOTA performance\nin terms of mean Dice coefficient (mDice) and mean Intersection over Union\n(mIoU) with low model complexity and memory consumption.",
    "descriptor": "",
    "authors": [
      "Yunxiao Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16950"
  },
  {
    "id": "arXiv:2211.16968",
    "title": "Decision support for the Technician Routing and Scheduling Problem",
    "abstract": "The technician routing and scheduling problem (TRSP) consists of technicians\nserving tasks subject to qualifications, time constraints and routing costs. In\nthe literature, the TRSP is solved either to provide actual technician plans or\nfor performing what-if analyses on different TRSP scenarios. We present a\nmethod for building optimal TRSP scenarios, e.g., how many technicians to\nemploy, which technician qualifications to upgrade, etc. The scenarios are\nbuilt such that the combined TRSP costs (OPEX) and investment costs (CAPEX) are\nminimized. Using a holistic approach we can generate scenarios that would not\nhave been found by studying the investments individually. The proposed method\nconsists of a matheuristic based on column generation. To reduce computational\ntime, the routing costs of a technician are approximated. The proposed method\nis evaluated on data from the literature and on real-life data from a\ntelecommunication company. The evaluation shows that the proposed method\nsuccessfully suggests attractive scenarios. The method especially excels in\nensuring that more tasks are serviced but also reduces travel time with around\n16% in the real-life instance. We believe that the proposed method could\nconstitute an important strategic tool in field service companies and we\npropose future research directions to further its applicability.",
    "descriptor": "",
    "authors": [
      "Mette Gamst",
      "David Pisinger"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.16968"
  },
  {
    "id": "arXiv:2211.16975",
    "title": "The Infinity of Randomness",
    "abstract": "This work starts from definition of randomness, the results of algorithmic\nrandomness are analyzed from the perspective of application. Then, the source\nand nature of randomness is explored, and the relationship between infinity and\nrandomness is found. The properties of randomness are summarized from the\nperspective of interaction between systems, that is, the set composed of\nsequences generated by randomness has the property of asymptotic completeness.\nFinally, the importance of randomness in AI research is emphasized.",
    "descriptor": "",
    "authors": [
      "Yongxin Li"
    ],
    "subjectives": [
      "General Mathematics (math.GM)",
      "Artificial Intelligence (cs.AI)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2211.16975"
  },
  {
    "id": "arXiv:2211.16992",
    "title": "Extreme Audio Time Stretching Using Neural Synthesis",
    "abstract": "A deep neural network solution for time-scale modification (TSM) focused on\nlarge stretching factors is proposed, targeting environmental sounds.\nTraditional TSM artifacts such as transient smearing, loss of presence, and\nphasiness are heavily accentuated and cause poor audio quality when the TSM\nfactor is four or larger. The weakness of established TSM methods, often based\non a phase vocoder structure, lies in the poor description and scaling of the\ntransient and noise components, or nuances, of a sound. Our novel solution\ncombines a sines-transients-noise decomposition with an independent WaveNet\nsynthesizer to provide a better description of the noise component and an\nimprove sound quality for large stretching factors. Results of a subjective\nlistening test against four other TSM algorithms are reported, showing the\nproposed method to be often superior. The proposed method is stereo compatible\nand has a wide range of applications related to the slow motion of media\ncontent.",
    "descriptor": "\nComments: Submitted to IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2023 on Oct 27, 2022\n",
    "authors": [
      "Leonardo Fierro",
      "Alec Wright",
      "Vesa V\u00e4lim\u00e4ki",
      "Matti H\u00e4m\u00e4l\u00e4inen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.16992"
  },
  {
    "id": "arXiv:2211.16994",
    "title": "Continual Learning with Distributed Optimization: Does COCOA Forget?",
    "abstract": "We focus on the continual learning problem where the tasks arrive\nsequentially and the aim is to perform well on the newly arrived task without\nperformance degradation on the previously seen tasks. In contrast to the\ncontinual learning literature focusing on the centralized setting, we\ninvestigate the distributed estimation framework. We consider the\nwell-established distributed learning algorithm \\cocoa{}. We derive closed form\nexpressions for the iterations for the overparametrized case. We illustrate the\nconvergence and the error performance of the algorithm based on the\nover/under-parametrization of the problem. Our results show that depending on\nthe problem dimensions and data generation assumptions, \\cocoa{} can perform\ncontinual learning over a sequence of tasks, i.e., it can learn a new task\nwithout forgetting previously learned tasks, with access only to one task at a\ntime.",
    "descriptor": "",
    "authors": [
      "Martin Hellkvist",
      "Ay\u00e7a \u00d6z\u00e7elikkale",
      "Anders Ahl\u00e9n"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.16994"
  },
  {
    "id": "arXiv:2211.16995",
    "title": "A hybrid motion estimation technique for fisheye video sequences based  on equisolid re-projection",
    "abstract": "Capturing large fields of view with only one camera is an important aspect in\nsurveillance and automotive applications, but the wide-angle fisheye imagery\nthus obtained exhibits very special characteristics that may not be very well\nsuited for typical image and video processing methods such as motion\nestimation. This paper introduces a motion estimation method that adapts to the\ntypical radial characteristics of fisheye video sequences by making use of an\nequisolid re-projection after moving part of the motion vector search into the\nperspective domain via a corresponding back-projection. By combining this\napproach with conventional translational motion estimation and compensation,\naverage gains in luminance PSNR of up to 1.14 dB are achieved for synthetic\nfish-eye sequences and up to 0.96 dB for real-world data. Maximum gains for\nselected frame pairs amount to 2.40 dB and 1.39 dB for synthetic and real-world\ndata, respectively.",
    "descriptor": "",
    "authors": [
      "Andrea Eichenseer",
      "Michel B\u00e4tz",
      "J\u00fcrgen Seiler",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16995"
  },
  {
    "id": "arXiv:2211.17030",
    "title": "A data set providing synthetic and real-world fisheye video sequences",
    "abstract": "In video surveillance as well as automotive applications, so-called fisheye\ncameras are often employed to capture a very wide angle of view. As such\ncameras depend on projections quite different from the classical perspective\nprojection, the resulting fisheye image and video data correspondingly exhibits\nnon-rectilinear image characteristics. Typical image and video processing\nalgorithms, however, are not designed for these fisheye characteristics. To be\nable to develop and evaluate algorithms specifically adapted to fisheye images\nand videos, a corresponding test data set is therefore introduced in this\npaper. The first of those sequences were generated during the authors' own work\non motion estimation for fish-eye videos and further sequences have gradually\nbeen added to create a more extensive collection. The data set now comprises\nsynthetically generated fisheye sequences, ranging from simple patterns to more\ncomplex scenes, as well as fisheye video sequences captured with an actual\nfisheye camera. For the synthetic sequences, exact information on the lens\nemployed is available, thus facilitating both verification and evaluation of\nany adapted algorithms. For the real-world sequences, we provide calibration\ndata as well as the settings used during acquisition. The sequences are freely\navailable via www.lms.lnt.de/fisheyedataset/.",
    "descriptor": "",
    "authors": [
      "Andrea Eichenseer",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.17030"
  },
  {
    "id": "arXiv:2211.17048",
    "title": "SNAF: Sparse-view CBCT Reconstruction with Neural Attenuation Fields",
    "abstract": "Cone beam computed tomography (CBCT) has been widely used in clinical\npractice, especially in dental clinics, while the radiation dose of X-rays when\ncapturing has been a long concern in CBCT imaging. Several research works have\nbeen proposed to reconstruct high-quality CBCT images from sparse-view 2D\nprojections, but the current state-of-the-arts suffer from artifacts and the\nlack of fine details. In this paper, we propose SNAF for sparse-view CBCT\nreconstruction by learning the neural attenuation fields, where we have\ninvented a novel view augmentation strategy to overcome the challenges\nintroduced by insufficient data from sparse input views. Our approach achieves\nsuperior performance in terms of high reconstruction quality (30+ PSNR) with\nonly 20 input views (25 times fewer than clinical collections), which\noutperforms the state-of-the-arts. We have further conducted comprehensive\nexperiments and ablation analysis to validate the effectiveness of our\napproach.",
    "descriptor": "",
    "authors": [
      "Yu Fang",
      "Lanzhuju Mei",
      "Changjian Li",
      "Yuan Liu",
      "Wenping Wang",
      "Zhiming Cui",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.17048"
  },
  {
    "id": "arXiv:2211.17050",
    "title": "Internal Closedness and von Neumann-Morgenstern Stability in Matching  Theory: Structures and Complexity",
    "abstract": "Let $G$ be a graph and suppose we are given, for each $v \\in V(G)$, a strict\nordering of the neighbors of $v$. A set of matchings $\\mathcal{M}$ of $G$ is\ncalled internally stable if there are no matchings $M,M' \\in \\mathcal{M}$ such\nthat an edge of $M$ blocks $M'$. The sets of stable matchings and of von\nNeumann-Morgenstern stable matchings are examples of internally stable sets of\nmatching.\nIn this paper, we introduce and study, in both the marriage and the roommate\ncase, inclusionwise maximal internally stable sets of matchings. We call those\nsets internally closed. By building on known and newly developed algebraic\nstructures associated to sets of matchings, we investigate the complexity of\ndeciding if a set of matchings is internally closed, and if it is von\nNeumann-Morgenstern stable.",
    "descriptor": "",
    "authors": [
      "Yuri Faenza",
      "Clifford Stein",
      "Jia Wan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.17050"
  },
  {
    "id": "arXiv:2211.17053",
    "title": "Interaction-aware Model Predictive Control for Autonomous Driving",
    "abstract": "Lane changing and lane merging remains a challenging task for autonomous\ndriving, due to the strong interaction between the controlled vehicle and the\nuncertain behavior of the surrounding traffic participants. The interaction\ninduces a dependence of the vehicles' states on the (stochastic) dynamics of\nthe surrounding vehicles, increasing the difficulty of predicting future\ntrajectories. Furthermore, the small relative distances cause traditional\nrobust approaches to become overly conservative, necessitating control methods\nthat are explicitly aware of inter-vehicle interaction. Towards these goals, we\npropose an interaction-aware stochastic model predictive control (MPC) strategy\nintegrated with an online learning framework, which models a given driver's\ncooperation level as an unknown parameter in a state-dependent probability\ndistribution. The online learning framework adaptively estimates the\nsurrounding vehicle's cooperation level with the vehicle's past trajectory and\ncombines this with a kinematic vehicle model to predict the probability of a\nmultimodal future state trajectory. The learning is conducted with logistic\nregression which enables fast online computation. The multi-future prediction\nis used in the MPC algorithm to compute the optimal control input while\nsatisfying safety constraints. We demonstrate our algorithm in an interactive\nlane changing scenario with drivers in different randomly selected cooperation\nlevels.",
    "descriptor": "",
    "authors": [
      "Renzi Wang",
      "Mathijs Schuurmans",
      "Panagiotis Patrinos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.17053"
  },
  {
    "id": "arXiv:2211.17089",
    "title": "Quantum Cryptography: Quantum Key Distribution, a Non-technical Approach",
    "abstract": "With the rapid development of quantum computers the currently secure\ncryptographic protocols may not stay that way. Quantum mechanics provides means\nto create an inherently secure communication channel that is protected by the\nlaws of physics and not by the computational hardness of certain mathematical\nproblems. This paper is a non-technical overview of quantum key distribution,\none of the most well-known application of quantum cryptography, a type of\ncryptography poised to exploit the laws of quantum mechanics directly.",
    "descriptor": "",
    "authors": [
      "Andrew Frigyik"
    ],
    "subjectives": [
      "Popular Physics (physics.pop-ph)",
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.17089"
  },
  {
    "id": "arXiv:2211.17094",
    "title": "Better Transcription of UK Supreme Court Hearings",
    "abstract": "Transcription of legal proceedings is very important to enable access to\njustice. However, speech transcription is an expensive and slow process. In\nthis paper we describe part of a combined research and industrial project for\nbuilding an automated transcription tool designed specifically for the Justice\nsector in the UK. We explain the challenges involved in transcribing court room\nhearings and the Natural Language Processing (NLP) techniques we employ to\ntackle these challenges. We will show that fine-tuning a generic off-the-shelf\npre-trained Automatic Speech Recognition (ASR) system with an in-domain\nlanguage model as well as infusing common phrases extracted with a collocation\ndetection model can improve not only the Word Error Rate (WER) of the\ntranscribed hearings but avoid critical errors that are specific of the legal\njargon and terminology commonly used in British courts.",
    "descriptor": "",
    "authors": [
      "Hadeel Saadany",
      "Constantin Or\u0103san",
      "Catherine Breslin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.17094"
  },
  {
    "id": "arXiv:2211.17096",
    "title": "PAC Verification of Statistical Algorithms",
    "abstract": "Goldwasser et al.\\ (2021) recently proposed the setting of PAC verification,\nwhere a hypothesis (machine learning model) that purportedly satisfies the\nagnostic PAC learning objective is verified using an interactive proof. In this\npaper we develop this notion further in a number of ways. First, we prove a\nlower bound for PAC verification of $\\Omega(\\sqrt{d})$ i.i.d.\\ samples for\nhypothesis classes of VC dimension $d$. Second, we present a protocol for PAC\nverification of unions of intervals over $\\mathbb{R}$ that improves upon their\nproposed protocol for that task, and matches our lower bound. Third, we\nintroduce a natural generalization of their definition to verification of\ngeneral statistical algorithms, which is applicable to a wider variety of\npractical algorithms beyond agnostic PAC learning. Showcasing our proposed\ndefinition, our final result is a protocol for the verification of statistical\nquery algorithms that satisfy a combinatorial constraint on their queries.",
    "descriptor": "",
    "authors": [
      "Saachi Mutreja",
      "Jonathan Shafer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17096"
  },
  {
    "id": "arXiv:2211.17099",
    "title": "Representations of Domains via CF-approximation Spaces",
    "abstract": "Representations of domains mean in a general way representing a domain as a\nsuitable family endowed with set-inclusion order of some mathematical\nstructures. In this paper, representations of domains via CF-approximation\nspaces are considered. Concepts of CF-approximation spaces and CF-closed sets\nare introduced. It is proved that the family of CF-closed sets in a\nCF-approximation space endowed with set-inclusion order is a continuous domain\nand that every continuous domain is isomorphic to the family of CF-closed sets\nof some CF-approximation space endowed with set-inclusion order. The concept of\nCF-approximable relations is introduced using a categorical approach, which\nlater facilitates the proof that the category of CF-approximation spaces and\nCF-approximable relations is equivalent to that of continuous domains and Scott\ncontinuous maps.",
    "descriptor": "\nComments: 13pages, an interaction of Mathematics and information science\n",
    "authors": [
      "Guojun Wu",
      "Luoshan Xu"
    ],
    "subjectives": [
      "Rings and Algebras (math.RA)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.17099"
  },
  {
    "id": "arXiv:2211.17125",
    "title": "Distributed Averaging in Population Protocols",
    "abstract": "We consider a simple one-way averaging protocol on graphs. Initially, every\nnode of the graph has a value. A node $u$ is chosen uniformly at random and $u$\nsamples $k$ neighbours $v_1,v_2,\\cdots, v_k \\in N(u)$ uniformly at random.\nThen, $u$ averages its value with $v$ as follows: $\\xi_u(t+1) = \\alpha \\xi_u(t)\n+ \\frac{(1-\\alpha)}{k} \\sum_{i=1}^k \\xi_{v_i}(t)$ for some $\\alpha \\in (0,1)$,\nwhere $\\xi_u(t)$ is the value of node $u$ at time $t$. Note that, in contrast\nto neighbourhood value balancing, only $u$ changes its value. Hence, the sum\n(and the average) of the values of all nodes changes over time.\nOur results are two-fold. First, we show a bound on the convergence time (the\ntime it takes until all values are roughly the same) that is asymptotically\ntight for some initial assignments of values to the nodes. Our second set of\nresults concerns the ability of this protocol to approximate well the initial\naverage of all values: we bound the probability that the final outcome is\nsignificantly away from the initial average. Interestingly, the variance of the\noutcome does not depend on the graph structure. The proof introduces an\ninteresting generalisation of the duality between coalescing random walks and\nthe voter model.",
    "descriptor": "\nComments: 27 pages, 3 figures\n",
    "authors": [
      "Petra Berenbrink",
      "Colin Cooper",
      "Cristina Gava",
      "David Kohan Marzag\u00e3o",
      "Frederik Mallmann-Trenn",
      "Nicol\u00e1s Rivera",
      "Tomasz Radzik"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.17125"
  },
  {
    "id": "arXiv:2211.17154",
    "title": "On Regret-optimal Cooperative Nonstochastic Multi-armed Bandits",
    "abstract": "We consider the nonstochastic multi-agent multi-armed bandit problem with\nagents collaborating via a communication network with delays. We show a lower\nbound for individual regret of all agents. We show that with suitable\nregularizers and communication protocols, a collaborative multi-agent\n\\emph{follow-the-regularized-leader} (FTRL) algorithm has an individual regret\nupper bound that matches the lower bound up to a constant factor when the\nnumber of arms is large enough relative to degrees of agents in the\ncommunication graph. We also show that an FTRL algorithm with a suitable\nregularizer is regret optimal with respect to the scaling with the edge-delay\nparameter. We present numerical experiments validating our theoretical results\nand demonstrate cases when our algorithms outperform previously proposed\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Jialin Yi",
      "Milan Vojnovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.17154"
  },
  {
    "id": "arXiv:2211.17193",
    "title": "Metaheuristic Approach to Solve Portfolio Selection Problem",
    "abstract": "In this paper, a heuristic method based on TabuSearch and TokenRing Search is\nbeing used in order to solve the Portfolio Optimization Problem. The seminal\nmean-variance model of Markowitz is being considered with the addition of\ncardinality and quantity constraints to better capture the dynamics of the\ntrading procedure, the model becomes an NP-hard problem that can not be solved\nusing an exact method. The combination of three different neighborhood\nrelations is being explored with Tabu Search. In addition, a new constructive\nmethod for the initial solution is proposed. Finally, I show how the proposed\ntechniques perform on public benchmarks",
    "descriptor": "",
    "authors": [
      "Taylan Kabbani"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.17193"
  },
  {
    "id": "arXiv:2211.17202",
    "title": "Assisted RTF-Vector-Based Binaural Direction of Arrival Estimation  Exploiting a Calibrated External Microphone Array",
    "abstract": "Recently, a relative transfer function (RTF)-vector-based method has been\nproposed to estimate the direction of arrival (DOA) of a target speaker for a\nbinaural hearing aid setup, assuming the availability of external microphones.\nThis method exploits the external microphones to estimate the RTF vector\ncorresponding to the binaural hearing aid and constructs a one-dimensional\nspatial spectrum by comparing the estimated RTF vector against a database of\nanechoic prototype RTF vectors for several directions. In this paper we assume\nthe availability of a calibrated array of external microphones, which is\ncharacterized by a second database of anechoic prototype RTF vectors. We\npropose a method, where the external microphones are not only exploited to\nestimate the RTF vector corresponding to the binaural hearing aid but also\nassist in estimating the DOA of the target speaker. Based on the estimated RTF\nvector for all microphones and both prototype databases, a two-dimensional\nspatial spectrum is constructed from which the DOA is estimated. Experimental\nresults for a reverberant environment with diffuse-like noise show that\nassisted DOA estimation outperforms DOA estimation where the prototype database\ncharacterizing the array of external microphones is not used.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Daniel Fejgin",
      "Simon Doclo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.17202"
  },
  {
    "id": "arXiv:1504.06963",
    "title": "Generalized solution for the Herman Protocol Conjecture",
    "abstract": "Comments: 18 pages, 2 figures, extended and improved version",
    "descriptor": "\nComments: 18 pages, 2 figures, extended and improved version\n",
    "authors": [
      "Endre Cs\u00f3ka",
      "Szabolcs M\u00e9sz\u00e1ros",
      "Andr\u00e1s Pongr\u00e1cz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1504.06963"
  },
  {
    "id": "arXiv:1903.09755",
    "title": "Trifocal Relative Pose from Lines at Points and its Efficient Solution",
    "abstract": "Comments: First appeared at CVPR - Computer Vision and Pattern Recognition Conference 2020. This material is based upon work supported by the National Science Foundation under Grant No. DMS-1439786 while most authors were in residence at Brown University's Institute for Computational and Experimental Research in Mathematics -- ICERM, in Providence, RI",
    "descriptor": "\nComments: First appeared at CVPR - Computer Vision and Pattern Recognition Conference 2020. This material is based upon work supported by the National Science Foundation under Grant No. DMS-1439786 while most authors were in residence at Brown University's Institute for Computational and Experimental Research in Mathematics -- ICERM, in Providence, RI\n",
    "authors": [
      "Ricardo Fabbri",
      "Timothy Duff",
      "Hongyi Fan",
      "Margaret Regan",
      "David da Costa de Pinho",
      "Elias Tsigaridas",
      "Charles Wampler",
      "Jonathan Hauenstein",
      "Benjamin Kimia",
      "Anton Leykin",
      "Tomas Pajdla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1903.09755"
  },
  {
    "id": "arXiv:1909.01769",
    "title": "Complexity of Computing the Shapley Value in Games with Externalities",
    "abstract": "Complexity of Computing the Shapley Value in Games with Externalities",
    "descriptor": "",
    "authors": [
      "Oskar Skibski"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1909.01769"
  },
  {
    "id": "arXiv:2006.14201",
    "title": "Convex Incremental Dissipativity Analysis of Nonlinear Systems -  Extended version",
    "abstract": "Comments: Original version (without Remark 21, Example 24, and Appendix B) accepted for publication in Automatica",
    "descriptor": "\nComments: Original version (without Remark 21, Example 24, and Appendix B) accepted for publication in Automatica\n",
    "authors": [
      "Chris Verhoek",
      "Patrick J. W. Koelewijn",
      "Sofie Haesaert",
      "Roland T\u00f3th"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.14201"
  },
  {
    "id": "arXiv:2009.09778",
    "title": "Computation of Parameter Dependent Robust Invariant Sets for LPV Models  with Guaranteed Performance",
    "abstract": "Comments: 15 pages, 6 figures, preprint submitted to Automatica",
    "descriptor": "\nComments: 15 pages, 6 figures, preprint submitted to Automatica\n",
    "authors": [
      "Ankit Gupta",
      "Manas Mejari",
      "Paolo Falcone",
      "Dario Piga"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2009.09778"
  },
  {
    "id": "arXiv:2010.04674",
    "title": "Learning Context-Free Languages with Nondeterministic Stack RNNs",
    "abstract": "Comments: 13 pages, 5 figures. Published at CoNLL 2020. This revision fixes a typo",
    "descriptor": "\nComments: 13 pages, 5 figures. Published at CoNLL 2020. This revision fixes a typo\n",
    "authors": [
      "Brian DuSell",
      "David Chiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.04674"
  },
  {
    "id": "arXiv:2010.10194",
    "title": "Optimistic search: Change point estimation for large-scale data via  adaptive logarithmic queries",
    "abstract": "Comments: Generalize the univariate theory to Gaussian mean changes of general dimension, including high-dimensional scenarios",
    "descriptor": "\nComments: Generalize the univariate theory to Gaussian mean changes of general dimension, including high-dimensional scenarios\n",
    "authors": [
      "Solt Kov\u00e1cs",
      "Housen Li",
      "Lorenz Haubner",
      "Axel Munk",
      "Peter B\u00fchlmann"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.10194"
  },
  {
    "id": "arXiv:2010.14060",
    "title": "Nonlinear Monte Carlo Method for Imbalanced Data Learning",
    "abstract": "Comments: update experimental data",
    "descriptor": "\nComments: update experimental data\n",
    "authors": [
      "Xuli Shen",
      "Qing Xu",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.14060"
  },
  {
    "id": "arXiv:2101.01323",
    "title": "On the global convergence of randomized coordinate gradient descent for  non-convex optimization",
    "abstract": "On the global convergence of randomized coordinate gradient descent for  non-convex optimization",
    "descriptor": "",
    "authors": [
      "Ziang Chen",
      "Yingzhou Li",
      "Jianfeng Lu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.01323"
  },
  {
    "id": "arXiv:2104.12031",
    "title": "Low-rank Tensor Estimation via Riemannian Gauss-Newton: Statistical  Optimality and Second-Order Convergence",
    "abstract": "Low-rank Tensor Estimation via Riemannian Gauss-Newton: Statistical  Optimality and Second-Order Convergence",
    "descriptor": "",
    "authors": [
      "Yuetian Luo",
      "Anru R. Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2104.12031"
  },
  {
    "id": "arXiv:2104.14131",
    "title": "Actor-centered Representations for Action Localization in Streaming  Videos",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Sathyanarayanan N. Aakur",
      "Sudeep Sarkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.14131"
  },
  {
    "id": "arXiv:2106.08684",
    "title": "Reliability of Content and Echo Chambers on YouTube during the COVID-19  Debate",
    "abstract": "Reliability of Content and Echo Chambers on YouTube during the COVID-19  Debate",
    "descriptor": "",
    "authors": [
      "Niccol\u00f2 Di Marco",
      "Matteo Cinelli",
      "Walter Quattrociocchi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.08684"
  },
  {
    "id": "arXiv:2106.13239",
    "title": "Federated Noisy Client Learning",
    "abstract": "Comments: ur code is available on this https URL",
    "descriptor": "\nComments: ur code is available on this https URL\n",
    "authors": [
      "Kahou Tam",
      "Li Li",
      "Bo Han",
      "Chengzhong Xu",
      "Huazhu Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.13239"
  },
  {
    "id": "arXiv:2106.13520",
    "title": "Complexity of Deciding Syntactic Equivalence up to Renaming for Term  Rewriting Systems (Extended Version)",
    "abstract": "Complexity of Deciding Syntactic Equivalence up to Renaming for Term  Rewriting Systems (Extended Version)",
    "descriptor": "",
    "authors": [
      "Michael Christian Fink Amores",
      "David Sabel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.13520"
  },
  {
    "id": "arXiv:2108.13650",
    "title": "Heterogeneous Graph Neural Network with Multi-view Representation  Learning",
    "abstract": "Comments: Accepted by TKDE",
    "descriptor": "\nComments: Accepted by TKDE\n",
    "authors": [
      "Zezhi Shao",
      "Yongjun Xu",
      "Wei Wei",
      "Fei Wang",
      "Zhao Zhang",
      "Feida Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13650"
  },
  {
    "id": "arXiv:2109.01982",
    "title": "Learning Hierarchical Structures with Differentiable Nondeterministic  Stacks",
    "abstract": "Comments: 17 pages, 4 figures. Published as a spotlight paper at ICLR 2022. This revision fixes typos and minor errors",
    "descriptor": "\nComments: 17 pages, 4 figures. Published as a spotlight paper at ICLR 2022. This revision fixes typos and minor errors\n",
    "authors": [
      "Brian DuSell",
      "David Chiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.01982"
  },
  {
    "id": "arXiv:2109.08958",
    "title": "AutoInit: Analytic Signal-Preserving Weight Initialization for Neural  Networks",
    "abstract": "Comments: To appear in AAAI 2023. 19 pages, 10 figures, 3 tables",
    "descriptor": "\nComments: To appear in AAAI 2023. 19 pages, 10 figures, 3 tables\n",
    "authors": [
      "Garrett Bingham",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.08958"
  },
  {
    "id": "arXiv:2109.13493",
    "title": "Designed to Cooperate: A Kant-Inspired Ethic of Machine-to-Machine  Cooperation",
    "abstract": "Comments: AI Ethics (2022)",
    "descriptor": "\nComments: AI Ethics (2022)\n",
    "authors": [
      "Seng W. Loke"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.13493"
  },
  {
    "id": "arXiv:2110.00944",
    "title": "Kalman Bayesian Neural Networks for Closed-form Online Learning",
    "abstract": "Comments: 37th AAAI Conference on Artificial Intelligence (AAAI)",
    "descriptor": "\nComments: 37th AAAI Conference on Artificial Intelligence (AAAI)\n",
    "authors": [
      "Philipp Wagner",
      "Xinyang Wu",
      "Marco F. Huber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.00944"
  },
  {
    "id": "arXiv:2110.09066",
    "title": "Fairness Concepts for Indivisible Items with Externalities",
    "abstract": "Fairness Concepts for Indivisible Items with Externalities",
    "descriptor": "",
    "authors": [
      "Haris Aziz",
      "Warut Suksompong",
      "Zhaohong Sun",
      "Toby Walsh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.09066"
  },
  {
    "id": "arXiv:2110.12484",
    "title": "Micro Batch Streaming: Allowing the Training of DNN Models to Use a  large Batch Size in Memory Constrained Environments",
    "abstract": "Comments: In submitted",
    "descriptor": "\nComments: In submitted\n",
    "authors": [
      "XinYu Piao",
      "DoangJoo Synn",
      "JooYoung Park",
      "Jong-Kook Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.12484"
  },
  {
    "id": "arXiv:2110.14476",
    "title": "An Arbitrary Scale Super-Resolution Approach for 3D MR Images via  Implicit Neural Representation",
    "abstract": "Comments: 12 pagee, acceted by IEEE J-BHI",
    "descriptor": "\nComments: 12 pagee, acceted by IEEE J-BHI\n",
    "authors": [
      "Qing Wu",
      "Yuwei Li",
      "Yawen Sun",
      "Yan Zhou",
      "Hongjiang Wei",
      "Jingyi Yu",
      "Yuyao Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14476"
  },
  {
    "id": "arXiv:2111.00543",
    "title": "A modular construction or type theories",
    "abstract": "A modular construction or type theories",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Blanqui",
      "Gilles Dowek",
      "Emilie Grienenberger",
      "Gabriel Hondet",
      "Fran\u00e7ois Thir\u00e9"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.00543"
  },
  {
    "id": "arXiv:2111.02644",
    "title": "A Concentration Bound for LSPE($\u03bb$)",
    "abstract": "Comments: 17 pages, accepted for publication in Systems and Control Letters",
    "descriptor": "\nComments: 17 pages, accepted for publication in Systems and Control Letters\n",
    "authors": [
      "Siddharth Chandak",
      "Vivek S. Borkar",
      "Harsh Dolhare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02644"
  },
  {
    "id": "arXiv:2111.06812",
    "title": "Sci-Net: a Scale Invariant Model for Buildings Segmentation from Aerial  Imagery",
    "abstract": "Sci-Net: a Scale Invariant Model for Buildings Segmentation from Aerial  Imagery",
    "descriptor": "",
    "authors": [
      "Hasan Nasrallah",
      "Ali J. Ghandour"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06812"
  },
  {
    "id": "arXiv:2111.09154",
    "title": "Execution Order Matters in Greedy Algorithms with Limited Information",
    "abstract": "Execution Order Matters in Greedy Algorithms with Limited Information",
    "descriptor": "",
    "authors": [
      "Rohit Konda",
      "David Grimsman",
      "Jason Marden"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.09154"
  },
  {
    "id": "arXiv:2111.13636",
    "title": "On a Stochastic Fundamental Lemma and Its Use for Data-Driven Optimal  Control",
    "abstract": "On a Stochastic Fundamental Lemma and Its Use for Data-Driven Optimal  Control",
    "descriptor": "",
    "authors": [
      "Guanru Pan",
      "Ruchuan Ou",
      "Timm Faulwasser"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.13636"
  },
  {
    "id": "arXiv:2112.00165",
    "title": "Coordinated Multi-Robot Trajectory Tracking Control over Sampled  Communication",
    "abstract": "Comments: Revised version after second round of review",
    "descriptor": "\nComments: Revised version after second round of review\n",
    "authors": [
      "Enrica Rossi",
      "Marco Tognon",
      "Luca Ballotta",
      "Ruggero Carli",
      "Juan Cort\u00e9s",
      "Antonio Franchi",
      "Luca Schenato"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00165"
  },
  {
    "id": "arXiv:2112.01773",
    "title": "Adaptive Zeroing-Type Neural Dynamics for Solving Quadratic Minimization  and Applied to Target Tracking",
    "abstract": "Comments: 24 pages, 25 figures",
    "descriptor": "\nComments: 24 pages, 25 figures\n",
    "authors": [
      "Huiting He",
      "Chengze Jiang",
      "Yudong Zhang",
      "Xiuchun Xiao",
      "Zhiyuan Song"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.01773"
  },
  {
    "id": "arXiv:2112.04583",
    "title": "Computing Divergences between Discrete Decomposable Models",
    "abstract": "Comments: 13 pages, 4 Figures, 3 Tables. Accepted to the 37th AAAI Conference on Artificial Intelligence (AAAI 2023)",
    "descriptor": "\nComments: 13 pages, 4 Figures, 3 Tables. Accepted to the 37th AAAI Conference on Artificial Intelligence (AAAI 2023)\n",
    "authors": [
      "Loong Kuan Lee",
      "Nico Piatkowski",
      "Fran\u00e7ois Petitjean",
      "Geoffrey I. Webb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04583"
  },
  {
    "id": "arXiv:2112.08806",
    "title": "Dataset correlation inference attacks against machine learning models",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Ana-Maria Cre\u0163u",
      "Florent Gu\u00e9pin",
      "Yves-Alexandre de Montjoye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.08806"
  },
  {
    "id": "arXiv:2112.13414",
    "title": "Reinforcement Learning with Dynamic Convex Risk Measures",
    "abstract": "Comments: 26 pages, 9 figures",
    "descriptor": "\nComments: 26 pages, 9 figures\n",
    "authors": [
      "Anthony Coache",
      "Sebastian Jaimungal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Mathematical Finance (q-fin.MF)",
      "Risk Management (q-fin.RM)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2112.13414"
  },
  {
    "id": "arXiv:2112.13736",
    "title": "How do centrality measures choose the root of trees?",
    "abstract": "How do centrality measures choose the root of trees?",
    "descriptor": "",
    "authors": [
      "Cristian Riveros",
      "Jorge Salas",
      "Oskar Skibski"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Discrete Mathematics (cs.DM)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.13736"
  },
  {
    "id": "arXiv:2201.06297",
    "title": "Transfer Learning for Quantum Classifiers: An Information-Theoretic  Generalization Analysis",
    "abstract": "Comments: Submitted to conference",
    "descriptor": "\nComments: Submitted to conference\n",
    "authors": [
      "Sharu Theresa Jose",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06297"
  },
  {
    "id": "arXiv:2201.08984",
    "title": "PiCO+: Contrastive Label Disambiguation for Robust Partial Label  Learning",
    "abstract": "Comments: Extended version of the ICLR 2022 paper PiCO; see this https URL",
    "descriptor": "\nComments: Extended version of the ICLR 2022 paper PiCO; see this https URL\n",
    "authors": [
      "Haobo Wang",
      "Ruixuan Xiao",
      "Yixuan Li",
      "Lei Feng",
      "Gang Niu",
      "Gang Chen",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08984"
  },
  {
    "id": "arXiv:2201.10047",
    "title": "Are Commercial Face Detection Models as Biased as Academic Models?",
    "abstract": "Comments: This preprint and arXiv:2108.12508 were combined and a more rigorous analysis added to result in the NeurIPS Datasets & Benchmark 2022 paper arXiv:2211.15937",
    "descriptor": "\nComments: This preprint and arXiv:2108.12508 were combined and a more rigorous analysis added to result in the NeurIPS Datasets & Benchmark 2022 paper arXiv:2211.15937\n",
    "authors": [
      "Samuel Dooley",
      "George Z. Wei",
      "Tom Goldstein",
      "John P. Dickerson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10047"
  },
  {
    "id": "arXiv:2201.12741",
    "title": "GARNET: Reduced-Rank Topology Learning for Robust and Scalable Graph  Neural Networks",
    "abstract": "Comments: Published as a conference paper at LoG 2020",
    "descriptor": "\nComments: Published as a conference paper at LoG 2020\n",
    "authors": [
      "Chenhui Deng",
      "Xiuyu Li",
      "Zhuo Feng",
      "Zhiru Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12741"
  },
  {
    "id": "arXiv:2202.01243",
    "title": "Parameters or Privacy: A Provable Tradeoff Between Overparameterization  and Membership Inference",
    "abstract": "Comments: 25 pages, 8 figures",
    "descriptor": "\nComments: 25 pages, 8 figures\n",
    "authors": [
      "Jasper Tan",
      "Blake Mason",
      "Hamid Javadi",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01243"
  },
  {
    "id": "arXiv:2202.05728",
    "title": "Deep soccer captioning with transformer: dataset, semantics-related  losses, and multi-level evaluation",
    "abstract": "Deep soccer captioning with transformer: dataset, semantics-related  losses, and multi-level evaluation",
    "descriptor": "",
    "authors": [
      "Ahmad Hammoudeh",
      "Bastien Vanderplaetse",
      "St\u00e9phane Dupont"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05728"
  },
  {
    "id": "arXiv:2202.05770",
    "title": "Reliability function for streaming over a DMC with feedback",
    "abstract": "Reliability function for streaming over a DMC with feedback",
    "descriptor": "",
    "authors": [
      "Nian Guo",
      "Victoria Kostina"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.05770"
  },
  {
    "id": "arXiv:2202.07364",
    "title": "Zero-Shot Assistance in Sequential Decision Problems",
    "abstract": "Comments: 9 pages, 8 appendix pages, 13 figures. Accepted for publication at AAAI-23",
    "descriptor": "\nComments: 9 pages, 8 appendix pages, 13 figures. Accepted for publication at AAAI-23\n",
    "authors": [
      "Sebastiaan De Peuter",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.07364"
  },
  {
    "id": "arXiv:2202.07513",
    "title": "Post-Training Quantization for Cross-Platform Learned Image Compression",
    "abstract": "Post-Training Quantization for Cross-Platform Learned Image Compression",
    "descriptor": "",
    "authors": [
      "Dailan He",
      "Ziming Yang",
      "Yuan Chen",
      "Qi Zhang",
      "Hongwei Qin",
      "Yan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07513"
  },
  {
    "id": "arXiv:2202.08232",
    "title": "Quantum Lazy Training",
    "abstract": "Comments: 19 pages, 7 figures + 5 page appendix (V2: Added a couple of remarks; V3: Fixed typo, updated figure and added URL of GitHub repository; V4: Applied changes after getting reviewed; V5: Fixed typo)",
    "descriptor": "\nComments: 19 pages, 7 figures + 5 page appendix (V2: Added a couple of remarks; V3: Fixed typo, updated figure and added URL of GitHub repository; V4: Applied changes after getting reviewed; V5: Fixed typo)\n",
    "authors": [
      "Erfan Abedi",
      "Salman Beigi",
      "Leila Taghavi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08232"
  },
  {
    "id": "arXiv:2202.11354",
    "title": "Low-complexity Joint Beamforming for RIS-Aided Multi-User Downlink over  Correlated Channels",
    "abstract": "Low-complexity Joint Beamforming for RIS-Aided Multi-User Downlink over  Correlated Channels",
    "descriptor": "",
    "authors": [
      "Yu-Tse Wu",
      "Kuang-Hao Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.11354"
  },
  {
    "id": "arXiv:2202.11984",
    "title": "Fine-grained TLS services classification with reject option",
    "abstract": "Fine-grained TLS services classification with reject option",
    "descriptor": "",
    "authors": [
      "Jan Luxemburk",
      "Tom\u00e1\u0161 \u010cejka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.11984"
  },
  {
    "id": "arXiv:2202.13122",
    "title": "What ODE-Approximation Schemes of Time-Delay Systems Reveal about  Lyapunov-Krasovskii Functionals",
    "abstract": "Comments: 16 pages, 5 figures",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Tessina H. Scholl",
      "Veit Hagenmeyer",
      "Lutz Gr\u00f6ll"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.13122"
  },
  {
    "id": "arXiv:2203.00609",
    "title": "Models for digitally contact-traced epidemics",
    "abstract": "Comments: This work was partially funded by the H2020 SoBigData++ (Grant No 871042), H2020 HumaneAI-Net (Grant No 952026), and CHIST-ERA SAI (Grant No not yet available) projects",
    "descriptor": "\nComments: This work was partially funded by the H2020 SoBigData++ (Grant No 871042), H2020 HumaneAI-Net (Grant No 952026), and CHIST-ERA SAI (Grant No not yet available) projects\n",
    "authors": [
      "Chiara Boldrini",
      "Andrea Passarella",
      "Marco Conti"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Networking and Internet Architecture (cs.NI)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2203.00609"
  },
  {
    "id": "arXiv:2203.00995",
    "title": "Learning Efficiently Function Approximation for Contextual MDP",
    "abstract": "Learning Efficiently Function Approximation for Contextual MDP",
    "descriptor": "",
    "authors": [
      "Orin Levy",
      "Yishay Mansour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.00995"
  },
  {
    "id": "arXiv:2203.03398",
    "title": "Estimation under Model Misspecification with Fake Features",
    "abstract": "Estimation under Model Misspecification with Fake Features",
    "descriptor": "",
    "authors": [
      "Martin Hellkvist",
      "Ay\u00e7a \u00d6z\u00e7elikkale",
      "Anders Ahl\u00e9n"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.03398"
  },
  {
    "id": "arXiv:2203.04514",
    "title": "Surrogate \"Level-Based\" Lagrangian Relaxation for Mixed-Integer Linear  Programming",
    "abstract": "Surrogate \"Level-Based\" Lagrangian Relaxation for Mixed-Integer Linear  Programming",
    "descriptor": "",
    "authors": [
      "Mikhail A. Bragin",
      "Emily L. Tucker"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.04514"
  },
  {
    "id": "arXiv:2203.11876",
    "title": "Open-Vocabulary DETR with Conditional Matching",
    "abstract": "Comments: ECCV 2022 Oral",
    "descriptor": "\nComments: ECCV 2022 Oral\n",
    "authors": [
      "Yuhang Zang",
      "Wei Li",
      "Kaiyang Zhou",
      "Chen Huang",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11876"
  },
  {
    "id": "arXiv:2203.15756",
    "title": "Causal de Finetti: On the Identification of Invariant Causal Structure  in Exchangeable Data",
    "abstract": "Causal de Finetti: On the Identification of Invariant Causal Structure  in Exchangeable Data",
    "descriptor": "",
    "authors": [
      "Siyuan Guo",
      "Viktor T\u00f3th",
      "Bernhard Sch\u00f6lkopf",
      "Ferenc Husz\u00e1r"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.15756"
  },
  {
    "id": "arXiv:2204.00071",
    "title": "Numerical Solution of the Steady-State Network Flow Equations for a  Non-Ideal Gas",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Shriram Srinivasan",
      "Kaarthik Sundar",
      "Vitaliy Gyrya",
      "Anatoly Zlotnik"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.00071"
  },
  {
    "id": "arXiv:2204.01584",
    "title": "Synthesizing Attack-Aware Control and Active Sensing Strategies under  Reactive Sensor Attacks",
    "abstract": "Comments: 7 pages, 3 figure, 1 table, 1 algorithm",
    "descriptor": "\nComments: 7 pages, 3 figure, 1 table, 1 algorithm\n",
    "authors": [
      "Sumukha Udupa",
      "Abhishek N. Kulkarni",
      "Shuo Han",
      "Nandi O. Leslie",
      "Charles A. Kamhoua",
      "Jie Fu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.01584"
  },
  {
    "id": "arXiv:2204.06240",
    "title": "CowClip: Reducing CTR Prediction Model Training Time from 12 hours to 10  minutes on 1 GPU",
    "abstract": "Comments: AAAI 2023",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Zangwei Zheng",
      "Pengtai Xu",
      "Xuan Zou",
      "Da Tang",
      "Zhen Li",
      "Chenguang Xi",
      "Peng Wu",
      "Leqi Zou",
      "Yijie Zhu",
      "Ming Chen",
      "Xiangzhuo Ding",
      "Fuzhao Xue",
      "Ziheng Qin",
      "Youlong Cheng",
      "Yang You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.06240"
  },
  {
    "id": "arXiv:2204.06546",
    "title": "Disentangling Uncertainty in Machine Translation Evaluation",
    "abstract": "Comments: accepted at EMNLP 2022",
    "descriptor": "\nComments: accepted at EMNLP 2022\n",
    "authors": [
      "Chrysoula Zerva",
      "Taisiya Glushkova",
      "Ricardo Rei",
      "Andr\u00e9 F. T. Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.06546"
  },
  {
    "id": "arXiv:2204.06972",
    "title": "The multi-modal universe of fast-fashion: the Visuelle 2.0 benchmark",
    "abstract": "Comments: Accepted at the 5th Workshop on Computer Vision for Fashion, Art, and Design @ CVPR22",
    "descriptor": "\nComments: Accepted at the 5th Workshop on Computer Vision for Fashion, Art, and Design @ CVPR22\n",
    "authors": [
      "Geri Skenderi",
      "Christian Joppi",
      "Matteo Denitto",
      "Berniero Scarpa",
      "Marco Cristani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.06972"
  },
  {
    "id": "arXiv:2204.10037",
    "title": "DropMessage: Unifying Random Dropping for Graph Neural Networks",
    "abstract": "DropMessage: Unifying Random Dropping for Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Taoran Fang",
      "Zhiqing Xiao",
      "Chunping Wang",
      "Jiarong Xu",
      "Xuan Yang",
      "Yang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.10037"
  },
  {
    "id": "arXiv:2204.10070",
    "title": "Multi-UAV trajectory planning for 3D visual inspection of complex  structures",
    "abstract": "Comments: Revised version, final fixes and improvements, 17 pages",
    "descriptor": "\nComments: Revised version, final fixes and improvements, 17 pages\n",
    "authors": [
      "Stefan Ivi\u0107",
      "Bojan Crnkovi\u0107",
      "Luka Grb\u010di\u0107",
      "Lea Matlekovi\u0107"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.10070"
  },
  {
    "id": "arXiv:2204.10810",
    "title": "Learning to Scaffold: Optimizing Model Explanations for Teaching",
    "abstract": "Comments: 10 pages. NeurIPS 2022",
    "descriptor": "\nComments: 10 pages. NeurIPS 2022\n",
    "authors": [
      "Patrick Fernandes",
      "Marcos Treviso",
      "Danish Pruthi",
      "Andr\u00e9 F. T. Martins",
      "Graham Neubig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.10810"
  },
  {
    "id": "arXiv:2205.01420",
    "title": "Bridging Causal Reversibility and Time Reversibility: A Stochastic  Process Algebraic Approach",
    "abstract": "Bridging Causal Reversibility and Time Reversibility: A Stochastic  Process Algebraic Approach",
    "descriptor": "",
    "authors": [
      "Marco Bernardo",
      "Claudio Antares Mezzina"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.01420"
  },
  {
    "id": "arXiv:2205.01927",
    "title": "Probabilistic Symmetry for Multi-Agent Dynamics",
    "abstract": "Probabilistic Symmetry for Multi-Agent Dynamics",
    "descriptor": "",
    "authors": [
      "Sophia Sun",
      "Robin Walters",
      "Jinxi Li",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01927"
  },
  {
    "id": "arXiv:2205.03483",
    "title": "A Convergent Quadrature Based Method For The Monge-Amp\u00e8re Equation",
    "abstract": "Comments: 28 pages, 7 figures",
    "descriptor": "\nComments: 28 pages, 7 figures\n",
    "authors": [
      "Jake Brusca",
      "Brittany Froese Hamfeldt"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.03483"
  },
  {
    "id": "arXiv:2205.08704",
    "title": "Accurate Fairness: Improving Individual Fairness without Trading  Accuracy",
    "abstract": "Accurate Fairness: Improving Individual Fairness without Trading  Accuracy",
    "descriptor": "",
    "authors": [
      "Xuran Li",
      "Peng Wu",
      "Jing Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.08704"
  },
  {
    "id": "arXiv:2205.09045",
    "title": "POViT: Vision Transformer for Multi-objective Design and  Characterization of Nanophotonic Devices",
    "abstract": "Comments: The loss function should have been RMSE, not MSE, in the model evaluation section. As a result, the training results are all wrong. We need to withdraw this paper until we have come up with a solution to this issue",
    "descriptor": "\nComments: The loss function should have been RMSE, not MSE, in the model evaluation section. As a result, the training results are all wrong. We need to withdraw this paper until we have come up with a solution to this issue\n",
    "authors": [
      "Xinyu Chen",
      "Renjie Li",
      "Yueyao Yu",
      "Yuanwen Shen",
      "Wenye Li",
      "Zhaoyu Zhang",
      "Yin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2205.09045"
  },
  {
    "id": "arXiv:2205.09244",
    "title": "Riemannian Metric Learning via Optimal Transport",
    "abstract": "Riemannian Metric Learning via Optimal Transport",
    "descriptor": "",
    "authors": [
      "Christopher Scarvelis",
      "Justin Solomon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09244"
  },
  {
    "id": "arXiv:2205.09389",
    "title": "Simplifying Node Classification on Heterophilous Graphs with Compatible  Label Propagation",
    "abstract": "Simplifying Node Classification on Heterophilous Graphs with Compatible  Label Propagation",
    "descriptor": "",
    "authors": [
      "Zhiqiang Zhong",
      "Sergey Ivanov",
      "Jun Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.09389"
  },
  {
    "id": "arXiv:2205.10683",
    "title": "Scalable and Efficient Training of Large Convolutional Neural Networks  with Differential Privacy",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Zhiqi Bu",
      "Jialin Mao",
      "Shiyun Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.10683"
  },
  {
    "id": "arXiv:2205.12004",
    "title": "Quantum Kerr Learning",
    "abstract": "Comments: 20 pages, many figures. v2: significant updates, author added",
    "descriptor": "\nComments: 20 pages, many figures. v2: significant updates, author added\n",
    "authors": [
      "Junyu Liu",
      "Changchun Zhong",
      "Matthew Otten",
      "Anirban Chandra",
      "Cristian L. Cortes",
      "Chaoyang Ti",
      "Stephen K Gray",
      "Xu Han"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.12004"
  },
  {
    "id": "arXiv:2205.12689",
    "title": "Large Language Models are Few-Shot Clinical Information Extractors",
    "abstract": "Comments: Accepted as a long paper to The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    "descriptor": "\nComments: Accepted as a long paper to The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)\n",
    "authors": [
      "Monica Agrawal",
      "Stefan Hegselmann",
      "Hunter Lang",
      "Yoon Kim",
      "David Sontag"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12689"
  },
  {
    "id": "arXiv:2206.02095",
    "title": "ARC -- Actor Residual Critic for Adversarial Imitation Learning",
    "abstract": "ARC -- Actor Residual Critic for Adversarial Imitation Learning",
    "descriptor": "",
    "authors": [
      "Ankur Deka",
      "Changliu Liu",
      "Katia Sycara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02095"
  },
  {
    "id": "arXiv:2206.02777",
    "title": "Mask DINO: Towards A Unified Transformer-based Framework for Object  Detection and Segmentation",
    "abstract": "Mask DINO: Towards A Unified Transformer-based Framework for Object  Detection and Segmentation",
    "descriptor": "",
    "authors": [
      "Feng Li",
      "Hao Zhang",
      "Huaizhe xu",
      "Shilong Liu",
      "Lei Zhang",
      "Lionel M. Ni",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02777"
  },
  {
    "id": "arXiv:2206.03211",
    "title": "Variational Meta Reinforcement Learning for Social Robotics",
    "abstract": "Comments: 16 pages, 14 figures",
    "descriptor": "\nComments: 16 pages, 14 figures\n",
    "authors": [
      "Anand Ballou",
      "Xavier Alameda-Pineda",
      "Chris Reinke"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03211"
  },
  {
    "id": "arXiv:2206.03776",
    "title": "Circuit Privacy and Novel Protocols for Semi-Honest Three-Party Secure  Multiparty Computation with an Honest Majority",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Christopher Harth-Kitzerow"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.03776"
  },
  {
    "id": "arXiv:2206.06137",
    "title": "Absolute Expressiveness of Subgraph Motif Centrality Measures",
    "abstract": "Absolute Expressiveness of Subgraph Motif Centrality Measures",
    "descriptor": "",
    "authors": [
      "Andreas Pieris",
      "Jorge Salas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.06137"
  },
  {
    "id": "arXiv:2206.07729",
    "title": "Taxonomy of Benchmarks in Graph Representation Learning",
    "abstract": "Comments: In Proceedings of the First Learning on Graphs Conference (LoG 2022)",
    "descriptor": "\nComments: In Proceedings of the First Learning on Graphs Conference (LoG 2022)\n",
    "authors": [
      "Renming Liu",
      "Semih Cant\u00fcrk",
      "Frederik Wenkel",
      "Sarah McGuire",
      "Xinyi Wang",
      "Anna Little",
      "Leslie O'Bray",
      "Michael Perlmutter",
      "Bastian Rieck",
      "Matthew Hirn",
      "Guy Wolf",
      "Ladislav Ramp\u00e1\u0161ek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07729"
  },
  {
    "id": "arXiv:2206.09551",
    "title": "Eliminating The Impossible, Whatever Remains Must Be True",
    "abstract": "Eliminating The Impossible, Whatever Remains Must Be True",
    "descriptor": "",
    "authors": [
      "Jinqiang Yu",
      "Alexey Ignatiev",
      "Peter J. Stuckey",
      "Nina Narodytska",
      "Joao Marques-Silva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.09551"
  },
  {
    "id": "arXiv:2206.10092",
    "title": "BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object  Detection",
    "abstract": "Comments: Accepted by AAAI2023",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Yinhao Li",
      "Zheng Ge",
      "Guanyi Yu",
      "Jinrong Yang",
      "Zengran Wang",
      "Yukang Shi",
      "Jianjian Sun",
      "Zeming Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10092"
  },
  {
    "id": "arXiv:2206.12556",
    "title": "Graph Component Contrastive Learning for Concept Relatedness Estimation",
    "abstract": "Comments: 7 pages, Accepted to AAAI23, Github: this https URL",
    "descriptor": "\nComments: 7 pages, Accepted to AAAI23, Github: this https URL\n",
    "authors": [
      "Yueen Ma",
      "Zixing Song",
      "Xuming Hu",
      "Jingjing Li",
      "Yifei Zhang",
      "Irwin King"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.12556"
  },
  {
    "id": "arXiv:2206.12796",
    "title": "Transferring Fairness under Distribution Shifts via Fair Consistency  Regularization",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Bang An",
      "Zora Che",
      "Mucong Ding",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.12796"
  },
  {
    "id": "arXiv:2206.14282",
    "title": "Neural Integro-Differential Equations",
    "abstract": "Comments: 18 pages (including 8 pages Appendix), 8 figures and 6 tables. v4: Final version with reviewers' comments included, to appear in AAAI-23 (up to formatting differences)",
    "descriptor": "\nComments: 18 pages (including 8 pages Appendix), 8 figures and 6 tables. v4: Final version with reviewers' comments included, to appear in AAAI-23 (up to formatting differences)\n",
    "authors": [
      "Emanuele Zappala",
      "Antonio Henrique de Oliveira Fonseca",
      "Andrew Henry Moberly",
      "Michael James Higley",
      "Chadi Abdallah",
      "Jessica Cardin",
      "David van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14282"
  },
  {
    "id": "arXiv:2206.14938",
    "title": "Regularization of NeRFs using differential geometry",
    "abstract": "Regularization of NeRFs using differential geometry",
    "descriptor": "",
    "authors": [
      "Thibaud Ehret",
      "Roger Mar\u00ed",
      "Gabriele Facciolo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14938"
  },
  {
    "id": "arXiv:2207.01466",
    "title": "Physics-informed compressed sensing for PC-MRI: an inverse Navier-Stokes  problem",
    "abstract": "Physics-informed compressed sensing for PC-MRI: an inverse Navier-Stokes  problem",
    "descriptor": "",
    "authors": [
      "Alexandros Kontogiannis",
      "Matthew P. Juniper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2207.01466"
  },
  {
    "id": "arXiv:2207.02039",
    "title": "PKD: General Distillation Framework for Object Detectors via Pearson  Correlation Coefficient",
    "abstract": "Comments: Accepted in NeurIPS 2022",
    "descriptor": "\nComments: Accepted in NeurIPS 2022\n",
    "authors": [
      "Weihan Cao",
      "Yifan Zhang",
      "Jianfei Gao",
      "Anda Cheng",
      "Ke Cheng",
      "Jian Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.02039"
  },
  {
    "id": "arXiv:2207.04649",
    "title": "Fast Density-Peaks Clustering: Multicore-based Parallelization Approach",
    "abstract": "Comments: This is a corrected version of our SIGMOD2021 paper",
    "descriptor": "\nComments: This is a corrected version of our SIGMOD2021 paper\n",
    "authors": [
      "Daichi Amagata",
      "Takahiro Hara"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.04649"
  },
  {
    "id": "arXiv:2207.07190",
    "title": "Queueing games with an endogenous number of machines",
    "abstract": "Queueing games with an endogenous number of machines",
    "descriptor": "",
    "authors": [
      "Ata Atay",
      "Christian Trudeau"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.07190"
  },
  {
    "id": "arXiv:2207.07883",
    "title": "Neural modal ordinary differential equations: Integrating physics-based  modeling with neural ordinary differential equations for modeling  high-dimensional monitored structures",
    "abstract": "Comments: Accepted for publication in Data-Centric Engineering",
    "descriptor": "\nComments: Accepted for publication in Data-Centric Engineering\n",
    "authors": [
      "Zhilu Lai",
      "Wei Liu",
      "Xudong Jian",
      "Kiran Bacsa",
      "Limin Sun",
      "Eleni Chatzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2207.07883"
  },
  {
    "id": "arXiv:2207.08569",
    "title": "Multi-manifold Attention for Vision Transformers",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Dimitrios Konstantinidis",
      "Ilias Papastratis",
      "Kosmas Dimitropoulos",
      "Petros Daras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08569"
  },
  {
    "id": "arXiv:2207.10748",
    "title": "STARS Enabled Integrated Sensing and Communications",
    "abstract": "Comments: 33 pages, 8 figures",
    "descriptor": "\nComments: 33 pages, 8 figures\n",
    "authors": [
      "Zhaolin Wang",
      "Xidong Mu",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.10748"
  },
  {
    "id": "arXiv:2207.11697",
    "title": "Improving Mandarin Speech Recogntion with Block-augmented Transformer",
    "abstract": "Improving Mandarin Speech Recogntion with Block-augmented Transformer",
    "descriptor": "",
    "authors": [
      "Xiaoming Ren",
      "Huifeng Zhu",
      "Liuwei Wei",
      "Minghui Wu",
      "Jie Hao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.11697"
  },
  {
    "id": "arXiv:2207.12362",
    "title": "OpenRAN Gym: AI/ML Development, Data Collection, and Testing for O-RAN  on PAWR Platforms",
    "abstract": "OpenRAN Gym: AI/ML Development, Data Collection, and Testing for O-RAN  on PAWR Platforms",
    "descriptor": "",
    "authors": [
      "Leonardo Bonati",
      "Michele Polese",
      "Salvatore D'Oro",
      "Stefano Basagni",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.12362"
  },
  {
    "id": "arXiv:2207.13649",
    "title": "Explain My Surprise: Learning Efficient Long-Term Memory by Predicting  Uncertain Outcomes",
    "abstract": "Explain My Surprise: Learning Efficient Long-Term Memory by Predicting  Uncertain Outcomes",
    "descriptor": "",
    "authors": [
      "Artyom Sorokin",
      "Nazar Buzun",
      "Leonid Pugachev",
      "Mikhail Burtsev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.13649"
  },
  {
    "id": "arXiv:2207.13798",
    "title": "Look at Adjacent Frames: Video Anomaly Detection without Offline  Training",
    "abstract": "Comments: Accepted in ECCV 2022 RWS",
    "descriptor": "\nComments: Accepted in ECCV 2022 RWS\n",
    "authors": [
      "Yuqi Ouyang",
      "Guodong Shen",
      "Victor Sanchez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.13798"
  },
  {
    "id": "arXiv:2208.01942",
    "title": "Coupled Phase-Shift STAR-RISs: A General Optimization Framework",
    "abstract": "Comments: 6 pages, 3 figures",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Zhaolin Wang",
      "Xidong Mu",
      "Yuanwei Liu",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.01942"
  },
  {
    "id": "arXiv:2208.02108",
    "title": "Detecting Multivariate Time Series Anomalies with Zero Known Label",
    "abstract": "Detecting Multivariate Time Series Anomalies with Zero Known Label",
    "descriptor": "",
    "authors": [
      "Qihang Zhou",
      "Jiming Chen",
      "Haoyu Liu",
      "Shibo He",
      "Wenchao Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.02108"
  },
  {
    "id": "arXiv:2208.05264",
    "title": "Local Differentially Private Fuzzy Counting in Stream Data using  Probabilistic Data Structure",
    "abstract": "Comments: Version 2 14 pages, Accepted in IEEE Transactions on Data and Knowledge Engineering, 2022",
    "descriptor": "\nComments: Version 2 14 pages, Accepted in IEEE Transactions on Data and Knowledge Engineering, 2022\n",
    "authors": [
      "Dinusha Vatsalan",
      "Raghav Bhaskar",
      "Mohamed Ali Kaafar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.05264"
  },
  {
    "id": "arXiv:2208.07448",
    "title": "Self-Supervised Learning for Anomalous Channel Detection in EEG Graphs:  Application to Seizure Analysis",
    "abstract": "Comments: 9 pages, 5 figures, 4 tables",
    "descriptor": "\nComments: 9 pages, 5 figures, 4 tables\n",
    "authors": [
      "Thi Kieu Khanh Ho",
      "Narges Armanfard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.07448"
  },
  {
    "id": "arXiv:2208.08133",
    "title": "Metric Residual Networks for Sample Efficient Goal-Conditioned  Reinforcement Learning",
    "abstract": "Comments: Goal-conditioned reinforcement learning, neural architecture design",
    "descriptor": "\nComments: Goal-conditioned reinforcement learning, neural architecture design\n",
    "authors": [
      "Bo Liu",
      "Yihao Feng",
      "Qiang Liu",
      "Peter Stone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.08133"
  },
  {
    "id": "arXiv:2208.08268",
    "title": "Prediction of Oral Food Challenge Outcomes via Ensemble Learning",
    "abstract": "Prediction of Oral Food Challenge Outcomes via Ensemble Learning",
    "descriptor": "",
    "authors": [
      "Justin Zhang",
      "Deborah Lee",
      "Kylie Jungles",
      "Diane Shaltis",
      "Kayvan Najarian",
      "Rajan Ravikumar",
      "Georgiana Sanders",
      "Jonathan Gryak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08268"
  },
  {
    "id": "arXiv:2208.09790",
    "title": "Preemptive Scheduling of EV Charging for Providing Demand Response  Services",
    "abstract": "Comments: 21 pages, submitted to SEGAN",
    "descriptor": "\nComments: 21 pages, submitted to SEGAN\n",
    "authors": [
      "Shiping Shao",
      "Farshad Harirchi",
      "Devang Dave",
      "Abhishek Gupta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.09790"
  },
  {
    "id": "arXiv:2208.10162",
    "title": "Unscented Kalman filter with stable embedding for simple, accurate and  computationally efficient state estimation of systems on manifolds in  Euclidean space",
    "abstract": "Comments: This paper is published in International Journal of Robust and Nonliner Control",
    "descriptor": "\nComments: This paper is published in International Journal of Robust and Nonliner Control\n",
    "authors": [
      "Jae-Hyeon Park",
      "Dong Eui Chang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10162"
  },
  {
    "id": "arXiv:2208.10176",
    "title": "Competition for popularity and interventions on a Chinese microblogging  site",
    "abstract": "Comments: Main paper 16 pages, 8 figures. Supplementary information 13 pages, 10 figures, 3 tables",
    "descriptor": "\nComments: Main paper 16 pages, 8 figures. Supplementary information 13 pages, 10 figures, 3 tables\n",
    "authors": [
      "Hao Cui",
      "J\u00e1nos Kert\u00e9sz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.10176"
  },
  {
    "id": "arXiv:2208.12527",
    "title": "Unsupervised Spike Depth Estimation via Cross-modality Cross-domain  Knowledge Transfer",
    "abstract": "Unsupervised Spike Depth Estimation via Cross-modality Cross-domain  Knowledge Transfer",
    "descriptor": "",
    "authors": [
      "Jiaming Liu",
      "Qizhe Zhang",
      "Jianing Li",
      "Ming Lu",
      "Tiejun Huang",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.12527"
  },
  {
    "id": "arXiv:2208.12801",
    "title": "VMFormer: End-to-End Video Matting with Transformer",
    "abstract": "Comments: Project Page at this https URL",
    "descriptor": "\nComments: Project Page at this https URL\n",
    "authors": [
      "Jiachen Li",
      "Vidit Goel",
      "Marianna Ohanyan",
      "Shant Navasardyan",
      "Yunchao Wei",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.12801"
  },
  {
    "id": "arXiv:2209.00089",
    "title": "Analytic solution of the exact Daum-Huang flow equation for particle  filters",
    "abstract": "Analytic solution of the exact Daum-Huang flow equation for particle  filters",
    "descriptor": "",
    "authors": [
      "Oliv\u00e9r T\u00f6r\u0151",
      "Tam\u00e1s B\u00e9csi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.00089"
  },
  {
    "id": "arXiv:2209.01486",
    "title": "Differentially-private Distributed Algorithms for Aggregative Games with  Guaranteed Convergence",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2202.01113",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.01113\n",
    "authors": [
      "Yongqiang Wang",
      "Angelia Nedich"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.01486"
  },
  {
    "id": "arXiv:2209.02982",
    "title": "Improving the Cross-Lingual Generalisation in Visual Question Answering",
    "abstract": "Comments: This work is accepted by the AAAI 2023",
    "descriptor": "\nComments: This work is accepted by the AAAI 2023\n",
    "authors": [
      "Farhad Nooralahzadeh",
      "Rico Sennrich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.02982"
  },
  {
    "id": "arXiv:2209.03258",
    "title": "A Test for FLOPs as a Discriminant for Linear Algebra Algorithms",
    "abstract": "A Test for FLOPs as a Discriminant for Linear Algebra Algorithms",
    "descriptor": "",
    "authors": [
      "Aravind Sankaran",
      "Paolo Bientinesi"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2209.03258"
  },
  {
    "id": "arXiv:2209.06467",
    "title": "A deep learning energy-based method for classical elastoplasticity",
    "abstract": "A deep learning energy-based method for classical elastoplasticity",
    "descriptor": "",
    "authors": [
      "Junyan He",
      "Diab Abueidda",
      "Rashid Abu Al-Rub",
      "Seid Koric",
      "Iwona Jasiuk"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.06467"
  },
  {
    "id": "arXiv:2209.06979",
    "title": "Efficient Quantized Sparse Matrix Operations on Tensor Cores",
    "abstract": "Comments: Published in Proceedings of 2022 International Conference for High Performance Computing, Networking, Storage and Analysis (SC'22), Article No.: 37, Pages 1-15, Best Paper Finalist, this https URL (In this arXiv verion, we fix a typo at the bottom right of Page 6: For SDDMM, each thread block needs $\\textbf{K/BS}$$_k$ steps to obtain the final results.)",
    "descriptor": "\nComments: Published in Proceedings of 2022 International Conference for High Performance Computing, Networking, Storage and Analysis (SC'22), Article No.: 37, Pages 1-15, Best Paper Finalist, this https URL (In this arXiv verion, we fix a typo at the bottom right of Page 6: For SDDMM, each thread block needs $\\textbf{K/BS}$$_k$ steps to obtain the final results.)\n",
    "authors": [
      "Shigang Li",
      "Kazuki Osawa",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06979"
  },
  {
    "id": "arXiv:2209.07403",
    "title": "Private Stochastic Optimization With Large Worst-Case Lipschitz  Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to  Non-Convex Losses",
    "abstract": "Private Stochastic Optimization With Large Worst-Case Lipschitz  Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to  Non-Convex Losses",
    "descriptor": "",
    "authors": [
      "Andrew Lowy",
      "Meisam Razaviyayn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07403"
  },
  {
    "id": "arXiv:2209.08064",
    "title": "A Systematic Evaluation of Node Embedding Robustness",
    "abstract": "A Systematic Evaluation of Node Embedding Robustness",
    "descriptor": "",
    "authors": [
      "Alexandru Mara",
      "Jefrey Lijffijt",
      "Stephan G\u00fcnnemann",
      "Tijl De Bie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.08064"
  },
  {
    "id": "arXiv:2209.10271",
    "title": "Analyzing Social Media Activities at Bellingcat",
    "abstract": "Analyzing Social Media Activities at Bellingcat",
    "descriptor": "",
    "authors": [
      "Dominik B\u00e4r",
      "Fausto Calderon",
      "Michael Lawlor",
      "Sophia Licklederer",
      "Manuel Totzauer",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.10271"
  },
  {
    "id": "arXiv:2209.10310",
    "title": "Seeking Diverse Reasoning Logic: Controlled Equation Expression  Generation for Solving Math Word Problems",
    "abstract": "Comments: AACL 2022 short paper",
    "descriptor": "\nComments: AACL 2022 short paper\n",
    "authors": [
      "Yibin Shen",
      "Qianying Liu",
      "Zhuoyuan Mao",
      "Zhen Wan",
      "Fei Cheng",
      "Sadao Kurohashi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.10310"
  },
  {
    "id": "arXiv:2209.13763",
    "title": "Clustering-Induced Generative Incomplete Image-Text Clustering (CIGIT-C)",
    "abstract": "Comments: 13 pages,12 figures",
    "descriptor": "\nComments: 13 pages,12 figures\n",
    "authors": [
      "Dongjin Guo",
      "Xiaoming Su",
      "Jiatai Wang",
      "Limin Liu",
      "Zhiyong Pei",
      "Zhiwei Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.13763"
  },
  {
    "id": "arXiv:2209.13812",
    "title": "Universal Policy Tracking: Scheduling for Wireless Networks with Delayed  State Observation",
    "abstract": "Universal Policy Tracking: Scheduling for Wireless Networks with Delayed  State Observation",
    "descriptor": "",
    "authors": [
      "Bai Liu",
      "Eytan Modiano"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2209.13812"
  },
  {
    "id": "arXiv:2210.01041",
    "title": "Probabilistic Safeguard for Reinforcement Learning Using Safety Index  Guided Gaussian Process Models",
    "abstract": "Comments: First paper to use Gaussian Process for providing safety guarantee in energy-based safe control",
    "descriptor": "\nComments: First paper to use Gaussian Process for providing safety guarantee in energy-based safe control\n",
    "authors": [
      "Weiye Zhao",
      "Tairan He",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.01041"
  },
  {
    "id": "arXiv:2210.03142",
    "title": "On Distillation of Guided Diffusion Models",
    "abstract": "Comments: A short version of the paper is accepted to NeurIPS 2022 Workshop on Score-Based Methods",
    "descriptor": "\nComments: A short version of the paper is accepted to NeurIPS 2022 Workshop on Score-Based Methods\n",
    "authors": [
      "Chenlin Meng",
      "Robin Rombach",
      "Ruiqi Gao",
      "Diederik P. Kingma",
      "Stefano Ermon",
      "Jonathan Ho",
      "Tim Salimans"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03142"
  },
  {
    "id": "arXiv:2210.05392",
    "title": "TGDM: Target Guided Dynamic Mixup for Cross-Domain Few-Shot Learning",
    "abstract": "Comments: accepted by ACM MM 2022",
    "descriptor": "\nComments: accepted by ACM MM 2022\n",
    "authors": [
      "Linhai Zhuo",
      "Yuqian Fu",
      "Jingjing Chen",
      "Yixin Cao",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05392"
  },
  {
    "id": "arXiv:2210.05954",
    "title": "Image Projective Transformation Rectification with Synthetic Data for  Smartphone-captured Chest X-ray Photos Classification",
    "abstract": "Image Projective Transformation Rectification with Synthetic Data for  Smartphone-captured Chest X-ray Photos Classification",
    "descriptor": "",
    "authors": [
      "Chak Fong Chong",
      "Yapeng Wang",
      "Benjamin Ng",
      "Wuman Luo",
      "Xu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05954"
  },
  {
    "id": "arXiv:2210.06891",
    "title": "An Experiment Design Paradigm using Joint Feature Selection and Task  Optimization",
    "abstract": "An Experiment Design Paradigm using Joint Feature Selection and Task  Optimization",
    "descriptor": "",
    "authors": [
      "Stefano B. Blumberg",
      "Hongxiang Lin",
      "Yukun Zhou",
      "Paddy Slator",
      "Daniel C. Alexander"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.06891"
  },
  {
    "id": "arXiv:2210.07102",
    "title": "Corneal endothelium assessment in specular microscopy images with Fuchs'  dystrophy via deep regression of signed distance maps",
    "abstract": "Corneal endothelium assessment in specular microscopy images with Fuchs'  dystrophy via deep regression of signed distance maps",
    "descriptor": "",
    "authors": [
      "Juan S. Sierra",
      "Jesus Pineda",
      "Daniela Rueda",
      "Alejandro Tello",
      "Angelica M. Prada",
      "Virgilio Galvis",
      "Giovanni Volpe",
      "Maria S. Millan",
      "Lenny A. Romero",
      "Andres G. Marrugo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07102"
  },
  {
    "id": "arXiv:2210.07996",
    "title": "Degeneracy is OK: Logarithmic Regret for Network Revenue Management with  Indiscrete Distributions",
    "abstract": "Degeneracy is OK: Logarithmic Regret for Network Revenue Management with  Indiscrete Distributions",
    "descriptor": "",
    "authors": [
      "Jiashuo Jiang",
      "Will Ma",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.07996"
  },
  {
    "id": "arXiv:2210.10774",
    "title": "Learning to Discover and Detect Objects",
    "abstract": "Comments: Accepted to NeurIPS 2022, Homepage: this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2022, Homepage: this https URL\n",
    "authors": [
      "Vladimir Fomenko",
      "Ismail Elezi",
      "Deva Ramanan",
      "Laura Leal-Taix\u00e9",
      "Aljo\u0161a O\u0161ep"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10774"
  },
  {
    "id": "arXiv:2210.12152",
    "title": "WikiWhy: Answering and Explaining Cause-and-Effect Questions",
    "abstract": "WikiWhy: Answering and Explaining Cause-and-Effect Questions",
    "descriptor": "",
    "authors": [
      "Matthew Ho",
      "Aditya Sharma",
      "Justin Chang",
      "Michael Saxon",
      "Sharon Levy",
      "Yujie Lu",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.12152"
  },
  {
    "id": "arXiv:2210.13371",
    "title": "Time-Varying ALIP Model and Robust Foot-Placement Control for  Underactuated Bipedal Robot Walking on a Swaying Rigid Surface",
    "abstract": "Time-Varying ALIP Model and Robust Foot-Placement Control for  Underactuated Bipedal Robot Walking on a Swaying Rigid Surface",
    "descriptor": "",
    "authors": [
      "Yuan Gao",
      "Yukai Gong",
      "Victor Paredes",
      "Ayonga Hereid",
      "Yan Gu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.13371"
  },
  {
    "id": "arXiv:2210.14041",
    "title": "Enhanced Fuzzy Decomposition of Sound Into Sines, Transients, and Noise",
    "abstract": "Comments: Submitted for publication to the Journal of Audio Engineering Society on October 20th, 2022",
    "descriptor": "\nComments: Submitted for publication to the Journal of Audio Engineering Society on October 20th, 2022\n",
    "authors": [
      "Leonardo Fierro",
      "Vesa V\u00e4lim\u00e4ki"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.14041"
  },
  {
    "id": "arXiv:2210.15068",
    "title": "Improving Adversarial Robustness with Self-Paced Hard-Class Pair  Reweighting",
    "abstract": "Comments: AAAI-23",
    "descriptor": "\nComments: AAAI-23\n",
    "authors": [
      "Pengyue Hou",
      "Jie Han",
      "Xingyu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15068"
  },
  {
    "id": "arXiv:2210.15088",
    "title": "Personalized Dialogue Generation with Persona-Adaptive Attention",
    "abstract": "Comments: 8 pages, 3 figures",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Qiushi Huang",
      "Yu Zhang",
      "Tom Ko",
      "Xubo Liu",
      "Bo Wu",
      "Wenwu Wang",
      "Lilian Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15088"
  },
  {
    "id": "arXiv:2210.15235",
    "title": "SSD: Towards Better Text-Image Consistency Metric in Text-to-Image  Generation",
    "abstract": "SSD: Towards Better Text-Image Consistency Metric in Text-to-Image  Generation",
    "descriptor": "",
    "authors": [
      "Zhaorui Tan",
      "Zihan Ye",
      "Qiufeng Wang",
      "Yuyao Yan",
      "Anh Nguyen",
      "Xi Yang",
      "Kaizhu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15235"
  },
  {
    "id": "arXiv:2210.15445",
    "title": "Efficient Use of Large Pre-Trained Models for Low Resource ASR",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Peter Vieting",
      "Christoph L\u00fcscher",
      "Julian Dierkes",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15445"
  },
  {
    "id": "arXiv:2210.16133",
    "title": "Stop Measuring Calibration When Humans Disagree",
    "abstract": "Comments: Accepted at EMNLP 2022",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Joris Baan",
      "Wilker Aziz",
      "Barbara Plank",
      "Raquel Fern\u00e1ndez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16133"
  },
  {
    "id": "arXiv:2210.16506",
    "title": "Observable Perfect Equilibrium",
    "abstract": "Observable Perfect Equilibrium",
    "descriptor": "",
    "authors": [
      "Sam Ganzfried"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2210.16506"
  },
  {
    "id": "arXiv:2210.16556",
    "title": "MinUn: Accurate ML Inference on Microcontrollers",
    "abstract": "MinUn: Accurate ML Inference on Microcontrollers",
    "descriptor": "",
    "authors": [
      "Shikhar Jaiswal",
      "Rahul Kiran Kranti Goli",
      "Aayan Kumar",
      "Vivek Seshadri",
      "Rahul Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.16556"
  },
  {
    "id": "arXiv:2211.00611",
    "title": "MedSegDiff: Medical Image Segmentation with Diffusion Probabilistic  Model",
    "abstract": "MedSegDiff: Medical Image Segmentation with Diffusion Probabilistic  Model",
    "descriptor": "",
    "authors": [
      "Junde Wu",
      "Huihui Fang",
      "Yu Zhang",
      "Yehui Yang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00611"
  },
  {
    "id": "arXiv:2211.01638",
    "title": "Joint Chinese Word Segmentation and Span-based Constituency Parsing",
    "abstract": "Joint Chinese Word Segmentation and Span-based Constituency Parsing",
    "descriptor": "",
    "authors": [
      "Zhicheng Wang",
      "Tianyu Shi",
      "Cong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01638"
  },
  {
    "id": "arXiv:2211.01948",
    "title": "Efficiently Trained Mongolian Text-to-Speech System Based On FullConv",
    "abstract": "Efficiently Trained Mongolian Text-to-Speech System Based On FullConv",
    "descriptor": "",
    "authors": [
      "ZiQi Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01948"
  },
  {
    "id": "arXiv:2211.01962",
    "title": "GEC: A Unified Framework for Interactive Decision Making in MDP, POMDP,  and Beyond",
    "abstract": "Comments: We changed the title from the first version. We fixed a technical issue in the first version regarding the $\\ell_2$ eluder technique (Lemma D.2)",
    "descriptor": "\nComments: We changed the title from the first version. We fixed a technical issue in the first version regarding the $\\ell_2$ eluder technique (Lemma D.2)\n",
    "authors": [
      "Han Zhong",
      "Wei Xiong",
      "Sirui Zheng",
      "Liwei Wang",
      "Zhaoran Wang",
      "Zhuoran Yang",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01962"
  },
  {
    "id": "arXiv:2211.02050",
    "title": "Adaptive Batch Normalization for Training Data with Heterogeneous  Features",
    "abstract": "Comments: 6 pages,6 figures",
    "descriptor": "\nComments: 6 pages,6 figures\n",
    "authors": [
      "Wael Alsobhi",
      "Tarik Alafif",
      "Alaa Abdel-Hakim",
      "Weiwei Zong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02050"
  },
  {
    "id": "arXiv:2211.02274",
    "title": "Rally and WebScience: A Platform and Toolkit for Browser-Based Research  on Technology and Society Problems",
    "abstract": "Rally and WebScience: A Platform and Toolkit for Browser-Based Research  on Technology and Society Problems",
    "descriptor": "",
    "authors": [
      "Anne Kohlbrenner",
      "Ben Kaiser",
      "Kartikeya Kandula",
      "Rebecca Weiss",
      "Jonathan Mayer",
      "Ted Han",
      "Robert Helmer"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.02274"
  },
  {
    "id": "arXiv:2211.02786",
    "title": "Robot Basics: Representation, Rotation and Velocity",
    "abstract": "Comments: 29 Pages, 11 Figures",
    "descriptor": "\nComments: 29 Pages, 11 Figures\n",
    "authors": [
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02786"
  },
  {
    "id": "arXiv:2211.04247",
    "title": "Containminated Images Recovery by Implementing Non-negative Matrix  Factorisation",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Pengwei Yang",
      "Angel Teng",
      "Jack Mangos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04247"
  },
  {
    "id": "arXiv:2211.04439",
    "title": "Sampling from convex sets with a cold start using multiscale  decompositions",
    "abstract": "Comments: Changes from v1: Added a corollary on mixing of coordinate hit-and-run from a point. Also includes some minor corrections/simplifications and explanations",
    "descriptor": "\nComments: Changes from v1: Added a corollary on mixing of coordinate hit-and-run from a point. Also includes some minor corrections/simplifications and explanations\n",
    "authors": [
      "Hariharan Narayanan",
      "Amit Rajaraman",
      "Piyush Srivastava"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.04439"
  },
  {
    "id": "arXiv:2211.04583",
    "title": "Wall Street Tree Search: Risk-Aware Planning for Offline Reinforcement  Learning",
    "abstract": "Comments: Accepted to Foundation Models for Decision Making (FMDM) Workshop at 36th Conference on Neural Information Processing Systems (NeurIPS)",
    "descriptor": "\nComments: Accepted to Foundation Models for Decision Making (FMDM) Workshop at 36th Conference on Neural Information Processing Systems (NeurIPS)\n",
    "authors": [
      "Dan Elbaz",
      "Gal Novik",
      "Oren Salzman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04583"
  },
  {
    "id": "arXiv:2211.06993",
    "title": "GreenPLM: Cross-lingual pre-trained language models conversion with  (almost) no cost",
    "abstract": "GreenPLM: Cross-lingual pre-trained language models conversion with  (almost) no cost",
    "descriptor": "",
    "authors": [
      "Qingcheng Zeng",
      "Lucas Garay",
      "Peilin Zhou",
      "Dading Chong",
      "Yining Hua",
      "Jiageng Wu",
      "Yikang Pan",
      "Han Zhou",
      "Jie Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.06993"
  },
  {
    "id": "arXiv:2211.07263",
    "title": "Efficient Adversarial Training with Robust Early-Bird Tickets",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Zhiheng Xi",
      "Rui Zheng",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07263"
  },
  {
    "id": "arXiv:2211.07443",
    "title": "Calibrated Interpretation: Confidence Estimation in Semantic Parsing",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Elias Stengel-Eskin",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07443"
  },
  {
    "id": "arXiv:2211.07467",
    "title": "Cracking Double-Blind Review: Authorship Attribution with Deep Learning",
    "abstract": "Comments: 9 pages + 2 pages references",
    "descriptor": "\nComments: 9 pages + 2 pages references\n",
    "authors": [
      "Leonard Bauersfeld",
      "Angel Romero",
      "Manasi Muglikar",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07467"
  },
  {
    "id": "arXiv:2211.08165",
    "title": "What Can Algebraic Topology and Differential Geometry Teach Us About  Intrinsic Dynamics and Global Behavior of Robots?",
    "abstract": "What Can Algebraic Topology and Differential Geometry Teach Us About  Intrinsic Dynamics and Global Behavior of Robots?",
    "descriptor": "",
    "authors": [
      "Alin Albu-Sch\u00e4ffer",
      "Arne Sachtler"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08165"
  },
  {
    "id": "arXiv:2211.08518",
    "title": "Parameter-Covariance Maximum Likelihood Estimation",
    "abstract": "Comments: Incorrect Proof",
    "descriptor": "\nComments: Incorrect Proof\n",
    "authors": [
      "Alex Nguyen-Le",
      "Victor M. Preciado"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08518"
  },
  {
    "id": "arXiv:2211.10202",
    "title": "Some problems about co-consonance of topological spaces",
    "abstract": "Some problems about co-consonance of topological spaces",
    "descriptor": "",
    "authors": [
      "Zhengmao He",
      "Bin Zhao"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "General Topology (math.GN)"
    ],
    "url": "https://arxiv.org/abs/2211.10202"
  },
  {
    "id": "arXiv:2211.10298",
    "title": "Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control  Approach",
    "abstract": "Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control  Approach",
    "descriptor": "",
    "authors": [
      "Siddhant Bhambri",
      "Amrita Bhattacharjee",
      "Dimitri Bertsekas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10298"
  },
  {
    "id": "arXiv:2211.10866",
    "title": "Estimating Task Completion Times for Network Rollouts using Statistical  Models within Partitioning-based Regression Methods",
    "abstract": "Estimating Task Completion Times for Network Rollouts using Statistical  Models within Partitioning-based Regression Methods",
    "descriptor": "",
    "authors": [
      "Venkatachalam Natchiappan",
      "Shrihari Vasudevan",
      "Thalanayar Muthukumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.10866"
  },
  {
    "id": "arXiv:2211.11059",
    "title": "Coarse-to-fine Task-driven Inpainting for Geoscience Images",
    "abstract": "Coarse-to-fine Task-driven Inpainting for Geoscience Images",
    "descriptor": "",
    "authors": [
      "Huiming Sun",
      "Jin Ma",
      "Qing Guo",
      "Song Shaoyue",
      "Yuewei Lin",
      "Hongkai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11059"
  },
  {
    "id": "arXiv:2211.11446",
    "title": "SMAUG: Sparse Masked Autoencoder for Efficient Video-Language  Pre-training",
    "abstract": "SMAUG: Sparse Masked Autoencoder for Efficient Video-Language  Pre-training",
    "descriptor": "",
    "authors": [
      "Yuanze Lin",
      "Chen Wei",
      "Huiyu Wang",
      "Alan Yuille",
      "Cihang Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11446"
  },
  {
    "id": "arXiv:2211.11886",
    "title": "Value-based CTDE Methods in Symmetric Two-team Markov Game: from  Cooperation to Team Competition",
    "abstract": "Value-based CTDE Methods in Symmetric Two-team Markov Game: from  Cooperation to Team Competition",
    "descriptor": "",
    "authors": [
      "Pascal Leroy",
      "Jonathan Pisane",
      "Damien Ernst"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.11886"
  },
  {
    "id": "arXiv:2211.11982",
    "title": "BotSIM: An End-to-End Bot Simulation Framework for Commercial  Task-Oriented Dialog Systems",
    "abstract": "Comments: Paper accepted by the EMNLP 2022 System Demo Track; We have open-sourced the toolkit at this https URL",
    "descriptor": "\nComments: Paper accepted by the EMNLP 2022 System Demo Track; We have open-sourced the toolkit at this https URL\n",
    "authors": [
      "Guangsen Wang",
      "Samson Tan",
      "Shafiq Joty",
      "Gang Wu",
      "Jimmy Au",
      "Steven Hoi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11982"
  },
  {
    "id": "arXiv:2211.12024",
    "title": "TaylorBeamixer: Learning Taylor-Inspired All-Neural Multi-Channel Speech  Enhancement from Beam-Space Dictionary Perspective",
    "abstract": "Comments: In submission to ICASSP 2023, 5 pages",
    "descriptor": "\nComments: In submission to ICASSP 2023, 5 pages\n",
    "authors": [
      "Andong Li",
      "Guochen Yu",
      "Wenzhe Liu",
      "Xiaodong Li",
      "Chengshi Zheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.12024"
  },
  {
    "id": "arXiv:2211.12850",
    "title": "OOD-DiskANN: Efficient and Scalable Graph ANNS for Out-of-Distribution  Queries",
    "abstract": "OOD-DiskANN: Efficient and Scalable Graph ANNS for Out-of-Distribution  Queries",
    "descriptor": "",
    "authors": [
      "Shikhar Jaiswal",
      "Ravishankar Krishnaswamy",
      "Ankit Garg",
      "Harsha Vardhan Simhadri",
      "Sheshansh Agrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.12850"
  },
  {
    "id": "arXiv:2211.13523",
    "title": "Roboflow 100: A Rich, Multi-Domain Object Detection Benchmark",
    "abstract": "Roboflow 100: A Rich, Multi-Domain Object Detection Benchmark",
    "descriptor": "",
    "authors": [
      "Floriana Ciaglia",
      "Francesco Saverio Zuppichini",
      "Paul Guerrie",
      "Mark McQuade",
      "Jacob Solawetz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13523"
  },
  {
    "id": "arXiv:2211.13655",
    "title": "Learning with Partial Labels from Semi-supervised Perspective",
    "abstract": "Learning with Partial Labels from Semi-supervised Perspective",
    "descriptor": "",
    "authors": [
      "Ximing Li",
      "Yuanzhi Jiang",
      "Changchun Li",
      "Yiyuan Wang",
      "Jihong Ouyang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13655"
  },
  {
    "id": "arXiv:2211.14099",
    "title": "Fuzzy clustering for the within-season estimation of cotton phenology",
    "abstract": "Comments: also contained in arXiv:2211.12584",
    "descriptor": "\nComments: also contained in arXiv:2211.12584\n",
    "authors": [
      "Vasileios Sitokonstantinou",
      "Alkiviadis Koukos",
      "Ilias Tsoumas",
      "Nikolaos S. Bartsotas",
      "Charalampos Kontoes",
      "Vassilia Karathanassi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14099"
  },
  {
    "id": "arXiv:2211.14406",
    "title": "Exploring Temporal Information Dynamics in Spiking Neural Networks",
    "abstract": "Comments: Accepted to AAAI2023",
    "descriptor": "\nComments: Accepted to AAAI2023\n",
    "authors": [
      "Youngeun Kim",
      "Yuhang Li",
      "Hyoungseob Park",
      "Yeshwanth Venkatesha",
      "Anna Hambitzer",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.14406"
  },
  {
    "id": "arXiv:2211.14521",
    "title": "Robust One-shot Segmentation of Brain Tissues via Image-aligned Style  Transformation",
    "abstract": "Comments: Accepted by AAAI-2023",
    "descriptor": "\nComments: Accepted by AAAI-2023\n",
    "authors": [
      "Jinxin Lv",
      "Xiaoyu Zeng",
      "Sheng Wang",
      "Ran Duan",
      "Zhiwei Wang",
      "Qiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14521"
  },
  {
    "id": "arXiv:2211.14648",
    "title": "Learning Visuo-Haptic Skewering Strategies for Robot-Assisted Feeding",
    "abstract": "Learning Visuo-Haptic Skewering Strategies for Robot-Assisted Feeding",
    "descriptor": "",
    "authors": [
      "Priya Sundaresan",
      "Suneel Belkhale",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14648"
  },
  {
    "id": "arXiv:2211.14753",
    "title": "A Self-adaptive Neuroevolution Approach to Constructing Deep Neural  Network Architectures Across Different Types",
    "abstract": "A Self-adaptive Neuroevolution Approach to Constructing Deep Neural  Network Architectures Across Different Types",
    "descriptor": "",
    "authors": [
      "Zhenhao Shuai",
      "Hongbo Liu",
      "Zhaolin Wan",
      "Wei-Jie Yu",
      "Jun Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14753"
  },
  {
    "id": "arXiv:2211.14851",
    "title": "Performance evaluation of deep segmentation models on Landsat-8 imagery",
    "abstract": "Comments: Accepted to Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022",
    "descriptor": "\nComments: Accepted to Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022\n",
    "authors": [
      "Akshat Bhandari",
      "Sriya Rallabandi",
      "Sanchit Singhal",
      "Aditya Kasliwal",
      "Pratinav Seth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14851"
  },
  {
    "id": "arXiv:2211.15029",
    "title": "DiffusionBERT: Improving Generative Masked Language Models with  Diffusion Models",
    "abstract": "Comments: Work in progress. Code publicly available at this https URL",
    "descriptor": "\nComments: Work in progress. Code publicly available at this https URL\n",
    "authors": [
      "Zhengfu He",
      "Tianxiang Sun",
      "Kuanning Wang",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15029"
  },
  {
    "id": "arXiv:2211.15084",
    "title": "Exploring Immersive Interpersonal Communication via AR",
    "abstract": "Comments: Will be published in PACM HCI, CSCW1, April 2023 issue",
    "descriptor": "\nComments: Will be published in PACM HCI, CSCW1, April 2023 issue\n",
    "authors": [
      "Kyungjun Lee",
      "Hong Li",
      "Muhammad Rizky Wellyanto",
      "Yu Jiang Tham",
      "Andr\u00e9s Monroy-Hern\u00e1ndez",
      "Fannie Liu",
      "Brian A. Smith",
      "Rajan Vaish"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.15084"
  },
  {
    "id": "arXiv:2211.15308",
    "title": "Domain decomposition solvers for operators with fractional interface  perturbations",
    "abstract": "Comments: Extended version of article submitted to Proceedings of the 27th International Conference on Domain% Decomposition Methods in Prague, CZE",
    "descriptor": "\nComments: Extended version of article submitted to Proceedings of the 27th International Conference on Domain% Decomposition Methods in Prague, CZE\n",
    "authors": [
      "Miroslav Kuchta"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.15308"
  },
  {
    "id": "arXiv:2211.15516",
    "title": "DQ-DETR: Dual Query Detection Transformer for Phrase Extraction and  Grounding",
    "abstract": "Comments: Accepted to AAAI 2023",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Shilong Liu",
      "Yaoyuan Liang",
      "Feng Li",
      "Shijia Huang",
      "Hao Zhang",
      "Hang Su",
      "Jun Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15516"
  },
  {
    "id": "arXiv:2211.15542",
    "title": "Autonomous Assessment of Demonstration Sufficiency via Bayesian Inverse  Reinforcement Learning",
    "abstract": "Comments: Appears in Proceedings of AAAI FSS-22 Symposium \"Lessons Learned for Autonomous Assessment of Machine Abilities (LLAAMA)\"",
    "descriptor": "\nComments: Appears in Proceedings of AAAI FSS-22 Symposium \"Lessons Learned for Autonomous Assessment of Machine Abilities (LLAAMA)\"\n",
    "authors": [
      "Tu Trinh",
      "Daniel S. Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15542"
  },
  {
    "id": "arXiv:2211.15557",
    "title": "Beyond CAGE: Investigating Generalization of Learned Autonomous Network  Defense Policies",
    "abstract": "Comments: NeurIPS 2022 Workshop: Reinforcement Learning for Real Life",
    "descriptor": "\nComments: NeurIPS 2022 Workshop: Reinforcement Learning for Real Life\n",
    "authors": [
      "Melody Wolk",
      "Andy Applebaum",
      "Camron Dennler",
      "Patrick Dwyer",
      "Marina Moskowitz",
      "Harold Nguyen",
      "Nicole Nichols",
      "Nicole Park",
      "Paul Rachwalski",
      "Frank Rau",
      "Adrian Webster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.15557"
  },
  {
    "id": "arXiv:2211.15603",
    "title": "Action-GPT: Leveraging Large-scale Language Models for Improved and  Generalized Zero Shot Action Generation",
    "abstract": "Comments: WIP. Code, pretrained models and sample videos will be made available at \\url{this https URL}",
    "descriptor": "\nComments: WIP. Code, pretrained models and sample videos will be made available at \\url{this https URL}\n",
    "authors": [
      "Sai Shashank Kalakonda",
      "Shubh Maheshwari",
      "Ravi Kiran Sarvadevabhatla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.15603"
  },
  {
    "id": "arXiv:2211.15717",
    "title": "Train smarter, not harder: learning deep abdominal CT registration on  scarce data",
    "abstract": "Comments: 17 pages, 1 figure, 4 tables",
    "descriptor": "\nComments: 17 pages, 1 figure, 4 tables\n",
    "authors": [
      "Javier P\u00e9rez de Frutos",
      "Andr\u00e9 Pedersen",
      "Egidijus Pelanis",
      "David Bouget",
      "Shanmugapriya Survarachakan",
      "Thomas Lang\u00f8",
      "Ole-Jakob Elle",
      "Frank Lindseth"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15717"
  },
  {
    "id": "arXiv:2211.15728",
    "title": "Direct Heterogeneous Causal Learning for Resource Allocation Problems in  Marketing",
    "abstract": "Comments: Accepted by AAAI 2023",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Hao Zhou",
      "Shaoming Li",
      "Guibin Jiang",
      "Jiaqi Zheng",
      "Dong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15728"
  },
  {
    "id": "arXiv:2211.15910",
    "title": "Low-overhead Beam Training Scheme for Extremely Large-Scale RIS in  Near-field",
    "abstract": "Comments: This paper has been submitted to IEEE journal. (RIS, Near-field, extremely large-scale RIS, beam training, deep residual learning)",
    "descriptor": "\nComments: This paper has been submitted to IEEE journal. (RIS, Near-field, extremely large-scale RIS, beam training, deep residual learning)\n",
    "authors": [
      "Wang Liu",
      "Cunhua Pan",
      "Hong Ren",
      "Feng Shu",
      "Shi Jin",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.15910"
  },
  {
    "id": "arXiv:2211.15916",
    "title": "BotSIM: An End-to-End Bot Simulation Toolkit for Commercial  Task-Oriented Dialog Systems",
    "abstract": "Comments: Accompanying code documentation at this https URL arXiv admin note: text overlap with arXiv:2211.11982",
    "descriptor": "\nComments: Accompanying code documentation at this https URL arXiv admin note: text overlap with arXiv:2211.11982\n",
    "authors": [
      "Guangsen Wang",
      "Shafiq Joty",
      "Junnan Li",
      "Steven Hoi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15916"
  },
  {
    "id": "arXiv:2211.15920",
    "title": "Discrete Control in Real-World Driving Environments using Deep  Reinforcement Learning",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Avinash Amballa",
      "Advaith P.",
      "Pradip Sasmal",
      "Sumohana Channappayya"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15920"
  },
  {
    "id": "arXiv:2211.15940",
    "title": "PiggyBack: Pretrained Visual Question Answering Environment for Backing  up Non-deep Learning Professionals",
    "abstract": "Comments: Accepted by WSDM 2023",
    "descriptor": "\nComments: Accepted by WSDM 2023\n",
    "authors": [
      "Zhihao Zhang",
      "Siwen Luo",
      "Junyi Chen",
      "Sijia Lai",
      "Siqu Long",
      "Hyunsuk Chung",
      "Soyeon Caren Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15940"
  },
  {
    "id": "arXiv:2211.15977",
    "title": "One is All: Bridging the Gap Between Neural Radiance Fields  Architectures with Progressive Volume Distillation",
    "abstract": "Comments: Accepted by AAAI2023. Project Page: this https URL",
    "descriptor": "\nComments: Accepted by AAAI2023. Project Page: this https URL\n",
    "authors": [
      "Shuangkang Fang",
      "Weixin Xu",
      "Heng Wang",
      "Yi Yang",
      "Yufeng Wang",
      "Shuchang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15977"
  },
  {
    "id": "arXiv:2211.15988",
    "title": "Characterizing Engagement Dynamics across Topics on Facebook",
    "abstract": "Characterizing Engagement Dynamics across Topics on Facebook",
    "descriptor": "",
    "authors": [
      "Gabriele Etta",
      "Emanuele Sangiorgio",
      "Niccol\u00f2 Di Marco",
      "Michele Avalle",
      "Antonio Scala",
      "Matteo Cinelli",
      "Walter Quattrociocchi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.15988"
  },
  {
    "id": "arXiv:2211.15993",
    "title": "An Empirical Study on Snapshot DAOs",
    "abstract": "An Empirical Study on Snapshot DAOs",
    "descriptor": "",
    "authors": [
      "Qin Wang",
      "Guangsheng Yu",
      "Yilin Sai",
      "Caijun Sun",
      "Lam Duc Nguyen",
      "Sherry Xu",
      "Shiping Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.15993"
  },
  {
    "id": "arXiv:2211.16010",
    "title": "Graph Search based Polar Code Design",
    "abstract": "Comments: 5 pages, 8 figures, accepted to the 2022 Asilomar Conference on Signals, Systems, and Computers",
    "descriptor": "\nComments: 5 pages, 8 figures, accepted to the 2022 Asilomar Conference on Signals, Systems, and Computers\n",
    "authors": [
      "Marvin Geiselhart",
      "Andreas Zunker",
      "Ahmed Elkelesh",
      "Jannis Clausius",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.16010"
  },
  {
    "id": "arXiv:2211.16095",
    "title": "Better Generalized Few-Shot Learning Even Without Base Data",
    "abstract": "Comments: Accepted in AAAI-2023",
    "descriptor": "\nComments: Accepted in AAAI-2023\n",
    "authors": [
      "Seong-Woong Kim",
      "Dong-Wan Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16095"
  },
  {
    "id": "arXiv:2211.16135",
    "title": "AdaEnlight: Energy-aware Low-light Video Stream Enhancement on Mobile  Devices",
    "abstract": "AdaEnlight: Energy-aware Low-light Video Stream Enhancement on Mobile  Devices",
    "descriptor": "",
    "authors": [
      "Sicong Liu",
      "Xiaochen Li",
      "Zimu Zhou",
      "Bin Guo",
      "Meng Zhang",
      "Haochen Shen",
      "Zhiwen Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16135"
  },
  {
    "id": "arXiv:2211.16251",
    "title": "Utility Maximizer or Value Maximizer: Mechanism Design for Mixed Bidders  in Online Advertising",
    "abstract": "Comments: accepted by AAAI2023",
    "descriptor": "\nComments: accepted by AAAI2023\n",
    "authors": [
      "Hongtao Lv",
      "Zhilin Zhang",
      "Zhenzhe Zheng",
      "Jinghan Liu",
      "Chuan Yu",
      "Lei Liu",
      "Lizhen Cui",
      "Fan Wu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.16251"
  },
  {
    "id": "arXiv:2211.16254",
    "title": "Positivity-preserving and entropy-bounded discontinuous Galerkin method  for the chemically reacting, compressible Euler equations. Part I: The  one-dimensional case",
    "abstract": "Positivity-preserving and entropy-bounded discontinuous Galerkin method  for the chemically reacting, compressible Euler equations. Part I: The  one-dimensional case",
    "descriptor": "",
    "authors": [
      "Eric J. Ching",
      "Ryan F. Johnson",
      "Andrew D. Kercher"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.16254"
  },
  {
    "id": "arXiv:2211.16297",
    "title": "Positivity-preserving and entropy-bounded discontinuous Galerkin method  for the chemically reacting, compressible Euler equations. Part II: The  multidimensional case",
    "abstract": "Positivity-preserving and entropy-bounded discontinuous Galerkin method  for the chemically reacting, compressible Euler equations. Part II: The  multidimensional case",
    "descriptor": "",
    "authors": [
      "Eric J. Ching",
      "Ryan F. Johnson",
      "Andrew D. Kercher"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.16297"
  },
  {
    "id": "arXiv:2211.16299",
    "title": "Transferability Estimation Based On Principal Gradient Expectation",
    "abstract": "Comments: 13 pages, 3 figures, 9 tables",
    "descriptor": "\nComments: 13 pages, 3 figures, 9 tables\n",
    "authors": [
      "Huiyan Qi",
      "Lechao Cheng",
      "Jingjing Chen",
      "Yue Yu",
      "Zunlei Feng",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16299"
  },
  {
    "id": "arXiv:2211.16335",
    "title": "X-ICP: Localizability-Aware LiDAR Registration for Robust Localization  in Extreme Environments",
    "abstract": "Comments: 17 Pages, 17 Figures Submitted to IEEE Transactions On Robotics. Supplementary Video: this https URL Project Website: this https URL",
    "descriptor": "\nComments: 17 Pages, 17 Figures Submitted to IEEE Transactions On Robotics. Supplementary Video: this https URL Project Website: this https URL\n",
    "authors": [
      "Turcan Tuna",
      "Julian Nubert",
      "Yoshua Nava",
      "Shehryar Khattak",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.16335"
  },
  {
    "id": "arXiv:2211.16367",
    "title": "Optimisation of a global climate model ensemble for prediction of  extreme heat days",
    "abstract": "Optimisation of a global climate model ensemble for prediction of  extreme heat days",
    "descriptor": "",
    "authors": [
      "Mala Virdee",
      "Markus Kaiser",
      "Emily Shuckburgh",
      "Carl Henrik Ek",
      "Ieva Kazlauskaite"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16367"
  },
  {
    "id": "arXiv:2211.16398",
    "title": "Self-Supervised Mental Disorder Classifiers via Time Reversal",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Zafar Iqbal",
      "Usman Mahmood",
      "Zening Fu",
      "Sergey Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.16398"
  }
]
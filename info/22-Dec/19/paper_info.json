[
  {
    "id": "arXiv:2212.08072",
    "title": "Foresight -- Deep Generative Modelling of Patient Timelines using  Electronic Health Records",
    "abstract": "Electronic Health Records (EHRs) hold detailed longitudinal information about\neach patient's health status and general clinical history, a large portion of\nwhich is stored within the unstructured text. Temporal modelling of this\nmedical history, which considers the sequence of events, can be used to\nforecast and simulate future events, estimate risk, suggest alternative\ndiagnoses or forecast complications. While most prediction approaches use\nmainly structured data or a subset of single-domain forecasts and outcomes, we\nprocessed the entire free-text portion of EHRs for longitudinal modelling. We\npresent Foresight, a novel GPT3-based pipeline that uses NER+L tools (i.e.\nMedCAT) to convert document text into structured, coded concepts, followed by\nproviding probabilistic forecasts for future medical events such as disorders,\nmedications, symptoms and interventions. Since large portions of EHR data are\nin text form, such an approach benefits from a granular and detailed view of a\npatient while introducing modest additional noise. On tests in two large UK\nhospitals (King's College Hospital, South London and Maudsley) and the US\nMIMIC-III dataset precision@10 of 0.80, 0.81 and 0.91 was achieved for\nforecasting the next biomedical concept. Foresight was also validated on 34\nsynthetic patient timelines by 5 clinicians and achieved relevancy of 97% for\nthe top forecasted candidate disorder. Foresight can be easily trained and\ndeployed locally as it only requires free-text data (as a minimum). As a\ngenerative model, it can simulate follow-on disorders, medications and\ninterventions for as many steps as required. Foresight is a general-purpose\nmodel for biomedical concept modelling that can be used for real-world risk\nestimation, virtual trials and clinical research to study the progression of\ndiseases, simulate interventions and counterfactuals, and for educational\npurposes.",
    "descriptor": "",
    "authors": [
      "Zeljko Kraljevic",
      "Dan Bean",
      "Anthony Shek",
      "Rebecca Bendayan",
      "Joshua Au Yeung",
      "Alexander Deng",
      "Alfie Baston",
      "Jack Ross",
      "Esther Idowu",
      "James T Teo",
      "Richard J Dobson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08072"
  },
  {
    "id": "arXiv:2212.08073",
    "title": "Constitutional AI: Harmlessness from AI Feedback",
    "abstract": "As AI systems become more capable, we would like to enlist their help to\nsupervise other AIs. We experiment with methods for training a harmless AI\nassistant through self-improvement, without any human labels identifying\nharmful outputs. The only human oversight is provided through a list of rules\nor principles, and so we refer to the method as 'Constitutional AI'. The\nprocess involves both a supervised learning and a reinforcement learning phase.\nIn the supervised phase we sample from an initial model, then generate\nself-critiques and revisions, and then finetune the original model on revised\nresponses. In the RL phase, we sample from the finetuned model, use a model to\nevaluate which of the two samples is better, and then train a preference model\nfrom this dataset of AI preferences. We then train with RL using the preference\nmodel as the reward signal, i.e. we use 'RL from AI Feedback' (RLAIF). As a\nresult we are able to train a harmless but non-evasive AI assistant that\nengages with harmful queries by explaining its objections to them. Both the SL\nand RL methods can leverage chain-of-thought style reasoning to improve the\nhuman-judged performance and transparency of AI decision making. These methods\nmake it possible to control AI behavior more precisely and with far fewer human\nlabels.",
    "descriptor": "",
    "authors": [
      "Yuntao Bai",
      "Saurav Kadavath",
      "Sandipan Kundu",
      "Amanda Askell",
      "Jackson Kernion",
      "Andy Jones",
      "Anna Chen",
      "Anna Goldie",
      "Azalia Mirhoseini",
      "Cameron McKinnon",
      "Carol Chen",
      "Catherine Olsson",
      "Christopher Olah",
      "Danny Hernandez",
      "Dawn Drain",
      "Deep Ganguli",
      "Dustin Li",
      "Eli Tran-Johnson",
      "Ethan Perez",
      "Jamie Kerr",
      "Jared Mueller",
      "Jeffrey Ladish",
      "Joshua Landau",
      "Kamal Ndousse",
      "Kamile Lukosuite",
      "Liane Lovitt",
      "Michael Sellitto",
      "Nelson Elhage",
      "Nicholas Schiefer",
      "Noemi Mercado",
      "Nova DasSarma",
      "Robert Lasenby",
      "Robin Larson",
      "Sam Ringer",
      "Scott Johnston",
      "Shauna Kravec",
      "Sheer El Showk",
      "Stanislav Fort",
      "Tamera Lanham",
      "Timothy Telleen-Lawton",
      "Tom Conerly",
      "Tom Henighan",
      "Tristan Hume",
      "Samuel R. Bowman",
      "Zac Hatfield-Dodds",
      "Ben Mann",
      "Dario Amodei",
      "Nicholas Joseph",
      "Sam McCandlish",
      "Tom Brown",
      "Jared Kaplan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08073"
  },
  {
    "id": "arXiv:2212.08094",
    "title": "Joint processing of linguistic properties in brains and language models",
    "abstract": "Language models have been shown to be very effective in predicting brain\nrecordings of subjects experiencing complex language stimuli. For a deeper\nunderstanding of this alignment, it is important to understand the alignment\nbetween the detailed processing of linguistic information by the human brain\nversus language models. In NLP, linguistic probing tasks have revealed a\nhierarchy of information processing in neural language models that progresses\nfrom simple to complex with an increase in depth. On the other hand, in\nneuroscience, the strongest alignment with high-level language brain regions\nhas consistently been observed in the middle layers. These findings leave an\nopen question as to what linguistic information actually underlies the observed\nalignment between brains and language models. We investigate this question via\na direct approach, in which we eliminate information related to specific\nlinguistic properties in the language model representations and observe how\nthis intervention affects the alignment with fMRI brain recordings obtained\nwhile participants listened to a story. We investigate a range of linguistic\nproperties (surface, syntactic and semantic) and find that the elimination of\neach one results in a significant decrease in brain alignment across all layers\nof a language model. These findings provide direct evidence for the role of\nspecific linguistic information in the alignment between brain and language\nmodels, and opens new avenues for mapping the joint information processing in\nboth systems.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Subba Reddy Oota",
      "Manish Gupta",
      "Mariya Toneva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2212.08094"
  },
  {
    "id": "arXiv:2212.08099",
    "title": "DFEE: Interactive DataFlow Execution and Evaluation Kit",
    "abstract": "DataFlow has been emerging as a new paradigm for building task-oriented\nchatbots due to its expressive semantic representations of the dialogue tasks.\nDespite the availability of a large dataset SMCalFlow and a simplified syntax,\nthe development and evaluation of DataFlow-based chatbots remain challenging\ndue to the system complexity and the lack of downstream toolchains. In this\ndemonstration, we present DFEE, an interactive DataFlow Execution and\nEvaluation toolkit that supports execution, visualization and benchmarking of\nsemantic parsers given dialogue input and backend database. We demonstrate the\nsystem via a complex dialog task: event scheduling that involves temporal\nreasoning. It also supports diagnosing the parsing results via a friendly\ninterface that allows developers to examine dynamic DataFlow and the\ncorresponding execution results. To illustrate how to benchmark SoTA models, we\npropose a novel benchmark that covers more sophisticated event scheduling\nscenarios and a new metric on task success evaluation. The codes of DFEE have\nbeen released on https://github.com/amazonscience/dataflow-evaluation-toolkit.",
    "descriptor": "\nComments: Accepted to AAAI-23: the Thirty-Seventh AAAI Conference on Artificial Intelligence\n",
    "authors": [
      "Han He",
      "Song Feng",
      "Daniele Bonadiman",
      "Yi Zhang",
      "Saab Mansour"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08099"
  },
  {
    "id": "arXiv:2212.08104",
    "title": "The Role of AI in Drug Discovery: Challenges, Opportunities, and  Strategies",
    "abstract": "Artificial intelligence (AI) has the potential to revolutionize the drug\ndiscovery process, offering improved efficiency, accuracy, and speed. However,\nthe successful application of AI is dependent on the availability of\nhigh-quality data, the addressing of ethical concerns, and the recognition of\nthe limitations of AI-based approaches. In this article, the benefits,\nchallenges and drawbacks of AI in this field are reviewed, and possible\nstrategies and approaches for overcoming the present obstacles are proposed.\nThe use of data augmentation, explainable AI, and the integration of AI with\ntraditional experimental methods, as well as the potential advantages of AI in\npharmaceutical research are also discussed. Overall, this review highlights the\npotential of AI in drug discovery and provides insights into the challenges and\nopportunities for realizing its potential in this field.\nNote from the human-authors: This article was created to test the ability of\nChatGPT, a chatbot based on the GPT-3.5 language model, to assist human authors\nin writing review articles. The text generated by the AI following our\ninstructions (see Supporting Information) was used as a starting point, and its\nability to automatically generate content was evaluated. After conducting a\nthorough review, human authors practically rewrote the manuscript, striving to\nmaintain a balance between the original proposal and scientific criteria. The\nadvantages and limitations of using AI for this purpose are discussed in the\nlast section.",
    "descriptor": "\nComments: 11 pages, 1 figure\n",
    "authors": [
      "Alexandre Blanco-Gonzalez",
      "Alfonso Cabezon",
      "Alejandro Seco-Gonzalez",
      "Daniel Conde-Torres",
      "Paula Antelo-Riveiro",
      "Angel Pineiro",
      "Rebeca Garcia-Fandino"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.08104"
  },
  {
    "id": "arXiv:2212.08105",
    "title": "Moto: Enhancing Embedding with Multiple Joint Factors for Chinese Text  Classification",
    "abstract": "Recently, language representation techniques have achieved great performances\nin text classification. However, most existing representation models are\nspecifically designed for English materials, which may fail in Chinese because\nof the huge difference between these two languages. Actually, few existing\nmethods for Chinese text classification process texts at a single level.\nHowever, as a special kind of hieroglyphics, radicals of Chinese characters are\ngood semantic carriers. In addition, Pinyin codes carry the semantic of tones,\nand Wubi reflects the stroke structure information, \\textit{etc}.\nUnfortunately, previous researches neglected to find an effective way to\ndistill the useful parts of these four factors and to fuse them. In our works,\nwe propose a novel model called Moto: Enhancing Embedding with\n\\textbf{M}ultiple J\\textbf{o}int Fac\\textbf{to}rs. Specifically, we design an\nattention mechanism to distill the useful parts by fusing the four-level\ninformation above more effectively. We conduct extensive experiments on four\npopular tasks. The empirical results show that our Moto achieves SOTA 0.8316\n($F_1$-score, 2.11\\% improvement) on Chinese news titles, 96.38 (1.24\\%\nimprovement) on Fudan Corpus and 0.9633 (3.26\\% improvement) on THUCNews.",
    "descriptor": "",
    "authors": [
      "Xunzhu Tang",
      "Rujie Zhu",
      "Tiezhu Sun",
      "Shi Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08105"
  },
  {
    "id": "arXiv:2212.08108",
    "title": "DeepDFA: Dataflow Analysis-Guided Efficient Graph Learning for  Vulnerability Detection",
    "abstract": "Deep learning-based vulnerability detection models have recently been shown\nto be effective and, in some cases, outperform static analysis tools. However,\nthe highest-performing approaches use token-based transformer models, which do\nnot leverage domain knowledge. Classical program analysis techniques such as\ndataflow analysis can detect many types of bugs and are the most commonly used\nmethods in practice. Motivated by the causal relationship between bugs and\ndataflow analysis, we present DeepDFA, a dataflow analysis-guided graph\nlearning framework and embedding that uses program semantic features for\nvulnerability detection. We show that DeepDFA is performant and efficient.\nDeepDFA ranked first in recall, first in generalizing over unseen projects, and\nsecond in F1 among all the state-of-the-art models we experimented with. It is\nalso the smallest model in terms of the number of parameters, and was trained\nin 9 minutes, 69x faster than the highest-performing baseline. DeepDFA can be\nused with other models. By integrating LineVul and DeepDFA, we achieved the\nbest vulnerability detection performance of 96.4 F1 score, 98.69 precision, and\n94.22 recall.",
    "descriptor": "\nComments: 10 pages, 8 figures. Under review as a conference paper at ICLR 2023\n",
    "authors": [
      "Benjamin Steenhoek",
      "Wei Le",
      "Hongyang Gao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08108"
  },
  {
    "id": "arXiv:2212.08109",
    "title": "An Empirical Study of Deep Learning Models for Vulnerability Detection",
    "abstract": "Deep learning (DL) models of code have recently reported great progress for\nvulnerability detection. In some cases, DL-based models have outperformed\nstatic analysis tools. Although many great models have been proposed, we do not\nyet have a good understanding of these models. This limits the further\nadvancement of model robustness, debugging, and deployment for the\nvulnerability detection. In this paper, we surveyed and reproduced 9\nstate-of-the-art (SOTA) deep learning models on 2 widely used vulnerability\ndetection datasets: Devign and MSR. We investigated 6 research questions in\nthree areas, namely model capabilities, training data, and model\ninterpretation. We experimentally demonstrated the variability between\ndifferent runs of a model and the low agreement among different models'\noutputs. We investigated models trained for specific types of vulnerabilities\ncompared to a model that is trained on all the vulnerabilities at once. We\nexplored the types of programs DL may consider \"hard\" to handle. We\ninvestigated the relations of training data sizes and training data composition\nwith model performance. Finally, we studied model interpretations and analyzed\nimportant features that the models used to make predictions. We believe that\nour findings can help better understand model results, provide guidance on\npreparing training data, and improve the robustness of the models. All of our\ndatasets, code, and results are available at\nhttps://figshare.com/s/284abfba67dba448fdc2.",
    "descriptor": "\nComments: 11 pages, 14 figures. Accepted at ICSE 2023 (not camera-ready version). Corrected typos in Listing 2\n",
    "authors": [
      "Benjamin Steenhoek",
      "Md Mahbubur Rahman",
      "Richard Jiles",
      "Wei Le"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08109"
  },
  {
    "id": "arXiv:2212.08111",
    "title": "Routine Outcome Monitoring in Psychotherapy Treatment using  Sentiment-Topic Modelling Approach",
    "abstract": "Despite the importance of emphasizing the right psychotherapy treatment for\nan individual patient, assessing the outcome of the therapy session is equally\ncrucial. Evidence showed that continuous monitoring patient's progress can\nsignificantly improve the therapy outcomes to an expected change. By monitoring\nthe outcome, the patient's progress can be tracked closely to help clinicians\nidentify patients who are not progressing in the treatment. These monitoring\ncan help the clinician to consider any necessary actions for the patient's\ntreatment as early as possible, e.g., recommend different types of treatment,\nor adjust the style of approach. Currently, the evaluation system is based on\nthe clinical-rated and self-report questionnaires that measure patients'\nprogress pre- and post-treatment. While outcome monitoring tends to improve the\ntherapy outcomes, however, there are many challenges in the current method,\ne.g. time and financial burden for administering questionnaires, scoring and\nanalysing the results. Therefore, a computational method for measuring and\nmonitoring patient progress over the course of treatment is needed, in order to\nenhance the likelihood of positive treatment outcome. Moreover, this\ncomputational method could potentially lead to an inexpensive monitoring tool\nto evaluate patients' progress in clinical care that could be administered by a\nwider range of health-care professionals.",
    "descriptor": "",
    "authors": [
      "Noor Fazilla Abd Yusof",
      "Chenghua Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08111"
  },
  {
    "id": "arXiv:2212.08119",
    "title": "Representation of linear PDEs with spatial integral terms as Partial  Integral Equations",
    "abstract": "In this paper, we present the Partial Integral Equation (PIE) representation\nof linear Partial Differential Equations (PDEs) in one spatial dimension, where\nthe PDE has spatial integral terms appearing in the dynamics and the boundary\nconditions. The PIE representation is obtained by performing a change of\nvariable where every PDE state is replaced by its highest, well-defined\nderivative using the Fundamental Theorem of Calculus to obtain a new equation\n(a PIE). We show that this conversion from PDE representation to PIE\nrepresentation can be written in terms of explicit maps from the PDE parameters\nto PIE parameters. Lastly, we present numerical examples to demonstrate the\napplication of the PIE representation by performing stability analysis of PDEs\nvia convex optimization methods.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2204.00186\n",
    "authors": [
      "Sachin Shivakumar",
      "Amritam Das",
      "Matthew Peet"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.08119"
  },
  {
    "id": "arXiv:2212.08120",
    "title": "Injecting Domain Knowledge in Language Models for Task-Oriented Dialogue  Systems",
    "abstract": "Pre-trained language models (PLM) have advanced the state-of-the-art across\nNLP applications, but lack domain-specific knowledge that does not naturally\noccur in pre-training data. Previous studies augmented PLMs with symbolic\nknowledge for different downstream NLP tasks. However, knowledge bases (KBs)\nutilized in these studies are usually large-scale and static, in contrast to\nsmall, domain-specific, and modifiable knowledge bases that are prominent in\nreal-world task-oriented dialogue (TOD) systems. In this paper, we showcase the\nadvantages of injecting domain-specific knowledge prior to fine-tuning on TOD\ntasks. To this end, we utilize light-weight adapters that can be easily\nintegrated with PLMs and serve as a repository for facts learned from different\nKBs. To measure the efficacy of proposed knowledge injection methods, we\nintroduce Knowledge Probing using Response Selection (KPRS) -- a probe designed\nspecifically for TOD models. Experiments on KPRS and the response generation\ntask show improvements of knowledge injection with adapters over strong\nbaselines.",
    "descriptor": "\nComments: Published at EMNLP 2022 (main conference)\n",
    "authors": [
      "Denis Emelin",
      "Daniele Bonadiman",
      "Sawsan Alqahtani",
      "Yi Zhang",
      "Saab Mansour"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08120"
  },
  {
    "id": "arXiv:2212.08121",
    "title": "Backdoor Attack Detection in Computer Vision by Applying Matrix  Factorization on the Weights of Deep Networks",
    "abstract": "The increasing importance of both deep neural networks (DNNs) and cloud\nservices for training them means that bad actors have more incentive and\nopportunity to insert backdoors to alter the behavior of trained models. In\nthis paper, we introduce a novel method for backdoor detection that extracts\nfeatures from pre-trained DNN's weights using independent vector analysis (IVA)\nfollowed by a machine learning classifier. In comparison to other detection\ntechniques, this has a number of benefits, such as not requiring any training\ndata, being applicable across domains, operating with a wide range of network\narchitectures, not assuming the nature of the triggers used to change network\nbehavior, and being highly scalable. We discuss the detection pipeline, and\nthen demonstrate the results on two computer vision datasets regarding image\nclassification and object detection. Our method outperforms the competing\nalgorithms in terms of efficiency and is more accurate, helping to ensure the\nsafe application of deep learning and AI.",
    "descriptor": "\nComments: 7 pages, 4 figures, 5 tables, AAAI Workshop on Safe AI 2023\n",
    "authors": [
      "Khondoker Murad Hossain",
      "Tim Oates"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08121"
  },
  {
    "id": "arXiv:2212.08122",
    "title": "Hybrid Paradigm-based Brain-Computer Interface for Robotic Arm Control",
    "abstract": "Brain-computer interface (BCI) uses brain signals to communicate with\nexternal devices without actual control. Particularly, BCI is one of the\ninterfaces for controlling the robotic arm. In this study, we propose a\nknowledge distillation-based framework to manipulate robotic arm through hybrid\nparadigm induced EEG signals for practical use. The teacher model is designed\nto decode input data hierarchically and transfer knowledge to student model. To\nthis end, soft labels and distillation loss functions are applied to the\nstudent model training. According to experimental results, student model\nachieved the best performance among the singular architecture-based methods. It\nis confirmed that using hierarchical models and knowledge distillation, the\nperformance of a simple architecture can be improved. Since it is uncertain\nwhat knowledge is transferred, it is important to clarify this part in future\nstudies.",
    "descriptor": "",
    "authors": [
      "Byeong-Hoo Lee",
      "Jeong-Hyun Cho",
      "Byung-Hee Kwon"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08122"
  },
  {
    "id": "arXiv:2212.08123",
    "title": "Bayesian posterior approximation with stochastic ensembles",
    "abstract": "We introduce ensembles of stochastic neural networks to approximate the\nBayesian posterior, combining stochastic methods such as dropout with deep\nensembles. The stochastic ensembles are formulated as families of distributions\nand trained to approximate the Bayesian posterior with variational inference.\nWe implement stochastic ensembles based on Monte Carlo dropout, DropConnect and\na novel non-parametric version of dropout and evaluate them on a toy problem\nand CIFAR image classification. For CIFAR, the stochastic ensembles are\nquantitatively compared to published Hamiltonian Monte Carlo results for a\nResNet-20 architecture. We also test the quality of the posteriors directly\nagainst Hamiltonian Monte Carlo simulations in a simplified toy model. Our\nresults show that in a number of settings, stochastic ensembles provide more\naccurate posterior estimates than regular deep ensembles.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Oleksandr Balabanov",
      "Bernhard Mehlig",
      "Hampus Linander"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.08123"
  },
  {
    "id": "arXiv:2212.08124",
    "title": "Elasticity Solver in Minecraft for Learning Mechanics of Materials by  Gaming",
    "abstract": "Video games have emerged as a medium for learning by creating engaging\nenvironments, encouraging creative and deep thinking, and exposing learners to\ncomplex problems. Unfortunately, even though there are increasing examples of\nvideo games for many basic science and engineering concepts, similar efforts\nfor higher level engineering concepts such as mechanics of materials are still\nlacking. Here we present a mesh-free elasticity solver implementation in the\npopular video game Minecraft, a sandbox game where players can build any\nstructure they can imagine. Modifications to the game, called mods in the\nMinecraft community, are a common feature of this platform. Our elasticity mod\ncomputes the stress and deformation of arbitrary structures and colors the\nblocks with a heat-map to visualize the result of the analysis. We used this\nmod in the Honors section of two courses taught at Purdue University: Basic\nMechanics I Statics, Mechanics of Materials. This articles describes our\nexperience developing and deploying this tool to encourage its use in\nbiomedical engineering classrooms. A future goal is to engage the broader\naudience Minecraft players that already interact regularly with Minecraft mods.",
    "descriptor": "",
    "authors": [
      "Zachariah P. Beck",
      "Brandon Alpert",
      "Alexander J. Bowman",
      "William R. Watson",
      "Adrian Buganza Tepole"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.08124"
  },
  {
    "id": "arXiv:2212.08128",
    "title": "Error estimates of a theta-scheme for second-order mean field games",
    "abstract": "We introduce and analyze a new finite-difference scheme, relying on the\ntheta-method, for solving monotone second-order mean field games. These games\nconsist of a coupled system of the Fokker-Planck and the\nHamilton-Jacobi-Bellman equation. The theta-method is used for discretizing the\ndiffusion terms: we approximate them with a convex combination of an implicit\nand an explicit term. On contrast, we use an explicit centered scheme for the\nfirst-order terms. Assuming that the running cost is strongly convex and\nregular, we first prove the monotonicity and the stability of our theta-scheme,\nunder a CFL condition. Taking advantage of the regularity of the solution of\nthe continuous problem, we estimate the consistency error of the theta-scheme.\nOur main result is a convergence rate of order $\\mathcal{O}(h^r)$ for the\ntheta-scheme, where $h$ is the step length of the space variable and $r \\in\n(0,1)$ is related to the H\\\"older continuity of the solution of the continuous\nproblem and some of its derivatives.",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "J.Fr\u00e9d\u00e9ric Bonnans",
      "Kang Liu",
      "Laurent Pfeiffer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.08128"
  },
  {
    "id": "arXiv:2212.08131",
    "title": "Bridging the Gap Between Offline and Online Reinforcement Learning  Evaluation Methodologies",
    "abstract": "Reinforcement learning (RL) has shown great promise with algorithms learning\nin environments with large state and action spaces purely from scalar reward\nsignals. A crucial challenge for current deep RL algorithms is that they\nrequire a tremendous amount of environment interactions for learning. This can\nbe infeasible in situations where such interactions are expensive; such as in\nrobotics. Offline RL algorithms try to address this issue by bootstrapping the\nlearning process from existing logged data without needing to interact with the\nenvironment from the very beginning. While online RL algorithms are typically\nevaluated as a function of the number of environment interactions, there exists\nno single established protocol for evaluating offline RL methods.In this paper,\nwe propose a sequential approach to evaluate offline RL algorithms as a\nfunction of the training set size and thus by their data efficiency. Sequential\nevaluation provides valuable insights into the data efficiency of the learning\nprocess and the robustness of algorithms to distribution changes in the dataset\nwhile also harmonizing the visualization of the offline and online learning\nphases. Our approach is generally applicable and easy to implement. We compare\nseveral existing offline RL algorithms using this approach and present insights\nfrom a variety of tasks and offline datasets.",
    "descriptor": "\nComments: Offline RL Workshop, NeurIPS 2022\n",
    "authors": [
      "Shivakanth Sujit",
      "Pedro H. M. Braga",
      "Jorg Bornschein",
      "Samira Ebrahimi Kahou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08131"
  },
  {
    "id": "arXiv:2212.08132",
    "title": "WEKA-Based: Key Features and Classifier for French of Five Countries",
    "abstract": "This paper describes a French dialect recognition system that will\nappropriately distinguish between different regional French dialects. A corpus\nof five regions - Monaco, French-speaking, Belgium, French-speaking\nSwitzerland, French-speaking Canada and France, which is targeted\nforconstruction by the Sketch Engine. The content of the corpus is related to\nthe four themes of eating, drinking, sleeping and living, which are closely\nlinked to popular life. The experimental results were obtained through the\nprocessing of a python coded pre-processor and Waikato Environment for\nKnowledge Analysis (WEKA) data analytic tool which contains many filters and\nclassifiers for machine learning.",
    "descriptor": "",
    "authors": [
      "Zeqian Li",
      "Keyu Qiu",
      "Chenxu Jiao",
      "Wen Zhu",
      "Haoran Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08132"
  },
  {
    "id": "arXiv:2212.08136",
    "title": "Efficient Long Sequence Modeling via State Space Augmented Transformer",
    "abstract": "Transformer models have achieved superior performance in various natural\nlanguage processing tasks. However, the quadratic computational cost of the\nattention mechanism limits its practicality for long sequences. There are\nexisting attention variants that improve the computational efficiency, but they\nhave limited ability to effectively compute global information. In parallel to\nTransformer models, state space models (SSMs) are tailored for long sequences,\nbut they are not flexible enough to capture complicated local information. We\npropose SPADE, short for $\\underline{\\textbf{S}}$tate\ns$\\underline{\\textbf{P}}$ace\n$\\underline{\\textbf{A}}$ugmente$\\underline{\\textbf{D}}$\nTransform$\\underline{\\textbf{E}}$r. Specifically, we augment a SSM into the\nbottom layer of SPADE, and we employ efficient local attention methods for the\nother layers. The SSM augments global information, which complements the lack\nof long-range dependency issue in local attention methods. Experimental results\non the Long Range Arena benchmark and language modeling tasks demonstrate the\neffectiveness of the proposed method. To further demonstrate the scalability of\nSPADE, we pre-train large encoder-decoder models and present fine-tuning\nresults on natural language understanding and natural language generation\ntasks.",
    "descriptor": "",
    "authors": [
      "Simiao Zuo",
      "Xiaodong Liu",
      "Jian Jiao",
      "Denis Charles",
      "Eren Manavoglu",
      "Tuo Zhao",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08136"
  },
  {
    "id": "arXiv:2212.08140",
    "title": "A finite element model for concentration polarization and osmotic  effects in a membrane channel",
    "abstract": "In this paper we study a mathematical model that represents the concentration\npolarization and osmosis effects in a reverse osmosis cross-flow channel with\nporous membranes at some of its boundaries. The fluid is modeled using the\nNavier-Stokes equations and Darcy's law is used to impose the momentum balance\non the membrane. The scheme consist of a conforming finite element method with\nthe velocity-pressure formulation for the Navier-Stokes equations, together\nwith a primal scheme for the convection-diffusion equations. The Nitsche method\nis used to impose the permeability condition across the membrane. Several\nnumerical experiments are performed to show the robustness of the method. The\nresulting model accurately replicates the analytical models and predicts\nsimilar results to previous works. It is found that the submerged configuration\nhas the highest permeate production, but also has the greatest pressure loss of\nall three configurations studied.",
    "descriptor": "",
    "authors": [
      "Nicol\u00e1s Carro",
      "David Mora",
      "Jesus Vellojin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.08140"
  },
  {
    "id": "arXiv:2212.08141",
    "title": "Epistemological Equation for Analysing Uncontrollable States in Complex  Systems: Quantifying Cyber Risks from the Internet of Things",
    "abstract": "To enable quantitative risk assessment of uncontrollable risk states in\ncomplex and coupled IoT systems, a new epistemological equation is designed and\ntested though comparative and empirical analysis. The comparative analysis is\nconducted on national digital strategies, followed by an empirical analysis of\ncyber risk assessment approaches. The new epistemological analysis approach\nenables the assessment of uncontrollable risk states in complex IoT systems,\nwhich begin to resemble artificial intelligence, and can be used for a\nquantitative self-assessment of IoT cyber risk posture.",
    "descriptor": "",
    "authors": [
      "Petar Radanliev",
      "David De Roure",
      "Pete Burnap",
      "Omar Santos"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "General Literature (cs.GL)",
      "Systems and Control (eess.SY)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.08141"
  },
  {
    "id": "arXiv:2212.08143",
    "title": "Approximate counting using Taylor's theorem: a survey",
    "abstract": "In this article we consider certain well-known polynomials associated with\ngraphs including the independence polynomial and the chromatic polynomial.\nThese polynomials count certain objects in graphs: independent sets in the case\nof the independence polynomial and proper colourings in the case of the\nchromatic polynomial. They also have interpretations as partition functions in\nstatistical physics.\nThe algorithmic problem of (approximately) computing these types of\npolynomials has been studied for close to 50 years, especially using Markov\nchain techniques. Around eight years ago, Barvinok devised a new algorithmic\napproach based on Taylor's theorem for computing the permanent of certain\nmatrices, and the approach has been applied to various graph polynomials since\nthen. This article is intended as a gentle introduction to the approach as well\nas a partial survey of associated techniques and results.",
    "descriptor": "\nComments: 28 pages. Published in the October issue of the Bulletin of the EATC. This is a survey article and does not contain any new results\n",
    "authors": [
      "Viresh Patel",
      "Guus Regts"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2212.08143"
  },
  {
    "id": "arXiv:2212.08144",
    "title": "Distributed Maneuver Planning with Connected and Automated Vehicles for  Boosting Traffic Efficiency",
    "abstract": "Connected and automated vehicles (CAVs) have the potential to improve traffic\nthroughput and achieve a more efficient utilization of the available roadway\ninfrastructure. They also have the potential to reduce energy consumption\nthrough traffic motion harmonization, even when operating in mixed traffic with\nother human-driven vehicles. The key to realizing these potentials are\ncoordinated control schemes that can be implemented in a distributed manner\nwith the CAVs. In this paper, we propose a distributed predictive control\nframework that features a two-dimensional maneuver planner incorporating\nexplicit coordination constraints between connected vehicles operating in mixed\ntraffic at various penetration levels. The framework includes a distributed\nimplementation of a reference speed assigner that estimates local traffic speed\nfrom on-board measurements and communicated information. We present an\nextensive evaluation of the proposed framework in traffic micro-simulations at\nvarious CAV penetrations from traffic flow, energy use, and lane utilization\npoints of view. Results are compared to a baseline scenario with no CAVs, as\nwell as, a benchmark one-dimensional planner.",
    "descriptor": "",
    "authors": [
      "Nathan Goulet",
      "Beshah Ayalew"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08144"
  },
  {
    "id": "arXiv:2212.08146",
    "title": "Kernel-as-a-Service: A Serverless Interface to GPUs",
    "abstract": "Serverless computing has made it easier than ever to deploy applications over\nscalable cloud resources, all the while driving higher utilization for cloud\nproviders. While this technique has worked well for easily divisible resources\nlike CPU and local DRAM, it has struggled to incorporate more expensive and\nmonolithic resources like GPUs or other application accelerators. We cannot\nsimply slap a GPU on a FaaS platform and expect to keep all the benefits\nserverless promises. We need a more tailored approach if we want to best\nutilize these critical resources.\nIn this paper we present Kernel-as-a-Service (KaaS), a serverless interface\nto GPUs. In KaaS, GPUs are first-class citizens that are invoked just like any\nother serverless function. Rather than mixing host and GPU code as is typically\ndone, KaaS runs graphs of GPU-only code while host code is run on traditional\nfunctions. The KaaS system is responsible for managing GPU memory and schedules\nuser kernels across the entire pool of available GPUs rather than relying on\nstatic allocations. This approach allows us to more effectively share expensive\nGPU resources, especially in multitenant environments like the cloud. We add\nsupport for KaaS to the Ray distributed computing framework and evaluate it\nwith workloads including a TVM-based deep learning compiler and a BLAS library.\nOur results show that KaaS is able to drive up to 50x higher throughput and 16x\nlower latency when GPU resources are contended.",
    "descriptor": "",
    "authors": [
      "Nathan Pemberton",
      "Anton Zabreyko",
      "Zhoujie Ding",
      "Randy Katz",
      "Joseph Gonzalez"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.08146"
  },
  {
    "id": "arXiv:2212.08147",
    "title": "Small-Signal Stability of Load and Network Dynamics on Grid-Forming  Inverters",
    "abstract": "This paper presents several stability analyses for grid-forming inverters and\nsynchronous generators considering the dynamics of transmission lines and\ndifferent load models. Load models are usually of secondary importance compared\nto generation source models, but as the results show, they play a crucial role\nin stability studies with the introduction of inverter-based resources. Given\ninverter control time scales, the implications of considering or neglecting\nelectromagnetic transients of the network are very relevant in the stability\nassessments. In this paper, we perform eigenvalue analyses for inverter-based\nresources and synchronous machines connected to a load and explore the effects\nof multiples models under different network representations. We explore maximum\nloadability of inverter-based resources and synchronous machines, while\nanalyzing the effects of load and network dynamic models on small-signal\nstability. The results show that the network representation plays a fundamental\nrole in the stability of the system of different load models. The resulting\nstability regions are significantly different depending on the source and load\nmodel considered.",
    "descriptor": "\nComments: Submitted to IEEE PES General Meeting 2023\n",
    "authors": [
      "Rodrigo Henriquez-Auba",
      "Jose Daniel Lara",
      "Duncan S. Callaway"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08147"
  },
  {
    "id": "arXiv:2212.08148",
    "title": "Collision Avoidance Testing of the Waymo Automated Driving System",
    "abstract": "This paper describes Waymo's Collision Avoidance Testing (CAT) methodology: a\nscenario-based testing method that evaluates the safety of the Waymo Driver\nAutomated Driving Systems' (ADS) intended functionality in conflict situations\ninitiated by other road users that require urgent evasive maneuvers. Because\nSAE Level 4 ADS are responsible for the dynamic driving task (DDT), when\nengaged, without immediate human intervention, evaluating a Level 4 ADS using\nscenario-based testing is difficult due to the potentially infinite number of\noperational scenarios in which hazardous situations may unfold. To that end, in\nthis paper we first describe the safety test objectives for the CAT\nmethodology, including the collision and serious injury metrics and the\nreference behavior model representing a non-impaired eyes on conflict human\ndriver used to form an acceptance criterion. Afterward, we introduce the\nprocess for identifying potentially hazardous situations from a combination of\nhuman data, ADS testing data, and expert knowledge about the product design and\nassociated Operational Design Domain (ODD). The test allocation and execution\nstrategy is presented next, which exclusively utilize simulations constructed\nfrom sensor data collected on a test track, real-world driving, or from\nsimulated sensor data. The paper concludes with the presentation of results\nfrom applying CAT to the fully autonomous ride-hailing service that Waymo\noperates in San Francisco, California and Phoenix, Arizona. The iterative\nnature of scenario identification, combined with over ten years of experience\nof on-road testing, results in a scenario database that converges to a\nrepresentative set of responder role scenarios for a given ODD. Using Waymo's\nvirtual test platform, which is calibrated to data collected as part of many\nyears of ADS development, the CAT methodology provides a robust and scalable\nsafety evaluation.",
    "descriptor": "",
    "authors": [
      "Kristofer D. Kusano",
      "Kurt Beatty",
      "Scott Schnelle",
      "Francesca Favaro",
      "Cam Crary",
      "Trent Victor"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.08148"
  },
  {
    "id": "arXiv:2212.08151",
    "title": "First De-Trend then Attend: Rethinking Attention for Time-Series  Forecasting",
    "abstract": "Transformer-based models have gained large popularity and demonstrated\npromising results in long-term time-series forecasting in recent years. In\naddition to learning attention in time domain, recent works also explore\nlearning attention in frequency domains (e.g., Fourier domain, wavelet domain),\ngiven that seasonal patterns can be better captured in these domains. In this\nwork, we seek to understand the relationships between attention models in\ndifferent time and frequency domains. Theoretically, we show that attention\nmodels in different domains are equivalent under linear conditions (i.e.,\nlinear kernel to attention scores). Empirically, we analyze how attention\nmodels of different domains show different behaviors through various synthetic\nexperiments with seasonality, trend and noise, with emphasis on the role of\nsoftmax operation therein. Both these theoretical and empirical analyses\nmotivate us to propose a new method: TDformer (Trend Decomposition\nTransformer), that first applies seasonal-trend decomposition, and then\nadditively combines an MLP which predicts the trend component with Fourier\nattention which predicts the seasonal component to obtain the final prediction.\nExtensive experiments on benchmark time-series forecasting datasets demonstrate\nthat TDformer achieves state-of-the-art performance against existing\nattention-based models.",
    "descriptor": "\nComments: NeurIPS 2022 All Things Attention Workshop\n",
    "authors": [
      "Xiyuan Zhang",
      "Xiaoyong Jin",
      "Karthick Gopalswamy",
      "Gaurav Gupta",
      "Youngsuk Park",
      "Xingjian Shi",
      "Hao Wang",
      "Danielle C. Maddix",
      "Yuyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08151"
  },
  {
    "id": "arXiv:2212.08153",
    "title": "FiDO: Fusion-in-Decoder optimized for stronger performance and faster  inference",
    "abstract": "Fusion-in-Decoder (FiD) is a powerful retrieval-augmented language model that\nsets the state-of-the-art on many knowledge-intensive NLP tasks. However, FiD\nsuffers from very expensive inference. We show that the majority of inference\ntime results from memory bandwidth constraints in the decoder, and propose two\nsimple changes to the FiD architecture to speed up inference by 7x. The faster\ndecoder inference then allows for a much larger decoder. We denote FiD with the\nabove modifications as FiDO, and show that it strongly improves performance\nover existing FiD models for a wide range of inference budgets. For example,\nFiDO-Large-XXL performs faster inference than FiD-Base and achieves better\nperformance than FiD-Large.",
    "descriptor": "",
    "authors": [
      "Michiel de Jong",
      "Yury Zemlyanskiy",
      "Joshua Ainslie",
      "Nicholas FitzGerald",
      "Sumit Sanghai",
      "Fei Sha",
      "William Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08153"
  },
  {
    "id": "arXiv:2212.08158",
    "title": "MM-SHAP: A Performance-agnostic Metric for Measuring Multimodal  Contributions in Vision and Language Models & Tasks",
    "abstract": "Vision and language models (VL) are known to exploit unrobust indicators in\nindividual modalities (e.g., introduced by distributional biases), instead of\nfocusing on relevant information in each modality. A small drop in accuracy\nobtained on a VL task with a unimodal model suggests that so-called unimodal\ncollapse occurred. But how to quantify the amount of unimodal collapse\nreliably, at dataset and instance-level, to diagnose and combat unimodal\ncollapse in a targeted way? We present MM-SHAP, a performance-agnostic\nmultimodality score that quantifies the proportion by which a model uses\nindividual modalities in multimodal tasks. MM-SHAP is based on Shapley values\nand will be applied in two ways: (1) to compare models for their degree of\nmultimodality, and (2) to measure the contribution of individual modalities for\na given task and dataset. Experiments with 6 VL models -- LXMERT, CLIP and four\nALBEF variants -- on four VL tasks highlight that unimodal collapse can occur\nto different degrees and in different directions, contradicting the wide-spread\nassumption that unimodal collapse is one-sided. We recommend MM-SHAP for\nanalysing multimodal tasks, to diagnose and guide progress towards multimodal\nintegration. Code available at: https://github.com/Heidelberg-NLP/MM-SHAP",
    "descriptor": "\nComments: 10 pages, 13 appendix pages, 11 figures, 2 tables\n",
    "authors": [
      "Letitia Parcalabescu",
      "Anette Frank"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08158"
  },
  {
    "id": "arXiv:2212.08161",
    "title": "QF-MAC: Adaptive, Local Channel Hopping for Interference Avoidance in  Wireless Meshes",
    "abstract": "The throughput efficiency of a wireless mesh network with potentially\nmalicious external or internal interference can be significantly improved by\nequipping routers with multi-radio access over multiple channels. For reliably\nmitigating the effect of interference, frequency diversity (e.g., channel\nhopping) and time diversity (e.g., carrier sense multiple access) are\nconventionally leveraged to schedule communication channels. However,\nmulti-radio scheduling over a limited set of channels to minimize the effect of\ninterference and maximize network performance in the presence of concurrent\nnetwork flows remains a challenging problem. The state-of-the-practice in\nchannel scheduling of multi-radios reveals not only gaps in achieving network\ncapacity but also significant communication overhead.\nThis paper proposes an adaptive channel hopping algorithm for multi-radio\ncommunication, QuickFire MAC (QF-MAC), that assigns per-node, per-flow\n``local'' channel hopping sequences, using only one-hop neighborhood\ncoordination. QF-MAC achieves a substantial enhancement of throughput and\nlatency with low control overhead. QF-MAC also achieves robustness against\nnetwork dynamics, i.e., mobility and external interference, and selective\njamming attacker where a global channel hopping sequence (e.g., TSCH) fails to\nsustain the communication performance. Our simulation results quantify the\nperformance gains of QF-MAC in terms of goodput, latency, reliability,\ncommunication overhead, and jamming tolerance, both in the presence and absence\nof mobility, across diverse configurations of network densities, sizes, and\nconcurrent flows.",
    "descriptor": "",
    "authors": [
      "Yung-Fu Chen",
      "Anish Arora"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.08161"
  },
  {
    "id": "arXiv:2212.08166",
    "title": "Probabilistic Constraint Tightening Techniques for Trajectory Planning  with Predictive Control",
    "abstract": "In order for automated mobile vehicles to navigate in the real world with\nminimal collision risks, it is necessary for their planning algorithms to\nconsider uncertainties from measurements and environmental disturbances. In\nthis paper, we consider analytical solutions for a conservative approximation\nof the mutual probability of collision between two robotic vehicles in the\npresence of such uncertainties. Therein, we present two methods, which we call\nunitary scaling and principal axes rotation, for decoupling the bivariate\nintegral required for efficient approximation of the probability of collision\nbetween two vehicles including orientation effects. We compare the conservatism\nof these methods analytically and numerically. By closing a control loop\nthrough a model predictive guidance scheme, we observe through Monte-Carlo\nsimulations that directly implementing collision avoidance constraints from the\nconservative approximations remains infeasible for real-time planning. We then\npropose and implement a convexification approach based on the tightened\ncollision constraints that significantly improves the computational efficiency\nand robustness of the predictive guidance scheme.",
    "descriptor": "",
    "authors": [
      "Nathan Goulet",
      "Qian Wang",
      "Beshah Ayalew"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08166"
  },
  {
    "id": "arXiv:2212.08167",
    "title": "Evaluation of Synthetic Datasets for Conversational Recommender Systems",
    "abstract": "For researchers leveraging Large-Language Models (LLMs) in the generation of\ntraining datasets, especially for conversational recommender systems - the\nabsence of robust evaluation frameworks has been a long-standing problem. The\nefficiency brought about by LLMs in the data generation phase is impeded during\nthe process of evaluation of the generated data, since it generally requires\nhuman-raters to ensure that the data generated is of high quality and has\nsufficient diversity. Since the quality of training data is critical for\ndownstream applications, it is important to develop metrics that evaluate the\nquality holistically and identify biases. In this paper, we present a framework\nthat takes a multi-faceted approach towards evaluating datasets produced by\ngenerative models and discuss the advantages and limitations of various\nevaluation methods.",
    "descriptor": "",
    "authors": [
      "Harsh Lara",
      "Manoj Tiwari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08167"
  },
  {
    "id": "arXiv:2212.08170",
    "title": "BNSynth: Bounded Boolean Functional Synthesis",
    "abstract": "The automated synthesis of correct-by-construction Boolean functions from\nlogical specifications is known as the Boolean Functional Synthesis (BFS)\nproblem. BFS has many application areas that range from software engineering to\ncircuit design. In this paper, we introduce a tool BNSynth, that is the first\nto solve the BFS problem under a given bound on the solution space. Bounding\nthe solution space induces the synthesis of smaller functions that benefit\nresource constrained areas such as circuit design. BNSynth uses a\ncounter-example guided, neural approach to solve the bounded BFS problem.\nInitial results show promise in synthesizing smaller solutions; we observe at\nleast \\textbf{3.2X} (and up to \\textbf{24X}) improvement in the reduction of\nsolution size on average, as compared to state of the art tools on our\nbenchmarks. BNSynth is available on GitHub under an open source license.",
    "descriptor": "",
    "authors": [
      "Ravi Raja",
      "Stanly Samuel",
      "Chiranjib Bhattacharyya",
      "Deepak D'Souza",
      "Aditya Kanade"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2212.08170"
  },
  {
    "id": "arXiv:2212.08171",
    "title": "Graphon Pooling for Reducing Dimensionality of Signals and Convolutional  Operators on Graphs",
    "abstract": "In this paper we propose a pooling approach for convolutional information\nprocessing on graphs relying on the theory of graphons and limits of dense\ngraph sequences. We present three methods that exploit the induced graphon\nrepresentation of graphs and graph signals on partitions of [0, 1]2 in the\ngraphon space. As a result we derive low dimensional representations of the\nconvolutional operators, while a dimensionality reduction of the signals is\nachieved by simple local interpolation of functions in L2([0, 1]). We prove\nthat those low dimensional representations constitute a convergent sequence of\ngraphs and graph signals, respectively. The methods proposed and the\ntheoretical guarantees that we provide show that the reduced graphs and signals\ninherit spectral-structural properties of the original quantities. We evaluate\nour approach with a set of numerical experiments performed on graph neural\nnetworks (GNNs) that rely on graphon pooling. We observe that graphon pooling\nperforms significantly better than other approaches proposed in the literature\nwhen dimensionality reduction ratios between layers are large. We also observe\nthat when graphon pooling is used we have, in general, less overfitting and\nlower computational cost.",
    "descriptor": "",
    "authors": [
      "Alejandro Parada-Mayorga",
      "Zhiyang Wang",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08171"
  },
  {
    "id": "arXiv:2212.08172",
    "title": "Reliable Measures of Spread in High Dimensional Latent Spaces",
    "abstract": "Understanding geometric properties of natural language processing models'\nlatent spaces allows the manipulation of these properties for improved\nperformance on downstream tasks. One such property is the amount of data spread\nin a model's latent space, or how fully the available latent space is being\nused. In this work, we define data spread and demonstrate that the commonly\nused measures of data spread, Average Cosine Similarity and a partition\nfunction min/max ratio I(V), do not provide reliable metrics to compare the use\nof latent space across models. We propose and examine eight alternative\nmeasures of data spread, all but one of which improve over these current\nmetrics when applied to seven synthetic data distributions. Of our proposed\nmeasures, we recommend one principal component-based measure and one\nentropy-based measure that provide reliable, relative measures of spread and\ncan be used to compare models of different sizes and dimensionalities.",
    "descriptor": "\nComments: 24 pages, 11 figures, 13 tables\n",
    "authors": [
      "Anna C. Marbut",
      "Katy McKinney-Bock",
      "Travis J. Wheeler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08172"
  },
  {
    "id": "arXiv:2212.08174",
    "title": "Non-IID Transfer Learning on Graphs",
    "abstract": "Transfer learning refers to the transfer of knowledge or information from a\nrelevant source domain to a target domain. However, most existing transfer\nlearning theories and algorithms focus on IID tasks, where the source/target\nsamples are assumed to be independent and identically distributed. Very little\neffort is devoted to theoretically studying the knowledge transferability on\nnon-IID tasks, e.g., cross-network mining. To bridge the gap, in this paper, we\npropose rigorous generalization bounds and algorithms for cross-network\ntransfer learning from a source graph to a target graph. The crucial idea is to\ncharacterize the cross-network knowledge transferability from the perspective\nof the Weisfeiler-Lehman graph isomorphism test. To this end, we propose a\nnovel Graph Subtree Discrepancy to measure the graph distribution shift between\nsource and target graphs. Then the generalization error bounds on cross-network\ntransfer learning, including both cross-network node classification and link\nprediction tasks, can be derived in terms of the source knowledge and the Graph\nSubtree Discrepancy across domains. This thereby motivates us to propose a\ngeneric graph adaptive network (GRADE) to minimize the distribution shift\nbetween source and target graphs for cross-network transfer learning.\nExperimental results verify the effectiveness and efficiency of our GRADE\nframework on both cross-network node classification and cross-domain\nrecommendation tasks.",
    "descriptor": "\nComments: Accepted by AAAI-23\n",
    "authors": [
      "Jun Wu",
      "Jingrui He",
      "Elizabeth Ainsworth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08174"
  },
  {
    "id": "arXiv:2212.08177",
    "title": "The Functional Machine Calculus",
    "abstract": "This paper presents the Functional Machine Calculus (FMC) as a simple model\nof higher-order computation with \"reader/writer\" effects: higher-order mutable\nstore, input/output, and probabilistic and non-deterministic computation.\nThe FMC derives from the lambda-calculus by taking the standard operational\nperspective of a call-by-name stack machine as primary, and introducing two\nnatural generalizations. One, \"locations\", introduces multiple stacks, which\neach may represent an effect and so enable effect operators to be encoded into\nthe abstraction and application constructs of the calculus. The second,\n\"sequencing\", is known from kappa-calculus and concatenative programming\nlanguages, and introduces the imperative notions of \"skip\" and \"sequence\". This\nenables the encoding of reduction strategies, including call-by-value\nlambda-calculus and monadic constructs.\nThe encoding of effects into generalized abstraction and application means\nthat standard results from the lambda-calculus may carry over to effects. The\nmain result is confluence, which is possible because encoded effects reduce\nalgebraically rather than operationally. Reduction generates the familiar\nalgebraic laws for state, and unlike in the monadic setting, reader/writer\neffects combine seamlessly. A system of simple types confers termination of the\nmachine.",
    "descriptor": "",
    "authors": [
      "Willem Heijltjes"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2212.08177"
  },
  {
    "id": "arXiv:2212.08181",
    "title": "Preferential stiffness and the crack-tip fields of an elastic porous  solid based on the density-dependent moduli model",
    "abstract": "In this paper, we study the preferential stiffness and the crack-tip fields\nfor an elastic porous solid of which material properties are dependent upon the\ndensity. Such a description is necessary to describe the failure that can be\ncaused by damaged pores in many porous bodies such as ceramics, concrete and\nhuman bones. To that end, we revisit a new class of implicit constitutive\nrelations under the assumption of small deformation. Although the constitutive\nrelationship \\textit{appears linear} in both the Cauchy stress and linearized\nstrain, the governing equation bestowed from the balance of linear momentum\nresults in a quasi-linear partial differential equation (PDE) system. For the\nlinearization and obtaining a sequence of elliptic PDEs, we propose the\nsolution algorithm comprise a \\textit{Newton's method} coupled with a bilinear\ncontinuous Galerkin-type finite elements for the discretization. Our algorithm\nexhibits an optimal rate of convergence for a manufactured solution. In the\nnumerical experiments, we set the boundary value problems (BVPs) with edge\ncrack {under different modes of loading (i.e., the pure mode-I, II, and the\nmixed-mode). From the numerical results, we find that the density-dependent\nmoduli model describes diverse phenomena that are not captured within the\nframework of classical linearized elasticity. In particular,numerical solutions\nclearly indicate that the nonlinear \\textit{modeling} parameter depending on\nits sign and magnitude can control preferential mechanical stiffness along with\nthe change of volumetric strain; larger the parameter is in the positive\nvalue}, the responses are such that the strength of porous solid gets weaker\nagainst the tensile loading while stiffer against the in-plane shear (or\ncompressive) loading, which is vice versa for the negative value of it.",
    "descriptor": "",
    "authors": [
      "Hyun C. Yoon",
      "S. M. Mallikarjunaiah",
      "Dambaru Bhatta"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.08181"
  },
  {
    "id": "arXiv:2212.08183",
    "title": "Local Branching Relaxation Heuristics for Integer Linear Programs",
    "abstract": "Large Neighborhood Search (LNS) is a popular heuristic algorithm for solving\ncombinatorial optimization problems (COP). It starts with an initial solution\nto the problem and iteratively improves it by searching a large neighborhood\naround the current best solution. LNS relies on heuristics to select\nneighborhoods to search in. In this paper, we focus on designing effective and\nefficient heuristics in LNS for integer linear programs (ILP) since a wide\nrange of COPs can be represented as ILPs. Local Branching (LB) is a heuristic\nthat selects the neighborhood that leads to the largest improvement over the\ncurrent solution in each iteration of LNS. LB is often slow since it needs to\nsolve an ILP of the same size as input. Our proposed heuristics, LB-RELAX and\nits variants, use the linear programming relaxation of LB to select\nneighborhoods. Empirically, LB-RELAX and its variants compute as effective\nneighborhoods as LB but run faster. They achieve state-of-the-art anytime\nperformance on several ILP benchmarks.",
    "descriptor": "",
    "authors": [
      "Taoan Huang",
      "Aaron Ferber",
      "Yuandong Tian",
      "Bistra Dilkina",
      "Benoit Steiner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08183"
  },
  {
    "id": "arXiv:2212.08184",
    "title": "NBC-Softmax : Darkweb Author fingerprinting and migration tracking",
    "abstract": "Metric learning aims to learn distances from the data, which enhances the\nperformance of similarity-based algorithms. An author style detection task is a\nmetric learning problem, where learning style features with small intra-class\nvariations and larger inter-class differences is of great importance to achieve\nbetter performance. Recently, metric learning based on softmax loss has been\nused successfully for style detection. While softmax loss can produce separable\nrepresentations, its discriminative power is relatively poor. In this work, we\npropose NBC-Softmax, a contrastive loss based clustering technique for softmax\nloss, which is more intuitive and able to achieve superior performance. Our\ntechnique meets the criterion for larger number of samples, thus achieving\nblock contrastiveness, which is proven to outperform pair-wise losses. It uses\nmini-batch sampling effectively and is scalable. Experiments on 4 darkweb\nsocial forums, with NBCSAuthor that uses the proposed NBC-Softmax for author\nand sybil detection, shows that our negative block contrastive approach\nconstantly outperforms state-of-the-art methods using the same network\narchitecture.\nOur code is publicly available at : https://github.com/gayanku/NBC-Softmax",
    "descriptor": "",
    "authors": [
      "Gayan K. Kulatilleke",
      "Shekhar S. Chandra",
      "Marius Portmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.08184"
  },
  {
    "id": "arXiv:2212.08186",
    "title": "Learning Sparsity and Randomness for Data-driven Low Rank Approximation",
    "abstract": "Learning-based low rank approximation algorithms can significantly improve\nthe performance of randomized low rank approximation with sketch matrix. With\nthe learned value and fixed non-zero positions for sketch matrices from\nlearning-based algorithms, these matrices can reduce the test error of low rank\napproximation significantly. However, there is still no good method to learn\nnon-zero positions as well as overcome the out-of-distribution performance\nloss. In this work, we introduce two new methods Learning Sparsity and Learning\nRandomness which try to learn a better sparsity patterns and add randomness to\nthe value of sketch matrix. These two methods can be applied with any\nlearning-based algorithms which use sketch matrix directly. Our experiments\nshow that these two methods can improve the performance of previous\nlearning-based algorithm for both test error and out-of-distribution test error\nwithout adding too much complexity.",
    "descriptor": "",
    "authors": [
      "Tiejin Chen",
      "Yicheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08186"
  },
  {
    "id": "arXiv:2212.08187",
    "title": "Dual Moving Average Pseudo-Labeling for Source-Free Inductive Domain  Adaptation",
    "abstract": "Unsupervised domain adaptation reduces the reliance on data annotation in\ndeep learning by adapting knowledge from a source to a target domain. For\nprivacy and efficiency concerns, source-free domain adaptation extends\nunsupervised domain adaptation by adapting a pre-trained source model to an\nunlabeled target domain without accessing the source data. However, most\nexisting source-free domain adaptation methods to date focus on the\ntransductive setting, where the target training set is also the testing set. In\nthis paper, we address source-free domain adaptation in the more realistic\ninductive setting, where the target training and testing sets are mutually\nexclusive. We propose a new semi-supervised fine-tuning method named Dual\nMoving Average Pseudo-Labeling (DMAPL) for source-free inductive domain\nadaptation. We first split the unlabeled training set in the target domain into\na pseudo-labeled confident subset and an unlabeled less-confident subset\naccording to the prediction confidence scores from the pre-trained source\nmodel. Then we propose a soft-label moving-average updating strategy for the\nunlabeled subset based on a moving-average prototypical classifier, which\ngradually adapts the source model towards the target domain. Experiments show\nthat our proposed method achieves state-of-the-art performance and outperforms\nprevious methods by large margins.",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Hao Yan",
      "Yuhong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08187"
  },
  {
    "id": "arXiv:2212.08189",
    "title": "Multi-Resolution Online Deterministic Annealing: A Hierarchical and  Progressive Learning Architecture",
    "abstract": "Hierarchical learning algorithms that gradually approximate a solution to a\ndata-driven optimization problem are essential to decision-making systems,\nespecially under limitations on time and computational resources. In this\nstudy, we introduce a general-purpose hierarchical learning architecture that\nis based on the progressive partitioning of a possibly multi-resolution data\nspace. The optimal partition is gradually approximated by solving a sequence of\noptimization sub-problems that yield a sequence of partitions with increasing\nnumber of subsets. We show that the solution of each optimization problem can\nbe estimated online using gradient-free stochastic approximation updates. As a\nconsequence, a function approximation problem can be defined within each subset\nof the partition and solved using the theory of two-timescale stochastic\napproximation algorithms. This simulates an annealing process and defines a\nrobust and interpretable heuristic method to gradually increase the complexity\nof the learning architecture in a task-agnostic manner, giving emphasis to\nregions of the data space that are considered more important according to a\npredefined criterion. Finally, by imposing a tree structure in the progression\nof the partitions, we provide a means to incorporate potential multi-resolution\nstructure of the data space into this approach, significantly reducing its\ncomplexity, while introducing hierarchical feature extraction properties\nsimilar to certain classes of deep learning architectures. Asymptotic\nconvergence analysis and experimental results are provided for clustering,\nclassification, and regression problems.",
    "descriptor": "",
    "authors": [
      "Christos Mavridis",
      "John Baras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08189"
  },
  {
    "id": "arXiv:2212.08192",
    "title": "The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources  in Natural Language Understanding Systems",
    "abstract": "Many state-of-the-art natural language understanding (NLU) models are based\non pretrained neural language models. These models often make inferences using\ninformation from multiple sources. An important class of such inferences are\nthose that require both background knowledge, presumably contained in a model's\npretrained parameters, and instance-specific information that is supplied at\ninference time. However, the integration and reasoning abilities of NLU models\nin the presence of multiple knowledge sources have been largely understudied.\nIn this work, we propose a test suite of coreference resolution tasks that\nrequire reasoning over multiple facts. Our dataset is organized into subtasks\nthat differ in terms of which knowledge sources contain relevant facts. We\nevaluate state-of-the-art coreference resolution models on our dataset. Our\nresults indicate that several models struggle to reason on-the-fly over\nknowledge observed both at pretrain time and at inference time. However, with\ntask-specific training, a subset of models demonstrates the ability to\nintegrate certain knowledge types from multiple sources.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Akshatha Arodi",
      "Martin P\u00f6msl",
      "Kaheer Suleman",
      "Adam Trischler",
      "Alexandra Olteanu",
      "Jackie Chi Kit Cheung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08192"
  },
  {
    "id": "arXiv:2212.08193",
    "title": "Fault-Tolerant Locating-Dominating sets with Error-correction",
    "abstract": "A locating-dominating set is a subset of vertices representing \"detectors\" in\na graph G; each detector monitors its closed neighborhood and can distinguish\nits own location from its neighbors, and given all sensor input, the system can\nlocate an \"intruder\" anywhere in the graph. We explore a fault-tolerant variant\nof locating-dominating sets, error-correcting locating-dominating (ERR:LD)\nsets, which can tolerate an incorrect signal from a single detector. In\nparticular, we characterize error-correcting locating-dominating sets, and\nderive its existence criteria. We also prove that the problem of determining\nthe minimum cardinality of ERR:LD set in arbitrary graphs is NP-complete.\nAdditionally, we establish lower and upper bounds for the minimum density of\nERR:LD sets in infinite grids and cubic graphs, and prove the lower bound for\ncubic graphs is sharp.",
    "descriptor": "",
    "authors": [
      "Devin Jean",
      "Suk Seo"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2212.08193"
  },
  {
    "id": "arXiv:2212.08195",
    "title": "Improving Chess Commentaries by Combining Language Models with Symbolic  Reasoning Engines",
    "abstract": "Despite many recent advancements in language modeling, state-of-the-art\nlanguage models lack grounding in the real world and struggle with tasks\ninvolving complex reasoning. Meanwhile, advances in the symbolic reasoning\ncapabilities of AI have led to systems that outperform humans in games like\nchess and Go (Silver et al., 2018). Chess commentary provides an interesting\ndomain for bridging these two fields of research, as it requires reasoning over\na complex board state and providing analyses in natural language. In this work\nwe demonstrate how to combine symbolic reasoning engines with controllable\nlanguage models to generate chess commentaries. We conduct experiments to\ndemonstrate that our approach generates commentaries that are preferred by\nhuman judges over previous baselines.",
    "descriptor": "",
    "authors": [
      "Andrew Lee",
      "David Wu",
      "Emily Dinan",
      "Mike Lewis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08195"
  },
  {
    "id": "arXiv:2212.08196",
    "title": "Saved You A Click: Automatically Answering Clickbait Titles",
    "abstract": "Often clickbait articles have a title that is phrased as a question or vague\nteaser that entices the user to click on the link and read the article to find\nthe explanation. We developed a system that will automatically find the answer\nor explanation of the clickbait hook from the website text so that the user\ndoes not need to read through the text themselves. We fine-tune an extractive\nquestion and answering model (RoBERTa) and an abstractive one (T5), using data\nscraped from the 'StopClickbait' Facebook pages and Reddit's 'SavedYouAClick'\nsubforum. We find that both extractive and abstractive models improve\nsignificantly after finetuning. We find that the extractive model performs\nslightly better according to ROUGE scores, while the abstractive one has a\nslight edge in terms of BERTscores.",
    "descriptor": "",
    "authors": [
      "Oliver Johnson",
      "Beicheng Lou",
      "Janet Zhong",
      "Andrey Kurenkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08196"
  },
  {
    "id": "arXiv:2212.08199",
    "title": "Asymptotic Analysis of Deep Residual Networks",
    "abstract": "We investigate the asymptotic properties of deep Residual networks (ResNets)\nas the number of layers increases. We first show the existence of scaling\nregimes for trained weights markedly different from those implicitly assumed in\nthe neural ODE literature. We study the convergence of the hidden state\ndynamics in these scaling regimes, showing that one may obtain an ODE, a\nstochastic differential equation (SDE) or neither of these. In particular, our\nfindings point to the existence of a diffusive regime in which the deep network\nlimit is described by a class of stochastic differential equations (SDEs).\nFinally, we derive the corresponding scaling limits for the backpropagation\ndynamics.",
    "descriptor": "\nComments: 49 pages, 12 figures. arXiv admin note: substantial text overlap with arXiv:2105.12245\n",
    "authors": [
      "Rama Cont",
      "Alain Rossier",
      "Renyuan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08199"
  },
  {
    "id": "arXiv:2212.08200",
    "title": "Essentials of Parallel Graph Analytics",
    "abstract": "We identify the graph data structure, frontiers, operators, an iterative loop\nstructure, and convergence conditions as essential components of graph\nanalytics systems based on the native-graph approach. Using these essential\ncomponents, we propose an abstraction that captures all the significant\nprogramming models within graph analytics, such as bulk-synchronous,\nasynchronous, shared-memory, message-passing, and push vs. pull traversals.\nFinally, we demonstrate the power of our abstraction with an elegant modern C++\nimplementation of single-source shortest path and its required components.",
    "descriptor": "\nComments: Proceedings of the Workshop on Graphs, Architectures, Programming, and Learning\n",
    "authors": [
      "Muhammad Osama",
      "Serban D. Porumbescu",
      "John D. Owens"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.08200"
  },
  {
    "id": "arXiv:2212.08204",
    "title": "LegalRelectra: Mixed-domain Language Modeling for Long-range Legal Text  Comprehension",
    "abstract": "The application of Natural Language Processing (NLP) to specialized domains,\nsuch as the law, has recently received a surge of interest. As many legal\nservices rely on processing and analyzing large collections of documents,\nautomating such tasks with NLP tools emerges as a key challenge. Many popular\nlanguage models, such as BERT or RoBERTa, are general-purpose models, which\nhave limitations on processing specialized legal terminology and syntax. In\naddition, legal documents may contain specialized vocabulary from other\ndomains, such as medical terminology in personal injury text. Here, we propose\nLegalRelectra, a legal-domain language model that is trained on mixed-domain\nlegal and medical corpora. We show that our model improves over general-domain\nand single-domain medical and legal language models when processing\nmixed-domain (personal injury) text. Our training architecture implements the\nElectra framework, but utilizes Reformer instead of BERT for its generator and\ndiscriminator. We show that this improves the model's performance on processing\nlong passages and results in better long-range text comprehension.",
    "descriptor": "",
    "authors": [
      "Wenyue Hua",
      "Yuchen Zhang",
      "Zhe Chen",
      "Josie Li",
      "Melanie Weber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.08204"
  },
  {
    "id": "arXiv:2212.08205",
    "title": "A unified information-theoretic model of EEG signatures of human  language processing",
    "abstract": "We advance an information-theoretic model of human language processing in the\nbrain, in which incoming linguistic input is processed at two levels, in terms\nof a heuristic interpretation and in terms of error correction. We propose that\nthese two kinds of information processing have distinct electroencephalographic\nsignatures, corresponding to the well-documented N400 and P600 components of\nlanguage-related event-related potentials (ERPs). Formally, we show that the\ninformation content (surprisal) of a word in context can be decomposed into two\nquantities: (A) heuristic surprise, which signals processing difficulty of word\ngiven its inferred context, and corresponds with the N400 signal; and (B)\ndiscrepancy signal, which reflects divergence between the true context and the\ninferred context, and corresponds to the P600 signal. Both of these quantities\ncan be estimated using modern NLP techniques. We validate our theory by\nsuccessfully simulating ERP patterns elicited by a variety of linguistic\nmanipulations in previously-reported experimental data from Ryskin et al.\n(2021). Our theory is in principle compatible with traditional cognitive\ntheories assuming a `good-enough' heuristic interpretation stage, but with\nprecise information-theoretic formulation.",
    "descriptor": "\nComments: 4 pages, 3 figures, accepted InfoCog workshop at NeurIPS 2022\n",
    "authors": [
      "Jiaxuan Li",
      "Richard Futrell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08205"
  },
  {
    "id": "arXiv:2212.08206",
    "title": "Meeting Summarization: A Survey of the State of the Art",
    "abstract": "Information overloading requires the need for summarizers to extract salient\ninformation from the text. Currently, there is an overload of dialogue data due\nto the rise of virtual communication platforms. The rise of Covid-19 has led\npeople to rely on online communication platforms like Zoom, Slack, Microsoft\nTeams, Discord, etc. to conduct their company meetings. Instead of going\nthrough the entire meeting transcripts, people can use meeting summarizers to\nselect useful data. Nevertheless, there is a lack of comprehensive surveys in\nthe field of meeting summarizers. In this survey, we aim to cover recent\nmeeting summarization techniques. Our survey offers a general overview of text\nsummarization along with datasets and evaluation metrics for meeting\nsummarization. We also provide the performance of each summarizer on a\nleaderboard. We conclude our survey with different challenges in this domain\nand potential research opportunities for future researchers.",
    "descriptor": "",
    "authors": [
      "Lakshmi Prasanna Kumar",
      "Arman Kabiri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08206"
  },
  {
    "id": "arXiv:2212.08208",
    "title": "Location-aware Adaptive Denormalization: A Deep Learning Approach For  Wildfire Danger Forecasting",
    "abstract": "Climate change is expected to intensify and increase extreme events in the\nweather cycle. Since this has a significant impact on various sectors of our\nlife, recent works are concerned with identifying and predicting such extreme\nevents from Earth observations. This paper proposes a 2D/3D two-branch\nconvolutional neural network (CNN) for wildfire danger forecasting. To use a\nunified framework, previous approaches duplicate static variables along the\ntime dimension and neglect the intrinsic differences between static and dynamic\nvariables. Furthermore, most existing multi-branch architectures lose the\ninterconnections between the branches during the feature learning stage. To\naddress these issues, we propose a two-branch architecture with a\nLocation-aware Adaptive Denormalization layer (LOADE). Using LOADE as a\nbuilding block, we can modulate the dynamic features conditional on their\ngeographical location. Thus, our approach considers feature properties as a\nunified yet compound 2D/3D model. Besides, we propose using an absolute\ntemporal encoding for time-related forecasting problems. Our experimental\nresults show a better performance of our approach than other baselines on the\nchallenging FireCube dataset.",
    "descriptor": "",
    "authors": [
      "Mohamad Hakam Shams Eddin",
      "Ribana Roscher",
      "Juergen Gall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08208"
  },
  {
    "id": "arXiv:2212.08212",
    "title": "The $\\mathbb{DL}(P)$ vector space of pencils for singular matrix  polynomials",
    "abstract": "Given a possibly singular matrix polynomial $P(z)$, we study how the\neigenvalues, eigenvectors, root polynomials, minimal indices, and minimal bases\nof the pencils in the vector space $\\mathbb{DL}(P)$ introduced in Mackey,\nMackey, Mehl, and Mehrmann [SIAM J. Matrix Anal. Appl. 28(4), 971-1004, 2006]\nare related to those of $P(z)$. If $P(z)$ is regular, it is known that those\npencils in $\\mathbb{DL}(P)$ satisfying the generic assumptions in the so-called\neigenvalue exclusion theorem are strong linearizations for $P(z)$. This\nproperty and the block-symmetric structure of the pencils in $\\mathbb{DL}(P)$\nhave made these linearizations among the most influential for the theoretical\nand numerical treatment of structured regular matrix polynomials. However, it\nis also known that, if $P(z)$ is singular, then none of the pencils in\n$\\mathbb{DL}(P)$ is a linearization for $P(z)$. In this paper, we prove that\ndespite this fact a generalization of the eigenvalue exclusion theorem holds\nfor any singular matrix polynomial $P(z)$ and that such a generalization allows\nus to recover all the relevant quantities of $P(z)$ from any pencil in\n$\\mathbb{DL}(P)$ satisfying the eigenvalue exclusion hypothesis. Our proof of\nthis general theorem relies heavily in the representation of the pencils in\n$\\mathbb{DL} (P)$ via B\\'{e}zoutians by Nakatsukasa, Noferini and Townsend\n[SIAM J. Matrix Anal. Appl. 38(1), 181-209, 2015].",
    "descriptor": "",
    "authors": [
      "Froil\u00e1n Dopico",
      "Vanni Noferini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.08212"
  },
  {
    "id": "arXiv:2212.08214",
    "title": "Reinforcement Learning for Agile Active Target Sensing with a UAV",
    "abstract": "Active target sensing is the task of discovering and classifying an unknown\nnumber of targets in an environment and is critical in search-and-rescue\nmissions. This paper develops a deep reinforcement learning approach to plan\ninformative trajectories that increase the likelihood for an uncrewed aerial\nvehicle (UAV) to discover missing targets. Our approach efficiently (1)\nexplores the environment to discover new targets, (2) exploits its current\nbelief of the target states and incorporates inaccurate sensor models for\nhigh-fidelity classification, and (3) generates dynamically feasible\ntrajectories for an agile UAV by employing a motion primitive library.\nExtensive simulations on randomly generated environments show that our approach\nis more efficient in discovering and classifying targets than several other\nbaselines. A unique characteristic of our approach, in contrast to heuristic\ninformative path planning approaches, is that it is robust to varying amounts\nof deviations of the prior belief from the true target distribution, thereby\nalleviating the challenge of designing heuristics specific to the application\nconditions.",
    "descriptor": "\nComments: 5 pages, 2nd Workshop on Trends and Advances in Machine Learning and Automated Reasoning for Intelligent Robots and Systems Reasoning with IEEE/RSJ International Conference on Intelligent Robots and System (IROS 2022)\n",
    "authors": [
      "Harsh Goel",
      "Laura Jarin Lipschitz",
      "Saurav Agarwal",
      "Sandeep Manjanna",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08214"
  },
  {
    "id": "arXiv:2212.08216",
    "title": "Azimuth: Systematic Error Analysis for Text Classification",
    "abstract": "We present Azimuth, an open-source and easy-to-use tool to perform error\nanalysis for text classification. Compared to other stages of the ML\ndevelopment cycle, such as model training and hyper-parameter tuning, the\nprocess and tooling for the error analysis stage are less mature. However, this\nstage is critical for the development of reliable and trustworthy AI systems.\nTo make error analysis more systematic, we propose an approach comprising\ndataset analysis and model quality assessment, which Azimuth facilitates. We\naim to help AI practitioners discover and address areas where the model does\nnot generalize by leveraging and integrating a range of ML techniques, such as\nsaliency maps, similarity, uncertainty, and behavioral analyses, all in one\ntool. Our code and documentation are available at\ngithub.com/servicenow/azimuth.",
    "descriptor": "\nComments: To be published in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. 13 pages and 14 figures\n",
    "authors": [
      "Gabrielle Gauthier-Melan\u00e7on",
      "Orlando Marquez Ayala",
      "Lindsay Brin",
      "Chris Tyler",
      "Fr\u00e9d\u00e9ric Branchaud-Charron",
      "Joseph Marinier",
      "Karine Grande",
      "Di Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.08216"
  },
  {
    "id": "arXiv:2212.08217",
    "title": "Toward Improved Generalization: Meta Transfer of Self-supervised  Knowledge on Graphs",
    "abstract": "Despite the remarkable success achieved by graph convolutional networks for\nfunctional brain activity analysis, the heterogeneity of functional patterns\nand the scarcity of imaging data still pose challenges in many tasks.\nTransferring knowledge from a source domain with abundant training data to a\ntarget domain is effective for improving representation learning on scarce\ntraining data. However, traditional transfer learning methods often fail to\ngeneralize the pre-trained knowledge to the target task due to domain\ndiscrepancy. Self-supervised learning on graphs can increase the\ngeneralizability of graph features since self-supervision concentrates on\ninherent graph properties that are not limited to a particular supervised task.\nWe propose a novel knowledge transfer strategy by integrating meta-learning\nwith self-supervised learning to deal with the heterogeneity and scarcity of\nfMRI data. Specifically, we perform a self-supervised task on the source domain\nand apply meta-learning, which strongly improves the generalizability of the\nmodel using the bi-level optimization, to transfer the self-supervised\nknowledge to the target domain. Through experiments on a neurological disorder\nclassification task, we demonstrate that the proposed strategy significantly\nimproves target task performance by increasing the generalizability and\ntransferability of graph-based knowledge.",
    "descriptor": "",
    "authors": [
      "Wenhui Cui",
      "Haleh Akrami",
      "Anand A. Joshi",
      "Richard M. Leahy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08217"
  },
  {
    "id": "arXiv:2212.08221",
    "title": "SE Factual Knowledge in Frozen Giant Code Model: A Study on FQN and its  Retrieval",
    "abstract": "Pre-trained giant code models (PCMs) start coming into the developers' daily\npractices. Understanding what types of and how much software knowledge is\npacked into PCMs is the foundation for incorporating PCMs into software\nengineering (SE) tasks and fully releasing their potential. In this work, we\nconduct the first systematic study on the SE factual knowledge in the\nstate-of-the-art PCM CoPilot, focusing on APIs' Fully Qualified Names (FQNs),\nthe fundamental knowledge for effective code analysis, search and reuse. Driven\nby FQNs' data distribution properties, we design a novel lightweight in-context\nlearning on Copilot for FQN inference, which does not require code compilation\nas traditional methods or gradient update by recent FQN prompt-tuning. We\nsystematically experiment with five in-context-learning design factors to\nidentify the best in-context learning configuration that developers can adopt\nin practice. With this best configuration, we investigate the effects of amount\nof example prompts and FQN data properties on Copilot's FQN inference\ncapability. Our results confirm that Copilot stores diverse FQN knowledge and\ncan be applied for the FQN inference due to its high inference accuracy and\nnon-reliance on code analysis. Based on our experience interacting with\nCopilot, we discuss various opportunities to improve human-CoPilot interaction\nin the FQN inference task.",
    "descriptor": "",
    "authors": [
      "Qing Huang",
      "Dianshu Liao",
      "Zhenchang Xing",
      "Zhiqiang Yuan",
      "Qinghua Lu",
      "Xiwei Xu",
      "Jiaxing Lu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.08221"
  },
  {
    "id": "arXiv:2212.08224",
    "title": "A Survey on Biometrics Authentication",
    "abstract": "Nowadays, traditional authentication methods are vulnerable to face attacks\nthat are often based on inherent security issues. Professional attackers\nleverage adversarial offenses on the security holes. Biometrics has intrinsic\nadvantages to overcome the traditional authentication methods on security,\nsuccess rates, efficiency, and accessibility. Biometrics has wide prospects to\nimplement various applications in fields. Whether in authentication security or\nclinical medicine, biometrics is one of the mainstream studies. In this paper,\nwe surveyed and reviewed some related studies of biometrics, which are\noutstanding and significant in driving the development and popularization of\nbiometrics. Although they still have some inherent disadvantages to restrict\npopularization, these obstacles could not conceal the promising future of\nbiometrics. Multi-factors continuous biometrics authentication has become the\nmainstream trend of development. We reflect the findings as well as the\nchallenges of the studies in the survey paper.",
    "descriptor": "\nComments: 6 pages, 9 figures, 9 references\n",
    "authors": [
      "Fangshi Zhou",
      "Tianming Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.08224"
  },
  {
    "id": "arXiv:2212.08226",
    "title": "Implementing Simulation of Simplicity for geometric degeneracies",
    "abstract": "We describe how to implement Simulation of Simplicity (SoS). SoS removes\ngeometric degeneracies in point-in-polygon queries, polyhedron intersection,\nmap overlay, and other 2D and 3D geometric and spatial algorithms by\ndetermining the effect of adding non-Archimedian infinitesimals of different\norders to the coordinates. Then it modifies the geometric predicates to emulate\nthat, and evaluates them in the usual arithmetic.\nA geometric degeneracy is a coincidence, such as a vertex of one polygon on\nan edge of another polygon, that would have probability approaching zero if the\nobjects were distributed i.i.d. uniformly. However, in real data, they can\noccur often. Especially in 3D, there are too many types of degeneracies to\nreliably enumerate. But, if they are not handled, then predicates evaluate\nwrong, and the output topology may be wrong.\nWe describe the theory of SoS, and how several algorithms and programs were\nsuccessfully modified, including volume of the union of many cubes, point\nlocation in a 3D mesh, and intersecting 3D meshes.",
    "descriptor": "\nComments: 7 pages, 8 figures, from Spatial Gems workshop at ACM SIGSPATIAL 2022 conference, Seattle\n",
    "authors": [
      "W. Randolph Franklin",
      "Salles Viana Gomes de Magalh\u00e3es"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2212.08226"
  },
  {
    "id": "arXiv:2212.08228",
    "title": "SADM: Sequence-Aware Diffusion Model for Longitudinal Medical Image  Generation",
    "abstract": "Human organs constantly undergo anatomical changes due to a complex mix of\nshort-term (e.g., heartbeat) and long-term (e.g., aging) factors. Evidently,\nprior knowledge of these factors will be beneficial when modeling their future\nstate, i.e., via image generation. However, most of the medical image\ngeneration tasks only rely on the input from a single image, thus ignoring the\nsequential dependency even when longitudinal data is available. Sequence-aware\ndeep generative models, where model input is a sequence of ordered and\ntimestamped images, are still underexplored in the medical imaging domain that\nis featured by several unique challenges: 1) Sequences with various lengths; 2)\nMissing data or frame, and 3) High dimensionality. To this end, we propose a\nsequence-aware diffusion model (SADM) for the generation of longitudinal\nmedical images. Recently, diffusion models have shown promising results on\nhigh-fidelity image generation. Our method extends this new technique by\nintroducing a sequence-aware transformer as the conditional module in a\ndiffusion model. The novel design enables learning longitudinal dependency even\nwith missing data during training and allows autoregressive generation of a\nsequence of images during inference. Our extensive experiments on 3D\nlongitudinal medical images demonstrate the effectiveness of SADM compared with\nbaselines and alternative methods.",
    "descriptor": "",
    "authors": [
      "Jee Seok Yoon",
      "Chenghao Zhang",
      "Heung-Il Suk",
      "Jia Guo",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08228"
  },
  {
    "id": "arXiv:2212.08230",
    "title": "Multi-Agent Patrolling with Battery Constraints through Deep  Reinforcement Learning",
    "abstract": "Autonomous vehicles are suited for continuous area patrolling problems.\nHowever, finding an optimal patrolling strategy can be challenging for many\nreasons. Firstly, patrolling environments are often complex and can include\nunknown and evolving environmental factors. Secondly, autonomous vehicles can\nhave failures or hardware constraints such as limited battery lives.\nImportantly, patrolling large areas often requires multiple agents that need to\ncollectively coordinate their actions. In this work, we consider these\nlimitations and propose an approach based on a distributed, model-free deep\nreinforcement learning based multi-agent patrolling strategy. In this approach,\nagents make decisions locally based on their own environmental observations and\non shared information. In addition, agents are trained to automatically\nrecharge themselves when required to support continuous collective patrolling.\nA homogeneous multi-agent architecture is proposed, where all patrolling agents\nhave an identical policy. This architecture provides a robust patrolling system\nthat can tolerate agent failures and allow supplementary agents to be added to\nreplace failed agents or to increase the overall patrol performance. This\nperformance is validated through experiments from multiple perspectives,\nincluding the overall patrol performance, the efficiency of the battery\nrecharging strategy, the overall robustness of the system, and the agents'\nability to adapt to environment dynamics.",
    "descriptor": "",
    "authors": [
      "Chenhao Tong",
      "Aaron Harwood",
      "Maria A. Rodriguez",
      "Richard O. Sinnott"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.08230"
  },
  {
    "id": "arXiv:2212.08231",
    "title": "Localization & Mapping Requirements for Level 2+ Autonomous Vehicles",
    "abstract": "Autonomous vehicles are being deployed with a spectrum of capability,\nextending from driver assistance features for the highway in personal vehicles\n(SAE Level 2+) to fully autonomous fleet ride sharing services operating in\ncomplex city environments (SAE Level 4+). This spectrum of autonomy often\noperates in different physical environments with different degrees of assumed\ndriver in-the-loop oversight and hence have very different system and subsystem\nrequirements. At the heart of SAE Level 2 to 5 systems is localization and\nmapping, which ranges from road determination for feature geofencing or\nhigh-level routing, through lane determination for advanced driver assistance,\nto where-in-lane positioning for full vehicle control. We assess localization\nand mapping requirements for different levels of autonomy and supported\nfeatures. This work provides a framework for system decomposition, including\nthe level of redundancy needed to achieve the target level of safety. We\nexamine several representative autonomous and assistance features and make\nrecommendations on positioning requirements as well map georeferencing and\ninformation integrity.",
    "descriptor": "\nComments: ION ITM 2023\n",
    "authors": [
      "Tyler G.R. Reid",
      "Andrew Neish",
      "Brian Manning"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08231"
  },
  {
    "id": "arXiv:2212.08232",
    "title": "Offline Robot Reinforcement Learning with Uncertainty-Guided Human  Expert Sampling",
    "abstract": "Recent advances in batch (offline) reinforcement learning have shown\npromising results in learning from available offline data and proved offline\nreinforcement learning to be an essential toolkit in learning control policies\nin a model-free setting. An offline reinforcement learning algorithm applied to\na dataset collected by a suboptimal non-learning-based algorithm can result in\na policy that outperforms the behavior agent used to collect the data. Such a\nscenario is frequent in robotics, where existing automation is collecting\noperational data. Although offline learning techniques can learn from data\ngenerated by a sub-optimal behavior agent, there is still an opportunity to\nimprove the sample complexity of existing offline reinforcement learning\nalgorithms by strategically introducing human demonstration data into the\ntraining process. To this end, we propose a novel approach that uses\nuncertainty estimation to trigger the injection of human demonstration data and\nguide policy training towards optimal behavior while reducing overall sample\ncomplexity. Our experiments show that this approach is more sample efficient\nwhen compared to a naive way of combining expert data with data collected from\na sub-optimal agent. We augmented an existing offline reinforcement learning\nalgorithm Conservative Q-Learning with our approach and performed experiments\non data collected from MuJoCo and OffWorld Gym learning environments.",
    "descriptor": "",
    "authors": [
      "Ashish Kumar",
      "Ilya Kuzovkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.08232"
  },
  {
    "id": "arXiv:2212.08234",
    "title": "Innovation-Based Remote State Estimation Secrecy with no Acknowledgments",
    "abstract": "Secrecy encoding for remote state estimation in the presence of adversarial\neavesdroppers is a well studied problem. Typical existing secrecy encoding\nschemes rely on the transmitter's knowledge of the remote estimator's current\nperformance. This performance measure is often shared via packet receipt\nacknowledgments. However, in practical situations the acknowledgment channel\nmay be susceptible to interference from an active adversary, resulting in the\nsecrecy encoding scheme failing. Aiming to achieve a reliable state estimate\nfor a legitimate estimator while ensuring secrecy, we propose a secrecy\nencoding scheme without the need for packet receipt acknowledgments. Our\nencoding scheme uses a pre-arranged scheduling sequence established at the\ntransmitter and legitimate receiver. We transmit a packet containing either the\nstate measurement or encoded information for the legitimate user. The encoding\nmakes the packet appear to be the state but is designed to damage an\neavesdropper's estimate. The pre-arranged scheduling sequence and encoding is\nchosen psuedo-random. We analyze the performance of our encoding scheme against\na class of eavesdropper, and show conditions to force the eavesdropper to have\nan unbounded estimation performance. Further, we provide a numerical\nillustration and apply our encoding scheme to an application in power systems.",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Justin M. Kennedy",
      "Jason J. Ford",
      "Daniel E. Quevedo",
      "Falko Dressler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.08234"
  },
  {
    "id": "arXiv:2212.08235",
    "title": "A Simple Decentralized Cross-Entropy Method",
    "abstract": "Cross-Entropy Method (CEM) is commonly used for planning in model-based\nreinforcement learning (MBRL) where a centralized approach is typically\nutilized to update the sampling distribution based on only the top-$k$\noperation's results on samples. In this paper, we show that such a centralized\napproach makes CEM vulnerable to local optima, thus impairing its sample\nefficiency. To tackle this issue, we propose Decentralized CEM (DecentCEM), a\nsimple but effective improvement over classical CEM, by using an ensemble of\nCEM instances running independently from one another, and each performing a\nlocal improvement of its own sampling distribution. We provide both theoretical\nand empirical analysis to demonstrate the effectiveness of this simple\ndecentralized approach. We empirically show that, compared to the classical\ncentralized approach using either a single or even a mixture of Gaussian\ndistributions, our DecentCEM finds the global optimum much more consistently\nthus improves the sample efficiency. Furthermore, we plug in our DecentCEM in\nthe planning problem of MBRL, and evaluate our approach in several continuous\ncontrol environments, with comparison to the state-of-art CEM based MBRL\napproaches (PETS and POPLIN). Results show sample efficiency improvement by\nsimply replacing the classical CEM module with our DecentCEM module, while only\nsacrificing a reasonable amount of computational cost. Lastly, we conduct\nablation studies for more in-depth analysis. Code is available at\nhttps://github.com/vincentzhang/decentCEM",
    "descriptor": "\nComments: NeurIPS 2022. The last two authors advised equally\n",
    "authors": [
      "Zichen Zhang",
      "Jun Jin",
      "Martin Jagersand",
      "Jun Luo",
      "Dale Schuurmans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.08235"
  },
  {
    "id": "arXiv:2212.08236",
    "title": "Coded Distributed Computing for Hierarchical Multi-task Learning",
    "abstract": "In this paper, we consider a hierarchical distributed multi-task learning\n(MTL) system where distributed users wish to jointly learn different models\norchestrated by a central server with the help of a layer of multiple relays.\nSince the users need to download different learning models in the downlink\ntransmission, the distributed MTL suffers more severely from the communication\nbottleneck compared to the single-task learning system. To address this issue,\nwe propose a coded hierarchical MTL scheme that exploits the connection\ntopology and introduces coding techniques to reduce communication loads. It is\nshown that the proposed scheme can significantly reduce the communication loads\nboth in the uplink and downlink transmissions between relays and the server.\nMoreover, we provide information-theoretic lower bounds on the optimal uplink\nand downlink communication loads, and prove that the gaps between achievable\nupper bounds and lower bounds are within the minimum number of connected users\namong all relays. In particular, when the network connection topology can be\ndelicately designed, the proposed scheme can achieve the information-theoretic\noptimal communication loads. Experiments on real datasets show that our\nproposed scheme can reduce the overall training time by 17% $\\sim$ 26% compared\nto the conventional uncoded scheme.",
    "descriptor": "",
    "authors": [
      "Haoyang Hu",
      "Songze Li",
      "Minquan Cheng",
      "Youlong Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.08236"
  },
  {
    "id": "arXiv:2212.08239",
    "title": "Discovering Structural Hole Spanners in Dynamic Networks via Graph  Neural Networks",
    "abstract": "Structural Hole (SH) theory states that the node which acts as a connecting\nlink among otherwise disconnected communities gets positional advantages in the\nnetwork. These nodes are called Structural Hole Spanners (SHS). SHSs have many\napplications, including viral marketing, information dissemination, community\ndetection, etc. Numerous solutions are proposed to discover SHSs; however, most\nof the solutions are only applicable to static networks. Since real-world\nnetworks are dynamic networks; consequently, in this study, we aim to discover\nSHSs in dynamic networks. Discovering SHSs is an NP-hard problem, due to which,\ninstead of discovering exact k SHSs, we adopt a greedy approach to discover\ntop-k SHSs. Motivated from the success of Graph Neural Networks (GNNs) on\nvarious graph mining problems, we design a Graph Neural Network-based model,\nGNN-SHS, to discover SHSs in dynamic networks, aiming to reduce the\ncomputational cost while achieving high accuracy. We analyze the efficiency of\nthe proposed model through exhaustive experiments, and our results show that\nthe proposed GNN-SHS model is at least 31.8 times faster and, on an average\n671.6 times faster than the comparative method, providing a considerable\nefficiency advantage.",
    "descriptor": "",
    "authors": [
      "Diksha Goel",
      "Hong Shen",
      "Hui Tian",
      "Mingyu Guo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.08239"
  },
  {
    "id": "arXiv:2212.08241",
    "title": "H-LPS: a hybrid approach for user's location privacy in location-based  services",
    "abstract": "Applications providing location-based services (LBS) have gained much\nattention and importance with the notion of the internet of things (IoT). Users\nare utilizing LBS by providing their location information to third-party\nservice providers. However, location data is very sensitive that can reveal\nuser's private life to adversaries. The passive and pervasive data collection\nin IoT upsurges serious issues of location privacy. Privacy-preserving\nlocation-based services are a hot research topic. Many anonymization and\nobfuscation techniques have been proposed to overcome location privacy issues.\nIn this paper, we have proposed a hybrid location privacy scheme (H-LPS), a\nhybrid scheme mainly based on obfuscation and collaboration for protecting\nusers' location privacy while using location-based services. Obfuscation\nnaturally degrades the quality of service but provides more privacy as compared\nto anonymization. Our proposed scheme, H-LPS, provides a very high-level of\nprivacy yet provides good accuracy for most of the users. The privacy level and\nservice accuracy of H-LPS are compared with state-of-the-art location privacy\nschemes and it is shown that H-LPS could be a candidate solution for preserving\nuser location privacy in location-based services.",
    "descriptor": "",
    "authors": [
      "Sonia Sabir",
      "Inayat Ali",
      "Eraj Khan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.08241"
  },
  {
    "id": "arXiv:2212.08244",
    "title": "Offline Reinforcement Learning for Visual Navigation",
    "abstract": "Reinforcement learning can enable robots to navigate to distant goals while\noptimizing user-specified reward functions, including preferences for following\nlanes, staying on paved paths, or avoiding freshly mowed grass. However, online\nlearning from trial-and-error for real-world robots is logistically\nchallenging, and methods that instead can utilize existing datasets of robotic\nnavigation data could be significantly more scalable and enable broader\ngeneralization. In this paper, we present ReViND, the first offline RL system\nfor robotic navigation that can leverage previously collected data to optimize\nuser-specified reward functions in the real-world. We evaluate our system for\noff-road navigation without any additional data collection or fine-tuning, and\nshow that it can navigate to distant goals using only offline training from\nthis dataset, and exhibit behaviors that qualitatively differ based on the\nuser-specified reward function.",
    "descriptor": "\nComments: Project page this https URL\n",
    "authors": [
      "Dhruv Shah",
      "Arjun Bhorkar",
      "Hrish Leen",
      "Ilya Kostrikov",
      "Nick Rhinehart",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08244"
  },
  {
    "id": "arXiv:2212.08247",
    "title": "Relative Error-based Time-limited H2 Model Order Reduction via Oblique  Projection",
    "abstract": "In time-limited model order reduction, a reduced-order approximation of the\noriginal high-order model is obtained that accurately approximates the original\nmodel within the desired limited time interval. Accuracy outside that time\ninterval is not that important. The error incurred when a reduced-order model\nis used as a surrogate for the original model can be quantified in absolute or\nrelative terms to access the performance of the model reduction algorithm. The\nrelative error is generally more meaningful than an absolute error because if\nthe original and reduced systems' responses are of small magnitude, the\nabsolute error is small in magnitude as well. However, this does not\nnecessarily mean that the reduced model is accurate. The relative error in such\nscenarios is useful and meaningful as it quantifies percentage error\nirrespective of the magnitude of the system's response. In this paper, the\nnecessary conditions for a local optimum of the time-limited H2 norm of the\nrelative error system are derived. Inspired by these conditions, an oblique\nprojection algorithm is proposed that ensures small H2-norm relative error\nwithin the desired time interval. Unlike the existing relative error-based\nmodel reduction algorithms, the proposed algorithm does not require solutions\nof large-scale Lyapunov and Riccati equations. The proposed algorithm is\ncompared with time-limited balanced truncation, time-limited balanced\nstochastic truncation, and time-limited iterative Rational Krylov algorithm.\nNumerical results confirm the superiority of the proposed algorithm over these\nexisting algorithms.",
    "descriptor": "",
    "authors": [
      "Umair Zulfiqar",
      "Xin Du",
      "Qiuyan Song",
      "Zhi-Hua Xiao",
      "Victor Sreeram"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08247"
  },
  {
    "id": "arXiv:2212.08251",
    "title": "Robust Saliency Guidance for Data-free Class Incremental Learning",
    "abstract": "Data-Free Class Incremental Learning (DFCIL) aims to sequentially learn tasks\nwith access only to data from the current one. DFCIL is of interest because it\nmitigates concerns about privacy and long-term storage of data, while at the\nsame time alleviating the problem of catastrophic forgetting in incremental\nlearning. In this work, we introduce robust saliency guidance for DFCIL and\npropose a new framework, which we call RObust Saliency Supervision (ROSS), for\nmitigating the negative effect of saliency drift. Firstly, we use a\nteacher-student architecture leveraging low-level tasks to supervise the model\nwith global saliency. We also apply boundary-guided saliency to protect it from\ndrifting across object boundaries at intermediate layers. Finally, we introduce\na module for injecting and recovering saliency noise to increase robustness of\nsaliency preservation. Our experiments demonstrate that our method can retain\nbetter saliency maps across tasks and achieve state-of-the-art results on the\nCIFAR-100, Tiny-ImageNet and ImageNet-Subset DFCIL benchmarks. Code will be\nmade publicly available.",
    "descriptor": "",
    "authors": [
      "Xialei Liu",
      "Jiang-Tian Zhai",
      "Andrew D. Bagdanov",
      "Ke Li",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08251"
  },
  {
    "id": "arXiv:2212.08254",
    "title": "RepQ-ViT: Scale Reparameterization for Post-Training Quantization of  Vision Transformers",
    "abstract": "Post-training quantization (PTQ), which only requires a tiny dataset for\ncalibration without end-to-end retraining, is a light and practical model\ncompression technique. Recently, several PTQ schemes for vision transformers\n(ViTs) have been presented; unfortunately, they typically suffer from\nnon-trivial accuracy degradation, especially in low-bit cases. In this paper,\nwe propose RepQ-ViT, a novel PTQ framework for ViTs based on quantization scale\nreparameterization, to address the above issues. RepQ-ViT decouples the\nquantization and inference processes, where the former employs complex\nquantizers and the latter employs scale-reparameterized simplified quantizers.\nThis ensures both accurate quantization and efficient inference, which\ndistinguishes it from existing approaches that sacrifice quantization\nperformance to meet the target hardware. More specifically, we focus on two\ncomponents with extreme distributions: post-LayerNorm activations with severe\ninter-channel variation and post-Softmax activations with power-law features,\nand initially apply channel-wise quantization and log$\\sqrt{2}$ quantization,\nrespectively. Then, we reparameterize the scales to hardware-friendly\nlayer-wise quantization and log2 quantization for inference, with only slight\naccuracy or computational costs. Extensive experiments are conducted on\nmultiple vision tasks with different model variants, proving that RepQ-ViT,\nwithout hyperparameters and expensive reconstruction procedures, can outperform\nexisting strong baselines and encouragingly improve the accuracy of 4-bit PTQ\nof ViTs to a usable level.",
    "descriptor": "",
    "authors": [
      "Zhikai Li",
      "Junrui Xiao",
      "Lianwei Yang",
      "Qingyi Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08254"
  },
  {
    "id": "arXiv:2212.08262",
    "title": "Uniform Sequence Better: Time Interval Aware Data Augmentation for  Sequential Recommendation",
    "abstract": "Sequential recommendation is an important task to predict the next-item to\naccess based on a sequence of interacted items. Most existing works learn user\npreference as the transition pattern from the previous item to the next one,\nignoring the time interval between these two items. However, we observe that\nthe time interval in a sequence may vary significantly different, and thus\nresult in the ineffectiveness of user modeling due to the issue of\n\\emph{preference drift}. In fact, we conducted an empirical study to validate\nthis observation, and found that a sequence with uniformly distributed time\ninterval (denoted as uniform sequence) is more beneficial for performance\nimprovement than that with greatly varying time interval. Therefore, we propose\nto augment sequence data from the perspective of time interval, which is not\nstudied in the literature. Specifically, we design five operators (Ti-Crop,\nTi-Reorder, Ti-Mask, Ti-Substitute, Ti-Insert) to transform the original\nnon-uniform sequence to uniform sequence with the consideration of variance of\ntime intervals. Then, we devise a control strategy to execute data augmentation\non item sequences in different lengths. Finally, we implement these\nimprovements on a state-of-the-art model CoSeRec and validate our approach on\nfour real datasets. The experimental results show that our approach reaches\nsignificantly better performance than the other 11 competing methods. Our\nimplementation is available: https://github.com/KingGugu/TiCoSeRec.",
    "descriptor": "\nComments: 9 pages, 4 figures, AAAI-2023\n",
    "authors": [
      "Yizhou Dang",
      "Enneng Yang",
      "Guibing Guo",
      "Linying Jiang",
      "Xingwei Wang",
      "Xiaoxiao Xu",
      "Qinghui Sun",
      "Hong Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08262"
  },
  {
    "id": "arXiv:2212.08272",
    "title": "Communication-Efficient Federated Learning for Heterogeneous Edge  Devices Based on Adaptive Gradient Quantization",
    "abstract": "Federated learning (FL) enables geographically dispersed edge devices (i.e.,\nclients) to learn a global model without sharing the local datasets, where each\nclient performs gradient descent with its local data and uploads the gradients\nto a central server to update the global model. However, FL faces massive\ncommunication overhead resulted from uploading the gradients in each training\nround. To address this problem, most existing research compresses the gradients\nwith fixed and unified quantization for all the clients, which neither seeks\nadaptive quantization due to the varying gradient norms at different rounds,\nnor exploits the heterogeneity of the clients to accelerate FL. In this paper,\nwe propose a novel adaptive and heterogeneous gradient quantization algorithm\n(AdaGQ) for FL to minimize the wall-clock training time from two aspects: i)\nadaptive quantization which exploits the change of gradient norm to adjust the\nquantization resolution in each training round; and ii) heterogeneous\nquantization which assigns lower quantization resolution to slow clients to\nalign their training time with other clients to mitigate the communication\nbottleneck, and higher quantization resolution to fast clients to achieve a\nbetter communication efficiency and accuracy tradeoff. Evaluations based on\nvarious models and datasets validate the benefits of AdaGQ, reducing the total\ntraining time by up to 52.1% compared to baseline algorithms (e.g., FedAvg,\nQSGD).",
    "descriptor": "",
    "authors": [
      "Heting Liu",
      "Fang He",
      "Guohong Cao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.08272"
  },
  {
    "id": "arXiv:2212.08273",
    "title": "Learning for Vehicle-to-Vehicle Cooperative Perception under Lossy  Communication",
    "abstract": "Deep learning has been widely used in the perception (e.g., 3D object\ndetection) of intelligent vehicle driving. Due to the beneficial\nVehicle-to-Vehicle (V2V) communication, the deep learning based features from\nother agents can be shared to the ego vehicle so as to improve the perception\nof the ego vehicle. It is named as Cooperative Perception in the V2V research,\nwhose algorithms have been dramatically advanced recently. However, all the\nexisting cooperative perception algorithms assume the ideal V2V communication\nwithout considering the possible lossy shared features because of the Lossy\nCommunication (LC) which is common in the complex real-world driving scenarios.\nIn this paper, we first study the side effect (e.g., detection performance\ndrop) by the lossy communication in the V2V Cooperative Perception, and then we\npropose a novel intermediate LC-aware feature fusion method to relieve the side\neffect of lossy communication by a LC-aware Repair Network (LCRN) and enhance\nthe interaction between the ego vehicle and other vehicles by a specially\ndesigned V2V Attention Module (V2VAM) including intra-vehicle attention of ego\nvehicle and uncertainty-aware inter-vehicle attention. The extensive experiment\non the public cooperative perception dataset OPV2V (based on digital-twin CARLA\nsimulator) demonstrates that the proposed method is quite effective for the\ncooperative point cloud based 3D object detection under lossy V2V\ncommunication.",
    "descriptor": "",
    "authors": [
      "Jinlong Li",
      "Runsheng Xu",
      "Xinyu Liu",
      "Jin Ma",
      "Zicheng Chi",
      "Jiaqi Ma",
      "Hongkai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08273"
  },
  {
    "id": "arXiv:2212.08275",
    "title": "A Survey on Anonymous Communication Systems with a Focus on Dining  Cryptographers Networks",
    "abstract": "Traffic analysis attacks can counteract end-to-end encryption and use the\nleaked communication metadata to reveal information about the communicating\nparties. With an ever-increasing amount of traffic by an ever-increasing amount\nof networked devices, this undermines communication privacy and goes against\nthe uptrend of limiting personal data collection. Therefore, Anonymous\nCommunication Systems (ACSs) are proposed to protect the users' privacy by\nhiding the relationship between transmitted messages and their senders and\nreceivers, providing privacy properties known as anonymity, unlinkability and\nunobservability. This article aims to review the research in the ACSs field\nbased on its applicability in real-world scenarios. First, we present an\noverview of the underlying principles of ACSs and different methods. Then, we\nfocus on Dining Cryptographers Networks (DCNs) and the methods for anonymous\ncommunication that are based on them. We investigate the alignment of ACSs with\nthe privacy terminologies. Most notably, the DCN-based methods are\ninformation-theoretically secure and thus provide unconditional unobservability\nguarantees. Their initial adoption for anonymous communications was hindered\ninitially as their computational and communication overhead was deemed too\nsignificant at that time and scalability problems occurred. However, several\nmore recent contributions such as the possibility to transmit arbitrary length\nmessages, efficient handling of disruptors and improvements in overhead made\nthe integration of modern DCN-based methods more realistic. Previous surveys on\nACSs did not cover the most recent research advances in this area or did not\nfocus on DCN-based methods. This comprehensive investigation of modern ACSs and\nDCN-based systems closes this gap.",
    "descriptor": "",
    "authors": [
      "Mohsen Shirali",
      "Tobias Tefke",
      "Ralf C. Staudemeyer",
      "Henrich C. Poehls"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.08275"
  },
  {
    "id": "arXiv:2212.08276",
    "title": "Preventing RNN from Using Sequence Length as a Feature",
    "abstract": "Recurrent neural networks are deep learning topologies that can be trained to\nclassify long documents. However, in our recent work, we found a critical\nproblem with these cells: they can use the length differences between texts of\ndifferent classes as a prominent classification feature. This has the effect of\nproducing models that are brittle and fragile to concept drift, can provide\nmisleading performances and are trivially explainable regardless of text\ncontent. This paper illustrates the problem using synthetic and real-world data\nand provides a simple solution using weight decay regularization.",
    "descriptor": "\nComments: 6 pages, but my overleaf generrates 5 pages. I have no error, the font size seems different\n",
    "authors": [
      "Jean-Thomas Baillargeon",
      "H\u00e9l\u00e8ne Cossette",
      "Luc Lamontagne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08276"
  },
  {
    "id": "arXiv:2212.08277",
    "title": "Improving self-supervised representation learning via sequential  adversarial masking",
    "abstract": "Recent methods in self-supervised learning have demonstrated that\nmasking-based pretext tasks extend beyond NLP, serving as useful pretraining\nobjectives in computer vision. However, existing approaches apply random or ad\nhoc masking strategies that limit the difficulty of the reconstruction task\nand, consequently, the strength of the learnt representations. We improve upon\ncurrent state-of-the-art work in learning adversarial masks by proposing a new\nframework that generates masks in a sequential fashion with different\nconstraints on the adversary. This leads to improvements in performance on\nvarious downstream tasks, such as classification on ImageNet100, STL10, and\nCIFAR10/100 and segmentation on Pascal VOC. Our results further demonstrate the\npromising capabilities of masking-based approaches for SSL in computer vision.",
    "descriptor": "\nComments: 9 pages, 2 figures, Presented at NeurIPS 2022 SSL: Theory and Practice Workshop\n",
    "authors": [
      "Dylan Sam",
      "Min Bai",
      "Tristan McKinney",
      "Li Erran Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08277"
  },
  {
    "id": "arXiv:2212.08278",
    "title": "Seeing through Things: Exploring the Design Space of Privacy-Aware  Data-Enabled Objects",
    "abstract": "Increasing amounts of sensor-augmented research objects have been used in\ndesign research. We call these objects Data-Enabled Objects, which can be\nintegrated into daily activities capturing data about people's detailed\nwhereabouts, behaviours and routines. These objects provide data perspectives\non everyday life for contextual design research. However, data-enabled objects\nare still computational devices with limited privacy awareness and nuanced data\nsharing. To better design data-enabled objects, we explore privacy design\nspaces by inviting 18 teams of undergraduate design students to re-design the\nsame type of sensor-enabled home research camera. We developed the Connected\nPeekaboo Toolkit (CPT) to support the design teams in designing, building, and\ndirectly deploying their prototypes in real home studies. We conducted Thematic\nAnalysis to analyse their outcomes which led us to interpret that privacy is\nnot just an obstacle but can be a driver by unfolding an exploration of\npossible design spaces for data-enabled objects.",
    "descriptor": "\nComments: Data space exploration, privacy design, data-enabled objects, design ethnography, research projects, field study, 44 pages\n",
    "authors": [
      "Yu-Ting Cheng",
      "Mathias Funk",
      "Rung-Huei Liang",
      "Lin-Lin Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.08278"
  },
  {
    "id": "arXiv:2212.08279",
    "title": "Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion  Behaviors in Social Deduction Games",
    "abstract": "Persuasion modeling is a key building block for conversational agents.\nExisting works in this direction are limited to analyzing textual dialogue\ncorpus. We argue that visual signals also play an important role in\nunderstanding human persuasive behaviors. In this paper, we introduce the first\nmultimodal dataset for modeling persuasion behaviors. Our dataset includes 199\ndialogue transcriptions and videos captured in a multi-player social deduction\ngame setting, 26,647 utterance level annotations of persuasion strategy, and\ngame level annotations of deduction game outcomes. We provide extensive\nexperiments to show how dialogue context and visual signals benefit persuasion\nstrategy prediction. We also explore the generalization ability of language\nmodels for persuasion modeling and the role of persuasion strategies in\npredicting social deduction game outcomes. Our dataset, code, and models can be\nfound at https://persuasion-deductiongame.socialai-data.org.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Bolin Lai",
      "Hongxin Zhang",
      "Miao Liu",
      "Aryan Pariani",
      "Fiona Ryan",
      "Wenqi Jia",
      "Shirley Anugrah Hayati",
      "James M. Rehg",
      "Diyi Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08279"
  },
  {
    "id": "arXiv:2212.08281",
    "title": "HGAN: Hierarchical Graph Alignment Network for Image-Text Retrieval",
    "abstract": "Image-text retrieval (ITR) is a challenging task in the field of multimodal\ninformation processing due to the semantic gap between different modalities. In\nrecent years, researchers have made great progress in exploring the accurate\nalignment between image and text. However, existing works mainly focus on the\nfine-grained alignment between image regions and sentence fragments, which\nignores the guiding significance of context background information. Actually,\nintegrating the local fine-grained information and global context background\ninformation can provide more semantic clues for retrieval. In this paper, we\npropose a novel Hierarchical Graph Alignment Network (HGAN) for image-text\nretrieval. First, to capture the comprehensive multimodal features, we\nconstruct the feature graphs for the image and text modality respectively.\nThen, a multi-granularity shared space is established with a designed\nMulti-granularity Feature Aggregation and Rearrangement (MFAR) module, which\nenhances the semantic corresponding relations between the local and global\ninformation, and obtains more accurate feature representations for the image\nand text modalities. Finally, the ultimate image and text features are further\nrefined through three-level similarity functions to achieve the hierarchical\nalignment. To justify the proposed model, we perform extensive experiments on\nMS-COCO and Flickr30K datasets. Experimental results show that the proposed\nHGAN outperforms the state-of-the-art methods on both datasets, which\ndemonstrates the effectiveness and superiority of our model.",
    "descriptor": "",
    "authors": [
      "Jie Guo",
      "Meiting Wang",
      "Yan Zhou",
      "Bin Song",
      "Yuhao Chi",
      "Wei Fan",
      "Jianglong Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2212.08281"
  },
  {
    "id": "arXiv:2212.08283",
    "title": "SceneGATE: Scene-Graph based co-Attention networks for TExt visual  question answering",
    "abstract": "Most TextVQA approaches focus on the integration of objects, scene texts and\nquestion words by a simple transformer encoder. But this fails to capture the\nsemantic relations between different modalities. The paper proposes a Scene\nGraph based co-Attention Network (SceneGATE) for TextVQA, which reveals the\nsemantic relations among the objects, Optical Character Recognition (OCR)\ntokens and the question words. It is achieved by a TextVQA-based scene graph\nthat discovers the underlying semantics of an image. We created a\nguided-attention module to capture the intra-modal interplay between the\nlanguage and the vision as a guidance for inter-modal interactions. To make\nexplicit teaching of the relations between the two modalities, we proposed and\nintegrated two attention modules, namely a scene graph-based semantic\nrelation-aware attention and a positional relation-aware attention. We\nconducted extensive experiments on two benchmark datasets, Text-VQA and ST-VQA.\nIt is shown that our SceneGATE method outperformed existing ones because of the\nscene graph and its attention modules.",
    "descriptor": "",
    "authors": [
      "Siwen Luo",
      "Feiqi Cao",
      "Felipe Nunez",
      "Zean Wen",
      "Josiah Poon",
      "Caren Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08283"
  },
  {
    "id": "arXiv:2212.08284",
    "title": "ANKH: A Generalized O(N) Interpolated Ewald Strategy for Molecular  Dynamics Simulations",
    "abstract": "To evaluate electrostatics interactions, Molecular dynamics (MD) simulations\nrely on Particle Mesh Ewald (PME), an O(Nlog(N)) algorithm that uses Fast\nFourier Transforms (FFTs) or, alternatively, on O(N) Fast Multipole Methods\n(FMM) approaches. However, the FFTs low scalability remains a strong bottleneck\nfor large-scale PME simulations on supercomputers. On the opposite, - FFT-free\n- FMM techniques are able to deal efficiently with such systems but they fail\nto reach PME performances for small- to medium-size systems, limiting their\nreal-life applicability. We propose ANKH, a strategy grounded on interpolated\nEwald summations and designed to remain efficient/scalable for any size of\nsystems. The method is generalized for distributed point multipoles and so for\ninduced dipoles which makes it suitable for high performance simulations using\nnew generation polarizable force fields towards exascale computing.",
    "descriptor": "",
    "authors": [
      "Igor Chollet",
      "Louis Lagard\u00e8re",
      "Jean-Philip Piquemal"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.08284"
  },
  {
    "id": "arXiv:2212.08286",
    "title": "ALERT: Adapting Language Models to Reasoning Tasks",
    "abstract": "Current large language models can perform reasonably well on complex tasks\nthat require step-by-step reasoning with few-shot learning. Are these models\napplying reasoning skills they have learnt during pre-training and reason\noutside of their training context, or are they simply memorizing their training\ncorpus at finer granularity and have learnt to better understand their context?\nTo tease apart these possibilities, we introduce ALERT, a benchmark and suite\nof analyses for assessing language models' reasoning ability comparing\npre-trained and finetuned models on complex tasks that require reasoning skills\nto solve. ALERT provides a test bed to asses any language model on fine-grained\nreasoning skills, which spans over 20 datasets and covers 10 different\nreasoning skills. We leverage ALERT to further investigate the role of\nfinetuning. With extensive empirical analysis we find that language models\nlearn more reasoning skills such as textual entailment, abductive reasoning,\nand analogical reasoning during finetuning stage compared to pretraining state.\nWe also find that when language models are finetuned they tend to overfit to\nthe prompt template, which hurts the robustness of models causing\ngeneralization problems.",
    "descriptor": "",
    "authors": [
      "Ping Yu",
      "Tianlu Wang",
      "Olga Golovneva",
      "Badr Alkhamissy",
      "Gargi Ghosh",
      "Mona Diab",
      "Asli Celikyilmaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08286"
  },
  {
    "id": "arXiv:2212.08287",
    "title": "Rich Event Modeling for Script Event Prediction",
    "abstract": "Script is a kind of structured knowledge extracted from texts, which contains\na sequence of events. Based on such knowledge, script event prediction aims to\npredict the subsequent event. To do so, two aspects should be considered for\nevents, namely, event description (i.e., what the events should contain) and\nevent encoding (i.e., how they should be encoded). Most existing methods\ndescribe an event by a verb together with only a few core arguments (i.e.,\nsubject, object, and indirect object), which are not precise. In addition,\nexisting event encoders are limited to a fixed number of arguments, which are\nnot flexible to deal with extra information. Thus, in this paper, we propose\nthe Rich Event Prediction (REP) framework for script event prediction.\nFundamentally, it is based on the proposed rich event description, which\nenriches the existing ones with three kinds of important information, namely,\nthe senses of verbs, extra semantic roles, and types of participants. REP\ncontains an event extractor to extract such information from texts. Based on\nthe extracted rich information, a predictor then selects the most probable\nsubsequent event. The core component of the predictor is a transformer-based\nevent encoder to flexibly deal with an arbitrary number of arguments.\nExperimental results on the widely used Gigaword Corpus show the effectiveness\nof the proposed framework.",
    "descriptor": "\nComments: AAAI 2023 (main conference)\n",
    "authors": [
      "Long Bai",
      "Saiping Guan",
      "Zixuan Li",
      "Jiafeng Guo",
      "Xiaolong Jin",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08287"
  },
  {
    "id": "arXiv:2212.08290",
    "title": "Robust Learning Protocol for Federated Tumor Segmentation Challenge",
    "abstract": "In this work, we devise robust and efficient learning protocols for\norchestrating a Federated Learning (FL) process for the Federated Tumor\nSegmentation Challenge (FeTS 2022). Enabling FL for FeTS setup is challenging\nmainly due to data heterogeneity among collaborators and communication cost of\ntraining. To tackle these challenges, we propose Robust Learning Protocol\n(RoLePRO) which is a combination of server-side adaptive optimisation (e.g.,\nserver-side Adam) and judicious parameter (weights) aggregation schemes (e.g.,\nadaptive weighted aggregation). RoLePRO takes a two-phase approach, where the\nfirst phase consists of vanilla Federated Averaging, while the second phase\nconsists of a judicious aggregation scheme that uses a sophisticated\nreweighting, all in the presence of an adaptive optimisation algorithm at the\nserver. We draw insights from extensive experimentation to tune learning rates\nfor the two phases.",
    "descriptor": "\nComments: 14 pages, 2 figures, 3 tables\n",
    "authors": [
      "Ambrish Rawat",
      "Giulio Zizzo",
      "Swanand Kadhe",
      "Jonathan P. Epperlein",
      "Stefano Braghin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08290"
  },
  {
    "id": "arXiv:2212.08295",
    "title": "Learning on Persistence Diagrams as Radon Measures",
    "abstract": "Persistence diagrams are common descriptors of the topological structure of\ndata appearing in various classification and regression tasks. They can be\ngeneralized to Radon measures supported on the birth-death plane and endowed\nwith an optimal transport distance. Examples of such measures are expectations\nof probability distributions on the space of persistence diagrams. In this\npaper, we develop methods for approximating continuous functions on the space\nof Radon measures supported on the birth-death plane, as well as their\nutilization in supervised learning tasks. Indeed, we show that any continuous\nfunction defined on a compact subset of the space of such measures (e.g., a\nclassifier or regressor) can be approximated arbitrarily well by polynomial\ncombinations of features computed using a continuous compactly supported\nfunction on the birth-death plane (a template). We provide insights into the\nstructure of relatively compact subsets of the space of Radon measures, and\ntest our approximation methodology on various data sets and supervised learning\ntasks.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Alex Elchesen",
      "Iryna Hartsock",
      "Jose A. Perea",
      "Tatum Rask"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2212.08295"
  },
  {
    "id": "arXiv:2212.08296",
    "title": "DQnet: Cross-Model Detail Querying for Camouflaged Object Detection",
    "abstract": "Camouflaged objects are seamlessly blended in with their surroundings, which\nbrings a challenging detection task in computer vision. Optimizing a\nconvolutional neural network (CNN) for camouflaged object detection (COD) tends\nto activate local discriminative regions while ignoring complete object extent,\ncausing the partial activation issue which inevitably leads to missing or\nredundant regions of objects. In this paper, we argue that partial activation\nis caused by the intrinsic characteristics of CNN, where the convolution\noperations produce local receptive fields and experience difficulty to capture\nlong-range feature dependency among image regions. In order to obtain feature\nmaps that could activate full object extent, keeping the segmental results from\nbeing overwhelmed by noisy features, a novel framework termed Cross-Model\nDetail Querying network (DQnet) is proposed. It reasons the relations between\nlong-range-aware representations and multi-scale local details to make the\nenhanced representation fully highlight the object regions and eliminate noise\non non-object regions. Specifically, a vanilla ViT pretrained with\nself-supervised learning (SSL) is employed to model long-range dependencies\namong image regions. A ResNet is employed to enable learning fine-grained\nspatial local details in multiple scales. Then, to effectively retrieve\nobject-related details, a Relation-Based Querying (RBQ) module is proposed to\nexplore window-based interactions between the global representations and the\nmulti-scale local details. Extensive experiments are conducted on the widely\nused COD datasets and show that our DQnet outperforms the current\nstate-of-the-arts.",
    "descriptor": "",
    "authors": [
      "Wei Sun",
      "Chengao Liu",
      "Linyan Zhang",
      "Yu Li",
      "Pengxu Wei",
      "Chang Liu",
      "Jialing Zou",
      "Jianbin Jiao",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08296"
  },
  {
    "id": "arXiv:2212.08298",
    "title": "Exploring Hybrid Active-Passive RIS-Aided MEC Systems: From the  Mode-Switching Perspective",
    "abstract": "Mobile edge computing (MEC) has been regarded as a promising technique to\nsupport latencysensitivity and computation-intensive serves. However, the low\noffloading rate caused by the random channel fading characteristic becomes a\nmajor bottleneck in restricting the performance of the MEC. Fortunately,\nreconfigurable intelligent surface (RIS) can alleviate this problem since it\ncan boost both the spectrum- and energy- efficiency. Different from the\nexisting works adopting either fully active or fully passive RIS, we propose a\nnovel hybrid RIS in which reflecting units can flexibly switch between active\nand passive modes. To achieve a tradeoff between the latency and energy\nconsumption, an optimization problem is formulated by minimizing the total\ncost. In light of the intractability of the problem, we develop an alternating\noptimization-based iterative algorithm by combining the successive convex\napproximation method, the variable substitution, and the singular value\ndecomposition (SVD) to obtain sub-optimal solutions. Furthermore, in order to\ngain more insight into the problem, we consider two special cases involving a\nlatency minimization problem and an energy consumption minimization problem,\nand respectively analyze the tradeoff between the number of active and passive\nunits. Simulation results verify that the proposed algorithm can achieve\nflexible mode switching and significantly outperforms existing algorithms.",
    "descriptor": "",
    "authors": [
      "Hao Xie",
      "Bowen Gu",
      "Dong Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.08298"
  },
  {
    "id": "arXiv:2212.08299",
    "title": "Metaheuristic for Hub-Spoke Facility Location Problem: Application to  Indian E-commerce Industry",
    "abstract": "Indian e-commerce industry has evolved over the last decade and is expected\nto grow over the next few years. The focus has now shifted to turnaround time\n(TAT) due to the emergence of many third-party logistics providers and higher\ncustomer expectations. The key consideration for delivery providers is to\nbalance their overall operating costs while meeting the promised TAT to their\ncustomers. E-commerce delivery partners operate through a network of facilities\nwhose strategic locations help to run the operations efficiently. In this work,\nwe identify the locations of hubs throughout the country and their\ncorresponding mapping with the distribution centers. The objective is to\nminimize the total network costs with TAT adherence. We use Genetic Algorithm\nand leverage business constraints to reduce the solution search space and hence\nthe solution time. The results indicate an improvement of 9.73% in TAT\ncompliance compared with the current scenario.",
    "descriptor": "",
    "authors": [
      "Aakash Sachdeva",
      "Bhupinder Singh",
      "Rahul Prasad",
      "Nakshatra Goel",
      "Ronit Mondal",
      "Jatin Munjal",
      "Abhishek Bhatnagar",
      "Manjeet Dahiya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.08299"
  },
  {
    "id": "arXiv:2212.08302",
    "title": "Safe Evaluation For Offline Learning: Are We Ready To Deploy?",
    "abstract": "The world currently offers an abundance of data in multiple domains, from\nwhich we can learn reinforcement learning (RL) policies without further\ninteraction with the environment. RL agents learning offline from such data is\npossible but deploying them while learning might be dangerous in domains where\nsafety is critical. Therefore, it is essential to find a way to estimate how a\nnewly-learned agent will perform if deployed in the target environment before\nactually deploying it and without the risk of overestimating its true\nperformance. To achieve this, we introduce a framework for safe evaluation of\noffline learning using approximate high-confidence off-policy evaluation\n(HCOPE) to estimate the performance of offline policies during learning. In our\nsetting, we assume a source of data, which we split into a train-set, to learn\nan offline policy, and a test-set, to estimate a lower-bound on the offline\npolicy using off-policy evaluation with bootstrapping. A lower-bound estimate\ntells us how good a newly-learned target policy would perform before it is\ndeployed in the real environment, and therefore allows us to decide when to\ndeploy our learned policy.",
    "descriptor": "\nComments: NeurIPS 2021 Workshop on Deployable Decision Making in Embodied Systems [Spotlight]\n",
    "authors": [
      "Hager Radi",
      "Josiah P. Hanna",
      "Peter Stone",
      "Matthew E. Taylor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08302"
  },
  {
    "id": "arXiv:2212.08306",
    "title": "Application of Physics-Informed Neural Networks for Forward and Inverse  Analysis of Pile-Soil Interaction",
    "abstract": "The application of the Physics-Informed Neural Networks (PINNs) to forward\nand inverse analysis of pile-soil interaction problems is presented. The main\nchallenge encountered in the Artificial Neural Network (ANN) modelling of\npile-soil interaction is the presence of abrupt changes in material properties,\nwhich results in large discontinuities in the gradient of the displacement\nsolution. Therefore, a domain-decomposition multi-network model is proposed to\ndeal with the discontinuities in the strain fields at common boundaries of\npile-soil regions and soil layers. The application of the model to the analysis\nand parametric study of single piles embedded in both homogeneous and layered\nformations is demonstrated under axisymmetric and plane strain conditions. The\nperformance of the model in parameter identification (inverse analysis) of\npile-soil interaction is particularly investigated. It is shown that by using\nPINNs, the localized data acquired along the pile length - possibly obtained\nvia fiber optic strain sensing - can be successfully used for the inversion of\nsoil parameters in layered formations.",
    "descriptor": "\nComments: 17 Pages, 12 Figures\n",
    "authors": [
      "M. Vahab",
      "B. Shahbodagh",
      "E. Haghighat",
      "N. Khalili"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2212.08306"
  },
  {
    "id": "arXiv:2212.08307",
    "title": "Controllable Text Generation via Probability Density Estimation in the  Latent Space",
    "abstract": "Previous work on controllable text generation has explored the idea of\ncontrol from the latent space, such as optimizing a representation with\nattribute-related classifiers or sampling a representation from relevant\ndiscrete samples. However, they are not effective enough in modeling both the\nlatent space and the control, leaving controlled text with low quality and\ndiversity. In this work, we propose a novel control framework using probability\ndensity estimation in the latent space. Our method utilizes an invertible\ntransformation function, the Normalizing Flow, that maps the complex\ndistributions in the latent space to simple Gaussian distributions in the prior\nspace. Thus, we can perform sophisticated and flexible control in the prior\nspace and feed the control effects back into the latent space owing to the\none-one-mapping property of invertible transformations. Experiments on\nsingle-attribute controls and multi-attribute control reveal that our method\noutperforms several strong baselines on attribute relevance and text quality\nand achieves the SOTA. Further analysis of control strength adjustment\ndemonstrates the flexibility of our control strategy.",
    "descriptor": "\nComments: 13 pages, 6 figures, Work in progress\n",
    "authors": [
      "Yuxuan Gu",
      "Xiaocheng Feng",
      "Sicheng Ma",
      "Lingyuan Zhang",
      "Heng Gong",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08307"
  },
  {
    "id": "arXiv:2212.08308",
    "title": "Fluid Antenna with Linear MMSE Channel Estimation for Large-Scale  Cellular Networks",
    "abstract": "The concept of reconfigurable fluid antennas (FA) is a potential and\npromising solution to enhance the spectral efficiency of wireless communication\nnetworks. Despite their many advantages, FA-enabled communications have\nlimitations as they require an enormous amount of spectral resources in order\nto select the most desirable position of the radiating element from a large\nnumber of prescribed locations. In this paper, we present an analytical\nframework for the outage performance of large-scale FA-enabled communications,\nwhere all user equipments (UEs) employ circular multi-FA array. In contrast to\nexisting studies, which assume perfect channel state information, the developed\nframework accurately captures the channel estimation errors on the performance\nof the considered network deployments. In particular, we focus on the limited\ncoherence interval scenario, where a novel sequential linear minimum\nmean-squared error (LMMSE)-based channel estimation method is performed for\nonly a very small number of FA ports. Next, for the communication of each BS\nwith its associated UE, a low-complexity port-selection technique is employed,\nwhere the port that provides the highest\nsignal-to-interference-plus-noise-ratio is selected among the ports that are\nestimated to provide the strongest channel from each FA. By using stochastic\ngeometry tools, we derive both analytical and closed-form expressions for the\noutage probability, highlighting the impact of channel estimation on the\nperformance of FA-based UEs. Our results reveal the trade-off imposed between\nimproving the network's performance and reducing the channel estimation\nquality, indicating new insights for the design of FA-enabled communications.",
    "descriptor": "\nComments: 32 pages, 11 figures\n",
    "authors": [
      "Christodoulos Skouroumounis",
      "Ioannis Krikidis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.08308"
  },
  {
    "id": "arXiv:2212.08311",
    "title": "Can We Find Strong Lottery Tickets in Generative Models?",
    "abstract": "Yes. In this paper, we investigate strong lottery tickets in generative\nmodels, the subnetworks that achieve good generative performance without any\nweight update. Neural network pruning is considered the main cornerstone of\nmodel compression for reducing the costs of computation and memory.\nUnfortunately, pruning a generative model has not been extensively explored,\nand all existing pruning algorithms suffer from excessive weight-training\ncosts, performance degradation, limited generalizability, or complicated\ntraining. To address these problems, we propose to find a strong lottery ticket\nvia moment-matching scores. Our experimental results show that the discovered\nsubnetwork can perform similarly or better than the trained dense model even\nwhen only 10% of the weights remain. To the best of our knowledge, we are the\nfirst to show the existence of strong lottery tickets in generative models and\nprovide an algorithm to find it stably. Our code and supplementary materials\nare publicly available.",
    "descriptor": "",
    "authors": [
      "Sangyeop Yeo",
      "Yoojin Jang",
      "Jy-yong Sohn",
      "Dongyoon Han",
      "Jaejun Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08311"
  },
  {
    "id": "arXiv:2212.08312",
    "title": "An Efficient Framework for Monitoring Subgroup Performance of Machine  Learning Systems",
    "abstract": "Monitoring machine learning systems post deployment is critical to ensure the\nreliability of the systems. Particularly importance is the problem of\nmonitoring the performance of machine learning systems across all the data\nsubgroups (subpopulations). In practice, this process could be prohibitively\nexpensive as the number of data subgroups grows exponentially with the number\nof input features, and the process of labelling data to evaluate each\nsubgroup's performance is costly. In this paper, we propose an efficient\nframework for monitoring subgroup performance of machine learning systems.\nSpecifically, we aim to find the data subgroup with the worst performance using\na limited number of labeled data. We mathematically formulate this problem as\nan optimization problem with an expensive black-box objective function, and\nthen suggest to use Bayesian optimization to solve this problem. Our\nexperimental results on various real-world datasets and machine learning\nsystems show that our proposed framework can retrieve the worst-performing data\nsubgroup effectively and efficiently.",
    "descriptor": "\nComments: Accepted to the ML Safety Workshop at NeurIPS 2022\n",
    "authors": [
      "Huong Ha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08312"
  },
  {
    "id": "arXiv:2212.08320",
    "title": "Autoencoders as Cross-Modal Teachers: Can Pretrained 2D Image  Transformers Help 3D Representation Learning?",
    "abstract": "The success of deep learning heavily relies on large-scale data with\ncomprehensive labels, which is more expensive and time-consuming to fetch in 3D\ncompared to 2D images or natural languages. This promotes the potential of\nutilizing models pretrained with data more than 3D as teachers for cross-modal\nknowledge transferring. In this paper, we revisit masked modeling in a unified\nfashion of knowledge distillation, and we show that foundational Transformers\npretrained with 2D images or natural languages can help self-supervised 3D\nrepresentation learning through training Autoencoders as Cross-Modal Teachers\n(ACT). The pretrained Transformers are transferred as cross-modal 3D teachers\nusing discrete variational autoencoding self-supervision, during which the\nTransformers are frozen with prompt tuning for better knowledge inheritance.\nThe latent features encoded by the 3D teachers are used as the target of masked\npoint modeling, wherein the dark knowledge is distilled to the 3D Transformer\nstudents as foundational geometry understanding. Our ACT pretrained 3D learner\nachieves state-of-the-art generalization capacity across various downstream\nbenchmarks, e.g., 88.21% overall accuracy on ScanObjectNN. Codes will be\nreleased at https://github.com/RunpeiDong/ACT.",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Runpei Dong",
      "Zekun Qi",
      "Linfeng Zhang",
      "Junbo Zhang",
      "Jianjian Sun",
      "Zheng Ge",
      "Li Yi",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08320"
  },
  {
    "id": "arXiv:2212.08322",
    "title": "ReCo: Reliable Causal Chain Reasoning via Structural Causal Recurrent  Neural Networks",
    "abstract": "Causal chain reasoning (CCR) is an essential ability for many decision-making\nAI systems, which requires the model to build reliable causal chains by\nconnecting causal pairs. However, CCR suffers from two main transitive\nproblems: threshold effect and scene drift. In other words, the causal pairs to\nbe spliced may have a conflicting threshold boundary or scenario. To address\nthese issues, we propose a novel Reliable Causal chain reasoning\nframework~(ReCo), which introduces exogenous variables to represent the\nthreshold and scene factors of each causal pair within the causal chain, and\nestimates the threshold and scene contradictions across exogenous variables via\nstructural causal recurrent neural networks~(SRNN). Experiments show that ReCo\noutperforms a series of strong baselines on both Chinese and English CCR\ndatasets. Moreover, by injecting reliable causal chain knowledge distilled by\nReCo, BERT can achieve better performances on four downstream causal-related\ntasks than BERT models enhanced by other kinds of knowledge.",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Kai Xiong",
      "Xiao Ding",
      "Zhongyang Li",
      "Li Du",
      "Bing Qin",
      "Yi Zheng",
      "Baoxing Huai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08322"
  },
  {
    "id": "arXiv:2212.08324",
    "title": "Mobile Augmented Reality with Federated Learning in the Metaverse",
    "abstract": "The Metaverse is deemed the next evolution of the Internet and has received\nmuch attention recently. Metaverse applications via mobile augmented reality\n(MAR) require rapid and accurate object detection to mix digital data with the\nreal world. As mobile devices evolve, they become more potent in computing.\nHence, their computational resources can be leveraged to train machine learning\nmodels. In light of the increasing concerns of user privacy and data security,\nfederated learning (FL) has become a promising distributed learning framework\nfor privacy-preserving analytics. In this article, FL and MAR are brought\ntogether in the Metaverse. We discuss the necessity and rationality of the\ncombination of FL and MAR. The prospective technologies that power FL and MAR\nin the Metaverse are also identified. In addition, existing challenges that\nprevent the fulfilment of FL and MAR in the Metaverse and several application\nscenarios are presented. Finally, two case studies of Metaverse FL-MAR systems\nare demonstrated.",
    "descriptor": "",
    "authors": [
      "Xinyu Zhou",
      "Jun Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.08324"
  },
  {
    "id": "arXiv:2212.08327",
    "title": "WavEnhancer: Unifying Wavelet and Transformer for Image Enhancement",
    "abstract": "Image enhancement is a technique that frequently utilized in digital image\nprocessing. In recent years, the popularity of learning-based techniques for\nenhancing the aesthetic performance of photographs has increased. However, the\nmajority of current works do not optimize an image from different frequency\ndomains and typically focus on either pixel-level or global-level enhancements.\nIn this paper, we propose a transformer-based model in the wavelet domain to\nrefine different frequency bands of an image. Our method focuses both on local\ndetails and high-level features for enhancement, which can generate superior\nresults. On the basis of comprehensive benchmark evaluations, our method\noutperforms the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Zinuo Li",
      "Xuhang Chen",
      "Chi-Man Pun",
      "Shuqiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.08327"
  },
  {
    "id": "arXiv:2212.08328",
    "title": "MEIL-NeRF: Memory-Efficient Incremental Learning of Neural Radiance  Fields",
    "abstract": "Hinged on the representation power of neural networks, neural radiance fields\n(NeRF) have recently emerged as one of the promising and widely applicable\nmethods for 3D object and scene representation. However, NeRF faces challenges\nin practical applications, such as large-scale scenes and edge devices with a\nlimited amount of memory, where data needs to be processed sequentially. Under\nsuch incremental learning scenarios, neural networks are known to suffer\ncatastrophic forgetting: easily forgetting previously seen data after training\nwith new data. We observe that previous incremental learning algorithms are\nlimited by either low performance or memory scalability issues. As such, we\ndevelop a Memory-Efficient Incremental Learning algorithm for NeRF (MEIL-NeRF).\nMEIL-NeRF takes inspiration from NeRF itself in that a neural network can serve\nas a memory that provides the pixel RGB values, given rays as queries. Upon the\nmotivation, our framework learns which rays to query NeRF to extract previous\npixel values. The extracted pixel values are then used to train NeRF in a\nself-distillation manner to prevent catastrophic forgetting. As a result,\nMEIL-NeRF demonstrates constant memory consumption and competitive performance.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Jaeyoung Chung",
      "Kanggeon Lee",
      "Sungyong Baik",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08328"
  },
  {
    "id": "arXiv:2212.08330",
    "title": "Convolution-enhanced Evolving Attention Networks",
    "abstract": "Attention-based neural networks, such as Transformers, have become ubiquitous\nin numerous applications, including computer vision, natural language\nprocessing, and time-series analysis. In all kinds of attention networks, the\nattention maps are crucial as they encode semantic dependencies between input\ntokens. However, most existing attention networks perform modeling or reasoning\nbased on representations, wherein the attention maps of different layers are\nlearned separately without explicit interactions. In this paper, we propose a\nnovel and generic evolving attention mechanism, which directly models the\nevolution of inter-token relationships through a chain of residual\nconvolutional modules. The major motivations are twofold. On the one hand, the\nattention maps in different layers share transferable knowledge, thus adding a\nresidual connection can facilitate the information flow of inter-token\nrelationships across layers. On the other hand, there is naturally an\nevolutionary trend among attention maps at different abstraction levels, so it\nis beneficial to exploit a dedicated convolution-based module to capture this\nprocess. Equipped with the proposed mechanism, the convolution-enhanced\nevolving attention networks achieve superior performance in various\napplications, including time-series representation, natural language\nunderstanding, machine translation, and image classification. Especially on\ntime-series representation tasks, Evolving Attention-enhanced Dilated\nConvolutional (EA-DC-) Transformer outperforms state-of-the-art models\nsignificantly, achieving an average of 17% improvement compared to the best\nSOTA. To the best of our knowledge, this is the first work that explicitly\nmodels the layer-wise evolution of attention maps. Our implementation is\navailable at https://github.com/pkuyym/EvolvingAttention",
    "descriptor": "\nComments: Extension of the previous work (arXiv:2102.12895). arXiv admin note: text overlap with arXiv:2102.12895\n",
    "authors": [
      "Yujing Wang",
      "Yaming Yang",
      "Zhuo Li",
      "Jiangang Bai",
      "Mingliang Zhang",
      "Xiangtai Li",
      "Jing Yu",
      "Ce Zhang",
      "Gao Huang",
      "Yunhai Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2212.08330"
  },
  {
    "id": "arXiv:2212.08333",
    "title": "AnyGrasp: Robust and Efficient Grasp Perception in Spatial and Temporal  Domains",
    "abstract": "As the basis for prehensile manipulation, it is vital to enable robots to\ngrasp as robustly as humans. In daily manipulation, our grasping system is\nprompt, accurate, flexible and continuous across spatial and temporal domains.\nFew existing methods cover all these properties for robot grasping. In this\npaper, we propose a new methodology for grasp perception to enable robots these\nabilities. Specifically, we develop a dense supervision strategy with real\nperception and analytic labels in the spatial-temporal domain. Additional\nawareness of objects' center-of-mass is incorporated into the learning process\nto help improve grasping stability. Utilization of grasp correspondence across\nobservations enables dynamic grasp tracking. Our model, AnyGrasp, can generate\naccurate, full-DoF, dense and temporally-smooth grasp poses efficiently, and\nworks robustly against large depth sensing noise. Embedded with AnyGrasp, we\nachieve a 93.3% success rate when clearing bins with over 300 unseen objects,\nwhich is comparable with human subjects under controlled conditions. Over 900\nMPPH is reported on a single-arm system. For dynamic grasping, we demonstrate\ncatching swimming robot fish in the water.",
    "descriptor": "\nComments: project page at this https URL\n",
    "authors": [
      "Hao-Shu Fang",
      "Chenxi Wang",
      "Hongjie Fang",
      "Minghao Gou",
      "Jirong Liu",
      "Hengxu Yan",
      "Wenhai Liu",
      "Yichen Xie",
      "Cewu Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.08333"
  },
  {
    "id": "arXiv:2212.08334",
    "title": "Lightweight integration of 3D features to improve 2D image segmentation",
    "abstract": "Scene understanding is a major challenge of today's computer vision. Center\nto this task is image segmentation, since scenes are often provided as a set of\npictures. Nowadays, many such datasets also provide 3D geometry information\ngiven as a 3D point cloud acquired by a laser scanner or a depth camera. To\nexploit this geometric information, many current approaches rely on both a 2D\nloss and 3D loss, requiring not only 2D per pixel labels but also 3D per point\nlabels. However obtaining a 3D groundtruth is challenging, time-consuming and\nerror-prone. In this paper, we show that image segmentation can benefit from 3D\ngeometric information without requiring any 3D groundtruth, by training the\ngeometric feature extraction with a 2D segmentation loss in an end-to-end\nfashion. Our method starts by extracting a map of 3D features directly from the\npoint cloud by using a lightweight and simple 3D encoder neural network. The 3D\nfeature map is then used as an additional input to a classical image\nsegmentation network. During training, the 3D features extraction is optimized\nfor the segmentation task by back-propagation through the entire pipeline. Our\nmethod exhibits state-of-the-art performance with much lighter input dataset\nrequirements, since no 3D groundtruth is required.",
    "descriptor": "\nComments: main : 7 pages, 4 figures; supplementary : 4 pages, 3 figures; submitted to CVIU\n",
    "authors": [
      "Olivier Pradelle",
      "Raphaelle Chaine",
      "David Wendland",
      "Julie Digne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08334"
  },
  {
    "id": "arXiv:2212.08335",
    "title": "Law to Binary Tree -- An Formal Interpretation of Legal Natural Language",
    "abstract": "Knowledge representation and reasoning in law are essential to facilitate the\nautomation of legal analysis and decision-making tasks. In this paper, we\npropose a new approach based on legal science, specifically legal taxonomy, for\nrepresenting and reasoning with legal documents. Our approach interprets the\nregulations in legal documents as binary trees, which facilitates legal\nreasoning systems to make decisions and resolve logical contradictions. The\nadvantages of this approach are twofold. First, legal reasoning can be\nperformed on the basis of the binary tree representation of the regulations.\nSecond, the binary tree representation of the regulations is more\nunderstandable than the existing sentence-based representations. We provide an\nexample of how our approach can be used to interpret the regulations in a legal\ndocument.",
    "descriptor": "\nComments: LN2FR 2022\n",
    "authors": [
      "Ha-Thanh Nguyen",
      "Vu Tran",
      "Ngoc-Cam Le",
      "Thi-Thuy Le",
      "Quang-Huy Nguyen",
      "Le-Minh Nguyen",
      "Ken Satoh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08335"
  },
  {
    "id": "arXiv:2212.08339",
    "title": "Generalization Bounds for Inductive Matrix Completion in Low-noise  Settings",
    "abstract": "We study inductive matrix completion (matrix completion with side\ninformation) under an i.i.d. subgaussian noise assumption at a low noise\nregime, with uniform sampling of the entries. We obtain for the first time\ngeneralization bounds with the following three properties: (1) they scale like\nthe standard deviation of the noise and in particular approach zero in the\nexact recovery case; (2) even in the presence of noise, they converge to zero\nwhen the sample size approaches infinity; and (3) for a fixed dimension of the\nside information, they only have a logarithmic dependence on the size of the\nmatrix. Differently from many works in approximate recovery, we present results\nboth for bounded Lipschitz losses and for the absolute loss, with the latter\nrelying on Talagrand-type inequalities. The proofs create a bridge between two\napproaches to the theoretical analysis of matrix completion, since they consist\nin a combination of techniques from both the exact recovery literature and the\napproximate recovery literature.",
    "descriptor": "\nComments: 30 Pages, 1 figure; Accepted for publication at AAAI 2023\n",
    "authors": [
      "Antoine Ledent",
      "Rodrigo Alves",
      "Yunwen Lei",
      "Yann Guermeur",
      "Marius Kloft"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.08339"
  },
  {
    "id": "arXiv:2212.08340",
    "title": "Neural Enhanced Belief Propagation for Multiobject Tracking",
    "abstract": "Algorithmic solutions for multi-object tracking (MOT) are a key enabler for\napplications in autonomous navigation and applied ocean sciences.\nState-of-the-art MOT methods fully rely on a statistical model and typically\nuse preprocessed sensor data as measurements. In particular, measurements are\nproduced by a detector that extracts potential object locations from the raw\nsensor data collected for a discrete time step. This preparatory processing\nstep reduces data flow and computational complexity but may result in a loss of\ninformation. State-of-the-art Bayesian MOT methods that are based on belief\npropagation (BP) systematically exploit graph structures of the statistical\nmodel to reduce computational complexity and improve scalability. However, as a\nfully model-based approach, BP can only provide suboptimal estimates when there\nis a mismatch between the statistical model and the true data-generating\nprocess. Existing BP-based MOT methods can further only make use of\npreprocessed measurements. In this paper, we introduce a variant of BP that\ncombines model-based with data-driven MOT. The proposed neural enhanced belief\npropagation (NEBP) method complements the statistical model of BP by\ninformation learned from raw sensor data. This approach conjectures that the\nlearned information can reduce model mismatch and thus improve data association\nand false alarm rejection. Our NEBP method improves tracking performance\ncompared to model-based methods. At the same time, it inherits the advantages\nof BP-based MOT, i.e., it scales only quadratically in the number of objects,\nand it can thus generate and maintain a large number of object tracks. We\nevaluate the performance of our NEBP approach for MOT on the nuScenes\nautonomous driving dataset and demonstrate that it has state-of-the-art\nperformance.",
    "descriptor": "",
    "authors": [
      "Mingchao Liang",
      "Florian Meyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.08340"
  },
  {
    "id": "arXiv:2212.08341",
    "title": "Adversarial Example Defense via Perturbation Grading Strategy",
    "abstract": "Deep Neural Networks have been widely used in many fields. However, studies\nhave shown that DNNs are easily attacked by adversarial examples, which have\ntiny perturbations and greatly mislead the correct judgment of DNNs.\nFurthermore, even if malicious attackers cannot obtain all the underlying model\nparameters, they can use adversarial examples to attack various DNN-based task\nsystems. Researchers have proposed various defense methods to protect DNNs,\nsuch as reducing the aggressiveness of adversarial examples by preprocessing or\nimproving the robustness of the model by adding modules. However, some defense\nmethods are only effective for small-scale examples or small perturbations but\nhave limited defense effects for adversarial examples with large perturbations.\nThis paper assigns different defense strategies to adversarial perturbations of\ndifferent strengths by grading the perturbations on the input examples.\nExperimental results show that the proposed method effectively improves defense\nperformance. In addition, the proposed method does not modify any task model,\nwhich can be used as a preprocessing module, which significantly reduces the\ndeployment cost in practical applications.",
    "descriptor": "",
    "authors": [
      "Shaowei Zhu",
      "Wanli Lyu",
      "Bin Li",
      "Zhaoxia Yin",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08341"
  },
  {
    "id": "arXiv:2212.08343",
    "title": "SplitGP: Achieving Both Generalization and Personalization in Federated  Learning",
    "abstract": "A fundamental challenge to providing edge-AI services is the need for a\nmachine learning (ML) model that achieves personalization (i.e., to individual\nclients) and generalization (i.e., to unseen data) properties concurrently.\nExisting techniques in federated learning (FL) have encountered a steep\ntradeoff between these objectives and impose large computational requirements\non edge devices during training and inference. In this paper, we propose\nSplitGP, a new split learning solution that can simultaneously capture\ngeneralization and personalization capabilities for efficient inference across\nresource-constrained clients (e.g., mobile/IoT devices). Our key idea is to\nsplit the full ML model into client-side and server-side components, and impose\ndifferent roles to them: the client-side model is trained to have strong\npersonalization capability optimized to each client's main task, while the\nserver-side model is trained to have strong generalization capability for\nhandling all clients' out-of-distribution tasks. We analytically characterize\nthe convergence behavior of SplitGP, revealing that all client models approach\nstationary points asymptotically. Further, we analyze the inference time in\nSplitGP and provide bounds for determining model split ratios. Experimental\nresults show that SplitGP outperforms existing baselines by wide margins in\ninference time and test accuracy for varying amounts of out-of-distribution\nsamples.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Dong-Jun Han",
      "Do-Yeon Kim",
      "Minseok Choi",
      "Christopher G. Brinton",
      "Jaekyun Moon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08343"
  },
  {
    "id": "arXiv:2212.08344",
    "title": "Roundoff error problem in L2-type methods for time-fractional problems",
    "abstract": "Roundoff error problems have occurred frequently in interpolation methods of\ntime-fractional equations, which can lead to undesirable results such as the\nfailure of optimal convergence. These problems are essentially caused by\ncatastrophic cancellations. Currently, a feasible way to avoid these\ncancellations is using the Gauss--Kronrod quadrature to approximate the\nintegral formulas of coefficients rather than computing the explicit formulas\ndirectly for example in the L2-type methods. This nevertheless increases\ncomputational cost and arises additional integration errors. In this work, a\nnew framework to handle catastrophic cancellations is proposed, in particular,\nin the computation of the coefficients for standard and fast L2-type methods on\ngeneral nonuniform meshes. We propose a concept of $\\delta$-cancellation and\nthen some threshold conditions ensuring that $\\delta$-cancellations will not\nhappen. If the threshold conditions are not satisfied, a Taylor-expansion\ntechnique is proposed to avoid $\\delta$-cancellation. Numerical experiments\nshow that our proposed method performs as accurate as the Gauss--Kronrod\nquadrature method and meanwhile much more efficient. This enables us to\ncomplete long time simulations with hundreds of thousands of time steps in\nshort time.",
    "descriptor": "",
    "authors": [
      "Chaoyu Quan",
      "Shijie Wang",
      "Xu Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.08344"
  },
  {
    "id": "arXiv:2212.08348",
    "title": "Towards Unified All-Neural Beamforming for Time and Frequency Domain  Speech Separation",
    "abstract": "Recently, frequency domain all-neural beamforming methods have achieved\nremarkable progress for multichannel speech separation. In parallel, the\nintegration of time domain network structure and beamforming also gains\nsignificant attention. This study proposes a novel all-neural beamforming\nmethod in time domain and makes an attempt to unify the all-neural beamforming\npipelines for time domain and frequency domain multichannel speech separation.\nThe proposed model consists of two modules: separation and beamforming. Both\nmodules perform temporal-spectral-spatial modeling and are trained from\nend-to-end using a joint loss function. The novelty of this study lies in two\nfolds. Firstly, a time domain directional feature conditioned on the direction\nof the target speaker is proposed, which can be jointly optimized within the\ntime domain architecture to enhance target signal estimation. Secondly, an\nall-neural beamforming network in time domain is designed to refine the\npre-separated results. This module features with parametric time-variant\nbeamforming coefficient estimation, without explicitly following the derivation\nof optimal filters that may lead to an upper bound. The proposed method is\nevaluated on simulated reverberant overlapped speech data derived from the\nAISHELL-1 corpus. Experimental results demonstrate significant performance\nimprovements over frequency domain state-of-the-arts, ideal magnitude masks and\nexisting time domain neural beamforming methods.",
    "descriptor": "",
    "authors": [
      "Rongzhi Gu",
      "Shi-Xiong Zhang",
      "Yuexian Zou",
      "Dong Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.08348"
  },
  {
    "id": "arXiv:2212.08349",
    "title": "Swing Distillation: A Privacy-Preserving Knowledge Distillation  Framework",
    "abstract": "Knowledge distillation (KD) has been widely used for model compression and\nknowledge transfer. Typically, a big teacher model trained on sufficient data\ntransfers knowledge to a small student model. However, despite the success of\nKD, little effort has been made to study whether KD leaks the training data of\nthe teacher model. In this paper, we experimentally reveal that KD suffers from\nthe risk of privacy leakage. To alleviate this issue, we propose a novel\nknowledge distillation method, swing distillation, which can effectively\nprotect the private information of the teacher model from flowing to the\nstudent model. In our framework, the temperature coefficient is dynamically and\nadaptively adjusted according to the degree of private information contained in\nthe data, rather than a predefined constant hyperparameter. It assigns\ndifferent temperatures to tokens according to the likelihood that a token in a\nposition contains private information. In addition, we inject noise into soft\ntargets provided to the student model, in order to avoid unshielded knowledge\ntransfer. Experiments on multiple datasets and tasks demonstrate that the\nproposed swing distillation can significantly reduce (by over 80% in terms of\ncanary exposure) the risk of privacy leakage in comparison to KD with\ncompetitive or better performance. Furthermore, swing distillation is robust\nagainst the increasing privacy budget.",
    "descriptor": "",
    "authors": [
      "Junzhuo Li",
      "Xinwei Wu",
      "Weilong Dong",
      "Shuangzhi Wu",
      "Chao Bian",
      "Deyi Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.08349"
  },
  {
    "id": "arXiv:2212.08350",
    "title": "Structure preserving discontinuous Galerkin approximation of  one-dimensional port-Hamiltonian systems",
    "abstract": "In this article, we present the structure-preserving discretization of linear\none-dimensional port-Hamiltonian (PH) systems of two conservation laws using\ndiscontinuous Galerkin (DG) methods. We recall the DG discretization procedure\nwhich is based on a subdivision of the computational domain, an elementwise\nweak formulation with up to two integration by parts, and the interconnection\nof the elements using several numerical fluxes. We present the interconnection\nof the element models, which is power preserving in the case of conservative\n(unstabilized) numerical fluxes, and we set up the resulting global PH state\nspace model. We discuss the properties of the obtained models, including the\neffect of the flux stabilization parameter on the spectrum. Finally, we show\nsimulations with different parameters for a boundary controlled linear\nhyperbolic system.",
    "descriptor": "\nComments: 7 pages, 7 figures, submitted to the 22nd World Congress of the International Federation of Automatic Control\n",
    "authors": [
      "Tobias Thoma",
      "Paul Kotyczka"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08350"
  },
  {
    "id": "arXiv:2212.08353",
    "title": "How to disagree well: Investigating the dispute tactics used on  Wikipedia",
    "abstract": "Disagreements are frequently studied from the perspective of either detecting\ntoxicity or analysing argument structure. We propose a framework of dispute\ntactics that unifies these two perspectives, as well as other dialogue acts\nwhich play a role in resolving disputes, such as asking questions and providing\nclarification. This framework includes a preferential ordering among\nrebuttal-type tactics, ranging from ad hominem attacks to refuting the central\nargument. Using this framework, we annotate 213 disagreements (3,865\nutterances) from Wikipedia Talk pages. This allows us to investigate research\nquestions around the tactics used in disagreements; for instance, we provide\nempirical validation of the approach to disagreement recommended by Wikipedia.\nWe develop models for multilabel prediction of dispute tactics in an utterance,\nachieving the best performance with a transformer-based label powerset model.\nAdding an auxiliary task to incorporate the ordering of rebuttal tactics\nfurther yields a statistically significant increase. Finally, we show that\nthese annotations can be used to provide useful additional signals to improve\nperformance on the task of predicting escalation.",
    "descriptor": "\nComments: Accepted to EMNLP 2022 (Long paper)\n",
    "authors": [
      "Christine de Kock",
      "Tom Stafford",
      "Andreas Vlachos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.08353"
  },
  {
    "id": "arXiv:2212.08354",
    "title": "FewFedWeight: Few-shot Federated Learning Framework across Multiple NLP  Tasks",
    "abstract": "Massively multi-task learning with large language models has recently made\nsubstantial progress on few-shot generalization. However, this is usually\nperformed in a centralized learning fashion, ignoring the privacy sensitivity\nissue of (annotated) data used in multiple tasks. To mitigate this issue, we\npropose FewFedWeight, a few-shot federated learning framework across multiple\ntasks, to achieve the best of both worlds: privacy preservation and cross-task\ngeneralization. FewFedWeight trains client models in isolated devices without\nsharing data. It broadcasts the global model in the server to each client and\nproduces pseudo data for clients so that knowledge from the global model can be\nexplored to enhance few-shot learning of each client model. An energy-based\nalgorithm is further proposed to weight pseudo samples in order to reduce the\nnegative impact of noise from the generated pseudo data. Adaptive model weights\nof client models are also tuned according to their performance. We use these\nmodel weights to dynamically aggregate client models to update the global\nmodel. Experiments on 118 NLP tasks show that FewFedWeight can significantly\nimprove the performance of client models on 61% tasks with an average\nperformance improvement rate of 30.5% over the baseline and substantially\noutperform FedAvg and other decentralized learning methods.",
    "descriptor": "",
    "authors": [
      "Weilong Dong",
      "Xinwei Wu",
      "Junzhuo Li",
      "Shuangzhi Wu",
      "Chao Bian",
      "Deyi Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08354"
  },
  {
    "id": "arXiv:2212.08355",
    "title": "Learning Classifiers of Prototypes and Reciprocal Points for Universal  Domain Adaptation",
    "abstract": "Universal Domain Adaptation aims to transfer the knowledge between the\ndatasets by handling two shifts: domain-shift and category-shift. The main\nchallenge is correctly distinguishing the unknown target samples while adapting\nthe distribution of known class knowledge from source to target. Most existing\nmethods approach this problem by first training the target adapted known\nclassifier and then relying on the single threshold to distinguish unknown\ntarget samples. However, this simple threshold-based approach prevents the\nmodel from considering the underlying complexities existing between the known\nand unknown samples in the high-dimensional feature space. In this paper, we\npropose a new approach in which we use two sets of feature points, namely dual\nClassifiers for Prototypes and Reciprocals (CPR). Our key idea is to associate\neach prototype with corresponding known class features while pushing the\nreciprocals apart from these prototypes to locate them in the potential unknown\nfeature space. The target samples are then classified as unknown if they fall\nnear any reciprocals at test time. To successfully train our framework, we\ncollect the partial, confident target samples that are classified as known or\nunknown through on our proposed multi-criteria selection. We then additionally\napply the entropy loss regularization to them. For further adaptation, we also\napply standard consistency regularization that matches the predictions of two\ndifferent views of the input to make more compact target feature space. We\nevaluate our proposal, CPR, on three standard benchmarks and achieve comparable\nor new state-of-the-art results. We also provide extensive ablation experiments\nto verify our main design choices in our framework.",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Sungsu Hur",
      "Inkyu Shin",
      "Kwanyong Park",
      "Sanghyun Woo",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08355"
  },
  {
    "id": "arXiv:2212.08356",
    "title": "CD-TTA: Compound Domain Test-time Adaptation for Semantic Segmentation",
    "abstract": "Test-time adaptation (TTA) has attracted significant attention due to its\npractical properties which enable the adaptation of a pre-trained model to a\nnew domain with only target dataset during the inference stage. Prior works on\nTTA assume that the target dataset comes from the same distribution and thus\nconstitutes a single homogeneous domain. In practice, however, the target\ndomain can contain multiple homogeneous domains which are sufficiently\ndistinctive from each other and those multiple domains might occur cyclically.\nOur preliminary investigation shows that domain-specific TTA outperforms\nvanilla TTA treating compound domain (CD) as a single one. However, domain\nlabels are not available for CD, which makes domain-specific TTA not\npracticable. To this end, we propose an online clustering algorithm for finding\npseudo-domain labels to obtain similar benefits as domain-specific\nconfiguration and accumulating knowledge of cyclic domains effectively.\nMoreover, we observe that there is a significant discrepancy in terms of\nprediction quality among samples, especially in the CD context. This further\nmotivates us to boost its performance with gradient denoising by considering\nthe image-wise similarity with the source distribution. Overall, the key\ncontribution of our work lies in proposing a highly significant new task\ncompound domain test-time adaptation (CD-TTA) on semantic segmentation as well\nas providing a strong baseline to facilitate future works to benchmark.",
    "descriptor": "",
    "authors": [
      "Junha Song",
      "Kwanyong Park",
      "Inkyu Shin",
      "Sanghyun Woo",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08356"
  },
  {
    "id": "arXiv:2212.08362",
    "title": "NetRPC: Enabling In-Network Computation in Remote Procedure Calls",
    "abstract": "People have shown that in-network computation (INC) significantly boosts\nperformance in many application scenarios include distributed training,\nMapReduce, agreement, and network monitoring. However, existing INC programming\nis unfriendly to the normal application developers, demanding tedious network\nengineering details like flow control, packet organization, chip-specific\nprogramming language, and ASIC architecture with many limitations. We propose a\ngeneral INC-enabled RPC system, NetRPC. NetRPC provides a set of familiar and\nlightweight interfaces for software developers to describe an INC application\nusing a traditional RPC programming model. NetRPC also proposes a\ngeneral-purpose INC implementation together with a set of optimization\ntechniques to guarantee the efficiency of various types of INC applications\nrunning on a shared INC data plane. We conduct extensive experiments on\ndifferent types of applications on the real testbed. Results show that using\nonly about 5% or even fewer human-written lines of code, NetRPC can achieve\nperformance similar to the state-of-the-art INC solutions.",
    "descriptor": "",
    "authors": [
      "Bohan Zhao",
      "Wenfei Wu",
      "Wei Xu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.08362"
  },
  {
    "id": "arXiv:2212.08363",
    "title": "Fast Learning of Dynamic Hand Gesture Recognition with Few-Shot Learning  Models",
    "abstract": "We develop Few-Shot Learning models trained to recognize five or ten\ndifferent dynamic hand gestures, respectively, which are arbitrarily\ninterchangeable by providing the model with one, two, or five examples per hand\ngesture. All models were built in the Few-Shot Learning architecture of the\nRelation Network (RN), in which Long-Short-Term Memory cells form the backbone.\nThe models use hand reference points extracted from RGB-video sequences of the\nJester dataset which was modified to contain 190 different types of hand\ngestures. Result show accuracy of up to 88.8% for recognition of five and up to\n81.2% for ten dynamic hand gestures. The research also sheds light on the\npotential effort savings of using a Few-Shot Learning approach instead of a\ntraditional Deep Learning approach to detect dynamic hand gestures. Savings\nwere defined as the number of additional observations required when a Deep\nLearning model is trained on new hand gestures instead of a Few Shot Learning\nmodel. The difference with respect to the total number of observations required\nto achieve approximately the same accuracy indicates potential savings of up to\n630 observations for five and up to 1260 observations for ten hand gestures to\nbe recognized. Since labeling video recordings of hand gestures implies\nsignificant effort, these savings can be considered substantial.",
    "descriptor": "",
    "authors": [
      "Niels Schl\u00fcsener",
      "Michael B\u00fccker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08363"
  },
  {
    "id": "arXiv:2212.08364",
    "title": "Three lines of defense against risks from AI",
    "abstract": "Organizations that develop and deploy artificial intelligence (AI) systems\nneed to manage the associated risks - for economic, legal, and ethical reasons.\nHowever, it is not always clear who is responsible for AI risk management. The\nThree Lines of Defense (3LoD) model, which is considered best practice in many\nindustries, might offer a solution. It is a risk management framework that\nhelps organizations to assign and coordinate risk management roles and\nresponsibilities. In this article, I suggest ways in which AI companies could\nimplement the model. I also discuss how the model could help reduce risks from\nAI: it could identify and close gaps in risk coverage, increase the\neffectiveness of risk management practices, and enable the board of directors\nto oversee management more effectively. The article is intended to inform\ndecision-makers at leading AI companies, regulators, and standard-setting\nbodies.",
    "descriptor": "\nComments: 22 pages, 2 figures\n",
    "authors": [
      "Jonas Schuett"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.08364"
  },
  {
    "id": "arXiv:2212.08365",
    "title": "Geometric Rectification of Creased Document Images based on Isometric  Mapping",
    "abstract": "Geometric rectification of images of distorted documents finds wide\napplications in document digitization and Optical Character Recognition (OCR).\nAlthough smoothly curved deformations have been widely investigated by many\nworks, the most challenging distortions, e.g. complex creases and large\nfoldings, have not been studied in particular. The performance of existing\napproaches, when applied to largely creased or folded documents, is far from\nsatisfying, leaving substantial room for improvement. To tackle this task,\nknowledge about document rectification should be incorporated into the\ncomputation, among which the developability of 3D document models and\nparticular textural features in the images, such as straight lines, are the\nmost essential ones. For this purpose, we propose a general framework of\ndocument image rectification in which a computational isometric mapping model\nis utilized for expressing a 3D document model and its flattening in the plane.\nBased on this framework, both model developability and textural features are\nconsidered in the computation. The experiments and comparisons to the\nstate-of-the-art approaches demonstrated the effectiveness and outstanding\nperformance of the proposed method. Our method is also flexible in that the\nrectification results can be enhanced by any other methods that extract\nhigh-quality feature lines in the images.",
    "descriptor": "\nComments: 23 pages,17 figures\n",
    "authors": [
      "Dong Luo",
      "Pengbo Bo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2212.08365"
  },
  {
    "id": "arXiv:2212.08369",
    "title": "Temporal Variation Measure Analysis: An Improved Second-Order Difference  Plot",
    "abstract": "In this study, an improved second-order difference plot is proposed to\nanalyze the variability of heart rate variability. Although the variation of\nphysiological status of cardiovascular system can be shown graphically by the\nsecond-order difference plot, the descriptive ability of existing indicators\nfor this plot is insufficient. As a result, the physiological information\ncontained in the second-order difference plot cannot be extracted adequately.\nAddressing the problem, the temporal variation measure analysis is presented to\ndescribe distribution patterns of scatter points in the second-order difference\nplot quantitatively and extract the acceleration information for variation of\nheart rate variability. Experiment results demonstrate the effectiveness of the\ntemporal variation measure analysis. As a quantitative indicator, the temporal\nvariation entropy is properly designed and successfully applied in the\nrecognition and classification of the physiological statuses of the heart.",
    "descriptor": "",
    "authors": [
      "Chen Diao",
      "Ning Cai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08369"
  },
  {
    "id": "arXiv:2212.08370",
    "title": "Shapley variable importance cloud for machine learning models",
    "abstract": "Current practice in interpretable machine learning often focuses on\nexplaining the final model trained from data, e.g., by using the Shapley\nadditive explanations (SHAP) method. The recently developed Shapley variable\nimportance cloud (ShapleyVIC) extends the current practice to a group of\n\"nearly optimal models\" to provide comprehensive and robust variable importance\nassessments, with estimated uncertainty intervals for a more complete\nunderstanding of variable contributions to predictions. ShapleyVIC was\ninitially developed for applications with traditional regression models, and\nthe benefits of ShapleyVIC inference have been demonstrated in real-life\nprediction tasks using the logistic regression model. However, as a\nmodel-agnostic approach, ShapleyVIC application is not limited to such\nscenarios. In this work, we extend ShapleyVIC implementation for machine\nlearning models to enable wider applications, and propose it as a useful\ncomplement to the current SHAP analysis to enable more trustworthy applications\nof these black-box models.",
    "descriptor": "",
    "authors": [
      "Yilin Ning",
      "Mingxuan Liu",
      "Nan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08370"
  },
  {
    "id": "arXiv:2212.08371",
    "title": "Generalizing Reduction-Based Algebraic Multigrid",
    "abstract": "Algebraic Multigrid (AMG) methods are often robust and effective solvers for\nsolving the large and sparse linear systems that arise from discretized PDEs\nand other problems, relying on heuristic graph algorithms to achieve their\nperformance. Reduction-based AMG (AMGr) algorithms attempt to formalize these\nheuristics by providing two-level convergence bounds that depend concretely on\nproperties of the partitioning of the given matrix into its fine- and\ncoarse-grid degrees of freedom. MacLachlan and Saad (SISC 2007) proved that the\nAMGr method yields provably robust two-level convergence for symmetric and\npositive-definite matrices that are diagonally dominant, with a convergence\nfactor bounded as a function of a coarsening parameter. However, when applying\nAMGr algorithms to matrices that are not diagonally dominant, not only do the\nconvergence factor bounds not hold, but measured performance is notably\ndegraded. Here, we present modifications to the classical AMGr algorithm that\nimprove its performance on matrices that are not diagonally dominant, making\nuse of strength of connection, sparse approximate inverse (SPAI) techniques,\nand interpolation truncation and rescaling, to improve robustness while\nmaintaining control of the algorithmic costs. We present numerical results\ndemonstrating the robustness of this approach for both classical isotropic\ndiffusion problems and for non-diagonally dominant systems coming from\nanisotropic diffusion.",
    "descriptor": "",
    "authors": [
      "Tareq Zaman",
      "Nicolas Nytko",
      "Ali Taghibakhshi",
      "Scott MacLachlan",
      "Luke Olson",
      "Matthew West"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.08371"
  },
  {
    "id": "arXiv:2212.08377",
    "title": "PointAvatar: Deformable Point-based Head Avatars from Videos",
    "abstract": "The ability to create realistic, animatable and relightable head avatars from\ncasual video sequences would open up wide ranging applications in communication\nand entertainment. Current methods either build on explicit 3D morphable meshes\n(3DMM) or exploit neural implicit representations. The former are limited by\nfixed topology, while the latter are non-trivial to deform and inefficient to\nrender. Furthermore, existing approaches entangle lighting in the color\nestimation, thus they are limited in re-rendering the avatar in new\nenvironments. In contrast, we propose PointAvatar, a deformable point-based\nrepresentation that disentangles the source color into intrinsic albedo and\nnormal-dependent shading. We demonstrate that PointAvatar bridges the gap\nbetween existing mesh- and implicit representations, combining high-quality\ngeometry and appearance with topological flexibility, ease of deformation and\nrendering efficiency. We show that our method is able to generate animatable 3D\navatars using monocular videos from multiple sources including hand-held\nsmartphones, laptop webcams and internet videos, achieving state-of-the-art\nquality in challenging cases where previous methods fail, e.g., thin hair\nstrands, while being significantly more efficient in training than competing\nmethods.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yufeng Zheng",
      "Wang Yifan",
      "Gordon Wetzstein",
      "Michael J. Black",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2212.08377"
  },
  {
    "id": "arXiv:2212.08378",
    "title": "Feature Dropout: Revisiting the Role of Augmentations in Contrastive  Learning",
    "abstract": "What role do augmentations play in contrastive learning? Recent work suggests\nthat good augmentations are label-preserving with respect to a specific\ndownstream task. We complicate this picture by showing that label-destroying\naugmentations can be useful in the foundation model setting, where the goal is\nto learn diverse, general-purpose representations for multiple downstream\ntasks. We perform contrastive learning experiments on a range of image and\naudio datasets with multiple downstream tasks (e.g. for digits superimposed on\nphotographs, predicting the class of one vs. the other). We find that Viewmaker\nNetworks, a recently proposed model for learning augmentations for contrastive\nlearning, produce label-destroying augmentations that stochastically destroy\nfeatures needed for different downstream tasks. These augmentations are\ninterpretable (e.g. altering shapes, digits, or letters added to images) and\nsurprisingly often result in better performance compared to expert-designed\naugmentations, despite not preserving label information. To support our\nempirical results, we theoretically analyze a simple contrastive learning\nsetting with a linear model. In this setting, label-destroying augmentations\nare crucial for preventing one set of features from suppressing the learning of\nfeatures useful for another downstream task. Our results highlight the need for\nanalyzing the interaction between multiple downstream tasks when trying to\nexplain the success of foundation models.",
    "descriptor": "",
    "authors": [
      "Alex Tamkin",
      "Margalit Glasgow",
      "Xiluo He",
      "Noah Goodman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.08378"
  },
  {
    "id": "arXiv:2212.08379",
    "title": "GeneFormer: Learned Gene Compression using Transformer-based Context  Modeling",
    "abstract": "With the development of gene sequencing technology, an explosive growth of\ngene data has been witnessed. And the storage of gene data has become an\nimportant issue. Traditional gene data compression methods rely on general\nsoftware like G-zip, which fails to utilize the interrelation of nucleotide\nsequence. Recently, many researchers begin to investigate deep learning based\ngene data compression method. In this paper, we propose a transformer-based\ngene compression method named GeneFormer. Specifically, we first introduce a\nmodified transformer structure to fully explore the nucleotide sequence\ndependency. Then, we propose fixed-length parallel grouping to accelerate the\ndecoding speed of our autoregressive model. Experimental results on real-world\ndatasets show that our method saves 29.7% bit rate compared with the\nstate-of-the-art method, and the decoding speed is significantly faster than\nall existing learning-based gene compression methods.",
    "descriptor": "",
    "authors": [
      "Zhanbei Cui",
      "Yu Liao",
      "Tongda Xu",
      "Yan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2212.08379"
  },
  {
    "id": "arXiv:2212.08380",
    "title": "Instance-specific Label Distribution Regularization for Learning with  Label Noise",
    "abstract": "Modeling noise transition matrix is a kind of promising method for learning\nwith label noise. Based on the estimated noise transition matrix and the noisy\nposterior probabilities, the clean posterior probabilities, which are jointly\ncalled Label Distribution (LD) in this paper, can be calculated as the\nsupervision. To reliably estimate the noise transition matrix, some methods\nassume that anchor points are available during training. Nonetheless, if anchor\npoints are invalid, the noise transition matrix might be poorly learned,\nresulting in poor performance. Consequently, other methods treat reliable data\npoints, extracted from training data, as pseudo anchor points. However, from a\nstatistical point of view, the noise transition matrix can be inferred from\ndata with noisy labels under the clean-label-domination assumption. Therefore,\nwe aim to estimate the noise transition matrix without (pseudo) anchor points.\nThere is evidence showing that samples are more likely to be mislabeled as\nother similar class labels, which means the mislabeling probability is highly\ncorrelated with the inter-class correlation. Inspired by this observation, we\npropose an instance-specific Label Distribution Regularization (LDR), in which\nthe instance-specific LD is estimated as the supervision, to prevent DCNNs from\nmemorizing noisy labels. Specifically, we estimate the noisy posterior under\nthe supervision of noisy labels, and approximate the batch-level noise\ntransition matrix by estimating the inter-class correlation matrix with neither\nanchor points nor pseudo anchor points. Experimental results on two synthetic\nnoisy datasets and two real-world noisy datasets demonstrate that our LDR\noutperforms existing methods.",
    "descriptor": "",
    "authors": [
      "Zehui Liao",
      "Shishuai Hu",
      "Yutong Xie",
      "Yong Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08380"
  },
  {
    "id": "arXiv:2212.08384",
    "title": "Fast-moving object counting with an event camera",
    "abstract": "This paper proposes the use of an event camera as a component of a vision\nsystem that enables counting of fast-moving objects - in this case, falling\ncorn grains. These type of cameras transmit information about the change in\nbrightness of individual pixels and are characterised by low latency, no motion\nblur, correct operation in different lighting conditions, as well as very low\npower consumption. The proposed counting algorithm processes events in real\ntime. The operation of the solution was demonstrated on a stand consisting of a\nchute with a vibrating feeder, which allowed the number of grains falling to be\nadjusted. The objective of the control system with a PID controller was to\nmaintain a constant average number of falling objects. The proposed solution\nwas subjected to a series of tests to determine the correctness of the\ndeveloped method operation. On their basis, the validity of using an event\ncamera to count small, fast-moving objects and the associated wide range of\npotential industrial applications can be confirmed.",
    "descriptor": "\nComments: Paper accepted for the Automation 2023 (7-9 March 2023, Warsaw, Poland) conference and PAR journal (original manuscript in Polish)\n",
    "authors": [
      "Kamil Bialik",
      "Marcin Kowalczyk",
      "Krzysztof Blachut",
      "Tomasz Kryjak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08384"
  },
  {
    "id": "arXiv:2212.08385",
    "title": "Search Budget in Multi-Objective Refactoring Optimization: a Model-Based  Empirical Study",
    "abstract": "Software model optimization is the task of automatically generate design\nalternatives, usually to improve quality aspects of software that are\nquantifiable, like performance and reliability. In this context,\nmulti-objective optimization techniques have been applied to help the designer\nfind suitable trade-offs among several non-functional properties. In this\nprocess, design alternatives can be generated through automated model\nrefactoring, and evaluated on non-functional models. Due to their complexity,\nthis type of optimization tasks require considerable time and resources, often\nlimiting their application in software engineering processes.\nIn this paper, we investigate the effects of using a search budget,\nspecifically a time limit, to the search for new solutions. We performed\nexperiments to quantify the impact that a change in the search budget may have\non the quality of solutions. Furthermore, we analyzed how different genetic\nalgorithms (i.e., NSGA-II, SPEA2, and PESA2) perform when imposing different\nbudgets. We experimented on two case studies of different size, complexity, and\ndomain.\nWe observed that imposing a search budget considerably deteriorates the\nquality of the generated solutions, but the specific algorithm we choose seems\nto play a crucial role. From our experiments, NSGA-II is the fastest algorithm,\nwhile PESA2 generates solutions with the highest quality. Differently, SPEA2 is\nthe slowest algorithm, and produces the solutions with the lowest quality.",
    "descriptor": "\nComments: 8 pages, 4 figures, and 3 tables -- 48th Euromicro Conference Series on Software Engineering and Advanced Applications - MDEML track\n",
    "authors": [
      "Daniele Di Pompeo",
      "Michele Tucci"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.08385"
  },
  {
    "id": "arXiv:2212.08387",
    "title": "Traffic sign detection and recognition using event camera image  reconstruction",
    "abstract": "This paper presents a method for detection and recognition of traffic signs\nbased on information extracted from an event camera. The solution used a\nFireNet deep convolutional neural network to reconstruct events into greyscale\nframes. Two YOLOv4 network models were trained, one based on greyscale images\nand the other on colour images. The best result was achieved for the model\ntrained on the basis of greyscale images, achieving an efficiency of 87.03%.",
    "descriptor": "\nComments: Paper accepted for publication in: Zeszyty Studenckiego Towarzystwa Naukowego, 59. Hutnicza Konferencja Studenckich Kol Naukowych AGH,ISSN 1732-0925, 2022 nr 38, pp. 127-134. (original manuscript in Polish)\n",
    "authors": [
      "Kamil Jeziorek",
      "Tomasz Kryjak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.08387"
  },
  {
    "id": "arXiv:2212.08388",
    "title": "Homonymy Information for English WordNet",
    "abstract": "A widely acknowledged shortcoming of WordNet is that it lacks a distinction\nbetween word meanings which are systematically related (polysemy), and those\nwhich are coincidental (homonymy). Several previous works have attempted to\nfill this gap, by inferring this information using computational methods. We\nrevisit this task, and exploit recent advances in language modelling to\nsynthesise homonymy annotation for Princeton WordNet. Previous approaches treat\nthe problem using clustering methods; by contrast, our method works by linking\nWordNet to the Oxford English Dictionary, which contains the information we\nneed. To perform this alignment, we pair definitions based on their proximity\nin an embedding space produced by a Transformer model. Despite the simplicity\nof this approach, our best model attains an F1 of .97 on an evaluation set that\nwe annotate. The outcome of our work is a high-quality homonymy annotation\nlayer for Princeton WordNet, which we release.",
    "descriptor": "",
    "authors": [
      "Rowan Hall Maudslay",
      "Simone Teufel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08388"
  },
  {
    "id": "arXiv:2212.08389",
    "title": "A certified wavelet-based physics-informed neural network for the  solution of parameterized partial differential equations",
    "abstract": "Physics Informed Neural Networks (PINNs) have frequently been used for the\nnumerical approximation of Partial Differential Equations (PDEs). The goal of\nthis paper is to construct PINNs along with a computable upper bound of the\nerror, which is particularly relevant for model reduction of Parameterized PDEs\n(PPDEs). To this end, we suggest to use a weighted sum of expansion\ncoefficients of the residual in terms of an adaptive wavelet expansion both for\nthe loss function and an error bound.\nThis approach is shown here for elliptic PPDEs using both the standard\nvariational and an optimally stable ultra-weak formulation. Numerical examples\nshow a very good quantitative effectivity of the wavelet-based error bound.",
    "descriptor": "",
    "authors": [
      "Lewin Ernst",
      "Karsten Urban"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.08389"
  },
  {
    "id": "arXiv:2212.08390",
    "title": "Lessons learned from the evaluation of Spanish Language Models",
    "abstract": "Given the impact of language models on the field of Natural Language\nProcessing, a number of Spanish encoder-only masked language models (aka BERTs)\nhave been trained and released. These models were developed either within large\nprojects using very large private corpora or by means of smaller scale academic\nefforts leveraging freely available data. In this paper we present a\ncomprehensive head-to-head comparison of language models for Spanish with the\nfollowing results: (i) Previously ignored multilingual models from large\ncompanies fare better than monolingual models, substantially changing the\nevaluation landscape of language models in Spanish; (ii) Results across the\nmonolingual models are not conclusive, with supposedly smaller and inferior\nmodels performing competitively. Based on these empirical results, we argue for\nthe need of more research to understand the factors underlying them. In this\nsense, the effect of corpus size, quality and pre-training techniques need to\nbe further investigated to be able to obtain Spanish monolingual models\nsignificantly better than the multilingual ones released by large private\ncompanies, specially in the face of rapid ongoing progress in the field. The\nrecent activity in the development of language technology for Spanish is to be\nwelcomed, but our results show that building language models remains an open,\nresource-heavy problem which requires to marry resources (monetary and/or\ncomputational) with the best research expertise and practice.",
    "descriptor": "\nComments: 10 pages, three tables\n",
    "authors": [
      "Rodrigo Agerri",
      "Eneko Agirre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08390"
  },
  {
    "id": "arXiv:2212.08395",
    "title": "Metaphorical Polysemy Detection: Conventional Metaphor meets Word Sense  Disambiguation",
    "abstract": "Linguists distinguish between novel and conventional metaphor, a distinction\nwhich the metaphor detection task in NLP does not take into account. Instead,\nmetaphoricity is formulated as a property of a token in a sentence, regardless\nof metaphor type. In this paper, we investigate the limitations of treating\nconventional metaphors in this way, and advocate for an alternative which we\nname 'metaphorical polysemy detection' (MPD). In MPD, only conventional\nmetaphoricity is treated, and it is formulated as a property of word senses in\na lexicon. We develop the first MPD model, which learns to identify\nconventional metaphors in the English WordNet. To train it, we present a novel\ntraining procedure that combines metaphor detection with word sense\ndisambiguation (WSD). For evaluation, we manually annotate metaphor in two\nsubsets of WordNet. Our model significantly outperforms a strong baseline based\non a state-of-the-art metaphor detection model, attaining an ROC-AUC score of\n.78 (compared to .65) on one of the sets. Additionally, when paired with a WSD\nmodel, our approach outperforms a state-of-the-art metaphor detection model at\nidentifying conventional metaphors in text (.659 F1 compared to .626).",
    "descriptor": "",
    "authors": [
      "Rowan Hall Maudslay",
      "Simone Teufel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08395"
  },
  {
    "id": "arXiv:2212.08396",
    "title": "\"We are a startup to the core\": A qualitative interview study on the  security and privacy development practices in Turkish software startups",
    "abstract": "Security and privacy are often neglected in software development, and rarely\na priority for developers. This insight is commonly based on research conducted\nby researchers and on developer populations living and working in the United\nStates, Europe, and the United Kingdom. However, the production of software is\nglobal, and crucial populations in important technology hubs are not adequately\nstudied. The software startup scene in Turkey is impactful, and comprehension,\nknowledge, and mitigations related to software security and privacy remain\nunderstudied. To close this research gap, we conducted a semi-structured\ninterview study with 16 developers working in Turkish software startups. The\ngoal of the interview study was to analyze if and how developers ensure that\ntheir software is secure and preserves user privacy. Our main finding is that\ndevelopers rarely prioritize security and privacy, due to a lack of awareness,\nskills, and resources. We find that regulations can make a positive impact on\nsecurity and privacy. Based on the study, we issue recommendations for\nindustry, individual developers, research, educators, and regulators. Our\nrecommendations can inform a more globalized approach to security and privacy\nin software development.",
    "descriptor": "\nComments: In Proceedings of the 44th IEEE Symposium on Security and Privacy (IEEESP'23)\n",
    "authors": [
      "Dilara Kek\u00fcll\u00fco\u011flu",
      "Yasemin Acar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.08396"
  },
  {
    "id": "arXiv:2212.08397",
    "title": "Criticality of $AC^0$ formulae",
    "abstract": "Rossman [In \\emph{Proc.\\ $34$th Comput.\\ Complexity Conf.}, 2019] introduced\nthe notion of \\emph{criticality}. The criticality of a Boolean function $f\n\\colon \\zo^n \\to \\zo$ is the minimum $\\lambda \\geq 1$ such that for all\npositive integers $t$, \\[ \\Pr_{\\brho \\sim\n\\calR_p}\\left[\\DT_{\\depth}(f|_{\\brho}) \\geq t\\right] \\leq (p\\lambda)^t. \\]\n\\hastad's celebrated switching lemma shows that the criticality of any $k$-DNF\nis at most $O(k)$. Subsequent improvements to correlation bounds of\n$\\AC^0$-circuits against parity showed that the criticality of any\n$\\AC^0$-\\emph{circuit} of size $S$ and depth $d+1$ is at most $O(\\log S)^d$ and\nany \\emph{regular} $\\AC^0$-\\emph{formula} of size $S$ and depth $d+1$ is at\nmost $O(\\frac1d \\cdot \\log S)^d$. We strengthen these results by showing that\nthe criticality of \\emph{any} $\\AC^0$-formula (not necessarily regular) of size\n$S$ and depth $d+1$ is at most $O(\\frac{\\log S}{d})^d$, resolving a conjecture\ndue to Rossman.\nThis result also implies Rossman's optimal lower bound on the size of any\ndepth-$d$ $\\AC^0$-formula computing parity [Comput.\\ Complexity,\n27(2):209--223, 2018.]. Our result implies tight correlation bounds against\nparity, tight Fourier concentration results and improved \\#SAT algorithm for\n$\\AC^0$-formulae.",
    "descriptor": "",
    "authors": [
      "Prahladh Harsha",
      "Tulasi mohan Molli",
      "Ashutosh Shankar"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2212.08397"
  },
  {
    "id": "arXiv:2212.08398",
    "title": "Structure-preserving discretizations of two-phase Navier-Stokes flow  using fitted and unfitted approaches",
    "abstract": "We consider the numerical approximation of a sharp-interface model for\ntwo-phase flow, which is given by the incompressible Navier-Stokes equations in\nthe bulk domain together with the classical interface conditions on the\ninterface. We propose structure-preserving finite element methods for the\nmodel, meaning in particular that volume preservation and energy decay are\nsatisfied on the discrete level. For the evolving fluid interface, we employ\nparametric finite element approximations that introduce an implicit tangential\nvelocity to improve the quality of the interface mesh. For the two-phase\nNavier-Stokes equations, we consider two different approaches: an unfitted and\na fitted finite element method, respectively. In the unfitted approach, the\nconstructed method is based on an Eulerian weak formulation, while in the\nfitted approach a novel arbitrary Lagrangian-Eulerian (ALE) weak formulation is\nintroduced. Using suitable discretizations of these two formulations, we\nintroduce two finite element methods and prove their structure-preserving\nproperties. Numerical results are presented to show the accuracy and efficiency\nof the introduced methods.",
    "descriptor": "",
    "authors": [
      "Harald Garcke",
      "Robert N\u00fcrnberg",
      "Quan Zhao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.08398"
  },
  {
    "id": "arXiv:2212.08399",
    "title": "Reducing Sequence Length Learning Impacts on Transformer Models",
    "abstract": "Classification algorithms using Transformer architectures can be affected by\nthe sequence length learning problem whenever observations from different\nclasses have a different length distribution. This problem brings models to use\nsequence length as a predictive feature instead of relying on important textual\ninformation. Even if most public datasets are not affected by this problem,\nprivately corpora for fields such as medicine and insurance may carry this data\nbias. This poses challenges throughout the value chain given their usage in a\nmachine learning application. In this paper, we empirically expose this problem\nand present approaches to minimize its impacts.",
    "descriptor": "\nComments: 10 pages, 8 content - 2 appendix, 2 figures\n",
    "authors": [
      "Jean-Thomas Baillargeon",
      "Luc Lamontagne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08399"
  },
  {
    "id": "arXiv:2212.08401",
    "title": "Near-Field Wideband Channel Estimation for Extremely Large-Scale MIMO",
    "abstract": "Extremely large-scale multiple-input-multiple-output (XL-MIMO) at\nmillimeter-wave (mmWave) and terahertz (THz) bands plays an important role in\nsupporting extreme high beamforming gain as well as ultra-wideband spectrum\nresources. Unfortunately, accurate wideband XL-MIMO channel estimation suffers\nfrom the new challenge called as the near-field beam split effect. Prior works\neither neglect the accurate near-field channel model or fail to exploit the\nbeam split effect, resulting in poor channel estimation accuracy for wideband\nXL-MIMO. To tackle this problem, this paper proposes a bilinear pattern\ndetection (BPD) based approach to accurately recover the wideband XL-MIMO\nchannel. Specifically, by analyzing the characteristics of near-field wideband\nchannels, we first reveal the bilinear pattern of the near-field beam split\neffect, which implies that the sparse support set of near-field channels in\nboth the angle and the distance domains can be regarded as a linear function\nagainst frequency. Then, inspired by the classical simultaneously orthogonal\nmatching pursuit technique, we use the bilinear pattern to estimate the\nangle-of-arrival (AoA) and distance parameters of each near-field path\ncomponent at all frequencies. In this way, the entire wideband XL-MIMO channel\ncan be recovered by compressed sensing algorithms. Moreover, we provide the\ncomputational complexity of the proposed algorithm compared with existing\nalgorithms. Finally, simulation results demonstrate that our scheme can achieve\nthe accurate estimation of the near-field wideband XL-MIMO channel in the\npresence of near-field beam split effect.",
    "descriptor": "\nComments: This paper has been accepted by Science China Information Sciences. Simulation codes will be provided to reproduce the results in this paper: this http URL\n",
    "authors": [
      "Mingyao Cui",
      "Linglong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.08401"
  },
  {
    "id": "arXiv:2212.08403",
    "title": "LiFe-net: Data-driven Modelling of Time-dependent Temperatures and  Charging Statistics Of Tesla's LiFePo4 EV Battery",
    "abstract": "Modelling the temperature of Electric Vehicle (EV) batteries is a fundamental\ntask of EV manufacturing. Extreme temperatures in the battery packs can affect\ntheir longevity and power output. Although theoretical models exist for\ndescribing heat transfer in battery packs, they are computationally expensive\nto simulate. Furthermore, it is difficult to acquire data measurements from\nwithin the battery cell. In this work, we propose a data-driven surrogate model\n(LiFe-net) that uses readily accessible driving diagnostics for battery\ntemperature estimation to overcome these limitations. This model incorporates\nNeural Operators with a traditional numerical integration scheme to estimate\nthe temperature evolution. Moreover, we propose two further variations of the\nbaseline model: LiFe-net trained with a regulariser and LiFe-net trained with\ntime stability loss. We compared these models in terms of generalization error\non test data. The results showed that LiFe-net trained with time stability loss\noutperforms the other two models and can estimate the temperature evolution on\nunseen data with a relative error of 2.77 % on average.",
    "descriptor": "",
    "authors": [
      "Jeyhun Rustamov",
      "Luisa Fennert",
      "Nico Hoffmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08403"
  },
  {
    "id": "arXiv:2212.08405",
    "title": "Exponentially Stable Adaptive Observation without System Representation  in Observable Form",
    "abstract": "The method to design exponentially stable adaptive observers is proposed for\nlinear time-invariant not necessarily observable, but detectable systems with\nunknown parameters. Unlike existing adaptive solutions, the system state-space\nmatrices A, B are not restricted to be represented in the observer canonical\nform to implement the observer. The original system description is used\ninstead, and, consequently, the original state vector is obtained. The class of\nsystems for which the method is applicable is identified via three assumptions\nrelated to: (i) the identifiability of the unique parameters of A and B from\nthe characteristic polynomials of output transfer function and the fact that we\nknow mappings (ii) from such polynomials parameters to unique parameters of A\nand B and (iii) from them to Luenberger correction gain. In case they are met\nand the regressor is finitely exciting, the proposed adaptive observer, which\nis based on the known GPEBO and DREM procedures, ensures exponential\nconvergence of both system parameters and states estimates to their true\nvalues. Detailed analysis for stability and convergence has been provided along\nwith simulation results to validate the developed theory.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Anton Glushchenko",
      "Konstantin Lastochkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08405"
  },
  {
    "id": "arXiv:2212.08407",
    "title": "Utilizing distilBert transformer model for sentiment classification of  COVID-19's Persian open-text responses",
    "abstract": "The COVID-19 pandemic has caused drastic alternations in human life in all\naspects. The government's laws in this regard affected the lifestyle of all\npeople. Due to this fact studying the sentiment of individuals is essential to\nbe aware of the future impacts of the coming pandemics. To contribute to this\naim, we proposed an NLP (Natural Language Processing) model to analyze\nopen-text answers in a survey in Persian and detect positive and negative\nfeelings of the people in Iran. In this study, a distilBert transformer model\nwas applied to take on this task. We deployed three approaches to perform the\ncomparison, and our best model could gain accuracy: 0.824, Precision: 0.824,\nRecall: 0.798, and F1 score: 0.804.",
    "descriptor": "\nComments: The paper is accepted at The 7th International Conference on Science and Technology of Electrical, Computer, and Mechanical Engineering of Iran\n",
    "authors": [
      "Fatemeh Sadat Masoumi",
      "Mohammad Bahrani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.08407"
  },
  {
    "id": "arXiv:2212.08408",
    "title": "Decoder Tuning: Efficient Language Understanding as Decoding",
    "abstract": "With the evergrowing sizes of pre-trained models (PTMs), it has been an\nemerging practice to only provide the inference APIs for users, namely\nmodel-as-a-service (MaaS) setting. To adapt PTMs with model parameters frozen,\nmost current approaches focus on the input side, seeking for powerful prompts\nto stimulate models for correct answers. However, we argue that input-side\nadaptation could be arduous due to the lack of gradient signals and they\nusually require thousands of API queries, resulting in high computation and\ntime costs. In light of this, we present Decoder Tuning (DecT), which in\ncontrast optimizes task-specific decoder networks on the output side.\nSpecifically, DecT first extracts prompt-stimulated output scores for initial\npredictions. On top of that, we train an additional decoder network on the\noutput representations to incorporate posterior data knowledge. By\ngradient-based optimization, DecT can be trained within several seconds and\nrequires only one PTM query per sample. Empirically, we conduct extensive\nnatural language understanding experiments and show that DecT significantly\noutperforms state-of-the-art algorithms with a $10^3\\times$ speed-up.",
    "descriptor": "\nComments: Work in progress. 13 pages\n",
    "authors": [
      "Ganqu Cui",
      "Wentao Li",
      "Ning Ding",
      "Longtao Huang",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08408"
  },
  {
    "id": "arXiv:2212.08410",
    "title": "Teaching Small Language Models to Reason",
    "abstract": "Chain of thought prompting successfully improves the reasoning capabilities\nof large language models, achieving state of the art results on a range of\ndatasets. However, these reasoning capabilities only appear to emerge in models\nwith a size of over 100 billion parameters. In this paper, we explore the\ntransfer of such reasoning capabilities to models with less than 100 billion\nparameters via knowledge distillation. Specifically, we finetune a student\nmodel on the chain of thought outputs generated by a larger teacher model. Our\nexperiments show that the proposed method improves task performance across\narithmetic, commonsense and symbolic reasoning datasets. For example, the\naccuracy of T5 XXL on GSM8K improves from 8.11% to 21.99% when finetuned on\nPaLM-540B generated chains of thought.",
    "descriptor": "",
    "authors": [
      "Lucie Charlotte Magister",
      "Jonathan Mallinson",
      "Jakub Adamek",
      "Eric Malmi",
      "Aliaksei Severyn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08410"
  },
  {
    "id": "arXiv:2212.08414",
    "title": "Deep Learning Methods for Calibrated Photometric Stereo and Beyond: A  Survey",
    "abstract": "Photometric stereo recovers the surface normals of an object from multiple\nimages with varying shading cues, i.e., modeling the relationship between\nsurface orientation and intensity at each pixel. Photometric stereo prevails in\nsuperior per-pixel resolution and fine reconstruction details. However, it is a\ncomplicated problem because of the non-linear relationship caused by\nnon-Lambertian surface reflectance. Recently, various deep learning methods\nhave shown a powerful ability in the context of photometric stereo against\nnon-Lambertian surfaces. This paper provides a comprehensive review of existing\ndeep learning-based calibrated photometric stereo methods. We first analyze\nthese methods from different perspectives, including input processing,\nsupervision, and network architecture. We summarize the performance of deep\nlearning photometric stereo models on the most widely-used benchmark data set.\nThis demonstrates the advanced performance of deep learning-based photometric\nstereo methods. Finally, we give suggestions and propose future research trends\nbased on the limitations of existing models.",
    "descriptor": "\nComments: 16 pages, 10 figures, 4 tables\n",
    "authors": [
      "Yakun Ju",
      "Kin-Man Lam",
      "Wuyuan Xie",
      "Huiyu Zhou",
      "Junyu Dong",
      "Boxin Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08414"
  },
  {
    "id": "arXiv:2212.08415",
    "title": "Person Detection Using an Ultra Low-resolution Thermal Imager on a  Low-cost MCU",
    "abstract": "Detecting persons in images or video with neural networks is a well-studied\nsubject in literature. However, such works usually assume the availability of a\ncamera of decent resolution and a high-performance processor or GPU to run the\ndetection algorithm, which significantly increases the cost of a complete\ndetection system. However, many applications require low-cost solutions,\ncomposed of cheap sensors and simple microcontrollers. In this paper, we\ndemonstrate that even on such hardware we are not condemned to simple classic\nimage processing techniques. We propose a novel ultra-lightweight CNN-based\nperson detector that processes thermal video from a low-cost 32x24 pixel static\nimager. Trained and compressed on our own recorded dataset, our model achieves\nup to 91.62% accuracy (F1-score), has less than 10k parameters, and runs as\nfast as 87ms and 46ms on low-cost microcontrollers STM32F407 and STM32F746,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Maarten Vandersteegen",
      "Wouter Reusen",
      "Kristof Van Beeck",
      "Toon Goedem\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08415"
  },
  {
    "id": "arXiv:2212.08416",
    "title": "Methods and Tools for the Management of Renewable Energy Communities:  the ComER project",
    "abstract": "Renewable Energy Communities (RECs) have been officially introduced into the\nEuropean legislation through the Clean Energy for all Europeans package. A REC\nis defined as an association of citizens, commercial activities, enterprises,\nand local authorities that own small-scale power plants based on Renewable\nEnergy Sources (RESs). The community has the objective of maximizing the share\nof renewable energy, i.e. the self-consumption of the energy generated by the\ncommunity RES power plants and to generally optimize the use of electrical\nenergy. This paper describes the ComER project, developed by the University of\nCassino and the Campus Bio-Medico University of Rome. The project focuses on\nthe main technical problems to face for the realization of a REC. The principal\nobjective is to develop methods and tools necessary for the management and\ncontrol of RECs. In particular, this paper describes the rules established for\nRECs in the Italian legislations, the organization of the ComER project, the\nadopted solutions and the first obtained results.",
    "descriptor": "",
    "authors": [
      "Anna Rita Di Fazio",
      "Arturo Losi",
      "Mario Russo",
      "Filippo Cacace",
      "Francesco Conte",
      "Giulio Iannello",
      "Gianluca Natrella",
      "Matteo Saviozzi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08416"
  },
  {
    "id": "arXiv:2212.08418",
    "title": "rWiFiSLAM: Effective WiFi Ranging based SLAM System in Ambient  Environments",
    "abstract": "In this paper, we propose rWiFiSLAM, an indoor localisation system based on\nWiFi ranging measurements. Indoor localisation techniques play an important\nrole in mobile robots when they cannot access good quality GPS signals in\nindoor environments. Indoor localisation also has many other applications, such\nas rescue, smart buildings, etc. Inertial Measurement Units (IMU) have been\nused for Pedestrian Dead Reckoning (PDR) to provide localisation services in\nthe indoor environment as it does not rely on any other signals. Although PDR\nis a promising technique, it still suffers from unavoidable noise and bias from\nIMUs in mobile devices. Loop closure is necessary for these scenarios. In this\npaper, we design an efficient loop closure mechanism based on WiFi ranging\nmeasurements along with IMU measurements in a robust pose graph SLAM framework\nfor indoor localisation. One novelty of the proposed method is that we remove\nthe requirement of the full knowledge of the WiFi access point locations, which\nmakes our proposed method feasible for new and/or dynamic environments. We\nevaluate our designed system in real environments and show the proposed method\ncan achieve sub-meter localisation accuracy and improve the localisation\nperformance by more than 90\\% compared with the IMU based PDR.",
    "descriptor": "",
    "authors": [
      "Bo Wei",
      "Mingcen Gao",
      "Chengwen Luo",
      "Sen Wang",
      "Jin Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.08418"
  },
  {
    "id": "arXiv:2212.08420",
    "title": "Fake it till you make it: Learning(s) from a synthetic ImageNet clone",
    "abstract": "Recent large-scale image generation models such as Stable Diffusion have\nexhibited an impressive ability to generate fairly realistic images starting\nfrom a very simple text prompt. Could such models render real images obsolete\nfor training image prediction models? In this paper, we answer part of this\nprovocative question by questioning the need for real images when training\nmodels for ImageNet classification. More precisely, provided only with the\nclass names that have been used to build the dataset, we explore the ability of\nStable Diffusion to generate synthetic clones of ImageNet and measure how\nuseful they are for training classification models from scratch. We show that\nwith minimal and class-agnostic prompt engineering those ImageNet clones we\ndenote as ImageNet-SD are able to close a large part of the gap between models\nproduced by synthetic images and models trained with real images for the\nseveral standard classification benchmarks that we consider in this study. More\nimportantly, we show that models trained on synthetic images exhibit strong\ngeneralization properties and perform on par with models trained on real data.",
    "descriptor": "",
    "authors": [
      "Mert Bulent Sariyildiz",
      "Karteek Alahari",
      "Diane Larlus",
      "Yannis Kalantidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08420"
  },
  {
    "id": "arXiv:2212.08423",
    "title": "Context Label Learning: Improving Background Class Representations in  Semantic Segmentation",
    "abstract": "Background samples provide key contextual information for segmenting regions\nof interest (ROIs). However, they always cover a diverse set of structures,\ncausing difficulties for the segmentation model to learn good decision\nboundaries with high sensitivity and precision. The issue concerns the highly\nheterogeneous nature of the background class, resulting in multi-modal\ndistributions. Empirically, we find that neural networks trained with\nheterogeneous background struggle to map the corresponding contextual samples\nto compact clusters in feature space. As a result, the distribution over\nbackground logit activations may shift across the decision boundary, leading to\nsystematic over-segmentation across different datasets and tasks. In this\nstudy, we propose context label learning (CoLab) to improve the context\nrepresentations by decomposing the background class into several subclasses.\nSpecifically, we train an auxiliary network as a task generator, along with the\nprimary segmentation model, to automatically generate context labels that\npositively affect the ROI segmentation accuracy. Extensive experiments are\nconducted on several challenging segmentation tasks and datasets. The results\ndemonstrate that CoLab can guide the segmentation model to map the logits of\nbackground samples away from the decision boundary, resulting in significantly\nimproved segmentation accuracy. Code is available.",
    "descriptor": "\nComments: Provisionally accepted to IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Zeju Li",
      "Konstantinos Kamnitsas",
      "Cheng Ouyang",
      "Chen Chen",
      "Ben Glocker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08423"
  },
  {
    "id": "arXiv:2212.08424",
    "title": "Weakly weighted generalised quasi-metric spaces and semilattices",
    "abstract": "Motivated by recent applications to entropy theory in dynamical systems, we\ngeneralise notions introduced by Matthews and define weakly weighted and\ncomponentwisely weakly weighted (generalised) quasi-metrics. We then\nsystematise and extend to full generality the correspondences between these\nobjects and other structures arising in theoretical computer science and\ndynamics. In particular, we study the correspondences with weak partial\nmetrics, and, if the underlying space is a semilattice, with invariant\n(generalised) quasi-metrics satisfying the descending path condition, and with\nstrictly monotone semi(-co-)valuations. We conclude discussing, for\nendomorphisms of generalised quasi-metric semilattices, a generalisation of\nboth the known intrinsic semilattice entropy and the semigroup entropy.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Ilaria Castellano",
      "Anna Giordano Bruno",
      "Nicol\u00f2 Zava"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Dynamical Systems (math.DS)",
      "General Topology (math.GN)"
    ],
    "url": "https://arxiv.org/abs/2212.08424"
  },
  {
    "id": "arXiv:2212.08427",
    "title": "WebAssembly Diversification for Malware Evasion",
    "abstract": "WebAssembly is a binary format that has become an essential component of the\nweb nowadays. Providing a faster alternative to JavaScript in the browser, this\nnew technology has been embraced from its early days to create cryptomalware.\nThis has triggered a solid effort to propose defenses that can detect\nWebAssembly malware. Yet, no defensive work has assumed that attackers would\nuse evasion techniques. In this paper, we study how to evade WebAssembly\ncryptomalware detectors. We propose a novel evasion technique based on a\nstate-of-the-art WebAssembly binary diversifier. We use the worldwide\nauthoritative VirusTotal as malware detector to evaluate our technique. Our\nresults demonstrate that it is possible to automatically generate variants of\nWebAssembly cryptomalware, which evade the considered strong detector.\nRemarkably, the variants introduce limited performance overhead. Our\nexperiments also provide novel insights about which WebAssembly code\ntransformations are the best suited for malware evasion. This provides insights\nfor the community to improve the state of the art of WebAssembly malware\ndetection.",
    "descriptor": "",
    "authors": [
      "Javier Cabrera-Arteaga",
      "Martin Monperrus",
      "Tim Toady",
      "Benoit Baudry"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.08427"
  },
  {
    "id": "arXiv:2212.08445",
    "title": "Conditional Generative Adversarial Network for keystroke presentation  attack",
    "abstract": "Cybersecurity is a crucial step in data protection to ensure user security\nand personal data privacy. In this sense, many companies have started to\ncontrol and restrict access to their data using authentication systems.\nHowever, these traditional authentication methods, are not enough for ensuring\ndata protection, and for this reason, behavioral biometrics have gained\nimportance. Despite their promising results and the wide range of applications,\nbiometric systems have shown to be vulnerable to malicious attacks, such as\nPresentation Attacks. For this reason, in this work, we propose to study a new\napproach aiming to deploy a presentation attack towards a keystroke\nauthentication system. Our idea is to use Conditional Generative Adversarial\nNetworks (cGAN) for generating synthetic keystroke data that can be used for\nimpersonating an authorized user. These synthetic data are generated following\ntwo different real use cases, one in which the order of the typed words is\nknown (ordered dynamic) and the other in which this order is unknown\n(no-ordered dynamic). Finally, both keystroke dynamics (ordered and no-ordered)\nare validated using an external keystroke authentication system. Results\nindicate that the cGAN can effectively generate keystroke dynamics patterns\nthat can be used for deceiving keystroke authentication systems.",
    "descriptor": "",
    "authors": [
      "Idoia Eizaguirre-Peral",
      "Lander Segurola-Gil",
      "Francesco Zola"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08445"
  },
  {
    "id": "arXiv:2212.08448",
    "title": "From Xception to NEXcepTion: New Design Decisions and Neural  Architecture Search",
    "abstract": "In this paper, we present a modified Xception architecture, the NEXcepTion\nnetwork. Our network has significantly better performance than the original\nXception, achieving top-1 accuracy of 81.5% on the ImageNet validation dataset\n(an improvement of 2.5%) as well as a 28% higher throughput. Another variant of\nour model, NEXcepTion-TP, reaches 81.8% top-1 accuracy, similar to ConvNeXt\n(82.1%), while having a 27% higher throughput. Our model is the result of\napplying improved training procedures and new design decisions combined with an\napplication of Neural Architecture Search (NAS) on a smaller dataset. These\nfindings call for revisiting older architectures and reassessing their\npotential when combined with the latest enhancements.",
    "descriptor": "\nComments: Accepted at ICPRAM 2023\n",
    "authors": [
      "Hadar Shavit",
      "Filip Jatelnicki",
      "Pol Mor-Puigvent\u00f3s",
      "Wojtek Kowalczyk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08448"
  },
  {
    "id": "arXiv:2212.08450",
    "title": "Comparing Approaches to Distributed Control of Fluid Systems based on  Multi-Agent Systems",
    "abstract": "Conventional control of fluid systems does not consider system-wide knowledge\nfor optimising energy efficient operation. Distributed control of fluid systems\ncombines reliable local control of components while using system-wide\ncooperation to ensure energy efficient operation. The presented work compares\nthree approaches to distributed control based on multi-agent systems,\ndistributed model predictive control (DMPC), multi-agent deep reinforcement\nlearning (MADRL) and market mechanism design. These approaches were applied to\na generic fluid system and evaluated with regard to functionality, energy\nefficient operation, modeling effort, reliability in the face of disruptions,\nand transparency of control decisions. All approaches were shown to fulfil the\nfunctionality, though a trade-off between functional quality and energy\nefficiency was identified. Increased modeling effort was shown to improve the\nperformance slightly while a strong interdependence of information caused by\nexcessive information sharing has proven to be disadvantageous. DMPC and\npartially observable MADRL were less sensitive to disruptions than market\nmechanism. In conclusion, agent-based control of fluid systems achieves greater\nenergy efficiency than conventional methods, with values similar to centralized\noptimal control and thus represent a viable design approach of fluid system\ncontrol.",
    "descriptor": "\nComments: 42 pages, 10 figures\n",
    "authors": [
      "Kevin T. Logan",
      "J. Marius St\u00fcrmer",
      "Tim M. M\u00fcller",
      "Peter F. Pelz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.08450"
  },
  {
    "id": "arXiv:2212.08458",
    "title": "Fast Rule-Based Decoding: Revisiting Syntactic Rules in Neural  Constituency Parsing",
    "abstract": "Most recent studies on neural constituency parsing focus on encoder\nstructures, while few developments are devoted to decoders. Previous research\nhas demonstrated that probabilistic statistical methods based on syntactic\nrules are particularly effective in constituency parsing, whereas syntactic\nrules are not used during the training of neural models in prior work probably\ndue to their enormous computation requirements. In this paper, we first\nimplement a fast CKY decoding procedure harnessing GPU acceleration, based on\nwhich we further derive a syntactic rule-based (rule-constrained) CKY decoding.\nIn the experiments, our method obtains 95.89 and 92.52 F1 on the datasets of\nPTB and CTB respectively, which shows significant improvements compared with\nprevious approaches. Besides, our parser achieves strong and competitive\ncross-domain performance in zero-shot settings.",
    "descriptor": "",
    "authors": [
      "Tianyu Shi",
      "Zhicheng Wang",
      "Liyin Xiao",
      "Cong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08458"
  },
  {
    "id": "arXiv:2212.08459",
    "title": "Experiments on Generalizability of BERTopic on Multi-Domain Short Text",
    "abstract": "Topic modeling is widely used for analytically evaluating large collections\nof textual data. One of the most popular topic techniques is Latent Dirichlet\nAllocation (LDA), which is flexible and adaptive, but not optimal for e.g.\nshort texts from various domains. We explore how the state-of-the-art BERTopic\nalgorithm performs on short multi-domain text and find that it generalizes\nbetter than LDA in terms of topic coherence and diversity. We further analyze\nthe performance of the HDBSCAN clustering algorithm utilized by BERTopic and\nfind that it classifies a majority of the documents as outliers. This crucial,\nyet overseen problem excludes too many documents from further analysis. When we\nreplace HDBSCAN with k-Means, we achieve similar performance, but without\noutliers.",
    "descriptor": "\nComments: Accepted poster presentation at WiNLP 2022, as a part of EMNLP 2022, 2 pages\n",
    "authors": [
      "Muri\u00ebl de Groot",
      "Mohammad Aliannejadi",
      "Marcel R. Haas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08459"
  },
  {
    "id": "arXiv:2212.08464",
    "title": "Free-form 3D Scene Inpainting with Dual-stream GAN",
    "abstract": "Nowadays, the need for user editing in a 3D scene has rapidly increased due\nto the development of AR and VR technology. However, the existing 3D scene\ncompletion task (and datasets) cannot suit the need because the missing regions\nin scenes are generated by the sensor limitation or object occlusion. Thus, we\npresent a novel task named free-form 3D scene inpainting. Unlike scenes in\nprevious 3D completion datasets preserving most of the main structures and\nhints of detailed shapes around missing regions, the proposed inpainting\ndataset, FF-Matterport, contains large and diverse missing regions formed by\nour free-form 3D mask generation algorithm that can mimic human drawing\ntrajectories in 3D space. Moreover, prior 3D completion methods cannot perform\nwell on this challenging yet practical task, simply interpolating nearby\ngeometry and color context. Thus, a tailored dual-stream GAN method is\nproposed. First, our dual-stream generator, fusing both geometry and color\ninformation, produces distinct semantic boundaries and solves the interpolation\nissue. To further enhance the details, our lightweight dual-stream\ndiscriminator regularizes the geometry and color edges of the predicted scenes\nto be realistic and sharp. We conducted experiments with the proposed\nFF-Matterport dataset. Qualitative and quantitative results validate the\nsuperiority of our approach over existing scene completion methods and the\nefficacy of all proposed components.",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Ru-Fen Jheng",
      "Tsung-Han Wu",
      "Jia-Fong Yeh",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08464"
  },
  {
    "id": "arXiv:2212.08472",
    "title": "One-Stage Cascade Refinement Networks for Infrared Small Target  Detection",
    "abstract": "Single-frame InfraRed Small Target (SIRST) detection has been a challenging\ntask due to a lack of inherent characteristics, imprecise bounding box\nregression, a scarcity of real-world datasets, and sensitive localization\nevaluation. In this paper, we propose a comprehensive solution to these\nchallenges. First, we find that the existing anchor-free label assignment\nmethod is prone to mislabeling small targets as background, leading to their\nomission by detectors. To overcome this issue, we propose an all-scale\npseudo-box-based label assignment scheme that relaxes the constraints on scale\nand decouples the spatial assignment from the size of the ground-truth target.\nSecond, motivated by the structured prior of feature pyramids, we introduce the\none-stage cascade refinement network (OSCAR), which uses the high-level head as\nsoft proposals for the low-level refinement head. This allows OSCAR to process\nthe same target in a cascade coarse-to-fine manner. Finally, we present a new\nresearch benchmark for infrared small target detection, consisting of the\nSIRST-V2 dataset of real-world, high-resolution single-frame targets, the\nnormalized contrast evaluation metric, and the DeepInfrared toolkit for\ndetection. We conduct extensive ablation studies to evaluate the components of\nOSCAR and compare its performance to state-of-the-art model-driven and\ndata-driven methods on the SIRST-V2 benchmark. Our results demonstrate that a\ntop-down cascade refinement framework can improve the accuracy of infrared\nsmall target detection without sacrificing efficiency. The DeepInfrared\ntoolkit, dataset, and trained models are available at\nhttps://github.com/YimianDai/open-deepinfrared to advance further research in\nthis field.",
    "descriptor": "\nComments: Submitted to TGRS, Major Revision\n",
    "authors": [
      "Yimian Dai",
      "Xiang Li",
      "Fei Zhou",
      "Yulei Qian",
      "Yaohong Chen",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08472"
  },
  {
    "id": "arXiv:2212.08475",
    "title": "Best-Answer Prediction in Q&A Sites Using User Information",
    "abstract": "Community Question Answering (CQA) sites have spread and multiplied\nsignificantly in recent years. Sites like Reddit, Quora, and Stack Exchange are\nbecoming popular amongst people interested in finding answers to diverse\nquestions. One practical way of finding such answers is automatically\npredicting the best candidate given existing answers and comments. Many studies\nwere conducted on answer prediction in CQA but with limited focus on using the\nbackground information of the questionnaires. We address this limitation using\na novel method for predicting the best answers using the questioner's\nbackground information and other features, such as the textual content or the\nrelationships with other participants. Our answer classification model was\ntrained using the Stack Exchange dataset and validated using the Area Under the\nCurve (AUC) metric. The experimental results show that the proposed method\ncomplements previous methods by pointing out the importance of the\nrelationships between users, particularly throughout the level of involvement\nin different communities on Stack Exchange. Furthermore, we point out that\nthere is little overlap between user-relation information and the information\nrepresented by the shallow text features and the meta-features, such as time\ndifferences.",
    "descriptor": "\nComments: 22 pages, 3 figures, 4 tables\n",
    "authors": [
      "Rafik Hadfi",
      "Ahmed Moustafa",
      "Kai Yoshino",
      "Takayuki Ito"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.08475"
  },
  {
    "id": "arXiv:2212.08476",
    "title": "SteerNeRF: Accelerating NeRF Rendering via Smooth Viewpoint Trajectory",
    "abstract": "Neural Radiance Fields (NeRF) have demonstrated superior novel view synthesis\nperformance but are slow at rendering. To speed up the volume rendering\nprocess, many acceleration methods have been proposed at the cost of large\nmemory consumption. To push the frontier of the efficiency-memory trade-off, we\nexplore a new perspective to accelerate NeRF rendering, leveraging a key fact\nthat the viewpoint change is usually smooth and continuous in interactive\nviewpoint control. This allows us to leverage the information of preceding\nviewpoints to reduce the number of rendered pixels as well as the number of\nsampled points along the ray of the remaining pixels. In our pipeline, a\nlow-resolution feature map is rendered first by volume rendering, then a\nlightweight 2D neural renderer is applied to generate the output image at\ntarget resolution leveraging the features of preceding and current frames. We\nshow that the proposed method can achieve competitive rendering quality while\nreducing the rendering time with little memory overhead, enabling 30FPS at\n1080P image resolution with a low memory footprint.",
    "descriptor": "",
    "authors": [
      "Sicheng Li",
      "Hao Li",
      "Yue Wang",
      "Yiyi Liao",
      "Lu Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2212.08476"
  },
  {
    "id": "arXiv:2212.08481",
    "title": "Neural Network Augmented Compartmental Pandemic Models",
    "abstract": "Compartmental models are a tool commonly used in epidemiology for the\nmathematical modelling of the spread of infectious diseases, with their most\npopular representative being the Susceptible-Infected-Removed (SIR) model and\nits derivatives. However, current SIR models are bounded in their capabilities\nto model government policies in the form of non-pharmaceutical interventions\n(NPIs) and weather effects and offer limited predictive power. More capable\nalternatives such as agent based models (ABMs) are computationally expensive\nand require specialized hardware. We introduce a neural network augmented SIR\nmodel that can be run on commodity hardware, takes NPIs and weather effects\ninto account and offers improved predictive power as well as counterfactual\nanalysis capabilities. We demonstrate our models improvement of the\nstate-of-the-art modeling COVID-19 in Austria during the 03.2020 to 03.2021\nperiod and provide an outlook for the future up to 01.2024.",
    "descriptor": "\nComments: 13 pages, 19 figures\n",
    "authors": [
      "Lorenz Kummer",
      "Kevin Sidak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2212.08481"
  },
  {
    "id": "arXiv:2212.08482",
    "title": "Implementation of general formal translators",
    "abstract": "The general translator formalism and computing specific implementations are\nproposed. The implementation of specific elements necessary to process the\nsource and destination information within the translators are presented. Some\ncommon directives or instructions, such as classes and procedures, were unified\nand generalized in order to allow general translations implementations. In\norder to cover general cases, two levels of processing are required, related to\nthe source and destination information appropriate transformations, with the\nrelated control and processing instructions. The proposed general translator\nelements are useful for processing natural or artificial information described\nthrough any types of languages or systems.",
    "descriptor": "",
    "authors": [
      "Iosif Iulian Petrila"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Programming Languages (cs.PL)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2212.08482"
  },
  {
    "id": "arXiv:2212.08484",
    "title": "Emergent communication enhances foraging behaviour in evolved swarms  controlled by Spiking Neural Networks",
    "abstract": "Social insects such as ants communicate via pheromones which allows them to\ncoordinate their activity and solve complex tasks as a swarm, e.g. foraging for\nfood. This behaviour was shaped through evolutionary processes. In\ncomputational models, self-coordination in swarms has been implemented using\nprobabilistic or action rules to shape the decision of each agent and the\ncollective behaviour. However, manual tuned decision rules may limit the\nbehaviour of the swarm. In this work we investigate the emergence of\nself-coordination and communication in evolved swarms without defining any\nrule. We evolve a swarm of agents representing an ant colony. We use a genetic\nalgorithm to optimize a spiking neural network (SNN) which serves as an\nartificial brain to control the behaviour of each agent. The goal of the colony\nis to find optimal ways to forage for food in the shortest amount of time. In\nthe evolutionary phase, the ants are able to learn to collaborate by depositing\npheromone near food piles and near the nest to guide its cohorts. The pheromone\nusage is not encoded into the network; instead, this behaviour is established\nthrough the optimization procedure. We observe that pheromone-based\ncommunication enables the ants to perform better in comparison to colonies\nwhere communication did not emerge. We assess the foraging performance by\ncomparing the SNN based model to a rule based system. Our results show that the\nSNN based model can complete the foraging task more efficiently in a shorter\ntime. Our approach illustrates that even in the absence of pre-defined rules,\nself coordination via pheromone emerges as a result of the network\noptimization. This work serves as a proof of concept for the possibility of\ncreating complex applications utilizing SNNs as underlying architectures for\nmulti-agent interactions where communication and self-coordination is desired.",
    "descriptor": "\nComments: 18, pages, 8 figures\n",
    "authors": [
      "Cristian Jimenez Romero",
      "Alper Yegenoglu",
      "Aar\u00f3n P\u00e9rez Mart\u00edn",
      "Sandra Diaz-Pier",
      "Abigail Morrison"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2212.08484"
  },
  {
    "id": "arXiv:2212.08486",
    "title": "BLASER: A Text-Free Speech-to-Speech Translation Evaluation Metric",
    "abstract": "End-to-End speech-to-speech translation (S2ST) is generally evaluated with\ntext-based metrics. This means that generated speech has to be automatically\ntranscribed, making the evaluation dependent on the availability and quality of\nautomatic speech recognition (ASR) systems. In this paper, we propose a\ntext-free evaluation metric for end-to-end S2ST, named BLASER, to avoid the\ndependency on ASR systems. BLASER leverages a multilingual multimodal encoder\nto directly encode the speech segments for source input, translation output and\nreference into a shared embedding space and computes a score of the translation\nquality that can be used as a proxy to human evaluation. To evaluate our\napproach, we construct training and evaluation sets from more than 40k human\nannotations covering seven language directions. The best results of BLASER are\nachieved by training with supervision from human rating scores. We show that\nwhen evaluated at the sentence level, BLASER correlates significantly better\nwith human judgment compared to ASR-dependent metrics including ASR-SENTBLEU in\nall translation directions and ASR-COMET in five of them. Our analysis shows\ncombining speech and text as inputs to BLASER does not increase the correlation\nwith human scores, but best correlations are achieved when using speech, which\nmotivates the goal of our research. Moreover, we show that using ASR for\nreferences is detrimental for text-based metrics.",
    "descriptor": "",
    "authors": [
      "Mingda Chen",
      "Paul-Ambroise Duquenne",
      "Pierre Andrews",
      "Justine Kao",
      "Alexandre Mourachko",
      "Holger Schwenk",
      "Marta R. Costa-juss\u00e0"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08486"
  },
  {
    "id": "arXiv:2212.08487",
    "title": "Semantics-Empowered Communication: A Tutorial-cum-Survey",
    "abstract": "Along with the springing up of semantics-empowered communication research\nspanning from theories, applications, metrics to implementation, it is now\nwitnessing an unprecedented growing interest in both academia and industry. In\nthis work, we primarily aim to provide a comprehensive survey on both the\nbackground and research taxonomy, as well as a detailed technical tutorial for\npotential participants. Specifically, we start by reviewing the literature and\nanswering the \"what\" and \"why\" questions in semantic transmissions. Afterwards,\nwe present corresponding ecosystems, including theories, metrics, datasets and\ntoolkits, on top of which the taxonomy for macro research directions is\npresented. Furthermore, we propose to categorize the critical enabling\ntechniques by explicit and implicit reasoning-based methods, and elaborate on\nhow they evolve and contribute to modern content & channel semantics-empowered\ncommunications. Besides reviewing and summarizing the latest efforts in\nsemantics-empowered communications, we discuss the relations with other\ncommunication levels (e.g., reliable and goal-oriented communications) from a\nholistic and unified viewpoint. Subsequently, in order to facilitate the future\ndevelopments and industrial applications, we also highlight advanced practical\ntechniques for boosting semantic accuracy, robustness, and large-scale\nscalability, just to mention a few. Finally, we discuss the technical\nchallenges that shed light on future research opportunities. Considering the\ngrowing yet the ever-updating status of semantics-empowered communications, we\nhope this work would benefit not only sophisticated but also intended\npractitioners.",
    "descriptor": "",
    "authors": [
      "Zhilin Lu",
      "Rongpeng Li",
      "Kun Lu",
      "Xianfu Chen",
      "Ekram Hossain",
      "Zhifeng Zhao",
      "Honggang Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.08487"
  },
  {
    "id": "arXiv:2212.08489",
    "title": "Effectiveness of Text, Acoustic, and Lattice-based representations in  Spoken Language Understanding tasks",
    "abstract": "In this paper, we perform an exhaustive evaluation of different\nrepresentations to address the intent classification problem in a Spoken\nLanguage Understanding (SLU) setup. We benchmark three types of systems to\nperform the SLU intent detection task: 1) text-based, 2) lattice-based, and a\nnovel 3) multimodal approach. Our work provides a comprehensive analysis of\nwhat could be the achievable performance of different state-of-the-art SLU\nsystems under different circumstances, e.g., automatically- vs.\nmanually-generated transcripts. We evaluate the systems on the publicly\navailable SLURP spoken language resource corpus. Our results indicate that\nusing richer forms of Automatic Speech Recognition (ASR) outputs allows SLU\nsystems to improve in comparison to the 1-best setup (4% relative improvement).\nHowever, crossmodal approaches, i.e., learning from acoustic and text\nembeddings, obtains performance similar to the oracle setup, and a relative\nimprovement of 18% over the 1-best configuration. Thus, crossmodal\narchitectures represent a good alternative to overcome the limitations of\nworking purely automatically generated textual data.",
    "descriptor": "\nComments: Submitted to ICASSP 2023 (Under review)\n",
    "authors": [
      "Esa\u00fa Villatoro-Tello",
      "Srikanth Madikeri",
      "Juan Zuluaga-Gomez",
      "Bidisha Sharma",
      "Seyyed Saeed Sarfjoo",
      "Iuliia Nigmatulina",
      "Petr Motlicek",
      "Alexei V. Ivanov",
      "Aravind Ganapathiraju"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.08489"
  },
  {
    "id": "arXiv:2212.08490",
    "title": "LEDCNet: A Lightweight and Efficient Semantic Segmentation Algorithm  Using Dual Context Module for Extracting Ground Objects from UAV Aerial  Remote Sensing Images",
    "abstract": "Semantic segmentation of UAV aerial remote sensing images provides a more\nefficient and convenient surveying and mapping method for traditional surveying\nand mapping. In order to make the model lightweight and improve a certain\naccuracy, this research developed a new lightweight and efficient network for\nthe extraction of ground features from UAV aerial remote sensing images, called\nLDMCNet. Meanwhile, this research develops a powerful lightweight backbone\nnetwork for the proposed semantic segmentation model. It is called LDCNet, and\nit is hoped that it can become the backbone network of a new generation of\nlightweight semantic segmentation algorithms. The proposed model uses dual\nmulti-scale context modules, namely the Atrous Space Pyramid Pooling module\n(ASPP) and the Object Context Representation module (OCR). In addition, this\nresearch constructs a private dataset for semantic segmentation of aerial\nremote sensing images from drones. This data set contains 2431 training sets,\n945 validation sets, and 475 test sets. The proposed model performs well on\nthis dataset, with only 1.4M parameters and 5.48G floating-point operations\n(FLOPs), achieving an average intersection-over-union ratio (mIoU) of 71.12%.\n7.88% higher than the baseline model. In order to verify the effectiveness of\nthe proposed model, training on the public datasets \"LoveDA\" and \"CITY-OSM\"\nalso achieved excellent results, achieving mIoU of 65.27% and 74.39%,\nrespectively.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Xiaoxiang Han",
      "Yiman Liu",
      "Gang Liu",
      "Qiaohong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08490"
  },
  {
    "id": "arXiv:2212.08495",
    "title": "Adaptive Tracking Control of Uncertain Euler-Lagrange Systems with State  and Input Constraints",
    "abstract": "This paper proposes a novel control architecture for state and input\nconstrained Euler-Lagrange (E-L) systems with parametric uncertainties. A\nsimple saturated controller is strategically coupled with a Barrier Lyapunov\nFunction (BLF) based controller to ensure state and input constraint\nsatisfaction. To the best of the authors' knowledge, this is the first result\nfor E-L systems that guarantee asymptotic tracking with user-specified state\nand input constraints. The proposed controller also ensures that all the\nclosed-loop signals remain bounded. The efficacy of the proposed controller in\nterms of constraint satisfaction and tracking performance is verified using\nsimulation on a robot manipulator system.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2206.13084\n",
    "authors": [
      "Poulomee Ghosh",
      "Shubhendu Bhasin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08495"
  },
  {
    "id": "arXiv:2212.08496",
    "title": "Federated Learning with Flexible Control",
    "abstract": "Federated learning (FL) enables distributed model training from local data\ncollected by users. In distributed systems with constrained resources and\npotentially high dynamics, e.g., mobile edge networks, the efficiency of FL is\nan important problem. Existing works have separately considered different\nconfigurations to make FL more efficient, such as infrequent transmission of\nmodel updates, client subsampling, and compression of update vectors. However,\nan important open problem is how to jointly apply and tune these control knobs\nin a single FL algorithm, to achieve the best performance by allowing a high\ndegree of freedom in control decisions. In this paper, we address this problem\nand propose FlexFL - an FL algorithm with multiple options that can be adjusted\nflexibly. Our FlexFL algorithm allows both arbitrary rates of local computation\nat clients and arbitrary amounts of communication between clients and the\nserver, making both the computation and communication resource consumption\nadjustable. We prove a convergence upper bound of this algorithm. Based on this\nresult, we further propose a stochastic optimization formulation and algorithm\nto determine the control decisions that (approximately) minimize the\nconvergence bound, while conforming to constraints related to resource\nconsumption. The advantage of our approach is also verified using experiments.",
    "descriptor": "\nComments: Accepted to IEEE INFOCOM 2023\n",
    "authors": [
      "Shiqiang Wang",
      "Jake Perazzone",
      "Mingyue Ji",
      "Kevin S. Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.08496"
  },
  {
    "id": "arXiv:2212.08506",
    "title": "Weakly Supervised Video Anomaly Detection Based on Cross-Batch  Clustering Guidance",
    "abstract": "Weakly supervised video anomaly detection (WSVAD) is a challenging task since\nonly video-level labels are available for training. In previous studies, the\ndiscriminative power of the learned features is not strong enough, and the data\nimbalance resulting from the mini-batch training strategy is ignored. To\naddress these two issues, we propose a novel WSVAD method based on cross-batch\nclustering guidance. To enhance the discriminative power of features, we\npropose a batch clustering based loss to encourage a clustering branch to\ngenerate distinct normal and abnormal clusters based on a batch of data.\nMeanwhile, we design a cross-batch learning strategy by introducing clustering\nresults from previous mini-batches to reduce the impact of data imbalance. In\naddition, we propose to generate more accurate segment-level anomaly scores\nbased on batch clustering guidance further improving the performance of WSVAD.\nExtensive experiments on two public datasets demonstrate the effectiveness of\nour approach.",
    "descriptor": "",
    "authors": [
      "Congqi Cao",
      "Xin Zhang",
      "Shizhou Zhang",
      "Peng Wang",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08506"
  },
  {
    "id": "arXiv:2212.08507",
    "title": "Robust Explanation Constraints for Neural Networks",
    "abstract": "Post-hoc explanation methods are used with the intent of providing insights\nabout neural networks and are sometimes said to help engender trust in their\noutputs. However, popular explanations methods have been found to be fragile to\nminor perturbations of input features or model parameters. Relying on\nconstraint relaxation techniques from non-convex optimization, we develop a\nmethod that upper-bounds the largest change an adversary can make to a\ngradient-based explanation via bounded manipulation of either the input\nfeatures or model parameters. By propagating a compact input or parameter set\nas symbolic intervals through the forwards and backwards computations of the\nneural network we can formally certify the robustness of gradient-based\nexplanations. Our bounds are differentiable, hence we can incorporate provable\nexplanation robustness into neural network training. Empirically, our method\nsurpasses the robustness provided by previous heuristic approaches. We find\nthat our training method is the only method able to learn neural networks with\ncertificates of explanation robustness across all six datasets tested.",
    "descriptor": "\nComments: 23 pages, 12 figures\n",
    "authors": [
      "Matthew Wicker",
      "Juyeon Heo",
      "Luca Costabello",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08507"
  },
  {
    "id": "arXiv:2212.08511",
    "title": "Road Detection in Snowy Forest Environment using RGB Camera",
    "abstract": "Automated driving technology has gained a lot of momentum in the last few\nyears. For the exploration field, navigation is the important key for\nautonomous operation. In difficult scenarios such as snowy environment, the\nroad is covered with snow and road detection is impossible in this situation\nusing only basic techniques. This paper introduces detection of snowy road in\nforest environment using RGB camera. The method combines noise filtering\ntechnique with morphological operation to classify the image component. By\nusing the assumption that all road is covered by snow and the snow part is\ndefined as road area. From the perspective image of road, the vanishing point\nof road is one of factor to scope the region of road. This vanishing point is\nfound with fitting triangle technique. The performance of algorithm is\nevaluated by two error value: False Negative Rate and False Positive Rate. The\nerror shows that the method has high efficiency for detect road with straight\nroad but low performance for curved road. This road region will be applied with\ndepth information from camera to detect for obstacle in the future work.",
    "descriptor": "\nComments: 5 pages, 9 figures, conference proceeding\n",
    "authors": [
      "Sirawich Vachmanus",
      "Takanori Emaru",
      "Ankit A. Ravankar",
      "Yukinori Kobayashi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08511"
  },
  {
    "id": "arXiv:2212.08514",
    "title": "Check-worthy Claim Detection across Topics for Automated Fact-checking",
    "abstract": "An important component of an automated fact-checking system is the claim\ncheck-worthiness detection system, which ranks sentences by prioritising them\nbased on their need to be checked. Despite a body of research tackling the\ntask, previous research has overlooked the challenging nature of identifying\ncheck-worthy claims across different topics. In this paper, we assess and\nquantify the challenge of detecting check-worthy claims for new, unseen topics.\nAfter highlighting the problem, we propose the AraCWA model to mitigate the\nperformance deterioration when detecting check-worthy claims across topics. The\nAraCWA model enables boosting the performance for new topics by incorporating\ntwo components for few-shot learning and data augmentation. Using a publicly\navailable dataset of Arabic tweets consisting of 14 different topics, we\ndemonstrate that our proposed data augmentation strategy achieves substantial\nimprovements across topics overall, where the extent of the improvement varies\nacross topics. Further, we analyse the semantic similarities between topics,\nsuggesting that the similarity metric could be used as a proxy to determine the\ndifficulty level of an unseen topic prior to undertaking the task of labelling\nthe underlying sentences.",
    "descriptor": "",
    "authors": [
      "Amani S. Abumansour",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08514"
  },
  {
    "id": "arXiv:2212.08515",
    "title": "The Formal Theory of Monads, Univalently",
    "abstract": "We study the formal theory of monads, as developed by Street, in univalent\nfoundations. This allows us to formally reason about various kinds of monads on\nthe right level of abstraction. In particular, we define the bicategory of\nmonads internal to a bicategory, and prove its univalence. We also define\nEilenberg-Moore objects, and we show that both Eilenberg-Moore categories and\nKleisli categories give rise to Eilenberg-Moore objects. Finally, we relate\nmonads and adjunctions in arbitrary bicategories. Our work is formalized in Coq\nusing the UniMath library.",
    "descriptor": "",
    "authors": [
      "Niels van der Weide"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2212.08515"
  },
  {
    "id": "arXiv:2212.08522",
    "title": "Rewriting the Infinite Chase",
    "abstract": "Guarded tuple-generating dependencies (GTGDs) are a natural extension of\ndescription logics and referential constraints. It has long been known that\nqueries over GTGDs can be answered by a variant of the chase - a quintessential\ntechnique for reasoning with dependencies. However, there has been little work\non concrete algorithms and even less on implementation. To address this gap, we\nrevisit Datalog rewriting approaches to query answering, where GTGDs are\ntransformed to a Datalog program that entails the same base facts on each base\ninstance. We show that the rewriting can be seen as containing \"shortcut\" rules\nthat circumvent certain chase steps, we present several algorithms that compute\nthe rewriting by simulating specific types of chase steps, and we discuss\nimportant implementation issues. Finally, we show empirically that our\ntechniques can process complex GTGDs derived from synthetic and real benchmarks\nand are thus suitable for practical use.",
    "descriptor": "",
    "authors": [
      "Michael Benedikt",
      "Maxime Buron",
      "Stefano Germano",
      "Kevin Kappelmann",
      "Boris Motik"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.08522"
  },
  {
    "id": "arXiv:2212.08525",
    "title": "Resource-Interaction Graph: Efficient Graph Representation for Anomaly  Detection",
    "abstract": "Security research has concentrated on converting operating system audit logs\ninto suitable graphs, such as provenance graphs, for analysis. However,\nprovenance graphs can grow very large requiring significant computational\nresources beyond what is necessary for many security tasks and are not feasible\nfor resource constrained environments, such as edge devices. To address this\nproblem, we present the \\textit{resource-interaction graph} that is built\ndirectly from the audit log. We show that the resource-interaction graph's\nstorage requirements are significantly lower than provenance graphs using an\nopen-source data set with two container escape attacks captured from an edge\ndevice. We use a graph autoencoder and graph clustering technique to evaluate\nthe representation for an anomaly detection task. Both approaches are\nunsupervised and are thus suitable for detecting zero-day attacks. The\napproaches can achieve f1 scores typically over 80\\% and in some cases over\n90\\% for the selected data set and attacks.",
    "descriptor": "\nComments: 15 pages, 11 figures, 6 tables, for dataset see this https URL, for code see this https URL\n",
    "authors": [
      "James Pope",
      "Jinyuan Liang",
      "Vijay Kumar",
      "Francesco Raimondo",
      "Xinyi Sun",
      "Ryan McConville",
      "Thomas Pasquier",
      "Rob Piechocki",
      "George Oikonomou",
      "Bo Luo",
      "Dan Howarth",
      "Ioannis Mavromatis",
      "Adrian Sanchez Mompo",
      "Pietro Carnelli",
      "Theodoros Spyridopoulos",
      "Aftab Khan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08525"
  },
  {
    "id": "arXiv:2212.08526",
    "title": "Unifying Human Motion Synthesis and Style Transfer with Denoising  Diffusion Probabilistic Models",
    "abstract": "Generating realistic motions for digital humans is a core but challenging\npart of computer animations and games, as human motions are both diverse in\ncontent and rich in styles. While the latest deep learning approaches have made\nsignificant advancements in this domain, they mostly consider motion synthesis\nand style manipulation as two separate problems. This is mainly due to the\nchallenge of learning both motion contents that account for the inter-class\nbehaviour and styles that account for the intra-class behaviour effectively in\na common representation. To tackle this challenge, we propose a denoising\ndiffusion probabilistic model solution for styled motion synthesis. As\ndiffusion models have a high capacity brought by the injection of\nstochasticity, we can represent both inter-class motion content and intra-class\nstyle behaviour in the same latent. This results in an integrated, end-to-end\ntrained pipeline that facilitates the generation of optimal motion and\nexploration of content-style coupled latent space. To achieve high-quality\nresults, we design a multi-task architecture of diffusion model that\nstrategically generates aspects of human motions for local guidance. We also\ndesign adversarial and physical regulations for global guidance. We demonstrate\nsuperior performance with quantitative and qualitative results and validate the\neffectiveness of our multi-task architecture.",
    "descriptor": "",
    "authors": [
      "Ziyi Chang",
      "Edmund J. C. Findlay",
      "Haozheng Zhang",
      "Hubert P. H. Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2212.08526"
  },
  {
    "id": "arXiv:2212.08531",
    "title": "Learning and Extrapolation of Robotic Skills using Task-Parameterized  Equation Learner Networks",
    "abstract": "Imitation learning approaches achieve good generalization within the range of\nthe training data, but tend to generate unpredictable motions when querying\noutside this range. We present a novel approach to imitation learning with\nenhanced extrapolation capabilities that exploits the so-called Equation\nLearner Network (EQLN). Unlike conventional approaches, EQLNs use supervised\nlearning to fit a set of analytical expressions that allows them to extrapolate\nbeyond the range of the training data. We augment the task demonstrations with\na set of task-dependent parameters representing spatial properties of each\nmotion and use them to train the EQLN. At run time, the features are used to\nquery the Task-Parameterized Equation Learner Network (TP-EQLN) and generate\nthe corresponding robot trajectory. The set of features encodes kinematic\nconstraints of the task such as desired height or a final point to reach. We\nvalidate the results of our approach on manipulation tasks where it is\nimportant to preserve the shape of the motion in the extrapolation domain. Our\napproach is also compared with existing state-of-the-art approaches, in\nsimulation and in real setups. The experimental results show that TP-EQLN can\nrespect the constraints of the trajectory encoded in the feature parameters,\neven in the extrapolation domain, while preserving the overall shape of the\ntrajectory provided in the demonstrations.",
    "descriptor": "",
    "authors": [
      "Hector Villeda",
      "Justus Piater",
      "Matteo Saveriano"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.08531"
  },
  {
    "id": "arXiv:2212.08532",
    "title": "Do Not Trust a Model Because It is Confident: Uncovering and  Characterizing Unknown Unknowns to Student Success Predictors in Online-Based  Learning",
    "abstract": "Student success models might be prone to develop weak spots, i.e., examples\nhard to accurately classify due to insufficient representation during model\ncreation. This weakness is one of the main factors undermining users' trust,\nsince model predictions could for instance lead an instructor to not intervene\non a student in need. In this paper, we unveil the need of detecting and\ncharacterizing unknown unknowns in student success prediction in order to\nbetter understand when models may fail. Unknown unknowns include the students\nfor which the model is highly confident in its predictions, but is actually\nwrong. Therefore, we cannot solely rely on the model's confidence when\nevaluating the predictions quality. We first introduce a framework for the\nidentification and characterization of unknown unknowns. We then assess its\ninformativeness on log data collected from flipped courses and online courses\nusing quantitative analyses and interviews with instructors. Our results show\nthat unknown unknowns are a critical issue in this domain and that our\nframework can be applied to support their detection. The source code is\navailable at https://github.com/epfl-ml4ed/unknown-unknowns.",
    "descriptor": "\nComments: Accepted as a full paper at the International Conference on Learning Analytics & Knowledge (LAK23)\n",
    "authors": [
      "Roberta Galici",
      "Tanja K\u00e4ser",
      "Gianni Fenu",
      "Mirko Marras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.08532"
  },
  {
    "id": "arXiv:2212.08535",
    "title": "Design Considerations of a Coordinative Demand Charge Mitigation  Strategy",
    "abstract": "This paper presents a coordinative demand charge mitigation (DCM) strategy\nfor reducing electricity consumption during system peak periods. Available DCM\nresources include batteries, diesel generators, controllable loads, and\nconservation voltage reduction. All resources are directly controlled by load\nserving entities. A mixed integer linear programming based energy management\nalgorithm is developed to optimally coordinate of DCM resources considering the\nload payback effect. To better capture system peak periods, two different kinds\nof load forecast are used: the day-ahead load forecast and the peak-hour\nprobability forecast. Five DCM strategies are compared for reconciling the\ndiscrepancy between the two forecasting results. The DCM strategies are tested\nusing actual utility data. Simulation results show that the proposed algorithm\ncan effectively mitigate the demand charge while preventing the system peak\nfrom being shifted to the payback hours. We also identify the diminishing\nreturn effect, which can help load serving entities optimize the size of their\nDCM resources.",
    "descriptor": "\nComments: 5 pages, 2023 PESGM\n",
    "authors": [
      "Rongxing Hu",
      "Kai Ye",
      "Hyeonjin Kim",
      "Hanpyo Lee",
      "Ning Lu",
      "Di Wu",
      "PJ Rehm"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08535"
  },
  {
    "id": "arXiv:2212.08536",
    "title": "Detection-aware multi-object tracking evaluation",
    "abstract": "How would you fairly evaluate two multi-object tracking algorithms (i.e.\ntrackers), each one employing a different object detector? Detectors keep\nimproving, thus trackers can make less effort to estimate object states over\ntime. Is it then fair to compare a new tracker employing a new detector with\nanother tracker using an old detector? In this paper, we propose a novel\nperformance measure, named Tracking Effort Measure (TEM), to evaluate trackers\nthat use different detectors. TEM estimates the improvement that the tracker\ndoes with respect to its input data (i.e. detections) at frame level\n(intra-frame complexity) and sequence level (inter-frame complexity). We\nevaluate TEM over well-known datasets, four trackers and eight detection sets.\nResults show that, unlike conventional tracking evaluation measures, TEM can\nquantify the effort done by the tracker with a reduced correlation on the input\ndetections. Its implementation is publicly available online at\nhttps://github.com/vpulab/MOT-evaluation.",
    "descriptor": "\nComments: This paper was accepted at IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\n",
    "authors": [
      "Juan C. SanMiguel",
      "Jorge Mu\u00f1oz",
      "Fabio Poiesi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08536"
  },
  {
    "id": "arXiv:2212.08539",
    "title": "Predicting Autonomous Vehicle Collision Injury Severity Levels for  Ethical Decision Making and Path Planning",
    "abstract": "Developments in autonomous vehicles (AVs) are rapidly advancing and will in\nthe next 20 years become a central part to our society. However, especially in\nthe early stages of deployment, there is expected to be incidents involving\nAVs. In the event of AV incidents, decisions will need to be made that require\nethical decisions, e.g., deciding between colliding into a group of pedestrians\nor a rigid barrier. For an AV to undertake such ethical decision making and\npath planning, simulation models of the situation will be required that are\nused in real-time on-board the AV. These models will enable path planning and\nethical decision making to be undertaken based on predetermined collision\ninjury severity levels. In this research, models are developed for the path\nplanning and ethical decision making that predetermine knowledge regarding the\npossible collision injury severities, i.e., peak deformation of the AV\ncolliding into the rigid barrier or the impact velocity of the AV colliding\ninto a pedestrian. Based on such knowledge and using fuzzy logic, a novel\nnonlinear weighted utility cost function for the collision injury severity\nlevels is developed. This allows the model-based predicted collision outcomes\narising from AV peak deformation and AV-pedestrian impact velocity to be\nexamined separately via weighted utility cost functions with a common\nstructure. The general form of the weighted utility cost function exploits a\nfuzzy sets approach, thus allowing common utility costs from the two separate\nutility cost functions to be meaningfully compared. A decision-making\nalgorithm, which makes use of a utilitarian ethical approach, ensures that the\nAV will always steer onto the path which represents the lowest injury severity\nlevel, hence utility cost to society.",
    "descriptor": "",
    "authors": [
      "James E. Pickering",
      "Keith J. Burnham"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08539"
  },
  {
    "id": "arXiv:2212.08540",
    "title": "A Comprehensive Survey of Benchmarks for Automated Improvement of  Software's Non-Functional Properties",
    "abstract": "Performance is a key quality of modern software. Although recent years have\nseen a spike in research on automated improvement of software's execution time,\nenergy, memory consumption, etc., there is a noticeable lack of standard\nbenchmarks for such work. It is also unclear how such benchmarks are\nrepresentative of current software. Furthermore, frequently non-functional\nproperties of software are targeted for improvement one-at-a-time, neglecting\npotential negative impact on other properties.\nIn order to facilitate more research on automated improvement of\nnon-functional properties of software, we conducted a survey gathering\nbenchmarks used in previous work. We considered 5 major online repositories of\nsoftware engineering work: ACM Digital Library, IEEE Xplore, Scopus, Google\nScholar, and ArXiV. We gathered 5000 publications (3749 unique), which were\nsystematically reviewed to identify work that empirically improves\nnon-functional properties of software. We identified 386 relevant papers.\nWe find that execution time is the most frequently targeted property for\nimprovement (in 62% of relevant papers), while multi-objective improvement is\nrarely considered (5%). Static approaches are prevalent (in 53% of papers),\nwith exploratory approaches (evolutionary in 18% and non-evolutionary in 14% of\npapers) increasingly popular in the last 10 years. Only 40% of 386 papers\ndescribe work that uses benchmark suites, rather than single software, of those\nSPEC is most popular (covered in 33 papers). We also provide recommendations\nfor choice of benchmarks in future work, noting, e.g., lack of work that covers\nPython or JavaScript. We provide all programs found in the 386 papers on our\ndedicated webpage at https://bloa.github.io/nfunc_survey/\nWe hope that this effort will facilitate more research on the topic of\nautomated improvement of software's non-functional properties.",
    "descriptor": "\nComments: 43 pages, 18 figures\n",
    "authors": [
      "Aymeric Blot",
      "Justyna Petke"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.08540"
  },
  {
    "id": "arXiv:2212.08541",
    "title": "Learnable Commutative Monoids for Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) have been shown to be highly sensitive to the\nchoice of aggregation function. While summing over a node's neighbours can\napproximate any permutation-invariant function over discrete inputs,\nCohen-Karlik et al. [2020] proved there are set-aggregation problems for which\nsumming cannot generalise to unbounded inputs, proposing recurrent neural\nnetworks regularised towards permutation-invariance as a more expressive\naggregator. We show that these results carry over to the graph domain: GNNs\nequipped with recurrent aggregators are competitive with state-of-the-art\npermutation-invariant aggregators, on both synthetic benchmarks and real-world\nproblems. However, despite the benefits of recurrent aggregators, their $O(V)$\ndepth makes them both difficult to parallelise and harder to train on large\ngraphs. Inspired by the observation that a well-behaved aggregator for a GNN is\na commutative monoid over its latent space, we propose a framework for\nconstructing learnable, commutative, associative binary operators. And with\nthis, we construct an aggregator of $O(\\log V)$ depth, yielding exponential\nimprovements for both parallelism and dependency length while achieving\nperformance competitive with recurrent aggregators. Based on our empirical\nobservations, our proposed learnable commutative monoid (LCM) aggregator\nrepresents a favourable tradeoff between efficient and expressive aggregators.",
    "descriptor": "\nComments: Accepted to the proceedings of the First Learning on Graphs Conference (LoG 2022)\n",
    "authors": [
      "Euan Ong",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.08541"
  },
  {
    "id": "arXiv:2212.08545",
    "title": "Enriched finite element approach for modeling discontinuous electric  field in multimaterial problems",
    "abstract": "This work is devoted to the development of an efficient and robust technique\nfor accurate capturing of the electric field in multi-material problems. The\nformulation is based on the finite element method enriched by the introduction\nof hat-type shape function within the elements crossed by the material\ninterface. The peculiar feature of the proposed method consists in the direct\nemployment of the hat-function that requires solely one additional degree of\nfreedom per cut element for capturing the discontinuity in the electric\npotential gradient and, thus, the electric field. This additional degree of\nfreedom is subsequently statically condensed element-wise prior to the assembly\nof the global discrete system. As a consequence, the graph of the system matrix\nremains the same as that of the standard finite element method. In order to\nguarantee the robust performance of the proposed method for a wide range of\nelectrical material property ratios, it also accounts for the possible\ndiscontinuities among the neighboring cut elements that arise due to employing\nadditional degrees of freedom fully local to the element. The method is tested\nusing several examples solved on structured and unstructured grids. The\nproposed approach constitutes a basis for enriched FEM applicable to a wide\nrange of electromagnetic problems.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Christian Narv\u00e1ez-Mu\u00f1oz",
      "Mohammad R. Hashemi",
      "Pavel B. Ryzhakov",
      "Jordi Pons-Prats",
      "Herbert Owen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.08545"
  },
  {
    "id": "arXiv:2212.08550",
    "title": "Fine-grained Czech News Article Dataset: An Interdisciplinary Approach  to Trustworthiness Analysis",
    "abstract": "We present the Verifee Dataset: a novel dataset of news articles with\nfine-grained trustworthiness annotations. We develop a detailed methodology\nthat assesses the texts based on their parameters encompassing editorial\ntransparency, journalist conventions, and objective reporting while penalizing\nmanipulative techniques. We bring aboard a diverse set of researchers from\nsocial, media, and computer sciences to overcome barriers and limited framing\nof this interdisciplinary problem. We collect over $10,000$ unique articles\nfrom almost $60$ Czech online news sources. These are categorized into one of\nthe $4$ classes across the credibility spectrum we propose, raging from\nentirely trustworthy articles all the way to the manipulative ones. We produce\ndetailed statistics and study trends emerging throughout the set. Lastly, we\nfine-tune multiple popular sequence-to-sequence language models using our\ndataset on the trustworthiness classification task and report the best testing\nF-1 score of $0.52$. We open-source the dataset, annotation methodology, and\nannotators' instructions in full length at https://verifee.ai/research to\nenable easy build-up work. We believe similar methods can help prevent\ndisinformation and educate in the realm of media literacy.",
    "descriptor": "\nComments: 13 pages, 3 figures; to be published at the Second Workshop on Multimodal Fact-Checking and Hate Speech Detection (DEFACTIFY 2023) at the AAAI 2023 Conference, February 14, 2023, Washington, D.C\n",
    "authors": [
      "Maty\u00e1\u0161 Boh\u00e1\u010dek",
      "Michal Bravansk\u00fd",
      "Filip Trhl\u00edk",
      "V\u00e1clav Moravec"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08550"
  },
  {
    "id": "arXiv:2212.08553",
    "title": "Is it Required? Ranking the Skills Required for a Job-Title",
    "abstract": "In this paper, we describe our method for ranking the skills required for a\ngiven job title. Our analysis shows that important/relevant skills appear more\nfrequently in similar job titles. We train a Language-agnostic BERT Sentence\nEncoder (LaBSE) model to predict the importance of the skills using weak\nsupervision. We show the model can learn the importance of skills and perform\nwell in other languages. Furthermore, we show how the Inverse Document\nFrequency factor of skill boosts the specialised skills.",
    "descriptor": "",
    "authors": [
      "Sarthak Anand",
      "Jens-Joris Decorte",
      "Niels Lowie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08553"
  },
  {
    "id": "arXiv:2212.08558",
    "title": "Simulating Road Spray Effects in Automotive Lidar Sensor Models",
    "abstract": "Modeling perception sensors is key for simulation based testing of automated\ndriving functions. Beyond weather conditions themselves, sensors are also\nsubjected to object dependent environmental influences like tire spray caused\nby vehicles moving on wet pavement. In this work, a novel modeling approach for\nspray in lidar data is introduced. The model conforms to the Open Simulation\nInterface (OSI) standard and is based on the formation of detection clusters\nwithin a spray plume. The detections are rendered with a simple custom ray\ncasting algorithm without the need of a fluid dynamics simulation or physics\nengine. The model is subsequently used to generate training data for object\ndetection algorithms. It is shown that the model helps to improve detection in\nreal-world spray scenarios significantly. Furthermore, a systematic real-world\ndata set is recorded and published for analysis, model calibration and\nvalidation of spray effects in active perception sensors. Experiments are\nconducted on a test track by driving over artificially watered pavement with\nvarying vehicle speeds, vehicle types and levels of pavement wetness. All\nmodels and data of this work are available open source.",
    "descriptor": "\nComments: Submitted to IEEE Sensors Journal\n",
    "authors": [
      "Clemens Linnhoff",
      "Dominik Scheuble",
      "Mario Bijelic",
      "Lukas Elster",
      "Philipp Rosenberger",
      "Werner Ritter",
      "Dengxin Dai",
      "Hermann Winner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.08558"
  },
  {
    "id": "arXiv:2212.08565",
    "title": "Automatic Identification of Motivation for Code-Switching in Speech  Transcripts",
    "abstract": "Code-switching, or switching between languages, occurs for many reasons and\nhas important linguistic, sociological, and cultural implications. Multilingual\nspeakers code-switch for a variety of purposes, such as expressing emotions,\nborrowing terms, making jokes, introducing a new topic, etc. The reason for\ncode-switching may be quite useful for analysis, but is not readily apparent.\nTo remedy this situation, we annotate a new dataset of motivations for\ncode-switching in Spanish-English. We build the first system (to our knowledge)\nto automatically identify a wide range of motivations that speakers code-switch\nin everyday speech, achieving an accuracy of 75% across all motivations.\nAdditionally, we show that the system can be adapted to new language pairs,\nachieving 66% accuracy on a new language pair (Hindi-English), demonstrating\nthe cross-lingual applicability of our annotation scheme",
    "descriptor": "",
    "authors": [
      "Ritu Belani",
      "Jeffrey Flanigan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08565"
  },
  {
    "id": "arXiv:2212.08567",
    "title": "Optimized Symbolic Interval Propagation for Neural Network Verification",
    "abstract": "Neural networks are increasingly applied in safety critical domains, their\nverification thus is gaining importance. A large class of recent algorithms for\nproving input-output relations of feed-forward neural networks are based on\nlinear relaxations and symbolic interval propagation. However, due to variable\ndependencies, the approximations deteriorate with increasing depth of the\nnetwork. In this paper we present DPNeurifyFV, a novel branch-and-bound solver\nfor ReLU networks with low dimensional input-space that is based on symbolic\ninterval propagation with fresh variables and input-splitting. A new heuristic\nfor choosing the fresh variables allows to ameliorate the dependency problem,\nwhile our novel splitting heuristic, in combination with several other\nimprovements, speeds up the branch-and-bound procedure. We evaluate our\napproach on the airborne collision avoidance networks ACAS Xu and demonstrate\nruntime improvements compared to state-of-the-art tools.",
    "descriptor": "\nComments: Published at the 1st Workshop on Formal Verification of Machine Learning (WFVML 2022) (this https URL)\n",
    "authors": [
      "Philipp Kern",
      "Marko Kleine B\u00fcning",
      "Carsten Sinz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.08567"
  },
  {
    "id": "arXiv:2212.08568",
    "title": "Biomedical image analysis competitions: The state of current  participation practice",
    "abstract": "The number of international benchmarking competitions is steadily increasing\nin various fields of machine learning (ML) research and practice. So far,\nhowever, little is known about the common practice as well as bottlenecks faced\nby the community in tackling the research questions posed. To shed light on the\nstatus quo of algorithm development in the specific field of biomedical imaging\nanalysis, we designed an international survey that was issued to all\nparticipants of challenges conducted in conjunction with the IEEE ISBI 2021 and\nMICCAI 2021 conferences (80 competitions in total). The survey covered\nparticipants' expertise and working environments, their chosen strategies, as\nwell as algorithm characteristics. A median of 72% challenge participants took\npart in the survey. According to our results, knowledge exchange was the\nprimary incentive (70%) for participation, while the reception of prize money\nplayed only a minor role (16%). While a median of 80 working hours was spent on\nmethod development, a large portion of participants stated that they did not\nhave enough time for method development (32%). 25% perceived the infrastructure\nto be a bottleneck. Overall, 94% of all solutions were deep learning-based. Of\nthese, 84% were based on standard architectures. 43% of the respondents\nreported that the data samples (e.g., images) were too large to be processed at\nonce. This was most commonly addressed by patch-based training (69%),\ndownsampling (37%), and solving 3D analysis tasks as a series of 2D tasks.\nK-fold cross-validation on the training set was performed by only 37% of the\nparticipants and only 50% of the participants performed ensembling based on\nmultiple identical models (61%) or heterogeneous models (39%). 48% of the\nrespondents applied postprocessing steps.",
    "descriptor": "",
    "authors": [
      "Matthias Eisenmann",
      "Annika Reinke",
      "Vivienn Weru",
      "Minu Dietlinde Tizabi",
      "Fabian Isensee",
      "Tim J. Adler",
      "Patrick Godau",
      "Veronika Cheplygina",
      "Michal Kozubek",
      "Sharib Ali",
      "Anubha Gupta",
      "Jan Kybic",
      "Alison Noble",
      "Carlos Ortiz de Sol\u00f3rzano",
      "Samiksha Pachade",
      "Caroline Petitjean",
      "Daniel Sage",
      "Donglai Wei",
      "Elizabeth Wilden",
      "Deepak Alapatt",
      "Vincent Andrearczyk",
      "Ujjwal Baid",
      "Spyridon Bakas",
      "Niranjan Balu",
      "Sophia Bano",
      "Vivek Singh Bawa",
      "Jorge Bernal",
      "Sebastian Bodenstedt",
      "Alessandro Casella",
      "Jinwook Choi",
      "Olivier Commowick",
      "Marie Daum",
      "Adrien Depeursinge",
      "Reuben Dorent",
      "Jan Egger",
      "Hannah Eichhorn",
      "Sandy Engelhardt",
      "Melanie Ganz",
      "Gabriel Girard",
      "Lasse Hansen",
      "Mattias Heinrich",
      "Nicholas Heller",
      "Alessa Hering",
      "Arnaud Huaulm\u00e9",
      "Hyunjeong Kim",
      "Bennett Landman",
      "Hongwei Bran Li",
      "Jianning Li",
      "Jun Ma",
      "Anne Martel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08568"
  },
  {
    "id": "arXiv:2212.08570",
    "title": "Audio-based AI classifiers show no evidence of improved COVID-19  screening over simple symptoms checkers",
    "abstract": "Recent work has reported that AI classifiers trained on audio recordings can\naccurately predict severe acute respiratory syndrome coronavirus 2 (SARSCoV2)\ninfection status. Here, we undertake a large scale study of audio-based deep\nlearning classifiers, as part of the UK governments pandemic response. We\ncollect and analyse a dataset of audio recordings from 67,842 individuals with\nlinked metadata, including reverse transcription polymerase chain reaction\n(PCR) test outcomes, of whom 23,514 tested positive for SARS CoV 2. Subjects\nwere recruited via the UK governments National Health Service Test-and-Trace\nprogramme and the REal-time Assessment of Community Transmission (REACT)\nrandomised surveillance survey. In an unadjusted analysis of our dataset AI\nclassifiers predict SARS-CoV-2 infection status with high accuracy (Receiver\nOperating Characteristic Area Under the Curve (ROCAUC) 0.846 [0.838, 0.854])\nconsistent with the findings of previous studies. However, after matching on\nmeasured confounders, such as age, gender, and self reported symptoms, our\nclassifiers performance is much weaker (ROC-AUC 0.619 [0.594, 0.644]). Upon\nquantifying the utility of audio based classifiers in practical settings, we\nfind them to be outperformed by simple predictive scores based on user reported\nsymptoms.",
    "descriptor": "",
    "authors": [
      "Harry Coppock",
      "George Nicholson",
      "Ivan Kiskin",
      "Vasiliki Koutra",
      "Kieran Baker",
      "Jobie Budd",
      "Richard Payne",
      "Emma Karoune",
      "David Hurley",
      "Alexander Titcomb",
      "Sabrina Egglestone",
      "Ana Tendero Ca\u00f1adas",
      "Lorraine Butler",
      "Radka Jersakova",
      "Jonathon Mellor",
      "Selina Patel",
      "Tracey Thornley",
      "Peter Diggle",
      "Sylvia Richardson",
      "Josef Packham",
      "Bj\u00f6rn W. Schuller",
      "Davide Pigoli",
      "Steven Gilmour",
      "Stephen Roberts",
      "Chris Holmes"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.08570"
  },
  {
    "id": "arXiv:2212.08571",
    "title": "Statistical Design and Analysis for Robust Machine Learning: A Case  Study from COVID-19",
    "abstract": "Since early in the coronavirus disease 2019 (COVID-19) pandemic, there has\nbeen interest in using artificial intelligence methods to predict COVID-19\ninfection status based on vocal audio signals, for example cough recordings.\nHowever, existing studies have limitations in terms of data collection and of\nthe assessment of the performances of the proposed predictive models. This\npaper rigorously assesses state-of-the-art machine learning techniques used to\npredict COVID-19 infection status based on vocal audio signals, using a dataset\ncollected by the UK Health Security Agency. This dataset includes acoustic\nrecordings and extensive study participant meta-data. We provide guidelines on\ntesting the performance of methods to classify COVID-19 infection status based\non acoustic features and we discuss how these can be extended more generally to\nthe development and assessment of predictive methods based on public health\ndatasets.",
    "descriptor": "",
    "authors": [
      "Davide Pigoli",
      "Kieran Baker",
      "Jobie Budd",
      "Lorraine Butler",
      "Harry Coppock",
      "Sabrina Egglestone",
      "Steven G. Gilmour",
      "Chris Holmes",
      "David Hurley",
      "Radka Jersakova",
      "Ivan Kiskin",
      "Vasiliki Koutra",
      "Jonathon Mellor",
      "George Nicholson",
      "Joe Packham",
      "Selina Patel",
      "Richard Payne",
      "Stephen J. Roberts",
      "Bj\u00f6rn W. Schuller",
      "Ana Tendero-Ca\u00f1adas",
      "Tracey Thornley",
      "Alexander Titcomb"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2212.08571"
  },
  {
    "id": "arXiv:2212.08577",
    "title": "An Ethical Trajectory Planning Algorithm for Autonomous Vehicles",
    "abstract": "With the rise of AI and automation, moral decisions are being put into the\nhands of algorithms that were formerly the preserve of humans. In autonomous\ndriving, a variety of such decisions with ethical implications are made by\nalgorithms for behavior and trajectory planning. Therefore, we present an\nethical trajectory planning algorithm with a framework that aims at a fair\ndistribution of risk among road users. Our implementation incorporates a\ncombination of five essential ethical principles: minimization of the overall\nrisk, priority for the worst-off, equal treatment of people, responsibility,\nand maximum acceptable risk. To the best of the authors' knowledge, this is the\nfirst ethical algorithm for trajectory planning of autonomous vehicles in line\nwith the 20 recommendations from the EU Commission expert group and with\ngeneral applicability to various traffic situations. We showcase the ethical\nbehavior of our algorithm in selected scenarios and provide an empirical\nanalysis of the ethical principles in 2000 scenarios. The code used in this\nresearch is available as open-source software.",
    "descriptor": "",
    "authors": [
      "Maximilian Geisslinger",
      "Franziska Poszler",
      "Markus Lienkamp"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.08577"
  },
  {
    "id": "arXiv:2212.08578",
    "title": "Provable Fairness for Neural Network Models using Formal Verification",
    "abstract": "Machine learning models are increasingly deployed for critical\ndecision-making tasks, making it important to verify that they do not contain\ngender or racial biases picked up from training data. Typical approaches to\nachieve fairness revolve around efforts to clean or curate training data, with\npost-hoc statistical evaluation of the fairness of the model on evaluation\ndata. In contrast, we propose techniques to \\emph{prove} fairness using\nrecently developed formal methods that verify properties of neural network\nmodels.Beyond the strength of guarantee implied by a formal proof, our methods\nhave the advantage that we do not need explicit training or evaluation data\n(which is often proprietary) in order to analyze a given trained model. In\nexperiments on two familiar datasets in the fairness literature (COMPAS and\nADULTS), we show that through proper training, we can reduce unfairness by an\naverage of 65.4\\% at a cost of less than 1\\% in AUC score.",
    "descriptor": "",
    "authors": [
      "Giorgian Borca-Tasciuc",
      "Xingzhi Guo",
      "Stanley Bak",
      "Steven Skiena"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.08578"
  },
  {
    "id": "arXiv:2212.08580",
    "title": "Nested Gradient Codes for Straggler Mitigation in Distributed Machine  Learning",
    "abstract": "We consider distributed learning in the presence of slow and unresponsive\nworker nodes, referred to as stragglers. In order to mitigate the effect of\nstragglers, gradient coding redundantly assigns partial computations to the\nworker such that the overall result can be recovered from only the\nnon-straggling workers. Gradient codes are designed to tolerate a fixed number\nof stragglers. Since the number of stragglers in practice is random and unknown\na priori, tolerating a fixed number of stragglers can yield a sub-optimal\ncomputation load and can result in higher latency. We propose a gradient coding\nscheme that can tolerate a flexible number of stragglers by carefully\nconcatenating gradient codes for different straggler tolerance. By proper task\nscheduling and small additional signaling, our scheme adapts the computation\nload of the workers to the actual number of stragglers. We analyze the latency\nof our proposed scheme and show that it has a significantly lower latency than\ngradient codes.",
    "descriptor": "",
    "authors": [
      "Luis Ma\u00dfny",
      "Christoph Hofmeister",
      "Maximilian Egger",
      "Rawad Bitar",
      "Antonia Wachter-Zeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.08580"
  },
  {
    "id": "arXiv:2212.08583",
    "title": "Semi-Siamese Network for Robust Change Detection Across Different  Domains with Applications to 3D Printing",
    "abstract": "Automatic defect detection for 3D printing processes, which shares many\ncharacteristics with change detection problems, is a vital step for quality\ncontrol of 3D printed products. However, there are some critical challenges in\nthe current state of practice. First, existing methods for computer\nvision-based process monitoring typically work well only under specific camera\nviewpoints and lighting situations, requiring expensive pre-processing,\nalignment, and camera setups. Second, many defect detection techniques are\nspecific to pre-defined defect patterns and/or print schematics. In this work,\nwe approach the automatic defect detection problem differently using a novel\nSemi-Siamese deep learning model that directly compares a reference schematic\nof the desired print and a camera image of the achieved print. The model then\nsolves an image segmentation problem, identifying the locations of defects with\nrespect to the reference frame. Unlike most change detection problems, our\nmodel is specially developed to handle images coming from different domains and\nis robust against perturbations in the imaging setup such as camera angle and\nillumination. Defect localization predictions were made in 2.75 seconds per\nlayer using a standard MacBookPro, which is comparable to the typical tens of\nseconds or less for printing a single layer on an inkjet-based 3D printer,\nwhile achieving an F1-score of more than 0.9.",
    "descriptor": "",
    "authors": [
      "Yushuo Niu",
      "Ethan Chadwick",
      "Anson W. K. Ma",
      "Qian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08583"
  },
  {
    "id": "arXiv:2212.08586",
    "title": "Rethinking Cooking State Recognition with Vision Transformers",
    "abstract": "To ensure proper knowledge representation of the kitchen environment, it is\nvital for kitchen robots to recognize the states of the food items that are\nbeing cooked. Although the domain of object detection and recognition has been\nextensively studied, the task of object state classification has remained\nrelatively unexplored. The high intra-class similarity of ingredients during\ndifferent states of cooking makes the task even more challenging. Researchers\nhave proposed adopting Deep Learning based strategies in recent times, however,\nthey are yet to achieve high performance. In this study, we utilized the\nself-attention mechanism of the Vision Transformer (ViT) architecture for the\nCooking State Recognition task. The proposed approach encapsulates the globally\nsalient features from images, while also exploiting the weights learned from a\nlarger dataset. This global attention allows the model to withstand the\nsimilarities between samples of different cooking objects, while the employment\nof transfer learning helps to overcome the lack of inductive bias by utilizing\npretrained weights. To improve recognition accuracy, several augmentation\ntechniques have been employed as well. Evaluation of our proposed framework on\nthe `Cooking State Recognition Challenge Dataset' has achieved an accuracy of\n94.3%, which significantly outperforms the state-of-the-art.",
    "descriptor": "\nComments: Accepted in 25th ICCIT (6 pages, 5 Figures, 5 Tables)\n",
    "authors": [
      "Akib Mohammed Khan",
      "Alif Ashrafee",
      "Reeshoon Sayera",
      "Shahriar Ivan",
      "Sabbir Ahmed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08586"
  },
  {
    "id": "arXiv:2212.08589",
    "title": "Data-Driven Model Reduction by Two-Sided Moment Matching",
    "abstract": "In this brief paper, we propose a time-domain data-driven method for model\norder reduction by two-sided moment matching for linear systems. An algorithm\nthat asymptotically approximates the matrix product $\\Upsilon \\Pi$ from\ntime-domain samples of the so-called two-sided interconnection is provided.\nExploiting this estimated matrix, we determine the unique reduced-order model\nof order $\\nu$, which asymptotically matches the moments at $2 \\nu$ distinct\ninterpolation points. Furthermore, we discuss the impact that certain\ndisturbances and data distortions may have on the algorithm. Finally, we\nillustrate the use of the proposed methodology by means of a benchmark model.",
    "descriptor": "",
    "authors": [
      "Junyu Mao",
      "Giordano Scarciotti"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08589"
  },
  {
    "id": "arXiv:2212.08593",
    "title": "A Principled, Flexible and Efficient Framework for Hypergraph  Benchmarking",
    "abstract": "In recent years hypergraphs have emerged as a powerful tool to study systems\nwith multi-body interactions which cannot be trivially reduced to pairs. While\nhighly structured benchmark models have proved fundamental for the standardized\nevaluation of algorithms and the statistical study of real-world networked\ndata, these are scarcely available in the context of hypergraphs. Here we\npropose a flexible and efficient framework for the generation of hypergraphs\nwith many nodes and large hyperedges, which allows to specify general community\nstructures and tune different local statistics. We illustrate how to use our\nmodel to sample synthetic data with desired features (assortative or\ndisassortative communities, mixed or hard community assignments, etc.),\nbenchmark community detection algorithms, and generate hypergraphs structurally\nsimilar to real-world data. Overcoming previous limitations on the generation\nof synthetic hypergraphs, our work constitutes a substantial advancement in the\nstatistical modeling of higher-order systems.",
    "descriptor": "\nComments: 18 pages, 8 figures\n",
    "authors": [
      "Nicol\u00f2 Ruggeri",
      "Federico Battiston",
      "Caterina De Bacco"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.08593"
  },
  {
    "id": "arXiv:2212.08594",
    "title": "Call-By-Name Is Just Call-By-Value with Delimited Control",
    "abstract": "Delimited control operator shift0 exhibits versatile capabilities: it can\nexpress layered monadic effects, or equivalently, algebraic effects. Little did\nwe know it can express lambda calculus too! We present $ \\Lambda_\\$ $, a\ncall-by-value lambda calculus extended with shift0 and control delimiter \\$\nwith carefully crafted reduction theory, such that the lambda calculus with\nbeta and eta reductions can be isomorphically embedded into $ \\Lambda_\\$ $ via\na right inverse of a continuation-passing style translation. While call-by-name\nreductions of lambda calculus can trivially simulate its call-by-value version,\nwe show that addition of shift0 and \\$ is the golden mean of expressive power\nthat suffices to simulate beta and eta reductions while still admitting a\nsimulation back. As a corollary, calculi $ \\Lambda\\mu_v $, $ \\lambda_\\$ $, $\n\\Lambda_\\$ $ and $ \\lambda $ all correspond equationally.",
    "descriptor": "",
    "authors": [
      "Mateusz Pyzik"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2212.08594"
  },
  {
    "id": "arXiv:2212.08597",
    "title": "Detecting and Mitigating Hallucinations in Machine Translation: Model  Internal Workings Alone Do Well, Sentence Similarity Even Better",
    "abstract": "While the problem of hallucinations in neural machine translation has long\nbeen recognized, so far the progress on its alleviation is very little. Indeed,\nrecently it turned out that without artificially encouraging models to\nhallucinate, previously existing methods fall short and even the standard\nsequence log-probability is more informative. It means that characteristics\ninternal to the model can give much more information than we expect, and before\nusing external models and measures, we first need to ask: how far can we go if\nwe use nothing but the translation model itself ? We propose to use a method\nthat evaluates the percentage of the source contribution to a generated\ntranslation. Intuitively, hallucinations are translations \"detached\" from the\nsource, hence they can be identified by low source contribution. This method\nimproves detection accuracy for the most severe hallucinations by a factor of 2\nand is able to alleviate hallucinations at test time on par with the previous\nbest approach that relies on external models. Next, if we move away from\ninternal model characteristics and allow external tools, we show that using\nsentence similarity from cross-lingual embeddings further improves these\nresults.",
    "descriptor": "",
    "authors": [
      "David Dale",
      "Elena Voita",
      "Lo\u00efc Barrault",
      "Marta R. Costa-juss\u00e0"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08597"
  },
  {
    "id": "arXiv:2212.08601",
    "title": "Source Tracing: Detecting Voice Spoofing",
    "abstract": "Recent anti-spoofing systems focus on spoofing detection, where the task is\nonly to determine whether the test audio is fake. However, there are few\nstudies putting attention to identifying the methods of generating fake speech.\nCommon spoofing attack algorithms in the logical access (LA) scenario, such as\nvoice conversion and speech synthesis, can be divided into several stages:\ninput processing, conversion, waveform generation, etc. In this work, we\npropose a system for classifying different spoofing attributes, representing\ncharacteristics of different modules in the whole pipeline. Classifying\nattributes for the spoofing attack other than determining the whole spoofing\npipeline can make the system more robust when encountering complex combinations\nof different modules at different stages. In addition, our system can also be\nused as an auxiliary system for anti-spoofing against unseen spoofing methods.\nThe experiments are conducted on ASVspoof 2019 LA data set and the proposed\nmethod achieved a 20\\% relative improvement against conventional binary spoof\ndetection methods.",
    "descriptor": "\nComments: Accepted by APSIPA ASC\n",
    "authors": [
      "Tinglong Zhu",
      "Xingming Wang",
      "Xiaoyi Qin",
      "Ming Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.08601"
  },
  {
    "id": "arXiv:2212.08604",
    "title": "Planning Visual-Tactile Precision Grasps via Complementary Use of Vision  and Touch",
    "abstract": "Reliably planning fingertip grasps for multi-fingered hands lies as a key\nchallenge for many tasks including tool use, insertion, and dexterous in-hand\nmanipulation. This task becomes even more difficult when the robot lacks an\naccurate model of the object to be grasped. Tactile sensing offers a promising\napproach to account for uncertainties in object shape. However, current robotic\nhands tend to lack full tactile coverage. As such, a problem arises of how to\nplan and execute grasps for multi-fingered hands such that contact is made with\nthe area covered by the tactile sensors. To address this issue, we propose an\napproach to grasp planning that explicitly reasons about where the fingertips\nshould contact the estimated object surface while maximizing the probability of\ngrasp success. Key to our method's success is the use of visual surface\nestimation for initial planning to encode the contact constraint. The robot\nthen executes this plan using a tactile-feedback controller that enables the\nrobot to adapt to online estimates of the object's surface to correct for\nerrors in the initial plan. Importantly, the robot never explicitly integrates\nobject pose or surface estimates between visual and tactile sensing, instead it\nuses the two modalities in complementary ways. Vision guides the robots motion\nprior to contact; touch updates the plan when contact occurs differently than\npredicted from vision. We show that our method successfully synthesises and\nexecutes precision grasps for previously unseen objects using surface estimates\nfrom a single camera view. Further, our approach outperforms a state of the art\nmulti-fingered grasp planner, while also beating several baselines we propose.",
    "descriptor": "",
    "authors": [
      "Martin Matak",
      "Tucker Hermans"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08604"
  },
  {
    "id": "arXiv:2212.08607",
    "title": "MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text  Generation",
    "abstract": "Prompting large language models has enabled significant recent progress in\nmulti-step reasoning over text. However, when applied to text generation from\nsemi-structured data (e.g., graphs or tables), these methods typically suffer\nfrom low semantic coverage, hallucination, and logical inconsistency. We\npropose MURMUR, a neuro-symbolic modular approach to text generation from\nsemi-structured data with multi-step reasoning. MURMUR is a best-first search\nmethod that generates reasoning paths using: (1) neural and symbolic modules\nwith specific linguistic and logical skills, (2) a grammar whose production\nrules define valid compositions of modules, and (3) value functions that assess\nthe quality of each reasoning step. We conduct experiments on two diverse\ndata-to-text generation tasks like WebNLG and LogicNLG. These tasks differ in\ntheir data representations (graphs and tables) and span multiple linguistic and\nlogical skills. MURMUR obtains significant improvements over recent few-shot\nbaselines like direct prompting and chain-of-thought prompting, while also\nachieving comparable performance to fine-tuned GPT-2 on out-of-domain data.\nMoreover, human evaluation shows that MURMUR generates highly faithful and\ncorrect reasoning paths that lead to 26% more logically consistent summaries on\nLogicNLG, compared to direct prompting.",
    "descriptor": "\nComments: 22 pages (9 figures, 18 tables)\n",
    "authors": [
      "Swarnadeep Saha",
      "Xinyan Velocity Yu",
      "Mohit Bansal",
      "Ramakanth Pasunuru",
      "Asli Celikyilmaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08607"
  },
  {
    "id": "arXiv:2212.08610",
    "title": "Huruf: An Application for Arabic Handwritten Character Recognition Using  Deep Learning",
    "abstract": "Handwriting Recognition has been a field of great interest in the Artificial\nIntelligence domain. Due to its broad use cases in real life, research has been\nconducted widely on it. Prominent work has been done in this field focusing\nmainly on Latin characters. However, the domain of Arabic handwritten character\nrecognition is still relatively unexplored. The inherent cursive nature of the\nArabic characters and variations in writing styles across individuals makes the\ntask even more challenging. We identified some probable reasons behind this and\nproposed a lightweight Convolutional Neural Network-based architecture for\nrecognizing Arabic characters and digits. The proposed pipeline consists of a\ntotal of 18 layers containing four layers each for convolution, pooling, batch\nnormalization, dropout, and finally one Global average pooling and a Dense\nlayer. Furthermore, we thoroughly investigated the different choices of\nhyperparameters such as the choice of the optimizer, kernel initializer,\nactivation function, etc. Evaluating the proposed architecture on the publicly\navailable 'Arabic Handwritten Character Dataset (AHCD)' and 'Modified Arabic\nhandwritten digits Database (MadBase)' datasets, the proposed model\nrespectively achieved an accuracy of 96.93% and 99.35% which is comparable to\nthe state-of-the-art and makes it a suitable solution for real-life end-level\napplications.",
    "descriptor": "\nComments: Accepted in 25th ICCIT (6 pages, 4 tables, 4 figures)\n",
    "authors": [
      "Minhaz Kamal",
      "Fairuz Shaiara",
      "Chowdhury Mohammad Abdullah",
      "Sabbir Ahmed",
      "Tasnim Ahmed",
      "Md. Hasanul Kabir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08610"
  },
  {
    "id": "arXiv:2212.08613",
    "title": "Atrous Space Bender U-Net (ASBU-Net/LogiNet)",
    "abstract": "$ $With recent advances in CNNs, exceptional improvements have been made in\nsemantic segmentation of high resolution images in terms of accuracy and\nlatency. However, challenges still remain in detecting objects in crowded\nscenes, large scale variations, partial occlusion, and distortions, while still\nmaintaining mobility and latency. We introduce a fast and efficient\nconvolutional neural network, ASBU-Net, for semantic segmentation of high\nresolution images that addresses these problems and uses no novelty layers for\nease of quantization and embedded hardware support. ASBU-Net is based on a new\nfeature extraction module, atrous space bender layer (ASBL), which is efficient\nin terms of computation and memory. The ASB layers form a building block that\nis used to make ASBNet. Since this network does not use any special layers it\ncan be easily implemented, quantized and deployed on FPGAs and other hardware\nwith limited memory. We present experiments on resource and accuracy trade-offs\nand show strong performance compared to other popular models.",
    "descriptor": "",
    "authors": [
      "Anurag Bansal",
      "Oleg Ostap",
      "Miguel Maestre Trueba",
      "Kristopher Perry"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08613"
  },
  {
    "id": "arXiv:2212.08616",
    "title": "Translating Social Media Crisis Narratives into Road Network Utilization  Metrics: The Case of 2020 Oklahoma Ice Storm",
    "abstract": "Risk communication in times of disasters is complex, involving rapid and\ndiverse communication in social networks (i.e., public and/or private agencies;\nlocal residents) as well as limited mobilization capacity and operational\nconstraints of physical infrastructure networks. Despite a growing literature\non infrastructure interdependencies and co-dependent social-physical systems,\nan in-depth understanding of how risk communication in online social networks\nweighs into physical infrastructure networks during a major disaster remains\nlimited, let alone in compounding risk events. This study analyzes large-scale\ndatasets of crisis mobility and activity-related social interactions and\nconcerns available through social media (Twitter) for communities that were\nimpacted by an ice storm (Oct. 2020) in Oklahoma. Compounded by the COVID-19\npandemic, Oklahoma residents faced this historic ice storm (Oct. 26, 2020-Oct.\n29, 2020) that caused devastating traffic impacts (among others) due to\nexcessive ice accumulation. By using the recently released academic Application\nProgramming Interface (API) by Twitter that provides complete and unbiased\ndata, geotagged tweets (approx. 210K) were collected covering the entire state\nof Oklahoma, and ice storm-related tweets (approx. 14.2K) were considered.\nFirst, the study uses natural language processing and text quantification\ntechniques to translate crisis narratives (i.e., tweets). Next, geo-tagged\ntweets are mapped into co-located road networks using traditional GIS\ntechniques. Finally, insights are generated using network science theories and\nquantified social narratives to interpret different elements of road networks\n(e.g., local roads, freeways, etc.) for the Oklahoma communities that were\nimpacted by the ice storm event during the pandemic.",
    "descriptor": "",
    "authors": [
      "H M Imran Kays",
      "Khondhaker Al Momin",
      "Menziwokuhle Bandise Thwala",
      "K.K. \"Muralee\" Muraleetharan",
      "Arif Mohaimin Sadri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.08616"
  },
  {
    "id": "arXiv:2212.08619",
    "title": "Planting and Mitigating Memorized Content in Predictive-Text Language  Models",
    "abstract": "Language models are widely deployed to provide automatic text completion\nservices in user products. However, recent research has revealed that language\nmodels (especially large ones) bear considerable risk of memorizing private\ntraining data, which is then vulnerable to leakage and extraction by\nadversaries. In this study, we test the efficacy of a range of\nprivacy-preserving techniques to mitigate unintended memorization of sensitive\nuser text, while varying other factors such as model size and adversarial\nconditions. We test both \"heuristic\" mitigations (those without formal privacy\nguarantees) and Differentially Private training, which provides provable levels\nof privacy at the cost of some model performance. Our experiments show that\n(with the exception of L2 regularization), heuristic mitigations are largely\nineffective in preventing memorization in our test suite, possibly because they\nmake too strong of assumptions about the characteristics that define\n\"sensitive\" or \"private\" text. In contrast, Differential Privacy reliably\nprevents memorization in our experiments, despite its computational and\nmodel-performance costs.",
    "descriptor": "",
    "authors": [
      "C.M. Downey",
      "Wei Dai",
      "Huseyin A. Inan",
      "Kim Laine",
      "Saurabh Naik",
      "Tomasz Religa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.08619"
  },
  {
    "id": "arXiv:2212.08620",
    "title": "POTATO: The Portable Text Annotation Tool",
    "abstract": "We present POTATO, the Portable text annotation tool, a free, fully\nopen-sourced annotation system that 1) supports labeling many types of text and\nmultimodal data; 2) offers easy-to-configure features to maximize the\nproductivity of both deployers and annotators (convenient templates for common\nML/NLP tasks, active learning, keypress shortcuts, keyword highlights,\ntooltips); and 3) supports a high degree of customization (editable UI,\ninserting pre-screening questions, attention and qualification tests).\nExperiments over two annotation tasks suggest that POTATO improves labeling\nspeed through its specially-designed productivity features, especially for long\ndocuments and complex tasks. POTATO is available at\nhttps://github.com/davidjurgens/potato and will continue to be updated.",
    "descriptor": "\nComments: EMNLP 2022 DEMO\n",
    "authors": [
      "Jiaxin Pei",
      "Aparna Ananthasubramaniam",
      "Xingyao Wang",
      "Naitian Zhou",
      "Jackson Sargent",
      "Apostolos Dedeloudis",
      "David Jurgens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08620"
  },
  {
    "id": "arXiv:2212.08622",
    "title": "Reconfigurable Wearable Antenna for 5G Applications using Nematic Liquid  Crystals",
    "abstract": "The antenna is one of the key building blocks of many wearable electronic\ndevice, and its functions include wireless communications, energy harvesting\nand radiative wireless power transfer (WPT). In an effort to realise\nlightweight, autonomous and battery-less wearable devices, we demonstrate a\nreconfigurable antenna design for 5G wearable applications that require\nultra-low driving voltages ($0.4$-$0.6\\,$V) and operate over a high frequency\nrange ($3.3$-$3.8\\,$GHz). For smart glasses application, previous antenna\ndesigns were `fixed' and mounted on the eyeglass frame itself. Here, we\ndemonstrate a reconfigurable design that could be achieved on the lens itself,\nusing an anisotropic liquid crystal (LC) material. We demonstrate how LC\nalignment and electric field patterns strongly influence the tuning\ncapabilities of these antennas in the gigahertz range and present a smart,\nreconfigurable spiral antenna system with a LC substrate.",
    "descriptor": "",
    "authors": [
      "Yuanjie Xia",
      "Mengyao Yuan",
      "Alexandra Dobrea",
      "Chong Li",
      "Hadi Heidari",
      "Nigel Mottram",
      "Rami Ghannam"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.08622"
  },
  {
    "id": "arXiv:2212.08626",
    "title": "Hippocampus-Inspired Cognitive Architecture (HICA) for Operant  Conditioning",
    "abstract": "The neural implementation of operant conditioning with few trials is unclear.\nWe propose a Hippocampus-Inspired Cognitive Architecture (HICA) as a neural\nmechanism for operant conditioning. HICA explains a learning mechanism in which\nagents can learn a new behavior policy in a few trials, as mammals do in\noperant conditioning experiments. HICA is composed of two different types of\nmodules. One is a universal learning module type that represents a cortical\ncolumn in the neocortex gray matter. The working principle is modeled as\nModulated Heterarchical Prediction Memory (mHPM). In mHPM, each module learns\nto predict a succeeding input vector given the sequence of the input vectors\nfrom lower layers and the context vectors from higher layers. The prediction is\nfed into the lower layers as a context signal (top-down feedback signaling),\nand into the higher layers as an input signal (bottom-up feedforward\nsignaling). Rewards modulate the learning rate in those modules to memorize\nmeaningful sequences effectively. In mHPM, each module updates in a local and\ndistributed way compared to conventional end-to-end learning with\nbackpropagation of the single objective loss. This local structure enables the\nheterarchical network of modules. The second type is an innate, special-purpose\nmodule representing various organs of the brain's subcortical system. Modules\nmodeling organs such as the amygdala, hippocampus, and reward center are\npre-programmed to enable instinctive behaviors. The hippocampus plays the role\nof the simulator. It is an autoregressive prediction model of the top-most\nlevel signal with a loop structure of memory, while cortical columns are lower\nlayers that provide detailed information to the simulation. The simulation\nbecomes the basis for learning with few trials and the deliberate planning\nrequired for operant conditioning.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2108.03793\n",
    "authors": [
      "Deokgun Park",
      "Md Ashaduzzaman Rubel Mondol",
      "SM Mazharul Islam",
      "Aishwarya Pothula"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08626"
  },
  {
    "id": "arXiv:2212.08630",
    "title": "Brauer's Group Equivariant Neural Networks",
    "abstract": "We provide a full characterisation of all of the possible group equivariant\nneural networks whose layers are some tensor power of $\\mathbb{R}^{n}$ for\nthree symmetry groups that are missing from the machine learning literature:\n$O(n)$, the orthogonal group; $SO(n)$, the special orthogonal group; and\n$Sp(n)$, the symplectic group. In particular, we find a spanning set of\nmatrices for the learnable, linear, equivariant layer functions between such\ntensor power spaces in the standard basis of $\\mathbb{R}^{n}$ when the group is\n$O(n)$ or $SO(n)$, and in the symplectic basis of $\\mathbb{R}^{n}$ when the\ngroup is $Sp(n)$. The neural networks that we characterise are simple to\nimplement since our method circumvents the typical requirement when building\ngroup equivariant neural networks of having to decompose the tensor power\nspaces of $\\mathbb{R}^{n}$ into irreducible representations. We also describe\nhow our approach generalises to the construction of neural networks that are\nequivariant to local symmetries.\nThe theoretical background for our results comes from the Schur-Weyl\ndualities that were established by Brauer in his 1937 paper \"On Algebras Which\nare Connected with the Semisimple Continuous Groups\" for each of the three\ngroups in question. We suggest that Schur-Weyl duality is a powerful\nmathematical concept that could be used to understand the structure of neural\nnetworks that are equivariant to groups beyond those considered in this paper.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Edward Pearce-Crump"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Representation Theory (math.RT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.08630"
  },
  {
    "id": "arXiv:2212.08631",
    "title": "Control and Placement of Finite-Resolution Intelligent Surfaces in IoT  Systems with Imperfect CSI",
    "abstract": "In this paper, we study the advantages of using reconfigurable intelligent\nsurfaces (RISs) for interference suppression in single-input single-output\n(SISO) distributed Internet of Things (IoT) networks. Implementing RIS-assisted\nnetworks confronts various problems, mostly related to the control and\nplacement of the RIS. To tackle the control-related challenges, we consider\nnoisy and local channel knowledge, based on which we devise algorithms to\noptimize the potentially distributed RISs to achieve an overall network\nobjective, such as the sum-rate. We use a network with a centralized RIS as a\nbenchmark for our comparisons. We further assume low-bit phase shifters at the\nRIS to capture real-world hardware limitations. We also study the placement of\nthe RIS and analytically quantify the minimum required degrees-of-control for\nthe RIS as a function of its location to guarantee a specific network\nperformance metric and verify the results via simulations.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Sajjad Nassirpour",
      "Alireza Vahid",
      "Dinh-Thuan Do",
      "Dinesh Bharadia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.08631"
  },
  {
    "id": "arXiv:2212.08632",
    "title": "Enhancing Multi-modal and Multi-hop Question Answering via Structured  Knowledge and Unified Retrieval-Generation",
    "abstract": "Multi-modal and multi-hop question answering aims to answer a question based\non multiple input sources from different modalities. Previous methods retrieve\nthe evidence separately and feed the retrieved evidence to a language model to\ngenerate the corresponding answer. However, these methods fail to build\nconnections between candidates and thus cannot model the inter-dependent\nrelation during retrieval. Moreover, the reasoning process over multi-modality\ncandidates can be unbalanced without building alignments between different\nmodalities. To address this limitation, we propose a Structured Knowledge and\nUnified Retrieval Generation based method (SKURG). We align the sources from\ndifferent modalities via the shared entities and map them into a shared\nsemantic space via structured knowledge. Then, we utilize a unified\nretrieval-generation decoder to integrate intermediate retrieval results for\nanswer generation and adaptively determine the number of retrieval steps. We\nperform experiments on two multi-modal and multi-hop datasets: WebQA and\nMultimodalQA. The results demonstrate that SKURG achieves state-of-the-art\nperformance on both retrieval and answer generation.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Qian Yang",
      "Qian Chen",
      "Wen Wang",
      "Baotian Hu",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08632"
  },
  {
    "id": "arXiv:2212.08633",
    "title": "Cartographer_glass: 2D Graph SLAM Framework using LiDAR for Glass  Environments",
    "abstract": "We study algorithms for detecting and including glass objects in an\noptimization-based Simultaneous Localization and Mapping (SLAM) algorithm in\nthis work. When LiDAR data is the primary exteroceptive sensory input, glass\nobjects are not correctly registered. This occurs as the incident light\nprimarily passes through the glass objects or reflects away from the source,\nresulting in inaccurate range measurements for glass surfaces. Consequently,\nthe localization and mapping performance is impacted, thereby rendering\nnavigation in such environments unreliable. Optimization-based SLAM solutions,\nwhich are also referred to as Graph SLAM, are widely regarded as state of the\nart. In this paper, we utilize a simple and computationally inexpensive glass\ndetection scheme for detecting glass objects and present the methodology to\nincorporate the identified objects into the occupancy grid maintained by such\nan algorithm (Google Cartographer). We develop both local (submap level) and\nglobal algorithms for achieving the objective mentioned above and compare the\nmaps produced by our method with those produced by an existing algorithm that\nutilizes particle filter based SLAM.",
    "descriptor": "",
    "authors": [
      "Lasitha Weerakoon",
      "Gurtajbir Singh Herr",
      "Jasmine Blunt",
      "Miao Yu",
      "Nikhil Chopra"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.08633"
  },
  {
    "id": "arXiv:2212.08635",
    "title": "Self-Prompting Large Language Models for Open-Domain QA",
    "abstract": "Open-Domain Question Answering (ODQA) requires models to answer factoid\nquestions with no context given. The common way for this task is to train\nmodels on a large-scale annotated dataset to retrieve related documents and\ngenerate answers based on these documents. In this paper, we show that the ODQA\narchitecture can be dramatically simplified by treating Large Language Models\n(LLMs) as a knowledge corpus and propose a Self-Prompting framework for LLMs to\nperform ODQA so as to eliminate the need for training data and external\nknowledge corpus. Concretely, we firstly generate multiple pseudo QA pairs with\nbackground passages and one-sentence explanations for these QAs by prompting\nLLMs step by step and then leverage the generated QA pairs for in-context\nlearning. Experimental results show our method surpasses previous\nstate-of-the-art methods by +8.8 EM averagely on three widely-used ODQA\ndatasets, and even achieves comparable performance with several\nretrieval-augmented fine-tuned models.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Junlong Li",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.08635"
  },
  {
    "id": "arXiv:2212.08639",
    "title": "An annotated instance segmentation XXL-CT dataset from a historic  airplane",
    "abstract": "The Me 163 was a Second World War fighter airplane and a result of the German\nair force secret developments. One of these airplanes is currently owned and\ndisplayed in the historic aircraft exhibition of the Deutsches Museum in\nMunich, Germany. To gain insights with respect to its history, design and state\nof preservation, a complete CT scan was obtained using an industrial\nXXL-computer tomography scanner.\nUsing the CT data from the Me 163, all its details can visually be examined\nat various levels, ranging from the complete hull down to single sprockets and\nrivets. However, while a trained human observer can identify and interpret the\nvolumetric data with all its parts and connections, a virtual dissection of the\nairplane and all its different parts would be quite desirable. Nevertheless,\nthis means, that an instance segmentation of all components and objects of\ninterest into disjoint entities from the CT data is necessary.\nAs of currently, no adequate computer-assisted tools for automated or\nsemi-automated segmentation of such XXL-airplane data are available, in a first\nstep, an interactive data annotation and object labeling process has been\nestablished. So far, seven 512 x 512 x 512 voxel sub-volumes from the Me 163\nairplane have been annotated and labeled, whose results can potentially be used\nfor various new applications in the field of digital heritage, non-destructive\ntesting, or machine-learning.\nThis work describes the data acquisition process of the airplane using an\nindustrial XXL-CT scanner, outlines the interactive segmentation and labeling\nscheme to annotate sub-volumes of the airplane's CT data, describes and\ndiscusses various challenges with respect to interpreting and handling the\nannotated and labeled data.",
    "descriptor": "",
    "authors": [
      "Roland Gruber",
      "Nils Reims",
      "Andreas Hempfer",
      "Stefan Gerth",
      "Michael Salamon",
      "Thomas Wittenberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08639"
  },
  {
    "id": "arXiv:2212.08641",
    "title": "GFPose: Learning 3D Human Pose Prior with Gradient Fields",
    "abstract": "Learning 3D human pose prior is essential to human-centered AI. Here, we\npresent GFPose, a versatile framework to model plausible 3D human poses for\nvarious applications. At the core of GFPose is a time-dependent score network,\nwhich estimates the gradient on each body joint and progressively denoises the\nperturbed 3D human pose to match a given task specification. During the\ndenoising process, GFPose implicitly incorporates pose priors in gradients and\nunifies various discriminative and generative tasks in an elegant framework.\nDespite the simplicity, GFPose demonstrates great potential in several\ndownstream tasks. Our experiments empirically show that 1) as a\nmulti-hypothesis pose estimator, GFPose outperforms existing SOTAs by 20% on\nHuman3.6M dataset. 2) as a single-hypothesis pose estimator, GFPose achieves\ncomparable results to deterministic SOTAs, even with a vanilla backbone. 3)\nGFPose is able to produce diverse and realistic samples in pose denoising,\ncompletion and generation tasks. Project page\nhttps://sites.google.com/view/gfpose/",
    "descriptor": "",
    "authors": [
      "Hai Ci",
      "Mingdong Wu",
      "Wentao Zhu",
      "Xiaoxuan Ma",
      "Hao Dong",
      "Fangwei Zhong",
      "Yizhou Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08641"
  },
  {
    "id": "arXiv:2212.08645",
    "title": "Efficient Conditionally Invariant Representation Learning",
    "abstract": "We introduce the Conditional Independence Regression CovariancE (CIRCE), a\nmeasure of conditional independence for multivariate continuous-valued\nvariables. CIRCE applies as a regularizer in settings where we wish to learn\nneural features $\\varphi(X)$ of data $X$ to estimate a target $Y$, while being\nconditionally independent of a distractor $Z$ given $Y$. Both $Z$ and $Y$ are\nassumed to be continuous-valued but relatively low dimensional, whereas $X$ and\nits features may be complex and high dimensional. Relevant settings include\ndomain-invariant learning, fairness, and causal learning. The procedure\nrequires just a single ridge regression from $Y$ to kernelized features of $Z$,\nwhich can be done in advance. It is then only necessary to enforce independence\nof $\\varphi(X)$ from residuals of this regression, which is possible with\nattractive estimation properties and consistency guarantees. By contrast,\nearlier measures of conditional feature dependence require multiple regressions\nfor each step of feature learning, resulting in more severe bias and variance,\nand greater computational cost. When sufficiently rich features are used, we\nestablish that CIRCE is zero if and only if $\\varphi(X) \\perp \\!\\!\\! \\perp Z\n\\mid Y$. In experiments, we show superior performance to previous methods on\nchallenging benchmarks, including learning conditionally invariant image\nfeatures.",
    "descriptor": "",
    "authors": [
      "Roman Pogodin",
      "Namrata Deka",
      "Yazhe Li",
      "Danica J. Sutherland",
      "Victor Veitch",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.08645"
  },
  {
    "id": "arXiv:2212.08648",
    "title": "Connecting Permutation Equivariant Neural Networks and Partition  Diagrams",
    "abstract": "We show how the Schur-Weyl duality that exists between the partition algebra\nand the symmetric group results in a stronger theoretical foundation for\ncharacterising all of the possible permutation equivariant neural networks\nwhose layers are some tensor power of the permutation representation $M_n$ of\nthe symmetric group $S_n$. In doing so, we unify two separate bodies of\nliterature, and we correct some of the major results that are now widely quoted\nby the machine learning community. In particular, we find a basis of matrices\nfor the learnable, linear, permutation equivariant layer functions between such\ntensor power spaces in the standard basis of $M_n$ by using an elegant\ngraphical representation of a basis of set partitions for the partition algebra\nand its related vector spaces. Also, we show how we can calculate the number of\nweights that must appear in these layer functions by looking at certain paths\nthrough the McKay quiver for $M_n$. Finally, we describe how our approach\ngeneralises to the construction of neural networks that are equivariant to\nlocal symmetries.",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Edward Pearce-Crump"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Representation Theory (math.RT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.08648"
  },
  {
    "id": "arXiv:2212.08649",
    "title": "Better May Not Be Fairer: Can Data Augmentation Mitigate Subgroup  Degradation?",
    "abstract": "It is no secret that deep learning models exhibit undesirable behaviors such\nas learning spurious correlations instead of learning correct relationships\nbetween input/output pairs. Prior works on robustness study datasets that mix\nlow-level features to quantify how spurious correlations affect predictions\ninstead of considering natural semantic factors due to limitations in accessing\nrealistic datasets for comprehensive evaluation. To bridge this gap, in this\npaper we first investigate how natural background colors play a role as\nspurious features in image classification tasks by manually splitting the test\nsets of CIFAR10 and CIFAR100 into subgroups based on the background color of\neach image. We name our datasets CIFAR10-B and CIFAR100-B. We find that while\nstandard CNNs achieve human-level accuracy, the subgroup performances are not\nconsistent, and the phenomenon remains even after data augmentation (DA). To\nalleviate this issue, we propose FlowAug, a semantic DA method that leverages\nthe decoupled semantic representations captured by a pre-trained generative\nflow. Experimental results show that FlowAug achieves more consistent results\nacross subgroups than other types of DA methods on CIFAR10 and CIFAR100.\nAdditionally, it shows better generalization performance. Furthermore, we\npropose a generic metric for studying model robustness to spurious\ncorrelations, where we take a macro average on the weighted standard deviations\nacross different classes. Per our metric, FlowAug demonstrates less reliance on\nspurious correlations. Although this metric is proposed to study our curated\ndatasets, it applies to all datasets that have subgroups or subclasses. Lastly,\naside from less dependence on spurious correlations and better generalization\non in-distribution test sets, we also show superior out-of-distribution results\non CIFAR10.1 and competitive performances on CIFAR10-C and CIFAR100-C.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Ming-Chang Chiu",
      "Pin-Yu Chen",
      "Xuezhe Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08649"
  },
  {
    "id": "arXiv:2212.08650",
    "title": "On Human Visual Contrast Sensitivity and Machine Vision Robustness: A  Comparative Study",
    "abstract": "It is well established in neuroscience that color vision plays an essential\npart in the human visual perception system. Meanwhile, many novel designs for\ncomputer vision inspired by human vision have achieved success in a wide range\nof tasks and applications. Nonetheless, how color differences affect machine\nvision has not been well explored. Our work tries to bridge this gap between\nthe human color vision aspect of visual recognition and that of the machine. To\nachieve this, we curate two datasets: CIFAR10-F and CIFAR100-F, which are based\non the foreground colors of the popular CIFAR datasets. Together with CIFAR10-B\nand CIFAR100-B, the existing counterpart datasets with information on the\nbackground colors of CIFAR test sets, we assign each image based on its color\ncontrast level per its foreground and background color labels and use this as a\nproxy to study how color contrast affects machine vision. We first conduct a\nproof-of-concept study, showing the effect of color difference and validate our\ndatasets. Furthermore, on a broader level, an important characteristic of human\nvision is its robustness against ambient changes; therefore, drawing\ninspirations from ophthalmology and the robustness literature, we analogize\ncontrast sensitivity from the human visual aspect to machine vision and\ncomplement the current robustness study using corrupted images with our\nCIFAR-CoCo datasets. In summary, motivated by neuroscience and equipped with\nthe datasets we curate, we devise a new framework in two dimensions to perform\nextensive analyses on the effect of color contrast and corrupted images: (1)\nmodel architecture, (2) model size, to measure the perception ability of\nmachine vision beyond total accuracy. We also explore how task complexity and\ndata augmentation play a role in this setup. Our results call attention to new\nevaluation approaches for human-like machine perception.",
    "descriptor": "\nComments: 9 pages, 11 figures\n",
    "authors": [
      "Ming-Chang Chiu",
      "Yingfei Wang",
      "Derrick Eui Gyu Kim",
      "Pin-Yu Chen",
      "Xuezhe Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.08650"
  },
  {
    "id": "arXiv:2212.08653",
    "title": "Attentive Mask CLIP",
    "abstract": "Image token removal is an efficient augmentation strategy for reducing the\ncost of computing image features. However, this efficient augmentation strategy\nhas been found to adversely affect the accuracy of CLIP-based training. We\nhypothesize that removing a large portion of image tokens may improperly\ndiscard the semantic content associated with a given text description, thus\nconstituting an incorrect pairing target in CLIP training. To address this\nissue, we propose an attentive token removal approach for CLIP training, which\nretains tokens with a high semantic correlation to the text description. The\ncorrelation scores are computed in an online fashion using the EMA version of\nthe visual encoder. Our experiments show that the proposed attentive masking\napproach performs better than the previous method of random token removal for\nCLIP training. The approach also makes it efficient to apply multiple\naugmentation views to the image, as well as introducing instance contrastive\nlearning tasks between these views into the CLIP framework. Compared to other\nCLIP improvements that combine different pre-training targets such as SLIP and\nMaskCLIP, our method is not only more effective, but also much more efficient.\nSpecifically, using ViT-B and YFCC-15M dataset, our approach achieves $43.9\\%$\ntop-1 accuracy on ImageNet-1K zero-shot classification, as well as $62.7/42.1$\nand $38.0/23.2$ I2T/T2I retrieval accuracy on Flickr30K and MS COCO, which are\n$+1.1\\%$, $+5.5/+0.9$, and $+4.4/+1.3$ higher than the SLIP method, while being\n$2.30\\times$ faster. An efficient version of our approach running $1.16\\times$\nfaster than the plain CLIP model achieves significant gains of $+5.3\\%$,\n$+11.3/+8.0$, and $+9.5/+4.9$ on these benchmarks.",
    "descriptor": "",
    "authors": [
      "Yifan Yang",
      "Weiquan Huang",
      "Yixuan Wei",
      "Houwen Peng",
      "Xinyang Jiang",
      "Huiqiang Jiang",
      "Fangyun Wei",
      "Yin Wang",
      "Han Hu",
      "Lili Qiu",
      "Yuqing Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.08653"
  },
  {
    "id": "arXiv:2212.08101",
    "title": "Learning to repeatedly solve routing problems",
    "abstract": "In the last years, there has been a great interest in machine-learning-based\nheuristics for solving NP-hard combinatorial optimization problems. The\ndeveloped methods have shown potential on many optimization problems. In this\npaper, we present a learned heuristic for the reoptimization of a problem after\na minor change in its data. We focus on the case of the capacited vehicle\nrouting problem with static clients (i.e., same client locations) and changed\ndemands. Given the edges of an original solution, the goal is to predict and\nfix the ones that have a high chance of remaining in an optimal solution after\na change of client demands. This partial prediction of the solution reduces the\ncomplexity of the problem and speeds up its resolution, while yielding a good\nquality solution. The proposed approach resulted in solutions with an\noptimality gap ranging from 0\\% to 1.7\\% on different benchmark instances\nwithin a reasonable computing time.",
    "descriptor": "",
    "authors": [
      "Mouad Morabit",
      "Guy Desaulniers",
      "Andrea Lodi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08101"
  },
  {
    "id": "arXiv:2212.08102",
    "title": "A Multi-Modal Machine Learning Approach to Detect Extreme Rainfall  Events in Sicily",
    "abstract": "In 2021 300 mm of rain, nearly half the average annual rainfall, fell near\nCatania (Sicily island, Italy). Such events took place in just a few hours,\nwith dramatic consequences on the environmental, social, economic, and health\nsystems of the region. This is the reason why, detecting extreme rainfall\nevents is a crucial prerequisite for planning actions able to reverse possibly\nintensified dramatic future scenarios. In this paper, the Affinity Propagation\nalgorithm, a clustering algorithm grounded on machine learning, was applied, to\nthe best of our knowledge, for the first time, to identify excess rain events\nin Sicily. This was possible by using a high-frequency, large dataset we\ncollected, ranging from 2009 to 2021 which we named RSE (the Rainfall Sicily\nExtreme dataset). Weather indicators were then been employed to validate the\nresults, thus confirming the presence of recent anomalous rainfall events in\neastern Sicily. We believe that easy-to-use and multi-modal data science\ntechniques, such as the one proposed in this study, could give rise to\nsignificant improvements in policy-making for successfully contrasting climate\nchanges.",
    "descriptor": "",
    "authors": [
      "Eleonora Vitanza",
      "Giovanna Maria Dimitri",
      "Chiara Mocenni"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.08102"
  },
  {
    "id": "arXiv:2212.08130",
    "title": "On Evaluating Adversarial Robustness of Chest X-ray Classification:  Pitfalls and Best Practices",
    "abstract": "Vulnerability to adversarial attacks is a well-known weakness of Deep Neural\nNetworks. While most of the studies focus on natural images with standardized\nbenchmarks like ImageNet and CIFAR, little research has considered real world\napplications, in particular in the medical domain. Our research shows that,\ncontrary to previous claims, robustness of chest x-ray classification is much\nharder to evaluate and leads to very different assessments based on the\ndataset, the architecture and robustness metric. We argue that previous studies\ndid not take into account the peculiarity of medical diagnosis, like the\nco-occurrence of diseases, the disagreement of labellers (domain experts), the\nthreat model of the attacks and the risk implications for each successful\nattack.\nIn this paper, we discuss the methodological foundations, review the pitfalls\nand best practices, and suggest new methodological considerations for\nevaluating the robustness of chest xray classification models. Our evaluation\non 3 datasets, 7 models, and 18 diseases is the largest evaluation of\nrobustness of chest x-ray classification models.",
    "descriptor": "",
    "authors": [
      "Salah Ghamizi",
      "Maxime Cordy",
      "Michail Papadakis",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08130"
  },
  {
    "id": "arXiv:2212.08134",
    "title": "A New Berry-Esseen Theorem for Expander Walks",
    "abstract": "We prove that the sum of $t$ boolean-valued random variables sampled by a\nrandom walk on a regular expander converges in total variation distance to a\ndiscrete normal distribution at a rate of $O(\\lambda/t^{1/2-o(1)})$, where\n$\\lambda$ is the second largest eigenvalue of the random walk matrix in\nabsolute value. To the best of our knowledge, among known Berry-Esseen bounds\nfor Markov chains, our result is the first to show convergence in total\nvariation distance, and is also the first to incorporate a linear dependence on\nexpansion $\\lambda$. In contrast, prior Markov chain Berry-Esseen bounds showed\na convergence rate of $O(1/\\sqrt{t})$ in weaker metrics such as Kolmogorov\ndistance.\nOur result also improves upon prior work in the pseudorandomness literature,\nwhich showed that the total variation distance is $O(\\lambda)$ when the\napproximating distribution is taken to be a binomial distribution. We achieve\nthe faster $O(\\lambda/t^{1/2-o(1)})$ convergence rate by generalizing the\nbinomial distribution to discrete normals of arbitrary variance. We\nspecifically construct discrete normals using a random walk on an appropriate\n2-state Markov chain. Our bound can therefore be viewed as a regularity lemma\nthat reduces the study of arbitrary expanders to a small class of particularly\nsimple expanders.",
    "descriptor": "",
    "authors": [
      "Louis Golowich"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2212.08134"
  },
  {
    "id": "arXiv:2212.08149",
    "title": "Agent-Based Model of Crowd Dynamics in Emergency Situations: A Focus on  People With Disabilities",
    "abstract": "Collective behavior of people in large groups and emergent crowd dynamics can\nhave dangerous and disastrous results when panic is introduced. These events\ncan be caused by emergency situations such as fires in a large building or a\nstampeding effect when people are rushing in a densely packed area. In this\npaper, we will use an agent-based modeling approach to simulate different\nevacuation events in an attempt to understand what is the most efficient\nscenario. Specifically, we will focus on how people with disabilities are\nimpacted by chosen parameters during an emergency evacuation. We chose an ABM\nto simulate this because we want to specify specific roles for different\n\"agents\" in our model. Specifically, we will focus on the influence of people\nwith disabilities on crowd dynamics and the optimal exits. Does the placement\nof seating for people with disabilities affect the time it takes for the last\nperson to exit the building? What effect does poor signage have on the time it\ntakes for able-bodied and people with disabilities to exit safely? What happens\nif some people do not know about alternative exits in their panicked state?\nUsing our agent-based model, we will investigate these questions while also\nadjusting other outside effects such as the density of the crowd, the speed at\nwhich people exit, and the location of people at the start of the simulation.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Janey Alex",
      "Jason Stillerman",
      "Noah Fritzhand",
      "Tucker Paron"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2212.08149"
  },
  {
    "id": "arXiv:2212.08162",
    "title": "Huber-energy measure quantization",
    "abstract": "We describe a measure quantization procedure i.e., an algorithm which finds\nthe best approximation of a target probability law (and more generally signed\nfinite variation measure) by a sum of Q Dirac masses (Q being the quantization\nparameter). The procedure is implemented by minimizing the statistical distance\nbetween the original measure and its quantized version; the distance is built\nfrom a negative definite kernel and, if necessary, can be computed on the fly\nand feed to a stochastic optimization algorithm (such as SGD, Adam, ...). We\ninvestigate theoretically the fundamental questions of existence of the optimal\nmeasure quantizer and identify what are the required kernel properties that\nguarantee suitable behavior. We test the procedure, called HEMQ, on several\ndatabases: multi-dimensional Gaussian mixtures, Wiener space cubature, Italian\nwine cultivars and the MNIST image database. The results indicate that the HEMQ\nalgorithm is robust and versatile and, for the class of Huber-energy kernels,\nit matches the expected intuitive behavior.",
    "descriptor": "",
    "authors": [
      "Gabriel Turinici"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2212.08162"
  },
  {
    "id": "arXiv:2212.08202",
    "title": "Voltage-controlled Cryogenic Boolean Logic Family Based on Ferroelectric  SQUID",
    "abstract": "The recent progress in quantum computing and space exploration led to a surge\nin interest in cryogenic electronics. Superconducting devices such as Josephson\njunction, Josephson field effect transistor, cryotron, and superconducting\nquantum interference device (SQUID) are traditionally used to build cryogenic\nlogic gates. However, due to the superconducting nature, gate-voltage-based\ncontrol of these devices is extremely difficult. Even more challenging is to\ncascade the logic gates because most of these devices require current bias for\ntheir operation. Therefore, these devices are not as convenient as the\nsemiconducting transistors to design logic gates. Here, to overcome these\nchallenges, we propose a ferroelectric SQUID (FeSQUID) based voltage-controlled\nlogic gates. FeSQUID exhibits two different critical current levels for two\ndifferent voltage-switchable polarization states of the ferroelectric. We\nutilize the polarization-dependent (hence, voltage-controllable)\nsuperconducting to resistive switching of FeSQUID to design Boolean logic gates\nsuch as Copy, NOT, AND, and OR gates. The operations of these gates are\nverified using a Verilog-A-based compact model of FeSQUID. Finally, to\ndemonstrate the fanning out capability of FeSQUID-based logic family, we\nsimulate a 2-input XOR gate using FeSQUID-based NOT, AND, and OR gates.\nTogether with the ongoing progress on FeSQUID-based non-volatile memory, our\ndesigned FeSQUID-based logic family will enable all-FeSQUID based cryogenic\ncomputer, ensure minimum mismatch between logic and memory blocks in terms of\nspeed, power consumption, and fabrication process.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Shamiul Alam",
      "Md Shafayat Hossain",
      "Kai Ni",
      "Vijaykrishnan Narayanan",
      "Ahmedullah Aziz"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2212.08202"
  },
  {
    "id": "arXiv:2212.08225",
    "title": "Materials Discovery using Max K-Armed Bandit",
    "abstract": "Search algorithms for the bandit problems are applicable in materials\ndiscovery. However, the objectives of the conventional bandit problem are\ndifferent from those of materials discovery. The conventional bandit problem\naims to maximize the total rewards, whereas materials discovery aims to achieve\nbreakthroughs in material properties. The max K-armed bandit (MKB) problem,\nwhich aims to acquire the single best reward, matches with the discovery tasks\nbetter than the conventional bandit. Thus, here, we propose a search algorithm\nfor materials discovery based on the MKB problem using a pseudo-value of the\nupper confidence bound of expected improvement of the best reward. This\napproach is pseudo-guaranteed to be asymptotic oracles that do not depends on\nthe time horizon. In addition, compared with other MKB algorithms, the proposed\nalgorithm has only one hyperparameter, which is advantageous in materials\ndiscovery. We applied the proposed algorithm to synthetic problems and\nmolecular-design demonstrations using a Monte Carlo tree search. According to\nthe results, the proposed algorithm stably outperformed other bandit algorithms\nin the late stage of the search process when the optimal arm of the MKB could\nnot be determined based on its expectation reward.",
    "descriptor": "",
    "authors": [
      "Nobuaki Kikkawa",
      "Hiroshi Ohno"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.08225"
  },
  {
    "id": "arXiv:2212.08233",
    "title": "Geometry-aware Autoregressive Models for Calorimeter Shower Simulations",
    "abstract": "Calorimeter shower simulations are often the bottleneck in simulation time\nfor particle physics detectors. A lot of effort is currently spent on\noptimizing generative architectures for specific detector geometries, which\ngeneralize poorly. We develop a geometry-aware autoregressive model on a range\nof calorimeter geometries such that the model learns to adapt its energy\ndeposition depending on the size and position of the cells. This is a key\nproof-of-concept step towards building a model that can generalize to new\nunseen calorimeter geometries with little to no additional training. Such a\nmodel can replace the hundreds of generative models used for calorimeter\nsimulation in a Large Hadron Collider experiment. For the study of future\ndetectors, such a model will dramatically reduce the large upfront investment\nusually needed to generate simulations.",
    "descriptor": "\nComments: This paper was submitted to NeurIPS Machine Learning and the Physical Sciences Workshop 2022\n",
    "authors": [
      "Junze Liu",
      "Aishik Ghosh",
      "Dylan Smith",
      "Pierre Baldi",
      "Daniel Whiteson"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2212.08233"
  },
  {
    "id": "arXiv:2212.08321",
    "title": "Investigation of Japanese PnG BERT language model in text-to-speech  synthesis for pitch accent language",
    "abstract": "End-to-end text-to-speech synthesis (TTS) can generate highly natural\nsynthetic speech from raw text. However, rendering the correct pitch accents is\nstill a challenging problem for end-to-end TTS. To tackle the challenge of\nrendering correct pitch accent in Japanese end-to-end TTS, we adopt PnG~BERT, a\nself-supervised pretrained model in the character and phoneme domain for TTS.\nWe investigate the effects of features captured by PnG~BERT on Japanese TTS by\nmodifying the fine-tuning condition to determine the conditions helpful\ninferring pitch accents. We manipulate content of PnG~BERT features from being\ntext-oriented to speech-oriented by changing the number of fine-tuned layers\nduring TTS. In addition, we teach PnG~BERT pitch accent information by\nfine-tuning with tone prediction as an additional downstream task. Our\nexperimental results show that the features of PnG~BERT captured by pretraining\ncontain information helpful inferring pitch accent, and PnG~BERT outperforms\nbaseline Tacotron on accent correctness in a listening test.",
    "descriptor": "",
    "authors": [
      "Yusuke Yasuda",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08321"
  },
  {
    "id": "arXiv:2212.08323",
    "title": "An ensemble neural network approach to forecast Dengue outbreak based on  climatic condition",
    "abstract": "Dengue fever is a virulent disease spreading over 100 tropical and\nsubtropical countries in Africa, the Americas, and Asia. This arboviral disease\naffects around 400 million people globally, severely distressing the healthcare\nsystems. The unavailability of a specific drug and ready-to-use vaccine makes\nthe situation worse. Hence, policymakers must rely on early warning systems to\ncontrol intervention-related decisions. Forecasts routinely provide critical\ninformation for dangerous epidemic events. However, the available forecasting\nmodels (e.g., weather-driven mechanistic, statistical time series, and machine\nlearning models) lack a clear understanding of different components to improve\nprediction accuracy and often provide unstable and unreliable forecasts. This\nstudy proposes an ensemble wavelet neural network with exogenous factor(s)\n(XEWNet) model that can produce reliable estimates for dengue outbreak\nprediction for three geographical regions, namely San Juan, Iquitos, and\nAhmedabad. The proposed XEWNet model is flexible and can easily incorporate\nexogenous climate variable(s) confirmed by statistical causality tests in its\nscalable framework. The proposed model is an integrated approach that uses\nwavelet transformation into an ensemble neural network framework that helps in\ngenerating more reliable long-term forecasts. The proposed XEWNet allows\ncomplex non-linear relationships between the dengue incidence cases and\nrainfall; however, mathematically interpretable, fast in execution, and easily\ncomprehensible. The proposal's competitiveness is measured using computational\nexperiments based on various statistical metrics and several statistical\ncomparison tests. In comparison with statistical, machine learning, and deep\nlearning methods, our proposed XEWNet performs better in 75% of the cases for\nshort-term and long-term forecasting of dengue incidence.",
    "descriptor": "",
    "authors": [
      "Madhurima Panja",
      "Tanujit Chakraborty",
      "Sk Shahid Nadim",
      "Indrajit Ghosh",
      "Uttam Kumar",
      "Nan Liu"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08323"
  },
  {
    "id": "arXiv:2212.08329",
    "title": "Text-to-speech synthesis based on latent variable conversion using  diffusion probabilistic model and variational autoencoder",
    "abstract": "Text-to-speech synthesis (TTS) is a task to convert texts into speech. Two of\nthe factors that have been driving TTS are the advancements of probabilistic\nmodels and latent representation learning. We propose a TTS method based on\nlatent variable conversion using a diffusion probabilistic model and the\nvariational autoencoder (VAE). In our TTS method, we use a waveform model based\non VAE, a diffusion model that predicts the distribution of latent variables in\nthe waveform model from texts, and an alignment model that learns alignments\nbetween the text and speech latent sequences. Our method integrates diffusion\nwith VAE by modeling both mean and variance parameters with diffusion, where\nthe target distribution is determined by approximation from VAE. This latent\nvariable conversion framework potentially enables us to flexibly incorporate\nvarious latent feature extractors. Our experiments show that our method is\nrobust to linguistic labels with poor orthography and alignment errors.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Yusuke Yasuda",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.08329"
  },
  {
    "id": "arXiv:2212.08406",
    "title": "Antichain Codes",
    "abstract": "A family of sets $A$ is said to be an antichain if $x\\not\\subset y$ for all\ndistinct $x,y\\in A$, and it is said to be a distance-$r$ code if every pair of\ndistinct elements of $A$ has Hamming distance at least $r$. Here, we prove that\nif $A\\subset 2^{[n]}$ is both an antichain and a distance-$(2r+1)$ code, then\n$|A| = O_r(2^n n^{-r-1/2})$. This result, which is best-possible up to the\nimplied constant, is a purely combinatorial strengthening of a number of\nresults in Littlewood--Offord theory; for example, our result gives a short\ncombinatorial proof of H\\'alasz's theorem, while all previously known proofs of\nthis result are Fourier-analytic.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Benjamin Gunby",
      "Xiaoyu He",
      "Bhargav Narayanan",
      "Sam Spiro"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.08406"
  },
  {
    "id": "arXiv:2212.08426",
    "title": "Statistically consistent inverse optimal control for discrete-time  indefinite linear-quadratic systems",
    "abstract": "The Inverse Optimal Control (IOC) problem is a structured system\nidentification problem that aims to identify the underlying objective function\nbased on observed optimal trajectories. This provides a data-driven way to\nmodel experts' behavior. In this paper, we consider the case of discrete-time\nfinite-horizon linear-quadratic problems where: the quadratic cost term in the\nobjective is not necessarily positive semi-definite; the planning horizon is a\nrandom variable; we have both process noise and observation noise; the dynamics\ncan have a drift term; and where we can have a linear cost term in the\nobjective. In this setting, we first formulate the necessary and sufficient\nconditions for when the forward optimal control problem is solvable. Next, we\nshow that the corresponding IOC problem is identifiable. Using the optimality\nconditions of the forward problem, we then formulate an estimator for the\nparameters in the objective function of the forward problem as the globally\noptimal solution to a convex optimization problem, and prove that the estimator\nis statistical consistent. Finally, the performance of the algorithm is\ndemonstrated on a numerical example.",
    "descriptor": "\nComments: 19 pages; 1 figure\n",
    "authors": [
      "Han Zhang",
      "Axel Ringh"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.08426"
  },
  {
    "id": "arXiv:2212.08479",
    "title": "Neural Implicit k-Space for Binning-free Non-Cartesian Cardiac MR  Imaging",
    "abstract": "In this work, we propose a novel image reconstruction framework that directly\nlearns a neural implicit representation in k-space for ECG-triggered\nnon-Cartesian Cardiac Magnetic Resonance Imaging (CMR). While existing methods\nbin acquired data from neighboring time points to reconstruct one phase of the\ncardiac motion, our framework allows for a continuous, binning-free, and\nsubject-specific k-space representation.We assign a unique coordinate that\nconsists of time, coil index, and frequency domain location to each sampled\nk-space point. We then learn the subject-specific mapping from these unique\ncoordinates to k-space intensities using a multi-layer perceptron with\nfrequency domain regularization. During inference, we obtain a complete k-space\nfor Cartesian coordinates and an arbitrary temporal resolution. A simple\ninverse Fourier transform recovers the image, eliminating the need for density\ncompensation and costly non-uniform Fourier transforms for non-Cartesian data.\nThis novel imaging framework was tested on 42 radially sampled datasets from 6\nsubjects. The proposed method outperforms other techniques qualitatively and\nquantitatively using data from four and one heartbeat(s) and 30 cardiac phases.\nOur results for one heartbeat reconstruction of 50 cardiac phases show improved\nartifact removal and spatio-temporal resolution, leveraging the potential for\nreal-time CMR.",
    "descriptor": "",
    "authors": [
      "Wenqi Huang",
      "Hongwei Li",
      "Gastao Cruz",
      "Jiazhen Pan",
      "Daniel Rueckert",
      "Kerstin Hammernik"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.08479"
  },
  {
    "id": "arXiv:2212.08498",
    "title": "Evaluating vaccine allocation strategies using simulation-assisted  causal modelling",
    "abstract": "Early on during a pandemic, vaccine availability is limited, requiring\nprioritisation of different population groups. Evaluating vaccine allocation is\ntherefore a crucial element of pandemics response. In the present work, we\ndevelop a model to retrospectively evaluate age-dependent counterfactual\nvaccine allocation strategies against the COVID-19 pandemic. To estimate the\neffect of allocation on the expected severe-case incidence, we employ a\nsimulation-assisted causal modelling approach which combines a compartmental\ninfection-dynamics simulation, a coarse-grained, data-driven causal model and\nliterature estimates for immunity waning. We compare Israel's implemented\nvaccine allocation strategy in 2021 to counterfactual strategies such as no\nprioritisation, prioritisation of younger age groups or a strict risk-ranked\napproach; we find that Israel's implemented strategy was indeed highly\neffective. We also study the marginal impact of increasing vaccine uptake for a\ngiven age group and find that increasing vaccinations in the elderly is most\neffective at preventing severe cases, whereas additional vaccinations for\nmiddle-aged groups reduce infections most effectively. Due to its modular\nstructure, our model can easily be adapted to study future pandemics. We\ndemonstrate this flexibility by investigating vaccine allocation strategies for\na pandemic with characteristics of the Spanish Flu. Our approach thus helps\nevaluate vaccination strategies under the complex interplay of core epidemic\nfactors, including age-dependent risk profiles, immunity waning, vaccine\navailability and spreading rates.",
    "descriptor": "",
    "authors": [
      "Armin Keki\u0107",
      "Jonas Dehning",
      "Luigi Gresele",
      "Julius von K\u00fcgelgen",
      "Viola Priesemann",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.08498"
  },
  {
    "id": "arXiv:2212.08542",
    "title": "Context-aware Fine-tuning of Self-supervised Speech Models",
    "abstract": "Self-supervised pre-trained transformers have improved the state of the art\non a variety of speech tasks. Due to the quadratic time and space complexity of\nself-attention, they usually operate at the level of relatively short (e.g.,\nutterance) segments. In this paper, we study the use of context, i.e.,\nsurrounding segments, during fine-tuning and propose a new approach called\ncontext-aware fine-tuning. We attach a context module on top of the last layer\nof a pre-trained model to encode the whole segment into a context embedding\nvector which is then used as an additional feature for the final prediction.\nDuring the fine-tuning stage, we introduce an auxiliary loss that encourages\nthis context embedding vector to be similar to context vectors of surrounding\nsegments. This allows the model to make predictions without access to these\nsurrounding segments at inference time and requires only a tiny overhead\ncompared to standard fine-tuned models. We evaluate the proposed approach using\nthe SLUE and Librilight benchmarks for several downstream tasks: Automatic\nspeech recognition (ASR), named entity recognition (NER), and sentiment\nanalysis (SA). The results show that context-aware fine-tuning not only\noutperforms a standard fine-tuning baseline but also rivals a strong context\ninjection baseline that uses neighboring speech segments during inference.",
    "descriptor": "",
    "authors": [
      "Suwon Shon",
      "Felix Wu",
      "Kwangyoun Kim",
      "Prashant Sridhar",
      "Karen Livescu",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.08542"
  },
  {
    "id": "arXiv:2212.08546",
    "title": "Estimating truncation effects of quantum bosonic systems using sampling  algorithms",
    "abstract": "To simulate bosons on a qubit- or qudit-based quantum computer, one has to\nregularize the theory by truncating infinite-dimensional local Hilbert spaces\nto finite dimensions. In the search for practical quantum applications, it is\nimportant to know how big the truncation errors can be. In general, it is not\neasy to estimate errors unless we have a good quantum computer. In this paper\nwe show that traditional sampling methods on classical devices, specifically\nMarkov Chain Monte Carlo, can address this issue with a reasonable amount of\ncomputational resources available today. As a demonstration, we apply this idea\nto the scalar field theory on a two-dimensional lattice, with a size that goes\nbeyond what is achievable using exact diagonalization methods. This method can\nbe used to estimate the resources needed for realistic quantum simulations of\nbosonic theories, and also, to check the validity of the results of the\ncorresponding quantum simulations.",
    "descriptor": "\nComments: 19 pages, 3 figures\n",
    "authors": [
      "Masanori Hanada",
      "Junyu Liu",
      "Enrico Rinaldi",
      "Masaki Tezuka"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Lattice (hep-lat)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2212.08546"
  },
  {
    "id": "arXiv:2212.08554",
    "title": "An automated parameter domain decomposition approach for gravitational  wave surrogates using hp-greedy refinement",
    "abstract": "We introduce hp-greedy, a refinement approach for building gravitational wave\nsurrogates as an extension of the standard reduced basis framework. Our\nproposal is data-driven, with a domain decomposition of the parameter space,\nlocal reduced basis, and a binary tree as the resulting structure, which are\nobtained in an automated way. When compared to the standard global reduced\nbasis approach, the numerical simulations of our proposal show three salient\nfeatures: i) representations of lower dimension with no loss of accuracy, ii) a\nsignificantly higher accuracy for a fixed maximum dimensionality of the basis,\nin some cases by orders of magnitude, and iii) results that depend on the\nreduced basis seed choice used by the refinement algorithm. We first illustrate\nthe key parts of our approach with a toy model and then present a more\nrealistic use case of gravitational waves emitted by the collision of two\nspinning, non-precessing black holes. We discuss performance aspects of\nhp-greedy, such as overfitting with respect to the depth of the tree structure,\nand other hyperparameter dependences. As two direct applications of the\nproposed hp-greedy refinement, we envision: i) a further acceleration of\nstatistical inference, which might be complementary to focused reduced-order\nquadratures, and ii) the search of gravitational waves through clustering and\nnearest neighbors.",
    "descriptor": "\nComments: 16 pages, code available from authors upon request\n",
    "authors": [
      "Franco Cerino",
      "J. Andr\u00e9s Diaz-Pace",
      "Manuel Tiglio"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Machine Learning (cs.LG)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2212.08554"
  },
  {
    "id": "arXiv:2212.08559",
    "title": "Grothendieck inequalities characterize converses to the polynomial  method",
    "abstract": "A surprising 'converse to the polynomial method' of Aaronson et al. (CCC'16)\nshows that any bounded quadratic polynomial can be computed exactly in\nexpectation by a 1-query algorithm up to a universal multiplicative factor\nrelated to the famous Grothendieck constant. Here we show that such a result\ndoes not generalize to quartic polynomials and 2-query algorithms, even when we\nallow for additive approximations. We also show that the additive approximation\nimplied by their result is tight for bounded bilinear forms, which gives a new\ncharacterization of the Grothendieck constant in terms of 1-query quantum\nalgorithms. Along the way we provide reformulations of the completely bounded\nnorm of a form, and its dual norm.",
    "descriptor": "",
    "authors": [
      "Jop Bri\u00ebt",
      "Francisco Escudero Guti\u00e9rrez",
      "Sander Gribling"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2212.08559"
  },
  {
    "id": "arXiv:2212.08596",
    "title": "De-risking Carbon Capture and Sequestration with Explainable CO2 Leakage  Detection in Time-lapse Seismic Monitoring Images",
    "abstract": "With the growing global deployment of carbon capture and sequestration\ntechnology to combat climate change, monitoring and detection of potential CO2\nleakage through existing or storage induced faults are critical to the safe and\nlong-term viability of the technology. Recent work on time-lapse seismic\nmonitoring of CO2 storage has shown promising results in its ability to monitor\nthe growth of the CO2 plume from surface recorded seismic data. However, due to\nthe low sensitivity of seismic imaging to CO2 concentration, additional\ndevelopments are required to efficiently interpret the seismic images for\nleakage. In this work, we introduce a binary classification of time-lapse\nseismic images to delineate CO2 plumes (leakage) using state-of-the-art deep\nlearning models. Additionally, we localize the leakage region of CO2 plumes by\nleveraging Class Activation Mapping methods.",
    "descriptor": "",
    "authors": [
      "Huseyin Tuna Erdinc",
      "Abhinav Prakash Gahlot",
      "Ziyi Yin",
      "Mathias Louboutin",
      "Felix J. Herrmann"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.08596"
  },
  {
    "id": "arXiv:2212.08599",
    "title": "Computing Well-Covered Vector Spaces of Graphs using Modular  Decomposition",
    "abstract": "A graph is well-covered if all its maximal independent sets have the same\ncardinality. This well studied concept was introduced by Plummer in 1970 and\nnaturally generalizes to the weighted case. Given a graph $G$, a real-valued\nvertex weight function $w$ is said to be a well-covered weighting of $G$ if all\nits maximal independent sets are of the same weight. The set of all\nwell-covered weightings of a graph $G$ forms a vector space over the field of\nreal numbers, called the well-covered vector space of $G$. Since the problem of\nrecognizing well-covered graphs is $\\mathsf{co}$-$\\mathsf{NP}$-complete, the\nproblem of computing the well-covered vector space of a given graph is\n$\\mathsf{co}$-$\\mathsf{NP}$-hard. Levit and Tankus showed in 2015 that the\nproblem admits a polynomial-time algorithm in the class of claw-free graph. In\nthis paper, we give two general reductions for the problem, one based on\nanti-neighborhoods and one based on modular decomposition, combined with\nGaussian elimination. Building on these results, we develop a polynomial-time\nalgorithm for computing the well-covered vector space of a given fork-free\ngraph, generalizing the result of Levit and Tankus. Our approach implies that\nwell-covered fork-free graphs can be recognized in polynomial time and also\ngeneralizes some known results on cographs.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Martin Milani\u010d",
      "Nevena Piva\u010d"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.08599"
  },
  {
    "id": "arXiv:2212.08624",
    "title": "Development of A Real-time POCUS Image Quality Assessment and  Acquisition Guidance System",
    "abstract": "Point-of-care ultrasound (POCUS) is one of the most commonly applied tools\nfor cardiac function imaging in the clinical routine of the emergency\ndepartment and pediatric intensive care unit. The prior studies demonstrate\nthat AI-assisted software can guide nurses or novices without prior sonography\nexperience to acquire POCUS by recognizing the interest region, assessing image\nquality, and providing instructions. However, these AI algorithms cannot simply\nreplace the role of skilled sonographers in acquiring diagnostic-quality POCUS.\nUnlike chest X-ray, CT, and MRI, which have standardized imaging protocols,\nPOCUS can be acquired with high inter-observer variability. Though being with\nvariability, they are usually all clinically acceptable and interpretable. In\nchallenging clinical environments, sonographers employ novel heuristics to\nacquire POCUS in complex scenarios. To help novice learners to expedite the\ntraining process while reducing the dependency on experienced sonographers in\nthe curriculum implementation, We will develop a framework to perform real-time\nAI-assisted quality assessment and probe position guidance to provide training\nprocess for novice learners with less manual intervention.",
    "descriptor": "",
    "authors": [
      "Zhenge Jia",
      "Yiyu Shi",
      "Jingtong Hu",
      "Lei Yang",
      "Benjamin Nti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.08624"
  },
  {
    "id": "arXiv:1904.06666",
    "title": "Mutual Information-Maximizing Quantized Belief Propagation Decoding of  Regular LDPC Codes",
    "abstract": "Mutual Information-Maximizing Quantized Belief Propagation Decoding of  Regular LDPC Codes",
    "descriptor": "",
    "authors": [
      "Xuan He",
      "Kui Cai",
      "Zhen Mei",
      "Peng Kang",
      "Xiaohu Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1904.06666"
  },
  {
    "id": "arXiv:1910.02519",
    "title": "FIS-GAN: GAN with Flow-based Importance Sampling",
    "abstract": "FIS-GAN: GAN with Flow-based Importance Sampling",
    "descriptor": "",
    "authors": [
      "Shiyu Yi",
      "Donglin Zhan",
      "Wenqing Zhang",
      "Denglin Jiang",
      "Kang An",
      "Hao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.02519"
  },
  {
    "id": "arXiv:1912.11686",
    "title": "Convergence of a Distributed Least Squares",
    "abstract": "Comments: 8 pages, published in IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: 8 pages, published in IEEE Transactions on Automatic Control\n",
    "authors": [
      "Siyu Xie",
      "Yaqi Zhang",
      "Lei Guo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1912.11686"
  },
  {
    "id": "arXiv:2006.10102",
    "title": "Capturing Label Characteristics in VAEs",
    "abstract": "Comments: Accepted to ICLR 2021",
    "descriptor": "\nComments: Accepted to ICLR 2021\n",
    "authors": [
      "Tom Joy",
      "Sebastian M. Schmon",
      "Philip H. S. Torr",
      "N. Siddharth",
      "Tom Rainforth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10102"
  },
  {
    "id": "arXiv:2009.04709",
    "title": "Quantifying the Preferential Direction of the Model Gradient in  Adversarial Training With Projected Gradient Descent",
    "abstract": "Quantifying the Preferential Direction of the Model Gradient in  Adversarial Training With Projected Gradient Descent",
    "descriptor": "",
    "authors": [
      "Ricardo Bigolin Lanfredi",
      "Joyce D. Schroeder",
      "Tolga Tasdizen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.04709"
  },
  {
    "id": "arXiv:2012.14309",
    "title": "General Mechanism of Evolution Shared by Proteins and Words",
    "abstract": "General Mechanism of Evolution Shared by Proteins and Words",
    "descriptor": "",
    "authors": [
      "Li-Min Wang",
      "Hsing-Yi Lai",
      "Sun-Ting Tsai",
      "Chen Siang Ng",
      "Shan-Jyun Wu",
      "Meng-Xue Tsai",
      "Yi-Ching Su",
      "Daw-Wei Wang",
      "Tzay-Ming Hong"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Computation and Language (cs.CL)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.14309"
  },
  {
    "id": "arXiv:2101.11878",
    "title": "CORL: Compositional Representation Learning for Few-Shot Classification",
    "abstract": "CORL: Compositional Representation Learning for Few-Shot Classification",
    "descriptor": "",
    "authors": [
      "Ju He",
      "Adam Kortylewski",
      "Alan Yuille"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.11878"
  },
  {
    "id": "arXiv:2102.00512",
    "title": "Quantum game theory and the complexity of approximating quantum Nash  equilibria",
    "abstract": "Quantum game theory and the complexity of approximating quantum Nash  equilibria",
    "descriptor": "",
    "authors": [
      "John Bostanci",
      "John Watrous"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.00512"
  },
  {
    "id": "arXiv:2102.07085",
    "title": "Light Field Reconstruction via Deep Adaptive Fusion of Hybrid Lenses",
    "abstract": "Comments: 18 pages, 12 figures. arXiv admin note: text overlap with arXiv:1907.09640",
    "descriptor": "\nComments: 18 pages, 12 figures. arXiv admin note: text overlap with arXiv:1907.09640\n",
    "authors": [
      "Jing Jin",
      "Mantang Guo",
      "Hui Liu",
      "Junhui Hou",
      "Hongkai Xiong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.07085"
  },
  {
    "id": "arXiv:2102.11270",
    "title": "Softmax Policy Gradient Methods Can Take Exponential Time to Converge",
    "abstract": "Comments: accepted to Mathematical Programming (Series A); also presented in part in Conference on Learning Theory (COLT) 2021",
    "descriptor": "\nComments: accepted to Mathematical Programming (Series A); also presented in part in Conference on Learning Theory (COLT) 2021\n",
    "authors": [
      "Gen Li",
      "Yuting Wei",
      "Yuejie Chi",
      "Yuxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.11270"
  },
  {
    "id": "arXiv:2104.02461",
    "title": "Sorted Range Reporting",
    "abstract": "Sorted Range Reporting",
    "descriptor": "",
    "authors": [
      "Waseem Akram",
      "Sanjeev Saxena"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.02461"
  },
  {
    "id": "arXiv:2104.09884",
    "title": "Multi-objective Evolutionary Algorithms are Generally Good: Maximizing  Monotone Submodular Functions over Sequences",
    "abstract": "Comments: 46 pages, 5 figures, 15 tables",
    "descriptor": "\nComments: 46 pages, 5 figures, 15 tables\n",
    "authors": [
      "Chao Qian",
      "Dan-Xuan Liu",
      "Chao Feng",
      "Ke Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2104.09884"
  },
  {
    "id": "arXiv:2105.04187",
    "title": "A Rigorous Information-Theoretic Definition of Redundancy and Relevancy  in Feature Selection Based on (Partial) Information Decomposition",
    "abstract": "Comments: 43 pages, 12 figures. Reorganization and shortening of manuscript, added Appendix with theoretical guarantees, background information on the algorithm used, and an additional example application on a larger problem",
    "descriptor": "\nComments: 43 pages, 12 figures. Reorganization and shortening of manuscript, added Appendix with theoretical guarantees, background information on the algorithm used, and an additional example application on a larger problem\n",
    "authors": [
      "Patricia Wollstadt",
      "Sebastian Schmitt",
      "Michael Wibral"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04187"
  },
  {
    "id": "arXiv:2105.14452",
    "title": "A unified logical framework for explanations in classifier systems",
    "abstract": "Comments: 36 pages",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Xinghan Liu",
      "Emiliano Lorini"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14452"
  },
  {
    "id": "arXiv:2106.02735",
    "title": "Learning particle swarming models from data with Gaussian processes",
    "abstract": "Comments: 44 pages; Appendix 5 pages",
    "descriptor": "\nComments: 44 pages; Appendix 5 pages\n",
    "authors": [
      "Jinchao Feng",
      "Charles Kulick",
      "Yunxiang Ren",
      "Sui Tang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.02735"
  },
  {
    "id": "arXiv:2106.12570",
    "title": "Learning Multimodal VAEs through Mutual Supervision",
    "abstract": "Learning Multimodal VAEs through Mutual Supervision",
    "descriptor": "",
    "authors": [
      "Tom Joy",
      "Yuge Shi",
      "Philip H.S. Torr",
      "Tom Rainforth",
      "Sebastian M. Schmon",
      "N. Siddharth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.12570"
  },
  {
    "id": "arXiv:2107.06127",
    "title": "On the impact of Performance Antipatterns in multi-objective software  model refactoring optimization",
    "abstract": "On the impact of Performance Antipatterns in multi-objective software  model refactoring optimization",
    "descriptor": "",
    "authors": [
      "Vittorio Cortellessa",
      "Daniele Di Pompeo",
      "Vincenzo Stoico",
      "Michele Tucci"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2107.06127"
  },
  {
    "id": "arXiv:2108.05075",
    "title": "Jujutsu: A Two-stage Defense against Adversarial Patch Attacks on Deep  Neural Networks",
    "abstract": "Comments: To appear in AsiaCCS'23",
    "descriptor": "\nComments: To appear in AsiaCCS'23\n",
    "authors": [
      "Zitao Chen",
      "Pritam Dash",
      "Karthik Pattabiraman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.05075"
  },
  {
    "id": "arXiv:2108.07639",
    "title": "Learning C to x86 Translation: An Experiment in Neural Compilation",
    "abstract": "Comments: Published in AIPLANS 2021",
    "descriptor": "\nComments: Published in AIPLANS 2021\n",
    "authors": [
      "Jordi Armengol-Estap\u00e9",
      "Michael F.P. O'Boyle"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2108.07639"
  },
  {
    "id": "arXiv:2108.08125",
    "title": "Multi-Variant Execution at the Edge",
    "abstract": "Multi-Variant Execution at the Edge",
    "descriptor": "",
    "authors": [
      "Javier Cabrera-Arteaga",
      "Pierre Laperdrix",
      "Martin Monperrus",
      "Benoit Baudry"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2108.08125"
  },
  {
    "id": "arXiv:2109.01126",
    "title": "An Electro-Photonic System for Accelerating Deep Neural Networks",
    "abstract": "An Electro-Photonic System for Accelerating Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Cansu Demirkiran",
      "Furkan Eris",
      "Gongyu Wang",
      "Jonathan Elmhurst",
      "Nick Moore",
      "Nicholas C. Harris",
      "Ayon Basumallik",
      "Vijay Janapa Reddi",
      "Ajay Joshi",
      "Darius Bunandar"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2109.01126"
  },
  {
    "id": "arXiv:2109.05952",
    "title": "Adapting the Tesseract Open-Source OCR Engine for Tamil and Sinhala  Legacy Fonts and Creating a Parallel Corpus for Tamil-Sinhala-English",
    "abstract": "Comments: 7 Pages",
    "descriptor": "\nComments: 7 Pages\n",
    "authors": [
      "Charangan Vasantharajan",
      "Laksika Tharmalingam",
      "Uthayasanker Thayasivam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05952"
  },
  {
    "id": "arXiv:2110.03905",
    "title": "COVID-19 Monitoring System using Social Distancing and Face Mask  Detection on Surveillance video datasets",
    "abstract": "Comments: I, Rujula Singh R, would like to apologize to the research community for the confusion caused by the inconsistency in author lists between multiple versions of this paper. I take full responsibility for this error and will be more diligent in the future to ensure the accuracy and consistency of our research publications",
    "descriptor": "\nComments: I, Rujula Singh R, would like to apologize to the research community for the confusion caused by the inconsistency in author lists between multiple versions of this paper. I take full responsibility for this error and will be more diligent in the future to ensure the accuracy and consistency of our research publications\n",
    "authors": [
      "Sahana Srinivasan",
      "Rujula Singh R",
      "Ruchita R Biradar",
      "Revathi SA"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03905"
  },
  {
    "id": "arXiv:2110.15701",
    "title": "Successor Feature Representations",
    "abstract": "Comments: source code available at this https URL [v2] added experiments with learned features [v3] renamed paper and changed scope",
    "descriptor": "\nComments: source code available at this https URL [v2] added experiments with learned features [v3] renamed paper and changed scope\n",
    "authors": [
      "Chris Reinke",
      "Xavier Alameda-Pineda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15701"
  },
  {
    "id": "arXiv:2112.01955",
    "title": "Revisiting Neuron Coverage for DNN Testing: A Layer-Wise and  Distribution-Aware Criterion",
    "abstract": "Comments: The extended version of a paper to appear in the Proceedings of the 45th IEEE/ACM International Conference on Software Engineering, 2023, (ICSE '23), 14 pages",
    "descriptor": "\nComments: The extended version of a paper to appear in the Proceedings of the 45th IEEE/ACM International Conference on Software Engineering, 2023, (ICSE '23), 14 pages\n",
    "authors": [
      "Yuanyuan Yuan",
      "Qi Pang",
      "Shuai Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.01955"
  },
  {
    "id": "arXiv:2201.10835",
    "title": "Perfect Matching in Random Graphs is as Hard as Tseitin",
    "abstract": "Comments: 43 pages, 4 figures, SODA 2022",
    "descriptor": "\nComments: 43 pages, 4 figures, SODA 2022\n",
    "authors": [
      "Per Austrin",
      "Kilian Risse"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.10835"
  },
  {
    "id": "arXiv:2201.12584",
    "title": "Convolutional Filtering in Simplicial Complexes",
    "abstract": "Comments: 5 pages, 2 figures, accepted in ICASSP 2022 (The first version has some errors and we fixed them in the second version)",
    "descriptor": "\nComments: 5 pages, 2 figures, accepted in ICASSP 2022 (The first version has some errors and we fixed them in the second version)\n",
    "authors": [
      "Elvin Isufi",
      "Maosheng Yang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12584"
  },
  {
    "id": "arXiv:2201.12592",
    "title": "Exact Decomposition of Joint Low Rankness and Local Smoothness Plus  Sparse Matrices",
    "abstract": "Comments: 15 pages, 14 figures, 4 tables",
    "descriptor": "\nComments: 15 pages, 14 figures, 4 tables\n",
    "authors": [
      "Jiangjun Peng",
      "Yao Wang",
      "Hongying Zhang",
      "Jianjun Wang",
      "Deyu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12592"
  },
  {
    "id": "arXiv:2202.05085",
    "title": "MONI can find k-MEMs",
    "abstract": "MONI can find k-MEMs",
    "descriptor": "",
    "authors": [
      "Igor Tatarnikov",
      "Ardavan Shahrabi Farahani",
      "Sana Kashgouli",
      "Travis Gagie"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.05085"
  },
  {
    "id": "arXiv:2202.05159",
    "title": "Dimensional criterion for forecasting nonlinear systems by reservoir  computing",
    "abstract": "Comments: 9 pages, 7 figures",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Pauliina K\u00e4rkk\u00e4inen",
      "Riku Linna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2202.05159"
  },
  {
    "id": "arXiv:2202.06997",
    "title": "Cross-Modality Neuroimage Synthesis: A Survey",
    "abstract": "Cross-Modality Neuroimage Synthesis: A Survey",
    "descriptor": "",
    "authors": [
      "Guoyang Xie",
      "Jinbao Wang",
      "Yawen Huang",
      "Jiayi Lyu",
      "Feng Zheng",
      "Yefeng Zheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.06997"
  },
  {
    "id": "arXiv:2202.08081",
    "title": "Reasoning with fuzzy and uncertain evidence using epistemic random fuzzy  sets: general framework and practical models",
    "abstract": "Reasoning with fuzzy and uncertain evidence using epistemic random fuzzy  sets: general framework and practical models",
    "descriptor": "",
    "authors": [
      "Thierry Denoeux"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.08081"
  },
  {
    "id": "arXiv:2203.05701",
    "title": "6-DoF Pose Estimation of Household Objects for Robotic Manipulation: An  Accessible Dataset and Benchmark",
    "abstract": "Comments: IROS 2022. Project page is at this https URL",
    "descriptor": "\nComments: IROS 2022. Project page is at this https URL\n",
    "authors": [
      "Stephen Tyree",
      "Jonathan Tremblay",
      "Thang To",
      "Jia Cheng",
      "Terry Mosier",
      "Jeffrey Smith",
      "Stan Birchfield"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05701"
  },
  {
    "id": "arXiv:2203.07158",
    "title": "Lowerbounds for Bisimulation by Partition Refinement",
    "abstract": "Comments: Submitted to special issue of CONCUR 2021. This update is the revised version",
    "descriptor": "\nComments: Submitted to special issue of CONCUR 2021. This update is the revised version\n",
    "authors": [
      "Jan Friso Groote",
      "Jan Martens",
      "Erik. P. de Vink"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.07158"
  },
  {
    "id": "arXiv:2203.17068",
    "title": "EEND-SS: Joint End-to-End Neural Speaker Diarization and Speech  Separation for Flexible Number of Speakers",
    "abstract": "Comments: Accepted in SLT 2022",
    "descriptor": "\nComments: Accepted in SLT 2022\n",
    "authors": [
      "Soumi Maiti",
      "Yushi Ueda",
      "Shinji Watanabe",
      "Chunlei Zhang",
      "Meng Yu",
      "Shi-Xiong Zhang",
      "Yong Xu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.17068"
  },
  {
    "id": "arXiv:2204.01900",
    "title": "RIS-aided Cooperative FD-SWIPT-NOMA Outage Performance in Nakagami-m  Channels",
    "abstract": "Comments: 30 pages, 8 figures, full paper",
    "descriptor": "\nComments: 30 pages, 8 figures, full paper\n",
    "authors": [
      "Wilson de Souza Junior",
      "Taufik Abrao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.01900"
  },
  {
    "id": "arXiv:2204.02704",
    "title": "Fundamental limits to learning closed-form mathematical models from data",
    "abstract": "Fundamental limits to learning closed-form mathematical models from data",
    "descriptor": "",
    "authors": [
      "Oscar Fajardo-Fontiveros",
      "Ignasi Reichardt",
      "Harry R. De Los Rios",
      "Jordi Duch",
      "Marta Sales-Pardo",
      "Roger Guimera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2204.02704"
  },
  {
    "id": "arXiv:2204.10779",
    "title": "CgAT: Center-Guided Adversarial Training for Deep Hashing-Based  Retrieval",
    "abstract": "CgAT: Center-Guided Adversarial Training for Deep Hashing-Based  Retrieval",
    "descriptor": "",
    "authors": [
      "Xunguang Wang",
      "Yinqun Lin",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.10779"
  },
  {
    "id": "arXiv:2204.13825",
    "title": "A node-based uniform strain virtual element method for compressible and  nearly incompressible elasticity",
    "abstract": "A node-based uniform strain virtual element method for compressible and  nearly incompressible elasticity",
    "descriptor": "",
    "authors": [
      "A. Ortiz-Bernardin",
      "R. Silva-Valenzuela",
      "S. Salinas-Fern\u00e1ndez",
      "N. Hitschfeld-Kahler",
      "S. Luza",
      "B. Rebolledo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.13825"
  },
  {
    "id": "arXiv:2204.14153",
    "title": "Guarded Kleene Algebra with Tests: Automata Learning",
    "abstract": "Guarded Kleene Algebra with Tests: Automata Learning",
    "descriptor": "",
    "authors": [
      "Stefan Zetzsche",
      "Alexandra Silva",
      "Matteo Sammartino"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2204.14153"
  },
  {
    "id": "arXiv:2205.04769",
    "title": "Reliable Monte Carlo Localization for Mobile Robots",
    "abstract": "Reliable Monte Carlo Localization for Mobile Robots",
    "descriptor": "",
    "authors": [
      "Naoki Akai"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.04769"
  },
  {
    "id": "arXiv:2205.04948",
    "title": "Transformer-based Cross-Modal Recipe Embeddings with Large Batch  Training",
    "abstract": "Comments: Accepted at MMM2023",
    "descriptor": "\nComments: Accepted at MMM2023\n",
    "authors": [
      "Jing Yang",
      "Junwen Chen",
      "Keiji Yanai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.04948"
  },
  {
    "id": "arXiv:2205.06327",
    "title": "Image Gradient Decomposition for Parallel and Memory-Efficient  Ptychographic Reconstruction",
    "abstract": "Image Gradient Decomposition for Parallel and Memory-Efficient  Ptychographic Reconstruction",
    "descriptor": "",
    "authors": [
      "Xiao Wang",
      "Aristeidis Tsaris",
      "Debangshu Mukherjee",
      "Mohamed Wahib",
      "Peng Chen",
      "Mark Oxley",
      "Olga Ovchinnikova",
      "Jacob Hinkle"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.06327"
  },
  {
    "id": "arXiv:2205.06974",
    "title": "On the Joint Optimization of Energy Harvesting and Sensing of  Piezoelectric Energy Harvesters: Case Study of a Cable-Stayed Bridge",
    "abstract": "On the Joint Optimization of Energy Harvesting and Sensing of  Piezoelectric Energy Harvesters: Case Study of a Cable-Stayed Bridge",
    "descriptor": "",
    "authors": [
      "Patricio Peralta-Braz",
      "Mehrisadat Makki Alamdari",
      "Rafael O. Ruiz",
      "Elena Atroshchenko",
      "Mahbub Hassan"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.06974"
  },
  {
    "id": "arXiv:2205.11495",
    "title": "Flexible Diffusion Modeling of Long Videos",
    "abstract": "Flexible Diffusion Modeling of Long Videos",
    "descriptor": "",
    "authors": [
      "William Harvey",
      "Saeid Naderiparizi",
      "Vaden Masrani",
      "Christian Weilbach",
      "Frank Wood"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11495"
  },
  {
    "id": "arXiv:2205.12134",
    "title": "Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box  Score-Based Query Attacks",
    "abstract": "Comments: accepted by NeurIPS 2022",
    "descriptor": "\nComments: accepted by NeurIPS 2022\n",
    "authors": [
      "Sizhe Chen",
      "Zhehao Huang",
      "Qinghua Tao",
      "Yingwen Wu",
      "Cihang Xie",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.12134"
  },
  {
    "id": "arXiv:2205.14100",
    "title": "GIT: A Generative Image-to-text Transformer for Vision and Language",
    "abstract": "GIT: A Generative Image-to-text Transformer for Vision and Language",
    "descriptor": "",
    "authors": [
      "Jianfeng Wang",
      "Zhengyuan Yang",
      "Xiaowei Hu",
      "Linjie Li",
      "Kevin Lin",
      "Zhe Gan",
      "Zicheng Liu",
      "Ce Liu",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14100"
  },
  {
    "id": "arXiv:2206.00129",
    "title": "Fairness Transferability Subject to Bounded Distribution Shift",
    "abstract": "Fairness Transferability Subject to Bounded Distribution Shift",
    "descriptor": "",
    "authors": [
      "Yatong Chen",
      "Reilly Raab",
      "Jialu Wang",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.00129"
  },
  {
    "id": "arXiv:2206.07144",
    "title": "Flatten the Curve: Efficiently Training Low-Curvature Neural Networks",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Suraj Srinivas",
      "Kyle Matoba",
      "Himabindu Lakkaraju",
      "Francois Fleuret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07144"
  },
  {
    "id": "arXiv:2206.08871",
    "title": "How Robust is Unsupervised Representation Learning to Distribution  Shift?",
    "abstract": "How Robust is Unsupervised Representation Learning to Distribution  Shift?",
    "descriptor": "",
    "authors": [
      "Yuge Shi",
      "Imant Daunhawer",
      "Julia E. Vogt",
      "Philip H.S. Torr",
      "Amartya Sanyal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.08871"
  },
  {
    "id": "arXiv:2206.10963",
    "title": "FLaaS: Cross-App On-device Federated Learning in Mobile Environments",
    "abstract": "Comments: 12 pages, 6 figures, 46 references",
    "descriptor": "\nComments: 12 pages, 6 figures, 46 references\n",
    "authors": [
      "Kleomenis Katevas",
      "Diego Perino",
      "Nicolas Kourtellis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.10963"
  },
  {
    "id": "arXiv:2206.12275",
    "title": "Rise of the Planet of Serverless Computing: A Systematic Review",
    "abstract": "Rise of the Planet of Serverless Computing: A Systematic Review",
    "descriptor": "",
    "authors": [
      "Jinfeng Wen",
      "Zhenpeng Chen",
      "Xin Jin",
      "Xuanzhe Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.12275"
  },
  {
    "id": "arXiv:2207.01546",
    "title": "Approximation bounds for convolutional neural networks in operator  learning",
    "abstract": "Approximation bounds for convolutional neural networks in operator  learning",
    "descriptor": "",
    "authors": [
      "Nicola Rares Franco",
      "Stefania Fresca",
      "Andrea Manzoni",
      "Paolo Zunino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.01546"
  },
  {
    "id": "arXiv:2207.02062",
    "title": "Image Amodal Completion: A Survey",
    "abstract": "Comments: The manuscript is under consideration at Computer Vision and Image Understanding",
    "descriptor": "\nComments: The manuscript is under consideration at Computer Vision and Image Understanding\n",
    "authors": [
      "Jiayang Ao",
      "Qiuhong Ke",
      "Krista A. Ehinger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02062"
  },
  {
    "id": "arXiv:2207.04159",
    "title": "The SPEC-RG Reference Architecture for the Edge Continuum",
    "abstract": "Comments: 14 pages, SPEC-RG technical report",
    "descriptor": "\nComments: 14 pages, SPEC-RG technical report\n",
    "authors": [
      "Matthijs Jansen",
      "Auday Al-Dulaimy",
      "Alessandro V. Papadopoulos",
      "Animesh Trivedi",
      "Alexandru Iosup"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.04159"
  },
  {
    "id": "arXiv:2207.04931",
    "title": "Online bin stretching lower bounds: Improved search of computational  proofs",
    "abstract": "Online bin stretching lower bounds: Improved search of computational  proofs",
    "descriptor": "",
    "authors": [
      "Antoine Lhomme",
      "Olivier Romane",
      "Nicolas Catusse",
      "Nadia Brauner"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.04931"
  },
  {
    "id": "arXiv:2207.07694",
    "title": "Parikh Automata over Infinite Words",
    "abstract": "Parikh Automata over Infinite Words",
    "descriptor": "",
    "authors": [
      "Shibashis Guha",
      "Isma\u00ebl Jecker",
      "Karoliina Lehtinen",
      "Martin Zimmermann"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.07694"
  },
  {
    "id": "arXiv:2207.07859",
    "title": "Deep Learning and Its Applications to WiFi Human Sensing: A Benchmark  and A Tutorial",
    "abstract": "Comments: A benchmark and tutorial for WiFi CSI Human sensing based on deep learning methods",
    "descriptor": "\nComments: A benchmark and tutorial for WiFi CSI Human sensing based on deep learning methods\n",
    "authors": [
      "Jianfei Yang",
      "Xinyan Chen",
      "Dazhuo Wang",
      "Han Zou",
      "Chris Xiaoxuan Lu",
      "Sumei Sun",
      "Lihua Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.07859"
  },
  {
    "id": "arXiv:2207.08253",
    "title": "Rationality-Robust Information Design: Bayesian Persuasion under Quantal  Response",
    "abstract": "Rationality-Robust Information Design: Bayesian Persuasion under Quantal  Response",
    "descriptor": "",
    "authors": [
      "Yiding Feng",
      "Chien-Ju Ho",
      "Wei Tang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.08253"
  },
  {
    "id": "arXiv:2207.08329",
    "title": "Bayesian Quickest Change Detection of an Intruder in Acknowledgments for  Private Remote State Estimation",
    "abstract": "Comments: 6 pages, 5 figures",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Justin M. Kennedy",
      "Jason J. Ford",
      "Daniel E. Quevedo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.08329"
  },
  {
    "id": "arXiv:2207.08701",
    "title": "Notes on Boolean Read-k and Multilinear Circuits",
    "abstract": "Comments: Revised version. Added Corollary 1, Facts 1 to 4, Remarks 4 and 5",
    "descriptor": "\nComments: Revised version. Added Corollary 1, Facts 1 to 4, Remarks 4 and 5\n",
    "authors": [
      "Stasys Jukna"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2207.08701"
  },
  {
    "id": "arXiv:2207.11448",
    "title": "Airfoil Optimization using Design-by-Morphing",
    "abstract": "Airfoil Optimization using Design-by-Morphing",
    "descriptor": "",
    "authors": [
      "Haris Moazam Sheikh",
      "Sangjoon Lee",
      "Jinge Wang",
      "Philip S. Marcus"
    ],
    "subjectives": [
      "Geometric Topology (math.GT)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.11448"
  },
  {
    "id": "arXiv:2207.12065",
    "title": "Dynamic Channel Selection in Self-Supervised Learning",
    "abstract": "Comments: Accepted in Irish Machine Vision and Image Processing Conference 2022",
    "descriptor": "\nComments: Accepted in Irish Machine Vision and Image Processing Conference 2022\n",
    "authors": [
      "Tarun Krishna",
      "Ayush K. Rai",
      "Yasser A. D. Djilali",
      "Alan F. Smeaton",
      "Kevin McGuinness",
      "Noel E. O'Connor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.12065"
  },
  {
    "id": "arXiv:2207.12080",
    "title": "Intention-Conditioned Long-Term Human Egocentric Action Forecasting",
    "abstract": "Comments: Validation report Winner of CVPR@2022 and ECCV@2022 EGO4D LTA Challenge Accepted in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023 More info this https URL",
    "descriptor": "\nComments: Validation report Winner of CVPR@2022 and ECCV@2022 EGO4D LTA Challenge Accepted in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023 More info this https URL\n",
    "authors": [
      "Esteve Valls Mascaro",
      "Hyemin Ahn",
      "Dongheui Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.12080"
  },
  {
    "id": "arXiv:2207.12194",
    "title": "Domain Decorrelation with Potential Energy Ranking",
    "abstract": "Comments: 2022 ECCV jury award, accepted by AAAI 2023",
    "descriptor": "\nComments: 2022 ECCV jury award, accepted by AAAI 2023\n",
    "authors": [
      "Sen Pei",
      "Jiaxi Sun",
      "Richard Yi Da Xu",
      "Shiming Xiang",
      "Gaofeng Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.12194"
  },
  {
    "id": "arXiv:2207.13240",
    "title": "Contrastive Image Synthesis and Self-supervised Feature Adaptation for  Cross-Modality Biomedical Image Segmentation",
    "abstract": "Contrastive Image Synthesis and Self-supervised Feature Adaptation for  Cross-Modality Biomedical Image Segmentation",
    "descriptor": "",
    "authors": [
      "Xinrong Hu",
      "Corey Wang",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.13240"
  },
  {
    "id": "arXiv:2207.13959",
    "title": "ZDD-Based Algorithmic Framework for Solving Shortest Reconfiguration  Problems",
    "abstract": "ZDD-Based Algorithmic Framework for Solving Shortest Reconfiguration  Problems",
    "descriptor": "",
    "authors": [
      "Takehiro Ito",
      "Jun Kawahara",
      "Yu Nakahata",
      "Takehide Soh",
      "Akira Suzuki",
      "Junichi Teruyama",
      "Takahisa Toda"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2207.13959"
  },
  {
    "id": "arXiv:2208.02541",
    "title": "MVSFormer: Multi-View Stereo by Learning Robust Image Features and  Temperature-based Depth",
    "abstract": "MVSFormer: Multi-View Stereo by Learning Robust Image Features and  Temperature-based Depth",
    "descriptor": "",
    "authors": [
      "Chenjie Cao",
      "Xinlin Ren",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.02541"
  },
  {
    "id": "arXiv:2208.02879",
    "title": "PointConvFormer: Revenge of the Point-based Convolution",
    "abstract": "PointConvFormer: Revenge of the Point-based Convolution",
    "descriptor": "",
    "authors": [
      "Wenxuan Wu",
      "Qi Shan",
      "Li Fuxin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.02879"
  },
  {
    "id": "arXiv:2208.03926",
    "title": "Achievable Refined Asymptotics for Successive Refinement Using Gaussian  Codebooks",
    "abstract": "Achievable Refined Asymptotics for Successive Refinement Using Gaussian  Codebooks",
    "descriptor": "",
    "authors": [
      "Lin Bai",
      "Zhuangfei Wu",
      "Lin Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.03926"
  },
  {
    "id": "arXiv:2208.07775",
    "title": "SAT-Inspired Higher-Order Eliminations",
    "abstract": "Comments: 23 pages, 1 figure",
    "descriptor": "\nComments: 23 pages, 1 figure\n",
    "authors": [
      "Jasmin Blanchette",
      "Petar Vukmirovi\u0107"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2208.07775"
  },
  {
    "id": "arXiv:2208.10521",
    "title": "Estimation Contracts for Outlier-Robust Geometric Perception",
    "abstract": "Comments: 95 pages, 12 figures",
    "descriptor": "\nComments: 95 pages, 12 figures\n",
    "authors": [
      "Luca Carlone"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10521"
  },
  {
    "id": "arXiv:2208.11674",
    "title": "On the Dependency Heaviness of CRAN/Bioconductor Ecosystem",
    "abstract": "On the Dependency Heaviness of CRAN/Bioconductor Ecosystem",
    "descriptor": "",
    "authors": [
      "Zuguang Gu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.11674"
  },
  {
    "id": "arXiv:2208.13290",
    "title": "Domain Adaptation Principal Component Analysis: base linear method for  learning with out-of-distribution data",
    "abstract": "Domain Adaptation Principal Component Analysis: base linear method for  learning with out-of-distribution data",
    "descriptor": "",
    "authors": [
      "Evgeny M Mirkes",
      "Jonathan Bac",
      "Aziz Fouch\u00e9",
      "Sergey V. Stasenko",
      "Andrei Zinovyev",
      "Alexander N. Gorban"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.13290"
  },
  {
    "id": "arXiv:2208.13921",
    "title": "Dynamic Network Sampling for Community Detection",
    "abstract": "Comments: 18 pages, 8 figures",
    "descriptor": "\nComments: 18 pages, 8 figures\n",
    "authors": [
      "Cong Mu",
      "Youngser Park",
      "Carey E. Priebe"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.13921"
  },
  {
    "id": "arXiv:2208.14311",
    "title": "Modeling Volatility and Dependence of European Carbon and Energy Prices",
    "abstract": "Comments: Accepted for publication in Finance Research Letters",
    "descriptor": "\nComments: Accepted for publication in Finance Research Letters\n",
    "authors": [
      "Jonathan Berrisch",
      "Sven Pappert",
      "Florian Ziel",
      "Antonia Arsova"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2208.14311"
  },
  {
    "id": "arXiv:2209.00626",
    "title": "The alignment problem from a deep learning perspective",
    "abstract": "The alignment problem from a deep learning perspective",
    "descriptor": "",
    "authors": [
      "Richard Ngo",
      "Lawrence Chan",
      "S\u00f6ren Mindermann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.00626"
  },
  {
    "id": "arXiv:2209.02882",
    "title": "Sgap: Towards Efficient Sparse Tensor Algebra Compilation for GPU",
    "abstract": "Comments: 23 pages, 10 figures",
    "descriptor": "\nComments: 23 pages, 10 figures\n",
    "authors": [
      "Genghan Zhang",
      "Yuetong Zhao",
      "Yanting Tao",
      "Zhongming Yu",
      "Guohao Dai",
      "Sitao Huang",
      "Yuan Wen",
      "Pavlos Petoumenos",
      "Yu Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2209.02882"
  },
  {
    "id": "arXiv:2209.05166",
    "title": "Global Prototype Encoding for Incremental Video Highlights Detection",
    "abstract": "Global Prototype Encoding for Incremental Video Highlights Detection",
    "descriptor": "",
    "authors": [
      "Sen Pei",
      "Shixiong Xu",
      "Ye Yuan",
      "Jiashi Feng",
      "Xiaohui Shen",
      "Xiaojie Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.05166"
  },
  {
    "id": "arXiv:2209.05957",
    "title": "Adversarial Inter-Group Link Injection Degrades the Fairness of Graph  Neural Networks",
    "abstract": "Comments: A shorter version of this work has been accepted by IEEE ICDM 2022",
    "descriptor": "\nComments: A shorter version of this work has been accepted by IEEE ICDM 2022\n",
    "authors": [
      "Hussain Hussain",
      "Meng Cao",
      "Sandipan Sikdar",
      "Denis Helic",
      "Elisabeth Lex",
      "Markus Strohmaier",
      "Roman Kern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.05957"
  },
  {
    "id": "arXiv:2209.08037",
    "title": "DAGMA: Learning DAGs via M-matrices and a Log-Determinant Acyclicity  Characterization",
    "abstract": "Comments: 28 pages, 13 figures, published at NeurIPS 2022",
    "descriptor": "\nComments: 28 pages, 13 figures, published at NeurIPS 2022\n",
    "authors": [
      "Kevin Bello",
      "Bryon Aragam",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.08037"
  },
  {
    "id": "arXiv:2209.09024",
    "title": "Dataset Inference for Self-Supervised Models",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Adam Dziedzic",
      "Haonan Duan",
      "Muhammad Ahmad Kaleem",
      "Nikita Dhawan",
      "Jonas Guan",
      "Yannis Cattan",
      "Franziska Boenisch",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.09024"
  },
  {
    "id": "arXiv:2209.12590",
    "title": "Learning to Drop Out: An Adversarial Approach to Training Sequence VAEs",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "\u0110or\u0111e Miladinovi\u0107",
      "Kumar Shridhar",
      "Kushal Jain",
      "Max B. Paulus",
      "Joachim M. Buhmann",
      "Mrinmaya Sachan",
      "Carl Allen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.12590"
  },
  {
    "id": "arXiv:2209.14561",
    "title": "Phase function methods for second order linear ordinary differential  equations with turning points",
    "abstract": "Phase function methods for second order linear ordinary differential  equations with turning points",
    "descriptor": "",
    "authors": [
      "James Bremer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.14561"
  },
  {
    "id": "arXiv:2209.14990",
    "title": "Partially Observable RL with B-Stability: Unified Structural Condition  and Sharp Sample-Efficient Algorithms",
    "abstract": "Partially Observable RL with B-Stability: Unified Structural Condition  and Sharp Sample-Efficient Algorithms",
    "descriptor": "",
    "authors": [
      "Fan Chen",
      "Yu Bai",
      "Song Mei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.14990"
  },
  {
    "id": "arXiv:2209.15154",
    "title": "Variable-Based Calibration for Machine Learning Classifiers",
    "abstract": "Variable-Based Calibration for Machine Learning Classifiers",
    "descriptor": "",
    "authors": [
      "Markelle Kelly",
      "Padhraic Smyth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.15154"
  },
  {
    "id": "arXiv:2210.01636",
    "title": "Long-Range QKD without Trusted Nodes is Not Possible with Current  Technology",
    "abstract": "Comments: 9 pages, 2 figures and 1 table",
    "descriptor": "\nComments: 9 pages, 2 figures and 1 table\n",
    "authors": [
      "Bruno Huttner",
      "Romain All\u00e9aume",
      "Eleni Diamanti",
      "Florian Fr\u00f6wis",
      "Philippe Grangier",
      "Hannes H\u00fcbel",
      "Vicente Martin",
      "Andreas Poppe",
      "Joshua A. Slater",
      "Tim Spiller",
      "Wolfgang Tittel",
      "Benoit Tranier",
      "Adrian Wonfor",
      "Hugo Zbinden"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.01636"
  },
  {
    "id": "arXiv:2210.01959",
    "title": "Detect, Retrieve, Comprehend: A Flexible Framework for Zero-Shot  Document-Level Question Answering",
    "abstract": "Detect, Retrieve, Comprehend: A Flexible Framework for Zero-Shot  Document-Level Question Answering",
    "descriptor": "",
    "authors": [
      "Tavish McDonald",
      "Brian Tsan",
      "Amar Saini",
      "Juanita Ordonez",
      "Luis Gutierrez",
      "Phan Nguyen",
      "Blake Mason",
      "Brenda Ng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01959"
  },
  {
    "id": "arXiv:2210.05833",
    "title": "Parameter estimation of the homodyned K distribution based on neural  networks and trainable fractional-order moments",
    "abstract": "Comments: 5 pages, 3 figures",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Michal Byra",
      "Ziemowit Klimonda",
      "Piotr Jarosik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.05833"
  },
  {
    "id": "arXiv:2210.07011",
    "title": "Variational Graph Generator for Multi-View Graph Clustering",
    "abstract": "Comments: submitted to TNNLS",
    "descriptor": "\nComments: submitted to TNNLS\n",
    "authors": [
      "Jianpeng Chen",
      "Yawen Ling",
      "Jie Xu",
      "Yazhou Ren",
      "Shudong Huang",
      "Xiaorong Pu",
      "Zhifeng Hao",
      "Philip S. Yu",
      "Lifang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07011"
  },
  {
    "id": "arXiv:2210.08349",
    "title": "When to Update Your Model: Constrained Model-based Reinforcement  Learning",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Tianying Ji",
      "Yu Luo",
      "Fuchun Sun",
      "Mingxuan Jing",
      "Fengxiang He",
      "Wenbing Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08349"
  },
  {
    "id": "arXiv:2210.10047",
    "title": "From Play to Policy: Conditional Behavior Generation from Uncurated  Robot Data",
    "abstract": "Comments: Code and data available at: this https URL; (fixed metadata author name format)",
    "descriptor": "\nComments: Code and data available at: this https URL; (fixed metadata author name format)\n",
    "authors": [
      "Zichen Jeff Cui",
      "Yibin Wang",
      "Nur Muhammad Mahi Shafiullah",
      "Lerrel Pinto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10047"
  },
  {
    "id": "arXiv:2210.11291",
    "title": "Cyclical Self-Supervision for Semi-Supervised Ejection Fraction  Prediction from Echocardiogram Videos",
    "abstract": "Comments: Accepted in IEEE Transactions on Medical Imaging",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Weihang Dai",
      "Xiaomeng Li",
      "Xinpeng Ding",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11291"
  },
  {
    "id": "arXiv:2210.12655",
    "title": "A Trustless Architecture of Blockchain-enabled Metaverse",
    "abstract": "Comments: 7 pages, 4 figures",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Minghui Xu",
      "Yihao Guo",
      "Qin Hu",
      "Zehui Xiong",
      "Dongxiao Yu",
      "Xiuzhen Cheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.12655"
  },
  {
    "id": "arXiv:2210.14670",
    "title": "Boosting Semi-Supervised Semantic Segmentation with Probabilistic  Representations",
    "abstract": "Comments: Accepted to AAAI 2023",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Haoyu Xie",
      "Changqi Wang",
      "Mingkai Zheng",
      "Minjing Dong",
      "Shan You",
      "Chong Fu",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.14670"
  },
  {
    "id": "arXiv:2210.16810",
    "title": "SL3D: Self-supervised-Self-labeled 3D Recognition",
    "abstract": "Comments: This paper has already been accepted by Neural Information Processing Systems (NeurIPS 2022) Workshop on Self-Supervised Learning: Theory and Practice",
    "descriptor": "\nComments: This paper has already been accepted by Neural Information Processing Systems (NeurIPS 2022) Workshop on Self-Supervised Learning: Theory and Practice\n",
    "authors": [
      "Fernando Julio Cendra",
      "Lan Ma",
      "Jiajun Shen",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16810"
  },
  {
    "id": "arXiv:2211.03649",
    "title": "Optimal Zero-Error Coding for Computing under Pairwise Shared Side  Information",
    "abstract": "Optimal Zero-Error Coding for Computing under Pairwise Shared Side  Information",
    "descriptor": "",
    "authors": [
      "Nicolas Charpenay",
      "Ma\u00ebl le Treust",
      "Aline Roumy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.03649"
  },
  {
    "id": "arXiv:2211.06108",
    "title": "RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object  Detection System",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Yanlong Yang",
      "Jianan Liu",
      "Tao Huang",
      "Qing-Long Han",
      "Gang Ma",
      "Bing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.06108"
  },
  {
    "id": "arXiv:2211.07915",
    "title": "Backdoor Attacks on Time Series: A Generative Approach",
    "abstract": "Backdoor Attacks on Time Series: A Generative Approach",
    "descriptor": "",
    "authors": [
      "Yujing Jiang",
      "Xingjun Ma",
      "Sarah Monazam Erfani",
      "James Bailey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.07915"
  },
  {
    "id": "arXiv:2211.09718",
    "title": "Numerical Optimizations for Weighted Low-rank Estimation on Language  Model",
    "abstract": "Comments: long paper EMNLP 2022",
    "descriptor": "\nComments: long paper EMNLP 2022\n",
    "authors": [
      "Ting Hua",
      "Yen-Chang Hsu",
      "Felicity Wang",
      "Qian Lou",
      "Yilin Shen",
      "Hongxia Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09718"
  },
  {
    "id": "arXiv:2211.12268",
    "title": "Out-of-Candidate Rectification for Weakly Supervised Semantic  Segmentation",
    "abstract": "Out-of-Candidate Rectification for Weakly Supervised Semantic  Segmentation",
    "descriptor": "",
    "authors": [
      "Zesen Cheng",
      "Pengchong Qiao",
      "Kehan Li",
      "Siheng Li",
      "Pengxu Wei",
      "Xiangyang Ji",
      "Li Yuan",
      "Chang Liu",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12268"
  },
  {
    "id": "arXiv:2211.14821",
    "title": "Towards Realistic Underwater Dataset Generation and Color Restoration",
    "abstract": "Comments: Published at The Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP) 2022",
    "descriptor": "\nComments: Published at The Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP) 2022\n",
    "authors": [
      "Neham Jain",
      "Gopi Matta",
      "Kaushik Mitra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.14821"
  },
  {
    "id": "arXiv:2211.15792",
    "title": "Provably Efficient Model-free RL in Leader-Follower MDP with Linear  Function Approximation",
    "abstract": "Provably Efficient Model-free RL in Leader-Follower MDP with Linear  Function Approximation",
    "descriptor": "",
    "authors": [
      "Arnob Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15792"
  },
  {
    "id": "arXiv:2211.16161",
    "title": "Artifact Removal in Histopathology Images",
    "abstract": "Comments: Corrected typos, small modification of Figure 1 (+ reflected in Section 2.1), results unchanged",
    "descriptor": "\nComments: Corrected typos, small modification of Figure 1 (+ reflected in Section 2.1), results unchanged\n",
    "authors": [
      "Cameron Dahan",
      "Stergios Christodoulidis",
      "Maria Vakalopoulou",
      "Joseph Boyd"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16161"
  },
  {
    "id": "arXiv:2211.16822",
    "title": "A Probabilistic-Logic based Commonsense Representation Framework for  Modelling Inferences with Multiple Antecedents and Varying Likelihoods",
    "abstract": "A Probabilistic-Logic based Commonsense Representation Framework for  Modelling Inferences with Multiple Antecedents and Varying Likelihoods",
    "descriptor": "",
    "authors": [
      "Shantanu Jaiswal",
      "Liu Yan",
      "Dongkyu Choi",
      "Kenneth Kwok"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16822"
  },
  {
    "id": "arXiv:2212.00357",
    "title": "FADEC: FPGA-based Acceleration of Video Depth Estimation by HW/SW  Co-design",
    "abstract": "Comments: 9 pages, 8 figures, 3 tables, FPT 2022 (Full paper), Program: this https URL, GitHub: this https URL, Slides: this https URL, Movie: this https URL, Profile: this https URL",
    "descriptor": "\nComments: 9 pages, 8 figures, 3 tables, FPT 2022 (Full paper), Program: this https URL, GitHub: this https URL, Slides: this https URL, Movie: this https URL, Profile: this https URL\n",
    "authors": [
      "Nobuho Hashimoto",
      "Shinya Takamaeda-Yamazaki"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2212.00357"
  },
  {
    "id": "arXiv:2212.01176",
    "title": "Physical layer insecurity",
    "abstract": "Physical layer insecurity",
    "descriptor": "",
    "authors": [
      "Muriel M\u00e9dard",
      "Ken R. Duffy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.01176"
  },
  {
    "id": "arXiv:2212.01199",
    "title": "Gibbs-Helmholtz Graph Neural Network: capturing the temperature  dependency of activity coefficients at infinite dilution",
    "abstract": "Comments: Code available at: this https URL",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "Edgar Ivan Sanchez Medina",
      "Steffen Linke",
      "Martin Stoll",
      "Kai Sundmacher"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01199"
  },
  {
    "id": "arXiv:2212.01688",
    "title": "LDL: A Defense for Label-Based Membership Inference Attacks",
    "abstract": "Comments: to appear in ACM ASIA Conference on Computer and Communications Security (ACM ASIACCS 2023)",
    "descriptor": "\nComments: to appear in ACM ASIA Conference on Computer and Communications Security (ACM ASIACCS 2023)\n",
    "authors": [
      "Arezoo Rajabi",
      "Dinuka Sahabandu",
      "Luyao Niu",
      "Bhaskar Ramasubramanian",
      "Radha Poovendran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.01688"
  },
  {
    "id": "arXiv:2212.02144",
    "title": "Low-Resolution Horizontal and Vertical Layered Mutual Information  Maximizing LDPC Decoding",
    "abstract": "Comments: This paper has been presented at the Asilomar Conference 2022. The updated version involves improvements in section III d)",
    "descriptor": "\nComments: This paper has been presented at the Asilomar Conference 2022. The updated version involves improvements in section III d)\n",
    "authors": [
      "Philipp Mohr",
      "Gerhard Bauch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.02144"
  },
  {
    "id": "arXiv:2212.04800",
    "title": "AUC Maximization for Low-Resource Named Entity Recognition",
    "abstract": "Comments: 10 pages, 4 figures, AAAI 2023 accepted paper",
    "descriptor": "\nComments: 10 pages, 4 figures, AAAI 2023 accepted paper\n",
    "authors": [
      "Ngoc Dang Nguyen",
      "Wei Tan",
      "Wray Buntine",
      "Richard Beare",
      "Changyou Chen",
      "Lan Du"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.04800"
  },
  {
    "id": "arXiv:2212.05098",
    "title": "Transcoding Unicode Characters with AVX-512 Instructions",
    "abstract": "Transcoding Unicode Characters with AVX-512 Instructions",
    "descriptor": "",
    "authors": [
      "Robert Clausecker",
      "Daniel Lemire"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.05098"
  },
  {
    "id": "arXiv:2212.05153",
    "title": "Algorithmic progress in computer vision",
    "abstract": "Algorithmic progress in computer vision",
    "descriptor": "",
    "authors": [
      "Ege Erdil",
      "Tamay Besiroglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.05153"
  },
  {
    "id": "arXiv:2212.05729",
    "title": "ROIFormer: Semantic-Aware Region of Interest Transformer for Efficient  Self-Supervised Monocular Depth Estimation",
    "abstract": "Comments: 9 Pages, AAAI 2023",
    "descriptor": "\nComments: 9 Pages, AAAI 2023\n",
    "authors": [
      "Daitao Xing",
      "Jinglin Shen",
      "Chiuman Ho",
      "Anthony Tzes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.05729"
  },
  {
    "id": "arXiv:2212.05781",
    "title": "Robust Recurrent Neural Network to Identify Ship Motion in Open Water  with Performance Guarantees -- Technical Report",
    "abstract": "Robust Recurrent Neural Network to Identify Ship Motion in Open Water  with Performance Guarantees -- Technical Report",
    "descriptor": "",
    "authors": [
      "Daniel Frank",
      "Decky Aspandi Latif",
      "Michael Muehlebach",
      "Benjamin Unger",
      "Steffen Staab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.05781"
  },
  {
    "id": "arXiv:2212.07127",
    "title": "Towards mapping the contemporary art world with ArtLM: an art-specific  NLP model",
    "abstract": "Towards mapping the contemporary art world with ArtLM: an art-specific  NLP model",
    "descriptor": "",
    "authors": [
      "Qinkai Chen",
      "Mohamed El-Mennaoui",
      "Antoine Fosset",
      "Amine Rebei",
      "Haoyang Cao",
      "Philine Bouscasse",
      "Christy E\u00f3in O'Beirne",
      "Sasha Shevchenko",
      "Mathieu Rosenbaum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.07127"
  },
  {
    "id": "arXiv:2212.07231",
    "title": "Cutting Plane Selection with Analytic Centers and Multiregression",
    "abstract": "Cutting Plane Selection with Analytic Centers and Multiregression",
    "descriptor": "",
    "authors": [
      "Mark Turner",
      "Timo Berthold",
      "Mathieu Besan\u00e7on",
      "Thorsten Koch"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.07231"
  },
  {
    "id": "arXiv:2212.07282",
    "title": "Directional Direct Feedback Alignment: Estimating Backpropagation Paths  for Efficient Learning on Neural Processors",
    "abstract": "Directional Direct Feedback Alignment: Estimating Backpropagation Paths  for Efficient Learning on Neural Processors",
    "descriptor": "",
    "authors": [
      "Florian Bacho",
      "Dominique Chu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.07282"
  },
  {
    "id": "arXiv:2212.07316",
    "title": "\"I Knew It Was Me\": Understanding Users' Interaction with Login  Notifications",
    "abstract": "\"I Knew It Was Me\": Understanding Users' Interaction with Login  Notifications",
    "descriptor": "",
    "authors": [
      "Philipp Markert",
      "Leona Lassak",
      "Maximilian Golla",
      "Markus D\u00fcrmuth"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.07316"
  },
  {
    "id": "arXiv:2212.07409",
    "title": "Self-Supervised Geometry-Aware Encoder for Style-Based 3D GAN Inversion",
    "abstract": "Comments: An encoder-based 3D GAN inversion method. Project page: this https URL",
    "descriptor": "\nComments: An encoder-based 3D GAN inversion method. Project page: this https URL\n",
    "authors": [
      "Yushi Lan",
      "Xuyi Meng",
      "Shuai Yang",
      "Chen Change Loy",
      "Bo Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2212.07409"
  },
  {
    "id": "arXiv:2212.07428",
    "title": "Towards Linguistically Informed Multi-Objective Pre-Training for Natural  Language Inference",
    "abstract": "Towards Linguistically Informed Multi-Objective Pre-Training for Natural  Language Inference",
    "descriptor": "",
    "authors": [
      "Maren Pielka",
      "Svetlana Schmidt",
      "Lisa Pucknat",
      "Rafet Sifa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.07428"
  },
  {
    "id": "arXiv:2212.07555",
    "title": "IMoS: Intent-Driven Full-Body Motion Synthesis for Human-Object  Interactions",
    "abstract": "Comments: 9 pages, 9 figures",
    "descriptor": "\nComments: 9 pages, 9 figures\n",
    "authors": [
      "Anindita Ghosh",
      "Rishabh Dabral",
      "Vladislav Golyanik",
      "Christian Theobalt",
      "Philipp Slusallek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.07555"
  },
  {
    "id": "arXiv:2212.07648",
    "title": "Relightable Neural Human Assets from Multi-view Gradient Illuminations",
    "abstract": "Comments: 9 pages, 9 figures",
    "descriptor": "\nComments: 9 pages, 9 figures\n",
    "authors": [
      "Taotao Zhou",
      "Kai He",
      "Di Wu",
      "Teng Xu",
      "Qixuan Zhang",
      "Kuixiang Shao",
      "Wenzheng Chen",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.07648"
  },
  {
    "id": "arXiv:2212.07666",
    "title": "Surrogate-assisted level-based learning evolutionary search for heat  extraction optimization of enhanced geothermal system",
    "abstract": "Surrogate-assisted level-based learning evolutionary search for heat  extraction optimization of enhanced geothermal system",
    "descriptor": "",
    "authors": [
      "Guodong Chen",
      "Xin Luo",
      "Chuanyin Jiang",
      "Jiu Jimmy Jiao"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2212.07666"
  },
  {
    "id": "arXiv:2212.08038",
    "title": "Redefining Relationships in Music",
    "abstract": "Comments: Presented at Cultures in AI/AI in Culture workshop at NeurIPS 2022",
    "descriptor": "\nComments: Presented at Cultures in AI/AI in Culture workshop at NeurIPS 2022\n",
    "authors": [
      "Christian Detweiler",
      "Beth Coleman",
      "Fernando Diaz",
      "Lieke Dom",
      "Chris Donahue",
      "Jesse Engel",
      "Cheng-Zhi Anna Huang",
      "Larry James",
      "Ethan Manilow",
      "Amanda McCroskery",
      "Kyle Pedersen",
      "Pamela Peter-Agbia",
      "Negar Rostamzadeh",
      "Robert Thomas",
      "Marco Zamarato",
      "Ben Zevenbergen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.08038"
  }
]
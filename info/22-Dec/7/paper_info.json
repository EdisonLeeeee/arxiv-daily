[
  {
    "id": "arXiv:2212.02503",
    "title": "Relation-based Motion Prediction using Traffic Scene Graphs",
    "abstract": "Representing relevant information of a traffic scene and understanding its\nenvironment is crucial for the success of autonomous driving. Modeling the\nsurrounding of an autonomous car using semantic relations, i.e., how different\ntraffic participants relate in the context of traffic rule based behaviors, is\nhardly been considered in previous work. This stems from the fact that these\nrelations are hard to extract from real-world traffic scenes. In this work, we\nmodel traffic scenes in a form of spatial semantic scene graphs for various\ndifferent predictions about the traffic participants, e.g., acceleration and\ndeceleration. Our learning and inference approach uses Graph Neural Networks\n(GNNs) and shows that incorporating explicit information about the spatial\nsemantic relations between traffic participants improves the predicdtion\nresults. Specifically, the acceleration prediction of traffic participants is\nimproved by up to 12% compared to the baselines, which do not exploit this\nexplicit information. Furthermore, by including additional information about\nprevious scenes, we achieve 73% improvements.",
    "descriptor": "",
    "authors": [
      "Maximilian Zipfl",
      "Felix Hertlein",
      "Achim Rettinger",
      "Steffen Thoma",
      "Lavdim Halilaj",
      "Juergen Luettin",
      "Stefan Schmid",
      "Cory Henson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.02503"
  },
  {
    "id": "arXiv:2212.02506",
    "title": "This changes to that : Combining causal and non-causal explanations to  generate disease progression in capsule endoscopy",
    "abstract": "Due to the unequivocal need for understanding the decision processes of deep\nlearning networks, both modal-dependent and model-agnostic techniques have\nbecome very popular. Although both of these ideas provide transparency for\nautomated decision making, most methodologies focus on either using the\nmodal-gradients (model-dependent) or ignoring the model internal states and\nreasoning with a model's behavior/outcome (model-agnostic) to instances. In\nthis work, we propose a unified explanation approach that given an instance\ncombines both model-dependent and agnostic explanations to produce an\nexplanation set. The generated explanations are not only consistent in the\nneighborhood of a sample but can highlight causal relationships between image\ncontent and the outcome. We use Wireless Capsule Endoscopy (WCE) domain to\nillustrate the effectiveness of our explanations. The saliency maps generated\nby our approach are comparable or better on the softmax information score.",
    "descriptor": "",
    "authors": [
      "Anuja Vats",
      "Ahmed Mohammed",
      "Marius Pedersen",
      "Nirmalie Wiratunga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02506"
  },
  {
    "id": "arXiv:2212.02507",
    "title": "FEMa-FS: Finite Element Machines for Feature Selection",
    "abstract": "Identifying anomalies has become one of the primary strategies towards\nsecurity and protection procedures in computer networks. In this context,\nmachine learning-based methods emerge as an elegant solution to identify such\nscenarios and learn irrelevant information so that a reduction in the\nidentification time and possible gain in accuracy can be obtained. This paper\nproposes a novel feature selection approach called Finite Element Machines for\nFeature Selection (FEMa-FS), which uses the framework of finite elements to\nidentify the most relevant information from a given dataset. Although FEMa-FS\ncan be applied to any application domain, it has been evaluated in the context\nof anomaly detection in computer networks. The outcomes over two datasets\nshowed promising results.",
    "descriptor": "",
    "authors": [
      "Lucas Biaggi",
      "Jo\u00e3o P. Papa",
      "Kelton A. P Costa",
      "Danillo R. Pereira",
      "Leandro A. Passos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02507"
  },
  {
    "id": "arXiv:2212.02508",
    "title": "MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music  Audio Representation Learning",
    "abstract": "The deep learning community has witnessed an exponentially growing interest\nin self-supervised learning (SSL). However, it still remains unexplored how to\nbuild a framework for learning useful representations of raw music waveforms in\na self-supervised manner. In this work, we design Music2Vec, a framework\nexploring different SSL algorithmic components and tricks for music audio\nrecordings. Our model achieves comparable results to the state-of-the-art\n(SOTA) music SSL model Jukebox, despite being significantly smaller with less\nthan 2% of parameters of the latter. The model will be released on\nHuggingface(Please refer to: https://huggingface.co/m-a-p/music2vec-v1)",
    "descriptor": "",
    "authors": [
      "Yizhi Li",
      "Ruibin Yuan",
      "Ge Zhang",
      "Yinghao Ma",
      "Chenghua Lin",
      "Xingran Chen",
      "Anton Ragni",
      "Hanzhi Yin",
      "Zhijie Hu",
      "Haoyu He",
      "Emmanouil Benetos",
      "Norbert Gyenge",
      "Ruibo Liu",
      "Jie Fu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.02508"
  },
  {
    "id": "arXiv:2212.02560",
    "title": "Cross-Domain Few-Shot Relation Extraction via Representation Learning  and Domain Adaptation",
    "abstract": "Cross-domain few-shot relation extraction poses a great challenge for the\nexisting few-shot learning methods and domain adaptation methods when the\nsource domain and target domain have large discrepancies. This paper proposes a\nmethod by combining the idea of few-shot learning and domain adaptation to deal\nwith this problem. In the proposed method, an encoder, learned by optimizing a\nrepresentation loss and an adversarial loss, is used to extract the relation of\nsentences in the source and target domain. The representation loss, including a\ncross-entropy loss and a contrastive loss, makes the encoder extract the\nrelation of the source domain and keep the geometric structure of the classes\nin the source domain. And the adversarial loss is used to merge the source\ndomain and target domain. The experimental results on the benchmark FewRel\ndataset demonstrate that the proposed method can outperform some\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Zhongju Yuan",
      "Zhenkun Wang",
      "Genghui Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02560"
  },
  {
    "id": "arXiv:2212.02563",
    "title": "A Large-Scale Analysis of Phishing Websites Hosted on Free Web Hosting  Domains",
    "abstract": "While phishing attacks have evolved to utilize several obfuscation tactics to\nevade prevalent detection measures, implementing said measures often requires\nsignificant technical competence and logistical overhead from the attacker's\nperspective. In this work, we identify a family of phishing attacks hosted over\nFree web-Hosting Domains (FHDs), which can be created and maintained at scale\nwith very little effort while also effectively evading prevalent anti-phishing\ndetection and resisting website takedown. We observed over 8.8k such phishing\nURLs shared on Twitter and Facebook from February to August 2022 using 24\nunique FHDs. Our large-scale analysis of these attacks shows that phishing\nwebsites hosted on FHDs remain active on Twitter and Facebook for at least 1.5\ntimes longer than regular phishing URLs. In addition, on average, they have 1.7\ntimes lower coverage from anti-phishing blocklists than regular phishing\nattacks, with a coverage time also being 3.8 times slower while only having\nhalf the number of detections from anti-phishing tools. Moreover, only 23.6% of\nFHD URLs were removed by the hosting domain a week after their first\nappearance, with a median removal time of 12.2 hours. We also identified\nseveral gaps in the prevalent anti-phishing ecosystem in detecting these\nthreats. Based on our findings, we developed FreePhish, an ML-aided framework\nthat acts as an effective countermeasure to detect and mitigate these URLs\nautomatically and more effectively. By regularly reporting phishing URLs found\nby FreePhish to FHDs and hosting registrars over a period of two weeks, we note\na significant decrease in the time taken to remove these websites. Finally, we\nalso provide FreePhish as a free Chromium web extension that can be utilized to\nprevent end-users from accessing potential FHD-based phishing attacks.",
    "descriptor": "",
    "authors": [
      "Sayak Saha Roy",
      "Unique Karanjit",
      "Shirin Nilizadeh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.02563"
  },
  {
    "id": "arXiv:2212.02564",
    "title": "INCLUSIFY: A benchmark and a model for gender-inclusive German",
    "abstract": "Gender-inclusive language is important for achieving gender equality in\nlanguages with gender inflections, such as German. While stirring some\ncontroversy, it is increasingly adopted by companies and political\ninstitutions. A handful of tools have been developed to help people use\ngender-inclusive language by identifying instances of the generic masculine and\nproviding suggestions for more inclusive reformulations. In this report, we\ndefine the underlying tasks in terms of natural language processing, and\npresent a dataset and measures for benchmarking them. We also present a model\nthat implements these tasks, by combining an inclusive language database with\nan elaborate sequence of processing steps via standard pre-trained models. Our\nmodel achieves a recall of 0.89 and a precision of 0.82 in our benchmark for\nidentifying exclusive language; and one of its top five suggestions is chosen\nin real-world texts in 44% of cases. We sketch how the area could be further\nadvanced by training end-to-end models and using large language models; and we\nurge the community to include more gender-inclusive texts in their training\ndata in order to not present an obstacle to the adoption of gender-inclusive\nlanguage. Through these efforts, we hope to contribute to restoring justice in\nlanguage and, to a small extent, in reality.",
    "descriptor": "",
    "authors": [
      "David Pomerenke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.02564"
  },
  {
    "id": "arXiv:2212.02567",
    "title": "cs-net: structural approach to time-series forecasting for  high-dimensional feature space data with limited observations",
    "abstract": "In recent years, deep-learning-based approaches have been introduced to\nsolving time-series forecasting-related problems. These novel methods have\ndemonstrated impressive performance in univariate and low-dimensional\nmultivariate time-series forecasting tasks. However, when these novel methods\nare used to handle high-dimensional multivariate forecasting problems, their\nperformance is highly restricted by a practical training time and a reasonable\nGPU memory configuration. In this paper, inspired by a change of basis in the\nHilbert space, we propose a flexible data feature extraction technique that\nexcels in high-dimensional multivariate forecasting tasks. Our approach was\noriginally developed for the National Science Foundation (NSF) Algorithms for\nThreat Detection (ATD) 2022 Challenge. Implemented using the attention\nmechanism and Convolutional Neural Networks (CNN) architecture, our method\ndemonstrates great performance and compatibility. Our models trained on the\nGDELT Dataset finished 1st and 2nd places in the ATD sprint series and hold\npromise for other datasets for time series forecasting.",
    "descriptor": "",
    "authors": [
      "Weiyu Zong",
      "Mingqian Feng",
      "Griffin Heyrich",
      "Peter Chin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.02567"
  },
  {
    "id": "arXiv:2212.02571",
    "title": "A Dataless FaceSwap Detection Approach Using Synthetic Images",
    "abstract": "Face swapping technology used to create \"Deepfakes\" has advanced\nsignificantly over the past few years and now enables us to create realistic\nfacial manipulations. Current deep learning algorithms to detect deepfakes have\nshown promising results, however, they require large amounts of training data,\nand as we show they are biased towards a particular ethnicity. We propose a\ndeepfake detection methodology that eliminates the need for any real data by\nmaking use of synthetically generated data using StyleGAN3. This not only\nperforms at par with the traditional training methodology of using real data\nbut it shows better generalization capabilities when finetuned with a small\namount of real data. Furthermore, this also reduces biases created by facial\nimage datasets that might have sparse data from particular ethnicities.",
    "descriptor": "\nComments: IJCB 2022\n",
    "authors": [
      "Anubhav Jain",
      "Nasir Memon",
      "Julian Togelius"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02571"
  },
  {
    "id": "arXiv:2212.02573",
    "title": "Domain-general Crowd Counting in Unseen Scenarios",
    "abstract": "Domain shift across crowd data severely hinders crowd counting models to\ngeneralize to unseen scenarios. Although domain adaptive crowd counting\napproaches close this gap to a certain extent, they are still dependent on the\ntarget domain data to adapt (e.g. finetune) their models to the specific\ndomain. In this paper, we aim to train a model based on a single source domain\nwhich can generalize well on any unseen domain. This falls into the realm of\ndomain generalization that remains unexplored in crowd counting. We first\nintroduce a dynamic sub-domain division scheme which divides the source domain\ninto multiple sub-domains such that we can initiate a meta-learning framework\nfor domain generalization. The sub-domain division is dynamically refined\nduring the meta-learning. Next, in order to disentangle domain-invariant\ninformation from domain-specific information in image features, we design the\ndomain-invariant and -specific crowd memory modules to re-encode image\nfeatures. Two types of losses, i.e. feature reconstruction and orthogonal\nlosses, are devised to enable this disentanglement. Extensive experiments on\nseveral standard crowd counting benchmarks i.e. SHA, SHB, QNRF, and NWPU, show\nthe strong generalizability of our method.",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Zhipeng Du",
      "Jiankang Deng",
      "Miaojing Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02573"
  },
  {
    "id": "arXiv:2212.02575",
    "title": "A Mobility-Aware Deep Learning Model for Long-Term COVID-19 Pandemic  Prediction and Policy Impact Analysis",
    "abstract": "Pandemic(epidemic) modeling, aiming at disease spreading analysis, has always\nbeen a popular research topic especially following the outbreak of COVID-19 in\n2019. Some representative models including SIR-based deep learning prediction\nmodels have shown satisfactory performance. However, one major drawback for\nthem is that they fall short in their long-term predictive ability. Although\ngraph convolutional networks (GCN) also perform well, their edge\nrepresentations do not contain complete information and it can lead to biases.\nAnother drawback is that they usually use input features which they are unable\nto predict. Hence, those models are unable to predict further future. We\npropose a model that can propagate predictions further into the future and it\nhas better edge representations. In particular, we model the pandemic as a\nspatial-temporal graph whose edges represent the transition of infections and\nare learned by our model. We use a two-stream framework that contains GCN and\nrecursive structures (GRU) with an attention mechanism. Our model enables\nmobility analysis that provides an effective toolbox for public health\nresearchers and policy makers to predict how different lock-down strategies\nthat actively control mobility can influence the spread of pandemics.\nExperiments show that our model outperforms others in its long-term predictive\npower. Moreover, we simulate the effects of certain policies and predict their\nimpacts on infection control.",
    "descriptor": "",
    "authors": [
      "Danfeng Guo",
      "Zijie Huang",
      "Junheng Hao",
      "Yizhou Sun",
      "Wei Wang",
      "Demetri Terzopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.02575"
  },
  {
    "id": "arXiv:2212.02578",
    "title": "Auxiliary Quantile Forecasting with Linear Networks",
    "abstract": "We propose a novel multi-task method for quantile forecasting with shared\nLinear layers. Our method is based on the Implicit quantile learning approach,\nwhere samples from the Uniform distribution $\\mathcal{U}(0, 1)$ are\nreparameterized to quantile values of the target distribution. We combine the\nimplicit quantile and input time series representations to directly forecast\nmultiple quantile estimations for multiple horizons jointly. Prior works have\nadopted a Linear layer for the direct estimation of all forecasting horizons in\na multi-task learning setup. We show that following similar intuition from\nmulti-task learning to exploit correlations among forecast horizons, we can\nmodel multiple quantile estimates as auxiliary tasks for each of the forecast\nhorizon to improve forecast accuracy across the quantile estimates compared to\nmodeling only a single quantile estimate. We show learning auxiliary quantile\ntasks leads to state-of-the-art performance on deterministic forecasting\nbenchmarks concerning the main-task of forecasting the 50$^{th}$ percentile\nestimate.",
    "descriptor": "\nComments: Under submission\n",
    "authors": [
      "Shayan Jawed",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.02578"
  },
  {
    "id": "arXiv:2212.02582",
    "title": "Rethinking Backdoor Data Poisoning Attacks in the Context of  Semi-Supervised Learning",
    "abstract": "Semi-supervised learning methods can train high-accuracy machine learning\nmodels with a fraction of the labeled training samples required for traditional\nsupervised learning. Such methods do not typically involve close review of the\nunlabeled training samples, making them tempting targets for data poisoning\nattacks. In this paper we investigate the vulnerabilities of semi-supervised\nlearning methods to backdoor data poisoning attacks on the unlabeled samples.\nWe show that simple poisoning attacks that influence the distribution of the\npoisoned samples' predicted labels are highly effective - achieving an average\nattack success rate as high as 96.9%. We introduce a generalized attack\nframework targeting semi-supervised learning methods to better understand and\nexploit their limitations and to motivate future defense strategies.",
    "descriptor": "\nComments: 18 pages, 14 figures\n",
    "authors": [
      "Marissa Connor",
      "Vincent Emanuele"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.02582"
  },
  {
    "id": "arXiv:2212.02587",
    "title": "Learning Sampling Distributions for Model Predictive Control",
    "abstract": "Sampling-based methods have become a cornerstone of contemporary approaches\nto Model Predictive Control (MPC), as they make no restrictions on the\ndifferentiability of the dynamics or cost function and are straightforward to\nparallelize. However, their efficacy is highly dependent on the quality of the\nsampling distribution itself, which is often assumed to be simple, like a\nGaussian. This restriction can result in samples which are far from optimal,\nleading to poor performance. Recent work has explored improving the performance\nof MPC by sampling in a learned latent space of controls. However, these\nmethods ultimately perform all MPC parameter updates and warm-starting between\ntime steps in the control space. This requires us to rely on a number of\nheuristics for generating samples and updating the distribution and may lead to\nsub-optimal performance. Instead, we propose to carry out all operations in the\nlatent space, allowing us to take full advantage of the learned distribution.\nSpecifically, we frame the learning problem as bi-level optimization and show\nhow to train the controller with backpropagation-through-time. By using a\nnormalizing flow parameterization of the distribution, we can leverage its\ntractable density to avoid requiring differentiability of the dynamics and cost\nfunction. Finally, we evaluate the proposed approach on simulated robotics\ntasks and demonstrate its ability to surpass the performance of prior methods\nand scale better with a reduced number of samples.",
    "descriptor": "\nComments: Accepted at the Conference on Robot Learning (CoRL), 2022. Main paper is 9 pages with 4 figures. Appendix is 12 pages with 11 figures and 1 table\n",
    "authors": [
      "Jacob Sacks",
      "Byron Boots"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.02587"
  },
  {
    "id": "arXiv:2212.02591",
    "title": "Fine-tuning a Subtle Parsing Distinction Using a Probabilistic Decision  Tree: the Case of Postnominal \"that\" in Noun Complement Clauses vs. Relative  Clauses",
    "abstract": "In this paper we investigated two different methods to parse relative and\nnoun complement clauses in English and resorted to distinct tags for their\ncorresponding that as a relative pronoun and as a complementizer. We used an\nalgorithm to relabel a corpus parsed with the GUM Treebank using Universal\nDependency. Our second experiment consisted in using TreeTagger, a\nProbabilistic Decision Tree, to learn the distinction between the two\ncomplement and relative uses of postnominal \"that\". We investigated the effect\nof the training set size on TreeTagger accuracy and how representative the GUM\nTreebank files are for the two structures under scrutiny. We discussed some of\nthe linguistic and structural tenets of the learnability of this distinction.",
    "descriptor": "\nComments: Published in the ACL anthology, ALTA 2022\n",
    "authors": [
      "Zineddine Tighidet",
      "Nicolas Ballier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02591"
  },
  {
    "id": "arXiv:2212.02602",
    "title": "Automatic Anomalies Detection in Hydraulic Devices",
    "abstract": "Nowadays, the applications of hydraulic systems are present in a wide variety\nof devices in both industrial and everyday environments. The implementation and\nusage of hydraulic systems have been well documented; however, today, this\nstill faces a challenge, the integration of tools that allow more accurate\ninformation about the functioning and operation of these systems for proactive\ndecision-making. In industrial applications, many sensors and methods exist to\nmeasure and determine the status of process variables (e.g., flow, pressure,\nforce). Nevertheless, little has been done to have systems that can provide\nusers with device-health information related to hydraulic devices integrated\ninto the machinery. Implementing artificial intelligence (AI) technologies and\nmachine learning (ML) models in hydraulic system components has been identified\nas a solution to the challenge many industries currently face: optimizing\nprocesses and carrying them out more safely and efficiently. This paper\npresents a solution for the characterization and estimation of anomalies in one\nof the most versatile and used devices in hydraulic systems, cylinders. AI and\nML models were implemented to determine the current operating status of these\nhydraulic components and whether they are working correctly or if a failure\nmode or abnormal condition is present.",
    "descriptor": "",
    "authors": [
      "Jose A. Solorio",
      "Jose M. Garcia",
      "Sudip Vhaduri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.02602"
  },
  {
    "id": "arXiv:2212.02603",
    "title": "Learning to Optimize in Model Predictive Control",
    "abstract": "Sampling-based Model Predictive Control (MPC) is a flexible control framework\nthat can reason about non-smooth dynamics and cost functions. Recently,\nsignificant work has focused on the use of machine learning to improve the\nperformance of MPC, often through learning or fine-tuning the dynamics or cost\nfunction. In contrast, we focus on learning to optimize more effectively. In\nother words, to improve the update rule within MPC. We show that this can be\nparticularly useful in sampling-based MPC, where we often wish to minimize the\nnumber of samples for computational reasons. Unfortunately, the cost of\ncomputational efficiency is a reduction in performance; fewer samples results\nin noisier updates. We show that we can contend with this noise by learning how\nto update the control distribution more effectively and make better use of the\nfew samples that we have. Our learned controllers are trained via imitation\nlearning to mimic an expert which has access to substantially more samples. We\ntest the efficacy of our approach on multiple simulated robotics tasks in\nsample-constrained regimes and demonstrate that our approach can outperform a\nMPC controller with the same number of samples.",
    "descriptor": "\nComments: Proceedings of the IEEE Conference on Robotics and Automation (ICRA), 2022. Paper is 6 pages with 2 figures and 2 tables\n",
    "authors": [
      "Jacob Sacks",
      "Byron Boots"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.02603"
  },
  {
    "id": "arXiv:2212.02604",
    "title": "A \\texttt{Matlab} Toolbox for the Regularization of Descriptor Systems  Arising from Generalized Realization Procedures",
    "abstract": "In this report we introduce a \\texttt{Matlab} toolbox for the regularization\nof descriptor systems. We apply it, in particular, for systems resulting from\nthe generalized realization procedure of \\cite{MayA07}, which generates, via\nrational interpolation techniques, a linear \\emph{descriptor system} from\ninterpolation data. The resulting system needs to be regularized to make it\nfeasible for the use in simulation, optimization, and control. This process is\ncalled \\emph{regularization}",
    "descriptor": "",
    "authors": [
      "A. Binder",
      "V. Mehrmann",
      "A. Miedlar",
      "P. Schulze"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.02604"
  },
  {
    "id": "arXiv:2212.02605",
    "title": "Proving False in Object-Oriented Verification Programs by Exploiting  Non-Termination",
    "abstract": "We looked at three different object-oriented program verifiers: Gobra, KeY,\nand Dafny. We show that all three can be made to prove false by using a simple\ntrick with ghost variable declaration and non-terminating code. This shows that\nverifiers for these languages can produce unsound results without much\ndifficulty and that this is possibly common throughout all OO verifiers.",
    "descriptor": "\nComments: Unsound 2022 paper\n",
    "authors": [
      "Jaymon Furniss"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2212.02605"
  },
  {
    "id": "arXiv:2212.02610",
    "title": "Audio Latent Space Cartography",
    "abstract": "We explore the generation of visualisations of audio latent spaces using an\naudio-to-image generation pipeline. We believe this can help with the\ninterpretability of audio latent spaces. We demonstrate a variety of results on\nthe NSynth dataset. A web demo is available.",
    "descriptor": "\nComments: Late Breaking / Demo, ISMIR 2022 (this https URL)\n",
    "authors": [
      "Nicolas Jonason",
      "Bob L.T. Sturm"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.02610"
  },
  {
    "id": "arXiv:2212.02611",
    "title": "StyleGAN as a Utility-Preserving Face De-identification Method",
    "abstract": "Several face de-identification methods have been proposed to preserve users'\nprivacy by obscuring their faces. These methods, however, can degrade the\nquality of photos, and they usually do not preserve the utility of faces, e.g.,\ntheir age, gender, pose, and facial expression. Recently, advanced generative\nadversarial network models, such as StyleGAN, have been proposed, which\ngenerate realistic, high-quality imaginary faces. In this paper, we investigate\nthe use of StyleGAN in generating de-identified faces through style mixing,\nwhere the styles or features of the target face and an auxiliary face get mixed\nto generate a de-identified face that carries the utilities of the target face.\nWe examined this de-identification method with respect to preserving utility\nand privacy, by implementing several face detection, verification, and\nidentification attacks. Through extensive experiments and also comparing with\ntwo state-of-the-art face de-identification methods, we show that StyleGAN\npreserves the quality and utility of the faces much better than the other\napproaches and also by choosing the style mixing levels correctly, it can\npreserve the privacy of the faces much better than other methods.",
    "descriptor": "",
    "authors": [
      "Seyyed Mohammad Sadegh Moosavi Khorzooghi",
      "Shirin Nilizadeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02611"
  },
  {
    "id": "arXiv:2212.02614",
    "title": "Can Ensembling Pre-processing Algorithms Lead to Better Machine Learning  Fairness?",
    "abstract": "As machine learning (ML) systems get adopted in more critical areas, it has\nbecome increasingly crucial to address the bias that could occur in these\nsystems. Several fairness pre-processing algorithms are available to alleviate\nimplicit biases during model training. These algorithms employ different\nconcepts of fairness, often leading to conflicting strategies with\nconsequential trade-offs between fairness and accuracy. In this work, we\nevaluate three popular fairness pre-processing algorithms and investigate the\npotential for combining all algorithms into a more robust pre-processing\nensemble. We report on lessons learned that can help practitioners better\nselect fairness algorithms for their models.",
    "descriptor": "",
    "authors": [
      "Khaled Badran",
      "Pierre-Olivier C\u00f4t\u00e9",
      "Amanda Kolopanis",
      "Rached Bouchoucha",
      "Antonio Collante",
      "Diego Elias Costa",
      "Emad Shihab",
      "Foutse Khomh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.02614"
  },
  {
    "id": "arXiv:2212.02618",
    "title": "Collabs: Composable Collaborative Data Structures",
    "abstract": "Replicated data types (RDTs), such as Conflict-free Replicated Data Types\n(CRDTs), provide an abstraction for reasoning about replication and consistency\nin distributed systems. To make them as useful as ordinary, local data\nstructures, RDTs need to be both modular and composable, so that programmers\ncan create new app-specific RDTs by composing existing ones. However, no\nexisting RDT libraries combine these properties; either they use monolithic\narchitectures that rule out new RDTs or they do not support composition\ntechniques.\nIn this work, we introduce the Collab (collaborative data structure), a novel\nabstraction for modular and composable RDTs. We also describe the collabs\nlibrary, an open-source TypeScript library that we built around this\nabstraction. Our library supports arbitrary programmer-added RDTs and includes\ncomposition techniques that make them easier to implement. This allows\nprogrammers to work at a higher level of abstraction: custom RDTs for arbitrary\nconcepts in their application, instead of just a fixed menu of generic RDTs. It\nalso allows programmers to extend the library with new RDT algorithms as they\nare published, instead of waiting for the library to implement them. Our\nlibrary includes a collection of built-in op-based CRDT implementations,\nincluding several that were not previously implemented. To demonstrate the\nlibrary, we built numerous apps on top of it, including decentralized\ncollaborative apps that can be deployed from a static web page. Benchmarks show\nthat its CRDTs have performance comparable to state-of-the-art CRDT libraries\nfor web apps, and that unlike existing libraries, it can support 100\nsimultaneous users with low latency in a geo-distributed collaborative app.",
    "descriptor": "\nComments: 26 pages, 17 figures\n",
    "authors": [
      "Matthew Weidner",
      "Heather Miller",
      "Huairui Qi",
      "Maxime Kjaer",
      "Ria Pradeep",
      "Benito Geordie",
      "Christopher Meiklejohn"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.02618"
  },
  {
    "id": "arXiv:2212.02620",
    "title": "Benchmarking Offline Reinforcement Learning Algorithms for E-Commerce  Order Fraud Evaluation",
    "abstract": "Amazon and other e-commerce sites must employ mechanisms to protect their\nmillions of customers from fraud, such as unauthorized use of credit cards. One\nsuch mechanism is order fraud evaluation, where systems evaluate orders for\nfraud risk, and either \"pass\" the order, or take an action to mitigate high\nrisk. Order fraud evaluation systems typically use binary classification models\nthat distinguish fraudulent and legitimate orders, to assess risk and take\naction. We seek to devise a system that considers both financial losses of\nfraud and long-term customer satisfaction, which may be impaired when incorrect\nactions are applied to legitimate customers. We propose that taking actions to\noptimize long-term impact can be formulated as a Reinforcement Learning (RL)\nproblem. Standard RL methods require online interaction with an environment to\nlearn, but this is not desirable in high-stakes applications like order fraud\nevaluation. Offline RL algorithms learn from logged data collected from the\nenvironment, without the need for online interaction, making them suitable for\nour use case. We show that offline RL methods outperform traditional binary\nclassification solutions in SimStore, a simplified e-commerce simulation that\nincorporates order fraud risk. We also propose a novel approach to training\noffline RL policies that adds a new loss term during training, to better align\npolicy exploration with taking correct actions.",
    "descriptor": "\nComments: 2022 NeurIPS Offline Reinforcement Learning Workshop paper\n",
    "authors": [
      "Soysal Degirmenci",
      "Chris Jones"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02620"
  },
  {
    "id": "arXiv:2212.02622",
    "title": "Towards a Taxonomy for the Use of Synthetic Data in Advanced Analytics",
    "abstract": "The proliferation of deep learning techniques led to a wide range of advanced\nanalytics applications in important business areas such as predictive\nmaintenance or product recommendation. However, as the effectiveness of\nadvanced analytics naturally depends on the availability of sufficient data, an\norganization's ability to exploit the benefits might be restricted by limited\ndata or likewise data access. These challenges could force organizations to\nspend substantial amounts of money on data, accept constrained analytics\ncapacities, or even turn into a showstopper for analytics projects. Against\nthis backdrop, recent advances in deep learning to generate synthetic data may\nhelp to overcome these barriers. Despite its great potential, however,\nsynthetic data are rarely employed. Therefore, we present a taxonomy\nhighlighting the various facets of deploying synthetic data for advanced\nanalytics systems. Furthermore, we identify typical application scenarios for\nsynthetic data to assess the current state of adoption and thereby unveil\nmissed opportunities to pave the way for further research.",
    "descriptor": "",
    "authors": [
      "Peter Kowalczyk",
      "Giacomo Welsch",
      "Fr\u00e9d\u00e9ric Thiesse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02622"
  },
  {
    "id": "arXiv:2212.02623",
    "title": "Unifying Vision, Text, and Layout for Universal Document Processing",
    "abstract": "We propose Universal Document Processing (UDOP), a foundation Document AI\nmodel which unifies text, image, and layout modalities together with varied\ntask formats, including document understanding and generation. UDOP leverages\nthe spatial correlation between textual content and document image to model\nimage, text, and layout modalities with one uniform representation. With a\nnovel Vision-Text-Layout Transformer, UDOP unifies pretraining and multi-domain\ndownstream tasks into a prompt-based sequence generation scheme. UDOP is\npretrained on both large-scale unlabeled document corpora using innovative\nself-supervised objectives and diverse labeled data. UDOP also learns to\ngenerate document images from text and layout modalities via masked image\nreconstruction. To the best of our knowledge, this is the first time in the\nfield of document AI that one model simultaneously achieves high-quality neural\ndocument editing and content customization. Our method sets the\nstate-of-the-art on 9 Document AI tasks, e.g., document understanding and QA,\nacross diverse data domains like finance reports, academic papers, and\nwebsites. UDOP ranks first on the leaderboard of the Document Understanding\nBenchmark (DUE).",
    "descriptor": "",
    "authors": [
      "Zineng Tang",
      "Ziyi Yang",
      "Guoxin Wang",
      "Yuwei Fang",
      "Yang Liu",
      "Chenguang Zhu",
      "Michael Zeng",
      "Cha Zhang",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02623"
  },
  {
    "id": "arXiv:2212.02626",
    "title": "A Generic Methodology for the Modular Verification of Security Protocol  Implementations",
    "abstract": "Security protocols are essential building blocks of modern IT systems. Subtle\nflaws in their design or implementation may compromise the security of entire\nsystems. It is, thus, important to prove the absence of such flaws through\nformal verification. Much existing work focuses on the verification of protocol\n*models*, which is not sufficient to show that their *implementations* are\nactually secure. Verification techniques for protocol implementations (e.g.,\nvia code generation or model extraction) typically impose severe restrictions\non the used programming language and code design, which may lead to sub-optimal\nimplementations. In this paper, we present a methodology for the modular\nverification of strong security properties directly on the level of the\nprotocol implementations. Our methodology leverages state-of-the-art\nverification logics and tools to support a wide range of implementations and\nprogramming languages. We demonstrate its effectiveness by verifying memory\nsafety and security of Go implementations of the Needham-Schroeder-Lowe and\nWireGuard protocols, including forward secrecy and injective agreement for\nWireGuard. We also show that our methodology is agnostic to a particular\nlanguage or program verifier with a prototype implementation for C.",
    "descriptor": "",
    "authors": [
      "Linard Arquint",
      "Malte Schwerhoff",
      "Vaibhav Mehta",
      "Peter M\u00fcller"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2212.02626"
  },
  {
    "id": "arXiv:2212.02629",
    "title": "POQue: Asking Participant-specific Outcome Questions for a Deeper  Understanding of Complex Events",
    "abstract": "Knowledge about outcomes is critical for complex event understanding but is\nhard to acquire. We show that by pre-identifying a participant in a complex\nevent, crowd workers are able to (1) infer the collective impact of salient\nevents that make up the situation, (2) annotate the volitional engagement of\nparticipants in causing the situation, and (3) ground the outcome of the\nsituation in state changes of the participants. By creating a multi-step\ninterface and a careful quality control strategy, we collect a high quality\nannotated dataset of 8K short newswire narratives and ROCStories with high\ninter-annotator agreement (0.74-0.96 weighted Fleiss Kappa). Our dataset, POQue\n(Participant Outcome Questions), enables the exploration and development of\nmodels that address multiple aspects of semantic understanding. Experimentally,\nwe show that current language models lag behind human performance in subtle\nways through our task formulations that target abstract and specific\ncomprehension of a complex event, its outcome, and a participant's influence\nover the event culmination.",
    "descriptor": "\nComments: Accepted to EMNLP 2022 main conference as a long paper\n",
    "authors": [
      "Sai Vallurupalli",
      "Sayontan Ghosh",
      "Katrin Erk",
      "Niranjan Balasubramanian",
      "Francis Ferraro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.02629"
  },
  {
    "id": "arXiv:2212.02630",
    "title": "A Sparse DAE Solver in Maple",
    "abstract": "In this paper, some adaptive single-step methods like Trapezoid (TR),\nImplicit-mid point (IMP), Euler-backward (EB), and Radau IIA (Rad) methods are\nimplemented in Maple to solve index-1 nonlinear Differential Algebraic\nEquations (DAEs). Maple's robust and efficient ability to search within a\nlist/set is exploited to identify the sparsity pattern and the analytic\nJacobian. The algorithm and implementation were found to be robust and\nefficient for index-1 DAE problems and scales well for finite difference/finite\nelement discretization of two-dimensional models with system size up to 10,000\nnonlinear DAEs and solves the same in few seconds.",
    "descriptor": "",
    "authors": [
      "Taejin Jang",
      "Maitri Uppaluri",
      "Venkat R. Subramanian"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.02630"
  },
  {
    "id": "arXiv:2212.02635",
    "title": "Stars: Tera-Scale Graph Building for Clustering and Graph Learning",
    "abstract": "A fundamental procedure in the analysis of massive datasets is the\nconstruction of similarity graphs. Such graphs play a key role for many\ndownstream tasks, including clustering, classification, graph learning, and\nnearest neighbor search. For these tasks, it is critical to build graphs which\nare sparse yet still representative of the underlying data. The benefits of\nsparsity are twofold: firstly, constructing dense graphs is infeasible in\npractice for large datasets, and secondly, the runtime of downstream tasks is\ndirectly influenced by the sparsity of the similarity graph. In this work, we\npresent $\\textit{Stars}$: a highly scalable method for building extremely\nsparse graphs via two-hop spanners, which are graphs where similar points are\nconnected by a path of length at most two. Stars can construct two-hop spanners\nwith significantly fewer similarity comparisons, which are a major bottleneck\nfor learning based models where comparisons are expensive to evaluate.\nTheoretically, we demonstrate that Stars builds a graph in nearly-linear time,\nwhere approximate nearest neighbors are contained within two-hop neighborhoods.\nIn practice, we have deployed Stars for multiple data sets allowing for graph\nbuilding at the $\\textit{Tera-Scale}$, i.e., for graphs with tens of trillions\nof edges. We evaluate the performance of Stars for clustering and graph\nlearning, and demonstrate 10~1000-fold improvements in pairwise similarity\ncomparisons compared to different baselines, and 2~10-fold improvement in\nrunning time without quality loss.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "CJ Carey",
      "Jonathan Halcrow",
      "Rajesh Jayaram",
      "Vahab Mirrokni",
      "Warren Schudy",
      "Peilin Zhong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.02635"
  },
  {
    "id": "arXiv:2212.02640",
    "title": "Low Power Mesh Algorithms for Image Problems",
    "abstract": "We analyze a physically motivated fine-grained mesh-connected computer model,\nassuming that a word of information takes a fixed area and that it takes unit\ntime and unit energy to move a word unit distance. This is a representation of\ncomputing on a chip with myriad tiny processors arranged as a mesh. While most\nmesh algorithms assume all processors are active at all times, we give\nalgorithms that have only a few processors on at any one time, which reduces\nthe power required. We apply this approach to basic problems involving images,\nshowing that there can be dramatic reductions in the peak power with only\nsmall, if any, changes in the time required. We also show that these algorithms\ngive a more efficient way to utilize power when more power is available.",
    "descriptor": "",
    "authors": [
      "Quentin Stout"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.02640"
  },
  {
    "id": "arXiv:2212.02645",
    "title": "AIDA: Analytic Isolation and Distance-based Anomaly Detection Algorithm",
    "abstract": "We combine the metrics of distance and isolation to develop the\n\\textit{Analytic Isolation and Distance-based Anomaly (AIDA) detection\nalgorithm}. AIDA is the first distance-based method that does not rely on the\nconcept of nearest-neighbours, making it a parameter-free model.\nDifferently from the prevailing literature, in which the isolation metric is\nalways computed via simulations, we show that AIDA admits an analytical\nexpression for the outlier score, providing new insights into the isolation\nmetric. Additionally, we present an anomaly explanation method based on AIDA,\nthe \\textit{Tempered Isolation-based eXplanation (TIX)} algorithm, which finds\nthe most relevant outlier features even in data sets with hundreds of\ndimensions. We test both algorithms on synthetic and empirical data: we show\nthat AIDA is competitive when compared to other state-of-the-art methods, and\nit is superior in finding outliers hidden in multidimensional feature\nsubspaces. Finally, we illustrate how the TIX algorithm is able to find\noutliers in multidimensional feature subspaces, and use these explanations to\nanalyze common benchmarks used in anomaly detection.",
    "descriptor": "",
    "authors": [
      "Luis Antonio Souto Arias",
      "Cornelis W. Oosterlee",
      "Pasquale Cirillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02645"
  },
  {
    "id": "arXiv:2212.02648",
    "title": "Spuriosity Rankings: Sorting Data for Spurious Correlation Robustness",
    "abstract": "We present a framework for ranking images within their class based on the\nstrength of spurious cues present. By measuring the gap in accuracy on the\nhighest and lowest ranked images (we call this spurious gap), we assess\nspurious feature reliance for $89$ diverse ImageNet models, finding that even\nthe best models underperform in images with weak spurious presence. However,\nthe effect of spurious cues varies far more dramatically across classes,\nemphasizing the crucial, often overlooked, class-dependence of the spurious\ncorrelation problem. While most spurious features we observe are clarifying\n(i.e. improving test-time accuracy when present, as is typically expected), we\nsurprisingly find many cases of confusing spurious features, where models\nperform better when they are absent. We then close the spurious gap by training\nnew classification heads on lowly ranked (i.e. without common spurious cues)\nimages, resulting in improved effective robustness to distribution shifts\n(ObjectNet, ImageNet-R, ImageNet-Sketch). We also propose a second metric to\nassess feature reliability, finding that spurious features are generally less\nreliable than non-spurious (core) ones, though again, spurious features can be\nmore reliable for certain classes. To enable our analysis, we annotated $5,000$\nfeature-class dependencies over {\\it all} of ImageNet as core or spurious using\nminimal human supervision. Finally, we show the feature discovery and\nspuriosity ranking framework can be extended to other datasets like CelebA and\nWaterBirds in a lightweight fashion with only linear layer training, leading to\ndiscovering a previously unknown racial bias in the Celeb-A hair\nclassification.",
    "descriptor": "",
    "authors": [
      "Mazda Moayeri",
      "Wenxiao Wang",
      "Sahil Singla",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02648"
  },
  {
    "id": "arXiv:2212.02649",
    "title": "Thales: Formulating and Estimating Architectural Vulnerability Factors  for DNN Accelerators",
    "abstract": "As Deep Neural Networks (DNNs) are increasingly deployed in safety critical\nand privacy sensitive applications such as autonomous driving and biometric\nauthentication, it is critical to understand the fault-tolerance nature of\nDNNs. Prior work primarily focuses on metrics such as Failures In Time (FIT)\nrate and the Silent Data Corruption (SDC) rate, which quantify how often a\ndevice fails. Instead, this paper focuses on quantifying the DNN accuracy given\nthat a transient error has occurred, which tells us how well a network behaves\nwhen a transient error occurs. We call this metric Resiliency Accuracy (RA). We\nshow that existing RA formulation is fundamentally inaccurate, because it\nincorrectly assumes that software variables (model weights/activations) have\nequal faulty probability under hardware transient faults. We present an\nalgorithm that captures the faulty probabilities of DNN variables under\ntransient faults and, thus, provides correct RA estimations validated by\nhardware. To accelerate RA estimation, we reformulate RA calculation as a Monte\nCarlo integration problem, and solve it using importance sampling driven by DNN\nspecific heuristics. Using our lightweight RA estimation method, we show that\ntransient faults lead to far greater accuracy degradation than what todays DNN\nresiliency tools estimate. We show how our RA estimation tool can help design\nmore resilient DNNs by integrating it with a Network Architecture Search\nframework.",
    "descriptor": "",
    "authors": [
      "Abhishek Tyagi",
      "Yiming Gan",
      "Shaoshan Liu",
      "Bo Yu",
      "Paul Whatmough",
      "Yuhao Zhu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02649"
  },
  {
    "id": "arXiv:2212.02651",
    "title": "Explaining Link Predictions in Knowledge Graph Embedding Models with  Influential Examples",
    "abstract": "We study the problem of explaining link predictions in the Knowledge Graph\nEmbedding (KGE) models. We propose an example-based approach that exploits the\nlatent space representation of nodes and edges in a knowledge graph to explain\npredictions. We evaluated the importance of identified triples by observing\nprogressing degradation of model performance upon influential triples removal.\nOur experiments demonstrate that this approach to generate explanations\noutperforms baselines on KGE models for two publicly available datasets.",
    "descriptor": "",
    "authors": [
      "Adrianna Janik",
      "Luca Costabello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02651"
  },
  {
    "id": "arXiv:2212.02659",
    "title": "Continual learning on deployment pipelines for Machine Learning Systems",
    "abstract": "Following the development of digitization, a growing number of large Original\nEquipment Manufacturers (OEMs) are adapting computer vision or natural language\nprocessing in a wide range of applications such as anomaly detection and\nquality inspection in plants. Deployment of such a system is becoming an\nextremely important topic. Our work starts with the least-automated deployment\ntechnologies of machine learning systems includes several iterations of\nupdates, and ends with a comparison of automated deployment techniques. The\nobjective is, on the one hand, to compare the advantages and disadvantages of\nvarious technologies in theory and practice, so as to facilitate later adopters\nto avoid making the generalized mistakes when implementing actual use cases,\nand thereby choose a better strategy for their own enterprises. On the other\nhand, to raise awareness of the evaluation framework for the deployment of\nmachine learning systems, to have more comprehensive and useful evaluation\nmetrics (e.g. table 2), rather than only focusing on a single factor (e.g.\ncompany cost). This is especially important for decision-makers in the\nindustry.",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022). Accepted by blind review at DMML Workshop this https URL\n",
    "authors": [
      "Qiang Li",
      "Chongyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02659"
  },
  {
    "id": "arXiv:2212.02661",
    "title": "Learning Trust Over Directed Graphs in Multiagent Systems (extended  version)",
    "abstract": "We address the problem of learning the legitimacy of other agents in a\nmultiagent network when an unknown subset is comprised of malicious actors. We\nspecifically derive results for the case of directed graphs and where\nstochastic side information, or observations of trust, is available. We refer\nto this as ``learning trust'' since agents must identify which neighbors in the\nnetwork are reliable, and we derive a protocol to achieve this. We also provide\nanalytical results showing that under this protocol i) agents can learn the\nlegitimacy of all other agents almost surely, and that ii) the opinions of the\nagents converge in mean to the true legitimacy of all other agents in the\nnetwork. Lastly, we provide numerical studies showing that our convergence\nresults hold in practice for various network topologies and variations in the\nnumber of malicious agents in the network.",
    "descriptor": "\nComments: 16 pages, 7 figures, extended version of conference submission\n",
    "authors": [
      "Orhan Eren Akg\u00fcn",
      "Arif Kerem Day\u0131",
      "Stephanie Gil",
      "Angelia Nedi\u0107"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2212.02661"
  },
  {
    "id": "arXiv:2212.02663",
    "title": "Efficient Malware Analysis Using Metric Embeddings",
    "abstract": "In this paper, we explore the use of metric learning to embed Windows PE\nfiles in a low-dimensional vector space for downstream use in a variety of\napplications, including malware detection, family classification, and malware\nattribute tagging. Specifically, we enrich labeling on malicious and benign PE\nfiles using computationally expensive, disassembly-based malicious\ncapabilities. Using these capabilities, we derive several different types of\nmetric embeddings utilizing an embedding neural network trained via contrastive\nloss, Spearman rank correlation, and combinations thereof. We then examine\nperformance on a variety of transfer tasks performed on the EMBER and SOREL\ndatasets, demonstrating that for several tasks, low-dimensional,\ncomputationally efficient metric embeddings maintain performance with little\ndecay, which offers the potential to quickly retrain for a variety of transfer\ntasks at significantly reduced storage overhead. We conclude with an\nexamination of practical considerations for the use of our proposed embedding\napproach, such as robustness to adversarial evasion and introduction of\ntask-specific auxiliary objectives to improve performance on mission critical\ntasks.",
    "descriptor": "\nComments: Pre-print of a manuscript submitted to the ACM Digital Threats: Research and Practice (DTRAP) Special Issue on Applied Machine Learning for Information Security. 19 Pages\n",
    "authors": [
      "Ethan M. Rudd",
      "David Krisiloff",
      "Scott Coull",
      "Daniel Olszewski",
      "Edward Raff",
      "James Holt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.02663"
  },
  {
    "id": "arXiv:2212.02666",
    "title": "Transformers for End-to-End InfoSec Tasks: A Feasibility Study",
    "abstract": "In this paper, we assess the viability of transformer models in end-to-end\nInfoSec settings, in which no intermediate feature representations or\nprocessing steps occur outside the model. We implement transformer models for\ntwo distinct InfoSec data formats - specifically URLs and PE files - in a novel\nend-to-end approach, and explore a variety of architectural designs, training\nregimes, and experimental settings to determine the ingredients necessary for\nperformant detection models. We show that in contrast to conventional\ntransformers trained on more standard NLP-related tasks, our URL transformer\nmodel requires a different training approach to reach high performance levels.\nSpecifically, we show that 1) pre-training on a massive corpus of unlabeled URL\ndata for an auto-regressive task does not readily transfer to binary\nclassification of malicious or benign URLs, but 2) that using an auxiliary\nauto-regressive loss improves performance when training from scratch. We\nintroduce a method for mixed objective optimization, which dynamically balances\ncontributions from both loss terms so that neither one of them dominates. We\nshow that this method yields quantitative evaluation metrics comparable to that\nof several top-performing benchmark classifiers. Unlike URLs, binary\nexecutables contain longer and more distributed sequences of information-rich\nbytes. To accommodate such lengthy byte sequences, we introduce additional\ncontext length into the transformer by providing its self-attention layers with\nan adaptive span similar to Sukhbaatar et al. We demonstrate that this approach\nperforms comparably to well-established malware detection models on benchmark\nPE file datasets, but also point out the need for further exploration into\nmodel improvements in scalability and compute efficiency.",
    "descriptor": "\nComments: Post-print of a manuscript accepted to ACM Asia-CCS Workshop on Robust Malware Analysis (WoRMA) 2022. 11 Pages total. arXiv admin note: substantial text overlap with arXiv:2011.03040\n",
    "authors": [
      "Ethan M. Rudd",
      "Mohammad Saidur Rahman",
      "Philip Tully"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.02666"
  },
  {
    "id": "arXiv:2212.02671",
    "title": "Visibility-Aware Navigation Among Movable Obstacles",
    "abstract": "In this paper, we examine the problem of visibility-aware robot navigation\namong movable obstacles (VANAMO). A variant of the well-known NAMO robotic\nplanning problem, VANAMO puts additional visibility constraints on robot motion\nand object movability. This new problem formulation lifts the restrictive\nassumption that the map is fully visible and the object positions are fully\nknown. We provide a formal definition of the VANAMO problem and propose the\nLook and Manipulate Backchaining (LaMB) algorithm for solving such problems.\nLaMB has a simple vision-based API that makes it more easily transferable to\nreal-world robot applications and scales to the large 3D environments. To\nevaluate LaMB, we construct a set of tasks that illustrate the complex\ninterplay between visibility and object movability that can arise in mobile\nbase manipulation problems in unknown environments. We show that LaMB\noutperforms NAMO and visibility-aware motion planning approaches as well as\nsimple combinations of them on complex manipulation problems with partial\nobservability.",
    "descriptor": "",
    "authors": [
      "Jose Muguira-Iturralde",
      "Aidan Curtis",
      "Yilun Du",
      "Leslie Pack Kaelbling",
      "Tom\u00e1s Lozano-P\u00e9rez"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.02671"
  },
  {
    "id": "arXiv:2212.02675",
    "title": "Attend Who is Weak: Pruning-assisted Medical Image Localization under  Sophisticated and Implicit Imbalances",
    "abstract": "Deep neural networks (DNNs) have rapidly become a \\textit{de facto} choice\nfor medical image understanding tasks. However, DNNs are notoriously fragile to\nthe class imbalance in image classification. We further point out that such\nimbalance fragility can be amplified when it comes to more sophisticated tasks\nsuch as pathology localization, as imbalances in such problems can have highly\ncomplex and often implicit forms of presence. For example, different pathology\ncan have different sizes or colors (w.r.t.the background), different underlying\ndemographic distributions, and in general different difficulty levels to\nrecognize, even in a meticulously curated balanced distribution of training\ndata. In this paper, we propose to use pruning to automatically and adaptively\nidentify \\textit{hard-to-learn} (HTL) training samples, and improve pathology\nlocalization by attending them explicitly, during training in\n\\textit{supervised, semi-supervised, and weakly-supervised} settings. Our main\ninspiration is drawn from the recent finding that deep classification models\nhave difficult-to-memorize samples and those may be effectively exposed through\nnetwork pruning \\cite{hooker2019compressed} - and we extend such observation\nbeyond classification for the first time. We also present an interesting\ndemographic analysis which illustrates HTLs ability to capture complex\ndemographic imbalances. Our extensive experiments on the Skin Lesion\nLocalization task in multiple training settings by paying additional attention\nto HTLs show significant improvement of localization performance by\n$\\sim$2-3\\%.",
    "descriptor": "\nComments: Accepted in WACV 2023\n",
    "authors": [
      "Ajay Jaiswal",
      "Tianlong Chen",
      "Justin F. Rousseau",
      "Yifan Peng",
      "Ying Ding",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02675"
  },
  {
    "id": "arXiv:2212.02679",
    "title": "Self-supervised Graph Representation Learning for Black Market Account  Detection",
    "abstract": "Nowadays, Multi-purpose Messaging Mobile App (MMMA) has become increasingly\nprevalent. MMMAs attract fraudsters and some cybercriminals provide support for\nfrauds via black market accounts (BMAs). Compared to fraudsters, BMAs are not\ndirectly involved in frauds and are more difficult to detect. This paper\nillustrates our BMA detection system SGRL (Self-supervised Graph Representation\nLearning) used in WeChat, a representative MMMA with over a billion users. We\ntailor Graph Neural Network and Graph Self-supervised Learning in SGRL for BMA\ndetection. The workflow of SGRL contains a pretraining phase that utilizes\nstructural information, node attribute information and available human\nknowledge, and a lightweight detection phase. In offline experiments, SGRL\noutperforms state-of-the-art methods by 16.06%-58.17% on offline evaluation\nmeasures. We deploy SGRL in the online environment to detect BMAs on the\nbillion-scale WeChat graph, and it exceeds the alternative by 7.27% on the\nonline evaluation measure. In conclusion, SGRL can alleviate label reliance,\ngeneralize well to unseen data, and effectively detect BMAs in WeChat.",
    "descriptor": "\nComments: WSDM 2023. This is the complete version containing the appendix\n",
    "authors": [
      "Zequan Xu",
      "Lianyun Li",
      "Hui Li",
      "Qihang Sun",
      "Shaofeng Hu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02679"
  },
  {
    "id": "arXiv:2212.02682",
    "title": "A New Locally Divergence-Free Path-Conservative Central-Upwind Scheme  for Ideal and Shallow Water Magnetohydrodynamics",
    "abstract": "We develop a new second-order unstaggered path-conservative central-upwind\n(PCCU) scheme for ideal and shallow water magnetohydrodynamics (MHD) equations.\nThe new scheme possesses several important properties: it locally preserves the\ndivergence-free constraint, it does not rely on any (approximate) Riemann\nproblem solver, and it robustly produces high-resolution and non-oscillatory\nresults. The derivation of the scheme is based on the Godunov-Powell\nnonconservative modifications of the studied MHD systems. The local\ndivergence-free property is enforced by augmenting the modified systems with\nthe evolution equations for the corresponding derivatives of the magnetic field\ncomponents. These derivatives are then used to design a special piecewise\nlinear reconstruction of the magnetic field, which guarantees a non-oscillatory\nnature of the resulting scheme. In addition, the proposed PCCU discretization\naccounts for the jump of the nonconservative product terms across cell\ninterfaces, thereby ensuring stability. We test the proposed PCCU scheme on\nseveral benchmarks for both ideal and shallow water MHD systems. The obtained\nnumerical results illustrate the performance of the new scheme, its robustness,\nand its ability not only to achieve high resolution, but also preserve the\npositivity of computed quantities such as density, pressure, and water depth.",
    "descriptor": "",
    "authors": [
      "Alina Chertock",
      "Alexander Kurganov",
      "Michael Redle",
      "Kailiang Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.02682"
  },
  {
    "id": "arXiv:2212.02684",
    "title": "Codex Hacks HackerRank: Memorization Issues and a Framework for Code  Synthesis Evaluation",
    "abstract": "The Codex model has demonstrated extraordinary competence in synthesizing\ncode from natural language problem descriptions. However, in order to reveal\nunknown failure modes and hidden biases, such large-scale models must be\nsystematically subjected to multiple and diverse evaluation studies.\nIn this work, we evaluate the code synthesis capabilities of the Codex model\nbased on a set of 115 Python problem statements from a popular competitive\nprogramming portal: HackerRank. Our evaluation shows that Codex is indeed\nproficient in Python, solving 96% of the problems in a zero-shot setting, and\n100% of the problems in a few-shot setting. However, Codex exhibits clear signs\nof generating memorized code based on our evaluation. This is alarming,\nespecially since the adoption and use of such models could directly impact how\ncode is written and produced in the foreseeable future. With this in mind, we\nfurther discuss and highlight some of the prominent risks associated with\nlarge-scale models of source code. Finally, we propose a framework for\ncode-synthesis evaluation using variations of problem statements based on\nmutations.",
    "descriptor": "",
    "authors": [
      "Anjan Karmakar",
      "Julian Aron Prenner",
      "Marco D'Ambros",
      "Romain Robbes"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02684"
  },
  {
    "id": "arXiv:2212.02687",
    "title": "Enabling and Accelerating Dynamic Vision Transformer Inference for  Real-Time Applications",
    "abstract": "Many state-of-the-art deep learning models for computer vision tasks are\nbased on the transformer architecture. Such models can be computationally\nexpensive and are typically statically set to meet the deployment scenario.\nHowever, in real-time applications, the resources available for every inference\ncan vary considerably and be smaller than what state-of-the-art models use. We\ncan use dynamic models to adapt the model execution to meet real-time\napplication resource constraints. While prior dynamic work has primarily\nminimized resource utilization for less complex input images while maintaining\naccuracy and focused on CNNs and early transformer models such as BERT, we\nadapt vision transformers to meet system dynamic resource constraints,\nindependent of the input image. We find that unlike early transformer models,\nrecent state-of-the-art vision transformers heavily rely on convolution layers.\nWe show that pretrained models are fairly resilient to skipping computation in\nthe convolution and self-attention layers, enabling us to create a low-overhead\nsystem for dynamic real-time inference without additional training. Finally, we\ncreate a optimized accelerator for these dynamic vision transformers in a 5nm\ntechnology. The PE array occupies 2.26mm$^2$ and is 17 times faster than a\nNVIDIA TITAN V GPU for state-of-the-art transformer-based models for semantic\nsegmentation.",
    "descriptor": "",
    "authors": [
      "Kavya Sreedhar",
      "Jason Clemons",
      "Rangharajan Venkatesan",
      "Stephen W. Keckler",
      "Mark Horowitz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2212.02687"
  },
  {
    "id": "arXiv:2212.02689",
    "title": "Visual Area of Interests based Multimodal Trajectory Prediction for  Probabilistic Risk Assessment",
    "abstract": "Accurate and reliable prediction of driving intentions and future\ntrajectories contributes to cooperation between human drivers and ADAS in\ncomplex traffic environments. This paper proposes a visual AOI (Area of\nInterest) based multimodal trajectory prediction model for probabilistic risk\nassessment at intersections. In this study, we find that the visual AOI implies\nthe driving intention and is about 0.6-2.1 s ahead of the operation. Therefore,\nwe designed a trajectory prediction model that integrates the driving intention\n(DI) and the multimodal trajectory (MT) predictions. The DI model was\npre-trained independently to extract the driving intention using features\nincluding the visual AOI, historical vehicle states, and environmental context.\nThe intention prediction experiments verify that the visual AOI-based DI model\npredicts steering intention 0.925 s ahead of the actual steering operation. The\ntrained DI model is then integrated into the trajectory prediction model to\nfilter multimodal trajectories. The trajectory prediction experiments show that\nthe proposed model outperforms the state-of-the-art models. Risk assessment for\ntraffics at intersections verifies that the proposed method achieves high\naccuracy and a low false alarm rate, and identifies the potential risk about 3\ns before a conflict occurs.",
    "descriptor": "\nComments: 11 pages, 13 figures\n",
    "authors": [
      "Qiang Zhang",
      "Lingfang Yang",
      "Xiaoliang Zhang",
      "Xiaolin Song",
      "Zhi Huang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.02689"
  },
  {
    "id": "arXiv:2212.02691",
    "title": "LUNA: Language Understanding with Number Augmentations on Transformers  via Number Plugins and Pre-training",
    "abstract": "Transformers are widely used in NLP tasks. However, current approaches to\nleveraging transformers to understand language expose one weak spot: Number\nunderstanding. In some scenarios, numbers frequently occur, especially in\nsemi-structured data like tables. But current approaches to rich-number tasks\nwith transformer-based language models abandon or lose some of the numeracy\ninformation - e.g., breaking numbers into sub-word tokens - which leads to many\nnumber-related errors. In this paper, we propose the LUNA framework which\nimproves the numerical reasoning and calculation capabilities of\ntransformer-based language models. With the number plugin of NumTok and NumBed,\nLUNA represents each number as a whole to model input. With number\npre-training, including regression loss and model distillation, LUNA bridges\nthe gap between number and vocabulary embeddings. To the best of our knowledge,\nthis is the first work that explicitly injects numeracy capability into\nlanguage models using Number Plugins. Besides evaluating toy models on toy\ntasks, we evaluate LUNA on three large-scale transformer models (RoBERTa, BERT,\nTabBERT) over three different downstream tasks (TATQA, TabFact, CrediTrans),\nand observe the performances of language models are constantly improved by\nLUNA. The augmented models also improve the official baseline of TAT-QA (EM:\n50.15 -> 59.58) and achieve SOTA performance on CrediTrans (F1 = 86.17).",
    "descriptor": "",
    "authors": [
      "Hongwei Han",
      "Jialiang Xu",
      "Mengyu Zhou",
      "Yijia Shao",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.02691"
  },
  {
    "id": "arXiv:2212.02692",
    "title": "Learning Locally, Communicating Globally: Reinforcement Learning of  Multi-robot Task Allocation for Cooperative Transport",
    "abstract": "We consider task allocation for multi-object transport using a multi-robot\nsystem, in which each robot selects one object among multiple objects with\ndifferent and unknown weights. The existing centralized methods assume the\nnumber of robots and tasks to be fixed, which is inapplicable to scenarios that\ndiffer from the learning environment. Meanwhile, the existing distributed\nmethods limit the minimum number of robots and tasks to a constant value,\nmaking them applicable to various numbers of robots and tasks. However, they\ncannot transport an object whose weight exceeds the load capacity of robots\nobserving the object. To make it applicable to various numbers of robots and\nobjects with different and unknown weights, we propose a framework using\nmulti-agent reinforcement learning for task allocation. First, we introduce a\nstructured policy model consisting of 1) predesigned dynamic task priorities\nwith global communication and 2) a neural network-based distributed policy\nmodel that determines the timing for coordination. The distributed policy\nbuilds consensus on the high-priority object under local observations and\nselects cooperative or independent actions. Then, the policy is optimized by\nmulti-agent reinforcement learning through trial and error. This structured\npolicy of local learning and global communication makes our framework\napplicable to various numbers of robots and objects with different and unknown\nweights, as demonstrated by numerical simulations.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Kazuki Shibata",
      "Tomohiko Jimbo",
      "Tadashi Odashima",
      "Keisuke Takeshita",
      "Takamitsu Matsubara"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.02692"
  },
  {
    "id": "arXiv:2212.02701",
    "title": "On the Discredibility of Membership Inference Attacks",
    "abstract": "With the wide-spread application of machine learning models, it has become\ncritical to study the potential data leakage of models trained on sensitive\ndata. Recently, various membership inference (MI) attacks are proposed that\ndetermines if a sample was part of the training set or not. Although the first\ngeneration of MI attacks has been proven to be ineffective in practice, a few\nrecent studies proposed practical MI attacks that achieve reasonable true\npositive rate at low false positive rate. The question is whether these attacks\ncan be reliably used in practice. We showcase a practical application of\nmembership inference attacks where it is used by an auditor (investigator) to\nprove to a judge/jury that an auditee unlawfully used sensitive data during\ntraining. Then, we show that the auditee can provide a dataset (with\npotentially unlimited number of samples) to a judge where MI attacks\ncatastrophically fail. Hence, the auditee challenges the credibility of the\nauditor and can get the case dismissed. More importantly, we show that the\nauditee does not need to know anything about the MI attack neither a query\naccess to it. In other words, all currently SOTA MI attacks in literature\nsuffer from the same issue. Through comprehensive experimental evaluation, we\nshow that our algorithms can increase the false positive rate from ten to\nthousands times larger than what auditor claim to the judge. Lastly, we argue\nthat the implication of our algorithms is beyond discredibility: Current\nmembership inference attacks can identify the memorized subpopulations, but\nthey cannot reliably identify which exact sample in the subpopulation was used\nduring training.",
    "descriptor": "",
    "authors": [
      "Shahbaz Rezaei",
      "Xin Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02701"
  },
  {
    "id": "arXiv:2212.02704",
    "title": "Benchmarking AutoML algorithms on a collection of binary problems",
    "abstract": "Automated machine learning (AutoML) algorithms have grown in popularity due\nto their high performance and flexibility to adapt to different problems and\ndata sets. With the increasing number of AutoML algorithms, deciding which\nwould best suit a given problem becomes increasingly more work. Therefore, it\nis essential to use complex and challenging benchmarks which would be able to\ndifferentiate the AutoML algorithms from each other. This paper compares the\nperformance of four different AutoML algorithms: Tree-based Pipeline\nOptimization Tool (TPOT), Auto-Sklearn, Auto-Sklearn 2, and H2O AutoML. We use\nthe Diverse and Generative ML benchmark (DIGEN), a diverse set of synthetic\ndatasets derived from generative functions designed to highlight the strengths\nand weaknesses of the performance of common machine learning algorithms. We\nconfirm that AutoML can identify pipelines that perform well on all included\ndatasets. Most AutoML algorithms performed similarly without much room for\nimprovement; however, some were more consistent than others at finding\nhigh-performing solutions for some datasets.",
    "descriptor": "",
    "authors": [
      "Pedro Henrique Ribeiro",
      "Patryk Orzechowski",
      "Joost Wagenaar",
      "Jason H. Moore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02704"
  },
  {
    "id": "arXiv:2212.02705",
    "title": "What is the Solution for State Adversarial Multi-Agent Reinforcement  Learning?",
    "abstract": "Various types of Multi-Agent Reinforcement Learning (MARL) methods have been\ndeveloped, assuming that agents' policies are based on true states. Recent\nworks have improved the robustness of MARL under uncertainties from the reward,\ntransition probability, or other partners' policies. However, in real-world\nmulti-agent systems, state estimations may be perturbed by sensor measurement\nnoise or even adversaries. Agents' policies trained with only true state\ninformation will deviate from optimal solutions when facing adversarial state\nperturbations during execution. MARL under adversarial state perturbations has\nlimited study. Hence, in this work, we propose a State-Adversarial Markov Game\n(SAMG) and make the first attempt to study the fundamental properties of MARL\nunder state uncertainties. We prove that the optimal agent policy and the\nrobust Nash equilibrium do not always exist for an SAMG. Instead, we define the\nsolution concept, robust agent policy, of the proposed SAMG under adversarial\nstate perturbations, where agents want to maximize the worst-case expected\nstate value. We then design a gradient descent ascent-based robust MARL\nalgorithm to learn the robust policies for the MARL agents. Our experiments\nshow that adversarial state perturbations decrease agents' rewards for several\nbaselines from the existing literature, while our algorithm outperforms\nbaselines with state perturbations and significantly improves the robustness of\nthe MARL policies under state uncertainties.",
    "descriptor": "",
    "authors": [
      "Songyang Han",
      "Sanbao Su",
      "Sihong He",
      "Shuo Han",
      "Haizhao Yang",
      "Fei Miao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02705"
  },
  {
    "id": "arXiv:2212.02706",
    "title": "Predicted Trajectory Guidance Control Framework of Teleoperated Ground  Vehicles Compensating for Delays",
    "abstract": "Maneuverability and drivability of the teleoperated ground vehicle could be\nseriously degraded by large communication delays if the delays are not properly\ncompensated. This paper proposes a predicted trajectory guidance control (PTGC)\nframework to compensate for such delays, thereby improving the performance of\nthe teleoperation system. The novelty of this PTGC framework is that\nteleoperators intended trajectory is predicted at the vehicle side with their\ndelayed historical control commands and the LiDAR 3D point cloud of the\nenvironment, and then the vehicle is guided by the predicted trajectory. By\nremoving the teleoperator from the direct control loop, the presented method is\nless sensitive to delays, and delays are compensated as long as the prediction\nhorizon exceeds the delays. Human-in-the-loop simulation experiments are\ndesigned to evaluate the teleoperation performance with the proposed method\nunder five delay levels. Based on the repeated measurement analysis of\nvariance, it is concluded that the PTGC method can significantly improve the\nperformance of the teleoperated ground vehicles under large delays(>200ms),\nsuch as the task completion time (TCT), deviation to centerline (D2C) and\nsteering effort (SE). In addition, the results also show that teleoperators can\nadapt to smaller delays, and the presented method is ineffective in such cases.",
    "descriptor": "\nComments: 10 pages, 11 figures\n",
    "authors": [
      "Qiang Zhang",
      "Zhouli Xu",
      "Yihang Wang",
      "Lingfang Yang",
      "Xiaolin Song",
      "Zhi Huang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.02706"
  },
  {
    "id": "arXiv:2212.02710",
    "title": "Beyond Object Recognition: A New Benchmark towards Object Concept  Learning",
    "abstract": "Understanding objects is a central building block of artificial intelligence,\nespecially for embodied AI. Even though object recognition excels with deep\nlearning, current machines still struggle to learn higher-level knowledge,\ne.g., what attributes an object has, and what can we do with an object. In this\nwork, we propose a challenging Object Concept Learning (OCL) task to push the\nenvelope of object understanding. It requires machines to reason out object\naffordances and simultaneously give the reason: what attributes make an object\npossesses these affordances. To support OCL, we build a densely annotated\nknowledge base including extensive labels for three levels of object concept\n(category, attribute, affordance), and the causal relations of three levels. By\nanalyzing the causal structure of OCL, we present a baseline, Object Concept\nReasoning Network (OCRN). It leverages causal intervention and concept\ninstantiation to infer the three levels following their causal relations. In\nexperiments, OCRN effectively infers the object knowledge while following the\ncausalities well. Our data and code are available at https://mvig-rhos.com/ocl.",
    "descriptor": "\nComments: Preprint. Webpage: this https URL\n",
    "authors": [
      "Yong-Lu Li",
      "Yue Xu",
      "Xinyu Xu",
      "Xiaohan Mao",
      "Yuan Yao",
      "Siqi Liu",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02710"
  },
  {
    "id": "arXiv:2212.02712",
    "title": "Improved Beam Search for Hallucination Mitigation in Abstractive  Summarization",
    "abstract": "Advancement in large pretrained language models has significantly improved\ntheir performance for conditional language generation tasks including\nsummarization albeit with hallucinations. To reduce hallucinations,\nconventional methods proposed improving beam search or using a fact checker as\na postprocessing step. In this paper, we investigate the use of the Natural\nLanguage Inference (NLI) entailment metric to detect and prevent hallucinations\nin summary generation. We propose an NLI-assisted beam re-ranking mechanism by\ncomputing entailment probability scores between the input context and\nsummarization model-generated beams during saliency-enhanced greedy decoding.\nMoreover, a diversity metric is introduced to compare its effectiveness against\nvanilla beam search. Our proposed algorithm significantly outperforms vanilla\nbeam decoding on XSum and CNN/DM datasets.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Arvind Krishna Sridhar",
      "Erik Visser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02712"
  },
  {
    "id": "arXiv:2212.02715",
    "title": "Efficient Learning of Voltage Control Strategies via Model-based Deep  Reinforcement Learning",
    "abstract": "This article proposes a model-based deep reinforcement learning (DRL) method\nto design emergency control strategies for short-term voltage stability\nproblems in power systems. Recent advances show promising results in model-free\nDRL-based methods for power systems, but model-free methods suffer from poor\nsample efficiency and training time, both critical for making state-of-the-art\nDRL algorithms practically applicable. DRL-agent learns an optimal policy via a\ntrial-and-error method while interacting with the real-world environment. And\nit is desirable to minimize the direct interaction of the DRL agent with the\nreal-world power grid due to its safety-critical nature. Additionally,\nstate-of-the-art DRL-based policies are mostly trained using a physics-based\ngrid simulator where dynamic simulation is computationally intensive, lowering\nthe training efficiency. We propose a novel model-based-DRL framework where a\ndeep neural network (DNN)-based dynamic surrogate model, instead of a\nreal-world power-grid or physics-based simulation, is utilized with the policy\nlearning framework, making the process faster and sample efficient. However,\nstabilizing model-based DRL is challenging because of the complex system\ndynamics of large-scale power systems. We solved these issues by incorporating\nimitation learning to have a warm start in policy learning, reward-shaping, and\nmulti-step surrogate loss. Finally, we achieved 97.5% sample efficiency and\n87.7% training efficiency for an application to the IEEE 300-bus test system.",
    "descriptor": "",
    "authors": [
      "Ramij R. Hossain",
      "Tianzhixi Yin",
      "Yan Du",
      "Renke Huang",
      "Jie Tan",
      "Wenhao Yu",
      "Yuan Liu",
      "Qiuhua Huang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.02715"
  },
  {
    "id": "arXiv:2212.02719",
    "title": "Integrating Intelligent Reflecting Surface into Base Station:  Architecture, Channel Model, and Passive Reflection Design",
    "abstract": "Existing works on IRS have mainly considered IRS being deployed in the\nenvironment to dynamically control the wireless channels between the BS and its\nserved users. In contrast, we propose in this paper a new integrated IRS BS\narchitecture by deploying IRSs inside the BS antenna radome. Since the distance\nbetween the integrated IRSs and BS antenna array is practically small, the path\nloss among them is significantly reduced and the real time control of the IRS\nreflection by the BS becomes easier to implement. However, the resultant near\nfield channel model also becomes drastically different. Thus, we propose an\nelement wise channel model for IRS to characterize the channel vector between\neach single antenna user and the antenna array of the BS, which includes the\ndirect (without any IRS reflection) as well as the single and double\nIRS-reflection channel components. Then, we formulate a problem to optimize the\nreflection coefficients of all IRS reflecting elements for maximizing the\nuplink sum rate of the users. By considering two typical cases with/without\nperfect CSI at the BS, the formulated problem is solved efficiently by adopting\nthe successive refinement method and iterative random phase algorithm (IRPA),\nrespectively. Numerical results validate the substantial capacity gain of the\nintegrated IRS BS architecture over the conventional multi antenna BS without\nintegrated IRS. Moreover, the proposed algorithms significantly outperform\nother benchmark schemes in terms of sum rate, and the IRPA without CSI can\napproach the performance upper bound with perfect CSI as the training overhead\nincreases.",
    "descriptor": "\nComments: 30 pages, 10 figures, submitted to IEEE journal for possible publication\n",
    "authors": [
      "Yuwei Huang",
      "Lipeng Zhu",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.02719"
  },
  {
    "id": "arXiv:2212.02723",
    "title": "Learning with Opponent Modeling in Repeated Auctions",
    "abstract": "We design an algorithm to learn bidding strategies in repeated auctions. We\nconsider seller and all bidders simultaneously for strategy learning and\nexplore the convergence of this system. We apply and improve the opponent\nmodeling class algorithm to allow bidders to learn optimal bidding strategies\nin this multiagent reinforcement learning environment. The algorithm uses\nalmost no private information about the opponent and has no restrictions on the\nstrategy space, so it can be extended to multiple scenarios. Our algorithm\nimproves the utility compared to both static bidding strategies and dynamic\nlearning strategies. We hope the application of opponent modeling in auctions\nwill promote the research of bidding strategies in online auctions and the\ndesign of non-incentive compatible auction mechanisms.",
    "descriptor": "",
    "authors": [
      "Yudong Hu",
      "Congying Han",
      "Tiande Guo",
      "Hao Xiao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2212.02723"
  },
  {
    "id": "arXiv:2212.02724",
    "title": "Decentralized Stochastic Gradient Descent Ascent for Finite-Sum Minimax  Problems",
    "abstract": "Minimax optimization problems have attracted significant attention in recent\nyears due to their widespread application in numerous machine learning models.\nTo solve the minimax optimization problem, a wide variety of stochastic\noptimization methods have been proposed. However, most of them ignore the\ndistributed setting where the training data is distributed on multiple workers.\nIn this paper, we developed a novel decentralized stochastic gradient descent\nascent method for the finite-sum minimax optimization problem. In particular,\nby employing the variance-reduced gradient, our method can achieve\n$O(\\frac{\\sqrt{n}\\kappa^3}{(1-\\lambda)^2\\epsilon^2})$ sample complexity and\n$O(\\frac{\\kappa^3}{(1-\\lambda)^2\\epsilon^2})$ communication complexity for the\nnonconvex-strongly-concave minimax optimization problem. As far as we know, our\nwork is the first one to achieve such theoretical complexities for this kind of\nproblem. At last, we apply our method to optimize the AUC maximization problem\nand the experimental results confirm the effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Hongchang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.02724"
  },
  {
    "id": "arXiv:2212.02726",
    "title": "Dataset vs Reality: Understanding Model Performance from the Perspective  of Information Need",
    "abstract": "Deep learning technologies have brought us many models that outperform human\nbeings on a few benchmarks. An interesting question is: can these models well\nsolve real-world problems with similar settings (e.g., same input/output) to\nthe benchmark datasets? We argue that a model is trained to answer the same\ninformation need for which the training dataset is created. Although some\ndatasets may share high structural similarities, e.g., question-answer pairs\nfor the question answering (QA) task and image-caption pairs for the image\ncaptioning (IC) task, not all datasets are created for the same information\nneed. To support our argument, we conduct a comprehensive analysis on widely\nused benchmark datasets for both QA and IC tasks. We compare the dataset\ncreation process (e.g., crowdsourced, or collected data from real users or\ncontent providers) from the perspective of information need in the context of\ninformation retrieval. To show the differences between datasets, we perform\nboth word-level and sentence-level analysis. We show that data collected from\nreal users or content providers tend to have richer, more diverse, and more\nspecific words than data annotated by crowdworkers. At sentence level, data by\ncrowdworkers share similar dependency distributions and higher similarities in\nsentence structure, compared to data collected from content providers. We\nbelieve our findings could partially explain why some datasets are considered\nmore challenging than others, for similar tasks. Our findings may also be\nhelpful in guiding new dataset construction.",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Mengying Yu",
      "Aixin Sun"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.02726"
  },
  {
    "id": "arXiv:2212.02728",
    "title": "Multifidelity conditional value-at-risk estimation by dimensionally  decomposed generalized polynomial chaos-Kriging",
    "abstract": "We propose novel methods for Conditional Value-at-Risk (CVaR) estimation for\nnonlinear systems under high-dimensional dependent random inputs. We propose a\nDD-GPCE-Kriging surrogate that merges dimensionally decomposed generalized\npolynomial chaos expansion and Kriging to accurately approximate nonlinear and\nnonsmooth random outputs. We integrate DD-GPCE-Kriging with (1) Monte Carlo\nsimulation (MCS) and (2) multifidelity importance sampling (MFIS). The\nMCS-based method samples from DD-GPCE-Kriging, which is efficient and accurate\nfor high-dimensional dependent random inputs. A surrogate model introduces\nbias, so we propose an MFIS-based method where DD-GPCE-Kriging determines the\nbiasing density efficiently and the high-fidelity model is used to estimate\nCVaR from biased samples. To speed up the biasing density construction, we\ncompute DD-GPCE-Kriging using a cheap-to-evaluate low-fidelity model. Numerical\nresults for mathematical functions show that the MFIS-based method is more\naccurate than the MCS-based method when the output is nonsmooth. The\nscalability of the proposed methods and their applicability to complex\nengineering problems are demonstrated on a two-dimensional composite laminate\nwith 28 (partly dependent) random inputs and a three-dimensional composite\nT-joint with 20 (partly dependent) random inputs. In the former, the proposed\nMFIS-based method achieves 104x speedup compared to standard MCS using the\nhigh-fidelity model, while accurately estimating CVaR with 1.15% error.",
    "descriptor": "\nComments: 31 pages, 6 figures, research paper\n",
    "authors": [
      "Dongjin Lee",
      "Boris Kramer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.02728"
  },
  {
    "id": "arXiv:2212.02732",
    "title": "Deterministic $K$-identification For Slow Fading Channel",
    "abstract": "Deterministic $K$-identification (DKI) is addressed for Gaussian channels\nwith slow fading (GSF), where the transmitter is restricted to an average power\nconstraint and channel side information is available at the decoder. We derive\nlower and upper bounds on the DKI capacity when the number identifiable\nmessages $K$ may grow with the codeword length $n$. As a key finding, we\nestablish that for deterministic encoding, the codebook size scales as\n$2^{(n\\log n)R}$ assuming that the number of identifiable messages scales as $K\n= 2^{\\kappa \\log n}$, where $R$ is the coding rate and $\\kappa \\in [0,1)$ is\nthe identification target rate.",
    "descriptor": "\nComments: 24 pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2211.11024, arXiv:2203.02784. substantial text overlap with arXiv:2211.11024, arXiv:2203.02784\n",
    "authors": [
      "Mohammad Javad Salariseddigh",
      "Muris Spahovic",
      "Christian Deppe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.02732"
  },
  {
    "id": "arXiv:2212.02733",
    "title": "Curriculum Learning for Relative Overgeneralization",
    "abstract": "In multi-agent reinforcement learning (MARL), many popular methods, such as\nVDN and QMIX, are susceptible to a critical multi-agent pathology known as\nrelative overgeneralization (RO), which arises when the optimal joint action's\nutility falls below that of a sub-optimal joint action in cooperative tasks. RO\ncan cause the agents to get stuck into local optima or fail to solve tasks that\nrequire significant coordination between agents within a given timestep. Recent\nvalue-based MARL algorithms such as QPLEX and WQMIX can overcome RO to some\nextent. However, our experimental results show that they can still fail to\nsolve cooperative tasks that exhibit strong RO. In this work, we propose a\nnovel approach called curriculum learning for relative overgeneralization\n(CURO) to better overcome RO. To solve a target task that exhibits strong RO,\nin CURO, we first fine-tune the reward function of the target task to generate\nsource tasks that are tailored to the current ability of the learning agent and\ntrain the agent on these source tasks first. Then, to effectively transfer the\nknowledge acquired in one task to the next, we use a novel transfer learning\nmethod that combines value function transfer with buffer transfer, which\nenables more efficient exploration in the target task. We demonstrate that,\nwhen applied to QMIX, CURO overcomes severe RO problem and significantly\nimproves performance, yielding state-of-the-art results in a variety of\ncooperative multi-agent tasks, including the challenging StarCraft II\nmicromanagement benchmarks.",
    "descriptor": "",
    "authors": [
      "Lin Shi",
      "Bei Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2212.02733"
  },
  {
    "id": "arXiv:2212.02738",
    "title": "RIS-Assisted Green Secure Communications: Active RIS or Passive RIS?",
    "abstract": "Reconfigurable Intelligent Surface (RIS) is one of the promising techniques\nfor 6G wireless communications, and recently has also been shown to be able to\nimprove secure communications. However, there is a \"double fading\" effect in\nthe reflection link between base station and user, thus passive RIS only\nachieves a negligible secrecy gain in typical communications scenarios.In this\nletter, we propose an active RIS-aided multi-antenna physical layer secrecy\ntransmission scheme, where the active RIS can amplify the signal actively. Our\naim is to minimize the transmit power subject to the constraint of secrecy\nrate. To solve the non-convex optimization problem, a penalty-based alternating\nminimization (AltMin) algorithm is proposed to optimize both the beamformer at\nthe transmitter and the reflection matrix at RIS. Simulation results show that\nactive RIS can resist the impact of \"double fading\" effect effectively, and is\nmore energy efficient than passive RIS.",
    "descriptor": "",
    "authors": [
      "Weigang Lv",
      "Jiale Bai",
      "Qingli Yan",
      "Hui-Ming Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.02738"
  },
  {
    "id": "arXiv:2212.02739",
    "title": "Semantic-aware Message Broadcasting for Efficient Unsupervised Domain  Adaptation",
    "abstract": "Vision transformer has demonstrated great potential in abundant vision tasks.\nHowever, it also inevitably suffers from poor generalization capability when\nthe distribution shift occurs in testing (i.e., out-of-distribution data). To\nmitigate this issue, we propose a novel method, Semantic-aware Message\nBroadcasting (SAMB), which enables more informative and flexible feature\nalignment for unsupervised domain adaptation (UDA). Particularly, we study the\nattention module in the vision transformer and notice that the alignment space\nusing one global class token lacks enough flexibility, where it interacts\ninformation with all image tokens in the same manner but ignores the rich\nsemantics of different regions. In this paper, we aim to improve the richness\nof the alignment features by enabling semantic-aware adaptive message\nbroadcasting. Particularly, we introduce a group of learned group tokens as\nnodes to aggregate the global information from all image tokens, but encourage\ndifferent group tokens to adaptively focus on the message broadcasting to\ndifferent semantic regions. In this way, our message broadcasting encourages\nthe group tokens to learn more informative and diverse information for\neffective domain alignment. Moreover, we systematically study the effects of\nadversarial-based feature alignment (ADA) and pseudo-label based self-training\n(PST) on UDA. We find that one simple two-stage training strategy with the\ncooperation of ADA and PST can further improve the adaptation capability of the\nvision transformer. Extensive experiments on DomainNet, OfficeHome, and\nVisDA-2017 demonstrate the effectiveness of our methods for UDA.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Xin Li",
      "Cuiling Lan",
      "Guoqiang Wei",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02739"
  },
  {
    "id": "arXiv:2212.02740",
    "title": "Stealthy Peers: Understanding Security Risks of WebRTC-Based  Peer-Assisted Video Streaming",
    "abstract": "As an emerging service for in-browser content delivery, peer-assisted\ndelivery network (PDN) is reported to offload up to 95\\% of bandwidth\nconsumption for video streaming, significantly reducing the cost incurred by\ntraditional CDN services. With such benefits, PDN services significantly impact\ntoday's video streaming and content delivery model. However, their security\nimplications have never been investigated. In this paper, we report the first\neffort to address this issue, which is made possible by a suite of\nmethodologies, e.g., an automatic pipeline to discover PDN services and their\ncustomers, and a PDN analysis framework to test the potential security and\nprivacy risks of these services. Our study has led to the discovery of 3\nrepresentative PDN providers, along with 134 websites and 38 mobile apps as\ntheir customers. Most of these PDN customers are prominent video streaming\nservices with millions of monthly visits or app downloads (from Google Play).\nAlso found in our study are another 9 top video/live streaming websites with\neach equipped with a proprietary PDN solution. Most importantly, our analysis\non these PDN services has brought to light a series of security risks, which\nhave never been reported before, including free riding of the public PDN\nservices, video segment pollution, exposure of video viewers' IPs to other\npeers, and resource squatting. All such risks have been studied through\ncontrolled experiments and measurements, under the guidance of our\ninstitution's IRB. We have responsibly disclosed these security risks to\nrelevant PDN providers, who have acknowledged our findings, and also discussed\nthe avenues to mitigate these risks.",
    "descriptor": "",
    "authors": [
      "Siyuan Tang",
      "Eihal Alowaisheq",
      "Xianghang Mi",
      "Yi Chen",
      "XiaoFeng Wang",
      "Yanzhi Dou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.02740"
  },
  {
    "id": "arXiv:2212.02742",
    "title": "A Learning Based Hypothesis Test for Harmful Covariate Shift",
    "abstract": "The ability to quickly and accurately identify covariate shift at test time\nis a critical and often overlooked component of safe machine learning systems\ndeployed in high-risk domains. While methods exist for detecting when\npredictions should not be made on out-of-distribution test examples,\nidentifying distributional level differences between training and test time can\nhelp determine when a model should be removed from the deployment setting and\nretrained. In this work, we define harmful covariate shift (HCS) as a change in\ndistribution that may weaken the generalization of a predictive model. To\ndetect HCS, we use the discordance between an ensemble of classifiers trained\nto agree on training data and disagree on test data. We derive a loss function\nfor training this ensemble and show that the disagreement rate and entropy\nrepresent powerful discriminative statistics for HCS. Empirically, we\ndemonstrate the ability of our method to detect harmful covariate shift with\nstatistical certainty on a variety of high-dimensional datasets. Across\nnumerous domains and modalities, we show state-of-the-art performance compared\nto existing methods, particularly when the number of observed test samples is\nsmall.",
    "descriptor": "",
    "authors": [
      "Tom Ginsberg",
      "Zhongyuan Liang",
      "Rahul G. Krishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02742"
  },
  {
    "id": "arXiv:2212.02744",
    "title": "First-order perturbation theory of trust-region subproblems",
    "abstract": "Trust-region subproblem (TRS) is an important problem arising in many\napplications such as numerical optimization, Tikhonov regularization of\nill-posed problems, and constrained eigenvalue problems. In recent decades,\nextensive works focus on how to solve the trust-region subproblem efficiently.\nTo the best of our knowledge, there are few results on perturbation analysis of\nthe trust-region subproblem. In order to fill in this gap, we focus on\nfirst-order perturbation theory of the trust-region subproblem. The main\ncontributions of this paper are three-fold. First, suppose that the TRS is in\neasy case, we give a sufficient condition under which the perturbed TRS is\nstill in easy case. Second, with the help of the structure of the TRS and the\nclassical eigenproblem perturbation theory, we perform first-order perturbation\nanalysis on the Lagrange multiplier and the solution of the TRS, and define the\ncondition numbers of them. Third, we point out that the solution and the\nLagrange multiplier could be well-conditioned even if TRS is in nearly hard\ncase. The established results are computable, and are helpful to evaluate\nill-conditioning of the TRS problem beforehand. Numerical experiments show the\nsharpness of the established bounds and the effectiveness of the proposed\nstrategies.",
    "descriptor": "",
    "authors": [
      "Feng Bo",
      "Wu Gang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.02744"
  },
  {
    "id": "arXiv:2212.02745",
    "title": "Sources of Noise in Dialogue and How to Deal with Them",
    "abstract": "Training dialogue systems often entails dealing with noisy training examples\nand unexpected user inputs. Despite their prevalence, there currently lacks an\naccurate survey of dialogue noise, nor is there a clear sense of the impact of\neach noise type on task performance. This paper addresses this gap by first\nconstructing a taxonomy of noise encountered by dialogue systems. In addition,\nwe run a series of experiments to show how different models behave when\nsubjected to varying levels of noise and types of noise. Our results reveal\nthat models are quite robust to label errors commonly tackled by existing\ndenoising algorithms, but that performance suffers from dialogue-specific\nnoise. Driven by these observations, we design a data cleaning algorithm\nspecialized for conversational settings and apply it as a proof-of-concept for\ntargeted dialogue denoising.",
    "descriptor": "\nComments: 23 pages, 6 Figures, 5 tables. Preprint\n",
    "authors": [
      "Derek Chen",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.02745"
  },
  {
    "id": "arXiv:2212.02746",
    "title": "UniGeo: Unifying Geometry Logical Reasoning via Reformulating  Mathematical Expression",
    "abstract": "Geometry problem solving is a well-recognized testbed for evaluating the\nhigh-level multi-modal reasoning capability of deep models. In most existing\nworks, two main geometry problems: calculation and proving, are usually treated\nas two specific tasks, hindering a deep model to unify its reasoning capability\non multiple math tasks. However, in essence, these two tasks have similar\nproblem representations and overlapped math knowledge which can improve the\nunderstanding and reasoning ability of a deep model on both two tasks.\nTherefore, we construct a large-scale Unified Geometry problem benchmark,\nUniGeo, which contains 4,998 calculation problems and 9,543 proving problems.\nEach proving problem is annotated with a multi-step proof with reasons and\nmathematical expressions. The proof can be easily reformulated as a proving\nsequence that shares the same formats with the annotated program sequence for\ncalculation problems. Naturally, we also present a unified multi-task Geometric\nTransformer framework, Geoformer, to tackle calculation and proving problems\nsimultaneously in the form of sequence generation, which finally shows the\nreasoning ability can be improved on both two tasks by unifying formulation.\nFurthermore, we propose a Mathematical Expression Pretraining (MEP) method that\naims to predict the mathematical expressions in the problem solution, thus\nimproving the Geoformer model. Experiments on the UniGeo demonstrate that our\nproposed Geoformer obtains state-of-the-art performance by outperforming\ntask-specific model NGS with over 5.6% and 3.2% accuracies on calculation and\nproving problems, respectively.",
    "descriptor": "",
    "authors": [
      "Jiaqi Chen",
      "Tong Li",
      "Jinghui Qin",
      "Pan Lu",
      "Liang Lin",
      "Chongyu Chen",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02746"
  },
  {
    "id": "arXiv:2212.02747",
    "title": "Semi-Supervised Object Detection with Object-wise Contrastive Learning  and Regression Uncertainty",
    "abstract": "Semi-supervised object detection (SSOD) aims to boost detection performance\nby leveraging extra unlabeled data. The teacher-student framework has been\nshown to be promising for SSOD, in which a teacher network generates\npseudo-labels for unlabeled data to assist the training of a student network.\nSince the pseudo-labels are noisy, filtering the pseudo-labels is crucial to\nexploit the potential of such framework. Unlike existing suboptimal methods, we\npropose a two-step pseudo-label filtering for the classification and regression\nheads in a teacher-student framework. For the classification head, OCL\n(Object-wise Contrastive Learning) regularizes the object representation\nlearning that utilizes unlabeled data to improve pseudo-label filtering by\nenhancing the discriminativeness of the classification score. This is designed\nto pull together objects in the same class and push away objects from different\nclasses. For the regression head, we further propose RUPL\n(Regression-Uncertainty-guided Pseudo-Labeling) to learn the aleatoric\nuncertainty of object localization for label filtering. By jointly filtering\nthe pseudo-labels for the classification and regression heads, the student\nnetwork receives better guidance from the teacher network for object detection\ntask. Experimental results on Pascal VOC and MS-COCO datasets demonstrate the\nsuperiority of our proposed method with competitive performance compared to\nexisting methods.",
    "descriptor": "\nComments: Accepted to BMVC 2022\n",
    "authors": [
      "Honggyu Choi",
      "Zhixiang Chen",
      "Xuepeng Shi",
      "Tae-Kyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02747"
  },
  {
    "id": "arXiv:2212.02749",
    "title": "A Hyperspectral and RGB Dataset for Building Facade Segmentation",
    "abstract": "Hyperspectral Imaging (HSI) provides detailed spectral information and has\nbeen utilised in many real-world applications. This work introduces an HSI\ndataset of building facades in a light industry environment with the aim of\nclassifying different building materials in a scene. The dataset is called the\nLight Industrial Building HSI (LIB-HSI) dataset. This dataset consists of nine\ncategories and 44 classes. In this study, we investigated deep learning based\nsemantic segmentation algorithms on RGB and hyperspectral images to classify\nvarious building materials, such as timber, brick and concrete.",
    "descriptor": "",
    "authors": [
      "Nariman Habili",
      "Ernest Kwan",
      "Weihao Li",
      "Christfried Webers",
      "Jeremy Oorloff",
      "Mohammad Ali Armin",
      "Lars Petersson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02749"
  },
  {
    "id": "arXiv:2212.02750",
    "title": "Improving Molecule Properties Through 2-Stage VAE",
    "abstract": "Variational autoencoder (VAE) is a popular method for drug discovery and\nthere had been a great deal of architectures and pipelines proposed to improve\nits performance. But the VAE model itself suffers from deficiencies such as\npoor manifold recovery when data lie on low-dimensional manifold embedded in\nhigher dimensional ambient space and they manifest themselves in each\napplications differently. The consequences of it in drug discovery is somewhat\nunder-explored. In this paper, we study how to improve the similarity of the\ndata generated via VAE and the training dataset by improving manifold recovery\nvia a 2-stage VAE where the second stage VAE is trained on the latent space of\nthe first one. We experimentally evaluated our approach using the ChEMBL\ndataset as well as a polymer datasets. In both dataset, the 2-stage VAE method\nis able to improve the property statistics significantly from a pre-existing\nmethod.",
    "descriptor": "",
    "authors": [
      "Chenghui Zhou",
      "Barnabas Poczos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2212.02750"
  },
  {
    "id": "arXiv:2212.02751",
    "title": "Daycare Matching in Japan: Transfers and Siblings",
    "abstract": "In this paper, we study a daycare matching problem in Japan and report the\ndesign and implementation of a new centralized algorithm, which is going to be\ndeployed in one municipality in the Tokyo metropolis. There are two features\nthat make this market different from the classical hospital-doctor matching\nproblem: i) some children are initially enrolled and prefer to be transferred\nto other daycare centers; ii) one family may be associated with two or more\nchildren and is allowed to submit preferences over combinations of daycare\ncenters. We revisit some well-studied properties including individual\nrationality, non-wastefulness, as well as stability, and generalize them to\nthis new setting. We design an algorithm based on integer programming (IP) that\ncaptures these properties and conduct experiments on five real-life data sets\nprovided by three municipalities. Experimental results show that i) our\nalgorithm performs at least as well as currently used methods in terms of\nnumbers of matched children and blocking coalition; ii) we can find a stable\noutcome for all instances, although the existence of such an outcome is not\nguaranteed in theory.",
    "descriptor": "",
    "authors": [
      "Zhaohong Sun",
      "Yoshihiro Takenami",
      "Daisuke Moriwaki",
      "Yoji Tomita",
      "Makoto Yokoo"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2212.02751"
  },
  {
    "id": "arXiv:2212.02752",
    "title": "An Index Policy for Minimizing the Uncertainty-of-Information of Markov  Sources",
    "abstract": "This paper focuses on the information freshness of finite-state Markov\nsources, using the uncertainty of information (UoI) as the performance metric.\nMeasured by Shannon's entropy, UoI can capture not only the transition dynamics\nof the Markov source but also the different evolutions of information quality\ncaused by the different values of the last observation. We consider an\ninformation update system with M finite-state Markov sources transmitting\ninformation to a remote monitor via m communication channels. Our goal is to\nexplore the optimal scheduling policy to minimize the sum-UoI of the Markov\nsources. The problem is formulated as a restless multi-armed bandit (RMAB). We\nrelax the RMAB and then decouple the relaxed problem into M single bandit\nproblems. Analyzing the single bandit problem provides useful properties with\nwhich the relaxed problem reduces to maximizing a concave and piecewise linear\nfunction, allowing us to develop a gradient method to solve the relaxed problem\nand obtain its optimal policy. By rounding up the optimal policy for the\nrelaxed problem, we obtain an index policy for the original RMAB problem.\nNotably, the proposed index policy is universal in the sense that it applies to\ngeneral RMABs with bounded cost functions.",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "Gongpu Chen",
      "Soung Chang Liew"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2212.02752"
  },
  {
    "id": "arXiv:2212.02753",
    "title": "Safe Inverse Reinforcement Learning via Control Barrier Function",
    "abstract": "Learning from Demonstration (LfD) is a powerful method for enabling robots to\nperform novel tasks as it is often more tractable for a non-roboticist end-user\nto demonstrate the desired skill and for the robot to efficiently learn from\nthe associated data than for a human to engineer a reward function for the\nrobot to learn the skill via reinforcement learning (RL). Safety issues arise\nin modern LfD techniques, e.g., Inverse Reinforcement Learning (IRL), just as\nthey do for RL; yet, safe learning in LfD has received little attention. In the\ncontext of agile robots, safety is especially vital due to the possibility of\nrobot-environment collision, robot-human collision, and damage to the robot. In\nthis paper, we propose a safe IRL framework, CBFIRL, that leverages the Control\nBarrier Function (CBF) to enhance the safety of the IRL policy. The core idea\nof CBFIRL is to combine a loss function inspired by CBF requirements with the\nobjective in an IRL method, both of which are jointly optimized via gradient\ndescent. In the experiments, we show our framework performs safer compared to\nIRL methods without CBF, that is $\\sim15\\%$ and $\\sim20\\%$ improvement for two\nlevels of difficulty of a 2D racecar domain and $\\sim 50\\%$ improvement for a\n3D drone domain.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Yue Yang",
      "Letian Chen",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02753"
  },
  {
    "id": "arXiv:2212.02754",
    "title": "Automatically Transform Rust Source to Petri Nets for Checking Deadlocks",
    "abstract": "This paper presents a method of automatically converting source codes (Rust\nprograms) into Petri nets, focusing on the detection of deadlocks caused by the\ndouble locks and lock conflicts in the parallel Rust programs. We construct the\ntransformation rules and develop a tool. Our method can omit those Rust codes\nwithout relations to locks when scanning the input codes, and thus tool can\nhandle a large-scale code. We do a number of experiments to show the advantages\nof our method compared with the state-of-the-art ones.",
    "descriptor": "",
    "authors": [
      "Kaiwen Zhang",
      "Guanjun Liua"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.02754"
  },
  {
    "id": "arXiv:2212.02755",
    "title": "Objects as Spatio-Temporal 2.5D points",
    "abstract": "Determining accurate bird's eye view (BEV) positions of objects and tracks in\na scene is vital for various perception tasks including object interactions\nmapping, scenario extraction etc., however, the level of supervision required\nto accomplish that is extremely challenging to procure. We propose a\nlight-weight, weakly supervised method to estimate 3D position of objects by\njointly learning to regress the 2D object detections and scene's depth\nprediction in a single feed-forward pass of a network. Our proposed method\nextends a center-point based single-shot object detector\n\\cite{zhou2019objects}, and introduces a novel object representation where each\nobject is modeled as a BEV point spatio-temporally, without the need of any 3D\nor BEV annotations for training and LiDAR data at query time. The approach\nleverages readily available 2D object supervision along with LiDAR point clouds\n(used only during training) to jointly train a single network, that learns to\npredict 2D object detection alongside the whole scene's depth, to\nspatio-temporally model object tracks as points in BEV. The proposed method is\ncomputationally over $\\sim$10x efficient compared to recent SOTA approaches [1,\n38] while achieving comparable accuracies on KITTI tracking benchmark.",
    "descriptor": "",
    "authors": [
      "Paridhi Singh",
      "Gaurav Singh",
      "Arun Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02755"
  },
  {
    "id": "arXiv:2212.02757",
    "title": "Attention-Enhanced Cross-modal Localization Between 360 Images and Point  Clouds",
    "abstract": "Visual localization plays an important role for intelligent robots and\nautonomous driving, especially when the accuracy of GNSS is unreliable.\nRecently, camera localization in LiDAR maps has attracted more and more\nattention for its low cost and potential robustness to illumination and weather\nchanges. However, the commonly used pinhole camera has a narrow Field-of-View,\nthus leading to limited information compared with the omni-directional LiDAR\ndata. To overcome this limitation, we focus on correlating the information of\n360 equirectangular images to point clouds, proposing an end-to-end learnable\nnetwork to conduct cross-modal visual localization by establishing similarity\nin high-dimensional feature space. Inspired by the attention mechanism, we\noptimize the network to capture the salient feature for comparing images and\npoint clouds. We construct several sequences containing 360 equirectangular\nimages and corresponding point clouds based on the KITTI-360 dataset and\nconduct extensive experiments. The results demonstrate the effectiveness of our\napproach.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Zhipeng Zhao",
      "Huai Yu",
      "Chenwei Lyv",
      "Wen Yang",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.02757"
  },
  {
    "id": "arXiv:2212.02758",
    "title": "Tackling Data Heterogeneity in Federated Learning with Class Prototypes",
    "abstract": "Data heterogeneity across clients in federated learning (FL) settings is a\nwidely acknowledged challenge. In response, personalized federated learning\n(PFL) emerged as a framework to curate local models for clients' tasks. In PFL,\na common strategy is to develop local and global models jointly - the global\nmodel (for generalization) informs the local models, and the local models (for\npersonalization) are aggregated to update the global model. A key observation\nis that if we can improve the generalization ability of local models, then we\ncan improve the generalization of global models, which in turn builds better\npersonalized models. In this work, we consider class imbalance, an overlooked\ntype of data heterogeneity, in the classification setting. We propose FedNH, a\nnovel method that improves the local models' performance for both\npersonalization and generalization by combining the uniformity and semantics of\nclass prototypes. FedNH initially distributes class prototypes uniformly in the\nlatent space and smoothly infuses the class semantics into class prototypes. We\nshow that imposing uniformity helps to combat prototype collapse while infusing\nclass semantics improves local models. Extensive experiments were conducted on\npopular classification datasets under the cross-device setting. Our results\ndemonstrate the effectiveness and stability of our method over recent works.",
    "descriptor": "\nComments: Accepted for presentation at AAAI 2023. This is a technical report version that contains an appendix with additional details about experiments and proofs for technical results\n",
    "authors": [
      "Yutong Dai",
      "Zeyuan Chen",
      "Junnan Li",
      "Shelby Heinecke",
      "Lichao Sun",
      "Ran Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02758"
  },
  {
    "id": "arXiv:2212.02761",
    "title": "Learning Neural Parametric Head Models",
    "abstract": "We propose a novel 3D morphable model for complete human heads based on\nhybrid neural fields. At the core of our model lies a neural parametric\nrepresentation which disentangles identity and expressions in disjoint latent\nspaces. To this end, we capture a person's identity in a canonical space as a\nsigned distance field (SDF), and model facial expressions with a neural\ndeformation field. In addition, our representation achieves high-fidelity local\ndetail by introducing an ensemble of local fields centered around facial anchor\npoints. To facilitate generalization, we train our model on a newly-captured\ndataset of over 2200 head scans from 124 different identities using a custom\nhigh-end 3D scanning setup. Our dataset significantly exceeds comparable\nexisting datasets, both with respect to quality and completeness of geometry,\naveraging around 3.5M mesh faces per scan. Finally, we demonstrate that our\napproach outperforms state-of-the-art methods by a significant margin in terms\nof fitting error and reconstruction quality.",
    "descriptor": "\nComments: Project Page: this https URL ; Project Video: this https URL\n",
    "authors": [
      "Simon Giebenhain",
      "Tobias Kirschstein",
      "Markos Georgopoulos",
      "Martin R\u00fcnz",
      "Lourdes Agapito",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02761"
  },
  {
    "id": "arXiv:2212.02762",
    "title": "Automated Identification of Eviction Status from Electronic Health  Record Notes",
    "abstract": "Objective: Evictions are involved in a cascade of negative events that can\nlead to unemployment, homelessness, long-term poverty, and mental health\nproblems. In this study, we developed a natural language processing system to\nautomatically detect eviction incidences and their attributes from electronic\nhealth record (EHR) notes.\nMaterials and Methods: We annotated eviction status in 5000 EHR notes from\nthe Veterans Health Administration. We developed a novel model, called\nKnowledge Injection based on Ripple Effects of Social and Behavioral\nDeterminants of Health (KIRESH), that has shown to substantially outperform\nother state-of-the-art models such as fine-tuning pre-trained language models\nlike BioBERT and Bio_ClinicalBERT. Moreover, we designed a prompt to further\nimprove the model performance by using the intrinsic connection between the two\nsub-tasks of eviction presence and period prediction. Finally, we used the\nTemperature Scaling-based Calibration on our KIRESH-Prompt method to avoid\nover-confidence issues arising from the imbalance dataset.\nResults: KIRESH-Prompt achieved a Macro-F1 of 0.6273 (presence) and 0.7115\n(period), which was significantly higher than 0.5382 (presence) and 0.67167\n(period) for just fine-tuning Bio_ClinicalBERT model.\nConclusion and Future Work: KIRESH-Prompt has substantially improved eviction\nstatus classification. In future work, we will evaluate the generalizability of\nthe model framework to other applications.",
    "descriptor": "\nComments: submitted to JAMIA Focus Issue: Social Determinants of Health (SDOH) Extraction through Natural Language Processing\n",
    "authors": [
      "Zonghai Yao",
      "Jack Tsai",
      "Weisong Liu",
      "David A. Levy",
      "Emily Druhl",
      "Joel I Reisman",
      "Hong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.02762"
  },
  {
    "id": "arXiv:2212.02763",
    "title": "Semi-supervised Deep Large-baseline Homography Estimation with  Progressive Equivalence Constraint",
    "abstract": "Homography estimation is erroneous in the case of large-baseline due to the\nlow image overlay and limited receptive field. To address it, we propose a\nprogressive estimation strategy by converting large-baseline homography into\nmultiple intermediate ones, cumulatively multiplying these intermediate items\ncan reconstruct the initial homography. Meanwhile, a semi-supervised homography\nidentity loss, which consists of two components: a supervised objective and an\nunsupervised objective, is introduced. The first supervised loss is acting to\noptimize intermediate homographies, while the second unsupervised one helps to\nestimate a large-baseline homography without photometric losses. To validate\nour method, we propose a large-scale dataset that covers regular and\nchallenging scenes. Experiments show that our method achieves state-of-the-art\nperformance in large-baseline scenes while keeping competitive performance in\nsmall-baseline scenes. Code and dataset are available at\nhttps://github.com/megvii-research/LBHomo.",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Hai Jiang",
      "Haipeng Li",
      "Yuhang Lu",
      "Songchen Han",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02763"
  },
  {
    "id": "arXiv:2212.02765",
    "title": "Pixel2ISDF: Implicit Signed Distance Fields based Human Body Model from  Multi-view and Multi-pose Images",
    "abstract": "In this report, we focus on reconstructing clothed humans in the canonical\nspace given multiple views and poses of a human as the input. To achieve this,\nwe utilize the geometric prior of the SMPLX model in the canonical space to\nlearn the implicit representation for geometry reconstruction. Based on the\nobservation that the topology between the posed mesh and the mesh in the\ncanonical space are consistent, we propose to learn latent codes on the posed\nmesh by leveraging multiple input images and then assign the latent codes to\nthe mesh in the canonical space. Specifically, we first leverage normal and\ngeometry networks to extract the feature vector for each vertex on the SMPLX\nmesh. Normal maps are adopted for better generalization to unseen images\ncompared to 2D images. Then, features for each vertex on the posed mesh from\nmultiple images are integrated by MLPs. The integrated features acting as the\nlatent code are anchored to the SMPLX mesh in the canonical space. Finally,\nlatent code for each 3D point is extracted and utilized to calculate the SDF.\nOur work for reconstructing the human shape on canonical pose achieves 3rd\nperformance on WCPA MVP-Human Body Challenge.",
    "descriptor": "\nComments: 8 pages, 3 figures, published to ECCV2022 WCPA Workshop\n",
    "authors": [
      "Jianchuan Chen",
      "Wentao Yi",
      "Tiantian Wang",
      "Xing Li",
      "Liqian Ma",
      "Yangyu Fan",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02765"
  },
  {
    "id": "arXiv:2212.02766",
    "title": "Ref-NPR: Reference-Based Non-Photorealistic Radiance Fields",
    "abstract": "Existing 3D scene stylization methods employ an arbitrary style reference to\ntransfer textures and colors as styles without establishing meaningful semantic\ncorrespondences. We present Reference-Based Non-Photorealistic Radiance Fields,\ni.e., Ref-NPR. It is a controllable scene stylization method utilizing radiance\nfields to stylize a 3D scene, with a single stylized 2D view taken as\nreference. To achieve decent results, we propose a ray registration process\nbased on the stylized reference view to obtain pseudo-ray supervision in novel\nviews, and exploit the semantic correspondence in content images to fill\noccluded regions with perceptually similar styles. Combining these operations,\nRef-NPR generates non-photorealistic and continuous novel view sequences with a\nsingle reference while obtaining reasonable stylization in occluded regions.\nExperiments show that Ref-NPR significantly outperforms other scene and video\nstylization methods in terms of both visual quality and semantic\ncorrespondence. Code and data will be made publicly available.",
    "descriptor": "\nComments: 15 pages, 16 figures, Project page: this https URL\n",
    "authors": [
      "Yuechen Zhang",
      "Zexin He",
      "Jinbo Xing",
      "Xufeng Yao",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02766"
  },
  {
    "id": "arXiv:2212.02770",
    "title": "CSQ: Growing Mixed-Precision Quantization Scheme with Bi-level  Continuous Sparsification",
    "abstract": "Mixed-precision quantization has been widely applied on deep neural networks\n(DNNs) as it leads to significantly better efficiency-accuracy tradeoffs\ncompared to uniform quantization. Meanwhile, determining the exact precision of\neach layer remains challenging. Previous attempts on bit-level regularization\nand pruning-based dynamic precision adjustment during training suffer from\nnoisy gradients and unstable convergence. In this work, we propose Continuous\nSparsification Quantization (CSQ), a bit-level training method to search for\nmixed-precision quantization schemes with improved stability. CSQ stabilizes\nthe bit-level mixed-precision training process with a bi-level gradual\ncontinuous sparsification on both the bit values of the quantized weights and\nthe bit selection in determining the quantization precision of each layer. The\ncontinuous sparsification scheme enables fully-differentiable training without\ngradient approximation while achieving an exact quantized model in the end.A\nbudget-aware regularization of total model size enables the dynamic growth and\npruning of each layer's precision towards a mixed-precision quantization scheme\nof the desired size. Extensive experiments show CSQ achieves better\nefficiency-accuracy tradeoff than previous methods on multiple models and\ndatasets.",
    "descriptor": "",
    "authors": [
      "Lirui Xiao",
      "Huanrui Yang",
      "Zhen Dong",
      "Kurt Keutzer",
      "Li Du",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02770"
  },
  {
    "id": "arXiv:2212.02771",
    "title": "Detection of large exact subgraph isomorphisms with a topology-only  graphlet index built using deterministic walks",
    "abstract": "We introduce the first algorithm to perform topology-only local graph\nmatching (a.k.a. local network alignment or subgraph isomorphism): BLANT, for\nBasic Local Alignment of Network Topology. BLANT first creates a limited,\nhigh-specificity index of a single graph containing connected k-node induced\nsubgraphs called k-graphlets, for k=6-15. The index is constructed in a\ndeterministic way such that, if significant common network topology exists\nbetween two networks, their indexes are likely to overlap. To align two\nnetworks, BLANT queries their respective indexes and creates a pool of aligned\ngraphlet pairs. Then, BLANT merges graphlet pairs together in order to form\nlarge, high quality local alignments. Using BLANT, we discovered perfect\nsubgraph isomorphisms of over 5,000 nodes with more than 95% of the aligned\nnodes being \"functionally\" identical among biological networks, as well as\nalignments of hundreds of nodes of similarly high accuracy on numerous temporal\nsocial networks. These alignments are anywhere from 10x-100x larger than\nalignments built by the state-of-the-art closest competitor.",
    "descriptor": "\nComments: 13 pages, 11 figures, 4 tables\n",
    "authors": [
      "Patrick Wang",
      "Henry Ye",
      "Wayne Hayes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.02771"
  },
  {
    "id": "arXiv:2212.02773",
    "title": "DiffusionInst: Diffusion Model for Instance Segmentation",
    "abstract": "Recently, diffusion frameworks have achieved comparable performance with\nprevious state-of-the-art image generation models. Researchers are curious\nabout its variants in discriminative tasks because of its powerful\nnoise-to-image denoising pipeline. This paper proposes DiffusionInst, a novel\nframework that represents instances as instance-aware filters and formulates\ninstance segmentation as a noise-to-filter denoising process. The model is\ntrained to reverse the noisy groundtruth without any inductive bias from RPN.\nDuring inference, it takes a randomly generated filter as input and outputs\nmask in one-step or multi-step denoising. Extensive experimental results on\nCOCO and LVIS show that DiffusionInst achieves competitive performance compared\nto existing instance segmentation models. We hope our work could serve as a\nsimple yet effective baseline, which could inspire designing more efficient\ndiffusion frameworks for challenging discriminative tasks. Our code is\navailable in https://github.com/chenhaoxing/DiffusionInst.",
    "descriptor": "",
    "authors": [
      "Zhangxuan Gu",
      "Haoxing Chen",
      "Zhuoer Xu",
      "Jun Lan",
      "Changhua Meng",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02773"
  },
  {
    "id": "arXiv:2212.02774",
    "title": "Adaptive Testing of Computer Vision Models",
    "abstract": "Vision models often fail systematically on groups of data that share common\nsemantic characteristics (e.g., rare objects or unusual scenes), but\nidentifying these failure modes is a challenge. We introduce AdaVision, an\ninteractive process for testing vision models which helps users identify and\nfix coherent failure modes. Given a natural language description of a coherent\ngroup, AdaVision retrieves relevant images from LAION-5B with CLIP. The user\nthen labels a small amount of data for model correctness, which is used in\nsuccessive retrieval rounds to hill-climb towards high-error regions, refining\nthe group definition. Once a group is saturated, AdaVision uses GPT-3 to\nsuggest new group descriptions for the user to explore. We demonstrate the\nusefulness and generality of AdaVision in user studies, where users find major\nbugs in state-of-the-art classification, object detection, and image captioning\nmodels. These user-discovered groups have failure rates 2-3x higher than those\nsurfaced by automatic error clustering methods. Finally, finetuning on examples\nfound with AdaVision fixes the discovered bugs when evaluated on unseen\nexamples, without degrading in-distribution accuracy, and while also improving\nperformance on out-of-distribution datasets.",
    "descriptor": "",
    "authors": [
      "Irena Gao",
      "Gabriel Ilharco",
      "Scott Lundberg",
      "Marco Tulio Ribeiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02774"
  },
  {
    "id": "arXiv:2212.02779",
    "title": "PrefRec: Preference-based Recommender Systems for Reinforcing Long-term  User Engagement",
    "abstract": "Current advances in recommender systems have been remarkably successful in\noptimizing immediate engagement. However, long-term user engagement, a more\ndesirable performance metric, remains difficult to improve. Meanwhile, recent\nreinforcement learning (RL) algorithms have shown their effectiveness in a\nvariety of long-term goal optimization tasks. For this reason, RL is widely\nconsidered as a promising framework for optimizing long-term user engagement in\nrecommendation. Despite being a promising approach, the application of RL\nheavily relies on well-designed rewards, but designing rewards related to\nlong-term user engagement is quite difficult. To mitigate the problem, we\npropose a novel paradigm, Preference-based Recommender systems (PrefRec), which\nallows RL recommender systems to learn from preferences about users' historical\nbehaviors rather than explicitly defined rewards. Such preferences are easily\naccessible through techniques such as crowdsourcing, as they do not require any\nexpert knowledge. With PrefRec, we can fully exploit the advantages of RL in\noptimizing long-term goals, while avoiding complex reward engineering. PrefRec\nuses the preferences to automatically train a reward function in an end-to-end\nmanner. The reward function is then used to generate learning signals to train\nthe recommendation policy. Furthermore, we design an effective optimization\nmethod for PrefRec, which uses an additional value function, expectile\nregression and reward model pre-training to improve the performance. Extensive\nexperiments are conducted on a variety of long-term user engagement\noptimization tasks. The results show that PrefRec significantly outperforms\nprevious state-of-the-art methods in all the tasks.",
    "descriptor": "",
    "authors": [
      "Wanqi Xue",
      "Qingpeng Cai",
      "Zhenghai Xue",
      "Shuo Sun",
      "Shuchang Liu",
      "Dong Zheng",
      "Peng Jiang",
      "Bo An"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02779"
  },
  {
    "id": "arXiv:2212.02780",
    "title": "Parameter Efficient Transfer Learning for Various Speech Processing  Tasks",
    "abstract": "Fine-tuning of self-supervised models is a powerful transfer learning method\nin a variety of fields, including speech processing, since it can utilize\ngeneric feature representations obtained from large amounts of unlabeled data.\nFine-tuning, however, requires a new parameter set for each downstream task,\nwhich is parameter inefficient. Adapter architecture is proposed to partially\nsolve this issue by inserting lightweight learnable modules into a frozen\npre-trained model. However, existing adapter architectures fail to adaptively\nleverage low- to high-level features stored in different layers, which is\nnecessary for solving various kinds of speech processing tasks. Thus, we\npropose a new adapter architecture to acquire feature representations more\nflexibly for various speech tasks. In experiments, we applied this adapter to\nWavLM on four speech tasks. It performed on par or better than naive\nfine-tuning, with only 11% of learnable parameters. It also outperformed an\nexisting adapter architecture.",
    "descriptor": "",
    "authors": [
      "Shinta Otake",
      "Rei Kawakami",
      "Nakamasa Inoue"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.02780"
  },
  {
    "id": "arXiv:2212.02781",
    "title": "QEBVerif: Quantization Error Bound Verification of Neural Networks",
    "abstract": "While deep neural networks (DNNs) have demonstrated impressive performance in\nsolving many challenging tasks, they are limited to resource-constrained\ndevices owing to their demand for computation power and storage space.\nQuantization is one of the most promising techniques to address this issue by\nquantizing the weights and/or activation tensors of a DNN into lower bit-width\nfixed-point numbers. While quantization has been empirically shown to introduce\nminor accuracy loss, it lacks formal guarantees on that, especially when the\nresulting quantized neural networks (QNNs) are deployed in safety-critical\napplications. A majority of existing verification methods focus exclusively on\nindividual neural networks, either DNNs or QNNs. While promising attempts have\nbeen made to verify the quantization error bound between DNNs and their\nquantized counterparts, they are not complete and more importantly do not\nsupport fully quantified neural networks, namely, only weights are quantized.\nTo fill this gap, in this work, we propose a quantization error bound\nverification method (QEBVerif), where both weights and activation tensors are\nquantized. QEBVerif consists of two analyses: a differential reachability\nanalysis (DRA) and a mixed-integer linear programming (MILP) based verification\nmethod. DRA performs difference analysis between the DNN and its quantized\ncounterpart layer-by-layer to efficiently compute a tight quantization error\ninterval. If it fails to prove the error bound, then we encode the verification\nproblem into an equivalent MILP problem which can be solved by off-the-shelf\nsolvers. Thus, QEBVerif is sound, complete, and arguably efficient. We\nimplement QEBVerif in a tool and conduct extensive experiments, showing its\neffectiveness and efficiency.",
    "descriptor": "",
    "authors": [
      "Yedi Zhang",
      "Fu Song",
      "Jun Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02781"
  },
  {
    "id": "arXiv:2212.02785",
    "title": "Union-set Multi-source Model Adaptation for Semantic Segmentation",
    "abstract": "This paper solves a generalized version of the problem of multi-source model\nadaptation for semantic segmentation. Model adaptation is proposed as a new\ndomain adaptation problem which requires access to a pre-trained model instead\nof data for the source domain. A general multi-source setting of model\nadaptation assumes strictly that each source domain shares a common label space\nwith the target domain. As a relaxation, we allow the label space of each\nsource domain to be a subset of that of the target domain and require the union\nof the source-domain label spaces to be equal to the target-domain label space.\nFor the new setting named union-set multi-source model adaptation, we propose a\nmethod with a novel learning strategy named model-invariant feature learning,\nwhich takes full advantage of the diverse characteristics of the source-domain\nmodels, thereby improving the generalization in the target domain. We conduct\nextensive experiments in various adaptation settings to show the superiority of\nour method. The code is available at\nhttps://github.com/lzy7976/union-set-model-adaptation.",
    "descriptor": "\nComments: Accepted by ECCV2022\n",
    "authors": [
      "Zongyao Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki haseyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02785"
  },
  {
    "id": "arXiv:2212.02789",
    "title": "A K-variate Time Series Is Worth K Words: Evolution of the Vanilla  Transformer Architecture for Long-term Multivariate Time Series Forecasting",
    "abstract": "Multivariate time series forecasting (MTSF) is a fundamental problem in\nnumerous real-world applications. Recently, Transformer has become the de facto\nsolution for MTSF, especially for the long-term cases. However, except for the\none forward operation, the basic configurations in existing MTSF Transformer\narchitectures were barely carefully verified. In this study, we point out that\nthe current tokenization strategy in MTSF Transformer architectures ignores the\ntoken uniformity inductive bias of Transformers. Therefore, the vanilla MTSF\ntransformer struggles to capture details in time series and presents inferior\nperformance. Based on this observation, we make a series of evolution on the\nbasic architecture of the vanilla MTSF transformer. We vary the flawed\ntokenization strategy, along with the decoder structure and embeddings.\nSurprisingly, the evolved simple transformer architecture is highly effective,\nwhich successfully avoids the over-smoothing phenomena in the vanilla MTSF\ntransformer, achieves a more detailed and accurate prediction, and even\nsubstantially outperforms the state-of-the-art Transformers that are\nwell-designed for MTSF.",
    "descriptor": "",
    "authors": [
      "Zanwei Zhou",
      "Ruizhe Zhong",
      "Chen Yang",
      "Yan Wang",
      "Xiaokang Yang",
      "Wei Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02789"
  },
  {
    "id": "arXiv:2212.02791",
    "title": "Event-based Monocular Dense Depth Estimation with Recurrent Transformers",
    "abstract": "Event cameras, offering high temporal resolutions and high dynamic ranges,\nhave brought a new perspective to address common challenges (e.g., motion blur\nand low light) in monocular depth estimation. However, how to effectively\nexploit the sparse spatial information and rich temporal cues from asynchronous\nevents remains a challenging endeavor. To this end, we propose a novel\nevent-based monocular depth estimator with recurrent transformers, namely\nEReFormer, which is the first pure transformer with a recursive mechanism to\nprocess continuous event streams. Technically, for spatial modeling, a novel\ntransformer-based encoder-decoder with a spatial transformer fusion module is\npresented, having better global context information modeling capabilities than\nCNN-based methods. For temporal modeling, we design a gate recurrent vision\ntransformer unit that introduces a recursive mechanism into transformers,\nimproving temporal modeling capabilities while alleviating the expensive GPU\nmemory cost. The experimental results show that our EReFormer outperforms\nstate-of-the-art methods by a margin on both synthetic and real-world datasets.\nWe hope that our work will attract further research to develop stunning\ntransformers in the event-based vision community. Our open-source code can be\nfound in the supplemental material.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Xu Liu",
      "Jianing Li",
      "Xiaopeng Fan",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02791"
  },
  {
    "id": "arXiv:2212.02794",
    "title": "Hybrid Model using Feature Extraction and Non-linear SVM for Brain Tumor  Classification",
    "abstract": "It is essential to classify brain tumors from magnetic resonance imaging\n(MRI) accurately for better and timely treatment of the patients. In this\npaper, we propose a hybrid model, using VGG along with Nonlinear-SVM (Soft and\nHard) to classify the brain tumors: glioma and pituitary and tumorous and\nnon-tumorous. The VGG-SVM model is trained for two different datasets of two\nclasses; thus, we perform binary classification. The VGG models are trained via\nthe PyTorch python library to obtain the highest testing accuracy of tumor\nclassification. The method is threefold, in the first step, we normalize and\nresize the images, and the second step consists of feature extraction through\nvariants of the VGG model. The third step classified brain tumors using\nnon-linear SVM (soft and hard). We have obtained 98.18% accuracy for the first\ndataset and 99.78% for the second dataset using VGG19. The classification\naccuracies for non-linear SVM are 95.50% and 97.98% with linear and rbf kernel\nand 97.95% for soft SVM with RBF kernel with D1, and 96.75% and 98.60% with\nlinear and RBF kernel and 98.38% for soft SVM with RBF kernel with D2. Results\nindicate that the hybrid VGG-SVM model, especially VGG 19 with SVM, is able to\noutperform existing techniques and achieve high accuracy.",
    "descriptor": "",
    "authors": [
      "Lalita Mishra",
      "Shekhar Verma",
      "Shirshu Varma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02794"
  },
  {
    "id": "arXiv:2212.02795",
    "title": "Emerging Technology and Policy Co-Design Considerations for the Safe and  Transparent Use of Small Unmanned Aerial Systems",
    "abstract": "The rapid technological growth observed in the sUAS sector over the past\ndecade has been unprecedented and has left gaps in policies and regulations to\nadequately provide for a safe and trusted environment in which to operate these\ndevices. The Center for Security in Politics at UC Berkeley, via a two-day\nworkshop, analyzed these gaps by addressing the entire sUAS vertical. From\nhuman factors to autonomy, we recommend a series of steps that can be taken by\npartners in the academic, commercial, and government sectors to reduce policy\ngaps introduced in the wake of the growth of the sUAS industry.",
    "descriptor": "",
    "authors": [
      "Ritwik Gupta",
      "Alexander Bayen",
      "Sarah Rohrschneider",
      "Adrienne Fulk",
      "Andrew Reddie",
      "Sanjit A. Seshia",
      "Shankar Sastry",
      "Janet Napolitano"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.02795"
  },
  {
    "id": "arXiv:2212.02796",
    "title": "DiffuPose: Monocular 3D Human Pose Estimation via Denoising Diffusion  Probabilistic Model",
    "abstract": "Thanks to the development of 2D keypoint detectors, monocular 3D human pose\nestimation (HPE) via 2D-to-3D uplifting approaches have achieved remarkable\nimprovements. Still, monocular 3D HPE is a challenging problem due to the\ninherent depth ambiguities and occlusions. To handle this problem, many\nprevious works exploit temporal information to mitigate such difficulties.\nHowever, there are many real-world applications where frame sequences are not\naccessible. This paper focuses on reconstructing a 3D pose from a single 2D\nkeypoint detection. Rather than exploiting temporal information, we alleviate\nthe depth ambiguity by generating multiple 3D pose candidates which can be\nmapped to an identical 2D keypoint. We build a novel diffusion-based framework\nto effectively sample diverse 3D poses from an off-the-shelf 2D detector. By\nconsidering the correlation between human joints by replacing the conventional\ndenoising U-Net with graph convolutional network, our approach accomplishes\nfurther performance improvements. We evaluate our method on the widely adopted\nHuman3.6M and HumanEva-I datasets. Comprehensive experiments are conducted to\nprove the efficacy of the proposed method, and they confirm that our model\noutperforms state-of-the-art multi-hypothesis 3D HPE methods.",
    "descriptor": "",
    "authors": [
      "Jeongjun Choi",
      "Dongseok Shim",
      "H. Jin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02796"
  },
  {
    "id": "arXiv:2212.02797",
    "title": "FlowFace: Semantic Flow-guided Shape-aware Face Swapping",
    "abstract": "In this work, we propose a semantic flow-guided two-stage framework for\nshape-aware face swapping, namely FlowFace. Unlike most previous methods that\nfocus on transferring the source inner facial features but neglect facial\ncontours, our FlowFace can transfer both of them to a target face, thus leading\nto more realistic face swapping. Concretely, our FlowFace consists of a face\nreshaping network and a face swapping network. The face reshaping network\naddresses the shape outline differences between the source and target faces. It\nfirst estimates a semantic flow (i.e., face shape differences) between the\nsource and the target face, and then explicitly warps the target face shape\nwith the estimated semantic flow. After reshaping, the face swapping network\ngenerates inner facial features that exhibit the identity of the source face.\nWe employ a pre-trained face masked autoencoder (MAE) to extract facial\nfeatures from both the source face and the target face. In contrast to previous\nmethods that use identity embedding to preserve identity information, the\nfeatures extracted by our encoder can better capture facial appearances and\nidentity information. Then, we develop a cross-attention fusion module to\nadaptively fuse inner facial features from the source face with the target\nfacial attributes, thus leading to better identity preservation. Extensive\nquantitative and qualitative experiments on in-the-wild faces demonstrate that\nour FlowFace outperforms the state-of-the-art significantly.",
    "descriptor": "",
    "authors": [
      "Hao Zeng",
      "Wei Zhang",
      "Changjie Fan",
      "Tangjie Lv",
      "Suzhen Wang",
      "Zhimeng Zhang",
      "Bowen Ma",
      "Lincheng Li",
      "Yu Ding",
      "Xin Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02797"
  },
  {
    "id": "arXiv:2212.02800",
    "title": "Life-long Learning for Multilingual Neural Machine Translation with  Knowledge Distillation",
    "abstract": "A common scenario of Multilingual Neural Machine Translation (MNMT) is that\neach translation task arrives in a sequential manner, and the training data of\nprevious tasks is unavailable. In this scenario, the current methods suffer\nheavily from catastrophic forgetting (CF). To alleviate the CF, we investigate\nknowledge distillation based life-long learning methods. Specifically, in\none-tomany scenario, we propose a multilingual distillation method to make the\nnew model (student) jointly learn multilingual output from old model (teacher)\nand new task. In many-to one scenario, we find that direct distillation faces\nthe extreme partial distillation problem, and we propose two different methods\nto address it: pseudo input distillation and reverse teacher distillation. The\nexperimental results on twelve translation tasks show that the proposed methods\ncan better consolidate the previous knowledge and sharply alleviate the CF.",
    "descriptor": "",
    "authors": [
      "Yang Zhao",
      "Junnan Zhu",
      "Lu Xiang",
      "Jiajun Zhang",
      "Yu Zhou",
      "Feifei Zhai",
      "Chengqing Zong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.02800"
  },
  {
    "id": "arXiv:2212.02801",
    "title": "Dist-PU: Positive-Unlabeled Learning from a Label Distribution  Perspective",
    "abstract": "Positive-Unlabeled (PU) learning tries to learn binary classifiers from a few\nlabeled positive examples with many unlabeled ones. Compared with ordinary\nsemi-supervised learning, this task is much more challenging due to the absence\nof any known negative labels. While existing cost-sensitive-based methods have\nachieved state-of-the-art performances, they explicitly minimize the risk of\nclassifying unlabeled data as negative samples, which might result in a\nnegative-prediction preference of the classifier. To alleviate this issue, we\nresort to a label distribution perspective for PU learning in this paper.\nNoticing that the label distribution of unlabeled data is fixed when the class\nprior is known, it can be naturally used as learning supervision for the model.\nMotivated by this, we propose to pursue the label distribution consistency\nbetween predicted and ground-truth label distributions, which is formulated by\naligning their expectations. Moreover, we further adopt the entropy\nminimization and Mixup regularization to avoid the trivial solution of the\nlabel distribution consistency on unlabeled data and mitigate the consequent\nconfirmation bias. Experiments on three benchmark datasets validate the\neffectiveness of the proposed method.Code available at:\nhttps://github.com/Ray-rui/Dist-PU-Positive-Unlabeled-Learning-from-a-Label-Distribution-Perspective.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Yunrui Zhao",
      "Qianqian Xu",
      "Yangbangyan Jiang",
      "Peisong Wen",
      "Qingming Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02801"
  },
  {
    "id": "arXiv:2212.02802",
    "title": "Diffusion Video Autoencoders: Toward Temporally Consistent Face Video  Editing via Disentangled Video Encoding",
    "abstract": "Inspired by the impressive performance of recent face image editing methods,\nseveral studies have been naturally proposed to extend these methods to the\nface video editing task. One of the main challenges here is temporal\nconsistency among edited frames, which is still unresolved. To this end, we\npropose a novel face video editing framework based on diffusion autoencoders\nthat can successfully extract the decomposed features - for the first time as a\nface video editing model - of identity and motion from a given video. This\nmodeling allows us to edit the video by simply manipulating the temporally\ninvariant feature to the desired direction for the consistency. Another unique\nstrength of our model is that, since our model is based on diffusion models, it\ncan satisfy both reconstruction and edit capabilities at the same time, and is\nrobust to corner cases in wild face videos (e.g. occluded faces) unlike the\nexisting GAN-based methods.",
    "descriptor": "\nComments: The code will be available soon\n",
    "authors": [
      "Gyeongman Kim",
      "Hajin Shim",
      "Hyunsu Kim",
      "Yunjey Choi",
      "Junho Kim",
      "Eunho Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02802"
  },
  {
    "id": "arXiv:2212.02804",
    "title": "MUS-CDB: Mixed Uncertainty Sampling with Class Distribution Balancing  for Active Annotation in Aerial Object Detection",
    "abstract": "Recent aerial object detection models rely on a large amount of labeled\ntraining data, which requires unaffordable manual labeling costs in large\naerial scenes with dense objects. Active learning is effective in reducing the\ndata labeling cost by selectively querying the informative and representative\nunlabelled samples. However, existing active learning methods are mainly with\nclass-balanced setting and image-based querying for generic object detection\ntasks, which are less applicable to aerial object detection scenario due to the\nlong-tailed class distribution and dense small objects in aerial scenes. In\nthis paper, we propose a novel active learning method for cost-effective aerial\nobject detection. Specifically, both object-level and image-level\ninformativeness are considered in the object selection to refrain from\nredundant and myopic querying. Besides, an easy-to-use class-balancing\ncriterion is incorporated to favor the minority objects to alleviate the\nlong-tailed class distribution problem in model training. To fully utilize the\nqueried information, we further devise a training loss to mine the latent\nknowledge in the undiscovered image regions. Extensive experiments are\nconducted on the DOTA-v1.0 and DOTA-v2.0 benchmarks to validate the\neffectiveness of the proposed method. The results show that it can save more\nthan 75% of the labeling cost to reach the same performance compared to the\nbaselines and state-of-the-art active object detection methods. Code is\navailable at https://github.com/ZJW700/MUS-CDB",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Dong Liang",
      "Jing-Wei Zhang",
      "Ying-Peng Tang",
      "Sheng-Jun Hang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02804"
  },
  {
    "id": "arXiv:2212.02809",
    "title": "An advanced YOLOv3 method for small object detection",
    "abstract": "In recent years, object detection has achieved a very large performance\nimprovement, but the detection result of small objects is still not very\nsatisfactory. This work proposes a strategy based on feature fusion and dilated\nconvolution that employs dilated convolution to broaden the receptive field of\nfeature maps at various scales in order to address this issue. On the one hand,\nit can improve the detection accuracy of larger objects. On the other hand, it\nprovides more contextual information for small objects, which is beneficial to\nimproving the detection accuracy of small objects. The shallow semantic\ninformation of small objects is obtained by filtering out the noise in the\nfeature map, and the feature information of more small objects is preserved by\nusing multi-scale fusion feature module and attention mechanism. The fusion of\nthese shallow feature information and deep semantic information can generate\nricher feature maps for small object detection. Experiments show that this\nmethod can have higher accuracy than the traditional YOLOv3 network in the\ndetection of small objects and occluded objects. In addition, we achieve 32.8\\%\nMean Average Precision on the detection of small objects on MS COCO2017 test\nset. For 640*640 input, this method has 88.76\\% mAP on the PASCAL VOC2012\ndataset.",
    "descriptor": "",
    "authors": [
      "Baokai Liu",
      "Fengjie He",
      "Shiqiang Du",
      "Jiacheng Li",
      "Wenjie Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02809"
  },
  {
    "id": "arXiv:2212.02810",
    "title": "Data Imputation with Iterative Graph Reconstruction",
    "abstract": "Effective data imputation demands rich latent ``structure\" discovery\ncapabilities from ``plain\" tabular data. Recent advances in graph neural\nnetworks-based data imputation solutions show their strong structure learning\npotential by directly translating tabular data as bipartite graphs. However,\ndue to a lack of relations between samples, those solutions treat all samples\nequally which is against one important observation: ``similar sample should\ngive more information about missing values.\" This paper presents a novel\nIterative graph Generation and Reconstruction framework for Missing data\nimputation(IGRM). Instead of treating all samples equally, we introduce the\nconcept: ``friend networks\" to represent different relations among samples. To\ngenerate an accurate friend network with missing data, an end-to-end friend\nnetwork reconstruction solution is designed to allow for continuous friend\nnetwork optimization during imputation learning. The representation of the\noptimized friend network, in turn, is used to further optimize the data\nimputation process with differentiated message passing. Experiment results on\neight benchmark datasets show that IGRM yields 39.13% lower mean absolute error\ncompared with nine baselines and 9.04% lower than the second-best.",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Jiajun Zhong",
      "Weiwei Ye",
      "Ning Gui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02810"
  },
  {
    "id": "arXiv:2212.02811",
    "title": "Asynchronous Cell-Free Massive MIMO With Rate-Splitting",
    "abstract": "In practical cell-free (CF) massive multiple-input multiple-output (MIMO)\nnetworks with distributed and low-cost access points, the asynchronous arrival\nof signals at the user equipments increases multi-user interference that\ndegrades the system performance. Meanwhile, rate-splitting (RS), exploiting the\ntransmission of both common and private messages, has demonstrated to offer\nconsiderable spectral efficiency (SE) improvements and its robustness against\nchannel state information (CSI) imperfection. The signal performance of a CF\nmassive MIMO system is first analyzed for asynchronous reception capturing the\njoint effects of propagation delays and oscillator phases of transceivers.\nTaking into account the imperfect CSI caused by asynchronous phases and pilot\ncontamination, we derive novel and closed-form downlink SE expressions for\ncharacterizing the performance of both the RS-assisted and conventional\nnon-RS-based systems adopting coherent and non-coherent data transmission\nschemes, respectively. Moreover, we formulate the design of robust precoding\nfor the common messages as an optimization problem that maximizes the minimum\nindividual SE of the common message. To address the non-convexity of the design\nproblem, a bisection method is proposed to solve the problem optimally.\nSimulation results show that asynchronous reception indeed destroys both the\northogonality of the pilots and the coherent data transmission resulting in\npoor system performance. Besides, thanks to the uniform coverage properties of\nCF massive MIMO systems, RS with a simple low-complexity precoding for the\ncommon message obtained by the equal ratio sum of the private precoding is able\nto achieve substantial downlink sum SE gains, while the application of robust\nprecoding to the common message is shown to be useful in some extreme cases,\ne.g., serious oscillator mismatch and unknown delay phase.",
    "descriptor": "\nComments: 34 pages, 11 figures, Accepted in IEEE Journal on Selected Areas in Communications\n",
    "authors": [
      "Jiakang Zheng",
      "Jiayi Zhang",
      "Julian Cheng",
      "Victor C. M. Leung",
      "Derrick Wing Kwan Ng",
      "Bo Ai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.02811"
  },
  {
    "id": "arXiv:2212.02814",
    "title": "Mixer: DNN Watermarking using Image Mixup",
    "abstract": "It is crucial to protect the intellectual property rights of DNN models prior\nto their deployment. The DNN should perform two main tasks: its primary task\nand watermarking task. This paper proposes a lightweight, reliable, and secure\nDNN watermarking that attempts to establish strong ties between these two\ntasks. The samples triggering the watermarking task are generated using image\nMixup either from training or testing samples. This means that there is an\ninfinity of triggers not limited to the samples used to embed the watermark in\nthe model at training. The extensive experiments on image classification models\nfor different datasets as well as exposing them to a variety of attacks, show\nthat the proposed watermarking provides protection with an adequate level of\nsecurity and robustness.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2206.11024. text overlap with arXiv:2206.11024\n",
    "authors": [
      "Kassem Kallas",
      "Teddy Furon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2212.02814"
  },
  {
    "id": "arXiv:2212.02821",
    "title": "New Quantum codes from constacyclic codes over a general non-chain ring",
    "abstract": "Let $q$ be a prime power and let $\\mathcal{R}=\\mathbb{F}_{q}[u_1,u_2, \\cdots,\nu_k]/\\langle f_i(u_i),u_iu_j-u_ju_i\\rangle$ be a finite non-chain ring, where\n$f_i(u_i), 1\\leq i \\leq k$ are polynomials, not all linear, which split into\ndistinct linear factors over $\\mathbb{F}_{q}$. We characterize constacyclic\ncodes over the ring $\\mathcal{R}$ and study quantum codes from these. As an\napplication, some new and better quantum codes, as compared to the best known\ncodes, are obtained. We also prove that the choice of the polynomials\n$f_i(u_i),$ $1 \\leq i \\leq k$ is irrelevant while constructing quantum codes\nfrom constacyclic codes over $\\mathcal{R}$, it depends only on their degrees.\nIt is shown that there always exists Quantum MDS code $[[n,n-2,2]]_q$ for any\n$n$ with $\\gcd (n,q)\\neq 1.$",
    "descriptor": "",
    "authors": [
      "Swati Bhardwaj",
      "Mokshi Goyal",
      "Madhu Raka"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.02821"
  },
  {
    "id": "arXiv:2212.02822",
    "title": "A Robust Image Steganographic Scheme against General Scaling Attacks",
    "abstract": "Conventional covert image communication is assumed to transmit the message,\nin the securest way possible for a given payload, over lossless channels, and\nthe associated steganographic schemes are generally vulnerable to active\nattacks, e.g., JPEG re-compression, scaling, as seen on social networks.\nAlthough considerable progress has been made on robust steganography against\nJPEG re-compression, there exist few steganographic schemes capable of\nresisting to scaling attacks due to the tricky inverse interpolations involved\nin algorithm design. To tackle this issue, a framework for robust image\nsteganography resisting to scaling with general interpolations either in\nstandard form with fixed interpolation block, or pre-filtering based\nanti-aliasing implementation with variable block, is proposed in this paper.\nAnd the task of robust steganography can be formulated as one of constrained\ninteger programming aiming at perfectly recover the secret message from stego\nimage while minimizing the difference between cover and stego images. By\nintroducing a metric - the degree of pixel involvement (dPI) to identify the\nmodifiable pixels in cover image, the optimization problem above could be\neffectively solved using branch and bound algorithm (B\\&B). In addition, a\ncustomized distortion function for scaled stego images is adopted to further\nboost the security performance. Extensive experiments are carried out which\ndemonstrate that the proposed scheme could not only outperform the prior art in\nterms of security by a clear margin, but also be applicable to resisting the\nscaling attacks with various interpolation techniques at arbitrary scaling\nfactors (SFs).",
    "descriptor": "",
    "authors": [
      "Qingliang Liu",
      "Jiangqun Ni",
      "Weizhe Zhang",
      "Xiangyang Luo",
      "Jiwu Huang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2212.02822"
  },
  {
    "id": "arXiv:2212.02823",
    "title": "Hierarchical Termination Analysis for Generalized Planning",
    "abstract": "This paper presents a new approach for analyzing and identifying potentially\nuseful generalized plans. It presents a new conceptual framework along with an\nalgorithmic process for assessing termination and reachability related\nproperties of generalized plans. The presented framework builds upon classic\nresults on the analysis of graphs to decompose generalized plans into smaller\ncomponents in a novel algorithm for conducting a hierarchical analysis for\ntermination of arbitrary generalized plans. Theoretical analysis of the new\nframework establishes soundness of the presented algorithms and shows how it\ngoes beyond existing approaches; empirical analysis illustrates the scope of\nthis approach. Our analysis shows that this new approach can effectively\nidentify termination for a significantly larger class of generalized plans than\nwas possible using existing methods.",
    "descriptor": "",
    "authors": [
      "Siddharth Srivastava"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02823"
  },
  {
    "id": "arXiv:2212.02827",
    "title": "Political Honeymoon Effect on Social Media: Characterizing Social Media  Reaction to the Changes of Prime Minister in Japan",
    "abstract": "New leaders in democratic countries typically enjoy high approval ratings\nimmediately after taking office. This phenomenon is called the honeymoon effect\nand is regarded as a significant political phenomenon; however, its mechanism\nremains underexplored. Therefore, this study examines how social media users\nrespond to changes in political leadership in order to better understand the\nhoneymoon effect in politics. In particular, we constructed a 15-year Twitter\ndataset on eight change timings of Japanese prime ministers consisting of 6.6M\ntweets and analyzed them in terms of sentiments, topics, and users. We found\nthat, while not always, social media tend to show a honeymoon effect at the\nchange timings of prime minister. The study also revealed that sentiment about\nprime ministers differed by topic, indicating that public expectations vary\nfrom one prime minister to another. Furthermore, the user base was largely\nreplaced before and after the change in the prime minister, and their sentiment\nwas also significantly different. The implications of this study would be\nbeneficial for administrative management.",
    "descriptor": "\nComments: 11 pages, 5 figures. Under review\n",
    "authors": [
      "Kunihiro Miyazaki",
      "Taichi Murayama",
      "Akira Matsui",
      "Masaru Nishikawa",
      "Takayuki Uchiba",
      "Haewoon Kwak",
      "Jisun An"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.02827"
  },
  {
    "id": "arXiv:2212.02837",
    "title": "Pretrained Diffusion Models for Unified Human Motion Synthesis",
    "abstract": "Generative modeling of human motion has broad applications in computer\nanimation, virtual reality, and robotics. Conventional approaches develop\nseparate models for different motion synthesis tasks, and typically use a model\nof a small size to avoid overfitting the scarce data available in each setting.\nIt remains an open question whether developing a single unified model is\nfeasible, which may 1) benefit the acquirement of novel skills by combining\nskills learned from multiple tasks, and 2) help in increasing the model\ncapacity without overfitting by combining multiple data sources. Unification is\nchallenging because 1) it involves diverse control signals as well as targets\nof varying granularity, and 2) motion datasets may use different skeletons and\ndefault poses. In this paper, we present MoFusion, a framework for unified\nmotion synthesis. MoFusion employs a Transformer backbone to ease the inclusion\nof diverse control signals via cross attention, and pretrains the backbone as a\ndiffusion model to support multi-granularity synthesis ranging from motion\ncompletion of a body part to whole-body motion generation. It uses a learnable\nadapter to accommodate the differences between the default skeletons used by\nthe pretraining and the fine-tuning data. Empirical results show that\npretraining is vital for scaling the model size without overfitting, and\ndemonstrate MoFusion's potential in various tasks, e.g., text-to-motion, motion\ncompletion, and zero-shot mixing of multiple control signals. Project page:\n\\url{https://ofa-sys.github.io/MoFusion/}.",
    "descriptor": "",
    "authors": [
      "Jianxin Ma",
      "Shuai Bai",
      "Chang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.02837"
  },
  {
    "id": "arXiv:2212.02842",
    "title": "VISEM-Tracking: Human Spermatozoa Tracking Dataset",
    "abstract": "Manually analyzing spermatozoa is a tremendous task for biologists due to the\nmany fast-moving spermatozoa, causing inconsistencies in the quality of the\nassessments. Therefore, computer-assisted sperm analysis (CASA) has become a\npopular solution. Despite this, more data is needed to train supervised machine\nlearning approaches in order to improve accuracy and reliability. In this\nregard, we provide a dataset called VISEM-Tracking with 20 video recordings of\n30s of spermatozoa with manually annotated bounding-box coordinates and a set\nof sperm characteristics analyzed by experts in the domain. VISEM-Tracking is\nan extension of the previously published VISEM dataset. In addition to the\nannotated data, we provide unlabeled video clips for easy-to-use access and\nanalysis of the data. As part of this paper, we present baseline sperm\ndetection performances using the YOLOv5 deep learning model trained on the\nVISEM-Tracking dataset. As a result, the dataset can be used to train complex\ndeep-learning models to analyze spermatozoa. The dataset is publicly available\nat https://zenodo.org/record/7293726.",
    "descriptor": "",
    "authors": [
      "Vajira Thambawita",
      "Steven A. Hicks",
      "Andrea M. Stor\u00e5s",
      "Thu Nguyen",
      "Jorunn M. Andersen",
      "Oliwia Witczak",
      "Trine B. Haugen",
      "Hugo L. Hammer",
      "P\u00e5l Halvorsen",
      "Michael A. Riegler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02842"
  },
  {
    "id": "arXiv:2212.02845",
    "title": "SSDA3D: Semi-supervised Domain Adaptation for 3D Object Detection from  Point Cloud",
    "abstract": "LiDAR-based 3D object detection is an indispensable task in advanced\nautonomous driving systems. Though impressive detection results have been\nachieved by superior 3D detectors, they suffer from significant performance\ndegeneration when facing unseen domains, such as different LiDAR\nconfigurations, different cities, and weather conditions. The mainstream\napproaches tend to solve these challenges by leveraging unsupervised domain\nadaptation (UDA) techniques. However, these UDA solutions just yield\nunsatisfactory 3D detection results when there is a severe domain shift, e.g.,\nfrom Waymo (64-beam) to nuScenes (32-beam). To address this, we present a novel\nSemi-Supervised Domain Adaptation method for 3D object detection (SSDA3D),\nwhere only a few labeled target data is available, yet can significantly\nimprove the adaptation performance. In particular, our SSDA3D includes an\nInter-domain Adaptation stage and an Intra-domain Generalization stage. In the\nfirst stage, an Inter-domain Point-CutMix module is presented to efficiently\nalign the point cloud distribution across domains. The Point-CutMix generates\nmixed samples of an intermediate domain, thus encouraging to learn\ndomain-invariant knowledge. Then, in the second stage, we further enhance the\nmodel for better generalization on the unlabeled target set. This is achieved\nby exploring Intra-domain Point-MixUp in semi-supervised learning, which\nessentially regularizes the pseudo label distribution. Experiments from Waymo\nto nuScenes show that, with only 10% labeled target data, our SSDA3D can\nsurpass the fully-supervised oracle model with 100% target label. Our code is\navailable at https://github.com/yinjunbo/SSDA3D.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Yan Wang",
      "Junbo Yin",
      "Wei Li",
      "Pascal Frossard",
      "Ruigang Yang",
      "Jianbing Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02845"
  },
  {
    "id": "arXiv:2212.02848",
    "title": "SignNet: Single Channel Sign Generation using Metric Embedded Learning",
    "abstract": "A true interpreting agent not only understands sign language and translates\nto text, but also understands text and translates to signs. Much of the AI work\nin sign language translation to date has focused mainly on translating from\nsigns to text. Towards the latter goal, we propose a text-to-sign translation\nmodel, SignNet, which exploits the notion of similarity (and dissimilarity) of\nvisual signs in translating. This module presented is only one part of a\ndual-learning two task process involving text-to-sign (T2S) as well as\nsign-to-text (S2T). We currently implement SignNet as a single channel\narchitecture so that the output of the T2S task can be fed into S2T in a\ncontinuous dual learning framework. By single channel, we refer to a single\nmodality, the body pose joints.\nIn this work, we present SignNet, a T2S task using a novel metric embedding\nlearning process, to preserve the distances between sign embeddings relative to\ntheir dissimilarity. We also describe how to choose positive and negative\nexamples of signs for similarity testing. From our analysis, we observe that\nmetric embedding learning-based model perform significantly better than the\nother models with traditional losses, when evaluated using BLEU scores. In the\ntask of gloss to pose, SignNet performed as well as its state-of-the-art (SoTA)\ncounterparts and outperformed them in the task of text to pose, by showing\nnoteworthy enhancements in BLEU 1 - BLEU 4 scores (BLEU 1: 31->39; ~26%\nimprovement and BLEU 4: 10.43->11.84; ~14\\% improvement) when tested on the\npopular RWTH PHOENIX-Weather-2014T benchmark dataset",
    "descriptor": "\nComments: 9 pages, 4 figures, 4 tables - IEEE Face and Gestures, 2023\n",
    "authors": [
      "Tejaswini Ananthanarayana",
      "Lipisha Chaudhary",
      "Ifeoma Nwogu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02848"
  },
  {
    "id": "arXiv:2212.02851",
    "title": "DiSTRICT: Dialogue State Tracking with Retriever Driven In-Context  Tuning",
    "abstract": "Dialogue State Tracking (DST), a key component of task-oriented conversation\nsystems, represents user intentions by determining the values of pre-defined\nslots in an ongoing dialogue. Existing approaches use hand-crafted templates\nand additional slot information to fine-tune and prompt large pre-trained\nlanguage models and elicit slot values from the dialogue context. Significant\nmanual effort and domain knowledge is required to design effective prompts,\nlimiting the generalizability of these approaches to new domains and tasks. In\nthis work, we propose DiSTRICT, a generalizable in-context tuning approach for\nDST that retrieves highly relevant training examples for a given dialogue to\nfine-tune the model without any hand-crafted templates. Experiments with the\nMultiWOZ benchmark datasets show that DiSTRICT outperforms existing approaches\nin various zero-shot and few-shot settings using a much smaller model, thereby\nproviding an important advantage for real-world deployments that often have\nlimited resource availability.",
    "descriptor": "",
    "authors": [
      "Praveen Venkateswaran",
      "Evelyn Duesterwald",
      "Vatche Isahagian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.02851"
  },
  {
    "id": "arXiv:2212.02858",
    "title": "Enhancing Data-Awareness of Object-Centric Event Logs",
    "abstract": "When multiple objects are involved in a process, there is an opportunity for\nprocesses to be discovered from different angles with new information that\npreviously might not have been analyzed from a single object point of view.\nThis does require that all the information of event/object attributes and their\nvalues are stored within logs including attributes that have a list of values\nor attributes with values that change over time. It also requires that\nattributes can unambiguously be linked to an object, an event or both. As such,\nobject-centric event logs are an interesting development in process mining as\nthey support the presence of multiple types of objects. First, this paper shows\nthat the current object-centric event log formats do not support the\naforementioned aspects to their full potential since the possibility to support\ndynamic object attributes (attributes with changing values) is not supported by\nexisting formats. Next, this paper introduces a novel enriched object-centric\nevent log format tackling the aforementioned issues alongside an algorithm that\nautomatically translates XES logs to this Data-aware OCEL (DOCEL) format.",
    "descriptor": "\nComments: Submitted and Accepted at the 4th International Conference on Process Mining (ICPM) 2022: Event Data and Behavioral Analytics (EdbA) Workshop\n",
    "authors": [
      "Alexandre Goossens",
      "Johannes De Smedt",
      "Jan Vanthienen",
      "Wil van der Aalst"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.02858"
  },
  {
    "id": "arXiv:2212.02859",
    "title": "Non-interactive Multi-client Searchable Symmetric Encryption with Small  Client Storage",
    "abstract": "Considerable attention has been paid to dynamic searchable symmetric\nencryption (DSSE) which allows users to search on dynamically updated encrypted\ndatabases. To improve the performance of real-world applications, recent\nnon-interactive multi-client DSSE schemes are targeted at avoiding per-query\ninteraction between data owners and data users. However, existing\nnon-interactive multi-client DSSE schemes do not consider forward privacy or\nbackward privacy, making them exposed to leakage abuse attacks. Besides, most\nexisting DSSE schemes with forward and backward privacy rely on keeping a\nkeyword operation counter or an inverted index, resulting in a heavy storage\nburden on the data owner side. To address these issues, we propose a\nnon-interactive multi-client DSSE scheme with small client storage, and our\nproposed scheme can provide both forward privacy and backward privacy.\nSpecifically, we first design a lightweight storage chain structure that binds\nall keywords to a single state to reduce the storage cost. Then, we present a\nHidden Key technique, which preserves non-interactive forward privacy through\ntime range queries, ensuring that data with newer timestamps cannot match\nearlier time ranges. We conduct extensive experiments to validate our methods,\nwhich demonstrate computational efficiency. Moreover, security analysis proves\nthe privacy-preserving property of our methods.",
    "descriptor": "",
    "authors": [
      "Hanqi Zhang",
      "Chang Xu",
      "Rongxing Lu",
      "Liehuang Zhu",
      "Chuan Zhang",
      "Yunguo Guan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.02859"
  },
  {
    "id": "arXiv:2212.02861",
    "title": "RBF-MGN:Solving spatiotemporal PDEs with Physics-informed Graph Neural  Network",
    "abstract": "Physics-informed neural networks (PINNs) have lately received significant\nattention as a representative deep learning-based technique for solving partial\ndifferential equations (PDEs). Most fully connected network-based PINNs use\nautomatic differentiation to construct loss functions that suffer from slow\nconvergence and difficult boundary enforcement. In addition, although\nconvolutional neural network (CNN)-based PINNs can significantly improve\ntraining efficiency, CNNs have difficulty in dealing with irregular geometries\nwith unstructured meshes. Therefore, we propose a novel framework based on\ngraph neural networks (GNNs) and radial basis function finite difference\n(RBF-FD). We introduce GNNs into physics-informed learning to better handle\nirregular domains with unstructured meshes. RBF-FD is used to construct a\nhigh-precision difference format of the differential equations to guide model\ntraining. Finally, we perform numerical experiments on Poisson and wave\nequations on irregular domains. We illustrate the generalizability, accuracy,\nand efficiency of the proposed algorithms on different PDE parameters, numbers\nof collection points, and several types of RBFs.",
    "descriptor": "\nComments: 21 pages,20 figures\n",
    "authors": [
      "Zixue Xiang",
      "Wei Peng",
      "Wen Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02861"
  },
  {
    "id": "arXiv:2212.02863",
    "title": "Evidential Deep Learning for Class-Incremental Semantic Segmentation",
    "abstract": "Class-Incremental Learning is a challenging problem in machine learning that\naims to extend previously trained neural networks with new classes. This is\nespecially useful if the system is able to classify new objects despite the\noriginal training data being unavailable. While the semantic segmentation\nproblem has received less attention than classification, it poses distinct\nproblems and challenges since previous and future target classes can be\nunlabeled in the images of a single increment. In this case, the background,\npast and future classes are correlated and there exist a background-shift. In\nthis paper, we address the problem of how to model unlabeled classes while\navoiding spurious feature clustering of future uncorrelated classes. We propose\nto use Evidential Deep Learning to model the evidence of the classes as a\nDirichlet distribution. Our method factorizes the problem into a separate\nforeground class probability, calculated by the expected value of the Dirichlet\ndistribution, and an unknown class (background) probability corresponding to\nthe uncertainty of the estimate. In our novel formulation, the background\nprobability is implicitly modeled, avoiding the feature space clustering that\ncomes from forcing the model to output a high background score for pixels that\nare not labeled as objects. Experiments on the incremental Pascal VOC, and\nADE20k benchmarks show that our method is superior to state-of-the-art,\nespecially when repeatedly learning new classes with increasing number of\nincrements.",
    "descriptor": "",
    "authors": [
      "Karl Holmquist",
      "Lena Klas\u00e9n",
      "Michael Felsberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02863"
  },
  {
    "id": "arXiv:2212.02870",
    "title": "TripCEAiR: A Multi-Loss minimization approach for surface EMG based  Airwriting Recognition",
    "abstract": "Airwriting Recognition refers to the problem of identification of letters\nwritten in space with movement of the finger. It can be seen as a special case\nof dynamic gesture recognition wherein the set of gestures are letters in a\nparticular language. Surface Electromyography (sEMG) is a non-invasive approach\nused to capture electrical signals generated as a result of contraction and\nrelaxation of the muscles. sEMG has been widely adopted for gesture recognition\napplications. Unlike static gestures, dynamic gestures are user-friendly and\ncan be used as a method for input with applications in Human Computer\nInteraction. There has been limited work in recognition of dynamic gestures\nsuch as airwriting, using sEMG signals and forms the core of the current work.\nIn this work, a multi-loss minimization framework for sEMG based airwriting\nrecognition is proposed. The proposed framework aims at learning a feature\nembedding vector that minimizes the triplet loss, while simultaneously learning\nthe parameters of a classifier head to recognize corresponding alphabets. The\nproposed method is validated on a dataset recorded in the lab comprising of\nsEMG signals from 50 participants writing English uppercase alphabets. The\neffect of different variations of triplet loss, triplet mining strategies and\nfeature embedding dimension is also presented. The best-achieved accuracy was\n81.26% and 65.62% in user-dependent and independent scenarios respectively by\nusing semihard positive and hard negative triplet mining. The code for our\nimplementation will be made available at https://github.com/ayushayt/TripCEAiR.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2210.17185. text overlap with arXiv:2210.17185\n",
    "authors": [
      "Ayush Tripathi",
      "Lalan Kumar",
      "Prathosh AP",
      "Suriya Prakash Muthukrishnan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.02870"
  },
  {
    "id": "arXiv:2212.02871",
    "title": "Video Object of Interest Segmentation",
    "abstract": "In this work, we present a new computer vision task named video object of\ninterest segmentation (VOIS). Given a video and a target image of interest, our\nobjective is to simultaneously segment and track all objects in the video that\nare relevant to the target image. This problem combines the traditional video\nobject segmentation task with an additional image indicating the content that\nusers are concerned with. Since no existing dataset is perfectly suitable for\nthis new task, we specifically construct a large-scale dataset called\nLiveVideos, which contains 2418 pairs of target images and live videos with\ninstance-level annotations. In addition, we propose a transformer-based method\nfor this task. We revisit Swin Transformer and design a dual-path structure to\nfuse video and image features. Then, a transformer decoder is employed to\ngenerate object proposals for segmentation and tracking from the fused\nfeatures. Extensive experiments on LiveVideos dataset show the superiority of\nour proposed method.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Siyuan Zhou",
      "Chunru Zhan",
      "Biao Wang",
      "Tiezheng Ge",
      "Yuning Jiang",
      "Li Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02871"
  },
  {
    "id": "arXiv:2212.02872",
    "title": "A 64-core mixed-signal in-memory compute chip based on phase-change  memory for deep neural network inference",
    "abstract": "The need to repeatedly shuttle around synaptic weight values from memory to\nprocessing units has been a key source of energy inefficiency associated with\nhardware implementation of artificial neural networks. Analog in-memory\ncomputing (AIMC) with spatially instantiated synaptic weights holds high\npromise to overcome this challenge, by performing matrix-vector multiplications\n(MVMs) directly within the network weights stored on a chip to execute an\ninference workload. However, to achieve end-to-end improvements in latency and\nenergy consumption, AIMC must be combined with on-chip digital operations and\ncommunication to move towards configurations in which a full inference workload\nis realized entirely on-chip. Moreover, it is highly desirable to achieve high\nMVM and inference accuracy without application-wise re-tuning of the chip.\nHere, we present a multi-core AIMC chip designed and fabricated in 14-nm\ncomplementary metal-oxide-semiconductor (CMOS) technology with\nbackend-integrated phase-change memory (PCM). The fully-integrated chip\nfeatures 64 256x256 AIMC cores interconnected via an on-chip communication\nnetwork. It also implements the digital activation functions and processing\ninvolved in ResNet convolutional neural networks and long short-term memory\n(LSTM) networks. We demonstrate near software-equivalent inference accuracy\nwith ResNet and LSTM networks while implementing all the computations\nassociated with the weight layers and the activation functions on-chip. The\nchip can achieve a maximal throughput of 63.1 TOPS at an energy efficiency of\n9.76 TOPS/W for 8-bit input/output matrix-vector multiplications.",
    "descriptor": "",
    "authors": [
      "Manuel Le Gallo",
      "Riduan Khaddam-Aljameh",
      "Milos Stanisavljevic",
      "Athanasios Vasilopoulos",
      "Benedikt Kersting",
      "Martino Dazzi",
      "Geethan Karunaratne",
      "Matthias Braendli",
      "Abhairaj Singh",
      "Silvia M. Mueller",
      "Julian Buechel",
      "Xavier Timoneda",
      "Vinay Joshi",
      "Urs Egger",
      "Angelo Garofalo",
      "Anastasios Petropoulos",
      "Theodore Antonakopoulos",
      "Kevin Brew",
      "Samuel Choi",
      "Injo Ok",
      "Timothy Philip",
      "Victor Chan",
      "Claire Silvestre",
      "Ishtiaq Ahsan",
      "Nicole Saulnier",
      "Vijay Narayanan",
      "Pier Andrea Francese",
      "Evangelos Eleftheriou",
      "Abu Sebastian"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2212.02872"
  },
  {
    "id": "arXiv:2212.02875",
    "title": "Multi-Task Edge Prediction in Temporally-Dynamic Video Graphs",
    "abstract": "Graph neural networks have shown to learn effective node representations,\nenabling node-, link-, and graph-level inference. Conventional graph networks\nassume static relations between nodes, while relations between entities in a\nvideo often evolve over time, with nodes entering and exiting dynamically. In\nsuch temporally-dynamic graphs, a core problem is inferring the future state of\nspatio-temporal edges, which can constitute multiple types of relations. To\naddress this problem, we propose MTD-GNN, a graph network for predicting\ntemporally-dynamic edges for multiple types of relations. We propose a\nfactorized spatio-temporal graph attention layer to learn dynamic node\nrepresentations and present a multi-task edge prediction loss that models\nmultiple relations simultaneously. The proposed architecture operates on top of\nscene graphs that we obtain from videos through object detection and\nspatio-temporal linking. Experimental evaluations on ActionGenome and CLEVRER\nshow that modeling multiple relations in our temporally-dynamic graph network\ncan be mutually beneficial, outperforming existing static and spatio-temporal\ngraph neural networks, as well as state-of-the-art predicate classification\nmethods.",
    "descriptor": "\nComments: BMVC2022\n",
    "authors": [
      "Osman \u00dclger",
      "Julian Wiederer",
      "Mohsen Ghafoorian",
      "Vasileios Belagiannis",
      "Pascal Mettes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02875"
  },
  {
    "id": "arXiv:2212.02876",
    "title": "Space optimal and asymptotically move optimal Arbitrary Pattern  Formation on rectangular grid by asynchronous robot swarm",
    "abstract": "Arbitrary pattern formation (\\textsc{Apf}) is well studied problem in swarm\nrobotics. The problem has been considered in two different settings so far; one\nis in plane and another is in infinite grid. This work deals the problem in\ninfinite rectangular grid setting. The previous works in literature dealing\nwith \\textsc{Apf} problem in infinite grid had a fundamental issue. These\ndeterministic algorithms use a lot space of the grid to solve the problem\nmainly because of maintaining asymmetry of the configuration or to avoid\ncollision. These solution techniques can not be useful if there is a space\nconstrain in the application field. In this work, we consider luminous robots\n(with one light that can take two colors) in order to avoid symmetry, but we\ncarefully designed a deterministic algorithm which solves the \\textsc{Apf}\nproblem using minimal required space in the grid. The robots are autonomous,\nidentical, anonymous and they operate in Look-Compute-Move cycles under a fully\nasynchronous scheduler. The \\textsc{Apf} algorithm proposed in [WALCOM'2019] by\nBose et al. can be modified using luminous robots so that it uses minimal space\nbut that algorithm is not move optimal. The algorithm proposed in this paper\nnot only uses minimal space but also asymptotically move optimal. The algorithm\nproposed in this work is designed for infinite rectangular grid but it can be\neasily modified to work in a finite grid as well.",
    "descriptor": "",
    "authors": [
      "Avisek Sharma",
      "Satakshi Ghosh",
      "Pritam Goswami",
      "Buddhadeb Sau"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.02876"
  },
  {
    "id": "arXiv:2212.02882",
    "title": "Electromagnetic Information Theory: Fundamentals, Modeling,  Applications, and Open Problems",
    "abstract": "Traditional single-input single-output and multiple-input multiple-output\ninformation theory adopt spatially discrete modeling, which does not fully\ncapture the continuous nature of the underlying electromagnetic (EM) fields\nsupporting the physical layer of wireless communication systems. Thus, it is of\ninterest to examine the information-carrying capability of continuous EM\nfields, which motivates research on EM information theory (EIT). In this\narticle, we systematically investigate the basic ideas and main results of EIT.\nFirst, we review the fundamental analytical tools of classical information\ntheory and EM theory. Then, we introduce the modeling and analysis\nmethodologies of EIT, including continuous field modeling, degree of freedom,\nmutual information, and capacity analyses. After that, several EIT-inspired\napplications are discussed to illustrate how EIT guides the design of practical\nwireless systems. Finally, we point out several open problems of EIT, where\nfurther research efforts are required for EIT to construct a unified\ninterdisciplinary theory.",
    "descriptor": "\nComments: In this paper, the emerging interdisciplinary subject of electromagnetic information theory (EIT) is reviewed. More information will be provided at: this http URL\n",
    "authors": [
      "Jieao Zhu",
      "Zhongzhichao Wan",
      "Linglong Dai",
      "M\u00e9rouane Debbah",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.02882"
  },
  {
    "id": "arXiv:2212.02883",
    "title": "Improved Approximation Schemes for (Un-)Bounded Subset-Sum and Partition",
    "abstract": "We consider the SUBSET SUM problem and its important variants in this paper.\nIn the SUBSET SUM problem, a (multi-)set $X$ of $n$ positive numbers and a\ntarget number $t$ are given, and the task is to find a subset of $X$ with the\nmaximal sum that does not exceed $t$. It is well known that this problem is\nNP-hard and admits fully polynomial-time approximation schemes (FPTASs). In\nrecent years, it has been shown that there does not exist an FPTAS of running\ntime $\\tilde\\OO( 1/\\epsilon^{2-\\delta})$ for arbitrary small $\\delta>0$\nassuming ($\\min$,+)-convolution conjecture~\\cite{bringmann2021fine}. However,\nthe lower bound can be bypassed if we relax the constraint such that the task\nis to find a subset of $X$ that can slightly exceed the threshold $t$ by\n$\\epsilon$ times, and the sum of numbers within the subset is at least\n$1-\\tilde\\OO(\\epsilon)$ times the optimal objective value that respects the\nconstraint. Approximation schemes that may violate the constraint are also\nknown as weak approximation schemes. For the SUBSET SUM problem, there is a\nrandomized weak approximation scheme running in time $\\tilde\\OO(n+\n1/\\epsilon^{5/3})$ [Mucha et al.'19]. For the special case where the target $t$\nis half of the summation of all input numbers, weak approximation schemes are\nequivalent to approximation schemes that do not violate the constraint, and the\nbest-known algorithm runs in $\\tilde\\OO(n+1/\\epsilon^{{3}/{2}})$ time\n[Bringmann and Nakos'21].",
    "descriptor": "",
    "authors": [
      "Xiaoyu Wu",
      "Lin Chen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2212.02883"
  },
  {
    "id": "arXiv:2212.02885",
    "title": "Template-based Recruitment Email Generation For Job Recommendation",
    "abstract": "Text generation has long been a popular research topic in NLP. However, the\ntask of generating recruitment emails from recruiters to candidates in the job\nrecommendation scenario has received little attention by the research\ncommunity. This work aims at defining the topic of automatic email generation\nfor job recommendation, identifying the challenges, and providing a baseline\ntemplate-based solution for Danish jobs. Evaluation by human experts shows that\nour method is effective. We wrap up by discussing the future research\ndirections for better solving this task.",
    "descriptor": "\nComments: Accepted by GEM2022 workshop\n",
    "authors": [
      "Qiuchi Li",
      "Christina Lioma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.02885"
  },
  {
    "id": "arXiv:2212.02886",
    "title": "GAS-Net: Generative Artistic Style Neural Networks for Fonts",
    "abstract": "Generating new fonts is a time-consuming and labor-intensive, especially in a\nlanguage with a huge amount of characters like Chinese. Various deep learning\nmodels have demonstrated the ability to efficiently generate new fonts with a\nfew reference characters of that style. This project aims to develop a few-shot\ncross-lingual font generator based on AGIS-Net and improve the performance\nmetrics mentioned. Our approaches include redesigning the encoder and the loss\nfunction. We will validate our method on multiple languages and datasets\nmentioned.",
    "descriptor": "",
    "authors": [
      "Haoyang He",
      "Xin Jin",
      "Angela Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02886"
  },
  {
    "id": "arXiv:2212.02893",
    "title": "Generation and Prediction of Difficult Model Counting Instances",
    "abstract": "We present a way to create small yet difficult model counting instances. Our\ngenerator is highly parameterizable: the number of variables of the instances\nit produces, as well as their number of clauses and the number of literals in\neach clause, can all be set to any value. Our instances have been tested on\nstate of the art model counters, against other difficult model counting\ninstances, in the Model Counting Competition. The smallest unsolved instances\nof the competition, both in terms of number of variables and number of clauses,\nwere ours. We also observe a peak of difficulty when fixing the number of\nvariables and varying the number of clauses, in both random instances and\ninstances built by our generator. Using these results, we predict the parameter\nvalues for which the hardest to count instances will occur.",
    "descriptor": "",
    "authors": [
      "Guillaume Escamocher",
      "Barry O'Sullivan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02893"
  },
  {
    "id": "arXiv:2212.02895",
    "title": "Loss Adapted Plasticity in Deep Neural Networks to Learn from Data with  Unreliable Sources",
    "abstract": "When data is streaming from multiple sources, conventional training methods\nupdate model weights often assuming the same level of reliability for each\nsource; that is: a model does not consider data quality of each source during\ntraining. In many applications, sources can have varied levels of noise or\ncorruption that has negative effects on the learning of a robust deep learning\nmodel. A key issue is that the quality of data or labels for individual sources\nis often not available during training and could vary over time. Our solution\nto this problem is to consider the mistakes made while training on data\noriginating from sources and utilise this to create a perceived data quality\nfor each source. This paper demonstrates a straight-forward and novel technique\nthat can be applied to any gradient descent optimiser: Update model weights as\na function of the perceived reliability of data sources within a wider data\nset. The algorithm controls the plasticity of a given model to weight updates\nbased on the history of losses from individual data sources. We show that\napplying this technique can significantly improve model performance when\ntrained on a mixture of reliable and unreliable data sources, and maintain\nperformance when models are trained on data sources that are all considered\nreliable. All code to reproduce this work's experiments and implement the\nalgorithm in the reader's own models is made available.",
    "descriptor": "",
    "authors": [
      "Alexander Capstick",
      "Francesca Palermo",
      "Payam Barnaghi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.02895"
  },
  {
    "id": "arXiv:2212.02896",
    "title": "Multimodal Tree Decoder for Table of Contents Extraction in Document  Images",
    "abstract": "Table of contents (ToC) extraction aims to extract headings of different\nlevels in documents to better understand the outline of the contents, which can\nbe widely used for document understanding and information retrieval. Existing\nworks often use hand-crafted features and predefined rule-based functions to\ndetect headings and resolve the hierarchical relationship between headings.\nBoth the benchmark and research based on deep learning are still limited.\nAccordingly, in this paper, we first introduce a standard dataset, HierDoc,\nincluding image samples from 650 documents of scientific papers with their\ncontent labels. Then we propose a novel end-to-end model by using the\nmultimodal tree decoder (MTD) for ToC as a benchmark for HierDoc. The MTD model\nis mainly composed of three parts, namely encoder, classifier, and decoder. The\nencoder fuses the multimodality features of vision, text, and layout\ninformation for each entity of the document. Then the classifier recognizes and\nselects the heading entities. Next, to parse the hierarchical relationship\nbetween the heading entities, a tree-structured decoder is designed. To\nevaluate the performance, both the metric of tree-edit-distance similarity\n(TEDS) and F1-Measure are adopted. Finally, our MTD approach achieves an\naverage TEDS of 87.2% and an average F1-Measure of 88.1% on the test set of\nHierDoc. The code and dataset will be released at:\nhttps://github.com/Pengfei-Hu/MTD.",
    "descriptor": "\nComments: Accepted by ICPR2022\n",
    "authors": [
      "Pengfei Hu",
      "Zhenrong Zhang",
      "Jianshu Zhang",
      "Jun Du",
      "Jiajia Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02896"
  },
  {
    "id": "arXiv:2212.02907",
    "title": "Emotion Conditioned Creative Dialog Generation",
    "abstract": "We present a DialGPT based model for generating creative dialog responses\nthat are conditioned based on one of the following emotions: anger, disgust,\nfear, happiness, pain, sadness and surprise. Our model is capable of producing\na contextually apt response given an input sentence and a desired emotion\nlabel. Our model is capable of expressing the desired emotion with an accuracy\nof 0.6. The best performing emotions are neutral, fear and disgust. When\nmeasuring the strength of the expressed emotion, we find that anger, fear and\ndisgust are expressed in the most strong fashion by the model.",
    "descriptor": "\nComments: NLP4DH 2022\n",
    "authors": [
      "Khalid Alnajjar",
      "Mika H\u00e4m\u00e4l\u00e4inen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.02907"
  },
  {
    "id": "arXiv:2212.02908",
    "title": "Towards human-compatible autonomous car: A study of non-verbal Turing  test in automated driving with affective transition modelling",
    "abstract": "Autonomous cars are indispensable when humans go further down the hands-free\nroute. Although existing literature highlights that the acceptance of the\nautonomous car will increase if it drives in a human-like manner, sparse\nresearch offers the naturalistic experience from a passenger's seat perspective\nto examine the human likeness of current autonomous cars. The present study\ntested whether the AI driver could create a human-like ride experience for\npassengers based on 69 participants' feedback in a real-road scenario. We\ndesigned a ride experience-based version of the non-verbal Turing test for\nautomated driving. Participants rode in autonomous cars (driven by either human\nor AI drivers) as a passenger and judged whether the driver was human or AI.\nThe AI driver failed to pass our test because passengers detected the AI driver\nabove chance. In contrast, when the human driver drove the car, the passengers'\njudgement was around chance. We further investigated how human passengers\nascribe humanness in our test. Based on Lewin's field theory, we advanced a\ncomputational model combining signal detection theory with pre-trained language\nmodels to predict passengers' humanness rating behaviour. We employed affective\ntransition between pre-study baseline emotions and corresponding post-stage\nemotions as the signal strength of our model. Results showed that the\npassengers' ascription of humanness would increase with the greater affective\ntransition. Our study suggested an important role of affective transition in\npassengers' ascription of humanness, which might become a future direction for\nautonomous driving.",
    "descriptor": "\nComments: 16 pages, 9 figures, 3 tables\n",
    "authors": [
      "Zhaoning Li",
      "Qiaoli Jiang",
      "Zhengming Wu",
      "Anqi Liu",
      "Haiyan Wu",
      "Miner Huang",
      "Kai Huang",
      "Yixuan Ku"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.02908"
  },
  {
    "id": "arXiv:2212.02909",
    "title": "Scalable Planning and Learning Framework Development for Swarm-to-Swarm  Engagement Problems",
    "abstract": "Development of guidance, navigation and control frameworks/algorithms for\nswarms attracted significant attention in recent years. That being said,\nalgorithms for planning swarm allocations/trajectories for engaging with enemy\nswarms is largely an understudied problem. Although small-scale scenarios can\nbe addressed with tools from differential game theory, existing approaches fail\nto scale for large-scale multi-agent pursuit evasion (PE) scenarios. In this\nwork, we propose a reinforcement learning (RL) based framework to decompose to\nlarge-scale swarm engagement problems into a number of independent multi-agent\npursuit-evasion games. We simulate a variety of multi-agent PE scenarios, where\nfinite time capture is guaranteed under certain conditions. The calculated PE\nstatistics are provided as a reward signal to the high level allocation layer,\nwhich uses an RL algorithm to allocate controlled swarm units to eliminate\nenemy swarm units with maximum efficiency. We verify our approach in\nlarge-scale swarm-to-swarm engagement simulations.",
    "descriptor": "\nComments: Accepted to SciTech2023\n",
    "authors": [
      "Umut Demir",
      "A. Sadik Satir",
      "Gulay Goktas Sever",
      "Cansu Yikilmaz",
      "Nazim Kemal Ure"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.02909"
  },
  {
    "id": "arXiv:2212.02910",
    "title": "G-MSM: Unsupervised Multi-Shape Matching with Graph-based Affinity  Priors",
    "abstract": "We present G-MSM (Graph-based Multi-Shape Matching), a novel unsupervised\nlearning approach for non-rigid shape correspondence. Rather than treating a\ncollection of input poses as an unordered set of samples, we explicitly model\nthe underlying shape data manifold. To this end, we propose an adaptive\nmulti-shape matching architecture that constructs an affinity graph on a given\nset of training shapes in a self-supervised manner. The key idea is to combine\nputative, pairwise correspondences by propagating maps along shortest paths in\nthe underlying shape graph. During training, we enforce cycle-consistency\nbetween such optimal paths and the pairwise matches which enables our model to\nlearn topology-aware shape priors. We explore different classes of shape graphs\nand recover specific settings, like template-based matching (star graph) or\nlearnable ranking/sorting (TSP graph), as special cases in our framework.\nFinally, we demonstrate state-of-the-art performance on several recent shape\ncorrespondence benchmarks, including real-world 3D scan meshes with topological\nnoise and challenging inter-class pairs.",
    "descriptor": "",
    "authors": [
      "Marvin Eisenberger",
      "Aysim Toker",
      "Laura Leal-Taix\u00e9",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02910"
  },
  {
    "id": "arXiv:2212.02911",
    "title": "Modern French Poetry Generation with RoBERTa and GPT-2",
    "abstract": "We present a novel neural model for modern poetry generation in French. The\nmodel consists of two pretrained neural models that are fine-tuned for the poem\ngeneration task. The encoder of the model is a RoBERTa based one while the\ndecoder is based on GPT-2. This way the model can benefit from the superior\nnatural language understanding performance of RoBERTa and the good natural\nlanguage generation performance of GPT-2. Our evaluation shows that the model\ncan create French poetry successfully. On a 5 point scale, the lowest score of\n3.57 was given by human judges to typicality and emotionality of the output\npoetry while the best score of 3.79 was given to understandability.",
    "descriptor": "\nComments: ICCC 2022\n",
    "authors": [
      "Mika H\u00e4m\u00e4l\u00e4inen",
      "Khalid Alnajjar",
      "Thierry Poibeau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.02911"
  },
  {
    "id": "arXiv:2212.02913",
    "title": "Higher Lower Bounds for Sparse Oblivious Subspace Embeddings",
    "abstract": "An oblivious subspace embedding (OSE), characterized by parameters\n$m,n,d,\\epsilon,\\delta$, is a random matrix $\\Pi\\in \\mathbb{R}^{m\\times n}$\nsuch that for any $d$-dimensional subspace $T\\subseteq \\mathbb{R}^n$,\n$\\Pr_\\Pi[\\forall x\\in T, (1-\\epsilon)\\|x\\|_2 \\leq \\|\\Pi x\\|_2\\leq\n(1+\\epsilon)\\|x\\|_2] \\geq 1-\\delta$. When an OSE has $1/(9\\epsilon)$ nonzero\nentries in each column, we show it must hold that $m =\n\\Omega(d^2/\\epsilon^{1-O(\\delta)})$, which is the first lower bound with\nmultiplicative factors of $d^2$ and $1/\\epsilon$, improving on the previous\n$\\Omega(\\epsilon^{O(\\delta)}d^2)$ lower bound due to Li and Liu (PODS 2022).",
    "descriptor": "",
    "authors": [
      "Yi Li",
      "Mingmou Liu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2212.02913"
  },
  {
    "id": "arXiv:2212.02916",
    "title": "Graphnics: Combining FEniCS and NetworkX to simulate flow in complex  networks",
    "abstract": "Network models facilitate inexpensive simulations, but require careful\nhandling of bifurcation conditions. We here present the graphnics library,\nwhich combines FEniCS with NetworkX to facilitate network simulations using the\nfinite element method. Graphnics features (i) a FenicsGraph class built on top\nof the NetworkX DiGraph class, that constructs a global mesh for a network and\nprovides FEniCS mesh functions describing how they relate to the graph\nstructure. (ii) Example models showing how the FenicsGraph class can be used to\nassemble and solve different network flow models. (iii) Demos showing e.g. how\nto run simulations on complex biological networks. Interestingly, the results\nshow that vasomotion modelled as a travelling sinusoidal wave is capable of\ndriving net perivascular fluid flow through an arterial tree, as has been\nproposed based on experimental data.",
    "descriptor": "\nComments: This is an extended version of a software manuscript\n",
    "authors": [
      "Ingeborg G. Gjerde"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.02916"
  },
  {
    "id": "arXiv:2212.02918",
    "title": "Thermal Dissipation Resulting from Everyday Interactions as a Sensing  Modality -- The MIDAS Touch",
    "abstract": "We contribute MIDAS as a novel sensing solution for characterizing everyday\nobjects using thermal dissipation. MIDAS takes advantage of the fact that\nanytime a person touches an object it results in heat transfer. By capturing\nand modeling the dissipation of the transferred heat, e.g., through the\ndecrease in the captured thermal radiation, MIDAS can characterize the object\nand determine its material. We validate MIDAS through extensive empirical\nbenchmarks and demonstrate that MIDAS offers an innovative sensing modality\nthat can recognize a wide range of materials with up to 83% accuracy and\ngeneralize to variations in the people interacting with objects. We also\ndemonstrate that MIDAS can detect thermal dissipation through objects, up to 2\nmm thickness, and support analysis of multiple objects that are interacted with",
    "descriptor": "",
    "authors": [
      "Farooq Dar",
      "Hilary Emenike",
      "Zhigang Yin",
      "Mohan Liyanage",
      "Rajesh Sharma",
      "Agustin Zuniga",
      "Mohammad A. Hoque",
      "Marko Radeta",
      "Petteri Nurmi",
      "Huber Flores"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2212.02918"
  },
  {
    "id": "arXiv:2212.02924",
    "title": "Controlled Text Generation using T5 based Encoder-Decoder Soft Prompt  Tuning and Analysis of the Utility of Generated Text in AI",
    "abstract": "Controlled text generation is a very important task in the arena of natural\nlanguage processing due to its promising applications. In order to achieve this\ntask we mainly introduce the novel soft prompt tuning method of using soft\nprompts at both encoder and decoder levels together in a T5 model and\ninvestigate the performance as the behaviour of an additional soft prompt\nrelated to the decoder of a T5 model in controlled text generation remained\nunexplored. Then we also investigate the feasibility of steering the output of\nthis extended soft prompted T5 model at decoder level and finally analyse the\nutility of generated text to be used in AI related tasks such as training AI\nmodels with an interpretability analysis of the classifier trained with\nsynthetic text, as there is a lack of proper analysis of methodologies in\ngenerating properly labelled data to be utilized in AI tasks. Through the\nperformed in-depth intrinsic and extrinsic evaluations of this generation model\nalong with the artificially generated data, we found that this model produced\nbetter results compared to the T5 model with a single soft prompt at encoder\nlevel and the sentiment classifier trained using this artificially generated\ndata can produce comparable classification results to the results of a\nclassifier trained with real labelled data and also the classifier decision is\ninterpretable with respect to the input text content.",
    "descriptor": "",
    "authors": [
      "Damith Chamalke Senadeera",
      "Julia Ive"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02924"
  },
  {
    "id": "arXiv:2212.02927",
    "title": "Trajectory Flow Map: Graph-based Approach to Analysing Temporal  Evolution of Aggregated Traffic Flows in Large-scale Urban Networks",
    "abstract": "This paper proposes a graph-based approach to representing spatio-temporal\ntrajectory data that allows an effective visualization and characterization of\ncity-wide traffic dynamics. With the advance of sensor, mobile, and Internet of\nThings (IoT) technologies, vehicle and passenger trajectories are being\nincreasingly collected on a massive scale and are becoming a critical source of\ninsight into traffic pattern and traveller behaviour. To leverage such\ntrajectory data to better understand traffic dynamics in a large-scale urban\nnetwork, this study develops a trajectory-based network traffic analysis method\nthat converts individual trajectory data into a sequence of graphs that evolve\nover time (known as dynamic graphs or time-evolving graphs) and analyses\nnetwork-wide traffic patterns in terms of a compact and informative\ngraph-representation of aggregated traffic flows. First, we partition the\nentire network into a set of cells based on the spatial distribution of data\npoints in individual trajectories, where the cells represent spatial regions\nbetween which aggregated traffic flows can be measured. Next, dynamic flows of\nmoving objects are represented as a time-evolving graph, where regions are\ngraph vertices and flows between them are treated as weighted directed edges.\nGiven a fixed set of vertices, edges can be inserted or removed at every time\nstep depending on the presence of traffic flows between two regions at a given\ntime window. Once a dynamic graph is built, we apply graph mining algorithms to\ndetect change-points in time, which represent time points where the graph\nexhibits significant changes in its overall structure and, thus, correspond to\nchange-points in city-wide mobility pattern throughout the day (e.g., global\ntransition points between peak and off-peak periods).",
    "descriptor": "\nComments: 20 pages, 5 figures; Presented at the 96th Annual Meeting of the Transportation Research Board, January 2017\n",
    "authors": [
      "Jiwon Kim",
      "Kai Zheng",
      "Jonathan Corcoran",
      "Sanghyung Ahn",
      "Marty Papamanolis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.02927"
  },
  {
    "id": "arXiv:2212.02929",
    "title": "Deep Neural Networks Based on Iterative Thresholding and Projection  Algorithms for Sparse LQR Control Design",
    "abstract": "In this paper, we consider an LQR design problem for distributed control\nsystems. For large-scale distributed systems, finding a solution might be\ncomputationally demanding due to communications among agents. To this aim, we\ndeal with LQR minimization problem with a regularization for sparse feedback\nmatrix, which can lead to achieve the reduction of the communication links in\nthe distributed control systems. For this work, we introduce a simple but\nefficient iterative algorithms - Iterative Shrinkage Thresholding Algorithm\n(ISTA) and Iterative Sparse Projection Algorithm (ISPA). They can give us a\ntrade-off solution between LQR cost and sparsity level on feedback matrix.\nMoreover, in order to improve the speed of the proposed algorithms, we design\ndeep neural network models based on the proposed iterative algorithms.\nNumerical experiments demonstrate that our algorithms can outperform the\nprevious methods using the Alternating Direction Method of Multiplier (ADMM)\n[1] and the Gradient Support Pursuit (GraSP) [2], and their deep neural network\nmodels can improve the performance of the proposed algorithms in convergence\nspeed.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Myung Cho"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.02929"
  },
  {
    "id": "arXiv:2212.02931",
    "title": "Leveraging Different Learning Styles for Improved Knowledge Distillation",
    "abstract": "Learning style refers to a type of training mechanism adopted by an\nindividual to gain new knowledge. As suggested by the VARK model, humans have\ndifferent learning preferences like visual, auditory, etc., for acquiring and\neffectively processing information. Inspired by this concept, our work explores\nthe idea of mixed information sharing with model compression in the context of\nKnowledge Distillation (KD) and Mutual Learning (ML). Unlike conventional\ntechniques that share the same type of knowledge with all networks, we propose\nto train individual networks with different forms of information to enhance the\nlearning process. We formulate a combined KD and ML framework with one teacher\nand two student networks that share or exchange information in the form of\npredictions and feature maps. Our comprehensive experiments with benchmark\nclassification and segmentation datasets demonstrate that with 15% compression,\nthe ensemble performance of networks trained with diverse forms of knowledge\noutperforms the conventional techniques both quantitatively and qualitatively.",
    "descriptor": "",
    "authors": [
      "Usma Niyaz",
      "Deepti R. Bathula"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02931"
  },
  {
    "id": "arXiv:2212.02932",
    "title": "Learning to Bound Counterfactual Inference in Structural Causal Models  from Observational and Randomised Data",
    "abstract": "We address the problem of integrating data from multiple observational and\ninterventional studies to eventually compute counterfactuals in structural\ncausal models. We derive a likelihood characterisation for the overall data\nthat leads us to extend a previous EM-based algorithm from the case of a single\nstudy to that of multiple ones. The new algorithm learns to approximate the\n(unidentifiability) region of model parameters from such mixed data sources. On\nthis basis, it delivers interval approximations to counterfactual results,\nwhich collapse to points in the identifiable case. The algorithm is very\ngeneral, it works on semi-Markovian models with discrete variables and can\ncompute any counterfactual. Moreover, it automatically determines if a problem\nis feasible (the parameter region being nonempty), which is a necessary step\nnot to yield incorrect results. Systematic numerical experiments show the\neffectiveness and accuracy of the algorithm, while hinting at the benefits of\nintegrating heterogeneous data to get informative bounds in case of\nunidentifiability.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Marco Zaffalon",
      "Alessandro Antonucci",
      "David Huber",
      "Rafael Caba\u00f1as"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.02932"
  },
  {
    "id": "arXiv:2212.02934",
    "title": "Yggdrasil Decision Forests: A Fast and Extensible Decision Forests  Library",
    "abstract": "Yggdrasil Decision Forests is a library for the training, serving and\ninterpretation of decision forest models, targeted both at research and\nproduction work, implemented in C++, and available in C++, command line\ninterface, Python (under the name TensorFlow Decision Forests), JavaScript, and\nGo. The library has been developed organically since 2018 following a set of\nfour design principles applicable to machine learning libraries and frameworks:\nsimplicity of use, safety of use, modularity and high-level abstraction, and\nintegration with other machine learning libraries. In this paper, we describe\nthose principles in detail and present how they have been used to guide the\ndesign of the library. We then showcase the use of our library on a set of\nclassical machine learning problems. Finally, we report a benchmark comparing\nour library to related solutions.",
    "descriptor": "",
    "authors": [
      "Mathieu Guillame-Bert",
      "Sebastian Bruch",
      "Richard Stotz",
      "Jan Pfeifer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02934"
  },
  {
    "id": "arXiv:2212.02935",
    "title": "ACRO: A multi-language toolkit for supporting Automated Checking of  Research Outputs",
    "abstract": "This paper discusses the development of an open source tool ACRO, (Automatic\nChecking of Research Outputs) to assist researchers and data governance teams\nby distinguishing between: research output that is safe to publish; output that\nrequires further analysis; and output that cannot be published because it\ncreates substantial risk of disclosing private data. ACRO extends the\nfunctionality and accessibility of a previous prototype by providing a\nlight-weight 'skin' that sits over well-known analysis tools, and enables\naccess in a variety of programming languages researchers might use. This adds\nfunctionality to (i) identify potentially disclosive outputs against a range of\ncommonly used disclosure tests; (ii) suppress outputs where required; (iii)\nreport reasons for suppression; and (iv) produce simple summary documents\nTrusted Research Environment (TRE) staff can use to streamline their workflow.\nThe ACRO code and documentation are available under an MIT license at\nhttps://github.com/AI-SDC/ACRO",
    "descriptor": "",
    "authors": [
      "Richard J. Preen",
      "Jim Smith"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)",
      "Software Engineering (cs.SE)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.02935"
  },
  {
    "id": "arXiv:2212.02936",
    "title": "M-VADER: A Model for Diffusion with Multimodal Context",
    "abstract": "We introduce M-VADER: a diffusion model (DM) for image generation where the\noutput can be specified using arbitrary combinations of images and text. We\nshow how M-VADER enables the generation of images specified using combinations\nof image and text, and combinations of multiple images. Previously, a number of\nsuccessful DM image generation algorithms have been introduced that make it\npossible to specify the output image using a text prompt. Inspired by the\nsuccess of those models, and led by the notion that language was already\ndeveloped to describe the elements of visual contexts that humans find most\nimportant, we introduce an embedding model closely related to a vision-language\nmodel. Specifically, we introduce the embedding model S-MAGMA: a 13 billion\nparameter multimodal decoder combining components from an autoregressive\nvision-language model MAGMA and biases finetuned for semantic search.",
    "descriptor": "\nComments: 22 pages, 14 figures, 2 tables\n",
    "authors": [
      "Samuel Weinbach",
      "Marco Bellagente",
      "Constantin Eichenberg",
      "Andrew Dai",
      "Robert Baldock",
      "Souradeep Nanda",
      "Bj\u00f6rn Deiseroth",
      "Koen Oostermeijer",
      "Hannah Teufel",
      "Andres Felipe Cruz-Salinas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02936"
  },
  {
    "id": "arXiv:2212.02940",
    "title": "Non-Computability of the Pseudoinverse on Digital Computers",
    "abstract": "The pseudoinverse of a matrix, a generalized notion of the inverse, is of\nfundamental importance in linear algebra. However, there does not exist a\nclosed form representation of the pseudoinverse, which can be straightforwardly\ncomputed. Therefore, an algorithmic computation is necessary. An algorithmic\ncomputation can only be evaluated by also considering the underlying hardware,\ntypically digital hardware, which is responsible for performing the actual\ncomputations step by step. In this paper, we analyze if and to what degree the\npseudoinverse actually can be computed on digital hardware platforms modeled as\nTuring machines. For this, we utilize the notion of an effective algorithm\nwhich describes a provably correct computation: upon an input of any error\nparameter, the algorithm provides an approximation within the given error bound\nwith respect to the unknown solution. We prove that an effective algorithm for\ncomputing the pseudoinverse of any matrix can not exist on a Turing machine,\nalthough provably correct algorithms do exist for specific classes of matrices.\nEven more, our results introduce a lower bound on the accuracy that can be\nobtained algorithmically when computing the pseudoinverse on Turing machines.",
    "descriptor": "",
    "authors": [
      "Holger Boche",
      "Adalbert Fono",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.02940"
  },
  {
    "id": "arXiv:2212.02941",
    "title": "Safe Imitation Learning of Nonlinear Model Predictive Control for  Flexible Robots",
    "abstract": "Flexible robots may overcome the industry's major problems: safe human-robot\ncollaboration and increased load-to-mass ratio. However, oscillations and high\ndimensional state space complicate the control of flexible robots. This work\ninvestigates nonlinear model predictive control (NMPC) of flexible robots --\nfor simultaneous planning and control -- modeled via the rigid finite element\nmethod. Although NMPC performs well in simulation, computational complexity\nprevents its deployment in practice. We show that imitation learning of NMPC\nwith neural networks as function approximator can massively improve the\ncomputation time of the controller at the cost of slight performance loss and,\nmore critically, loss of safety guarantees. We leverage a safety filter\nformulated as a simpler NMPC to recover safety guarantees. Experiments on a\nsimulated three degrees of freedom flexible robot manipulator demonstrate that\nthe average computational time of the proposed safe approximate NMPC controller\nis 3.6 ms while of the original NMPC is 11.8 ms. Fast and safe approximate NMPC\nmight facilitate the industry's adoption of flexible robots and new solutions\nfor similar problems, e.g., deformable object manipulation and soft robot\ncontrol.",
    "descriptor": "\nComments: Submitted to L4DC conference\n",
    "authors": [
      "Shamil Mamedov",
      "Rudolf Reiter",
      "Moritz Diehl",
      "Jan Swevers"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2212.02941"
  },
  {
    "id": "arXiv:2212.02945",
    "title": "Counterfeits on Darknet Markets: A measurement between Jan-2014 and  Sep-2015",
    "abstract": "Counterfeits harm consumers, governments, and intellectual property holders.\nThey accounted for 3.3% of worldwide trades in 2016, having an estimated value\nof $509 billion in the same year. While estimations are mostly based on border\nseizures, we examined openly labeled counterfeits on darknet markets, which\nallowed us to gather and analyze information from a different perspective.\nHere, we analyzed data from 11 darknet markets for the period Jan-2014 and\nSep-2015. The findings suggest that darknet markets harbor similar counterfeit\nproduct types as found in seizures but that the share of watches is higher and\nlower for electronics, clothes, shoes, and Tobacco on darknet markets. Also,\ndarknet market counterfeits seem to have similar shipping origins as seized\ngoods, with some exceptions, such as a relatively high share (5%) of dark\nmarket counterfeits originating from the US. Lastly, counterfeits on dark\nmarkets tend to have a relatively low price and sales volume. However, based on\npreliminary estimations, the original products on the surface web seem to be\nworth a multiple of the prices of the counterfeit counterparts on darknet\nmarkets. Gathering insights about counterfeits from darknet markets can be\nvaluable for businesses and authorities and be cost-effective compared to\nborder seizures. Thus, monitoring darknet markets can help us understand the\ncounterfeit landscape better.",
    "descriptor": "\nComments: This paper is a pre-print\n",
    "authors": [
      "Felix Soldner",
      "Bennett Kleinberg",
      "Shane D Johnson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2212.02945"
  },
  {
    "id": "arXiv:2212.02951",
    "title": "State Space Closure: Revisiting Endless Online Level Generation via  Reinforcement Learning",
    "abstract": "In this paper we revisit endless online level generation with the recently\nproposed experience-driven procedural content generation via reinforcement\nlearning (EDRL) framework, from an observation that EDRL tends to generate\nrecurrent patterns. Inspired by this phenomenon, we formulate a notion of state\nspace closure, which means that any state that may appear in an\ninfinite-horizon online generation process can be found in a finite horizon.\nThrough theoretical analysis we find that though state space closure arises a\nconcern about diversity, it makes the EDRL trained on a finite-horizon\ngeneralised to the infinite-horizon scenario without deterioration of content\nquality. Moreover, we verify the quality and diversity of contents generated by\nEDRL via empirical studies on the widely used Super Mario Bros. benchmark.\nExperimental results reveal that the current EDRL approach's ability of\ngenerating diverse game levels is limited due to the state space closure,\nwhereas it does not suffer from reward deterioration given a horizon longer\nthan the one of training. Concluding our findings and analysis, we argue that\nfuture works in generating online diverse and high-quality contents via EDRL\nshould address the issue of diversity on the premise of state space closure\nwhich ensures the quality.",
    "descriptor": "",
    "authors": [
      "Ziqi Wang",
      "Tianye Shu",
      "Jialin Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02951"
  },
  {
    "id": "arXiv:2212.02952",
    "title": "Simple Baseline for Weather Forecasting Using Spatiotemporal Context  Aggregation Network",
    "abstract": "Traditional weather forecasting relies on domain expertise and\ncomputationally intensive numerical simulation systems. Recently, with the\ndevelopment of a data-driven approach, weather forecasting based on deep\nlearning has been receiving attention. Deep learning-based weather forecasting\nhas made stunning progress, from various backbone studies using CNN, RNN, and\nTransformer to training strategies using weather observations datasets with\nauxiliary inputs. All of this progress has contributed to the field of weather\nforecasting; however, many elements and complex structures of deep learning\nmodels prevent us from reaching physical interpretations. This paper proposes a\nSImple baseline with a spatiotemporal context Aggregation Network (SIANet) that\nachieved state-of-the-art in 4 parts of 5 benchmarks of W4C22. This simple but\nefficient structure uses only satellite images and CNNs in an end-to-end\nfashion without using a multi-model ensemble or fine-tuning. This simplicity of\nSIANet can be used as a solid baseline that can be easily applied in weather\nforecasting using deep learning.",
    "descriptor": "\nComments: 1st place solution for stage1 and Core Transfer in the Weather4Cast competition on NeurIPS 22\n",
    "authors": [
      "Minseok Seo",
      "Doyi Kim",
      "Seungheon Shin",
      "Eunbin Kim",
      "Sewoong Ahn",
      "Yeji Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02952"
  },
  {
    "id": "arXiv:2212.02954",
    "title": "A Cost-Efficient Space-Time Adaptive Algorithm for Coupled Flow and  Transport",
    "abstract": "In this work, a cost-efficient space-time adaptive algorithm based on the\nDual Weighted Residual (DWR) method is developed and studied for a coupled\nmodel problem of flow and convection-dominated transport. Key ingredients are a\nmultirate approach adapted to varying dynamics in time of the subproblems,\nweighted and non-weighted error indicators for the transport and flow problem,\nrespectively, and the concept of space-time slabs based on tensor product\nspaces for the data structure. In numerical examples the performance of the\nunderlying algorithm is studied for benchmark problems and applications of\npractical interest. Moreover, the interaction of stabilization and\ngoal-oriented adaptivity is investigated for strongly convection-dominated\ntransport.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.03748. text overlap with arXiv:2202.03748\n",
    "authors": [
      "Marius Paul Bruchh\u00e4user",
      "Markus Bause"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.02954"
  },
  {
    "id": "arXiv:2212.02955",
    "title": "Solving Rearrangement Puzzles using Path Defragmentation in Factored  State Spaces",
    "abstract": "Rearrangement puzzles are variations of rearrangement problems in which the\nelements of a problem are potentially logically linked together. To efficiently\nsolve such puzzles, we develop a motion planning approach based on a new state\nspace that is logically factored, integrating the capabilities of the robot\nthrough factors of simultaneously manipulatable joints of an object. Based on\nthis factored state space, we propose less-actions RRT (LA-RRT), a planner\nwhich optimizes for a low number of actions to solve a puzzle. At the core of\nour approach lies a new path defragmentation method, which rearranges and\noptimizes consecutive edges to minimize action cost. We solve six rearrangement\nscenarios with a Fetch robot, involving planar table puzzles and an escape room\nscenario. LA-RRT significantly outperforms the next best asymptotically-optimal\nplanner by 4.01 to 6.58 times improvement in final action cost.",
    "descriptor": "\nComments: 8 pages, 9 figures, submitted to RAL\n",
    "authors": [
      "S. Bora Bayraktar",
      "Andreas Orthey",
      "Zachary Kingston",
      "Marc Toussaint",
      "Lydia E. Kavraki"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.02955"
  },
  {
    "id": "arXiv:2212.02963",
    "title": "SDM: Spatial Diffusion Model for Large Hole Image Inpainting",
    "abstract": "Generative adversarial networks (GANs) have made great success in image\ninpainting yet still have difficulties tackling large missing regions. In\ncontrast, iterative algorithms, such as autoregressive and denoising diffusion\nmodels, have to be deployed with massive computing resources for decent effect.\nTo overcome the respective limitations, we present a novel spatial diffusion\nmodel (SDM) that uses a few iterations to gradually deliver informative pixels\nto the entire image, largely enhancing the inference efficiency. Also, thanks\nto the proposed decoupled probabilistic modeling and spatial diffusion scheme,\nour method achieves high-quality large-hole completion. On multiple benchmarks,\nwe achieve new state-of-the-art performance. Code is released at\nhttps://github.com/fenglinglwb/SDM.",
    "descriptor": "\nComments: 18 pages, 14 figures\n",
    "authors": [
      "Wenbo Li",
      "Xin Yu",
      "Kun Zhou",
      "Yibing Song",
      "Zhe Lin",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02963"
  },
  {
    "id": "arXiv:2212.02968",
    "title": "Domain Generalization Strategy to Train Classifiers Robust to  Spatial-Temporal Shift",
    "abstract": "Deep learning-based weather prediction models have advanced significantly in\nrecent years. However, data-driven models based on deep learning are difficult\nto apply to real-world applications because they are vulnerable to\nspatial-temporal shifts. A weather prediction task is especially susceptible to\nspatial-temporal shifts when the model is overfitted to locality and\nseasonality. In this paper, we propose a training strategy to make the weather\nprediction model robust to spatial-temporal shifts. We first analyze the effect\nof hyperparameters and augmentations of the existing training strategy on the\nspatial-temporal shift robustness of the model. Next, we propose an optimal\ncombination of hyperparameters and augmentation based on the analysis results\nand a test-time augmentation. We performed all experiments on the W4C22\nTransfer dataset and achieved the 1st performance.",
    "descriptor": "\nComments: Core Transfer Track 1st place solution in Weather4Cast competition at NeuIPS22\n",
    "authors": [
      "Minseok Seo",
      "Doyi Kim",
      "Seungheon Shin",
      "Eunbin Kim",
      "Sewoong Ahn",
      "Yeji Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02968"
  },
  {
    "id": "arXiv:2212.02969",
    "title": "Open World DETR: Transformer based Open World Object Detection",
    "abstract": "Open world object detection aims at detecting objects that are absent in the\nobject classes of the training data as unknown objects without explicit\nsupervision. Furthermore, the exact classes of the unknown objects must be\nidentified without catastrophic forgetting of the previous known classes when\nthe corresponding annotations of unknown objects are given incrementally. In\nthis paper, we propose a two-stage training approach named Open World DETR for\nopen world object detection based on Deformable DETR. In the first stage, we\npre-train a model on the current annotated data to detect objects from the\ncurrent known classes, and concurrently train an additional binary classifier\nto classify predictions into foreground or background classes. This helps the\nmodel to build an unbiased feature representations that can facilitate the\ndetection of unknown classes in subsequent process. In the second stage, we\nfine-tune the class-specific components of the model with a multi-view\nself-labeling strategy and a consistency constraint. Furthermore, we alleviate\ncatastrophic forgetting when the annotations of the unknown classes becomes\navailable incrementally by using knowledge distillation and exemplar replay.\nExperimental results on PASCAL VOC and MS-COCO show that our proposed method\noutperforms other state-of-the-art open world object detection methods by a\nlarge margin.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Na Dong",
      "Yongqiang Zhang",
      "Mingli Ding",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02969"
  },
  {
    "id": "arXiv:2212.02973",
    "title": "UAS Simulator for Modeling, Analysis and Control in Free Flight and  Physical Interaction",
    "abstract": "This paper presents the ARCAD simulator for the rapid development of Unmanned\nAerial Systems (UAS), including underactuated and fully-actuated multirotors,\nfixed-wing aircraft, and Vertical Take-Off and Landing (VTOL) hybrid vehicles.\nThe simulator is designed to accelerate these aircraft's modeling and control\ndesign. It provides various analyses of the design and operation, such as\nwrench-set computation, controller response, and flight optimization. In\naddition to simulating free flight, it can simulate the physical interaction of\nthe aircraft with its environment. The simulator is written in MATLAB to allow\nrapid prototyping and is capable of generating graphical visualization of the\naircraft and the environment in addition to generating the desired plots. It\nhas been used to develop several real-world multirotor and VTOL applications.\nThe source code is available at\nhttps://github.com/keipour/aircraft-simulator-matlab.",
    "descriptor": "\nComments: Accepted to 2023 AIAA SciTech Forum. American Institute of Aeronautics and Astronautics\n",
    "authors": [
      "Azarakhsh Keipour",
      "Mohammadreza Mousaei",
      "Dongwei Bai",
      "Junyi Geng",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.02973"
  },
  {
    "id": "arXiv:2212.02974",
    "title": "CySecBERT: A Domain-Adapted Language Model for the Cybersecurity Domain",
    "abstract": "The field of cybersecurity is evolving fast. Experts need to be informed\nabout past, current and - in the best case - upcoming threats, because attacks\nare becoming more advanced, targets bigger and systems more complex. As this\ncannot be addressed manually, cybersecurity experts need to rely on machine\nlearning techniques. In the texutual domain, pre-trained language models like\nBERT have shown to be helpful, by providing a good baseline for further\nfine-tuning. However, due to the domain-knowledge and many technical terms in\ncybersecurity general language models might miss the gist of textual\ninformation, hence doing more harm than good. For this reason, we create a\nhigh-quality dataset and present a language model specifically tailored to the\ncybersecurity domain, which can serve as a basic building block for\ncybersecurity systems that deal with natural language. The model is compared\nwith other models based on 15 different domain-dependent extrinsic and\nintrinsic tasks as well as general tasks from the SuperGLUE benchmark. On the\none hand, the results of the intrinsic tasks show that our model improves the\ninternal representation space of words compared to the other models. On the\nother hand, the extrinsic, domain-dependent tasks, consisting of sequence\ntagging and classification, show that the model is best in specific application\nscenarios, in contrast to the others. Furthermore, we show that our approach\nagainst catastrophic forgetting works, as the model is able to retrieve the\npreviously trained domain-independent knowledge. The used dataset and trained\nmodel are made publicly available",
    "descriptor": "\nComments: 13 Pages, 7 tables, 1 figure\n",
    "authors": [
      "Markus Bayer",
      "Philipp Kuehn",
      "Ramin Shanehsaz",
      "Christian Reuter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.02974"
  },
  {
    "id": "arXiv:2212.02977",
    "title": "Denoising diffusion probabilistic models for probabilistic energy  forecasting",
    "abstract": "Scenario-based probabilistic forecasts have become a vital tool to equip\ndecision-makers to address the uncertain nature of renewable energies. This\npaper presents a recent promising deep learning generative approach: denoising\ndiffusion probabilistic models. It is a class of latent variable models that\nhave recently demonstrated impressive results in the computer vision community.\nHowever, to the best of our knowledge, there has yet to be a demonstration that\nthey can generate high-quality samples of load, PV, or wind power time series\nthat are crucial to face the new challenges in power systems applications.\nThus, we propose the first implementation of this model for energy forecasting\nusing the open data of the Global Energy Forecasting Competition 2014. The\nresults demonstrate that this approach is competitive with other\nstate-of-the-art deep learning generative models: generative adversarial\nnetworks, variational autoencoders, and normalizing flows.",
    "descriptor": "\nComments: Version submitted to Powertech 2023. arXiv admin note: text overlap with arXiv:2106.09370, arXiv:2107.01034. text overlap with arXiv:2106.09370, arXiv:2107.01034\n",
    "authors": [
      "Esteban Hernandez",
      "Jonathan Dumas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02977"
  },
  {
    "id": "arXiv:2212.02978",
    "title": "Muscles in Action",
    "abstract": "Small differences in a person's motion can engage drastically different\nmuscles. While most visual representations of human activity are trained from\nvideo, people learn from multimodal experiences, including from the\nproprioception of their own muscles. We present a new visual perception task\nand dataset to model muscle activation in human activities from monocular\nvideo. Our Muscles in Action (MIA) dataset consists of 2 hours of synchronized\nvideo and surface electromyography (sEMG) data of subjects performing various\nexercises. Using this dataset, we learn visual representations that are\npredictive of muscle activation from monocular video. We present several\nmodels, including a transformer model, and measure their ability to generalize\nto new exercises and subjects. Putting muscles into computer vision systems\nwill enable richer models of virtual humans, with applications in sports,\nfitness, and AR/VR.",
    "descriptor": "",
    "authors": [
      "Mia Chiquier",
      "Carl Vondrick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2212.02978"
  },
  {
    "id": "arXiv:2212.02985",
    "title": "Multi-Layer Personalized Federated Learning for Mitigating Biases in  Student Predictive Analytics",
    "abstract": "Traditional learning-based approaches to student modeling (e.g., predicting\ngrades based on measured activities) generalize poorly to\nunderrepresented/minority student groups due to biases in data availability. In\nthis paper, we propose a Multi-Layer Personalized Federated Learning (MLPFL)\nmethodology which optimizes inference accuracy over different layers of student\ngrouping criteria, such as by course and by demographic subgroups within each\ncourse. In our approach, personalized models for individual student subgroups\nare derived from a global model, which is trained in a distributed fashion via\nmeta-gradient updates that account for subgroup heterogeneity while preserving\nmodeling commonalities that exist across the full dataset. To evaluate our\nmethodology, we consider case studies of two popular downstream student\nmodeling tasks, knowledge tracing and outcome prediction, which leverage\nmultiple modalities of student behavior (e.g., visits to lecture videos and\nparticipation on forums) in model training. Experiments on three real-world\ndatasets from online courses demonstrate that our approach obtains substantial\nimprovements over existing student modeling baselines in terms of increasing\nthe average and decreasing the variance of prediction quality across different\nstudent subgroups. Visual analysis of the resulting students' knowledge state\nembeddings confirm that our personalization methodology extracts activity\npatterns which cluster into different student subgroups, consistent with the\nperformance enhancements we obtain over the baselines.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2208.01182\n",
    "authors": [
      "Yun-Wei Chu",
      "Seyyedali Hosseinalipour",
      "Elizabeth Tenorio",
      "Laura Cruz",
      "Kerrie Douglas",
      "Andrew Lan",
      "Christopher Brinton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.02985"
  },
  {
    "id": "arXiv:2212.02988",
    "title": "PRISM: Probabilistic Real-Time Inference in Spatial World Models",
    "abstract": "We introduce PRISM, a method for real-time filtering in a probabilistic\ngenerative model of agent motion and visual perception. Previous approaches\neither lack uncertainty estimates for the map and agent state, do not run in\nreal-time, do not have a dense scene representation or do not model agent\ndynamics. Our solution reconciles all of these aspects. We start from a\npredefined state-space model which combines differentiable rendering and 6-DoF\ndynamics. Probabilistic inference in this model amounts to simultaneous\nlocalisation and mapping (SLAM) and is intractable. We use a series of\napproximations to Bayesian inference to arrive at probabilistic map and state\nestimates. We take advantage of well-established methods and closed-form\nupdates, preserving accuracy and enabling real-time capability. The proposed\nsolution runs at 10Hz real-time and is similarly accurate to state-of-the-art\nSLAM in small to medium-sized indoor environments, with high-speed UAV and\nhandheld camera agents (Blackbird, EuRoC and TUM-RGBD).",
    "descriptor": "\nComments: Will appear in PMLR, CoRL 2022\n",
    "authors": [
      "Atanas Mirchev",
      "Baris Kayalibay",
      "Ahmed Agha",
      "Patrick van der Smagt",
      "Daniel Cremers",
      "Justin Bayer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.02988"
  },
  {
    "id": "arXiv:2212.02992",
    "title": "Sparse Message Passing Network with Feature Integration for Online  Multiple Object Tracking",
    "abstract": "Existing Multiple Object Tracking (MOT) methods design complex architectures\nfor better tracking performance. However, without a proper organization of\ninput information, they still fail to perform tracking robustly and suffer from\nfrequent identity switches. In this paper, we propose two novel methods\ntogether with a simple online Message Passing Network (MPN) to address these\nlimitations. First, we explore different integration methods for the graph node\nand edge embeddings and put forward a new IoU (Intersection over Union) guided\nfunction, which improves long term tracking and handles identity switches.\nSecond, we introduce a hierarchical sampling strategy to construct sparser\ngraphs which allows to focus the training on more difficult samples.\nExperimental results demonstrate that a simple online MPN with these two\ncontributions can perform better than many state-of-the-art methods. In\naddition, our association method generalizes well and can also improve the\nresults of private detection based methods.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Bisheng Wang",
      "Horst Possegger",
      "Horst Bischof",
      "Guo Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02992"
  },
  {
    "id": "arXiv:2212.02995",
    "title": "Knowledge-Bridged Causal Interaction Network for Causal Emotion  Entailment",
    "abstract": "Causal Emotion Entailment aims to identify causal utterances that are\nresponsible for the target utterance with a non-neutral emotion in\nconversations. Previous works are limited in thorough understanding of the\nconversational context and accurate reasoning of the emotion cause. To this\nend, we propose Knowledge-Bridged Causal Interaction Network (KBCIN) with\ncommonsense knowledge (CSK) leveraged as three bridges. Specifically, we\nconstruct a conversational graph for each conversation and leverage the\nevent-centered CSK as the semantics-level bridge (S-bridge) to capture the deep\ninter-utterance dependencies in the conversational context via the CSK-Enhanced\nGraph Attention module. Moreover, social-interaction CSK serves as\nemotion-level bridge (E-bridge) and action-level bridge (A-bridge) to connect\ncandidate utterances with the target one, which provides explicit causal clues\nfor the Emotional Interaction module and Actional Interaction module to reason\nthe target emotion. Experimental results show that our model achieves better\nperformance over most baseline models. Our source code is publicly available at\nhttps://github.com/circle-hit/KBCIN.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Weixiang Zhao",
      "Yanyan Zhao",
      "Zhuojun Li",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.02995"
  },
  {
    "id": "arXiv:2212.02997",
    "title": "Weakly-Supervised Gaze Estimation from Synthetic Views",
    "abstract": "3D gaze estimation is most often tackled as learning a direct mapping between\ninput images and the gaze vector or its spherical coordinates. Recently, it has\nbeen shown that pose estimation of the face, body and hands benefits from\nrevising the learning target from few pose parameters to dense 3D coordinates.\nIn this work, we leverage this observation and propose to tackle 3D gaze\nestimation as regression of 3D eye meshes. We overcome the absence of\ncompatible ground truth by fitting a rigid 3D eyeball template on existing gaze\ndatasets and propose to improve generalization by making use of widely\navailable in-the-wild face images. To this end, we propose an automatic\npipeline to retrieve robust gaze pseudo-labels from arbitrary face images and\ndesign a multi-view supervision framework to balance their effect during\ntraining. In our experiments, our method achieves improvement of 30% compared\nto state-of-the-art in cross-dataset gaze estimation, when no ground truth data\nare available for training, and 7% when they are. We make our project publicly\navailable at https://github.com/Vagver/dense3Deyes.",
    "descriptor": "\nComments: 10 pages, 15 figures\n",
    "authors": [
      "Evangelos Ververas",
      "Polydefkis Gkagkos",
      "Jiankang Deng",
      "Jia Guo",
      "Michail Christos Doukas",
      "Stefanos Zafeiriou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02997"
  },
  {
    "id": "arXiv:2212.02998",
    "title": "Super-resolution Probabilistic Rain Prediction from Satellite Data Using  3D U-Nets and EarthFormers",
    "abstract": "Accurate and timely rain prediction is crucial for decision making and is\nalso a challenging task. This paper presents a solution which won the 2 nd\nprize in the Weather4cast 2022 NeurIPS competition using 3D U-Nets and\nEarthFormers for 8-hour probabilistic rain prediction based on multi-band\nsatellite images. The spatial context effect of the input satellite image has\nbeen deeply explored and optimal context range has been found. Based on the\nimbalanced rain distribution, we trained multiple models with different loss\nfunctions. To further improve the model performance, multi-model ensemble and\nthreshold optimization were used to produce the final probabilistic rain\nprediction. Experiment results and leaderboard scores demonstrate that optimal\nspatial context, combined loss function, multi-model ensemble, and threshold\noptimization all provide modest model gain. A permutation test was used to\nanalyze the effect of each satellite band on rain prediction, and results show\nthat satellite bands signifying cloudtop phase (8.7 um) and cloud-top height\n(10.8 and 13.4 um) are the best predictors for rain prediction. The source code\nis available at https://github.com/bugsuse/weather4cast-2022-stage2.",
    "descriptor": "\nComments: Weather4cast-2022 & NeurIPS\n",
    "authors": [
      "Yang Li",
      "Haiyu Dong",
      "Zuliang Fang",
      "Jonathan Weyn",
      "Pete Luferenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02998"
  },
  {
    "id": "arXiv:2212.03000",
    "title": "SODA: A Natural Language Processing Package to Extract Social  Determinants of Health for Cancer Studies",
    "abstract": "Objective: We aim to develop an open-source natural language processing (NLP)\npackage, SODA (i.e., SOcial DeterminAnts), with pre-trained transformer models\nto extract social determinants of health (SDoH) for cancer patients, examine\nthe generalizability of SODA to a new disease domain (i.e., opioid use), and\nevaluate the extraction rate of SDoH using cancer populations.\nMethods: We identified SDoH categories and attributes and developed an SDoH\ncorpus using clinical notes from a general cancer cohort. We compared four\ntransformer-based NLP models to extract SDoH, examined the generalizability of\nNLP models to a cohort of patients prescribed with opioids, and explored\ncustomization strategies to improve performance. We applied the best NLP model\nto extract 19 categories of SDoH from the breast (n=7,971), lung (n=11,804),\nand colorectal cancer (n=6,240) cohorts.\nResults and Conclusion: We developed a corpus of 629 cancer patients notes\nwith annotations of 13,193 SDoH concepts/attributes from 19 categories of SDoH.\nThe Bidirectional Encoder Representations from Transformers (BERT) model\nachieved the best strict/lenient F1 scores of 0.9216 and 0.9441 for SDoH\nconcept extraction, 0.9617 and 0.9626 for linking attributes to SDoH concepts.\nFine-tuning the NLP models using new annotations from opioid use patients\nimproved the strict/lenient F1 scores from 0.8172/0.8502 to 0.8312/0.8679. The\nextraction rates among 19 categories of SDoH varied greatly, where 10 SDoH\ncould be extracted from >70% of cancer patients, but 9 SDoH had a low\nextraction rate (<70% of cancer patients). The SODA package with pre-trained\ntransformer models is publicly available at\nhttps://github.com/uf-hobiinformatics-lab/SDoH_SODA.",
    "descriptor": "",
    "authors": [
      "Zehao Yu",
      "Xi Yang",
      "Chong Dang",
      "Prakash Adekkanattu",
      "Braja Gopal Patra",
      "Yifan Peng",
      "Jyotishman Pathak",
      "Debbie L. Wilson",
      "Ching-Yuan Chang",
      "Wei-Hsuan Lo-Ciganic",
      "Thomas J. George",
      "William R. Hogan",
      "Yi Guo",
      "Jiang Bian",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03000"
  },
  {
    "id": "arXiv:2212.03002",
    "title": "Supervised Image Segmentation for High Dynamic Range Imaging",
    "abstract": "Regular cameras and cell phones are able to capture limited luminosity. Thus,\nin terms of quality, most of the produced images from such devices are not\nsimilar to the real world. They are overly dark or too bright, and the details\nare not perfectly visible. Various methods, which fall under the name of High\nDynamic Range (HDR) Imaging, can be utilised to cope with this problem. Their\nobjective is to produce an image with more details. However, unfortunately,\nmost methods for generating an HDR image from Multi-Exposure images only\nconcentrate on how to combine different exposures and do not have any focus on\nchoosing the best details of each image. Therefore, it is strived in this\nresearch to extract the most visible areas of each image with the help of image\nsegmentation. Two methods of producing the Ground Truth were considered, as\nmanual threshold and Otsu threshold, and a neural network will be used to train\nsegment these areas. Finally, it will be shown that the neural network is able\nto segment the visible parts of pictures acceptably.",
    "descriptor": "",
    "authors": [
      "Ali Reza Omrani",
      "Davide Moroni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.03002"
  },
  {
    "id": "arXiv:2212.03008",
    "title": "A Strongly Polynomial Algorithm for Approximate Forster Transforms and  its Application to Halfspace Learning",
    "abstract": "The Forster transform is a method of regularizing a dataset by placing it in\n{\\em radial isotropic position} while maintaining some of its essential\nproperties. Forster transforms have played a key role in a diverse range of\nsettings spanning computer science and functional analysis. Prior work had\ngiven {\\em weakly} polynomial time algorithms for computing Forster transforms,\nwhen they exist. Our main result is the first {\\em strongly polynomial time}\nalgorithm to compute an approximate Forster transform of a given dataset or\ncertify that no such transformation exists. By leveraging our strongly\npolynomial Forster algorithm, we obtain the first strongly polynomial time\nalgorithm for {\\em distribution-free} PAC learning of halfspaces. This learning\nresult is surprising because {\\em proper} PAC learning of halfspaces is {\\em\nequivalent} to linear programming. Our learning approach extends to give a\nstrongly polynomial halfspace learner in the presence of random classification\nnoise and, more generally, Massart noise.",
    "descriptor": "",
    "authors": [
      "Ilias Diakonikolas",
      "Christos Tzamos",
      "Daniel M. Kane"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.03008"
  },
  {
    "id": "arXiv:2212.03010",
    "title": "GD-MAE: Generative Decoder for MAE Pre-training on LiDAR Point Clouds",
    "abstract": "Despite the tremendous progress of Masked Autoencoders (MAE) in developing\nvision tasks such as image and video, exploring MAE in large-scale 3D point\nclouds remains challenging due to the inherent irregularity. In contrast to\nprevious 3D MAE frameworks, which either design a complex decoder to infer\nmasked information from maintained regions or adopt sophisticated masking\nstrategies, we instead propose a much simpler paradigm. The core idea is to\napply a \\textbf{G}enerative \\textbf{D}ecoder for MAE (GD-MAE) to automatically\nmerges the surrounding context to restore the masked geometric knowledge in a\nhierarchical fusion manner. In doing so, our approach is free from introducing\nthe heuristic design of decoders and enjoys the flexibility of exploring\nvarious masking strategies. The corresponding part costs less than\n\\textbf{12\\%} latency compared with conventional methods, while achieving\nbetter performance. We demonstrate the efficacy of the proposed method on\nseveral large-scale benchmarks: Waymo, KITTI, and ONCE. Consistent improvement\non downstream detection tasks illustrates strong robustness and generalization\ncapability. Not only our method reveals state-of-the-art results, but\nremarkably, we achieve comparable accuracy even with \\textbf{20\\%} of the\nlabeled data on the Waymo dataset. The code will be released at\n\\url{https://github.com/Nightmare-n/GD-MAE}.",
    "descriptor": "",
    "authors": [
      "Honghui Yang",
      "Tong He",
      "Jiaheng Liu",
      "Hua Chen",
      "Boxi Wu",
      "Binbin Lin",
      "Xiaofei He",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03010"
  },
  {
    "id": "arXiv:2212.03012",
    "title": "Estimating Cardiac Tissue Conductivity from Electrograms with Fully  Convolutional Networks",
    "abstract": "Atrial Fibrillation (AF) is characterized by disorganised electrical activity\nin the atria and is known to be sustained by the presence of regions of\nfibrosis (scars) or functional cellular remodeling, both of which may lead to\nareas of slow conduction. Estimating the effective conductivity of the\nmyocardium and identifying regions of abnormal propagation is therefore crucial\nfor the effective treatment of AF. We hypothesise that the spatial distribution\nof tissue conductivity can be directly inferred from an array of concurrently\nacquired contact electrograms (EGMs). We generate a dataset of simulated\ncardiac AP propagation using randomised scar distributions and a\nphenomenological cardiac model and calculate contact electrograms at various\npositions on the field. A deep neural network, based on a modified U-net\narchitecture, is trained to estimate the location of the scar and quantify\nconductivity of the tissue with a Jaccard index of $91$%. We adapt a\nwavelet-based surrogate testing analysis to confirm that the inferred\nconductivity distribution is an accurate representation of the ground truth\ninput to the model. We find that the root mean square error (RMSE) between the\nground truth and our predictions is significantly smaller ($p_{val}=0.007$)\nthan the RMSE between the ground truth and surrogate samples.",
    "descriptor": "\nComments: 15 pages, 13 figures\n",
    "authors": [
      "Konstantinos Ntagiantas",
      "Eduardo Pignatelli",
      "Nicholas S. Peters",
      "Chris D. Cantwell",
      "Rasheda A.Chowdhury",
      "Anil A. Bharath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2212.03012"
  },
  {
    "id": "arXiv:2212.03013",
    "title": "Document-Level Abstractive Summarization",
    "abstract": "The task of automatic text summarization produces a concise and fluent text\nsummary while preserving key information and overall meaning. Recent approaches\nto document-level summarization have seen significant improvements in recent\nyears by using models based on the Transformer architecture. However, the\nquadratic memory and time complexities with respect to the sequence length make\nthem very expensive to use, especially with long sequences, as required by\ndocument-level summarization. Our work addresses the problem of document-level\nsummarization by studying how efficient Transformer techniques can be used to\nimprove the automatic summarization of very long texts. In particular, we will\nuse the arXiv dataset, consisting of several scientific papers and the\ncorresponding abstracts, as baselines for this work. Then, we propose a novel\nretrieval-enhanced approach based on the architecture which reduces the cost of\ngenerating a summary of the entire document by processing smaller chunks. The\nresults were below the baselines but suggest a more efficient memory a\nconsumption and truthfulness.",
    "descriptor": "\nComments: This paper was made for an assignment of the Deep Structured Learning 2021/2022 course at Instituto Superior T\\'ecnico\n",
    "authors": [
      "Gon\u00e7alo Raposo",
      "Afonso Raposo",
      "Ana Sofia Carmo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.03013"
  },
  {
    "id": "arXiv:2212.03016",
    "title": "Online Min-Max Paging",
    "abstract": "Motivated by fairness requirements in communication networks, we introduce a\nnatural variant of the online paging problem, called \\textit{min-max} paging,\nwhere the objective is to minimize the maximum number of faults on any page.\nWhile the classical paging problem, whose objective is to minimize the total\nnumber of faults, admits $k$-competitive deterministic and $O(\\log\nk)$-competitive randomized algorithms, we show that min-max paging does not\nadmit a $c(k)$-competitive algorithm for any function $c$. Specifically, we\nprove that the randomized competitive ratio of min-max paging is\n$\\Omega(\\log(n))$ and its deterministic competitive ratio is\n$\\Omega(k\\log(n)/\\log(k))$, where $n$ is the total number of pages ever\nrequested.\nWe design a fractional algorithm for paging with a more general objective --\nminimize the value of an $n$-variate differentiable convex function applied to\nthe vector of the number of faults on each page. This gives an\n$O(\\log(n)\\log(k))$-competitive fractional algorithm for min-max paging. We\nshow how to round such a fractional algorithm with at most a $k$ factor loss in\nthe competitive ratio, resulting in a deterministic\n$O(k\\log(n)\\log(k))$-competitive algorithm for min-max paging. This matches our\nlower bound modulo a $\\mathrm{poly}(\\log(k))$ factor. We also give a randomized\nrounding algorithm that results in a $O(\\log^2 n \\log k)$-competitive\nalgorithm.",
    "descriptor": "\nComments: 25 pages, 1 figure, to appear in SODA 2023\n",
    "authors": [
      "Ashish Chiplunkar",
      "Monika Henzinger",
      "Sagar Sudhir Kale",
      "Maximilian V\u00f6tsch"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.03016"
  },
  {
    "id": "arXiv:2212.03019",
    "title": "Style transfer and classification in hebrew news items",
    "abstract": "Hebrew is a Morphological rich language, making its modeling harder than\nsimpler language. Recent developments such as Transformers in general and Bert\nin particular opened a path for Hebrew models that reach SOTA results, not\nfalling short from other non-MRL languages. We explore the cutting edge in this\nfield performing style transfer, text generation and classification over news\narticles collected from online archives. Furthermore, the news portals that\nfeed our collective consciousness are an interesting corpus to study, as their\nanalysis and tracing might reveal insights about our society and discourse.",
    "descriptor": "\nComments: Published at ISCOL2022 as a poster. For generated Hebrew fake news articles, visit this https URL\n",
    "authors": [
      "Nir Weingarten"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03019"
  },
  {
    "id": "arXiv:2212.03022",
    "title": "Iterative Next Boundary Detection for Instance Segmentation of Tree  Rings in Microscopy Images of Shrub Cross Sections",
    "abstract": "We analyze the problem of detecting tree rings in microscopy images of shrub\ncross sections. This can be regarded as a special case of the instance\nsegmentation task with several particularities such as the concentric circular\nring shape of the objects and high precision requirements due to which existing\nmethods don't perform sufficiently well. We propose a new iterative method\nwhich we term Iterative Next Boundary Detection (INBD). It intuitively models\nthe natural growth direction, starting from the center of the shrub cross\nsection and detecting the next ring boundary in each iteration step. In our\nexperiments, INBD shows superior performance to generic instance segmentation\nmethods and is the only one with a built-in notion of chronological order. Our\ndataset and source code are available at this http URL",
    "descriptor": "",
    "authors": [
      "Alexander Gillert",
      "Giulia Resente",
      "Alba Anadon-Rosell",
      "Martin Wilmking",
      "Uwe Freiherr von Lukas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03022"
  },
  {
    "id": "arXiv:2212.03029",
    "title": "AbHE: All Attention-based Homography Estimation",
    "abstract": "Homography estimation is a basic computer vision task, which aims to obtain\nthe transformation from multi-view images for image alignment. Unsupervised\nlearning homography estimation trains a convolution neural network for feature\nextraction and transformation matrix regression. While the state-of-the-art\nhomography method is based on convolution neural networks, few work focuses on\ntransformer which shows superiority in high-level vision tasks. In this paper,\nwe propose a strong-baseline model based on the Swin Transformer, which\ncombines convolution neural network for local features and transformer module\nfor global features. Moreover, a cross non-local layer is introduced to search\nthe matched features within the feature maps coarsely.In the homography\nregression stage, we adopts an attention layer for the channels of correlation\nvolume, which can drop out some weak correlation feature points. The experiment\nshows that in 8 Degree-of-Freedoms(DOFs) homography estimation our methods\noverperform the state-of-the-art method.",
    "descriptor": "",
    "authors": [
      "Mingxiao Huo",
      "Zhihao Zhang",
      "Xianqiang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03029"
  },
  {
    "id": "arXiv:2212.03030",
    "title": "Improved Algebraic Degeneracy Testing",
    "abstract": "In the classical linear degeneracy testing problem, we are given $n$ real\nnumbers and a $k$-variate linear polynomial $F$, for some constant $k$, and\nhave to determine whether there exist $k$ numbers $a_1,\\ldots,a_k$ from the set\nsuch that $F(a_1,\\ldots,a_k) = 0$. We consider a generalization of this problem\nin which $F$ is an arbitrary constant-degree polynomial, we are given $k$ sets\nof $n$ numbers, and have to determine whether there exist a $k$-tuple of\nnumbers, one in each set, on which $F$ vanishes. We give the first improvement\nover the na\\\"ive $O^*(n^{k-1})$ algorithm for this problem (where the\n$O^*(\\cdot)$ notation omits subpolynomial factors).\nWe show that the problem can be solved in time $O^*\\left( n^{k - 2 + \\frac\n4{k+2}}\\right)$ for even $k$ and in time $O^*\\left( n^{k - 2 +\n\\frac{4k-8}{k^2-5}}\\right)$ for odd $k$ in the real RAM model of computation.\nWe also prove that for $k=4$, the problem can be solved in time\n$O^*(n^{2.625})$ in the algebraic decision tree model, and for $k=5$ it can be\nsolved in time $O^*(n^{3.56})$ in the same model, both improving on the above\nuniform bounds.\nAll our results rely on an algebraic generalization of the standard\nmeet-in-the-middle algorithm for $k$-SUM, powered by recent algorithmic\nadvances in the polynomial method for semi-algebraic range searching. In fact,\nour main technical result is much more broadly applicable, as it provides a\ngeneral tool for detecting incidences and other interactions between points and\nalgebraic surfaces in any dimension. In particular, it yields an efficient\nalgorithm for a general, algebraic version of Hopcroft's point-line incidence\ndetection problem in any dimension.",
    "descriptor": "\nComments: 16 pages, 2 figures\n",
    "authors": [
      "Jean Cardinal",
      "Micha Sharir"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.03030"
  },
  {
    "id": "arXiv:2212.03034",
    "title": "Integration of a systolic array based hardware accelerator into a DNN  operator auto-tuning framework",
    "abstract": "The deployment of neural networks on heterogeneous SoCs coupled with custom\naccelerators is a challenging task because of the lack of end-to-end software\ntools provided for these systems. Moreover, the already available low level\nschedules and mapping strategies provided by the accelerator developers for\ntypical tensor operations are not necessarily the best possible ones for each\nparticular use case. This is why frameworks which automatically test the\nperformance of the generated code on a specific hardware configuration are of\nspecial interest. In this work, the integration between the code generation\nframework TVM and the systolic array-based accelerator Gemmini is presented. A\ngeneric schedule to offload the GEneral Matrix Multiply (GEMM) tensor operation\nonto Gemmini is detailed, and its suitability is tested by executing the\nAutoTVM tuning process on it. Our generated code achieves a peak throughput of\n46 giga-operations per second (GOPs) under a 100 MHz clock on a Xilinx ZCU102\nFPGA, outperforming previous work. Furthermore, the code generated by this\nintegration was able to surpass the default hand-tuned schedules provided by\nthe Gemmini developers in real-world workloads.",
    "descriptor": "\nComments: 6 pages, 5 figures, submitted to the CODAI Workshop at the 2022 ESWEEK\n",
    "authors": [
      "F. N. Peccia",
      "O. Bringmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2212.03034"
  },
  {
    "id": "arXiv:2212.03035",
    "title": "IncepFormer: Efficient Inception Transformer with Pyramid Pooling for  Semantic Segmentation",
    "abstract": "Semantic segmentation usually benefits from global contexts, fine\nlocalisation information, multi-scale features, etc. To advance\nTransformer-based segmenters with these aspects, we present a simple yet\npowerful semantic segmentation architecture, termed as IncepFormer. IncepFormer\nhas two critical contributions as following. First, it introduces a novel\npyramid structured Transformer encoder which harvests global context and fine\nlocalisation features simultaneously. These features are concatenated and fed\ninto a convolution layer for final per-pixel prediction. Second, IncepFormer\nintegrates an Inception-like architecture with depth-wise convolutions, and a\nlight-weight feed-forward module in each self-attention layer, efficiently\nobtaining rich local multi-scale object features. Extensive experiments on five\nbenchmarks show that our IncepFormer is superior to state-of-the-art methods in\nboth accuracy and speed, e.g., 1) our IncepFormer-S achieves 47.7% mIoU on\nADE20K which outperforms the existing best method by 1% while only costs half\nparameters and fewer FLOPs. 2) Our IncepFormer-B finally achieves 82.0% mIoU on\nCityscapes dataset with 39.6M parameters. Code is\navailable:github.com/shendu0321/IncepFormer.",
    "descriptor": "\nComments: Preprint with 8 pages of main body and 3 pages of supplementary material\n",
    "authors": [
      "Lihua Fu",
      "Haoyue Tian",
      "Xiangping Bryce Zhai",
      "Pan Gao",
      "Xiaojiang Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03035"
  },
  {
    "id": "arXiv:2212.03038",
    "title": "Unifying Short and Long-Term Tracking with Graph Hierarchies",
    "abstract": "Tracking objects over long videos effectively means solving a spectrum of\nproblems, from short-term association for un-occluded objects to long-term\nassociation for objects that are occluded and then reappear in the scene.\nMethods tackling these two tasks are often disjoint and crafted for specific\nscenarios, and top-performing approaches are often a mix of techniques, which\nyields engineering-heavy solutions that lack generality. In this work, we\nquestion the need for hybrid approaches and introduce SUSHI, a unified and\nscalable multi-object tracker. Our approach processes long clips by splitting\nthem into a hierarchy of subclips, which enables high scalability. We leverage\ngraph neural networks to process all levels of the hierarchy, which makes our\nmodel unified across temporal scales and highly general. As a result, we obtain\nsignificant improvements over state-of-the-art on four diverse datasets. Our\ncode and models will be made available.",
    "descriptor": "",
    "authors": [
      "Orcun Cetintas",
      "Guillem Bras\u00f3",
      "Laura Leal-Taix\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03038"
  },
  {
    "id": "arXiv:2212.03039",
    "title": "Covariance Regularization for Probabilistic Linear Discriminant Analysis",
    "abstract": "Probabilistic linear discriminant analysis (PLDA) is commonly used in speaker\nverification systems to score the similarity of speaker embeddings. Recent\nstudies improved the performance of PLDA in domain-matched conditions by\ndiagonalizing its covariance. We suspect such brutal pruning approach could\neliminate its capacity in modeling dimension correlation of speaker embeddings,\nleading to inadequate performance with domain adaptation. This paper explores\ntwo alternative covariance regularization approaches, namely, interpolated PLDA\nand sparse PLDA, to tackle the problem. The interpolated PLDA incorporates the\nprior knowledge from cosine scoring to interpolate the covariance of PLDA. The\nsparse PLDA introduces a sparsity penalty to update the covariance.\nExperimental results demonstrate that both approaches outperform diagonal\nregularization noticeably with domain adaptation. In addition, in-domain data\ncan be significantly reduced when training sparse PLDA for domain adaptation.",
    "descriptor": "",
    "authors": [
      "Zhiyuan Peng",
      "Mingjie Shao",
      "Xuanji He",
      "Xu Li",
      "Tan Lee",
      "Ke Ding",
      "Guanglu Wan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.03039"
  },
  {
    "id": "arXiv:2212.03041",
    "title": "Towards a more efficient computation of individual attribute and policy  contribution for post-hoc explanation of cooperative multi-agent systems  using Myerson values",
    "abstract": "A quantitative assessment of the global importance of an agent in a team is\nas valuable as gold for strategists, decision-makers, and sports coaches. Yet,\nretrieving this information is not trivial since in a cooperative task it is\nhard to isolate the performance of an individual from the one of the whole\nteam. Moreover, it is not always clear the relationship between the role of an\nagent and his personal attributes. In this work we conceive an application of\nthe Shapley analysis for studying the contribution of both agent policies and\nattributes, putting them on equal footing. Since the computational complexity\nis NP-hard and scales exponentially with the number of participants in a\ntransferable utility coalitional game, we resort to exploiting a-priori\nknowledge about the rules of the game to constrain the relations between the\nparticipants over a graph. We hence propose a method to determine a\nHierarchical Knowledge Graph of agents' policies and features in a Multi-Agent\nSystem. Assuming a simulator of the system is available, the graph structure\nallows to exploit dynamic programming to assess the importances in a much\nfaster way. We test the proposed approach in a proof-of-case environment\ndeploying both hardcoded policies and policies obtained via Deep Reinforcement\nLearning. The proposed paradigm is less computationally demanding than\ntrivially computing the Shapley values and provides great insight not only into\nthe importance of an agent in a team but also into the attributes needed to\ndeploy the policy at its best.",
    "descriptor": "\nComments: Accepted for publication in Elsevier's Knowledge-Based Systems\n",
    "authors": [
      "Giorgio Angelotti",
      "Natalia D\u00edaz-Rodr\u00edguez"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2212.03041"
  },
  {
    "id": "arXiv:2212.03044",
    "title": "On the Importance of Clinical Notes in Multi-modal Learning for EHR Data",
    "abstract": "Understanding deep learning model behavior is critical to accepting machine\nlearning-based decision support systems in the medical community. Previous\nresearch has shown that jointly using clinical notes with electronic health\nrecord (EHR) data improved predictive performance for patient monitoring in the\nintensive care unit (ICU). In this work, we explore the underlying reasons for\nthese improvements. While relying on a basic attention-based model to allow for\ninterpretability, we first confirm that performance significantly improves over\nstate-of-the-art EHR data models when combining EHR data and clinical notes. We\nthen provide an analysis showing improvements arise almost exclusively from a\nsubset of notes containing broader context on patient state rather than\nclinician notes. We believe such findings highlight deep learning models for\nEHR data to be more limited by partially-descriptive data than by modeling\nchoice, motivating a more data-centric approach in the field.",
    "descriptor": "\nComments: Workshop on Learning from Time Series for Health, 36th Conference on Neural Information Processing Systems (NeurIPS 2022) 15 pages (including appendices)\n",
    "authors": [
      "Severin Husmann",
      "Hugo Y\u00e8che",
      "Gunnar R\u00e4tsch",
      "Rita Kuznetsova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03044"
  },
  {
    "id": "arXiv:2212.03053",
    "title": "Control of Grid-Forming VSCs: A Perspective of Adaptive Fast/Slow  Internal Voltage Source",
    "abstract": "Grid-forming (GFM) capability requirements are increasingly imposed on\ngrid-connected voltage-source converters (VSCs). Under large grid disturbances,\nGFM-VSCs need to remain stable while providing GFM services. Yet, such\nobjectives, as pointed out in this paper, inherently lead to conflicting\nrequirements on the dynamics of internal voltage source (IVS) of GFM-VSCs,\ni.e., the fast IVS dynamics is needed to avoid the loss of synchronism with the\ngrid, whereas the slow IVS dynamics is preferred for maintaining GFM\ncapability. To tackle this challenge, an adaptive fast/slow IVS control is\nproposed, which switches GFM-VSC between fast and slow IVS dynamics based on\nsystem needs. The proposed method enhances the transient stability of GFM-VSC,\nwhilst maximizing its capability of providing GFM service. Further, the\napproach is robust to different grid strengths and different types of grid\ndisturbances. The experimental results verify the theoretical findings and the\neffectiveness of the proposed control method.",
    "descriptor": "",
    "authors": [
      "Heng Wu",
      "Xiongfei Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.03053"
  },
  {
    "id": "arXiv:2212.03054",
    "title": "DisTRaC: Accelerating High Performance Compute Processing for Temporary  Data Storage",
    "abstract": "High Performance Compute (HPC) clusters often produce intermediate files as\npart of code execution and message passing is not always possible to supply\ndata to these cluster jobs. In these cases, I/O goes back to central\ndistributed storage to allow cross node data sharing. These systems are often\nhigh performance and characterised by their high cost per TB and sensitivity to\nworkload type such as being tuned to small or large file I/O. However, compute\nnodes often have large amounts of RAM, so when dealing with intermediate files\nwhere longevity or reliability of the system is not as important, local RAM\ndisks can be used to obtain performance benefits. In this paper we show how\nthis problem was tackled by creating a RAM block that could interact with the\nobject storage system Ceph, as well as creating a deployment tool to deploy\nCeph on HPC infrastructure effectively. This work resulted in a system that was\nmore performant than the central high performance distributed storage system\nused at Diamond reducing I/O overhead and processing time for Savu, a\ntomography data processing application, by 81.04% and 8.32% respectively.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Gabryel Mason-Williams",
      "Dave Bond",
      "Mark Basham"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2212.03054"
  },
  {
    "id": "arXiv:2212.03059",
    "title": "Exploring the Critical Success Factors for Data Democratization",
    "abstract": "With the advent of the Data Age, organisations are constantly under pressure\nto pay attention to the diffusion of data skills, data responsibilities, and\nmanagement of accessibility to data analysis tools for the technical as well as\nnon-technical employees. As such, in recent times, organisations are focusing\non data governance and management strategies such as data democratization. Data\ndemocratization is an ongoing process of broadening data access to employees to\nfind, access, self-analyse, and share data by removing data silos. By\ndemocratizing organisational data, organisations attempt to ensure that\nemployees can speak the language of data and empower them to use data\nefficiently to improve their business functionalities. This paper aims to\nidentify the critical success factors for data democratization through an\nin-depth review of the literature. Based on the findings of the analysis, nine\ncritical success factors were identified as successors of the data\ndemocratization strategy.",
    "descriptor": "",
    "authors": [
      "Sasari Samarasinghe",
      "Sachithra Lokuge"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.03059"
  },
  {
    "id": "arXiv:2212.03061",
    "title": "Data-driven Innovation: Understanding the Direction for Future Research",
    "abstract": "In the contemporary age of information, organisations have realised the\nimportance of data to innovate and thereby attain a competitive advantage. As a\nresult, firms are more focused on understanding the potential to achieve\ndata-driven innovation (DDI). Researchers too have focused on examining this\nnovel phenomenon in a broader scope. In this study, we conducted a systematic\nand comprehensive review of the literature to understand the DDI phenomenon.\nThe findings of this study benefit scholars in determining the gaps in the\ncurrent body of knowledge as well as for practitioners to improve their data\nstrategy to enhance and develop innovation capabilities.",
    "descriptor": "",
    "authors": [
      "Sasari Samarasinghe",
      "Sachithra Lokuge"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.03061"
  },
  {
    "id": "arXiv:2212.03063",
    "title": "Front-door Adjustment via Style Transfer for Out-of-distribution  Generalisation",
    "abstract": "Out-of-distribution (OOD) generalisation aims to build a model that can well\ngeneralise its learnt knowledge from source domains to an unseen target domain.\nHowever, current image classification models often perform poorly in the OOD\nsetting due to statistically spurious correlations learning from model\ntraining. From causality-based perspective, we formulate the data generation\nprocess in OOD image classification using a causal graph. On this graph, we\nshow that prediction P(Y|X) of a label Y given an image X in statistical\nlearning is formed by both causal effect P(Y|do(X)) and spurious effects caused\nby confounding features (e.g., background). Since the spurious features are\ndomain-variant, the prediction P(Y|X) becomes unstable on unseen domains. In\nthis paper, we propose to mitigate the spurious effect of confounders using\nfront-door adjustment. In our method, the mediator variable is hypothesized as\nsemantic features that are essential to determine a label for an image.\nInspired by capability of style transfer in image generation, we interpret the\ncombination of the mediator variable with different generated images in the\nfront-door formula and propose novel algorithms to estimate it. Extensive\nexperimental results on widely used benchmark datasets verify the effectiveness\nof our method.",
    "descriptor": "\nComments: 22 pages, 15 figures\n",
    "authors": [
      "Toan Nguyen",
      "Kien Do",
      "Duc Thanh Nguyen",
      "Bao Duong",
      "Thin Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.03063"
  },
  {
    "id": "arXiv:2212.03067",
    "title": "Pareto Optimal Compression of Genomic Dictionaries, with or without  Random Access in Main Memory",
    "abstract": "Motivation: A Genomic Dictionary, i.e., the set of the k-mers appearing in a\ngenome, is a fundamental source of genomic information: its collection is the\nfirst step in strategic computational methods ranging from assembly to sequence\ncomparison and phylogeny. Unfortunately, it is costly to store. This motivates\nsome recent studies regarding the compression of those k-mer sets. However,\nsuch an area does not have the maturity of genomic compression, lacking an\nhomogeneous and methodologically sound experimental foundation that allows to\nfairly compare the relative merits of the available solutions, and that takes\ninto account also the rich choices of compression methods that can be used.\nResults: We provide such a foundation here, supporting it with an extensive\nset of experiments that use reference datasets and a carefully selected set of\nrepresentative data compressors. Our results highlight the spectrum of\ncompressor choices one has in terms of Pareto Optimality of compression vs.\npost-processing, this latter being important when the Dictionary needs to be\ndecompressed many times. In addition to the useful indications, not available\nelsewhere, that this study offers to the researchers interested in storing\nk-mer dictionaries in compressed form, a software system that can be readily\nused to explore the Pareto Optimal solutions available r a given Dictionary is\nalso provided.\nAvailability: The software system is available at\nhttps://github.com/GenGrim76/Pareto-Optimal-GDC, together with user manuals and\ninstallation instructions.\nContact: raffaele.giancarlo@unipa.it\nSupplementary information: Additional data are available in the Supplementary\nMaterial.",
    "descriptor": "\nComments: Main: 13 pages, 3 tables, 3 figures; Supplementary Material: 17 pages, 20 tables, 10 figures\n",
    "authors": [
      "Raffaele Giancarlo",
      "Gennaro Grimaudo"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2212.03067"
  },
  {
    "id": "arXiv:2212.03068",
    "title": "Active Classification of Moving Targets with Learned Control Policies",
    "abstract": "In this paper, we consider the problem where a drone has to collect semantic\ninformation to classify multiple moving targets. In particular, we address the\nchallenge of computing control inputs that move the drone to informative\nviewpoints, position and orientation, when the information is extracted using a\n``black-box'' classifier, e.g., a deep learning neural network. These\nalgorithms typically lack of analytical relationships between the viewpoints\nand their associated outputs, preventing their use in information-gathering\nschemes. To fill this gap, we propose a novel attention-based architecture,\ntrained via Reinforcement Learning (RL), that outputs the next viewpoint for\nthe drone favoring the acquisition of evidence from as many unclassified\ntargets as possible while reasoning about their movement, orientation, and\nocclusions. Then, we use a low-level MPC controller to move the drone to the\ndesired viewpoint taking into account its actual dynamics. We show that our\napproach not only outperforms a variety of baselines but also generalizes to\nscenarios unseen during training. Additionally, we show that the network scales\nto large numbers of targets and generalizes well to different movement dynamics\nof the targets.",
    "descriptor": "\nComments: 8 pages, 6 figures, Submitted to IEEE RA-L\n",
    "authors": [
      "\u00c1lvaro Serra-G\u00f3mez",
      "Eduardo Montijano",
      "Wendelin B\u00f6hmer",
      "Javier Alonso-Mora"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.03068"
  },
  {
    "id": "arXiv:2212.03069",
    "title": "Multiple Perturbation Attack: Attack Pixelwise Under Different  $\\ell_p$-norms For Better Adversarial Performance",
    "abstract": "Adversarial machine learning has been both a major concern and a hot topic\nrecently, especially with the ubiquitous use of deep neural networks in the\ncurrent landscape. Adversarial attacks and defenses are usually likened to a\ncat-and-mouse game in which defenders and attackers evolve over the time. On\none hand, the goal is to develop strong and robust deep networks that are\nresistant to malicious actors. On the other hand, in order to achieve that, we\nneed to devise even stronger adversarial attacks to challenge these defense\nmodels. Most of existing attacks employs a single $\\ell_p$ distance (commonly,\n$p\\in\\{1,2,\\infty\\}$) to define the concept of closeness and performs steepest\ngradient ascent w.r.t. this $p$-norm to update all pixels in an adversarial\nexample in the same way. These $\\ell_p$ attacks each has its own pros and cons;\nand there is no single attack that can successfully break through defense\nmodels that are robust against multiple $\\ell_p$ norms simultaneously.\nMotivated by these observations, we come up with a natural approach: combining\nvarious $\\ell_p$ gradient projections on a pixel level to achieve a joint\nadversarial perturbation. Specifically, we learn how to perturb each pixel to\nmaximize the attack performance, while maintaining the overall visual\nimperceptibility of adversarial examples. Finally, through various experiments\nwith standardized benchmarks, we show that our method outperforms most current\nstrong attacks across state-of-the-art defense mechanisms, while retaining its\nability to remain clean visually.",
    "descriptor": "\nComments: 19 pages, 8 figures, 7 tables\n",
    "authors": [
      "Ngoc N. Tran",
      "Anh Tuan Bui",
      "Dinh Phung",
      "Trung Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03069"
  },
  {
    "id": "arXiv:2212.03071",
    "title": "Does IT Matter (Now)? A Global Panel Data Analysis of 7 Regions from  2018-2020 on Digitalization and its Impact on Economic Growth",
    "abstract": "There has been a long-running debate in Information Technology (IT) and\neconomics literature about the contrary arguments of IT concerning\ndigitalization and the economic growth of nations. While many empirical studies\nhave shown a significant value of IT, others revealed a detrimental impact.\nGiven the ambiguous results and anecdotal commentary on the increase in\ndigitalization attributed to the COVID19 global pandemic, this paper aims to\nexplore the economic growth-digitalization nexus of 59 countries in 7 regions\nby employing correlation and regression analyses over the period 2018-2020. The\nfindings indicate a positive relationship between economic growth and\ndigitalization for both HIGH and LOW digitalized country categorization and\nregional assessment. Consistent with regional results, except for Northern\nAfrica and Western Asia, and Sub-Saharan Africa regions, the remaining regions\nshow a positive correlation and regression results. The findings of this study\ncan be helpful in future prospective national IT and economic development\npolicies.",
    "descriptor": "",
    "authors": [
      "Mahikala Niranga",
      "Darshana Sedera",
      "Golam Sorwar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.03071"
  },
  {
    "id": "arXiv:2212.03072",
    "title": "Inapproximability of counting independent sets in linear hypergraphs",
    "abstract": "It is shown in this note that approximating the number of independent sets in\na $k$-uniform linear hypergraph with maximum degree at most $\\Delta$ is NP-hard\nif $\\Delta\\geq 5\\cdot 2^{k-1}+1$. This confirms that for the relevant sampling\nand approximate counting problems, the regimes on the maximum degree where the\nstate-of-the-art algorithms work are tight, up to some small factors. These\nalgorithms include: the approximate sampler and randomised approximation scheme\nby Hermon, Sly and Zhang (2019), the perfect sampler by Qiu, Wang and Zhang\n(2022), and the deterministic approximation scheme by Feng, Guo, Wang, Wang and\nYin (2022).",
    "descriptor": "\nComments: Short note, 5 pages\n",
    "authors": [
      "Guoliang Qiu",
      "Jiaheng Wang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.03072"
  },
  {
    "id": "arXiv:2212.03074",
    "title": "Personal Green IT Use: Findings from a Literature Review",
    "abstract": "Research addressing the greening of internet user behaviours at hedonic and\nutilitarian levels is scarce. To identify dimensions, scales and strong\nrelationships arising from motivation, we reviewed a sample of research\narticles related to the personal green IT context. We used Self-determination\ntheory as the theoretical framework to categorize factors into different\nmotivation dimensions. A qualitative literature review analyses five pair-wise\nassociations between motivation constructs of the theory and green IT use. This\nwork builds on the prior research related to environmental motivation by\nsummarizing the measures applied to the evaluation of personal green IT\nbehaviours and by examining the relationships broadly defined in the\nSelf-determination theory, distinguishing between hedonic and utilitarian green\nIT use.",
    "descriptor": "",
    "authors": [
      "Ayodhya Wathuge",
      "Darshana Sedera",
      "Golam Sorwar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.03074"
  },
  {
    "id": "arXiv:2212.03075",
    "title": "How to Compare Fuzzers",
    "abstract": "Fuzzing is a key method to discover vulnerabilities in programs. Despite\nconsiderable progress in this area in the past years, measuring and comparing\nthe effectiveness of fuzzers is still an open research question. In software\ntesting, the gold standard for evaluating test quality is mutation analysis,\nassessing the ability of a test to detect synthetic bugs; if a set of tests\nfails to detect such mutations, it will also fail to detect real bugs. Mutation\nanalysis subsumes various coverage measures and provides a large and diverse\nset of faults that can be arbitrarily hard to trigger and detect, thus\npreventing the problems of saturation and overfitting. Unfortunately, the cost\nof traditional mutation analysis is exorbitant for fuzzing, as mutations need\nindependent evaluation.\nIn this paper, we apply modern mutation analysis techniques that pool\nmultiple mutations; allowing us, for the first time, to evaluate and compare\nfuzzers with mutation analysis. We introduce an evaluation bench for fuzzers\nand apply it to a number of popular fuzzers and subjects. In a comprehensive\nevaluation, we show how it allows us to assess fuzzer performance and measure\nthe impact of improved techniques. While we find that today's fuzzers can\ndetect only a small percentage of mutations, this should be seen as a challenge\nfor future research -- notably in improving (1) detecting failures beyond\ngeneric crashes (2) triggering mutations (and thus faults).",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Philipp G\u00f6rz",
      "Bj\u00f6rn Mathis",
      "Keno Hassler",
      "Emre G\u00fcler",
      "Thorsten Holz",
      "Andreas Zeller",
      "Rahul Gopinath"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.03075"
  },
  {
    "id": "arXiv:2212.03078",
    "title": "An unified material interpolation for topology optimization of  multi-materials",
    "abstract": "Topology optimization is one of the engineering tools for finding efficient\ndesign. For the material interpolation scheme, it is usual to employ the SIMP\n(Solid Isotropic Material with Penalization) or the homogenization based\ninterpolation function for the parameterization of the material properties with\nrespect to the design variables assigned to each finite element. For topology\noptimization with single material design, i.e., solid or void, the\nparameterization with 1 for solid and 0 for void becomes relatively straight\nforward using a polynomial function. For the case of multiple materials, some\nissues of the equality modeling of each material and \\textcolor{red}{the clear\n0, 1 result of each element for the topology optimization} issues become\nserious because of the curse of the dimension. To relieve these issues, this\nresearch proposes a new mapping based interpolation function for multi-material\ntopology optimization. Unlike the polynomial based interpolation, this new\ninterpolation is formulated by the ratio of the $p$-norm of the design\nvariables to the 1-norm of the design variable multiplied by the design\nvariable for a specific material. With this alternative mapping based\ninterpolation function, each material are equally modeled and \\textcolor{red}{\nthe clear 0, 1 result of each material for the multi-material topology\noptimization model} can be improved. This paper solves several topology\noptimization problems to prove the validity of the present interpolation\nfunction.",
    "descriptor": "\nComments: 16 pages, 25 figures\n",
    "authors": [
      "Bing Yi",
      "Gil Ho Yoon",
      "Ran Zheng",
      "Long Liu",
      "Daping Li",
      "Xiang Peng"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2212.03078"
  },
  {
    "id": "arXiv:2212.03080",
    "title": "Straggler-Resilient Differentially-Private Decentralized Learning",
    "abstract": "We consider the straggler problem in decentralized learning over a logical\nring while preserving user data privacy. Especially, we extend the recently\nproposed framework of differential privacy (DP) amplification by\ndecentralization by Cyffers and Bellet to include overall training\nlatency--comprising both computation and communication latency. Analytical\nresults on both the convergence speed and the DP level are derived for both a\nskipping scheme (which ignores the stragglers after a timeout) and a baseline\nscheme that waits for each node to finish before the training continues. A\ntrade-off between overall training latency, accuracy, and privacy,\nparameterized by the timeout of the skipping scheme, is identified and\nempirically validated for logistic regression on a real-world dataset.",
    "descriptor": "\nComments: This paper was presented in part at the IEEE Information Theory Workshop (ITW), Mumbai, India, November 2022\n",
    "authors": [
      "Yauhen Yakimenka",
      "Chung-Wei Weng",
      "Hsuan-Yin Lin",
      "Eirik Rosnes",
      "J\u00f6rg Kliewer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.03080"
  },
  {
    "id": "arXiv:2212.03081",
    "title": "Data analytics on key indicators for the city's urban services and  dashboards for leadership and decision-making",
    "abstract": "Cities are continuously evolving human settlements. Our cities are under\nstrain in an increasingly urbanized world, and planners, decision-makers, and\ncommunities must be ready to adapt. Data is an important resource for municipal\nadministration. Some technologies aid in the collection, processing, and\nvisualization of urban data, assisting in the interpretation and comprehension\nof how urban systems operate. The relationship between data analytics and smart\ncities has come to light in recent years as interest in both has grown. A\nsophisticated network of interconnected systems, including planners and\ninhabitants, is what is known as a smart city. Data analysis has the potential\nto support data-driven decision-making in the context of smart cities. Both\nurban managers and residents are becoming more interested in city dashboards.\nDashboards may collect, display, analyze, and provide information on regional\nperformance to help smart cities development having sustainability. In order to\nassist decision-making processes and enhance the performance of cities, we\nexamine how dashboards might be used to acquire accurate and representative\ninformation regarding urban challenges. This chapter culminates Data Analytics\non key indicators for the city's urban services and dashboards for leadership\nand decision-making. A single web page with consolidated information, real-time\ndata streams pertinent to planners and decision-makers as well as residents'\neveryday lives, and site analytics as a method to assess user interactions and\npreferences are among the proposals for urban dashboards.\nKeywords: -Dashboard, data analytics, smart city, sustainability.",
    "descriptor": "",
    "authors": [
      "Md Aminul Islam",
      "Abu Sufian",
      "Shabbir Ahmed Shuvo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.03081"
  },
  {
    "id": "arXiv:2212.03084",
    "title": "Land Use Prediction using Electro-Optical to SAR Few-Shot Transfer  Learning",
    "abstract": "Satellite image analysis has important implications for land use,\nurbanization, and ecosystem monitoring. Deep learning methods can facilitate\nthe analysis of different satellite modalities, such as electro-optical (EO)\nand synthetic aperture radar (SAR) imagery, by supporting knowledge transfer\nbetween the modalities to compensate for individual shortcomings. Recent\nprogress has shown how distributional alignment of neural network embeddings\ncan produce powerful transfer learning models by employing a sliced Wasserstein\ndistance (SWD) loss. We analyze how this method can be applied to Sentinel-1\nand -2 satellite imagery and develop several extensions toward making it\neffective in practice. In an application to few-shot Local Climate Zone (LCZ)\nprediction, we show that these networks outperform multiple common baselines on\ndatasets with a large number of classes. Further, we provide evidence that\ninstance normalization can significantly stabilize the training process and\nthat explicitly shaping the embedding space using supervised contrastive\nlearning can lead to improved performance.",
    "descriptor": "\nComments: Published at Tackling Climate Change with Machine Learning workshop at NeurIPS 2022\n",
    "authors": [
      "Marcel Hussing",
      "Karen Li",
      "Eric Eaton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03084"
  },
  {
    "id": "arXiv:2212.03085",
    "title": "Synthesizing nested relational queries from implicit specifications: via  model theory and via proof theory",
    "abstract": "Derived datasets can be defined implicitly or explicitly. An implicit\ndefinition (of dataset O in terms of datasets I) is a logical specification\ninvolving the source data I and the interface data O. It is a valid definition\nof O in terms of I, if any two models of the specification agreeing on I agree\non O. In contrast, an explicit definition is a query that produces O from I.\nVariants of Beth's theorem state that one can convert implicit definitions to\nexplicit ones. Further, this conversion can be done effectively given a proof\nwitnessing implicit definability in a suitable proof system.\nWe prove the analogous implicit-to-explicit result for nested relations:\nimplicit definitions, given in the natural logic for nested relations, can be\nconverted to explicit definitions in the nested relational calculus (NRC) We\nfirst provide a model-theoretic argument for this result, which makes some\nadditional connections that may be of independent interest. between NRC\nqueries, interpretations, a standard mechanisms for defining\nstructure-to-structure translation in logic, and between interpretations and\nimplicit to definability ``up to unique isomorphism''. The latter connection\nmakes use of a variation of a result of Gaifman.\nWe also provide a proof-theoretic result that provides an effective argument:\nfrom a proof witnessing implicit definability, we can efficiently produce an\nNRC definition. This will involve introducing the appropriate proof system for\nreasoning with nested sets, along with some auxiliary Beth-type results for\nthis system. As a consequence, we can effectively extract rewritings of NRC\nqueries in terms of NRC views, given a proof witnessing that the query is\ndetermined by the views.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2209.08299, arXiv:2005.06503. substantial text overlap with arXiv:2209.08299, arXiv:2005.06503\n",
    "authors": [
      "Michael Benedikt",
      "Pierre Pradic",
      "Christoph Wernhard"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.03085"
  },
  {
    "id": "arXiv:2212.03087",
    "title": "Fresh-CSMA: A Distributed Protocol for Minimizing Age of Information",
    "abstract": "We consider the design of distributed scheduling algorithms that minimize age\nof information in single-hop wireless networks. The centralized max-weight\npolicy is known to be nearly optimal in this setting; hence, our goal is to\ndesign a distributed CSMA scheme that can mimic its performance. To that end,\nwe propose a distributed protocol called Fresh-CSMA and show that in an\nidealized setting, Fresh-CSMA can match the scheduling decisions of the\nmax-weight policy with high probability in each frame, and also match the\ntheoretical performance guarantees of the max-weight policy over the entire\ntime horizon. We then consider a more realistic setting and study the impact of\nprotocol parameters on the probability of collisions and the overhead caused by\nthe distributed nature of the protocol. Finally, we provide simulations that\nsupport our theoretical results and show that the performance gap between the\nideal and realistic versions of Fresh-CSMA is small.",
    "descriptor": "\nComments: To be presented at IEEE INFOCOM 2023\n",
    "authors": [
      "Vishrant Tripathi",
      "Nicholas Jones",
      "Eytan Modiano"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.03087"
  },
  {
    "id": "arXiv:2212.03088",
    "title": "An Empirical Study on the Efficacy of Deep Active Learning for Image  Classification",
    "abstract": "Deep Active Learning (DAL) has been advocated as a promising method to reduce\nlabeling costs in supervised learning. However, existing evaluations of DAL\nmethods are based on different settings, and their results are controversial.\nTo tackle this issue, this paper comprehensively evaluates 19 existing DAL\nmethods in a uniform setting, including traditional\nfully-\\underline{s}upervised \\underline{a}ctive \\underline{l}earning (SAL)\nstrategies and emerging \\underline{s}emi-\\underline{s}upervised\n\\underline{a}ctive \\underline{l}earning (SSAL) techniques. We have several\nnon-trivial findings. First, most SAL methods cannot achieve higher accuracy\nthan random selection. Second, semi-supervised training brings significant\nperformance improvement compared to pure SAL methods. Third, performing data\nselection in the SSAL setting can achieve a significant and consistent\nperformance improvement, especially with abundant unlabeled data. Our findings\nproduce the following guidance for practitioners: one should (i) apply SSAL\nearly and (ii) collect more unlabeled data whenever possible, for better model\nperformance.",
    "descriptor": "",
    "authors": [
      "Yu Li",
      "Muxi Chen",
      "Yannan Liu",
      "Daojing He",
      "Qiang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.03088"
  },
  {
    "id": "arXiv:2212.03090",
    "title": "Label-free Knowledge Distillation with Contrastive Loss for Light-weight  Speaker Recognition",
    "abstract": "Very deep models for speaker recognition (SR) have demonstrated remarkable\nperformance improvement in recent research. However, it is impractical to\ndeploy these models for on-device applications with constrained computational\nresources. On the other hand, light-weight models are highly desired in\npractice despite their sub-optimal performance. This research aims to improve\nlight-weight SR models through large-scale label-free knowledge distillation\n(KD). Existing KD approaches for SR typically require speaker labels to learn\ntask-specific knowledge, due to the inefficiency of conventional loss for\ndistillation. To address the inefficiency problem and achieve label-free KD, we\npropose to employ the contrastive loss from self-supervised learning for\ndistillation. Extensive experiments are conducted on a collection of public\nspeech datasets from diverse sources. Results on light-weight SR models show\nthat the proposed approach of label-free KD with contrastive loss consistently\noutperforms both conventional distillation methods and self-supervised learning\nmethods by a significant margin.",
    "descriptor": "",
    "authors": [
      "Zhiyuan Peng",
      "Xuanji He",
      "Ke Ding",
      "Tan Lee",
      "Guanglu Wan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.03090"
  },
  {
    "id": "arXiv:2212.03091",
    "title": "ZeroKBC: A Comprehensive Benchmark for Zero-Shot Knowledge Base  Completion",
    "abstract": "Knowledge base completion (KBC) aims to predict the missing links in\nknowledge graphs. Previous KBC tasks and approaches mainly focus on the setting\nwhere all test entities and relations have appeared in the training set.\nHowever, there has been limited research on the zero-shot KBC settings, where\nwe need to deal with unseen entities and relations that emerge in a constantly\ngrowing knowledge base. In this work, we systematically examine different\npossible scenarios of zero-shot KBC and develop a comprehensive benchmark,\nZeroKBC, that covers these scenarios with diverse types of knowledge sources.\nOur systematic analysis reveals several missing yet important zero-shot KBC\nsettings. Experimental results show that canonical and state-of-the-art KBC\nsystems cannot achieve satisfactory performance on this challenging benchmark.\nBy analyzing the strength and weaknesses of these systems on solving ZeroKBC,\nwe further present several important observations and promising future\ndirections.",
    "descriptor": "\nComments: ICDMW 2022\n",
    "authors": [
      "Pei Chen",
      "Wenlin Yao",
      "Hongming Zhang",
      "Xiaoman Pan",
      "Dian Yu",
      "Dong Yu",
      "Jianshu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.03091"
  },
  {
    "id": "arXiv:2212.03093",
    "title": "Cooperative Guidance Strategy for Active Defense Spacecraft with  Imperfect Information via Deep Reinforcement Learning",
    "abstract": "In this paper, an adaptive cooperative guidance strategy for the active\nprotection of a target spacecraft trying to evade an interceptor was developed.\nThe target spacecraft performs evasive maneuvers, launching an active defense\nvehicle to divert the interceptor. Instead of classical strategies, which are\nbased on optimal control or differential game theory, the problem was solved by\nusing the deep reinforcement learning method, and imperfect information was\nassumed for the interceptor maneuverability. To address the sparse reward\nproblem, a universal reward design method and an increasingly difficult\ntraining approach were presented utilizing the shaping technique. Guidance law,\nreward function, and training approach were demonstrated through the learning\nprocess and Monte Carlo simulations. The application of the non-sparse reward\nfunction and increasingly difficult training approach accelerated the model\nconvergence, alleviating the overfitting problem. Considering a standard\noptimal guidance law as a benchmark, the effectiveness, and the advantages,\nthat guarantee the target spacecraft's escape and win rates in a multi-agent\ngame, of the proposed guidance strategy were validated by the simulation\nresults. The trained agent's adaptiveness to the interceptor maneuverability\nwas superior to the optimal guidance law. Moreover, compared to the standard\noptimal guidance law, the proposed guidance strategy performed better with less\nprior knowledge.",
    "descriptor": "",
    "authors": [
      "Li Zhi",
      "Haizhao Liang",
      "Jinze Wu",
      "Jianying Wang",
      "Yu Zheng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.03093"
  },
  {
    "id": "arXiv:2212.03095",
    "title": "Interpretation of Neural Networks is Susceptible to Universal  Adversarial Perturbations",
    "abstract": "Interpreting neural network classifiers using gradient-based saliency maps\nhas been extensively studied in the deep learning literature. While the\nexisting algorithms manage to achieve satisfactory performance in application\nto standard image recognition datasets, recent works demonstrate the\nvulnerability of widely-used gradient-based interpretation schemes to\nnorm-bounded perturbations adversarially designed for every individual input\nsample. However, such adversarial perturbations are commonly designed using the\nknowledge of an input sample, and hence perform sub-optimally in application to\nan unknown or constantly changing data point. In this paper, we show the\nexistence of a Universal Perturbation for Interpretation (UPI) for standard\nimage datasets, which can alter a gradient-based feature map of neural networks\nover a significant fraction of test samples. To design such a UPI, we propose a\ngradient-based optimization method as well as a principal component analysis\n(PCA)-based approach to compute a UPI which can effectively alter a neural\nnetwork's gradient-based interpretation on different samples. We support the\nproposed UPI approaches by presenting several numerical results of their\nsuccessful applications to standard image datasets.",
    "descriptor": "",
    "authors": [
      "Haniyeh Ehsani Oskouie",
      "Farzan Farnia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.03095"
  },
  {
    "id": "arXiv:2212.03097",
    "title": "Analytical Uncertainty Propagation for Multi-Period Stochastic Optimal  Power Flow",
    "abstract": "The increase in renewable energy sources (RESs), like wind or solar power,\nresults in growinguncertainty also in transmission grids. This affects grid\nstability through fluctuating energy supplyand an increased probability of\noverloaded lines. One key strategy to cope with this uncertainty isthe use of\ndistributed energy storage systems (ESSs). In order to securely operate power\nsystemscontaining renewables and use storage, optimization models are needed\nthat both handle uncertaintyand apply ESSs. This paper introduces a compact\ndynamic stochastic chance-constrained DC optimalpower flow (CC-OPF) model, that\nminimizes generation costs and includes distributed ESSs. AssumingGaussian\nuncertainty, we use affine policies to obtain a tractable, analytically exact\nreformulation asa second-order cone problem (SOCP). We test the new model on\nfive different IEEE networks withvarying sizes of 5, 39, 57, 118 and 300 nodes\nand include complexity analysis. The results showthat the model is\ncomputationally efficient and robust with respect to constraint violation risk.\nThedistributed energy storage system leads to more stable operation with\nflattened generation profiles.Storage absorbed RES uncertainty, and reduced\ngeneration cost.",
    "descriptor": "",
    "authors": [
      "Rebecca Bauer",
      "Tillmann M\u00fchlpfordt",
      "Nicole Ludwig",
      "Veit Hagenmeyer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.03097"
  },
  {
    "id": "arXiv:2212.03099",
    "title": "Semantic-Conditional Diffusion Networks for Image Captioning",
    "abstract": "Recent advances on text-to-image generation have witnessed the rise of\ndiffusion models which act as powerful generative models. Nevertheless, it is\nnot trivial to exploit such latent variable models to capture the dependency\namong discrete words and meanwhile pursue complex visual-language alignment in\nimage captioning. In this paper, we break the deeply rooted conventions in\nlearning Transformer-based encoder-decoder, and propose a new diffusion model\nbased paradigm tailored for image captioning, namely Semantic-Conditional\nDiffusion Networks (SCD-Net). Technically, for each input image, we first\nsearch the semantically relevant sentences via cross-modal retrieval model to\nconvey the comprehensive semantic information. The rich semantics are further\nregarded as semantic prior to trigger the learning of Diffusion Transformer,\nwhich produces the output sentence in a diffusion process. In SCD-Net, multiple\nDiffusion Transformer structures are stacked to progressively strengthen the\noutput sentence with better visional-language alignment and linguistical\ncoherence in a cascaded manner. Furthermore, to stabilize the diffusion\nprocess, a new self-critical sequence training strategy is designed to guide\nthe learning of SCD-Net with the knowledge of a standard autoregressive\nTransformer model. Extensive experiments on COCO dataset demonstrate the\npromising potential of using diffusion models in the challenging image\ncaptioning task. Source code is available at\n\\url{https://github.com/YehLi/xmodaler/tree/master/configs/image_caption/scdnet}.",
    "descriptor": "\nComments: Source code is available at \\url{this https URL}\n",
    "authors": [
      "Jianjie Luo",
      "Yehao Li",
      "Yingwei Pan",
      "Ting Yao",
      "Jianlin Feng",
      "Hongyang Chao",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2212.03099"
  },
  {
    "id": "arXiv:2212.03102",
    "title": "A comparative study of emotion recognition methods using facial  expressions",
    "abstract": "Understanding the facial expressions of our interlocutor is important to\nenrich the communication and to give it a depth that goes beyond the explicitly\nexpressed. In fact, studying one's facial expression gives insight into their\nhidden emotion state. However, even as humans, and despite our empathy and\nfamiliarity with the human emotional experience, we are only able to guess what\nthe other might be feeling. In the fields of artificial intelligence and\ncomputer vision, Facial Emotion Recognition (FER) is a topic that is still in\nfull growth mostly with the advancement of deep learning approaches and the\nimprovement of data collection. The main purpose of this paper is to compare\nthe performance of three state-of-the-art networks, each having their own\napproach to improve on FER tasks, on three FER datasets. The first and second\nsections respectively describe the three datasets and the three studied network\narchitectures designed for an FER task. The experimental protocol, the results\nand their interpretation are outlined in the remaining sections.",
    "descriptor": "",
    "authors": [
      "Rim EL Cheikh",
      "H\u00e9l\u00e8ne Tran",
      "Issam Falih",
      "Engelbert Mephu Nguifo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03102"
  },
  {
    "id": "arXiv:2212.03103",
    "title": "A Comprehensively Improved Hybrid Algorithm for Learning Bayesian  Networks: Multiple Compound Memory Erasing",
    "abstract": "Using a Bayesian network to analyze the causal relationship between nodes is\na hot spot. The existing network learning algorithms are mainly\nconstraint-based and score-based network generation methods. The\nconstraint-based method is mainly the application of conditional independence\n(CI) tests, but the inaccuracy of CI tests in the case of high dimensionality\nand small samples has always been a problem for the constraint-based method.\nThe score-based method uses the scoring function and search strategy to find\nthe optimal candidate network structure, but the search space increases too\nmuch with the increase of the number of nodes, and the learning efficiency is\nvery low. This paper presents a new hybrid algorithm, MCME (multiple compound\nmemory erasing). This method retains the advantages of the first two methods,\nsolves the shortcomings of the above CI tests, and makes innovations in the\nscoring function in the direction discrimination stage. A large number of\nexperiments show that MCME has better or similar performance than some existing\nalgorithms.",
    "descriptor": "\nComments: Bayesian networks, Structure learning, Conditional independence tests, Scoring function\n",
    "authors": [
      "Baokui Mou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.03103"
  },
  {
    "id": "arXiv:2212.03106",
    "title": "Scale-Invariant Specifications for \\\\Human-Swarm Systems",
    "abstract": "We present a method for controlling a swarm using its spectral decomposition\n-- that is, by describing the set of trajectories of a swarm in terms of a\nspatial distribution throughout the operational domain -- guaranteeing scale\ninvariance with respect to the number of agents both for computation and for\nthe operator tasked with controlling the swarm. We use ergodic control,\ndecentralized across the network, for implementation. In the DARPA OFFSET\nprogram field setting, we test this interface design for the operator using the\nSTOMP interface -- the same interface used by Raytheon BBN throughout the\nduration of the OFFSET program. In these tests, we demonstrate that our\napproach is scale-invariant -- the user specification does not depend on the\nnumber of agents; it is persistent -- the specification remains active until\nthe user specifies a new command; and it is real-time -- the user can interact\nwith and interrupt the swarm at any time. Moreover, we show that the\nspectral/ergodic specification of swarm behavior degrades gracefully as the\nnumber of agents goes down, enabling the operator to maintain the same approach\nas agents become disabled or are added to the network. We demonstrate the\nscale-invariance and dynamic response of our system in a field relevant\nsimulator on a variety of tactical scenarios with up to 50 agents. We also\ndemonstrate the dynamic response of our system in the field with a smaller team\nof agents. Lastly, we make the code for our system available.",
    "descriptor": "\nComments: Journal of Field Robotics, Accepted for Publication. 25 pages\n",
    "authors": [
      "Joel Meyer",
      "Ahalya Prabhakar",
      "Allison Pinosky",
      "Ian Abraham",
      "Annalisa Taylor",
      "Millicent Schlafly",
      "Katarina Popovic",
      "Giovani Diniz",
      "Brendan Teich",
      "Borislava Simidchieva",
      "Shane Clark",
      "Todd Murphey"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.03106"
  },
  {
    "id": "arXiv:2212.03107",
    "title": "Microservice Architecture Practices and Experience: a Focused Look on  Docker Configuration Files",
    "abstract": "Cloud applications are more and more microservice-oriented, but a concrete\ncharting of the microservices architecture landscape -- namely, the space of\ntechnical options available for microservice software architects in their\ndecision-making -- is still very much lacking, thereby limiting the ability of\nsoftware architects to properly evaluate their architectural decisions with\nsound experiential devices and/or practical design principles. On the one hand,\nMicroservices are fine-grained, loosely coupled services that communicate\nthrough lightweight protocols. On the other hand, each microservice can use a\ndifferent software stack, be deployed and scaled independently or even executed\nin different containers, which provide isolation and a wide-range of\nconfiguration options but also offer unforeseeable architectural interactions\nand under-explored architecture smells, with such experience captured mainly in\nsoftware repositories where such solutions are cycled.\nThis paper adopts a mining software repositories (MSR) approach to capture\nthe practice within the microservice architecture landscape, by eliciting and\nanalysing Docker configuration files, being Docker the leading technical device\nto design for, and implement modern microservices. Our analysis of Docker-based\nmicroservices gives an interesting summary of the current state of\nmicroservices practice and experience. Conversely, observing that all our\ndatapoints have their own shape and characteristics, we conclude that further\ncomparative assessment with industrial systems is needed to better address the\nrecurring positive principles and patterns around microservices.",
    "descriptor": "",
    "authors": [
      "Luciano Baresi",
      "Giovanni Quattrocchi",
      "Damian Andrew Tamburri"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2212.03107"
  },
  {
    "id": "arXiv:2212.03109",
    "title": "Risk management in the Artificial Intelligence Act",
    "abstract": "The proposed EU AI Act is the first comprehensive attempt to regulate AI in a\nmajor jurisdiction. This article analyses Article 9, the key risk management\nprovision in the AI Act. It gives an overview of the regulatory concept behind\nArticle 9, determines its purpose and scope of application, offers a\ncomprehensive interpretation of the specific risk management requirements, and\noutlines ways in which the requirements can be enforced. This article is\nwritten with the aim of helping providers of high-risk systems comply with the\nrequirements set out in Article 9. In addition, it can inform revisions of the\ncurrent draft of the AI Act and efforts to develop harmonised standards on AI\nrisk management.",
    "descriptor": "",
    "authors": [
      "Jonas Schuett"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.03109"
  },
  {
    "id": "arXiv:2212.03112",
    "title": "Fast Online Hashing with Multi-Label Projection",
    "abstract": "Hashing has been widely researched to solve the large-scale approximate\nnearest neighbor search problem owing to its time and storage superiority. In\nrecent years, a number of online hashing methods have emerged, which can update\nthe hash functions to adapt to the new stream data and realize dynamic\nretrieval. However, existing online hashing methods are required to update the\nwhole database with the latest hash functions when a query arrives, which leads\nto low retrieval efficiency with the continuous increase of the stream data. On\nthe other hand, these methods ignore the supervision relationship among the\nexamples, especially in the multi-label case. In this paper, we propose a novel\nFast Online Hashing (FOH) method which only updates the binary codes of a small\npart of the database. To be specific, we first build a query pool in which the\nnearest neighbors of each central point are recorded. When a new query arrives,\nonly the binary codes of the corresponding potential neighbors are updated. In\naddition, we create a similarity matrix which takes the multi-label supervision\ninformation into account and bring in the multi-label projection loss to\nfurther preserve the similarity among the multi-label data. The experimental\nresults on two common benchmarks show that the proposed FOH can achieve\ndramatic superiority on query time up to 6.28 seconds less than\nstate-of-the-art baselines with competitive retrieval accuracy.",
    "descriptor": "\nComments: This paper is accepted by AAAI Conference on Artificial Intelligence (AAAI), 2023\n",
    "authors": [
      "Wenzhe Jia",
      "Yuan Cao",
      "Junwei Liu",
      "Jie Gui"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03112"
  },
  {
    "id": "arXiv:2212.03117",
    "title": "Q-Pensieve: Boosting Sample Efficiency of Multi-Objective RL Through  Memory Sharing of Q-Snapshots",
    "abstract": "Many real-world continuous control problems are in the dilemma of weighing\nthe pros and cons, multi-objective reinforcement learning (MORL) serves as a\ngeneric framework of learning control policies for different preferences over\nobjectives. However, the existing MORL methods either rely on multiple passes\nof explicit search for finding the Pareto front and therefore are not\nsample-efficient, or utilizes a shared policy network for coarse knowledge\nsharing among policies. To boost the sample efficiency of MORL, we propose\nQ-Pensieve, a policy improvement scheme that stores a collection of Q-snapshots\nto jointly determine the policy update direction and thereby enables data\nsharing at the policy level. We show that Q-Pensieve can be naturally\nintegrated with soft policy iteration with convergence guarantee. To\nsubstantiate this concept, we propose the technique of Q replay buffer, which\nstores the learned Q-networks from the past iterations, and arrive at a\npractical actor-critic implementation. Through extensive experiments and an\nablation study, we demonstrate that with much fewer samples, the proposed\nalgorithm can outperform the benchmark MORL methods on a variety of MORL\nbenchmark tasks.",
    "descriptor": "\nComments: 17 pages, 15 figures\n",
    "authors": [
      "Wei Hung",
      "Bo-Kai Huang",
      "Ping-Chun Hsieh",
      "Xi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03117"
  },
  {
    "id": "arXiv:2212.03125",
    "title": "Self-supervised and Weakly Supervised Contrastive Learning for  Frame-wise Action Representations",
    "abstract": "Previous work on action representation learning focused on global\nrepresentations for short video clips. In contrast, many practical\napplications, such as video alignment, strongly demand learning the intensive\nrepresentation of long videos. In this paper, we introduce a new framework of\ncontrastive action representation learning (CARL) to learn frame-wise action\nrepresentation in a self-supervised or weakly-supervised manner, especially for\nlong videos. Specifically, we introduce a simple but effective video encoder\nthat considers both spatial and temporal context by combining convolution and\ntransformer. Inspired by the recent massive progress in self-supervised\nlearning, we propose a new sequence contrast loss (SCL) applied to two related\nviews obtained by expanding a series of spatio-temporal data in two versions.\nOne is the self-supervised version that optimizes embedding space by minimizing\nKL-divergence between sequence similarity of two augmented views and prior\nGaussian distribution of timestamp distance. The other is the weakly-supervised\nversion that builds more sample pairs among videos using video-level labels by\ndynamic time wrapping (DTW). Experiments on FineGym, PennAction, and Pouring\ndatasets show that our method outperforms previous state-of-the-art by a large\nmargin for downstream fine-grained action classification and even faster\ninference. Surprisingly, although without training on paired videos like in\nprevious works, our self-supervised version also shows outstanding performance\nin video alignment and fine-grained frame retrieval tasks.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Minghao Chen",
      "Renbo Tu",
      "Chenxi Huang",
      "Yuqi Lin",
      "Boxi Wu",
      "Deng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03125"
  },
  {
    "id": "arXiv:2212.03129",
    "title": "Formally Verified Native Code Generation in an Effectful JIT -- or:  Turning the CompCert Backend into a Formally Verified JIT Compiler",
    "abstract": "Modern Just-in-Time compilers (or JITs) typically interleave several\nmechanisms to execute a program. For faster startup times and to observe the\ninitial behavior of an execution, interpretation can be initially used. But\nafter a while, JITs dynamically produce native code for parts of the program\nthey execute often. Although some time is spent compiling dynamically, this\nmechanism makes for much faster times for the remaining of the program\nexecution. Such compilers are complex pieces of software with various\ncomponents, and greatly rely on a precise interplay between the different\nlanguages being executed, including on-stack-replacement. Traditional static\ncompilers like CompCert have been mechanized in proof assistants, but JITs have\nbeen scarcely formalized so far, partly due to their impure nature and their\nnumerous components. This work presents a model JIT with dynamic generation of\nnative code, implemented and formally verified in Coq. Although some parts of a\nJIT cannot be written in Coq, we propose a proof methodology to delimit,\nspecify and reason on the impure effects of a JIT. We argue that the daunting\ntask of formally verifying a complete JIT should draw on existing proofs of\nnative code generation. To this end, our work successfully reuses CompCert and\nits correctness proofs during dynamic compilation. Finally, our prototype can\nbe extracted and executed.",
    "descriptor": "\nComments: Proceedings of the ACM on Programming Languages, 2023\n",
    "authors": [
      "Aur\u00e8le Barri\u00e8re",
      "Sandrine Blazy",
      "David Pichardie"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2212.03129"
  },
  {
    "id": "arXiv:2212.03130",
    "title": "Deep Learning Methods for Partial Differential Equations and Related  Parameter Identification Problems",
    "abstract": "Recent years have witnessed a growth in mathematics for deep learning--which\nseeks a deeper understanding of the concepts of deep learning with mathematics,\nand explores how to make it more robust--and deep learning for mathematics,\nwhere deep learning algorithms are used to solve problems in mathematics. The\nlatter has popularised the field of scientific machine learning where deep\nlearning is applied to problems in scientific computing. Specifically, more and\nmore neural network architectures have been developed to solve specific classes\nof partial differential equations (PDEs). Such methods exploit properties that\nare inherent to PDEs and thus solve the PDEs better than classical feed-forward\nneural networks, recurrent neural networks, and convolutional neural networks.\nThis has had a great impact in the area of mathematical modeling where\nparametric PDEs are widely used to model most natural and physical processes\narising in science and engineering, In this work, we review such methods and\nextend them for parametric studies as well as for solving the related inverse\nproblems. We equally proceed to show their relevance in some industrial\napplications.",
    "descriptor": "",
    "authors": [
      "Derick Nganyu Tanyu",
      "Jianfeng Ning",
      "Tom Freudenberg",
      "Nick Heilenk\u00f6tter",
      "Andreas Rademacher",
      "Uwe Iben",
      "Peter Maass"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.03130"
  },
  {
    "id": "arXiv:2212.03131",
    "title": "Explainability as statistical inference",
    "abstract": "A wide variety of model explanation approaches have been proposed in recent\nyears, all guided by very different rationales and heuristics. In this paper,\nwe take a new route and cast interpretability as a statistical inference\nproblem. We propose a general deep probabilistic model designed to produce\ninterpretable predictions. The model parameters can be learned via maximum\nlikelihood, and the method can be adapted to any predictor network architecture\nand any type of prediction problem. Our method is a case of amortized\ninterpretability models, where a neural network is used as a selector to allow\nfor fast interpretation at inference time. Several popular interpretability\nmethods are shown to be particular cases of regularised maximum likelihood for\nour general model. We propose new datasets with ground truth selection which\nallow for the evaluation of the features importance map. Using these datasets,\nwe show experimentally that using multiple imputation provides more reasonable\ninterpretations.",
    "descriptor": "\nComments: 10 pages, 22 figures, submitted at ICLR 2023\n",
    "authors": [
      "Hugo Henri Joseph Senetaire",
      "Damien Garreau",
      "Jes Frellsen",
      "Pierre-Alexandre Mattei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.03131"
  },
  {
    "id": "arXiv:2212.03132",
    "title": "How does the partition of unity influence SORAS preconditioner?",
    "abstract": "We investigate numerically the influence of the choice of the partition of\nunity on the convergence of the Symmetrized Optimized Restricted Additive\nSchwarz (SORAS) preconditioner for the heterogeneous\nreaction-convection-diffusion equation.",
    "descriptor": "",
    "authors": [
      "Marcella Bonazzoli",
      "Xavier Claeys",
      "Fr\u00e9d\u00e9ric Nataf",
      "Pierre-Henri Tournier"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.03132"
  },
  {
    "id": "arXiv:2212.03140",
    "title": "Neural Machine Translation with Contrastive Translation Memories",
    "abstract": "Retrieval-augmented Neural Machine Translation models have been successful in\nmany translation scenarios. Different from previous works that make use of\nmutually similar but redundant translation memories~(TMs), we propose a new\nretrieval-augmented NMT to model contrastively retrieved translation memories\nthat are holistically similar to the source sentence while individually\ncontrastive to each other providing maximal information gains in three phases.\nFirst, in TM retrieval phase, we adopt a contrastive retrieval algorithm to\navoid redundancy and uninformativeness of similar translation pieces. Second,\nin memory encoding stage, given a set of TMs we propose a novel Hierarchical\nGroup Attention module to gather both local context of each TM and global\ncontext of the whole TM set. Finally, in training phase, a Multi-TM contrastive\nlearning objective is introduced to learn salient feature of each TM with\nrespect to target sentence. Experimental results show that our framework\nobtains improvements over strong baselines on the benchmark datasets.",
    "descriptor": "\nComments: EMNLP2022 Main Conference\n",
    "authors": [
      "Xin Cheng",
      "Shen Gao",
      "Lemao Liu",
      "Dongyan Zhao",
      "Rui Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.03140"
  },
  {
    "id": "arXiv:2212.03141",
    "title": "Analysis-aware defeaturing of complex geometries",
    "abstract": "Local modifications of a computational domain are often performed in order to\nsimplify the meshing process and to reduce computational costs and memory\nrequirements. However, removing geometrical features of a domain often\nintroduces a non-negligible error in the solution of a differential problem in\nwhich it is defined. In this paper, we aim at generalizing the work from [1],\nin which an a posteriori estimator of the geometrical defeaturing error is\nderived for domains from which one geometrical feature is removed. More\nprecisely, we study the case of domains containing an arbitrary number of\ndistinct features, and we perform an analysis on Poisson's, linear elasticity,\nand Stokes' equations. We introduce a simple and computationally cheap a\nposteriori estimator of the geometrical defeaturing error, whose reliability\nand efficiency are rigorously proved, and we introduce a geometric refinement\nstrategy that accounts for the defeaturing error: Starting from a fully\ndefeatured geometry, the algorithm determines at each iteration step which\nfeatures need to be added to the geometrical model to reduce the defeaturing\nerror. These important features are then added to the (partially) defeatured\ngeometrical model at the next iteration, until the solution attains a\nprescribed accuracy. A wide range of numerical experiments are finally reported\nto illustrate and validate this work.",
    "descriptor": "\nComments: 55 pages\n",
    "authors": [
      "Pablo Antolin",
      "Ondine Chanon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.03141"
  },
  {
    "id": "arXiv:2212.03145",
    "title": "FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer",
    "abstract": "Recent work has explored the potential to adapt a pre-trained vision\ntransformer (ViT) by updating only a few parameters so as to improve storage\nefficiency, called parameter-efficient transfer learning (PETL). Current PETL\nmethods have shown that by tuning only 0.5% of the parameters, ViT can be\nadapted to downstream tasks with even better performance than full fine-tuning.\nIn this paper, we aim to further promote the efficiency of PETL to meet the\nextreme storage constraint in real-world applications. To this end, we propose\na tensorization-decomposition framework to store the weight increments, in\nwhich the weights of each ViT are tensorized into a single 3D tensor, and their\nincrements are then decomposed into lightweight factors. In the fine-tuning\nprocess, only the factors need to be updated and stored, termed Factor-Tuning\n(FacT). On VTAB-1K benchmark, our method performs on par with NOAH, the\nstate-of-the-art PETL method, while being 5x more parameter-efficient. We also\npresent a tiny version that only uses 8K (0.01% of ViT's parameters) trainable\nparameters but outperforms full fine-tuning and many other PETL methods such as\nVPT and BitFit. In few-shot settings, FacT also beats all PETL baselines using\nthe fewest parameters, demonstrating its strong capability in the low-data\nregime.",
    "descriptor": "\nComments: Accepted at AAAI 2023. Code: this https URL\n",
    "authors": [
      "Shibo Jie",
      "Zhi-Hong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03145"
  },
  {
    "id": "arXiv:2212.03146",
    "title": "Univalent Monoidal Categories",
    "abstract": "Univalent categories constitute a well-behaved and useful notion of category\nin univalent foundations. The notion of univalence has subsequently been\ngeneralized to bicategories and other structures in (higher) category theory.\nHere, we zoom in on monoidal categories and study them in a univalent setting.\nSpecifically, we show that the bicategory of univalent monoidal categories is\nunivalent. Furthermore, we construct a Rezk completion for monoidal categories:\nwe show how any monoidal category is weakly equivalent to a univalent monoidal\ncategory, universally. We have fully formalized these results in UniMath, a\nlibrary of univalent mathematics in the Coq proof assistant.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Kobe Wullaert",
      "Ralph Matthes",
      "Benedikt Ahrens"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2212.03146"
  },
  {
    "id": "arXiv:2212.03152",
    "title": "Regret Minimization with Dynamic Benchmarks in Repeated Games",
    "abstract": "In repeated games, strategies are often evaluated by their ability to\nguarantee the performance of the single best action that is selected in\nhindsight (a property referred to as \\emph{Hannan consistency}, or\n\\emph{no-regret}). However, the effectiveness of the single best action as a\nyardstick to evaluate strategies is limited, as any static action may perform\npoorly in common dynamic settings. We propose the notion of \\emph{dynamic\nbenchmark consistency}, which requires a strategy to asymptotically guarantee\nthe performance of the best \\emph{dynamic} sequence of actions selected in\nhindsight subject to a constraint on the number of action changes the\ncorresponding dynamic benchmark admits. We show that dynamic benchmark\nconsistent strategies exist if and only if the number of changes in the\nbenchmark scales sublinearly with the horizon length. Further, our main result\nestablishes that the set of empirical joint distributions of play that may\nemerge, when all players deploy such strategies, asymptotically coincides with\nthe set of \\emph{Hannan equilibria} (also referred to as \\emph{coarse\ncorrelated equilibria}) of the stage game. This general characterization allows\none to leverage analyses developed for frameworks that consider static\nbenchmarks, which we demonstrate by bounding the social efficiency of the\npossible outcomes in our~setting. Together, our results imply that dynamic\nbenchmark consistent strategies introduce the following \\emph{Pareto-type}\nimprovement over no-regret strategies: They enable stronger individual\nguarantees against arbitrary strategies of the other players, while maintaining\nthe same worst-case guarantees on the social welfare, when all players adopt\nthese strategies.",
    "descriptor": "",
    "authors": [
      "Ludovico Crippa",
      "Yonatan Gur",
      "Bar Light"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2212.03152"
  },
  {
    "id": "arXiv:2212.03155",
    "title": "A Learned Simulation Environment to Model Plant Growth in Indoor Farming",
    "abstract": "We developed a simulator to quantify the effect of changes in environmental\nparameters on plant growth in precision farming. Our approach combines the\nprocessing of plant images with deep convolutional neural networks (CNN),\ngrowth curve modeling, and machine learning. As a result, our system is able to\npredict growth rates based on environmental variables, which opens the door for\nthe development of versatile reinforcement learning agents.",
    "descriptor": "\nComments: 8 pages, 6 figures, 1 table\n",
    "authors": [
      "J. Amacker",
      "T. Kleiven",
      "M. Grigore",
      "P. Albrecht",
      "C. Horn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03155"
  },
  {
    "id": "arXiv:2212.03158",
    "title": "Robust Switching Control of DC-DC Boost Converter for EV Charging  Stations",
    "abstract": "In this work, the problem of switching control design for DC-DC boost\nconverter is considered, in the case of operation under uncertain equilibrium\ncondition arising due to perturbations in the input and load parameters.\nAssuming that these uncertain parameters are generated via a known linear\nexo-system, a parameter estimator is designed to update the equilibrium point\nfor the switching controller in real-time. In order to mitigate the noise\namplification problem associated with the designed parameter estimator, the\nestimation error injection term is filtered via a set of first-order filters to\nobtain the desired level of noise suppression in the final set of estimates. To\ndemonstrate the efficiency of the developed scheme, a realistic application\nscenario of a DC charging station for electric vehicles is considered, with\nphotovoltaic array as the source and a battery connected at the load side.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Saif Ahmad",
      "Ryan P.C. de Souza",
      "Pauline Kergus",
      "Zohra Kader",
      "Stephane Caux"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.03158"
  },
  {
    "id": "arXiv:2212.03161",
    "title": "Branching execution symmetry in Jeopardy by available implicit arguments  analysis",
    "abstract": "When the inverse of an algorithm is well-defined -- that is, when its output\ncan be deterministically transformed into the input producing it -- we say that\nthe algorithm is invertible. While one can describe an invertible algorithm\nusing a general-purpose programming language, it is generally not possible to\nguarantee that its inverse is well-defined without additional argument.\nReversible languages enforce deterministic inverse interpretation at the cost\nof expressibility, by restricting the building blocks from which an algorithm\nmay be constructed.\nJeopardy is a functional programming language designed for writing invertible\nalgorithms \\emph{without} the syntactic restrictions of reversible programming.\nIn particular, Jeopardy allows the limited use of locally non-invertible\noperations, provided that they are used in a way that can be statically\ndetermined to be globally invertible. However, guaranteeing invertibility in\nJeopardy is not obvious.\nOne of the central problems in guaranteeing invertibility is that of deciding\nwhether a program is symmetric in the face of branching control flow. In this\npaper, we show how Jeopardy can solve this problem, using a program analysis\ncalled available implicit arguments analysis, to approximate branching\nsymmetries.",
    "descriptor": "",
    "authors": [
      "Joachim Tilsted Kristensen",
      "Robin Kaarsgaard",
      "Michael Kirkedal Thomsen"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2212.03161"
  },
  {
    "id": "arXiv:2212.03162",
    "title": "Design of Linear Passive Mixer-First Receivers for mmWave Digital  Beamforming Arrays",
    "abstract": "A 25-40GHz passive mixer-first receiver using a novel architecture for\ndigital beamforming arrays is proposed. The architecture uses a novel technique\nfor impedance matching using the on-resistance of the mixers in the receiver\nand matching networks. The small switch resistance of the mixers can be matched\nto the antenna using matching networks. Several matching networks are\ndiscussed, including a tunable matching network for wideband applications. The\ndesign achieves a noise figure that is lower than 8dB, a conversion gain of\n18dB, and an IIP3 of around +4dBm across the frequency range of 25-40GHz. A\nprototype chip is fabricated in 28nm bulk CMOS process.",
    "descriptor": "\nComments: 8 pages, 17 figures, to be submitted to IEEE Transactions on Circuits and Systems I: Regular Papers\n",
    "authors": [
      "Rawan Al Kubaisy",
      "Sashank Krishnamurthy",
      "Ali Niknejad"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.03162"
  },
  {
    "id": "arXiv:2212.03169",
    "title": "When Brain-Computer Interfaces Meet the Metaverse: Landscape,  Demonstrator, Trends, Challenges, and Concerns",
    "abstract": "The metaverse has gained tremendous popularity in recent years, allowing the\ninterconnection of users worldwide. However, current systems used in metaverse\nscenarios, such as virtual reality glasses, offer a partial immersive\nexperience. In this context, Brain-Computer Interfaces (BCIs) can introduce a\nrevolution in the metaverse, although a study of the applicability and\nimplications of BCIs in these virtual scenarios is required. Based on the\nabsence of literature, this work studies, for the first time, the applicability\nof BCIs in the metaverse, analyzing the current status of this integration\nbased on different categories related to virtual worlds and the evolution of\nBCIs in these scenarios in the medium and long term. This work also presents a\ndemonstration of what current BCI solutions can provide to the metaverse. It\nuses a metaverse consisting in driving a car within a simulation, using VR, a\nsteering wheel and pedals, and a BCI for neural data acquisition. Four use\ncases are selected, focusing on cognitive and emotional assessment of the\ndriver, detection of drowsiness, and driver authentication while using the\nvehicle. Then, it offers an analysis of BCI trends in the metaverse, also\nidentifying future challenges that the intersection of these technologies will\nface. Finally, it reviews the concerns that the use of BCIs in virtual world\napplications could generate according to different categories: accessibility,\nuser inclusion, privacy, cybersecurity, physical safety, and ethics.",
    "descriptor": "",
    "authors": [
      "Sergio L\u00f3pez Bernal",
      "Mario Quiles P\u00e9rez",
      "Enrique Tom\u00e1s Mart\u00ednez Beltr\u00e1n",
      "Gregorio Mart\u00ednez P\u00e9rez",
      "Alberto Huertas Celdr\u00e1n"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.03169"
  },
  {
    "id": "arXiv:2212.03172",
    "title": "Estimating Meetings' Air Flight $CO_2$ Equivalent Emissions An  Illustrative Example with IETF meetings",
    "abstract": "These notes describe CO2eq a tool that estimates $CO_2$ equivalent emissions\nassociated with air traffic and applies it to the Internet Engineering Task\nForce (IETF), an international standard developing organization that meets 3\ntimes a year. CO2eq estimates that the participation to IETF meetings (by a\nsingle participant) generates as much $CO_2$ equivalent as the $CO_2$ emissions\nper capita of European countries generating their energy using coal -- like\nGermany or Poland for example. This suggests some radical changes should be\nconsidered by the IETF.\nAccording to the conclusion of the $26^{th}$ Conference of the Parties\n(COP26) from the United Nations Secretary-General Ant\\'onio Guterres; in 2021,\nthe number of meetings should be limited to a maximum of one meeting per year.\nIn addition, the incorporation of sustainability principles into the IETF's\nstrategy, should include, for example, increasing the effort to enhance the\nexperience of 'remote' participation as well as adhering to programs (such as\nfor example the United Nations Global Compact and the caring for climate\ninitiative) to align its strategy and report progress toward sustainability.",
    "descriptor": "\nComments: 10 pages, 14 figures\n",
    "authors": [
      "Daniel Migault"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2212.03172"
  },
  {
    "id": "arXiv:2212.03175",
    "title": "Learning Representations that Enable Generalization in Assistive Tasks",
    "abstract": "Recent work in sim2real has successfully enabled robots to act in physical\nenvironments by training in simulation with a diverse ''population'' of\nenvironments (i.e. domain randomization). In this work, we focus on enabling\ngeneralization in assistive tasks: tasks in which the robot is acting to assist\na user (e.g. helping someone with motor impairments with bathing or with\nscratching an itch). Such tasks are particularly interesting relative to prior\nsim2real successes because the environment now contains a human who is also\nacting. This complicates the problem because the diversity of human users\n(instead of merely physical environment parameters) is more difficult to\ncapture in a population, thus increasing the likelihood of encountering\nout-of-distribution (OOD) human policies at test time. We advocate that\ngeneralization to such OOD policies benefits from (1) learning a good latent\nrepresentation for human policies that test-time humans can accurately be\nmapped to, and (2) making that representation adaptable with test-time\ninteraction data, instead of relying on it to perfectly capture the space of\nhuman policies based on the simulated population only. We study how to best\nlearn such a representation by evaluating on purposefully constructed OOD test\npolicies. We find that sim2real methods that encode environment (or population)\nparameters and work well in tasks that robots do in isolation, do not work well\nin assistance. In assistance, it seems crucial to train the representation\nbased on the history of interaction directly, because that is what the robot\nwill have access to at test time. Further, training these representations to\nthen predict human actions not only gives them better structure, but also\nenables them to be fine-tuned at test-time, when the robot observes the partner\nact. https://adaptive-caregiver.github.io.",
    "descriptor": "",
    "authors": [
      "Jerry Zhi-Yang He",
      "Aditi Raghunathan",
      "Daniel S. Brown",
      "Zackory Erickson",
      "Anca D. Dragan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.03175"
  },
  {
    "id": "arXiv:2212.03177",
    "title": "Privacy-Preserving Visual Localization with Event Cameras",
    "abstract": "We present a robust, privacy-preserving visual localization algorithm using\nevent cameras. While event cameras can potentially make robust localization due\nto high dynamic range and small motion blur, the sensors exhibit large domain\ngaps making it difficult to directly apply conventional image-based\nlocalization algorithms. To mitigate the gap, we propose applying\nevent-to-image conversion prior to localization which leads to stable\nlocalization. In the privacy perspective, event cameras capture only a fraction\nof visual information compared to normal cameras, and thus can naturally hide\nsensitive visual details. To further enhance the privacy protection in our\nevent-based pipeline, we introduce privacy protection at two levels, namely\nsensor and network level. Sensor level protection aims at hiding facial details\nwith lightweight filtering while network level protection targets hiding the\nentire user's view in private scene applications using a novel neural network\ninference pipeline. Both levels of protection involve light-weight computation\nand incur only a small performance loss. We thus project our method to serve as\na building block for practical location-based services using event cameras. The\ncode and dataset will be made public through the following link:\nhttps://github.com/82magnolia/event_localization.",
    "descriptor": "",
    "authors": [
      "Junho Kim",
      "Young Min Kim",
      "Yicheng Wu",
      "Ramzi Zahreddine",
      "Weston A. Welge",
      "Gurunandan Krishnan",
      "Sizhuo Ma",
      "Jian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03177"
  },
  {
    "id": "arXiv:2212.03178",
    "title": "Longest Common Substring in Longest Common Subsequence's Solution  Service: A Novel Hyper-Heuristic",
    "abstract": "The Longest Common Subsequence (LCS) is the problem of finding a subsequence\namong a set of strings that has two properties of being common to all and is\nthe longest. The LCS has applications in computational biology and text\nediting, among many others. Due to the NP-hardness of the general longest\ncommon subsequence, numerous heuristic algorithms and solvers have been\nproposed to give the best possible solution for different sets of strings. None\nof them has the best performance for all types of sets. In addition, there is\nno method to specify the type of a given set of strings. Besides that, the\navailable hyper-heuristic is not efficient and fast enough to solve this\nproblem in real-world applications. This paper proposes a novel hyper-heuristic\nto solve the longest common subsequence problem using a novel criterion to\nclassify a set of strings based on their similarity. To do this, we offer a\ngeneral stochastic framework to identify the type of a given set of strings.\nFollowing that, we introduce the set similarity dichotomizer ($S^2D$) algorithm\nbased on the framework that divides the type of sets into two. This algorithm\nis introduced for the first time in this paper and opens a new way to go beyond\nthe current LCS solvers. Then, we present a novel hyper-heuristic that exploits\nthe $S^2D$ and one of the internal properties of the set to choose the best\nmatching heuristic among a set of heuristics. We compare the results on\nbenchmark datasets with the best heuristics and hyper-heuristics. The results\nshow a higher performance of our proposed hyper-heuristic in both quality of\nsolutions and run time factors.",
    "descriptor": "",
    "authors": [
      "Alireza Abdi",
      "Masih Hajsaeedi",
      "Mohsen Hooshmand"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.03178"
  },
  {
    "id": "arXiv:2212.03179",
    "title": "Where the Bee Sucks -- A Dynamic Bayesian Network Approach to Decision  Support for Pollinator Abundance Strategies",
    "abstract": "For policymakers wishing to make evidence-based decisions, one of the\nchallenges is how to combine the relevant information and evidence in a\ncoherent and defensible manner in order to formulate and evaluate candidate\npolicies. Policymakers often need to rely on experts with disparate fields of\nexpertise when making policy choices in complex, multi-faceted, dynamic\nenvironments such as those dealing with ecosystem services. The pressures\naffecting the survival and pollination capabilities of honey bees (Apis\nmellifera), wild bees and other pollinators is well-documented, but incomplete.\nIn order to estimate the potential effectiveness of various candidate policies\nto support pollination services, there is an urgent need to quantify the effect\nof various combinations of variables on the pollination ecosystem service,\nutilising available information, models and expert judgement. In this paper, we\npresent a new application of the integrating decision support system\nmethodology for combining inputs from multiple panels of experts to evaluate\npolicies to support an abundant pollinator population.",
    "descriptor": "",
    "authors": [
      "Martine J. Barons",
      "Aditi Shenvi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2212.03179"
  },
  {
    "id": "arXiv:2212.03181",
    "title": "Reinforcement Learning for Signal Temporal Logic using Funnel-Based  Approach",
    "abstract": "Signal Temporal Logic (STL) is a powerful framework for describing the\ncomplex temporal and logical behaviour of the dynamical system. Several works\npropose a method to find a controller for the satisfaction of STL specification\nusing reinforcement learning but fail to address either the issue of robust\nsatisfaction in continuous state space or ensure the tractability of the\napproach. In this paper, leveraging the concept of funnel functions, we propose\na tractable reinforcement learning algorithm to learn a time-dependent policy\nfor robust satisfaction of STL specification in continuous state space. We\ndemonstrate the utility of our approach on several tasks using a pendulum and\nmobile robot examples.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Naman Saxena",
      "Gorantla Sandeep",
      "Pushpak Jagtap"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03181"
  },
  {
    "id": "arXiv:2212.03182",
    "title": "Overlapping oriented imbalanced ensemble learning method based on  projective clustering and stagewise hybrid sampling",
    "abstract": "The challenge of imbalanced learning lies not only in class imbalance\nproblem, but also in the class overlapping problem which is complex. However,\nmost of the existing algorithms mainly focus on the former. The limitation\nprevents the existing methods from breaking through. To address this\nlimitation, this paper proposes an ensemble learning algorithm based on dual\nclustering and stage-wise hybrid sampling (DCSHS). The DCSHS has three parts.\nFirstly, we design a projection clustering combination framework (PCC) guided\nby Davies-Bouldin clustering effectiveness index (DBI), which is used to obtain\nhigh-quality clusters and combine them to obtain a set of cross-complete\nsubsets (CCS) with balanced class and low overlapping. Secondly, according to\nthe characteristics of subset classes, a stage-wise hybrid sampling algorithm\nis designed to realize the de-overlapping and balancing of subsets. Finally, a\nprojective clustering transfer mapping mechanism (CTM) is constructed for all\nprocessed subsets by means of transfer learning, thereby reducing class\noverlapping and explore structure information of samples. The major advantage\nof our algorithm is that it can exploit the intersectionality of the CCS to\nrealize the soft elimination of overlapping majority samples, and learn as much\ninformation of overlapping samples as possible, thereby enhancing the class\noverlapping while class balancing. In the experimental section, more than 30\npublic datasets and over ten representative algorithms are chosen for\nverification. The experimental results show that the DCSHS is significantly\nbest in terms of various evaluation criteria.",
    "descriptor": "\nComments: 23 pages, 3 figures\n",
    "authors": [
      "Fan Li",
      "Bo Wang",
      "Pin Wang",
      "Yongming Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03182"
  },
  {
    "id": "arXiv:2212.03183",
    "title": "A novel convergence enhancement method based on Online Dimension  Reduction Optimization",
    "abstract": "Iterative steady-state solvers are widely used in computational fluid\ndynamics. Unfortunately, it is difficult to obtain steady-state solution for\nunstable problem caused by physical instability and numerical instability.\nOptimization is a better choice for solving unstable problem because\nsteady-state solution is always the extreme point of optimization regardless of\nwhether the problem is unstable or ill-conditioned, but it is difficult to\nsolve partial differential equations (PDEs) due to too many optimization\nvariables. In this study, we propose an Online Dimension Reduction Optimization\n(ODRO) method to enhance the convergence of the traditional iterative method to\nobtain the steady-state solution of unstable problem. This method performs\nproper orthogonal decomposition (POD) on the snapshots collected from a few\niteration steps, optimizes PDE residual in the POD subspace to get a solution\nwith lower residual, and then continues to iterate with the optimized solution\nas the initial value, repeating the above three steps until the residual\nconverges. Several typical cases show that the proposed method can efficiently\ncalculate the steady-state solution of unstable problem with both the high\nefficiency and robustness of the iterative method and the good convergence of\nthe optimization method. In addition, this method is easy to implement in\nalmost any iterative solver with minimal code modification.",
    "descriptor": "",
    "authors": [
      "Wenbo Cao",
      "Yilang Liu",
      "Xianglin Shan",
      "Chuanqiang Gao",
      "Weiwei Zhang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2212.03183"
  },
  {
    "id": "arXiv:2212.03184",
    "title": "The AI Definition and a Program Which Satisfies this Definition",
    "abstract": "We will consider all policies of the agent and will prove that one of them is\nthe best performing policy. While that policy is not computable, computable\npolicies do exist in its proximity. We will define AI as a computable policy\nwhich is sufficiently proximal to the best performing policy. Before we can\ndefine the agent's best performing policy, we need a language for description\nof the world. We will also use this language to develop a program which\nsatisfies the AI definition. The program will first understand the world by\ndescribing it in the selected language. The program will then use the\ndescription in order to predict the future and select the best possible move.\nWhile this program is extremely inefficient and practically unusable, it can be\nimproved by refining both the language for description of the world and the\nalgorithm used to predict the future. This can yield a program which is both\nefficient and consistent with the AI definition.",
    "descriptor": "",
    "authors": [
      "Dimiter Dobrev"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03184"
  },
  {
    "id": "arXiv:2212.03185",
    "title": "Rethinking the Objectives of Vector-Quantized Tokenizers for Image  Synthesis",
    "abstract": "Vector-Quantized (VQ-based) generative models usually consist of two basic\ncomponents, i.e., VQ tokenizers and generative transformers. Prior research\nfocuses on improving the reconstruction fidelity of VQ tokenizers but rarely\nexamines how the improvement in reconstruction affects the generation ability\nof generative transformers. In this paper, we surprisingly find that improving\nthe reconstruction fidelity of VQ tokenizers does not necessarily improve the\ngeneration. Instead, learning to compress semantic features within VQ\ntokenizers significantly improves generative transformers' ability to capture\ntextures and structures. We thus highlight two competing objectives of VQ\ntokenizers for image synthesis: semantic compression and details preservation.\nDifferent from previous work that only pursues better details preservation, we\npropose Semantic-Quantized GAN (SeQ-GAN) with two learning phases to balance\nthe two objectives. In the first phase, we propose a semantic-enhanced\nperceptual loss for better semantic compression. In the second phase, we fix\nthe encoder and codebook, but enhance and finetune the decoder to achieve\nbetter details preservation. The proposed SeQ-GAN greatly improves VQ-based\ngenerative models and surpasses the GAN and Diffusion Models on both\nunconditional and conditional image generation. Our SeQ-GAN (364M) achieves\nFrechet Inception Distance (FID) of 6.25 and Inception Score (IS) of 140.9 on\n256x256 ImageNet generation, a remarkable improvement over VIT-VQGAN (714M),\nwhich obtains 11.2 FID and 97.2 IS.",
    "descriptor": "",
    "authors": [
      "Yuchao Gu",
      "Xintao Wang",
      "Yixiao Ge",
      "Ying Shan",
      "Xiaohu Qie",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03185"
  },
  {
    "id": "arXiv:2212.03186",
    "title": "Towards Better User Requirements: How to Involve Human Participants in  XAI Research",
    "abstract": "Human-Center eXplainable AI (HCXAI) literature identifies the need to address\nuser needs. This paper examines how existing XAI research involves human users\nin designing and developing XAI systems and identifies limitations in current\npractices, especially regarding how researchers identify user requirements.\nFinally, we propose several suggestions on how to derive better user\nrequirements.",
    "descriptor": "\nComments: 4 pages. 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Thu Nguyen",
      "Jichen Zhu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2212.03186"
  },
  {
    "id": "arXiv:2212.03189",
    "title": "Towards Energy Efficient Mobile Eye Tracking for AR Glasses through  Optical Sensor Technology",
    "abstract": "After the introduction of smartphones and smartwatches, AR glasses are\nconsidered the next breakthrough in the field of wearables. While the\ntransition from smartphones to smartwatches was based mainly on established\ndisplay technologies, the display technology of AR glasses presents a\ntechnological challenge. Many display technologies, such as retina projectors,\nare based on continuous adaptive control of the display based on the user's\npupil position. Furthermore, head-mounted systems require an adaptation and\nextension of established interaction concepts to provide the user with an\nimmersive experience. Eye-tracking is a crucial technology to help AR glasses\nachieve a breakthrough through optimized display technology and gaze-based\ninteraction concepts. Available eye-tracking technologies, such as VOG, do not\nmeet the requirements of AR glasses, especially regarding power consumption,\nrobustness, and integrability. To further overcome these limitations and push\nmobile eye-tracking for AR glasses forward, novel laser-based eye-tracking\nsensor technologies are researched in this thesis. The thesis contributes to a\nsignificant scientific advancement towards energy-efficient mobile eye-tracking\nfor AR glasses.",
    "descriptor": "\nComments: Accepted PhD Thesis at the University of T\\\"ubingen by Johannes Meyer\n",
    "authors": [
      "Johannes Meyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.03189"
  },
  {
    "id": "arXiv:2212.03191",
    "title": "InternVideo: General Video Foundation Models via Generative and  Discriminative Learning",
    "abstract": "The foundation models have recently shown excellent performance on a variety\nof downstream tasks in computer vision. However, most existing vision\nfoundation models simply focus on image-level pretraining and adpation, which\nare limited for dynamic and complex video-level understanding tasks. To fill\nthe gap, we present general video foundation models, InternVideo, by taking\nadvantage of both generative and discriminative self-supervised video learning.\nSpecifically, InternVideo efficiently explores masked video modeling and\nvideo-language contrastive learning as the pretraining objectives, and\nselectively coordinates video representations of these two complementary\nframeworks in a learnable manner to boost various video applications. Without\nbells and whistles, InternVideo achieves state-of-the-art performance on 39\nvideo datasets from extensive tasks including video action\nrecognition/detection, video-language alignment, and open-world video\napplications. Especially, our methods can obtain 91.1% and 77.2% top-1 accuracy\non the challenging Kinetics-400 and Something-Something V2 benchmarks,\nrespectively. All of these results effectively show the generality of our\nInternVideo for video understanding. The code will be released at\nhttps://github.com/OpenGVLab/InternVideo .",
    "descriptor": "\nComments: technical report\n",
    "authors": [
      "Yi Wang",
      "Kunchang Li",
      "Yizhuo Li",
      "Yinan He",
      "Bingkun Huang",
      "Zhiyu Zhao",
      "Hongjie Zhang",
      "Jilan Xu",
      "Yi Liu",
      "Zun Wang",
      "Sen Xing",
      "Guo Chen",
      "Junting Pan",
      "Jiashuo Yu",
      "Yali Wang",
      "Limin Wang",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03191"
  },
  {
    "id": "arXiv:2212.03194",
    "title": "DiffTune$^+$: Hyperparameter-Free Auto-Tuning using Auto-Differentiation",
    "abstract": "Controller tuning is a vital step to ensure the controller delivers its\ndesigned performance. DiffTune has been proposed as an automatic tuning method\nthat unrolls the dynamical system and controller into a computational graph and\nuses auto-differentiation to obtain the gradient for the controller's parameter\nupdate. However, DiffTune uses the vanilla gradient descent to iteratively\nupdate the parameter, in which the performance largely depends on the choice of\nthe learning rate (as a hyperparameter). In this paper, we propose to use\nhyperparameter-free methods to update the controller parameters. We find the\noptimal parameter update by maximizing the loss reduction, where a predicted\nloss based on the approximated state and control is used for the maximization.\nTwo methods are proposed to optimally update the parameters and are compared\nwith related variants in simulations on a Dubin's car and a quadrotor.\nSimulation experiments show that the proposed first-order method outperforms\nthe hyperparameter-based methods and is more robust than the second-order\nhyperparameter-free methods.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2209.10021. text overlap with arXiv:2209.10021\n",
    "authors": [
      "Sheng Cheng",
      "Lin Song",
      "Minkyung Kim",
      "Shenlong Wang",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.03194"
  },
  {
    "id": "arXiv:2212.03196",
    "title": "Collision-tolerant Aerial Robots: A Survey",
    "abstract": "As aerial robots are tasked to navigate environments of increased complexity,\nembedding collision tolerance in their design becomes important. In this survey\nwe review the current state-of-the-art within the niche field of\ncollision-tolerant micro aerial vehicles and present different design\napproaches identified in the literature, as well as methods that have focused\non autonomy functionalities that exploit collision resilience. Subsequently, we\ndiscuss the relevance to biological systems and provide our view on key\ndirections of future fruitful research.",
    "descriptor": "\nComments: 12 pages, 1 figure\n",
    "authors": [
      "Paolo De Petris",
      "Stephen J. Carlson",
      "Christos Papachristos",
      "Kostas Alexis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.03196"
  },
  {
    "id": "arXiv:2212.03201",
    "title": "Misspecification in Inverse Reinforcement Learning",
    "abstract": "The aim of Inverse Reinforcement Learning (IRL) is to infer a reward function\n$R$ from a policy $\\pi$. To do this, we need a model of how $\\pi$ relates to\n$R$. In the current literature, the most common models are optimality,\nBoltzmann rationality, and causal entropy maximisation. One of the primary\nmotivations behind IRL is to infer human preferences from human behaviour.\nHowever, the true relationship between human preferences and human behaviour is\nmuch more complex than any of the models currently used in IRL. This means that\nthey are misspecified, which raises the worry that they might lead to unsound\ninferences if applied to real-world data. In this paper, we provide a\nmathematical analysis of how robust different IRL models are to\nmisspecification, and answer precisely how the demonstrator policy may differ\nfrom each of the standard models before that model leads to faulty inferences\nabout the reward function $R$. We also introduce a framework for reasoning\nabout misspecification in IRL, together with formal tools that can be used to\neasily derive the misspecification robustness of new IRL models.",
    "descriptor": "",
    "authors": [
      "Joar Skalse",
      "Alessandro Abate"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03201"
  },
  {
    "id": "arXiv:2212.03217",
    "title": "A geospatial source selector for federated GeoSPARQL querying",
    "abstract": "Background: Geospatial linked data brings into the scope of the Semantic Web\nand its technologies, a wealth of datasets that combine semantically-rich\ndescriptions of resources with their geo-location. There are, however, various\nSemantic Web technologies where technical work is needed in order to achieve\nthe full integration of geospatial data, and federated query processing is one\nof these technologies. Methods: In this paper, we explore the idea of\nannotating data sources with a bounding polygon that summarizes the spatial\nextent of the resources in each data source, and of using such a summary as an\n(additional) source selection criterion in order to reduce the set of sources\nthat will be tested as potentially holding relevant data. We present our source\nselection method, and we discuss its correctness and implementation. Results:\nWe evaluate the proposed source selection using three different types of\nsummaries with different degrees of accuracy, against not using geospatial\nsummaries. We use datasets and queries from a practical use case that combines\ncrop-type data with water availability data for food security. The experimental\nresults suggest that more complex summaries lead to slower source selection\ntimes, but also to more precise exclusion of unneeded sources. Moreover, we\nobserve the source selection runtime is (partially or fully) recovered by\nshorter planning and execution runtimes. As a result, the federated sources are\nnot burdened by pointless querying from the federation engine. Conclusions: The\nevaluation draws on data and queries from the agroenvironmental domain and\nshows that our source selection method substantially improves the effectiveness\nof federated GeoSPARQL query processing.",
    "descriptor": "\nComments: Published in Open Research Europe\n",
    "authors": [
      "Antonis Troumpoukis",
      "Stasinos Konstantopoulos",
      "Nefeli Prokopaki-Kostopoulou"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2212.03217"
  },
  {
    "id": "arXiv:2212.03218",
    "title": "The Future of Integrated Digital Governance in the EU: EBSI and GLASS",
    "abstract": "In the past, citizen identity has been used within siloed data areas, and\nwhere government agencies have linked citizens across different services. Often\nthese identifiers were simple alphanumeric strings, and which were assigned by\ngovernment agencies. These identifiers are then linked in some way to the\ncitizen, and where citizens often have to request access to documents that\nprove certain aspects of their citizenship. These systems, too, often use\npaper-based approaches and have little in the way of real digital trust. But,\nin an information age, we now have the ability to provide unique digital\nidentifiers for each citizen, and then for them to claim access to their\ncitizenship documents. This might be in the form of their academic\nqualifications, their tax status, or even their driver's licence. While, at one\ntime, these documents were either held by the trusted issuers of the\ninformation, or in a paper form, we now have the opportunity for these\ndocuments to be linked to a citizen wallet. This would allow citizens the\nopportunity to request documents once, but use them many times. A core part of\nthis is the unique private key associated with the citizen, and in the usage of\ndigital signing by trusted entities. While many countries have struggled to\nimplement a digital identity scheme, the EU Commission has the ambition to\nprovide every EU citizen with a digital wallet, and thus moved towards improved\nfreedom of movement and integration of the countries within the EU. The scale\nof this cannot be underestimated, and it could break down the barriers that\nhave been created by legacy systems. In order to harmonise the integration of\nboth citizens and trusted signers, the EU Commission proposes the usage of EBSI\n(European Blockchain Services Infrastructure).",
    "descriptor": "",
    "authors": [
      "William J Buchanan",
      "Mwarwan Abubakar",
      "Owen Lo",
      "Christos Chrysoulas",
      "Nikolaos Pitropakis",
      "Pavlos Papadopoulos",
      "Sarwar Sayeed",
      "Marc Sel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.03218"
  },
  {
    "id": "arXiv:2212.03220",
    "title": "Visual Query Tuning: Towards Effective Usage of Intermediate  Representations for Parameter and Memory Efficient Transfer Learning",
    "abstract": "Intermediate features of a pre-trained model have been shown informative for\nmaking accurate predictions on downstream tasks, even if the model backbone is\nkept frozen. The key challenge is how to utilize these intermediate features\ngiven their gigantic amount. We propose visual query tuning (VQT), a simple yet\neffective approach to aggregate intermediate features of Vision Transformers.\nThrough introducing a handful of learnable ``query'' tokens to each layer, VQT\nleverages the inner workings of Transformers to ``summarize'' rich intermediate\nfeatures of each layer, which can then be used to train the prediction heads of\ndownstream tasks. As VQT keeps the intermediate features intact and only learns\nto combine them, it enjoys memory efficiency in training, compared to many\nother parameter-efficient fine-tuning approaches that learn to adapt features\nand need back-propagation through the entire backbone. This also suggests the\ncomplementary role between VQT and those approaches in transfer learning.\nEmpirically, VQT consistently surpasses the state-of-the-art approach that\nutilizes intermediate features for transfer learning and outperforms full\nfine-tuning in many cases. Compared to parameter-efficient approaches that\nadapt features, VQT achieves much higher accuracy under memory constraints.\nMost importantly, VQT is compatible with these approaches to attain even higher\naccuracy, making it a simple add-on to further boost transfer learning.",
    "descriptor": "\nComments: Cheng-Hao Tu and Zheda Mai contributed equally to this work\n",
    "authors": [
      "Cheng-Hao Tu",
      "Zheda Mai",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03220"
  },
  {
    "id": "arXiv:2212.03221",
    "title": "ADIR: Adaptive Diffusion for Image Reconstruction",
    "abstract": "In recent years, denoising diffusion models have demonstrated outstanding\nimage generation performance. The information on natural images captured by\nthese models is useful for many image reconstruction applications, where the\ntask is to restore a clean image from its degraded observations. In this work,\nwe propose a conditional sampling scheme that exploits the prior learned by\ndiffusion models while retaining agreement with the observations. We then\ncombine it with a novel approach for adapting pretrained diffusion denoising\nnetworks to their input. We examine two adaption strategies: the first uses\nonly the degraded image, while the second, which we advocate, is performed\nusing images that are ``nearest neighbors'' of the degraded image, retrieved\nfrom a diverse dataset using an off-the-shelf visual-language model. To\nevaluate our method, we test it on two state-of-the-art publicly available\ndiffusion models, Stable Diffusion and Guided Diffusion. We show that our\nproposed `adaptive diffusion for image reconstruction' (ADIR) approach achieves\na significant improvement in the super-resolution, deblurring, and text-based\nediting tasks.",
    "descriptor": "\nComments: Our code and additional results are available online in the project page this https URL\n",
    "authors": [
      "Shady Abu-Hussein",
      "Tom Tirer",
      "Raja Giryes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2212.03221"
  },
  {
    "id": "arXiv:2212.03222",
    "title": "LawngNLI: A Long-Premise Benchmark for In-Domain Generalization from  Short to Long Contexts and for Implication-Based Retrieval",
    "abstract": "Natural language inference has trended toward studying contexts beyond the\nsentence level. An important application area is law: past cases often do not\nforetell how they apply to new situations and implications must be inferred.\nThis paper introduces LawngNLI, constructed from U.S. legal opinions with\nautomatic labels with high human-validated accuracy. Premises are long and\nmultigranular. Experiments show two use cases. First, LawngNLI can benchmark\nfor in-domain generalization from short to long contexts. It has remained\nunclear if large-scale long-premise NLI datasets actually need to be\nconstructed: near-top performance on long premises could be achievable by\nfine-tuning using short premises. Without multigranularity, benchmarks cannot\ndistinguish lack of fine-tuning on long premises versus domain shift between\nshort and long datasets. In contrast, our long and short premises share the\nsame examples and domain. Models fine-tuned using several past NLI datasets\nand/or our short premises fall short of top performance on our long premises.\nSo for at least certain domains (such as ours), large-scale long-premise\ndatasets are needed. Second, LawngNLI can benchmark for implication-based\nretrieval. Queries are entailed or contradicted by target documents, allowing\nusers to move between arguments and evidence. Leading retrieval models perform\nreasonably zero shot on a LawngNLI-derived retrieval task. We compare different\nsystems for re-ranking, including lexical overlap and cross-encoders fine-tuned\nusing a modified LawngNLI or past NLI datasets. LawngNLI can train and test\nsystems for implication-based case retrieval and argumentation.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "William Bruno",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.03222"
  },
  {
    "id": "arXiv:2212.03228",
    "title": "ISAACS: Iterative Soft Adversarial Actor-Critic for Safety",
    "abstract": "The deployment of robots in uncontrolled environments requires them to\noperate robustly under previously unseen scenarios, like irregular terrain and\nwind conditions. Unfortunately, while rigorous safety frameworks from robust\noptimal control theory scale poorly to high-dimensional nonlinear dynamics,\ncontrol policies computed by more tractable \"deep\" methods lack guarantees and\ntend to exhibit little robustness to uncertain operating conditions. This work\nintroduces a novel approach enabling scalable synthesis of robust\nsafety-preserving controllers for robotic systems with general nonlinear\ndynamics subject to bounded modeling error by combining game-theoretic safety\nanalysis with adversarial reinforcement learning in simulation. Following a\nsoft actor-critic scheme, a safety-seeking fallback policy is co-trained with\nan adversarial \"disturbance\" agent that aims to invoke the worst-case\nrealization of model error and training-to-deployment discrepancy allowed by\nthe designer's uncertainty. While the learned control policy does not\nintrinsically guarantee safety, it is used to construct a real-time safety\nfilter (or shield) with robust safety guarantees based on forward reachability\nrollouts. This shield can be used in conjunction with a safety-agnostic control\npolicy, precluding any task-driven actions that could result in loss of safety.\nWe evaluate our learning-based safety approach in a 5D race car simulator,\ncompare the learned safety policy to the numerically obtained optimal solution,\nand empirically validate the robust safety guarantee of our proposed safety\nshield against worst-case model discrepancy.",
    "descriptor": "\nComments: Submitted to 5th L4DC for review\n",
    "authors": [
      "Kai-Chieh Hsu",
      "Duy Phuong Nguyen",
      "Jaime Fern\u00e1ndez Fisac"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.03228"
  },
  {
    "id": "arXiv:2212.03229",
    "title": "Rethinking Video ViTs: Sparse Video Tubes for Joint Image and Video  Learning",
    "abstract": "We present a simple approach which can turn a ViT encoder into an efficient\nvideo model, which can seamlessly work with both image and video inputs. By\nsparsely sampling the inputs, the model is able to do training and inference\nfrom both inputs. The model is easily scalable and can be adapted to\nlarge-scale pre-trained ViTs without requiring full finetuning. The model\nachieves SOTA results and the code will be open-sourced.",
    "descriptor": "",
    "authors": [
      "AJ Piergiovanni",
      "Weicheng Kuo",
      "Anelia Angelova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03229"
  },
  {
    "id": "arXiv:2212.03230",
    "title": "Switching to Discriminative Image Captioning by Relieving a Bottleneck  of Reinforcement Learning",
    "abstract": "Discriminativeness is a desirable feature of image captions: captions should\ndescribe the characteristic details of input images. However, recent\nhigh-performing captioning models, which are trained with reinforcement\nlearning (RL), tend to generate overly generic captions despite their high\nperformance in various other criteria. First, we investigate the cause of the\nunexpectedly low discriminativeness and show that RL has a deeply rooted side\neffect of limiting the output words to high-frequency words. The limited\nvocabulary is a severe bottleneck for discriminativeness as it is difficult for\na model to describe the details beyond its vocabulary. Then, based on this\nidentification of the bottleneck, we drastically recast discriminative image\ncaptioning as a much simpler task of encouraging low-frequency word generation.\nHinted by long-tail classification and debiasing methods, we propose methods\nthat easily switch off-the-shelf RL models to discriminativeness-aware models\nwith only a single-epoch fine-tuning on the part of the parameters. Extensive\nexperiments demonstrate that our methods significantly enhance the\ndiscriminativeness of off-the-shelf RL models and even outperform previous\ndiscriminativeness-aware methods with much smaller computational costs.\nDetailed analysis and human evaluation also verify that our methods boost the\ndiscriminativeness without sacrificing the overall quality of captions.",
    "descriptor": "\nComments: WACV 2023 (19 pages, 9 figures)\n",
    "authors": [
      "Ukyo Honda",
      "Taro Watanabe",
      "Yuji Matsumoto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.03230"
  },
  {
    "id": "arXiv:2212.03232",
    "title": "Learning the joint distribution of two sequences using little or no  paired data",
    "abstract": "We present a noisy channel generative model of two sequences, for example\ntext and speech, which enables uncovering the association between the two\nmodalities when limited paired data is available. To address the intractability\nof the exact model under a realistic data setup, we propose a variational\ninference approximation. To train this variational model with categorical data,\nwe propose a KL encoder loss approach which has connections to the wake-sleep\nalgorithm. Identifying the joint or conditional distributions by only observing\nunpaired samples from the marginals is only possible under certain conditions\nin the data distribution and we discuss under what type of conditional\nindependence assumptions that might be achieved, which guides the architecture\ndesigns. Experimental results show that even tiny amount of paired data (5\nminutes) is sufficient to learn to relate the two modalities (graphemes and\nphonemes here) when a massive amount of unpaired data is available, paving the\npath to adopting this principled approach for all seq2seq models in low data\nresource regimes.",
    "descriptor": "",
    "authors": [
      "Soroosh Mariooryad",
      "Matt Shannon",
      "Siyuan Ma",
      "Tom Bagby",
      "David Kao",
      "Daisy Stanton",
      "Eric Battenberg",
      "RJ Skerry-Ryan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.03232"
  },
  {
    "id": "arXiv:2212.03235",
    "title": "Towards A Most Probable Recovery in Optical Imaging",
    "abstract": "Light is a complex-valued field. The intensity and phase of the field are\naffected by imaged objects. However, imaging sensors measure only real-valued\nnon-negative intensities. This results in a nonlinear relation between the\nmeasurements and the unknown imaged objects. Moreover, the sensor readouts are\ncorrupted by Poissonian-distributed photon noise. In this work, we seek the\nmost probable object (or clear image), given noisy measurements, that is,\nmaximizing the a-posteriori probability of the sought variables. Hence, we\ngeneralize annealed Langevin dynamics, tackling fundamental challenges in\noptical imaging, including phase recovery and Poisson (photon) denoising. We\nleverage deep neural networks, not for explicit recovery of the imaged object,\nbut as an approximate gradient for a prior term. We show results on empirical\ndata, acquired by a real experiment. We further show results of simulations.",
    "descriptor": "\nComments: 24 pages, 21 figures\n",
    "authors": [
      "Nadav Torem",
      "Roi Ronen",
      "Yoav Y. Schechner",
      "Michael Elad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.03235"
  },
  {
    "id": "arXiv:2212.03236",
    "title": "Self-Supervised Correspondence Estimation via Multiview Registration",
    "abstract": "Video provides us with the spatio-temporal consistency needed for visual\nlearning. Recent approaches have utilized this signal to learn correspondence\nestimation from close-by frame pairs. However, by only relying on close-by\nframe pairs, those approaches miss out on the richer long-range consistency\nbetween distant overlapping frames. To address this, we propose a\nself-supervised approach for correspondence estimation that learns from\nmultiview consistency in short RGB-D video sequences. Our approach combines\npairwise correspondence estimation and registration with a novel SE(3)\ntransformation synchronization algorithm. Our key insight is that\nself-supervised multiview registration allows us to obtain correspondences over\nlonger time frames; increasing both the diversity and difficulty of sampled\npairs. We evaluate our approach on indoor scenes for correspondence estimation\nand RGB-D pointcloud registration and find that we perform on-par with\nsupervised approaches.",
    "descriptor": "\nComments: Accepted to WACV 2023. Project page: this https URL\n",
    "authors": [
      "Mohamed El Banani",
      "Ignacio Rocco",
      "David Novotny",
      "Andrea Vedaldi",
      "Natalia Neverova",
      "Justin Johnson",
      "Benjamin Graham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03236"
  },
  {
    "id": "arXiv:2212.03237",
    "title": "RANA: Relightable Articulated Neural Avatars",
    "abstract": "We propose RANA, a relightable and articulated neural avatar for the\nphotorealistic synthesis of humans under arbitrary viewpoints, body poses, and\nlighting. We only require a short video clip of the person to create the avatar\nand assume no knowledge about the lighting environment. We present a novel\nframework to model humans while disentangling their geometry, texture, and also\nlighting environment from monocular RGB videos. To simplify this otherwise\nill-posed task we first estimate the coarse geometry and texture of the person\nvia SMPL+D model fitting and then learn an articulated neural representation\nfor photorealistic image generation. RANA first generates the normal and albedo\nmaps of the person in any given target body pose and then uses spherical\nharmonics lighting to generate the shaded image in the target lighting\nenvironment. We also propose to pretrain RANA using synthetic images and\ndemonstrate that it leads to better disentanglement between geometry and\ntexture while also improving robustness to novel body poses. Finally, we also\npresent a new photorealistic synthetic dataset, Relighting Humans, to\nquantitatively evaluate the performance of the proposed approach.",
    "descriptor": "\nComments: project page: this https URL\n",
    "authors": [
      "Umar Iqbal",
      "Akin Caliskan",
      "Koki Nagano",
      "Sameh Khamis",
      "Pavlo Molchanov",
      "Jan Kautz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03237"
  },
  {
    "id": "arXiv:2212.03238",
    "title": "Walk These Ways: Tuning Robot Control for Generalization with  Multiplicity of Behavior",
    "abstract": "Learned locomotion policies can rapidly adapt to diverse environments similar\nto those experienced during training but lack a mechanism for fast tuning when\nthey fail in an out-of-distribution test environment. This necessitates a slow\nand iterative cycle of reward and environment redesign to achieve good\nperformance on a new task. As an alternative, we propose learning a single\npolicy that encodes a structured family of locomotion strategies that solve\ntraining tasks in different ways, resulting in Multiplicity of Behavior (MoB).\nDifferent strategies generalize differently and can be chosen in real-time for\nnew tasks or environments, bypassing the need for time-consuming retraining. We\nrelease a fast, robust open-source MoB locomotion controller, Walk These Ways,\nthat can execute diverse gaits with variable footswing, posture, and speed,\nunlocking diverse downstream tasks: crouching, hopping, high-speed running,\nstair traversal, bracing against shoves, rhythmic dance, and more. Video and\ncode release: https://gmargo11.github.io/walk-these-ways/",
    "descriptor": "\nComments: Oral presentation at CoRL 2022. Website at this https URL\n",
    "authors": [
      "Gabriel B Margolis",
      "Pulkit Agrawal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.03238"
  },
  {
    "id": "arXiv:2212.03239",
    "title": "Perspective Fields for Single Image Camera Calibration",
    "abstract": "Geometric camera calibration is often required for applications that\nunderstand the perspective of the image. We propose perspective fields as a\nrepresentation that models the local perspective properties of an image.\nPerspective Fields contain per-pixel information about the camera view,\nparameterized as an up vector and a latitude value. This representation has a\nnumber of advantages as it makes minimal assumptions about the camera model and\nis invariant or equivariant to common image editing operations like cropping,\nwarping, and rotation. It is also more interpretable and aligned with human\nperception. We train a neural network to predict Perspective Fields and the\npredicted Perspective Fields can be converted to calibration parameters easily.\nWe demonstrate the robustness of our approach under various scenarios compared\nwith camera calibration-based methods and show example applications in image\ncompositing.",
    "descriptor": "\nComments: Project Page this https URL\n",
    "authors": [
      "Linyi Jin",
      "Jianming Zhang",
      "Yannick Hold-Geoffroy",
      "Oliver Wang",
      "Kevin Matzen",
      "Matthew Sticha",
      "David F. Fouhey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03239"
  },
  {
    "id": "arXiv:2212.03241",
    "title": "P\u00d8DA: Prompt-driven Zero-shot Domain Adaptation",
    "abstract": "Domain adaptation has been vastly investigated in computer vision but still\nrequires access to target images at train time, which might be intractable in\nsome conditions, especially for long-tail samples. In this paper, we propose\nthe task of `Prompt-driven Zero-shot Domain Adaptation', where we adapt a model\ntrained on a source domain using only a general textual description of the\ntarget domain, i.e., a prompt. First, we leverage a pretrained contrastive\nvision-language model (CLIP) to optimize affine transformations of source\nfeatures, bringing them closer to target text embeddings, while preserving\ntheir content and semantics. Second, we show that augmented features can be\nused to perform zero-shot domain adaptation for semantic segmentation.\nExperiments demonstrate that our method significantly outperforms CLIP-based\nstyle transfer baselines on several datasets for the downstream task at hand.\nOur prompt-driven approach even outperforms one-shot unsupervised domain\nadaptation on some datasets, and gives comparable results on others. The code\nis available at https://github.com/astra-vision/PODA.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Mohammad Fahes",
      "Tuan-Hung Vu",
      "Andrei Bursuc",
      "Patrick P\u00e9rez",
      "Raoul de Charette"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03241"
  },
  {
    "id": "arXiv:2212.03242",
    "title": "Robust Point Cloud Segmentation with Noisy Annotations",
    "abstract": "Point cloud segmentation is a fundamental task in 3D. Despite recent progress\non point cloud segmentation with the power of deep networks, current learning\nmethods based on the clean label assumptions may fail with noisy labels. Yet,\nclass labels are often mislabeled at both instance-level and boundary-level in\nreal-world datasets. In this work, we take the lead in solving the\ninstance-level label noise by proposing a Point Noise-Adaptive Learning (PNAL)\nframework. Compared to noise-robust methods on image tasks, our framework is\nnoise-rate blind, to cope with the spatially variant noise rate specific to\npoint clouds. Specifically, we propose a point-wise confidence selection to\nobtain reliable labels from the historical predictions of each point. A\ncluster-wise label correction is proposed with a voting strategy to generate\nthe best possible label by considering the neighbor correlations. To handle\nboundary-level label noise, we also propose a variant ``PNAL-boundary \" with a\nprogressive boundary label cleaning strategy. Extensive experiments demonstrate\nits effectiveness on both synthetic and real-world noisy datasets. Even with\n$60\\%$ symmetric noise and high-level boundary noise, our framework\nsignificantly outperforms its baselines, and is comparable to the upper bound\ntrained on completely clean data. Moreover, we cleaned the popular real-world\ndataset ScanNetV2 for rigorous experiment. Our code and data is available at\nhttps://github.com/pleaseconnectwifi/PNAL.",
    "descriptor": "\nComments: To Appear at TPAMI 2022. arXiv admin note: substantial text overlap with arXiv:2107.14230\n",
    "authors": [
      "Shuquan Ye",
      "Dongdong Chen",
      "Songfang Han",
      "Jing Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03242"
  },
  {
    "id": "arXiv:2104.04543",
    "title": "Understanding Event-Generation Networks via Uncertainties",
    "abstract": "Following the growing success of generative neural networks in LHC\nsimulations, the crucial question is how to control the networks and assign\nuncertainties to their event output. We show how Bayesian normalizing flow or\ninvertible networks capture uncertainties from the training and turn them into\nan uncertainty on the event weight. Fundamentally, the interplay between\ndensity and uncertainty estimates indicates that these networks learn functions\nin analogy to parameter fits rather than binned event counts.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Marco Bellagente",
      "Manuel Hau\u00dfmann",
      "Michel Luchmann",
      "Tilman Plehn"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.04543"
  },
  {
    "id": "arXiv:2212.02401",
    "title": "Geometric Constellation Shaping with Low-complexity Demappers for Wiener  Phase-noise Channels",
    "abstract": "We show that separating the in-phase and quadrature component in optimized,\nmachine-learning based demappers of optical communications systems with\ngeometric constellation shaping reduces the required computational complexity\nwhilst retaining their good performance.",
    "descriptor": "\nComments: Submitted to the Optical Fiber Communication Conference (OFC) 2023\n",
    "authors": [
      "Andrej Rode",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2212.02401"
  },
  {
    "id": "arXiv:2212.02504",
    "title": "COmic: Convolutional Kernel Networks for Interpretable End-to-End  Learning on (Multi-)Omics Data",
    "abstract": "Motivation: The size of available omics datasets is steadily increasing with\ntechnological advancement in recent years. While this increase in sample size\ncan be used to improve the performance of relevant prediction tasks in\nhealthcare, models that are optimized for large datasets usually operate as\nblack boxes. In high stakes scenarios, like healthcare, using a black-box model\nposes safety and security issues. Without an explanation about molecular\nfactors and phenotypes that affected the prediction, healthcare providers are\nleft with no choice but to blindly trust the models. We propose a new type of\nartificial neural networks, named Convolutional Omics Kernel Networks (COmic).\nBy combining convolutional kernel networks with pathway-induced kernels, our\nmethod enables robust and interpretable end-to-end learning on omics datasets\nranging in size from a few hundred to several hundreds of thousands of samples.\nFurthermore, COmic can be easily adapted to utilize multi-omics data.\nResults: We evaluate the performance capabilities of COmic on six different\nbreast cancer cohorts. Additionally, we train COmic models on multi-omics data\nusing the METABRIC cohort. Our models perform either better or similar to\ncompetitors on both tasks. We show how the use of pathway-induced Laplacian\nkernels opens the black-box nature of neural networks and results in\nintrinsically interpretable models that eliminate the need for\n\\textit{post-hoc} explanation models.",
    "descriptor": "",
    "authors": [
      "Jonas C. Ditz",
      "Bernhard Reuter",
      "Nico Pfeifer"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02504"
  },
  {
    "id": "arXiv:2212.02531",
    "title": "Enhancing Quantum Adversarial Robustness by Randomized Encodings",
    "abstract": "The interplay between quantum physics and machine learning gives rise to the\nemergent frontier of quantum machine learning, where advanced quantum learning\nmodels may outperform their classical counterparts in solving certain\nchallenging problems. However, quantum learning systems are vulnerable to\nadversarial attacks: adding tiny carefully-crafted perturbations on legitimate\ninput samples can cause misclassifications. To address this issue, we propose a\ngeneral scheme to protect quantum learning systems from adversarial attacks by\nrandomly encoding the legitimate data samples through unitary or quantum error\ncorrection encoders. In particular, we rigorously prove that both global and\nlocal random unitary encoders lead to exponentially vanishing gradients (i.e.\nbarren plateaus) for any variational quantum circuits that aim to add\nadversarial perturbations, independent of the input data and the inner\nstructures of adversarial circuits and quantum classifiers. In addition, we\nprove a rigorous bound on the vulnerability of quantum classifiers under local\nunitary adversarial attacks. We show that random black-box quantum error\ncorrection encoders can protect quantum classifiers against local adversarial\nnoises and their robustness increases as we concatenate error correction codes.\nTo quantify the robustness enhancement, we adapt quantum differential privacy\nas a measure of the prediction stability for quantum classifiers. Our results\nestablish versatile defense strategies for quantum classifiers against\nadversarial perturbations, which provide valuable guidance to enhance the\nreliability and security for both near-term and future quantum learning\ntechnologies.",
    "descriptor": "",
    "authors": [
      "Weiyuan Gong",
      "Dong Yuan",
      "Weikang Li",
      "Dong-Ling Deng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02531"
  },
  {
    "id": "arXiv:2212.02548",
    "title": "Robustness of Quantum Algorithms for Nonconvex Optimization",
    "abstract": "Recent results suggest that quantum computers possess the potential to speed\nup nonconvex optimization problems. However, a crucial factor for the\nimplementation of quantum optimization algorithms is their robustness against\nexperimental and statistical noises. In this paper, we systematically study\nquantum algorithms for finding an $\\epsilon$-approximate second-order\nstationary point ($\\epsilon$-SOSP) of a $d$-dimensional nonconvex function, a\nfundamental problem in nonconvex optimization, with noisy zeroth- or\nfirst-order oracles as inputs. We first prove that, up to noise of\n$O(\\epsilon^{10}/d^5)$, accelerated perturbed gradient descent with quantum\ngradient estimation takes $O(\\log d/\\epsilon^{1.75})$ quantum queries to find\nan $\\epsilon$-SOSP. We then prove that perturbed gradient descent is robust to\nthe noise of $O(\\epsilon^6/d^4)$ and $O(\\epsilon/d^{0.5+\\zeta})$ for $\\zeta>0$\non the zeroth- and first-order oracles, respectively, which provides a quantum\nalgorithm with poly-logarithmic query complexity. We then propose a stochastic\ngradient descent algorithm using quantum mean estimation on the Gaussian\nsmoothing of noisy oracles, which is robust to $O(\\epsilon^{1.5}/d)$ and\n$O(\\epsilon/\\sqrt{d})$ noise on the zeroth- and first-order oracles,\nrespectively. The quantum algorithm takes $O(d^{2.5}/\\epsilon^{3.5})$ and\n$O(d^2/\\epsilon^3)$ queries to the two oracles, giving a polynomial speedup\nover the classical counterparts. Moreover, we characterize the domains where\nquantum algorithms can find an $\\epsilon$-SOSP with poly-logarithmic,\npolynomial, or exponential number of queries in $d$, or the problem is\ninformation-theoretically unsolvable even by an infinite number of queries. In\naddition, we prove an $\\Omega(\\epsilon^{-12/7})$ lower bound in $\\epsilon$ for\nany randomized classical and quantum algorithm to find an $\\epsilon$-SOSP using\neither noisy zeroth- or first-order oracles.",
    "descriptor": "",
    "authors": [
      "Weiyuan Gong",
      "Chenyi Zhang",
      "Tongyang Li"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.02548"
  },
  {
    "id": "arXiv:2212.02565",
    "title": "Distributed Bayesian Learning of Dynamic States",
    "abstract": "This work studies networked agents cooperating to track a dynamical state of\nnature under partial information. The proposed algorithm is a distributed\nBayesian filtering algorithm for finite-state hidden Markov models (HMMs). It\ncan be used for sequential state estimation tasks, as well as for modeling\nopinion formation over social networks under dynamic environments. We show that\nthe disagreement with the optimal centralized solution is asymptotically\nbounded for the class of geometrically ergodic state transition models, which\nincludes rapidly changing models. We also derive recursions for calculating the\nprobability of error and establish convergence under Gaussian observation\nmodels. Simulations are provided to illustrate the theory and to compare\nagainst alternative approaches.",
    "descriptor": "\nComments: Submitted for publication\n",
    "authors": [
      "Mert Kayaalp",
      "Virginia Bordignon",
      "Stefan Vlaski",
      "Vincenzo Matta",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.02565"
  },
  {
    "id": "arXiv:2212.02581",
    "title": "Editing a Woman's Voice",
    "abstract": "Do societal pressures encourage women to be more uncertain than their male\ncounterparts? We explore this question in the context of academic publishing,\nby examining the evolution of cautionary language used in manuscripts over the\ncourse of the review process. Comparing pre-submission versions of manuscripts\nto their published versions reveals a robust pattern: in first drafts of\nacademic manuscripts, male and female authors write with similar levels of\nuncertainty. However, when we trace those early drafts to their published\nversions, an 11 point gap in uncertainty arises. We take a multi-method\napproach to isolate the role of gender in changes in uncertainty, including\nextensive control variables and fixed effects, and by training an NLP model to\nsimulate all-else-equal counterfactual observations. Finally, we explore the\nrole of individual editors in contributing to the gender gap in changes in\nuncertainty; we do so by constructing a network of author-to-editor matches\nthat allow us to extract editor-specific fixed effects, capturing how a\nparticular editor influences female-authored papers relative to male-authored\npapers (the editor's author-gender gap). We find considerable variation in\neditors' author-gender gaps and find that these editor-specific effects account\nfor significant variation in the changes in uncertainty of an article through\nthe review process. Finally, we show that an editor's author-gender gap\ncorrelates with observable editor characteristics such as societal norms in\ntheir country-of-origin, their work history, and the year that they obtained\ntheir PhD. Overall, our study speaks to the critical role of editors in shaping\nhow female academics communicate.",
    "descriptor": "",
    "authors": [
      "Anna Costello",
      "Ekaterina Fedorova",
      "Zhijing Jin",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.02581"
  },
  {
    "id": "arXiv:2212.02616",
    "title": "Standard sound emergence as a predictor of short-term annoyance from  wind turbine noise",
    "abstract": "While sound emergence is used in several countries to regulate wind energy\ndevelopment, there is no published evidence that it is a relevant noise\ndescriptor for this purpose. In the present work, we carried out two listening\ntests to evaluate the merits of sound emergence. Three definitions of sound\nemergence were considered: the one in ISO 1996-1, sound emergence under\naudibility condition $e_{UAC}$, and spectral emergence $e_{SP}$. We also\nconsidered the specific to residual ratio and loudness metrics. In each\nlistening test, the sound stimuli consisted of 48 sound stimuli at 3 A-weighted\nsound pressure levels $\\{30, 40, 50\\}$~dB and 4 specific-to-residual ratios\n$\\{-10, -5, 0, +5 \\}$~dB. The results lead to the conclusion that short term\nannoyance is better predicted by the total sound pressure level than by sound\nemergence, whatever the definition considered for the latter, or than by the\nspecific to residual ratio. Short-term annoyance is slightly better predicted\nby $e_{UAC}$ than by $e$, while $e$ is a better predictor than $e_{SP}$. The\ntotal sound pressure level and the loudness metrics performed similarly.\nFurthermore, the results provide evidence that sound emergence is a poor\npredictor of the audibility of wind turbine sounds.",
    "descriptor": "\nComments: Submitted to the Journal or the Acoustical Society of America. 17 pages, 8 figures, 3 tables\n",
    "authors": [
      "Elise Ruaud",
      "Guillaume Dutilleux"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)",
      "Classical Physics (physics.class-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.02616"
  },
  {
    "id": "arXiv:2212.02634",
    "title": "QFT: Post-training quantization via fast joint finetuning of all degrees  of freedom",
    "abstract": "The post-training quantization (PTQ) challenge of bringing quantized neural\nnet accuracy close to original has drawn much attention driven by industry\ndemand. Many of the methods emphasize optimization of a specific\ndegree-of-freedom (DoF), such as quantization step size, preconditioning\nfactors, bias fixing, often chained to others in multi-step solutions. Here we\nrethink quantized network parameterization in HW-aware fashion, towards a\nunified analysis of all quantization DoF, permitting for the first time their\njoint end-to-end finetuning. Our single-step simple and extendable method,\ndubbed quantization-aware finetuning (QFT), achieves 4-bit weight quantization\nresults on-par with SoTA within PTQ constraints of speed and resource.",
    "descriptor": "\nComments: Presented at CADL2022 workshop at ECCV2022\n",
    "authors": [
      "Alex Finkelstein",
      "Ella Fuchs",
      "Idan Tal",
      "Mark Grobman",
      "Niv Vosco",
      "Eldad Meller"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02634"
  },
  {
    "id": "arXiv:2212.02653",
    "title": "Finite model theory for pseudovarieties and universal algebra:  preservation, definability and complexity",
    "abstract": "We explore new interactions between finite model theory and a number of\nclassical streams of universal algebra and semigroup theory. After refocussing\nsome finite model theoretic tools in universal algebraic context, we present a\nnumber of results. A key result is an example of a finite algebra whose variety\nis not finitely axiomatisable in first order logic, but which has first order\ndefinable finite membership problem. This algebra witnesses the simultaneous\nfailure of the {\\L}os-Tarski Theorem, the SP-preservation theorem and\nBirkhoff's HSP-preservation theorem at the finite level as well as providing a\nnegative solution to the first order formulation of the long-standing Eilenberg\nSch\\\"utzenberger problem. The example also shows that a pseudovariety without\nany finite pseudo-identity basis may be finitely axiomatisable in first order\nlogic. Other results include the undecidability of deciding first order\ndefinability of the pseudovariety of a finite algebra and a mapping from any\nfixed template constraint satisfaction problem to a first order equivalent\nvariety membership problem, thereby providing examples of variety membership\nproblems complete in each of the classes $\\texttt{L}$, $\\texttt{NL}$,\n$\\texttt{Mod}_p(\\texttt{L})$, $\\texttt{P}$ (provided they are nonempty), and\ninfinitely many others (depending on complexity-theoretic assumptions).",
    "descriptor": "",
    "authors": [
      "Lucy Ham",
      "Marcel Jackson"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.02653"
  },
  {
    "id": "arXiv:2212.02693",
    "title": "Online Saddle Point Tracking with Decision-Dependent Data",
    "abstract": "In this work, we consider a time-varying stochastic saddle point problem in\nwhich the objective is revealed sequentially, and the data distribution depends\non the decision variables. Problems of this type express the distributional\ndependence via a distributional map, and are known to have two distinct types\nof solutions--saddle points and equilibrium points. We demonstrate that, under\nsuitable conditions, online primal-dual type algorithms are capable of tracking\nequilibrium points. In contrast, since computing closed-form gradient of the\nobjective requires knowledge of the distributional map, we offer an online\nstochastic primal-dual algorithm for tracking equilibrium trajectories. We\nprovide bounds in expectation and in high probability, with the latter\nleveraging a sub-Weibull model for the gradient error. We illustrate our\nresults on an electric vehicle charging problem where responsiveness to prices\nfollows a location-scale family based distributional map.",
    "descriptor": "\nComments: Submitted to the Learning for Dynamics and Control Conference (L4DC)\n",
    "authors": [
      "Killian Wood",
      "Emiliano Dall'Anese"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.02693"
  },
  {
    "id": "arXiv:2212.02698",
    "title": "CDOpt: A Python Package for a Class of Riemannian Optimization",
    "abstract": "Optimization over the embedded submanifold defined by constraints $c(x) = 0$\nhas attracted much interest over the past few decades due to its wide\napplications in various areas. Plenty of related optimization packages have\nbeen developed based on Riemannian optimization approaches, which rely on some\nbasic geometrical materials of Riemannian manifolds, including retractions,\nvector transports, etc. These geometrical materials can be challenging to\ndetermine in general. Existing packages only accommodate a few well-known\nmanifolds whose geometrical materials are easily accessible. For other\nmanifolds which are not contained in these packages, the users have to develop\nthe geometric materials by themselves. In addition, it is not always tractable\nto adopt advanced features from various state-of-the-art unconstrained\noptimization solvers to Riemannian optimization approaches.\nWe introduce CDOpt (available at https://cdopt.github.io/), a user-friendly\nPython package for a class Riemannian optimization. Based on constraint\ndissolving approaches, Riemannian optimization problems are transformed into\ntheir equivalent unconstrained counterparts in CDOpt. Therefore, solving\nRiemannian optimization problems through CDOpt directly benefits from various\nexisting solvers and the rich expertise gained over decades for unconstrained\noptimization. Moreover, all the computations in CDOpt related to any manifold\nin question are conducted on its constraints expression, hence users can easily\ndefine new manifolds in CDOpt without any background on differential geometry.\nFurthermore, CDOpt extends the neural layers from PyTorch and Flax, thus allows\nusers to train manifold constrained neural networks directly by the solvers for\nunconstrained optimization. Extensive numerical experiments demonstrate that\nCDOpt is highly efficient and robust in solving various classes of Riemannian\noptimization problems.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Nachuan Xiao",
      "Xiaoyin Hu",
      "Xin Liu",
      "Kim-Chuan Toh"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2212.02698"
  },
  {
    "id": "arXiv:2212.02721",
    "title": "A Novel Deep Reinforcement Learning Based Automated Stock Trading System  Using Cascaded LSTM Networks",
    "abstract": "More and more stock trading strategies are constructed using deep\nreinforcement learning (DRL) algorithms, but DRL methods originally widely used\nin the gaming community are not directly adaptable to financial data with low\nsignal-to-noise ratios and unevenness, and thus suffer from performance\nshortcomings. In this paper, to capture the hidden information, we propose a\nDRL based stock trading system using cascaded LSTM, which first uses LSTM to\nextract the time-series features from stock daily data, and then the features\nextracted are fed to the agent for training, while the strategy functions in\nreinforcement learning also use another LSTM for training. Experiments in DJI\nin the US market and SSE50 in the Chinese stock market show that our model\noutperforms previous baseline models in terms of cumulative returns and Sharp\nratio, and this advantage is more significant in the Chinese stock market, a\nmerging market. It indicates that our proposed method is a promising way to\nbuild a automated stock trading system.",
    "descriptor": "",
    "authors": [
      "Jie Zou",
      "Jiashu Lou",
      "Baohua Wang",
      "Sixue Liu"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Artificial Intelligence (cs.AI)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2212.02721"
  },
  {
    "id": "arXiv:2212.02735",
    "title": "A Realizable GAS-based Quantum Algorithm for Traveling Salesman Problem",
    "abstract": "The paper proposes a quantum algorithm for the traveling salesman problem\n(TSP) based on the Grover Adaptive Search (GAS), which can be successfully\nexecuted on IBM's Qiskit library. Under the GAS framework, there are at least\ntwo fundamental difficulties that limit the application of quantum algorithms\nfor combinatorial optimization problems. One difficulty is that the solutions\ngiven by the quantum algorithms may not be feasible. The other difficulty is\nthat the number of qubits of current quantum computers is still very limited,\nand it cannot meet the minimum requirements for the number of qubits required\nby the algorithm. In response to the above difficulties, we designed and\nimproved the Hamiltonian Cycle Detection (HCD) oracle based on mathematical\ntheorems. It can automatically eliminate infeasible solutions during the\nexecution of the algorithm. On the other hand, we design an anchor register\nstrategy to save the usage of qubits. The strategy fully considers the\nreversibility requirement of quantum computing, overcoming the difficulty that\nthe used qubits cannot be simply overwritten or released. As a result, we\nsuccessfully implemented the numerical solution to TSP on IBM's Qiskit. For the\nseven-node TSP, we only need 31 qubits, and the success rate in obtaining the\noptimal solution is 86.71%.",
    "descriptor": "\nComments: This paper proposes a Grover Adaptive Search (GAS)-based quantum travelling salesman problem (TSP) solver that achieves the precise optimal solution within reasonable qubit usage. Simulation codes will be provided at GitHub website\n",
    "authors": [
      "Jieao Zhu",
      "Yihuai Gao",
      "Hansen Wang",
      "Tiefu Li",
      "Hao Wu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2212.02735"
  },
  {
    "id": "arXiv:2212.02748",
    "title": "An Online Newton's Method for Time-varying Linear Equality Constraints",
    "abstract": "We consider online optimization problems with time-varying linear equality\nconstraints. In this framework, an agent makes sequential decisions using only\nprior information. At every round, the agent suffers an environment-determined\nloss and must satisfy time-varying constraints. Both the loss functions and the\nconstraints can be chosen adversarially. We propose the Online Projected\nEquality-constrained Newton Method (OPEN-M) to tackle this family of problems.\nWe obtain sublinear dynamic regret and constraint violation bounds for OPEN-M\nunder mild conditions. Namely, smoothness of the loss function and boundedness\nof the inverse Hessian at the optimum are required, but not convexity. Finally,\nwe show OPEN-M outperforms state-of-the-art online constrained optimization\nalgorithms in a numerical network flow application.",
    "descriptor": "",
    "authors": [
      "Jean-Luc Lupien",
      "Antoine Lesage-Landry"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.02748"
  },
  {
    "id": "arXiv:2212.02764",
    "title": "A Trustworthy Framework for Medical Image Analysis with Deep Learning",
    "abstract": "Computer vision and machine learning are playing an increasingly important\nrole in computer-assisted diagnosis; however, the application of deep learning\nto medical imaging has challenges in data availability and data imbalance, and\nit is especially important that models for medical imaging are built to be\ntrustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning\nframework for medical image analysis, which adopts a modular design, leverages\nself-supervised pre-training, and utilizes a novel surrogate loss function.\nExperimental evaluations indicate that models generated from the framework are\nboth trustworthy and high-performing. It is anticipated that the framework will\nsupport researchers and clinicians in advancing the use of deep learning for\ndealing with public health crises including COVID-19.",
    "descriptor": "",
    "authors": [
      "Kai Ma",
      "Siyuan He",
      "Pengcheng Xi",
      "Ashkan Ebadi",
      "St\u00e9phane Tremblay",
      "Alexander Wong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02764"
  },
  {
    "id": "arXiv:2212.02768",
    "title": "Non-trivial lower bound for 3-coloring the ring in the quantum LOCAL  model",
    "abstract": "We consider the LOCAL model of distributed computing, where in a single round\nof communication each node can send to each of its neighbors a message of an\narbitrary size. It is know that, classically, the round complexity of\n3-coloring an $n$-node ring is $\\Theta(\\log^*\\!n)$. In the case where\ncommunication is quantum, only trivial bounds were known: at least some\ncommunication must take place.\nWe study distributed algorithms for coloring the ring that perform only a\nsingle round of one-way communication. Classically, such limited communication\nis already known to reduce the number of required colors from $\\Theta(n)$, when\nthere is no communication, to $\\Theta(\\log n)$. In this work, we show that the\nprobability of any quantum single-round one-way distributed algorithm to output\na proper $3$-coloring is exponentially small in $n$.",
    "descriptor": "\nComments: 26 pages, 5 figures\n",
    "authors": [
      "Fran\u00e7ois Le Gall",
      "Ansis Rosmanis"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.02768"
  },
  {
    "id": "arXiv:2212.02782",
    "title": "Self-Supervised Audio-Visual Speech Representations Learning By  Multimodal Self-Distillation",
    "abstract": "In this work, we present a novel method, named AV2vec, for learning\naudio-visual speech representations by multimodal self-distillation. AV2vec has\na student and a teacher module, in which the student performs a masked latent\nfeature regression task using the multimodal target features generated online\nby the teacher. The parameters of the teacher model are a momentum update of\nthe student. Since our target features are generated online, AV2vec needs no\niteration step like AV-HuBERT and the total training time cost is reduced to\nless than one-fifth. We further propose AV2vec-MLM in this study, which\naugments AV2vec with a masked language model (MLM)-style loss using multitask\nlearning. Our experimental results show that AV2vec achieved comparable\nperformance to the AV-HuBERT baseline. When combined with an MLM-style loss,\nAV2vec-MLM outperformed baselines and achieved the best performance on the\ndownstream tasks.",
    "descriptor": "\nComments: submitted to ICASSP 2023\n",
    "authors": [
      "Jing-Xuan Zhang",
      "Genshun Wan",
      "Zhen-Hua Ling",
      "Jia Pan",
      "Jianqing Gao",
      "Cong Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2212.02782"
  },
  {
    "id": "arXiv:2212.02805",
    "title": "Interdisciplinary Discovery of Nanomaterials Based on Convolutional  Neural Networks",
    "abstract": "The material science literature contains up-to-date and comprehensive\nscientific knowledge of materials. However, their content is unstructured and\ndiverse, resulting in a significant gap in providing sufficient information for\nmaterial design and synthesis. To this end, we used natural language processing\n(NLP) and computer vision (CV) techniques based on convolutional neural\nnetworks (CNN) to discover valuable experimental-based information about\nnanomaterials and synthesis methods in energy-material-related publications.\nOur first system, TextMaster, extracts opinions from texts and classifies them\ninto challenges and opportunities, achieving 94% and 92% accuracy,\nrespectively. Our second system, GraphMaster, realizes data extraction of\ntables and figures from publications with 98.3\\% classification accuracy and\n4.3% data extraction mean square error. Our results show that these systems\ncould assess the suitability of materials for a certain application by\nevaluation of synthesis insights and case analysis with detailed references.\nThis work offers a fresh perspective on mining knowledge from scientific\nliterature, providing a wide swatch to accelerate nanomaterial research through\nCNN.",
    "descriptor": "\nComments: Paper at NeurIPS 2022 AI for Science: Progress and Promises\n",
    "authors": [
      "Tong Xie",
      "Yuwei Wan",
      "Weijian Li",
      "Qingyuan Linghu",
      "Shaozhou Wang",
      "Yalun Cai",
      "Han Liu",
      "Chunyu Kit",
      "Clara Grazian",
      "Bram Hoex"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02805"
  },
  {
    "id": "arXiv:2212.02833",
    "title": "Metalinear structures and the substructural logic of quantum  measurements",
    "abstract": "This paper presents three classes of metalinear structures that abstract some\nof the properties of Hilbert spaces. Those structures include a binary relation\nthat expresses orthogonality between elements and enables the definition of an\noperation that generalizes the projection operation in Hilbert spaces. The\nlogic defined by the most general class has a unitary connective and two dual\nbinary connectives that are neither commutative nor associative. It is a\nsubstructural logic of sequents in which the Exchange rule is extremely limited\nand Weakening is also restricted. This provides a logic for quantum\nmeasurements whose proof theory is attractive. A completeness result is proved.\nAn additional property of the binary relation ensures that the structure\nsatisfies the MacLane-Steinitz exchange property and is some kind of matroid.\nPreliminary results on richer structures based on a sort of real inner product\nthat generalizes the Born factor of Quantum Physics are also presented.",
    "descriptor": "\nComments: 46 pages, draft to be submitted, comments and remarks welcomed to lehmann@cs.huji.ac.il\n",
    "authors": [
      "Daniel Lehmann"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.02833"
  },
  {
    "id": "arXiv:2212.02835",
    "title": "BALPA: A Balanced Primal-Dual Algorithm for Nonsmooth Optimization with  Application to Distributed Optimization",
    "abstract": "In this paper, we propose a novel primal-dual proximal splitting algorithm\n(PD-PSA), named BALPA, for the composite optimization problem with equality\nconstraints, where the loss function consists of a smooth term and a nonsmooth\nterm composed with a linear mapping. In BALPA, the dual update is designed as a\nproximal point for a time-varying quadratic function, which balances the\nimplementation of primal and dual update and retains the proximity-induced\nfeature of classic PD-PSAs. In addition, by this balance, BALPA eliminates the\ninefficiency of classic PD-PSAs for composite optimization problems in which\nthe Euclidean norm of the linear mapping or the equality constraint mapping is\nlarge. Therefore, BALPA not only inherits the advantages of simple structure\nand easy implementation of classic PD-PSAs but also ensures a fast convergence\nwhen these norms are large. Moreover, we propose a stochastic version of BALPA\n(S-BALPA) and apply the developed BALPA to distributed optimization to devise a\nnew distributed optimization algorithm. Furthermore, a comprehensive\nconvergence analysis for BALPA and S-BALPA is conducted, respectively. Finally,\nnumerical experiments demonstrate the efficiency of the proposed algorithms.",
    "descriptor": "",
    "authors": [
      "Luyao Guo",
      "Jinde Cao",
      "Xinli Shi",
      "Shaofu Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02835"
  },
  {
    "id": "arXiv:2212.02846",
    "title": "Statistical mechanics of continual learning: variational principle and  mean-field potential",
    "abstract": "An obstacle to artificial general intelligence is set by the continual\nlearning of multiple tasks of different nature. Recently, various heuristic\ntricks, both from machine learning and from neuroscience angles, were proposed,\nbut they lack a unified theory ground. Here, we focus on the continual learning\nin single-layered and multi-layered neural networks of binary weights. A\nvariational Bayesian learning setting is thus proposed, where the neural\nnetwork is trained in a field-space, rather than the gradient-ill-defined\ndiscrete-weight space, and furthermore, the weight uncertainty is naturally\nincorporated, and modulates the synaptic resources among tasks. From a physics\nperspective, we translate the variational continual learning into the\nFranz-Parisi thermodynamic potential framework, where the previous task\nknowledge acts as a prior and a reference as well. Therefore, the learning\nperformance can be analytically studied with mean-field order parameters, whose\npredictions coincide with the numerical experiments using stochastic gradient\ndescent methods. Our proposed principled frameworks also connect to elastic\nweight consolidation, and neuroscience inspired metaplasticity, providing a\ntheory-grounded method for the real-world multi-task learning with deep\nnetworks.",
    "descriptor": "\nComments: 45 pages, 7 figures\n",
    "authors": [
      "Chan Li",
      "Zhenyue Huang",
      "Wenxuan Zou",
      "Haiping Huang"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2212.02846"
  },
  {
    "id": "arXiv:2212.02854",
    "title": "Automated Segmentation of Computed Tomography Images with Submanifold  Sparse Convolutional Networks",
    "abstract": "Quantitative cancer image analysis relies on the accurate delineation of\ntumours, a very specialised and time-consuming task. For this reason, methods\nfor automated segmentation of tumours in medical imaging have been extensively\ndeveloped in recent years, being Computed Tomography one of the most popular\nimaging modalities explored. However, the large amount of 3D voxels in a\ntypical scan is prohibitive for the entire volume to be analysed at once in\nconventional hardware. To overcome this issue, the processes of downsampling\nand/or resampling are generally implemented when using traditional\nconvolutional neural networks in medical imaging. In this paper, we propose a\nnew methodology that introduces a process of sparsification of the input images\nand submanifold sparse convolutional networks as an alternative to\ndownsampling. As a proof of concept, we applied this new methodology to\nComputed Tomography images of renal cancer patients, obtaining performances of\nsegmentations of kidneys and tumours competitive with previous methods (~84.6%\nDice similarity coefficient), while achieving a significant improvement in\ncomputation time (2-3 min per training epoch).",
    "descriptor": "",
    "authors": [
      "Sa\u00fal Alonso-Monsalve",
      "Leigh H. Whitehead",
      "Adam Aurisano",
      "Lorena Escudero Sanchez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02854"
  },
  {
    "id": "arXiv:2212.02868",
    "title": "Oppressed species can form a winning pair in a multi-species ecosystem",
    "abstract": "The self-protection of alliances against external invaders is a key concept\nbehind the maintenance of biodiversity in the face of natural selection. But\nsince these alliances, which can be formed by different numbers of competitors,\ncan also compete against each other, it is important to identify their\nstrengths and weaknesses. Here, we therefore compare the vitalities of two\ntwo-species alliances whose members either beat each other mutually via a\nbidirectional invasion or they exchange their positions during an inner\ndynamics. The resulting four-species model shows rich behavior in dependence on\nthe model parameter $p$, which characterizes the inner invasions, and $\\beta$,\nwhich determines the intensity of site exchanges. In the low $p$ and the large\n$p$ limit, when the inner invasion becomes biased, three-member\nrock-scissors-paper-type solutions emerge, where one of the members is\noppressed by having the smallest average concentration due to heterogeneous\ninner invasion rates. Interestingly, however, if we allow a more intensive site\nexchange between the oppressed species, they can morph into a winning pair and\ndominate the full parameter plane. We show that their victory utilizes the\nvulnerability of the rival alliance based on cyclic dominance, where a species\ncan easily fixate a limited-size domain.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Attila Szolnoki",
      "Matjaz Perc"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computer Science and Game Theory (cs.GT)",
      "Pattern Formation and Solitons (nlin.PS)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.02868"
  },
  {
    "id": "arXiv:2212.02906",
    "title": "A Time Series Approach to Explainability for Neural Nets with  Applications to Risk-Management and Fraud Detection",
    "abstract": "Artificial intelligence is creating one of the biggest revolution across\ntechnology driven application fields. For the finance sector, it offers many\nopportunities for significant market innovation and yet broad adoption of AI\nsystems heavily relies on our trust in their outputs. Trust in technology is\nenabled by understanding the rationale behind the predictions made. To this\nend, the concept of eXplainable AI emerged introducing a suite of techniques\nattempting to explain to users how complex models arrived at a certain\ndecision. For cross-sectional data classical XAI approaches can lead to\nvaluable insights about the models' inner workings, but these techniques\ngenerally cannot cope well with longitudinal data (time series) in the presence\nof dependence structure and non-stationarity. We here propose a novel XAI\ntechnique for deep learning methods which preserves and exploits the natural\ntime ordering of the data.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Marc Wildi",
      "Branka Hadji Misheva"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2212.02906"
  },
  {
    "id": "arXiv:2212.02922",
    "title": "Consensus of Double Integrator Multiagent Systems under Nonuniform  Sampling and Changing Topology",
    "abstract": "This article considers consensus problem of multiagent systems with double\nintegrator dynamics under nonuniform sampling. It is considered the maximum\nsampling time can be selected arbitrarily. Moreover, the communication graph\ncan change to any possible topology as long as its associated graph Laplacian\nhas eigenvalues in a given region, which can be selected arbitrarily. Existence\nof a controller that ensures consensus in this setting is shown when the\nchanging topology graphs are balanced and has a spanning tree. Also, explicit\nbounds for controller parameters are given. A novel sufficient condition is\ngiven to solve the consensus problem based on making the closed loop system\nmatrix a contraction using a particular coordinate system for general linear\ndynamics. It is shown that the given condition immediately generalizes to\nchanging topology in the case of balanced topology graphs. This condition is\napplied to double integrator dynamics to obtain explicit bounds on the\ncontroller.",
    "descriptor": "\nComments: 16 pages, 3 figures, under review for a peer-reviewed journal\n",
    "authors": [
      "Ufuk Sevim",
      "Leyla Goren-Sumer"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2212.02922"
  },
  {
    "id": "arXiv:2212.02939",
    "title": "Evaluation of particle motions in stabilized specimens of transparent  sand using deep learning segmentation",
    "abstract": "Individual particle rotation and displacement were measured in triaxial tests\non transparent sand stabilized with geogrid simulants. The Cellpose U-Net\nmodel, originally developed to segment biological cells, was trained to segment\nimages of fused quartz particles. The Score-CAM metric from the field of\nExplainable AI was used to validate the application of Cellpose to segment\nparticles of fused quartz. These segmented particles were characterized in\nterms of Fourier shape descriptors and tracked across images. The measured\nparticle displacements in the monotonic triaxial tests correlated with\ndisplacement fields from Digital Image Correlation (DIC). In contrast to DIC,\nthe new technique also allows for the measurement of individual particle\nrotation. The particle rotation measurements were found to be repeatable across\ndifferent specimens. A state boundary line between probable and improbable\nparticle motions could be identified for a given test based on the measured\nparticle displacements and rotations. The size of the zone of probable motions\nwas used to quantify the effectiveness of the stabilizing inclusions. The\nresults of repeated load tests revealed that the honeycomb inclusions used\nstabilized the specimens by reducing both particle displacements and rotations.",
    "descriptor": "",
    "authors": [
      "David Marx",
      "Krishna Kumar",
      "Jorge Zornberg"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02939"
  },
  {
    "id": "arXiv:2212.02989",
    "title": "A new eye segmentation method based on improved U2Net in TCM eye  diagnosis",
    "abstract": "For the diagnosis of Chinese medicine, tongue segmentation has reached a\nfairly mature point, but it has little application in the eye diagnosis of\nChinese medicine.First, this time we propose Res-UNet based on the architecture\nof the U2Net network, and use the Data Enhancement Toolkit based on small\ndatasets, Finally, the feature blocks after noise reduction are fused with the\nhigh-level features.Finally, the number of network parameters and inference\ntime are used as evaluation indicators to evaluate the model. At the same time,\ndifferent eye data segmentation frames were compared using Miou, Precision,\nRecall, F1-Score and FLOPS. To convince people, we cite the UBIVIS. V1 public\ndataset this time, in which Miou reaches 97.8%, S-measure reaches 97.7%,\nF1-Score reaches 99.09% and for 320*320 RGB input images, the total parameter\nvolume is 167.83 MB,Due to the excessive number of parameters, we experimented\nwith a small-scale U2Net combined with a Res module with a parameter volume of\n4.63 MB, which is similar to U2Net in related indicators, which verifies the\neffectiveness of our structure.which achieves the best segmentation effect in\nall the comparison networks and lays a foundation for the application of\nsubsequent visual apparatus recognition symptoms.",
    "descriptor": "",
    "authors": [
      "Peng Hong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02989"
  },
  {
    "id": "arXiv:2212.02991",
    "title": "Proximal methods for point source localisation",
    "abstract": "Point source localisation is generally modelled as a Lasso-type problem on\nmeasures. However, optimisation methods in non-Hilbert spaces, such as the\nspace of Radon measures, are much less developed than in Hilbert spaces. Most\nnumerical algorithms for point source localisation are based on the Frank-Wolfe\nconditional gradient method, for which ad hoc convergence theory is developed.\nWe develop extensions of proximal-type methods to spaces of measures. This\nincludes forward-backward splitting, its inertial version, and primal-dual\nproximal splitting. Their convergence proofs follow standard patterns. We\ndemonstrate their numerical efficacy.",
    "descriptor": "",
    "authors": [
      "Tuomo Valkonen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02991"
  },
  {
    "id": "arXiv:2212.02996",
    "title": "BC-VAD: A Robust Bone Conduction Voice Activity Detection",
    "abstract": "Voice Activity Detection (VAD) is a fundamental module in many audio\napplications. Recent state-of-the-art VAD systems are often based on neural\nnetworks, but they require a computational budget that usually exceeds the\ncapabilities of a small battery-operated device when preserving the performance\nof larger models. In this work, we rely on the input from a bone conduction\nmicrophone (BCM) to design an efficient VAD (BC-VAD) robust against residual\nnon-stationary noises originating from the environment or speakers not wearing\nthe BCM.We first show that a larger VAD system (58k parameters) achieves\nstate-of-the-art results on a publicly available benchmark but fails when\nrunning on bone conduction signals. We then compare its variant BC-VAD (5k\nparameters and trained on BC data) with a baseline especially designed for a\nBCM and show that the proposed method achieves better performances under\nvarious metrics while keeping the realtime processing requirement for a\nmicrocontroller.",
    "descriptor": "",
    "authors": [
      "Niccolo' Polvani",
      "Damien Ronssin",
      "Milos Cernak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2212.02996"
  },
  {
    "id": "arXiv:2212.03023",
    "title": "FretNet: Continuous-Valued Pitch Contour Streaming for Polyphonic Guitar  Tablature Transcription",
    "abstract": "In recent years, the task of Automatic Music Transcription (AMT), whereby\nvarious attributes of music notes are estimated from audio, has received\nincreasing attention. At the same time, the related task of Multi-Pitch\nEstimation (MPE) remains a challenging but necessary component of almost all\nAMT approaches, even if only implicitly. In the context of AMT, pitch\ninformation is typically quantized to the nominal pitches of the Western music\nscale. Even in more general contexts, MPE systems typically produce pitch\npredictions with some degree of quantization. In certain applications of AMT,\nsuch as Guitar Tablature Transcription (GTT), it is more meaningful to estimate\ncontinuous-valued pitch contours. Guitar tablature has the capacity to\nrepresent various playing techniques, some of which involve pitch modulation.\nContemporary approaches to AMT do not adequately address pitch modulation, and\noffer only less quantization at the expense of more model complexity. In this\npaper, we present a GTT formulation that estimates continuous-valued pitch\ncontours, grouping them according to their string and fret of origin. We\ndemonstrate that for this task, the proposed method significantly improves the\nresolution of MPE and simultaneously yields tablature estimation results\ncompetitive with baseline models.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Frank Cwitkowitz",
      "Toni Hirvonen",
      "Anssi Klapuri"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2212.03023"
  },
  {
    "id": "arXiv:2212.03027",
    "title": "On Zero-Knowledge Proofs over the Quantum Internet",
    "abstract": "This paper presents a new method for quantum identity authentication (QIA)\nprotocols. The logic of classical zero-knowledge proofs (ZKPs) due to Schnorr\nis applied in quantum circuits and algorithms. This novel approach gives an\nexact way with which a prover $P$ can prove they know some secret without\ntransmitting that directly to a verifier $V$ by means of a quantum channel -\nallowing for a ZKP wherein an eavesdropper or manipulation can be detected with\na `fail safe' design. With the anticipated advent of a `quantum internet', such\nprotocols and ideas may soon have utility and execution in the real world.",
    "descriptor": "\nComments: 3 pages, no figures or tables\n",
    "authors": [
      "Mark Carney"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2212.03027"
  },
  {
    "id": "arXiv:2212.03082",
    "title": "Semi-supervised Learning with Robust Loss in Brain Segmentation",
    "abstract": "In this work, we used a semi-supervised learning method to train deep\nlearning model that can segment the brain MRI images. The semi-supervised model\nuses less labeled data, and the performance is competitive with the supervised\nmodel with full labeled data. This framework could reduce the cost of labeling\nMRI images. We also introduced robust loss to reduce the noise effects of\ninaccurate labels generated in semi-supervised learning.",
    "descriptor": "",
    "authors": [
      "Hedong Zhang",
      "Anand A. Joshi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.03082"
  },
  {
    "id": "arXiv:2212.03094",
    "title": "Which products activate a product? An explainable machine learning  approach",
    "abstract": "Tree-based machine learning algorithms provide the most precise assessment of\nthe feasibility for a country to export a target product given its export\nbasket. However, the high number of parameters involved prevents a\nstraightforward interpretation of the results and, in turn, the explainability\nof policy indications. In this paper, we propose a procedure to statistically\nvalidate the importance of the products used in the feasibility assessment. In\nthis way, we are able to identify which products, called explainers,\nsignificantly increase the probability to export a target product in the near\nfuture. The explainers naturally identify a low dimensional representation, the\nFeature Importance Product Space, that enhances the interpretability of the\nrecommendations and provides out-of-sample forecasts of the export baskets of\ncountries. Interestingly, we detect a positive correlation between the\ncomplexity of a product and the complexity of its explainers.",
    "descriptor": "",
    "authors": [
      "Massimiliano Fessina",
      "Giambattista Albora",
      "Andrea Tacchella",
      "Andrea Zaccaria"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03094"
  },
  {
    "id": "arXiv:2212.03120",
    "title": "Towards a Better Understanding of the Characteristics of Fractal  Networks",
    "abstract": "The fractal nature of complex networks has received a great deal of research\ninterest in the last two decades. Similarly to geometric fractals, the\nfractality of networks can also be defined with the so-called box-covering\nmethod. A network is called fractal if the minimum number of boxes needed to\ncover the entire network follows a power-law relation with the size of the\nboxes. The fractality of networks has been associated with various network\nproperties throughout the years, for example, disassortativity, repulsion\nbetween hubs, long-range-repulsive correlation, and small edge betweenness\ncentralities. However, these assertions are usually based on tailor-made\nnetwork models and on a small number of real networks, hence their ubiquity is\noften disputed.\nSince fractal networks have been shown to have important properties, such as\nrobustness against intentional attacks, it is in dire need to uncover the\nunderlying mechanisms causing fractality. Hence, the main goal of this work is\nto get a better understanding of the origins of fractality in complex networks.\nTo this end, we systematically review the previous results on the relationship\nbetween various network characteristics and fractality. Moreover, we perform a\ncomprehensive analysis of these relations on five network models and a large\nnumber of real-world networks originating from six domains. We clarify which\ncharacteristics are universally present in fractal networks and which features\nare just artifacts or coincidences.",
    "descriptor": "",
    "authors": [
      "Enik\u0151 Zakar-Poly\u00e1k",
      "Marcell Nagy",
      "Roland Molontay"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Discrete Mathematics (cs.DM)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2212.03120"
  },
  {
    "id": "arXiv:2212.03121",
    "title": "On the Size of Chromatic Delaunay Mosaics",
    "abstract": "Given a locally finite set $A \\subseteq \\mathbb{R}^d$ and a coloring $\\chi\n\\colon A \\to \\{0,1,\\ldots,s\\}$, we introduce the chromatic Delaunay mosaic of\n$\\chi$, which is a Delaunay mosaic in $\\mathbb{R}^{s+d}$ that represents how\npoints of different colors mingle. Our main results are bounds on the size of\nthe chromatic Delaunay mosaic, in which we assume that $d$ and $s$ are\nconstants. For example, if $A$ is finite with $n = \\#{A}$, and the coloring is\nrandom, then the chromatic Delaunay mosaic has $O(n^{\\lceil{d/2}\\rceil})$ cells\nin expectation. In contrast, for Delone sets and Poisson point processes in\n$\\mathbb{R}^d$, the expected number of cells within a closed ball is only a\nconstant times the number of points in this ball. Furthermore, in\n$\\mathbb{R}^2$ all colorings of a dense set of $n$ points have chromatic\nDelaunay mosaics of size $O(n)$. This encourages the use of chromatic Delaunay\nmosaics in applications.",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Ranita Biswas",
      "Sebastiano Cultrera di Montesano",
      "Ond\u0159ej Draganov",
      "Herbert Edelsbrunner",
      "Morteza Saghafian"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2212.03121"
  },
  {
    "id": "arXiv:2212.03128",
    "title": "Persistent Homology of Chromatic Alpha Complexes",
    "abstract": "Motivated by applications in medical sciences, we study finite chromatic sets\nin Euclidean space from a topological perspective. Based on persistent homology\nfor images, kernels and cokernels, we design provably stable homological\nquantifiers that describe the geometric micro- and macro-structure of how the\ncolor classes mingle. These can be efficiently computed using chromatic\nvariants of Delaunay mosaics and Alpha complexes.",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Sebastiano Cultrera di Montesano",
      "Ond\u0159ej Draganov",
      "Herbert Edelsbrunner",
      "Morteza Saghafian"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2212.03128"
  },
  {
    "id": "arXiv:2212.03156",
    "title": "Extending Snow's algorithm for computations in the finite Weyl groups",
    "abstract": "In 1990, D.Snow proposed an effective algorithm for computing the orbits of\nfinite Weyl groups. Snow's algorithm is designed for computation of weights,\n$W$-orbits and elements of the Weyl group. An extension of Snow's algorithm is\nproposed, which allows to find pairs of mutually inverse elements together with\nthe calculation of $W$-orbits in the same runtime cycle. This simplifies the\ncalculation of conjugacy classes in the Weyl group. As an example, the complete\nlist of elements of the Weyl group $W(D_4)$ obtained using the extended Snow's\nalgorithm is given. The elements of $W(D_4)$ are specified in two ways: as\nreduced expressions and as matrices of the faithful representation. We present\na partition of this group into conjugacy classes with elements specified as\nreduced expressions. Various forms are given for representatives of the\nconjugacy classes of $W(D_4)$: using Carter diagrams, using reduced expressions\nand using signed cycle-types. In the appendix, we provide an implementation of\nthe algorithm in Python.",
    "descriptor": "\nComments: 45 pages, 9 figures, 37 tables\n",
    "authors": [
      "Rafael Stekolshchik"
    ],
    "subjectives": [
      "Representation Theory (math.RT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.03156"
  },
  {
    "id": "arXiv:2212.03164",
    "title": "Discrete quantum harmonic oscillator and Kravchuk transform",
    "abstract": "We consider a particular discretization of the harmonic oscillator which\nadmits an orthogonal basis of eigenfunctions called Kravchuk functions\npossessing appealing properties from the numerical point of view. We\nanalytically prove the almost second-order convergence of these discrete\nfunctions towards Hermite functions, uniformly for large numbers of modes. We\nthen describe an efficient way to simulate these eigenfunctions and the\ncorresponding transformation. We finally show some numerical experiments\ncorroborating our different results.",
    "descriptor": "",
    "authors": [
      "Quentin Chauleur",
      "Erwan Faou"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.03164"
  },
  {
    "id": "arXiv:2212.03176",
    "title": "Domain Adaptation and Generalization on Functional Medical Images: A  Systematic Survey",
    "abstract": "Machine learning algorithms have revolutionized different fields, including\nnatural language processing, computer vision, signal processing, and medical\ndata processing. Despite the excellent capabilities of machine learning\nalgorithms in various tasks and areas, the performance of these models mainly\ndeteriorates when there is a shift in the test and training data distributions.\nThis gap occurs due to the violation of the fundamental assumption that the\ntraining and test data are independent and identically distributed (i.i.d). In\nreal-world scenarios where collecting data from all possible domains for\ntraining is costly and even impossible, the i.i.d assumption can hardly be\nsatisfied. The problem is even more severe in the case of medical images and\nsignals because it requires either expensive equipment or a meticulous\nexperimentation setup to collect data, even for a single domain. Additionally,\nthe decrease in performance may have severe consequences in the analysis of\nmedical records. As a result of such problems, the ability to generalize and\nadapt under distribution shifts (domain generalization (DG) and domain\nadaptation (DA)) is essential for the analysis of medical data. This paper\nprovides the first systematic review of DG and DA on functional brain signals\nto fill the gap of the absence of a comprehensive study in this era. We provide\ndetailed explanations and categorizations of datasets, approaches, and\narchitectures used in DG and DA on functional brain images. We further address\nthe attention-worthy future tracks in this field.",
    "descriptor": "\nComments: 41 pages, 8 figures\n",
    "authors": [
      "Gita Sarafraz",
      "Armin Behnamnia",
      "Mehran Hosseinzadeh",
      "Ali Balapour",
      "Amin Meghrazi",
      "Hamid R. Rabiee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03176"
  },
  {
    "id": "arXiv:2212.03188",
    "title": "An Unsupervised Machine Learning Approach for Ground Motion Clustering  and Selection",
    "abstract": "Clustering analysis of sequence data continues to address many applications\nin engineering design, aided with the rapid growth of machine learning in\napplied science. This paper presents an unsupervised machine learning algorithm\nto extract defining characteristics of earthquake ground-motion records, also\ncalled latent features, to aid in ground-motion clustering and selection. In\nthis context, a latent feature is a low dimensional machine-discovered spectral\ncharacteristic learned through nonlinear relationships of a neural network\nautoencoder. Clustering can be performed on the latent features and used to\nselect a representative archetypal subgroup from a large ground-motion suite.\nThe objective of efficient ground-motion selection is to choose records\nrepresentative of what the structure will probabilistically experience in its\nlifetime. Three examples are presented to validate this approach, including a\nsynthetic spectral dataset and spectra from field recorded ground-motion\nrecords. Deep embedding clustering of ground motion spectra improves on the\nresults of static feature extraction, utilizing characteristics that represent\nthe sparse spectral content of ground motions.",
    "descriptor": "\nComments: 24 pages, 15 Figures\n",
    "authors": [
      "R. Bailey Bond",
      "Pu Ren",
      "Jerome F. Hajjar",
      "Hao Sun"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03188"
  },
  {
    "id": "arXiv:2212.03223",
    "title": "Financial Risk Management on a Neutral Atom Quantum Processor",
    "abstract": "Machine Learning models capable of handling the large datasets collected in\nthe financial world can often become black boxes expensive to run. The quantum\ncomputing paradigm suggests new optimization techniques, that combined with\nclassical algorithms, may deliver competitive, faster and more interpretable\nmodels. In this work we propose a quantum-enhanced machine learning solution\nfor the prediction of credit rating downgrades, also known as fallen-angels\nforecasting in the financial risk management field. We implement this solution\non a neutral atom Quantum Processing Unit with up to 60 qubits on a real-life\ndataset. We report competitive performances against the state-of-the-art Random\nForest benchmark whilst our model achieves better interpretability and\ncomparable training times. We examine how to improve performance in the\nnear-term validating our ideas with Tensor Networks-based numerical\nsimulations.",
    "descriptor": "\nComments: 17 pages, 11 figures, 2 tables\n",
    "authors": [
      "Lucas Leclerc",
      "Luis Ortiz-Guitierrez",
      "Sebastian Grijalva",
      "Boris Albrecht",
      "Julia R. K. Cline",
      "Vincent E. Elfving",
      "Adrien Signoles",
      "Lo\u00efc Henriet",
      "Gianni Del Bimbo",
      "Usman Ayub Sheikh",
      "Maitree Shah",
      "Luc Andrea",
      "Faysal Ishtiaq",
      "Andoni Duarte",
      "Samuel Mugel",
      "Irene Caceres",
      "Michel Kurek",
      "Roman Orus",
      "Achraf Seddik",
      "Oumaima Hammammi",
      "Hacene Isselnane",
      "Didier M'tamon"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.03223"
  },
  {
    "id": "arXiv:2212.03225",
    "title": "Robust Local Stabilization of Nonlinear Systems with  Controller-Dependent Norm Bounds: A Convex Approach with Input-Output  Sampling",
    "abstract": "This letter presents a framework for synthesizing a robust full-state\nfeedback controller for systems with unknown nonlinearities. Our approach\ncharacterizes input-output behavior of the nonlinearities in terms of local\nnorm bounds using available sampled data corresponding to a known region about\nan equilibrium point. A challenge in this approach is that if the\nnonlinearities have explicit dependence on the control inputs, an a priori\nselection of the control input sampling region is required to determine the\nlocal norm bounds. This leads to a \"chicken and egg\" problem, where the local\nnorm bounds are required for controller synthesis, but the region of control\ninputs needed to be characterized cannot be known prior to synthesis of the\ncontroller. To tackle this issue, we constrain the closed-loop control inputs\nwithin the sampling region while synthesizing the controller. As the resulting\nsynthesis problem is non-convex, three semi-definite programs (SDPs) are\nobtained through convex relaxations of the main problem, and an iterative\nalgorithm is constructed using these SDPs for control synthesis. Two numerical\nexamples are included to demonstrate the effectiveness of the proposed\nalgorithm.",
    "descriptor": "\nComments: Accepted for publication in the IEEE Control Systems Letters (L-CSS)\n",
    "authors": [
      "Sze Kwan Cheah",
      "Diganta Bhattacharjee",
      "Maziar S. Hemati",
      "Ryan J. Caverly"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.03225"
  },
  {
    "id": "arXiv:1304.1511",
    "title": "A Tractable Inference Algorithm for Diagnosing Multiple Diseases",
    "abstract": "Comments: Appears in Proceedings of the Fifth Conference on Uncertainty in Artificial Intelligence (UAI1989)",
    "descriptor": "\nComments: Appears in Proceedings of the Fifth Conference on Uncertainty in Artificial Intelligence (UAI1989)\n",
    "authors": [
      "David Heckerman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1304.1511"
  },
  {
    "id": "arXiv:1807.09647",
    "title": "Variational Bayesian Reinforcement Learning with Regret Bounds",
    "abstract": "Variational Bayesian Reinforcement Learning with Regret Bounds",
    "descriptor": "",
    "authors": [
      "Brendan O'Donoghue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1807.09647"
  },
  {
    "id": "arXiv:1901.03744",
    "title": "Exponentially Faster Massively Parallel Maximal Matching",
    "abstract": "Comments: A preliminary version of this paper appeared in the proceedings of The 60th Annual IEEE Symposium on Foundations of Computer Science (FOCS 2019)",
    "descriptor": "\nComments: A preliminary version of this paper appeared in the proceedings of The 60th Annual IEEE Symposium on Foundations of Computer Science (FOCS 2019)\n",
    "authors": [
      "Soheil Behnezhad",
      "MohammadTaghi Hajiaghayi",
      "David G. Harris"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/1901.03744"
  },
  {
    "id": "arXiv:1906.06873",
    "title": "Running Time Analysis of the (1+1)-EA for Robust Linear Optimization",
    "abstract": "Comments: 17 pages, 1 table",
    "descriptor": "\nComments: 17 pages, 1 table\n",
    "authors": [
      "Chao Bian",
      "Chao Qian",
      "Ke Tang",
      "Yang Yu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1906.06873"
  },
  {
    "id": "arXiv:1910.06078",
    "title": "MUTLA: A Large-Scale Dataset for Multimodal Teaching and Learning  Analytics",
    "abstract": "Comments: 3 pages, 1 figure, 2 tables workshop paper",
    "descriptor": "\nComments: 3 pages, 1 figure, 2 tables workshop paper\n",
    "authors": [
      "Fangli Xu",
      "Lingfei Wu",
      "KP Thai",
      "Carol Hsu",
      "Wei Wang",
      "Richard Tong"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.06078"
  },
  {
    "id": "arXiv:2003.09737",
    "title": "BoostTree and BoostForest for Ensemble Learning",
    "abstract": "BoostTree and BoostForest for Ensemble Learning",
    "descriptor": "",
    "authors": [
      "Changming Zhao",
      "Dongrui Wu",
      "Jian Huang",
      "Ye Yuan",
      "Hai-Tao Zhang",
      "Ruimin Peng",
      "Zhenhua Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.09737"
  },
  {
    "id": "arXiv:2004.13077",
    "title": "Self-Supervised Attention Learning for Depth and Ego-motion Estimation",
    "abstract": "Self-Supervised Attention Learning for Depth and Ego-motion Estimation",
    "descriptor": "",
    "authors": [
      "Assem Sadek",
      "Boris Chidlovskii"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2004.13077"
  },
  {
    "id": "arXiv:2006.13659",
    "title": "Partial Information Sharing over Social Learning Networks",
    "abstract": "Partial Information Sharing over Social Learning Networks",
    "descriptor": "",
    "authors": [
      "Virginia Bordignon",
      "Vincenzo Matta",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2006.13659"
  },
  {
    "id": "arXiv:2010.07583",
    "title": "Scattering resonances in unbounded transmission problems with  sign-changing coefficient",
    "abstract": "Comments: 36 pages, 14 figures. Revision of the previous version",
    "descriptor": "\nComments: 36 pages, 14 figures. Revision of the previous version\n",
    "authors": [
      "Camille Carvalho",
      "Zo\u00efs Moitier"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2010.07583"
  },
  {
    "id": "arXiv:2011.01104",
    "title": "Efficient PAC Learning from the Crowd with Pairwise Comparisons",
    "abstract": "Comments: v3 proposes a simpler Filter algorithm, hence simpler analysis. v4 added more related works and was accepted to ICML 2022",
    "descriptor": "\nComments: v3 proposes a simpler Filter algorithm, hence simpler analysis. v4 added more related works and was accepted to ICML 2022\n",
    "authors": [
      "Shiwei Zeng",
      "Jie Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.01104"
  },
  {
    "id": "arXiv:2012.09423",
    "title": "Advanced NOMA Assisted Semi-Grant-Free Transmission Schemes for Randomly  Distributed Users",
    "abstract": "Comments: 41 pages, 9 figures",
    "descriptor": "\nComments: 41 pages, 9 figures\n",
    "authors": [
      "Huabing Lu",
      "Xianzhong Xie",
      "Zhaoyuan Shi",
      "Hongjiang Lei",
      "Helin Yang",
      "Jun Cai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.09423"
  },
  {
    "id": "arXiv:2102.11423",
    "title": "The Curious Case of Integrator Reach Sets, Part I: Basic Theory",
    "abstract": "The Curious Case of Integrator Reach Sets, Part I: Basic Theory",
    "descriptor": "",
    "authors": [
      "Shadi Haddad",
      "Abhishek Halder"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.11423"
  },
  {
    "id": "arXiv:2103.07886",
    "title": "Decomposing and colouring some locally semicomplete digraphs",
    "abstract": "Comments: Nothing new in this version, which only corrected wrongly typed author names",
    "descriptor": "\nComments: Nothing new in this version, which only corrected wrongly typed author names\n",
    "authors": [
      "Pierre Aboulker",
      "Guillaume Aubian",
      "Pierre Charbit"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2103.07886"
  },
  {
    "id": "arXiv:2103.11869",
    "title": "Robust Orthogonal Machine Learning of Treatment Effects",
    "abstract": "Robust Orthogonal Machine Learning of Treatment Effects",
    "descriptor": "",
    "authors": [
      "Yiyan Huang",
      "Cheuk Hang Leung",
      "Qi Wu",
      "Xing Yan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2103.11869"
  },
  {
    "id": "arXiv:2104.09082",
    "title": "Machine-learning-based head impact subtyping based on the spectral  densities of the measurable head kinematics",
    "abstract": "Comments: 33 pages, 5 figures",
    "descriptor": "\nComments: 33 pages, 5 figures\n",
    "authors": [
      "Xianghao Zhan",
      "Yiheng Li",
      "Yuzhe Liu",
      "Nicholas J. Cecchi",
      "Samuel J. Raymond",
      "Zhou Zhou",
      "Hossein Vahid Alizadeh",
      "Jesse Ruan",
      "Saeed Barbat",
      "Stephen Tiernan",
      "Olivier Gevaert",
      "Michael M. Zeineh",
      "Gerald A. Grant",
      "David B. Camarillo"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.09082"
  },
  {
    "id": "arXiv:2104.09760",
    "title": "HCMS: Hierarchical and Conditional Modality Selection for Efficient  Video Recognition",
    "abstract": "Comments: 18 pages, 7 figures",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Zejia Weng",
      "Zuxuan Wu",
      "Hengduo Li",
      "Jingjing Chen",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.09760"
  },
  {
    "id": "arXiv:2104.11667",
    "title": "Deep Learning for Bayesian Optimization of Scientific Problems with  High-Dimensional Structure",
    "abstract": "Comments: 32 pages, 16 figures; published in TMLR",
    "descriptor": "\nComments: 32 pages, 16 figures; published in TMLR\n",
    "authors": [
      "Samuel Kim",
      "Peter Y. Lu",
      "Charlotte Loh",
      "Jamie Smith",
      "Jasper Snoek",
      "Marin Solja\u010di\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)",
      "Chemical Physics (physics.chem-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2104.11667"
  },
  {
    "id": "arXiv:2105.05381",
    "title": "Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference  Perspective",
    "abstract": "Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference  Perspective",
    "descriptor": "",
    "authors": [
      "Shahbaz Rezaei",
      "Zubair Shafiq",
      "Xin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.05381"
  },
  {
    "id": "arXiv:2106.01866",
    "title": "Simultaneous Multi-View Object Recognition and Grasping in Open-Ended  Domains",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2103.10997",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.10997\n",
    "authors": [
      "Hamidreza Kasaei",
      "Sha Luo",
      "Remo Sasso",
      "Mohammadreza Kasaei"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01866"
  },
  {
    "id": "arXiv:2106.05350",
    "title": "Generative Feature-driven Image Replay for Continual Learning",
    "abstract": "Comments: Revised method, evaluation, and discussion",
    "descriptor": "\nComments: Revised method, evaluation, and discussion\n",
    "authors": [
      "Kevin Thandiackal",
      "Tiziano Portenier",
      "Andrea Giovannini",
      "Maria Gabrani",
      "Orcun Goksel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05350"
  },
  {
    "id": "arXiv:2106.10989",
    "title": "ImageNet Pre-training also Transfers Non-Robustness",
    "abstract": "Comments: Accepted by AAAI2023",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Jiaming Zhang",
      "Jitao Sang",
      "Qi Yi",
      "Yunfan Yang",
      "Huiwen Dong",
      "Jian Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10989"
  },
  {
    "id": "arXiv:2107.07623",
    "title": "Correlation detection in trees for planted graph alignment",
    "abstract": "Comments: 38 pages, 9 figures",
    "descriptor": "\nComments: 38 pages, 9 figures\n",
    "authors": [
      "Luca Ganassali",
      "Laurent Massouli\u00e9",
      "Marc Lelarge"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07623"
  },
  {
    "id": "arXiv:2107.09885",
    "title": "On Reconfigurability of Target Sets",
    "abstract": "Comments: 36 pages; changed according to referee suggestions; to appear in Theoretical Computer Science",
    "descriptor": "\nComments: 36 pages; changed according to referee suggestions; to appear in Theoretical Computer Science\n",
    "authors": [
      "Naoto Ohsaka"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.09885"
  },
  {
    "id": "arXiv:2108.03553",
    "title": "Self-Adversarial Disentangling for Specific Domain Adaptation",
    "abstract": "Self-Adversarial Disentangling for Specific Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Qianyu Zhou",
      "Qiqi Gu",
      "Jiangmiao Pang",
      "Xuequan Lu",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.03553"
  },
  {
    "id": "arXiv:2109.02580",
    "title": "Ultra-high Resolution Image Segmentation via Locality-aware Context  Fusion and Alternating Local Enhancement",
    "abstract": "Comments: Extension of ICCV 2021 \"From Contexts to Locality: Ultra-high Resolution Image Segmentation via Locality-aware Contextual Correlation\"",
    "descriptor": "\nComments: Extension of ICCV 2021 \"From Contexts to Locality: Ultra-high Resolution Image Segmentation via Locality-aware Contextual Correlation\"\n",
    "authors": [
      "Wenxi Liu",
      "Qi Li",
      "Xindai Lin",
      "Weixiang Yang",
      "Shengfeng He",
      "Yuanlong Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.02580"
  },
  {
    "id": "arXiv:2109.11128",
    "title": "Peg solitaire and Conway's soldiers on infinite graphs",
    "abstract": "Comments: 13 pages, 5 figures; incorporated referee comments",
    "descriptor": "\nComments: 13 pages, 5 figures; incorporated referee comments\n",
    "authors": [
      "Valentino Vito"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.11128"
  },
  {
    "id": "arXiv:2110.05044",
    "title": "Biometric Template Protection for Neural-Network-based Face Recognition  Systems: A Survey of Methods and Evaluation Techniques",
    "abstract": "Comments: Version 4 corresponds to the version of the manuscript accepted for publication in IEEE TIFS. Revisions: A few broken URLs have been fixed. Consists of: 29 pages, 2 figures, 10 tables",
    "descriptor": "\nComments: Version 4 corresponds to the version of the manuscript accepted for publication in IEEE TIFS. Revisions: A few broken URLs have been fixed. Consists of: 29 pages, 2 figures, 10 tables\n",
    "authors": [
      "Vedrana Krivoku\u0107a Hahn",
      "S\u00e9bastien Marcel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05044"
  },
  {
    "id": "arXiv:2110.08265",
    "title": "Knowledge-driven Active Learning",
    "abstract": "Comments: Submitted to the ICLR 2023 conference",
    "descriptor": "\nComments: Submitted to the ICLR 2023 conference\n",
    "authors": [
      "Gabriele Ciravegna",
      "Frederic Precioso",
      "Marco Gori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08265"
  },
  {
    "id": "arXiv:2110.09923",
    "title": "Speech Enhancement-assisted Stargan Voice Conversion in Noisy  Environments",
    "abstract": "Speech Enhancement-assisted Stargan Voice Conversion in Noisy  Environments",
    "descriptor": "",
    "authors": [
      "Yun-Ju Chan",
      "Chiang-Jen Peng",
      "Syu-Siang Wang",
      "Hsin-Min Wang",
      "Yu Tsao",
      "Tai-Shih Chi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.09923"
  },
  {
    "id": "arXiv:2110.09924",
    "title": "Speech Enhancement Based on Cyclegan with Noise-informed Training",
    "abstract": "Speech Enhancement Based on Cyclegan with Noise-informed Training",
    "descriptor": "",
    "authors": [
      "Wen-Yuan Ting",
      "Syu-Siang Wang",
      "Hsin-Li Chang",
      "Borching Su",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.09924"
  },
  {
    "id": "arXiv:2110.14317",
    "title": "Ask \"Who\", Not \"What\": Bitcoin Volatility Forecasting with Twitter Data",
    "abstract": "Comments: 11 pages, 11 figures, 6 tables. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (WSDM '23), February 27-March 3, 2023, Singapore, Singapore. ACM, New York, NY, USA",
    "descriptor": "\nComments: 11 pages, 11 figures, 6 tables. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (WSDM '23), February 27-March 3, 2023, Singapore, Singapore. ACM, New York, NY, USA\n",
    "authors": [
      "M. Eren Akbiyik",
      "Mert Erkul",
      "Killian Kaempf",
      "Vaiva Vasiliauskaite",
      "Nino Antulov-Fantulin"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.14317"
  },
  {
    "id": "arXiv:2111.01721",
    "title": "Bayes-Newton Methods for Approximate Bayesian Inference with PSD  Guarantees",
    "abstract": "Comments: Code for methods and experiments: this https URL",
    "descriptor": "\nComments: Code for methods and experiments: this https URL\n",
    "authors": [
      "William J. Wilkinson",
      "Simo S\u00e4rkk\u00e4",
      "Arno Solin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01721"
  },
  {
    "id": "arXiv:2111.05504",
    "title": "Collocation approximation by deep neural ReLU networks for parametric  elliptic PDEs with lognormal inputs",
    "abstract": "Collocation approximation by deep neural ReLU networks for parametric  elliptic PDEs with lognormal inputs",
    "descriptor": "",
    "authors": [
      "Dinh D\u0169ng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.05504"
  },
  {
    "id": "arXiv:2111.06091",
    "title": "A Survey of Visual Transformers",
    "abstract": "Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS)",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS)\n",
    "authors": [
      "Yang Liu",
      "Yao Zhang",
      "Yixin Wang",
      "Feng Hou",
      "Jin Yuan",
      "Jiang Tian",
      "Yang Zhang",
      "Zhongchao Shi",
      "Jianping Fan",
      "Zhiqiang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06091"
  },
  {
    "id": "arXiv:2111.08131",
    "title": "Quantum soundness of testing tensor codes",
    "abstract": "Comments: v3: published version",
    "descriptor": "\nComments: v3: published version\n",
    "authors": [
      "Zhengfeng Ji",
      "Anand Natarajan",
      "Thomas Vidick",
      "John Wright",
      "Henry Yuen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Operator Algebras (math.OA)"
    ],
    "url": "https://arxiv.org/abs/2111.08131"
  },
  {
    "id": "arXiv:2112.08772",
    "title": "Sharpness-Aware Minimization with Dynamic Reweighting",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Wenxuan Zhou",
      "Fangyu Liu",
      "Huan Zhang",
      "Muhao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08772"
  },
  {
    "id": "arXiv:2112.09429",
    "title": "Federated Learning with Superquantile Aggregation for Heterogeneous Data",
    "abstract": "Comments: Machine Learning Journal, Special Issue on Safe and Fair Machine Learning (To appear)",
    "descriptor": "\nComments: Machine Learning Journal, Special Issue on Safe and Fair Machine Learning (To appear)\n",
    "authors": [
      "Krishna Pillutla",
      "Yassine Laguel",
      "J\u00e9r\u00f4me Malick",
      "Zaid Harchaoui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.09429"
  },
  {
    "id": "arXiv:2112.09549",
    "title": "Channel Characterization and Performance of a 3-D Molecular  Communication System with Multiple Fully-Absorbing Receivers",
    "abstract": "Channel Characterization and Performance of a 3-D Molecular  Communication System with Multiple Fully-Absorbing Receivers",
    "descriptor": "",
    "authors": [
      "Nithin V. Sabu",
      "Abhishek K. Gupta",
      "Neeraj Varshney",
      "Anshuman Jindal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.09549"
  },
  {
    "id": "arXiv:2112.11317",
    "title": "Deep Learning Based Cloud Cover Parameterization for ICON",
    "abstract": "Comments: 42 pages, 17 figures, Submitted to 'Journal of Advances in Modeling Earth Systems' (JAMES)",
    "descriptor": "\nComments: 42 pages, 17 figures, Submitted to 'Journal of Advances in Modeling Earth Systems' (JAMES)\n",
    "authors": [
      "Arthur Grundner",
      "Tom Beucler",
      "Pierre Gentine",
      "Fernando Iglesias-Suarez",
      "Marco A. Giorgetta",
      "Veronika Eyring"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.11317"
  },
  {
    "id": "arXiv:2112.13257",
    "title": "A Fast Row-Stochastic Decentralized Optimization Method Over Directed  Graphs",
    "abstract": "A Fast Row-Stochastic Decentralized Optimization Method Over Directed  Graphs",
    "descriptor": "",
    "authors": [
      "Diyako Ghaderyan",
      "Necdet Serhat Aybat",
      "A. Pedro Aguiar",
      "Fernando Lobo Pereira"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.13257"
  },
  {
    "id": "arXiv:2201.04603",
    "title": "Characterizations of families of morphisms and words via binomial  complexities",
    "abstract": "Comments: 35 pages, 2 figures. Short version under a different title: M. Rigo, M. Stipulanti, and M. A. Whiteland. Binomial complexities and Parikh-collinear morphisms. In V. Diekert and M. V. Volkov, editors, DLT 2022, volume 13257 of LNCS, 251-262. Springer, 2022. doi:10.1007/978-3-031-05578-2\\_20",
    "descriptor": "\nComments: 35 pages, 2 figures. Short version under a different title: M. Rigo, M. Stipulanti, and M. A. Whiteland. Binomial complexities and Parikh-collinear morphisms. In V. Diekert and M. V. Volkov, editors, DLT 2022, volume 13257 of LNCS, 251-262. Springer, 2022. doi:10.1007/978-3-031-05578-2\\_20\n",
    "authors": [
      "Michel Rigo",
      "Manon Stipulanti",
      "Markus A. Whiteland"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2201.04603"
  },
  {
    "id": "arXiv:2201.05767",
    "title": "Ensemble Transformer for Efficient and Accurate Ranking Tasks: an  Application to Question Answering Systems",
    "abstract": "Comments: Accepted to EMNLP 2022 as a long paper (Findings). Model code is available at this https URL",
    "descriptor": "\nComments: Accepted to EMNLP 2022 as a long paper (Findings). Model code is available at this https URL\n",
    "authors": [
      "Yoshitomo Matsubara",
      "Luca Soldaini",
      "Eric Lind",
      "Alessandro Moschitti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.05767"
  },
  {
    "id": "arXiv:2201.06475",
    "title": "Infinite Hex is a draw",
    "abstract": "Comments: 28 pages, 36 figures. Commentary and inquires can be made at this http URL",
    "descriptor": "\nComments: 28 pages, 36 figures. Commentary and inquires can be made at this http URL\n",
    "authors": [
      "Joel David Hamkins",
      "Davide Leonessi"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computer Science and Game Theory (cs.GT)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.06475"
  },
  {
    "id": "arXiv:2201.11329",
    "title": "Block-encoding dense and full-rank kernels using hierarchical matrices:  applications in quantum numerical linear algebra",
    "abstract": "Comments: Published version",
    "descriptor": "\nComments: Published version\n",
    "authors": [
      "Quynh T. Nguyen",
      "Bobak T. Kiani",
      "Seth Lloyd"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11329"
  },
  {
    "id": "arXiv:2201.13099",
    "title": "How Vulnerable is an Undirected Planar Graph with respect to Max Flow",
    "abstract": "Comments: 20 pages, 13 figures",
    "descriptor": "\nComments: 20 pages, 13 figures\n",
    "authors": [
      "Lorenzo Balzotti",
      "Paolo G. Franciosa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.13099"
  },
  {
    "id": "arXiv:2201.13243",
    "title": "FastIoT -- A framework and holistic approach for rapid development of  IIoT systems",
    "abstract": "FastIoT -- A framework and holistic approach for rapid development of  IIoT systems",
    "descriptor": "",
    "authors": [
      "Tilman Klaeger",
      "Konstantin Merker"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.13243"
  },
  {
    "id": "arXiv:2202.03834",
    "title": "Managing Sets of Flying Base Stations Using Energy Efficient 3D  Trajectory Planning in Cellular Networks",
    "abstract": "Comments: This paper is a draft of a submitted paper to the IEEE Sensors journal",
    "descriptor": "\nComments: This paper is a draft of a submitted paper to the IEEE Sensors journal\n",
    "authors": [
      "Mohammad Javad Sobouti",
      "Amir Hossein Mohajerzadeh",
      "Seyed Amin Hosseini Seno",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03834"
  },
  {
    "id": "arXiv:2202.08780",
    "title": "Selling Information in Competitive Environments",
    "abstract": "Selling Information in Competitive Environments",
    "descriptor": "",
    "authors": [
      "Alessandro Bonatti",
      "Munther Dahleh",
      "Thibaut Horel",
      "Amir Nouripour"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.08780"
  },
  {
    "id": "arXiv:2203.00054",
    "title": "LISA: Learning Interpretable Skill Abstractions from Language",
    "abstract": "Comments: NeurIPS 2022. Website: this https URL",
    "descriptor": "\nComments: NeurIPS 2022. Website: this https URL\n",
    "authors": [
      "Divyansh Garg",
      "Skanda Vaidyanath",
      "Kuno Kim",
      "Jiaming Song",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.00054"
  },
  {
    "id": "arXiv:2203.00633",
    "title": "Transformer Grammars: Augmenting Transformer Language Models with  Syntactic Inductive Biases at Scale",
    "abstract": "Comments: 17 pages, 5 figures, 2 tables and 1 algorithm. To appear in TACL, to be presented at EMNLP 2022",
    "descriptor": "\nComments: 17 pages, 5 figures, 2 tables and 1 algorithm. To appear in TACL, to be presented at EMNLP 2022\n",
    "authors": [
      "Laurent Sartran",
      "Samuel Barrett",
      "Adhiguna Kuncoro",
      "Milo\u0161 Stanojevi\u0107",
      "Phil Blunsom",
      "Chris Dyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.00633"
  },
  {
    "id": "arXiv:2203.16634",
    "title": "Transformer Language Models without Positional Encodings Still Learn  Positional Information",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Adi Haviv",
      "Ori Ram",
      "Ofir Press",
      "Peter Izsak",
      "Omer Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16634"
  },
  {
    "id": "arXiv:2203.16816",
    "title": "Budget-Constrained Auctions with Unassured Priors: Strategic Equivalence  and Structural Properties",
    "abstract": "Comments: 52 pages, 4 figures, 2 tables. A thorough re-writing of the manuscript",
    "descriptor": "\nComments: 52 pages, 4 figures, 2 tables. A thorough re-writing of the manuscript\n",
    "authors": [
      "Zhaohua Chen",
      "Xiaotie Deng",
      "Jicheng Li",
      "Chang Wang",
      "Mingwei Yang",
      "Zheng Cai",
      "Yukun Ren",
      "Zhihua Zhu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2203.16816"
  },
  {
    "id": "arXiv:2203.16940",
    "title": "Direction of Arrival Estimation of Sound Sources Using Icosahedral CNNs",
    "abstract": "Comments: The code to reproduce this work can be found in our GitHub repository: this https URL",
    "descriptor": "\nComments: The code to reproduce this work can be found in our GitHub repository: this https URL\n",
    "authors": [
      "David Diaz-Guerra",
      "Antonio Miguel",
      "Jose R. Beltran"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16940"
  },
  {
    "id": "arXiv:2204.03789",
    "title": "Broadening AI Ethics Narratives: An Indic Art View",
    "abstract": "Broadening AI Ethics Narratives: An Indic Art View",
    "descriptor": "",
    "authors": [
      "Ajay Divakaran",
      "Aparna Sridhar",
      "Ramya Srinivasan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.03789"
  },
  {
    "id": "arXiv:2204.03865",
    "title": "Frequency Selective Augmentation for Video Representation Learning",
    "abstract": "Comments: AAAI23",
    "descriptor": "\nComments: AAAI23\n",
    "authors": [
      "Jinhyung Kim",
      "Taeoh Kim",
      "Minho Shim",
      "Dongyoon Han",
      "Dongyoon Wee",
      "Junmo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03865"
  },
  {
    "id": "arXiv:2204.04238",
    "title": "Elastic shape analysis of surfaces with second-order Sobolev metrics: a  comprehensive numerical framework",
    "abstract": "Comments: 28 pages, 16 figures, 2 tables",
    "descriptor": "\nComments: 28 pages, 16 figures, 2 tables\n",
    "authors": [
      "Emmanuel Hartman",
      "Yashil Sukurdeep",
      "Eric Klassen",
      "Nicolas Charon",
      "Martin Bauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04238"
  },
  {
    "id": "arXiv:2204.07874",
    "title": "Ergo, SMIRK is Safe: A Safety Case for a Machine Learning Component in a  Pedestrian Automatic Emergency Brake System",
    "abstract": "Comments: Accepted for publication in Software Quality Journal",
    "descriptor": "\nComments: Accepted for publication in Software Quality Journal\n",
    "authors": [
      "Markus Borg",
      "Jens Henriksson",
      "Kasper Socha",
      "Olof Lennartsson",
      "Elias Sonnsj\u00f6 L\u00f6negren",
      "Thanh Bui",
      "Piotr Tomaszewski",
      "Sankar Raman Sathyamoorthy",
      "Sebastian Brink",
      "Mahshid Helali Moghadam"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07874"
  },
  {
    "id": "arXiv:2204.08471",
    "title": "AI for human assessment: What do professional assessors need?",
    "abstract": "Comments: To appear in Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (Case Study)",
    "descriptor": "\nComments: To appear in Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (Case Study)\n",
    "authors": [
      "Riku Arakawa",
      "Hiromu Yakura"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08471"
  },
  {
    "id": "arXiv:2204.09911",
    "title": "STFT-Domain Neural Speech Enhancement with Very Low Algorithmic Latency",
    "abstract": "Comments: in IEEE/ACM Transactions on Audio, Speech, and Language Processing",
    "descriptor": "\nComments: in IEEE/ACM Transactions on Audio, Speech, and Language Processing\n",
    "authors": [
      "Zhong-Qiu Wang",
      "Gordon Wichern",
      "Shinji Watanabe",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.09911"
  },
  {
    "id": "arXiv:2204.10184",
    "title": "INSPIRE: Distributed Bayesian Optimization for ImproviNg SPatIal REuse  in Dense WLANs",
    "abstract": "INSPIRE: Distributed Bayesian Optimization for ImproviNg SPatIal REuse  in Dense WLANs",
    "descriptor": "",
    "authors": [
      "Anthony Bardou",
      "Thomas Begin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.10184"
  },
  {
    "id": "arXiv:2204.10923",
    "title": "You Only Linearize Once: Tangents Transpose to Gradients",
    "abstract": "You Only Linearize Once: Tangents Transpose to Gradients",
    "descriptor": "",
    "authors": [
      "Alexey Radul",
      "Adam Paszke",
      "Roy Frostig",
      "Matthew Johnson",
      "Dougal Maclaurin"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2204.10923"
  },
  {
    "id": "arXiv:2204.11505",
    "title": "Offline and online energy-efficient monitoring of scattered uncertain  logs using a bounding model",
    "abstract": "Comments: This is the author version of the manuscript published in the proceedings of FORTE 2022 AND THE EXTENDED VERSION submitted to LMCS because arXiv does not want to separate these versions. This work is partially supported by the ANR-NRF French-Singaporean research program ProMiS (ANR-19-CE25-0015), and the National Science Foundation (NSF) of the United States of America under grant number 2038960",
    "descriptor": "\nComments: This is the author version of the manuscript published in the proceedings of FORTE 2022 AND THE EXTENDED VERSION submitted to LMCS because arXiv does not want to separate these versions. This work is partially supported by the ANR-NRF French-Singaporean research program ProMiS (ANR-19-CE25-0015), and the National Science Foundation (NSF) of the United States of America under grant number 2038960\n",
    "authors": [
      "Bineet Ghosh",
      "\u00c9tienne Andr\u00e9"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.11505"
  },
  {
    "id": "arXiv:2204.11964",
    "title": "SceneTrilogy: On Human Scene-Sketch and its Complementarity with Photo  and Text",
    "abstract": "SceneTrilogy: On Human Scene-Sketch and its Complementarity with Photo  and Text",
    "descriptor": "",
    "authors": [
      "Pinaki Nath Chowdhury",
      "Ayan Kumar Bhunia",
      "Aneeshan Sain",
      "Subhadeep Koley",
      "Tao Xiang",
      "Yi-Zhe Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.11964"
  },
  {
    "id": "arXiv:2205.00180",
    "title": "Katana: Dual Slicing-Based Context for Learning Bug Fixes",
    "abstract": "Katana: Dual Slicing-Based Context for Learning Bug Fixes",
    "descriptor": "",
    "authors": [
      "Mifta Sintaha",
      "Noor Nashid",
      "Ali Mesbah"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.00180"
  },
  {
    "id": "arXiv:2205.01733",
    "title": "Application of belief functions to medical image segmentation: A review",
    "abstract": "Comments: Accepted by Information fusion",
    "descriptor": "\nComments: Accepted by Information fusion\n",
    "authors": [
      "Ling Huang",
      "Su Ruan",
      "Thierry Denoeux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01733"
  },
  {
    "id": "arXiv:2205.08491",
    "title": "Elon Musk's Twitter Takeover: Politician Accounts",
    "abstract": "Elon Musk's Twitter Takeover: Politician Accounts",
    "descriptor": "",
    "authors": [
      "Veli Safak",
      "Aniish Sridhar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.08491"
  },
  {
    "id": "arXiv:2205.14337",
    "title": "List-Decodable Sparse Mean Estimation",
    "abstract": "Comments: v2 introduces low-degree polynomials to improve error rate, and is accepted to NeurIPS 2022",
    "descriptor": "\nComments: v2 introduces low-degree polynomials to improve error rate, and is accepted to NeurIPS 2022\n",
    "authors": [
      "Shiwei Zeng",
      "Jie Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14337"
  },
  {
    "id": "arXiv:2205.15050",
    "title": "Multi-fidelity robust controller design with gradient sampling",
    "abstract": "Comments: 28 pages, 4 figures",
    "descriptor": "\nComments: 28 pages, 4 figures\n",
    "authors": [
      "Steffen W. R. Werner",
      "Michael L. Overton",
      "Benjamin Peherstorfer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15050"
  },
  {
    "id": "arXiv:2206.00052",
    "title": "CodeAttack: Code-based Adversarial Attacks for Pre-Trained Programming  Language Models",
    "abstract": "CodeAttack: Code-based Adversarial Attacks for Pre-Trained Programming  Language Models",
    "descriptor": "",
    "authors": [
      "Akshita Jha",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.00052"
  },
  {
    "id": "arXiv:2206.00060",
    "title": "Universal Early Warning Signals of Phase Transitions in Climate Systems",
    "abstract": "Universal Early Warning Signals of Phase Transitions in Climate Systems",
    "descriptor": "",
    "authors": [
      "Daniel Dylewsky",
      "Timothy M. Lenton",
      "Marten Scheffer",
      "Thomas M. Bury",
      "Christopher G. Fletcher",
      "Madhur Anand",
      "Chris T. Bauch"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.00060"
  },
  {
    "id": "arXiv:2206.00702",
    "title": "Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal  Search",
    "abstract": "Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal  Search",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Zawalski",
      "Micha\u0142 Tyrolski",
      "Konrad Czechowski",
      "Damian Stachura",
      "Piotr Pi\u0119kos",
      "Tomasz Odrzyg\u00f3\u017ad\u017a",
      "Yuhuai Wu",
      "\u0141ukasz Kuci\u0144ski",
      "Piotr Mi\u0142o\u015b"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00702"
  },
  {
    "id": "arXiv:2206.02405",
    "title": "Robust Image Protection Countering Cropping Manipulation",
    "abstract": "Comments: Redo some of the experiments to re-evaluate the role of KD-JPEG in robustness",
    "descriptor": "\nComments: Redo some of the experiments to re-evaluate the role of KD-JPEG in robustness\n",
    "authors": [
      "Qichao Ying",
      "Hang Zhou",
      "Zhenxing Qian",
      "Sheng Li",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02405"
  },
  {
    "id": "arXiv:2206.04356",
    "title": "A Simple Unified Approach to Testing High-Dimensional Conditional  Independences for Categorical and Ordinal Data",
    "abstract": "A Simple Unified Approach to Testing High-Dimensional Conditional  Independences for Categorical and Ordinal Data",
    "descriptor": "",
    "authors": [
      "Ankur Ankan",
      "Johannes Textor"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04356"
  },
  {
    "id": "arXiv:2206.06460",
    "title": "MetaTPTrans: A Meta Learning Approach for Multilingual Code  Representation Learning",
    "abstract": "Comments: Accepted by AAAI 2023",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Weiguo Pian",
      "Hanyu Peng",
      "Xunzhu Tang",
      "Tiezhu Sun",
      "Haoye Tian",
      "Andrew Habib",
      "Jacques Klein",
      "Tegawend\u00e9 F. Bissyand\u00e9"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06460"
  },
  {
    "id": "arXiv:2206.07234",
    "title": "Brownian Noise Reduction: Maximizing Privacy Subject to Accuracy  Constraints",
    "abstract": "Comments: 18 pages, 4 figures",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Justin Whitehouse",
      "Zhiwei Steven Wu",
      "Aaditya Ramdas",
      "Ryan Rogers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.07234"
  },
  {
    "id": "arXiv:2206.07275",
    "title": "CARD: Classification and Regression Diffusion Models",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Xizewen Han",
      "Huangjie Zheng",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.07275"
  },
  {
    "id": "arXiv:2207.01524",
    "title": "Variational Neural Networks",
    "abstract": "Comments: 5 pages, 2 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 5 pages, 2 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Illia Oleksiienko",
      "Dat Thanh Tran",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.01524"
  },
  {
    "id": "arXiv:2207.07417",
    "title": "Near-Linear Time and Fixed-Parameter Tractable Algorithms for Tensor  Decompositions",
    "abstract": "Near-Linear Time and Fixed-Parameter Tractable Algorithms for Tensor  Decompositions",
    "descriptor": "",
    "authors": [
      "Arvind V. Mahankali",
      "David P. Woodruff",
      "Ziyu Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.07417"
  },
  {
    "id": "arXiv:2207.09844",
    "title": "Stability and interpolation properties for Stokes-like virtual element  spaces",
    "abstract": "Stability and interpolation properties for Stokes-like virtual element  spaces",
    "descriptor": "",
    "authors": [
      "L. Beir\u00e3o da Veiga",
      "L. Mascotto",
      "J. Meng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.09844"
  },
  {
    "id": "arXiv:2207.10911",
    "title": "Jacobi polynomials and design theory I",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Himadri Shekhar Chakraborty",
      "Tsuyoshi Miezaki",
      "Manabu Oura",
      "Yuuho Tanaka"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)",
      "Group Theory (math.GR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2207.10911"
  },
  {
    "id": "arXiv:2207.11514",
    "title": "Semantic Abstraction: Open-World 3D Scene Understanding from 2D  Vision-Language Models",
    "abstract": "Comments: 16 pages, 9 figures, project website at this https URL",
    "descriptor": "\nComments: 16 pages, 9 figures, project website at this https URL\n",
    "authors": [
      "Huy Ha",
      "Shuran Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.11514"
  },
  {
    "id": "arXiv:2207.13050",
    "title": "Efficient High-Resolution Deep Learning: A Survey",
    "abstract": "Efficient High-Resolution Deep Learning: A Survey",
    "descriptor": "",
    "authors": [
      "Arian Bakhtiarnia",
      "Qi Zhang",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.13050"
  },
  {
    "id": "arXiv:2207.13395",
    "title": "A Direct Construction of 2D-CCC with Arbitrary Array Size and Flexible  Set Size Using Multivariable Function",
    "abstract": "A Direct Construction of 2D-CCC with Arbitrary Array Size and Flexible  Set Size Using Multivariable Function",
    "descriptor": "",
    "authors": [
      "Gobinda Ghosh",
      "Sudhan Majhi",
      "Ashish Kumar Upadhyay"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.13395"
  },
  {
    "id": "arXiv:2208.02313",
    "title": "Image-based Detection of Surface Defects in Concrete during Construction",
    "abstract": "Image-based Detection of Surface Defects in Concrete during Construction",
    "descriptor": "",
    "authors": [
      "Dominik Kuhnke",
      "Monika Kwiatkowski",
      "Olaf Hellwich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.02313"
  },
  {
    "id": "arXiv:2208.05282",
    "title": "Deep Reinforcement Learning for Orchestrating Cost-Aware  Reconfigurations of vRANs",
    "abstract": "Comments: The manuscript has been submitted to IEEE for possible publication",
    "descriptor": "\nComments: The manuscript has been submitted to IEEE for possible publication\n",
    "authors": [
      "Fahri Wisnu Murti",
      "Samad Ali",
      "George Iosifidis",
      "Matti Latva-aho"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.05282"
  },
  {
    "id": "arXiv:2208.08865",
    "title": "Lessons from a Space Lab -- An Image Acquisition Perspective",
    "abstract": "Lessons from a Space Lab -- An Image Acquisition Perspective",
    "descriptor": "",
    "authors": [
      "Leo Pauly",
      "Michele Lynn Jamrozik",
      "Miguel Ortiz Del Castillo",
      "Olivia Borgue",
      "Inder Pal Singh",
      "Mohatashem Reyaz Makhdoomi",
      "Olga-Orsalia Christidi-Loumpasefski",
      "Vincent Gaudilliere",
      "Carol Martinez",
      "Arunkumar Rathinam",
      "Andreas Hein",
      "Miguel Olivares-Mendez",
      "Djamila Aouada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2208.08865"
  },
  {
    "id": "arXiv:2208.09591",
    "title": "Diffusion Models Beat GANs on Topology Optimization",
    "abstract": "Diffusion Models Beat GANs on Topology Optimization",
    "descriptor": "",
    "authors": [
      "Fran\u00e7ois Maz\u00e9",
      "Faez Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2208.09591"
  },
  {
    "id": "arXiv:2208.12210",
    "title": "Learning Relational Causal Models with Cycles through Relational  Acyclification",
    "abstract": "Learning Relational Causal Models with Cycles through Relational  Acyclification",
    "descriptor": "",
    "authors": [
      "Ragib Ahsan",
      "David Arbour",
      "Elena Zheleva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.12210"
  },
  {
    "id": "arXiv:2208.13930",
    "title": "SAFE: Sensitivity-Aware Features for Out-of-Distribution Object  Detection",
    "abstract": "SAFE: Sensitivity-Aware Features for Out-of-Distribution Object  Detection",
    "descriptor": "",
    "authors": [
      "Samuel Wilson",
      "Tobias Fischer",
      "Feras Dayoub",
      "Dimity Miller",
      "Niko S\u00fcnderhauf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.13930"
  },
  {
    "id": "arXiv:2208.14037",
    "title": "Towards Artificial Virtuous Agents: Games, Dilemmas and Machine Learning",
    "abstract": "Comments: Revision of manuscript. Clarified philosophical aspects and other important terminologies. Submitted to AI and Ethics journal",
    "descriptor": "\nComments: Revision of manuscript. Clarified philosophical aspects and other important terminologies. Submitted to AI and Ethics journal\n",
    "authors": [
      "Ajay Vishwanath",
      "Einar Duenger B\u00f8hn",
      "Ole-Christoffer Granmo",
      "Charl Maree",
      "Christian Omlin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.14037"
  },
  {
    "id": "arXiv:2208.14153",
    "title": "Identifying Weight-Variant Latent Causal Models",
    "abstract": "Identifying Weight-Variant Latent Causal Models",
    "descriptor": "",
    "authors": [
      "Yuhang Liu",
      "Zhen Zhang",
      "Dong Gong",
      "Mingming Gong",
      "Biwei Huang",
      "Anton van den Hengel",
      "Kun Zhang",
      "Javen Qinfeng Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.14153"
  },
  {
    "id": "arXiv:2209.01635",
    "title": "Towards Adaptive Storage Views in Virtual Memory",
    "abstract": "Towards Adaptive Storage Views in Virtual Memory",
    "descriptor": "",
    "authors": [
      "Felix Schuhknecht",
      "Justus Henneberg"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2209.01635"
  },
  {
    "id": "arXiv:2209.02422",
    "title": "Jeopardy: An Invertible Functional Programming Language",
    "abstract": "Comments: Paper submitted to 34th Symposium on Implementation and Application of Functional Languages, Aug 31--Sep 2, 2022, Copenhagen, DK",
    "descriptor": "\nComments: Paper submitted to 34th Symposium on Implementation and Application of Functional Languages, Aug 31--Sep 2, 2022, Copenhagen, DK\n",
    "authors": [
      "Joachim Tilsted Kristensen",
      "Robin Kaarsgaard",
      "Michael Kirkedal Thomsen"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.02422"
  },
  {
    "id": "arXiv:2209.04587",
    "title": "Bayesian Algorithm Execution for Tuning Particle Accelerator Emittance  with a Virtual Objective",
    "abstract": "Bayesian Algorithm Execution for Tuning Particle Accelerator Emittance  with a Virtual Objective",
    "descriptor": "",
    "authors": [
      "Sara A. Miskovich",
      "Willie Neiswanger",
      "William Colocho",
      "Claudio Emma",
      "Jacqueline Garrahan",
      "Timothy Maxwell",
      "Christopher Mayes",
      "Stefano Ermon",
      "Auralee Edelen",
      "Daniel Ratner"
    ],
    "subjectives": [
      "Accelerator Physics (physics.acc-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.04587"
  },
  {
    "id": "arXiv:2209.07687",
    "title": "Comprehensive Evaluation of Emergency Shelters in Wuhan City Based on  GIS",
    "abstract": "Comments: Accepted to the 29th International Conference on Geoinformatics",
    "descriptor": "\nComments: Accepted to the 29th International Conference on Geoinformatics\n",
    "authors": [
      "Tingyu Luo",
      "Boheng Li",
      "Qingxiang Meng"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.07687"
  },
  {
    "id": "arXiv:2209.08893",
    "title": "A Secure Authentication Framework to Guarantee the Traceability of  Avatars in Metaverse",
    "abstract": "Comments: 13 pages, 12 figures",
    "descriptor": "\nComments: 13 pages, 12 figures\n",
    "authors": [
      "Kedi Yang",
      "Zhenyong Zhang",
      "Youliang Tian",
      "Jianfeng Ma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.08893"
  },
  {
    "id": "arXiv:2209.09056",
    "title": "Concept Embedding Models: Beyond the Accuracy-Explainability Trade-Off",
    "abstract": "Comments: To appear at NeurIPS 2022",
    "descriptor": "\nComments: To appear at NeurIPS 2022\n",
    "authors": [
      "Mateo Espinosa Zarlenga",
      "Pietro Barbiero",
      "Gabriele Ciravegna",
      "Giuseppe Marra",
      "Francesco Giannini",
      "Michelangelo Diligenti",
      "Zohreh Shams",
      "Frederic Precioso",
      "Stefano Melacci",
      "Adrian Weller",
      "Pietro Lio",
      "Mateja Jamnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.09056"
  },
  {
    "id": "arXiv:2209.09131",
    "title": "Optimized Design Method for Satellite Constellation Configuration Based  on Real-time Coverage Area Evaluation",
    "abstract": "Comments: Accepted to the 29th International Conference on Geoinformatics",
    "descriptor": "\nComments: Accepted to the 29th International Conference on Geoinformatics\n",
    "authors": [
      "Jiahao Zhou",
      "Boheng Li",
      "Qingxiang Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2209.09131"
  },
  {
    "id": "arXiv:2209.09358",
    "title": "Development of a Modular and Submersible Soft Robotic Arm and  Corresponding Learned Kinematics Models",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "W. David Null"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.09358"
  },
  {
    "id": "arXiv:2209.10080",
    "title": "Deep Double Descent via Smooth Interpolation",
    "abstract": "Deep Double Descent via Smooth Interpolation",
    "descriptor": "",
    "authors": [
      "Matteo Gamba",
      "Erik Englesson",
      "M\u00e5rten Bj\u00f6rkman",
      "Hossein Azizpour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.10080"
  },
  {
    "id": "arXiv:2209.10584",
    "title": "Continuous Mixtures of Tractable Probabilistic Models",
    "abstract": "Continuous Mixtures of Tractable Probabilistic Models",
    "descriptor": "",
    "authors": [
      "Alvaro H.C. Correia",
      "Gennaro Gala",
      "Erik Quaeghebeur",
      "Cassio de Campos",
      "Robert Peharz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.10584"
  },
  {
    "id": "arXiv:2209.11518",
    "title": "Marine Video Kit: A New Marine Video Dataset for Content-based Analysis  and Retrieval",
    "abstract": "Comments: Camera Ready for MMM 2023, Bergen, Norway",
    "descriptor": "\nComments: Camera Ready for MMM 2023, Bergen, Norway\n",
    "authors": [
      "Quang-Trung Truong",
      "Tuan-Anh Vu",
      "Tan-Sang Ha",
      "Lokoc Jakub",
      "Yue Him Wong Tim",
      "Ajay Joneja",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.11518"
  },
  {
    "id": "arXiv:2209.12429",
    "title": "Online Submodular Coordination with Bounded Tracking Regret: Theory,  Algorithm, and Applications to Multi-Robot Coordination",
    "abstract": "Online Submodular Coordination with Bounded Tracking Regret: Theory,  Algorithm, and Applications to Multi-Robot Coordination",
    "descriptor": "",
    "authors": [
      "Zirui Xu",
      "Hongyu Zhou",
      "Vasileios Tzoumas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.12429"
  },
  {
    "id": "arXiv:2209.12581",
    "title": "Two-Tailed Averaging: Anytime Adaptive Once-in-a-while Optimal Iterate  Averaging for Stochastic Optimization",
    "abstract": "Two-Tailed Averaging: Anytime Adaptive Once-in-a-while Optimal Iterate  Averaging for Stochastic Optimization",
    "descriptor": "",
    "authors": [
      "G\u00e1bor Melis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.12581"
  },
  {
    "id": "arXiv:2210.00178",
    "title": "On the tightness of linear relaxation based robustness certification  methods",
    "abstract": "On the tightness of linear relaxation based robustness certification  methods",
    "descriptor": "",
    "authors": [
      "Cheng Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00178"
  },
  {
    "id": "arXiv:2210.01705",
    "title": "Tensor-reduced atomic density representations",
    "abstract": "Comments: 6 pages, 3 figures",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "James P. Darby",
      "D\u00e1vid P. Kov\u00e1cs",
      "Ilyes Batatia",
      "Miguel A. Caro",
      "Gus L. W. Hart",
      "Christoph Ortner",
      "G\u00e1bor Cs\u00e1nyi"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01705"
  },
  {
    "id": "arXiv:2210.02615",
    "title": "Learning to Reason With Relational Abstractions",
    "abstract": "Learning to Reason With Relational Abstractions",
    "descriptor": "",
    "authors": [
      "Andrew J. Nam",
      "Mengye Ren",
      "Chelsea Finn",
      "James L. McClelland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02615"
  },
  {
    "id": "arXiv:2210.04168",
    "title": "Galaxy Spin Classification I: Z-wise vs S-wise Spirals With Chirality  Equivariant Residual Network",
    "abstract": "Comments: 13+4 pages, 11 figures, 2 tables, accepted by ApJ",
    "descriptor": "\nComments: 13+4 pages, 11 figures, 2 tables, accepted by ApJ\n",
    "authors": [
      "He Jia",
      "Hong-Ming Zhu",
      "Ue-Li Pen"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04168"
  },
  {
    "id": "arXiv:2210.05756",
    "title": "Streaming Punctuation for Long-form Dictation with Transformers",
    "abstract": "Streaming Punctuation for Long-form Dictation with Transformers",
    "descriptor": "",
    "authors": [
      "Piyush Behre",
      "Sharman Tan",
      "Padma Varadharajan",
      "Shuangyu Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.05756"
  },
  {
    "id": "arXiv:2210.05938",
    "title": "Robust Models are less Over-Confident",
    "abstract": "Comments: accepted at NeurIPS 2022",
    "descriptor": "\nComments: accepted at NeurIPS 2022\n",
    "authors": [
      "Julia Grabinski",
      "Paul Gavrikov",
      "Janis Keuper",
      "Margret Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05938"
  },
  {
    "id": "arXiv:2210.07128",
    "title": "Language Models of Code are Few-Shot Commonsense Learners",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Aman Madaan",
      "Shuyan Zhou",
      "Uri Alon",
      "Yiming Yang",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07128"
  },
  {
    "id": "arXiv:2210.08350",
    "title": "Self-Improving SLAM in Dynamic Environments: Learning When to Mask",
    "abstract": "Comments: Accepted to BMVC 2022. Dataset link: this https URL",
    "descriptor": "\nComments: Accepted to BMVC 2022. Dataset link: this https URL\n",
    "authors": [
      "Adrian Bojko",
      "Romain Dupont",
      "Mohamed Tamaazousti",
      "Herv\u00e9 Le Borgne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08350"
  },
  {
    "id": "arXiv:2210.13291",
    "title": "NVIDIA FLARE: Federated Learning from Simulation to Real-World",
    "abstract": "Comments: Accepted at the International Workshop on Federated Learning, NeurIPS 2022, New Orleans, USA (this https URL); Revised version v2: added Key Components list, system metrics for homomorphic encryption experiment",
    "descriptor": "\nComments: Accepted at the International Workshop on Federated Learning, NeurIPS 2022, New Orleans, USA (this https URL); Revised version v2: added Key Components list, system metrics for homomorphic encryption experiment\n",
    "authors": [
      "Holger R. Roth",
      "Yan Cheng",
      "Yuhong Wen",
      "Isaac Yang",
      "Ziyue Xu",
      "Yuan-Ting Hsieh",
      "Kristopher Kersten",
      "Ahmed Harouni",
      "Can Zhao",
      "Kevin Lu",
      "Zhihong Zhang",
      "Wenqi Li",
      "Andriy Myronenko",
      "Dong Yang",
      "Sean Yang",
      "Nicola Rieke",
      "Abood Quraini",
      "Chester Chen",
      "Daguang Xu",
      "Nic Ma",
      "Prerna Dogra",
      "Mona Flores",
      "Andrew Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Networking and Internet Architecture (cs.NI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.13291"
  },
  {
    "id": "arXiv:2210.14616",
    "title": "A Late Multi-Modal Fusion Model for Detecting Hybrid Spam E-mail",
    "abstract": "Comments: Accepted by 2023 the 2nd International Conference on Mechatronics and Electrical Engineering (MEEE 2023)",
    "descriptor": "\nComments: Accepted by 2023 the 2nd International Conference on Mechatronics and Electrical Engineering (MEEE 2023)\n",
    "authors": [
      "Zhibo Zhang",
      "Ernesto Damiani",
      "Hussam Al Hamadi",
      "Chan Yeob Yeun",
      "Fatma Taher"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14616"
  },
  {
    "id": "arXiv:2210.15336",
    "title": "Multi-class Detection of Pathological Speech with Latent Features: How  does it perform on unseen data?",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Dominik Wagner",
      "Ilja Baumann",
      "Franziska Braun",
      "Sebastian P. Bayerl",
      "Elmar N\u00f6th",
      "Korbinian Riedhammer",
      "Tobias Bocklet"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15336"
  },
  {
    "id": "arXiv:2210.15615",
    "title": "ACES: Translation Accuracy Challenge Sets for Evaluating Machine  Translation Metrics",
    "abstract": "Comments: preprint for WMT 2022 with updated tables",
    "descriptor": "\nComments: preprint for WMT 2022 with updated tables\n",
    "authors": [
      "Chantal Amrhein",
      "Nikita Moghe",
      "Liane Guillou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15615"
  },
  {
    "id": "arXiv:2210.15889",
    "title": "Towards Data-and Knowledge-Driven Artificial Intelligence: A Survey on  Neuro-Symbolic Computing",
    "abstract": "Comments: Ongoing project",
    "descriptor": "\nComments: Ongoing project\n",
    "authors": [
      "Wenguan Wang",
      "Yi Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15889"
  },
  {
    "id": "arXiv:2211.00111",
    "title": "Unsafe's Betrayal: Abusing Unsafe Rust in Binary Reverse Engineering via  Machine Learning",
    "abstract": "Unsafe's Betrayal: Abusing Unsafe Rust in Binary Reverse Engineering via  Machine Learning",
    "descriptor": "",
    "authors": [
      "Sangdon Park",
      "Xiang Cheng",
      "Taesoo Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.00111"
  },
  {
    "id": "arXiv:2211.00414",
    "title": "Using coevolution and substitution of the fittest for health and  well-being recommender systems",
    "abstract": "Comments: 16 pages, 11 figures. arXiv admin note: substantial text overlap with arXiv:2108.03156",
    "descriptor": "\nComments: 16 pages, 11 figures. arXiv admin note: substantial text overlap with arXiv:2108.03156\n",
    "authors": [
      "Hugo Alcaraz-Herrera",
      "John Cartlidge"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00414"
  },
  {
    "id": "arXiv:2211.01287",
    "title": "Evaluating Impact of Social Media Posts by Executives on Stock Prices",
    "abstract": "Comments: Accepted at the 14th meeting of Forum for Information Retrieval Evaluation (FIRE-2022)",
    "descriptor": "\nComments: Accepted at the 14th meeting of Forum for Information Retrieval Evaluation (FIRE-2022)\n",
    "authors": [
      "Anubhav Sarkar",
      "Swagata Chakraborty",
      "Sohom Ghosh",
      "Sudip Kumar Naskar"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.01287"
  },
  {
    "id": "arXiv:2211.04041",
    "title": "ParticleNeRF: A Particle-Based Encoding for Online Neural Radiance  Fields in Dynamic Scenes",
    "abstract": "ParticleNeRF: A Particle-Based Encoding for Online Neural Radiance  Fields in Dynamic Scenes",
    "descriptor": "",
    "authors": [
      "Jad Abou-Chakra",
      "Feras Dayoub",
      "Niko S\u00fcnderhauf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04041"
  },
  {
    "id": "arXiv:2211.04583",
    "title": "Wall Street Tree Search: Risk-Aware Planning for Offline Reinforcement  Learning",
    "abstract": "Comments: Accepted to Foundation Models for Decision Making (FMDM) Workshop at 36th Conference on Neural Information Processing Systems (NeurIPS)",
    "descriptor": "\nComments: Accepted to Foundation Models for Decision Making (FMDM) Workshop at 36th Conference on Neural Information Processing Systems (NeurIPS)\n",
    "authors": [
      "Dan Elbaz",
      "Gal Novik",
      "Oren Salzman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04583"
  },
  {
    "id": "arXiv:2211.05244",
    "title": "Deep Learning for Time Series Anomaly Detection: A Survey",
    "abstract": "Deep Learning for Time Series Anomaly Detection: A Survey",
    "descriptor": "",
    "authors": [
      "Zahra Zamanzadeh Darban",
      "Geoffrey I. Webb",
      "Shirui Pan",
      "Charu C. Aggarwal",
      "Mahsa Salehi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05244"
  },
  {
    "id": "arXiv:2211.07267",
    "title": "The Best Path Algorithm automatic variables selection via High  Dimensional Graphical Models",
    "abstract": "The Best Path Algorithm automatic variables selection via High  Dimensional Graphical Models",
    "descriptor": "",
    "authors": [
      "Luigi Riso",
      "Maria G. Zoia",
      "Consuelo R. Nava"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07267"
  },
  {
    "id": "arXiv:2211.08285",
    "title": "Identifying Spurious Correlations and Correcting them with an  Explanation-based Learning",
    "abstract": "Comments: Presented at the NeurIPS 2022 workshop on Human-in-the-Loop Learning (HILL)",
    "descriptor": "\nComments: Presented at the NeurIPS 2022 workshop on Human-in-the-Loop Learning (HILL)\n",
    "authors": [
      "Misgina Tsighe Hagos",
      "Kathleen M. Curran",
      "Brian Mac Namee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08285"
  },
  {
    "id": "arXiv:2211.08451",
    "title": "kogito: A Commonsense Knowledge Inference Toolkit",
    "abstract": "Comments: 8 pages. Submitted to EACL",
    "descriptor": "\nComments: 8 pages. Submitted to EACL\n",
    "authors": [
      "Mete Ismayilzada",
      "Antoine Bosselut"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08451"
  },
  {
    "id": "arXiv:2211.08718",
    "title": "Topology of cognitive maps",
    "abstract": "Comments: 27 pages, 23 figures",
    "descriptor": "\nComments: 27 pages, 23 figures\n",
    "authors": [
      "Konstantin Sorokin",
      "Anton Ayzenberg",
      "Konstantin Anokhin",
      "Vladimir Sotskov",
      "Maxim Beketov",
      "Andrey Zaitsew",
      "Robert Drynkin"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.08718"
  },
  {
    "id": "arXiv:2211.08771",
    "title": "On the symmetries in the dynamics of wide two-layer neural networks",
    "abstract": "On the symmetries in the dynamics of wide two-layer neural networks",
    "descriptor": "",
    "authors": [
      "Karl Hajjar",
      "Lenaic Chizat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08771"
  },
  {
    "id": "arXiv:2211.08842",
    "title": "Fast and Accurate FSA System Using ELBERT: An Efficient and Lightweight  BERT",
    "abstract": "Fast and Accurate FSA System Using ELBERT: An Efficient and Lightweight  BERT",
    "descriptor": "",
    "authors": [
      "Siyuan Lu",
      "Chenchen Zhou",
      "Keli Xie",
      "Jun Lin",
      "Zhongfeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08842"
  },
  {
    "id": "arXiv:2211.09783",
    "title": "UniSumm: Unified Few-shot Summarization with Multi-Task Pre-Training and  Prefix-Tuning",
    "abstract": "UniSumm: Unified Few-shot Summarization with Multi-Task Pre-Training and  Prefix-Tuning",
    "descriptor": "",
    "authors": [
      "Yulong Chen",
      "Yang Liu",
      "Ruochen Xu",
      "Ziyi Yang",
      "Chenguang Zhu",
      "Michael Zeng",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09783"
  },
  {
    "id": "arXiv:2211.11024",
    "title": "Deterministic Identification For MC ISI-Poisson Channel",
    "abstract": "Comments: 29 pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2203.02784",
    "descriptor": "\nComments: 29 pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2203.02784\n",
    "authors": [
      "Mohammad Javad Salariseddigh",
      "Vahid Jamali",
      "Uzi Pereg",
      "Holger Boche",
      "Christian Deppe",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.11024"
  },
  {
    "id": "arXiv:2211.11059",
    "title": "Coarse-to-fine Task-driven Inpainting for Geoscience Images",
    "abstract": "Coarse-to-fine Task-driven Inpainting for Geoscience Images",
    "descriptor": "",
    "authors": [
      "Huiming Sun",
      "Jin Ma",
      "Qing Guo",
      "Qin Zou",
      "Shaoyue Song",
      "Yuewei Lin",
      "Hongkai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11059"
  },
  {
    "id": "arXiv:2211.12205",
    "title": "Utopia: Efficient Address Translation using Hybrid Virtual-to-Physical  Address Mapping",
    "abstract": "Utopia: Efficient Address Translation using Hybrid Virtual-to-Physical  Address Mapping",
    "descriptor": "",
    "authors": [
      "Konstantinos Kanellopoulos",
      "Rahul Bera",
      "Kosta Stojiljkovic",
      "Can Firtina",
      "Rachata Ausavarungnirun",
      "Nastaran Hajinazar",
      "Jisung Park",
      "Nandita Vijaykumar",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.12205"
  },
  {
    "id": "arXiv:2211.12921",
    "title": "Hybrid Learning of Time-Series Inverse Dynamics Models for Locally  Isotropic Robot Motion",
    "abstract": "Comments: Accepted for publication in IEEE Robotics and Automation Letters ( see this https URL ). 8 pages, 8 figures",
    "descriptor": "\nComments: Accepted for publication in IEEE Robotics and Automation Letters ( see this https URL ). 8 pages, 8 figures\n",
    "authors": [
      "Tolga-Can \u00c7allar",
      "Sven B\u00f6ttger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12921"
  },
  {
    "id": "arXiv:2211.13032",
    "title": "Monte Carlo Tree Search Algorithms for Risk-Aware and Multi-Objective  Reinforcement Learning",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2102.00966",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2102.00966\n",
    "authors": [
      "Conor F. Hayes",
      "Mathieu Reymond",
      "Diederik M. Roijers",
      "Enda Howley",
      "Patrick Mannion"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13032"
  },
  {
    "id": "arXiv:2211.13337",
    "title": "Multi-Environment Pretraining Enables Transfer to Action Limited  Datasets",
    "abstract": "Multi-Environment Pretraining Enables Transfer to Action Limited  Datasets",
    "descriptor": "",
    "authors": [
      "David Venuto",
      "Sherry Yang",
      "Pieter Abbeel",
      "Doina Precup",
      "Igor Mordatch",
      "Ofir Nachum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13337"
  },
  {
    "id": "arXiv:2211.13481",
    "title": "The Second-place Solution for CVPR 2022 SoccerNet Tracking Challenge",
    "abstract": "The Second-place Solution for CVPR 2022 SoccerNet Tracking Challenge",
    "descriptor": "",
    "authors": [
      "Fan Yang",
      "Shigeyuki Odashima",
      "Shoichi Masui",
      "Shan Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13481"
  },
  {
    "id": "arXiv:2211.13509",
    "title": "The Second-place Solution for ECCV 2022 Multiple People Tracking in  Group Dance Challenge",
    "abstract": "The Second-place Solution for ECCV 2022 Multiple People Tracking in  Group Dance Challenge",
    "descriptor": "",
    "authors": [
      "Fan Yang",
      "Shigeyuki Odashima",
      "Shoichi Masui",
      "Shan Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13509"
  },
  {
    "id": "arXiv:2211.14317",
    "title": "Hard to Track Objects with Irregular Motions and Similar Appearances?  Make It Easier by Buffering the Matching Space",
    "abstract": "Comments: Accepted to WACV 2023. arXiv admin note: text overlap with arXiv:2211.13509. text overlap with arXiv:2211.13509",
    "descriptor": "\nComments: Accepted to WACV 2023. arXiv admin note: text overlap with arXiv:2211.13509. text overlap with arXiv:2211.13509\n",
    "authors": [
      "Fan Yang",
      "Shigeyuki Odashima",
      "Shoichi Masui",
      "Shan Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.14317"
  },
  {
    "id": "arXiv:2211.14515",
    "title": "Instance-level Heterogeneous Domain Adaptation for Limited-labeled  Sketch-to-Photo Retrieval",
    "abstract": "Instance-level Heterogeneous Domain Adaptation for Limited-labeled  Sketch-to-Photo Retrieval",
    "descriptor": "",
    "authors": [
      "Fan Yang",
      "Yang Wu",
      "Zheng Wang",
      "Xiang Li",
      "Sakriani Sakti",
      "Satoshi Nakamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14515"
  },
  {
    "id": "arXiv:2211.15089",
    "title": "Continuous diffusion for categorical data",
    "abstract": "Comments: 26 pages, 8 figures; added additional references",
    "descriptor": "\nComments: 26 pages, 8 figures; added additional references\n",
    "authors": [
      "Sander Dieleman",
      "Laurent Sartran",
      "Arman Roshannai",
      "Nikolay Savinov",
      "Yaroslav Ganin",
      "Pierre H. Richemond",
      "Arnaud Doucet",
      "Robin Strudel",
      "Chris Dyer",
      "Conor Durkan",
      "Curtis Hawthorne",
      "R\u00e9mi Leblond",
      "Will Grathwohl",
      "Jonas Adler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15089"
  },
  {
    "id": "arXiv:2211.15350",
    "title": "Three classes of BCH codes and their duals",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Yanhui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.15350"
  },
  {
    "id": "arXiv:2211.15657",
    "title": "Is Conditional Generative Modeling all you need for Decision-Making?",
    "abstract": "Comments: Website: this https URL",
    "descriptor": "\nComments: Website: this https URL\n",
    "authors": [
      "Anurag Ajay",
      "Yilun Du",
      "Abhi Gupta",
      "Joshua Tenenbaum",
      "Tommi Jaakkola",
      "Pulkit Agrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15657"
  },
  {
    "id": "arXiv:2211.16253",
    "title": "Advancing Deep Metric Learning Through Multiple Batch Norms And  Multi-Targeted Adversarial Examples",
    "abstract": "Advancing Deep Metric Learning Through Multiple Batch Norms And  Multi-Targeted Adversarial Examples",
    "descriptor": "",
    "authors": [
      "Inderjeet Singh",
      "Kazuya Kakizaki",
      "Toshinori Araki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16253"
  },
  {
    "id": "arXiv:2211.16254",
    "title": "Positivity-preserving and entropy-bounded discontinuous Galerkin method  for the chemically reacting, compressible Euler equations. Part I: The  one-dimensional case",
    "abstract": "Positivity-preserving and entropy-bounded discontinuous Galerkin method  for the chemically reacting, compressible Euler equations. Part I: The  one-dimensional case",
    "descriptor": "",
    "authors": [
      "Eric J. Ching",
      "Ryan F. Johnson",
      "Andrew D. Kercher"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.16254"
  },
  {
    "id": "arXiv:2211.16718",
    "title": "GPU-Accelerated DNS of Compressible Turbulent Flows",
    "abstract": "GPU-Accelerated DNS of Compressible Turbulent Flows",
    "descriptor": "",
    "authors": [
      "Youngdae Kim",
      "Debojyoti Ghosh",
      "Emil M. Constantinescu",
      "Ramesh Balakrishnan"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.16718"
  },
  {
    "id": "arXiv:2211.16878",
    "title": "Transformers are Short Text Classifiers: A Study of Inductive Short Text  Classifiers on Benchmarks and Real-world Datasets",
    "abstract": "Transformers are Short Text Classifiers: A Study of Inductive Short Text  Classifiers on Benchmarks and Real-world Datasets",
    "descriptor": "",
    "authors": [
      "Fabian Karl",
      "Ansgar Scherp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16878"
  },
  {
    "id": "arXiv:2211.17139",
    "title": "Multidimensional analysis using sensor arrays with deep learning for  high-precision and high-accuracy diagnosis",
    "abstract": "Comments: Corrected typo",
    "descriptor": "\nComments: Corrected typo\n",
    "authors": [
      "Julie Payette",
      "Sylvain G.Cloutier",
      "Fabrice Vaussenat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.17139"
  },
  {
    "id": "arXiv:2212.00133",
    "title": "Generative Adversarial Learning of Sinkhorn Algorithm Initializations",
    "abstract": "Comments: Updated figure. Added universality result for the generator. Improved literature review. Fixed typos. 12 pages, 7 figures",
    "descriptor": "\nComments: Updated figure. Added universality result for the generator. Improved literature review. Fixed typos. 12 pages, 7 figures\n",
    "authors": [
      "Jonathan Geuter",
      "Vaios Laschos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2212.00133"
  },
  {
    "id": "arXiv:2212.00532",
    "title": "EBHI-Seg: A Novel Enteroscope Biopsy Histopathological Haematoxylin and  Eosin Image Dataset for Image Segmentation Tasks",
    "abstract": "EBHI-Seg: A Novel Enteroscope Biopsy Histopathological Haematoxylin and  Eosin Image Dataset for Image Segmentation Tasks",
    "descriptor": "",
    "authors": [
      "Liyu Shi",
      "Xiaoyan Li",
      "Weiming Hu",
      "Haoyuan Chen",
      "Jing Chen",
      "Zizhen Fan",
      "Minghe Gao",
      "Yujie Jing",
      "Guotao Lu",
      "Deguo Ma",
      "Zhiyu Ma",
      "Qingtao Meng",
      "Dechao Tang",
      "Hongzan Sun",
      "Marcin Grzegorzek",
      "Shouliang Qi",
      "Yueyang Teng",
      "Chen Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.00532"
  },
  {
    "id": "arXiv:2212.00700",
    "title": "High Dimensional Binary Classification under Label Shift: Phase  Transition and Regularization",
    "abstract": "High Dimensional Binary Classification under Label Shift: Phase  Transition and Regularization",
    "descriptor": "",
    "authors": [
      "Jiahui Cheng",
      "Minshuo Chen",
      "Hao Liu",
      "Tuo Zhao",
      "Wenjing Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2212.00700"
  },
  {
    "id": "arXiv:2212.00800",
    "title": "The purpose of qualia: What if human thinking is not (only) information  processing?",
    "abstract": "The purpose of qualia: What if human thinking is not (only) information  processing?",
    "descriptor": "",
    "authors": [
      "Martin Korth"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.00800"
  },
  {
    "id": "arXiv:2212.01051",
    "title": "VeriX: Towards Verified Explainability of Deep Neural Networks",
    "abstract": "Comments: To appear in Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023)",
    "descriptor": "\nComments: To appear in Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023)\n",
    "authors": [
      "Min Wu",
      "Haoze Wu",
      "Clark Barrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01051"
  },
  {
    "id": "arXiv:2212.01068",
    "title": "Fast Algorithm for Constrained Linear Inverse Problems",
    "abstract": "Fast Algorithm for Constrained Linear Inverse Problems",
    "descriptor": "",
    "authors": [
      "Mohammed Rayyan Sheriff",
      "Floor Fenne Redel",
      "Peyman Mohajerin Esfahani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.01068"
  },
  {
    "id": "arXiv:2212.01099",
    "title": "Linear Data-Driven Economic MPC with Generalized Terminal Constraint",
    "abstract": "Linear Data-Driven Economic MPC with Generalized Terminal Constraint",
    "descriptor": "",
    "authors": [
      "Yifan Xie",
      "Julian Berberich",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2212.01099"
  },
  {
    "id": "arXiv:2212.01233",
    "title": "Safe machine learning model release from Trusted Research Environments:  The AI-SDC package",
    "abstract": "Safe machine learning model release from Trusted Research Environments:  The AI-SDC package",
    "descriptor": "",
    "authors": [
      "Jim Smith",
      "Richard J. Preen",
      "Andrew McCarthy",
      "Alba Crespi-Boixader",
      "James Liley",
      "Simon Rogers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2212.01233"
  },
  {
    "id": "arXiv:2212.01438",
    "title": "On the optimal rank-1 approximation of matrices in the Chebyshev norm",
    "abstract": "On the optimal rank-1 approximation of matrices in the Chebyshev norm",
    "descriptor": "",
    "authors": [
      "Stanislav Morozov",
      "Matvey Smirnov",
      "Nikolai Zamarashkin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.01438"
  },
  {
    "id": "arXiv:2212.01470",
    "title": "Prediction of Scene Plausibility",
    "abstract": "Prediction of Scene Plausibility",
    "descriptor": "",
    "authors": [
      "Or Nachmias",
      "Ohad Fried",
      "Ariel Shamir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.01470"
  },
  {
    "id": "arXiv:2212.01473",
    "title": "Parallelizing Maximal Clique Enumeration on GPUs",
    "abstract": "Parallelizing Maximal Clique Enumeration on GPUs",
    "descriptor": "",
    "authors": [
      "Mohammad Almasri",
      "Yen-Hsiang Chang",
      "Izzat El Hajj",
      "Rakesh Nagi",
      "Jinjun Xiong",
      "Wen-mei Hwu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2212.01473"
  },
  {
    "id": "arXiv:2212.01515",
    "title": "Orders Are Unwanted: Dynamic Deep Graph Convolutional Network for  Personality Detection",
    "abstract": "Comments: The current version contains some errors. We will resubmit it after revision",
    "descriptor": "\nComments: The current version contains some errors. We will resubmit it after revision\n",
    "authors": [
      "Tao Yang",
      "Jinghao Deng",
      "Xiaojun Quan",
      "Qifan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2212.01515"
  },
  {
    "id": "arXiv:2212.01546",
    "title": "UniSyn: An End-to-End Unified Model for Text-to-Speech and Singing Voice  Synthesis",
    "abstract": "UniSyn: An End-to-End Unified Model for Text-to-Speech and Singing Voice  Synthesis",
    "descriptor": "",
    "authors": [
      "Yi Lei",
      "Shan Yang",
      "Xinsheng Wang",
      "Qicong Xie",
      "Jixun Yao",
      "Lei Xie",
      "Dan Su"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2212.01546"
  },
  {
    "id": "arXiv:2212.01574",
    "title": "Calibration and generalizability of probabilistic models on low-data  chemical datasets with DIONYSUS",
    "abstract": "Comments: 15+4 pages, 9+3 figures Comments: Fix author name typo in article and meta data",
    "descriptor": "\nComments: 15+4 pages, 9+3 figures Comments: Fix author name typo in article and meta data\n",
    "authors": [
      "Gary Tom",
      "Riley J. Hickman",
      "Aniket Zinzuwadia",
      "Afshan Mohajeri",
      "Benjamin Sanchez-Lengeling",
      "Alan Aspuru-Guzik"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.01574"
  },
  {
    "id": "arXiv:2212.01615",
    "title": "OSC-Qasm: Interfacing Music Software with Quantum Computing",
    "abstract": "OSC-Qasm: Interfacing Music Software with Quantum Computing",
    "descriptor": "",
    "authors": [
      "Omar Costa Hamido",
      "Paulo Vitor Itabora\u00ed"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2212.01615"
  },
  {
    "id": "arXiv:2212.02019",
    "title": "SASFormer: Transformers for Sparsely Annotated Semantic Segmentation",
    "abstract": "Comments: 7 pages, 4 figures, 5 tables; version2.0",
    "descriptor": "\nComments: 7 pages, 4 figures, 5 tables; version2.0\n",
    "authors": [
      "Hui Su",
      "Yue Ye",
      "Wei Hua",
      "Lechao Cheng",
      "Mingli Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02019"
  },
  {
    "id": "arXiv:2212.02021",
    "title": "Analysis of Utterance Embeddings and Clustering Methods Related to  Intent Induction for Task-Oriented Dialogue",
    "abstract": "Analysis of Utterance Embeddings and Clustering Methods Related to  Intent Induction for Task-Oriented Dialogue",
    "descriptor": "",
    "authors": [
      "Jeiyoon Park",
      "Yoonna Jang",
      "Chanhee Lee",
      "Heuiseok Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2212.02021"
  },
  {
    "id": "arXiv:2212.02085",
    "title": "RGB-L: Enhancing Indirect Visual SLAM using LiDAR-based Dense Depth Maps",
    "abstract": "Comments: Accepted at ICCCR 2023",
    "descriptor": "\nComments: Accepted at ICCCR 2023\n",
    "authors": [
      "Florian Sauerbeck",
      "Benjamin Obermeier",
      "Martin Rudolph",
      "Johannes Betz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2212.02085"
  },
  {
    "id": "arXiv:2212.02229",
    "title": "GPS++: An Optimised Hybrid MPNN/Transformer for Molecular Property  Prediction",
    "abstract": "GPS++: An Optimised Hybrid MPNN/Transformer for Molecular Property  Prediction",
    "descriptor": "",
    "authors": [
      "Dominic Masters",
      "Josef Dean",
      "Kerstin Klaser",
      "Zhiyi Li",
      "Sam Maddrell-Mander",
      "Adam Sanders",
      "Hatem Helal",
      "Deniz Beker",
      "Ladislav Ramp\u00e1\u0161ek",
      "Dominique Beaini"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2212.02229"
  },
  {
    "id": "arXiv:2212.02260",
    "title": "Complementary Romanovski-Routh polynomials and their zeros",
    "abstract": "Complementary Romanovski-Routh polynomials and their zeros",
    "descriptor": "",
    "authors": [
      "Luana L. Silva Ribeiro",
      "Alagacone Sri Ranga",
      "Yen Chi Lun"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2212.02260"
  },
  {
    "id": "arXiv:2212.02264",
    "title": "Bagging is an Optimal PAC Learner",
    "abstract": "Bagging is an Optimal PAC Learner",
    "descriptor": "",
    "authors": [
      "Kasper Green Larsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2212.02264"
  },
  {
    "id": "arXiv:2212.02277",
    "title": "R2FD2: Fast and Robust Matching of Multimodal Remote Sensing Image via  Repeatable Feature Detector and Rotation-invariant Feature Descriptor",
    "abstract": "Comments: 18 pages, 14 figures",
    "descriptor": "\nComments: 18 pages, 14 figures\n",
    "authors": [
      "Bai Zhu",
      "Chao Yang",
      "Jinkun Dai",
      "Jianwei Fan",
      "Yuanxin Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02277"
  },
  {
    "id": "arXiv:2212.02375",
    "title": "D-TensoRF: Tensorial Radiance Fields for Dynamic Scenes",
    "abstract": "Comments: 21 pages, 11 figures",
    "descriptor": "\nComments: 21 pages, 11 figures\n",
    "authors": [
      "Hankyu Jang",
      "Daeyoung Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2212.02375"
  },
  {
    "id": "arXiv:2212.02494",
    "title": "Equivalence of eval-readback and eval-apply big-step evaluators by  regimentation of the lambda-calculus's strategy space",
    "abstract": "Comments: 55 pages, 10 figures",
    "descriptor": "\nComments: 55 pages, 10 figures\n",
    "authors": [
      "Pablo Nogueira",
      "\u00c1lvaro Garc\u00eda-P\u00e9rez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2212.02494"
  }
]